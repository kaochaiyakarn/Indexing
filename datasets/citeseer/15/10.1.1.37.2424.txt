statistical description visual signals david mumford bayesian statistical methods successfully applied speech recognition language parsing computer vision image analysis object recognition medical expert systems 
instances grenander general conception pattern theory statistical analysis patterned noisy distorted signals produced world 
apply ideas class signals need construct probability models observed random variables unobserved world variables caused signal need algorithms inferring high probability values unobserved variables 
talk introduce series models visual signals incorporate successively deeper layers unobserved variables 
model involves observed signal basic scale invariant gaussian process model 
model introduces local feature variables line processes belongs class markov random field models 
model introduces variables describing surfaces subsets domain image leads stochastic grammar formalisms 
class models natural stage dimensional structure world producing signal explicit 
model introduces templates learned classes objects matched observed signal pointers random variables values addresses 
examples call mixed markov models propose basic tool object recognition 
study visual signals commonly referred images process extracting meaning traditionally studied quite different groups 
group consists going back great german von helmholtz started field 
group asks animals man particular see pattern light striking retina acquire construct mental representation world front 
second group consists engineers sought david mumford computer algorithms tasks grasping objects seen video camera robot automatic navigation vehicles human drivers automatic reading medical scans rays 
david marr influential voices bringing groups 
book ma described called theory computation level problem vision animals computers 
solved different algorithms certainly different implementations different classes agents analyze components problem computational complexity unified way 
mathematician issue remains sort theory 
example ai artificial intelligence school proposed studying problem vision cognitive problems logic languages 
transcribe formal logic prolog databases facts physics light shapes objects world interact produce observed images 
propose develop heuristics efficiently searching combinatorially explosive tree combinations facts arrive high level scene description compatible observed image 
ulf grenander gre gre pioneered second approach statistics 
perspective problem learn extensive experience statistics images objects represented find fast algorithms statistical estimation random variables directly observed distance identity objects viewed observed raw retinal video signal estimation problem bayesian approach combining learned priors unobserved variables imaging model dominant approach 
statistical approach vision gaining means universally accepted 
note briefly similar trends grown related fields ffl speech recognition bayesian statistical theory hidden markov models em algorithm learning model parameters totally dominated field ffl control theory bayesian statistical tool kalman filter central technique dealing noise uncertainty ffl ai statistical theories grown importance medical expert systems see pearl lauritzen spiegelhalter pe statistical description visual signals called pac learning models probably approximately correct valiant 
article way codify statistical approach vision describing series classes probability models successively deeper layers unobserved variables incorporated 
inspiration describing various stages vision computation way came trying understand analogies vision speech language 
clearer mean series probability models successively approximate class real signals want giving samples successively refined models english developed shannon early information theory sh 
low level syntax semantics models point statistics capture great deal structure language 
random sequence english letters plus space linguistic analog white noise signal second sample model individual letter frequencies english hli eu ll th oo third sample model letter pairs correct frequency compile table probabilities events representative samples english speech prose string choosing new letter conditional probability occurence previously chosen letter st andy tobe way strings chosen randomly correct letter triple frequencies ist lay bers cre tuple frequencies generated job better displayed code hock david mumford modeling english incorporate lexicon strings valid english words correct frequency representing apt come different natural came expert gray come string correct word pair frequencies head frontal attack english writer character point method models give sense steady convergence true probabilities english speech prose 
analogs random strings vision 
explore refer back descriptions speech language comparison class visual models 
model scale invariant gaussian process fixing notation 
image simplest case shall mean rectangular array fi mg positive real numbers 
refer light intensity recorded rectangular grid receptors tv camera retina 
sample points called pixels image 
course may generalized ways pixels may spaced rectangular grid fact retina uses approximately hexagonal array fovea regular grid incident light may sampled frequency leading vector color values scalar brightness may pass continuum limit pixels wavelength 
sticking simplest case main object study probability distribution delta delta delta delta delta delta di nm dimensional space 
taken literally meant capture statistics average agent world sees moves world 
course varies agent agent visual world mouse living forest quite different professor working city seeks class probability models parameters allow agent learn environment capture regularities 
ask models infra red radar images differ radically 
simplest probability distributions high dimensional spaces gaussian ones model general form model statistical description visual signals gamma ij kl rest stands normalizing constant needed various functions probabilities 
consider image function torus zz theta zz rectangular grid ask image translate equally translation independent 
discrete fourier transform quadratic form appearing translation invariant gaussian distribution diagonalized new variables gamma gamma represents expected power spatial frequency band 
visual signals fundamental property shared types sensory signals 
distinguished scale 
means model images functions continuous variables allow scales image rescaled image oex oey equally 
reason observer moves closer scene image rescaled observer closer image enlarged factor oe away image reduced factor oe 
distance observer fixed scale 
true touch finger contact sensed object object size tactile array sensors 
audition constants frequency vocal cords set fixed scale time axis relative sound durations calibrated 
go assume rotation invariance probability distribution leads model gaussian model images unique parameter fi gammafi rr expression poses questions defined distribution scale invariant 
accepting defined sense simplest way argue formally scale invariant note independent normally distributed variables variances david mumford fi annulus plane inner radius outer radius fi fi log expected amount power spatial frequency band depends ratio high low frequencies frequencies 
hand letting high frequency cutoff go infinity find infinite amount power typical samples probability distribution continuous locally stochastic process formally defined probability distribution known physicists process supported space measurable functions sample paths taken distributions 
instance samples torus readily constructed random fourier series zz zz fi yj independent normal sequence variance mean gamma gammaj series barely measurable functions 
hand little reflection shows wouldn expect sample images functions 
imagine ray vision see face crawling leaf laws reflectance cause black white fluctuations image size arbitrarily small scale 
macroscopic scale known photographers visual world cluttered objects size photographs carefully composed emphasize composition scale 
clutter basic problem computer vision algorithms come article 
fourier series formula enables construct readily computer random samples model 
shown 
note quite reminiscent fractal everyday objects clouds see various shapes imagination lots structure 
contrast white noise quite boring featureless 
statistical description visual signals sample model image power certainly typical image world 
linguistic analogy model model english strings letter frequencies correct 
leaving model helpful inverse fourier transform express model terms original image rules fourier transform derivative see beautiful fact gammafi rr dxdy note dimension fi intensity followed expression expected power annulus involve distance confirming scale invariance model 
discrete form probability obtained replacing gradient sums adjacent pairs pixels gammafi gammai model local features markov random fields natural way improve model images model occurence gray levels adjacent pixels adjacent pixels david mumford attempt model called occurence statistics pair intensity values 
obvious thing happens images edges 
sharp discontinuities image intensity primarily caused pixel part surface object pixel part foreground background 
edges caused surface markings abrupt changes surface normal folds illumination effects shadows highlights 
clear lacks sharp edges 
simple way increase probability sudden intensity changes replace squared term gamma robust variant gamma function approximately small approaches upper bound jxj large 
examples tanh gamma gammax 
define model gammafi gammai second natural way model arises particular 
introducing auxiliary set random variables line process 
imagine rectangular grid pixels vertices graph edges linking pixel horizontally vertically adjacent neighbors 
line process function edges graph values pixels qg gamma 
assertion means bond pixels intact try equal assertion means bond broken totally independent 
may expressed formula gamma fi gammai gamma quite remarkable model suitable choice just marginal probability distribution 
precisely possible gamma gammai log gammafi gamma gamma statistical description visual signals sample model local part image line processes 
simple sample model simulated annealing hopefully long time show kind sample find 
model model scale parameter considered close scene objects visible 
having broken scale invariance model means images sampled model regarded real world images simplifications real images clutter smaller scales rejected 
observed image regarded sample model plus fine detail 
simplest way artifical assumption fine detail white noise 
leads full version model random processes observed image simplified version clutter call cartoon line process 
full probability distribution gamma gammaj oe gamma fi gammaj gamma model introduced independently geman blake zisserman 
model bayes theorem find segmentations image 
assumes uses conditional distribution induced remaining variables order find probable segmentations image 
expect elementary model incorporate knowledge world going find correct segmentation david mumford image segmentation model 
left image eye center cartoon right line process 
image multiple objects expect correct segmentation relatively high probability 
shows typical application model way 
shows real image eye estimate probable cartoon line process model 
generated algorithm approximating probable result probably optimal 
striking aspect approach prior model cartoons fj crude imaging model white noise crude results reasonable 
deficiencies prior model imaging model different sorts strengths model help weaknesses 
looking language analogies phenomenon jelinek group ibm doing machine translation similarly crude statistical models 
word triple called trigram statistics model english language strings corpus french english sentence pairs supplied canadian parliament built statistical english french dictionary example answer time noun time infinitive verb time omitted corresponding french sentence 
french sentence computed english string maximizing product delta je 
spite obvious deficiencies probability models total absence grammar rules translations correct 
strengths model compensate weaknesses 
going back table model natural vision statistical description visual signals analog english string model incorporates letter pair frequencies 
deal homogeneous regions image smoothly varying intensity sudden jumps intensity regions 
real world textured surfaces local image homogeneous particular types local statistics 
modeling analogous looking higher order letter frequency statistics 
need model higher order occurence statistics intensities local clusters pixels 
space elaborate various theories direction especially texture proved easy describe mathematically 
want describe basic mathematical formalism class models type 
basic idea introduce local feature descriptors respond certain pattern texture try group sets pixels regions local feature descriptors active 
appropriate formalism markov random field 
generality need assume random variables model observed image auxiliary local feature variables form vertices graph 
write variables fx set vertices 
edges graph supposed represent variables direct influence 
markov random field probability space random variables markov property subset fixed vertices joined path containing vertex conditionally independent 
hammersley clifford theorem equivalent probabilities gibbs formula fx gamma cliques ec clique subset vertices graph vertices joined edges term ec exponential clique 
graph markov random field model shown 
markov random field models model textured images include auxiliary vertices edges linking nearby pixels larger local neighborhoods 
shows output algorithm zhu yuille lee 
simple local statistics region growing algorithm find high probability segmentation scene 
david mumford variables variables variables graph markov random field segmenting image line process cartoon segmenting scene plains africa local texture statistics modeled markov random field 
model surface descriptors stochastic grammars local patterns structures arising markov random field create images local look feel real world image statistical description visual signals left observed image right representation set layers increasing depth 
captured 
stage explicit larger structures arise dimensional geometry world especially objects world parts surface visible image 
analogous identifying speech language larger groups letters words grammatical phrases clauses 
clear simplest example nitzberg called sketch 
note model line process implicitly defines decomposition set pixels regions 
consider set pixels joined edges edges intact line process breaks rest 
fr connected components graph 
connected regions resulting cutting apart image domain edges 
cases may objects scene may happen object appears places partly occluded nearer object 
edge nakayama calls edge sides nearer object lies accidental position farther 
strong local cue threedimensional structure 
edge vanishes edge set edges forms called junction objects seen stem object top 
example shown observed image consists potato front david mumford orange beer bottle intermediate distance background consisting cardboard box faint letters 
mentally represent scene diagram showing layers separately 
note junctions beer bottle orange disappear potato 
mathematically define sketch ordered sequence fr subsets image domain overlap ways 
assume objects projected image domain nearer background assume domain 
gamma visible part object sketch regions computed probable values variables fr precise model relies heavily junctions 
giving details model want note layered representations arise analysis binocular stereoscopic image pairs temporal image sequences 
show example wang adelson right see frames movie images left see decomposition scene layers foreground tree intermediate flower bed background house trees 
fact human infants born able segment visual signals layers basis relative motion presumably brainstem structure called superior colliculus 
develop ability segment layers stereoscopic vision ability perceive layers single images 
claim underlying sketch extremely simple stochastic grammar 
recall stochastic grammar described giving set symbols called non terminals set terminals set production rules form delta delta delta example simple class sentences may generated simple rules gamma 
np vp prob np gamma 
np prob np gamma 
prob gamma vp gamma 
verb prob gamma 
prob gamma 
noun prob np vp non terminals gamma expected number adjectives random noun phrase stand large number possible terminals lexicon probabilities frequencies occurrence various verbs adjectives nouns 
statistical description visual signals top frames movie sequence images bottom representation set layers increasing depth courtesy wang adelson 
exactly way sketch generated stochastic grammar im gamma 
frg prob frg gamma 
obj frg prob frg gamma 
obj prob gamma gamma 
prob obj gamma 
prob im frg obj non terminals gamma expected number foreground objects random image non terminals domain image subset image david mumford center percept bars front cube right percept persists bars left separates shapes occluding part bars kanizsa 
domain define probabilities gamma oe ds boundary curvature boundary ds arc length boundary oe function bx prior regions encourages regions short smooth boundaries particular try reconstruct hidden edges partially occluded objects curves minimize functional class curves invented euler called 
tied simple imaging model gamma variance get model simplest grammatical model generating global structure image 
just ordinary linguistic grammar purpose pick large subsets signal interpreted may interrupted structures 
foreground objects occluding part surface distant object relative clauses embedded larger clause 
idea grammar images invented gestalt school psychology early part century 
discovered laws grouping typically proved testing human responses elegantly constructed images 
example shown due statistical description visual signals generating grammar part description dog non terminals symbols subsets image domain corresponding terminal variables final dog silhouette medial axis 
ka 
see middle wire frame cube occluded set parallel diagonal bars 
note percept persists right edges wire frames abruptly kind junction invisible top stroke percept absent left edges wire frame joined making fragment self contained dimensional shape 
complex grammars called deal aspects images 
particular set grammatical rules decomposition complex articulated objects ribbons blobs protrusions 
ideas go back blum bl fu fu 
set non terminals infinite number realizations terminals subsets image domain ribbons produce worm shapes described axis width protrusions produce fin shapes described angular sector circle radius function angle 
give example type decomposition zhu yuille 
general characteristic grammatical models incorporate new class variable 
variables value subset image domain 
hard force markov random field framework global entities unlimited supply david mumford shelf region variables waiting called 
perfectly satisfactory mathematical point view raises big problem try imagine brain manipulates entities 
brain looked neuro anatomically hard wired graph neurons reminiscent kind graph markov random field 
model favor tries reconcile adaptive pyramid architecture sort introduced hong rosenfeld 
construction series successively coarser pixel grids levels pyramid original high resolution image bottom 
linked level lower level higher level correspondence original proposal pixel possible parents possible children making pyramid dimensional graph 
add vertical line process cut leave intact vertical links give weight pixels higher levels adaptively linked general subsets original lowest level creating subset variables 
model object templates mixed markov models final class models want discuss incorporating semantics visual signals 
semantics deals construction database individual things agent encountered categories things 
language learn names objects meanings words language correctly 
vision learn shape appearance objects clustering objects categories recognize object instances category anew robotic applications knowledge navigation grasping 
want start extremely simple example yuille hallinan cohen see image face outline eye consisting edges eyelids circle pupil drawn computer correctly 
theory goes back early fischler elschlager identify objects belonging category known variable shape observed image find pixels image set feature points model object located 
approach goes name flexible templates 
speech recognition time warping plays statistical description visual signals flexible template eye fit face image 
similar role matching expected temporal frequency pattern specific phoneme observed sound 
general imagine recognize objects learn model object called template may typical image object may cartoon points edges combination 
learn typical amount geometric variability template intensity values image match model 
recognize instance object model fit image 
extensively studied example approach known model matching 
precise geometric description object machine part factory assembly line available 
assumption object seen unknown point view unknown lighting conditions 
matching strategy employed identify edges object image various special points corners 
highly successful trick look lines straight lines image domain tangent points edge object 
solve viewpoint outlines model match reasonably closely edges detected image conditions partial occlusion entire outline model seen image 
people remarkably jigsaw puzzle ability 
difficulty recognizing objects highly dependent type object 
unoccluded alphanumeric character known font flat machine part lighting conditions lie easiest spectrum 
objects bunch possess seemingly unlimited david mumford left input face input matched warping template template warping indicated arrows right template 
note template stretched mouth area mouth input open 
variability 
case received attention applications face recognition 
intermediate difficulty faces stereotyped gray level appearance especially dependent lighting conditions small number sharp internal edges 
extensive modeling variability caused viewpoint lighting expression gross individual differences glasses facial hair subtle individual characteristics inter ocular distance shape nose identify person 
develop ideas describe model face recognition comes phd thesis peter hallinan ha ha 
quite similar model developed cootes lanitis taylor 
face edges hallinan model involves dense set feature points template face matched observed image diffeomorphism phi 
domain template domain image hand model arbitrary lighting conditions oe gray level image resulting illuminating template face spot light angle oe 
sampling face pixels gives set points oe ir take principle components cluster ir fj approximate arbitrarily illuminated faces linear combination final probability model phi oe gammac rr phi gamma dxdy gammac rr kd phi phi gammaoe dxdy phi jacobian matrix diffeomorphism phi vector statistical description visual signals eigenfaces principle components set images obtained possible illuminations face 
lighting components oe scale parameter 
prior quite crude distortions typical rotating head changing expression changing facial proportions modeled explicitly 
give example show principle probability models involving flexible templates variable illumination built 
give example warping phi show largest principle components known eigenfaces individual 
new type model 
fitting template small number feature points eye dense set involves computing pixels template points observed image pixels intensities weights boolean values addresses variables image values 
address valued random variables pointers called programming language theory 
natural way incorporate variables framework markov random fields imagine edges model hard wired may chosen run time 
formally imagine graph vertices divided groups suppose random variable vertex value variable real number value variable vertex restricted subset david mumford mixed markov models face recognition left clique kd phi ffi phi gamma oe right clique ffi phi gamma ae part definition 
effect assigning values variables fx vp augment graph new set dynamic edges 
creates new graph call set mixed markov model 
ways define gibbs distributions associated mixed markov models 
pull back definition fx gamma cliques ec jv cg jw xv value variable definition involves pulling back random variables referred dynamically members clique model includes probability model show 
quite interesting find generalization theorem mixed markov models 
blake zisserman visual reconstruction mit press 
bl blum transformation extracting new descriptors shape symp 
models perception speech visual form mit press 
fischler elschlager representation matching pictorial structures ieee trans 
computers 
fu fu syntactic pattern recognition applications prentice hall 
statistical description visual signals geiger yuille common framework image segmentation int 
comp 
vis 
geman geman stochastic relaxation gibbs distribution bayesian restoration images ieee trans 
patt 
anal 
mach 
int 
gre grenander lectures pattern theory springer verlag 
gre grenander general pattern theory oxford univ press ha hallinan low dimensional representation human faces arbitrary lighting conditions ieee conf 
comp 
vis 
patt 
rec 
ha hallinan phd thesis applied science harvard university von helmholtz physiological optics original german edition dover publ 
translation 
hong rosenfeld compact region extraction weighted pixel linking pyramid ieee trans 
patt 
anal 
mach 
int pp 
ka kanizsa organization vision praeger 
kearns vazirani computational learning theory mit press 
lanitis taylor cootes unified approach coding interpreting face images proc 
ieee th int 
conf 
comp 
vis 
ma marr vision freeman 
nitzberg mumford sketch proc 
rd ieee int 
conf comp vision 
pe pearl probabilistic reasoning intelligent systems kaufmann 
reed colella lectures constructive quantum field theory springer lecture notes physics 
sh shannon mathematical theory communication bell system tech 

david mumford wang adelson representing moving images layers ieee trans 
image proc 
yuille hallinan cohen feature extraction faces deformable templates int 
comp 
vision 
zhu lee yuille region competition unifying snake region growing bayes mdl multi band image segmentation submitted ieee trans 
patt 
anal 
mach 
int 
zhu yuille framework object representation recognition proc 
st int conf image proc 
address mumford department mathematics harvard university cambridge ma usa email mumford math harvard edu 
