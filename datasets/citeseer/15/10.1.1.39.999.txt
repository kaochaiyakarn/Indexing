generalization band joins merge purge problem mauricio hern andez salvatore stolfo mauricio cs columbia edu sal cs columbia edu department computer science columbia university new york ny problem merging multiple databases information common entities frequently encountered large commercial government organizations 
problem study called merge purge problem difficult solve scale accuracy 
large repositories data numerous duplicate information entries entities difficult cull intelligent equational theory identifies equivalent items complex matching process 
developed system accomplishing task lists names potential customers direct marketing type application 
results statistically generated data shown accurate effective processing data multiple times different keys sorting 
system provides rule programming module easy program quite finding duplicates especially environment massive amounts data 
details improvements system reports successful implementation real world database conclusively validates results previously achieved statistically generated data 
keywords band joins duplicate elimination instance identification multidatabase systems semantic integration supported part new york state science technology foundation center advanced technology telecommunications polytechnic university nsf iri 
author supported cooperative research program fellowship 
merging large databases acquired different sources heterogenous representations information increasingly important difficult problem organizations 
instances problem appearing literature called semantic integration problem instance identification problem 
consider problem large databases information need processed quickly efficiently accurately possible 
instance month typical business cycle certain direct marketing operations 
means sources data need identified acquired conditioned correlated merged small portion month order prepare response analyses 
uncommon large businesses acquire scores databases month total size hundreds millions records need analyzed days 
general setting data mining applications depend conditioned sample data multiple sources information accurate database merging operations highly desirable 
problem merging databases solved simple sort concatenated data followed duplicate elimination phase sorted list 
databases involved heterogeneous meaning share schema real world entities represented differently datasets problem merging difficult 
issue databases different schema addressed extensively literature known schema integration problem 
primarily interested second problem heterogeneous representations data implication merging joining multiple datasets 
simple way find duplicates relational databases compute equijoin naive means implementing joins compute cartesian product quadratic time process followed selection relevant tuples 
obvious optimizations parallel variants join computation known sort merge hash partitioning 
strategies assume total ordering domain join attributes index easily computable near perfect hash function provides means inspecting small partitions tuples computing join 
case study assume exists total ordering perfect hash distribution lead completely accurate result meaning slight errors data imply possible matches common data entity may 
techniques study implemented strategies fast execution particular desire improve accuracy 
errors data severe ideally expect find matching instance tuple sorted band tuples type non equijoin joins called band joins studied 
band join join relations join predicate form gamma represent join attributes respectively numeric constants 
generalize definition band joins allowing complex function just simple arithmetic predicate defined totally ordered numeric domain 
concreteness relations attrs attrs represent sets attributes respective relation 
study efficient execution queries form oe theta attrs boolean function fb attrs attrs nonempty 
function simple arithmetic predicate complex inference procedure defined mixture domains chosen attributes 
application problems generalization band joins 
probably common example merge purge version instance identification problem main case study 
merge purge ubiquitous modern commercial organizations typically solved today expensive mainframe computing solutions 
fundamental problem merge purge data supplied various sources typically include identifiers string data different different datasets simply erroneous due variety reasons including typographical transcription errors purposeful fraudulent activity aliases case names 
equality values domain common join attribute specified simple arithmetic predicate set equational axioms define equivalence equational theory 
determining records databases provide information entity highly complex 
rule knowledge base implement equational theory detailed section 
dealing large databases seek reduce complexity problem partitioning database partitions clusters way potentially matching records assigned cluster 
term cluster line common terminology statistical pattern recognition 
discuss solutions merge purge sorting entire data set bring matching records close bounded neighborhood linear list optimization basic technique seeks eliminate records sorting exact duplicate keys 
treated case clustering sorting replaced single scan process 
demonstrate may expect basic approaches guarantee high accuracy 
accuracy means actual duplicates appearing data matched merged correctly 
detail system implemented performs generic merge purge process includes declarative rule language specifying equational theory making easier experiment modify criteria equivalence 
alternative algorithms implemented fundamental merge process comparatively evaluated demonstrate single pass data particular scheme key performs computing transitive closure independent runs different key ordering data 
show example multiple passes followed computation closure consistently dominates accuracy modest performance penalty 
moral simply distinct cheap passes data produces accurate results expensive pass data 
sections detail sorted neighborhood multi pass methods previously reported 
repeated completeness exposition order set stage new improvements basic methods 
previously published alternative algorithms implemented fundamental merge process comparatively evaluated accuracy statistically generated databases 
provide detailed treatment real world data set establish validity results 
prior statistically generated databases allowed devise controlled studies optimal accuracy results known priori 
real world datasets obviously know best attainable results high precision time consuming expensive human inspection validation 
cases datasets huge may feasible 
results reported due human inspection small substantial sample data relative entire data set 
results real world data validate previous predictions quite accurate 
previous lines database community bearing efficient solutions merge purge problem 
semantic integration problem seeks identify multiplicity database objects represent related real world entity database representations different 
problem studied researchers heterogenous multi database community 
solutions merge purge problem primarily sorting database bring potentially matching tuples close neighborhood resulting sorted database 
sorting data probably oldest studied problem computer science different algorithms years 
interested sorting algorithms duplicates removed final sorted database 
date relevant area 
proposed solution merge purge problem resembles sort merge join join condition user defined equivalence function 
particular relevance merge purge solution proposed band joins 
briefly describe band joins closest solutions merge purge developed 
band joins mentioned merge purge thought relational join tables special function determines equality 
section show equality functions complex may require knowledge intensive inference return answer 
consider simple example relations contain laboratory results want find results temperature fields sigma degrees 
define temp gamma temp temp temp 
algorithms executing kind non equijoin predicate 
joins join predicate form gamma called band joins 
presents new algorithm termed partitioned band join evaluate special type joins 
partitioned band join works range partitioning relations partitions partition fits entirely memory buffer 
second relation range partitioned elements replicating tuples neighboring partitions 
example value divides buckets values gamma put partitions compute band join partition brought memory turn 
partition window pages partition read memory 
join computed pages currently memory 
tuple current window pages page read window page window discarded 
similarly tuple partition read memory 
assumed range band exceed range values window pages initial solution propose merge purge problem uses similar idea partitioned band join identify matching tuples 
main differences 
provide complex equational theory determine equivalence items considered 
equational theory simple arithmetic predicate discussed solution reduces dewitt partitioned band join 

dewitt band join assumes data easily compared numeric predicates outcome comparison categorical 
assume true cases equivalence complex inference process 
discuss section demonstrate experimental results equational theory capture tuples equivalent instances incorrectly identify tuples equivalent false positives 
aim find algorithms efficient accurate 

comparing tuples may result determination relationship remains unknown concurrently occupy band 
provide multi pass approach followed transitive closure phase increase accuracy 

propose approach original relations partitioned number disjoint subsets variety clustering methods exclusively range partitioning solution methods applied independent parallel processes 
note disjoint subset reduced complexity simply size data set reduced 
method discussed 
sorted neighborhood method reduces partitioned band join method generalization band joins 
basic solutions merge purge problem previous introduced basic sorted neighborhood method solving merge purge 
describe detail basic approach followed description variant duplicate elimination method 
basic sorted neighborhood method collection databases concatenate sequential list records conditioning records apply sorted neighborhood method 
sorted neighborhood method solving merge purge problem summarized phases 
create keys compute key record list extracting relevant fields portions fields 
choice key depends error model may current window records records window window scan merge phase viewed knowledge intensive domain specific effectiveness method highly depends properly chosen key intent common erroneous data closely matching keys 
discuss effect choice key section 
sort data sort records data list key step 
merge move fixed size window sequential list records limiting comparisons matching records records window 
size window records new record entering window compared previous gamma records find matching records 
record window slides window see 
procedure executed serially main memory process create keys phase operation sorting phase log merging phase wn number records database 
total time complexity method log dlog ne wn 
constants equations differ greatly 
relatively expensive extract relevant key values record create key phase 
sorting requires machine instructions compare keys 
merge phase requires application potentially large number rules compare records potential largest constant factor 
notice parameter window scanning procedure 
legitimate values may range consecutive elements compared element compared 
case pertains full quadratic time process maximal potential accuracy defined equational theory percentage duplicates correctly merging process 
case may viewed small constant relative pertains optimal time performance time minimal accuracy 
question optimal settings maximize accuracy minimizing computational cost 
note large databases dominant cost disk number passes data set 
case passes needed pass conditioning data preparing keys second pass high speed sort example final pass window processing application rule program record entering sliding window 
depending complexity rule program window size pass may dominant cost 
introduced means speeding phase processing parallel windows sorted list 
note interest sorts optimizations detailed may course fruitfully applied 
concerned alternative process architectures lead higher accuracies computed results reducing time complexity 
consider alternative metrics purposes merge purge include accurately merge purge fixed dollar time constraint specific cost time metrics proposed 
selection keys effectiveness sorted neighborhood method highly depends key selected sort records 
key defined sequence subset attributes substrings attributes chosen record 
example consider records displayed table 
particular application suppose key designer sorting phase determined typical data set keys extracted data provide sufficient discriminating power identifying candidates matching 
key consists concatenation ordered fields attributes data consonants name concatenated letters name field followed address number field consonants street name 
followed digits social security field 
choices key designer determined names typically misspelled due mistakes sounds vowels names typically common prone misunderstood recorded incorrectly 
keys sorting entire dataset intention equivalent matching data appear close final sorted list 
notice second records exact duplicates third person misspelled name 
expect name address id key sal stolfo street sal stolfo street sal street sal stiles forest street table example records keys phonetically mistake caught reasonable equational theory 
fourth record having exact key prior records appears person 
equational theory comparison records merge phase determine equivalence complex inferential process considers information compared records keys sorting 
example suppose person names spelled nearly identically exact address 
infer person 
hand suppose records exactly social security numbers names addresses completely different 
assume records represent person changed name moved records represent different persons social security number field incorrect 
information may assume 
information records better inferences 
example michael smith michele smith address names reasonably close 
gender age information available field data infer michael michele married siblings 
need specify inferences equational theory dictates logic domain equivalence simply value string equivalence 
users general purpose merge purge facility benefit higher level formalisms languages permitting ease experimentation modification 
reasons natural approach specifying equational theory making practical declarative rule language 
rule languages effectively wide range applications requiring inference large data sets 
research conducted provide efficient means compilation evaluation technology exploited purposes solving merge purge efficiently 
example simplified rule english exemplifies axiom equational theory relevant merge purge applied idealized employee database records 
name equals name names differ slightly address equals address equivalent 
implementation differ slightly specified english computation distance function applied name fields records comparison results threshold capture obvious typographical errors may occur data 
selection distance function proper threshold knowledge intensive activity demands experimental evaluation 
improperly chosen threshold lead increase number falsely matched records decrease number matching records merged 
number alternative distance functions typographical mistakes implemented tested experiments reported including distances edit distance phonetic distance typewriter distance 
results displayed section edit distance computation outcome program vary different distance functions particular databases study 
purpose experimental study wrote ops rule program consisting rules particular domain employee records tested repeatedly relatively small databases records 
satisfied performance rules distance functions thresholds recoded rules directly obtain speedup ops implementation 
appendix shows ops version equational theory implemented 
rules encoding knowledge equational theory shown appendix 
inference process encoded rules divided stages 
stage records window compared see similar fields social security field name field street address field 
second stage information gathered stage joined see merge pairs records 
example pair records similar social security numbers similar names rule similar ssn names declares merged 
pair records merged information gathered stage rule program takes closer look fields city name state zipcode see merge done 
third stage precise edit distance ssn name initial address lisa boardman wars st lisa brown ward st ramon ward st raymond ward st diana church av 
diana brick church av 
th st apt 
john th st ap 
florida av 
kegan florida st table example matching records detected equational theory rule base 
functions fields attempt merging pair records 
table demonstrates number actual records rule program correctly deems equivalent 
appendix shows version equational theory 
appendix shows subroutine rule program main code rule implementation comments code show rule ops version implemented 
important note essence approach proposed permits wide range equational theories various data types 
chose string data study names addresses pedagogical reasons gets faulty junk mail 
equally demonstrate concepts alternative databases different typed objects correspondingly different rule sets 
table displays records errors may commonly mailing lists junk mail example 
poor implementations merge purge task commercial organizations typically lead pieces junk mail mailed obviously greater expense household nearly experienced 
records identified rule base equivalent 
duplicate elimination sorted neighborhood method previous algorithm basic sorted neighborhood method note observation 
record enters window happens exactly equal closely matching duplicate record window keys records question exact duplicates records matched equational theory 
exact closely matching duplicate records equivalent keys appear commonly datasets process efficient find records sorting phase 
removing dataset retaining representative member set duplicates comparison rule set records different keys may yield better results 
call single retained member set equivalent records duplicate keys prime representative set records 
algorithm captures heuristic strategy 
sorting consider records exactly equal keys consider records exactly equal matching records 
records exact duplicates matching records replaced prime example processed method records different keys 
strategy removing matching records tend records enter window comparison equational theory possible allowed records duplicate keys occupy available slots window 
algorithm detail compare performance time accuracy basic sorted neighborhood method optimization strategy 
small window scan regular scan window sort merge dup 
elimination merge input database duplicates results duplicates unmatched tuples returned list duplicate elimination sorted neighborhood method wish determine strategy improve accuracy 
recall concatenate datasets sequential list records 
duplicate elimination sorted neighborhood de snm method solving merge purge problem works follows see 
create keys compute key record list extracting relevant fields portions fields 

sort data eliminating duplicates merge sort records data list key step dividing sorted output lists 
list deposit records exact duplicate keys detected 
records participate merge sort final sorted list call duplicates sorted list 

sort duplicate list notice duplicates list generated incrementally merge sort completely sorted 
duplicates record sort merge phases merge sort duplicates may final sorted order 
records duplicate keys sort phase merge sort necessarily close merge phase key 
proceeding step sort duplicate list key 

window scan move small window sequential list duplicate records limiting comparisons records window having key 
size small window step 
record enter window key records window key distinct keys records presently window 
key new record exactly equal key records window new record compared equational theory rule base gamma previous records window find matching records 
record window slides window 
key new record exactly equal keys records window steps followed append returned list records records window matched record 
append returned list distinct record matched number times record window 
record prime representative key step meaning frequently occurring example serves represent equivalent matches 
window moved gamma positions making new record window 

merge merge returned list records records duplicates sorted list 
list sorted simple way merge sufficient 
extra bit field added resulting sorted data indicate record came returned list duplicates list 

second window scan move fixed sized window sequential list records produced previous step limiting comparisons matching records records window 
size window records new record entering window compared previous gamma records find matching records 
notice record entering window came returned list detected extra bit field compared records come returned list 
reason records compared equational theory window scan step procedure non matching 
hand record coming duplicates list compared gamma previous records compared record 
computing transitive closure results independent runs general single key sufficient catch matching records compute basic algorithm duplicate elimination version 
attributes fields appear key higher discriminating power appearing 
error record occurs particular field portion field important part key may little chance record close matching record sorting 
instance employee records database social security number social security number numbers transposed social security number principal field key records fall window records transposed social security numbers far apart sorted list may merged 
show section number matching records missed run sorted neighborhood method large neighborhood grows large 
increase number similar records merged options explored 
simply widening scanning window size increasing clearly increases computational complexity discussed section increase dramatically number similar records merged test cases ran course window spans entire database presumed infeasible strict time cost constraints 
alternative strategy implemented execute independent runs sorted neighborhood method time different key relatively small window 
call strategy multi pass approach 
instance run address principal part key run name employee principal part key 
independent run produce set pairs records merged 
apply transitive closure pairs records 
results union pairs discovered independent runs duplicates plus pairs inferred transitivity equality 
reason approach works test cases explored nature errors data 
transposing digits social security number leads non mergeable records noted 
records variability error appearing field records may large 
social security numbers records grossly error name fields may 
sorting name fields primary key bring records closer lessening negative effects gross error social security field 
notice transitive closure step limited multi pass approach 
improve accuracy single pass computing transitive closure results 
records similar time records similar transitive closure step mark similar relation detected equational theory 
records records marked similar equational theory 
true records transitive closure step need records detected similar 
transitive closure single pass run sorted neighborhood method allow reduce size scanning window detect comparable number similar pairs find final closure phase larger single run results reported section include final closure phase 
utility approach determined nature occurrences errors appearing data 
choice keys sorting order extraction relevant information key field knowledge intensive activity explored carefully evaluated prior running merge purge process 
section show multi pass approach drastically improve accuracy results run sorted neighborhood method varying large windows 
particular interest observation small search window needed multi pass approach obtain high accuracy individual run single key sorting produced comparable accuracy results large window window sizes approaching size full database 
results consistently variety generated databases variable errors introduced fields systematic fashion 
experimental results generating databases databases test methods generated automatically database generator allows perform controlled studies establish accuracy solution method 
database generator provides user large number parameters may set including size database percentage duplicate records database amount error introduced duplicated records attribute fields 
accuracy measured percentage number duplicates correctly process 
false positives measured percentage records claimed equivalent actual duplicates 
generated database viewed concatenation multiple databases 
merging records resultant single database object study experiments 
record generated consists fields empty social security number name initial name address apartment city state zip code 
names chosen randomly list real names cities states zip codes come publicly available lists data generated intended model processed real world datasets 
errors introduced duplicate records range small typographical mistakes complete change names addresses 
setting parameters typographical errors known frequencies studies spelling correction algorithms 
study generator selected generated records duplication errors error spelling words names cities controlled published statistics common real world datasets 
performance measurement accuracy percentage duplicates captured standard error model plotted varying sized windows may better understand relationship tradeoffs computational complexity accuracy 
believe results substantially different different databases sorts errors duplicated records 
help better establish conjecture widely varying error models afforded database generator 
statistically generated databases may bear direct relationship see ftp ftp dk pub ftp cdrom com cd pub freebsd freebsd current src share misc real data 
believe experiments realistic 
section provides substantial evidence case 
results accuracy purpose experiment determine baseline accuracy method 
ran independent runs sorted neighborhood method database different key sorting phase independent run 
run name principal field key name attribute key 
second run name principal field run street address principal field 
selection attribute ordering keys purely arbitrary 
social security number say street address 
assume fields noisy control data generator matter field ordering select purposes study 
shows effect varying window size records database records additional duplicate records varying errors 
record may duplicated 
notice independent run duplicated pairs 
notice increasing window size help consideration time complexity procedure goes window size increases obviously fruitless point large window 
line marked multi pass keys shows results program computes transitive closure pairs independent runs 
percent duplicates goes 
manual inspection window size records sorted neighborhood method records duplicates key name key name key st addr 
multi pass keys percent correctly detected duplicated pairs window size records sorted neighborhood method records duplicates key name key name key st addr 
multi pass keys percent incorrectly detected duplicated pairs accuracy results records database records equivalent revealed pairs hard human identify information 
equational theory completely trustworthy 
decide records similar equivalent may represent real world entity incorrectly paired records called false positives 
shows percent records incorrectly marked duplicates function window size 
percent false positives insignificant independent run grows slowly window size increases 
percent false positives transitive closure small grows faster individual run 
suggests transitive closure may accurate window size constituent pass large 
number independent runs needed obtain results computation transitive closure depends corrupt data keys selected 
corrupted data runs needed capture matching records 
transitive closure executed pairs tuple id bits fast solutions compute transitive closure exist 
observing real world scenarios size data set closure computed order magnitude smaller corresponding database records contribute large cost 
note pay heavy price due number sorts clusterings original large data set 
parallel implementation alternatives reduce price 
duplicate elimination method de snm ran series experiments evaluate performance de snm compared performance basic counterpart 
experiments reported section started database records allowed generator select tuples duplication modifications 
experiment maximum number times selected record duplicated varied respectively 
runs snm basic duplicate elimination executed run different key 
results independent runs processed transitive closure phase improve accuracy results 
size window basic snm de snm varied range 
size small window special window scan phase de snm 
average results experiments shown 
key name followed smaller dataset experiments reported previously better model real world dataset discussed section 
duplicates detected window size records basic snm key basic snm key basic snm key basic snm keys snm key snm key snm key snm keys accuracy results window size records basic snm max dups recs basic snm max dups recs basic snm max dups recs snm max dups recs snm max dups recs snm max dups recs average total times duplicate elimination vs basic records name key name followed name key street address followed name field 
notice accuracy duplicate elimination sorted neighborhood method de snm closely follows accuracy basic snm accuracy slightly higher accuracy counterpart 
reason small difference window scan finds number duplicates removing considerable number records middle window second window scan phase 
records match fell outside window basic method closer removing duplicates matched window size unsuccessfully basic method 
important question tuples identified similar detected duplicates list non duplicates list key key key multi pass keys percent records identified similar duplicate elimination algorithm window scan phase window scan small window duplicates detected second window scan phase window scan returned duplicates list sorted records 
pie charts show percent records identified similar phase de snm database maximum duplicates selected record cases key theta total number records detected similar detected window scan phase 
large part matching done window scan uses smaller window second second window scan 
large part done window scan de snm merges tuples duplicate list duplicate list perform second window scan phase 
fact duplicate elimination algorithm contains phases basic version snm 
question answer time performance de snm charts experiments similar 
better basic method 
compares time results experiments databases described 
experiment lines graph representing average time single pass runs basic snm representing average time de snm 
cases notice basic snm better de snm small window sizes 
size window grows complexity window scan phase basic approach complexity second window scan phase duplicate elimination approach grows de snm starts doing better basic snm 
notice number possible duplicates record increases total execution time difference de snm basic snm 
difference explained recalling large portion duplicates matched removed consideration window scan duplicate elimination version uses constant sized window experiments 
duplicates eliminated left database size change experiment 
time apply second window scan database virtually experiment window size 
leaving second window scan window size fixed increase time de snm driven increased number duplicates considered small window window scan 
hand increase time basic version driven size window total size input database 
expected de snm better time performance basic snm 
expected performance versions 
clearly shows relations true 
results conclude de snm version choice databases number possible duplicates record known large 
amount time larger window duplicate elimination version providing larger accuracy basic version 
hand number duplicates records small difference version snm window size relatively large 
analysis natural question pose multi pass approach superior single pass case 
answer question lies complexity approaches fixed accuracy rate consider percentage correctly matches 
consider question context main memory sequential process 
reason shall see clustering provides opportunity reduce problem sorting entire disk resident database sequence smaller main memory analysis tasks 
serial time complexity multi pass approach passes time create keys time sort times time window scan times window size plus time compute transitive closure 
experiments creation keys integrated sorting phase 
treat phases analysis 
simplifying assumption data memory resident bound multipass sort rn log number passes time transitive closure 
constants depict costs comparison related ffc sort ff 
analyzing experimental program window scanning phase contributes constant ff times large comparisons performed sorting 
replace constants term single constant complexity closure directly related accuracy rate pass depends duplication database 
assume time compute transitive closure database orders magnitude smaller input database time scan input database contributes factor closure 
multipass crn log window size complexity single pass snm similarly cn log window size fixed accuracy rate question value single pass snm multi pass approach perform better time cn log crn log gamma ff log rw gamma validate model generated small database records original window size key name key name key street addr multi pass keys time single pass runs multi pass run window size key name key name key street addr multi pass keys ideal vs real accuracy run time accuracy small database records selected duplications maximum duplicates selected record 
total size database bytes approximately mbyte 
read database stayed core phases 
ran independent single pass runs different keys multi pass run results single pass runs 
parameters experiment records 
particular case ff theta gamma 
multi pass approach dominates single sort approach datasets 
shows time required run independent run snm processor total time required multi pass approach shows accuracy independent run accuracy multi pass approach please note logarithm scale 
shows multi pass approach needed produce accuracy rate 
looking times single pass run total time close slightly higher estimated model 
accuracy single pass runs accuracy level multi pass approach 
single pass run reaches accuracy point shown execution time seconds minutes 
detailed analysis techniques process bound 
earlier describe parallel variants basic techniques including clustering show modest amount cheap parallel hardware speedup multi pass approach level comparable time single pass approach high accuracy small windows ultimately wins 
reader encouraged read earlier details speed readily achieved 
results real world data results achieved wide variety statistically controlled generated data indicate multi pass approach quite may regard definitive validation efficacy techniques 
state washington department social health services maintains large databases transactions years state residents 
march office children administrative research ocar department social health services posted request kdd nuggets asking assistance analyzing databases 
answered request section details results 
ocar analyzes database payments state families businesses provide services children 
ocar goal answer questions children foster care long children stay foster care 
different homes children typically stay 
accurately answer questions computer records payments services identified child 
obviously matching records appropriate individual client frequency distributions services grossly error 
unique identifier individual child exists generated assigned algorithm compares multiple service records database 
fields records help identify child include name birth date case number social security number unreliable containing misspellings typographical errors incomplete information 
unique situation real world databases 
need develop computer processes accurately identified records child spurred ocar seek assistance 
database description ocar data stored relation contains payments service providers 
currently approximately total records relation number grows approximately month 
relation attributes relevant carrying information infer identify individual entities name name birthday social security number case number service id service dates dates gender race provider id amount payment date payment worker id record bytes long 
typical problems ocar data follows 
names frequently misspelled 
nicknames similar sounding names real name 
parent guardian name child name 

social security numbers missing clearly wrong records social security number 
likewise parent guardian information child proper information 

case number uniquely identify family changes child family moves part state referred service second time couple years referral 

records assigned person name entered record child name service provider 
names anonymous male anonymous female 
call type records ghost records 
private nature data recorded database produce sample records illustrate mentioned cases 
database administrator responsible large corporate agency database immediately see parallels data 
real world data dirty 
ocar provided sample database conduct study 
sample contains data service office records mbytes 
provided current individual identification number record sample number uniquely identify child database number records cluster number records child computed ocar graph drawn cluster size 
actuality continues 
analysis 
ocar assigned identifiers serve basis comparing accuracy varying window sizes 
shows distribution number records individual detected ocar 
individuals database represented average records database approximately individuals represented record database 
note individuals may represented records shown individuals records records 
task apply merge purge techniques compute new individual identification number record compare accuracy attained ocar provided identification number 
merge purge system ocar data ocar individual identification numbers course perfect 
set identifiers computed single scan clustering technique hashing records letters name letters name birth month year case number hashing keys 
strategy identified individuals sample database 
task create equational theory consultation ocar expert resultant rule base consists rules 
applied equational theory data basic sorted neighborhood method multi pass method rigorous comparative evaluation 
keys independent run 
name name social security number case number 

name name social security number case number 

case number name name social security number 
displays number individuals detected independent pass basic sorted neighborhood method number individuals closure phase function window size 
constant individuals detected ocar plotted straight line means comparison 
statistically generated data number individuals detected initially goes window size increases stabilizes remains constant 
notice large improvement timothy clark computer information consultant ocar provided necessary expertise define rule base 
window size number individuals detected ocar result st pass nd pass rd pass combined number individuals detected ocar analysis fr fr fr fr snm analysis fr fr fr fr separation fr sorted neighborhood method snm counted possible 
union fr fr counted possible false positive 
example definition possible misses possible false positives performance combining results passes transitive closure phase results demonstrated controlled studies validated set real world data 
window size multi pass process detected individuals sample 
passes experiments describe passes third key produced similar results 
second key pass marginally improved results 
significant observation may occur real world data indicating multi pass approach may simply pass approach significantly reducing complexity process achieving accurate results 
question answer individuals closer actual number individuals data ocar individuals 
answer question looked different group individuals detected ocar sample results 
call possible misses groups individuals merge purge program considered different ocar considered similar 
call possible false positives groups individuals ocar consider similar grouped system 
shows example false positive definition 
depicts number possible misses possible false positives comparing results ocar 
previous experiments total number misses goes window size goes drops sharply transitive closure phase 
behaviour false positives expected contrary misses number grows window size goes transitive closure phase 
multi pass sorted neighborhood method improve ocar results conditions met ffl number possible misses merge purge program correctly merge larger number real misses ocar correctly merged merge purge 
ffl number possible false positives records correctly merged multi pass sorted neighborhood method larger real false positives cases approach incorrectly merged records ocar 
study results met conditions ocar group manually window size misses st pass nd pass rd pass combined misses respect ocar results window size false positives st pass nd pass rd pass combined false positives respect ocar results accuracy results snm ocar data inspected possible misses possible false positives case window size 
results manual inspection follows ffl possible misses multi pass sorted neighborhood method failed detect individuals ocar detected 
possible misses correctly separated approach real misses 
ocar results wrong 
incorrectly separated approach real misses 
special cases involving ghost records records payments outside agencies 
agreed ocar exclude cases consideration 
ffl possible false positives instances multi pass method joining records individuals ocar 
cases manually inspected results incorrectly merged approach 
correctly merged approach 
way summary possible misses real misses correctly classified records estimated possible false positives real false positives 
results lead ocar confident multi pass method improve individual detection procedure 
sorted neighborhood method expensive due sorting phase need search large windows high accuracy 
alternative methods data clustering modestly improves process time reported 
achieves high accuracy inspecting large neighborhoods records 
particular interest performing merge purge process multiple times small windows followed computation transitive closure dominates accuracy method 
multiple passes small windows increases number successful matches small windows favor decreases false positives leading high accuracy merge phase 
alternative view single pass approach far slower achieve comparable accuracy multi pass approach 
results demonstrate statistically generated databases provide means quantifying accuracy alternative methods 
real world data comparable means rigorously evaluating results 
application merge purge program real world data provided state washington child welfare department validated claims improved accuracy multi pass method eye significant sample data 
controlled empirical studies shown indicates improved accuracy exhibited real world data sorts errors complexity matching described 
acknowledgments grateful timothy clark computer information consultant ocar help provided obtaining results section 
dr diana english ocar chair allowing database 
acm 
sigmod record december 
agrawal jagadish 
multiprocessor transitive closure algorithms 
proc 
int symp 
databases parallel distributed systems pages december 
batini lenzerini navathe 
comparative analysis methodologies database schema integration 
acm computing surverys december 
bitton dewitt 
duplicate record elimination large data files 
acm transactions database systems june 
church gale 
probability scoring spelling correction 
statistics computing 
dewitt naughton schneider 
evaluation non equijoin algorithms 
proc 
th int 
conf 
large databases pages barcelona spain 
forgy 
ops user manual 
technical report cmu cs carnegie mellon university july 

computing joins relations 
proceedings acm sigmod conference 
hern andez stolfo 
merge purge problem large databases 
proceedings acm sigmod conference may 
kent 
breakdown information model multi database systems 
sigmod record december 
knuth 
art computer programming sorting searching volume 
addison wesley 
kukich 
techniques automatically correcting words text 
acm computing surveys 
nyberg barclay gray lomet 
risc machine sort 
proceedings acm sigmod conference pages 
shapiro 
kdd nuggets 
info gte com kdd nuggets 
volume 
pollock zamora 
automatic spelling correction scientific scholarly text 
acm computing surveys 
wang madnick 
inter database instance identification problem integrating autonomous systems 
proceedings sixth international conference data engineering february 
ops version equational theory rules merge purge procedure mauricio hernandez computer science department columbia university window size max top pid goal name merged id id similar id id similar id id id id similar id id person id ssn name addr fname lname stnum aptm city state zipcode status rules section program match records finding candidates merged 
find goal name initial person status active id id 
ssn 
person status active id id 
id 
ssn 
ssn 
gamma similar id id 
id id 
gamma gamma 
similar id id 
id id compare goal name initial person status active id id 
name name 
person status active id id 
id 
name compare names name gamma similar id id 
id id 
gamma gamma 
similar id id 
id id compare goal name initial person status active id id 
stnum num 
addr 
person status active id id 
id 
stnum num 
person status active id id 
compare addresses addr 
num 
num gamma similar id id 
id id 
gamma gamma 
similar id id 
id id closer goal name initial similar id id 
id id 
person status active id id 
city zipcode 
person status active id id 
city city zipcode zipcode gamma id id 
id id 
gamma gamma 
id id 
id id closer goal name initial similar id id 
id id 
gamma id id 
id id 
person status active id id 
city state 
person status active id id 
city city state gamma gamma 
id id 
id id change gamma goal name initial gamma gamma 
modify name second context second matches records ssns names determine person 
declare records 
compare goal name second person status active id id 
stnum num 
addr 
aptm 
city state 
person status active id id 
id 
stnum close num num 
close addr 
aptm 
close str city city state gamma similar id id 
id id 
gamma id id 
id id 
gamma gamma 
similar id id 
id id 
id id 
id id compare goal name second person status active id id 
stnum num 
addr 
aptm 
city zipcode 
person status active id id 
id 
stnum close num num 
close addr 
aptm 
close str city city zipcode zipcode gamma similar id id 
id id 
gamma id id 
id id 
gamma gamma 
similar id id 
id id 
id id 
id id goal name second similar id id 
id id 
gamma id id 
id id 
gamma merged id id 
id id 
person status active id id 
stnum num 
aptm 
zipcode 
person status active id id 
stnum close num num 
aptm 
close str zipcode zipcode gamma gamma 
id id 
id id goal name second similar id id 
id id 
ssns 
similar id id 
id id 
names 
gamma merged id id 
id id 
gamma gamma 
remove ssns 
names 
merged id id 
id id goal name second similar id id 
id id 
ssns 
id id 
id id 
vsa 
gamma merged id id 
id id 
gamma gamma 
remove ssns 
vsa 
merged id id 
id id goal name second similar id id 
id id 
names 
id id 
id id 
vsa 
gamma merged id id 
id id 
gamma gamma 
remove names 
vsa 
merged id id 
id id change gamma goal name second gamma gamma 
modify name third context third matches goal name third similar id id 
id id 
similar id id 
id id 
gamma similar id id 
id id 
person status active id id 
ssn 
person status active id id 
ssn ssn 
gamma merged id id 
id id 
gamma gamma 
merged id id 
id id hard gamma goal name third id id 
id id 
sa 
person status active id id 
fname fn 
addr 
zipcode 
person status active id id 
fname name initial fn 
addr 
zipcode gamma merged id id 
id id 
gamma gamma 
remove sa 
merged id id 
id id goto goal name third gamma gamma 
modify name version equational theory rule program number tuples tuple window size compare tuples inside window 
match call merge tuples 
void rule program int int start int register int register person person boolean similar ssns similar names similar addrs boolean similar city similar state similar zip boolean similar close aptm close stnum close tuples consideration start person points th tuple person tuples tuples inside window tuples th tuple 
gamma gamma gamma person points th tuple person tuples compare person person rule find similar ssns similar ssns ssn person ssn person ssn rule compare names similar names compare names person name person name person fname person person lname person fname person person lname person fname init person fname init rule ssn name similar ssns similar names merge tuples person person continue rule compare addresses similar addrs compare addresses person person compare fields address similar city city person city person city similar zip zipcode person zipcode person zipcode similar state strcmp person state person state rules closer addresses zips closer address states similar addrs similar addrs similar city similar state jj similar zip rules ssn address name address similar ssns jj similar names similar addrs merge tuples person person continue close close person person person stnum person stnum close stnum close num person stnum person stnum close stnum false person aptm person aptm close aptm close str person aptm person aptm close aptm false rules compare addresses numbers state compare addresses numbers zipcode address city close stnum close close aptm similar city similar state jj similar zip similar addrs jj similar addrs close stnum close aptm similar zip similar addrs true rules ssn address name address similar ssns jj similar names merge tuples person person continue rule close ssn close address similar addrs similar ssns similar names ssn person ssn person ssn merge tuples person person continue rule hard case similar ssns similar addrs similar zip name initial person fname person fname merge tuples person person continue 
