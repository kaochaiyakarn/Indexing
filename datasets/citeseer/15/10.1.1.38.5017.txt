effect heavy tailed job size distributions computer system design 
mor harchol balter laboratory computer science mit ne cambridge ma harchol theory lcs mit edu heavy tailed distributions power law distributions observed natural phenomena ranging physical phenomena sociological phenomena 
heavy tailed distributions discovered computer systems 
particular sizes service demands computing jobs exhibit heavy tailed power law distribution 
previous analytic area computer system design assumed job sizes service demands exponentially distributed 
policies algorithms general rules thumb currently computer systems originated analyses assumed workload 
argue need reevaluate existing computer system algorithms light discovery heavy tailed workloads 
argue algorithm optimal exponentially distributed workload may far optimal workload heavy tailed 
demonstrate point common problems design computer systems 
choosing migration policy network workstations 

choosing task assignment policy distributed server 

scheduling requests web server 
problem show answer highly dependent job size distribution 
show analysis heavy tailed job size distributions 
show analysis leads policies performance improves greatly commonly solutions cases orders magnitude 
compilation sequence papers author wrote 
far detail contained original papers 
supported nsf postdoctoral fellowship mathematical sciences 
heavy tailed distributions known power law distributions observed natural phenomena including physical sociological phenomena 
commonly cited example distribution hurricane damage cause little damage small percentage cause lot damage density function describes statement form power law 
surprisingly distribution fire damage earthquake damage heavy tailed 
distribution national wealth heavytailed 
heavy tailed distributions discovered computer systems 
particular sizes service demands computing jobs exhibit heavy tailed power law distribution 
example consider cpu requirement jobs turns jobs low cpu requirements jobs high cpu requirements density function form power law 
previous analytic area computer system design assumed job sizes service demands exponentially distributed 
assumption may part analytical tractability 
policies algorithms general rules thumb currently computer systems originated analyses assumed exponentially distributed workload 
point existing policies intuitions respect computer system design may severely suboptimal applied heavy tailed workloads 
correct heavytailed distributions need understood intuitive level form new intuitions policies effective aren 
existing policies new policies evaluated new analysis incorporate heavy tailed distributions 
section describe measurements computing systems heavy tailed distributions observed define mean heavy tailed distribution 
characterize important properties heavy tailed distributions respect computer system design 
sections case study common system design problem 
problem solve problem context exponentially distributed job size distribution context heavy tailed job size distribution obtaining different answers 
sequence papers author wrote 
provides brief summaries insights learned original papers 
reader referred original papers detail 
measurements heavy tailed job size distributions computer systems depicts graphically log log plot measured distribution cpu requirements unix processes taken 
note shows jobs require second cpu 
distribution closely fits curve cpu requirement xg shown distribution cpu requirements variety computing environments including instructional research administrative environments 
says jobs small require little cpu jobs large require lot cpu 
fact case exponential distribution 
curve shown far exponential 
demonstrate point shows best possible fit exponential distribution measured data 
distribution process lifetimes log plot fraction processes duration duration secs 
measured distribution unix process cpu lifetimes taken hd 
data indicates fraction jobs cpu service demands exceed seconds function bumpy line indicates measured data 
straight line curve fit 
observed distribution curve fits fraction processes duration duration secs 
fit best exponential fit curve shows best possible fit exponential distribution measured data 
distribution shown measurements example heavy tailed distribution 
general heavy tailed distribution prfx xg gammaff ff 
measurements ff 
simplest heavy tailed distribution pareto distribution probability mass function ffk ff gammaff gamma ff cumulative distribution function prfx xg gamma ff thinking computer system design problems key characteristic properties heavy tailed distributions 
list 
decreasing failure rate particular longer task run longer expected continue running 
fact distribution shown job cpu age job far seconds cpu probability half seconds cpu 
words median remaining lifetime job current age 
contrast exponential distribution memoryless 
exponential distribution heavy tailed distribution similar ski slope shape drawn non logarithmic scales heavy tailed distribution drops slower slower rate move axis exponential distribution drops constant rate 

infinite variance ff infinite mean 
reality course finite set measurements finite trace finite variance 
point variance high workload heavy tailed 

property small fraction 
largest jobs large fraction half workload 
refer key property heavytailed property 
contrast exponential distribution largest largest jobs total workload 
understand heavy tailed property consider example distribution national wealth people little money people lot money richest people money people combined 
lower parameter ff variable distribution pronounced heavytailed property smaller faction large tasks comprise half load 
fact heavy tailed distributions appear fit measurements computing systems 
include example ffl unix process cpu requirements measured bellcore ff 
ffl unix process cpu requirements measured uc berkeley ff 
ffl sizes files stored web sites sizes files accessed web requests ff 
ffl sizes files stored unix filesystems 
ffl times 
ffl sizes ftp transfers internet ff 
cases estimates ff ff 
fact typically ff tends close represents high variability task service requirements 
case study choosing migration policy network workstations discussion section taken entirely 
small subset material 
consider problem network workstations processes currently running workstations 
interested running automated cpu load balancing policy processes migrated heavily loaded hosts network hosts receive greater share cpu 
types load balancing possible remote execution active process migration 
remote execution placement process may migrated started running 
active process migration hand migration active running processes 
types migration cost cost remote execution small cost active process migration quite large active process accumulated memory moved process 
active process migration fact expensive cost migrating process charged migrant source target hosts 
interested answering policy questions 
active process migration really necessary achieve load balancing remote execution 

opt active process migration active migration policy 
active processes pay migrate 
answering questions assume somewhat simplified model processes consist cpu memory interactive jobs 
hosts timesharing hosts 
discussion section center distribution process sizes effects answer question 
process size lifetime defined total cpu requirement 
likewise process age defined amount cpu far 
say process old lot cpu far 
note process lifetimes known priori 
returning question suppose distribution process lifetimes exponential 
processes ages expected remaining lifetime benefit migrating active processes higher migration costs 
distribution unix process lifetimes heavy tailed measurements show older processes live longer older job second cpu 
may pay migrate old active jobs migration cost high remaining cpu requirement job may higher 
answer question active process migration fact necessary performed simulation 
simulated network hosts 
process start times durations taken real machine traces unix processes 
performed independent hour experiments 
experiment involved processes 
system utilization experiments ranged 
complete details trace driven simulation experiment setup described 
purpose trace driven simulation experiment compare load balancing strategies remote execution versus active process migration described choosing remote execution strategy important observe remote execution cheap free 
measurements size processes total cpu requirement smaller cost remote execution 
known standard remote execution strategy practical systems name lists 
name list list names jobs average tend large size 
examples cc gcc 
name list created looking past history 
newborn process busy host chosen remotely executed name appears name list 
trace driven simulation experiment chose standard name list remote execution strategy constructing name list allowed remote execution policy see traces ahead time best possible name list trace 
details described 
purpose doing give remote execution strategy possible advantage 
deriving active migration policy trace driven simulation experiment obvious 
mean slowdown run number migration remote execution active age migration trace driven simulation results different runs 
mean slowdown shown load balancing remote execution migration active processes 
job size distribution unix processes suggests may pay migrate older jobs live longer old 
particular particular job size distribution suggests remaining cpu requirement job infinity 
show job size distribution derive migration policy active processes show interesting properties 
simply state policy active process migrated age process migration cost process source gamma target gamma source target represents number jobs source respectively target host 
intuitively policy says process migration cost high process needs old afford migration cost 
difference loads source target hosts really great process doesn need quite old migration worthwhile 
trace driven simulation experiment performed load balancing remote execution policy active migration policy 
results runs shown 
shows remote execution policy improved mean slowdown improved load balancing active migration policy created dramatic effect improvement load balancing 
slowdown process wall time divided size 
example process cpu requirement seconds wall time response time seconds experienced slowdown factor 
see metrics mean response time variance slowdown number severely slowed processes improvements dramatic favor active process migration 
experiment just described average active migration cost processes memory bandwidth seconds cost charged migrant process source host 
cost remote execution seconds 
experiment active process migration effective remote execution 
begs question suppose mean active migration cost higher say bandwidth low active migration effective remote execution 
answers question 
scaled mean cost active migration holding cost remote execution constant seconds 
shows cost active process migration high seconds active process migration effective reducing mean slowdown remote execution 
migration mean slowdown function increasing cost active migration remote execution shows effect increasing cost active process migration holding constant cost remote execution 
axis shows cost active process migration 
axis shows mean slowdown 
shows cost active process migration high seconds active process migration effective reducing mean slowdown remote execution 

migration active processes effective load balancing remote execution especially highly optimized remote execution policy 
answer lies understanding job size distribution 
decreasing failure rate property job size distribution active process migration better able detect long jobs remote execution 
fact mean lifetime migrant remote execution policy gamma seconds mean lifetime migrant active process migration gamma seconds 
simply says best indicator long process going live long lived 
matter remote execution misses opportunity migrate big jobs 
see need go back heavy tailed property distribution 
active migration policy migrated jobs accounted total cpu 
detecting largest jobs migrating active process migration policy able affect large percentage total load 
summarize case study important properties process size distribution decreasing failure rate property heavy tailed property 
reader encouraged seek original complete understanding results 
case study choosing task assignment policy distributed server system material section taken entirely papers 
build high capacity server systems developers increasingly turning distributed designs scalability cost effectiveness 
examples trend include distributed web servers tasks fcfs fcfs fcfs fcfs distributed server model dispatcher assigns tasks hosts distributed server model distributed database servers high performance computing clusters 
system requests service arrive assigned host machines processing 
rule assigning tasks host machines known task assignment policy 
limit discussion particular model distributed server system incoming task immediately assigned host machine host machine processes assigned tasks come served fcfs order shown 
assume task service demand known advance 
motivation considering model abstraction existing distributed servers described section 
consider task assignment policies commonly proposed distributed server systems ask best mean response time mean slowdown task assignment policies random incoming task sent host probability round robin tasks assigned hosts cyclical fashion ith task assigned host mod size host serves tasks service demand falls designated range 
dynamic incoming task assigned host smallest amount outstanding sum sizes tasks host queue plus remaining task currently served 
goal understand influence job size distribution question task assignment policy best 
particular interested heavy tailed job size distributions exponential job size distributions 
model problem formulation concerned specific model distributed server 
server composed hosts equal processing power 
tasks arrive system poisson process rate task arrives system inspected dispatcher facility assigns means task averages 
power law exponent second moment bounded pareto distribution alpha parameters bounded pareto distribution left second moment ff function ff fxg right 
hosts service 
assume dispatcher facility knows size task 
tasks assigned host served fcfs order tasks preemptible 
assume processing power resource tasks 
model distributed server initially inspired batch distributed computing facility mit laboratory computer science 
consists identical multiprocessor hosts 
users specify upper bound job processing demand 
job exceeds demand killed 
facility dispatcher front assigns job hosts service 
user upper bound time job wait queue sum sizes jobs queue 
jobs queued host run completion fcfs order 
assume task sizes show maximum large value 
result model task sizes distribution follows power law upper bound 
refer distribution bounded pareto 
characterized parameters ff exponent power law smallest possible observation largest possible observation 
probability mass function bounded pareto ff defined ffk ff gamma ff gammaff gamma section model task sizes ff distribution vary ff range order observe effect changing variability distribution 
focus effect changing variance keep distributional mean fixed maximum value fixed 
order keep mean constant adjust slightly ff changes 
parameters summarized table 
note bounded pareto distribution moments finite 
heavy tailed distribution sense defined 
distribution show high variability example right shows second moment phi psi distribution function ff chosen keep fxg constant 
shows second moment explodes exponentially ff declines 
furthermore bounded pareto distribution exhibits heavy tailed property extent decreasing failure rate property unbounded pareto distribution 
number hosts 
system load ae 
mean service time fxg time units task arrival process poisson rate ae delta fxg delta tasks unit time maximum task service time time units ff parameter ff minimum task service time chosen mean task service time stays constant ff varies table parameters evaluating task assignment policies new size task assignment policy sita delving simulation analytic results need specify parameters size policy 
size task assignment size range associated host task sent appropriate host size 
practice size ranges associated hosts chosen somewhat arbitrarily 
minute queue tasks size minutes hour queue tasks size minutes hours hour queue hour queue hour queue example 
example practice cornell theory center ibm sp job scheduler 
choose formal algorithm size task assignment refer sita size interval task assignment equal load 
idea simple define size range associated host total load directed host 
motivation doing balancing load minimizes mean waiting time 
mechanism achieving balanced expected load hosts task size distribution define cutoff points defining ranges expected directed host 
task size distribution easy obtain maintaining histogram dispatcher unit task sizes witnessed period time 
precisely prfx xg denote cumulative distribution function task sizes finite mean denote smallest task size possibly equal infinity denote largest task size number hosts 
determine cutoff points gamma delta df delta df delta delta delta gamma delta df delta df assign ith host tasks ranging size gamma sita defined applied task size distribution finite mean 
remainder case study assume task size distribution bounded pareto distribution ff 
simulation results section compare random round robin sita dynamic policies simulation 
simulation parameters shown table 
simulating server system heavy tailed highly variable service times difficult system approaches steady state slowly usually 
occurs running average task sizes typically outset true mean true mean isn achieved large tasks arrive 
consequence system simulation outputs appear optimistic steady state 
simulation measurements sensitive startup transient run simulation theta arrivals capture data single arrival system 
data point shown plots average independent runs started empty system 
consider ff values range high variability lower variability 
described section ff values range tend common empirical measurements computing systems 
simulated mean waiting time alpha random 
round robin 
dynamic sita simulated mean slowdown alpha random 
round robin 
dynamic sita mean waiting time mean slowdown simulation task assignment policies function ff 
simulated standard deviation waiting time alpha fcfs random 
fcfs rr 
fcfs dyn fcfs sita simulated standard deviation slowdown alpha fcfs random 
fcfs rr 
fcfs dyn fcfs sita standard deviation waiting time standard deviation slowdown simulation task assignment policies function ff 
show performance system policies function ff note logarithmic scale axis 
shows mean waiting time shows mean slowdown 
simply summarize results section analysis explain results 
observe performance system random round robin policies similar cases perform poorly sita dynamic 
ff declines performance metrics random round robin policies explode approximately exponentially 
gives indication severe impacts heavy tailed workloads systems naive task assignment policies 
dynamic policy shows benefits instantaneous load balancing 
dynamic order times better metrics compared random round robin 
large ff means dynamic performs quite mean slowdown 
variability task size increases ff dynamic unable maintain performance 
suffers roughly exponential explosion performance metrics ff declines 
contrast behavior sita quite different 
entire range ff values studied performance system sita relatively unchanged mean slowdown 
striking aspect data range ff performance metrics random round robin dynamic explode sita performance remains remarkably insensitive increase task size variability 
result find task size variable dynamic task assignment exhibits better performance order magnitude better sita task sizes show variability characteristic empirical measurements ff sita performance orders magnitude times better dynamic 
simulate range loads ae show load increases sita preferable dynamic larger range ff 
remarkable consistency system performance sita policy range ff difficult understand tools simulation 
reason section develops analysis sita policies uses analysis explain sita performance 
analysis task assignment policies understand differences performance task assignment policies provide full analysis round robin random sita policies approximation dynamic policy 
analysis repeatedly pollaczek formula analyzes fcfs queue gamma ae pollaczek formula fw xg fwg delta gamma denotes rate arrival process denotes service time distribution ae denotes utilization ae fxg 
slowdown formulas follow fact independent fcfs queue 
observe metric simple fcfs queue dependent phi psi second moment service time 
recall workload heavy tailed second moment service time explodes shown 
random task assignment 
random policy simply performs bernoulli splitting input stream result host independent ff queue 
load ith host equal system load ae ae 
pollaczek formula applies directly performance metrics proportional second moment ff 
performance generally poor second moment ff high 
round robin 
round robin policy splits incoming stream host sees ff queue utilization ae ae 
system performance close random case sees high variability service times dominates performance 
sita 
sita policy performs bernoulli splitting arrival stream follows assumption task sizes independent 
definition sita ae ae 
task sizes queue determined particular values interval cutoffs fx fact host sees gamma ff queue 
reason partitioning bounded pareto distribution contiguous regions renormalizing resulting regions unit probability yields new set bounded pareto distributions 
show calculate set ff distribution resulting formulas provide full analysis system sita policy performance metrics 
dynamic 
dynamic policy analytically tractable performed simulation study 
prove distributed system type hosts performs dynamic task assignment equivalent queue 
fortunately exist known approximations performance metrics queue qm qm delta fxg denotes service time distribution denotes number queue 
important observe mean queue length mean waiting time mean slowdown proportional second moment service time distribution case random round robin task assignment policies 
analysis compute performance task assignment policies range ff values 
shows analytically derived mean waiting time mean slowdown system policy range ff 
shows analytically derived metrics range ff range ff corresponding empirical measurements process lifetimes file sizes see section 
note slow simulation convergence described section simulation values generally lower analytic predictions simulation trends agree analysis 
observe performance random dynamic policies figures grows worse ff decreases performance curves follow shape second moment bounded pareto distribution shown 
expected performance random dynamic directly proportional second moment service time distribution 
contrast looking see range ff mean waiting time especially mean slowdown sita policy remarkably constant mean slowdowns random dynamic explode range 
insensitivity sita performance ff range striking property simulations analysis 
sita perform region task size variability dynamic policy explodes 
careful analysis performance sita queue system see leads answers 
limiting range task sizes host sita greatly reduces variance task size distribution witnessed lowered numbered hosts improving performance hosts 
fact performance hosts superior queue utilization ae 

load balanced majority tasks assigned low numbered hosts hosts best performance 
heavy tailed property implies tasks assigned high numbered hosts 
analytically derived mean waiting time alpha random sita 
dynamic approximation analytically derived mean slowdown alpha random sita 
dynamic approximation analysis mean waiting time mean slowdown range ff ff 
analytically derived mean waiting time alpha random sita 
dynamic approximation analytically derived mean slowdown alpha random sita 
dynamic approximation analysis mean waiting time mean slowdown empirically relevant range ff ff 
furthermore mean slowdown improved small tasks observe proportionately lower waiting times 
case ff shown sita policy system performance eventually deteriorates badly 
reason variability task sizes increases eventually host witness high variability 
analysis indicates adding hosts extend range sita shows performance 
example number hosts sita performance deteriorate ff 
studied task size distribution influences task assignment policy best distributed system 
considered policies random round robin sita size policy dynamic sending task host remaining 
best choice task assignment policy depends critically variability task size distribution 
task sizes highly variable example case exponential distribution dynamic policy preferable order magnitude performance 
task sizes heavy tailed ff common empirical measurements see section sita best orders magnitude performance 
case study scheduling web server discussion section taken entirely papers 
brief overview material papers 
consider web server servicing multiple connections jobs 
traditionally web server time slice connections 
resource cpu shared fairly open connections 
may possible achieve better mean response time mean jobs different scheduling policy favors small jobs 
heretofore web servers obtained utilized information size job resource requirement 
size job fact easy information gauge static requests requests simply get file size job proportional size file retrieved 
size job fact obtainable propose changing scheduling policy web servers give preference small jobs connections big ones 
specifically propose giving preference jobs remaining size remaining service demands smallest 
motivation type scheduling known scheduling theorem states single resource scheduling running job shortest remaining processing time minimize mean response time 
minimizes mean response time allows small jobs get fast 
observe scheduling theorem applies single resource scheduling 
contrast web server multiple resources requires multiple jobs system order achieve throughput 
context web server obvious scheduling means 
define meant giving preference jobs remaining size smallest context web server 
build web server show type scheduling policy fact leads substantial performance improvements web servers respect mean response time 
attempt issues brought long detailed papers 
concentrate just particular issue starvation 
smaller jobs getting preference imply bigger jobs starved 
show fact happen 
fact long connections pay little penalty 
surprising result understood looking job size distribution interest current consider job th percentile job size distribution large job 
turns job lower expected slowdown scheduling policy fair scheduling processor sharing type policy 
see recall section sizes requests arriving web server shown heavy tailed distribution 
consider job th percentile job size distribution 
heavy tailed property see section half total workload contained jobs size greater job preempted half total workload turn implies see expected response time better scheduling processor sharing type scheduling job share resource total workload 
contrast case exponential distribution total workload contained jobs size greater exponential workload job held workload fact significantly worse performance scheduling policy processor sharing scheduling policy 
exponential workload scheduling idea 
argument holds job th percentile 
bottom line job size distribution heavy tailed starvation scheduling provably problem jobs isn observable practice 
question choosing best scheduling policy understanding job size distribution critical determining best solution 
discussed case studies area computer system design 
case study shown job size distribution great effect problem solution 
particular heavy tailed job size distribution leads different answers exponential job size distribution 
furthermore optimal solution assumption exponential job size distribution far optimal orders magnitude workload heavy tailed 
unfortunate reasons solving problems analytically far easier exponential job size distribution 
second case studies natural intuition tends lead solution best exponential job size distribution solution best heavy tailed job size distribution 
respect problem shown respect case studies analysis possible heavy tailed job size distributions 
combat problem characterized heavy tailed distributions terms properties especially important think solving problems system design decreasing failure rate greater variance imaginable heavy tailed property fraction biggest jobs account half total workload 
belief increasingly computer workload measurements show presence 
force reevaluate age old area system design develop new ones 
crovella harchol balter 
connection scheduling web servers 
technical report bucs tr bu computer science department march 
mark crovella azer bestavros 
self similarity world wide web traffic evidence possible causes 
ieee acm transactions networking december 
mark crovella lester 
long lasting transient conditions simulations heavy tailed workloads 
proceedings winter simulation conference pages 
mark crovella murad taqqu azer bestavros 
heavy tailed probability distributions world wide web 
robert adler feldman murad taqqu editors practical guide heavy tails chapter pages 
chapman hall new york 
john doyle 
highly optimized tolerance mechanism power laws designed systems 
talk slides mit march 
harchol balter crovella 
choosing task assignment policy distributed server system 
proceedings performance tools 
lecture notes computer science 
harchol balter crovella 
choosing task assignment policy distributed server system 
technical report mit lcs tr mit laboratory computer science 
harchol balter crovella park 
case scheduling web servers 
technical report mit lcs tr mit lab computer science october 
harchol balter downey 
exploiting process lifetime distributions dynamic load balancing 
acm transactions computer systems 
steven david schneider timothy donnell 
analysis early workload cornell theory center ibm sp 
technical report tr cornell theory center january 
gordon 
unix file size survey 
available www base com ufs html september 
leland ott 
load balancing heuristics process behavior 
proceedings performance acm sigmetrics pages 
vern paxson sally floyd 
wide area traffic failure poisson modeling 
ieee acm transactions networking pages june 
david peterson david adams 
fractal patterns traffic 
cmg proceedings december 
ronald wolff 
stochastic modeling theory queues 
prentice hall 

