methodology implementing highly concurrent data objects maurice herlihy digital equipment cambridge research lab crl october concurrent object data structure shared concurrent processes 
conventional techniques implementing concurrent objects typically rely critical sections ensuring process time operate object 
critical sections poorly suited asynchronous systems process halted delayed critical section nonfaulty processes unable progress 
contrast concurrent object implementation non blocking guarantees process complete operation finite number steps wait free guarantees process complete operation finite number steps 
proposes new methodology constructing nonblocking wait free implementations concurrent objects 
object representation operations written stylized sequential programs explicit synchronization 
sequential operation automatically transformed non blocking wait free operation novel synchronization memory management algorithms 
algorithms multiple instruction multiple data mimd architecture processes communicate applying read write load linked store conditional operations shared memory 
equipment 
rights reserved 
concurrent object data structure shared concurrent processes 
conventional techniques implementing concurrent objects typically rely critical sections ensure process time allowed access object 
critical sections poorly suited asynchronous systems process halted delayed critical section faster processes unable progress 
possible sources unexpected delay include page faults cache misses scheduling preemption processor failure 
contrast concurrent object implementation non blocking process complete operation system takes finite number steps wait free process complete operation finite number steps 
non blocking condition guarantees process progress despite arbitrary halting failures delays processes wait free condition guarantees non halted processes progress 
condition rules critical sections process halts critical section force processes trying enter critical section run forever making progress 
non blocking condition appropriate systems starvation strictly stronger condition may appropriate processes inherently slower certain heterogeneous architectures 
theoretical issues surrounding non blocking synchronization protocols received fair amount attention practical issues 
step addressing practical aspects proposing new methodology constructing non blocking wait free implementations concurrent objects 
approach focuses distinct issues ease reasoning performance 
ffl secret reasoning concurrent programs difficult 
practical methodology permit programmer design say correct non blocking priority queue result 
ffl non blocking wait free properties kinds faulttolerance incur cost especially absence failures delays 
methodology considered practical understand inherent costs resulting programs cost kept acceptable levels programmer ability influence costs 
address reasoning issue having programmers implement data objects stylized sequential programs explicit synchronization 
sequential implementation automatically transformed nonblocking wait free implementation collection novel synchronization memory management techniques introduced 
sequential implementation correct sequential program follows certain simple conventions described transformed program correct concurrent implementation 
advantage starting sequential programs clear formidable problem reasoning concurrent programs data structures reduced familiar sequential domain 
programmers required follow certain conventions methodology intended parallelize arbitrary sequential programs fact 
address performance issue built tested prototype implementations concurrent objects multiprocessor 
show naive implementation methodology performs poorly excessive memory contention simple techniques literature exponential backoff dramatic effect performance 
compare implementations conventional implementations spin locks 
absence timing anomalies example implementations outperform conventional spin lock techniques lie factor sophisticated spin lock techniques 
focus multiple instruction multiple data mimd architecture asynchronous processes communicate applying read write load linked store conditional operations shared memory 
load linked operation copies value shared variable local variable 
subsequent store conditional shared variable change value process modified variable interim 
way store conditional returns indication success failure 
note store conditional permitted fail variable changed 
assume spurious failures rare possible 
chose focus load linked store conditional synchronization primitives reasons 
implemented efficiently cache coherent architectures store conditional need check cached copy shared variable invalidated 
second classical synchronization primitives provably related adequate shown impossible construct non blocking wait free implementations simple useful data types combination read write test set fetch add memory register swap 
load linked store conditional operations universal principle powerful transform sequential object implementation nonblocking wait free implementation 
load linked store conditional easy 
collection synchronization memory management algorithms compare swap :10.1.1.38.1642
algorithms functionality efficient conceptually complex 
prototype implementations language encore multimax eighteen ns processors 
architecture provide load linked store conditional primitives simulated short critical sections 
naturally simulation efficient direct hardware support 
example successful store conditional requires twelve machine instructions 
prototype implementations instructive allow compare relative efficiency different implementations load linked store conditional permit approximate comparison relative efficiency waiting versus non waiting techniques 
assume readers knowledge syntax semantics section give brief survey related 
section describes model 
section protocols transforming sequential implementations small objects non blocking wait free implementations experimental results showing techniques perform process dedicated processor 
section extend methodology encompass large objects 
section summarizes results concludes discussion 
related early non blocking protocols focused impossibility results showing certain problems solved asynchronous systems certain primitives 
contrast synchronization primitive universal transform sequential object im impossibility results terms wait free implementations hold non blocking implementations 
related plementation wait free concurrent implementation 
author gives necessary sufficient condition universality synchronization primitive universal process system solves known consensus problem processes 
result established wait free non blocking implementations possible principle construction inefficient practical 
plotkin gives detailed universal construction sticky bit primitive 
construction theoretical practical interest 
author gives simple relatively efficient technique transforming stylized sequential object implementations non blocking wait free implementations compare swap synchronization primitive :10.1.1.38.1642
approach similar details quite different 
particular constructions simpler efficient reasons discussed 
researchers studied problem constructing wait free atomic registers simpler primitives 
atomic registers interesting applications concurrent data structures combined construct non blocking wait free implementations common data types 
exists extensive literature concurrent data structures constructed powerful primitives 
gottlieb give highly concurrent queue implementation replace add operation variant fetch add 
implementation permits concurrent enqueuing dequeuing processes blocking uses critical sections synchronize access individual queue elements 
lamport gives wait free queue implementation permits enqueuing process execute concurrently dequeuing process 
herlihy wing give non blocking queue implementation employing fetch add swap permits arbitrary number enqueuing dequeuing processes 
shasha give non blocking set implementation uses operations similar compare swap 
exists extensive literature locking algorithms concurrent trees related search structures 
anderson woll give efficient wait free solutions union find problem shared memory architecture 
load linked store conditional synchronization primitives proposed part project lawrence livermore laboratories currently supported mips ii architecture 
closely related compare swap operation introduced ibm architecture 
overview overview concurrent system consists collection sequential processes communicate shared typed objects 
processes sequential process applies sequence operations objects alternately issuing invocation receiving associated response 
fairness assumptions processes 
process halt display arbitrary variations speed 
particular process tell halted just running slowly 
objects data structures memory 
object type defines set possible values set primitive operations provide means manipulate object 
object sequential specification defines object behaves operations invoked time single process 
example behavior queue object specified requiring enqueue insert item queue dequeue remove oldest item queue 
concurrent system object operations invoked concurrent processes necessary give meaning interleaved operation executions 
object linearizable operation appears take effect instantaneously point operation invocation response 
linearizability implies processes appear interleaved granularity complete operations order non overlapping operations preserved 
discussed detail notion linearizability generalizes unifies number ad hoc correctness conditions literature related identical correctness criteria sequential consistency strict serializability 
linearizability basic correctness condition concurrent objects constructed 
methodology 

programmer provides sequential implementation object choosing representation implementing operations 
program written conventional sequential language subject certain restrictions 
implementation performs explicit synchronization 

synchronization memory management algorithms described sequential implementation transformed small objects non blocking wait free concurrent implementation 
address issue transformation simple performed compiler preprocessor 
refer data structures operations implemented programmer sequential objects sequential operations refer transformed data structures operations concurrent objects concurrent operations 
convention names sequential data types operations lower case names concurrent types operations capitalized 
compile time constants typically appear upper case 
small objects small object small copied efficiently 
section discuss construct non blocking wait free implementations small objects 
section slightly different methodology large objects large copied 
sequential object data structure occupies fixed size contiguous region memory called block 
sequential operation stylized sequential program subject simple constraints ffl sequential operation may side effects modifying block occupied object 
ffl sequential operation total meaning defined legal state object 
example dequeue operation may return error code signal exception applied empty queue may provoke core dump 
motivation restrictions clear discuss sequential operations transformed concurrent operations 
extended example 
priority queue type set items taken totally ordered domain examples integers 
provides operations enqueue enq inserts item queue dequeue deq removes returns item queue 
known technique implementing priority queue heap binary tree node higher priority children 
shows sequential implementation priority queue satisfies conditions 
code adapted 
small objects define parent 
define left 
define right 
void int int best swap left right best size elements elements best size elements elements best best best swap elements elements elements best elements best swap best int int int size return size elements parent elements elements parent parent elements return int int best size return best elements elements elements size return best sequential priority queue implementation small objects non blocking transformation discuss transform sequential object non blocking concurrent object 
section protocol guarantees correctness section extend protocol enhance performance 
omitting certain important details basic technique 
objects share variable holds pointer object current version 
process reads pointer load linked copies indicated version block applies sequential operation copy calls store conditional swing pointer old version new 
step fails process restarts step 
execution steps called attempt 
linearizability straightforward order operations appear happen order final calls store conditional barring spurious failures store conditional primitive protocol non blocking attempts succeed 
memory management small objects trivial 
process owns single block unused memory 
step process copies object current version block 
succeeds swinging pointer old version new gives ownership new version block acquires ownership old version block 
process replaces particular version uniquely determined block unique defined owner times 
blocks size support small objects requires blocks 
slow process may observe object inconsistent state 
example processes may read pointer block may swing pointer block start new operation 
copies copying copy may valid state sequential object 
race condition raises important software engineering issue 
subsequent store conditional certain fail may difficult ensure sequential operation store range location divide zero perform illegal action 
require programmers write sequential operations avoid actions arbitrary bit strings 
insert consistency check copying old version applying sequential operation 
consistency checked hardware software 
simple hardware solution include validate instruction checks variable read load linked small objects instruction modified 
implementing primitive architecture supports store conditional straightforward similar functionalities 
examples software solution 
version associated counters check check 
counters equal version consistent 
modify version process increments check modifications increments check 
copying process reads check copies version reads check 
incrementing counters order reading ensures counters match copy consistent 
protocol compare swap replaces store conditional consider execution reads pointer block completes operation replacing acquiring ownership completes second operation replacing compare swap erroneously install sequence version 
describe complex protocol freezes block reading ensuring block recycled attempt progress :10.1.1.38.1642:10.1.1.38.1642
mentioned resulting protocols complex efficient ones described store conditional optimizations possible 
hardware provides validate operation read operations complete successful validate store conditional object may significantly smaller full block 
programmers follow convention object true size kept fixed location block concurrent operation avoid unnecessary copying 
prototypes optimization 
ready review protocol detail 
concurrent object shared variable holds pointer structure fields version sequential object check array unsigned large integers 
process keeps pointer new points block owns 
process enters loop 
reads pointer load linked marks new version inconsistent setting check check 
reads old version check field copies version field reads check field 
counters fail match copy inconsistent process restarts loop 
process applies sequential operation counters bounded remote chance consistency check succeed incorrectly counter cycles way single attempt 
practical matter problem avoided simply large bit counter 
small objects typedef struct version unsigned check static int concurrent object seq object int result unsigned version version check copy check result break return result simple non blocking protocol small objects version field increments check indicating version consistent 
attempts reset pointer store conditional succeeds operation returns loop resumed 
experimental results non blocking property best thought kind fault tolerance 
return extra updating copy updating place program acquires ability withstand certain failures unexpected process failure delay 
section experimental results provide rough measure additional overhead allow identify evaluate certain additional techniques substantially enhance performance 
show naive implementation non blocking transformation performs poorly allowing cost simulated load linked store conditional adding simple exponential backoff dramatically increases throughput 
described constructed prototype implementation small priority queue encore multimax simulated load linked store conditional primitives 
benchmark measure elapsed time needed processes enqueue dequeue items shared element priority queue ranges 
control ran benchmark heap implementation priority queue updates done place line compiled test test set spin lock achieve mutual exclusion 
test test set spin lock built feature encore compiler represents current systems synchronize access shared data structures 
evaluating performance benchmarks important understand run circumstances timing anomalies delays occur 
process ran dedicated processor machine idle ensuring processes run 
processes repeatedly accessed small region memory making page faults 
circumstances costs avoiding waiting visible benefits 
chose circumstances best highlight inherent costs proposal 
test test set loop repeatedly reads lock observes lock free tries test set operation 
small objects define shared object int number processes process int int object random object concurrent heap benchmark horizontal axis represents number concurrent processes executing benchmark vertical axis represents time taken seconds 
top curve time taken non blocking protocol lower curve time taken spin lock 
reading graph important bear mind point represents approximately amount enqueuing dequeuing randomly generated numbers 
absence memory contention curves nearly flat simple non blocking protocol performs worse spinlock protocol allowing inherent inefficiency simulated load linked store conditional primitives 
poor performance non blocking protocol primarily result memory contention 
protocol processes making progress time 
spin lock protocol process critical section non blocking protocol process store conditional eventually succeed 
spin lock protocol processes outside critical section spinning cached copies lock generating bus traffic 
non blocking protocol contrast concurrent executions slightly efficient heap maximum possible size function level concurrency 
small objects number processes time seconds simple spin lock non blocking simple non blocking vs spin lock small objects dequeue average enq average deq maximum enq maximum simple non blocking protocol number attempts dequeue average enq average deq maximum enq maximum non blocking backoff number attempts processes generating bus traffic fraction bus bandwidth dedicated useful 
simple non blocking protocol second weakness starvation 
enqueue operation slower dequeue operation 
look average number attempts associated process see enqueues slightly unsuccessful attempts dequeues average fewer attempts 
look maximum number attempts dramatically different story emerges 
maximum number unsuccessful dequeue attempts high thousands maximum number enqueue hovers 
table shows starvation problem longer operation may difficulty completing competes shorter operations 
performance problems simple solution 
introduce exponential backoff successive attempts 
process keeps dynamically adjusted maximum delay 
operation starts halves current maximum delay 
time attempt fails process waits random duration maximum delay small objects doubles maximum delay fixed limit exponential backoff striking effect performance 
illustrated throughput non blocking protocol soon standard spin lock implementation 
starvation longer threat 
typical execution shown average number attempts operations maximum enqueues reduced order magnitude 
aside point known spin locks benefit exponential backoff 
replaced line compiled test set spin lock hand coded spin lock employs exponential backoff 
surprisingly protocol best throughput run dedicated processors twice nonblocking protocol 
summary exponential backoff non blocking protocol significantly outperforms straightforward spin lock protocol default provided encore compiler lies factor sophisticated spin lock implementation 
wait free protocol protocol wait free technique call operation combining 
process starts operation records call invocation structure inv type fields include operation name op name argument value arg toggle bit toggle distinguish old new invocations 
completes operation records result response res type structure fields include result value toggle bit 
concurrent object additional field responses element array responses th element result completed operation 
processes share element array announce invocations 
starts operation records operation name argument announce 
time process records new invocation complements invocation toggle bit 
wait free enqueue operation appears 
performing consistency check apply procedure scans responses announce arrays comparing toggle fields corresponding invocations responses 
bits disagree applies invocation speed process prototype uses precomputed table random numbers certain arithmetic operations performed equivalent bit wise logical operations 
small objects static int int int delay result unsigned version version check copy check result break backoff delay random delay return result non blocking protocol exponential backoff small objects number processes time seconds spin lock non blocking spin lock backoff backoff effect exponential backoff small objects new version records result matching position responses array complements response toggle bit 
calling apply procedure apply pending operations new version process calls store conditional replace old version just 
determine operation complete compares toggle bits invocation object matching response 
performs comparison twice comparisons match operation complete 
comparison done twice avoid race condition reads pointer version 
replaces 
starts operation scans announce applies operation new value stores tentative result responses array 
observes toggle bits match returns 
fails install version ensuring returned wrong result 
protocol guarantees long store conditional spurious failures operation complete loop iterations second store conditional succeeds operation complete 
suppose store conditional fails process executed earlier store conditional second store conditional fails process executed earlier store conditional scanned announce array performed store conditional performed store conditional updated invocation structure carried operation set toggle bits agree 
process applies termination test repeatedly backoff 
ready explain sequential operations total 
notice benchmark program process enqueues item dequeuing 
assume dequeue operation observe empty queue 
assumption wrong 
process reads object version announce array distinct steps data structures may mutually inconsistent 
slow process executing enqueue observe empty queue observe announce array dequeue operations outnumber enqueue operations 
process subsequent store conditional fail sequential dequeue operation applied empty queue 
issue arise non blocking protocol 
shows time needed complete benchmark program wait free protocol 
throughput increases concurrency spurious failures possible loop requires explicit termination test simply count 
large objects void apply announce object int announce toggle object toggle switch announce case object value object version announce arg break case object value object version break default fprintf stderr unknown operation code exit switch object toggle announce toggle apply operation amount copying operation reduced 
substantial overhead imposed scanning announce array importantly copying version responses array operation 
practical matter probabilistic guarantee starvation provided exponential backoff may preferable deterministic guarantee provided operation combining 
large objects section show extend previous section protocols objects large copied 
large objects copying major performance bottleneck 
basic premise copying explicit control programmer programmer position exploit semantics application 
large objects static static int static invocation announce static int current process id int int delay result unsigned announce announce toggle announce toggle 
responses toggle responses toggle version version check memcpy sizeof check result break backoff 
delay random delay return result wait free operation large objects number processes time seconds non blocking wait free backoff backoff non blocking vs wait free large objects large object represented set blocks linked pointers 
sequential operations large objects written functional style operation changes object state modify object place 
constructs returns logically distinct version object 
logically distinct mean old new versions may fact share substantial amount memory 
programmer responsibility choose sequential implementation performs little copying possible 
basic technique 
process reads pointer load linked applies sequential operation returns pointer new version calls store conditional swing pointer old version new 
memory management slightly complex 
operation may require allocating multiple blocks memory process owns pool blocks 
process creates new version object explicitly allocates new blocks calling alloc explicitly frees old blocks calling free 
copy primitive copies contents block 
attempt succeeds process acquires ownership blocks freed relinquishes ownership blocks allocated 
process keeps track blocks data structure called recoverable set set type 
state recoverable set sets blocks committed allocated freed 
set free operation inserts block freed set alloc moves block committed allocated returns address 
shown alloc calls set alloc marks resulting block inconsistent free simply calls set free 
recoverable set type provides additional operations explicitly called programmer 
executing store conditional process calls set prepare mark blocks allocated consistent 
store conditional succeeds calls set commit set committed union freed committed fails calls set abort set freed allocated empty set 
necessary processes share pool blocks 
process exhausts local pool allocate multiple blocks shared pool acquires blocks return surplus shared pool 
shared pool accessed infrequently possible risks contention hot spot 
techniques implementing shared pools appear shared pool prototypes shown :10.1.1.38.1642
large objects small object protocol process checks consistency copies block 
copy inconsistent process transfers control back main loop unix longjmp 
experimental results examples section convenient follow syntactic conventions 
procedures return result value follow convention sequential operations return pointer result type structure containing value field result dequeue version field new state object 
treating sequential concurrent objects distinct data structures convenient treat check array additional field sequential object invisible sequential operation 
skew heap approximately balanced binary tree node stores item node item equal item subtree rooted node 
skew heap implements priority queue amortized cost enqueuing dequeuing items skew heap logarithmic size tree 
purposes advantage skew heap conventional heap update operations leave tree nodes untouched 
skew operation merges heaps 
chooses heap lesser root swaps right left children balance right child heap 
insert item skew enq heap containing 
remove item skew deq removes item root root left right subtrees 
modified priority queue benchmark initialize priority queue hold randomly generated integers 
shows relative throughput non blocking skew heap spin lock heap updates place spin lock skew heap updates place 
non blocking skew heap spin lock heap spin lock skew heap twice throughput non blocking skew heap agreement experimental results small object protocol 
large objects typedef struct int full empty slots int number frees int size number committed entries int reset abort blocks pointers blocks settype settype size fprintf stderr alloc exit blocks return void settype size size void settype int blocks check alloc pool check check return part recoverable set implementation large objects typedef struct int value int toggle left right 
struct child left right children int check inserted system assumes argument copied 
qq int toggle return qq empty return qq return pool copy copy qq pool qq value value toggle toggle child toggle child toggle toggle toggle return toggle toggle child toggle child toggle toggle toggle return skew heap operation large objects left right buffer static value version copy buffer pool value buffer value left buffer child right buffer child 
left version right alloc pool copy left pool left version right return skew heap dequeue operation large objects number processes time seconds heap non blocking skew heap skew heap spin lock spin lock large heap throughput conventional concurrency control techniques mutual exclusion originally developed single processor machines processor multiplexed number processes 
maximize throughput uniprocessor architecture suffices keep processor busy 
multiprocessor architecture maximizing throughput complex 
individual processors subject unpredictable delays throughput suffer process capable making progress unnecessarily forced wait 
address problem number researchers investigated non blocking algorithms data structures rely waiting synchronization 
theoretical 
obstacles making approach practical conceptual complexity performance 
conceptual complexity refers known difficulty reasoning behavior concurrent programs 
practical methodology constructing highly concurrent data structures include mechanism ensuring correctness 
performance refers observation avoiding waiting kinds faulttolerance incurs cost needed 
methodology practical overhead kept minimum 
methodology proposed address issue conceptual complexity proposing programmers design data structures stylized sequential manner 
programs sequential formal informal reasoning greatly simplified 
address issue performance ways ffl observe load linked store conditional synchronization primitives permit significantly simpler efficient algorithms compare swap 
ffl propose extremely simple efficient memory management techniques 
ffl provide experimental evidence naive implementation non blocking protocol incurs unacceptable memory contention contention eliminated applying known techniques exponential backoff 
prototype implementations inefficient simulated synchronization primitives outperform conventional test test set spin lock implementations lie factor sophisticated exponential backoff spin lock implementations 
ffl large objects programmers free exercise ingenuity keep cost copying control 
possible correctness responsibility system performance responsibility programmer 
promising area research concerns exploit type specific properties increase concurrency 
approach sacrifice simplicity methodology programmer reason explicitly concurrency 
methodology construct simple concurrent objects combined implement complex concurrent objects way link trees combine sequence low level atomic operations implement single atomic operation level 
illustrated andrews schneider comprehensive survey language constructs shared memory architectures focus techniques managing mutual exclusion 
transformations described simple performed compiler preprocessor intriguing speculate programming language support methodology proposed 
example inheritance convenient way combine object fields check variables run time system introduced programmer 
programming language design raises complex issues lie scope issue merits attention 
anderson woll 
wait free parallel algorithms problem 
proceedings rd annual acm symposium theory computing pages may 
anderson 
performance spin lock alternatives sharedmemory multiprocessors 
ieee transactions parallel distributed systems january 
andrews schneider 
concepts notations concurrent programming 
acm computing surveys 
bayer 
concurrency operations trees 
acta informatica 
biswas browne 
simultaneous update priority structures 
proceedings international conference parallel processing pages 
bloom 
constructing writer atomic registers 
proceedings sixth acm symposium principles distributed computing pages 
burns peterson 
constructing multi reader atomic values non atomic values 
proceedings sixth acm symposium principles distributed computing pages 
chor israeli li 
processor coordination asynchronous hardware 
proceedings sixth acm symposium principles distributed computing pages 
mips computer 
mips risc architecture 
cormen leiserson rivest 
algorithms 
mit press cambridge ma 
encore computer 
multimax technical summary 
order number rev dolev dwork stockmeyer 
minimal synchronism needed distributed consensus 
journal acm january 
dwork lynch stockmeyer 
consensus presence partial synchrony 
journal acm april 
dwork shmoys stockmeyer 
flipping constant expected time 
seventh annual symposium foundations computer science pages october 
ellis 
concurrent search insertion trees 
acta informatica 
fischer lynch paterson 
impossibility distributed commit faulty process 
journal acm april 
ford 
concurrency control mechanisms serializability concurrent tree algorithms 
rd acm symposium database systems pages 
gottlieb grishman kruskal mcauliffe rudolph snir 
nyu designing mimd parallel computer 
ieee transactions computers february 
gottlieb rudolph 
basic techniques efficient coordination large numbers cooperating sequential processors 
acm transactions programming languages systems april 
guibas sedgewick 
dichromatic framework balanced trees 
th acm symposium foundations computer science pages 
herlihy wing 
axioms concurrent objects 
th acm symposium principles programming languages pages january 
herlihy 
impossibility universality results wait free synchronization 
seventh acm sigact sigops symposium principles distributed computing august 
herlihy :10.1.1.38.1642
methodology implementing highly concurrent data structures 
proceedings second acm sigplan symposium principles practice parallel programming pages march 
ibm 
system principles operation 
order number ga 
jensen 
new approach exclusive data access shared memory multiprocessors 
technical report lawrence livermore national laboratory november 
jones 
concurrent operations priority queues 
communications acm january 
kernighan ritchie 
programming language 
prentice hall englewood cliffs new jersey 
lamport 
concurrent reading writing 
communications acm november 
lamport 
multiprocessor computer correctly executes multiprocess programs 
ieee transactions computers september 
lamport 
specifying concurrent program modules 
acm transactions programming languages systems april 
lamport 
interprocess communication parts ii 
distributed computing 
shasha 
concurrent set manipulation locking 
proceedings seventh acm symposium principles database systems pages march 
lehman yao 
efficient locking concurrent operations trees 
acm transactions database systems december 
mellor crummey scott 
algorithms scalable synchronization shared memory multiprocessors 
technical report university rochester rochester ny april 
metcalfe boggs 
ethernet distributed packet switching local computer networks 
communications acm july 
newman wolfe 
protocol wait free atomic multi reader shared variables 
proceedings sixth acm symposium principles distributed computing pages 
papadimitriou 
serializability concurrent database updates 
journal acm october 
peterson 
concurrent reading writing 
acm transactions programming languages systems january 
peterson burns 
concurrent reading writing ii multi writer case 
technical report git ics georgia institute technology december 
plotkin 
sticky bits universality consensus 
proceedings eighth acm symposium principles distributed computing pages 
rudolph 
decentralized cache scheme mimd parallel processor 
th annual computing architecture conference pages 
sagiv 
concurrent operations trees overtaking 
acm database systems pages january 
singh anderson gouda 
elusive atomic register revisited 
proceedings sixth acm symposium principles distributed computing pages 
sleator tarjan 
self adjusting binary trees 
proceedings th acm symposium theory computing pages 
