comparing performance database selection algorithms james french allison powell department computer science university virginia charlottesville va alp gg cs virginia edu jamie callan center intelligent information retrieval computer science department university massachusetts amherst ma callan cs umass edu charles viles school information library science university north carolina chapel hill chapel hill nc viles ils unc edu travis kevin prey department computer science university virginia charlottesville va fte fg cs virginia edu yun mou center intelligent information retrieval computer science department university massachusetts amherst ma cs umass edu compare performance database selection algorithms reported literature 
performance compared common testbed designed specifically database selection techniques 
testbed decomposition trec tipster data subcollections 
results investigation performance cori algorithm compare performance earlier examined performance ggloss 
databases testbed ranked ggloss cori techniques compared rbr baseline baseline derived trec relevance judgements 
examined degree cori ggloss approximate baseline 
results confirm earlier observation ggloss ideal ranks estimate relevance supported part darpa contract nasa ngt 
supported part nsf library congress department commerce agreement eec patent trademark office darpa ito contract 
supported part darpa contract 
supported part darpa contract 
supported part nsf library congress department commerce agreement eec patent trademark office darpa ito contract 
ranks 
find cori uniformly better estimator relevance ranks ggloss test environment study 
part advantage cori algorithm explained strong correlation ggloss size baseline sbr 
find cori produces consistently accurate rankings testbeds ranging sites 
level recall search effort appears scale linearly number databases 
proliferation online resources growing need conduct search resources de facto requirement pruning resource set interest manageable size increased attention retrieval distributed environment 
distributed information retrieval encompasses important problems including ffl database collection selection ffl collection fusion results merging ffl dissemination collection information increase retrieval effectiveness :10.1.1.46.8448:10.1.1.31.1173
focus database selection fundamental problem distributed environment providing direct comparison database selection techniques described literature 
problem stated intuitively process selecting hopefully small set databases send query 
database selection step process continues search distributed sites fusing merging result lists sites 
primary goal step select small set collections possible send query sacrificing retrieval effectiveness 
evaluation database selection techniques involved approaches ir research community database research community 
ir approach embodied callan french xu callan focused importance including relevance information evaluation ranked list collections send query eventual lists documents returned collections 
db approach embodied gravano include relevance information compares selection technique ideal ordering represents behavior individual search systems :10.1.1.31.1173
rationale selection technique better underlying constituent systems 
techniques database selection proposed independently evaluated test environments varied underlying data evaluation methods 
little literature direct comparison competing techniques 
study directly compares techniques ggloss cori common test environment data evaluation techniques 
goals study 
goal demonstrate sound methodology systematic study algorithms relative performance 
second important goal gain insight collective individual behavior algorithms 
believe study achieves goals 
database selection experiment section describes comparative experiments database selection 
earlier described testbed methodology examining behavior algorithms 
proposed metrics analyses designed illuminate behavior algorithm study 
testbed metrics reviewed 
earlier concentrated measuring performance ggloss test environment 
concerned determining ggloss compares database selection algorithm cori 
problem distributed searching composed fundamental activities choosing specific databases search searching chosen databases merging results cohesive response 
focus specifically activity 
callan call collection selection problem gravano refer text database resource discovery problem 
french refer database selection retain terminology consistency 
experiments investigate ggloss cori methodologies common test environment compare performance ranking rbr baselines described fully 
testbed number researchers working issues distributed information retrieval systems test environments idiosyncratic data evaluation measures making impossible compare results 
french proposed test environment systematic study distributed information retrieval algorithms 
testbed tipster data trec conferences 
decompose large collections smaller subcollections serve hypothetical sites distributed information retrieval test environment 
data decomposed source year month resulting sites 
trec topics test queries earlier study 
characteristics testbed queries details french 
algorithms considered ggloss gravano proposed gloss glossary server approach database selection problem boolean ir model 
gloss generalized ggloss handle vector space information retrieval model 
generalization ir model computes score determine document satisfies query provided certain collection statistics available ggloss 
ggloss assumes databases characterized goodness respect particular query 
ggloss job estimate goodness candidate database respect particular query suggest ranking databases estimated goodness 
called optimal ranking callan 
goodness database db defined follows 
goodness db lg sim sim function calculates similarity query document goodness db calculated database db respect threshold ideal rank query threshold ideal formed sorting databases descending order goodness 
note ggloss compute ideal advanced goal ggloss estimated ranks max sum defined compared 
french showed ggloss max sum estimators job estimating ideal 
showed ideal correlated relevance 
complete details calculating max sum estimators reproduced 
note max sum ideal threshold estimators give identically ideal ranking databases queries 
addition allows consistent comparison ideal rankings comparing different underlying retrieval systems produce differently scaled similarity values sim equation 
evaluation follow ideal ggloss estimate ggloss compute exactly 
note ggloss needs vectors information database db order estimates 

document frequency df ij term db 
sum weight term documents db column sums document term matrix 
underlying database divulge information directly principle possible recover information issuing single term query vocabulary term 
choice ideal obviates compute ideal directly databases simply issuing test queries 
cori set databases search cori approach creates database selection index database represented terms document frequencies df 
databases ranked query variant inquery document ranking algorithm 
belief jc collection due observing query term determined df df delta cw cw log jcj cf log jcj jc delta delta df number documents containing cf number collections containing jcj number collections ranked cw number words cw mean cw collections ranked 
belief collection depends query structure usually just average jc values query term 
cori approach ranking collections summarized df icf icf inverse collection frequency 
experiment earlier evaluation determined ggloss estimates ideal ideal estimate relevance rankings 
step current study determine cori estimated relevance rankings 
tested cori algorithm testbed full subcollections trec data described earlier 
trec topics test query set 
controlling indexing vocabulary prepared test collection smart version parameters gravano 
note experiments sites parameters search engine smart process queries 
prepared union vocabulary incorporating terms appearing separate collections 
gave canonical global vocabulary store document frequencies weight sums required ggloss estimates 
control cori evaluation properly necessary guarantee indexing vocabulary ggloss cori 
sources variability arise parsing original trec documents tokenizing document words stemming algorithm stoplist 
control factors synthesized pseudo documents collection 
stemmed stopped vocabulary smart indexing done emitted term tf times padding document back original length fake word 
inquery run stemming single word stoplist 
necessary handle special characters differently 
result inquery indexed exactly vocabulary smart earlier experiments 
note possible steps took control indexing vocabulary hindered cori performance 
specifically cori default inquery tokenizer stemmer may produced better results 
evaluation baselines comparison refer number baselines evaluation specifically ggloss baseline ideal relevance ranking rbr size ranking sbr 
defined follows 
ideal ranking produced processing query subcollections goodness see equation rank subcollections 
rbr rankings produced query relevance judgements supplied trec data 
rbr baseline databases simply ordered number relevant documents contain 
sbr databases ordered total number documents contain 
note ranking constant queries 
evaluation metrics comparison earlier mean squared error recall metrics rn rn precision measure pn 
addition spearman coefficient rank correlation 
discussed 
mean squared error group databases rank candidate ranking compute mse base rank db gamma est rank db base rank db baseline desired rank est rank db predicted rank db recall precision analogs discussed performance metrics analogous known ir metrics recall precision 
briefly review metrics 
provide baseline ranking represents desired goal query 
algorithm produces estimated ranking query goal decide approximates assume database db collection merit merit db query baseline expressed terms merit estimate formed implicitly explicitly estimating merit 
db db denote database th ranked position rankings respectively 
merit db merit db denote merit associated th ranked database baseline estimated rankings respectively 
results follow convention 
ideal calculations merit db goodness db rbr define merit db number relevant documents db sbr define merit db total number documents db 
gravano defined rn follows 
rn measure available merit top ranked databases baseline accumulated top databases estimated ranking 
alternative definition rn maxk intuitively breakpoint useful useless databases 
denominator just total merit contributed databases useful query 
rn measure total merit accumulated top databases estimated ranking 
lu suggested measure 
gravano proposed measure pn defined follows 
pn db gj jt gives fraction top databases estimated ranking non zero merit 
spearman coefficient rank correlation spearman coefficient rank correlation ae ae gamma gamma difference th paired ranks 
gamma ae ae rankings perfect agreement ae gamma perfect disagreement 
results results follow report comparison database selection techniques ggloss cori baseline ideal represent ggloss 
metrics mse pn rn rn perform comparison 
examine potential reasons differences performance discuss heuristic lower bound performance 
query id mse ideal rbr mean cori rbr mean mse values cori ideal approximating rbr 
cori evaluation step evaluate performance cori database selection algorithm evaluation measures described french 
evaluation measures include mean squared error precision analog pn recall analogs rn rn cori evaluated measures 
comparison show performance ggloss ideal measures 
experiments rbr baseline standard compare algorithm performance best possible performance measure approximate rbr exactly 
considered mean squared error differences ideal cori rankings rbr baseline 
mse provide general impression similarity rankings query rbr rbr cori rbr ideal rbr cori results compared ggloss maximum achievable performance 
query basis 
shows mse values cori ideal 
mse values approaches range mse values cori lower average mse values ideal queries 
suggests cori may approximate rbr closely ggloss 
evaluated cori pn rn rn measures 
measures help reveal nature degree discrepancies shown mse 
results rn shown results pn rn included summary figures 
graph labeling convention needs word explanation 
label curve database selection algorithm estimator employed baseline compared 
curve labeled rbr rbr intended show best possible behavior baseline estimate 
figures plots ideal cori compared plot rbr rbr 
measures cori approximates rbr baseline closely ggloss ideal 
rn difference get different perspective impact performance difference examined data plotted 
displays average performance queries rn measure 
measure shows rate relevant documents accrued additional collections considered 
way view data determine collections ranking considered reach value rn table shows values cori ggloss ideal compared highest achievable value 
examining readily apparent fewer collections need considered reach level rn cori ranking ideal ranking 
reinforced table 
apparent table cori ranking greater advantage rn values 
goal exhaustive searching cori ranking efficient 
regions interest 
regions seen figures 
measures roughly performance algorithms fairly close 
greater roughly algorithms faced situation relevant documents located little improvement possible 
range cori evident advantage seen table 
rn number collections required achieve rn cori ideal best achievable table rn cori ideal analysis discussion cori ggloss comparison immediate question cori approximated rbr baseline closely ggloss ideal 
initial observation performance differences due indexing differences 
initial ggloss experiments intended reproduce experimental setup gravano garcia molina 
result exact underlying retrieval engine parameter settings reported smart ntc weights document terms nnn weights query terms 
shown different weights normalization approaches smart improves retrieval performance large trec collections considered improvement shown cori due simply better tuned indexing information 
underlying inquery collection indexes generate cori inference net generate additional ideal baseline inquery indexing information 
refer new ideal baseline ideal inquery 
ideal inquery approximated rbr accurately ideal imply indexing weights inquery provided better input ggloss algorithm 
case representative compare cori performance ideal inquery ideal 
comparisons ideal ideal inquery baseline rbr evaluation measure rn shown 
comparisons pn rn included summary figures 
rbr rbr ideal rbr ideal inquery rbr ideal note fact performance ggloss declined inquery weighting information 
conclude improved performance inquery due differences term weighting 
certain aspect cori database selection algorithm responsible performance difference 
conjectured ggloss database documents low similarity may appear useful database documents high similarity 
possible cori utilizing better length normalization strategy allows avoid difficulty 
formulation sbr collection testbed produced partitioning trec data publishing source year month 
result number documents collection varies widely testbed 
detailed examination results ggloss experiments noted recurring themes rankings produced ideal 
appeared ideal routinely ranked highly collections large numbers documents 
examination rbr baseline revealed collections large number documents tended representation relevant documents 
voorhees noticed similar phenomenon specifically distribution relevant documents uneven document sources 
noted strategy retrieving ap wsj effective trec data 
decomposition subcollections derived ap wsj tend large number documents 
created new baseline size ranking sbr databases ordered total number documents contain 
sbr baseline determine correlation collection size ideal rbr fact exist 
value spearman ae ranges denoting strong negative correlation denoting correlation denoting strong positive correlation 
spearman ae measure correlation ideal sbr rbr sbr 
results shown 
query id spearman ideal sbr mean rbr sbr mean cori sbr mean spearman ae values ideal rbr compared sbr 
noted strong positive correlation ideal sbr queries 
correlation cori sbr pronounced strong 
moderate positive correlation rbr sbr queries 
sbr simple heuristic constant queries computationally intensive 
show sbr closely approximate performance ideal testbed 
consider sbr useful lower bound database selection performance collection 
relationship sbr ideal ggloss computes collection scores summing documents collection 
result ggloss favors collections large number documents 
testbed performance ggloss ideal strongly influenced feature algorithm 
ideal strongly positively correlated sbr 
evidence correlation seen figures 
approximation rbr ideal closely tracks approximation rbr sbr 
note ideal consistently outperform sbr 
figures show approaches discussed approximate rbr 
measures cori outperforms ggloss 
note sbr represents useful lower bound performance testbed 
rbr rbr sbr rbr cori rbr ideal rbr ideal inquery rbr cori results compared ggloss maximum achievable performance pn ideal plots appear similar making difficult judge performance difference cori ideal 
examining plotted data determined cori shows rbr rbr sbr rbr cori rbr ideal rbr ideal inquery rbr cori results compared ggloss maximum achievable performance rn rbr rbr sbr rbr cori rbr ideal rbr ideal inquery rbr cori results compared ggloss maximum achievable performance rn total num 
size total db source queries gb docs trec trec subset trec vlc table characteristics testbeds scaling experiments 
improvement ideal approximately improvement 
note ideal shows sbr approximately ideal begins track sbr closely 
experiments need examine implications correlation ideal sbr 
testbed experiments reported clear preference large collections degraded performance ggloss testbed positive correlation sbr rbr 
testbed negative correlation sbr rbr preference large collections degrade performance ggloss database selection algorithm feature 
experiments create additional testbeds number documents collection held constant 
allow examine algorithm performance collection size preference controlled 
scaling database selection algorithms database selection algorithms increasingly necessary number databases grows databases 
early research database selection testbeds databases suggested selection algorithms accurate 
algorithms improved applied testbeds databases experimental results ambiguous 
high priority research determine cori algorithm remains effective number databases increases 
testbeds experiments conducted collection testbed additional testbeds collections collections 
summary characteristics testbeds provided table 
collection testbed created dividing trec cds smaller databases roughly equal size megabytes 
database contained documents single source ordered occur trec cds documents database usually similar 
cd contributed databases cd contributed databases cd contributed databases 
collection testbed created dividing trec vlc corpus smaller databases roughly equal size subject source document adjacency constraints creating collection testbed 
queries trec topics 
query sets inq inq inq created umass ciir part participation trec tipster evaluations 
queries sets long complex undergone automatic query expansion 
relevance assessments standard trec relevance assessments supplied national institute standards technology 
relevance judgements vlc data relatively sparse additional relevance judgements queries gathered trained undergraduates 
additional relevance judgements little impact results results reported 
experiments effectiveness cori database selection algorithm measured described 
tests applied percentage databases searched experiments testbeds different sizes compared 
call variations number databases testbed 
results figures summarize experimental results 
measurements show testbeds collections ranked highly cori selection algorithm contain large percentage relevant documents 
encouraging sign 
may appear algorithm effective databases available searching artifact distribution relevant documents databases 
measurements normalizes best result possible searching percentage databases show effectiveness collection testbeds similar 
difference small percentage collections searched case effectiveness large testbed substantially lower 
collections searched collections collections collections database selection accuracy testbeds different sizes 
collections searched collections collections collections scaled database selection accuracy testbeds different sizes 
collection testbed appears slightly easier testbed collection collection testbeds results similar 
effectiveness cori algorithm appears related consistently percentage databases searched irrespective testbed size 
inappropriate recall oriented metrics implies tenfold increase available databases requires tenfold increase search effort achieve level recall 
prefer linear relationship testbed size search effort suggests additional research database selection algorithms required 
examined performance database selection algorithms ggloss cori 
demonstrated high correlation ideal ranks sbr baseline 
supports conjecture ggloss database documents marginal similarity appear aggregate useful database having documents large similarity 
shown cori better estimator rbr ggloss effective rn levels 
part may due better length normalization strategy cori confounded databases documents small similarity 
shown difference performance cori ggloss due inquery weighting versus smart weighting 
experiments cori approach required fewer databases searched ggloss average achieve specific recall level 
implies cori cost effective large distributed environments having lower latency searches 
experiments investigating cori algorithm scales large numbers databases produced mixed message 
cori selection algorithm produced consistently accurate rankings testbeds ranging collections 
clearly positive result 
consistency observed percentage databases searched number databases searched 
level recall search effort appears scale linearly number available databases 
linear relationship desirable required environments containing large numbers databases 
results suggest research database selection algorithms required 
demonstrated systematic methodology examining database selection algorithms 
study kind 
investigate database selection algorithms framework able compare performance common experimental environment 
instructive repartition testbed similar number sites site having number documents 
number ways drawbacks 
partition completely defeat sbr baseline site equal merit sites equally useful sbr baseline 
think demanding search environment offer greater insight behavior kinds algorithms 
allan callan croft ballesteros byrd swan xu 
inquery battle trec 
sixth text retrieval conference trec 
belkin kantor fox shaw 
combining evidence multiple query representations informa tion retrieval 
information processing management 
buckley 
smart version 
ftp ftp cs cornell edu pub smart 
buckley allan salton 
automatic routing ad hoc retrieval smart trec 
proceedings second text retrieval conference trec pages march 
buckley salton allan 
automatic retrieval locality information smart 
proceedings text retrieval conference trec pages march 
callan croft broglio 
trec tipster experiments inquery 
information processing management 
callan lu croft 
searching distributed collections inference networks 
proceedings th international conference research development information retrieval pages 
fox shaw rao 
combining evidence multiple searches 
text retrieval conference trec pages november 
french powell viles prey 
evaluating database selection techniques testbed experiment 
proceedings st annual international acm sigir conference research development information retrieval pages august 
french viles 
ensuring retrieval effectiveness distributed digital libraries 
journal visual communication image representation 
fuhr 
decision theoretic approach database selection networked ir 
acm transactions information systems 
appear 
gibbons 
nonparametric methods analysis 
holt rinehart winston 
gravano garcia molina 
generalizing gloss vector space databases broker hierarchies 
proceedings st international conference large databases vldb 
gravano garcia molina tomasic 
gloss text source discovery internet 
acm transactions database systems appear 
gravano garcia molina tomasic 
effectiveness gloss text database discovery problem 
sigmod pages may 
harman 
overview fourth text retrieval conference trec 
proceedings fourth text retrieval conference trec 
lu callan croft 
measures collection ranking evaluation 
technical report tr computer science department university massachusetts 
moffat zobel 
information retrieval systems large document collections 
proceedings third text retrieval conference trec pages 
singhal buckley mitra 
pivoted document length normalization 
proceedings th annual international acm sigir conference research development information retrieval pages august 
viles french 
trec experiments drift 
proceedings fourth text retrieval conference trec 
viles french 
dissemination collection wide information distributed inform ation retrieval system 
proceedings th international conference research development information retrieval pages july 
voorhees gupta johnson laird 
learning collection fusion strategies 
proceedings th international conference research development information retrieval pages 
voorhees gupta johnson laird 
collection fusion problem 
proceedings third text retrieval conference trec pages 
xu callan 
effective retrieval distributed collections 
proceedings st annual international acm sigir conference research development information retrieval pages august 
lee 
server ranking distributed text retrieval systems internet 
proceedings fifth international conference database systems advanced applications pages april 

