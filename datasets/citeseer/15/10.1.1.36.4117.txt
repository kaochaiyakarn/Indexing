knowledge approach lifelike gesture animation 
inclusion additional modalities communicative behavior virtual agents speech moved focus human computer interface researchers humans consider computer generated figures lifelike appropriate nonverbal behaviors displayed addition speech 
propose knowledge approach automatic generation gesture animations articulated 
combines formalism representation spatiotemporal gesture features methods planning individual gestural animations form timing formation arm trajectories 
enhanced methods rendering animations motor programs incorporated execution planned gestures 
approach targetted achieve great variety gestures higher degree synthetic agents 
communicative behaviors virtual anthropomorphic agents widely human computer interfaces increasingly extended additional modalities speech order achieve natural efficient reliable communication link human machine 
increased robustness communication humans consider computer generated figures lifelike nonverbal behaviors displayed addition speech 
turn enables social communicative attributions artificial agent internal states communicative intent social responses increase efficiency smoothness human human communication 
hand arm gestures integral part human human dialogues ingredients practiced communicative skill candidates extending communicative capabilities virtual agents 
focus production gestures articulated agent gestural movements accompanying speech flow meet requirements simultaneously spatiotemporal features intended gesture produced properly spatial features handshape trajectories kinematic characteristics sudden halts gesture speech coordinated sensitively respect semantics pragmatics gestural movements fulfill severe timing constraints resulting temporal synchrony employed modalities agent gestures look natural humans sensitive observers motion particular motions supposed convey meaning gestures artificial intelligence group faculty technology university bielefeld germany email de stefan 
partial view articulated structure virtual agent comprising joints including hands 
generating movements highly articulated frequently low level providing detailed flexible control causes problem controlling excessive number degrees freedom dof coordinated way 
natural take account findings various fields relevant production performance gesture humans psycholinguistics motor control theory order construe appropriate method generating controlling gestural movements synthetic humanoid 
discuss results related disciplines hierarchical knowledge approach generation animation lifelike gestures articulated shown fig 

model conceived drive underlying kinematic skeleton virtual agent comprises dof joints main body dof joints hand 
gesturing humans contrast task oriented movements reaching grasping gestures derived great extent kind internal representation shape 
gestural movement exhibits shape dynamical properties enable humans distinguish subsidiary movements recognize meaningful 
kendon points human gestures considered composed gesture phrases 
turn consist movement phases preparation various holds stroke meaningful mandatory part gesture phrase retraction forming hierarchical structure 
mcneill gestures generated unconsciously closely related speech flow yielding semantic pragmatic temporal synchrony modalities 
points stroke onset time stressed syllable speech 
information processing models production gesture hybrid knowledge representations working memory including propositional information passed motor planning control system 
model provides module decides information conveyed gesture time 
different types information expressed different kinds gestures defined sketch encoding relevant information 
sketch passed lower levels gestural movement planned executed 
model contrast gestures precede conceptualization assumed products memory representations communicative intentions 
authors assume separate module responsible selection spatial dynamical features activated representations memory rendered spatial dynamic specifications movements passed motor planner 
models rely vaguely defined subprocesses translation information motor programs bodily movements 
models human motor control commonly conceived hierarchical structure 
highest levels global aspects movement represented form goal 
control passed progressively lower levels particular choices motor units 
higher levels system direct control low level motion generators muscle contractions adjacent levels control eventually result contractions 
control may appear reside levels simultaneously processes occuring parallel different levels 
proposes general scheme motor control incorporates levels approaches 
planning voluntary movements performed directly terms kinematics external cartesian space complex intrinsic representations joint rotation signals 
formation arm trajectories done basis knowledge initial arm position target location 
suggests primarily significant locations postures represented internally intermediate movements generated motor control system automatically 
planning movement constitutes step information processing goal planned movement expressed terms trajectory 
motor control system able perform internal simulation movement generate function reflects desired trajectory 
second step translate simulated trajectory motor variables drive lower structures 
resulting virtual trajectories partially encode certain properties movement including patterns transition initial final position 
third step execution commands lowest level leads movement ideal case exactly follows simulated trajectory 
motion generation synthetic gesture concerning automatic generation lifelike gesture virtual agents done developing presentational agents andr 
systems mainly focus formation planning multimodal presentations certain discourse situations 
resulting utterances include completely predefined stereotyped gestures chosen behavior databases 
similarly animated conversation system cassell focusses formation communicative acts discourse situations provides heuristic rules gen eration gestures 
gestural movements apparently predefined parametrized terms alteration single gesture phases foreshortening relaxation phase prerecorded canonical gesture time exceeds actual timing constraints appears means coherently modifying gestural movement preserving natural movement features typical velocity profiles 
perlin goldberg created lifelike motions virtual actors means script animations subject rhythmic constraints stochastic noise functions yielding slight permanently altered appearance 
sensori motor model restricted hand attached segment arm generates natural hand arm movements basis successive target points annotated synchronization properties 
natural motion achieved heuristic knowledge minimization cost function inverse kinematics computation arm postures estimation movement duration 
emote model zhao emphasizes qualitative aspects movement increase naturalness independently predefined human motions 
effort shape components laban movement analysis operational models expressive arm torso movements provide intuitive way controlling manner movements movement 
summary systems produce movements extent fully rely predefined motion sequences 
approach proves sufficient symbolic gestures waving clearly inadequate comes creation context dependent gestures careful synchronization coordination additional modalities 
flexible representation needed specifying significant spatial kinematic features gestures temporal relationships adjust individual context accompanying speech 
descriptions serve basis planning gestural movement respect form timing final execution 
comprehensive model automatic generation gestures flexible symbolic descriptions spatiotemporal features lacking 
model animation lifelike gesture general goal research operational model enables convincing gesture animation adequate representations spatiotemporal gesture knowledge filling gap models gesture production low level motion control 
provide means motion planning performed extrinsic representation principle smaller complexity controlling configurations highly articulated shown fig 
eventually described intrinsically joint angles 
furthermore flexible sense gestures fully parametrized respect kinematics velocity profile duration stroke time shape properties 
conceived model shown fig 
incorporates major stages gesture planning generation execution motor command provides necessary computational steps gesture planning movement execution 
section describes gesture generation process provides detailed analysis planning steps 
gesture planner automatic motion generation usually starts creating initial final optional intermediate postures 
actual motion created gesture request generation execution motor command hand motor system gesture planner body allocation gesture selection pointing movement pointing planning motor programs motor planner arm motor system trajectory formation kinematic model animation rendering 
overview proposed model gesture animation 
connecting postures sequences 
unrealistic assume final postures task level goal advance revert definite spatiotemporal properties gesture provide postural kinematic constraints movement see section 
gesture planning stage mandatory spatial dynamical features translated trajectory cartesian workspace meets intended motor goal 
involves creation image movement relevant limbs formed sequencing spatial features gesture 
spatiotemporal information previous stages gesture production location referent deictic gesture outlined shape iconic gestures retrieved representations gesture knowledge hand shape pointing preferred ways pointing 
model comprises lexicon contains feature descriptions gestural movements information usage transferring communicative intent function gesture called 
gesture knowledge agent defined mappings communicative content explicitly described movements 
gesture described template contains unique identifiers gesture function mandatory features gesture stroke described terms movement constraints 
turn define postural features static constraints significant movement phases dynamic constraints met far possible lower motor levels 
regard hand arm gestures template may contain slot value pairs hand shape hand orientation palm orientation forearm twist extended finger orientation rotational degrees freedom wrist hand location terms hand coincides root joint branched kinematic chain hand model hand movement 
certain invariant features defined independently symbolic gesture notation system determined individual gesture 
description accommodates entries uniquely refer specific values content gesture convey quantitative parameters position size 
order specify gesture course time temporal relationships simultaneous subsequent gesture features represented qualitatively constraint tree parallel sequence nodes optionally nested 
number parameters left unspecified exact hand location pointing duration gesture speaking gesture template 
consider example deictic gesture virtual agent convey location object certain direction gesture 
appropriate pointing gesture pointing index finger fulfills desired function ref loc retrieved mapping ident pointing function refer loc constraints parallel static handshape static static static static pointing gesture definition specifies invariant features symbolic descriptions explanations adjusted assigning parameter values derived actual content second applying optional external temporal constraints gesture stroke times validity individual movement constraints determined 
descriptions basis gesture selection movement planning described 
body allocation gesture selection gesture planner decide limb gesture 
choice partially resembled retrieval specific gesture template planner collects gestures fulfill required communicative function 
account information various sources proprioceptive feedback specific attributes actual gesture planner suggests particular gesture template description pointing suits best actual movement conditions 
movement planning succeeding gesture selection gesture planner starts plan individual movement 
relevant spatiotemporal characteristics gesture stroke planned stage 
positioning limb preparation stroke moving back rest position generated motor programs lower level 
step movement planning complete constraints gesture specification 
concrete values variant features determined inserted appropriate slots 
instance features pointing gesture pointing eventually determined follows symbols parentheses 
hand shape separated index finger completely stretched fingers bent 
vector denotes position index finger tip respect hand root joint 

palm oriented downwards extended finger orientation direction vector originating wrist running back hand collinear target direction bound vector 
location hand position index finger tip equals target position referred 
note relation holds hand pointing gestures index finger completely stretched 

hand movement halts simultaneously occurence features 
planner applies possible external temporal constraints stroke onset duration due cross modal synchronization schedules gesture stroke appropriately 
movement constraint assigned start time constraint needs satisfied resulting motion 
done traversing tree structure gesture specification see prescribes qualitatively general temporal relationships single movement constraints 
children parallel node assigned start time children sequence node ordered consecutively 
complete timing definition movement constraints course determined solely stroke timing 
stroke timing restricted necessary synchrony constraints concerning mainly stroke onset 
furthermore optional movements executed preparation satisfying certain constraint planned explicitly stage 
movement phases influence temporal structure resulting gesture movement timing may refined lower levels 
start times individual constraints ranked numerical values zero defining level commitment underlying motor system 
timing constraints qualified firmly stage assigned maximum value uncertain times left variable 
fig 
movement plan grasping gesture shown scheduled performed seconds 
time points stated definitely stroke timing may subject variations assigned commitment value zero 
summary gesture planner forms movement plan tree representation temporally ordered set movements constraints retrieving feature gesture specification adapting individual gesture context qualifying movement constraints extent possible applying external temporal constraints 
generation execution motor command human movements particular gestures exhibit typical movement patterns adopt concept motor programs encapsulate control patterns motion variables joint angle values 
motion control decomposed motor planner simple modules overcome problem driving excessive dof highly articulated structures 
motor planning distribution motion control specialized motor systems done distinguishing movement constraints affected body parts 
currently control hand arm movements separated system 
relying independence motor systems crucial guarantee synchronization discrete time points 
assured previous integrated movement handshape start start handshape start start start start 
hierarchical movement plan grasping gesture 
planning ordering related constraints lists preserving temporal relationships 
resulting constraint sets passed dedicated motor turn generate appropriate motor programs execution 
movement plan grasping gesture fig 
converted constraint lists shown fig 

handshape handshape hand arm hand 
motion generation decomposed creating independent temporally ordered constraint lists 
case timing movement constraint satisfied motor subsystem due extensive transitional movements achievable start times corresponding constraint generated integrated temporally related movement constraints preserve gesture temporal structure 
replanning movement necessary gesture generation process returns movement planner tries resolve temporal constraints 
resulting movement re scheduled due articulation effects 
current system hand motion controlled solely specialized hand model interprets descriptions hand shape translating directly hand poses applies stereotyped transitions 
contrast alterations hand location orientation caused arm movements 
constraints concerning features gesture transferred arm control module translates symbols numerical values position orientation constraints respect egocentric frame 
trajectory formed satisfies imposed spatiotemporal constraints smoothly connected lifelike preparation retraction movements 
trajectory formation phase arm trajectory created connects single events boundary conditions retrieved feedback information current movements 
target positions orientations input trajectory generated retrieving start position traversing kinematic model account currently executed motor programs 
resulting position velocity gives initial event limb trajectory planning time 
stereotyped retraction movement appended observed experiments report slight overshooting coming rest 
eventually form lifelike trajectory findings motor control theory taken account 
external coordinates appear superior representation human movement planning suggests trajectory formation cartesian coordinates 
spatiotemporal gesture features distinct times leads interpolation problem effector joint trajectories 
reasonable joint angle interpolation means guaranteed produce natural trajectories external coordinates due nonlinear mapping spaces 
second movement shape extent invariant movement duration simple scaling permitting movement different speeds humans 
complex movements consist elementary units glued relative movement speed drops points connection motor primitives frequently correspond points maximal trajectory curvature 
employ independent nonuniform cubic spline interpolants position curve defining movement trajectory space velocity curve expressing arclength time 
go detail position velocity curves achieved particular 
trajectory formation completed motor program created fed central animation queue see fig 

motor programs queue de activated depending predefined start time respect agent internal wall clock time planned executed motor program strictly timed manner 
rendering animations motor programs arbitrary number independent motor programs may simultaneously active activated executed concurrently 
motor programs created hand motor system directly affect kinematic model modifying joint angles arm movements defined terms trajectories cartesian coordinates arclength control movement velocity standard techniques 
incrementally altered limb position inherently ill posed inverse kinematics problem solved real time extension jacobian transpose method 
algorithm tracks position curve effector arbitrary kinematic chains account restrictions human body additional biomechanical heuristics 
motor program completed removed animation queue movement comes halt 
summary comprehensive knowledge approach animating gestures anthropomorphic agent relevant findings related disciplines 
developed methods feature movement representation planning provide flexibility compose gestural movements satisfy requirements stated 
movements adjusted actual gesture context temporal synchronization constraints 
virtual agent increased reproducing human movement characteristics articulation effects 
far see proposed routines includes methods lead computational complexity preventing execution gesture real time 
experimental implementation model includes animation rendering parts hand motor system gesture planning module arm motor control currently development 
mid range goals include integration text speech speech synthesis techniques run time extraction temporal constraints control coordination gesture speech 
elisabeth andr thomas rist jochen ller integrating reactive scripted behaviors life presentation agent proc 
second international conf 
autonomous agents agents pp 

justine cassell embodied conversational agents new paradigm study gesture human computer interface gesture speech sign eds lynn ruth campbell chapter oxford university press 
monica costa zhao diane chi norman badler emote model effort shape proceedings siggraph 
appear 
jan peter gesture speech production ph dissertation university nijmegen 
mpi series psycholinguistics 
kendon current issues study gestures biological foundations gestures motor semiotic aspects eds perron lawrence erlbaum associates 
stefan natural timing gesture articulated 
workshop communicative agents working notes autonomous agents seattle 
stefan planning motion control lifelike gesture refined approach proc 
computer animation pp 
philadelphia pa usa may 
robert uri role speech related arm hand gesture word retrieval gesture speech sign eds lynn ruth campbell oxford university press new york 
mark control human movement human kinetics publishers champaign il usa 
synthesis hand arm gestures progress gestural interaction proceedings gesture workshop eds philip alistair edwards london 
springer verlag 
david mcneill hand mind gestures reveal thought university chicago press chicago 
ken perlin goldberg improv system scripting interactive actors virtual worlds siggraph proceedings rd annual conference computer graphics pp 

regina heiko thomas jan henning version hamburg notation system sign languages introductory guide volume international studies sign language communication deaf signum press hamburg germany 
martin sheridan planning controlling simple movements psychology human movement eds mary smyth alan wing chapter academic press orlando florida 
ian voss untersuchungen zu im dialog master thesis faculty technology university bielefeld november 
alan watt mark watt advanced animation rendering techniques acm press new york new york 
douglas young richard schmidt motor programs units movement control move mechanics control animation articulated figures eds norman badler brian barsky david zeltzer chapter morgan kaufmann 
