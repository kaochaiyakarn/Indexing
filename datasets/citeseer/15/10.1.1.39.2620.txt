pattern recognition letters acoustic labial speaker verification luettin idiap rue du cp ch martigny switzerland lia des bp cedex france describes multimodal approach speaker verification 
system consists classifiers visual features acoustic features 
lip tracker extract visual information speaking face provides shape intensity features 
describe approach normalizing mapping different modalities common confidence interval 
describe novel method integrating scores multiple classifiers 
verification experiments reported individual modalities combined classifier 
integrated system outperformed sub system reduced false acceptance rate acoustic sub system 
elsevier science keywords person authentication bimodal speech decision fusion lip feature extraction hidden markov models 
automatic verification person identity difficult problem received considerable attention decade 
ability system reject impostors claim false identity critical issue security applications 
multiple modalities face profile motion speech decrease possibility false acceptance lead higher robustness performance see 
brunelli 
previously described bimodal approach person identification 
system visual features static face image acoustic features speech corresponding author 
performed framework vts multi modal verification security applications 
project granted acts program 
elsevier science rights reserved 
pii signal 
performance integrated subsystem shown superior subsystem 
cognitive aspect lip movements speech perception studied extensively complementary nature visual signal successfully exploited bimodal speech recognition systems 
fact temporal lip information contains speech information characteristic information person identity largely ignored luettin 
proposed new modality person recognition spatio temporal lip features 
extend approach address combination acoustic visual speech modality speaker verification system 
describe normalization mapping different modalities determination threshold rejecting impostors 
scheme combining evidence modalities described show multimodal system outperforms unimodal subsystems 

database vts audio visual database collected ucl catholic university louvain 
described pigeon contains speakers male female 
pronouncing french digits zero 
recording sequence digits pronounced continuously 
recordings taken speaker week intervals account minor face changes 
images contain head sampled hz 
divided database sets shots training set th shot validation set th shot test set 
th shot represents difficult recordings recognize 
shot differs face variation head tilted voice variation poor voice snr shot imperfections poor focus different zoom factor 
lip feature extraction interested facial changes due speech production analyse mouth region 
common approaches face recognition geometric features intensity features face parts face see chellappa 
combine approaches assuming information identity speaker contained lip contours grey level distribution mouth area 
speech production lip contours deform intensities mouth area change due lip deformation protrusion visibility teeth tongue 
features contain information specific speech articulators person way person speaks 
aim extract information speech production build spatio temporal models speaking person 

lip model lip model active shape models cootes 
described detail luettin thacker locate recognition letters track parameterize lips image sequence speaking person 
features recovered tracking results 
describe shape inner outer lip contours intensity mouth area 
shape features intensity features principal component analysis performed training set 
intensity model deforms lip contours represents shape independent intensity information 
important property model 
obtain detailed shape information shape parameters intensity model describe intensity information independent lip shape lip movements luettin 
lip tracking experiments performed shots vts database 
database consists colour images converted grey level images experiments 
subjects beard shave different recordings 
examples training set build lip model 
model track lips image sequences sets 
consisted analysing images believe largest experiment reported far lip tracking 
important evaluate performance tracking algorithm previously attempted visually inspecting tracking results fig 

examples lip tracking results 
tin thacker task laborious subjective 
omit direct performance evaluation tracking algorithm 
try evaluate combined performance feature extraction recognition process evaluating person recognition performance 
person recognition errors due inaccurate tracking results due classification errors 
examples lip tracking results shown fig 

speaker verification 
test protocol sequences training set shots 
customers training speaker models 
validation set serves computing normalization mapping function rejection threshold test set verification tests 
subject impostor claiming identity customers 
customer impostor customers 
verification mode text dependent sequence digits 
verification task world model represents average model large number subjects speakers acoustic model labial digit compute corresponding customer likelihood world likelihood 
obtain customer likelihood world likelihood speech data 
difference ratio scores threshold mapped interval function 
rl yt recognition letters final score sc equal decision speaker rejected accepted 
methods proposed find priori decision threshold various criteria equal error rate furui method furui due small amount speech data speaker calculated cus independent threshold method 
method implies function verification errors convex 
function computed set value number false acceptance false rejection errors minimum threshold value 

acoustic speaker word sequences known experiments hmm speech recognition system segment sentences digits 
recognizer uses known sequence digit word models trained polyphone database idiap chollet find word boundaries 
digit hmm trained examples speakers 
segmentation performed sets 
segmented training set train model digit speaker 
models called customer models 
acoustic parameters linear prediction cepstral coefficients second order derivatives 
vector components 
left right hmms emitting states depending digit length 
state modelled single gaussian mixture diagonal covariance matrix 
configuration world model 
world model trained polyphone database examples speakers digit 
access test performed speech segmented digits 
test protocol described applied customer world likelihoods obtained product digit likelihoods customer world models respectively 
mapping function obtained validation set test set map score confidence interval 
test set obtain false acceptance rate false rejection rate 
identification rate speakers see fig 
table worth noting tests con identification false rejection tests false acceptance 
fig 

acoustic verification results validation set 
labial speaker segmenting labial data previous acoustic segmentation 
lip features improve speech recognition results see 
provide information segment speech phonemic units 
lip movements may useful addition acoustic signal segmenting speech especially noisy acoustic environment see mak allen 
visual information segmentation acoustic models trained large database reliable labial models 
scoring method labial verification acoustic verification world model trained customers vts database 
labial data times lower sampling frequency acoustic data 
number emitting states chosen depending digit length 
parameter vectors consisted components shape intensity parameters scale 
test protocol recognition letters fig 

labial verification results validation set acoustic experiments labial verification 
test data set obtained false acceptance rate false rejection rate 
identification rate see fig 
table 
acoustic labial acoustic labial score computed weighted sum acoustic labial scores 
scores normalized described previous sections 
process uses individual threshold values modality maps scores common confidence interval 
normalization process critical point design integration scheme necessary ensure different modalities mapped interval share common threshold value 
different modalities normalized provide different levels confidence 
need weigh contribution modality confidence level 
weight acoustic score ya labial 
table results validation test set id correct identification fa false acceptance fr false rejection rate type score validation test id fa fr id fa fr acoustic labial bimodal number tests fig 

results different weights validation set algorithm compute thresholds find optimal weight function verification results validation data search reasons described threshold search 
results obtained test fig 

overview acoustic labial system 
recognition letters set weight obtain false acceptance rate false rejection rate correct identification rate 
absolute gain acoustic system reduction cumulated verification errors 
increase identification rate id fig 
shows effects weighing acoustic labial results acceptance threshold optimally fixed modality 
table sums results 
followed data driven approach fusion data fusion different levels 
stage learning decoding labial models segmentation obtained acoustic models 
score normalization performed normalizing scores respect world model modality 
final normalization obtained finding optimal mapping interval modality 
stage scores normalized know modality different levels reliability 
level fusion process find optimal weight sources information see fig 


described novel approach multimodal person authentication acoustic visual hmm speaker models 
experiments performed speaker identification verification largest audio visual speech databases 
results shown performance visual system considerably lower performance acoustic system 
due lower frame rate visual features lip tracking errors inappropriate features inappropriate modelling method 
research necessary investigate issues 
integrated system increased identification rate acoustic system reduced false acceptance rate 
results show acoustic labial features contain complementary information performance acoustic speaker recognition system improved visual information 
bigun chollet duc fischer lockwood pigeon pitas 
multi modal person verification tools speech images 
proc 
european conf 
multimedia applications services techniques louvain la neuve belgium pp 

brunelli 
person identification multiple cues 
ieee trans 
pattern anal 
mach 
intell 

chellappa wilson 
human machine recognition faces survey 
proc 
ieee 

chollet 
swiss french polyphone telephone speech databases study intra inter speaker variability 
tech 
rept idiap martigny switzerland 
cootes hill 
active shape models locating structures medical images 
image vision comput 


furui 
overview speaker recognition technology 
proc 
esca workshop automatic speaker recognition identification verification martigny switzerland pp 

bimbot chollet 
combin recognition letters ing methods improve speaker verification decision 
proc 
internat 
conf 
speech language processing philadelphia pa pp 

el 
bimodal speech recognition 
proc 
internat 
workshop automatic face gesture recognition zurich pp 


handling phenomena hmm connected speech 
proc 
european signal processing conf trieste italy pp 

luettin thacker 
speaker identification lipreading 
proc 
internat 
conf 
spoken language processing philadelphia pa pp 

luettin thacker 
shape intensity information 
proc 
internat 
conf 
spoken language processing philadelphia pa pp 

luettin thacker 
probabilistic models 
computer vision image understanding 

mak allen 
lip motion analysis speech segmentation noise 
speech communication 

pigeon 
vts multimodal face database release bigun chollet borgefors eds 
audio video biometric person authentication 
springer berlin pp 

