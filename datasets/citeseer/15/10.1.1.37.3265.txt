discipline experimental algorithmics bernard moret 
years seen enormous progress design algorithms little put practice academia gap theory practice continuously widened years 
developed algorithms hard characterize theoretically initially described su er large running time coecients 
algorithms data structures community needs return implementation standard value call approach experimental algorithmics 
experimental algorithmics studies algorithms data structures joining experimental studies traditional theoretical analyses 
experimentation algorithms data structures proving indispensable assessment heuristics hard problems design test cases characterization asymptotic behavior complex algorithms comparison competing designs tractable problems formulation new conjectures evaluation optimization criteria activities 
experimentation key transfer research results production code providing base tested implementations 
views suitable problem investigate approach suitable experimental setup lessons learned empirical sciences pitfalls await fails heed lessons 
illustrate points examples drawn research solutions np hard problems comparisons algorithms tractable problems experience reviewer editor 

implementation rigorous experimentation characteristic early algorithms data structures 
algorithms community shown signs returning implementation testing integral part algorithm development 
publication outlets remain rare orsa computing math 
programming published strong papers area standard journals algorithm community algorithms acm siam computing algorithmica specialized journals computational geometry areas slow publish experimental studies 
new line acm experimental algorithmics help new conferences targeted experimental algorithms workshop algorithm engineering workshop algorithm engineering experiments 
support experimental component algorithms research growing funding agencies 
author various related projects supported years oce naval research 
bernard moret may poised revival experimentation research methodology development algorithms data structures welcome prospect prompt re ection 
contemplate approaches making extensive experimentation may want re ect meanings adjectives denote approaches 
collegiate webster adjectives de ned follows 
experimental 
relating experience 
founded experiments 
serving ends experimentation 
tentative 
empirical 
relying experience observation 
experience observation 
capable veri ed disproved experience observation 
certainly part de nition experimental parts de nition empirical capture agree essential experiments 
unfortunately words problematic connotations tentative meaning experimental exclusion theory rst de nition empirical 
empirical approach may perfectly suitable natural science nal arbiter nature revealed experiments measurements incomplete arti cial mathematically precise world computing behavior algorithm data structure principle characterized entirely rst principles 
natural scientists run experiments way learning nature algorithm designers principle learn experiment build results de nition completely predictable 
words conduct experiments computer calculate numerical values predictions 
done computational scientists physics chemistry biology aim compare predictions model measurements nature contrast algorithm designers measuring actual algorithm model results assessed gold standard nature simply reported compared experiments type 
course build models gauge real system typically models mathematical functions characterize aspect algorithm asymptotic running time 
epistemological digression 
points necessity learning natural sciences experimentation centuries methodology known scienti method developed optimize experiments staying aware fundamental di erence natural sciences computer science goal experimentation algorithmic di ers fundamentally natural sciences 

background motivation years standard mode theoretical analysis main tool guide new designs asymptotic analysis big oh big theta worst case behavior running time quality solution 
asymptotic mode eliminates potentially confusing behavior small instances due start costs clearly shows growth rate running time 
discipline experimental algorithmics worst case mode gives clear bounds simpli es analysis removing need assumptions data 
resulting presentation easy communicate reasonably understood machine independent 
pay heavy price gains range values asymptotic behavior clearly exhibited named authors may include instance sizes conceivable application 
typical example algorithm fredman tarjan minimum spanning trees 
asymptotic worst case running time jej jej jv log ng particular just log bound better dense graphs prim algorithm jej log jv experimentation veri es crossover point occurs dense graphs vertices size reasonable data set 
worst case behavior may restricted small subset instances characteristic instances encountered practice 
classic example running time simplex method linear programming years known worst case behavior method exponential practical running time appears bounded low degree polynomial 
constants hidden asymptotic analysis may prevent practical implementation running completion growth rate quite reasonable 
extreme example problem provided theory graph minors robertson seymour see gave cubic time algorithm determine graph minor proportionality constants gigantic order substantially lowered making algorithm entirely impractical 
absence problems deriving tight asymptotic bounds may dicult 
interesting approximation algorithms np hard problems su er drawback considering large number parameters substantial slice history create complex state space hard analyze existing methods bound running time estimate quality returned solution 
obvious drawbacks 
insidious drawback prove damaging long term worst case asymptotic analysis tends promote development pencil algorithms algorithms get implemented 
problem compounds quickly developments rely earlier ones result interesting algorithms published years rely layers complex unimplemented algorithms data structures 
order implement algorithms computer scientist face daunting prospect developing implementations successive layers 
algorithms ignore issues critical making implementations ecient elementary ideas elaborate ones sacks sophisticated priority queues implementer resolve issues possibly poor results 
bernard moret improve situation 
reason abandon asymptotic worst case analysis served community years led major algorithmic advances 
de nite need supplement experimentation implies algorithms implemented just designed 
algorithms quite dicult implement case theoretician needs help practitioner practitioner little chance completing successful implementation independently 
examples computational geometry chazelle linear time simplicity testing chazelle convex decomposition algorithm chang yap potato peeling algorithm intricate remain knowledge unimplemented 
practitioner stands bene implementation implementation forces theoretician face issues glossed high level design phase 
resolving issues may bring deeper understanding algorithm resulting simpli cation modestly may lead theoretician new conjectures 
major theoretical breakthroughs chazelle linear time simplicity test robertson seymour polynomial time minor test justi cation incremental results judged practical grounds lead better faster robust implementations 
experimentation test goals algorithm design theoreticians spend time solving small puzzles little importance 
type scienti visualization including seen considerable orts algorithm design automated map labeling graph drawing provides obvious example case graph drawing little reason spend years developing algorithms draw graphs minimum number crossings instance empirical evidence see instance drawings easily interpreted humans drawings large numbers crossings 

modes empirical assessment classify modes empirical assessment number non exclusive categories checking accuracy correctness extreme cases standardized test suites numerical computing 
measuring running time exact algorithms real world instances np hard problems 
assessing quality heuristics approximate solution np hard problems incidentally generating hard instances 
comparing actual performance competing algorithms tractable problems 
discovering speed achieved parallel algorithms real machines 
investigating re ning optimization criteria directed human 
testing quality robustness simulations optimization strategies complex systems rst category reached high level maturity numerical computing standard test suites assess quality new numerical codes 
similarly operations research community developed number test cases linear program solvers 
comparable emphasis date combinatorial geometric computing 
category target large orts discipline experimental algorithmics department defense increasing reliance modeling simulation placed forefront movement develop validation veri cation tools algorithm community help providing certi cation levels various data structures optimization algorithms embedded large simulation systems 
studying speed ups parallel algorithms remains specialized endeavor dedicated nature software typically run machine major performance losses attending lack model parallel computation 
study optimization criteria directed human assessment value human users relatively new area motivated part renewed attention paid human computer interaction 
discuss categories seen bulk research date detail 

assessment heuristics generation hard instances 
goal measure performance heuristics real arti cial instances improve theoretical understanding problem presumably aim producing better heuristics proving current heuristics optimal 
performance implied running time quality solution produced 
behavior heuristics dicult characterize analytically experimental studies rule operations research community rst gave guidelines experimentation integer programming problems see chapter 
rst large scale combinatorial study include real world generated instances probably minimum test set problem large scale studies published time frame notably classic exemplary study simulated annealing david johnson group 
second dimacs computational challenge devoted satis ability graph coloring clique problems saw large collection results area 
proceedings acm siam symposium discrete algorithms soda included studies years outstanding example study cut algorithms chekuri 
traveling salesperson problem seen large numbers experimental studies including publicized study jon bentley possible part development library test cases 
graph coloring np hard version chromatic number determination easier challenging version planar graph coloring seen second study simulated annealing conducted johnson group discussed facets problem morgenstern shapiro provided detailed study algorithms color planar graphs 

assessment competing algorithms data structures tractable problems 
goal measure actual performance competing algorithms solved problems 
fairly new combinatorial algorithms data structures common operations research early data structures typically included code examples systematic study 
comprehensive began jones comparison data structures priority queues stasko vitter combination analytical experimental study pairing heaps 
rst experimental study large scale moret shapiro sorting algorithms chapter followed authors algorithms constructing bernard moret minimum spanning trees 
johnson initiated successful dimacs computational challenges rst focused network ow shortest path algorithms indirectly giving rise modern thorough studies cherkassky shortest paths cherkassky implementation push relabel method network ows 
dimacs computational challenges fth focused tractable problem priority queues point location data structures served highlight area establish common data formats particularly formats graphs networks set rst tailored test suites host problems 
conferences workshop algorithm engineering workshop algorithm experiments emphasized need develop libraries robust tested implementations basic discrete combinatorial algorithms task leda project successfully undertaken date 

worthwhile problems view preceding researchers area working 
propose partial list brie discuss reasons choices 

testing improving algorithms hard problems 
understanding heuristic works cut computational time generally dicult achieve formal derivations goes bounding quality approximations obtained heuristics 
aspects crucial evaluating performance helping design better heuristics 
vein understanding exact algorithm runs quickly generally dicult formal methods experimentation help assess performance real world instances crucial point develop ad hoc boundaries instances runs fast instances exhibit exponential worst case behavior 

comparing existing algorithms data structures tractable problems 
task somewhat easier algorithms tractable problems heuristics intractable problems characterizing behavior real world instances generally hard simply lack crucial instance parameters correlate running times 
experimentation quickly pinpoint bad implementations theoretical advantages retained practice 
process newer insights may gleaned enable re nement simpli cation algorithm 
experimentation enable determine actual constants running time analysis determining constants quite dicult see possible methodology simple regression analysis data gives quite accurate values 

supporting re ning conjectures 
theoretician knows committing research question sure outcome attempting prove statement true 
having means testing conjecture range instances best case set see front page acm experimental algorithmics www acm org links conferences 
discipline experimental algorithmics mind rest worst case avoid lot wasted 
importantly experiments rich source new conjectures theorems 

developing libraries basic algorithms data structures 
contemplating coding library module data structure basic algorithm take reasonable precautions ensure implementation ecient possible document conditions perform poorly 

developing tools facilitate design analysis algorithms 
category come statistical graphical tools analyze experiments animation tools visualize progress experiment 
underestimate value experimentation algorithms discovery tool order experimentation valuable animation analysis tools urgently needed 
algorithm animations shown communicate large amount information succinct manner currently hard develop lack suitable tools 

conducting human experiments value optimization data presentation 
pure theoretician answer asked worked problem incidentally attractive 
easy generate volumes intriguing unsolved optimization problems committing scarce resources solution evaluate importance relevance 
case various facilities problems economic analyses may available point important factors case human interaction may conduct experiments assess worth various criteria 

experimental setup experimental study conducted topic identi ed 
surely important criterion keep mind experiment run discovery tool means answer speci questions 
experiments explorations common endeavors computing sciences human activity setup essentially arbitrary particular allowed limit creativity 
shall focus experiments means answer speci questions essence scienti method physical sciences 
methodology formulating hypothesis question set gathering data test answer ensuring reproducibility signi cance 
terms experiments algorithms characteristics give rise procedural rules clear set objectives questions asking statements testing 
experimental design complete simply gather data 
alterations data gathered avoid bias drift 
analyze data answer original objectives 
consider new cycle experiments improve understanding 
noted earlier experiments little predict outcomes nal arbiter natural sciences 
beware number potential pitfalls including various biases due bernard moret choice machine caching addressing data movement language register manipulation built types compiler quality optimization code generation 
quality coding consistency sophistication programmers 
selection generation instances sucient size variety ensure signi cance 
method analysis minimize impact choice machine caching particular may strong ects comparing ecient algorithms 
instance study mst algorithms observed ratios running time depending order adjacency lists stored 
studies lamarca ladner quanti ed aspects caching ers suggestions caching ects 
typical pitfalls arise experimental algorithms include uninteresting comparing programming languages speci platforms particular unusual ones comparing algorithms widely di erent behavior linear quadratic say bad setup testing xed running time space verifying asymptotic behavior manifested testing instances rough code attempt optimization measuring running times code documentation temptation days net ignoring existing test suites ignoring existing libraries sui code possible confounding factors 
bad analysis presentation discarding data explanation warning presenting data analysis comparisons unde ned standards system sort routine 
avoided type routine care natural sciences point confounding factors assume subtle forms cursory study public health attest 
computer systems reached level complexity human behavior caution remains valid pays go design experimental study times just assess sensitivity potential confounding factors 

measure 
key elements experiment metrology 
measure measure ensure measurements interfere experiments 
universal piece advice area look obvious measures 
obvious measures may include value solution approximation algorithms running time exact algorithms algorithms solved problems running space measures useful understanding algorithm emerge global quantities 
need structural measures various types number iterations number calls crucial subroutine serve scale determining things convergence rates 
knuth advocated mems memory structural substitute running time 
authors number comparisons number data moves classical measures sorting algorithms number assignments discipline experimental algorithmics experience substitute evaluating competing algorithms tractable problems measuring actual running time time mems measurements take example may lead entirely di erent 
obvious measures hardest interpret hardest measure accurately 
running time instance uenced caching turn ected running processes ectively reproducible exactly 
case competing algorithms tractable problems running time extremely low obtain minimum spanning tree graph vertices second typical desktop machine granularity system clock may create problems case pays repeat entire algorithm times data order obtain running times digits precision 
similar vein measuring quality solution quite dicult due fact optimal solution closely approached instances small medium size due fact solution essentially zero decision determining chromatic index graph primality number appropriate measure statistical nature correct answer returned 
requires large number test instances 

analyze data rst requirement data presentation ensure reproducibility researchers need describe detail instances generated collected measurements collected preferably reader nd material line 
second requirement obvious ignored just discard appear anomalies explain presence anomaly explanation error indicator unusual possibly interesting going 
mentioned times ort minimize uence environment platform coding compiling paging caching cross checking multiple platforms environments normalization routines environmental precautions running quiescent machines 
data analyzed suitable statistical methods 
attaining levels statistical signi cance may quite dicult large state spaces commonly various techniques best available experiments applied see mcgeoch excellent survey discussion methods 
cross checking measurements available theoretical results especially attempt predict actual running time equivalent code fragments approach crucial serious discrepancy needs investigated 
data need readers form humans easily process tabular form raw plots multiple crossing curves suitable scaling normalization graphics colors animations convey enormous amounts information succinctly consider providing needed produce excessive 
bernard moret 
illustration algorithms constructing minimum spanning tree shall repeat results highlight problems encountered study solutions ective 
studied mst algorithms practical importance instances encountered practice large implementer faces large number algorithmic choices choice supporting data structures 
started study choice algorithms kruskal priority queue prior sorting sorting demand prim large number priority queues binary heaps rank run relaxed heaps cheriton tarjan lazy variation fredman tarjan gabow entirely di erent algorithm fredman willard list add newer algorithms klein tarjan karger chazelle 
prim algorithm commonly reason study demonstrated turn implemented binary heaps heaps pairing heaps leftist heaps skew heaps binomial heaps splay trees sophisticated structures fibonacci heaps rank relaxed heaps run relaxed heaps case heaps built dynamically pre built statically starting algorithm 
choices implemented time 
ran experimental study di erent platforms cisc risc multiple languages compilers programmer writing code keep level coding consistent 
explored lowlevel decisions pointers vs array indices data moves vs indirection committing speci implementations 
di erent graph families tests constructed speci worst case families adversaries families included large graphs vertices edges 
ran instances size checking independent series experiments consistency results 
took precautions start minimize ects paging easy caching hard 
data collection analysis goals eliminate residual ects caching machine dependencies ii normalize running times machines iii gauge uence lower order terms verify asymptotic behavior iv visualize quickly relative eciency algorithm type size graph 
realized goals simple strategy normalizing independently platform running times measured various mst algorithms running times simple linear time procedure roughly similar memory patterns case procedure counted number edges graph traversing adjacency lists 
similar memory addressing patterns canceled caching ects similar dereferencing pointers canceled cisc machines peculiarities direct comparison unattainable lower bound linear time procedure immediately showed asymptotic behavior highlighted relative eciency algorithm 
early implementation phase realized fibonacci heaps relaxed heaps competitive 
took suggestion original driscoll implementing relaxed heaps group nodes larger units changes key resolved unit discipline experimental algorithmics require restructuring heap 
decided implement idea called sacks types heaps turned crucial decision fibonacci heaps competitive addition sacks new result come implementation 
ndings practitioner theoretician fastest algorithm far prim implemented pairing heaps simple binary heaps 
sophisticated implementations pay reasonable graph sizes sophisticated algorithms 
report implementations prim fibonacci heaps nearly times faster rst 
experienced programmers understand details data structures algorithms re ne implementations point evolving entirely new 
case conclude prim algorithm fibonacci heaps appeared entirely hopelessly impractical rst fact competitive extreme sizes dense graphs 
somewhat obvious theoreticians polylogarithmic factors worth ort di erence jej log jv jej sucient signi cant di erences leading coecients 
study earlier study sorting algorithms enables draw regarding experimental studies algorithms solved problems multi machine multi compiler trials needed 
preference architecture data moves indirection instance easily mask ects 
rst dimacs challenge proposed simple measures assess ect compilers code optimization measures form starting point need supplemented 
large range sizes indispensable 
algorithms compared ecient sophisticated algorithms tend demonstrate asymptotic behavior larger sizes simpler algorithms run tests largest sizes accommodated platforms sizes may exceed encountered practice 
large range sizes help visualizing asymptotic behavior may uncover unexpected problems attributable caching 
extreme care generating instances 
problem particularly acute instances de ned multiple parameters graphs networks large numbers di erent families de ned potentially di erent behaviors 
ensure realistic instances generated large instances generated pseudo random number generators arti cial patterns caused problems generator worst case families included study 
normalization suitable baseline routine successful smoothing variations architecture caching highlighting asymptotic behavior relative eciency competing algorithms 
competing algorithms closely tied data presentation crucial importance 
bernard moret 
experimentation gold standard algorithm design compelling reasons experimentation lead establishment tested documented libraries routines instances 
experimentation bridge gap practitioner theoretician 
experimentation help theoreticians develop new conjectures new algorithms deeper understanding cleaner version existing algorithms 
experimentation point areas additional research needed 
experimentation algorithm design needs methodological development 
large extent follow guidelines physical sciences di erent setting purely arti cial experimental procedure subject test unavoidably mixed requires extra precautions 
fortunately number authors blazed appear trail follow experiments include clearly de ned goals large scale testing terms range instance sizes terms number instances size mix real world instances generated instances including signi cant test suites existence clearly articulated parameters including de ning arti cial instances governing collection data establishing test environment machines compilers statistical analysis results attempts relating nature algorithms test instances public availability instances instance generators allow researchers run algorithms instances preferably public availability code algorithms 
ahuja magnanti orlin network flows 
prentice hall nj 
bentley experiments geometric traveling salesman heuristics 
bell laboratories cs tr 
chekuri goldberg karger levine stein experimental study minimum cut algorithms proc 
th acm siam symp 
discrete 

cherkassky goldberg shortest paths algorithms theory experimental evaluation math 
progr 

cherkassky goldberg implementing push relabel method maximum ow problem algorithmica 
driscoll gabow tarjan relaxed heaps alternative fibonacci heaps applications parallel computation commun 
acm 
mehlhorn runtime prediction real programs real machines proc 
th acm siam symp 
discrete 

johnson aragon mcgeoch schevon optimization simulated annealing experimental evaluation 

graph partitioning operations research 
discipline experimental algorithmics johnson aragon mcgeoch schevon optimization simulated annealing experimental evaluation 

graph coloring number partitioning operations research 
johnson mcgeoch eds 
network flows matching dimacs implementation challenge dimacs series discrete mathematics theoretical computer science 
johnson trick eds 
cliques coloring satis ability second dimacs implementation challenge dimacs series discrete mathematics theoretical computer science appear 
jones empirical comparison priority queues event set implementations commun 
acm 
knuth stanford platform combinatorial computing 
addisonwesley reading mass 
lamarca ladner uence caches performance heaps acm experimental algorithmics article www acm org 
lamarca ladner uence caches performance sorting proc 
th acm siam symp 
discrete 

mcgeoch analysis algorithms simulation variance reduction techniques simulation speedups acm comput 
surveys 
mehlhorn leda platform combinatorial geometric computing commun 
acm 
moret shapiro 
algorithms np volume design ciency 
benjamin cummings publishing menlo park ca 
moret shapiro minimizing set tests siam scienti statistical comput 

moret shapiro empirical assessment algorithms constructing minimal spanning tree computational support discrete mathematics dean shannon eds dimacs series discrete mathematics theoretical computer science 
morgenstern shapiro heuristics rapidly coloring large planar graphs algorithmica 
purchase cohen james experimental study basis graph drawing algorithms acm experimental algorithmics article www acm org 
reinelt traveling salesman computational solutions tsp applications 
lecture notes computer science springer verlag berlin 
robertson seymour graph minors survey surveys combinatorics anderson ed cambridge press cambridge uk 
stasko vitter pairing heaps experiments analysis commun 
acm 
department computer science university new mexico albuquerque nm mail address moret cs unm edu 
