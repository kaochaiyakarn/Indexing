performance evaluation content image retrieval overview proposals henning uller wolfgang uller david mcg 
squire st ephane marchand thierry pun computer vision group university geneva rue du en eral ch gen eve switzerland evaluation retrieval performance crucial problem content image retrieval cbir 
di erent methods measuring performance system created researchers 
article discusses advantages shortcomings performance measures currently 
problems de ning common image database performance comparisons means getting relevance judgments ground truth queries explained 
relationship cbir information retrieval ir clear ir researchers decades experience evaluation problem 
solutions cbir despite di erences elds 
methods text retrieval explained 
proposals performance measures means developing standard test suite cbir similar ir annual text retrieval conference trec 
key words content image retrieval performance evaluation information retrieval early reports performance content image retrieval cbir systems restricted simply printing results example queries flickner 

easily tailored give supported swiss national foundation scienti research 
preprint submitted elsevier preprint august positive impression developers select queries give results 
objective performance measure means comparing di erent systems 
researchers subsequently developed variety cbir performance measures discussed 
narasimhalu 
gives grouping multimedia retrieval systems evaluation provides guidelines construction evaluation measures 
mir gives survey performance measures 
standard methods exist large number researchers 
measures cbir precision recall graphical representation long information retrieval ir 
standard ir tools imported cbir relevance feedback 
order avoid reinventing existing techniques logical systematic review evaluation methods ir suitability cbir 
ir researchers discussing performance evaluation rst concrete steps taken development smart system salton 
important steps common performance measures cran eld test cleverdon 

trec series started combining orts provide common performance tests 
trec project see tre provides focus activities worldwide standard ir 
research remains done evaluation interactive systems inclusion user query process 
novelties included trec regularly interactive track 
salton gives overview ir system evaluation 
textual information retrieval performance evaluation ir started focus newer results especially trec achievements ir community 
data collections trec collection main collection ir 
sponsored national institute standards technology nist defense advanced research projects agency darpa trec held annually inception saw trec 
trec participants index collection gigabytes textual data conference 
comparisons participating systems 
large amount training data provided conference 
di erent collections exist different topics evaluation methods 
special evaluations exist interactive systems spoken language high precision cross language retrieval 
collections grow computing power increases new research areas added 
relevance judgments determination relevant non relevant documents query important time consuming tasks 
real users takes long time judge large number documents 
unreasonable expect humans examine gb data pooling technique trec collection sparck jones van rijsbergen 
subset collection considered complete query users actual relevance judgments 
trec uses working de nition relevance writing report subject topic information contained document report document relevant 
binary judgments relevant relevant document judged relevant piece relevant regardless small piece relation rest document 
performance measures common evaluation measures ir precision recall see eq 
usually precision vs recall graph pr graph salton van rijsbergen 
researchers familiar pr graphs extract information interpretation problems 
precision 
relevant documents retrieved total 
documents retrieved recall 
relevant documents retrieved total 
relevant documents collection pr graphs may contain desired information salton measures trec precision recall nr precision rst nr documents retrieved nr number relevant documents topic 
mean average precision mean non interpolated average precision 
recall precision recall rank precision drops 
recall documents retrieved 
rank rst relevant rank highest ranked relevant document 
key numbers er set performance descriptors di erent systems compared meaningfully objectively 
basic problems cbir performance evaluation current status performance evaluation cbir far ir 
di erent groups sets specialized images 
common image collection common way get relevance judgments common evaluation scheme 
de ning common image collection problems addressed order create common image collection 
collection available free charge copyright restrictions images placed web publications 
greatest problem create collection diversity cater diverse partly specialized domains cbir medical images car images face recognition consumer photographs 
common means constructing image collection corel photo cds usually contains broadly similar images belongie 

cor 
unfortunately images copyrighted free 
research groups subset collection result collection consisting highly dissimilar groups images relatively high group similarity 
lead great apparent improvements performance hard distinguish sunsets underwater images sh 
commonly collection vistex contains primarily texture images vis 
candidate standard collection images videos mpeg mpeg requirements group 
unfortunately may shown web collection expensive 
alternative approach cbir researchers develop collection 
project underway university washington seattle ann 
collection freely available copyright ers annotated photographs di erent regions topics 
small images groups contributing enlarge data set 
collection size suciently high trade speed accuracy evaluated 
ir quite normal millions documents cbir systems images fewer uller 
obtaining relevance judgments cbir common means obtaining relevance judgments queries 
inclusion real users judgment process ir common shown 
collections prede ned subsets common technique standard image databases sets di erent topics air shows zebras corel collection 
relevance judgments collection contains distinct groups annotated images 
choice sets greatly uence results sets visually distant visually closely related 
grouping global visual similarity objects contained 
studies images visually di erent removed collection de nitely improves results belongie 

image grouping alternative approach collection creator domain expert group images criteria 
grouping necessarily readily perceptible visual features 
domain expert knowledge medical cbir 
dy 

seen real groundtruth images attached diagnosis certi ed medical doctor 
groups subsets discussed 
simulating users studies simulate user assuming users image similarity judgments modeled metric cbir system plus noise 

simulations provide results quality results controlled level noise 
real users hard model tversky shown human similarity judgments obey requirements metric certainly user task dependent 
simulations replace real user studies 
user judgments collection real user judgments time consuming user knows expects query result 
obtain judgments relevance de ned user examine entire database representative part see trec pooling sparck jones van rijsbergen 
user query image asked specify relevant images collection 
experiments show user judgments image di er squire pun squire 
observed ir borgman 
means obtaining relevance judgments acknowledges genuine differences user responses assume existence best query result 
individual di erences especially important want demonstrate ability system adapt users needs relevance feedback 
fundamental di erences methods 
ease obtaining relevance judgments advantage collections pre de ned groups similar images 
user judgments collection 
domain expert knowledge available medicine specialized elds 
general cbir tasks believe real users essential see squire pun 
complete evaluation user expectations vital part system 
number images user examine reduced pooling methods ir sparck jones van rijsbergen 
pooling alter results system signi cantly rst relevant images system pooling set 
essential user examines signi cantly large fraction database relevance judgments advance users tend easily satis ed result may contain images selected relevant advance 
characteristics group users relevant judgments obtained important cbir system developers di erent notions image similarity novice users 
performance evaluation methods user comparison user comparison interactive method 
users judge success query directly query 
hard get large number user comparisons time consuming 
comparison easiest test method 
users di erent results asked choose preferred relevant query 
method needs base system system comparison 
single valued measures rank best match berman shapiro measure relevant image rst rst images retrieved 
represents number images returned screen estimate maximum number images user look browsing 
average rank relevant images kasturi measure 
give indication system performance clearly contains information pr graph 
vulnerable outliers just relevant image high rank adversely ect 
simpler robust measure rank rst relevant image trec useful cbir 
precision recall discussed standard measures ir give indication system performance 
value contains insucient information 
recall simply retrieving images 
similarly precision kept high retrieving images 
precision recall precision recall number images retrieved speci ed recall images precision images retrieved 
precision recall averaged important know basis done 
aggarwal precision recall 
belongie 
averaged precision 
martinez uses recognition rate de ned text correspond precision query 
target testing target testing approach di ers signi cantly performance measures 
users target image number images user needs examine nding target image recorded 
starting random images user marks images relevant non relevant 
cox 
employ measure pichunter system 
uller 
elaborate version target testing notion moving targets evaluate ability system track changes user preferences query session 
error rate hwang 
measure common object face recognition 
fact single precision value important know value measured see 
error rate 
non relevant images retrieved total 
images retrieved retrieval eciency uller de ne retrieval eciency eq 

number images retrieved lower equal number relevant images value precision recall query 
de nition misleading mixes standard measures 
retrieval eciency 
relevant images retrieved total 
images retrieved 
retrieved 
relevant 
relevant images retrieved total 
relevant images correct incorrect detection 
measures object recognition context 
numbers correct incorrect classi cations counted 
divided number retrieved images measures equivalent error rate precision 
graphical representations precision vs recall graphs pr graphs standard evaluation method ir increasingly cbir community squire 

pr graphs contain lot information long means read easily researchers 
representation axes changed recall vs precision graph 
sake readability avoided 
common partial pr graph 
useful showing region detail misleading areas poor performance omitted 
interpretation harder scaling watched carefully 
partial graph conjunction complete graph 
recall hard hard easy easy feedback recall hard hard easy easy feedback fig 

pr graphs di erent queries feedback 
demonstrates pr graphs distinguish di ering results 
drawback pr graph depends number relevant images query 
see plot hard query starts hard looks better decrease curve faster 
practical information precision recall number images retrieved obtained 
precision vs 
images retrieved recall vs 
images retrieved graphs taken separately graphs contain information pr graph 
combined contain information easily interpreted 
recall graph looks positive pr graph especially relevant images retrieved late 

precision graph similar pr graph gives better indication number images retrieve 
sensitive number relevant images query 
part graph shown hard judge performance haralick 
number images hard hard easy easy recall graph number images hard hard easy easy precision graph fig 

recall vs 
images graph partial precision vs 
images graph see recall graph distinguish hard easy queries easy easy 
complete precision graph contain information case reason printing partial 
problem di erent numbers relevant images pr graph 
result hard query looks better result hard query 
correctly retrieved vs retrieved graphs vasconcelos lippman contain information recall graphs di erently scaled 
fraction correct vs 
images retrieved graphs belongie 
equivalent precision graphs 
average recognition rate vs 
images retrieved graphs comaniciu 
show average percentage relevant images rst retrievals 
equivalent recall graph 
retrieval accuracy vs noise graphs huet hancock measure show change retrieval accuracy noise added 
noisy image query rank original image observed 
model correspond cbir applications 
proposals preceding sections large number di erent evaluation techniques described 
apparent equivalent contain information 
clearly bene cial cbir community standardized names de nitions performance measures 
scaling partial graphs impedes interpretation techniques emphasis conjunction complete graph 
propose image databases freely available ann databases evaluated available possible compare results systems 
relevance judgments available everybody image database 
best sets di ering relevance judgments persons show ability system adapt users needs relevance feedback 
propose set performance measures similar trec measures interpreted easily contain complementary information 
set contains mixture rank single valued graphical measures rank rank rank rst relevant image retrieved normalized average rank relevant images see eq 

nr precision nr images retrieved recall precision images retrieved pr graph simple average rank see dicult interpret depends collection size number relevant images nr query 
consequently normalize numbers propose normalized average rank rank rank nr nr nr rank ith relevant image retrieved 
measure perfect performance approaches performance worsens 
random retrieval result 
examples measures queries figures 
shown table 
di erences measures di ering information contain seen 
table performance measures di erent queries database images 
query nr rank rank nr easy easy hard hard importance relevance feedback evident propose create relevance feedback initial query result relevance judgments feeding back relevant images rst images returned system 
methods creating positive negative relevance feedback performance comparison uller 

propose evaluate steps relevance feedback show adaptability system users needs 
relevance feedback performance measure relevance feedback show improvements 
depending eld application time takes execute query high importance evaluation 
recommend state execution time query conjunction computer system cpu speed memory 
systems compared retrieval performance trade accuracy speed pruning methods available 
article gives overview existing performance evaluation measures cbir 
need standardized evaluation measures clear measures slight variations de nition 
hard compare performance systems objectively 
overcome problem set standard performance measures standard image database needed 
proposed set measures similar trec 
frequently updated shared image database regular comparison system performances great bene cbir community 
needs done better integrate users evaluation process 
ultimate aim measure usefulness system user 
interactive performance evaluations including levels feedback user interaction need developed 
continuing area welcome discussion collaboration topic 
haralick 

graph theoretic clustering image grouping retrieval cvp pp 

ann 
annotated groundtruth database department computer science engineering university washington www cs washington edu research groundtruth 
belongie carson greenspan malik 

color image segmentation em application content image retrieval proceedings international conference computer vision iccv bombay india 
berman shapiro 

ecient content retrieval experimental results cba pp 

borgman 

users information retrieval systems created equal exploration individual di erences information processing management 
cba 
ieee workshop content access image video libraries fort collins colorado usa 
cleverdon mills keen 

factors determining performance indexing systems technical report cran eld project cran eld 
comaniciu meer xu tyler 

retrieval performance improvement low rank corrections cba pp 

cor 
corel photos www corel com products 
cox miller omohundro yianilos 

target testing pichunter bayesian multimedia retrieval system advances digital libraries adl library congress washington pp 

cvp 
proceedings ieee conference computer vision pattern recognition cvpr fort collins colorado usa 
dy brodley kak 


customized queries approach cbir em cvp pp 

flickner sawhney niblack ashley huang dom gorkani hafner lee petkovic steele yanker 

query image video content qbic system ieee computer 
kasturi 

image database querying multi scale localized color representation cba pp 



evaluation mars image indexing retrieval system technical report graduate school library information science university illinois urbana champaign champaign il usa 
huet hancock 

inexact graph retrieval cba pp 

hwang weng fang qian 

fast image retrieval algorithm automatically extracted discriminant features cba pp 

aggarwal 

applying perceptual grouping content image retrieval building images cvp pp 



searching photos journalists practices pictorial ir harper jose eds challenge image retrieval workshop symposium image retrieval electronic workshops computing british computer society newcastle tyne 
martinez 

face image retrieval hmms cba pp 

mir 
mira evaluation frameworks interactive multimedia retrieval applications 
esprit working group www dcs gla ac uk mira 
mpeg requirements group 
mpeg context objectives version atlantic city doc 
iso iec jtc sc wg international organisation standardisation 
uller uller squire marchand pun 

strategies positive negative relevance feedback image retrieval proceedings th international conference pattern recognition icpr ieee barcelona spain 
uller 

improved stochastic modeling shapes contentbased image retrieval cba pp 

uller squire uller pun 

hunting moving targets extension bayesian methods multimedia databases 
chang 
kuo eds multimedia storage archiving systems iv vv vol 
spie proceedings boston massachusetts usa 
spie symposium voice video data communications 
narasimhalu kankanhalli wu 

benchmarking multimedia databases multimedia tools applications 


review interactive trec mira workshop dublin ireland 
wolf 

graph object description information retrieval digital image video libraries cba pp 

maron grimson lozano perez 

framework learning query concepts image classi cation cvp pp 

salton 

evaluation parameters smart retrieval system experiments automatic document processing salton pp 

salton 

smart retrieval system experiments automatic document processing prentice hall englewood cli new jersey usa 
salton 

state retrieval system evaluation information processing management 
kak brodley 

testing human perceptual categories physician loop cbir system medical imagery cba pp 

sparck jones van rijsbergen 

report need provision ideal information retrieval test collection british library research development report computer laboratory university cambridge 
squire uller uller 

content query image databases inspirations text retrieval inverted les frequency weights relevance feedback th scandinavian conference image analysis greenland pp 

squire pun 

comparison human machine assessments image similarity organization image databases visa eds th scandinavian conference image analysis pattern recognition society finland finland pp 

tre 
text retrieval conference trec trec nist gov 
tversky 

features similarity psychological review 
van rijsbergen 

evaluation information retrieval prentice hall englewood cli new jersey usa chapter pp 

vasconcelos lippman 

probabilistic retrieval new insights experimental results cba pp 

worring smeulders 

filter image browsing exploiting interaction image retrieval smeulders eds third international conference visual information systems visual number lecture notes computer science springer verlag amsterdam netherlands pp 

vis 
vistex vision texture database maintained vision modeling group mit media lab 
media mit edu vismod 


overview seventh text retrieval conference trec seventh text retrieval conference gaithersburg md usa pp 


