maletic marcus iq data cleansing integrity analysis jonathan maletic marcus division computer science department mathematical sciences university memphis campus box memphis tn memphis edu memphis edu analyzes problem data cleansing automatically identifying potential errors data sets 
overview amount existing literature concerning data cleansing 
methods error detection go integrity analysis reviewed 
applicable methods include statistical outlier detection pattern matching clustering data mining techniques 
brief results supporting methods 
research directions necessary address data cleansing problem discussed 
keywords data cleansing data cleaning data quality error detection 

quality large real world data set depends number issues source data crucial factor 
data entry acquisition inherently prone errors simple complex 
effort front process respect reduction entry error fact remains errors large data set common 
organization takes extreme measures effort avoid data errors field errors rates typically 
existing data sets logical solution problem attempt data way 
explore data set possible problems endeavor correct errors 
course real world data set doing task hand completely question amount person hours involved 
organizations spend millions dollars year detect data errors 
manual process data cleansing laborious time consuming prone errors 
need useful powerful tools automate greatly assist data cleansing process necessary may practical cost effective way achieve reasonable quality level existing data set 
may obvious solution little basic research directly aimed methods support tools 
related research addresses issues data quality research supported part office naval research 
june maletic marcus iq tools assist hand data cleansing relational data integrity analysis 
differing views data cleansing surveyed reviewed 
general framework data cleansing process set general methods address problem 
experimental results applying methods real world data set 
research directions necessary address data cleansing problem discussed 

overview data cleansing data cleansing relatively new research field 
process computationally expensive large data sets impossible old technology 
new faster computers allow performing data cleansing process acceptable time large amounts data 
issues data cleansing area researchers attempting tackle 
consist dealing missing data determining record usability erroneous data different approaches address different issues 
particular interest search context called literature business world dirty data 
commonly agreed definition data cleansing 
various definitions depend particular area process applied 
major areas include data cleansing part defining processes data warehousing knowledge discovery databases termed data mining data information quality management 
data warehousing field data cleansing applied especially databases merged 
records referring entity represented different formats different data sets represented erroneously 
duplicate records appear merged database 
issue identify eliminate duplicates 
problem known merge purge problem 
instances problem appearing literature called record linkage semantic integration instance identification object identity problem 
perspective data cleansing defined similar ways 
data cleansing process eliminating errors inconsistencies data solving object identity problem 
defines data cleansing problem merge purge problem proposes basic sorted neighborhood method solve 
proposed method basis module tool 
data cleansing simply updating record data 
serious data cleansing involves decomposing reassembling data 
break cleansing steps standardizing verifying matching house holding documenting 
data cleansing take forms current marketplace current technology data cleansing heavily focused customer lists 
area companies dominate data cleansing marketplace specialize cleaning large customer address lists 
companies hanks data technologies innovative systems technology 
companies started produce tools offer data cleaning services address specifically customer address lists rely domain specific information provided customer merge purge module description design framework assisted data cleansing merge purge problem available 
june maletic marcus iq total data quality management area interest research business communities 
data quality issue integration entire information business process tackled various points view literature 
refers problem enterprise data quality management 
comprehensive survey research area available 
unfortunately mentioned papers refer explicitly data cleansing problem 
papers deal strictly process management issues data quality perspective definition data quality 
category interest research 
proposed model data life cycles application quality data acquisition data usage cycles contain series activities assessment analysis adjustment discarding data 
specifically addressed integrated data cleansing process data life cycles series steps define proposed model data quality perspective 
framework data quality fox proposes quality dimensions data accuracy current ness completeness consistency 
correctness data defined terms dimensions 
simplistic attempt define data cleansing process framework process assesses correctness data improve quality 
data cleansing regarded step preprocessing step kdd process 
precise definition perspective data cleansing process 
various kdd data mining systems perform data cleansing activities domain specific fashion 
discovering informative patterns perform kind data cleansing discovering garbage patterns meaningless mislabeled patterns 
machine learning techniques apply data cleansing process written characters classification problem 
data cleansing defined process implements computerized methods examining databases detecting missing incorrect data correcting errors 
recon data mining system assist human expert identify series error types financial data systems 

general methods data cleansing certainly mind data cleansing viewed process 
process may tied directly data acquisition definition may applied fact improve data quality existing system 
phases define data cleansing process define determine error types search identify error instances correct uncovered errors phases constitutes complex problem 
wide variety specialized methods technologies applied 
focus aspects generic framework 
aspect difficult automate outside strict welldefined domain 
aforementioned data cleansing tools utilize integrity analysis locate data errors 
data set data base adheres relational model data integrity analysis simple data cleansing operation 
relational data integrity including entity referential column integrity accomplished relational data base queries june maletic marcus iq sql 
database systems oracle ms access support type data cleansing degree 
database administrator type data cleansing unfortunately administrator lacks domain knowledge clearly defined responsibility correctly carry task 
tools usable non database experts support type cleansing 
example wang developed tool supports data integrity analysis framework 
data integrity analysis uncover number possible errors data set address errors complex 
errors involve relationships fields difficult uncover 
types errors require deeper inspection analysis 
view problem outlier detection 
put simply large percentage say data elements conform general form remaining data elements error candidates 
data elements considered outliers 
things done identifying outliers strange variations data set identifying trends normality data 
knowing data supposed look allows errors uncovered 
fact matter real world data diverse rarely conforms standard statistical distribution 
especially acute viewing data dimensions 
method outlier detection necessary capture outliers 
set general methods utilized error detection statistical identifying outlier fields records values mean standard deviation range chebyshev theorem considering confidence intervals field 
clustering identify outlier records clustering euclidian distance 
existing clustering algorithms provide little support identifying outliers 
cases clustering entire record space reveal outliers identified field level inspection 
main drawback method computational time 
clustering algorithms high computational complexity 
large record spaces large number records run time clustering algorithms prohibitive 
pattern identify outlier fields records conform existing patterns data 
combined techniques partitioning classification clustering identify patterns apply records 
pattern defined group records similar characteristics behavior fields data set user defined value usually 
association rules association rules high confidence support define different kind pattern 
records follow rules considered outliers 
power association rules deal data different types 
boolean association rules provide quantitative qualitative information 
ordinal association rules defined authors find rules gave information ordinal relationships data elements 
ordinal association rules yield special type patterns method general similar method 
method extended find kind associations groups data elements statistical correlations 
june maletic marcus iq 
experiments version mentioned methods implemented 
method tested data set comprised real world data supplied naval personnel research studies technology 
data set represents part navy officer personnel information system including officer candidates 
similar data sets personnel records division companies world 
subset records fields type dates data set demonstrate methods 
size data type data elements allowed fast multiple runs reducing generality proposed methods 
goal experiments prove methods successfully identify outliers constitute potential errors 
implementations designed larger data sets large amounts domain knowledge 
information needed user size data set values threshold parameters 

statistical outlier detection outlier values particular fields identified automatically computed statistics 
field average standard deviation utilized chebyshev theorem records values field outside number standard deviations mean identified 
number standard deviations considered customizable 
confidence intervals taken consideration field 
field fi considered variable realizations number records value 
field fi record rj considered outlier value fi value fi mean field fi standard deviation user defined factor 
regardless distribution field fi values certain number standard deviations mean 
value user defined domain data knowledge theoretically chebyshev theorem 
experiments values value generate best results false positives false negatives 
records experimental data set contain outlier values detected method 
visualization tool analyze results 
trying visualize entire data set identify outliers hand impossible 

clustering combined clustering method implemented group average clustering algorithm considering euclidean distance records 
clustering algorithm run times adjusting maximum size clusters 
ultimately goal identify outliers records identified containing outlier values 
computational time prohibits multiple runs day business application larger data sets 
executions data set turned larger threshold value maximum distance allowed clusters merged better outlier detection 
faster clustering algorithm utilized may allow automated tuning maximum cluster size scalability larger data sets 
domain knowledge important subspace selected guide clustering reduce size data 
method reduce search space june maletic marcus iq techniques 
identified clusters combine records bear certain similarity 
highly probable records cluster follow certain pattern 
test data set particular characteristic data elements empty 
particularity data set method general allowed definition new similarity measure relies feature 
strings zeros ones referred hamming value associated record 
string elements number fields 
string represents non empty field position record string 
string represents empty field position record string 
hamming distance utilized cluster records groups similar records 
initially clusters having zero hamming distance records identified 
unfortunately number identified clusters high clusters records 
largest cluster records second largest 
results encouraging hierarchical clustering method considered implementation determine clusters records diameter larger zero 
hamming distance clustering yield relevant outliers produce clusters records search spaces methods 

pattern detection patterns identified data distribution records field 
field records clustered euclidian distance mean algorithm 
starting elements randomly chosen equal distances mean empty field 
pattern defined large group records entire data set cluster way fields 
cluster classified number records contains cluster number largest size 
hypothesis considered pattern applicable fields records record pattern part cluster rank field 
method applied data set small number records total number records identified followed pattern fields 
tool adapted applied clusters records generated hamming distance entire data set 
chances identifying pattern increase records clusters certain similarity approximately fields empty 
real life data proved highly non uniform 

association rules term association rule introduced agrawal context market basket analysis 
association rule type referred literature classical boolean association rules 
concept extended studies experiments 
interest research particular quantitative association rules ratio rules identification possible erroneous data items certain modifications 
previous argued extension association rule ordinal association rules useful identification outliers errors 
introduced concept briefly defined 
june maletic marcus iq bn data set record bi collection items ik set items 
item ii numerical domain ii relationships defined equal equal greater equal 
op op ordinal association rule 
occur records support rule 
records occur op true confidence rule 
definition extends easily op op op jm op jm set items process identify potential errors data sets ordinal association rules composed steps 
find ordinal rules minimum confidence done variation apriori algorithm 

identify data items broke rules considered outliers potential errors 
point need consider minimum acceptable support 
investigate user specified minimum support 
change number initially identified patterns 
pairs items considered patterns 
number attributes fields data set 
record 
field field field field table part data set 
error identified record field identified previously 
data elements dates format 
confidence fields high probability errors identified records 
compared outliers identified statistical methods 
possible errors matched previously discovered ones errors unidentified previous methods 
distribution data influenced dramatically error identification data process previous utilized methods 
new method influenced distribution data proving robust 
table shows error identified ordinal association rules missed previous methods 
patterns identified confidence higher values field values field values field values field 
record fields marked high probability errors 
values fact minimum values respective fields 
field identified previously outlier field high value standard deviation field 
obvious consulting domain expert values fact wrong 
correct values identified 
values lie edge distributions identified errors 
june maletic marcus iq 
set methods addresses problem automatic identification errors data sets 
methods implemented results showed methods successfully applied real world data need fine tuned improvement 
proposed methods strength weakness 
unfortunately little basic research information systems computer science communities conducted directly related error detection data cleansing 
depth comparisons data cleansing techniques methods published 
typically real data cleansing done customized house manner 
scenes process results undocumented ad hoc methods 
concerted effort database information systems committees needed address problem 
research authors investigate integration various methods address error detection 
knowledge techniques utilized detection correction situations 
best solution automatic error detection integrated approach utilizes number methods 
methods analysis groups correlated fields statistical correlation prove powerful 
ultimate goal research devise set general operators theory relational algebra combined formed statements address data cleansing problems 
formal basis necessary design construct high quality useful software tools support data cleansing process 

agrawal imielinski swami mining association rules sets items large databases proceedings acm sigmod international conference management data washington may pp 

methodology allocating resources data quality enhancement cacm vol 
pp 

barnett lewis outliers statistical data john wiley sons 
bock data analysis springer 
brachman anand process knowledge discovery databases human centered approach advances knowledge discovery data mining fayyad piatetsky shapiro smyth eds mit press aaai press pp 

qualitative marketing software merge purge module webpage date accessed www com solutions merge htm 
date database systems addison wesley 
edd home page tool edd webpage date accessed www com edd 
english plain english data quality dm review date accessed www com 
june maletic marcus iq eti eti data tool international webpage date accessed www com products dc html 
fayyad piatetsky shapiro smyth data mining knowledge discovery overview advances knowledge discovery data mining fayyad piatetsky shapiro smyth eds mit press aaai press pp 

flanagan practical guide achieving enterprise data quality webpage date accessed www com 
fox notion data quality dimensions information processing management vol 
pp 

fox data data quality encyclopedia library information science 
galhardas florescu shasha simon extensible framework data cleaning institute national de recherche en informatique en automatique technical report 
guyon matic vapnik discovering information patterns data cleaning advances knowledge discovery data mining fayyad piatetsky shapiro smyth eds mit press aaai press pp 

hamming coding information theory new jersey prentice hall 
hernandez stolfo real world data dirty data cleansing merge purge problem journal data mining knowledge discovery vol 
pp 

johnson applied multivariate statistical analysis th ed prentice hall 
kaufman finding groups data cluster analysis john wiley sons 
kimball dealing dirty data dbms vol 
september pp 

knorr ng unified notion outliers properties computation proceedings kdd pp 

korn yannis ratio rules new paradigm fast quantifiable data mining proceedings th vldb conference new york pp 

model data life cycles application quality information software technology vol 
pp 

marcus maletic utilizing association rules identification errors data university memphis division computer science memphis technical report tr may 
moss data cleansing dichotomy data warehousing dm review february 
murtagh survey advances hierarchical clustering algorithms computer journal vol 
pp 

orr data quality systems theory cacm vol 
february pp 

june maletic marcus iq pak data quality analyzer software tool analyzing data quality data manufacturing systems webpage date accessed web mit edu papers pass html 
data quality information age artech house 
impact poor data quality typical enterprise cacm vol 
february pp 

simoudis kerber recon data cleaning proceedings kdd pp 

srikant vu agrawal mining association rules item constraints proceedings sigmod international conference management data montreal canada june pp 

strong yang wang data quality context cacm vol 
may pp 

integrity analysis methods automating data quality assurance edp auditors foundation vol 
pp 

software system data warehousing erp software webpage date accessed www com products htm 
integrity data re engineering environment technology webpage date accessed www com 
wang reddy gupta object oriented implementation quality data products proceedings wits wang storey firth framework analysis data quality research ieee transactions knowledge data engineering vol 
august pp 

wang strong accuracy data quality means data consumers journal management information systems vol 
spring pp 

yang carbonell brown pierce archibald liu learning approaches detecting tracking news events ieee intelligent systems vol 
july august 
zhang ramakrishnan livny birch new data clustering algorithm applications data mining knowledge discovery vol 
pp 

june 
