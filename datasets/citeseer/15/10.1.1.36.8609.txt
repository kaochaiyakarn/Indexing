divisive initialisation method clustering algorithms clara domenico talia giorgio isi cnr deis univ della cs italy si deis 
method initialisation step clustering algorithms 
concept cluster high density region points 
search space modelled set dimensional cells 
sample points chosen located appropriate cells 
cells iteratively split number points receive increases 
regions search space having higher density points considered candidates contain true centers clusters 
preliminary experimental results show quality estimated centroids respect random choice points 
accuracy clusters obtained running means algorithm different initialisation techniques random starting centers chosen uniformly datasets centers method evaluated better outcome means initialisation method shown 
clustering data analysis unsupervised technique searches separate data items objects having similar characteristics constituent groups 
importance technique recognized diverse fields sociology biology statistics artificial intelligence information retrieval 
years clustering identified main data mining tasks 
proposed definitions constitutes cluster concepts similarity distance objects 
general approach consists considering data item point dimensional space variables represented axes space 
variable values data item define dimensional coordinate space 
clusters described continuous regions space relatively high density points separated clusters regions relatively low density points 
clusters described way directly reflect process detect clusters visually dimensions lead see clustering density estimation problem 
density estimation addressed statistics recognized challenging problem 
approaches defined data clustering 
partitioning methods produce partition set objects clusters number groups priori 
performance methods strongly influenced choice initial clusters 
nearer initial starting points true centers clusters better quality clustering convergence method accelerated 
divisive method initialisation step clustering algorithms 
method provides estimation centroids clusters 
concept cluster high density region points intuition subsampling data naturally bias sample representatives near dense regions :10.1.1.44.5872
search space modelled set dimensional cells 
sample points chosen located appropriate cells 
cells iteratively split number points assigned increases 
way attention focused regions search space having higher density points candidates contain true centers clusters 
preliminary experimental results show quality estimated centroids respect random choice points 
furthermore accuracy clusters obtained running means algorithm different random starting centers chosen uniformly datasets centers method evaluated 
results point better performances means estimated centroids provided method 
organized follows section gives brief survey clustering methods section presents divisive method estimate centroids section shows effectiveness proposed approach set synthetic data 
background related algorithms clustering data proposed 
extensive overview clustering algorithms 
approaches clustering partitional approach 
partitional clustering algorithm produces partition set objects clusters optimizing criterion function 
approaches assume number groups priori 
formulated main steps initialisation clusters allocation objects clusters reallocation objects clusters initial grouping process completed 
differences methods mainly lie 
techniques initialisation clusters find points dimensional space initial estimates cluster centers 
choice points important aspect approach strongly biases performances methods 
partitioning methods direct means clustering known effective method practical applications 
direct means clustering data points partitioned clusters cluster contains data points data point belongs cluster 
criterion function adopted squared error criterion 
centroid cluster defined mean objects contains 
square error partition sum squared euclidean distances data point centroid 
square error partition sum square errors partitions smaller error better quality partitioning 
direct means algorithm starts randomly choosing initial centroids assigning data point cluster nearest centroid 
new centroids square error computed method stops change significantly movement points cluster occurs 
choice initial centroids sufficiently near actual centroids drastically reduce number steps needed means converge avoid problem empty clusters due choice starting points far centroids 
literature proposals initialisation methods :10.1.1.44.5872
proposed bradley fayyad algorithm refining initial starting condition 
method chooses number subsamples dataset groups kmeans 
subsample gives solution cm set solutions clustered means initialised cm giving solution fm fm having minimal squared error chosen refined initial point 
section initialisation method analogously works sample data exploits concept density focus attention parts search space contain high frequency count sampled points 
parts iteratively divided smaller subparts assumed possible candidates contain true centers 
method general method providing estimation centroids clusters clustering algorithms 
method exploits concept density search space focusing attention regions having high density data points 
dataset data points dimensions cell ae containing points defined way 
xmin xmax fx min max dg min ng max maxfx ng 
search space represented problem finding centroids formulated problem finding subcells having highest density points 
divisive initialisation algorithm shown initially partitions cell subcells dividing side equal parts 
takes input data points number different frequency times cells considered fig 

divisive method centroids subsample 
splitting number clusters 
randomly chooses subsamples data points finds centroids calling function shown 
sets considered possible fusion points representatives cluster 
function assigns cell level splitting equal zero 
level incremented point read subcells generated splitting cell received highest number points 
graphical view iterative splitting dataset ds described section subsample shown 
worth noting regions containing points subsample completely ignored division process 
fact point subsample located regions considered division process 
points belonging located appropriate subcell sample points considered cells having splitting level equal maxlevel maxlevel selected mean points points contain computed 
mean points considered possible representatives clusters 
fig 

iterative splitting cells ds 
experimental results goal experiments evaluate quality centroids estimated method respect actual centers synthetic datasets ds ds described 
datasets consists clusters dimensional data points 
ds grid pattern centers placed theta grid 
ds sine pattern places cluster centers curve sine function 
ds ds constituted data points grouped clusters 
size random subsamples full dataset number subsampling taken 
set experiments evaluated closeness centroids estimated divisive algorithm true centers synthetic data 
figures draws actual identified symbol estimated random centers ds 
show centroids computed method near true centers 
run means algorithm different random starting centers chosen uniformly datasets centers divisive initialisation algorithm 
visualizes clusters obtained step random start estimated centers dataset ds clusters steps 
comparing results actual clusters observe location centers random initialisation far away true location location estimated centers close actual number points contained clusters remarkably different actual number regard random start estimated centers contrary clusters move away 
results obtained ds omitted due lack space 
table shows iterations th fig 

centers ds true estimated random 
th th iterations square error difference square error previous step datasets ds ds means initialised method random choice centers 
value column reduc compares reduction square error means initialised respect random start 
initialisation methods estimate values centers clusters play important role supporting clustering algorithms accurately efficiently identify groups items large data sets 
preliminary results synthetic datasets showed quality estimated centers 
necessary assess effectiveness method 
comparison approach bradley fayyad random st iter estimated st iter random th iter estimated th iter fig 

clusters ds random estimated centers st th iterations 
synthetic data need done application real world data performed 

ranka singh 
efficient means clustering algorithm 
proceedings workshop high performance data mining orlando florida 

bradley mangasarian street 
clustering concave minimisation 
advances neural information processing systems mozer jordan eds 
pp 
mit press 

bradley fayyad 
refining initial points means clustering 
proceedings int 
conf 
machine learning pp 
morgan kaufmann 
table 
square errors ds ds 
ds ds divisive random start divisive random start iter reduc reduc 
dubes jain 
algorithms clustering data 
prentice hall 

ester kriegel sander xu 
density algorithm discovering clusters large spatial databases noise 
proceedings nd int 
conf 
knowledge discovery data mining aaai press 

everitt 
cluster analysis 
heinemann educational books london 

fayyad shapiro smith 
data mining knowledge discovery overview 
fayyad 
eds advances knowledge discovery data mining pp 
aaai mit press 

fayyad reina bradley 
initialisation iterative refinement clustering algorithms 
proceedings int 
conf 
knowledge discovery data mining aaai press 

jain 
algorithms clustering data 
prentice hall 

jain murty flynn 
data clustering review 
acm computing surveys june 

judd mckinley jain 
large scale parallel data clustering 
proceedings int 
conf 
pattern recognition 

kaufman 
finding groups data cluster analysis 
john wiley sons 

ng han 
efficient effective clustering methods spatial data mining 
proceedings th int 
conf 
large data bases pp 


silverman 
density estimation statistics data analysis 
london chapman hall 

zhang ramakrishnan livny 
birch efficient data clustering method large databases 
proceedings acm sigmod int 
conf 
managment data montreal canada pp 
june 
