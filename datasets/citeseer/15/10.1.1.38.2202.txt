color optical flow estimation golland color optical flow estimation research thesis submitted partial fulfillment requirements degree master science computer science golland submitted senate technion israel institute technology haifa may described supervised prof bruckstein dr lindenbaum computer science department 
prof bruckstein support guidance dr michael lindenbaum help final stages 
generous financial help intel gratefully acknowledged 
contents table contents list figures iii motion analysis optical flow basic definitions main gradient constraint optical flow determination smoothness constraints methods high order derivatives neighborhood sampling approach multiple constraints approach color vision color perception reflectivity model color representation normalized rgb representation hsv representation image flow color images brightness conservation approach color conservation approach experimental results bibliography ii list figures laplacian estimation mask 
light reflection surface 
interface body components reflection 
chromaticity diagram 
hsv color system 
error statistics translation 
error statistics rotation 
error statistics motion camera 
synthetic images translation 
synthetic images rotation 
synthetic images motion camera 
synthetic images moving light source 
real images translation 
real images rotation 
real images motion camera 
iii color images optical flow estimation investigated 
optical flow estimation low level phase motion recovery problem 
output projection velocity field image plane analyzed get highlevel motion descriptions 
known problem determining optical flow solved completely sequence black white images introducing additional assumptions nature motion 
color image considered combination number usually independent images obtained simultaneously viewpoint different visual sensors 
theoretically provides information set black white images taken different cameras 
color image significant advantage set different black white images acquisition full correspondence color image components 
eliminates need solve correspondence problem known difficult general case 
color images natural candidates improve solution optical flow estimation problem 
gradient approach optical flow estimation assumes brightness conservation motion 
provides constraint unknown local components velocity vector 
additional assumptions local behavior field velocities order obtain determined system equations yield components velocity vector point image 
methods optical flow estimation color images proposed 
component color image considered independent black image color image provides brightness functions point 
may straightforward way obtain constraints velocity vector components 
second proposed method extracts new quantities color image quantities hopefully represent intrinsic color properties object uses estimate velocity certain point 
connection invariant surface properties object new quantities extracted color image stronger surface properties brightness function image 
method assumes conservation quantities produces better motion estimates brightness conservation assumption 
different sets color related locally computable motion invariants analyzed tested thesis results optical flow estimation compared direct brightness functions 
chapter color images offer lot potential advantages black white images 
total light intensity point obtained black white image color image provides information distribution light energy visible range spectrum 
color image multi band number usually readings obtained different sensors provided pixel 
carries information number black white images taken different cameras 
color image significant advantage set different black white images full correspondence color image channels 
eliminates need solve correspondence problem known difficult general case 
additional information provided color vision solution various problems computer vision known require piece information pixel 
optical flow estimation problem examined 
optical flow estimation problem low level stage motion recovery sequence images 
output estimate projection velocity field image plane analyzed stages aimed yielding high level motion description 
known optical flow problem solved completely single sequence black white images introducing additional assumptions nature motion 
color images natural candidates improving solution problem 
color images optical flow estimation investigated 
addition straightforward method different color components separate images scene new approach notion color invariance motion developed tested 
organization thesis follows 
chapter optical flow estimation problem defined main constraint optical flow estimation derived 
existing methods optical flow estimation surveyed 
chapter color vision observations necessary discussion 
chapter presents new methods optical flow estimation color images discussion experimental results simulated real images 
chapter motion analysis chapter optical flow estimation problem introduced low level vision operator necessary general problem motion recovery 
basic definitions existing gradient methods optical flow estimation surveyed advantages drawbacks discussed 
optical flow basic definitions define basic concepts 
require preliminary discussion 
motion field field object velocities point space 
motion objects time varying scene defined completely motion field 
aims motion recovery process reconstruct motion field scene 
note motion field usually change time 
image flow visible portion projection motion field image plane 
obtain image flow intermediate result motion estimation process try recover motion field projection 
impossible priori knowledge motion field 
extract optical flow field velocities associated variation brightness patterns image 
examples help understand difference image flow optical flow 
uniformly painted ball rotating center way 
case image flow non zero point ball projection image plane optical flow zero image brightness change 
second example stationary scene moving light source 
situation exactly opposite optical flow non zero due intensity changes image absence motion causes zero image flow 
motion recovery problem introduced 
formulated follows sequence images dynamic scene recognize moving objects find velocities trajectories 
solution problem computer vision somewhat artificially divided main stages ffl low level processing 
stage field velocities optical flow associating velocity vector point image plane determined 
ffl high level motion analysis 
stage velocity field true motion field estimated field determined previous stage analyzed order get motion description objects scene 
high level stage motion recovery assumes receives image flow input low level stage called optical flow estimation stage produce optical flow defined image sequence 
immediately seen problem equivalence fields 
number authors investigated connection introducing constraints motion surface properties order satisfy assumptions yielding image flow optical flow identity methods obtain image flow optical flow 
motion recovery usually assumed optical flow image flow close interchangeably 
situations approximation quite reasonable forget examples shown optical flow image flow differ significantly 
new approaches optical flow image flow estimation proposed low level stage motion recovery process main concern 
highlevel stage scope discussed 
mentioned trivial problem recover structure projection unique solution general case 
done area usually assuming significant priori information nature motion certain properties moving surface 
number approaches developed optical flow estimation gradient methods region matching correlation methods energy methods approach variations proposed different authors 
new methods proposed belong gradient group discussion concentrate methods group general approach underlying 
main gradient constraint optical flow determination defined optical flow velocity field associated brightness changes image 
suggests assumption methods optical flow estimation brightness conservation assumption states brightness image point object invariant motion 
position image point scene time projection velocity vector point image plane 
time ffit image point move new position ffit 
brightness conservation assumption implies ffit brightness image plane 
taylor series expansion ffit gamma ffit ffit ffit ffit ffit ffit ffit ffit equation obtained ffit ffit ffit ffit assuming infinitesimal time interval equation referenced sequel major optical flow constraint 
involves unknowns point image plane optical flow components rewrite equation gradient notation re easily seen velocity component parallel brightness gradient vector determined major optical flow constraint 
form obvious optical flow field equation additional assumptions additional constraints order complete system equations determine optical flow components 
methods discuss sections solve problem different ways 
grouped classes type additional assumption order determine components optical flow field 
smoothness constraints case rigid body neighboring points body move similarly velocities differing slightly 
results smooth optical flow 
horn schunck assumption exploit determining optical flow 
measure field smoothness precisely square magnitude velocity field gradient transformed optical flow estimation optimization problem involving combination criteria error image brightness changes measurement quantity reflecting non smoothness velocity field weighted sum quantities summed image minimized ff dx dy input image corrupted noise quantization error expect identically zero 
quantity magnitude proportional noise measurement weighting factor ff sum chosen equal estimate noise variance image 
calculus variation horn schunck showed optimal optical flow satisfy equations image plane ff gamma ff gamma equations difficult solve general discrete approximation laplacian values system linear equations obtained 
horn schunck approximation defined theta mask displayed fig 
yielding gamma gamma average values calculated formulae gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma approximation substituted get ff gamma gammae ff gamma gammae yields equations point image 
costly solve laplacian estimation mask 
equations standard methods operate sparse matrix size proportional number pixels image 
iterative method proposed order solve problem 
iterative formulae obtained directly gamma ff gamma ff determined experimentally excellent estimates obtained iterations depending close initial estimate correct optical flow 
optical flow previous frame initial estimate sufficiently precise optical flow estimate frame obtained iterations 
method quite stable noise drawback fails sharp changes image flow edges moving objects 
explained fact smoothness assumption method clearly violated edge regions 
improvement previous method proposed nagel 
original smoothness constraint take account consideration brightness edge correspond motion front optical flow required maintain smoothness property 
drawback corrected nagel weighted optimization process involving matrix dependent brightness changes image way smoothness requirement retained essentially optical flow component normal intensity gradient places magnitude large 
easily seen rewritten way re trace trace du du notation new form equation re ff trace du du dx dy nagel correction oriented smoothness constraint equation re ff trace du du dx dy weight matrix 
extensive numerical experiments number different weight matrices involving second order derivatives image brightness introduced order improve oriented smoothness constraint 
methods high order derivatives facet approach low level image processing haralick lee developed new method optical flow estimation requiring intensity values points dt equal derivatives order 
approach assumes conservation order intensity derivatives motion intensity function 
additional requirement implies dt dt dt developing taylor series similarly way major optical flow constraint obtained get additional equations xx xy xt yx yy yt tx ty tt equations form overdetermined system linear equations unknown components optical flow proposed solve overdetermined system pseudo inverse method 
general overdetermined system linear equations ax matrix theta elements vector length vector unknowns pseudo inverse squares solution gamma solution multiplying sides equation obtaining determined system non zero determinant 
particular case xx xy yx yy tx ty gammae gammae xt gammae yt gammae tt independent done haralick lee pastor developed similar method 
differentiated respect implicitly assuming constant small neighborhood point image plane 
led new equations xx xy xt yx yy yt addition 
immediately seen identical equations 
haralick lee pastor pseudo inverse formalism solve resulting overdetermined system linear equations 
nagel showed methods haralick lee pastor particular cases general approach 
expanded brightness function taylor series second order optical flow components order derivatives substituted 
obtained equation xx yx tx dx xy yy ty dy xx yx dx xy xx yy yx dx dy xy yy dy right side equation vanishes dx dy coefficients identically zero 
leads system linear equations xx yx tx xy yy ty xx yx xy xx yy yx xy yy unknowns order derivatives 
system rank additional assumption added order determine unknowns 
nagel showed assume example rot implies get equations causes equations identical system obtained haralick lee 
assumption optical flow constant small neighborhood point consideration 
methods introduced section significant problem practical implementation issues 
high order derivatives quite difficult correctly estimate real images corrupted noise measurement quantization 
usually initial estimates optical flow obtained approaches section post processing procedures invoked order improve quality estimates 
neighborhood sampling approach neighborhood sampling approach assumes certain local behavior optical flow velocity components points chosen small neighborhood approximated velocity components usually central point neighborhood assumed behavior velocity field 
number equations provided neighborhood points equal system equations solved pseudo inverse method 
lucas kanade assumed optical flow components locally constant 
theta neighborhood obtaining equations point image plane 
verri proposed locally linear model optical flow behavior variations optical flow components small neighborhood approximated scheme linear space constant time 
developed optical flow components taylor series neglecting elements second higher orders deltax deltay deltax deltay deltax deltay deltax deltay substituted obtaining equation deltax deltay deltax deltay neighborhood theta pixel get equations type unknowns order spatial derivatives 
neighborhoods pixels experiments testing method 
method extended nagel 
spatial temporal neighborhood point 
optical flow components approximated linear functions space time equation obtained similarly deltax deltay deltat deltax deltay deltat case spatio temporal neighborhood theta theta pixels supplies equations smaller neighborhood considered order get number equations 
nagel theta theta neighborhood note theta theta neighborhood give equations pixel practical 
method provides velocity field point image linear variation space time 
results reported show optical flow generated camera motion relative scene recovered high accuracy 
problem computational cost order find estimation optical flow point compute solution overdetermined system consisting equations 
multiple constraints approach find functions ff associated object surface change object changes position space computable image object projects motion able write equations equivalent major optical flow constraint get system linear equations unknown components optical flow 
system solution equations linearly independent words determinant non zero fi fi fi fi fi fi fi fi fi fi fi fi fi fi family solutions equations dependent 
system overdetermined solved pseudo inverse method 
approach proposed independently number authors 
different functions brightness average median contrast entropy computed small neighborhood theta theta order get multiple constraints optical flow components 
davis functions brightness experiments ffl gradient magnitude ffl curvature gamma ffl moments pq came estimates obtained function unreliable 
main reason fault complexity functions estimation 
similarly high order derivatives functions difficult compute correctly noisy quantized images errors computation functions caused greater errors velocity estimates 
successful experiment approach carried got results comparable horn schunck algorithm 
simple functions velocity estimation ffl average theta window ffl variance theta window ffl median theta horizontal window ffl power content theta window particular frequency bands obtained considerably results 
multiple constraint approach promising point view real time applications 
deals order derivatives involves small amount computations provide reliable results high computational rate 
new methods proposed multiple constraint approach optical flow estimation 
properties corresponding color objects extracted image get overdetermined system linear equations unknown components optical flow 
chapter color vision chapter process vision color black white described models reflectivity color perception introduced 
different systems color representation discussed 
aim chapter provide necessary observations tools image flow estimation method color images 
color perception think vision system array light detectors different types 
type characterized sensitivity light range wavelengths 
number detector types system vary 
system detectors type associated black white vision 
biological research human vision system contains light detectors different types color cameras 
detectors different types produce different images response input spectrum due differences sensitivity functions 
system similar characteristics human vision system considered types called red green blue named corresponding colors sensitivity peaks occur 
remainder sensitivity functions types detectors denoted respectively 
detectors exposed input spectrum color perceived vision system determined non negative fl light reflection surface 
numbers denoted obtained formulae omega omega omega integration visible range wavelength omega nm nm human vision system 
difference black white vision system color type detectors produces single number usually called brightness intensity function image 
reflectivity model consider surface illuminated light characterized power distribution range wavelength point object surface 
reflected light power distribution necessarily equal incidental light 
common assumption reflectivity certain point depends material object surface geometry point fl material interface air body reflection interface reflection incident light interface body components reflection 
fl angles incidence observation phase respectively fig 
factor fl defines completely reflectivity properties surface called reflectivity function surface 
computer vision done assumption reflectivity function separated factors depending spectral properties object surface second depending geometry reflection process ae fl ae spectral factor representing color properties object surface fl geometric factor 
simple model reflects reality considerable accuracy cases 
complex dichromatic model introduced shafer 
model defines types light reflection interface reflection body reflection fig 

surface illuminated light assumed independent processes reflection take place simultaneously producing light components reflected object fl fl indices correspond interface body reflection respectively 
model reflectivity factors assumed separable spectral geometry factors ae fl ae fl total reflected light sum components large set experimental studies conducted order test dichromatic model reflection process 
separability reflectivity function proven experimentally 
furthermore shown materials divided classes reflectivity properties ffl homogeneous materials metals 
group ffl dielectrics 
depending weakly depending weakly incident angle 
matte areas satisfied high accuracy highlight areas const 
highlight areas model agrees simple model reflection state linear behavior separate spectral geometric factors 
highlight areas problematic algorithms computer vision areas image channels reaches full saturation real values cut 
dependable data extracted highlight regions usually identified pre processing stage ignored main stage feature extraction image 
active vision approach special attempts eliminate highlights control illumination 
experiment highlights avoided matte objects diffuse light sources 
color representation natural way represent color perceived vision system triplet output types light detectors 
approach red white pure color curve blue green chromaticity diagram 
represent intrinsic color best way color properties spectrum separated non chromatic ones brightness 
number representations developed separate intensity color characteristics 
systems discussion 
normalized rgb representation normalized rgb representation uses values divided sum clearly independent quantities third determined independent parameters describe uniquely point space vectors dimensional space 
representation consider intensity light having spectrum possible spectra normalized 
graphic illustration normalized rgb system called chromaticity diagram graph pairs corresponding different colors fig 
yellow green magenta cyan blue red black white hsv color system 
feasible colors represented points inside convex region defined pure color curve set points representing pure colors 
color represented point line passing white pure color generated mixing pure color white quantities proportional ratio lengths line segments nm hsv representation hsv representation uses values define color hue saturation value 
value intensity measure corresponds non chromatic light characteristics hue saturation chromaticity parameters encoding color information 
saturation measure pure color certain spectrum ratio pure color white light hue encodes color defined certain wavelength 
mathematical formulae relating rgb hsv systems alue max saturation max max hue max gammab max max gammar max max gammag max hue saturation undefined singular point corresponding black color 
common assume natural values point value hue saturation singularity arises hue computed formulae 
case corresponds different gray tones hue defined naturally 
graphical representation useful understanding system 
colors represented vectors points inside base cone origins axis cone 
pure colors points perimeter cone base 
closer certain vector point perimeter cone base saturated color represents 
hue defined angle radius passing point color vector radius red 
systems color representation systems introduced chosen reasons 
reason simplicity second ratios values order represent color characteristics different spectra 
clear need systems new approach image flow estimation introduced chapter 
chapter image flow color images chapter approaches color images image flow estimation introduced discussed 
assumes brightness conservation motion 
uses quantities provided color images straightforward way 
second method uses quantities represent color properties object precisely values uses image flow estimation 
assumption underlying method color conservation assumption weaker realistic brightness conservation assumption 
experimental testing methods carried results reported section chapter 
brightness conservation approach shown previous chapter color image straightforwardly considered different black white images produced types light detectors different sensitivity functions response input image 
color image components satisfy reasonable assumptions brightness function black white images 
brightness conservation assumption implies values certain point image remain unchanged motion point small temporal neighborhood 
images similar way brightness function constrain velocity flow components point image 
major optical flow constraint applied quantities overdetermined system linear equations obtained image flow components system pseudo inverse solution 
denote gammar gammag gammab pseudo inverse solution system equivalent solution defined system linear equations gamma assumes course matrix rank non singular 
consider cases singular 
matrix singular rank matrix equal columns linearly dependent means order spatial derivatives functions dependent 
sensitivity functions light detectors linearly independent functions order spatial derivatives independent images surface color changing different directions example red increasing direction blue direction 
case uniform color functions linearly dependent color surface changes direction gradient vectors color channels parallel spatial derivatives functions dependent 
image color changing directions brightness functions change independently matrix rank 
mentioned quantities totally independent strong correlation behavior 
reason sensitivity functions domains overlap value power distribution function input image certain wavelength affects quantities 
order de correlate brightness functions image design camera domains sensitivity functions light detectors overlap example infra red light detector detectors sensible visible range spectrum 
case brightness functions independent uncorrelated changes channels connected changes channels camera 
number functions motion estimation equal 
saw functions color channels provide velocity estimates quality provided gradient directions parallel close parallel 
ideal case gradient directions chosen color channels normal 
guaranteed possible input image increase number color channels order obtain precise estimates 
color channels standard camera increase number color light detectors filters order improve quality estimation 
doing remember new detectors sensitivity functions independent existing detectors 
better created sensitivity functions overlap minimal overlapping 
case data obtained vision system totally uncorrelated 
addition estimates image flow components certain point image get measure confidence result point tell extent trust estimates 
common called condition number coefficient matrix system case measure confidence solution system 
formal definition condition number matrix kbk kb gamma non singular singular kbk norm matrix equal maximal eigenvalue matrix condition number matrix measures numerical stability system form bx vector free coefficients vector unknowns 
provides estimate relative errors induced result due presence errors data vector 
summarize velocity vector condition number matrix computed point image analyzed order get final result 
similar method proposed ohta 
suggested pairs color channels order get equations unknown components image flow 
test method experimentally proposed ways combine results obtained different pairs equations 
experimental testing pseudo inverse method demonstrated quite stable noise produces accurate results images objects translating plane parallel image plane 
rotation motion normal image plane method provided highly erroneous estimates 
reason failure explained section new method capable deal kinds motion proposed 
color conservation approach discussion light reflection image generation previous chapter easily seen brightness conservation rough approximation 
defined equation brightness point image function sensitivity curves light detectors input spectrum 
input spectrum turn depends factors scene illumination object reflectivity reflection geometry 
factors change certain object moves scene faster scene changes greater errors introduced major optical flow constraint 
find new functions local color information remain invariant object motion brightness function constraining image flow components 
recalling reflectivity model introduced previous chapter see equation see power distribution reflected light proportional power distribution incident light reflectivity function object surface 
proven experimentally reflectivity function separated independent factors spectral component ae geometry component fl angles fl define reflection process geometry directions incident light reflected light normal vector object surface point equations combined obtain omega fl ae omega fl ae omega fl ae geometry component fl reflectivity function depend light wavelength moved integral obtain fl omega ae fl fl omega ae fl fl omega ae fl equations imply brightness functions separated geometry component fl depends entirely relative position orientation object light source camera spectral component defined omega ae fr bg examine factors influence quantities 
spectral component ae reflectivity function depends geometry scene illumination properties 
represents color properties object remains invariant changes object position orientation 
sensitivity function light detector change variations scene 
illumination spectrum assumed change slowly considered constant small temporal neighborhood quantities defined satisfy invariance assumption change object camera move 
think quantities representing object color certain illumination 
object color invariant motion talking chameleon quantities representing color constant illumination invariant motion estimation 
note flow estimates obtained color conservation assumption called optical flow definition optical flow associated brightness changes image 
new estimates associated color changes image closer image flow optical flow properties closely connected surface properties objects brightness function 
shall term image flow estimation denote flow estimates obtained color functions image 
obvious method brightness conservation assumption produces results close image flow reflection geometry geometry component fl change object moves 
parallel light source uniform illumination translation change geometry reflection process 
similar observation singh showed theoretically optical flow equal translation component image flow objects lambertian surface reflectivity 
geometry reflection process changes significantly object motion rotation motion camera brightness function satisfy conservation assumption 
new functions remain invariant kind motion influenced assumption illumination behavior quite realistic stationary light sources outdoor scene photographed weather conditions change sharply successive frames 
geometry reflection process 
question extract quantities functions provided color image 
impossible extract explicitly values values immediately seen ratio linear combinations values equal ratio corresponding values geometry component fl functions 
quantities invariant motion ratios invariant ratios values estimate motion 
order obtain ratios functions color representation systems introduced previous chapter normalized rgb system denoted rgb system hsv system 
systems introduces independent quantities represent color properties spectrum rgb system uses pair quantities hsv system defines hue saturation purpose 
systems independent quantities representing color properties spectrum defined different ratios quantities 
fact strengthens proposal systems defined independently problems discussed order represent color way color properties separated measure brightness 
quantities method denoted rgb system hue saturation hsv system color conservation assumption implies precisely gradients linearly independent system determined solution provides estimate image flow 
similarly method proposed previous section compute velocity estimates confidence measure estimates defined condition number coefficients matrix final stage estimation process results condition numbers certain threshold taken account 
new method proposed drawbacks discussed 
gradient methods new method proposed image flow estimation requires presence significant gradients functions 
magnitude brightness gradient image small gradient method brightness fail produce reliable results 
similar way gradient color scene spatial derivatives color functions equal zero method fail produce estimates 
quantized images corrupted noise singular point extended small neighborhood zero 
gradient object color close equal zero magnitude comparable noise image estimates obtained proposed methods unreliable 
implies method scene contains objects uniform color 
cases motion estimation necessary color gradient artificially created painting certain object areas color gradients 
possible reason failure method equations dependent 
happen color functions changes way proportional order spatial derivatives 
example hsv system hue saturation proportional spatial derivatives order equations dependent 
possible color functions linear function 
special case happen real image sequences 
experimental results methods proposed chapter tested equipment center intelligent systems computer science department technion 
synthetic real image sequences testing 
results obtained methods color functions compared results provided brightness functions motion estimation 
general description implementation provided results reported image sequence 
barron implemented number existing techniques optical flow estimation order compare performance 
provides useful information practical aspects optical flow estimation problem implementation 
implementation gradient method optical flow estimation consists basic stages smoothing extraction image functions optional estimation derivatives optical flow estimation post processing optical flow 
stage described detail 
smoothing image sequence 
images obtained camera corrupted noise quantization errors smoothing necessary estimation derivatives 
gaussian kernel smoothing different values oe parameter synthetic oe real oe images 
smoothing operation performed separately space directions time direction 
extraction image functions 
stage optional 
method optical flow estimation uses brightness functions stage omitted new quantities normalized rgb system hue saturation hsv system extracted brightness functions 
computation derivatives 
stage order derivatives image functions estimated 
gamma gamma kernel compute derivative 
spatial derivatives computed theta neighborhood line copy estimation kernel defined estimation temporal derivative theta theta spatio temporal neighborhood 
optical flow estimation 
stage optical flow computed estimated derivatives particular method 
experiments system testing method assuming brightness conservation system testing method color conservation assumption 
post processing 
field obtained previous stage processed order eliminate singularities usually median smoothing operators 
threshold operation condition numbers performed stage filtering results rgb rgb hsv error statistics ball moving plane parallel image plane 
results different methods reported rgb normalized rgb hsv quantities respectively 
methods demonstrate similar performance 
low confidence 
theta median filter postprocessing operation confidence threshold 
order obtain estimates temporal derivative image functions brightness functions color functions successive frames estimation 
technique real time applications takes time process long sequence 
fleet langley proposed new method estimating derivatives frames providing reasonable quality estimates method improved time computation significantly 
conjunction method achieving real time processing speed 
derivatives computed real time system real time optical flow estimation readily built methods proposed 
synthetic images 
synthetic image sequences generated way reflectivity function defined ball light source defined longitude tilt sensitivity functions light detectors defined 
images obtained simulation ball moving space light reflection image generation processes artificially corrupted noise quantized 
figures demonstrate statistics errors various displacements different kinds motion 
expected methods produced similar results translation complex motion considered method brightness conservation assumption failed produce accurate estimates 
normalized rgb hsv systems provide results kinds motion error rate method hsv functions slightly higher normalized rgb 
particular application sets color functions tested order select suitable particular sequences 
figures illustrate experiments 
images sequence expected image flow shown estimates reported different methods rgb normalized rgb hsv functions respectively 
method estimated flow difference expected estimated fields confidence measure shown 
flow fields displayed needle diagrams length needle certain point image proportional velocity magnitude point needle direction equal velocity vector 
confidence measure shown black white images grey level certain point image equal condition number coefficient matrix point 
darker certain region confidence measure image lower condition number represents higher confidence velocity estimates region 
seen image area edges white confidence measure image confidence considerably high dark regions confidence measure image 
real images 
real images obtained color camera frame grabber intelligent systems center 
object color pattern attached robot hand moving various ways image sequences taken 
rgb rgb hsv error statistics ball rotating axis normal image plane 
results different methods reported rgb normalized rgb hsv quantities respectively 
error rate method brightness functions higher color functions 
rgb rgb hsv error statistics ball moving camera 
results different methods reported rgb normalized rgb hsv quantities respectively 
error rate method brightness higher color functions 
difficult determine true image flow real images usually qualitative testing performed 
figures illustrate experiments carried order test proposed methods 
results reported similarly experiments synthetic images flow fields shown needle diagrams confidence measure estimates displayed gray level images dark areas corresponding high confidence light areas corresponding low confidence 
note synthetic sequences color gradient generated background estimates obtained image real images background uniformly painted confidence measure background region quite poor 
estimation obtained region taken account zero motion field assumed 
synthetic images translation 
synthetic images rotation 
synthetic images motion camera 
synthetic images moving light source 
real images translation 
real images rotation 
real images motion camera 
chapter demonstrated color images opposed black white ones provide reliable information motion estimation 
different approaches motion estimation color images introduced 
approach proposed considers color image set different black white images 
brightness conservation assumption applied color image components leads overdetermined system linear equations velocity vector components point image 
approach provides sufficient quality velocity estimates object undergoes translations plane parallel image plane complex motion involved method brightness conservation assumption produces estimates significant errors 
behavior expected due inherent assumption underlying method brightness function truly invariant types complex motions 
order improve quality motion estimation new approach proposed 
uses color functions motion estimation 
functions extracted brightness functions image represent color properties object surface certain illumination 
assuming illumination spectrum locally constant quantities truly invariant kind motion allow obtain better estimates brightness functions 
different sets color functions invariant motion normalized rgb hsv color representations 
experimental results obtained sets color functions compared estimates obtained brightness functions 
experiments confirmed expectations color functions directly related surface properties objects provide precise information object motion 
multiple constraint method estimate image flow 
note color functions gradient approach motion estimation 
chapter existing methods gradient approach discussed assumes brightness conservation uses brightness function estimate optical flow 
color functions method implemented color invariance motion result better estimation complex types motion 
user requirements carefully considered certain gradient method selected implemented 
example multiple constraint approach motion estimation uses entirely local information estimates stable ones produced neighborhood information 
black white images considered neighborhood sampling approach provides stable solution multiple constraint approach produce better results color functions brightness 
interested higher accuracy stability neighborhood sampling approach considered color functions brightness functions 
experimental testing confirmed new proposed methods provide estimates image flow regions considerable gradient color regions uniform color methods failed produce reliable results 
defines domain possible applications methods color motion estimation 
bibliography barron fleet beauchemin 
performance optical flow techniques 
international journal computer vision 
pp 
horn 
passive navigation 
computer vision graphics image processing 
pp 
buchsbaum 
spatial processor model object color perception 
journal franklin inst 
verri 
computing optical flow overconstrained system linear algebraic equations 
proceedings third international conference computer vision iccv osaka japan 
pp 
carlsson 
sufficient image structure motion shape estimation 
lecture notes computer science 
pp 
fleet langley 
real time optical flow 
proceedings conference vision interface toronto canada 
pp 
golland bruckstein 

design color displays 
technical report lab cs department technion haifa israel 

color vision 
principles neural science 
editor kandel prentice hall international london 
pp 
haralick lee 
facet approach optic flow 
proceedings image understanding workshop 
editor baumann science applications arlington va 
pp 
hardy 
theory color reproduction 
journal optical society america 
pp 
heeger jepson 
simple method computing motion depth 
proceedings third international conference computer vision osaka japan 
pp 
horn 
exact reproduction colored images 
computer vision graphics image processing 
pp 
horn schunck 
determining optical flow 
artificial intelligence 
pp 
jennings 
matrix computation engineers scientists 
john wiley sons 
land 
retinex theory color vision 
scientific american 
pp 

lee schulte 
modeling light reflection computer color vision 
ieee trans 
pattern analysis machine intelligence pami 
pp 
higgins prazdny 
interpretation moving retinal image 
proceedings royal society volume london 
pp 
lucas kanade 
iterative image registration technique application stereo vision 
proceedings darpa image understanding workshop 
pp 

luong 
color computer vision 
handbook pattern recognition computer vision chapter 
editors chen pau wang world scientific publishing 
pp 
wang aggarwal 
experiments computing optical flow gradient method 
pattern recognition 
pp 

nagel 
constraints estimation displacement vector fields image sequences 
proceedings ijcai karlsruhe germany 
pp 

nagel 
estimation optical flow relations different approaches new results 
artificial intelligence 
pp 
ohta 
optical flow detection color images 
proceedings ieee international conference image processing pan pacific singapore 
pp 
ortega 
numerical analysis second course 
siam press philadelphia usa 

nagel 
optical flow estimation advances comparisons 
lecture notes computer science 
pp 
shafer 
color separate reflection components 
color research application 
pp 
singh 
optic flow computation unified perspective 
ieee computer society press los alamitos california usa 

standard surface reflectance model illuminant estimation 
journal optical society america 
pp 
pastor 
velocity estimations image sequences second order differential operators 
proceedings international conference pattern recognition 
montreal canada 
pp 

dsp solutions run gamut color systems 
ieee signal processing magazine april 
pp 
verri poggio 
quantitative optical flow 
proceedings international conference computer vision london 
pp 

synthesis analysis color images 
ieee trans 
pattern analysis machine intelligence pami 
pp 
davis 
motion estimation multiple local constraints nonlinear smoothing 
pattern recognition 
pp 

