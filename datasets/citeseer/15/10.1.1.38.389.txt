automatic lip synchronization algorithm synthetic faces keith waters thomas digital equipment cambridge research lab crl september digital equipment research facilities systems research center western research laboratory palo alto california paris research laboratory paris cambridge research laboratory cambridge massachusetts 
cambridge laboratory operational located kendall square near mit 
crl engages computing research extend state computing art areas important digital customers years 
crl main focus applications technology creation knowledge tools useful preparation important classes applications 
crl technical reports ordered electronic mail 
receive instructions send message addresses word help subject line digital crl techreports internet techreports crl dec com may copied reproduced commercial purpose 
permission copy payment granted non profit educational research purposes provided copies include notice copying permission cambridge research lab digital equipment acknowledgment authors applicable portions copyright notice 
digital logo trademark digital equipment 
cambridge research laboratory kendall square cambridge massachusetts tm automatic lip synchronization algorithm synthetic faces keith waters thomas digital equipment cambridge research lab crl september report addresses problem automatically synchronizing computer generated faces synthetic speech 
complete process called provides novel form face face ability create new range talking synthetic characters 
plain ascii text input synthetic speech segment generated synchronized real time graphical display articulating mouth face 
key component run time facility adaptively synchronizes graphical display face audio 
keywords face face key framing anatomically text speech viseme phonetics equipment 
rights reserved 
unix trademark unix systems laboratories 
apple registered apple computer trademarks digital equipment alpha axp dec decstation ultrix digital logo 
early age sensitive bimodal nature speech cues visual auditory modalities comprehension 
visual stimuli tightly integrated perception speech commonly believe hearing impaired lip read mcg 
fact people normal hearing available visual information accompanies speech especially degradation acoustical signal mm 
fluent speech emphasized punctuated facial expressions increasing desire observe face speaker 
goal expressive bandwidth human face real time synthetic facial models capable interacting eliciting responses user 
ideal interface eventually natural dialogue humans computers consider subset larger goal technique automatically synchronize mouth shapes real time speech synthesizer 
computer generated face distinct advantages images real people primarily possible create control precise repeatable facial actions 
faces suggest unique novel scenarios presenting information particularly way interaction enhanced listening reading information 
examples type interaction walk kiosks atm tellers office environments tomorrow 
near going see man machine interfaces mimic way interact face face 
years ago apple computer produced futuristic video called knowledge navigator advertising notion active agents 
video phil active agent performs variety tasks request user 
reality system environment exists 
worth noting phil head shoulders image real actor primary interface computer 
synthetic facial images potential situations information controlled unbiased fashion interviewing 
furthermore synthetic speech face generator combined systems perform basic facial analysis tracking focus user analyzing user speech possible transform computer inert box computer chk 
background previous images animated speech created device called des 
device mounted images background previous lower face disk rotated fast exploit persistence vision 
nearly years old underlying process employed animation today 
photographs traditional animation relies hand drawn images lips tj 
sound track recorded exposure sheet marked timing phonetic information 
animator draws tailor mouth shape corresponding precise frame time 
expect process extremely labor intensive 
attempts computer facial animation involved key framing complete facial expressions captured frames computed interpolation par 
immense variety facial expressions approach extremely data intensive prompted development parametric models facial animation 
parametric facial models par par create expressions specifying sets parameter value sequences instance interpolating parameters direct key framing 
parameters control facial features mouth opening height width protrusion 
limitations ad hoc parameterized models prompted movement models parameters anatomy face pla pb wat wai mpt 
models operate parameters facial muscle structures 
anatomically models incorporate facial action coding schemes control procedures ef relatively straightforward synthesize range recognizable expressions 
geometric surface face typically described collection polygons displayed standard lighting models gou pho 
texture mapping reflectance data acquired photographs faces laser provide valuable technique enhancing realism facial modeling animation nhs wil ct 
geometry coarse striking images generated 
date non automated techniques commonly achieve 
process involves recording sound track series control files manually created 
files specify jaw lip positions key timing information graphics audio recorded exactly time face appears speak 
key framing requires complete face posture key position bl 
parametric models harness nodes moved synchronization timings script par 
likewise anatomical models coordinate muscle contractions synchronize timing information script file wat 
essence techniques obvious extensions traditional hand animation 
unfortunately inherent problem lack flexibility 
audio modified slightly ambiguities synchronization created process lip reading phonetics speech repeated 
automatic lip synchronization tackled directions synchronization synthetic speech synchronization real speech 
case objective speech analysis automatically identify lip shapes speech sequence 
brief speech sequence transferred representation formant frequencies emphasized pitch information largely removed 
representation parsed words 
task difficult acoustic pre processing reasonably effective driving phonetic scripts wei lp 
lip synchronization synthesizer converse problem governing speech parameters known 
hill pearce wyvill extended rulebased synthesizer incorporate parameters facial model 
synthesizer scripts created facial parameters modified 
speech sequence generated recorded audio channel video tape 
facial model generated frame frame recorded non real time video section tape 
consequently sequence played back face appeared speak 
lip reading phonetics speech english lip reading observation phonemes associated visemes wal 
traditionally lip reading considered completely visual process developed small number people completely deaf 
mechanisms employed visual speech perception auditory visual audio visual 
hearing impairment concern audio visual placing emphasis observing context words spoken posture facial expression 
speech comprises mixture audio frequencies speech sound belongs main classes known vowels consonants 
vowels consonants belong basic linguistic units known phonemes mapped visible mouth shapes known visemes 
vowel mouth shape viseme groups fp bg ff vg reliably observed vowels confusion individual consonants viseme group common mcg 
despite low threshold understanding misunderstanding discrete phonetics provide useful abstraction group speech sounds common acoustic articulatory features 
phonemes visemes basic units visible articulatory mouth shapes 
background previous speech synthesis automatic text speech synthesis describes process generating synthetic speech arbitrary text input 
cases achieved sound component synthesizer component 
complete review automatic speech synthesis see kla 
general letter sound system lts accepts arbitrary ascii text input produces phonemic transcription output 
lts component uses pronunciation lexicon possibly collection letter sound rules convert text phonemes lexical stress markings 
letter sound rule sets predict correct pronunciation dictionary match 
synthesizers typically accept input phonemes letter sound component produce synthetic audible speech 
classes segmental rule techniques identified klatt kla 
rules programs articulation rule programs concatenation systems 
technique attempts create natural intelligible synthetic speech phonemes 
formant synthesizer speech spectrum collection rules heuristics control digital filter model vocal tract 
kla examples formant synthesizers 
concatenation systems name suggests synthesize speech splicing short segments parameterized stored speech 
example speech segments stored sequences lpc linear predictive coding parameters speech 
olive utter system example diphone synthesis concatenative system 
formant rule programs concatenation systems capable producing intelligible synthetic speech 
concatenation systems tend introduce artifacts speech result discontinuities boundaries stored acoustic units 
furthermore concatenation systems store inventory sound units may order bytes voice diphone system 
formant synthesizers require far storage concatenative systems restricted number quality voices speakers produced 
particular synthesizing voice truly feminine quality difficult kla 
purpose synchronizing speech synthetic faces formant concatenative approach 
formant synthesizer 
previous described section produces animation single frame mode subsequently recorded video tape 
contrast previous report describes fundamentally different approach automatically synchronizing computer generated faces synthetic speech 
complete process called provides novel form real time face face communication 
unique feature ability generate speech graphics real time rates audio graphics tightly coupled generate expressive synthetic facial characters 
demands fundamentally different approach traditional techniques 
furthermore compute synthetic faces synchronize audio real time requires powerful computational resource alpha axp workstation 
algorithm section presents algorithm automate process synchronizing lip motion formant speech synthesizer 
key component algorithm run time facility adaptively synchronizes graphical display face audio 
executes sequence operations 
input ascii text 
create phonetic transcription text 
generate synthesized speech samples text 
query audio server determine current phoneme speech playback 
compute current mouth shape nodal trajectories 
play synthesized speech samples synchronize graphical display step integral component algorithm viewed pre processing stage 
phonetic transcription audio samples generated advance stored disk desired 
steps concerned adaptive synchronization repeated speech samples left played 
algorithm text audio server sever time waveform buffer tts face generator synchronization phonetic index viseme table mouth deformations display synchronization model tts text speech 
system requires digital analog converter dac produce analog speech waveform 
associated audio playback device sample clock maintaining representation time queried application program 
term audio server describe system software supporting audio device 
loss synchronization noticeable audio domain audio server clock global time base 
audio server device clock sampled initialization speech samples played relative initial device time 
text speech algorithm uses 
algorithm implementations case software implementation 
sufficient computing power available special hardware coprocessor needed synthesize real time speech 
comprises major algorithms letter sound system phonemic synthesizer vocal tract model 
letter sound system accepts arbitrary ascii text input produces phonemic transcription output pronunciation lexicon collection letter sound rules english 
part process input text may reformatted convert numbers abbreviations words punctuation 
time base phonemic synthesizer accepts phonemic transcription output letter sound system produces parameter control records vocal tract model 
component applies intonation duration stress rules modify phonemic representation phrase level context 
rules applied phonemic synthesizer calculates parameters vocal tract model 
resulting phonetic sequence provided synchronization component 
vocal tract model accepts control records phonemic synthesizer updates internal state order produce frame synthesized samples 
vocal tract model formant synthesizer model described klatt kla 
vocal tract model consists voiced unvoiced waveform generators cascade parallel resonators summing stage 
frequency bandwidth gain parameters control record compute filter coefficients resonators 
time base timing critical component algorithm audio graphics synchronization achieved common global time base exists 
initial time recorded audio server sample speech output 
re sampling audio server time exact correspondence phoneme phoneme pair determined 
relative time start speech output gamma calculate current viseme mouth shape 
audio server sample rate hz ideally graphical display frame rate hz 
avoid aliasing artifacts interpolation values computed server time 
mouth deformations current time relative determined audio device displacement mouth nodes calculated 
viseme mouth node defined position sequences nodes defining geometry topology mouth 
permit complete mouth shape interpolation topology remain fixed nodes prototype mouth shape correspondence 
intermediate interpolation position calculated viseme nodes ux sx ux sx ux sx algorithm gamma parameter usually described linear non linear transformation 
motions linear interpolation fail exhibit inertial motion characteristics acceleration deceleration 
closer interpolated approximation acceleration deceleration uses cosine function ease motion gamma cos gamma cosine interpolant efficient solution provides acceptable results 
fluent speech mouth shape rarely converges discrete viseme targets due short interval positions physical properties mouth 
emulate fluent speech need calculate articulated visemes 
piecewise linear interpolation smooth node trajectories various splines provide approximations node positions far 
addition parameters tension continuity bias splines begins emulate physical motion trajectories kb 
significant flaw splines animation originally developed means defining static geometry motion trajectories 
dynamic system nodal displacements physical behavior mouth developed initial configuration nodes specified positions masses velocities 
geometric configuration specified newtonian physics applied dx dt dv dt gamma know state positions fact calculating trajectory vector resolve forces applied nodes assumed forces applied nodes fl velocity dependent damping coefficient 
noted forces generated node neighbors mesh target node target node 
mouth shape deformations elastic force separation nodes providing approximation elastic behavior facial tissue synchronization vector separation nodes gamma equations motion integrated projected time derived audio server time calculate new velocities node positions dt dt equation uses previous velocity positions update new nodal positions 
rigorous numerical integration techniques improve numerical stability convergence complex implement increase computation time 
dynamic equations motion desirable attribute approximating node positions peaking viseme mouth shape 
addition dynamic system adapts rate speech increases reducing lip displacements tries accommodate new position 
behavior characteristic real lip motion 
synchronization synchronization audio graphics achieved follows 
audio server initialized returning start time sequence 
small number samples sequence played returning duration milliseconds current server time 
relative animation time computed current server time calculate current mouth deformation 
mouth deformation calculated manipulations eye blinking take place relative animation time 
face updated rendered displayed screen 
face model topologies facial synthesis typically created explicit polygons par 
simplicity construct simple wire frame representation frontal view 
model consists polygons represent mouth additional represent teeth 
jaw nodes moved vertically function displacement corners mouth fro 
lower teeth displaced lower jaw 
add level dynamic realism eyelids animated 
face model mapping screen space dv du uv texture space polygonal representation face 
texture mapping 
face rendering wire frame provides suitable model observe motion characteristics face visual representation clearly unrealistic 
face polygons shaded gouraud phong shading models results faces look plastic 
texture mapping powerful technique adds visual detail synthetic images hec 
particular texture mapping greatly enhances realism synthetic faces 
incremental scanline texture mapping technique achieve realistic faces 
incremental texture mapping scanline gouraud shading algorithm gou 
interpolating intensity values polygon vertices interpolates texture coordinates 
computing texture coordinates polygon provides fast mapping texture space 
color value extracted applied current scanline screen space 
step current scanline screen space du dv incremented constant amount texture space 
effectively increment slope dv du rapidly index texture space 
efficiency coordinate samples texture space returns value current scanline 
rr ax yu ae ix eh ch ix table phonemes durations milliseconds sample sentence 
example text practice questions demonstrate algorithm section 
words spoken words minute female voice 
words referred sample sentence 
synthesizer produces sequence phoneme duration pairs table sample sentence 
phonemes belong character direct correlation visemes depicted table 
create table persons mouth uttering cvc vcv strings table 
time displacement graph illustrating different computed trajectories illustrates third frame trajectories 
trajectory cosine displacement peaks viseme mouth shapes 
trajectories dynamic trajectories computed equation 
trajectories controlled variables fl representing velocity damping coefficient spring constant respectively 
mass remains constant examples 
sp fl sp fl 
illustrates sequence frames complete texture mapped facial model speaking sample sentence 
physical model facial tissue motion provides acceleration deceleration emulating inertial characteristics mouth changes shape 
evident rapid speech mouth complete mouth shapes produces blend shapes muscular forces 
final result natural looking mouth motion 
example time ms disp mid top lip vertical displacement trajectories sample sentence 
trajectory cosine activity peaking phonetic mouth shape 
trajectory physical model small damping coefficient large spring constant trajectory physical model larger damping coefficient lower spring constant 
trajectory trajectory trajectory ms ms ms ms ms ms ms ms ms third viseme produced sample sentence trajectory 
performance implementation implement real time version incorporated existing hardware software components alpha axp workstation running dec osf alpha operating system 
synthesized speech output vocal tract model played converter hardware supporting bit linear pcm pulse code modulation bit law log pcm encoded samples operating khz sampling rate 
example baseboard codec alpha axp workstations module lev may 
peripheral containing highly flexible audio converter capabilities 
audio server client library lpg interface audio hardware provide applications programming interface audio portion 
client library provides application programming interface accessing audio server audio hardware 
uses window system display rendered facial images 
tk ous ous widget user interface facilitates interactive 
variety commands piped 
speech synthesizer arbitary text created text widget spoken internal voices 
addition user specify number words minute comma period pause durations 
face synthesizer sliders associated linear muscles wat allowing simple facial expressions created 
graphical display characteristics selected including texture wireframe physical simulation muscles smp software motion pictures clip generator 
performance performance data dec alpha axp workstation mhz clock collected provide performance indicator 
wireframe texture mapped versions timed images pixels 
table illustrates frames rates wireframe texture modes 
timing data includes cost generate synthetic speech 
performances wireframe texture mapped models frames second 
frame rates convincing lip created 
texture mapping code highly optimized little effort spent improving performance wireframe model 
contraction coder decoder 
silence rr comma pause ax yu frames test sequence 
phonemic characters indicated key visemes 
emphasize mouth articulation cosine trajectory computed 
performance interface geometry pixels sec total frames sec wireframe computed wireframe physics computed texture mapped texture mapped physics table performance table dec workstation 
discussion expect naturalness synthetic speech intelligibility measure compelling factor presentation synthetic character voice 
easily imagine character expressive voice face closely interacting user 
easy envision significant technical issues addressed graphics audio domains 
example create character capable telling joke expressing anger distress emotional states 
challenge graphics perspective critical examination face model approaches reality 
shortcomings exaggerated plastic faces readily dismissed expectations low caricatures 
reason tolerant faces real people manipulated know precisely look articulate 
images real people articulations mimic reality extremely closely 
alternative exploit nuances caricatures create new synthetic character way cartoon animators today 
lip synchronization crucial building articulate characters important characteristics body posture facial expression convey information 
combining facial expression speech scope deliberately omitted 
research demonstrated basic expressions dramatically enhance realism talking face simple eye blinks bring face life 
important remember phonetic transcription interpretation imposed continuously varying acoustic signal 
visemes extensions phonemes 
algorithm extended articulated words viseme synchronization ultimately text speech synthesizer 
designed operate images extensions straightforward 
fact physically face systems simply modified incorporate 
plan incorporate facial model 
demonstrated algorithm automatically synchronizing lip motion speech synthesizer real time 
flexibility algorithm derived ability completely synthesize face speech explicitly stream appendix ascii text 
ability interpret unstructured text generate realtime facial articulations truly unique 
arbitary text derived sources database queries expert systems mail files editors face provides character capable engaging user simple verbal interactions 
dynamic model provides trajectories mimic motion real lips 
viseme table constructed little effort correlated specific speech synthesizer 
conjunction table visemes dynamic model provide necessary vehicle develop various mouth shape trajectories 
highly desirable people speak exactly 
believe completely synthetic facial models coupled synthetic speech generators provide unique form interaction computer 
richard szeliski crl re wrote optimized original texture mapping code assistance achieved real time graphical performance 
andy payne tutorial tk interface 
jan walker constant suggestions improvements 
lee sproull anne dix face lip images 
dick provided editorial skills 
acknowledge dave visualization group crl valuable suggestions comments 
appendix table illustrates mouth shapes associated phonemic characters derived observation real lips 
table illustrates mouth shapes associated phonemic characters examples 
si silence iy beat ih bit ey eh bet ae bat aa pot ay buy aw ah ao bought ow boat oy boy uh book uw rr bird yu cute ax ix kisses ir killer er bird ar butter ur churn wet red ll hx head rx lx met net nx sing el bottle debt en button fin vet th thin dh sit zoo sh shin zh measure pet bet test debt kit get dx tx latin gl ch church jh judge table viseme table mouth shapes associated phonemic characters examples 
table derived observation real lips appendix si silence iy beat ih bit ey eh bet ae bat aa pot ay buy aw ah ao bought ow boat oy boy uh book uw rr bird yu cute ax ix kisses ir killer er bird ar butter ur churn wet red ll hx head rx lx met net nx sing el bottle debt en button fin vet th thin dh sit zoo sh shin zh measure pet bet test debt kit get dx tx latin gl ch church jh judge table viseme table mouth shapes associated phonemic characters examples 
author information keith waters joined cambridge research lab crl 
research interests include computer graphics physically modeling volume visualization medical facial applications facial synthesis 
joining digital keith member staff schlumberger lab computer science austin texas 
ph computer graphics ba graphic design polytechnic 
joined crl 
tom focus speech audio related research 
involved alpha axp system software projects including experimental evaluation split user supervisor cache memories 
received electrical engineering electrical engineering worcester polytechnic institute 
authors reached digital equipment cambridge research lab kendall square bldg 
cambridge ma mail crl dec com 
bl bergeron 
techniques animating characters 
advanced computer animation volume siggraph tutorials pages 
acm 

tiered software vlsi aid developmental system read text aloud 
electronics 
chk hsu klinker szeliski waters doyle gettys harris palmer palmer terzopoulos wallace 
modeling analysis empirical data collaborative environments 
communications acm cacm june 
ct choi analysis synthesis facial expressions knowledge coding facial image sequences 
conference acoustics speech signal processing pages 
des 
du cinema 

ef ekman friesen 
manual facial action coding system 
consulting psychologists press palo alto ca 
far farin 
curves surfaces computer aided geometric design 
academic press new york 
fro 
lip positions american english vowels 
language speech 
gou gouraud 
continuous shading curved surfaces 

hec heckbert 
texture mapping 
ieee computer graphics applications 
hill pearce wyvill 
animating speech automated speech synthesis rules 
visual computer 
kb bartels 
interpolating splines local tension continuity bias control 
computer graphics 
kla dennis klatt 
software cascade parallel formant synthesizer 
acoust 
soc 
am 
kla dennis klatt 
review text speech conversion english 
acoust 
soc 
am 
lev thomas 
lofi audio module 
crl technical report digital equipment cambridge research lab 
lp lewis parke 
automatic lip synch speech synthesis character animation 
chi cg pages toronto 
lpg thomas andrew payne james gettys lawrence stewart 
network transparent system distributed audio applications 
technical report digital equipment cambridge research lab 
mcg mcgrath 
examination cues visual audio visual speech perception natural computer generated faces 
phd thesis university nottingham england november 
mm macdonald 
hearing lips seeing voices 
nature 
mpt magnenat thalmann thalmann 
muscle actions procedures human face animation 
visual computer 
nhs 
animation spline 
visual computer 
olive 
new algorithm concatenative speech synthesis system augmented acoustic inventory speech sounds 
proceedings european speech communications association workshop speech synthesis pages france september 
oka 
realtime manipulation texture mapped surfaces 
computer graphics 
ous john ousterhout 
tcl embeddable command language 
proceedings usenix winter conference january 
ous john ousterhout 
toolkit tcl language 
proceedings usenix winter conference january 
par parke 
computer generated animation faces 
master thesis university utah salt lake city june 
csc 
par parke 
model human faces 
phd thesis university utah salt lake city utah december 
csc 
par parke 
parameterized models facial animation 
ieee computer graphics applications 
par parke 
state art facial animation 
acm siggraph course notes 
pb platt badler 
animating facial expressions 
computer graphics 
press teukolsky 
numerical recipes art scientific computing 
cambridge university press cambridge 
pho phong 
illumination computer generated pictures 
cacm 
pla platt 
system computer simulation human face 
master thesis moore school pennsylvania 
tj thomas johnson 
disney illusion life 
press new york 
wai waite 
facial action control editor face parametric facial expression editor computer generated animation 
master thesis massachusetts institute technology media arts sciences cambridge 
wal walther 
lipreading 
nelson hall chicago 
wat waters 
muscle model animating dimensional facial expressions 
computer graphics siggraph july 
wei weil 
face 
master thesis massachusetts institute technology architecture group cambridge august 
wil williams 
driven facial animation 
computer graphics 
