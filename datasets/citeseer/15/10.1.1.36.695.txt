buyer guide conic fitting andrew fitzgibbon robert fisher department artificial intelligence edinburgh university forrest hill edinburgh eh ql evaluate methods fitting data conic sections 
conic fitting commonly required task machine vision algorithms perform badly incomplete noisy data 
evaluate algorithms various noise degeneracy conditions identify key parameters affect sensitivity results comparative experiments emphasize algorithms behaviours common examples degenerate data 
addition complexity analyses terms flop counts provided order inform choice algorithm specific application 
vision applications require extraction conic sections image data 
common examples calculation geometric invariants estimation centers radii circles industrial inspection 
textbooks provide discussions algorithms squares approximation conics include simple fast algebraic distance algorithm algorithm lin 
algorithm fares poorly real data sets due inherent statistical bias particularly image curves partially occluded 
number authors proposed alternative algorithms usually compared authors lin knowledge comparative studies relative accuracy efficiency alternatives 
important contributions area computer vision research ffl identification main conditions algorithms fail 
common comparative evaluations concentrate noise sensitivity case conic fitting important parameter amount occlusion 
ffl presentation algorithm complexities terms flop counts allows evaluation tradeoff accuracy speed execution specifics implementation environment 
funded uk epsrc gr 
british machine vision conference methods compared differ primarily terms error measure minimize terms techniques minimize measure 
particular error measure determines eventual accuracy methods generally dictates choice optimization algorithm execution speed 
problem statement problem algorithms solve may stated follows 
ffl set data points fx ffl family curves parameterized vector ffl distance metric ffi measures distance point curve find value min error function ffl ffi attains global minimum 
curve curve best fits data 
curve families considered represented implicit form fx 
families examine general conic sections xx xy xy yy circles fc note forms may written way separates parameters ff terms dot product delta xx xy yy delta algorithms algorithm lin algebraic distance algebraic distance algorithm minimizes objective function ffl subject constraint kak 
design matrix theta matrix rows constrained objective function gamma kak gamma da gamma gamma minimized analytically form eigenvector problem rae da gamma lagrange multiplier 
minimizer min eigenvector corresponding smallest eigenvalue 
british machine vision conference algorithm requires multiplications adds approximately flops construction unique elements evaluation eigensystem hessenberg reduction qr generally took iterations flops experiments giving total complexity flops 
algorithm book algebraic distance quadratic constraint bookstein algorithm attempts reduce bias lin imposing different constraint parameter vector derives constraint xx xy yy shows leads system da deltaa delta diag 
rank deficient generalized eigensystem bookstein solves block decomposition 
book requires flops lin form matrix 
matrix inversion eigensystem solution mean flop count yielding total complexity flops 
algorithm ams approximate mean square distance approximate mean square distance metric introduced taubin minimizes unusual objective function ffl kd ak kd ak matrices partial derivatives respect restating problem minimization subject kd ak kd ak minimizer min eigenvector generalized eigensystem da corresponding largest eigenvalue 
ams requires flops lin form matrix negligible additional time form elements generalized eigensystem routine mean flop count yielding total complexity flops 
matlab defines addition multiplication contribute flop golub van loan consider flop consist multiply accumulate 
matlab definition corresponds closely computer perform experiments multiplication addition require clock cycle 
british machine vision conference algorithm geom geometric distance geometric distance metric measures orthogonal distance point conic section 
metric proposed nakagawa rosenfeld approximately unbiased errors data points distributed normally curve 
distance evaluated point solving simultaneous equations rf defining ffi kx gamma pk equations involve solution quartic equation closed form solutions exist numerical instability result application analytic formula 
implementation extract roots eigensystem companion matrix 
turn means analytic derivatives ffi consequently ra ffl difficult calculate 
evaluation ffl involves solution averaging flops iteration eigenvalue calculation 
number iterations depends minimization algorithm chosen clear iterations geom orders magnitude slower previous algorithms extensively tested experiments 
algorithm bias statistical distance approach proposed kanatani improves lin algorithm explicitly calculating inherent statistical bias subtracting bias result minimization 
calculation bias depends knowing true minimum noise level process iterated predicted bias results noise level correction zero 
kanatani calls metric statistical distance argues bias sensitivity fact superior geometric distance case errors data points spherically distributed 
due pressure space discusses kanatani bias correction algorithm 
description algorithm long include due dependence tensor arithmetic 
note published noise level update formula eq replaced tr tr mq tr mq complexity algorithm order flops iteration test runs average iterations 
algorithm ac algebraic distance quadratic constraint ac algorithm ellipse specific imposing constraint xy gamma xx yy 
cleverly converts inequality xy gamma xx yy equality british machine vision conference high medium low visual depiction noise levels experiments 
high medium low levels correspond standard deviations pixels respectively 
incorporating normalisation factor 
corresponding generalized eigensystem nonnegative definite solved scheme 
ac requires flops lin form matrix 
matrix inversion eigensystem solution mean flop count 
experiments experiments conducted matlab system 
eigensystems solved underlying routines derivative free minimization needed geom algorithm nelder mead simplex algorithm 
execution speed characteristics interpreted matlab programs qualitatively different equivalent programs compiled language give timing statistics flop counts previous section 
noise model noise model applied experiments isotropic zero mean normally distributed 
models may considered particularly model variance perpendicular curve 
experiments illustrate degree occlusion curve noise parameter algorithms sensitive 
additionally noise model include outlier component 
described algorithms statistically robust 
algorithms may robust usual ways case outlier component added 
qualitatively important change results timing considerations prove unfavourable iterative algorithms outlier free case 
experiments performed typical noise levels depicted visually 
high medium low noise levels correspond roughly standard deviations pixels ellipse major diameter pixels 
british machine vision conference lin ams bias book ac noise standard deviation pixels th percentile center error log experiment center error vs noise level results experiment 
ac degrades smoothly wrt noise unoccluded data 
conic representation convenience defining experiments central conic parameters expressed vectors conic center radii respectively counterclockwise angle degrees ellipse positive axis 
experiments center position primary error measure 
performed experiments radius error measure qualitative difference results 
experiment noise experiment interested characterizing behaviour algorithms complete data respect noise 
experimental procedure follows 
ellipse sampled points uniformly distributed circumference 

noise sigma logarithmically varied gamma pixels 

sampled ellipse corrupted noise described runs distance true ellipse center center conic returned fitting algorithm recorded 
returned included 
shows th percentile error centers function noise level 
low noise levels oe algorithms seen perform similarly high levels ac algorithm degrades gracefully 
british machine vision conference algorithm ac algorithm book algorithm lin algorithm ams lin ams bias angle arc center experiment arc center error vs orientation results experiment 
highest errors center position occur curvature maxima lin maxima minima ams bias 
experiment orientation experiment investigate errors determining center ffi elliptical arc vary portion ellipse arc sampled rotates ellipse 
experiment may ensure subtended angle measurements taken pessimistic location ellipse 
experimental procedure follows 
counterclockwise orientation center arc varied ffi steps ffi 
ellipse sampled points uniformly distributed ffi arc 
sampled arc corrupted standard noise levels described 

distance true ellipse center center returned fitting algorithm recorded 
shows results ways 
top figures illustrate visually located circle positions algorithms ams lin book ac bottom graph shows error median center position function arc british machine vision conference experiment subtended angle experiment subtended angle mean principal points error experiment subtended angle lin ams bias book ac experiment subtended angle experiment subtended angle percentage non ellipses experiment subtended angle results experiment 
results low medium high noise left right 
upper curves show average sum errors principal points lower ones show proportion non ellipses produced conic algorithms 
orientation 
bias ams show greatest errors ffi points maximum errors lin occur arc sampled high curvature sections ffi ffi experiment occlusion third experiment designed locate breakdown point algorithms ellipse progressively occluded 
measure errors center position radius estimates arcs decreasing subtended angle 
experimental procedure follows 
angle subtended elliptical arc varied ffi steps ffi 
ellipse ffi sampled points uniformly distributed arc 
sampled arc corrupted standard noise levels described 

runs noisy arcs submitted fitting algorithm 
distances fitted principal points correspondents true ellipse calculated 
mean sum distance algorithms returned british machine vision conference lin conic ams conic ac linc experiment circle breakdown vs subtended angle results experiment 
specialized circle linc better breakdown characteristics corresponding general conic algorithms 
ellipses calculated percentage runs non ellipse conics returned 
shows plots principal point error percentage returned function decreasing subtended angle 
experiment circles final experiment consider breakdown performance general conic fitting algorithms specific particular task case circle fitting 
procedure similar experiment add new algorithms linc specializations lin ams respectively 
shows breakdown curves low noise case 
expected specialized linc break considerably general conic algorithms 
discussion discussed problem fitting conic sections ellipse data 
experiments illustrate key parameter affecting algorithms accuracy amount occlusion qualitative noise level 
complete data algorithms exhibit similar degradation presence increasing noise 
data progressively incomplete breakdown point reached algorithms fail 
breakdown point superior ac bias algorithms special case circle circle specific algorithms 
high noise bias superior accuracy produces non ellipses time highly occluded ellipses 
algorithm complexities increasing order book lin ac ams bias geom 
british machine vision conference current involves implementation testing algorithms alternative bias algorithm examining alternative error metrics conic invariants 
bookstein 
fitting conic sections scattered data 
computer graphics image processing 
forsyth mundy zisserman invariant descriptors object recognition pose 
ieee pami 

squares quadratic constraint 
numerische mathematik 
golub van loan 
matrix computations 
johns hopkins nd edition 
haralick shapiro 
computer robot vision volume 
addison wesley 
kanatani 
statistical bias conic fitting renormalization 
ieee pami 
mathworks natick ma usa 
matlab guide 
nakagawa rosenfeld 
note polygonal elliptical approximation mechanical parts 
pattern recognition 

fitting ellipses predicting confidence envelopes bias corrected kalman filter 
image vision computing february 
press numerical recipes 
cambridge university press nd edition 
rosin 
ellipse fitting accumulating point fits 
pattern recognition letters 
sampson 
fitting conic sections scattered data 
computer graphics image processing 
taubin 
estimation planar curves surfaces nonplanar space curves defined implicit equations applications edge range image segmentation 
ieee pami november 
torr 
robust vision 
proceedings bmvc 
