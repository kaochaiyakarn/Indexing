model selection criteria learning belief nets empirical comparison tim van allen cs ualberta ca russ greiner greiner cs ualberta ca department computing science university alberta edmonton alberta canada interested problem learning dependency structure belief net involves trade simplicity goodness training data 
describe results empirical comparison standard model selection criteria viz minimum description length criterion mdl akaike information criterion aic cross validation criterion applied problem 
results suggest aic cross validation criteria avoiding tting mdl context 

learning model data generating process random sample fundamental problem nding right balance complexity model goodness training data 
complex model usually achieve closer training data may model re ects just signi cant regularities data minor variations due random sampling give information underlying process 
true error model comes sources bias structure model prevents representing underlying process variance estimating parameters limited sample 
complex model structures bias parameters usually higher variances 
finding best model random sample requires nding balance competing objectives reducing bias model reducing variance sample question 
algorithms model learning generally divide components search algorithm nding best model class criterion comparing models 
handling bias variance trade primarily matter choosing criterion applied 
approach add complexity penalty training error complex models data considerably better smaller models order 
standard criteria minimum description length mdl rissanen akaike information criterion aic 
approach part sample set parameters rest sample get unbiased estimate true error 
approach called cross validation stone 
compare model selection criteria context learning belief nets de ned section 
goals carrying research 
rst nd criterion learning belief net structures 
second understand issues trade involved 
consequently prescriptive descriptive results 
hypothesized mdl ective cross validation aic fact case mdl criterion select model results drastically tting data cases 
endorse aic cross validation model selection criteria learning belief nets caution mdl 
descriptive results explain reasons mdl poor performance illustrate issues trade involved model selection 
outline follows 
rest section discusses previous research related topic 
section gives background information belief nets model selection criteria consideration 
section describes experimental design 
section presents results experiments case studies comprehensive tests establish claims 
section contains discussion results issues involved model selection 
responds possible criticisms research 
related considerable literature learning belief networks particular learning structure see heckerman detailed overview subject note researchers including lam bacchus suzuki friedman goldszmidt explicitly mdl criterion close evaluate candidate networks 
suggests problem mdl framework 
friedman yakhini carry analysis sample requirements various complexity penalty approaches belief net learning 
addresses suitability various selection criteria analysis theoretical asymptotic behaviour contrast empirically investigating small sample behaviour different class criteria 
provide overview general problem model selection covering aic cross validation mdl 
rissanen gives detailed development minimum description length principle information theoretic view induction mdl criterion 
provides easy read derivation aic discussion 
kearns describe experiment related covering similar range criteria applied problem function learning distribution learning 
study problematic behaviour mdl 

background notation capital letters denote random variables expressions denote probabilities 
expressions represent distributions represent set conditional distributions 
general unbound variables implicitly universally quanti ed domains equation means 
functions random variables random variables 
follows assume dealing learning network discrete variables fx xn sample size drawn distribution random variable ranging family models consideration true model 
note logs base 
belief networks belief network representation joint distribution set random variables fx xn consists parts dependency graph set conditional probability functions 
dependency graph directed acyclic graph vertices random variables 
variable assumed conditionally independent variables parents children graph 
joint probability distribution variables pseudo equation xn pa pa vector parents 
restrict attention case conditional probability functions unrestricted complete table listing joint assignments pa number parameters required represent function exponential number parents 
model selection negative log likelihood standard measure training error 
dl log sample hypothesis denote dl description length encoded optimal code distribution sequence instances xm dl log kl divergence kullback leibler standard measure error distribution learning 
true model hypothesized model kl divergence kld log ranges possible assignments measures expected cost encoding instances code 
note written kld dl dl expectations taken 
second term entropy 
depend rst term sucient compare models 
form estimate rst term info dl problem course estimate parameters depends info biased estimator tending favour complex models 
general complex tuned worse bias estimate 
note di erent kinds bias involved networks complex representationally biased represent larger class distributions parameters higher variance sampling training error biased estimator true error 
solution problem partition subsamples training sample validation sample 
training sample parameters validation sample estimate discrepancy 
removes bias estimate dl increases variance dl criterion 
way seemingly avoid increase variance partition subsamples repeat training process times time reserving subsample validation afterward combining estimates 
logical extreme divide sample subsamples datum 
family methods goes generic name cross validation respectively called simple fold leave crossvalidation stone 
experiments simple version dividing sample equal size subsamples training validation 
xv info split disjoint halves hypothesis instantiated instances note nal parameters chosen model estimated full data set model selection need data parameter estimation process 
approach add complexity penalty goodness term counteract bias introduced tting data 
penalty may function sample size number parameters model 
sample size depend data 
problem approach penalty function principle remove bias estimate bias estimate depends parameters true model 
complexity penalty way depends true distribution exactly counteract bias introduces bias 
known penalty functions motivated di erent theoretical considerations appropriate particular class learning problems 
minimum description length mdl criterion information theoretic view induction data compression see rissanen detailed development 
equivalent bayesian information criterion introduced originally schwarz bayesian interpretation 
information theoretic interpretation mdl criterion length encoding sample part code 
basic idea model de ne code sample encode sample rst encoding model encoding data code model 
model captures signi cant features data encoding considerably smaller simply sending sample hand model represents sample encoding size increase 
trade similar bias variance trade 
version di ers standard form normalized compare sample sizes criteria 
low order terms positive dropped seen negative impact criterion 
mdl criterion mdl info log number parameters akaike information criterion aic comes di erent theoretical perspective 
explicit attempt correct tting bias 
see derivation criterion 
complexity penalty considerably smaller mdl 
version aic aic info log base natural logarithm log simply conversion nats bits 

experimental design wanted observe behaviour criteria varying training sample size true distribution 
space network structures huge modest number variables systematic exploration space unrealistic goal 
focussed trajectories space particular trajectories simplest complex structure pass true structure 
short repeated experiments form 
generate edges vertices 

randomly order edges 

pick number edges true model 

true structure rst edges randomized list 

generate random probabilities parameters true model 

generate samples various sizes true model 

construct hypothesis structure rst edges randomized list 
refer edge structure 
hypothesis structure criteria evaluate criteria generated samples parameters 
generated parameters true model di erent distributions generally uniform distribution 
experimented di erent values suf ciently large number give interesting results larger numbers variables results simply scaled changing qualitatively 
binary valued variables qualitative impact results computation analysis easier 
describe results section follows 

results experimental apparatus described previous section observe behaviour criterion spectrum complexities range sample sizes 
observed followed remarkably consistent pattern suggests caution applying mdl principle 
figures snapshots taken di erent sample sizes results particular true model 
graphs show criteria compared hypothesis complexity truth complexity sample size mdl aic xv err 
case study 
hypothesis complexity truth complexity sample size mdl aic xv err 
case study 
hypothesis complexity truth complexity sample size mdl aic xv err 
case study 
complexity spectrum marked number dependencies number parameters evaluated samples size 
values plotted hypothesis structure err true error kl divergence network parameters estimated sample mdl mdl criterion aic aic criterion xv cross validation criterion 
scale true entropy distribution subtracted criterion 
true model edges 
set hypotheses ideal learner criteria pick hypothesis lowest value 
graph mdl learner pick edge structure aic learner select cross validation pick wrong recall true structure note structure returned mdl worst kl divergence answer returned aic may kl divergence answer xv 
mdl clearly doing poorly 
mdl picks kl aic picks kl cross validation picks kl correctly pick cases see cross validation nds structure close optimal mdl small samples 
general criterion suited optimizing function general shape function particular local global minima 
graphs show xv aic acquire relevant properties err function smaller samples mdl 
observed threshold pattern small increase sample size large di erence optimality mdl preferred structure 
observing critical quantity data mdl typically prefer sub optimal models models small reaching size returns optimal model 
mdl high bias simplicity bias dominates behaviour smaller samples actual data relatively little impact 
note data sucient nd model xv aic models 
shows complexity penalties mdl log aic log plotted actual amount tting measured dl info sample size truth figures 
hypothesis complexity truth complexity sample size mdl penalty aic penalty fitting bias 
case study penalties vs 
hypothesis complexity truth complexity sample size mdl aic xv err 
case study lower entropy truth 
see aic reasonably job matching tting network complexity gets high 
mdl penalty larger amount tting 
snapshot experiment di erent truth true structure changed parameters high low 
generation scheme tended produce lower entropy distributions potential data compression 
see pattern albeit smaller sample size shown 
mdl just overcome bias crossvalidation aic prefer ideal structure 
note cross validation great job predicting true error model consistently overestimates job predicting relative error models sucient model selection 
sample size truth complexity dependencies mdl aic xv exp 
comprehensive study empirical convergence rates 
shows empirical convergence rates truths dependencies parameters drawn uniform distribution 
point represents average experiments experiment involved generating new truth 
axis represents di erence kl divergence best scoring model criterion model lowest true error 
values go zero criterion converging ideal structure 
note curve created plotting averages smooth exponential curve best shown mdl actual behaviour criteria particular truth smooth convergence 
cases mdl tends shift immediately preferring high error networks preferring ideal structure seen figures 
table summarizes results comprehensive study 
size truth combination carried experiments type described uniform distribution generate true parameters 
experiment criterion took network scored best subtracted error lowest error attained network 
summarize values obtained giving mean median 
note manipulated number dependencies number parameters directly considerable amount variance values 
number parameters depends graph structure just number dependencies tends increase exponentially number dependencies increases 
fact sorting networks buckets number parameters little reduce variance parameter values large ect relative dif culty learning distribution 
large font indicate winners cell differences important distinguishing best 
mdl won low left example methods quite attaining low error mdl poorly high right poorly relative criteria 
real world reviewers suggested complementing random experiments real world problems 
carried additional experiments alarm insurance networks commonly belief net studies 
alarm insurance networks sparse alarm network variables links insurance network variables 
observed networks essentially mirrored results random distributions 
network generated samples size 
computed criteria consideration range network structures including networks edges subset true network networks created adding edges true network 
large sample spaces distributions exactly compute true entropy kl divergences large sample data empirical approximation 
cell table summarizes results experiments kind 
computed scores network spectrum complexity doing computed kl divergence network true model 
best scoring network criterion determined di erence lowest kl divergence obtained network tested true network structure 
determined minimum median maximum di erences criteria experiments 
observed random experiments mdl score lead signi cant tting model selection criterion aic considerably better slightly ective cross validation small sample sizes 

discussion empirical results show optimizing mdl criterion risky strategy learning belief net structures 
mdl suciently large samples arbitrarily worse slightly smaller samples table 
comprehensive study 
mdl aic xv mdl aic xv mdl aic xv mdl aic xv table 
results insurance criterion min median max mdl aic xv mdl aic xv mdl aic xv table 
results alarm criterion min median max mdl aic xv mdl aic xv mdl aic xv guarantee graceful degradation 
furthermore way know priori mdl su cient data ective 
contrast crossvalidation safe bet bad 
table shows cross validation average error exceeded aic performance inbetween closer cross validation terms risk 
known complexity penalty bias better learning problems expense 
course learner available prior knowledge supports complexity penalty aic mdl criterion 
hand cases prior knowledge cross validation minimizes worst case loss sacri cing terms average performance 
table shows minimax criteria 
consistent crossvalidation name jackknife jack trades master 
address possible criticisms ndings 
argue mdl criterion intended optimize true error simply implement mdl principle 
crossvalidation prefers complex network lower true error argue justi ed doing 
mdl optimize description length aware may obtain bad generalization error 
related argument truth tends simple strong prior beliefs bias model selection algorithms favour simplicity 
prior expectation simplicity incorporated training error term bayesian prior 
may re ected search strategy representational choice 
need part mechanism handle tting 
third possible mdl criteria chose wrong task learning belief nets 
example mdl criterion implicitly assumes parameters vary independently case 
note aic criterion assumption performed fairly 
natural parameterization learning domains exhibits parameter dependencies means rigorous application asymptotic criteria creates technical diculties 
cross validation problem 
note results corroborate results kearns 
considering di erent domain 
fourth argued natural realworld problems special structure results random experiments little value 
true primarily prescriptive results complemented descriptive results 
attempted show mdl criterion may lead tting large simplicity bias overwhelms goodness small samples risky strategy exhibits phase transition behaviour 
experiments real world data sets con rmed random experiments importantly carried exploratory analyses large number problem types seeking falsifying evidence 
ways extend research particular examining interactions di erent encoding schemes friedman goldszmidt search strategies model selection 
interest compare methods greedy algorithms hypothesis testing methods 
information including complete description data results see www cs ualberta ca models html 

carried empirical study compare criteria selecting belief network structures mdl aic cross validation 
cross validation ective criterion wide range sample sizes broad spectrum truth complexities terms number parameters parameter values 
aic ective somewhat smaller range truth complexities 
mdl contrast required larger sample sizes reach level performance crossvalidation aic 
experience learning belief net structures prior knowledge advise cross validation prior expectation simplicity advise aic advise mdl 
authors gratefully acknowledge support nserc 

model selection akaike information criterion aic general theory analytical extensions 
psychometrika 
cooper herskovits 
bayesian method induction probabilistic networks data 
machine learning 
friedman goldszmidt 
learning bayesian networks local structure 
uai 
friedman yakhini 

sample complexity learning bayesian networks 
uai 
heckerman 

tutorial learning bayesian networks technical report msr tr 
microsoft research 
kearns mansour ng ron 
experimental theoretical comparison model selection methods 
appear machine learning 
kullback leibler 
information suciency 
annals mathematical statistics 
lam bacchus 

learning bayesian belief networks approach mdl principle 
computational intelligence 

model selection 
new york john wiley sons 
rissanen 

stochastic complexity statistical inquiry 
singapore world scienti schwarz 

estimating dimension model 
annals statistics 
stone 

cross choice assessment statistical predictions 
royal statistical series 
suzuki 

learning bayesian belief networks minimum description length principle ecient algorithm branch bound technique 
machine learning 
