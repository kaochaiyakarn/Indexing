statistical parsing automatically extracted tree adjoining grammar david chiang department computer information science university pennsylvania rd st philadelphia pa linc cis upenn edu discuss advantages lexicalized tree adjoining grammar alternative lexicalized pcfg statistical parsing describing induction probabilistic ltag model penn treebank evaluating parsing performance 
nd induction method improvement em method hwa induced model yields results comparable lexicalized pcfg 
tree adjoining grammar statistical parsing 
statistical natural language processing concerned probable possible tag describe constructions arbitrarily large dutch verb clusters 
tag useful statistical parsing structural descriptions assigns butter sentences 
approach chelba jelinek language modeling illustrative probability estimate appearing kth word conditioned entire history quantity available training data limits usable context words 
trigram model chooses works quite model chose probably 
chelba jelinek chooses lexical heads previous constituents determined shift reduce parser works better trigram model 
virtual grammar serves structure history useful words cho sen structure problem entirely linear 
similarly parsing problem requires construct structure phrase structure 
magerman statistical parsers bilexical dependencies great success 
dependencies encoded plain phrase structure trees standard approach lexical heads percolate tree lexical head immediately dominated understood dependent 
ectively dependency structure parasitic phrase structure generated context free model 
solution ideal 
aside cases context free derivations incapable encoding constituency dependency somewhat isolated great interest statistical parsing common cases percolation single heads su cient encode dependencies correctly example relative clause attachment raising auxiliary verbs see section 
complicated grammar transformations necessary 
suitable approach employ grammar formalism produces structural descriptions encode constituency dependency 
lexicalized tag formalism assigns sentence parse tree built elementary trees interpreted encoding constituency derivation tree records various elementary trees combined commonly encoding dependency 
ability probabilistic ltag np nnp john md np vp vp vp vb leave np nn tomorrow np nnp john md vp vb leave grammar derivation john leave tomorrow model bilexical dependencies noted early resnik 
turns pieces contextual information need explicitly accounted cfg grammar transformations come free tag 
discuss cases section 
sections describe experiment test parsing accuracy probabilistic tag extracted automatically penn treebank 
nd automatically extracted grammar gives improvement em induction method hwa parser performs comparably lexicalized pcfg parsers certainly room improvement 
emphasize tag attractive things cfg cfg cleanly 
analogy chelba jelinek breaks 
certain possibilities apparent pcfg framework prohibitively complicated simple implement framework conclude ering possibilities 
formalism formalism variant lexicalized tree insertion grammar turn restriction ltag schabes vp np nn tomorrow waters 
variant kinds elementary tree initial predicative auxiliary modi er composition operations substitution adjunction sister adjunction 
auxiliary trees adjunction restricted tig essentially wrapping adjunction equivalent wrapping adjunction allowed 
sister adjunction operation standard de nitions tag borrowed tree grammar rambow 
root modi er tree added new daughter node 
note stands sister adjunction completely unconstrained constrained probability model 
introduce operation simply derive structures penn treebank 
schabes shieber multiple modi er trees sister adjoined single site auxiliary tree may adjoined single node 
shows example grammar derivation sentence john leave tomorrow 
derivation tree encodes process arc corresponding composition operation 
arcs corresponding substitution adjunction labeled address substitution ad address list integers root tree address jth child node junction site 
arc corresponding sister adjunction tree ith th children allowing imaginary children leftmost rightmost children labeled grammar grammar parser lexicalized sense elementary tree exactly terminal node lexical anchor 
sister adjunction simulated ordinary adjunction variant tig cfg weakly context free time parsable 
coin new acronym particular variant simply refer tag trust confusion arise 
parameters probabilistic tag resnik schabes pi ps pa ranges initial trees auxiliary trees modi er trees nodes 
probability derivation probability substituting probability adjoining nally probability adjoining 
carroll weir suggest parameterizations worth exploring 
variant adds set parameters psa sa probability sister adjoining ith th children allowing imaginary children leftmost rightmost children 
multiple modi er trees adjoin location sa conditioned ag indicates rst modi er tree closest head adjoin location 
probability derivation expressed product probabilities address address individual operations derivation 
probability example derivation sa true sa false sa true node address want obtain maximum likelihood estimate parameters estimate directly treebank sample space space tag derivations derived trees treebank 
approach taken hwa choose grammar general parse corpus obtain maximum likelihood estimate em 
approach taken magerman lexicalized pcfgs neumann xia chen vijay shanker heuristics reconstruct derivations directly estimate parameters reconstructed derivations 
take approach 
imagine combining approaches heuristics extract grammar em estimate parameters 
properties probabilistic tag lexicalized tag composition brings lexical items composition probability involves bilexical dependency 
cfg scheme equivalent tag constructed derivations mirror dependency analysis implicit scheme 
furthermore dependency analyses encodable tags encodable simple head percolation scheme 
example sentence john left magerman rules heads respective vps dependency left subject john see 
nearly quarter nonempty subjects appear con guration small problem 
left john left john bilexical dependencies john left 
vp head vp generate auxiliaries independently example john leave 
tag produce desired dependencies easily grammar 
complex lexicalization scheme cfg kept track heads time example tag account simpler cleaner 
bilexical dependencies nonlocal dependencies improve parsing accuracy 
example attachment depends presence absence embedded subject collins treebank style level nps pcfg collins johnson generation node depends label grandparent charniak johnson 
order capture dependencies pcfg model localized transforming data modifying parser 
changes obvious priori devised anew language corpus 
cases really requires special treatment model composition probability involves bilexical dependency tree tree dependency 
generates entire elementary tree conditioned entire elementary tree modi ed 
dependencies stipulated pcfg tree transformations parser modi cations captured free model 
course price model pays sparser data backo model chosen carefully 
inducing stochastic grammar treebank reconstructing derivations want extract penn treebank ltag derivations mirror dependency analysis implicit head percolation rules magerman collins 
node rules classify exactly child head rest arguments adjuncts 
classi cation construct tag derivation including elementary trees derived tree follows 
adjunct subtree rooted form modi er tree 

argument subtree rooted form initial tree leaving substitution node 

right corner argument label intervening nodes heads segment form auxiliary tree 
rules produce desired result rule changes analysis somewhat making subtrees recursive arguments predicative auxiliary trees 
produces things analysis auxiliary verbs described previous section 
applied greedy fashion potential considered top potential bottomup 
complicated restrictions simply ensure formed tig derivation produced 
parameter estimation smoothing augmented training data include tag derivations try directly estimate parameters model section 
number tree site pairs high data sparse 
generate elementary tree steps rst tree template elementary tree minus pp np np nns modi er trees auxiliary trees jj advp np np nns rb np vp vbd np initial trees np vp vbd vp vp vp vb np vp md vp frequently occurring tree templates 
marks lexical anchor inserted 
anchor anchor 
probabilities decomposed follows pi pi pi ps ps pa pa ps pa psa psa psa tree template part speech tag anchor anchor 
generation tree template backo levels rst level anchor ignored second level pos tag anchor ag ignored 
generation anchor backo levels rst third just conditions anchor pos tag 
backed models combined linear interpolation weights chosen bikel 
experiment extracting grammar ran algorithm section sections penn treebank 
extracted grammar large trees words seen fewer times replaced symbol unknown frequency rank frequency tree templates versus rank log log consider elementary tree templates grammar quite manageable tree templates occur see 
frequent tree template types account tree template tokens training data 
removing trees grammar increased error rate testing subset section 
frequent tree templates shown 
extracted grammar fairly compact complete 
plot growth grammar training clear grammar converge idea types tokens growth grammar training log log grammar requires 
possible explanations new constructions continue appear 
old constructions continue erroneously annotated new ways 
old constructions continue combined new ways extraction heuristics fail factor variation 
random sample seen elementary tree templates casual inspection resulted annotation errors de ciencies heuristics apparently performance errors 
twelve appeared genuine 
continued growth grammar rapid indicate 
extraction heuristics evidently room improve 
majority trees resulting de ciencies heuristics involved complicated coordination structures surprising coordination problematic tag 
see impact failure converge ran grammar extractor held data section 
tree tokens tree templates seen training 
amounts unseen tree template sentences 
consider lexicalized trees gure course rises tree tokens lexicalized trees seen training 
coverage grammar quite 
note cases parser encounters sentence fallible extraction heuristics produced unseen tree template possible parser trees produce correct bracketing 
parsing grammar cky style parser similar described schabes waters modi cation ensure completeness foot nodes treated empty cky prohibits reduce useless substitutions 
extended parser simulate sister adjunction regular adjunction compute ag distinguishes rst modi er subsequent modi ers 
beam search computing score item multiplying prior probability goodman item score times best item cell pruned 
collins words occurring fewer times training replaced symbol unknown tagged output part speech tagger described ratnaparkhi 
tree templates occurring training ignored entirely 
rst compared parser hwa trained model sentences length sections penn treebank parts speech tested sentences length section parsing part speech tag sequences fully bracketed parses 
metric percentage guessed brackets cross correct brackets 
parser scored compared hwa error reduction 
compared parser lexicalized pcfg parsers training sections testing section 
results shown 
results place parser roughly middle lexicalized pcfg parsers 
results state art demonstrate viability tag framework statistical parsing 
words words lr lp cb cb cb lr lp cb cb cb magerman collins model collins charniak parsing results 
lr labeled recall lp labeled precision cb average crossing brackets cb crossing brackets cb fewer crossing brackets 
gures cb percentages 
improvements smoothing cleaner handling punctuation coordination results brought upto date 
related neumann describes experiment similar grammar extracts arrives complete parse unseen sentences 
xia describes grammar extraction process similar describes techniques automatically ltering invalid elementary trees 
great deal common independent chen vijay shanker 
detailed discussion various grammar extraction processes performance supertagging models srinivas extracted grammars 
report parsing results intention evaluate various grammars ect parsing accuracy best supertagging parsing speed 
srinivas supertags srinivas uses tag statistical parsing di erent strategy tree templates thought extended parts ofspeech assigned words local gram context 
possibilities available tag remain explored 
suggested chen vijay shanker group elementary trees families relate trees family transformations 
example imagine distribution active verbs subjects similar distribution passive verbs notional subjects treated independent current model 
related sparseness verb argument dependencies reduced 
possibility trees 
requires elementary trees single anchor anchor trees example attachment pp dependent preposition current model lexical head prepositional object attachment relative clause dependent embedded verb relative pronoun 
smoothing method described modi ed account multiple anchors 
summary wehave argued tag provides cleaner way looking statistical parsing lexicalized pcfg demonstrated practice performs range 
greater exibility tag suggests potential improvements cumbersome implement lexicalized cfg 
research show advantages turn signi cant practice 
research supported part aro daag nsf sbr 
mike collins aravind joshi anonymous reviewers valuable help 
srinivas 

complexity lexical descriptions relevance parsing 
ph thesis univ pennsylvania 
daniel bikel scott miller richard schwartz ralph weischedel 

nymble highperformance learning name nder 
proceedings fifth conference applied natural language processing anlp pages 
john carroll david weir 

encoding frequency information lexicalized grammars 
proceedings fifth international workshop parsing technologies iwpt pages 
eugene charniak 

maximum parser 
proceedings meeting north american chapter association computational linguistics anlp naacl pages 
chelba frederick jelinek 

exploiting syntactic structure language modeling 
proceedings coling acl pages 
john chen vijay shanker 

automated extraction tags penn treebank 
proceedings sixth international workshop parsing technologies iwpt pages 
michael collins 

new statistical parser bigram lexical dependencies 
proceedings th annual meeting computational linguistics pages 
michael collins 

generative lexicalised models statistical parsing 
proceedings th annual meeting computational linguistics pages 
michael collins 

head driven statistical models natural language parsing 
ph thesis univ pennsylvania 
joshua goodman 

global thresholding multiple pass parsing 
proceedings second conference empirical methods natural language processing emnlp pages 
rebecca hwa 

empirical evaluation probabilistic lexicalized tree insertion grammars 
proceedings coling acl pages 
mark johnson 

pcfg models linguistic tree representations 
computational linguistics 
david magerman 

statistical models parsing 
proceedings rd annual meeting computational linguistics pages 
gunter neumann 

automatic extraction stochastic lexicalized tree grammars treebanks 
proceedings th international workshop tag related formalisms tag pages 
owen rambow vijay shanker david weir 

tree grammars 
proceedings rd annual meeting computational linguistics pages 
adwait ratnaparkhi 

maximum entropy model part speech tagging 
proceedings conference empirical methods natural language processing pages 
philip resnik 

probabilistic tree adjoining grammar framework statistical natural language processing 
proceedings fourteenth international conference computational linguistics coling pages 
yves schabes stuart shieber 

alternative conception tree adjoining derivation 
computational linguistics 
yves schabes richard waters 

tree insertion grammar cubic time parsable formalism context free grammar changing trees produced 
computational linguistics 
yves schabes richard waters 

stochastic lexicalized tree insertion grammar 
bunt tomita editors advances parsing technology pages 
kluwer academic press london 
yves schabes 

stochastic lexicalized grammars 
proceedings fourteenth international conference computational linguistics coling pages 
fei xia 

extracting tree adjoining grammars bracketed corpora 
proceedings th natural language processing paci rim symposium pages 
