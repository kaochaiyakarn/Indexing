probabilistic information retrieval model dependency structured indexing system lee gary lee department computer science engineering university science technology san dong nam gu korea phone fax ac kr previous information retrieval ir models assume terms queries documents statistically independent 
independence assumption obviously openly understood wrong new method incorporating term dependence probabilistic retrieval model adapting structural index system dependency parse tree chow expansion compensate weakness assumption 
describe theoretic process apply chow expansion general probabilistic models state art poisson model re examine weight phrase terms 
experiments document collections etri korean demonstrate incorporation term dependences chow expansion contribute improvement performance probabilistic ir systems 
keywords term dependence phrasal indexing chow expansion probabilistic model poisson model 
previous information retrieval ir models assume terms queries documents statistically independent 
independence assumption obviously openly understood wrong ir models assumption developed assumption leads formal representation model easily ir systems practically worked assumption 
researchers tried remove independent assumption incorporated various term dependence models diverse techniques 
higher order model term dependence easily reached formal representation model fact greatest merit term independence maintained face extreme difficulties inducing probabilities model 
clarified incorporation term dependence model improved performance 
approaches traditionally regarded tool increasing precision relaxing independent assumption phrases indexing retrieval documents 
phrases useful indexing unit leading groups participating nist darpa sponsored text retrieval conferences performance evaluations ir systems 
propose new method incorporating term dependence probabilistic retrieval model adapting structural index system dependency parse tree chow expansion originally pattern recognition field 
focused different aspects describe theoretic process applying chow expansion original probabilistic model state art poisson model re examine weight phrase terms 
second try empirically verify statistically significant improvement performance proposed models practical korean ir system 
experiments conducted standard document collection korean etri 
organized follows 
section discuss previous researches diverse techniques incorporate term dependences different retrieval models compare research 
section describe chow expansion theory dependency parse tree section describe adaptation theory probabilistic ir models poisson models particularly okapi bm 
section illustrate retrieval procedure model describe comprehensive experiment results analyses 
section draw plans works 

previous researches robertson sparck jones originally proposed probabilistic retrieval model distribution query terms relevant non relevant documents eq 
robertson walker formula combining prior weights pure evidence estimates 
estimated formula approximates inverse document frequency idf relevant information 
pr rel pr rel pr rel log log log pr rel pr rel pr rel document description rel designates relevance set 
probabilistic retrieval model poisson model proposed bookstein swanson assumes content word plays different roles documents 
documents low average number word occurrences occurrences accidental index terms 
hand documents high average number word occurrences word central content word index term 
robertson walker ir model approximating poisson model known okapi bm series integrate document term frequency document length query term frequency 
models widely ir important assumption linked dependence assumption pr rel pr rel pr rel pr rel pr rel pr rel regarded properties documents rel designates relevance set 
linked dependence assumption considerably weaker binary independence assumption cases ir systems formula linked dependence shown relatively experimental results 
unrealistic assumption researches tried address limitations linked dependence assumption computing term dependences diverse techniques basis different retrieval models 
raghavan showed retrieval functions dot products cosine vector space model weighted retrieval incompatible term independence query space 
proved term independence query space turned undesirable 
croft proposed approach integrate boolean statistical systems boolean queries interpreted way specifying term dependencies relevant set documents 
lewis algorithm generate dependent term groups developed representations 
showed performance improvements gained re ranking top documents dependent term groups 
losee proposed probabilistic model integrating boolean query cnf conjunctive normal form dependences exist disjunctions terms 
probabilistic models incorporating term dependences maximum entropy techniques proposed 
models require high cost computing parameter estimation performed real time 
previously losee incorporated term dependence information estimating pr rel bahadur expansion ble documents ranked expected precision ep documents follows pr rel pr rel pr rel pr vector document rel relevant set 
losee performed experiments cystic fibrosis cf spanning degree terms showed best performance obtained degree window terms 
experiment estimated parameters probabilities correlations appropriate relevance class retrospective technique 
retrieval process parameters estimated full knowledge characteristics relevant non relevant documents 
general know relevant non relevant documents fully real situations 
relatively small sized test collection experiments sufficient verify technique effective practical situations 
losee proposed expected mutual information measure emim superior inverse document frequency idf weighting function 
fact measures similar theoretical ground luhn zipf model meaningful empirical experiment results 
van rijsbergen explored way removing independence assumption 
constructed probabilistic model incorporating dependences index terms 
extent index terms depend derived distribution occurrences collection relevant non relevant document sets construct non linear weighting function 
practical situation values parameters function estimated small samples documents 
number estimating rules discussed particular recommended 
turtle described new formal retrieval model uses probabilistic inference networks represent documents information needs 
retrieval viewed evidential reasoning process multiple sources evidence document query content combined estimate probability document matches query 
model generalizes current retrieval models provides framework disparate information retrieval research results integrated 
chief advantage model allows complex dependencies represented easily understood form allows networks containing dependencies evaluated development closed form expression 
model limited term dependence information phrase thesaurus information extended incorporate additional dependencies term clustering 
works done trec programme phrases passages seen seeking capture dependencies informal means may motivations 
limiting candidate query expansion terms occurring passage neighborhoods matching terms seen way concentrating occurrence information discriminating occurrence information computed extended full texts 

chow expansion theory dependency parse tree components vector dn binary values problem estimating density problem estimating probability pr 
possible vectors estimate probabilities enormous task 
components statistically independent problem greatly simplified 
case write pr pr di pi pr di pi pr di 
natural ask compromise positions completely accurate requires estimating probabilities forced assume statistical independence reduce problem estimating probabilities 
answer provided finding expansion pr approximating pr partial sum rademacher walsh expansion bahadur expansion 
interesting class approximation joint probability distribution pr identity pr pr pr pr pr mpr 
suppose variables independent number variables pr di di solely dependent preceding variable dj 
obtain product expansion pr pr pr pr mpr substituting di dj verify pr di pi pr di dj pi pr di dj 
letting pi pr di substituting eq 
eq 
logarithm collecting terms obtain chow expansion 
log pr log di log pi log pi 
log pi pi similar results higher order dependence obtained obvious way 
chow liu suggest construction tree mutual information variable variable immediately maximized 
points tree ith point directly immediately jth point maximum spanning tree mst may defined maximizing sum node node represents expected mutual information provided pr pr log pr pr syntactical phrases obtain phrases linguistic information retrieval 
dependency parse tree represents term dependence relations syntactic structure apply dependency parse tree generated linguistic dependency parser chow expansion mutual information mst 
dependency relationship asymmetric binary relationship word called head governor parent word called modifier dependent daughter 
dependency grammars represent sentence structures set dependency relationships 
normally dependency relationships tree connect words sentence 
word sentence may modifiers word may modify word 
root dependency tree modify word 
called head sentence 
example dependency structure sentence 
head sentence 
pairs dependency relationships depicted arcs heads modifiers 

dependency structure sentence developed simple dependency parser korean apply dependency parse trees chow expansion 
dependency parser uses heuristics generally dependency parsing non crossing condition constraint surface information nearest principle 
dependency parser shows precision 
adapting probabilistic ir model propose method incorporating term dependence probabilistic models particular poisson models chow expansion structural indexing system 
chow liu suggest construction mst mutual information dependence tree originally chow expansion 
suggest dependency parse tree generated linguistic dependency parser mutual information mst dependency parse tree intuitively linguistically represents term dependence relations syntactic structure 
consider phrases way relaxing independence assumption terms 
structural indexing system consists dependency parse tree chow expansion relax independence assumption 

adapting chow expansion pr rel pr rel eq 
transformed adapting chow expansion eq 
follows log pr rel log pr rel pi log qi log pi log qi log pi pi log constant pi qi qi log constant rel pr rel rel qi pi pr pr rel pi qi pr equations note variables independent pi pi sums expansion disappear leaving familiar expansion independent case 
dependence exists obtain additional linear quadratic terms 
equations adapt chow expansion probabilistic ir model follows percentage dependency relationships output dependency parser answer follows pr rel log log pr rel log pr rel pr rel pi qi log qi pi pi qi log pi log pi qi log qi log constant rel pr rel pr rel eq 
transformed pr di pr rel log pr rel pi qi log pi qi log qi pi log pi log pi log log constant rel pr rel rel qi pi pr pi qi pr pr rel pi regarded probability phrase consists term term relevant qi counter part probability non relevant document 
define chow query document scoring function adapts chow expansion probabilistic model follows ms prob chow di log qi pi log log pi qi log log log qi pi qi pi model consists linear quadratic terms 
pi pi pj term term statistically independent model independence model consists linear terms 
model similar models weight phrases single term weight ignore second sum dj eq 

model efficient prevent problem scored phrase weight model subtracts weight single terms weight phrases 
overcome known anomaly document containing phrase scored highly system uses weighting function phrase single term 

relevance information probabilistic retrieval model relevant information available generally assume assume approximation ni rel qi pr pr size number documents collection ni number documents term occurs 
assume pi qi especially pi qi 
write coefficient di eq 
follows pi qi log log log qi pi qi original spark jones inverse collection frequency weight 
furthermore assume pi qi approximate coefficients dj eq 
respectively follows log pi log qi log qi log unknown constant parameter 
approximate coefficient eq 
follows log pi log log log qi log log log log qi qi unknown constant parameter 
assumption approximation adapt chow expansion probabilistic retrieval model relevance information follows pr rel qi log di log log pr rel log constant define chow query document scoring function adapts chow expansion probabilistic retrieval model relevance information follows ms prob chow log qi constant parameters 
log qi eq 
define weight ce term follows ce di log ni di log ni log 
extending poisson model qi log log qi method extended incorporate term dependence state art poisson model particular okapi bm chow expansion :10.1.1.32.9922
weight term poisson model represented eq 
tf log tf tf frequency term poisson means tf elite non elite sets respectively elite document rel probability non relevant document 
normally smaller tf give asymptotic maximum tf goes zero 
safely remove components small approximation log estimate directly alternative ce eq 

results eq 
transformed simple formulation bm 
tf ce qtf dl tf avdl qtf query term frequency tf frequency term dl document length avdl average length documents constant parameters 
define chow query document scoring function adapts chow expansion poisson model relevance information follows chow tf qi log log log dl qi tf avdl constant parameters 
model reflect term frequency phrasal term consisted term 
change model follows ms bm chow tf di log dl tf avdl qi tfi dl tf avdl iq log qi log tfi frequency term tfi frequency term constant parameters 
define model separates phrase terms single terms follows ms bm chow log dl tf 
experiments performance evaluation tf avdl tf qi log dl tf qi avdl tf log dl tf qi section empirically demonstrate poisson model incorporating chow expansion dependency parse tree term dependences eq 
gives significantly better performance poisson model conventional linked dependence assumption 
test collection evaluated poisson model incorporating chow expansion term dependences etri test collection korean encyclopedia published 
published volumes pages volume 
text data contains entries size mega bytes 
content entry describes concept entries fundamental words 
test set contains natural language queries relevance information entry lists related query 
average document length test set words 
average number relevant documents test set 
experiments results goal experiments validate proposed model 
took etri queries originally written retrieved top ranked documents 
shows example structural indexing system 
dependency structure analysis documents extract single terms phrase terms indexing 
retrieving keyword extraction query performed manner indexing process 
avdl 
structural indexing system followings brief descriptions methods tested compared 
bm okapi bm model 
bm chow proposed method eq 
chow expansion dependency parse trees 
performance assessed trec eval standard evaluation program smart project 
performance measures result table average precision non interpolated relevant documents avgp precision documents respectively precision 
results experiments cases listed table 
cases avgp bm bm chow table 
etri test collection proposed method achieved improvement bm average precision 
result modestly encouraging 
experiments conducted models chapter eq 


new method incorporating term dependences probabilistic retrieval model compensate weakness linked dependence assumption 
new weight function dependency phrase terms chow expansion dependency parse tree applied bm function widely poisson model term dependence generation 
occurrence terms obtained dependency parse tree 
carried experiments verity proposed models 
experiments performed etri test collection korean observations practicality usefulness 
results improvement performance obtained document collections incorporating term dependences chow expansion dependency structural indexing system 
conclude incorporating term dependences chow expansion structural indexing system poisson model viable appropriate technique overcome weakness linked dependence assumption model 
greatest disadvantage chow expansion retrieval cost dependence tree high dependence tree user query obtained dependency parser search time occurrence information terms obtained dependency parser indexing time 
reduce cost fast robust dependency parser need developed 
project apply chow expansion auto relevance feedback arf 
researches query expansions arf verified significant performance improvement 
known chow expansion techniques arf expanded queries question interest point chow expansion term dependency model 
van rijsbergen 
theoretical basis occurrence data information retrieval 
journal documentation 
clement yu chris buckley lam gerard salton 
generalized term dependence model information retrieval 
information technology research development 
croft harper probabilistic models document retrieval relevance information 
journal documentation 
luhn automatic creation literature abstracts 
ibm journal research development 

paul kantor 
maximum entropy optimal design automated information retrieval systems 
information technology research developments 
peter vijay raghavan 
necessity term dependence query space weighted retrieval 
journal american society information science 
spark jones walker robertson 
probabilistic model information retrieval development status 
technical report university cambridge computer laboratory 
robert losee abraham bookstein 
integrating boolean queries conjunctive normal form probabilistic retrieval models 
information processing 
turtle croft 
inference networks document retrieval 
intern 
conf 
research development information retrieval pages sigir 
losee 
term dependence truncating bahadur expansion 
information processing 
losee 
term dependence basis luhn zipf models 
journal american society information science technology 
robertson walker jones hancock beaulieu 
okapi trec 
overview third text retrieval conference trec 

robertson walker 
simple effective approximations poisson model probabilistic weighted retrieval 
proceedings acm sigir 
robertson sparck jones relevance weighting search terms 
journal american society information science 
robertson walker relevance weights little relevance information proceedings acm sigir 

bruce croft 
boolean queries term dependencies probabilistic retrieval models 
journal american society information science technology 
bruce croft david lewis 
approach natural language processing document retrieval 
proceedings acm sigir 
william cooper 
inconsistencies probabilistic information retrieval 
proceedings acm sigir 
william cooper 
maximum entropy principle application design probabilistic retrieval systems 
information technology research developments 
zipf human behavior principle effort 
wesley reading mass 
richard duda peter hart 
pattern classification scene analysis 
wiley interscience publication 
bookstein swanson 
decision theoretic foundation indexing 
journal american society information science vol 
william shaw jr judith wood robert wood helen 
cystic fibrosis database content research opportunities 
library information science research 
robert losee 
analytic measure predicting information retrieval system performance 
information processing management 
trec eval 
trec eval program available ftp smart site cornell university ftp ftp cs cornell edu pub smart 


new encyclopedia 
seoul publishing 
chow liu approximating discrete probability distributions dependence trees 
ieee transactions information theory 

david hays 
dependency theory formalism observations 
language 
kurohashi makoto nagao 
kn parser japanese dependency case structural analyzer 
proceedings workshop sharable natural language resources pp 

