spectral relaxation means clustering zha dept comp 
sci 
eng 
pennsylvania state university university park pa cse psu edu chris ding horst simon nersc division lawrence berkeley national lab 
uc berkeley berkeley ca lbl gov ming gu dept mathematics uc berkeley berkeley ca mgu math berkeley edu popular means clustering partitions data set minimizing sum squares cost function 
coordinate descend method find local minima 
show minimization reformulated trace maximization problem associated gram matrix data vectors 
furthermore show relaxed version trace maximization problem possesses global optimal solutions obtained computing partial eigendecomposition gram matrix cluster assignment data vectors computing pivoted qr decomposition eigenvector matrix 
product derive lower bound minimum sum squares cost function 
means popular method general clustering 
means clusters represented centers mass members shown means algorithm alternating assigning cluster membership data vector nearest cluster center computing center cluster centroid member data vectors equivalent finding minimum sum squares cost function coordinate descend 
despite popularity kmeans clustering major drawbacks coordinate descend search method prone local minima 
research done computing refined initial points adding explicit constraints sum squares cost function means clustering search converge better local minimum 
tackle problem different angle find equivalent formulation sum squares minimization trace maximization problem special constraints relaxing constraints leads maximization problem possesses optimal global solutions 
product easily computable lower bound minimum sum squares cost function 
inspired connection gram matrix extension kmeans method general mercer kernels investigated 
rest organized follows section derive equivalent trace maximization formulation discuss spectral relaxation 
section discuss assign cluster membership pivoted qr decomposition account special structure partial eigenvector matrix 
section illustrate performance clustering algorithms document clustering example 
notation 
delta denotes euclidean norm vector 
trace matrix sum diagonal elements denoted trace 
frobenius norm matrix trace 
denotes identity matrix order spectral relaxation set dimensional data vectors form data matrix 
partition pi date vectors written form ae permutation matrix ith cluster contains data vectors partition pi associated sum squares cost function defined ss pi ka gamma mean vector data vectors cluster vector appropriate dimension elements equal easy see ss ka gamma ka gamma ka gamma ee notice gamma ee projection matrix gamma ee gamma ee follows ss trace gamma ee trace gamma ee ss pi ss trace gamma orthonormal matrix 
sum squares cost function written ss pi trace gamma trace ax minimization equivalent maxf trace ax form 
loss generality 
cluster indicator vector easy see trace ax ax kax kx partition right hand side written fl fl fl fl fl fl fl fl km weighted sum squared euclidean norms mean vector clusters 

consider elements gram matrix measuring similarity data vectors shown euclidean distance leads euclidean inner product similarity 
inner product replaced general mercer kernel done 
ignoring special structure arbitrary orthonormal matrix obtain relaxed maximization problem max ik trace ax turns trace maximization problem closed form solution 
theorem 
ky fan symmetric matrix eigenvalues delta delta delta corresponding eigenvectors un 
delta delta delta max ik trace hx optimal arbitrary orthogonal matrix 
follows theorem need compute largest eigenvectors gram matrix product min pi ss pi trace gamma max ik trace ax minfm ng oe oe largest singular value gives lower bound minimum sum squares cost function 

easy see derivation replace gamma ae arbitrary vector 
lower bound min pi ss pi max minfm ng oe gamma ae 
try approach notice ka gamma ka gamma ka gamma ij ij ae ss pi wx min ik wz gammak unfortunately smallest eigenvalues negative 
matrix consisting largest eigenvectors row corresponds data vector process considered transforming original data vectors live dimensional space new data vectors live dimensional space 
attempted compute cluster assignment applying ordinary means method data vectors reduced dimension space 
section discuss alternative takes account structure eigenvector matrix 

similarity projection process principal component analysis deceiving goal reconstruct data matrix low rank approximation capture cluster structure 
cluster assignment pivoted qr decomposition loss generality assume best partition data vectors minimizes ss pi submatrix corresponding cluster 
write gram matrix 
overlaps clusters represented submatrices small norm small compare block diagonal matrix equation 
largest eigenvector ky columns matrix 
span invariant subspace eigenvalues eigenvectors ax assume gap eigenvalue sets ffi gamma ng davis kahan sin theta theorem states ky xn kek ffi theorem 
manipulation shown kek orthogonal matrix 
ignoring kek term see cluster ksk cluster key observation orthogonal selected jump clusters looking orthogonal complement notice ky elements small 
robust implementation idea obtained follows pick column largest norm say belongs cluster orthogonalize rest columns column 
columns belonging cluster residual vector small norm columns residual vectors tend small 
pick vector largest residual norm orthogonalize residual vectors residual vector 
process carried steps turns exactly qr decomposition column pivoting applied find permutation matrix qr orthogonal matrix upper triangular matrix 
compute matrix gamma gamma cluster membership data vector determined row index largest element absolute value corresponding column 
may advantageous include eigenvectors form qr decomposition column pivoting select columns form matrix say column compute squares solution argmin kz gamma 
cluster membership determined row index largest element absolute value experimental results section experimental results clustering dataset newsgroup articles submitted newsgroups 
dataset contains articles email messages evenly divided newsgroups 
list names newsgroups associated group labels 
newsgroup dataset bow toolkit processing downloaded www cs cmu edu afs cs project theo www naive bayes html 
qr kmeans clustering accuracy newsgroups ng ng ng ng ng qr vs kmeans left kmeans vs kmeans right ng alt atheism ng comp graphics ng comp os ms windows misc ng comp sys ibm pc hardware ng comp sys mac hardware ng comp windows ng misc ng rec autos ng rec motorcycles ng rec sport baseball ng rec sport hockey ng sci crypt ng sci electronics ng sci med ng sci space ng soc religion christian ng talk politics guns ng talk politics mideast ng talk politics misc ng talk religion misc bow toolkit construct term document matrix dataset specifically tokenization option usenet headers stripped applied stemming 
preprocessing steps done apply usual tf idf weighting scheme delete words appear times normalized document vector unit euclidean length 
tested clustering algorithms qr refers algorithm eigenvector matrix followed pivoted qr decomposition cluster membership assignment kmeans compute eigenvector matrix apply means rows eigenvector matrix means means directly applied original data vectors 
means methods start set cluster centers chosen randomly projected data vectors sure random set comparison 
assess quality clustering algorithm take advantage fact newsgroup data labeled measure performance accuracy clustering algorithm document category labels 
particular cluster case compute confusion matrix ij ij number documents cluster belongs newsgroup category quite subtle compute accuracy confusion matrix know cluster matches newsgroup category 
optimal way solve maximization problem maxf trace cp permutation divide maximum total number documents get accuracy 
equivalent finding perfect matching complete weighted bipartite graph kuhn algorithm 
experiments greedy algorithm compute sub optimal solution 
table comparison qr kmeans means way clustering newsgroups qr kmeans means ng ng sigma sigma sigma ng ng sigma sigma sigma ng ng sigma sigma sigma ng ng sigma sigma sigma ng ng sigma sigma sigma ng ng sigma sigma sigma table comparison qr kmeans means multi way clustering newsgroups qr kmeans means ng ng ng ng ng sigma sigma sigma ng ng ng ng ng sigma sigma sigma ng ng ng ng ng sigma sigma sigma ng ng ng ng ng sigma sigma sigma ng ng ng ng ng ng ng ng ng ng sigma sigma sigma ng ng ng ng ng ng ng ng ng ng sigma sigma sigma example 
example look binary clustering 
choose random document vectors newsgroups 
tested runs pair newsgroups list means standard deviations table 
clustering algorithms qr kmeans comparable better substantially better means 
example 
example consider way clustering 
newsgroup sets chosen random samples newsgroup indicated parenthesis 
runs tests means standard deviations listed table 
plot accuracy runs test ng ng ng ng ng 
qr kmeans perform better kmeans 
newsgroup sets small overlaps qr performs better kmeans 
explained fact qr explores special structure eigenvector matrix efficient 
thorough comparison information bottleneck method runs ng ng ng ng ng mean accuracy maximum accuracy obtained 
runs newsgroup set samples mean accuracy maximum accuracy obtained 
example 
compare lower bound 
list typical sample ng ng ng ng ng 
column ng labels indicates clustering newsgroup labels definition accuracy 
quite clear newsgroup categories completely captured sum squares cost function qr ng labels higher accuracy larger sum squares values 
interestingly qr captures information newsgroup categories 
qr kmeans means ng labels lower bound accuracy ss pi acknowledgments supported part nsf ccr department energy lbl fund 
bradley usama fayyad 

refining initial points means clustering 
proc 
th international conf 
machine learning 
bradley bennett 
constrained means clustering 
microsoft research msr tr 


mercer kernel clustering feature space 
appear ieee transactions neural networks 
golub van loan 

matrix computations 
johns hopkins university press rd edition 
ming gu zha chris ding horst simon 

spectral embedding way graph clustering 
technical report department computer science engineering cse pennsylvania state university 
hartigan wong 

means clustering algorithm 
applied statistics 
lovasz plummer 
matching theory 
amsterdam north holland 
mccallum 
bow toolkit statistical language modeling text retrieval classification clustering 
www cs cmu edu mccallum bow 
scholkopf smola muller 

nonlinear component analysis kernel eigenvalue problem 
neural computation 
slonim tishby 

document clustering word clusters information bottleneck method 
proceedings sigir 
stewart sun 

matrix perturbation theory 
academic press san diego ca 
