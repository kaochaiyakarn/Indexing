artificial intelligence robust monte carlo localization mobile robots sebastian thrun dieter fox wolfram burgard frank dellaert school computer science carnegie mellon university pittsburgh pa usa department computer science engineering university washington seattle wa usa computer science department university freiburg freiburg germany received april mobile robot localization problem determining robot pose sensor data 
article presents family probabilistic localization algorithms known monte carlo localization mcl 
mcl algorithms represent robot belief set weighted hypotheses samples approximate posterior common bayesian formulation localization problem 
building basic mcl algorithm article develops robust algorithm called mixture mcl integrates complimentary ways generating samples estimation 
apply algorithm mobile robots equipped range finders kernel density tree learned permits fast sampling 
systematic empirical results illustrate robustness computational efficiency approach 
published elsevier science keywords mobile robots localization position estimation particle filters kernel density trees 
mobile robot localization problem estimating robot pose location orientation relative environment 
localization problem key problem mobile robotics 
plays pivotal role various successful mobile robot systems see various chapters 
occasionally referred fundamental problem providing mobile robot autonomous capabilities 
mobile robot localization problem comes different flavors 
simple localization problem received far attention literature position tracking 
initial robot pose known corresponding author 
mail address thrun cs cmu edu thrun 
see front matter published elsevier science pii thrun artificial intelligence problem compensate incremental errors robot odometry 
algorithms position tracking restrictive assumptions size error shape robot uncertainty required range existing localization algorithms 
challenging global localization problem robot told initial pose determine scratch 
global localization problem difficult error robot estimate assumed small 
consequently robot able handle multiple distinct hypotheses 
difficult kidnapped robot problem localized robot place told 
problem differs global localization problem robot firmly believe time kidnapping 
kidnapped robot problem test robot ability recover catastrophic localization failures 
problems particularly hard dynamic environments robots operate proximity people corrupt robot sensor measurements 
vast majority existing algorithms address position tracking problem see review 
nature small incremental errors algorithms kalman filters applicable successfully applied range fielded systems :10.1.1.55.1680:10.1.1.116.6293:10.1.1.54.9615
kalman filters estimate posterior distributions robot poses conditioned sensor data 
exploiting range restrictive assumptions gaussian noise gaussian distributed initial uncertainty represent posteriors gaussians 
kalman filters offer elegant efficient algorithm localization 
restrictive nature belief representation plain kalman filters inapplicable global localization problems 
limitation overcome related families algorithms localization multi hypothesis kalman filters markov localization 
multi hypothesis kalman filters represent beliefs mixtures gaussians enabling pursue multiple distinct hypotheses represented separate gaussian 
approach inherits kalman filters gaussian noise assumption 
meet assumption virtually practical implementations extract low dimensional features sensor data ignoring information acquired robot sensors 
markov localization algorithms contrast represent beliefs piecewise constant functions histograms space possible poses :10.1.1.31.7646:10.1.1.40.2548:10.1.1.48.3521
just gaussian mixtures piecewise constant functions capable representing complex multi modal representations 
algorithms rely features subject similar shortcomings algorithms multi hypothesis kalman filters 
localize robots raw sensor data non gaussian noise distributions 
accommodating raw sensor data requires fine grained representations impose significant computational burdens 
overcome limitation researchers proposed selective updating algorithms tree representations dynamically change resolution :10.1.1.116.6293
remarkable algorithms share probabilistic basis 
estimate posterior distributions poses certain independence assumptions case approach article 
article presents probabilistic localization algorithm called monte carlo localization mcl 
mcl solves global localization kidnapped robot problem thrun artificial intelligence robust efficient way 
accommodate arbitrary noise distributions nonlinearities robot motion perception 
mcl avoids need extract features sensor data 
key idea mcl represent belief set samples called particles drawn posterior distribution robot poses 
words approximating posteriors parametric form case kalman filter markov localization algorithms mcl represents posteriors random collection weighted particles approximates desired distribution 
idea estimating state recursively particles new topic 
statistical literature known particle filters computer vision researchers proposed algorithm name condensation algorithm :10.1.1.117.9046:10.1.1.51.7851:10.1.1.36.8357:10.1.1.56.1897
context localization particle representation range characteristics sets aside previous approaches particle filters accommodate arbitrary sensor characteristics motion dynamics noise distributions 
particle filters universal density approximators weakening restrictive assumptions shape posterior density compared previous parametric approaches 
particle filters focus computational resources areas relevant sampling proportion posterior likelihood 
controlling number samples line particle filters adapt available computational resources 
code executed computers vastly different speed modification 
participle filters surprisingly easy implement attractive paradigm mobile robot localization 
consequently mcl adopted research teams extended basic paradigm interesting new ways :10.1.1.37.4334
pitfalls arising stochastic nature approximation 
pitfalls obvious example sample set size small robot lose track position just mcl fails generate sample right location 
regular mcl algorithm unfit kidnapped robot problem surviving samples nearby robot new pose kidnapped 
somewhat counter intuitive fact basic algorithm degrades poorly sensors accurate 
extreme regular mcl fail perfect noise free sensors 
problems overcome augmenting sample set uniformly distributed samples generating samples consistent sensor reading idea familiar multi hypothesis kalman filtering assuming higher level sensor noise case :10.1.1.2.342:10.1.1.2.342:10.1.1.37.4334
extensions yield improved performance mathematically questionable 
particular extensions approximate correct density interpretation results difficult 
overcome problems article describes extension mcl closely related called mixture mcl :10.1.1.142.1730:10.1.1.37.4334
mixture mcl addresses problems way mathematically motivated 
key idea modify way samples generated thrun artificial intelligence mcl 
mixture mcl combines regular mcl sampling dual mcl basically inverts mcl sampling process 
specifically regular mcl guesses new pose odometry uses sensor measurements assess importance sample dual mcl guesses poses sensor measurement uses odometry assess compliance guess robot previous belief odometry data 
sampling methodologies sufficient combination 
particular mixture mcl works sample set size small samples recovers faster robot kidnapping previous variation mcl works sensor models narrow regular mcl 
performance point view mixture mcl uniformly superior regular mcl particle filters 
key disadvantage mixture mcl requirement sensor model permits fast sampling poses 
certain cases model trivially obtained navigation domains studied :10.1.1.116.6293
overcome difficulty approach uses sufficient statistics density trees learn sampling model data 
specifically pre processing phase sensor readings mapped set discriminating features potential robot poses drawn randomly trees generated 
tree constructed dual sampling done efficiently 
shed light performance mixture mcl practice empirical results robot simulator data collected physical robots 
simulation allows systematically vary key parameters sensor noise enabling characterize degradation mcl extreme situations 
verify experimental findings obtained simulation mixture mcl applied extensive data sets gathered public museum smithsonian museum washington dc week period fall mobile robot minerva gave interactive tours thousands visitors 
data set comprises laser range data metric map museum localization 
data set contains image segments recorded camera pointed museum ceiling large scale ceiling mosaic cross referencing robot position 
past data benchmark localization crowded feature impoverished museum challenging problem 
experiments suggest new mcl algorithm highly efficient accurate 
remainder article organized follows 
section introduces regular mcl algorithm includes mathematical derivation principles experimental characterization mcl practice 
section compares mcl grid markov localization alternative localization algorithms capable global localization :10.1.1.116.6293
section presents examples regular mcl performs poorly brief analysis underlying causes 
section followed description dual mcl mixture mcl section 
section describes approach learning trees efficient sampling dual mcl 
experimental results section 
conclude article description related section discussion strengths weaknesses mixture mcl section 

monte carlo localization 
bayes filtering thrun artificial intelligence mcl recursive bayes filter estimates posterior distribution robot poses conditioned sensor data 
bayes filters address problem estimating state dynamical system partially observable markov chain sensor measurements 
example mobile robot localization dynamical system mobile robot environment state robot pose specified position twodimensional cartesian space robot heading direction measurements may include range measurements camera images odometry readings 
bayes filters assume environment markov past data conditionally independent knows current state 
markov assumption explicit 
key idea bayes filtering estimate probability density state space conditioned data 
posterior typically called belief denoted bel xt xt 
denotes state xt state time andd denotes data starting time time mobile robots distinguish types data perceptual data laser range measurements odometry data carry information robot motion 
denoting observation action bel xt xt ot ot 
loss generality assume observations actions arrive alternating sequence 
notice refer odometry reading measures motion occurred time interval illustrate motion result control action asserted time 
bayes filters estimate belief recursively 
belief characterizes initial knowledge system state 
absence knowledge typically initialized uniform distribution state space 
mobile robot localization uniform initial distribution corresponds global localization problem initial robot pose unknown 
derive recursive update equation observe expression transformed bayes rule bel xt ot xt xt 
ot denominator constant relative variable xt bayes rule usually written bel xt ot xt xt normalization constant ot 
thrun artificial intelligence noticed bayes filters rest assumption data independent past data knowledge current state assumption typically referred markov assumption 
put mathematically markov assumption implies ot xt ot xt target expression simplified bel xt ot xt xt 
expand rightmost term integrating state time bel xt ot xt xt xt xt dxt 
exploit markov assumption simplify xt xt xt xt xt xt gives expression bel xt ot xt xt xt xt dxt 
substituting basic definition belief bel back obtain important recursive equation bel xt ot xt xt xt bel xt dxt 
equation recursive update equation bayes filters 
initial belief defines recursive estimator state partially observable system 
equation central importance article basis various mcl algorithms studied 
implement needs know conditional densities probability xt xt refer state density simply motion model andthe density ot xt call perceptual model sensor model 
models typically stationary called time invariant depend specific time stationarity allows simplify notation denoting models andp respectively 

probabilistic models localization nature models depends specific estimation problem 
mobile robot localization focus article models relatively straightforward implemented lines code 
specific probabilistic models implementation described depth provide informal account :10.1.1.116.6293
motion model probabilistic generalization robot kinematics 
noticed robot operating plane poses thrun artificial intelligence fig 

density moving meter left diagram meter right diagram 
darker pose dimensional variables 
pose comprises robot dimensional cartesian coordinates heading direction orientation bearing 
value may odometry reading control command characterize change pose 
robotics change pose called kinematics 
conventional kinematic equations describe expected pose ideal noise free robot attain starting moving specified course physical robot motion erroneous pose uncertain 
account inherent uncertainty probabilistic motion model describes posterior density possible successors typically modeled zero centered gaussian noise added translation rotation components odometry measurements :10.1.1.116.6293
generalizes exact mobile robot kinematics typically described robot textbooks probabilistic component 
fig 
shows examples 
examples initial pose shown left solid line depicts odometry data measured robot 
shaded area right depicts density darker pose comparison diagrams reveals margin uncertainty depends motion pose noise free robot motion segments uncertainty right diagram larger due longer distance traversed robot 
mcl algorithm described need closed form description motion model 
sampling model suffices 
sampling model routine accepts input generates random poses distributed 
sampling models usually easier code routines compute densities closed form 
fig 
shows sample model applied sequence odometry measurements indicated solid line 
easy seen sequence particle sets approximates densities robot measures odometry 
turn attention perceptual model 
mobile robots commonly equipped range finders ultrasonic transducers sonar sensors laser range finders 
fig 
shows example laser range scan obtained rwi robot environment approximate shape shown fig 

notice range finder emits plateau light covers horizontal degree range measures distance nearest objects 
thrun artificial intelligence fig 

sampling approximation position belief robot measures odometry 
solid line displays actions samples represent robot belief different points time 
range finders decompose problem computing parts computation value noise free sensor generate modeling sensor noise integration individual sensor beams single density value 
assume robot pose denote individual sensor beam bearing relative robot 
denote measurement ideal noise free sensor relative bearing assume robot map environment shown fig 
computed ray tracing 
assume expected distance sufficient statistic probability oi thatis oi oi 
exact density oi shown fig 

density mixture densities gaussian centered models event measuring correct distance small added gaussian noise exponential density models random readings caused people discrete large probability mathematically modeled narrow uniform density models max range measurements frequently occur range sensor fails detect object 
specific parameters density fig 
estimated algorithm similar em starts crude initial model iteratively labels measurements collected smithsonian museum refining model 
smoothed version data shown fig 
illustrating probabilistic model highly accurate 
thrun artificial intelligence laser scan map sensor model oi probability distribution different poses fig 

laser range scan projected map 
density peak corresponds distance ideal noise free sensor measure 
scan shown 
single sensor scan robot assigns high likelihood main corridor 
thrun artificial intelligence individual density values oi integrated multiplicatively assuming conditional independence individual measurements oi 
clearly conditional independence violated presence people block sensor beam 
cases advisable subsample sensor readings reduced set localization :10.1.1.116.6293
fig 
depicts sensor scan shown fig 
map shown gray fig 

probability mass corridor region reflects fact specific sensor measurement originated corridor rooms 
probability mass roughly lies bands spread corridor 
density shown fig 
equivalent posterior belief globally localizing robot perceiving sensor measurement 

particle approximation state space continuous case mobile robot localization implementing trivial matter particularly concerned efficiency 
idea mcl particle filter algorithms represent belief bel set weighted samples distributed bel bel sample random variable hypothesized state pose 
non negative numerical parameters called importance factors sum strictly required particle filtering 
name suggests importance factors determine weight importance sample 
set samples define discrete probability function approximates continuous belief bel 
initial set samples represents initial knowledge bel state dynamical system 
example global mobile robot localization initial belief set poses drawn uniform distribution robot universe annotated uniform importance factor initial pose known small margin error bel may initialized samples drawn narrow gaussian centered correct pose 
recursive update realized steps 
sample bel xt weighted sample set representing bel xt 
particle distributed belief distribution bel xt 
sample xt 
obviously pair distributed product distribution qt xt xt bel xt 
accordance literature sir algorithm short sampling importance resampling refer distribution qt thrun artificial intelligence proposal distribution 
role propose samples desired posterior distribution eq 
equivalent desired posterior 
correct mismatch proposal distribution qt desired distribution specified eq 
restated sample pair ot bel 
mismatch accounted non normalized importance factor assigned ith sample ot 
importance factor obtained quotient target distribution proposal distribution constant scaling factor ot bel bel ot 
notice quotient proportional 
sampling routine repeated times producing set weighted samples 
importance factors normalized sum define discrete probability distribution 
table summarizes mcl algorithm 
known mild assumptions hold sample set converges true posterior bel xt goes infinity convergence speed 
speed may vary constant factor vary drastically depending proposal distribution 
due normalization particle filter asymptotically unbiased 
care taken number samples extremely small bias increases table mcl algorithm algorithm mcl generate random wm generate random add endfor normalize importance factors return thrun artificial intelligence sample set size decreases 
extreme case measurements ot plainly ignored resulting expectation single sample heavily biased prior 
implementations number samples sufficiently large 

examples performed systematic experiments range different settings evaluate performance mcl practice 

simulation simulation employed evaluation allows freely vary key parameters amount sensor noise 
freedom characterize situations mcl performs poorly 
fig 
shows example simulated mobile robot localizes object 
simulation robot detect approximate location object image taken camera lack depth estimation mono vision impossible localize object single camera image 
simulated robot view object multiple viewpoints 
changing viewpoint introduces additional uncertainty robot motion inaccurate 
additionally simulation visual field robot limited narrow region front robot fig 

successful localization sequence robot simulation object localization 
final error cm 
thrun artificial intelligence fig 

average error mcl function number simulated robot steps measurements 
complicates object localization problem 
noise simulation includes simulation measurement noise false positive measurements phantom detections false negative measurements failures detect target object 
enable systematically vary key parameters perceptual noise results mobile robot simulator models control error reminiscent rwi robot noise perception gaussian position noise false negatives false positives 
notice task difficult due impoverished nature robot sensors large number symmetries 
fig 
depicts different states global object localization 
initially pose object unknown represented uniform sample set fig 
diagram 
simulated robot turns wide circle unable see object despite handful phantom detections samples gradually populate unexplored part state space fig 
second diagram 
third diagram shows correct object sighting reinforces samples happen close correct object pose 
measurements repetitive sightings object lead posterior shown fourth diagram fig 

fig 
shows systematic error curves mcl global localization different sample set sizes averaged individual experiments 
bars confidence intervals level 
reader notice results obtained perceptual noise level false negative false positive additional position noise gaussian distributed variance degrees 
existing vision system error rates lower may necessarily independent 

robot sonar sensors fig 
shows example mcl context localizing mobile robot globally office environment 
robot called minerva rwi robot equipped sonar range finders 
map environment 
fig 
robot globally thrun artificial intelligence fig 

global localization mobile robot mcl samples initial particle set uniformly distributed projected 
particles approximately meters robot motion 
due environment symmetry particles centered locations 
particle set moving room breaking symmetry 
experiments carried rwi robot 
thrun artificial intelligence fig 

accuracy grid markov localization different spatial resolutions 
accuracy mcl different numbers samples log scale 
uncertain samples spread uniformly free space projected 
fig 
shows sample set approximately meters robot motion point mcl disambiguated robot position single symmetry 
meters robot motion ambiguity resolved robot knows majority samples centered tightly correct position shown fig 

particular interest shall comparison mcl alternative localization algorithm capable global mobile robot localization 
particular compared mcl grid markov localization previous best stochastic localization algorithm algorithms capable localizing robot globally :10.1.1.31.7646
localization algorithm relies fine grained piecewise constant approximation belief bel identical sensor motion models 
fact implementation employs identical sensor motion models capable processing data greatly facilitates comparison 
fig 
plots localization accuracy grid localization function grid resolution 
notice results fig 
generated real time 
shown accuracy increases resolution grid sonar solid line laser data dashed line 
grid sizes cm permit updating real time specific testing environment highly efficient selective update schemes applied :10.1.1.116.6293
results mcl fixed sample set sizes shown fig 

results generated real time conditions large sample sizes samples result loss sensor data due time constraints 
small sample sets disadvantageous infer large error approximation 
large sample sets disadvantageous processing requires time fewer sensor items processed real time 
optimal sample set size fig 
samples 
grid localization reach level accuracy grids cm resolution infeasible best computers 
thrun artificial intelligence fig 

ceiling map national museum american history perceptual model navigating vision sensor 
map acquired rwi robot 

robot upward pointed camera similar results obtained camera primary sensor localization 
test mcl challenging real world conditions evaluated data collected populated museum 
week exhibition robot minerva fig 
employed tour guide smithsonian museum natural history traversed km 
aid localization minerva equipped camera pointed ceiling 
fig 
shows mosaic museum ceiling 
ceiling height unknown center region camera image localization 
data set difficult possession robot traveled speeds cm sec 
entered left area center museum crossed cm bump introduced significant errors robot odometry 
vision information grid localization failed track robot 
enormous computational overhead impossible incorporate sufficiently images 
mcl succeeded globally localizing robot tracking robot position specific data set 
fig 
shows sequence belief distributions localization mcl 
see second data sequence recorded museum opening hours mcl failed localize robot vision information course actual exhibit laser instrumental localization 
thrun artificial intelligence fig 

global localization mobile robot camera pointed ceiling 
experiment carried minerva tour guide robot rwi robot 
thrun artificial intelligence fig 

solid curve error mcl steps function sensor noise 
confidence intervals indicated bars 
notice function monotonic expect 
dashed curve experiment high error model 
results obtained simulation 

limitations mcl noticed authors basic particle filter performs poorly proposal distribution generate samples places samples regions desired posterior bel xt large :10.1.1.117.9046:10.1.1.51.7851:10.1.1.56.1897
problem practical importance context mcl example illustrates 
solid curve fig 
shows object localization example accuracy mcl achieves steps samples 
results obtained simulation enabling vary amount perceptual noise right left 
appears mcl works best perceptual noise 
degradation performance right lot noise hardly surprises 
accurate sensor larger error expect 
mcl performs poorly noise level small 
words mcl accurate sensors may perform worse mcl inaccurate sensors 
glance finding may appear bit counter intuitive suggests mcl works specific situations sensors possess right amount noise 
fig 
depicts example run highly accurate sensors mcl fails 
object sighted samples close object true position 
consequence mcl gradually removes samples exception located simulated robot dead spot center circular trajectory 
clearly localization fails example final error cm 
unfortunately accurate sensors smaller support problem occurs 
course fixes 
glance add artificial noise sensor readings 
sensible strategy perceptual model ot xt overestimates actual sensor noise adding noise sensor measurements 
fact strategy adopted partially alleviates problem thrun artificial intelligence fig :10.1.1.2.342:10.1.1.2.342

unsuccessful localization sequence robot simulation object localization 
final error case cm 
dashed curve fig 
shows accuracy error model assumes fixed noise shown smaller true error rates 
performance better hardly fix 
overly pessimistic sensor model inaccurate throwing away precious information sensor readings 
fact resulting belief longer posterior infinitely samples 
fixes include addition random samples posterior generation samples locations consistent sensor readings strategy similar mixture mcl proper sample weighting mathematically questionable :10.1.1.2.342:10.1.1.2.342:10.1.1.37.4334
approaches shown superior performance strict mcl certain settings expected converge true posterior sample set size goes infinity 
analyze problem thoroughly notice true goal bayes filtering calculate product distribution specified eq 

optimal proposal distribution product distribution 
sampling distribution directly difficult 
noticed mcl samples proposal distribution qt defined eq 
uses importance factors account difference 
known statistical literature divergence determines convergence speed :10.1.1.117.9046:10.1.1.51.7851:10.1.1.56.1897
difference accounted perceptual density ot xt sensors entirely uninformative distribution flat equivalent 
low noise sensors ot xt typically quite narrow mcl converges slowly 
error thrun artificial intelligence fig 
fact caused different types errors arising limitation sensor data noise arises mismatch mcl 
show article alternative version mcl exists practically eliminates second error source enhancing accuracy robustness approach 

mixture mcl 
dual mcl derive alternative version mcl called dual monte carlo localization 
algorithm ultimately lead main algorithm proposed article mixture mcl algorithm 
key idea dual invert sampling process exchanging roles proposal distribution importance factors mcl 
specifically dual mcl generates samples state virtue proposal distribution qt ot xt ot ot xt dxt 
ot normalizer ot assumed finite case mobile robot localization environments bounded size 
dual mcl viewed logical inverse sampling regular mcl guessing state observation adjust importance guess dual mcl guesses states corresponding observation adjusts importance factor accordance prior belief bel xt 
consequently dual proposal distribution possesses complimentary strengths weaknesses ideal highly accurate sensors performance negatively affected measurement noise 
key advantage dual mcl distribution narrow case low noise sensors dual sampling effective conventional mcl 

importance factors provide alternative ways calculate importance factors qt mathematically elegant reasons detailed suited mobile robot localization 
require additional smoothing step 
mobile robot localization 

approach proposed arnaud doucet personal communication 
idea draw random pairs sampling described drawing bel xt 
obviously combined proposal distribution ot xt ot bel xt thrun artificial intelligence importance factors 
see notice importance factor quotient target distribution proposal distribution scaling factor ot bel ot ot bel ot 
approach mathematically elegant alternatives described avoids need transform sample sets densities case 
context global mobile robot localization importance factor zero vanishingly small pose pairs independently drawn poses consistent action motion model 
implemented approach 
estimation problems particle filters reason described article 

approach second approach seeks calculate importance factors samples directly 
approach requires separate forward phase auxiliary density function constructed subsequently calculate importance factors 
forward phase approach generates samples bel xt xt 
easily seen resulting sample distributed xt 
represent robot belief time incorporating sensor measurement ot belief distributions type referred predictive distributions kalman filtering literature represent prediction state xt previous data incorporating sensor measurement time distribution calculating importance factors trick transform samples kernel density tree kd tree represents predictive distribution xt closed form :10.1.1.17.2654
tree calculate sample generated dual sampler 
pieces define second version dual sampler 
similar previous approach samples generated proposal distribution qt defined eq 

sampling bel xt approach directly assigns importance factors samples kd tree represents 
verify correctness approach notice quotient bayes filter target distribution proposal distribution proportional importance factors thrun artificial intelligence ot ot ot ot ot xt bel xt dxt ot 
ot comparison approach discussed approach avoids danger generating pairs poses 
hand involves explicit forward sampling phase requires induction probability density function samples kd tree 
induction step smoothes resulting density reduces variance estimation 
primary role converting samples kd trees facilitates calculation importance weights 

approach third approach avoids explicit forward sampling phase second approach tends generate smaller importance factors 
particular third approach transforms initial belief bel xt kd tree forward phase second approach 
sample qt draws sample distribution xt xt dxt 
assume integral finite trivially case context mobile robot localization 
words approach projects back possible predecessor pose consequently pair poses distributed proposal distribution ot xt ot xt xt xt gives rise importance factor bel 
see notice proportional quotient target distribution proposal distribution ot ot ot ot bel bel 
thrun artificial intelligence table dual mcl algorithm third approach algorithm dual mcl generate kd tree generate random generate random add endfor normalize importance factors return calculating calculated kd tree representing belief density 
derivation silently assumed term constant omitted 
approximation mobile robot localization general case dynamical systems assumption may valid 
table shows algorithm implements specific version dual mcl 

performance reader notice approaches require method sampling poses observations qt non trivial mobile robot applications 
approach easiest implement mathematically straightforward 
noted suspect inefficient mobile robot localization 
approaches rely density estimation method kd trees 
third requires method sampling poses backwards time complicates implementation 
superior results may additional implementing dual worthwhile 
unfortunately dual mcl insufficient localization 
fig 
depicts performance dual mcl third approach conditions led mcl results shown fig 

figures horizontal axis depicts amount noise perception vertical axis depicts error centimeters averaged independent runs 
things remarkable accuracy monotonic perceptual noise accurate sensors give better results 
second performance poorer conventional mcl 
poor performance dual mcl due fact erroneous sensor measurements devastating effect estimated belief samples generated wrong place 
thrun artificial intelligence fig 

error dual mcl function sensor noise 
error appears increase monotonically sensor noise error level high 
compare graph fig 

results obtained simulation 

mixture mcl algorithm practical situations plain mcl sufficiently 
experimental results suggest version mcl plain mcl algorithm dual delivers satisfactory performance certain situations 
plain mcl algorithm fails perceptual likelihood peaked 
dual mcl considers sensor measurement prone failure sensors fail regardless alternatives calculate importance factors 
approach complimentary strengths weaknesses suggesting combination yield superior performance 
mixture mcl final algorithm described merges approaches 
mixture mcl samples generated plain mcl duals mixing rate 
achieved generating sample probability standard mcl probability dual 
table states mixture mcl algorithm third variant calculating importance factors dual 
easy seen mixture mcl algorithm combines mcl algorithms table dual algorithm table probabilistic mixing ratio 
probability mcl sampling mechanisms generate new sample 
samples generated dual 
notice types samples added sample set normalization 
types importance factors compatible necessary multiply importance factors dual samples compared algorithm stated table 
see notice eq 
suggests importance factors plain mcl 
similarly importance factors third version dual derived eq 
denotes tree generated corresponding belief bel 
constant occurs versions mcl thrun artificial intelligence table mixture mcl algorithm third variant dual mcl see table algorithm generate kd tree tom probability generate random wm generate random add generate random generate random add endif endfor normalize importance factors return safely omitted 
appropriate importance factor samples generated regular mcl samples generated dual 
implementation approximate constant 
fig 
shows results obtained simulation 
shown performance results mixture mcl second thick line third thin line variant dual calculating importance factors 
experiments fixed mixing ratio averaged independent experiments data point 
comparison fig 
suggests mixture mcl vastly superior regular mcl certain cases reduces error order magnitude 
results obtained third method calculating importance factors 
simulation experiments second approach yields slightly worse results difference significant confidence level 

sampling dual proposal distribution sensors sampling dual proposal distribution far trivial 
example mobile robot uses proximity sensors metric map described section sampling inverse straightforward 
reader may recall section outlines closed form routine computing forward model accepts pose observation input 
dual mcl thrun artificial intelligence fig 

error mixture mcl combining regular dual importance sampling 
mixture mcl outperforms components large margin error monotonic sensor noise 
thick line second approach thin line third approach dual sampling 
compare graph figs 

results obtained simulation 
requires sample poses density proportional just observation input 
words need routine accepts range scan input generates poses key idea learn sampling model joint distribution data samples desired proposal distribution generated ease 
specific representation chosen set kd trees models subset similar observations recursively partitions space poses way easy sample 
data construct trees samples poses observations distributed joint distribution 
ways sample joint synthetically existing probabilistic models physical robot gather data probabilistic model augment data 
synthetic sampling scheme relatively straightforward 
generate single sample joint done cascaded sampling steps pose sampled uniform distribution pose observation sampled 
sampling repeated sufficient number samples generated 
obviously resulting sample set represents joint distribution 
alternative way generate samples joint data collected physical robot 
approach preferable easily sample perceptual model case existing software implementation fixes rejection sampling inefficient 
general sampling perceptual model particularly difficult cameras problem similar computer graphics problem 
luckily sensor measurements randomly collected robot samples assuming thrun artificial intelligence robot placed randomly environment 
robots usually unable measure poses localization problem 
luckily importance sampling offers solution 
routine generates samples desired joint distribution generate observation physical robot known environment random unknown pose 
generate large number poses uniform distribution set robot poses 
pose compute importance factor perceptual model described section 
samples generated approach importance factors approximate joint 
equipped samples representing joint distribution turn attention learning trees permit fast sampling dual proposal distribution multiple options generate trees 
approach sensor measurements mapped low dimensional feature vector 
laser range scans set features location sensor scan center gravity relative robot local coordinate system 
center gravity obtained connecting points individual range measurements calculating center gravity enclosed area relative robot location 
location encoded polar coordinates parameters 
average distance measurement single numerical parameter 
values treated sufficient statistics assume suffices know sample 
discrete grid stipulated values kd tree grown discrete combination feature values 
tree conditioned 
depth tree depends total likelihood region pose space pose specific observation deeper tree smaller region covered leaf 
sampling tree efficient involves small number random coin flips 
fig 
illustrates sampling algorithm practice 
shown fig 
example range scan occupancy grid map described section 
scan approach extracts features described center gravity average distance 
fig 
shows tree corresponds features partitions state space recursively small hyper rectangular regions 
sampling tree yields sample sets shown fig 

tree constructed built line robot operation 
contrast trees represent beliefs mixture mcl built line belief update 
distinction important considering running times different variants mcl 
building tree representing line operation factor running time algorithm 
noted thrun artificial intelligence laser scan map tree scan samples poses generated tree fig 

sampling distribution proportional example range scan map tree partitions state space scan samples poses generated tree 
underlying data collected minerva data rwi robot 
thrun artificial intelligence tree significantly increases memory requirements approach 
example tree generating samples laser range scans museum environment requires approximately mb memory 

experimental results systematic experimental results conducted evaluate advantage mixture mcl regular mcl wide range circumstances 
comparisons carried range localization problems emphasis difficult global localization problem kidnapped robot problem 
real robot experiments augments systematic simulation results key parameters amount sensor noise easily controlled 
emulating global localization failures kidnapped robot problem important tree calculating importance factors dual filter non zero 
achieved dirichlet prior estimating probabilities leaves tree 

simulation fig 
shows performance mixture mcl conditions identical fig 

results suggest new mcl algorithm outperforms mcl dual large margin 
single noise level new algorithm outperforms alternatives factor ranges high noise level low noise level 
example noise level mixture mcl algorithm exhibits average error cm mcl error cm dual mcl cm 
comparison average error noise free sensors optimal estimator approximately cm 
mixture mcl degrades gracefully small sample sets 
fig 
plots error conventional mcl top curve mixture mcl bottom curve different error levels samples 
samples regular mcl basically fails track robot position simulation 
mixture mcl exhibits excellent performance slightly inferior samples 
viewed differently findings suggest mixture mcl computationally order magnitude efficient conventional mcl 
mixture mcl tends exhibit superior performance kidnapped robot problem 
fig 
shows average localization error averaged simulation runs function time 
different curves correspond different algorithms mcl thin curve mcl added random samples dashed curve mixture mcl thick curve 
time step simulated robot kidnapped tele ported random pose told 
argued kidnapping way test ability localization algorithm recover catastrophic failures 
results fig 
suggest mixture mcl recovers faster alternative mcl algorithm despite fact optimized parameters ratio random samples 
regular mcl fails entirely recover kidnapping tends lack samples new robot pose 
addition random samples overcomes thrun artificial intelligence fig 

error mcl top curve mixture mcl bottom curve samples belief state 
results obtained simulation 
fig 

kidnapped robot problem localization error function time different approaches mcl thin curve mcl added random samples dashed curve mixture mcl thick curve 
time robot tele ported random pose told 
results suggest mixture mcl efficient recovering incident 
results obtained simulation 
problem inefficient 
mixture mcl places samples increases efficiency recovering kidnapping 

robot laser range finder mixture mcl evaluated data recorded minerva 
outlined data contains logs odometry measurements sensor scans taken thrun artificial intelligence fig 

estimated path minerva robot smithsonian museum national history 
minerva laser range finders see details 
fig 
shows part map museum path robot evaluation 
reported section conventional mcl reliably succeeds localizing robot 
attention evaluate mixture mcl kidnapped robot problem 
repeatedly introduced errors odometry information 
errors robot lose track position probability advancing meter 
fig 
shows comparative results different approaches 
error measured percentage time estimated position deviates meters position 
obviously mixture mcl yields significantly better results plain mcl augmented random samples 
mixture mcl reduces error rate localization plain mcl compared case plain mcl augmented uniform samples 
results significant confidence level 

robot upward pointed camera compared mixture mcl context visual localization camera imagery obtained robot minerva public museum hours 
notice data set particular contains unexplained large odometry error occurred unknown reasons 
particular case odometry reported back robot low level motion controller jumped large mount 
suspect error caused overflow low level robot motion control software inaccessible 
expect error software check large odometry readings thrun artificial intelligence fig 

performance conventional top curve conventional random samples middle curve mixture bottom curve mcl kidnapped robot problem smithsonian museum 
error rate measured percentage time robot lost track position 
results obtained physical robot 
accepted correct 
error cause induces kidnapped robot problem 
image sequence evaluation poor quality people intentionally covered camera hand placed dirt lens 
fig 
shows sample sets large images superimposed ceiling mosaic generated mixture mcl localization 
arrows mark samples generated regular mcl sampler 
diagrams center regions camera images shown small diagrams generating samples dual filter 
fig 
image suggests robot ceiling light 
consequently dual sampler generates samples close light sources 
fig 
camera measurement considerably dark suggesting location center 
notice changed brightness ceiling map increase visibility samples authentic ceiling map shown fig 

fig 
depicts localization error obtained vision calculated localization results laser ground truth 
data covers period approximately seconds mcl processes total images 
approximately seconds aforementioned error robot odometry leads loss position 
curves fig 
illustrate regular mcl dashed curve unable recover event mixture mcl solid curve recovers 
data set mcl added random sample performs similarly mixture mcl 
results statistically significant single run considered confirm findings laser range finders indicating mixture mcl robust localization method 
thrun artificial intelligence sample set ceiling mosaic camera image center region sample set ceiling mosaic camera image center region fig 

sample sets generated mixture mcl camera image center region image 
arrows mark samples generated conventional mcl sampler samples generated dual 
camera measurement suggests minerva robot near ceiling light measurement suggests location center 

running times final issue addressed experiments concerns running time mcl algorithms 
clearly absolute time depends variety factors number samples nature probabilistic models sensor data amount preprocessing required extracting features camera images underlying computer platform 
numbers discussed section shed light relative thrun artificial intelligence fig 

plain mcl dashed curve compared mixture mcl solid line 
shown error second episode camera localization smithsonian museum robot minerva 
fig 

time seconds mhz pentium pc required full belief computation regular mcl dashed line mixture mcl solid line plotted function number particles 
percentage time spent generating density trees mixture mcl 
results averaged updates robot simulator 
requirements mcl mixture mcl 
illustrate mcl methods implemented highly efficiently requiring small fraction computational resources typical pc 
results reported obtained pentium pc running mhz equipped sufficient ram hold data main memory 
fig 
shows time required full mcl update function number samples robot simulation 
solid line fig 
corresponds regular mcl dashed line shows time required run mixture mcl 
coordinate axes logarithmic 
time measurement approximately linear expect increasing number samples 
regular mcl consumes average seconds update 
mixture mcl mixing ratio requires seconds slower regular mcl 
result appears invariant mixing ratio long 
total time thrun artificial intelligence spent constructing kd tree 
fig 
plots fraction time spent building tree mixture mcl different sample set sizes seen curve decreases increasing sample size samples 
samples percentage increases slightly increase statistically significant level 
exact cause nonmonotonic behavior unknown attribute side effects pc architecture computing cache versus main memory 
timing results physical robot implementation similar 
running times mcl implementation range data shown fig 

diagram shows computation time mhz pentium pc function sample set size plotted logarithmic scale 
computation time broken town basic components integration odometry measurements curve marked solid black squares integration range data curves 
example samples types updates performed thousands second approximately times faster sensor data arrives 
fig 
shows different timing graphs integrating range measurements 
correspond different sensors laser versus sonar different implementations 
top curves fig 
depict computation time straightforward implementation mcl 
implementation calculates distance nearest obstacle line integrating sensor data 
bottom curves show computation time fig 

processor time required mcl implementation range data 
results broken prediction step bottom curve odometry data processed sampling new poses observation step top curve range data incorporated importance factors 
notice axes logarithmic 
bars indicate confidence intervals 
thrun artificial intelligence implementation distances pre computed stored large table see details :10.1.1.116.6293
pre calculating distances integration sensor measurements sped factor 
downside technique memory requirement lies mb mb indoor maps ones shown 
difference computation time laser sonar data observed regardless distances pre computed stems fact laser beams scan sonar beams 
current software integrates individual laser measurements laser scan compared individual sonar measurements sonar scan 
results obtained sample sets fixed size 
notice physical robot implementation mcl generates sample sets variable sizes driven events 
specifically implementation generates samples new sensor measurement available maximum number samples 
advantage implementation adaptivity available computational resources 
algorithms referred time algorithms 
advantage ported different computer new faster pc exploit additional computational power modification program code 
argument emphasizes resource adaptive algorithms generic design principle mobile robot software 

related mobile robot localization fundamental problem mobile robotics received considerable attention past decades 
argued article vast majority focuses position tracking problem errors assumed small 
approaches incapable recovering localization failures methods exist detecting conditions 
usually failures localization component require robot position entered manually 
approaches solve global localization kidnapped robot problem relatively commonly rely bayes filtering multi modal density representations just mcl 
article gives comprehensive overview algorithms mobile robot localization :10.1.1.116.6293
argued article alternatives approach proposed 
prominent ones probabilistic algorithms piecewise constant functions gaussian mixtures represent robot belief 
known markov localization algorithms implemented multi hypothesis kalman filters 
approaches derived bayes filter described section mathematical basis various mcl algorithms article 
algorithms share mathematical basis 
example approximating posterior piecewise constant densities :10.1.1.31.7646:10.1.1.40.2548:10.1.1.48.3521
approaches approximate belief topological representations robot environments 
representations environment decomposed small number significant places size thrun artificial intelligence location depends structure environment 
belief distribution approximated finite distribution parameterized places heading direction 
variant described uses fine grained metric grid represent belief :10.1.1.116.6293
belief space dimensional size grid immense 
presents approximate updating algorithm restricts updates small subset grid cells deemed relevant :10.1.1.116.6293
idea carried proposes trees representing beliefs 
trees represent probability densities varying resolution regions approximated accurately similar kd trees generated samples dual mcl 
approaches differ mcl family algorithms parametric representations 
difficult implement high accuracy needed today best implementations yield somewhat inferior performance suggested comparison section 
localization algorithms multi hypothesis kalman filter represent beliefs mixtures gaussians 
calculate covariance matrices individual gaussian mixture components kalman filtering approach linearizes motion model perceptual model see non linear extension kalman filters 
assumes errors sensor measurements robot motion gaussian 
robot sensors measurement noise gaussian 
kalman filtering algorithms usually raw sensor data localization 
extract features robot poses estimated assumed gaussian noise 
literature suggests range methods extract features point features line features pairs points features raw sensor data loss free features sufficient statistics sensor data relative problem estimating poses 
practice usually case significant information may lost going raw data features 
lies primary difference mcl algorithms article handle arbitrary noise models capable raw sensor data laser range data localization 
multi hypothesis kalman filters applied great success various versions localization problem including position tracking global localization 
certain update steps multi hypothesis kalman filter leveraged multiple gaussians leads efficient implementation 
basic update equations approaches shown hybrid versions bayes filter continuous discrete components 
algorithms related mcl algorithms described 
conceptual point view gaussian mixtures similar sample sets key difference gaussians continuous distributions just discrete samples possess associated covariance matrix 
versions mixture mcl example require step kd tree generated sample set set necessary gaussian representations mixtures gaussians continuous distributions 
keep number mixture components manageable real time approaches referenced apply heuristics terminating gaussians creating new ones indicated sensor data 
heuristics similar identical techniques proposed 
mcl samples terminated probabilistically side effect thrun artificial intelligence sampling step 
mixture mcl creates new hypotheses momentary sensor measurements stochastically considers previous belief determining initial weight probability new hypothesis 
significance differences currently poorly understood 
generating sample generally faster kalman filter update requires matrix inversion suspect samples needed approximate density gaussian mixtures 
particle filters basic statistical tools popular tracking position estimation years example documented forthcoming book topic :10.1.1.51.7851:10.1.1.2.342
research led range variants basic particle filters 
poor performance particle filtering cases proposal distribution differs significantly target distribution observed authors 
typical fixes involve design different proposal distribution places weight tails distribution 
light mixture mcl viewed way deal mismatch problem works mobile robot localization 
particle filters applied great success estimation tracking problems practical importance 
computer vision particle filters commonly known condensation algorithm applied remarkable success visual tracking problems :10.1.1.36.8357:10.1.1.37.1434:10.1.1.126.7850
application mobile robot localization proposed adopted extended researchers :10.1.1.37.4334
extended basic paradigm collaborative localization team mobile robots 
best knowledge idea dual particle filter proposed new :10.1.1.142.1730
obviously works context mobile robot localization 
aim article evaluate mixture mcl algorithm practice straightforward devise proof convergence versions mixture mcl assuming convergence kd trees 
idea dual related article lenser veloso propose generate samples accordance sensor measurement :10.1.1.37.4334
evaluated approach context mobile robot localization 
main differences approach generates samples maximize perceptual density sampling 
second importantly approach take past evidence account generating samples sensor readings approach adjust importance factors samples generated dual accordance bel xt 
consequently resulting estimate approximate posterior 
example environment consists disconnected components rooms approach place non zero likelihood walls physically impossible traverse 
approach relies basic idea asymptotically approximates desired posterior 
idea sampling sensor measurement evidence proposed context bayes networks particular context marginalization monte carlo sampling :10.1.1.112.8434
name arc reversal kanazawa colleagues proposed efficient sampling algorithm jump starts samples bayes network nodes value known propagating samples network obtain estimate desired marginal distribution :10.1.1.48.7248
approach thrun artificial intelligence significantly efficient importance sampler bayes networks follows causality expressed bayes network reasons identical 
approach viewed implementing idea context particle filtering somewhat different mathematical equations account differences bayes networks particle filtering 
approach combines sampling methodologies essential superior performance approach 

article introduced new mobile robot localization algorithm called mixture monte carlo localization 
mixture mcl version particle filters combines regular sampler dual 
combining approach overcomes range limitations currently exist different versions mcl inability estimate posteriors highly accurate sensors poor degradation small sample sets ability recover unexpected large state changes robot kidnapping 
mixture mcl possesses range unique advantages previous localization algorithms capable global localization ambiguous features efficiency 
mixture mcl inherits computational efficiency particle filters focus computational resources areas probable 
versatility 
inherits particle filters ability approximate huge range non parametric densities accommodate arbitrary nonlinear system dynamics sensor characteristics non gaussian noise 
posterior centered small subspace state space 
mixture mcl require explicit parametric model subspace models subspaces implicitly generating samples accordingly 
resource adaptiveness 
implementation mixture mcl time number samples determined dynamically available computational time consecutive sensor measurements 
consequence software run different computer platforms adapts available computational resources 
robustness 
mixing regular forward sampling dual mixture mcl performs robustly range circumstances highly accurate sensors robot kidnapping small sample sets 
extensive experimental results suggest mixture mcl consistently outperforms mcl related markov localization algorithms 
article focused mobile robot localization problem conjecture basic algorithms transcend broader range state estimation problems temporal dynamic systems 
bayes filters applied estimation problems decades interest monte carlo approximations suggests probabilistic paradigm suited broad range state estimation problems noisy temporal domains 
article described limitations particle filtering context mobile robot localization envision estimation domains thrun artificial intelligence suffer similar problems overcome mixing particle filters duals 
authors de freitas arnaud doucet comments related substantially contributed presentation material 
scott lenser anonymous reviewers suggestions helped improving manuscript 
research sponsored national science foundation career number iis regular number iis darpa ato contract number darpa iso rome labs contract number gratefully acknowledged 
views contained document author interpreted necessarily representing official policies endorsements expressed implied united states government sponsoring institutions 
bar shalom fortmann tracking data association academic press new york 
bar shalom 
li estimation tracking principles techniques software ma 
bentley multidimensional divide conquer comm 
acm 
borenstein everett feng navigating mobile robots systems techniques peters wellesley ma 
burgard cremers fox hnel lakemeyer schulz steiner thrun experiences interactive museum tour guide robot artificial intelligence 
burgard fox cremers integrating global position estimation position tracking mobile robots dynamic markov localization approach proc 
ieee rsj international conference intelligent robots systems iros victoria bc 
burgard fox schmidt estimating absolute position mobile robot position probability grids proc 
aaai portland 
cox experiment guidance navigation autonomous robot vehicle ieee transactions robotics automation 
cox leonard modeling dynamic environment bayesian multiple hypothesis approach artificial intelligence 
cox wilfong eds autonomous robot vehicles springer berlin 
dean boddy analysis time dependent planning proc 
aaai san jose ca pp 

dellaert burgard fox thrun condensation algorithm robust vision mobile robot localization proc 
ieee international conference computer vision pattern recognition fort collins 
dellaert fox burgard thrun monte carlo localization mobile robots proc 
ieee international conference robotics automation icra detroit mi 
dellaert thorpe thrun mosaicing large number widely dispersed noisy distorted images bayesian approach technical report cmu ri tr carnegie mellon university pittsburgh pa 
thrun artificial intelligence dempster laird rubin maximum likelihood incomplete data em algorithm roy 
statist 
soc 
ser 

niemann combining computer graphics computer vision probabilistic self localization internal report 
doucet sequential simulation methods bayesian filtering technical report cued infeng tr cambridge university department engineering cambridge uk 
doucet de freitas gordon eds sequential monte carlo methods practice springer new york :10.1.1.51.7851:10.1.1.2.342
elfes occupancy grids probabilistic framework robot perception navigation ph thesis department electrical computer engineering carnegie mellon university pittsburgh pa 
engelson mcdermott error correction mobile robot map learning proc 
ieee international conference robotics automation nice france pp 

fox burgard dellaert thrun monte carlo localization efficient position estimation mobile robots proc :10.1.1.2.342
aaai orlando fl 
fox burgard kruppa thrun collaborative multi robot localization autonomous robots 
fox burgard thrun active markov localization mobile robots robotics autonomous systems 
fox burgard thrun markov localization mobile robots dynamic environments artificial intelligence res :10.1.1.116.6293

fukuda ito arai abe tanaka navigation system ceiling landmark recognition autonomous mobile robot proc 
internat 
conference industrial electronics control instrumentation vol 
pp 

gilks richardson spiegelhalter eds markov chain monte carlo practice chapman hall crc 

gutmann burgard fox konolige experimental comparison localization methods proc 
ieee rsj international conference intelligent robots systems iros victoria bc 

gutmann schlegel amos comparison scan matching approaches self localization indoor environments proc 
st euromicro workshop advanced mobile robots ieee computer society press 
heckerman tutorial learning bayesian networks technical report msr tr microsoft research revised november :10.1.1.36.8357
hertzberg kirchner landmark autonomous navigation pipes proc 
st euromicro workshop advanced mobile robots pp 

environment perception laser radar fast moving robot proc 
symposium robot control karlsruhe germany pp 

isard blake contour tracking stochastic propagation conditional density proc 
european conference computer vision cambridge uk pp 

isard blake condensation conditional density propagation visual tracking internat :10.1.1.36.8357
comput 
vision 
kristensen active global localisation mobile robot multiple hypothesis tracking proc 
ijcai workshop reasoning uncertainty robot navigation stockholm sweden pp 

julier uhlmann new extension kalman filter nonlinear systems proc 
aerosense th international symposium aerospace defence sensing simulation controls 
kaelbling cassandra kurien acting uncertainty discrete bayesian models mobile robot navigation proc 
ieee rsj international conference intelligent robots systems iros osaka japan 
kalman new approach linear filtering prediction problems trans :10.1.1.37.4334
asme basic engineering 
kanazawa koller russell stochastic simulation algorithms dynamic probabilistic networks proc 
th annual conference uncertainty ai montreal quebec 
thrun artificial intelligence kitagawa monte carlo filter smoother non gaussian nonlinear state space models computational graphical statistics 
koenig simmons passive distance learning robot navigation saitta ed proc 
th international conference machine learning bari italy 
kortenkamp bonasso murphy eds ai mobile robots case studies successful robot systems mit press cambridge ma 
le nguyen ha durrant whyte stevens autonomous zelinsky ed field service robotics springer london pp 

lenser veloso sensor resetting localization poorly modelled mobile robots proc :10.1.1.37.4334
ieee international conference robotics automation icra san francisco ca 
leonard durrant whyte directed sonar sensing mobile robot navigation kluwer academic boston ma 
leonard durrant whyte cox dynamic map building autonomous mobile robot internat 
robotics res 

liu chen sequential monte carlo methods dynamic systems amer 
statist 
assoc 

lu milios globally consistent range scan alignment environment mapping autonomous robots 
maccormick blake probabilistic exclusion principle tracking multiple objects proc 
international conference computer vision kerkyra 
ray tracing graphics extensions math 

mahadevan robust mobile robot navigation partially observable semi markov decision processes internal report 
maybeck stochastic models estimation control vol 
academic press new york 
mclachlan krishnan em algorithm extensions wiley series probability statistics wiley new york 
moore efficient memory learning robot control ph thesis trinity hall university cambridge cambridge 
moravec sensor fusion certainty grids mobile robots ai magazine 
nourbakhsh powers birchfield office navigating robot ai magazine 
hinton dudek mobile robot learns place neural computation 
pearl probabilistic reasoning intelligent systems networks plausible inference morgan kaufmann san mateo ca 
pitt shephard filtering simulation auxiliary particle filter amer 
statist 
assoc 

concurrent localisation map building mobile robots ultrasonic sensors proc 
ieee rsj international conference intelligent robots systems iros yokohama japan pp 

reuter mobile robot self localization proc 
ieee international conference robotics automation icra san francisco ca 
bekey bayesian estimation kalman filtering unified framework mobile robot localization proc 
ieee international conference robotics automation icra san francisco ca pp 

rubin sir algorithm simulate posterior distributions bernardo degroot lindley smith eds bayesian statistics oxford university press oxford uk 
stevens durrant whyte experiments autonomous underground guidance eds proc 
ieee international conference robotics automation icra albuquerque nm pp 

schiele crowley comparison position estimation techniques occupancy grids proc 
ieee international conference robotics automation icra san diego ca pp 

simmons goodwin haigh koenig sullivan layered architecture office delivery robots proc 
st international conference autonomous agents marina del rey ca 
thrun artificial intelligence simmons koenig probabilistic robot navigation partially observable environments proc 
ijcai montreal quebec pp 

smith gelfand bayesian statistics tears sampling resampling perspective american statistician 
smith self cheeseman estimating uncertain spatial relationships robotics cox wilfong eds autonomous robot springer berlin pp 

tanner tools statistical inference rd edn springer new york 
thrun bayesian landmark learning mobile robot localization machine learning 
thrun beetz burgard cremers dellaert fox hnel rosenberg roy schulte schulz probabilistic algorithms interactive museum tour guide robot minerva internat 
robotics res 

thrun fox burgard monte carlo localization mixture proposal distribution proc :10.1.1.142.1730
aaai austin tx 
robotics springer berlin 
wei von keeping track position orientation moving indoor systems correlation range finder scans proc 
international conference intelligent robots systems iros munich germany pp 

yamauchi beer spatial learning navigation dynamic environments ieee transactions systems man cybernetics part cybernetics special issue learning autonomous robots located www aic nrl navy mil yamauchi 
zilberstein russell approximate reasoning anytime algorithms natarajan ed imprecise approximate computation kluwer academic dordrecht 
