genetic programming multi agent layered learning reinforcements william hsu cis ksu edu department computing information sciences kansas state university manhattan ks usa adaptation standard genetic program gp hierarchically decomposable multi agent learning problems 
break problem requires cooperation multiple agents team objective function derive simpler intermediate objective function pairs cooperating agents 
apply gp optimize intermediate team objective function final population earlier gp initial seed population 
layered learning approach facilitates discovery primitive behaviors reused adapted complex objectives shared team goal 
method evolve agents play subproblem robotic soccer keep away soccer 
show layered learning gp evolves better agents standard gp including gp automatically defined functions problem decomposition results significant learning speed increase 
complex problems low level primitive operations robotic soccer ki intractable search direct solution genetic programming gp 
due part combinatorial explosion gp search space function problem state space size playing field 
svr factors operator granularity contribute growth 
gp researchers worked robotic soccer simplified gp search space problem redefinition raising level terminals order evolve higher level behaviors lu sophisticated fitness function :10.1.1.36.136
robotic soccer multi agent system mas problem real game played humans helpful compare learning strategies human teams different approach automatically develop solution 
important observation steven gustafson smg cs nott ac uk school computer science information technology university nottingham campus nottingham uk ng bb structure team training real soccer involves individual pair small group drills resulting welldefined hierarchy behaviors 
traditional gp produces hierarchical programs evolving reusing automatically defined functions adfs 
ko rb show layered learning achieve reuse faster reliably gp adfs developing solution mas subproblem robotic soccer 
just adfs provide reusable code subroutine structure ko layered learning provides way build solutions divide andconquer approach st sv 
difference adf learning layered learning gps methods layered learning describes way train learning intelligent agent adfs describe way implement structure agent representation code 
llgp gh break mas learning tasks evolving solutions smaller fitness cases smaller groups agents primitive fitness criterion 
adaptation layered learning gp part stone veloso reinforcement learning sv similar approaches developed perform sequential evolution populations different fitness functions de hhc 
extends previous study llgp mas task robotic soccer domain gh experiments analysis ll behavior 
focus automatic tuning validation intermediate representations incremental ll 
purpose test bed facilitate development fitness criteria coaching training agents strictly cooperative performance agent task 
evolved individuals seed population agents improved way competitive interaction fourth agent opponent 
new population associated gp form second layer llgp system 
product llgp agent evolved highly fit primitive agents necessarily contain exact copies primitive agents subroutines 
advantage layered learning provides logical methodology implementing hierarchical approach teamwork 
order evolve complex teamwork may able take advantage dependency behaviors involving teammates primitive behaviors involving just 
example low level primitive soccer passing ball agent activity incorporated multi agent activities guarding ball moving ball setting goal attempt rest shall explore llgp mas problems keep away soccer subproblem robotic soccer sv gh shows complex teamwork hierarchical nature learned efficiently hierarchical fashion 
keep away soccer domain definition justification call keep away soccer away defensive player attempting 
keep away soccer learning test bed mas 
captures compositional element teamwork composing refining passing behaviors achieve full keep away soccer behavior occurs real robotic soccer 
objectives soccer moving ball attempting score crucial study basic low level mas 
allows easily adjust opponent difficulty 
screen capture simulator 
offensive agents defender ball moves trajectory 
strong compositional element learning pass ball effectively part keep away soccer learning task 
real soccer human players learn minimize number offensive opponent passing accurately move receive pass open receive pass control ball effectively 
agents coordinate effectively able possession ball select teammate pass time pass appropriately maintain open passing lane 
shows text mode screen capture simple program visualize animate games keep away soccer 
depicts offensive agents passing ball counterclockwise motion agent passes ball twice defender 
trail ball denoted 
symbols show paths agents respectively 
simulation visualization run time steps collect screen capture 
mas variants robotic soccer exist keep away soccer belongs category multi agent learning homogeneous agents sv share identical code direct channels communication observing behavior teammates 
type problem requires robust autonomous solutions interesting framework teamwork learning 
soccer analyzed human robotic game broken skill optimization subproblems ball control passing moving 
keep away soccer decomposed manner 
natural way reduce complex mas problems investigated keep away soccer generalize cooperative mas problems ta 
problem specification test beds robotic soccer playing agents framed robocup competition kak 
rich experimental environments mas research areas including flexible teamwork learning methodologies including hierarchical sensing reinforcement learning learning temporal differences team partitioned algorithms sv artificial neural networks genetic programming 
hand coded hybrid learning techniques employ large amount hand coded domain specific knowledge outperform strategies learned automatically 
keep away soccer offensive agents located rectangular field ball defensive agent 
defensive agent moves twice quickly offensive agents ball passed moves twice quickly defensive agent 
similar problem ls agent required solve problem 
objective soccer minimize number times ball turned defender 
turnover occurs discrete time step defender grid unit ball 
subsidiary objectives offensive order minimize 
think keep away soccer consisting layers behavior passing accurately defensive agent moving passing defender minimize number occur game 
layers behaviors come view soccer heavily dependent domain knowledge 
types behavior important playing keep away soccer operational definition necessarily give way measure effectiveness team agents just played keep away soccer useful finding fitness function 
application layered learning gp explain keep away soccer illustrative test bed llgp 
layered learning layered learning intelligent agents literature st sv describe task driven incremental approach acquiring hierarchies behaviors reinforcement learning 
de garis de introduced similar concept called behavioral memory genetic algorithm encoded neural networks 
weights signs networks evolved behavior construct new population evolved second behavior 
initial network persisted solutions new behavior 
schoenauer sx applied concept constrained genetic algorithm optimization 
harvey hhc layered incremental learning approach robot control vision navigation system 
authors achieved sequentially evolving population range targets simple complex 
manjunath wm eriksson er analyzed approach incremental learning 
dorigo dc developed hierarchical learning system somewhat different layered learning adapted 
method inputs processing elements organized hierarchy simple complex layers incrementally trained frozen 
similar previous applied domains robot soccer identical layered learning behavioral memory methods arrest learning particular portion hierarchical model 
applying layered learning paradigm problem consists breaking problem hierarchy subproblems 
original problem solved sequentially learning results member problems layer layer 
conceptually similar divide conquer learning paradigms key difference structure solution necessarily reflect procedural hierarchy training 
example programs evolved subtask llgp seed initial population layer may incorporated verbatim solution adfs 
type hierarchical solution different type adf gp learning proposes find focuses code reuse structure subtasks learned 
problems attempt achieve human competitive behaviors ko robotic soccer keep away soccer lend bottom decomposition 
human task learning especially cooperative multi agent behavior occurs bottom fashion individuals small groups learn smaller tasks compose coordinate solve larger tasks 
problem type biologically motivated method gp natural bottomup decomposition problem simulates aspect human learning allows gp learn smaller problems 
table variant table sv adapted correlate prerequisite layered learning property genetic programming keep away soccer 
table requirements layered learning gp keep away soccer justifications 
layered learning genetic programming 
learning raw input tractable 
bottom decomposition 
learning occurs independently level 
output layer feeds layer input complex mas problems gp need defined multiple levels mas learning task compositional layer independently population generation layer layer initial population modify standard gp layered learning need develop learning objective layer fitness layer selects ideal individuals subtask 
seen lu single objective fitness value leads best performance easier trying define multi objective fitness functions :10.1.1.36.136
multi objective fitness functions allow gp evolve complex behaviors difficult decide components fitness important solution 
preliminary experiments infeasible develop set pareto optimization criteria weighted function multiple objectives keep away soccer 
chose focus automatically discovering compose passing agents keep away soccer agents 
issue addressed layered learning gp transfer population generation previous layer initial population 
ideal team consist individuals high fitness coordinated mas task 
population certain individuals better fitness 
consider copying best individual seeding entire initial population subsequent layer 
duplication removes diversity evolved previous layer may detrimental best individual subtask may suboptimal problem solver coordinated team activity 
designed experiments llgp duplicates best individual simply copies entire population 
final issue address llgp learning speed improvement degree layered learning simplify learning problem allowing target fitness reached faster standard gp 
increase slope learning speed curve ka distinguished speed learning efficiency learned problem solver improved 
show layered intermediate team fitness objectives achieve greater learning speed monolithic fitness objective keep away soccer test bed 
demonstrate technique empirically choosing point learning primitive mas behaviors switch high level mas behavior 
gp experiment design designed initial gp experiments investigate benchmark performance llgp standard gp sgp gp adfs llgp best individual duplicated fill initial populations llgp best llgp entire final population layer seed llgp 
sgp single monolithic non layered fitness function minimizing number occur simulation 
allows tree kicking moving additional trees represent adfs adf call second access full function set available sgp 
llgp best llgp layers fitness objective layer maximize number accurate passes agent task evaluated teams copies individual size field keep away soccer task fitness objective second layer minimize number 
developed variations experiment maximum generation values 
stopping criterion variations achieved ideal fitness measure fewer turnover turns better maximum generation reached 
preliminary experiments indicated population size yielded results keep away soccer domain sgp 
generation sgp achieved better convergence fitness individual size generation sgp negligible fitness improvement generations 
genetic crossover operator generates percent generation tournament selection generates percent 
ko tournament size maximum depth 
table summarizes terminal set consisting vectors egocentric relative agent tree evaluated 
table summarizes function set functions operate return vectors 
sets similar lu :10.1.1.36.136
table keep away soccer terminals egocentric vectors terminal description defender vector opponent mate vector teammate mate vector second teammate ball vector ball table keep away soccer function set function arguments description rotate rotate current vector degrees random counter clockwise new random vector magnitude current value negate reverse vector direction div divide vector magnitude mult multiply vector magnitude add vectors subtract vectors gp system developed luke called evolutionary computation java lu 
simulator developed keep away soccer abstracts low level details agents playing soccer ba environment turn abstracts low level details environment 
abstractions type allow keep away soccer simulator incorporated learn strategies environment 
players push ball maintain possession 
kick ball player needs certain distance 
keep away soccer eliminate need low level ball possession skills allow offensive agents possession ball 
agent possession lose possession kicking ball evaluating kick tree 
vectors direction magnitude implementation allow dribbling actions learned agent simply passes ball units away 
abstraction greatly simplifies problem allows wide range behaviors learned 
simulation step allows agents act agent possession ball agent ball occupy grid position agent kick tree evaluated 
kick tree evaluates vector gives direction distance kick ball 
agent move tree evaluated 
trees composed terminals listed table functions listed table 
layered learning experiments percent maximum number generations spent layer learning accurate passing defender 
evaluate accurate passes count number passes location grid units agent 
fitness function intermediate objective passes time steps simulation fitness best worst 
remaining percent generations spent layer fitness value inversely proportional number occur defender 
team objective 
defender uses hand coded strategy standard ba defensive agents moves ball cause turnover 
evaluation individual simulator takes time steps ball move step defender moves time step offensive agents move fourth time step 
initial configuration simulation places defensive agent center unit grid 
field partitioned sections top half bottom left right quadrants 
offensive agent placed randomly section ball placed units offensive agents chosen random 
early runs system resulted local optima achieved common control policy offensive agents crowded ball prevent defender stealing causing turnover 
eliminate loophole defender blocked ball move offensive agent ball simply trading places opponent adjacent grid 
results experiment run times averages taken runs 
experiments achieved best convergence behavior generations baseline sgp llgp variants 
table shows initial experimental results 
average represents average best runs selected 
experiments converged clusters fitnesses better sgp worse 
considered individual size cluster poor cluster contains individuals half number nodes individuals cluster 
prefiltering runs individual size may appropriate remedy scope focusing llgp 
report averages show llgp achieve performance high cluster shown table llgp experiment divided generations layer successful pass criterion layer minimum turnover criterion 
copy best represents llgp best seeding method layer copy llgp method 
initial results indicate notable advantage disadvantage llgp indicating obtain comparable solutions llgp sgp 
table results experiments population size max generations averaged runs 
lower anti fitness values better 
best gen mean gen avg 
ind sz 
gen gen best run sgp llgp avg 
avg 
copy best copy best fitness table results different layer durations population size averaged runs 
lower anti fitness values better 
layer start generation gen gen best gen best run learning speed curves step generation 
layer learning speed curves starting layer different layer durations 
lower better 
hypothesized realizing full improvement learning speed achieved llgp 
test hypothesis plotted layer learning speed curves ka shown table llgp configurations generations layer layer 
versions llgp achieve better convergence start layer 
accounting early start see convergence rate faster final fitness better llgp layer lasts generations 
ran second series layer learning speed curves step indicated learning rates significantly different 
evaluated inherent benefit generalization quality overfitting control reusability stopping layer earlier may question experimentation 
population size fitness curves performance similar reported gu 
note learning speed curve layer duration plotted equivalent sgp sgp runs generations team objective function layer fitness 
table results experiments population size max generations averaged runs 
lower anti fitness values better 
sgp llgp best gen mean gen avg 
ind sz 
gen st gen best run having llgp exhibited better learning speed curve repeated llgp experiment population size able match performance converged quickly gp resulted lowest best run fitness values fewer simulation 
result shown table sgp results repeated comparison 
note layer individuals larger llgp llgp 
stopping layer early yields slight improvement fitness significant improvement learning speed necessarily result streamlined agent code 
intuitive learning deferred layer passing behavior incorporated sophisticated keep away agents 
shown layered learning genetic programming evolve intelligent agents cooperative mas task keep away soccer quickly better fitness 
additionally layered learning gp allows natural decomposition mas learning problem subproblems easily solved gp 
keep away soccer problem test bed abstracting away complexities simulated soccer allows different gp methods evaluated relative merits compared 
easily extended full game robotic soccer highly portable platforms simulator ba lu written java 
conceptually success llgp success human soccer teams 
successful teams usually players unique strategies learning took place bottom fashion individuals learned play pairs small groups coordinated team 
llgp experiments simulate kind behavior attempt minimize number generations needed layer 
results indicate layered learning gp yields benefits standard gp handcoded hierarchical approaches depend large volume domain knowledge 
easier natural team fitness function derive intermediate fitness function evolve primitive mas agents higher level layer gp discover compose refine primitive mas behavior complex mas behavior 
considered extensions research 
developing full scale team robocup competition llgp way test abilities thoroughly focus evaluating mas task decomposition improvement learning accuracy learning speed 
diversity populations interesting issue continuing research llgp investigates llgp promotes diversity 
related question code versus refining higher layers 
interesting modifications include developing heterogeneous teams adding additional higher level layers adfs layered learning gp 
acknowledgments support research provided part army research lab arl pet imt ksu office naval research 
edmund burke providing support second author continuing 
sean luke providing help gp library develop system 
andre 
manual ver 
rev 
available world wide web www robocup org 
asada 
overview robocup 
robocup robot soccer world cup ii lecture notes artificial intelligence vol 

new york ny 
springer verlag andre teller 
evolving team darwin united 
robocup robot soccer world cup ii lecture notes artificial intelligence vol 

springer verlag new york ny 
ba balch 
software documentation 
available world wide web www org 
de 
genetic programming building artificial nervous systems genetically programmed neural network modules 
porter editors proceedings seventh international conference machine learning icml 
dc dorigo colombetti 
robot shaping experiment behavior engineering 
mit press bradford books 
er eriksson 
initial analysis ability learning maintain diversity incremental evolution 
freitas editor data mining evolutionary algorithms 

hhc harvey husbands cliff 
seeing light artificial evolution real vision 
cliff editors animals animats proceedings third international conference simulation adaptive behavior 
mit press bradford books boston ma 
gh gustafson hsu 
layered learning genetic programming cooperative robot soccer problem 
miller editors proceedings european conference genetic programming 
lake como italy 
springer verlag 
ka kadie 
seer maximum likelihood regression learning speed curves 
ph dissertation university illinois urbana champaign technical report uiuc dcs 
august 
kak kitano asada kuniyoshi noda osawa 
robocup robot world cup initiative 
proceedings international joint conference artificial intelligence ijcai workshop entertainment ai alife 
montr canada 
ki kitano 
robocup synthetic agent challenge 
proceedings international joint conference artificial intelligence ijcai nagoya japan 
ko koza 
genetic programming programming computers means natural selection 
mit press cambridge ma 
ko koza 
genetic programming ii automatic discovery reusable programs 
mit press cambridge ma 
ko koza 
genetic programming iii darwinian invention problem solving 
morgan kaufmann los altos ca 
ls luke spector 
evolving teamwork coordination genetic programming 
genetic programming proceedings annual conference 
koza eds 

mit press cambridge ma 
lu luke :10.1.1.36.136
genetic programming produced competitive soccer softbot teams robocup 
proceedings third annual genetic programming conference gp 
koza eds 

morgan kaufmann los altos ca 
lu luke 
issues scaling genetic programming breeding strategies tree generation code bloat 
ph dissertation department computer science university maryland college park md 
matsubara noda 
learning cooperative actions multi agent systems case study pass play soccer 
adaptation coevolution learning multiagent systems papers american association artificial intelligence aaai spring symposium aaai technical report ss 
aaai press menlo park ca 
rb rosca ballard 
hierarchical self organization genetic programming 
proceedings eleventh international conference machine learning icml 
morgan kaufmann los altos ca 
st stone 
layered learning multiagent systems winning approach robotic soccer 
mit press cambridge ma 
sv stone veloso 
layered approach learning client behaviors robocup soccer server 
applied artificial intelligence aai 
taylor francis london uk 
sv stone veloso 
layered learning 
proceedings eleventh european conference artificial intelligence ecai 

sv stone veloso 
multiagent systems survey machine learning perspective 
autonomous robots 
kluwer academic publishers norwell ma 
svr stone veloso riley 
cmunited champion simulator team 
robocup robot soccer world cup ii lecture notes artificial intelligence vol 

springer verlag new york ny 
sx schoenauer 
constrained ga optimization 
forrest editor proceedings fifth international conference genetic algorithms icga 
morgan kaufmann san mateo ca 
ta tambe 
flexible teamwork 
journal artificial intelligence research 
tambe erdem kaminka marsella muslea 
building agent teams explicit teamwork model learning artificial intelligence 
elsevier 
wm manjunath 
incremental evolution genetic programming 
koza editor genetic programming proceedings third annual conference 
morgan kaufmann san mateo ca 
