accurate real time lip tracking robert andrew blake dept engineering science university oxford oxford ox pj uk human speech inherently multi modal consisting audio visual components 
researchers shown incorporation information position lips acoustic speech recognisers enables robust recognition noisy speech 
case hidden markov show happens visual signal stabilises alignment states 
shown lips inner outer contours robustly tracked real time general purpose workstations 
accomplish efficient algorithms employed contain key components shape models motion models focused colour feature detectors learnt examples 
motivated complementary nature visual information human speech perception researchers shown incorporation visual information acoustic speech recognisers improves recognition performance especially acoustically noisy environments 
obvious appeal visual channel somewhat orthogonal acoustic channel visual signal unaffected presence background noise cross talk speakers 
promise audio visual speech recognition lies ability extend computer speech recognition adverse environments offices airports train stations inside automobiles hurdles overcome audio visual speech recognition systems commercial viable 
systems capable tracking lips inner outer contour reasoning presence absence position teeth tongue unconstrained speakers 
robust variations lighting shadowing 
furthermore tracking yield information discriminate various recognition units words phonemes tri phones 
extracted visual information intelligently integrated acoustic features presumably proportion information content channel 
course accomplished real time applications dealing man machine interfaces afford opportunity line processing 
tracking approach unique making fullest available visual information 
ensured learning characteristics moving lips 
learnt models lip shape motion visual appearance 
optimal information way ensures tracking algorithm efficient possible 
lip tracking problem accurately tracking rapidly moving articulating lips formidable 
task difficult computational time constraints required intended applications audio visual speech recognition lip synchronisation animation expression recognition considered 
lip trackers build pioneering snake approach kass terzopoulos deformable template methods yuille 
audio visual speech recognition systems developed bregler colleagues comprehensive systems developed date utilise kass snake approach shape constraints imposed possible contour deformations 
track outer lip contour restricting allowable lip shapes lie manifold learnt training sequences lip shapes 
despite impressive performance outer lip contour distinctive give reasonable recognition performance 
due image forces consisting grey level gradients known inadequate identifying outer lip contour 
researchers employ pared versions yuille iterative gradient descent minimisation deformable templates track inner outer lip contours 
interest computational efficiency full complement image potential fields heuristic constraints penalty terms proposed yuille abbreviated set typically resulting reduction processing time minutes frame second frame 
trade computational savings comes cost decreased tracking accuracy 
currently tracker capable tracking lips real time inner contour tracker petajan 
relying prior models deforming lips cleverly utilise fact human nostrils represent dark spots face 
nostrils seen anatomical constraints concentrate image processing eye region determine head tilt angle rectangular window mouth 
colour thresholds identify black area inner mouth region neighbouring pixels compared teeth coloured templates 
contour grown area identified inner mouth 
drawback system relies having clear view nostrils available applications camera mounted look speaker may satisfied general viewing conditions face typical fronto parallel views 
audio visual speech recognition previous assisted lips demonstrated visual information extracted outer lip contour provide robust recognition speech presence acoustic noise 
hmm recognition inclusion visual signal tends stabilise viterbi state alignment 
demonstrated incorporation visual information enables correct audio visual recognition noisy speech 
earlier extended ways 
difficult problem tracking lips resolved focused feature search mechanisms capture additional discrimination potential inherent colour imagery 
second tracking inner outer lip contours accomplished facilitates extraction information teeth tongue 
dynamic contour tracking lip trackers described descendants blake dynamic contour tracker 
real time performance obtained sparse representation window number edward clean waveform audio clean window number edward db noise waveform audio noisy window number edward db noise waveform audio visual noisy acoustic information inadequate accurately identify noisy speech 
shown viterbi state alignments correctly incorrectly recognised renditions clean noisy edward 
speech recognition deteriorates noise introduced correct viterbi state alignment disrupted 
incorporation visual information restore alignment 
lip contours splines combined kalman filter utilising prior shape motion models deforming lips 
motion lips represented coordinates spline control points varying time 
stability tracker obtained constraining lip movements deformations shape space lip template 
deformations contour represented control point vector spline space restricted lie shape space represented shape vector transformations shape vectors control point vectors applying matrices gamma gamma wq shape matrix composed basis vectors corresponding deformations template pseudo inverse 
motion dynamics learnt maximum likelihood ml estimation algorithm representative sequences connected speech 
kalman filter provides temporal continuity blending predicted lip position measurement observation features taken image 
interest speed search image features confined dimensional search lines normals lip curve 
image feature detection identifying features inner outer lip contours reliably accurately localise respective boundaries grey level images 
case outer lip contour principal difficulty lips set flesh tones consequently weak contrast discriminating edges 
different problem arises attempting identify inner lip contour boundary high contrast dark area inside mouth surrounding lips 
teeth come view distracting edges inner mouth difficult identify sought boundary 
complicating matters edge lips inner mouth changes sign teeth disappear re appear 
bayesian classification human skin colour primarily determined amount skin blood beneath layer 
usually restricted range hues 
fact variation skin colour members race small effectively identify people variety images proven effective locating faces initialising face trackers 
typically colour information provide coarse identification regions face sophisticated image processing fine tune positioning facial features 
shown pattern classification techniques applied colour images face accurately pinpoint lip boundaries overcoming limitations inherent greyscale images 
identification boundary lips surround formulated pattern classification grey level profiles search line position intensity grey level edges inadequate identifying lip contours 
little contrast boundary lower lip surrounding skin note lack features 
alternately numerous distracting edges inside mouth due presence teeth 
graph shows intensity profiles search lines lower lip 
absence sharp jump sudden change similarly demonstrates difficulty delineating lip boundary 
actual location lower lip boundary corresponds position problem 
specifically desired classify pixels came lips neighbouring regions 
surrounding facial skin inner mouth region 
bayesian framework colour pixel represented vector red green blue intensities classified belonging lips posteriori probability greater corresponding posteriori probability surrounding skin 
class conditional probability densities xj 
represents class pixel originated 
skin lips known learnt training images bayes rule compute corresponding posteriori probabilities 
standard parametric non parametric techniques learn underlying class conditional densities xj 

bear mind posteriori probabilities 
jx evaluated pixel search line time step 
order approach usable practical real time systems premium placed line processing time required discriminate classes 
fisher linear discriminant analysis determine boundary lips facial skin identify outer lip contour 
fisher linear discriminant case class discrimination problem distinguishing lips skin fisher linear discriminant analysis determine axis vector colour data projected preserves capability colour information possible 
resulting fisher linear discriminant maximises separability classes 
compelling aspect approach discriminating power colour data exploited providing degree invariance changes illumination 
learning fisher discriminant done line minimal additional computational load incurred tracking scalar feature detectors resultant fisher projection 
facial images representative encountered tracking learn fisher discriminant axis algorithm shown 
examples im 
calculate mean colour class xk 
determine class scatter matrices xk gamma gamma 
find fisher discriminant vector gamma gamma sw learning fisher linear discriminant axis 
discriminant vector learnt sample colour image data classes lips facial skin maximises separability classes maximising ratio class scatter class scatter 
ages acquired different days uncontrolled office environment overhead fluorescent lighting training data 
general case separate fisher axis computed search line normal practice biological consistency lips skin permit computation fisher axes corresponding right left portions upper lower lips 
hue locate humans skin faces scenes instructive see fisher discriminant provides additional benefit hue filtered images 
shows sample image colour hue image resultant image projection fisher axis 
hue channel shows high contrast localisation lip boundary poor 
fisher discriminant hand results image contrast localisation lip boundary 
greyscale image hue image fisher discriminant fisher discriminant analysis enhance contrast face lips 
greyscale images little contrast face lips particularly lower lip 
differing hue lips skin provide additional contrast coarse identification lip skin boundary available 
projection fisher axis enhances contrast enables identification boundary 
inner outer lip contour tracking known perceptual studies human rely information presence absence teeth tongue inside mouth natural try extract information visual images 
simplest case entire region bounded outer lip contour 
mouth extracted tracking pixels intensities inputs recognition engine 
achieved recognition performance pixel intensities directly applications controlled lighting conditions 
approach may prove effective natural settings recognition performance depend ability classifier generalise lighting changes compensate tracking errors 
interesting approach attempt extend dynamic contour tracking framework task tracking inner outer lip contours 
permit extraction region inside mouth accurately reason proportion teeth visible position tongue visible 
hybrid system utilising contour information mouth region data provide best recognition results 
dynamic contour framework extended task tracking contours inner outer lips constraints restricted shape space section 
shape matrix learnt principal component analysis sample lip shapes coupling inner outer contours directly encoded shape matrix 
identification inner mouth region principal difficulty tracking inner mouth contour erratic appearance disappearance teeth 
teeth obscured lips edge intensity valley inner lip contour teeth visible numerous edges inside mouth serve distract tracker 
method overcoming problem statistical models intensity profiles capable handling multi modal distributions account intermittent presence teeth tongue 
extending appearance modelling cootes 
alternate solution bayesian classification approach feature detection done earlier fisher linear discriminant 
modelling distribution colour pixel intensities facilitated observation prominent components inside mouth corresponding dark region teeth upper lower tongue 
image components necessarily suggested straightforward method modelling intensity distribution inside mouth mixture multi variate gaussians 
expectation maximisation em algorithm provide maximum likelihood ml estimates mixture weights underlying gaussian parameters 
approximately training images teeth tongue teeth dark portion inner mouth gathered various lighting conditions similar expected encountered tracking 
kmeans clustering provide initial estimates parameters 
gives overview parameter estimation algorithm 

select initial cluster centres mm 
initialise estimates means clustering xk gamma sigma xk gamma gamma 
iterate expectation maximisation gamma kjx gamma kjx sigma gamma kjx gamma gamma proportional change ffl mixture 
expectation maximisation learning mixture parameters representing colour intensity distribution inside mouth 
colour intensities upper lower lips modelled single gaussian mixtures gaussians 
gaussian may sufficient capture subtle intensity variations lip regions coarse representation needed adequately discriminate lip coloured pixels inside mouth 
temporal coherence provided kalman filter ensures pixels mouth region inspected permitting class discrimination solution opposed complicated multi class discrimination solution 
fisher discriminant axes identify lip skin boundary colour mixture models locate inner contour boundary integrated dynamic contour tracking framework enables accurate tracking continuous speech realtime rates hz standard workstation silicon graphics indy mhz 
gamma 
ou ee gamma 
ou ee fourteen average grey level tracking word fourteen 
inner outer contour trackers follow respective lips sequence 
tracker successfully handles nearly closed mouth appearance teeth 
underlying plot shows average grey level intensity inside mouth 
informative onset signalled rapid increase intensity 
summary combination powerful techniques shown permit accurate real time tracking lips 
comprehensive shape motion models provide global structure motion coherence enable focused image feature detection methods 
feature detectors employ discriminant analysis bayesian classification methods colour images provide fast accurate identification boundary lips surround 
successful tracking inner outer lip contours enables additional reasoning presence absence teeth tongue permit recognition benefits obtained visual channel 
blake isard reynard 
learning track visual motion contours 
artificial intelligence 
bregler konig 
robust speech recognition 
proc 
int 
conf 
acoust speech signal processing pp 
adelaide 
cootes taylor lanitis cooper graham 
building flexible models incorporating grey level information 
proc 
th int 
conf 
computer vision pp 

dempster laird rubin 
maximum likelihood incomplete data em algorithm 
stat 
soc 
meier waibel 
automatic lip reading speech recognition 
proc 
int 
conf 
acoust speech signal processing 
duda hart 
pattern classification scene analysis 
john wiley sons 
marcus venkatesh prasad david stork 
automatic speech recognition system visual signals 
th asilomar conference signals systems computers 
ieee computer society press 
kass witkin terzopoulos 
snakes active contour models 
proc 
st int 
conf 
computer vision pp 


lip tracking audio visual speech recognition 
phd thesis university oxford 
dalton blake 
real time audio visual speech recognition applications 
proc 
th european conf 
computer vision pp 
cambridge england apr 
petajan graf 
robust face feature analysis fo automatic character animation 
international conference automatic face gesture recognition pp 
oct 
pitas 
segmentation tracking faces color images 
international conference automatic face gesture recognition pp 
oct 
summerfield macleod mcgrath 
lips teeth benefits lipreading 
young ellis editors handbook research face processing pp 

elsevier science publishers 
yuille 
feature extraction faces deformable templates 
int 
journal computer vision 
