headline generation statistical translation michele banko computer science department johns hopkins university baltimore md banko cs jhu edu extractive summarization techniques generate document summaries shorter single sentence required 
ideal summarization system understand document generate appropriate summary directly results understanding 
practical approach problem results approximation viewing summarization problem analogous statistical machine translation 
issue generating target document concise language source document verbose language 
presents results experiments approach statistical models term selection term ordering jointly applied produce summaries style learned training corpus 
generating effective summaries requires ability select evaluate order aggregate items information relevance particular subject particular purpose 
previous summarization focused extractive summarization selecting text spans complete sentences paragraphs original document 
extracts mittal xerox parc coyote hill road palo alto ca usa 
mail parc xerox com michael witbrock initial system performed whilst just research 
mittal just research henry street pittsburgh pa mittal com michael witbrock lycos pond road waltham ma lycos com arranged linear order usually order original document form summary document 
possible drawbacks approach focus inability generate coherent summaries shorter smallest considered usually sentence paragraph 
problem situations short headline style indicative summary desired 
cases important information document scattered multiple sentences problem extractive summarization worse sentences ranked best summary selection tend longer average sentence document 
describes alternative approach summarization capable generating summaries shorter sentence examples 
building statistical models content selection surface realization 
reviews framework discusses pros cons approach examples corpus news wire stories presents initial evaluation 
related previous summarization focused extractive methods investigating issues cue phrases luhn positional indicators edmundson lexical occurrence statistics mathis probabilistic measures token salience salton implicit discourse structure marcu 
combining information extraction phase followed generation reported instance system dejong templates time beam new customers beam dell computer products beam new power macs strategy beam apple sell macintosh users beam new power macs strategy internet beam apple sell power macs distribution strategy beam new power macs distribution strategy internet products beam apple sell power macs distribution strategy internet beam sample output system variety target summary lengths single input document 
formation extraction presentation 
summarizers sophisticated strategies revision mckeown jing mckeown mani sophisticated grammar generation radev mckeown 
reported closely related statistical machine translation particularly ibm style brown 
approach statistical translation model mapped sets words source language sets words target language time ordering model constrain possible token sequences target language likelihood 
similar vein summarizer considered translating languages verbose succinct berger lafferty witbrock mittal 
definition translation summarization lossy consequently somewhat easier design experiment 
discuss built models varying complexity simplest reasonably summarization severely deficient traditional translation 
aware related builds complex structured models syntax trees compress single sentences knight marcu differs level compression possible ii accuracy possible 
system language generation task summarization conceptually modeled consisting major sub tasks content selection surface realization 
parameters statistical models tasks estimated training corpus approximately reuters news wire articles politics technology health sports business 
target documents summaries system needed learn translation mapping headlines accompanying news stories 
documents preprocessed training formatting mark information font changes sgml html tags removed punctuation removed 
apart steps normalization performed 
processing lemmatization useful producing smaller better language models evaluated 
content selection content selection requires system learn model relationship appearance features document appearance corresponding features summary 
modeled estimating likelihood token appearing summary tokens possibly different tokens appeared document summarized 
simplest zero level model relationship case tokens proportion documents summary lengths headlines length words distribution headline lengths early reuters news stories 
document summary identical 
computed conditional probability word occurring summary word appeared document represent bags words headline document contain 
parameters content selection model estimated suitable document summary corpus model compute selection scores candidate summary terms terms occurring particular source document 
specific subsets terms representing core summary content article compared suitability generating summary 
done levels likelihood length resulting summaries source document likelihood forming coherently ordered summary content selected 
length summary learned function source document 
simplest model document length fixed length document genre 
discussions model chosen 
shows distribution headline length 
seen gaussian distribution model lengths quite accurately 
simplify parameter estimation content selection model assume likelihood word summary independent words summary 
case probability particular candidate calculated simply product probabilities terms candidate set 
probability candidate summary consisting words simplest zero level summary model previous assumptions computed product likelihood terms selected summary ii length resulting summary iii sequencing terms content set 
general probability word appearing summary considered independent structure summary independence assumption initial modeling choice 
surface realization probability particular surface ordering headline candidate computed modeling probability word sequences 
simplest model bigram language model probability word sequence approximated product probabilities seeing term immediate left context 
probabilities sequences seen training data estimated back weights katz 
mentioned earlier principle surface linearization calculations carried respect textual spans characters take account additional information phrase level 
course extended higher order grams providing sufficient numbers training headlines available estimate probabilities 
search content selection summary structure generation separately reason occur independently fact current implementation simultaneously contribute weighting scheme ranks possible summary candidates 
score ranking obtained weighted combination content structure model log probabilities 
cross validation learn weights particular document genre 
generate summary necessary find sequence words maximizes probability content selection summary structure models generated document summarized 
simplest model discussed summary term selected independently summary structure model order markov possible viterbi beam search forney efficiently find near optimal summary 
statistical models require different heuristic search algorithm 
example results search candidates various lengths shown 
shows set headlines generated system run real news story discussing apple computer decision start direct internet sales comparing strategy computer makers 
experiments discussed section beam width minimum beam size states 
experiments tried strongly discourage paths repeated terms reweighting backtracking state bigrams start repeating overwhelm search reweighting violates order markovian assumptions harm 
experiments zero level model system trained approximately news articles reuters dated jan jun 
punctuation stripped contained unique tokens articles slightly tokens headlines 
representing pairwise conditional probabilities combinations article headline words added significant complexity simplified model investigated effectiveness training limited vocabulary set words appeared headlines 
conditional probabilities words headlines appeared articles computed 
discussed earlier zero level model system trained bigram transition probabilities approximation headline syntax 
sample output system simplified model shown figures 
zero level performance evaluation zero level model discussed far works surprisingly strong independence assumptions limited vocabulary 
problems due lack sufficient training data 
ideally want evaluate system performance terms content selection success realization quality 
hard computationally evaluate coherence phrasing effectiveness date restricted content aspect amenable quantitative analysis 
experience doing laborious human eval requires matrix entries gb memory 
requirement significantly reduced threshold prune values sparse matrix representation remaining pairs 
inertia easy availability cmu cambridge statistical modeling toolkit generates full matrix far prevent exercising option 
alternative approach limiting size mappings need estimated top words small value hundreds thousands words appearing headlines 
limit size model allowing flexible content selection 
estimate approximately mb training data give reasonable estimates models evaluate access 
headline pushes mideast peace headline president clinton met top mideast including secretary state peace dennis ross preparation session israel prime minister benjamin netanyahu tomorrow 
palestinian leader meet clinton week 
published reports israel say netanyahu warn clinton israel withdraw percent west bank scheduled pullback clinton wants percent pullback 
clinton clinton wants clinton netanyahu clinton mideast peace clinton meet netanyahu clinton meet netanyahu israel sample article original headline system generated output simplest zero level lexical model 
numbers right log probabilities string search beam size respectively 
uation plan statistical approach model producing summaries competitive alternative approaches 
training system evaluated separate previously unseen set reuters news stories distributed evenly topics training set 
stories headlines generated variety lengths compared actual headlines ii sentence ranked important summary sentence 
interesting helps suggest degree headlines different vocabulary story 
term summarizer test gen headline word percentage length words overlap complete matches table evaluating simplest lexical model content selection reuters news articles 
headline length overlap terms target headline generated summary maximized 
percentage complete matches indicates summaries length terms included target headline 
lap generated headlines test standards actual headline summary sentence metric performance 
news article maximum overlap actual headline generated headline noted length overlap maximal taken account 
tallied counts headlines matched completely words generated headline actual headline lengths 
statistics illustrate system performance selecting content words headlines 
actual headlines ungrammatical incomplete phrases 
sophisticated language models structure models chelba chelba jelinek longer ngram models lead system generating headlines similar phrasing real headlines longer range dependencies shelf carnegie mellon university summarizer top ranked extraction summarizer news stories darpa tipster evaluation workshop tip 
summarizer uses weighted combination sentence position lexical features simple syntactical measures sentence length rank sentences 
summarizer taken indicator value testing standard ease fact reasonable candidate 
overlap headline overlap summary lex position pos position pos lex position pos position pos table overlap terms generated headlines original headlines extracted summary sentences respectively article 
part speech pos information token location source document addition lexical information helps improve performance reuters test set 
taken account 
table shows results term selection schemes 
seen impoverished language model system quite generated headlines words long words matched article actual headline 
percentage drops expected headlines get longer 
multiple selection models pos position mentioned earlier zero level model discussed far extended take account additional information content selection surface realization strategy 
briefly discuss additional sources information part speech pos information ii positional information 
pos information content selection learn word senses part headline surface realization 
training pos model tasks requires far data training lexical model number pos tags smaller 
mixture model mclachlan basford combining lexical pos probabilities content selection linearization tasks 
indicator salience positional information cited important cues summarization ex clinton clinton wants clinton clinton meet clinton israel clinton israel meet system generated output lexical pos model 
clinton clinton mideast clinton netanyahu clinton netanyahu israel clinton meet netanyahu clinton meet netanyahu israel system generated output lexical positional model 
clinton clinton wants clinton israel clinton meet israel clinton meet israel clinton meet netanyahu system generated output lexical pos positional model 
output generated system augmented lexical models 
numbers right log probabilities generated strings generation model 
original term generated term original headline generated headline nations top judge wall street stocks decline dow jones index lower suspect ers roll ers nfc title game er top rated hospital drama corn wheat prices fall soybean grain prices lower drugs hopeful ireland accord britain ireland hopeful irish peace table pairs target headline generated summary terms counted errors evaluation semantically equivalent equally generated headlines counted wrong evaluation 
traction hovy lin mittal 
trained content selection model position tokens training set respective documents 
models positional salience proposed sentence selection simplest possible estimating probability token appearing headline appeared st nd rd th quartile body article 
tested mixtures lexical pos models lexical positional models models combined 
sample output article lexical pos positional information seen 
seen table adding pos information provide benefit positional information 
combination additional information sources improve model summary generation 
problems evaluation statistics previous discussion suggest relatively simple statistical summarization system compared extraction summarization systems radev mani 
worth emphasizing headlines generated system quite penalized evaluation metric word error rate generated headline terms exactly match original ones 
quick manual scan failures scored successes data table headlines contain words fewer 
subjective manual evaluation indicated errors avoided adding knowledge system example allowing alternate terms referring collective nouns 
errors shown table 
alternative extractive summarization approach possible generate coherent summaries shorter single sentence attempt conform particular style 
approach applies statistical models term selection term ordering processes produce short summaries shorter reported previously 
furthermore slight generalization system described summaries need contain words original document previous statistical summarization systems 
training corpora approach generate headlines variety formats case experimented corpora contained japanese documents english headlines 
resulted working system simultaneously translate summarize japanese documents 
performance system improved improving content selection linearization 
sophisticated models additional language models take account signed distance words original story condition initial corpus constructed running simple lexical translation system japanese headlines results poor high hopes usable summaries may produced training larger corpora 
probability appear separated distance headline 
extended model generate multi sentential summaries instance initial sentence clinton meet visit mideast words related nouns clinton mideast sentence system biases content selection model select nouns high mutual information nouns 
example sentence generated subsequent sentence urges israel plan model currently problems attempting address instance fact words occur adjacent sentences training set sufficient build coherent adjacent sentences problems pronominal cue phrases sequence abound 
furthermore initial experiments suffered lack training testing corpora news stories corpora contain multi sentential headlines 
results far seen indicative breed non extractive summarization holds great deal promise potential integrate types information source documents intended summaries potential produce brief coherent summaries 
expect improve quality scope summaries produced 
adam berger john lafferty 

information retrieval statistical translation 
proc 
nd acm sigir conference sigir berkeley ca 
peter brown stephen della pietra vincent della pietra robert mercer 

mathematics statistical machine translation parameter estimation 
computational linguistics 
chelba jelinek 

exploiting syntactic structure language modeling 
proc 
acl montreal canada 
acl 
chelba 

structured language model 
proc 
acl madrid spain 
acl 
gerald dejong 

overview system 
wendy lehnert martin editors strategies natural language processing pages 
lawrence erlbaum associates hillsdale nj 
edmundson 

problems automatic extracting 
communications acm 
forney 

viterbi algorithm 
proc 
ieee pages 
eduard hovy chin yew lin 

automated text summarization summarist 
proc 
wkshp intelligent scalable text summarization acl 
jing kathleen mckeown 

decomposition human written summary sentences 
proc 
nd acm sigir conference berkeley ca 
katz 

estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech signal processing 
kevin knight daniel marcu 

statistics summarization step sentence compression 
proc 
aaai austin tx 
luhn 

automatic creation literature abstracts 
ibm journal pages 
inderjeet mani barbara gates eric bloedorn 

improving summaries revising 
proc 
acl baltimore md daniel marcu 

discourse structures text summaries 
proc 
acl wkshp intelligent text summarization pages spain 
mathis rush young 

improvement automatic abstracts structural analysis 
jasis 
kathleen mckeown klavans hatzivassiloglou barzilay eskin 

multidocument summarization reformulation progress prospects 
proc 
aaai 
aaai 
mclachlan basford 

mixture models 
marcel dekker new york ny 
mittal mark jade goldstein jaime carbonell 

selecting text spans document summaries heuristics metrics 
proc 
aaai pages orlando fl july 
aaai 
dragomir radev inderjeet mani editors 

proc 
workshop intelligent scalable text summarization acl eacl madrid 
acl madrid spain 
dragomir radev kathy mckeown 

generating natural language summaries multiple online sources 
linguistics 
gerard salton singhal mitra buckley 

automatic text structuring summary 
info 
proc 
management march 

tipster text phase iii month workshop notes may fairfax va michael witbrock mittal 

headline generation framework generating non extractive summaries 
proc 
nd acm sigir conference sigir pages berkeley ca 
