efficient peer peer keyword searching patrick reynolds amin vahdat department computer science duke university cs duke edu today exponential growth network content difficult build maintain complete document index support efficient search 
centralized search services actively repeatedly probe network new changed content 
scope rapid evolution internet means best pull search services incomplete inaccurate 
tremendous interest new peer peer model publishing distributing network content 
nodes spread internet cooperatively store distribute network content explicit requests content publishers 
careful state maintenance enables location data item name lg steps 
date support search new paradigm 
believe opportunity build search system peer peer content distribution mechanism complete current efficient 
design analysis evaluation fully decentralized inverted index search engine peer peer content location systems 
results indicate proposed infrastructure incurs acceptable configurable network overhead search basis scales network size 
search fundamental part complete system distributing files resources 
opaque keys suffice bookmarks links locating unknown files description keywords resource metadata requires search 
current peer peer systems user retrieve content knows unique name 
contrast web search services allow users search content 
services research supported part national science foundation eia itr hewlett packard ibm intel microsoft 
vahdat supported nsf career award ccr reynolds supported nsf fellowship 
actively repeatedly index internet content hyperlinks resource 
web current search infrastructure limited centralized design pull nature 
current move peer peer systems file distribution affords opportunity improve search substantially :10.1.1.110.5867:10.1.1.140.3129:10.1.1.105.3673
web searching centralized peer peer searching entirely distributed scalable reliable 
web searching depends crawlers discover new updated content peer peer search system take advantage insert operations build current index networked content 
research peer peer systems chord pastry perform mappings keys locations entirely distributed manner :10.1.1.110.5867:10.1.1.140.3129:10.1.1.105.3673
just importantly location particular piece content full name scales system size requiring lg node storage lg routing steps 
retrieving content requires knowledge exact name object systems provide search capability 
principal contribution design evaluation fully distributed search system effects qualitative shift accuracy completeness index network content 
demonstrably possible build highperformance centralized search service believe search infrastructure distributed peer peer content storage distributed 
leveraging redundant distributed infrastructure supports peer peer content storage retrieval able achieve increased availability scalability load balancing 
natural way build distributed search system inverted index keywords evenly distributed available servers 
existing peer peer lookup mechanisms effect provide scalable distributed hash table allows individual keys mapped nodes network :10.1.1.110.5867:10.1.1.140.3129:10.1.1.105.3673
node wishes publish content hashes contents file discover node responsible storing 
enable accurate complete search node update inverted index keywords associated file 
overhead associated explicitly updating inverted index believe cost typically offset avoiding overhead associated repeated spidering web content 
keywords distributed proper nodes primary challenge scalability distributed search infrastructure minimizing bandwidth required perform multiple keyword searches 
describes design distributed inverted index particular emphasis techniques minimize bandwidth searches bloom filters caching incremental results 
bloom filters compact representation membership set eliminating need send entire document match lists servers 
caching reduces frequency servers transfer bloom filters 
incremental results allow search operations halt finding fixed number results leaving cost searching proportional number documents returned total number documents system 
rest organized follows 
section details assumed system model 
section describes architecture supporting search fully decentralized peer peer system presents analytical results supporting benefits proposed techniques 
section discusses simulation environment explore fully structure benefits search architecture section presents results experiments 
discuss related section conclude section 
architecture system model design traditional search engine service model 
client searches documents containing keywords 
system sends back unique names set number documents containing requested keywords title document words context keyword match 
documents ordered relevance metric instance documents linked frequently considered higher relevance return best matching documents 
system relevance ranking 
build peer peer distributed search infrastructure assume system model peer peer lookup services :10.1.1.110.5867:10.1.1.105.3673
general approach general techniques simplicity discussion assumes architecture closely related chord distributing inverted index peer peer network :10.1.1.105.3673
pastry :10.1.1.110.5867
system set tradeoffs interesting design decisions believe intricacies affect highlevel results 
assume presence large number computers order thousands millions spread network willing take task indexing internet content 
system maintain inverted index structure maps potential keyword set documents contain word 
assume presence hash function maps keyword random number range 
hash function maps computer ip address participating distributed search system number range 
depicted computer responsible keywords map range address address computer hash range thought logical ring 
previous shows arbitrary machine system locate remote computer responsible keyword hash lg routing hops lg routing state node number system wide peers 
details routing protocols scope 
roughly node maintains state route request halfway closer final destination hash space 
note publishing documents infrastructure explicit act 
user hashes document contents address hash function routes publish request node responsible region address space 
subsequent requests document similarly route requests appropriate node assuming know unique key file 
key unknown impossible locate files systems 
approach may appropriate archival filesystems example may impose hierarchical directory structure words search words search frequencies number keywords search operation ircache day period january 
hash space 
keyword search provided 
propose model explicit step publishing document storage infrastructure supplemented explicit act updating distributed inverted index keywords associated document 
keywords may include small set carefully chosen words user extreme may include entire list words contained text documents extreme 
process involves performing hash target keyword contacting appropriate peers peerto peer host lookup routing infrastructure update index 
performing search keywords involves performing hash keywords contacting appropriate peers responsible individual keywords performing join operation individual sets document names returned peer 
primary contribution demonstrate multi keyword searches carried internet efficiently low network overhead client latency manner scales system size 
show basic infrastructure scales demonstrate state node communication required request scale sub linearly system size key challenge deploying system minimizing wide area bandwidth consumed conjunctive searches improvements infrastructure easier deploy improve performance individual queries 
general case wide area peers contacted keyword search 
interesting question important design system performs multi keyword searches 
overhead incurred performing join multiple peers hosting individual keywords rare sense optimize aggressively case 
investigate popularity multi keyword searches worked administrators ircache proxy cache system cache system operating united states obtain trace search requests fifteen popular search services day period january 
ircache thousands clients users second level caches currently receives approximately total requests typical weekday 
plots number keywords searched search requests period 
interestingly search requests single keyword 
searches keywords largest search trace words 
conclude data confirms intuition multi keyword searches common case distributed search infrastructure reduce potential overhead associated join operations spread wide area 
discussion model raises number interesting points 
approach introduces extra overhead requiring client notify search service updates inverted index peer keyword contacted publishing modifying document 
believe inserts rare compared searches 
client may contact peers parallel background 
believe added cost insert offset savings realized eliminating need repeatedly spider web content addition expected improvements completeness accuracy index 
consider value distributing search peer peer infrastructure relative traditional centralized approach 
centralized search infrastructure somewhat simpler believe significant performance scalability availability benefits available fully distributed peer peer approach 
traditional centralized search services google attempt improve performance availability small scale wide area replication dns techniques individual client redirection 
distributed denial service attack site dns server network failure potentially leave entire service unavailable 
similar attacks failures replicated sites cause outage performance degradation significant portion client population 
massive replication peer peer system im plies outage denial service attack affect small portion client population keyword space 
technique omitted implementation evaluation discussed section mapping individual client keywords peer 
keyword mapped total nearest peers id space 
random nature hash function probabilistically ensures peers spread network 
simple locality optimizations routing infrastructure outlined enable forwarding requests peer topologically closest requesting client minimal overhead relative native ip routing :10.1.1.110.5867
manner outages middle network render service unavailable requests satisfied close client central location reducing probability network congestion encountered way 
interesting consideration need provide context search results 
current search services return ranked list documents match user search criteria 
document service typically provides excerpts document highlighting target keywords surrounding text better enable user select appropriate document returned set 
system support functionality require update inverted index include text surrounding keyword document 
approach increases overhead associated index update aid process multi keyword search queries case target keywords appear close document 
consider issue validating contents inverted indices 
malicious publisher may attempt insert entries inverted index keywords accurately reflect contents document 
ways address potential attack 
search service performs ranking number incident hypertext links documents inaccurate keywords unpopular people link documents content 
users see page part search query 
manual feedback system allow users identify search results match expectations reducing popularity document 
peer periodically probabilistically choose set documents retrieve verify keyword mapping 
users inserting inaccurate keywords restricted way making insertions 
server server client request network architecture simple approach queries 
server stores list document ids corresponding keyword 
efficient support peer topeer search previous section discussed architecture potential benefits fully distributed peer peer search infrastructure 
primary contribution demonstrate feasibility approach respect individual user requests 
conducting search single keyword consists looking keyword mapping index reveal documents containing keyword 
involves contacting single remote server operation network costs comparable accessing traditional search service section argue massive replication improve performance availability requests relative centralized approach bringing content closer individual clients 
boolean search consists looking sets keyword returning intersection 
traditional search engines return small subset matching documents 
operation requires contacting multiple peers wide area requisite join operation sets returned peer prohibitively expensive terms consumed network bandwidth latency incurred transmitting data wide area 
consider example shows simple network servers server contains set documents keyword ka server contains set documents keyword kb jaj jbj number documents containing ka kb respectively 
set documents containing ka kb primary challenge performing efficient keyword searches distributed inverted index limiting amount bandwidth multiple keyword searches 
naive approach shown consists server sending entire set matching document ids second server calculate send results client 
wasteful intersection far smaller resulting information getting discarded furthermore size number occurrences keyword ka scales roughly number documents system 
cost naive search operations grows linearly number documents system 
propose techniques limit wasted bandwidth ensure scalability reduce client latency bloom filters caches incremental results 
discuss approaches turn analytical results showing potential benefits technique variety conditions exploring tradeoffs detail simulation section 
bloom filters bloom filter hash data structure efficiently represents membership set :10.1.1.153.5656
sending bloom filter sending reduce amount communication required determine membership test returns false positives low probability returns false negatives 
intersection calculated contain true intersection hits contain kb ka number false positives falls exponentially size bloom filter increases 
optimal choice hash functions probability false positive fp number bits bloom filter number elements set 
maintain fixed probability false positives size bloom filter proportional number elements represented 
method bloom filters determine remote set intersections shown proceeds follows 
document sets intersect containing large number document ids keywords ka kb respectively 
client wishes retrieve intersection server sends bloom filter set server server tests member set membership 
server sends matching elements back server textual context match 
server removes false positives server server client request bloom filters help reduce bandwidth requirement queries 
gray box represents bloom filter set note false positive set server sb sends back server sa results calculating equivalent false positives affect correctness final intersection waste bandwidth 
eliminated final step intersects possible send directly client sending removing false positives 
doing eliminates smaller transfer associated latency expense correctness 
reasonable values jaj jbj size document record cache hit rate see section false positive rate may high low 
means jbj jbj extra elements contain ka example elements contain ka returning rough intersection client results jbj jbj jbj jbj results incorrect containing ka expression represents ratio number false positives total number elements 
decision optimization run time parameters known fp predicted 
server may choose value slightly larger optimal reduce fp improve likelihood return directly client 
total number bits sent exchange shown fp ja number bits document record 
final term ja size intersection 
ignored optimization represents resulting intersection sent regardless choice algorithm 
bits filter expected excess bits sent function total number excess bits sent excluding intersection fp substituting fp equation yields total number excess bits jaj derivative respect solving zero yields optimal bloom filter size jaj log jaj shows minimum number excess bits sent sets values jaj jbj optimal jaj jbj unique directly determines minimum number excess bits sent 
example jaj jbj minimum number excess bits sent representing compression compared cost sending bits documents bit id shown performance symmetric differ size 
constant minimum number excess bits jaj jbj lower minimum number jaj jbj 
bits represents compression compared bits needed send server smaller set initiate transfer 
bloom filter intersection technique expanded arbitrary numbers keywords shown 
server sends server sends 
final server sends intersection back server server server client request server bloom filters keywords words keyword frequencies distribution word popularity 
encoded transmission bloom filter process intersection remove false positives introduced filter 
intersection sent server second time 
expected number excess bits minimized jaj jbj jcj jzj 
caches caching eliminate need send server stored locally 
derive benefit caching bloom filters caching entire document match lists smaller size bloom representation means cache fixed size store data keywords 
benefit caching depends presence locality list words searched user population time 
quantify intuition day ircache trace described section determine word search popularity 
total words searched searches unique 
keyword popularity roughly followed zipf distribution common keyword searched times 
dominance popular keywords suggests small cache bloom filter actual document list produce high hit rates 
server bloom filter cache search operation keywords ka kb may skip step server sends bloom filter average bloom filter server cache probability equal cache hit rate 
excess bits formula equation adapted consider cache hit rate follows jaj setting derivative respect zero yields optimal jaj log jaj shows effect cache hit rates excess bits curves assuming jaj jbj 
curve unique minimum 
example hit rate minimum excess number bits sent representing compression compared sending improvements cache hit rate reduce minimum expected number excess bits increase optimal reduction expected number excess bits sent nearly linear improvements hit rate 
optimal increases send bloom filter increase size slightly reduce false positive rate 
increases store hundreds cache entries megabyte available local storage 
expect caching yield high hit rates moderate locality request stream 
cache consistency handled simple time field 
updates occur keyword primary location slightly stale match list information acceptable especially current state internet search services degree staleness unavoidable 
complex consistency protocols necessary 
incremental results clients rarely need results keyword search 
streaming transfers returning desired number results greatly reduce amount information needs sent 
bits filter hit rate hit rate hit rate hit rate hit rate improving cache hit rates reduces amount data sent increases size optimal bloom filter 
fact critical scalability number results query roughly proportional number documents network 
bandwidth cost returning results client grow linearly size network 
bloom filters caches yield substantial constant factor improvement technique eliminates linear growth cost 
truncating results way achieve constant cost independent number documents network 
client searches fixed number results servers communicate incrementally number reached 
server sends bloom filter chunks server sends block results true intersections false positives chunk server results return client 
single bloom filter divided retain meaning divide set chunks send full bloom filter chunk 
chunk size set adaptively elements needed produce desired number results 
protocol shown 
note overlap communication sends sends 
stream data caches store fractional bloom filters keyword storing entire bloom filter keyword 
allows servers retain discard partial entries cache 
server may get partial cache hit keyword needs chunks stored locally 
storing fraction keyword bloom filter reduces amount space cache keyword consumes increases expected hit rate 
server server client request servers sa sb send data chunk time desired intersection size reached 
discussion techniques described bloom filters caching yield constant factor improvements terms number bytes sent query latency 
bloom filters compress document id sets order magnitude exchange added latency configurable probability false positives 
caching exploits temporal locality query workload reduce probability document id sets need sent 
techniques leave bytes sent query time roughly proportional number documents system 
third technique incremental results reduces number bytes sent query latency constant cases 
long user wants constant number results constant amount done regardless possible results exist system 
incremental results yield improvement unusual cases 
user searches keywords individually popular uncorrelated document space may small nonzero number valid results 
number results nonzero smaller number client requests system consider entire search space rendering incremental results useless 
cases entire search space considered incremental results increase decrease number bytes sent query latency 
caching may alleviate problem words popular search queries bloom filters yield approximately compression factor 
expect searches containing popular un example difficult search openbsd birthday suggested david mazieres new york university 
web keywords match documents respectively 
documents contain 
correlated keywords rare 
ircache search trace queries small numbers results uncommon misspelled keywords 
uncommon keywords matching documents easy handle discussed section 
system considers common keyword bounding maximum size intersection set sent remainder query 
simulation infrastructure simple analysis described section provides insight potential benefits approaches efficiently supporting peer topeer search 
actual benefits tradeoffs depend heavily target system characteristics access patterns 
test validity approach range realistic circumstances developed simulation infrastructure implementing techniques 
section discuss details simulation infrastructure presenting results evaluation section 
goals goal writing simulator test system realistic workload test effects parameters features lend tractable analysis 
particular tested effects number hosts network virtual hosts bloom filter threshold bloom filter sizes caching techniques incremental results 
tested system sensitivity varying network characteristics 
key concern peer peer system inherent heterogeneity systems 
randomly distributing functionality keywords system runs risk assigning popular keyword relatively provisioned machine terms memory cpu network capacity 
hash function uniformly distribute functionality hash range 
individual machines may assigned disproportionate numbers keywords recall keywords assigned host id closest hash range 
virtual hosts technique address potential limitation 
approach node participates peer peer system logical hosts proportional request processing capacity 
node participates virtual hosts assigned proportionally load addressing heterogeneous node capabilities 
node times capacity baseline measure assigned virtual ids means mapped different ids hash range 
optional system wide scaling factor node number virtual hosts reduces probability single node assigned disproportionately large portion hash range 
effect quantified section consider example 
hosts equal power hosts assigned significantly hash range 
scaling factor host assigned range unlucky hash large portion hash region virtual host cancelled lucky hash small portion hash region virtual host physical node 
bloom filter threshold refers document set size host transmits full list bloom compressed set 
small documents total bandwidth consumed transmission remote host set intersection may small may worth cpu time required compress set 
eliminating bloom step eliminates need return transmitting host eliminate false positives join 
typically find extra cpu overhead network overhead returning result worth substantial saving network bandwidth realized bloom filters 
section quantify effect variety bloom thresholds 
bloom filter sizes affect number false positives transmitted search process 
client willing accept probability false positives returned document containing subset requested keywords sufficiently large bloom filters meet client accepted false positive rate eliminate need revisit nodes remove false positives described section 
small bloom filters result significant compression keyword set size cost generating false positives result returned client requiring transmission intersection back originating host false positive elimination 
design simulator runs single threaded java application 
implement inverted index word host mapping host measurement case random generation separate classes simulator reused full implementation protocol 
simulations real document set search trace 
document set totals gb html data comprising unique words documents retrieved crawling recursion depth seed urls 
searches performed read list searches containing unique keywords 
search trace ircache log file described section 
note results restricted particular traces 
expect benefits techniques differ significantly workloads 
hosts network generated random configurable distributions upload speed download speed cpu speed local storage capacity 
distributions network speeds modems backbone links measurements gnutella network performed saroiu 
heterogeneous set contains mixture modems broadband connections cable dsl high speed lan connections 
cpu speed distribution roughly bell curve mean mips local storage distribution heavy tailed piecewise function ranging mb mb 
experimented broad range host characteristics results representative subset 
generate random latencies place hosts random mile square grid assume network packets travel average miles second 
time required send network message propagation time determined distance hosts involved plus transmission time determined minimum sender upload speed recipient download speed size packet 
total network time search sum latency transmission time packets sent server nodes processing query 
ignore time spent client sending initial query receiving results times constant 
document ids assumed bits 
time required look words local index perform intersections bloom filter operations cpu speed assumptions operation costs simple operations hit look words index simple operations element intersect result sets simple operations document id inserted bloom filter checked bloom filter received host 
believe general assumptions place upper bound cpu cost operations 
assumptions find network time typically dominates cpu time target scenarios 
determine number virtual hosts assign simulated node network cpu speeds compared baseline host 
baseline host mips cpu kbit network links 
speeds chosen required compute transmit bloom operations second 
node compared baseline host categories upload speed download speed cpu speed 
nodes minimum margin baseline host categories rounded taken number virtual hosts 
perform query simulator looks keyword inverted index obtaining results incremental result size 
host intersects set data previous host forwards subsequent host described section 
node forwards current intersected set bloom filter full set depending set larger bloom threshold 
peer performs part join node sent bloom filter pass potentially revisited remove false positives 
number resulting documents large desired number search 
increased adaptively twice appears needed produce desired number results search rerun 
step host checks cache see data subsequent host document list local cache 
performs subsequent host portion join locally skips host sending sequence 
validation validated simulator ways 
calculated behavior performance short artificial traces hand confirmed simulator returns results 
second varied bloom filter size simulator compared results analytical results section 
analytical results shown closely resemble simulated results shown 
experimental results goal section understand performance effects proposed techniques peer peer search infrastructure 
ideally wish demonstrate proposed peer peer search system scales system size total resource consumption search grows sub linearly number participating hosts techniques bloom filters caching improve performance individual requests 
primarily focus metric bytes sent request 
techniques caching bloom filters largely serve reduce metric 
reducing bytes request added benefit reducing total time spent network client perceived latency 
study effects distribution network cpu characteristics system performance 
challenge peer peer systems number hosts virtual hosts virtual hosts scaling virtual hosts scaling virtual hosts scaling number bytes sent increases little networks hosts 
enabling virtual hosts reduces number bytes sent 
scaling number virtual hosts reduces number bytes sent additional 
addressing subset hosts significantly computation power network bandwidth required support high performance search infrastructure 
implemented incremental results results technique target document set large return large numbers hits queries 
workload optimization reduces network utilization best case 
believe technique increasingly valuable document space increases size 
scalability virtual hosts key goal demonstrate peerto peer search infrastructure scales number participating hosts 
specified results section assume heterogeneous distribution peer network connectivity default distribution cpu power described section 
caching bloom filters initially turned 
shown increasing number hosts simulation little effect total number bytes sent 
small networks keywords query may located single host resulting entirely local handling parts query 
hosts probability insignificant keyword query contact hosts independent size system 
addition demonstrating scalability system figures quantify benefits number hosts virtual hosts virtual hosts scaling virtual hosts scaling virtual hosts cut amount time spent transmitting 
scaling number virtual hosts yields small additional improvement 
virtual hosts system 
recall virtual hosts turned node assigned number hosts capacity relative predefined baseline described section 
virtual host scaling factor multiplies number hosts constant value ensure physical host assigned uniform portion hash range discussed section 
virtual hosts small effect number total bytes sent query 
enabling virtual hosts concentrates data powerful hosts increasing probability parts query handled entirely locally 
virtual host scaling results better expected load balancing slightly decreases amount data sent average 
virtual hosts little effect data sent significantly decrease amount time spent sending data shown 
assigning load capable hosts virtual hosts technique cut network times nearly 
virtual host scaling decreases expected network times reducing probability bottleneck host assigned disproportionate amount load mistake 
total bytes sent decreases slightly result better load balancing total network time decreases significantly capable hosts faster network connections responsible larger fraction requests 
bloom filters caching having established scalability general approach turn attention additional benefits available bloom filters reduce net bloom filter threshhold bytes sent different network sizes increasing bloom filter threshold bloom filters significantly reduces amount data sent eliminating need revisit nodes eliminate false positives certain cases 
utilization 
particular focus large bloom filter minimum data set size invoked 
bloom filters transfer results substantial unnecessary data transmissions 
time bloom filter host revisit query eliminate false positives 
bloom filters time saved outweigh time spent sending clean message 
shows total bytes transmitted query function bloom filter threshold assuming default value bits bloom entry 
find optimal bloom filter threshold trace approximately 
set size sent entirety savings bloom filters outweigh network mention latency overhead revisiting host eliminate false positives 
consider effects varying number bits entry bloom filter caching total network traffic 
plots total number bytes transmitted function bloom filter size 
sets curves represent case enable disable caching 
set set maximum rate allowable false positives set documents returned user particular query 
client allows false positives false positive removal steps may eliminated increasing bloom filter size enhances effect 
shows allowing false positives significantly effect varying total network time bytes transferred eliminates number required message transmissions 
bloom filter size bits entry bytes sent different network sizes caching allow fp caching allow fp caching allow fp caching allow fp caching allow fp caching allow fp bytes query function bloom filter size bloom filter size bits entry total network time caching allow false positives caching allow false positives caching allow false positives caching allow false positives caching allow false positives caching allow false positives network time latency plus transmission time query function bloom filter size effects caching shown similar derived analytically 
caching decreases total amount data sent increases optimal bloom filter size case bits entry bits entry 
optimal bloom filter sizes bits entry caching caching cases respectively caching technique introduces reduction total number bytes transmitted query 
putting average query times considering optimizations variety assumed network conditions 
break toend time principal components configure isolating effects caching virtual hosts different network characteristics optimal bloom threshold bloom filter sizes caching 
tribute latency cpu processing time network transmission time bytes transferred divided speed slower network connection speed communicating peers latency determined distance communicating peers 
recall section measure time associated client request final response size messages independent optimization techniques 
shows bar charts break total search time network conditions described section wan heterogeneous modem 
network setting individual bars representing effects virtual hosts caching 
bar broken network transmission time cpu processing time network latency 
case modem network query time dominated network transmission time 
virtual hosts effect query times network set homogeneous 
caching reduce network transmission portion roughly 
queries manage complete second shown optimizations reduces total bytes transferred query bytes target workload modem transfer kb sec best case 
results limited fact simulator model network contention 
general expect query average worse reported results individual node network connection saturated 
limitation significantly mitigated different network conditions individual nodes additional bandwidth available virtual hosts spread load avoid hosts 
homogeneous wan case network time negligible cases high transmission speeds 
caching reduces latency cpu time respectively avoiding need calculate transmit bloom filters case cache hit 
enabling virtual hosts reduces cpu time concentrating requests subset wan nodes cpu processing power 
recall network homogeneous case heterogeneity cpu processing power described section 
virtual hosts caching pronounced effect heterogeneous network reducing average query response times 
particular virtual hosts reduces network transmission portion average query response times concentrating keywords subset nodes network bandwidth 
caching uniformly reduces aspects average query time particular reducing latency components case eliminating need significant portion network communication 
related related divided categories generation peer peer systems consisting research peer peer systems web search engines database semijoin reductions 
dealt research peer peer systems section 
describe 
generation peer peer systems consists napster gnutella freenet 
napster gnutella searches core location determination technique 
napster performs searches centrally known servers store metadata location keywords document 
gnutella broadcasts search queries nodes allows node perform search manner 
yang garcia molina suggest techniques reduce number nodes contacted gnutella search preserving search semantics satisfactory number responses 
freenet provides search mechanism depends known names known directories names 
web search engines google operate centralized manner 
farm servers retrieves reachable content web builds inverted index 
farm servers performs lookups inverted index 
inverted index location multiple keyword searches performed entirely local area communication optimizations needed 
distributing index wide area provides greater availability centralized approach 
system take advantage explicit insert operations peer peer systems provide date results crawler approach 
general problem remotely intersecting sets document ids equivalent database problem performing remote natural join 
ideas database literature 
sending data necessary intersection join comes semijoin reductions 
bloom filter summarize set document ids comes bloom joins 
presents design evaluation peerto peer search infrastructure 
context contributions 
show architecture scalable global network state message traffic grows sub linearly increasing network size 
relative centralized search infrastructure approach maintain high performance availability face individual failures performance fluctuations replication 
explicit document publishing distributed keyword index delivers improved completeness accuracy relative traditional spidering techniques 
important consideration architecture reducing overhead multi keyword conjunctive searches 
describe evaluate number cooperating techniques bloom filters virtual hosts caching incremental results taken reduce consumed network resources perceived client search latency order magnitude target workload 
acknowledgments grateful duane wessels ircache project supported nsf ncr ncr access trace data files 
lim access gb html data set document trace 
rebecca provided helpful comments presentation 
philip bernstein dah ming chiu 
semi joins solve relational queries 
journal association computing machinery january 
burton bloom 
space time trade offs hash coding allowable errors 
communications acm 
sergey brin lawrence page 
anatomy largescale hypertextual web search engine 
th international world wide web conference 
junghoo cho hector garcia molina 
evolution web implications incremental crawler 
vldb journal september 
clarke 
distributed decentralised information storage retrieval system 
frank dabek frans kaashoek david karger robert morris ion stoica 
wide area cooperative storage cfs 
proceedings th acm symposium operating systems principles sosp october 
li fan pei cao almeida andrei broder 
summary cache scalable wide area web cache sharing protocol 
proceedings acm sigcomm pages 
gnutella 
gnutella wego com 
hong 
freenet distributed anonymous information storage retrieval system 
icsi workshop design issues anonymity unobservability 
david karger eric lehman frank thomson leighton rina panigrahy matthew levine daniel lewin 
consistent hashing random trees distributed caching protocols relieving hot spots world wide web 
acm symposium theory computing pages 
lothar guy lohman 
optimizer validation performance evaluation local queries 
acm sigmod conference management data 
james mullin 
optimal distributed database systems 
ieee transactions software engineering may 
napster 
www napster com 
ratnasamy paul francis mark handley richard karp scott shenker :10.1.1.140.3129
scalable content addressable network 
proceedings acm sigcomm 
antony rowstron peter druschel :10.1.1.110.5867
storage management caching past large scale persistent peerto peer storage utility 
acm symposium operating systems 
stefan saroiu krishna gummadi steven gribble 
measurement study peer peer file sharing systems 
proceedings multimedia computing networking mmcn january 
stefan savage david wetherall anna karlin tom anderson 
practical network support ip traceback 
proceedings acm sigcomm conference august 
ion stoica robert morris david karger frans kaashoek hari balakrishnan :10.1.1.105.3673
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm 
wessels claffy 
ircache project 
www ircache net 
beverly yang hector garcia molina 
efficient search peer peer networks 
technical report stanford university october 
ben zhao john kubiatowicz anthony joseph 
tapestry infrastructure fault tolerant wide area location routing 
technical report ucb csd computer science division eecs university california berkeley 

