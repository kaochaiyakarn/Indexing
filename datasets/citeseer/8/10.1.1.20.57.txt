production recognition emotions speech features algorithms pierre yves sony csl paris rue paris france years marked development robotic pets partners small animals humanoids 
interactions di erent traditional computers having human beings robotic conventions robots learn communicate fashion 
particular need able express recognize emotions 
done part speech advantage computationally cheap practical implement real world robots 
research area young 
algorithms allow young robot express emotions babies 
simple eciently provide life speech concatenative speech synthesis 
describe technique allows control continuously age synthetic voice quantity emotions expressed 
useful personal robots may grow degrees emotions 
rst large scale data mining preprint submitted elsevier science august experiment automatic recognition basic emotions everyday short utterances 
focus speaker dependant problem 
compare large set machine learning algorithms ranging neural networks support vector machines decision trees features large database thousands examples 
show di erence performance learning schemes substantial features previously unexplored crucial importance 
optimal feature set derived genetic algorithm 
explain study applied real world situations possibly examples available 
furthermore describe game play personal robot allows teach examples emotional utterances natural unconstrained manner 
key words emotions speech robots production recognition years marked increasing development personal robots new educational technologies druin hendler pure entertainment fujita kitano 
typically robots look familiar pets dogs cats sony aibo robot take shape young children humanoids sdr sony 
interactions machines radically di erent way interact traditional computers 
far humans learning unnatural conventions devices address py csl sony fr pierre yves 
url www csl sony fr py pierre yves 
boards dialog windows need know computers able 
opposite personal robots try learn natural conventions natural language social rules appropriate modalities speech touch humans thousands years 
capabilities personal robots need basic ability grasp human emotions picard particular able recognize human emotions express emotions :10.1.1.153.8488
emotions crucial human reasoning central social regulation halliday particular control dialog ows 
emotional communication primitive ecient lot interact pets particular tame 
certainly allows children bootstrap language learning halliday inspiring teach robots natural language 
apart words express emotions main ways modulation facial expression ekman modulation intonation voice 
research automated recognition emotions facial expressions rich samal research dealing speech modality automated production recognition machines active years bosch 
results research consisted providing robots means express emotions enabling recognize basic emotional information caretaker voice 
aspects original far production concerned existing dealing cartoon meaningless speech di erent needs constraints example trying produce naturally sounding adult normal emotional speech 
example emotions recognized people di erent cultural linguistic background 
similarities concatenative speech synthesis algorithm simple completely speci ed 
far recognition emotions concerned rst knowledge large scale data mining experiment compare standard machine learning algorithms explore value di erent features 
shown new features ecient ones traditionally literature 
freely available softwares reproduced minor diculties 
web site containing accompanying material sounds graphs available 
section presents general information acoustic correlates emotion speech form basis 
section presents algorithm production emotion validation human subjects 
section presents results data mining experiment concerning learning algorithms useful features recognition emotions human voice 
acoustic correlates emotions human speech possible achieve goal reliable acoustic correlates emotion ect acoustic characteristics signal 
num www csl sony fr py ber researchers investigated question burkhard 
results agree speech correlates come physiological constraints correspond broad classes basic emotions disagree unclear looks di erences acoustic correlates instance fear surprise boredom sadness 
certain emotional states correlated particular physiological states picard turn quite mechanical predictable ects speech especially pitch fundamental frequency timing voice quality :10.1.1.153.8488
instance state anger fear joy sympathetic nervous system aroused heart rate blood pressure increase mouth dry occasional muscle 
speech loud fast enunciated strong high frequency energy 
bored sad nervous system aroused heart rate blood pressure decrease increases producing speech slow low pitched little high frequency energy 
furthermore fact physiological ects universal means common tendencies acoustical correlates basic emotions di erent cultures 
precisely investigated studies experiments american people recognize emotion american japanese person acoustic information utterances meaningless semantic information 
reversely japanese listeners asked decide emotions japanese american people trying convey 
results came little di erence performance detecting emotions conveyed speaking language language true japanese american subjects subjects far perfect recognizer absolute best recognition score percent result partly explained fact subjects asked pronounce nonsense utterances quite unnatural con rmed studies asking people utter semantically neutral meaningful sentences burkhart 
rst result indicates goal build machine express ect meaningless speech way recognizable people di erent cultures accuracy human speaker attainable theory 
second result shows expect perfect recognition compare machine performance relation human performance 
fact humans mainly explained fact emotional states similar physiological correlates acoustic correlates 
actual situations solve ambiguities context modalities 
experiments shown multi modal nature expression ect lead ect emotions see massaro face showing emotion speaking emotion perceived expressing emotions third 
different contexts may lead people interpret intonation expressing di erent emotions context see 
ndings indicate shall try machine generate utterances ne distinctions basic ect categories investigated 
number experiments computer techniques sound manipulation conducted explore particular aspects speech re ect emotions saliency 
murray arnott scherer burkhardt williams stevens basically agree crucial aspects related prosody pitch contour intensity contour timing utterances 
studies shown voice quality certain articulatory phenomena reasonably correlated certain emotions 
generation cartoon emotional speech goal goal research quite di erent existing synthetic emotional speech 
traditionally see cahn iida aim produce adult naturally occuring emotional speech target provide young creature ability express emotions exaggerated cartoon manner nonsense words necessary experiments robots try teach language pre linguistic ability intonation express basic emotions serves bootstrap learning give details point falls far scope 
speech sound lively repetitive similar infants babbling 
wanted people di erent linguistic cultural background able recognize easily creature emotions 
additionally wanted algorithms simple possible control parameters possible brief simplest manner transmit emotions prosodic variations speech high quality computationally cheap generate robotic creatures usually scarce resources 
reasons chose concatenative speech synthesizer software freely available web enhancement traditional techniques produces distortions pitch manipulated 
price quality control signal possible compatible need simplicity 
constraints chosen investigate emotional states far corresponding calm regions de ned dimensions arousal valence anger sadness happiness comfort 
existing said existing concentrated adult naturally sounding emotional speech projects language 
see cahn murray arnott burkhardt formant synthesis basis mainly allows detailed rich control speech signal control voice quality pitch intensity spectral energy distributions harmonics noise ratio articulatory precision allows model articulation ects occurring emotional speech 
drawbacks formant synthesis quality produced speech remains satisfying voices quite unnatural 
furthermore algorithms developped case web page fpms ac synthesis html complicated necessitate control parameters renders ne tuning quite impractical see cahn discussion 
works breazeal described system similar cahn system robot kismet allows produce meaningless emotional speech 
cahn relies heavily commercial speech synthesizer parameters high level example speci cation pitch baseline sentence implemented undocumented manner 
consequence hardly reproducible wants speech synthesis system 
contrary algorithm describe completely speci ed directly system freely downloaded see 
drawback breazeal synthesizer formant correspond constraints 
superior quality concatenative speech synthesizers gained popularity years tried produce emotional speech 
challenge signi cantly dicult formant synthesis pitch contour intensity contour duration phonemes controlled narrow contraints control 
knowledge approaches literature 
rst described iida uses speech database emotion basis prerecorded segments concatenated synthesis 
gives satisfying results quite impractical wants change voice add new emotions control degree emotions 
second approach consists see example making databases human produced emotional speech computing pitch intensity contours apply sentences generated 
brings problems alignments partially solved syntactic similarities sentences 
showed method gave quite unsatisfying results speech sounds unnatural emotions recognized human listeners methods great diculties speech databases exaggerated cartoon baby voices 
approach take algorithmic point view completely generative rely recording human speech serve input uses concatenative speech synthesis basis 
show allows express emotions eciently formant synthesis simpler controls concatenative speech synthesis 
simple complete algorithm algorithm consists generating meaningless sentence specifying pitch contour duration phonemes rhythm sentence 
sake simplicity specify target phoneme pitch reveals 
ne control intensity contour show necessary manipulating pitch create auditory illusion intensity variations 
control volume sentences 
program generates le fed speech synthesizer 
le looks means phoneme duration ms percent ms try reach hz percent try reach hz rst step algorithm generate sentence composed random words word composed random syllables type cv ccv 
initially duration phonemes constant pitch phoneme constant equal pre determined value noise added crucial wants speech sound natural tried di erent kinds noise signi cant di erences perceptual experiment reported gaussian noise 
pitch duration informations sentence altered yield particular ect 
deformations consist deciding number syllables stressed applying certain stress contour syllables duration modi cations 
syllables applied certain default pitch contour duration deformation 
phoneme give pitch target xed percent duration phoneme 
state precisely di erent steps algorithm words capital letters denote parameters algorithm need set emotion choose number words sentence random number create words word choose number syllables random number decides probability word accented word accented choose randomly syllables mark accented create syllables syllable choose cv ccv syllable cv syllable probability instantiate picking randomly vowel phoneme database set duration phoneme random random set pitch set pitch vowels syllable accented add duration phonemes rising set pitch consonants set pitch vowel falling set pitch consonants set pitch vowel stable set pitch phonemes change contour word falling syllable word add pitch phonemes value index phoneme syllable rising syllable word add pitch phonemes value index phoneme syllable falling syllable word add duration phonemes set pitch consonants set pitch vowel rising syllable word add duration phonemes set pitch consonants set pitch vowel set loudness volume complete sentence volume 
remarks concerning algorithm 
useful words just dealing random sequences syllables avoids put accents adjacent syllables 
allows express easily operations done word 
typically maximum number words sentence depend particular ect parameter freely varied 
key aspect algorithm stochastic parts hand allows produce set parameters di erent utterance time mainly random number words random constituents phonemes syllables probabilistic attribution accents hand details adding noise duration pitch phonemes see line random means random number fundamental naturalness vocalizations remains xed perceives clearly machine talking 
accents implemented changing pitch loudness 
gives satisfying results human speech increase loudness correlated increase pitch 
course exaggerate pitch modulation ne explained earlier goal reproduce faithfully way humans express emotions produce lively natural caricature way express emotions cartoon 
step added algorithm order get voice typical young creature sound le sampling rate setting hz compared hz produced equivalent playing le quicker 
course speech rate remains normal initially slower program sent 
voice quality pitch modi ed 
step necessary child voice database exists 
female adult voice choosen 
described details algorithm give see table examples parameters values obtained ects calm anger sadness happiness comfort 
way parameters obtained rst looking studies describing acoustic correlates emotion murray arnott deducing coherent initial value parameters modifying hand trial error gave result 
validation human subjects order evaluate algorithm described section experiment conducted human subjects asked describe emotion calm anger sadness nil nil nil rising falling falling rising falling falling volume comfort happiness true true rising rising rising rising volume table parameter values di erent emotions felt hearing produced system precisely subject rst listened examples vocalizations emotion randomly chosen example got voice system 
sequence vocalizations unsupervised serie time corresponding emotion randomly choosen asked choice calm anger sadness comfort happiness 
hear example 
second experiment sample sounds available associated web page www csl sony fr py di erent subjects initially supervised examples emotion means label intended emotion 
vocalizations describe word cited 
naive adult subjects experiment french subjects english subject german subject brazilian subject japanese subjects familiar research special knowledge acoustic correlates emotion speech 
table shows results unsupervised serie experiment 
number means percentage times intended represent emotion perceived emotion 
instance table see percent vocalizations intended represent sadness ectively perceived sadness 
results unsupervised serie experiment compared experiments done human speech machine speech 
show similar setups humans asked produce emotional speech best humans percent success 
see mean result percent compares human performance 
errors types frequent related confusion neutral calm emotion 
annoying error involve confusion aroused aroused negative positive 
confusion anger happiness comfort sadness means confusions valence appear aroused speech 
nearly confusions aroused aroused speech 
second unsupervised experiment performed similar reported calm ect removed 
mean success percent calm anger sadness comfort happiness calm anger sadness comfort happiness table confusion matrix unsupervised series obtained great increase better human performance 
explained part fact acoustical correlates emotions 
results similar reported proves concatenative synthesizer lot parameters allows convey emotions general provides life sounds 
examination supervised serie shows presentation vocalizations intended emotion exactly emotion results increase percent success achieved 
see confusions involving neutral emotion confusions anger happiness nearly disappeared 
similarly experiment calm ect removed conducted gave mean success percent 
supervision implemented quite easily digital pets combinations color led lights express emotions experiment shows visually see robot times uttering emotional sentences able recognize intended emotion just listening 
calm anger sadness comfort happiness calm anger sadness comfort happiness table confusion matrix supervised series varying continuously age voice degree emotion typically robotic pets initially babies shall grow develop time interactions humans pets 
natural voice evolves accordingly continuous manner 
knowledge problem addressed literature 
generally voice databases segments speech choose corresponding di erent ages 
hand database di erent person having voice desired age means clear human ear voice di erent person course acceptable case 
hand limited number databases available having lot impractical requires lot memory means age vary smooth manner 
solution problem simple sucient see associated web page samples 
signal order change age voice override sample rate algorithm modify length new sound remains original sound 
case default age signal sampled hz validation experiment section want signal sound older override sample rate example hz shorten signal back original time length 
furthermore obviously useful robotic pets may able vary degrees emotion express instance di erence happy happy 
nd question addressed literature 
propose add set parameters normal degree emotion described previous section associated set similar parameters corresponding highest degree emotion give emotion happy 
example parameter normal happiness add parameter de ne variable delta values determines degree emotion normal maximum minimum 
generated delta set actual mean pitch utterance delta 
fact making kind local linear models emotion degrees 
experimentally gives satisfying results requires specify additional set parameters allowing nite range nuances 
validation age emotion degree control order validate techniques precedent part tests human subjects 
far age control concerned subject pairs utterances random emotion asked looks older 
re sampling fre taken range hz 
subject pairs utterances di erence re sampling frequency superior hz random 
mean rate correct age ranking percent satisfying goal 
evaluation control degree emotion test repeated age xed hz pairs consisted utterances emotion time random di erent random degree 
human subjects evaluate utterance expressed higher degree emotion 
pairs subject 
mean rate correct ranking percent goal 
recognition emotions human speech goal necessary robotic pets recognize emotions expressed humans interacting 
human beings generally context modalities ranging facial expression intonation 
unfortunately appropriately context easy thing machine uncontrolled environment instance robust speech recognition situations reach nowadays systems facial expression recognition needs computational resources video devices robotic creatures 
reason investigated far go prosodic information voice 
furthermore speech interested kind occurs everyday conversations means short informal utterances opposed speech produced asked read emotionally paragraph example newspaper 
broad classes emotional content studied joy pleasure sadness grief anger calm neutral 
existing opposed automatic recognition emotions facial expression samal iyengar research speech modality young bosch 
rst studies conducted murray arnott williams stevens trying get ecient machine recognition device searching general qualitative acoustic correlates emotion speech example happiness tends mean pitch utterances higher calm sentences 
increasing awareness ective computing important industrial potential picard pushed research quest performance automatic recognition emotions speech 
unfortunately knowledge large scale study modern tools developped data mining machine learning community conducted 
learning schemes tested polzin waibel slaney simple features polzin waibel slaney small databases examples speaker slaney means power statistical learning schemes may overlooked 
tried systematic data mining traditional standard set features rest literature mean max min max min variance pitch intensity distributions lengths phonemic syllabic segments pitch rising segments 
drawbacks kinds learning schemes support vector machines gaussian mixtures linear discriminants far best dealing data possibly irrelevant features particular allow derive automatically smaller set features optimal eciency feature set explored choosing learning scheme iteratively removing useful features classi cation hand ad hoc linked particular learning scheme selection procedure hand allow detect tness groups features 
speech generated asking human subjects read newspaper texts emotional manner correspond constraints 
knowledge research groups tried build automatic recognition machines everyday speech slaney 
small databases features di erent learning algorithms 
general existing corpus research recognition rates percent basic emotions impossible speakers 
enormous speaker variability described slaney 
chose focus speaker dependent emotion recognition 
necessarily bad point industrial point view targeted robotic pets may interact fact robots manage recognize owner positive feature source robot caretaker 
methodology extension features including new crucial ones learning schemes powerful feature space exploration tools 
large database speakers containing informal short emotional utterances 
experiments conducted freely available data mining software weka implements standards data mining techniques 
database order suciently large databases compromises recording conditions described slaney impractical thousands samples 
japanese professional speakers men women voice actor actress worked radio tv commercials japanese movies animations 
asked imitate everyday speech pronouncing short sentences phrase great exactly see hello see kind food wonderful name 
course english translation japanese utterances 
imagine utter sentences pet robot 
utterance imagine situation pronounce correspond emotional classes joy pleasure sadness grief anger normal neutral 
emotions compatible sentence meaning weka web page www cs waikato ac nz ml allowed utter 
example database evaluated human subjects decide appropriate utterance intonation compatible emotion 
ended database examples speaker emotion samples total 
know having speakers generality results far opportunity examples speaker power modern statistical learning algorithms 
potential drawback database self entrainment speakers asked perform particular task voice intonation produce variable speech natural situations 
data mining techniques features main measures done concerning intonation pitch intensity works reported 
signal measured intensity low passed high passed version cutting frequency chosen hz particular value appears crucial 
sake exhaustivity spectral measure consisting computing norm absolute vector derivative rst mfcc components mel frequency components 
measures performed time frame software signal processing toolkit freely available particular pitch computed algorithm described web page www org known accurate 
measures provides time series values transform produce di erent points view data 
serie values transformed series series minima series maxima series durations local extrema hz smoothed curve models aspects signal series 
get features series computed mean maximum minimum di erence maximum minimum variance median rst quartile third quartile interquartile range mean absolute value local derivative 
total features 
learning algorithms learning schemes developed years see witten frank equivalent ecient certain types class distributions better dealing features case seen posteriori structured feature sets syntactic combination values features crucial 
de nition know structure data ir relevance features mistake investigate problem learning schemes 
consequence chose set representative learning schemes ranging neural networks rule induction classi cation regression 
best meta learning scheme witten frank allows generally signi cant name description nn nearest neighbour nn voted nearest neighbours nn voted nearest neighbours decision tree decision trees decision rules part part decision rules kernel density radial basis function neural net 
linear regression classi cation linear regression lwr classi cation locally weighted regression voted perceptrons perceptrons svm polynomial deg 
support vector machine svm polynomial deg 
support vector machine svm polynomial deg 
support vector machine svm gaussian kernel support vector machine voted features interval prime cation prime regression method naive bayes naive bayes classi cation algorithm adaboosted version part adaboosted version part table learning schemes improvement generalization performance unstable learning schemes decision trees unstable learning algorithm produce di erent recognition machines slight change learning database performed 
chose weka software code executable freely available experiment large scale easily reproduced 
software provides means automatic cross validation search feature spaces genetic algorithms see 
list learning algorithms table 
details algorithms witten frank 
name mean correct generalization rate speakers nn nn nn decision trees decision rules part kernel density linear regression lwr voted perceptrons svm degree svm degree svm degree svm prime naive bayes adaboost adaboost part table features features algorithms rst experiment evaluation conducted algorithms normalized features trained percent database tested remaining percent 
repeated times time di erent percent split performed fold crossvalidation table gives average percentage correct classi cation folds 
see results high success rates obtained percent gures higher reported literature careful number classes types classes time unique 
example slaney report rates percent speaker dependant recognition classes di erent approval prohibition attention 
best way compare fact look results individual learning schemes features learning schemes features papers quote included 
di erence algorithms striking best results obtained adaboosted decision trees rules perform percent nearest neighbours rbf neural nets support vector machines ones typically studies percent perceptrons 
illustrates initial claim careful try di erent learning schemes wants solve problem prior intuitive knowledge 
surprising best results obtained decision trees rules kinds algorithms known dealing features case disparity results 
feature selection rst experiment naturally see feature set reduced reasons small features set provide better generalization performance general see witten frank obviously computationally cheaper compute fewer features interesting see useful features machine learning algorithms ones traditionally put forward psychoacoustic literature 
rst way exploring feature set look results learning schemes decision rules part mainly knowledge discovery devices calm angry sad happy surprisingly simple rules allow percentage correct classi cation generalization percent speaker number database 
striking fact repeated features related intensity low pass signal 
get view feature set simply try visualize 
just con rm precedent intuition low passed intensity crucial distinction emotions gure plots database axis st quartile rd quartile intensity distribution gure st quartile intensity happy angry sad calm fig 

data points speaker database st quartile intensity distribution quartile intensity distribution intensity low passed signal 
speaker 
striking ect happens speakers interesting clusters situated places anger happiness degrees rotated illustration great speaker variability earlier 
di erence scaling di erence qualitative di erence learning schemes learn features 
chosen features stable speaker 
order quantify individual relevance features attributes measure data mining literature expected information gain mutual information class attribute 
corresponds di erence entropies class class attribute see witten frank details computed 
table gives best attributes information gain provide 
table con rms great value features concerning quartiles st quartile intensity happy angry sad calm fig 

data points gure plot st quartile low passed signal intensity distribution rd quartile low passed signal intensity distribution distribution intensity values low passed signals 
shows surprising individually informative features part standard set put forward psychoacoustic studies murray arnott burkhardt stevens williams application oriented research slaney 
aware individual salience feature partially interesting rare success comes combination features 
rst experiment tried compare feature set containing features related low passed signal intensity lpf feature set composed standard features sf slaney mean min max max min variance pitch intensity un signal plus mean length syllabic segments results similar add jitter 
table summarizes feature information gain mean speakers table information gain best features experiments number corresponds mean percentage correct classi cation generalization fold cross validation 
table shows uses quartiles low passed signal intensity gets results extremely similar standard features best result obtained low passed intensity related features percent 
speakers result taken caution indicate previous missed crucial 
saw table intensity features yields substantially lower results learning scheme lpf mean speakers sf mean speakers nn nn nn decision trees decision rules part kernel density linear regression lwr voted perceptrons svm degree svm degree svm degree svm prime naive bayes adaboost adaboost part table comparing standard features low passed signal intensity features features decision rules 
order attain goal nding ecient small set features automatic search method genetic algorithms 
populations features limited generated evolved tness fold cross validation algorithms naive bayes nearest neighbours chose mainly fast train 
exact genetic algorithm simple described goldberg 
outcome experiment obvious selected feature set surprisingly features related quartiles signal intensity features related quartiles pitch contour features relatively low individual information name correct generalization rate mean speakers nn nn nn decision trees decision rules part kernel density linear regression lwr voted perceptrons svm degree svm degree svm degree svm prime naive bayes adaboost adaboost part table optimal feature set gain related quartiles un ltered smoothed intensity curve 
nal experiment features learning algorithms conducted max min median rd quartile st quartile low passed signal intensity pitch un ltered signal intensity 
results summarized table 
observe get similar highest results initially times features 
interestingly variation learning schemes important algorithms performed badly nearest neighbours naive bayes behave satisfying manner surprising set selected algorithms evaluators 
examples provided section large training databases crucial explore feature algorithmic spaces dealing speaker dependent task directly applicable real world robotic pet 
conceivable owner robot give hundreds supervised examples teach recognize way expressing basic emotions probably happens human babies real pets humans tend willing spending lot time robotic pets 
natural ask results training examples 
experiment optimal feature set earlier 
gave algorithms examples class tested remaining items database 
repeated times di erent sets examples results averaged standard deviation low typically table summarizes experiment 
see algorithms manage keep reasonable level performance percent success generalization adaboosted part 
examples cheap algorithms nearest neighbours naive bayes 
results comparable fact slightly superior described case learning line larger database female speakers important learning scheme mean speakers nn nn nn decision trees decision rules part kernel density linear regression lwr voted perceptrons svm degree svm degree svm degree svm prime naive bayes adaboost adaboost part table training examples provided conducted experiments showed level success sucient develop interesting interactions robotic pet 
showed results substantially improved integrated larger cognitive architecture working real world 
example linking recognition module arti cial emotional system kind emotional inertia rarely switches anger happiness half second give additional information tell system uncertainty result 
consequence robot may instance take posture showing sure happening human repeat utterance exaggerated intonation 
provides samples stylized 
teaching robot real world previous paragraph saw adequate features algorithms allows reasonable rate correct recognitions speaker dependent case 
remains problem providing examples robot user friendly manner stated communicate robotic pets relatively natural manner 
implies acceptable instance ask user connect robot computer windows mouse interface record samples 
developed experimented small game spirit language games robotic models acquisition language steels steels kirby 
idea regulate interactions simple keywords human robot ability express emotions see section 
continuous word spotting module implemented robot available instance sony aibo robot nec robot 
robot continuously listen humans say computing intonation parameters sentences hear classify react detected emotion 
instance robot detects happy sentence utters happy modi es facial expression accordingly changing colors leds face hears sad sentence gets sad calm neutral sentences special course 
robot reacts un appropriate manner human say sentence key word equivalent key word bad guess experiments 
say sentence containing key word designating intended emotion example angry 
robot stores intonation parameters sentence heard containing bad guess associated class corresponding second key word 
gives example put database 
possible key word done experiments means robots reacted sentence shall add intonation parameters sentence database 
note robots sony aibo robot possible replace bad guess done key words information coming gentle rm tap sensor head 
initially robot empty database pre programmed think neutral initially 
learning scheme nearest neighbour algorithm 
practice robust guesses possible typically examples class 
illustrate mechanism videos showing game virtual character projected wall human available shown generate life vocalizations basic emotions recognizable people di erent linguistic cultural background 
algorithm advantage extremely simple parameters need controlled completely speci ed 
www csl sony fr py showed concatenative speech synthesis successfully formant synthesis 
concentrate extending range emotions 
validated techniques allow continuous control degree emotion ways control smoothly age voice 
far recognition concerned showed large scale modern data mining techniques allowed nd non obvious features missed precedent studies 
particular interesting see features put forward psychoacoustic literature ones preferred machine learning algorithms 
precedent studies show emotion recognition dicult task principle suggest speaker dependent recognition reach high scores adequate features learning schemes 
showed right set features reasonable performance reached examples case real situation robots 
remain prudent results obtained professional speakers high quality microphones quiet environment 
microphones real noisy robots bring diculties 
fact professional speakers biased target research recognize emotional information humans talk pet 
case emphasize intonation professional speakers see breazeal 
note results improved algorithms embedded complete cognitive robot cues intonation vision linguistic cues semantic cues decide emotional state human beings 
serve basis necessary additional experiments databases including speakers di erent languages realistic settings 
freely available softwares allow people possess databases help pursue research 
tanaka colleagues sony digital creature lab tokyo providing databases dr doi president sony computer science labs sony digital creature lab tokyo support research 
cross linguistic interpretation emotional prosody proceedings isca workshop speech emotion 
acoustic pro les vocal emotion expression journal personality social psychology 

accurate short term analysis fundamental frequency harmonics noise ratio sampled sound proceedings institute phonetic sciences university amsterdam 

designing social robots mit press cambridge ma 
burkhardt veri cation acoustical correlates emotional speech formant synthesis proceedings isca workshop speech emotion 

emotions possible asr framework proceedings isca workshop speech emotion 
cahn 
generation ect synthesized speech journal voice american society 

anger go role context interpreting emotions speech isca workshop speech emotion 
druin hendler 
robots kids exploring new technologies learning morgan kau man publishers 

traitement de la parole presses 
mbr text speech synthesis re synthesis segments database speech communication 
investigating limitations concatenative speech synthesis proceedings eurospeech rhode greece 
ekman 
emotions human face cambridge university press cambridge 
fujita kitano 
development autonomous quadruped robot robot entertainment autonomous robots 

testing ective correlates voice quality analysis resynthesis proceedings isca workshop emotion speech 
goldberg 
genetic algorithms search optimization machine learning reading ma addison wesley 
halliday 
learning mean explorations development language elsevier ny 
iida 
speech synthesis system emotion assisting communication isca workshop speech emotion 

validation acoustical modelling emotional expression spanish speech synthesis techniques proceedings isca workshop speech emotion 

acoustical analysis spectral temporal changes emotional speech proccedings isca workshop emotion speech 
koike suzuki saito 
prosodic parameters emotional speech proccedings icslp pp 

kirby 
syntax natural selection emerges vocabulary population learners hurford knight 
eds approaches evolution language cambridge cambridge university press 

art creating subjective reality analysis japanese digital pets ed arti cial life workshop proceedings pp 

massaro multimodal emotion perception analogous speech processes isca workshop speech emotion belfast 

approaching automatic recognition emotion voice rough benchmark proceedings isca workshop speech emotion 
murray arnott implementation testing system producing emotion rule synthetic speech speech communication pp 

murray arnott simulation emotion synthetic speech review literature human vocal emotion jasa pp 


origins syllable systems operational model appear proceedings international conference cognitive science cogsci edinburgh scotland 

coupled neural maps origins vowel systems appear proceedings international conference arti cial neural networks icann vienna austria 
picard 
ective computing mit press 
polzin waibel 
emotion sensitive human computer interface proccedings isca workshop speech emotion 
reeves nass 
media equation cambridge university press 
samal iyengar automatic recognition analysis human faces facial expression survey 
pattern recognition 

cultural similarities di erences recognition audio visual speech stimuli proceedings icslp 
slaney 
baby ears recognition system affective proceedings icassp 
steels 
synthetic modelling language origins 
evolution communication 
steels 
cultural evolution syntactic constraints phonology bedau mccaskill packard rasmussen eds proceedings th international conference arti cial life pp 
mit press 

english japanese speaker emotion vocalizations recognition comparison highlighting vowel quality isca workshop speech emotion belfast 
vine synthesizing emotional speech concatenating multiple pitch recorded speech units isca workshop speech emotion belfast 

simulated emotions acoustic study voice perturbation measures proceedings icslp pp 

williams stevens emotions speech acoustical correlates jasa 
witten frank 
data mining morgan kau publishers 

