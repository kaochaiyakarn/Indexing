conscious data preparation large scale web search engines maxim tzi cker chiueh department computer science department computer science suny stony brook suny stony brook stony brook ny stony brook ny usa usa maxim cs sunysb edu chiueh cs sunysb edu commercial search engines cover billions web pages efficiently managing corresponding volumes disk resident data needed answer user queries quickly formidable data manipulation challenge 
general technique efficiently carrying large sets simple transformation querying operations external memory data tables 
greatly reduces number performed disk accesses seeks maximizing temporal locality data access organizing necessary disk accesses long sequential reads writes data reused times memory 
technique experience building functionally complete fully operational web search engine called yuntis 
particular suited data manipulation tasks modern web search engine employed yuntis 
key idea technique coordinated partitioning related data tables corresponding partitioning delayed batched execution transformation querying operations data 
data processing partitioning naturally compatible distributed data storage parallel execution cluster workstations 
empirical measurements yuntis prototype demonstrate technique permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings th vldb conference hong kong china improve performance external memory data preparation runs factor versus straightforward implementation 
web search engines altavista fast search google indispensable tool web surfers access information global web 
past years working implementation full scale web search engine general powerful resource ranking model google pagerank :10.1.1.31.1768
effort data preparation process search engine poses set different requirements traditional database applications deserves development new techniques optimize performance 
reports results investigation 
answer user queries efficiently search engines particular need prepare index usually form inverted index file 
approximation associates keyword list pages keyword appears 
construct inverted index search engine needs collect pages web parse assign identifier page put identifier page hit lists keywords contains 
process various types data structures inverted index need created 
addition developed search engines google compute various scores web pages performing non trivial iterative computation web linkage graph 
sheer data volume involved data tables including inverted index data page score computation fit main memory processing servers modern search engines presently index web pages manipulate terabytes data 
result efficient external memory algorithms minimize disk access overhead parallel processing clusters workstations crucial achieving acceptable performance search engine data preparation 
database system design standpoint key difference web search engines standard database systems consistency requirement response updates weaker search engine 
general assumption search engine keeping larger snapshot web important maintaining absolute todate view inevitably smaller portion web 
result search engine need react page updates immediately free incorporate order long completed period time days 
implementation experience line yuntis web search engine prototype derived general implementation approach external data manipulation believe equally applicable data intensive applications similar data volume processing performance requirements properties 
reduce disk access overhead apply data driven processing principle minimize costs external memory data major data preparation tasks search engine prototype 
paid cost group external data items try possible ram 
addition try organize necessary disk set long sequential buffered reads writes larger set smaller random accesses incur greater number disk seeks 
achieve physically splitting coordinated fashion closely related external data structures disjoint partition groups small fit ram 
logically arrange processing performed external data set sequences simple procedures need data partition group 
organize processing batched way input data procedures data partition group queued disk 
long possible queues executed sequentially bringing partition group data ram time queued procedures run 
addition perform data processing partitioning locally connected cluster workstations exploit inter operation parallelism 
efficient non preemptive uni threaded data driven process model allows exploit application concurrency inexpensively run coding time 
rest organized follows 
review related section 
section presents main distinguishing features web search engines common data manipulation pattern 
section show data driven processing technique ex data manipulation pattern high performance search engine data preparation 
illustrate technique example discuss various design issues describe cluster workstations event driven processing model improve performance 
report results performance evaluation study fully operational yuntis search engine prototype sections 
conclude summary major research contributions outline 
related substantial amount research design efficient implementation various features web search engines 
particular ribeiro neto described inverted index construction scheme carefully optimized clustered execution 
proposed distributed index construction method applied explicit disk cpu network communication pipeline 
hirai analyzed different design aspects repository system generic web page storage update retrieval 
haveliwala described disk efficient non distributed method compute pagerank large web linkage graphs :10.1.1.31.1768:10.1.1.31.1768
stata showed design construct filtered database interesting words web pages 
bharat described experience building server constructs queries compact representation forward backward linkage set web pages 
common property efforts concentrates search engine data preparation tasks develops efficient algorithm tailored 
hand open information available detailed integrated design processing tasks modern large scale commercial web search engine 
brin page briefly describe design decisions building early prototype google search engine :10.1.1.109.4049
approach taken loosely putting algorithms explicitly optimized specific data manipulation task 
area disk access optimization disk data placement smart disk head scheduling data replication disks reduce read seek times 
techniques usually disk driver os level automatically perform cases 
disk data prefetching schemes mask disk access data processing time larger time 
similarly data striping multiple independent disks simply produces virtual disk better seek throughput parameters real disks 
technique orthogonal complementary works application level increase temporal access locality proportion se disk accesses 
closest analogs approach batch filtering technique bulk simultaneous searching core dag data structure area external memory algorithms data driven processing ideas volume rendering yang chiueh 
methods rely reuse data items pre fetched disk possible delaying performing necessary processing shot 
focuses design general method efficient conscious bulk manipulation external memory data structures 
method mechanically applied improve performance natural formulation data manipulation algorithms eliminating need optimize task individually 
easily data preparation tasks modern web search engine including text indexing linkage construction incremental graph score computation extraction corpus phrases document key terms 
believe proposed approach similarly applies tasks large sets updating querying operations executed efficiently partitionable external memory data structures 
data preparation web search engines provide fast accurate response user queries web search engines pre compute various types data structures pages collected web :10.1.1.109.4049
examples include inverted index web page linkage graph list urls previously visited results text classification data structure data structure improve querying service efficiency 
instance page quality scores embedded inverted indexes filter undesirable pages early :10.1.1.109.4049
data preparation tasks data acquisition web crawler gets url needs check url visited 
crawler marks visited schedules crawled 
mark url crawler typically store url name string allocate internal identifier establish mappings add initial information record url 
standard data preprocessing update inverted index web pages crawler knows word occurs certain places crawled web page parsing determine internal identifier word possibly adding necessary records word appears time appropriately update hit list word word occurrences 
build internal data structure web page linkage crawler encounters hyper link page locate internal identifier page url adding new urls databases update lists forward backward links associated urls 
score computation web page score rank computation pagerank method hubs authorities approach voting model performed multiple iterations :10.1.1.31.1768:10.1.1.109.4049
iteration algorithm usually goes pages 
page algorithm retrieves current score values page list pages points point adjusts score values pointed pointing pages page current score values 
statistical data amount score changes consecutive iterations usually computed 
data preparation tasks constitute bulk pre query typical web search engine 
usually thought composed execution simple procedures relatively small number types input data items read update parts certain records data tables possibly initiate execution procedures 
instances kind procedures executed search engine data structures consistent large batch updates due crawling usually touch multiple times substantial portion external data tables working 
data manipulation approaches modern search engines cover web pages types data structures web search engines working external memory relatively large cluster modern workstations 
cases individual data items lists occurrences frequent words lists back links popular web pages fit ram affordable workstations 
result linear time disk aware data manipulation algorithms 
actual implementation algorithms small associated constant factors instance performance difference factor turn reasonable task runs days impossible job taken year complete 
particular implementation avoid performing unnecessary disk accesses especially seeks 
example basic information encountered url including name occupy bytes average prototype 
just basic information urls require gb storage 
naive way manipulate data follow control driven approach 
perform data updates soon done 
example web page collected parsed associated inverted index entries modified derived data structures web page linkage graph changed accordingly 
approach web page update may trigger large set disk os 
general control driven approach conceptually simple straightforward implement leads inefficient disk resource data brought disk os associated processing data modification necessarily reused processing subsequent updates 
somewhat improve performance control driven approach virtual striped disks better characteristics ram fitting data ram smart encodings start moving away purely control driven computation explicitly exploiting data patterns access locality exists particular workload abandon control driven approach favor developing task specific algorithms data structures :10.1.1.162.194:10.1.1.109.4049
methods provide radical performance improvement hard apply mechanically wide set data preparation tasks 
light failing control driven approach data driven approach considered appropriate 
case perform elementary manipulation procedures external memory data data need main memory 
achieved delaying execution procedures batching input queues associated external memory regions procedures going 
addition points time system bring ram data regions activate procedures queued data regions 
data regions reused multiple times associated disk overhead amortized multiple operations strive trigger computation external region lot procedures queued 
essentially data manipulation procedure triggered availability data needs memory 
note addition pure data flow requirements usually higher level control flow scheduling obeyed example breadth crawling required done arbitrarily frontiers new pages link away set currently known pages 
data driven approach relies batching procedures require data performing shot data memory 
known problem operation batching hash hash url uid uid lid nid uid url 
uid data table structures web page back linkage construction process 
creases operation latency 
fortunately latency individual procedures concern case web search engine 
performance goal search engine data preparation algorithm complete data update respect web page update quickly possible finish data updates large sets crawled web pages soon possible 
data driven data manipulation start concrete example illustrate typical processing flow data preparation large scale search engines specific implementation technique optimize external memory data manipulation process 
example scenario back linkage construction goal task construct backward linkage information set web pages 
assume working data tables see set fixed width url name hash values internal url identifiers uids locating data url name 
organized way records searched hash value added log amortized time 
memory heap data table holds variable width strings url names accessed fixed width pointers store url names 
data table similar contains lists uids pages point particular url 
table represents url linkage graph 
array fixed width url information records indexed uids particular contains pointers structures 
structure ties maps uid data stored url 
url identifier linking page url linked page back linkage construction procedure 
searches set uids hash value url pointed page 
verifies uids really correspond pointed page url reading comparing url names associated uids pointers 
creates new uid inserts appropriate new elements tables find match 
adds uid linking page list linked page updating pointer entry 
procedure corresponds pair linking linked pages touches portions tables related hash value linked page url 
executing procedure soon possible hyper linked page pair choose page pairs batches trying piece data table brought memory disk reused times possible 
specifically partition data tables coordinated fashion step procedure proceed data group data table partitions 
addition data table partition group procedure requires memory resident procedure attached data table partition group get executed data table partition group available memory 
usually wait multiple procedures get attached data table partition group executing data driven approach enables batching procedures require data table partition group greatly decreasing disk cost 
disk access pattern longer dictated control flow data manipulation algorithm 
result disk os sequential accesses improves disk bandwidth utilization 
data driven approach mainly oriented optimizing disk reads concerned disk writes synchronous disk writing small data items required search engine data preparation 
disk writing left standard file cache management underlying operating system regular os files data storage 
explicit long sequential file writes occur frequently see shortly 
case back linkage construction apply data driven processing approach split data tables ranges hash values urls information placed table table partition group workstation data table view proc input proc input partition group table table partition group partition group workstation coordinated partitioning related data tables input data transformation procedure batches data tables 
procedures partition group need data table partitions group 
records table partition groups provides simplified illustration tables omitted 
uids stored partition refer records partition turn contains pointers ith partitions 
new data table records created certain partition group determined hash value url name existing records move partitions created 
portion uid bits partition number remaining bits record identifiers partition 
pointers stored partition local portion partition number 
number partitions targeted data set size partition fit main memory simultaneously space left caching portion partition 
secondly introduce new table partitioned way tables organized queue records containing url identifiers expect hold complete partition memory individual link lists popular urls large number links follows powerlaw distribution 
url names hyper linked page pair 
back linkage procedure hyper linked page pair ready run start immediately 
queue input data partition hash value linked url hope batch execution multiple procedures 
procedure input pairs accumulated task proceed execute procedures partition partition batch stored ith partition procedure executed follows 
sequentially read memory ith partitions 
execute procedures input tuples ith partition sequentially reading contents 
procedures operate data ith partitions memory data ith partition 
appropriate organization table touching cached heads tails link lists execution procedures 
executing procedures associated ith partition unload resulting modified partitions disk sequential writing possibly performing compression clean operations 
case tables buffered data execute procedures example table table partition partition table 
main requirement execute procedures partition time take full advantage memory preferably doing input procedures accumulated keeping size buffered input data large 
analysis data driven approach analytical performance analysis overhead performance overhead datadriven data manipulation approach lies additional packing unpacking reading writing input data procedures execution delayed batched 
cpu disk cost linear respect number procedures executed sequential disk required 
table partitioning adds small constant overhead direct table access appropriate partition 
forced short batches data manipulation procedures meet computation dependencies revert performance control driven strategy 
benefits main benefit proposed datadriven strategy guarantees memory access data class data tables improved data access locality tables data preparation process 
addition accesses class data tables serviced sequential disk reads writes utilizing disk bandwidth efficiently 
assume data tables hold information objects gb data totally 
mb ram available data file cache disk average seek time msec sustainable data transfer rate mb sec 
assume need perform data manipulation procedures touches tables exactly requires input data size procedure average 
random access pattern control driven approach lead file cache hit ratio 
procedure require msec time disk seeks 
data tables decomposed partitions fits ram total disk data transfer requirement writing reading procedures input data data tables 
disk time procedure datadriven approach msec times better 
assume disk data driven approach sequential disk seek delay negligible 
optimization task specific optimizations task specific optimizations embedded general datadriven strategy 
example locality preserving hash function exploits existing data patterns high host locality urls close linkage graph achieve better cpu file cache utilization reduce intracluster communication 
compact data encoding applied individual data table partitions construction updating naturally included loading unloading data table partition 
periodically perform compaction external memory partitions data tables 
compaction changes pointers needed access records compacted partition update pointers additional cost typically stored respective partition data table data needed performing updates fits main memory 
exploiting parallelism pc cluster batch partition data manipulation procedures independent multiple batches downside technique experience indicates increase processing load different cluster nodes reducing effectiveness cluster 
benefits locality crawling significant urls host necessary crawled close time crawling guided estimated importance pages 
executed parallel shared cluster pcs connected high speed local area network 
data table partitions associated batch placed cluster node see additional cost parallelism intra cluster communication overhead due messages transferring input data procedures executed node different initiated 
result value needed returned messages incur significant synchronization delays nodes synchronization completion needed finish executing batches type node 
execution procedure batches proceed completely locally independently node 
experimental data section show data partitioning object name hashing dividing cluster nodes evenly proportionally node performance 
dynamic re balancing transfer data usually required cluster nodes achieve high utilization cluster 
efficient data driven process model maximize cpu utilization efficiency data manipulation structured non blocking respect operations transfer input data procedures cluster nodes request reply communication search engine components different cluster nodes communication web servers local disk reads writes 
addition exploit spare cpu cycles support execution large number potentially concurrent activities 
achieved main control thread performs descriptor polling user level scheduling small units blocking non blocking network disk call callback interfaces potentially blocking requests traditional call return interfaces 
approach avoids performance overheads associated threads kernel scheduling context switching stack task data structures allocation synchronization inter thread communication thread safety issues 
discussion conditions application prerequisite conditions allow successful application data driven approach data preparation search engines scale data table sizes needs known advance determine number partitions 
hash function decompose data tables approximately equally sized partitions 
type data manipulation procedure data partition group data tables partitioned way 
experiences show conditions guarantee data partition group fit available memory relatively easy meet 
third condition requires additional attention 
data manipulation procedure satisfy requirement needs split simpler ones satisfy requirement 
example assume wish construct forward linkage information table way backward linkage filled table earlier example 
augmenting previously data manipulation procedure introduce second data manipulation procedure separate queue input tuples 
uids new procedure adds second list forward links record corresponding uid 
new data manipulation procedure initiated soon uid linked document known 
splitting augmented version procedure new old initiation new needed updating forward linkage information touches data linking url done uid linked url known construction backward linkage information touches data linked url determines uid 
splitting computation procedures adds small level additional overhead enqueuing dequeuing input data additional types procedures 
extra condition general applicability data driven approach cases web search engines throughput performance large volume simple data transformation querying operations optimized operations external memory data sets automatic access locality 
universality important property proposed data driven approach place substantial restrictions structure data tables stored disk 
requirement partition number embedded identifiers object identifier address space 
property loading table partitions main memory time actively accessed gives additional freedom data table partitions organized 
demonstration universality data driven approach certain cases leads improved performance simple increment propagation algorithm operates memory resident sparse graph 
reason improvement approach enhances access locality takes better advantage cpu cache way performed numer procedures executed hit list url score querying hit list score filling data size right axis gb gb gb gb gb gb gb gb gb data set size number web pages linear growth handled data performed different workloads data set size grows 
effective memory os file cache access disk resident data 
performance evaluation implementation embodied techniques described previous section fully operational search engine prototype yuntis implemented linux os 
implementation consists files mb total size kb compressed gzip contain lines code logical modules 
latest version prototype accessible yuntis cs sunysb edu 
largest current data set millions crawled web pages 
yuntis utilizes new model assessing web pages relevance quality subsumes improves google model 
prototype running cluster linux pcs connected mb sec full duplex switch pentium iii mhz cpu mhz bus mb ram eide maxtor disk data msec average seek time gb capacity mb maximal media transfer rate 
flexibility proposed implementation techniques object orientation implementation communication database primitives allow experiment adding modifying different architectural features data tables data processing methods prototype quickly providing efficient network performance 
modern scsi disks maxtor atlas iii offer reduced msec seek time slightly higher media transfer rate mb threefold price increase compare disk installations 
data size pages compressed cpu utilization percentage total cpu utilization user mode cpu utilization performance right axis data set size number web pages cpu utilization performance constructing hit lists increasing data set sizes 
cpu utilization percentage total cpu utilization user mode cpu utilization performance right axis data set size number web pages cpu utilization performance querying url scores hits increasing data set sizes 
results analysis performed set experiments demonstrating effectiveness proposed data driven technique coordinated partitioning batching different search engine data manipulation workloads 
experiments show high cpu utilization high performance level handling data sets primarily located ram disk 
direct comparison straightforward control driven implementation shows significant performance improvements ram external memory data sets 
lowlevel measurements disk read requests indicate higher proportion fast reads seeks data driven technique compared 
technique primarily works increasing access locality reducing number misses ram os disk cpu caches absolute sizes data sets experiments important proving effectiveness approach sizes compared amount performance procedures sec performance procedures sec cpu utilization percentage total cpu utilization user mode cpu utilization performance right axis data set size number web pages cpu utilization performance filling url scores hits increasing data set sizes 
ram available os disk cache 
effectiveness data driven approach various workloads demonstrates essentially linear growth respect number crawled web pages total size compressed web pages required number data transformation procedures different data manipulation workloads chosen 
figures provide graphs total cpu utilization percentage application os cpu utilization percentage application performance terms number procedures executed second running workloads increasingly larger sets web pages 
workloads data tables partitioned hashing url word name strings partitions cluster node url word related data respectively 
procedures hit list construction workload see resolve word name identifier add information occurrences document hit list adding needed records newly encountered words 
workload performance somewhat reduces cpu utilization remains high due need sequential disk workload data set mainly disk resident 
url score querying workload procedure gets url score value particular url identifier array lookup initiates execution hit list score filling procedure 
step consists batching input data procedures appropriate partition disk cluster node 
procedure data sets largest breadth crawls sunysb edu domain starting www sunysb edu 
largest data sets composed portion pages referenced odp directory dmoz org 
reported data points averages cluster nodes 
performance procedures sec performance procedures sec partitions data driven mb ram partitions data driven mb ram partition control driven mb ram partition control driven mb ram data set size number web pages performance comparison data control driven approaches constructing hit lists different data set ram sizes 
hit list score filling workload consists simply changing score fields existing hit list data structure accessed addresses 
performance decline data point due peculiarity implementation measurement data size processes cluster nodes receive batch procedure input data nodes took portion cpu resources 
workloads require essentially constant amount cpu resources os tasks amount different different workloads 
results show higher level os cpu resource usage workloads requires intra cluster network communication writing disk 
important workloads see significant performance degradation web page set grows pages gb data tables cluster nodes mb ram file cache 
workloads cpu utilization percentage remains showing disk time largely overlapped computation 
means technique works providing efficient way access manipulate large sets disk resident data 
comparison data driven control driven approaches data figures contrasts performance characteristics hit list construction workload change amount memory mb mb number partitions cluster node 
setting number partitions node effectively converts data driven approach control driven 
difference pure control driven approach small overhead enqueuing dequeuing procedures input data total cpu utilization percentage partitions data driven mb ram partitions data driven mb ram partition control driven mb ram partition control driven mb ram data set size number web pages total cpu utilization comparison data control driven approaches constructing hit lists different data set ram sizes 
separation processing time different workloads 
procedures inputs enqueued dequeued order generated partitioning cluster node resulting data access pattern corresponds pure control driven approach workload 
shows reducing amount memory making data disk resident noticeably affect performance datadriven approach 
switching control driven approach reduces performance factor web pages 
cpu utilization percentage remains case random disk accesses needed 
reason performance drop increase cpu cache misses due larger working sets mainly memory resident 
reduce amount ram node working sets mainly disk resident processing web pages performance control driven approach drops factor procedures sec due substantial number non sequential disk accesses issued evidenced fact cpu utilization drops case 
point control driven approach performance lowered procedures sec processing web pages mb ram 
theoretical minimum performance workload assuming procedure needs msec disk seeks 
contrast data driven approach able sustain procedures sec performance rate handling web pages factor peak performance rate procedures sec entire data set 
hit list construction workload data driven approach performance percentage requests msec partitions data driven mb ram web pages partition control driven mb ram web pages ide drive read request time msec disk reading latency comparison data control driven approaches constructing hit lists 
times better compared control driven approach working set substantially exceeds available system memory times better working set fits memory 
obtain similar performance improvement results workloads possibly different data set memory sizes provided working set size control driven execution exceeds amount available memory 
disk utilization efficiency advantage proposed data driven approach disk access pattern sequential control flow dictate order data blocks fetched disk 
instrumented ide driver linux kernel directly evaluate degree data driven technique avoids disk seeks manipulating disk resident data measuring time taken individual read requests ide disk 
shows histograms percentages ide disk read requests took different amount time complete performing hit list construction task web pages node cluster mb memory node 
data manipulated workload mb cluster node processing core 
curve data driven approach shows majority disk reads take smaller amount time sequential 
disk seeks required disk reads case particular os may write dirty pages disk reads going cpu utilization percentage high 
curve control driven approach reflects expected sequentiality data driven approach 
figures conclusively demonstrate data driven approach better reuse factor disk block brought requires overhead disk result data driven approach data preparation large scale search engines perform orders magnitude better control driven approach modern hardware core data sets 
scalability clustering implementation aspects clustering effectiveness communication synchronization overheads balanced nodes 
data url score querying data driven technique document collection shows uniform workload communication intensive disk access intensive data driven execution communication model achieve cpu utilization cluster node due high parallelism weak synchronization requirements workload fractions idle cpu time cluster nodes processes node 
hard single cluster communication costs amount cluster traffic node order disk exchange traffic 
data partitioning simple hash functions object names effective providing partition sizes diverse sizes individual data items partitions 
result remaining resulting processing different cluster nodes leads effectiveness node cluster versus times faster execution node different workloads handling document collection 
internet scale search engines need build various types data structures efficiently support large number user queries substantial portion global web 
preparation data poses unique engineering challenge sheer volume external memory data sets involved 
key architectural requirement data manipulation search engines avoidance random small disk fortunately nature search engine applications allows concentrate improving throughput large groups modifications latency individual updates 
described data driven technique organize data manipulation triggers computation required data brought memory amortizes cost disk large groups computation operations 
analyzed applicability conditions showing easily large streams reads updates executed immediately operate partitionable data structures 
conceptually simple technique enormously powerful greatly improves disk memory data access locality converts small random disk os large sequential ones increases cpu throughput higher cache hit ratio 
result efficiency data preparation process significantly improved experiments demonstrate manipulated data sets grow far memory size execution performance improves factor typical workloads compared straightforward control driven execution model 
addition technique naturally combines clustering exploit parallelism manifested data manipulation 
experience applying techniques data manipulations tasks comprehensive search engine prototype yuntis convinced techniques equally effective data intensive internet applications similar requirements 
best knowledge open literature description driven manipulation technique universality effectiveness application data preparation large scale web search engines detailed empirical performance comparison control driven approach demonstrates fold performance advantage functionally complete fully operational search engine prototype yuntis 
includes selective asynchronous disk doing outperforms non blocking disk read ahead os 
plan investigate tradeoffs dynamic migration processing data cluster nodes achieve better cluster utilization 
acknowledgments partially supported nsf iri mip 
benefited comments anonymous reviewers 
kenneth salem 
placing replicated data reduce seek delays 
proceedings usenix file systems workshop pages berkeley california may 
usenix 
www com 
altavista www altavista com 
arvind arasu junghoo cho hector garcia molina andreas paepcke sriram raghavan 
searching web 
acm transactions internet technology volume pages 
acm press june 
krishna bharat andrei broder monika henzinger kumar suresh venkatasubramanian 
connectivity server fast access linkage information web 
proceedings th international world wide web conference april 
sergey brin lawrence page :10.1.1.109.4049
anatomy large scale hypertextual web search engine 
proceedings th international world wide web conference april 
andrei broder ravi kumar maghoul prabhakar raghavan sridhar rajagopalan raymie stata andrew tomkins janet wiener 
graph structure web experiments models 
proceedings th international world wide web conference amsterdam netherlands may 
junghoo cho hector garcia molina 
parallel crawlers 
technical report stanford university california 
junghoo cho hector garcia molina lawrence page 
efficient crawling url ordering 
proceedings seventh world wide web conference 
michael goodrich jong darren jeffrey scott vitter 
computational geometry 
proceedings th annual ieee symposium foundations computer science focs pages palo alto california november 
google www google com 
haveliwala 
efficient computation pagerank 
technical report stanford university california february 
allan heydon marc najork 
mercator scalable extensible web crawler 
world wide web december 
jun hirai sriram raghavan hector garcia molina andreas paepcke 
webbase repository web pages 
proceedings th international world wide web conference amsterdam netherlands may 
jon kleinberg 
authoritative sources hyperlinked environment 
proceedings ninth annual acm siam symposium discrete algorithms pages san francisco california january 
maxim 
rank computation methods web documents 
technical report tr department computer science suny stony brook stony brook new york november 
maxim 
voting model ranking web pages 
peter graham maheswaran editors proceedings international conference internet computing pages las vegas nevada june 
sergey melnik sriram raghavan beverly yang hector garcia molina 
building distributed full text index web 
proceedings th international world wide web conference hong kong may 
lawrence page sergey brin rajeev motwani terry winograd 
pagerank citation ranking bringing order web 
technical report stanford university california 
berthier ribeiro neto moura ziviani 
efficient distributed algorithms build inverted files 
proceedings nd annual international acm sigir conference information retrieval pages berkeley california august 
margo seltzer peter chen john ousterhout 
disk scheduling revisited 
proceedings winter usenix conference pages berkeley california january 
usenix 
raymie stata krishna bharat maghoul 
term vector database fast access indexing terms web pages 
proceedings th international world wide web conference amsterdam netherlands may 
jeffrey scott vitter 
external memory algorithms data structures dealing massive data 
acm computing surveys june 
paul scott carson 
system adaptive disk rearrangement 
software practice experience march 
chuan kai yang tzi cker chiueh 
conscious volume rendering 
ebert favre editors proceedings joint eurographics ieee symposium pages wien austria may 
xiang yu benjamin gum chen randolph wang kai li arvind krishnamurthy thomas anderson 
trading capacity performance disk array 
proceedings th symposium operating systems design implementation osdi pages berkeley california october 
usenix 
