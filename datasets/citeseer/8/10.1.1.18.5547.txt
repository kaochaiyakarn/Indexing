journal artificial intelligence research submitted published smote synthetic minority sampling technique chawla chawla csee edu department computer science engineering enb university south florida fowler ave tampa fl usa kevin bowyer cse nd edu department computer science engineering fitzpatrick hall university notre dame notre dame usa lawrence hall hall csee edu department computer science engineering enb university south florida fowler ave tampa fl usa philip kegelmeyer california sandia gov sandia national laboratories biosystems research department box ms livermore ca usa approach construction classifiers imbalanced datasets described 
dataset imbalanced classification categories approximately equally represented 
real world data sets predominately composed normal examples small percentage abnormal interesting examples 
case cost misclassifying abnormal interesting example normal example higher cost reverse error 
sampling majority normal class proposed means increasing sensitivity classifier minority class 
shows combination method sampling minority abnormal class sampling majority normal class achieve better classifier performance roc space sampling majority class 
shows combination method sampling minority class sampling majority class achieve better classifier performance roc space varying loss ratios ripper class priors naive bayes 
method sampling minority class involves creating synthetic minority class examples 
experiments performed ripper naive bayes classifier 
method evaluated area receiver operating characteristic curve auc roc convex hull strategy 

dataset imbalanced classes approximately equally represented 
imbalance order prevalent fraud detection imbalance ai access foundation morgan kaufmann publishers 
rights reserved 
chawla bowyer hall kegelmeyer reported applications provost fawcett 
attempts deal imbalanced datasets domains fraudulent telephone calls fawcett provost telecommunications management singh norton text classification lewis catlett dumais platt heckerman sahami mladenic grobelnik lewis ringuette cohen detection oil spills satellite images kubat holte matwin 
performance machine learning algorithms typically evaluated predictive accuracy 
appropriate data imbalanced costs di erent errors vary markedly 
example consider classification pixels mammogram images possibly woods bowyer kegelmeyer 
typical mammography dataset contain normal pixels abnormal pixels 
simple default strategy guessing majority class give predictive accuracy 
nature application requires fairly high rate correct detection minority class allows small error rate majority class order achieve 
simple predictive accuracy clearly appropriate situations 
receiver operating characteristic roc curve standard technique summarizing classifier performance range tradeo true positive false positive error rates swets 
area curve auc accepted traditional performance metric roc curve duda hart stork bradley lee 
roc convex hull robust method identifying potentially optimal classifiers provost fawcett 
line passes point convex hull line slope passing point larger true positive tp intercept 
classifier point optimal distribution assumptions tandem slope 
machine learning community addressed issue class imbalance ways 
assign distinct costs training examples pazzani merz murphy ali hume brunk domingos 
re sample original dataset oversampling minority class sampling majority class kubat matwin japkowicz lewis catlett ling li 
approach chawla bowyer hall kegelmeyer blends sampling majority class special form sampling minority class 
experiments various datasets decision tree classifier quinlan ripper cohen naive bayes classifier show approach improves previous re sampling modifying loss ratio class priors approaches auc roc convex hull 
section gives overview performance measures 
section reviews closely related dealing imbalanced datasets 
section presents details approach 
section presents experimental results comparing approach re sampling approaches 
section discusses results suggests directions 

performance measures performance machine learning algorithms typically evaluated confusion matrix illustrated class problem 
columns predicted class rows actual class 
confusion matrix tn number negative examples smote predicted negative predicted positive tn fp fn tp actual negative actual positive confusion matrix correctly classified true negatives fp number negative examples incorrectly classified positive false positives fn number positive examples incorrectly classified negative false negatives tp number positive examples correctly classified true positives 
predictive accuracy performance measure generally associated machine learning algorithms defined accuracy tp tn tp fp tn fn 
context balanced datasets equal error costs reasonable error rate performance metric 
error rate accuracy 
presence imbalanced datasets unequal error costs appropriate roc curve similar techniques ling li drummond holte provost fawcett bradley turney 
roc curves thought representing family best decision boundaries relative costs tp fp 
roc curve axis represents fp fp tn fp axis represents tp tp tp fn 
ideal point roc curve positive examples classified correctly negative examples misclassified positive 
way roc curve swept manipulating balance training samples class training set 
shows illustration 
line represents scenario randomly guessing class 
area roc curve auc useful metric classifier performance independent decision criterion selected prior probabilities 
auc comparison establish dominance relationship classifiers 
roc curves intersecting total auc average comparison models lee 
specific cost class distributions classifier having maximum auc may fact suboptimal 
compute roc convex hulls points lying roc convex hull potentially optimal provost fawcett kohavi provost fawcett :10.1.1.21.805

previous imbalanced datasets kubat matwin selectively sampled majority class keeping original population minority class 
geometric mean performance measure classifier related single point roc curve 
minority examples divided categories noise overlapping positive class decision region borderline samples redundant samples safe samples 
borderline examples detected tomek links concept tomek 
chawla bowyer hall kegelmeyer percent true positive percent false positive original data set increased undersampling majority class moves operating point upper right roc ideal point illustration sweeping roc curve sampling 
increased sampling majority negative class move performance lower left point upper right 
related proposed shrink system classifies overlapping region minority positive majority negative classes positive searches best positive region kubat 
japkowicz discussed ect imbalance dataset 
evaluated strategies sampling resampling recognition induction scheme 
focus sampling approaches 
experimented artificial data order easily measure construct concept complexity 
resampling methods considered 
random resampling consisted resampling smaller class random consisted samples majority class focused resampling consisted resampling minority examples occurred boundary minority majority classes 
random sampling considered involved sampling majority class samples random numbers matched number minority class samples focused sampling involved sampling majority class samples lying away 
noted sampling approaches ective observed sophisticated sampling techniques give clear advantage domain considered japkowicz 
approach particularly relevant ling li 
combined sampling minority class sampling majority class 
lift analysis accuracy measure classifier performance 
proposed test examples ranked confidence measure lift evaluation criteria 
lift curve similar roc curve tailored smote marketing analysis problem ling li 
experiment sampled majority class noted best lift index obtained classes equally represented ling li 
experiment sampled positive minority examples replacement match number negative majority examples number positive examples 
sampling sampling combination provide significant improvement lift index 
approach oversampling di ers theirs 
considered problem imbalanced data sets oil classification sar imagery 
sampling sampling techniques improve classification oil 
training data distribution oil look giving prior probability look 
imbalance lead learner appropriate loss functions methodology modify priors classify look correctly expense misclassifying oil samples 
overcome imbalance problem sampled replacement samples oil randomly sampled samples non oil class create new dataset equal probabilities 
learned classifier tree balanced data set achieved error rate oil leave method error estimation look achieved error rate 
approach similar domingos 
compares metacost approach majority sampling minority sampling 
finds metacost improves sampling preferable minority sampling 
error classifiers cost sensitive 
probability class example estimated examples relabeled optimally respect misclassification costs 
relabeling examples expands decision space creates new samples classifier may learn domingos 
feed forward neural network trained imbalanced dataset may learn discriminate classes brown schneider 
authors proposed learning rate neural network adapted statistics class representation data 
calculated attention factor proportion samples neural network training 
learning rate network elements adjusted attention factor 
experimented artificially generated training set real world training set multiple classes 
compared approach replicating minority class samples balance data set training 
classification accuracy minority class improved 
lewis catlett examined heterogeneous uncertainty sampling supervised learning 
method useful training samples uncertain classes 
training samples labeled incrementally phases uncertain instances passed phase 
modified include loss ratio determining class values leaves 
class values determined comparison probability threshold lr lr lr loss ratio lewis catlett 
information retrieval ir domain dumais mladenic grobelnik lewis ringuette cohen faces problem class imbalance dataset :10.1.1.161.6020
document web page converted bag words representation chawla bowyer hall kegelmeyer feature vector reflecting occurrences words page constructed 
usually instances interesting category text categorization 
negative class information retrieval problems cause problems evaluating classifiers performances 
error rate metric skewed datasets classification performance algorithms information retrieval usually measured precision recall recall tp tp fn precision tp tp fp mladenic grobelnik proposed feature subset selection approach deal imbalanced class distribution ir domain 
experimented various feature selection methods odds ratio van rijsbergen harper porter combined naive bayes classifier performs best domain 
odds ratio probabilistic measure rank documents relevance positive class minority class 
information gain word hand pay attention particular target class computed word class 
imbalanced text dataset assuming negative class features associated negative class 
odds ratio incorporates target class information metric giving better results compared information gain text categorization 
provost fawcett introduced roc convex hull method estimate classifier performance imbalanced datasets 
note problems unequal class distribution unequal error costs related little done address problem provost fawcett 
roc convex hull method roc space separate classification performance class cost distribution information 
summarize literature sampling majority class enables better classifiers built sampling minority class 
combination done previous lead classifiers outperform built utilizing undersampling 
sampling minority class done sampling replacement original data 
approach uses di erent method sampling 

smote synthetic minority sampling technique minority sampling replacement previous research ling li japkowicz discussed sampling replacement noted doesn significantly improve minority class recognition 
interpret underlying ect terms decision regions feature space 
essentially minority class sampled increasing amounts ect identify similar specific regions feature space decision region minority class 
ect decision trees understood plots 
smote attribute attributes data original mammography dataset attributes data original mammography dataset attribute attributes data original mammography dataset attribute decision region minority class samples shown reside building decision tree 
decision region indicated solid line rectangle 
zoomed view chosen minority class samples dataset 
small solid line rectangles show decision regions result oversampling minority class replication 
zoomed view chosen minority class samples dataset 
dashed lines show decision region sampling minority class synthetic generation 
chawla bowyer hall kegelmeyer data plot extracted mammography dataset woods 
minority class samples shown majority class samples shown plot 
region indicated solid line rectangle majority class decision region 
contains minority class samples shown false negatives 
replicate minority class decision region minority class specific cause new splits decision tree 
lead terminal nodes leaves learning algorithm tries learn specific regions minority class essence overfitting 
replication minority class cause decision boundary spread majority class region 
samples previously majority class decision region specific decision regions 
smote propose sampling approach minority class sampled creating synthetic examples sampling replacement 
approach inspired technique proved successful handwritten character recognition ha bunke 
created extra training data performing certain operations real data 
case operations rotation skew natural ways perturb training data 
generate synthetic examples application specific manner operating feature space data space 
minority class sampled minority class sample introducing synthetic examples line segments joining minority class nearest neighbors 
depending amount sampling required neighbors nearest neighbors randomly chosen 
implementation currently uses nearest neighbors 
instance amount sampling needed neighbors nearest neighbors chosen sample generated direction 
synthetic samples generated way take di erence feature vector sample consideration nearest neighbor 
multiply di erence random number add feature vector consideration 
causes selection random point line segment specific features 
approach ectively forces decision region minority class general 
algorithm smote page pseudo code smote 
table shows example calculation random synthetic samples 
amount sampling parameter system series roc curves generated di erent populations roc analysis performed 
synthetic examples cause classifier create larger specific decision regions shown dashed lines smaller specific regions 
general regions learned minority class samples subsumed majority class samples 
ect decision trees generalize better 
figures compare minority sampling replacement smote 
experiments conducted mammography dataset 
examples majority class examples minority class originally 
approximately examples majority class examples 
data available intelligent systems lab csee edu chawla 
smote minority class training set fold cross validation 
minority class sampled original size 
graphs show tree sizes minority sampling replacement higher degrees replication greater smote minority class recognition minority sampling replacement technique higher degrees replication isn smote 
algorithm smote input number minority class samples amount smote number nearest neighbors output synthetic minority class samples 
randomize minority class samples random percent 


randomize minority class samples 


endif 
int amount smote assumed integral multiples 

number nearest neighbors 
number attributes 
sample array original minority class samples 
keeps count number synthetic samples generated initialized 
synthetic array synthetic samples compute nearest neighbors minority class sample 


compute nearest neighbors save indices 
populate 
endfor populate function generate synthetic samples 


choose random number call nn 
step chooses nearest neighbors 
attr 
compute dif sample nn attr sample attr 
compute gap random number 
synthetic attr sample attr gap dif 
endfor 


endwhile 
return populate 
pseudo code 
chawla bowyer hall kegelmeyer consider sample nearest neighbor 
sample nearest neighbors identified 
nearest neighbors 
new samples generated rand rand generates random number 
table example generation synthetic examples smote 
degree minority sampling tree size number nodes pruned decision tree size vs degree minority sampling synthetic data replicated data comparison decision tree sizes replicated sampling smote mammography dataset smote degree minority sampling minority correct vs degree minority sampling synthetic data replicated data comparison minority correct replicated sampling smote mammography dataset sampling smote combination majority class sampled randomly removing samples majority class population minority class specified percentage majority class 
forces learner experience varying degrees sampling higher degrees sampling minority class larger presence training set 
describing experiments terminology sample majority class mean modified dataset contain twice elements minority class majority class minority class samples majority class samples sample majority majority class having samples 
applying combination sampling sampling initial bias learner negative majority class reversed favor positive minority class 
classifiers learned dataset perturbed minority class sampling majority class 

experiments di erent machine learning algorithms experiments 
provides overview experiments 

compared various combinations smote sampling plain sampling release quinlan base classifier 
chawla bowyer hall kegelmeyer ripper naive bayes smote undersampling 
loss ratio varied 
modify costs majority minority classes changing priors 
roc generated smote undersampling loss ratio comparisons 
performance evaluated auc roc convex hull 
roc generated comparison smote sampling smote naive bayes 
performance evaluated auc roc convex hull 
experiments overview 
ripper compared various combinations smote sampling plain sampling ripper cohen base classifier 
varied ripper loss ratio cohen singer lewis catlett means varying misclassification cost compared ect variation combination smote sampling 
reducing loss ratio able build set rules minority class 

naive bayes classifier naive bayes classifier cost sensitive varying priors minority class 
varied priors minority class times majority class compared smote sampling combination 
di erent learning algorithms allowed smote compared methods handle misclassification costs directly 
fp tp averaged fold cross validation runs data combinations 
minority class examples sampled calculating nearest neighbors generating synthetic examples 
auc calculated trapezoidal rule 
extrapolated extra point tp fp roc curve 
computed roc convex hull identify optimal classifiers points lying hull potentially optimal classifiers provost fawcett 

source code downloaded fuzzy cs uni magdeburg de borgelt software html 
smote datasets experimented di erent datasets 
datasets summarized table 
datasets vary extensively size class proportions ering di erent domains smote 
order increasing imbalance 
pima indian diabetes blake merz classes samples 
data identify positive diabetes cases population near phoenix arizona 
number positive class samples 
sensitivity detection diabetes cases desirable attribute classifier 

phoneme dataset elena project aim dataset distinguish nasal class oral sounds class 
features 
class distribution samples class samples class 
adult dataset blake merz samples samples belonging minority class 
dataset continuous features nominal features 
smote smote nc see section algorithms evaluated dataset 
smote extracted continuous features generated new dataset continuous features 

state data hall consists state descriptors series compounds national cancer institute yeast drug screen 
state descriptors nci yeast drug screen generated tripos briefly series compounds tested series yeast strains concentration 
test high throughput screen concentration results subject contamination growth inhibition yeast strain exposed compound respect growth yeast neutral solvent measured 
activity classes active single yeast strain inhibited inactive yeast strain inhibited 
dataset samples samples active compounds 

satimage dataset blake merz classes originally 
chose smallest class minority class collapsed rest classes done provost 
gave skewed class dataset majority class samples minority class samples 

forest cover dataset uci repository blake merz 
dataset classes samples 
dataset prediction forest cover type cartographic variables 
system currently works binary classes extracted data classes dataset ignored rest 
approaches classes ling li japkowicz kubat matwin provost fawcett 
classes considered pine samples willow 
ftp dice ucl ac directory pub neural nets elena databases 

steven providing dataset description 
chawla bowyer hall kegelmeyer dataset majority class minority class pima phoneme adult state satimage forest cover oil mammography table dataset distribution samples 
smote technique applied multiple class problem specifying class smote 
focused classes problems explicitly represent positive negative classes 

oil dataset provided robert holte kubat 
dataset oil samples non oil samples 

mammography dataset woods samples 
look predictive accuracy measure goodness classifier case default accuracy sample labeled 
desirable classifier predict correctly 

dataset generated data avatar chawla hall version visualization tool portion crushed marked interesting rest marked unknown 
dataset size samples samples marked interesting generated 
roc creation roc curve smote produced ripper create classifier series modified training datasets 
roc curve produced sampling minority class specified degree sampling majority class increasing degrees generate successive points curve 
amount sampling identical plain sampling 
corresponding point roc curve dataset represents number majority class samples 
di erent roc curves produced starting di erent levels minority sampling 
roc curves generated varying loss ratio ripper varying priors minority class original distribution times majority class naive bayes classifier 

visualization tool developed mike glass sandia national labs 
smote phoneme roc fp smote naive bayes hull phoneme 
comparison smote naive bayes 

dominates naive bayes roc space 

classifiers potentially optimal classifiers 
figures show experimental roc curves obtained datasets classifiers 
roc curve plain sampling majority class ling li japkowicz kubat matwin provost fawcett compared approach combining synthetic minority class sampling smote majority class sampling 
plain sampling curve labeled smote sampling combination roc curve labeled smote 
depending size relative imbalance dataset smote undersampling curves created 
show best results smote combined sampling plain sampling curve graphs 
smote roc curve compared roc curve obtained varying priors minority class naive bayes classifier labeled naive bayes 
smote loss ratio roc curves generated ripper compared 
family roc curves roc convex hull provost fawcett generated 
roc convex hull generated graham algorithm rourke 
show roc curve obtained minority sampling replication 
point roc curve result classifier ripper learned particular combination sampling smote classifier ripper learned plain sampling classifier ripper learned loss ratio classifier naive bayes learned di erent prior minority class 
point represents average tp fp fold cross validation result 
lower leftmost point roc curve raw dataset majority class chawla bowyer hall kegelmeyer phoneme roc ripper fp ripper smote ripper loss ratio hull phoneme 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper dominates ripper loss ratio roc space 
smote ripper classifiers lie roc convex hull 
pima roc fp smote naive bayes hull pima indians diabetes 
comparison smote naive bayes 
naive bayes dominates smote roc space 
smote pima roc ripper fp ripper smote ripper loss ratio hull pima indians diabetes 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper dominates ripper loss ratio roc space 
sampling minority class sampling 
minority class sampled 
majority class sampled 
amount majority class sampling minority class oversampling depended dataset size class proportions 
instance consider roc curves mammography dataset 
curves plain majority class sampling range sampling varied di erent intervals combination smote majority class sampling naive bayes roc convex hull curve 
roc curve shown minority class sampled 
point smote roc curves represents combination synthetic sampling undersampling amount sampling follows range plain sampling 
better understanding roc graphs shown di erent sets roc curves datasets appendix dataset smote lesser degree datasets due structural nature dataset 
dataset structural neighborhood established mesh geometry smote lead creating neighbors surface interesting looking feature space physics variables structural information 
roc curves show trend increase amount sampling coupled sampling minority classification accuracy increases course expense majority class errors 
roc curves smote approach dom chawla bowyer hall kegelmeyer satimage roc fp smote naive bayes hull satimage 
comparison smote naive bayes 
roc curves naive bayes smote show overlap higher tp points smote lie roc convex hull 
satimage roc ripper fp ripper smote ripper loss ratio hull satimage 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper dominates roc space 
roc convex hull constructed points smote ripper 
smote covtype roc fp smote naive bayes hull forest cover 
comparison smote naive bayes 
smote roc curves close 
points smote roc curve lie roc convex hull establishing dominance 

adhering definition roc convex hull potentially optimal classifiers ones generated smote 
auc calculation area roc curve auc calculated form trapezoid rule 
lower leftmost point roc curve classifier performance raw data 
upper rightmost point 
curve naturally point point added 
necessary order auc compared range fp 
aucs listed table show datasets combined synthetic minority sampling majority sampling able improve plain majority sampling base classifier 
smote approach provides improvement correct classification data underrepresented class 
holds examination roc convex hulls 
entries missing table smote applied amounts datasets 
amount smote skewed datasets 
included auc ripper naive bayes 
roc convex hull identifies smote classifiers potentially optimal compared plain sampling treatments misclassification costs generally 
exceptions follows pima dataset naive bayes dominates smote oil dataset ripper dominates smote ripper 
dataset smote classifier classifier ripper classifier roc chawla bowyer hall kegelmeyer covtype roc ripper fp ripper smote ripper loss ratio hull forest cover 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper shows domination roc space 
points smote ripper curve lie roc convex hull 
fp oil roc smote naive bayes hull oil 
comparison smote naive bayes 
smote roc curves intersect points points smote curve lie roc convex hull 
smote oil roc ripper fp ripper smote ripper loss ratio hull oil 
comparison smote ripper ripper modifying loss ratio ripper 
ripper smote ripper curves intersect points ripper curve lie roc convex hull 
mammography roc fp smote naive bayes hull mammography 
comparison smote naive bayes 
smote curves intersect roc space virtue number points roc convex hull smote potentially optimal classifiers 
chawla bowyer hall kegelmeyer mammography roc ripper fp ripper smote ripper loss ratio hull mammography 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper dominates roc space tp 
mammography roc fp smote replicate hull comparison sampling minority class examples smote oversampling minority class examples replication mammography dataset 
smote state roc fp smote naive bayes hull state 
comparison smote naive bayes 
smote curves intersect roc space smote potentially optimal classifiers number points roc convex hull 
state roc ripper fp ripper smote ripper loss ratio hull state 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper potentially optimal classifiers number points roc convex hull 
chawla bowyer hall kegelmeyer roc fp smote naive bayes hull 
comparison smote naive bayes 

roc curves overlap roc space 
roc ripper fp ripper smote ripper loss ratio hull 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper ripper roc curves overlap roc space 
smote dataset smote smote smote smote smote smote pima phoneme satimage forest cover oil mammography state table auc base classifier best highlighted bold 
curves overlap roc space 
datasets smote classifier potentially optimal classifiers approach 
additional comparison changing decision thresholds provost suggested simply changing decision threshold considered alternative sophisticated approaches 
case mean changing decision threshold leaves decision trees 
example leaf classify examples minority class training examples leaf represent majority class 
experimented setting decision thresholds leaves decision tree learner 
experimented phoneme dataset 
shows comparison smote sampling combination learning tuning bias minority class 
graph shows smote sampling combination roc curve dominating entire range values 
additional comparison sided selection shrink oil dataset followed slightly di erent line experiments obtain results comparable kubat 
alleviate problem imbalanced datasets authors proposed sided selection sampling majority class kubat matwin shrink system kubat 
table contains results kubat 
acc accuracy positive minority examples acc accuracy negative majority examples 
shows trend acc acc combination smote strategy varying degrees undersampling majority class 
axis represents accuracy axis represents percentage majority class sampled 
graphs indicate band sampling results comparable achieved shrink better shrink cases 
table summarizes results smote sampling combination 
tried combinations smote varying degrees sampling achieved comparable results 
chawla bowyer hall kegelmeyer phoneme roc comparison smote variation decision thresholds fp tp smote varying decision thresholds hull smote sampling combination learning tuning bias minority class smote sampling percentage sampling majority class accuracy accuracy majority negative class accuracy minority positive class smote ou sampling combination performance shrink approach smote approach directly comparable see di erent data points 
smote ers clear improvement sided selection 
smote method acc sided selection table cross validation results kubat sampling acc acc table cross validation results smote smote oil data set 
chawla bowyer hall kegelmeyer 
topics considered line research 
automated adaptive selection number nearest neighbors valuable 
di erent strategies creating synthetic neighbors may able improve performance 
selecting nearest neighbors focus examples incorrectly classified may improve performance 
minority class sample possibly majority class sample nearest neighbor minority class sample 
crowding contribute decision surfaces favor minority class 
addition topics subsections discuss possible extensions smote application smote information retrieval 
smote nc smote approach currently handle data sets nominal features generalized handle mixed datasets continuous nominal features 
call approach synthetic minority sampling technique nominal continuous smote nc 
tested approach adult dataset uci repository 
smote nc algorithm described 

median computation compute median standard deviations continuous features minority class 
nominal features di er sample potential nearest neighbors median included euclidean distance computation 
median penalize di erence nominal features amount related typical di erence continuous feature values 

nearest neighbor computation compute euclidean distance feature vector nearest neighbors identified minority class sample feature vectors minority class samples continuous feature space 
di ering nominal feature considered feature vector potential nearest neighbor include median standard deviations previously computed euclidean distance computation 
table demonstrates example 
sample computing nearest neighbors euclidean distance eucl sqrt med med med median standard deviations continuous features minority class 
median term included twice feature numbers di er feature vectors 
table example nearest neighbor computation smote nc 
smote 
populate synthetic sample continuous features new synthetic minority class sample created approach smote described earlier 
nominal feature value occuring majority nearest neighbors 
smote nc experiments reported set smote fact examine dataset 
smote nc adult dataset di ers typical result performs worse plain sampling auc shown figures 
extracted continuous features separate ect smote smote nc dataset determine due handling nominal features 
shown smote continuous features applied adult dataset achieve better performance plain sampling 
minority class continuous features high variance synthetic generation minority class samples overlapping majority class space leading false positives plain sampling 
hypothesis supported decreased auc measure smote degrees greater 
higher degrees smote lead minority class samples dataset greater overlap majority class decision space 
adult smote nc fp smote nc naive bayes hull adult 
comparison smote naive bayes 

roc curves overlap roc space 
smote potentially smote extended nominal features smote nearest neighbors computed modified version value di erence metric stanfill waltz proposed cost salzberg 
value di erence metric vdm looks overlap feature values feature vectors 
matrix defining distance chawla bowyer hall kegelmeyer adult roc ripper fp ripper smote ripper loss ratio hull adult 
comparison smote ripper ripper modifying loss ratio ripper 
smote ripper ripper roc curves overlap roc space 
adult continuous fp smote adult continuous features 
overlap smote 
observed scenario 
smote corresponding feature values feature vectors created 
distance corresponding feature values defined follows 
equation corresponding feature values 
total number occurrences feature value number occurrences feature value class similar convention applied constant usually set 
equation compute matrix value di erences nominal feature set feature vectors 
equation gives geometric distance fixed finite set values cost salzberg 
cost salzberg modified vdm omits weight term included computation stanfill waltz ect making symmetric 
distance feature vectors yields manhattan distance yields euclidean distance cost salzberg 
exemplar weights modified vdm 
new example feature vector bias reliable examples feature vectors computed ratio number uses feature vector number correct uses feature vector accurate feature vectors 
smote ignore weights equation smote classification purposes directly 
redefine weights give weight minority class feature vectors falling closer majority class feature vectors making minority class features appear away feature vector consideration 
interested forming broader accurate regions minority class weights avoid populating neighbors fall closer majority class 
generate new minority class feature vectors create new set feature values majority vote feature vector consideration nearest neighbors 
table shows example creating synthetic feature vector 
feature vector consideration nearest neighbors application smote create feature vector fs table example smote chawla bowyer hall kegelmeyer application smote information retrieval investigating application smote information retrieval ir 
ir problems come plethora features potentially categories 
smote applied conjunction feature selection algorithm transforming document web page bag words format 
interesting comparison smote combination naive bayes odds ratio 
odds ratio focuses target class ranks documents relevance target positive class 
smote focuses target class creating examples class 

summary results show smote approach improve accuracy classifiers minority class 
smote provides new approach sampling 
combination smote sampling performs better plain sampling 
smote tested variety datasets varying degrees imbalance varying amounts data training set providing diverse testbed 
combination smote sampling performs better domination roc space varying loss ratios ripper varying class priors naive bayes classifier methods directly handle skewed class distribution 
smote forces focused learning introduces bias minority class 
pima skewed dataset naive bayes classifier perform better smote 
oil dataset ripper perform better smote ripper 
dataset smote classifier classifier roc curves overlap roc space 
rest datasets smote classifier performs better classifier loss ratio naive bayes 
total experiments performed smote classifier perform best experiments 
interpretation synthetic minority sampling improves performance minority sampling replacement fairly straightforward 
consider ect decision regions feature space minority sampling done replication sampling replacement versus synthetic examples 
replication decision region results classification decision minority class smaller specific minority samples region replicated 
opposite desired ect 
method synthetic sampling works cause classifier build larger decision regions contain nearby minority class points 
reasons may applicable smote performs better ripper loss ratio naive bayes methods learning information provided dataset albeit di erent cost information 
smote provides related minority class samples learn allowing learner carve broader decision regions leading coverage minority class 
acknowledgments research partially supported united states department energy sandia national laboratories asci views data discovery program contract number smote de ac 
robert holte providing oil spill dataset 
foster provost clarifying method satimage dataset 
anonymous reviewers various insightful comments suggestions 
chawla bowyer hall kegelmeyer appendix roc graphs oil dataset figures show di erent sets roc curves oil dataset 
shows roc curves oil dataset included main text shows roc curves roc convex hull shows convex hulls obtained smote 
roc convex hull shown dashed lines stars computed including naive bayes family roc curves 
roc convex hull shown solid line small circles computed including smote naive bayes family roc curves 
roc convex hull smote dominates roc convex hull smote smote contributes optimal classifiers 
fp oil roc smote naive bayes hull fp oil smote naive bayes oil roc convex hulls fp convex hull smote convex hull smote roc curves oil dataset 
roc curves smote 
naive bayes roc convex hull 
roc curves 
naive bayes 
roc convex hulls smote 
smote blake merz 

uci repository machine learning databases www ics uci edu mlearn mlrepository html 
department information computer sciences university california irvine 
bradley 

area roc curve evaluation machine learning algorithms 
pattern recognition 
chawla bowyer hall kegelmeyer 

smote synthetic minority sampling technique 
international conference knowledge computer systems pp 

national center software technology mumbai india allied press 
chawla hall 

modifying capture salient data 
tech 
rep isl university south florida computer science eng 
dept cohen 

learning classify english text ilp methods 
proceedings th international workshop inductive logic programming pp 

department computer science katholieke universiteit leuven 
cohen 

fast ective rule induction 
proc 
th international conference machine learning pp 
lake tahoe ca 
morgan kaufmann 
cohen singer 

context sensitive learning methods text categorization 
frei harman schauble wilkinson 
eds proceedings sigir th acm international conference research development information retrieval pp 
zurich ch 
acm press new york 
cost salzberg 

weighted nearest neighbor algorithm learning symbolic features 
machine learning 
brown schneider 

neural network training unequally represented classes 
engineering systems artificial neural networks pp 
new york 
asme press 
domingos 

metacost general method making classifiers cost sensitive 
proceedings fifth acm sigkdd international conference knowledge discovery data mining pp 
san diego ca 
acm press 
drummond holte 

explicitly representing expected cost alternative roc representation 
proceedings sixth acm sigkdd international conference knowledge discovery data mining pp 
boston 
acm 
duda hart stork 

pattern classification 
wiley interscience 
dumais platt heckerman sahami 

inductive learning algorithms representations text categorization 
proceedings seventh international conference information knowledge management pp 

chawla bowyer hall kegelmeyer singh norton 

learning goal oriented bayesian networks telecommunications risk management 
proceedings international conference machine learning icml pp 
bari italy 
morgan kau man fawcett provost 

combining data mining machine learning effective user profile 
proceedings nd international conference knowledge discovery data mining pp 
portland 
aaai 
ha bunke 

line handwritten numeral recognition perturbation method 
pattern analysis machine intelligence 
hall 

state structure information atomic level molecular graphs 
journal chemical information computer science 
japkowicz 

class imbalance problem significance strategies 
proceedings international conference artificial intelligence ic ai special track inductive learning las vegas nevada 
kubat holte matwin 

machine learning detection oil spills satellite radar images 
machine learning 
kubat matwin 

addressing curse imbalanced training sets sided selection 
proceedings fourteenth international conference machine learning pp 
nashville 
morgan kaufmann 
lee 

noisy replication skewed binary classification 
computational statistics data analysis 
lewis catlett 

heterogeneous sampling supervised learning 
proceedings eleventh international conference machine learning pp 
san francisco ca 
morgan kaufmann 
lewis ringuette 

comparison learning algorithms text categorization 
proceedings sdair rd annual symposium document analysis information retrieval pp 

ling li 

data mining direct marketing problems solutions 
proceedings fourth international conference knowledge discovery data mining kdd new york ny 
aaai press 
mladenic grobelnik 

feature selection unbalanced class distribution naive bayes 
proceedings th international conference machine learning pp 

morgan kaufmann 
rourke 

computational geometry cambridge university press uk 
pazzani merz murphy ali hume brunk 

reducing misclassification costs 
proceedings eleventh international conference machine learning san francisco ca 
morgan kau mann 
smote provost fawcett 

robust classification imprecise environments 
machine learning 
provost fawcett kohavi 

case accuracy estimation comparing induction algorithms 
proceedings fifteenth international conference machine learning pp 
madison wi 
morgan kau mann 
quinlan 

programs machine learning 
morgan kaufmann san mateo ca 


large scale evaluation features automatic detection oil spills ers sar images 
international geoscience remote sensing symposium pp 
lincoln ne 
stanfill waltz 

memory reasoning 
communications acm 
swets 

measuring accuracy diagnostic systems 
science 
tomek 

modifications cnn 
ieee transactions systems man cybernetics 
turney 

cost sensitive bibliography 
ai iit nrc ca 
html 
van rijsbergen harper porter 

selection search terms 
information processing management 
woods bowyer kegelmeyer 

comparative evaluation pattern recognition techniques detection mammography 
international journal pattern recognition artificial intelligence 

