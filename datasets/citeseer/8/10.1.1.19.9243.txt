empirical verification coverage correctness general purpose sentence generator describes general purpose sentence generation system achieve broad scale coverage high quality aiming suitable variety generation tasks 
measure coverage correctness empirically section penn treebank corpus test set 
describe novel features help generator flexible easier variety tasks 
knowledge empirical measurement coverage reported literature highest reported measurements correctness 
natural language generation nlg subtask wide variety applications 
applications include machine translation human computer dialogue summarization report creation automatic technical documentation proof decision explanation customized instructions item event descriptions question answering tutorials stories 
applications custom built generator general purpose system facilitate reuse resources reduce costs building applications 
research general purpose generation tended focus sentence realization common recurring subtasks generation 
sentence realization process trans irene langkilde information sciences institute university southern california isi edu forming syntactic sentence plan grammatical string morphologically inflected words 
generally useful realizer needs able handle wide array syntactic phenomena 
needs produce grammatically correct output 
prominent general purpose realization systems developed date include fuf surge elhadad elhadad robin lavoie rambow penman bateman nitrogen langkilde knight knight hatzivassiloglou 
systems demonstrated general usefulness deployed variety different applications 
difficult ascertain degree achieved broad coverage natural language high quality output empirical evaluation performed 
best suites example inputs regression testing 
regression suites biased capabilities respective systems consist relatively inputs compared variety input classes possible 
example currently test inputs distributed surge english 
rate matter large regression suite may inherent irregularity natural language regression testing inadequate means assessing coverage quality 
practice seemingly irreconcilable conflict broad coverage high quality output 
usually case rules class features simultaneously general rule undesirable combinations restrictive assigned go defense defending offending meteer won lost straight consecutive won lost straight won lost consecutive robin finger vs digit vs zone vs zone tell hi vs say hi vase broke vs food ate knight expressibility problems allow combinations valid 
shows examples expressibility problem 
high quality output easier achieve smaller scale applications limited domains 
introduce halogen generalpurpose sentence generator achieves broad coverage english high quality output measured unseen section penn treebank marcus 
compare generation system performed evaluation limited purpose system named fergus bangalore 
halogen development guided part question simplest input notation suffices represent correctly generate valid sentences time easy applications describe novel aspects help generator flexible easier variety applications 
section gives brief overview halogen sentence generation system 
section describes setup empirical evaluation section discusses results 
section concludes 
halogen halogen successor nitrogen langkilde knight langkilde knight langkilde 
hybrid symbolic statistical system stage architecture 
stage symbolic knowledge transform input forest possible expressions 
second stage statistical ranker computes expression corpus probabilistic model 
section describes halogen input processing stages 
compares halogen predecessor 
input input halogen labeled feature value structure 
main types features relations properties 
relation features describe relationship instance head value values 
value word concept compound value composed nested structures 
relations syntactic semantic non linguistic 
example inputs shown 
seen examples multiple relations appear nesting level input 
relations occur nesting level 
main exceptions modifier adverbial relations occur number times 
relations order independent means order relations occur input affect order values occur output 
exception relation occurs nesting level 
situation values relation occur adjacent output order appeared input flag set 
flag set possible adjacent permutations tried 
halogen input property features 
features describe linguistic properties instance clause 
halogen require specified input may specified order eat subject dog object bone adjunct today eat agent dog patient bone temporal locating today example inputs verb mood infinitive infinitive imperative participle past participle indicative tense past person modal may taxis perfect aspect continuous simple voice active passive subject position default post aux post vp passive subject role logical object logical dative logical dative position shifted noun cat common proper pronoun cardinal number singular plural adjective adverb cat comparative superlative negative general lex root form word string cat open class vv nn jj rb closed class cc dt pdt rp sym wdt wp uh punctuation penn treebank property features halogen ride defaults system provides 
main properties halogen recognizes listed possible values 
symbolic generator input processed symbolic generator 
symbolic generator consists set mapping rules transform input packed set possible expressions referred forest 
forest non recursive context free grammar 
left hand side mapping rule specifies conditions matching presence particular feature top level input 
right hand side lists outcomes 
kinds mapping rules recasting ordering filling morphing 
recasting rules map relation 
map semantic relations syntactic ones agent subject object ex ample 
possible localize constraints 
result rule set modular concise 
recasting rules facilitate continuum abstraction levels application choose express input 
recasting rules tool application customize halogen desired 
recasting map non linguistic domain specific relations recognized halogen 
langkilde knight describe recasting technique greater detail 
ordering rules assign linear order values features matched rule 
ordering rules typically match syntactic features lowest level abstraction 
ordering rule splits input apart pieces 
values features matched rule extracted input independently mapping rules 
remaining portion original input continues circulate rules left 
pieces finishes circulating rules new forest node created composes results designated linear order 
filling rule adds missing information underspecified inputs 
type rule tests particular feature absent 
generate copies input possible value feature add feature value pair copy 
copy independently circulated mapping rules 
morph rule produces morphological inflection base lexeme property features associated 
symbolic generator proceeds comparing top level input mapping rules turn 
mapping rules decompose input recursively process nested levels 
base input fragments converted elementary forests recombined mapping rules 
final resulting forest processed statistical ranker 
halogen mapping rules hand written developed part tree grep program distributed treebank 
program indexes sections treebank including section section testing experiments described 
program indicate section number trees retrieved appears display matching trees sectional order section 
test section development mapping rules indirect 
statistical ranker forest ranker applies bottom dynamic programming algorithm extract phrases forest 
uses ngram language model built version cmu statistical language modeling toolkit clarkson rosenfeld 
unigram bigram trigram models available 
trained words wall street journal newspaper text excluding text penn treebank derived 
ranker finds optimal solution respect language model 
described greater detail langkilde 
comparison nitrogen nitrogen recognizes syntactic relations focus semantic relations 
halogen hand adds full set deep shallow syntactic features intended achieve extensive coverage english syntax 
semantic rules nitrogen modified halogen map syntactic ones directly specifying order constituents 
syntactic features facilitate methodical thorough coverage english syntax enable application precisely control desired output desired 
halogen handles adjunct relations semantic syntactic better nitrogen 
halogen semantic adjuncts temporal locating occur multiple times level nesting input artificially restricted just node 
halogen offers capability try possible order permutations adjuncts ability impose partial order constraints 
applications concerned rhetorical structure coherence sentences multi sentence generation need kind control 
contrast nitrogen arbitrarily assigns single fixed order adjuncts order respective semantic relations set mapping rules 
nitrogen uses categorial grammar notations mapping rules constrain generation output 
halogen abandons proved overly restrictive scaling broad coverage 
halogen relies heavily statistical ranker implement grammatical preferences 
constraints imposed done adding features input recasting mechanism 
halogen uses feature named type impose gross category constraints phrases verbal nominal 
symbolic processing engine checks consistency soundness input recasting 
improvements nitrogen space fully describe include input meta nodes possible level nesting just top level specify disjunctions values compound values permitted instance relation represent scope influence constituent ordering template capability template filler roles labels efficiency improved cache rule matching procedure weights possible grammar rules input concept word mappings polished output experimental setup goal empirical evaluation coverage quality measure extent valid english sentence represented generated 
generation usually notoriously difficult evaluate grammaticality difficult measure automatically output acceptable 
variations output usually acceptable context specific applications different applications different constraints kinds variation output accept 
demonstrating capability produce desired sentence exactly system assure possible application constraints output met 
experiments focus desired sentence produced exactly kind measurement necessary 
section penn treebank evaluate coverage quality 
inputs halogen automatically constructed treebank annotation regenerated system 
output compared original sentence 
penn treebank offers advantages test set 
contains real world sentences large assumed exhibit broad array syntactic phenomena 
biased system specific capabilities collected independently 
acts standard linguistic representation offering potential interoperability natural language programs parsers 
time limits usefulness 
represents domain newspaper text test stylistic structural content variations occur domains question answering dialogue 
evaluate system handles nonsensical inputs inputs expressible grammatical english 
input construction process involved finding root forms words factoring treebank categories open class words basic features heuristically designating constituent heads inferring syntactic logical roles node making coordination bracketing explicit reorganizing compound prepositions single constituent associating punctuation constituent flattening vp flattening nodes child removing null elements dropping function words ex simple dative logical subject auxiliary verbs punctuation 
resulting structure hierarchical functional dependency tree 
generator primary tasks evaluation determine linear order constituents perform morphological inflections insert needed function words 
experiments run evaluate halogen performance inputs underspecified different ways 
ability handle underspecification eases information burden client applications 
generator flexible meeting varying needs constraints different types applications 
experiments subset relations halogen recognizes 
specifi logical subject instance anchor logical object polarity topic logical dative adjunct closely related conj predicate punc determiner relations experiments cally mix deep shallow syntactic relations shown 
semantic relations straightforwardly derived penn treebank annotation ambiguous adequately handled scale experiments 
experiment labeled fully spec inputs contain nearly detail fully determine unique output 
inputs contain detail possible straight obtain treebank annotation 
example shown 
experiment adjuncts represented premodifiers postmodifiers modifiers 
verbal modifiers come subject object 
flag generator set constituents role occurring level nesting modifiers ordered output relative order appear input adjacent 
order flag allows applications plan discourse structure doing sentence realization control coherence sentences 
example dialogue systems want old background information appear new information 
partial order constraints specified extra levels nesting input 
capability exercised experiments 
second experiment permute roles permutation flag set experiment reversed 
constituents role permuted place statistical ranker expected choose order 
exception occurs happen constituents role 
computational reasons constituents permuted case 
placed reverse order output avoid unfairly inflating accuracy results 
remains experiment 
mood indicative cat rb cat comparative lex earlier logical subject det cat dt lex det cat nn cat common number sing lex cat vv tense past lex announce 
punc period bigram trigram earlier announced sell aging fleet boeing increasing maintenance costs 
original fragment fully specified input output adjunct earlier logical subject announce adjunct 
punc period bigram sell fleet age boeing maintenance costs increase announced earlier 
trigram earlier announced sell fleet age boeing increase maintenance costs 
original see fragment minimally specified input output third experiment permute dir second addition modifiers mapped adjunct relation increasing number constituents get permuted 
statistical ranker determine order modifiers respect determine direction respect head 
fourth experiment det common determiners left unspecified 
specifically dropped input 
feature dropped nominal phrases determiner original treebank annotation 
experiment tests ability generator supply appropriate determiner needed 
fifth experiment leaf clause experiment leaf clause properties listed dropped input 
value lex feature retained input 
sixth experiment min spec represents opposite extreme experiment 
information dropped experiments dropped experiment 
example input output shown 
computational reasons bigram model trigram applied ranker experiments 
sake comparison figures show output bigram trigram models 
results results experiments shown 
section penn treebank contains sentences 
average penn sentence consisted tokens shortest longest 
input construction tool produced inputs penn sentences inputs 
halogen produced output approximately inputs 
assuming test set representative english coverage defined percent syntactic constructions inputs generator produces correlative output estimate halogen coverage english 
applied different metrics evaluate quality ibm bleu score papineni average nist simple string accuracy exact match 
ibm bleu score geometric average gram accuracy respect original penn sentence adjusted length penalty factor lp 
bleu exp log lp 
permute permute leaf min input characteristics fully dir spec clause spec spec roles det median num sen gen input smallest num sen gen input max num sen gen input average ranking time input secs average total time input secs average length gen sentences average length exact matches num inputs produced output num exact matches percent inputs produced output percent exact matches output ave nist simple string accuracy ibm bleu score lp exp wn system output length length 
average nist simple string accuracy score reflects average number insertion deletion substitution errors output sentence original penn sentence 
formally ssa number tokens original sentence 
bleu nist metrics agree fairly closely experiments 
metrics halogen output ranged correct inputs fully specified correct minimally specified inputs 
outputs exact matches experiment dropping sixth 
quality sixth experiment substantially worse requires information input easier client application produce 
applications machine translation tolerate imperfect output difficulty supplying detailed inputs halogen appealing tool 
second third experiments show permuting role nodes big impact quality expect 
probably reflects ngram model strength capturing order information especially single word modi experimental results 
may reflect relative nodes having multiple modifiers 
fourth experiment halogen doesn selecting determiners expect 
divergence experiment exact match metric metrics probably results need choose determiners nearly sentence determiners fraction words sentence 
fifth experiment shows largest drop accuracy compared second fourth suggesting problem harder 
halogen achieves correct frequent problem 
topic interest causes generation failure causes inexact matches experiment 
cause syntactic phenomena known handled appropriately 
includes right node raising constituents discontinuous constituents constituents 
important cause errors inconsistencies original treebank annotation 
automatic input construction process introduces errors particularly heuristically selecting constituent heads 
times halogen deliberately fails generate input phrase malformed 
system done similar empirical evaluation fergus 
fergus applied statistical tree model tag grammar ngram language model inputs consisting complete dependency tree labeled fully inflected words roles 
realization problem limited determining constituent order 
fergus achieved correct nist metric result comparable min spec experiment just described 
contrast halogen fergus offers means controlling generation specific output exactly 
hand tree model fergus improve halogen accuracy 
see evidence 
currently way halogen 
summary empirically verified halogen coverage accuracy section penn treebank test set 
set automatically derived inputs produced output correct input fully specified 
accuracy measured ibm bleu scores nist simple string accuracy scores compared outputs original sentences 
outputs exact matches original 
minimally specified inputs accuracy exact matches 
flexibility halogen offers degree specification input adds general 
tasks dialogue require high quality output need exert significant control output wish tasks translation generally suffer inability provide information accept lower quality output obtain output providing specification details 
plan apply statistical model syntax continue broaden syntactic coverage extend system handle additional subtasks realization ellipsis evaluate system context different applications 
bangalore rambow whittaker 

evaluation metrics generation 
proc 
st inlg 
bateman 

development environment multilingual linguistic resource development sentence generation 
technical report german centre information technology gmd 
clarkson rosenfeld 

statistical language modeling cmu cambridge toolkit 
proc 
esca eurospeech 
knight langkilde marcu yamada 

experiments statistical model syntax 
submitted 
elhadad robin 

surge comprehensive plug syntactic realization component text generation 
www cs bgu ac il elhadad pub html submitted 
elhadad 

fuf universal unifier user manual version 
technical report cucs columbia university 
robin 

revision generation natural language summaries providing historical background corpus analysis design implementation evaluation 
ph thesis columbia university 
knight hatzivassiloglou 

level paths generation 
proc 
acl 
knight haines hatzivassiloglou hovy iida luk whitney yamada 

filling knowledge gaps mt system 
proc 
ijcai 
langkilde knight 

generation exploits corpus statistical knowledge 
proc 
coling acl 
langkilde knight 

practical value grams generation 
proc 
international natural language generation workshop 
langkilde 

forest statistical sentence generation 
proc 
naacl 
lavoie rambow 

fast portable sentence realizer 
anlp 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
meteer 

generation gap problem expressibility text planning 
ph thesis massachusetts 
papineni roukos ward 
zhu 

bleu method automatic evaluation machine translation 
technical report rc ibm research division 
