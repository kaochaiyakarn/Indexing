automating approximate record matching process verykios ahmed elmagarmid computer sciences department purdue university west lafayette june data quality dimensions accuracy 
accuracy usually compromised errors accidentally intensionally introduced database system 
errors result incon sistent incomplete erroneous data elements 
example small variation representation data object produces unique instantiation object represented 
order im prove accuracy data stored database system need compare real world counterparts data stored di erent system 
address problem matching records refer entity computing similarity 
exact record matching limited applicability context simple errors character transpositions captured record linking process 
methodology deploys advanced data mining techniques dealing high computational inferential complexity approximate record matching 
companies multiple legacy information systems support operations 
systems contain great deal redundant summarized overlapping data objects interdependent 
lack common data model errors data ows errors data entry situations updates re ected database cause inconsistencies arise ww 
inconsistencies common systems today cause signi cant revenue loss 
reported customers records erroneous typical billing system 
existing techniques cope problems listed data edits computerized routines certify data values representations satisfy predetermined constraints 
constraints called business rules simple quite sophisticated 
data edits may applied entire database screen lter data ow 
data correction matches data master lists tags elds bad automatically correctable 
example factory management software systems access data range tables lter range data 
record matching determines records di erent types represent object 
process involves value judgments requires sophisticated software tools 
customer matching retail house holding examples record matching applied 
rst application want nd customer customer buys second third product supplier second want nd group people comprise family member customer 
methodology improves existing techniques record match ing 
brute force approach matching records quadratic order respect number records database 
bottleneck large databases 
high dimension ality problem calls heuristics cut search space shortcuts similar ones unconsciously employed human ling clerk 
main contribution methodology complete automation knowledge acquisition record matching process 
comparison space resulting economically comparing records sample drawn original database clustered clusters described produce predictive patterns 
generated patterns simpli ed rule base matching records entire database 
results initial experiments indicate proposed methodology improves accuracy matching process reduces high complexity 
organization follows section provides background information respect approximate record matching 
section discusses related approaches record matching gives brief description approach ts big picture 
record matching methodology section example section 
concluding remarks section 
background idea linking records simple 
record linking matching means bringing informa tion entity 
principal steps linking process search potentially linkable pairs records searching step decide pair correctly matched matching step 
searching step aim reduce number failures bring potentially linkable records comparison 
technique applied address problem resorting excessive amounts additional searching 
matching step problem enabling computer infer apply rules judgment hu man clerk decide pair records relates entity identifying information agrees disagrees 
product space tables match pair represents entity non match pair represents di erent entities 
single database duplicate record represents entity record database 
regard pairs product space databases space single database may necessary consider pairs agree certain identi ers blocking criteria 
blocking criteria called sort keys 
missed matches false non matches agree set blocking criteria 
matching variables common record identi ers names addresses code numbers social security number identify matches 
vector keeps values attribute comparisons pair records called comparison vector 
set possible vectors called comparison space 
record linkage decision rule rule designates pair link possible link non link information contained comparison vector 
possible links pairs identifying information su cient determine pair match non match 
typically clerks review possible links decide match status 
false matches non matches erroneously designated links decision rule 
false non matches matches designated non links decision rule applied set pairs ii matches set pairs decision rule applied 
generally link non link refers designations decision rules match non match refers true status 
related identifying similar records various databases computationally intensive di cult task 
large databases storing millions records pair wise comparison records feasible 
implies technique record linking computationally cient intelligent 
paragraphs describe related viewpoint searching matching steps record linking process 
searching process case searching step errors form failures bring potentially linkable pairs records comparison reduced zero simply comparing record records 
les large procedure generally regarded excessively costly terms enormous numbers wasted comparisons pairs records matched 
reason usual order records database identifying information common records new 
ordering done information kept key combination record elds 
exact matching sorting le reduce complexity identifying duplicate records bd 
approximate record matching various compression codes phonetic ciently overcome failures bringing potentially linkable pairs records comparison 
number systems doing common known russell soundex code 
essentially phonetic coding assignment code digits phonetically similar group consonants 
technique cutting number unwanted comparisons approximate record matching scan database xed size window check matches comparing pair records falls inside window hs assuming records sorted 
process augmented authors multiple passes database sorted neighborhood approach di erent sort keys pass transitive closure phase combining results independent passes 
transitive closure step independently identi ed authors 
approach scan database comparing records agree de ned key example key sorting records 
technique known blocking 
approach proposed union nd structures keeping track clusters approximately duplicate records incrementally 
respect searching phase proposed methodology combination multi pass sorted neighborhood approach pre selected keys standardization values kept subset elds 
standardization similar coding schemes mentioned 
particular sorting starts pre processing phase applied records public domain software standardizing lists containing name address information 
matching process pairs records brought comparison decisions regarded linked linked possibly linked depending various agreements disagreements items identifying information 
example linking person records possible measurement compare family names records assign value pairs agreement pairs disagreement 
measurements yield vector observations record pair 
proposed statisticians uenced pioneering fellegi sunter fs 
documents derivation test statistic critical region deciding pair records match 
addition discusses assumptions necessary practical applications describes approaches estimating eld matching probabilities calculate test statistic 
authors hs suggest equational theory manually acquired domain experts codi ed rule base expert system 
authors suggest domain independent algorithm detecting approximately duplicate records 
authors suggest training prediction model generating table prospective matches training set reduction complexity model statistical techniques 
approach uses clustering technique automatically identify comparison classes com parison space sample set records 
space generated comparison vectors corresponding classes identi ed clustering automatically reduced feature subset selection process minimizes number vector components building predictive model determines linking status pair records database 
induced model automatically transformed set production rules simpli ed accurate 
methodology proposed methodology tries overcome computational ine ciencies previous ap proaches automatically building model captures important patterns exist data 
established machine learning techniques adequately utilized framework building minimal model ts data 
phases methodology listed explained subsequent subsections 
data pre processing records dealing various semantic inconsistencies data problems individual records missing values null values outliers data standardization important task preparation data phases 
sorting individual records values pre speci ed key blocking variable sampling records 
scanning records sample set pair wise comparison records falling inside constant size window 
result phase generation comparison vectors record pairs sample set 
clustering algorithm identify clusters comparison space sample set clusters identi ed labels comparison vectors building model decision tree inducer 
transformation decision tree rule set application simpli cation technique reducing size rule set improving predictive accuracy 
nal rule set linkage rule set deciding linking status pairs records falling inside constant size window entire sorted data set 
data pre processing preparing data phases important domain speci task 
example conversion characters data stream lowercase uppercase helps avoid variations may exist due case di erences various data elements 
systems records stored discrete entries 
provides powerful technique modeling analysis individual components combined way represent entity uniquely 
instance elds involving name rst name street number city state zip code need concatenated 
field values usually contain di erent types extraneous characters 
possible removed data stream 
useful reduce information represented eld minimum num ber categorical values 
allows conveying certain types information overhead representing single unique value 
standard unit adopted eld appearing data set 
example eld containing measures distance standard conversion unit adopted values represented database 
actual processing data record linking technique discussed earlier requires valuable computational time bene cial restrict data set minimal exhibits certain quality characteristics 
records containing empty null elds critical analysis usually removed 
value boundary violations result bad dirty data removed 
point data pre processing phase heavily dependent domain condition ow data 
example null values common entire data set better project attributes null values discarding entire data set 
addition boundary violation problems easily resolved nd semantics values represented records 
example value month eld may represent total values months speci ed year 
important pre processing task attempt link records standardization data 
appropriate parsing name address components crucial part computerized record linking 
true matches erroneously designated non links common identifying information compared 
basic ideas standardization replace spelling variations commonly occurring words standard spellings xed set abbreviations spellings ii certain key words standardization hints parsing subroutines 
standardizing names words little distinguishing power limited replaced consistent abbreviations respectively 
name spelling variations rob replaced consistent assumed original spelling robert identifying root word 
standardization addresses operates standardization names 
words road rural route typically replaced appropriate abbreviations 
sorting sampling sorted neighborhood approach able ciently process records need sort 
sort data generate linear ordering 
order technique ective domain knowledge important 
domain experts sort data priori knowledge certain elds parts elds discriminating power record linking process 
expect parts general sense clean large extent ected various kinds errors introduced system 
case multiple passes required achieving results 
reason multiple passes sorting purposes data help resolving problem 
blocking sorted neighborhood technique records having di erent values blocking variable falling outside certain window considered tested linking 
example error sort key record record placed incorrectly far away correct place sorted le hindering way identi cation true matching records 
selecting di erent sort keys di erent passes high probability passes record located right place identi cation linked records achieved 
scanning data times comes heavy duty decreased performance considered function available computational resources available time cost constraints met business environment balance kinds errors statistical sense 
rst identi es pair records link records match second identi es pair records non link records match 
depending impact errors decide selection sort keys number passes 
records sorted easily extract sequential subset records database sample processing 
reason need apply involved algorithm sampling important events data restricted small neighborhoods contiguous records 
selecting appropriate size sample set issue expect easily resolved experimentally 
sorted neighborhood technique suggested stolfo hs applied sample set records 
records falling range size location record sorted sample le compared process repeated records sample database 
notice value phase bigger corresponding value entire database searched linkable records 
training process phase requires positive linked negative non linked examples correctly learning underlying domain model 
comparison vector generated record pair comparison holding information related closeness various attributes pair records 
comparison pair records viewed set outcomes result comparing speci attribute record attribute record 
outcomes may de ned speci cally desired 
example de ne outcome comparison simply attributes agree disagree 
de ne agreement outcome speci cally possible values attribute take 
comparison attributes usually interpreted mean attribute recorded record compared directly 
possible compare di erent attributes known correlated information related record descriptors 
clustering classi cation comparison space said earlier consists comparison vectors containing information related di erences elds pair records 
particular components vectors contain values continuous discrete type 
value continuous attribute comparison vector real number value discrete attribute small set possible values 
step determine linking status pair records information kept comparison vector 
sure vector correspond possible classes link non link possible link easy way assign classes labels comparison vectors 
able assign classes comparison vectors comparison vectors corresponding classes building model predicting class comparison vector model record linkage rule set 
order solve problem labeling comparison vectors consider slightly di erent problem 
trying immediately assign labels comparison vectors technique identify clusters comparison vectors map clusters labels corresponding record linking status 
clustering common descriptive task seeks identify nite set categories clusters describe data 
categories may mutually exclusive exhaustive consist richer representation hierarchical overlapping categories 
clustering technique easily applied comparison space record linking methodology order identify clusters vectors 
combining cluster values identi ed clustering algorithm corresponding com parison vectors create set training vectors input data mining technique induces models labeled vectors 
technique inducing model decision tree inducer qui qui generates decision trees examples prediction purposes 
decision tree inducer builds trees predicting label pair previously unseen records values vector components computed pair records 
set comparison vectors known classes decision tree induced called training set 
collections comparison vectors seen tree developed known test sets commonly evaluate performance tree 
non leaf nodes decision tree labeled name vector components computed training phase edges originating nodes labeled values ranges values corresponding component labels node 
leaf nodes labeled linking status majority comparison vectors covered node belong 
case non leaf node may labeled edit distance strings corresponding rst name record outgoing edges node labeled possible values groups values attained component leaf node labeled value matched designating majority class comparison vectors covered particular leaf node belongs matched status 
pruning traditional techniques avoid tting usually initially induced model correctly classi es examples corrupted noise 
pruning produces trees smaller size initial tree higher predictive accuracy 
feature subset selection important technique ects complexity record linking process ways 
understood vector components discriminating power respect class 
including induced model subset components highest correlation class label induction algorithm applies implicit form feature selection 
computations required determining values component comparison vector intensive expect high payo feature selection mechanism respect cutting processing time 
new techniques feature selection induction algorithm applied reducing dimensionality feature space especially kinds algorithms entire feature comparison vector inferencing purposes instance techniques 
respect methodology restricted particular kind induction class class satis es sc sc satisfy sc sc table contingency table simpli cation decision trees sc number cases satisfy belong class sc number satisfy belong class 
technique alternatives explored tested predictive accuracy 
decision tree transformation simpli cation decision tree induced previous phase transformed set production rules constitute rule base expert system 
decision tree easily transformed rule set converting path tree rule follows internal nodes output branches converted conditions antecedent part rule leaf nodes converted consequent part rule 
side ect try increase accuracy induced model time decrease complexity size ciency reasons 
merely rewriting tree collection equivalent production rules represent simpli cation 
improvement quality rule set adopt method proposed qui qui 
process stages individual production rules rst generated polished rules produced evaluated collection 
rst stage examines production rule see generalized dropping conditions left hand side 
conditions consider comparison vectors training set satisfy conditions rule 
respect cases relevance determining comparison vector belongs certain class conditions satis ed summarized contingency table shown table 
contingency table form presentation grouped data 
simplest case group items may classi ed just groups say presence absence certain characteristic 
categories may qualitative quantitative 
characteristic data classi ed get way table 
ways classi cation table called way table 
nal step rst stage estimate certainty factor simpli ed rule 
left hand side rule satis ed cases training set belong class indicated right hand side certainty factor production rule taken computing certainty factor estimate eliminated antecedent tested condition completely dropped ecting accuracy rule 
number rules generated way smaller number rules generated initially transforming patterns decision tree rules 
consequences dropping conditions antecedents rules input case matched rules 
case expert system puts matched rules agenda res highest certainty factor 
second stage simpli cation process looks rules function set 
evaluation depends way rules 
simple strategy adopted classify case nd rule applies choose rule higher certainty factor rule applies take class default frequent class training set 
rule rule set count mis classi cations produced rule set frg training set 
reduced rule set frg gives accuracy entire set rule removed rule set example order test methodology database records taken student sta telephone directory purdue university 
record contains rst middle home address ce address telephone number individual 
record contains system speci key automatically assigned system 
done allowing compute accuracy proposed methodology 
software controls generation errors database simulate variety real life scenarios 
replicated possibly erroneous record maintains original key 
numerical elds compute euclidean distance character string elds compute known edit distance metric implementing minimum edit distance algorithm man complexity mn sizes compared strings 
pre processing phase consists applying standardization phase records 
records assumed conditioned database generation process reason need apply kind pre processing 
standardization task bureau census record matching system win includes module standardize names business personal street addresses 
sorting database easily resort sort unix command sorts lines named argument les writes results standard output 
comparisons sort keys extracted line input 
default sort key entire input line 
database sorted easily extract small portion contiguous records sample set generating training set 
rst characters rst name rst characters main street name sorting database 
apply sorted neighborhood approach sample set 
size window depends things size sample set select small respect size sample set 
usually window size 
application sorted neighborhood approach comparison vectors pairs records falling window size 
step process partition comparison space clusters comparison records exhibit probabilistic behavior features 
reason auto class known clustering tool developed nasa ames research center 
autoclass applicable observations objects described set features properties referring objects 
allows user represent observations data vector corresponding xed attribute set 
attributes names measurable distinguishable properties things observed 
data values corresponding attribute limited numbers elements xed set attribute speci symbols 
autoclass uses probability models describing classes ts probability models input data 
kinds models supported autoclass 
rst kind includes probability models assume attributes matched address edit distance name edit distance matched matched decision tree generated cases training set 
conditionally independent class second includes covariant models express mutual dependences class 
selection particular probabilistic model important ensuring correctness results 
probabilistic model example components comparison vector multi normal 
model implements likelihood term representing set real valued attributes constant measurement error missing values conditionally independent attributes class 
assumption error record independent error 
comparison vector autoclass components 
autoclass came list possible models probable containing clusters 
consistent theoretical results link non link possible link comparison classes 
comparing actual status pairs records classes identi ed clustering tool recall training set know correct matching status compared pair records map class corresponding label 
order able test predictive accuracy induced model having records keep system speci key know correct linking status linking vectors having labels values matched matched 
inducing model domain labels corresponding comparison vectors 
information decision tree inducer building model identi ed classes 
selected id qui algorithm top inducer decision trees 
implementation algorithm mlc library provides feature subset selection technique reducing initial dimension comparison vectors 
demonstrates decision tree corresponding small comparison space comparison vectors 
name edit distance address edit distance class matched certainty factor name edit distance address edit distance class matched certainty factor name edit distance class matched certainty factor rule set produced translating information induced decision tree 
name edit distance class matched certainty factor name edit distance class matched certainty factor rule set produced simplifying initial rule set 
transforming decision tree patterns production rules get rule set displayed 
applying step approach improving quality rule set left reduced rule set displayed exactly predictive accuracy original rule set certain level statistical signi cance 
accuracy attained example 
considered respect number comparison vectors assigned possible link class correspond total number comparison vectors case study 
expert system shell inference engine applying rule set entire database particular test set clips gia nasa johnson space center 
entire system coded perl ous 
data mining techniques clustering classi cation applied problem approxi mately duplicate record detection 
pruning certainty factors utilized increased accuracy domains uncertainty major problem 
expert system technology promising vehicle provide solutions incomplete imprecise uncertain information 
sampling handy domains overabundance information fact 
solution shows great improvements automation knowledge acquisition phase similarity searching procedure combining techniques single framework time limits human intervention minimum exclude 
bd bitton dewitt 
duplicate record elimination large data files 
acm trans actions database systems 
kurien shasha 
cient data reconciliation 
bellcore february 
elmagarmid horowitz 
issues tion achieving data reconciliation aspects solutions 
technical report bellcore research september 
fs fellegi sunter 
theory record linkage 
journal american statistical association 
gia 
clips user guide version 
nasa lyndon johnson space center 
georgakopoulos 
speci cation management interdependent data operational systems data warehouses 
distributed parallel databases 
hs stolfo 
real world data dirty data cleansing merge purge problem 
journal data mining knowledge discovery 
ron kohavi dan sommer eld james dougherty 
data mining mlc machine learning library 
tools arti cial intelligence 
ieee computer society press 
www sgi com technology mlc 
man manber 
algorithms 
addison wesley publishing 
monge elkan 
cient domain independent algorithm detecting approx duplicate database records 
proc 
sigmod workshop research issues dmkd pages 
motro 
answers equally estimating quality database answers 
editor flexible query answering systems 
kluwer academic publishers 
new newcombe 
record linking design cient systems linking records individual family histories 
american journal human genetics 
ous john ousterhout 
scripting higher level programming st century 
computer march 
qui quinlan 
induction decision trees 
machine learning 
qui quinlan 
generating production rules decision trees 
proc 
th interna tional joint conference arti cial intelligence pages 
qui quinlan 
simplifying decision trees 
int 
man machine studies 
qui quinlan 
learning decision tree classi ers 
acm computing surveys 
win winkler 
record linkage software 
bureau census 
wang storey firth 
framework analysis data quality research 
ieee transactions knowledge data engineering 
ww wand wang 
anchoring data quality dimensions ontological foundations 
communications acm 

