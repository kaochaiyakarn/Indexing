optimal sequential prediction general processes andrew nobel november stochastic sequential prediction problem elements random process successively revealed forecaster 
time forecaster prediction revealed forecaster incurs loss 
considers aspects sequential prediction problem unbounded non stationary processes th power loss ju vj 
rst part shown bayes prediction schemes cesaro optimal general conditions cesaro optimal prediction schemes unique natural sense cesaro optimality equivalent form weak calibration 
extensions existence uniqueness results generalized prediction prediction observations additive noise established 
binary processes shown thresholding optimal prediction scheme squared loss yields optimal binary prediction scheme hamming loss 
second part shown construct countable family prediction schemes single composite scheme asymptotic performance suitable process dominates performance member family 
construction aggregating methods individual binary sequences 
construction results algoet existence cesaro optimal schemes families ergodic processes direct way extended unbounded processes 
andrew nobel department statistics university north carolina chapel hill nc 
email nobel stat unc edu 
supported part nsf dms 
subject stochastic sequential prediction 
problem elements real valued stochastic process revealed forecaster time time forecaster real valued prediction observed values revealed forecaster incurs non negative loss 
focus unbounded nonstationary processes restrict attention th power loss form ju vj 
denote real line collection nite length sequences real numbers sequence length zero represented empty set 
prediction scheme map assumed follows restriction tuples measurable function prediction scheme represents deterministic strategy prediction problem having observed past values process scheme prediction value value depend side information auxiliary randomization 
scheme applied successively rst terms process average cumulative loss random variable denoted central interest prediction schemes having small long run average cumulative loss 
notion optimality considered example 
de nition prediction scheme cesaro optimal optimal long run average sense process lim inf wp measurable prediction scheme prediction scheme cesaro optimal family processes cesaro optimal process de nition prediction scheme cesaro optimal process average cumulative loss asymptotically average cumulative loss competing scheme process 
note de nition require quantities converge tends nity 
notion cesaro optimality somewhat weak requires optimal scheme perform average 
may show example cesaro optimal schemes exist countable family processes see foster proposition 
cases stronger criteria predictive performance may appropriate 
criteria strong optimality eciency discussed brie section 
seeking prediction schemes perform uncountable family processes cesaro optimality provides sensible measure success 
noted section decision scheme strongly optimal uncountable family bounded ergodic processes contrast may construct cesaro optimal prediction schemes family variety ways see theorem 
numerous examples sequential prediction problems stationary general processes literature see example 
account stochastic non stochastic sequential decision problems relation calibration foundational questions statistics dawid 
thorough treatment sequential decision prediction problems ergodic stationary processes related time series prediction algoet 
algoet studies general loss functions 
exists envelope existence nite envelope th power loss requires process study take values bounded subset assumption 
algoet extension stability theorem martingale di erences see lemma plays central role results 
application section aggregating methods individual sequences stochastic prediction generalizes extends gy lugosi aggregating method de ne randomized predictors binary ergodic processes 
related methods applied weissman merhav prediction individual ergodic binary sequences 
aggregating methods applied di erent way foster prediction binary processes squared error 
generalizations sequential prediction bounded real valued ergodic processes squared error derived independently gy lugosi 
overview preliminary results section 
section existence uniqueness cesaro optimal decision schemes processes satisfying suitable population sample moment conditions established 
particular shown bayes decision scheme cesaro optimal cesaro optimal schemes natural sense equivalent 
extensions results generalized prediction prediction observations additive noise established sections respectively 
forms optimality related described section 
section shown cesaro optimality squared loss equivalent form weak calibration stronger form calibration considered dawid equivalent stronger form optimality 
existence uniqueness properties strongly optimal prediction schemes brie discussed 
section shown suitably thresholding prediction scheme cesaro optimal squared loss binary process obtains optimal prediction scheme hamming loss 
problem aggregating prediction schemes studied section 
countable family prediction schemes composite scheme constructed asymptotic performance suitable process dominates asymptotic performance member family 
appropriate choice countable family results algoet existence universal decision schemes ergodic processes extended unbounded processes direct way section 
particular shown exists single prediction scheme cesaro optimal th power loss ergodic process fx ejx preliminary results repeated stability result martingale di erences due algoet 
general account results 
bounded lemma may deduced standard exponential inequalities martingale di erence sequences 
lemma stochastic process random vectors measurable function sup jz log wp elementary lemma useful 
lemma function 
non negative numbers lim sup ifa cg lim sup ifa cg tend zero 
proof large 
rst claim follows readily ifa cg ifa cg cn second claim consequence inequalities ifa cg ifa cg existence uniqueness cesaro optimal schemes section existence uniqueness cesaro optimal schemes general nonstationary stochastic processes established 
process satisfying population sample moment conditions sup ejx log jx lim sup jx function 
ergodic follows immediately ergodic theorem 
general implication need hold 
de nition bayes prediction scheme ferguson process th power loss de ned arg min jx aj time bayes scheme selects unique prediction minimizing conditional expected loss outcome previous values process 
follows readily ejx ejx measurable function particular may view projection space functions 
ando studied general properties projections shown general increasing sequence sigma elds share convergence integrability properties conditional expectations see section details 
require preliminary fact concerning integrability bayes scheme related results 
lemma bayes scheme process satisfying 
set log 
jb jx wp jb jx wp sup jb proof process satisfying 
xed jb jx jx jx jx 
jx jx 
second inequality consequence monotonicity norms third follows directly de nition 
elementary inequality implies jb jx 
jx jensen inequality rst term right jx follows 
inequality follows directly convexity inequality immediate consequence assumption 
processes values bounded interval reals cesaro optimality bayes scheme follows directly theorem 
theorem shows bayes scheme cesaro optimal general conditions 
cases bayes scheme optimal stronger senses see section 
theorem existence stochastic process values 
conditions hold bayes prediction scheme arg min jx aj cesaro optimal th power loss 
proof prediction scheme 
simplify notation 
fix de ne auxiliary schemes cg cg 
routine calculation shows jx observe jx jf jx jx yields lower bound jx 
jx follows displays lim inf lim inf lim sup jx wp show fjx fjx satisfy moment condition lemma uniformly bounded niteness sup jx follows directly assumption 
jx jx jb jx jb sup jx nite lemma 
applying lemma yields equation lim inf lim inf jx jx wp de nition ensures term sum positive probability 
follows inequality lim inf lim sup wp letting tend nity condition lemma imply limit supremum tends zero 
arbitrary cesaro optimal result shows cesaro optimal schemes essentially unique form uniqueness depending value taken theorems show cesaro optimal scheme equivalent bayes scheme theorem uniqueness satisfy 
suppose bayes scheme de ned cesaro optimal scheme jf wp jf wp proof cesaro optimal lim inf lim sup lim inf wp 
de ne compound decision scheme write follows equation lim inf lim inf lim inf juj jvj ja bj ja bj jaj jbj lemma 
setting rearranging terms shows ju vj follows lim inf lim inf jf lim sup jf lim sup jf positive positive probability inequality fails cesaro consistent contradicts theorem 
case considered section 
example simple example illustrate theorems 
measurable nonlinear function suppose simplicity range bounded 
ej log 
random variable independent de ne recursion fx possibly non stationary nonlinear ar process 
squared loss bayes prediction scheme 
theorem cesaro optimal expected limiting average cumulative loss scheme bounded lim theorem implies cesaro optimal prediction scheme probability 
extensions generalized prediction generalized prediction problem goal determine past observations value known function observation observation 
stochastic process 
suppose having observed wish predict value way minimize long run average th power loss 
prediction problem considered corresponds special case generalized prediction problem average performance prediction scheme time units jg prediction scheme cesaro optimal lim inf wp measurable prediction scheme fix real valued process sup jg log 
lim sup jg function 
generalized bayes prediction scheme de ned arg min jg aj result extension theorems problem generalized prediction 
proof omit details 
theorem hold generalized bayes scheme cesaro optimal cesaro optimal prediction scheme jf probability 
jf probability prediction observations additive noise suppose 
consider variant prediction problem forecaster direct access values process noisy observations form zero mean random variables de ned probability space particular assume independent martingale di erence sequence wp sup jn log 
available sequence noisy observations follows sup jy 
suppose performance scheme time units measured average squared loss prediction scheme called cesaro optimal measurable prediction scheme lim inf wp bayes prediction scheme 
may establish 
coincides bayes prediction scheme weissman merhav studied prediction individual ergodic binary sequences presence noise variety loss functions 
exhibited cesaro optimal schemes di erent noise models joint process clean noisy observations ergodic satis es conditional mixing condition 
additive noise satisfying existence uniqueness cesaro optimal prediction schemes holds general conditions 
proposition suppose hold hold 
bayes scheme cesaro optimal 
cesaro optimal prediction scheme jf probability 
proof proof follows theorem 
prediction scheme 
de ne cg 
arguments leading nds lim inf lim inf lim sup jx wp consider rst term right hand side 
simple calculation shows fact jn jn jb assumption part lemma imply sup jn nite 
lemma wp assumptions imply probability 
similar argument shows probability 
cesaro optimal follows lim inf lim inf conjunction inequality implies lim inf lim sup jx wp optimality follows letting 
proof uniqueness similar theorem omitted 
forms optimality cesaro optimal average performance prediction scheme dominate equal competing scheme limit increasing observations 
describe forms optimality received attention literature 
forms essentially stronger cesaro optimality apply stronger competitive criteria 
case bayes scheme optimal unique appropriate sense 
strong optimality strong optimality notion calibration discussed section de ned terms place selection schemes 
de nition measurable place selection scheme binary valued function restriction tuples measurable function 
stochastic process 
place selection scheme selects random subsequence minft minft 
de nition inclusion subsequence depends previous values process 
way assessing performance prediction scheme evaluate di erence selected time prediction observed value de nition decision scheme strongly optimal bounded process decision scheme measurable selection scheme lim inf surely event selects nite subsequence strong optimality introduced equivalent form dawid means assessing empirical validity prediction scheme applied individual binary sequence 
avoid pathologies arising individual sequence setting restricts attention computable selection schemes computable prediction rules 
stochastic process pathologies occur probability zero loss considering measurable selection schemes prediction rules provided satis ed sure results 
analysis strong optimality relies analog lemma proof discussion see dawid 
lemma process values random variables measurable function constant jz probability jx surely 
proposition may established lemma arguments similar theorems 
noted imply dawid setting computable prediction schemes conversely 
uniqueness computable schemes individual binary sequences established theorem 
proposition bounded process 
bayes scheme strongly optimal strongly optimal scheme jf probability 
eciency notion predictive optimality eciency considered dawid see 
de nition prediction scheme ecient process measurable decision scheme lim sup jx jx probability 
multivariate version result appears theorem subsequent remarks 
noted case remains open 
var jx conditional variance theorem bayes scheme ecient squared loss sup var jx nite probability generally holds surely event supremum nite 
ecient prediction scheme nite probability 
bounded processes squared error comparative strengths di erent forms optimality follow readily relation bayes scheme 
proposition bounded squared error eciency implies strong optimality strong optimality implies cesaro optimality 
optimal prediction calibration cesaro optimality weak calibration recall section place selection scheme selects subsequence process non anticipating manner 
motivated dawid de nition 
de nition prediction scheme rst order calibrated measurable selection scheme lim probability 
scheme second order calibrated measurable selection scheme lim sup probability 
de nition weak sense averages taken respect time scale original process subsequence 
note relation implies surely event inf selected times occupy non negligible fraction positive integers 
similar remarks apply relation 
proposition proved section proposition assumptions prediction scheme cesaro optimal rst second order calibrated strong optimality strong calibration bounded processes may strengthen natural way notion calibration studied requiring convergence hold selects nite subsequence de nition decision scheme strongly calibrated measurable selection scheme surely event strong calibration introduced individual binary sequences 
proposition may established lemma arguments proposition 
analogous result individual binary sequences theorem 
proposition prediction scheme strongly optimal squared loss strongly calibrated threshold prediction binary processes establish connection prediction binary processes squared hamming loss functions 
process values 
take popular example suppose binary record rainfall speci location rains th day 
square loss predictions bayes scheme conditional probabilities decision scheme models predictions weather forecaster day predicts conditional probability rain day incurs loss value revealed 
suppose forecaster employing decision scheme values restricted binary predictions form tomorrow rain tomorrow rain incurs loss depending prediction correct 
discrete version prediction problem hamming loss ifu vg 
case bayes decision scheme arg min ifb obtained thresholding bayes scheme 
may readily show cesaro optimal light natural forecaster employ threshold scheme iff order predict value conditional probability estimates fact cesaro optimality implies version result ergodic processes established independently 
theorem binary process 
cesaro optimal squared loss threshold prediction scheme cesaro optimal hamming loss 
proof 
shown see proofs theorems jf fix binary valued prediction scheme 
wish establish lim inf lim inf wp lemma suces show lim inf wp inequality equation imply jf follows jf theorem 
straightforward modi cation preceding proof substituting lemma lemma yields result 
theorem binary process 
strongly optimal squared loss threshold prediction scheme strongly optimal hamming loss 
aggregating decision schemes consider general prediction problem described goal constructing prediction scheme cesaro optimal th power loss family stochastic processes satisfying 
recall prediction scheme cesaro optimal family processes cesaro optimal member family 
analogous de nitions hold forms optimality 
clear de nition bayes scheme process generally cesaro optimal di erent process dawid bayesian approach combine bayes predictors parametric family processes fx suitable families positive prior construct prediction schemes ecient lebesgue member family 
particular prediction scheme cesaro optimal member parametric family bounded processes 
may readily verify decision scheme cesaro optimal family processes satisfying 
holds restrict attention bounded binary processes 
prediction scheme de ne recursively sequence jf 
probability cumulative loss bayes scheme equal zero 
absence universal prediction schemes useful way assess quality prediction scheme compare process asymptotic performance scheme best asymptotic performance nite countable family competing schemes 
way attention shifts absolute comparative measures performance 
central problem comparative framework construct single scheme competes favorably member family wide variety processes 
cases may accomplished suitably combining aggregating decisions individual schemes aggregating methods corresponding bounds di erence loss aggregate scheme best scheme family established variety settings 
representative :10.1.1.37.1595
foster vohra give account aggregating problem history 
merhav feder give overview prediction individual sequences 
weissman merhav establish nite sample aggregation bounds prediction individual binary sequences observed additive independent noise th power loss 
describe aggregating method prediction schemes weighted majority techniques predicting individual binary sequences 
fix countable family ff prediction schemes 
assume scheme bounded sense jf sup sup jf ff contain rst prediction schemes de ne weighted sum predictions schemes time weights note weight assigned scheme time depends cumulative loss predictions time time 
equal weight jf related weight assignment combine binary predictors 
proposition shows suitable processes long run average cumulative loss equal long run average cumulative loss scheme proof section 
foster established analogous result bounded processes squared loss recursive construction 
proposition suppose jf 
stochastic process sup ejx nite ii lim sup jx nite probability 
probability lim sup lim sup lim inf countable family ff bounded prediction schemes may ensure replicating schemes necessary growth condition jf satis ed 
proposition hold family 
bounded processes squared loss exhibit aggregate prediction schemes inf ln wp universal constant 
prior distribution elements 
proof proposition relies weaker general inequality sort arguments cesa bianchi see lemma 
sequential prediction ergodic processes random variable de ned probability space 
sub sigma eld de ne xjs arg min jx de nition ensures xjs measurable random variable ejx xjs ejx measurable random variable xjs natural projection family measurable random variables 
properties projections studied ando established result 
theorem 
increasing sub sigma elds limit relations hold xjs xjs probability sup xjs constant 
alternative approach may establish de nition fact probability jx aj convex functions converging pointwise uniformly bounded intervals convex function jx aj 
part theorem shows expected value supremum nite 
stronger moment assumptions may established direct arguments 
obvious extension lemma sup xjs sup jxj fe jxj uniformly integrable martingale converges probability expectation integrable random variable jxj 
follows maximal inequality standard bounds see theorems sup jxj nite jxj log jxj nite 
theorem breiman ergodic theorem may give simple characterization cesaro optimal prediction schemes ergodic processes terms limiting average loss competing prediction schemes 
characterization proposition deduced results algoet 
sketch direct simpler proof completeness 
standard arguments breiman chapter may assume loss generality ergodic process consideration doubly nite time index de ned probability space consists doubly nite sequences real numbers generated nite dimensional cylinder sets 

proposition fx stationary ergodic process jx log jx 
prediction scheme cesaro optimal ejx jx wp jx 
optimal limiting average loss written inf inf ejx second mum bounded uniformly continuous functions proof theorem relation imply cesaro optimal probability bayes scheme establish suces consider case note jx jx left shift operator 
assumption preserving ergodic 
follow expression breiman generalized ergodic theorem see proof jx jx jx jx probability sup jx jx 
relations follow immediately theorem establish note dominated convergence theorem imply ej jx lim ej jx de nition 

th term limit equal ej jx inf ejx mum measurable functions expectations decreasing equation follows bounded uniformly continuous functions dense 
universal prediction schemes ergodic processes recall decision scheme cesaro optimal family processes cesaro optimal process algoet established existence cesaro optimal schemes families ergodic processes general setting sequential decision problems 
schemes derived estimates conditional probabilities jx property converges weakly jx probability ergodic process 
estimates see 
specialized setting results establish exist cesaro optimal schemes family ergodic processes values 
describe prediction schemes cesaro consistent unbounded ergodic processes relatively weak moment conditions 
schemes elementary aggregating method described previous section avoid conditional probability estimates 
modha exhibited probability consistent estimates jx bounded alpha mixing processes mixing coecients decay known exponential rate 
additional conditions established rates convergence estimates jx nite memory 
nested sequence nite partitions constituent cells shrink sense lim diam unique cell containing diam sup ju vj denotes maximum distance points nite necessarily unbounded cells 
condition ensures sequence cells containing xed point eventually shrink partition may obtained example dividing intervals length letting complement comprise single cell 
fix 
de ne th order markov prediction scheme follows 
set arg min ifx understand de nition say match occurs position vectors preceding lie cells vectors preceding element minimizes sum losses occurring match positions 
note increases predictions longer precise matches 
prediction schemes analogous brie discussed algoet similar randomized schemes proposed prediction binary processes 
note randomization required setting 
proof theorem section 
theorem aggregate prediction scheme derived fh 
cesaro optimal th power loss ergodic process ejx existence cesaro optimal schemes general bounded loss functions established algoet results bounded processes squared error generalizations discussed 
aggregation bounds form gy lugosi independently established cesaro optimality prediction scheme similar bounded processes squared loss 
consider cesaro optimality prediction schemes generalized linear estimates obtain rates convergence predicting gaussian processes 
results assume boundedness loss function equivalent case take values prespeci ed bounded interval 
assumptions theorem 
strongly optimal schemes ergodic processes family ergodic processes values bounded aggregate scheme de ned previous section cesaro optimal contrast prediction scheme strongly optimal squared loss elements 
illustrate family binary ergodic processes squared loss 
corresponding bayes scheme form jx 
strongly optimal follows proposition binary ergodic process jf jx wp known line estimation scheme exists 
prediction scheme strongly optimal reasoning prediction scheme strongly optimal squared loss cardinality greater 
similar negative holds ecient prediction schemes 
properties universal schemes squared loss section aggregate prediction scheme derived markov schemes fh squared loss 
theorem ensures cesaro optimal ergodic process ejx 
process 
theorem jx wp property derived bounded processes di erent arguments 
proposition ensures jx wp suppose fn zero mean random variables independent satisfy 
observations corrupted additive noise 
predict clean value limiting average cumulative loss natural form 
related results binary processes general loss functions 
proposition wp proof 
theorem 
fact cauchy schwartz inequality may readily show wp follows breiman ergodic theorem alternatively arguments similar proof proposition probability 
interesting question received attention literature estimate conditional expectation observations ergodic process fx 
ornstein described surely consistent estimates binary processes case bounded real valued processes studied algoet see nal word 
prediction scheme yields estimates consistent weaker expectation sense 
proposition fx bounded ergodic estimate converges probability 
proof jx bayes prediction scheme follows identity jx martingale convergence theorem converges expectation 
suces show ej 
expectation jh rst equality follows stationarity nal expectation tends zero theorem bounded convergence theorem 
family binary ergodic processes 
calibration breiman ergodic theorem elementary corollary 
suppose fje jx pj 
ratio lim inf lim sup suppose binary record rainfall location 
inequalities show predict probability rain day days predicted probability rain near fraction days near words calibrated classical sense 
note threshold prediction scheme associated jx jx wp cesaro optimal additional derivations proof theorem case 
suppose cesaro optimal decision scheme 
claim lim sup jb ii lim sup iii lim sup jf follows lemma assumption 
relation ii consequence relation iii follows ii elementary inequality jf jf jx 
suppose lim sup jf relations iii imply exists lim sup jf cg lim sup jb cg jf cg jb cg truncated versions respectively 
imply lim sup jf bounded follows lim sup expression imply lim sup continuity strict convexity juj ensure see equation positive values compact set ju vj juj jvj jxj follows inequality lim inf lim inf lim sup positive probability 
contradicts cesaro optimality fails hold result follows 
proof proposition satisfy 
bayes prediction equal 
applications lemma show rst second order weakly calibrated suppose cesaro optimal theorem 
note selection scheme jf arguments proof theorem case time averages bounded 
nal term tends zero increasing second order calibration follows similar argument shows rst order calibrated suppose rst second order calibrated note cesaro optimal second order calibrated sequences bounded establish optimality suces show probability 
application inequality selection schemes cg shows lim sup lim sup cg lim sup cg cg cg cg follows display assumption lemma lim lim sup cg wp relation holds bayes scheme second order calibrated exists lim sup lim sup jf jb cg 
establish proposition show xed de ned wp term sum uniformly bounded relation holds events lim sup iff lim sup ifb probability zero 
fix de ne new selection scheme 
iff clearly iff lemma rst order calibration imply lim sup lim sup wp 
similar argument shows holds desired 
proof proposition nite family prediction schemes xed 
numbers integers de ne composite prediction scheme 
jf xed positive constant 
convex combination predictions individual schemes weight assigned time depends success predicting values proof lemma follows closely argument cesa bianchi individual binary sequences 
lemma fix 
time interval cumulative loss composite decision scheme satis es inequality min ln jf max jf proof proof telescoping argument 
set jf de ne clear right hand side equation moment generating function random variable chosen distribution 
clearly takes values interval 
centering expectation applying hoe ding inequality moment generating function bounded random variable nd ln 



second inequality consequence convexity 

follows summing ln hand clear max ln min ln jf combining inequalities completes proof lemma 
proof proposition simplify notation de ne 

fix jf 
increasing constants jf 
de nition ensures fix de ne blog nc 
cumulative loss may written follows de ne max jf repeated application lemma shows sum second third terms min min log jf min log jf previous displays show min log jf nc wish show terms tend zero tends nity 
nite probability clear wp log jf log jf nc tends zero tends nity note max jf jx jx assumption sup ejx nite 
fix 
constants satisfy particular jx rst term right side converges zero 
second term note markov inequality jx fjx sup ejx assumption supremum nite sum rightmost probabilities nite 
follows borel cantelli lemma probability jx nitely value lim sup jx 
lim sup jx wp arbitrary limit supremum nite assumption ii conclude jx wp combining relations inequality follows lim sup min lim sup wp lim sup min wp arbitrary inequalities immediate 
proof theorem de nition family functions measurable respect sigma eld generated sets form 
form ifx choice xed number 
proof theorem stationary ergodic process ejx consider moment sequence cells pfx 
de ne ifx de ne ifx note bounded strictly convex function true probability functions large ifx 
ergodic theorem implies probability 
follows standard results convex analysis see convergence uniform sense sup wp de ne minima arg min arg min suciently large strict convexity imply minima achieved unique 
guarantees probability 
de nition prediction equal 
de ne new prediction scheme 
di erence jl ifx claim term sum tends zero tends nity 
pfx corresponding average zero probability 
suppose pfx 
application lemma suces include second sum xed arbitrary 
restriction average tends zero increasing 
lim sup lim sup lim ifx ifx min ifx min ifx min bounded uniformly continuous 
suciently large exists ejx ejx 
follows proposition relation lim sup min lim sup min min ejx arbitrary cesaro optimal lemma 
ando convergence prediction sequences verw 
geb vol pp 
algoet strong law large numbers sequential decisions uncertainty ieee trans 
info 
theory vol pp 
algoet universal schemes prediction gambling portfolio selection ann 
probab vol pp 
correction ibid vol pp 
algoet universal schemes learning best nonlinear predictor nite past side information ieee trans 
info 
theory vol pp 
azuma 
weighted sums certain dependent random variables math 
journal vol pp 
bailey sequential schemes classifying predicting ergodic processes phd 
thesis department mathematics stanford university stanford ca 
breiman probability siam philadelphia pa 
cesa bianchi analysis gradient algorithms line regression proc 
th annual conference computational learning theory pp acm press 
cesa bianchi freund helmbold warmuth line prediction conversion strategies machine learning vol pp 
cesa bianchi freund haussler helmbold schapire warmuth expert advice assoc 
comp 
mach vol pp 
dawid calibrated bayesian discussion amer 
stat 
assoc vol pp 
dawid statistical theory 
prequential approach discussion roy 
statist 
soc 
vol pp 
dawid calibration empirical probability discussion ann 
statist vol pp 
dawid vovk prequential probability principles properties bernoulli vol pp 
devroye gy lugosi probabilistic theory pattern recognition springer new york 
stochastic processes wiley new york 
feder merhav gutman universal prediction individual sequences 
ieee trans 
info 
theory vol pp 
foster prediction worst case ann 
statist vol pp 
foster vohra regret line decision problem games economic behavior vol pp 
ferguson mathematical statistics academic press san diego 
gray probability random processes ergodic properties springer new york 
gy lugosi strategies sequential prediction stationary time series modeling uncertainty examination theory methods applications dror eds kluwer 
gy limits consistent line forecasting ergodic time series ieee trans 
info 
theory vol pp 
gy lugosi 
simple randomized algorithm consistent sequential prediction ergodic time series ieee trans 
info 
theory vol pp 
haussler warmuth sequential prediction individual sequences general loss functions ieee trans 
info 
theory vol pp 
hoe ding probability inequalities sums bounded random variables journal american statistical association vol pp 
littlestone warmuth weighted majority algorithm info 
comput vol pp 
merhav feder universal prediction ieee trans 
info 
theory vol pp 
modha memory universal prediction stationary random processes ieee trans 
info 
theory vol pp 
gy nonparametric inference ergodic stationary time series 
ann 
stat vol pp 
algoet weakly convergent nonparametric forecasting stationary time series ieee trans 
info 
theory vol pp 
murphy winkler reliability subjective probability forecasts precipitation temperature 
series vol pp 
ornstein guessing output stationary process israel math vol pp 
parthasarathy probability measures metric spaces academic press new york 
rockafellar convex analysis princeton univ press princeton nj 
real analysis third edition prentice hall nj 
ryabko prediction random sequences universal coding ieee trans 
info 
theory vol pp 
dawid ecient point prediction systems roy 
statist 
soc 
vol pp 
dawid ecient probability forecasting systems biometrika vol pp 
stout sure convergence academic press new york 
vovk aggregating strategies proc 
rd annual workshop computational learning theory pp 
morgan kaufman san mateo weissman merhav universal prediction random binary sequences noisy environment preprint 
weissman merhav universal prediction individual binary sequences presence noise ieee trans 
info 
theory vol pp 

