evolving integrated controllers autonomous learning robots dynamic neural networks inman harvey matt quinn centre computational neurosciences robotics school cognitive computing sciences university sussex brighton bn qh united kingdom phone fax eliot cogs susx ac uk yamauchi beer attempted evolve dynamic neural network control system simulated agent capable performing learning behaviour 
tried evolve integrated network modularized attempt failed 
ended recommending independent evolution separate controller modules arbitrarily partitioned researcher 
provided agents hard wired reinforcement signals 
model describe demonstrates possible evolve integrated dynamic neural network successfully controls behaviour khepera robot engaged simple learning task 
show dynamic neural networks leaky integrator neuron shaped evolution appear able integrate reactive learned behaviour integrated control system bene ts evolved reinforcement signal 
yamauchi beer pointed research learning robots typically drew sharp distinction mechanisms responsible agent behaviour responsible learning kaelbling 
claimed distinction dicult defend biologically biological processes involved reactive learned behaviour 
claim looking current theory study learning biology suggest animals learning capabilities tuned evolution particular niche occupy garcia wilcoxon davey 
set experiment tried evolve autonomous learning robot selectively integrating necessary plasticity directly mechanisms responsible robot behaviour 
methodology meant guarantee structural functional decomposition may analysis behaviour evolved control system result entirely evolutionary contingencies animals 
previous research learning robots relied explicitly hand designed decomposition modularization behaviour robot control system kaelbling 
approach undertaken yamauchi beer part general way assuming evolutionary perspective designing control architecture autonomous agents 
research area generally referred evolutionary robotics harvey nol floreano 
potential bene ts evolutionary approach design simulated real agents control systems possibly agents morphologies engineering purposes new methodology biology widely debated see webb nol 
generally speaking appeal evolutionary approach robotics fold 
firstly basically ers possibility automating complex design task meyer nol floreano harvey 
secondly arti cial evolution needs understand decompose problem order nd solution ers possibly exploring regions design space conventional design approaches constrained ignore harvey 
growing amount research evolutionary robotics focusing evolution controllers ability modify behaviour robot order adapt variation operating conditions 
variation mean changes relationship robot sensors actuators environment floreano floreano mondada nol floreano eggenberger 
yamauchi beer approach clearly represents rst attempts continuous time recurrent neural net works exploited integrate reactive sequential learned behaviour simulated robot 
apart yamauchi beer current research area investigating neural network controllers form synaptic plasticity networks incorporate mechanisms change connection weights 
yamauchi beer distinctively di erent unique due characteristics control system singularity learning task employed 
employed continuous time recurrent neural networks described brie section genetically de ned xed contrasted plastic connection weights leaky integrator neuron neurons activation decays time 
di erence learning task described robot learning experiments nol parisi floreano 
specifically required robot learn current relationship goal landmark relationship changes time time require robot adapt general variation concerning relationship robot sensors actuators environment variation color arena walls nol parisi variation lighting levels floreano 
yamauchi beer attempts evolve integrated modularized dynamic neural network control system simulated agent capable performing learning behaviour failed 
ended recommending independent evolution separate controller modules dedicated reactive sequencing behaviour dedicated learning 
hard wired model reinforcement signal works feedback signal learning module 
reasons explained section believe important carry yamauchi beer experiments originally intended forced compromises nd unsatisfactory 
model describing intended simply proof concept 
go yamauchi beer approach demonstrating possible evolve integrated dynamic neural network xed connection weights leaky integrator neurons successfully control behaviour khepera robot engaged learning task similar proposed yamauchi beer 
bring evidence leaky integrator neuron shaped evolution appears able integrate reactive learned behaviour single control system explicitly modularized 
integrated control system describing bene ts evolved reinforcement signals generate appropriate behavioural responses contrast explicit hard wired reinforcement signals 
structure follows rstly brief description yamauchi beer experiment see section 
point promising yamauchi beer approach completely satisfactory autonomy simulated agent severely compromised external reinforcement signal externally imposed modularization controller 
section describe methodology task evaluation function evolution integrated network simulated robot genetic algorithm 
section show experimental results 
section comparisons original yamauchi beer experiment 
discuss di erences contribute possible evolve integrated dynamic neural network assume priori separated controller module priori external reinforcement signal yamauchi beer 
drawn section 
yamauchi beer model learning robot yamauchi beer set experiment simulated robot repeatedly nd goal landmark guidance 
relationship position goal position landmark changed occasionally sequence searches successful behaviour required robot learn changes occurred 
picture adopted yamauchi beer 
environment dimensional navigation task 
triangle represents agent circle represents goal rectangle represents landmark 
landmark near environments left landmark far environments right 
yamauchi beer model agent move direction dimensional continuum environment see gure 
environment contains goal landmark 
start trial agent positioned center goal positioned randomly left right 
possible way landmark located environment 
environments landmark located side agent goal 
environments landmark located opposite side agent goal 
agent task learn series successive trials current environment landmark far landmark near reach goal 
trial lasted agent reached goal agent reached non goal continuum time limit exceeded 
attempts yamauchi beer evolve single fully capable solving task unsuccessful modular incremental approach network architectures split separately evolved subnetworks behaviour landmark far environment goal seeking behaviour landmark near environment environment classi cation 
subnetwork consisted neuron fully interconnected 
subnetworks sensor input landmark detection activated agents directly contact landmark motor outputs left right motor neuron 
addition classi er network sensor input reinforcement provided time network reached goal classi cation output determine environment type 
goal seeking networks speci cally evolved properly navigate type environment 
classi er network speci cally evolved control behaviour agent rst trial decide agent living landmark far landmark near environment 
classi cation environment landmark far output classi cation neuron rst trial landmark near 
evolved strategy quite simple 
classi er network starts classi er output high indicating choice landmark near environment moving robot left side 
sensing landmark causes reversion direction movement reinforcement signal hard wired model classi er output go low indicating choice landmark far environment 
reinforcement provided classi er output remains high regardless agents encountered landmark 
evolved responses classi er network able correctly identify possible combination environment type goal location 
thoughts comments believe yamauchi beer model evolved learning behaviour arti cial agents valuable clearly represents rst attempts arti cial evolution exploited design internal dynamics integrate perceptions agents determine agent actions perceptions 
model tness function rewards behavioural responses ful conditions learning 
external evolved reinforcement signal directly available robot signals robot performs correctly 
reward signal clearly externally imposed supervision severely compromises autonomy system 
attempts evolve integrated control system simulated agent capable performing learning behaviour failed 
ended recommending independent evolution separate controller modules dedicated reactive sequencing behaviour dedicated learning 
modularization controller structural functional decomposition externally imposed facilitate time integration di erent behavioural responses 
argue yamauchi beer model relying independent evolution separate controller modules arbitrarily designed researcher clearly dedicated separate behavioural responses external reinforcement signal failed evolve autonomous learning robot selectively integrating necessary plasticity directly mechanisms responsible robot behaviour 
evolving controllers autonomous learning robots drawing inspiration yamauchi beer experiment set evolve integrated dynamic neural network xed synaptic weights leaky integrator neurons control system robot engaged task learning behaviour required 
description task task requires navigation rectangular arena order nd goal represented black stripe white arena oor 
learning aspect requires robots learn series successive trials relationship position goal respect landmark robot guidance nd goal 
start trial robot positioned left right side empty arena see black points landmark far landmark near depiction task 
small circle represents robot 
white oval represents landmark light source black stripe arena goal 
picture top represents arena single trial landmark goal 
black points represent possible starting points 
curved dotted lines represent possible routes central part arena delimited dashed lines 
pictures represent possible arrangement landmark goal landmark near environment 
pictures represent possible arrangement landmark goal landmark far environment 
arrows pictures represent directions successful robot moves 
gure 
soon robot reaches central part arena delimited gure dashed lines goal represented black stripe randomly positioned white arena oor 
front robot perceivable proximity sensors see gure 
robot behaviour evaluated tness function rewards penalises certain behaviours evaluation determine spring evolutionary algorithm sense reinforcement directly available robot 
robot rewarded leaving current central position goal nds see arrows gure penalized sets away goal 
robot decide way go clue goal better making random decision 
robot landmark guidance 
landmark light lights soon goal positioned perceived robot arena 
relationship landmark goal vary trials landmark close goal landmark near environment gure trials opposite side landmark far environment gure 
possibilities exploited robot nd right way goal 
robot approaches landmark landmark near environment moves away landmark landmark far environment consequently nd goal signi cantly expected random walk 
current relationship landmark goal remains unknown robot gathered experience able disambiguate environment landmark near 
task requires robot learn series successive trials landmark goal relationships currently holds true 
robot disambiguate environment landmark near landmark far behaviour previous experience relationship location light location goal 
simplicity scenario means light signi cant robot particular context 
adaptive reason robot pay attention light light cue exploited part learning process 
robot reason pay attention light context 
robot light presents useful information trial predictable relationship light goal 
presents slight problem wish evolve control mechanisms necessary robot learn relative positioning light 
reasonable suggest robot evolved pay attention light dicult evolve learn relative relationship light position goal position 
problem addressed light signi cance learning cue 
way doing bias proportion type environment robots experience 
example robots landmark near environment landmark far environment goal close light far 
way light serve cue exploited purely reactive robot robot moves light correct wrong 
fully successful behaviour require robot learn distinguish type environment act appropriately 
bias proportion times environment kept proportion equal biased relative weighting scores achieved environment detailed section order achieve ect 
robot undergoes test sessions landmark near landmark far en vironment 
time environment changes robot control system reset internal state memory remaining previous environment 
test sessions trial corresponds lapse time robot reaching middle arena nding goal 
robot seconds reach middle arena 
landmark goal positioned robot seconds nd goal 
trial terminated earlier rst time limit reach middle arena exceeded agent reaches remains goal seconds robot crashes arena wall 
rst trial trial unsuccessful robot positioned left right part rectangular arena close short side 
trial successful robot normally keeps position orientation ended previous trial small probability replaced randomly 
simulation deliberately noisy noise added sensors motors see section extended environment dimensions 
time robot replaced width length arena width central area triggers appearance landmark goal rede ned randomly certain limits 
robot undergoes trials test session 
time relationship landmark goal kept xed relationship remains unknown robot discover experience 
position goal arena left right randomly determined single trial landmark subsequently appropriately positioned depending currently landmark far 
full set trials landmark goal combinations gure occur equal likelihood 
evaluation function robot rewarded evaluation function st test session trial reaching central area arena moving goal nd see arrows gure penalized fails reach central area central area set away goal 
st abcd dn pmax 
robot doesn get score rst trial test session assumed robot doesn know kind environment situated landmark near landmark far environment 
represents furthest distance robot reaches goal light 
time light goes xed distance centre robot body nearest point goal 
updated time step new bigger previous 
dn represents nearest distance robot reaches goal light 
time light goes dn xed equal subsequently updated time step robot gets closer goal robot goes away goal 
dn updated time updated 
case dn set equal new represents number steps robot goal longest period permanence 
pmax maximum number steps robot allowed goal trial ended bias term type environment set landmark near environment environment 
penalties 
set robot fails reach central part arena time limit exceeded crashes arena wall set robot leaves central area opposite side arena respect goal unsuccessful behaviour set robot crashes arena wall robot doesn fall penalties set 
total tness robot averaging robot performance assessed single trail test session 
simulated robot simple dimensional model khepera interactions arena responsible generating base set aspects simulation see jakobi de nition base set 
implementation simulator function updates position robot environment function calculates values returned infra red sensors ambient light sensors closely matches way jakobi designed minimal simulation khepera robot nite corridor see jakobi detailed description simulator 
simulation robot sensor values extrapolated look table 
noise applied sensor reading 
robot sensor ability includes infra red sensors ir ir gure ambient light sensors positioned degrees left right degrees respect face direction gure 
robot left right motor independently driven forward reverse allowing turn fully direction 
light modelled bar illuminates front back plan khepera mini robot showing sensors wheels 
robot equipped infra red sensors ir ir ambient light sensors 
oor sensor indicated central gray circle 
arena luminosity 
ambient light sensor faces point exterior robot detects light plus minus degrees normal boundary 
values returned ambient light sensors light set exceed xed threshold return 
robot extra oor sensor positioned robot functionally simulated ambient light sensor returns robot positioned white oor black oor 
simulation updated equivalent times second 
network fully connected neuron 
neurons governed state equation dy dt ji gi exp terms derived analogy real neurons represents cell potential decay constant bias term ring rate ji strength synaptic connections neuron th neuron th corresponding number input connections neuron neurons intensity sensory perturbation sensory neuron network neurons receive input robot sensors 
input neurons receive real value range simple linear scaling reading taken associated sensor neuron infra red sensor ir ir ir ir ir ir ir ir ambient light oor sensor 
th th neuron don receive input robot sensors 
cell potential mapped sigmoid function linearly scaled set robot motors output 
strength synaptic connections ji decay constant bias term gain factor genetically encoded parameters 
states initialized circuits integrated forward euler method integration step size 
states set time network reset 
genetic algorithm simple generational genetic algorithm ga employed goldberg 
populations contained genotypes 
genotype vector real numbers length neurons connections decay constants bias terms gain factor 
initially random population vectors generated initializing component genotype random values uniformly distributed range 
subsequent generations produced combination selection elitism recombination mutation 
new generation highest scoring individuals elite previous generation retained unchanged 
remainder new population generated tness proportional selection best individuals old population 
new genotypes elite produced recombination 
mutation entails random gaussian set applied real valued vector component encoded genotype probability 
mean gaussian 
evolution vector component values constrained range 
search parameters linearly mapped parameters ranges biases connection weights ji gain factor decay constants rstly linearly coded range exponentially mapped generations norm 
avg 
fitness graph shows normalized tness best robot continuous line normalized average tness population dotted line generation run 
results evolutionary simulations di erent random seed run generations see gure 
examined best individual nal generation runs order establish evolved appropriate learning strategy 
recall perform task successfully robot light source order navigate goal 
course test session robot learn come exploit relationship light source goal exists particular environment placed 
order test ability nal generation controllers subjected test sessions types environment landmark near landmark far 
session comprised consecutive trials controllers reset starting new session 
evaluations recorded number times controller successfully navigated target target directly rst going wrong arena 
results best controller runs seen gure shows percent successful behaviour trial session environmental condition 
clear runs run robots quickly table table gives connection weights ij neuron neuron best network generation run 
table decay constants bias terms neurons best network generation run 
table table gives connection weights ij neuron neuron best network generation run 
table decay constants bias terms neurons best network generation run 
gain factor equal 
run run run run run run run run run run trials single graph refers performance best control system nal generation single run evaluated test sessions types environment 
dashed lines indicate percent successful behaviour trial landmark near environment 
continuous lines indicate percent successful behaviour trial landmark far environment 
come successfully light navigate goal irrespective environment requires moving away light source 
controllers employ default strategy moving light successful landmark near environment see gure dashed lines 
consequently initially unsuccessful landmark far environment see gure continuous lines 
seen gure controllers placed landmark far environment capable adapting behaviour course trials subsequently come behave di erently respect light 
controllers placed landmark far environment initially navigates light fails encounter target subsequently reaches wrong arena 
point turns proceeds back correct arena ultimately encounters target stripe 
fact subsequent trials robot moves away light demonstrates robot learnt aspect aspects earlier experience current environment 
controllers learn mistakes 
noted controllers runs whilst performing task varying degrees success modify behaviour course initial trails case results improved performance 
example controller run initially success rate landmark near environment success rate landmark far environment 
landmark near environment success rate climb 
landmark far environment success rate climb course trials 
similarly controller run success landmark far environment increases rapidly whilst success landmark near remains consistently 
provide connection weights see table table bias terms decay constants gain factor see table table best evolved network best network generation run 
notice weights equal zero 
suggests aspects robot behaviour underpinned mechanisms relay highly distributed network causal relationships neurons modularized structures smaller number neurons functionally dedicated particular sub tasks 
discussion clearly strong similarities yamauchi beer experiment 
employed network style control behaviour robot tested robot similar environmental conditions described yamauchi beer 
di erences contributed successful results 
contrary yamauchi beer biased relative weighting score achieved environment order give landmark signi cance learning cue 
ects feature tness function clearly singled gure gure 
evolutionary perspective best robots run get stage employ photo taxis see plateau continuous lines tness gure 
means best robots light navigate arena 
evolution mechanisms photo taxis contributes quarters total score signi cantly helped guided evolution subsequent appearance learning controllers 
evolved learning robots consistently look light conditions reinforce phototaxis run landmark far environment robots change behaviour anti photo taxis see gure 
secondly didn terminate trial time robot nished wrong arena far away goal yamauchi beer agents 
robots slightly penalized allowed recover mistakes 
produces richer environment having time freedom explore help evolve proper reinforcement signal robot employ right behaviour environment landmark far 
complexity richness set harder identify condition reinforcement exploited learning robot 
clearly aspect evolved learning behaviour needs clari ed investigation 
thirdly tness function designed discrete fashion strongly reward successful behaviour strongly penalize unsuccessful behaviour 
yamauchi beer agents get reaching goal don reach goal 
black white approach arranged shades grey gradually increasing reward starting completely unsuccessful behaviours robots don manage landmark goal appear arena successful ones robots reach central part arena head successfully goal 
main di erences yamauchi beer experiment contributed successful results 
assess contribution brought achievement results tests analysis need carried 
yamauchi beer wanted determine dynamic neural networks provide ective control mechanism integrating reactive sequential learned behaviour autonomous systems having assume sharp division components reactive charge sequencing learning yamauchi beer 
gave brief description experiment due characteristics control system singularity learning task employed distinctive unique example area autonomous learning robots see section 
approach clearly represents rst attempts xed connection weights leaky integrator neurons exploited integrate reactive sequential learned behaviour simulated robot 
attempts evolve integrated controllers simulated agents capable perform learning behaviour failed 
ended recommending independent evolution separate controller modules dedicated reactive sequencing behaviour dedicated learning 
hard wired model reinforcement signal intended feedback signal learning module 
model described demonstrated possible evolve integrated successfully controls behaviour simulated khepera mini robot engaged learning task 
showed dynamic neural network shaped evolution integrate reactive learned behaviour single control system rely independent evolution separate controller modules arbitrarily partitioned researcher rely hard wired reinforcement signal 
evolved integrated control systems bene ts evolved reinforcement signals generate appropriated behavioural responses 
hope evolutionary approach undertaken model represent methodological tool test speci hypothesis selection pressures involved evolution speci learning skills possessed particular species possible solution engineering plastic control systems learning robots 
acknowledgments authors members centre computational neuroscience robotics www cogs sussex ac uk constructive discussion sussex high performance computing initiative www hpc sussex ac uk computing support 
likes elisa andrea vaccaro 
davey 

ecological learning theory 
routledge london england uk 


homeostatic adaptation inversion visual eld sensorimotor disruptions 
animals animats vi proceedings th conference simulation adaptive behavior 
eggenberger ishiguro kondo 

seamless transfer simulated real worlds neural network approach 
watt demiris eds advances robot learning th european workshop learning robots lausanne switzerland september proceedings volume lecture notes computer science 
springer 
floreano mondada 

evolution plastic situated agents 
maes mataric meyer pollack wilson eds animals animats iv proceedings th international conference simulation adaptive behavior 
ma mit press 
floreano 

evolutionary robots generation 
th international symposium evolutionary robotics er intelligent robots arti cial life 
floreano 

evolution plastic control networks 
autonomous robots 
press 
floreano 

neural morphogenesis synaptic plasticity evolution 
theory biosciences 
press 
garcia 

relation cue consequence avoidance learning 
science 
goldberg 

genetic algorithms search optimization machine learning 
addison wesley 
harvey husband thompson jakobi 

evolutionary robotics sussex approach 
robotics autonomous systems 
harvey husbands cli 

issues evolutionary robotics 
meyer roitblat wilson eds animals animats ii proceedings nd international conference simulation adaptive behavior pages cambridge ma 
mit press bradford books 
jakobi 

evolutionary robotics radical envelope noise hypothesis 
adaptive behavior 
kaelbling 

learning embedded systems 
mit press 
meyer husbands harvey 

evolutionary robotics survey applications problems 
husbands meyer eds evolutionary robotics proceedings st european workshop 
springer 
nol 

evolutionary robotics exploring full power self organization 
connection science 
nol floreano 

learning evolution 
robots 
nol floreano 

evolutionary robotics biology intelligence technology selforganizing machines 
ma mit press bradford books 
nol parisi 

learning adapt changing environments evolving neural networks 
adaptive behavior 
webb 

robotics er animal behaviour animal behaviour 
wilcoxon 

illness induced rat relative salience visual cues 
science 
yamauchi beer 

integrating reactive sequential learning behavior dynamical neural network 
cli husbands meyer wilson eds animals animats iii proceedings rd international conference simulation adaptive behavior 
