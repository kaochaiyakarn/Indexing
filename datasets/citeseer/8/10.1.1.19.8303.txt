predictive representations state michael littman richard sutton labs research florham park new jersey research att com satinder singh capital new york new york cs colorado edu show states dynamical system usefully represented multi step action conditional predictions observations 
state representations grounded data way may easier learn generalize better dependent accurate prior models example pomdp state representations 
building prior jaeger rivest schapire compare contrast linear specialization predictive approach state representations pomdps order markov models 
rst speci formulation predictive idea includes stochasticity actions controls 
show system linear predictive state representation number predictions greater number states minimal pomdp model 
predicting controlling sequence observations concepts state state estimation inevitably arise 
dominant approaches 
generative model approach typi ed research partially observable markov decision processes pomdps hypothesizes structure generating observations estimates state state dynamics 
history approach typi ed order markov methods uses simple functions past observations state immediate basis prediction control 
data ow approaches diagrammed 
generative model approach general 
model internal state gives temporally unlimited memory ability remember event happened arbitrarily long ago history approach remember far back history extends 
bane generative model approaches strongly dependent model system dynamics 
uses pomdps example assume perfect dynamics model attempt estimate state 
algorithms simultaneously estimating state dynamics chrisman analogous baum welch algorithm uncontrolled case baum ective tuning parameters approximately correct shatkay kaelbling :10.1.1.56.7115
state update observations actions state rep observations actions state rep step delays data ow pomdp recursive updating state representation history state representation 
practice history approaches ective 
state representation relatively simple record stream past actions observations 
record occurrence speci subsequence event occurred 
representations far closely linked data pomdp representations 
way saying pomdp learning algorithms encounter local minima saddle points states 
history systems immediately break symmetry direct learning procedure comparably simple 
mccallum shown number examples sophisticated history methods ective large problems practical pomdp methods small ones 
predictive state representation psr approach develop generative model approach updates state representation recursively directly computing data 
show enables attain generality compactness equal generative model approach 
psr approach history approach representations grounded data 
history representation looks past records happen psr looks represents happen 
particular psr vector predictions specially selected set action observation sequences called tests rivest schapire 
example consider test speci actions speci observations 
correct prediction test data stream time probability observations occurring order actions taken order fo 
test kind experiment performed tell system 
knew outcome possible tests know know system 
psr set tests sucient information determine prediction possible tests sucient statistic 
example points consider oat reset problem consisting linear string states distinguished reset state far right 
action oat causes system move uniformly random right left state bounded ends 
action reset causes jump reset state irrespective current state 
observation action taken system reset state case observation 
action correct prediction action correct prediction depends fs zero fs fs fs fs decreasing second asymptotically 
order markov method model system exactly limited float action reset action underlying dynamics oat reset problem oat action reset action 
numbers arcs indicate transition probabilities 
observation reset action rightmost state produces observation 
length history sucient statistic 
pomdp approach model exactly maintaining belief state representation states 
psr hand exactly model oat reset system just tests 
starting rightmost state correct predictions tests successive probabilities sequence sucient statistic predict pair sequence 
informational analysis indicates solution possible principle require nonlinear updating process psr 
restrict consideration linear special case psrs guarantee number tests needed exceed number states minimal pomdp representation ruled possibility considerably smaller 
greater ultimate interest prospects learning psrs update functions speculate time 
diculty learning pomdp structures prior models known 
extent diculty due indirect link pomdp states data predictive representations may able better 
jaeger introduced idea predictive representations alternative belief states hidden markov models provided learning procedure models 
build treating control case actions signi cantly analyze 
strongly uenced rivest schapire consider tests including actions treated deterministic case signi cantly di erent 
explored construction learning algorithms discovering system structure 
predictive state representations consider dynamical systems accept actions discrete set generate observations discrete set consider predicting system controlling designate explicit reward observation 
refer system environment 
term history denote test forming initial stream experience characterize environment probability distribution possible histories 

ja 
probability observations generated order actions taken order 
probability test conditional history de ned tjh ht 
set tests ft de ne prediction vector jh jh jh predictive state representation psr forms sucient statistic environment tjh test history projection function 

focus linear psrs projection functions linear exist projection vector test tjh histories denote ith component prediction vector psr 
updated recursively new action observation pair hao ot jha ao ao step speci linear psrs 
state main result theorem environment represented nite pomdp model exists linear psr number tests larger number states minimal pomdp model 
proof theorem constructing psr pomdp prove theorem showing pomdp model environment construct polynomial time linear psr pomdp lesser equal complexity produces probability distribution histories pomdp model 
proceed steps 
review pomdp models assign probabilities tests 
de ne algorithm takes state pomdp model produces set fewer tests length equal show set tests constitute psr pomdp projection vectors tests predictions produce probability distribution histories pomdp 
pomdp lovejoy kaelbling de ned hs oi 
set underlying hidden states discrete set actions discrete set observations 
vector initial state distribution 
set consists transition matrices action ij probability transition state action chosen 
set consists diagonal observation matrices pair observation action ii probability observation action selected state reached 
state representation pomdp belief state vector state occupation probabilities history computed recursively new action observation hao vector 
pomdp de nes probability distribution tests histories 
jha 

equivalent formulations conversion procedure described easily modi ed accommodate pomdp de nitions 
algorithm constructing psr pomdp 
uses function mapping tests vectors de ned recursively represents null test 
conceptually components probabilities test applied underlying state pomdp call outcome vector test say test linearly independent set tests outcome vector linearly independent set outcome vectors tests algorithm search de ned search fg search linearly independent search return algorithm maintains set tests searches new tests linearly independent 
form depth rst search 
algorithm halts checks step extensions tests nds linearly independent 
set tests returned search linearly independent outcome vectors cardinality bounded ensuring algorithm halts polynomial number iterations 
test formed step extension test test longer action observation pairs 
check linear independence performed ways including gaussian elimination implying search terminates polynomial time 
construction step extensions set tests returned search linearly dependent show true test 
lemma outcome vectors tests linearly combined produce outcome vector test 
proof matrix formed concatenating outcome vectors tests combinations columns linearly dependent columns write uw matrix weights test linearly dependent step extension linearly dependent write outcome vector uw weight vector outcome vector uw uw linearly dependent note step tests linearly dependent structure search algorithm 
previous paragraph inductive argument implies tests linearly dependent returning oat reset example pomdp search begins enumerating extensions null test 
linearly independent 
extensions linearly independent 
remaining tests added search 
extensions tests linearly independent tests procedure halts 
show set tests constitute psr pomdp constructing projection vectors tests predictions produce probability distribution histories pomdp 
combination de ne matrix ao vector ao matrix outcome vectors de ned previous section pseudoinverse ith row ao probability distribution histories implied projection vectors 
jha 


uu 
uu 
pomdp equation 
step uses fact uu linearly dependent columns holds construction previous section 
completes proof theorem 
completing oat reset example consider matrix process de ned section 
derives predictions test action quite simple tests similar new prediction exactly old prediction example 
non trivial test 
outcome computed jh jh jh 
example illustrates projection vectors need contain positive entries 
introduced predictive state representation dynamical systems grounded actions observations shown linear form general compact pomdps 
essence established psrs non inferior alternative pomdps suggested important advantages leaving demonstration advantages 
conclude summarizing potential advantages explored learnability 
order markov model similar psrs entirely actions observations 
models learned trivially data counting open question similar done psr 
jaeger showed learn model uncontrolled setting situation complex multiple action case outcomes conditioned behavior violating required independence assumptions 
compactness 
shown exist linear psrs complex minimal pomdp environment cases minimal linear psr smaller 
example pomdp extension factored mdps explored singh cohn cross products separate pomdps linear psrs increase linearly number size component pomdps minimal pomdp representation grow size singular value decomposition pseudoinverse 
pseudoinverse diagonal matrix replaces non zero element reciprocal 
state space exponential number component pomdps 
apparent advantage stems psr combinatorial factored structure 
vector state variables capable diverse values psr may inherently powerful distribution discrete states belief state pomdp 
seen general psrs compact pomdps capable eciently capturing environments diversity representation rivest schapire known provide extremely compact representation environments 
generalization 
reasons think state variables predictions may particularly useful learning predictions 
things predict ect set sequence learning problems due environment 
cases solutions earlier problems shown provide features generalize particularly subsequent problems baxter thrun pratt 
powerful extensible representations 
psrs predict tests generalized predict outcomes multi step options sutton 
case particularly constitute powerful language representing state complex environments 
acknowledgments peter dayan lawrence saul fernando pereira rob schapire helpful discussions related ideas 
baum petrie soules weiss 

maximization technique occurring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
baxter 

model inductive bias learning 
journal arti cial intelligence research 
chrisman 

reinforcement learning perceptual aliasing perceptual distinctions approach 
proceedings tenth national conference arti cial intelligence pp 

san jose california aaai press 
jaeger 

observable operator models discrete stochastic time series 
neural computation 
kaelbling littman cassandra 

planning acting partially observable stochastic domains 
arti cial intelligence 
lovejoy 

survey algorithmic methods partially observable markov decision processes 
annals operations research 
mccallum 

reinforcement learning selective perception hidden state 
doctoral dissertation department computer science university rochester 
rivest schapire 

diversity inference nite automata 
journal acm 
shatkay kaelbling 

learning topological maps weak local odometric information 
proceedings fifteenth international joint conference arti cial intelligence ijcai pp 

singh cohn 

dynamically merge markov decision processes 
advances neural information processing systems pp 

sutton precup singh 

mdps semi mdps framework temporal abstraction reinforcement learning 
arti cial intelligence 
thrun pratt 
eds 

learning learn 
kluwer academic publishers 
