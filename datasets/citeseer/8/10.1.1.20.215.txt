background foreground modeling nonparametric kernel density estimation visual surveillance ahmed elgammal member ieee david harwood larry davis fellow ieee invited automatic understanding events happening site ultimate goal visual surveillance systems 
higher level understanding events requires certain lower level computer vision tasks performed 
may include detection unusual motion tracking targets labeling body parts understanding interactions people 
achieve tasks necessary build representations appearance objects scene 
focuses issues related problem 
construct statistical representation scene background supports sensitive detection moving objects scene robust clutter arising natural scene variations 
second build statistical representations foreground regions moving objects support tracking support occlusion reasoning 
probability density functions pdfs associated background foreground vary image image general known parametric form 
accordingly utilize general nonparametric kernel density estimation techniques building statistical representations background foreground 
techniques estimate pdf directly data assumptions underlying distributions 
example results applications 
keywords background subtraction color modeling kernel density estimation occlusion modeling tracking visual surveillance 
manuscript received may revised february 
supported part arda video analysis content exploitation project contract mda part philips research 
elgammal computer vision laboratory university maryland institute advanced computer studies department computer science university maryland college park md usa mail elgammal cs umd edu 
harwood davis computer vision laboratory university maryland institute advanced computer studies university maryland college park md usa mail umiacs umd edu harwood umiacs umd edu lsd cs umd edu 
publisher item identifier 
ieee automated surveillance systems cameras sensors typically monitor activities site goal automatically understanding events happening site 
automatic event understanding enable functionalities detection suspicious activities site security 
current systems archive huge volumes video eventual line human inspection 
automatic detection events videos facilitate efficient archiving automatic annotation 
direct attention human operators potential problems 
automatic detection events dramatically reduce bandwidth required video transmission storage interesting pieces need transmitted stored 
higher level understanding events requires certain lower level computer vision tasks performed detection unusual motion tracking targets labeling body parts understanding interactions people 
tasks necessary build representations appearance objects scene 
example detection unusual motions achieved building representation scene background comparing new frames representation 
process called background subtraction 
building representations foreground objects targets essential tracking maintaining identities 
focuses issues construct statistical representation scene background supports sensitive detection moving objects scene build statistical representations foreground moving objects support tracking 
useful tool building representations statistical modeling process modeled random variable feature space associated probability density function pdf 
density function represented parametrically specified statistical distribution proceedings ieee vol 
july assumed approximate actual distribution associated parameters estimated training data 
alternatively nonparametric approaches 
estimate density function directly data assumptions underlying distribution 
avoids having choose model estimating distribution parameters 
particular nonparametric technique estimates underlying density avoids having store complete data quite general kernel density estimation technique 
technique underlying pdf estimated kernel function typically gaussian centered data points feature space weighting coefficients typically uniform weights 
kernel density estimators asymptotically converge density function 
property techniques quite general applicable vision problems underlying density known 
kernel density estimation techniques utilized building representations background foreground 
adaptive background modeling background subtraction technique able detect moving targets challenging outdoor environments moving trees changing illumination 
technique modeling foreground regions show segmenting major body parts person segmenting groups people 
ii 
kernel density estimation techniques sample distribution density function estimate density calculated kernel function called window function bandwidth scale kernel function satisfy think estimating pdf averaging effect set kernel functions centered data point 
alternatively kernel function symmetric regard computation averaging effect kernel function centered estimation point evaluated data point 
kernel density estimators asymptotically converge density function sufficient samples 
property technique quite general estimating density distribution 
fact nonparametric density estimation methods histograms shown asymptotically kernel methods 
higher dimensions products dimensional kernels kernel function dimension suitable bandwidth dimension 
avoid having store complete data set weighting samples weighting coefficients sum 
variety kernel functions different properties literature 
typically gaussian kernel continuity differentiability locality properties 
note choosing gaussian kernel function different fitting distribution gaussian model normal distribution 
gaussian function weight data points 
parametric fitting mixture gaussians kernel density estimation general approach assume specific shape density function 
discussion kernel estimation techniques 
major drawback nonparametric kernel density estimator computational cost 
problem available computational power increases efficient computational methods available 
iii 
modeling background background subtraction review concept video surveillance systems stationary cameras typically monitor activities outdoor indoor sites 
cameras stationary detection moving objects achieved comparing new frame representation scene background 
process called background subtraction scene representation called background model 
typically background subtraction forms stage automated visual surveillance system 
results background subtraction processing tracking targets understanding events 
central issue building representation scene background features representation words model background 
literature variety features background modeling including pixel features pixel intensity edges disparity region features block correlation 
choice features affects background model tolerates changes scene granularity detected foreground objects 
indoor outdoor scene changes occur time may classified changes scene background 
important background model tolerates kind changes invariant adapting 
changes local affecting part background global affecting entire background 
study changes essential understand motivations different background subtraction techniques 
classify changes source 
illumination changes gradual change illumination occur outdoor scenes due change location sun proceedings ieee vol 
july sudden change illumination occur indoor environment switching lights outdoor environment change cloudy sunny conditions shadows cast background objects background buildings trees moving foreground objects 
motion changes image changes due small camera displacements common outdoor situations due wind load sources motion causes global motion images motion parts background example tree branches moving wind rippling water 
changes introduced background include change geometry appearance background scene introduced targets 
changes typically occur relatively permanent introduced scene background example somebody moves introduces background car parked scene moves scene person stays stationary scene extended period 
practice researchers proposed methods address issues regarding background modeling provide brief review relevant 
pixel intensity commonly feature background modeling 
monitor intensity value pixel time completely static scene pixel intensity reasonably modeled gaussian distribution image noise time modeled zero mean gaussian distribution gaussian distribution model intensity value pixel underlying model background subtraction techniques 
example simplest background subtraction techniques calculate average image scene subtract new frame image threshold result 
basic gaussian model adapt slow changes scene example gradual illumination changes recursively updating model simple adaptive filter 
basic adaptive model kalman filtering adaptation :10.1.1.47.9503
typically outdoor environments moving trees bushes scene background completely static 
example pixel image sky frame tree leaf frame tree branch third frame mixture subsequently 
situation pixel different intensity color single gaussian assumption pdf pixel intensity hold 
generalization mixture gaussians model variations 
pixel intensity modeled mixture gaussian distributions small number 
mixture weighted frequency gaussians explains background 
mixture gaussian distributions model pixel value traffic surveillance applications 
pixel intensity modeled weighted mixture gaussian distributions corresponding road shadow vehicle distribution 
adaptation gaussian mixture models achieved incremental version em algorithm 
linear prediction wiener filter predict pixel intensity history values 
prediction coefficients recomputed frame sample covariance achieve adaptivity 
linear prediction kalman filter 
previously mentioned models statistical modeling pixel intensity ability adapt model 
pixel intensity invariant illumination changes model adaptation possible techniques adapt gradual changes illumination 
hand sudden change illumination presents challenge models 
approach model wide range variations pixel intensity represent variations discrete states corresponding modes environment lights cloudy sunny skies 
hidden markov models hmms purpose 
state hmm model intensity pixel traffic monitoring application states correspond background shadow foreground 
hmms imposes temporal continuity constraint pixel intensity pixel detected part foreground expected remain part foreground period time switching back part background 
topology hmm representing global image intensity learned learning background 
global intensity state pixel intensity modeled single gaussian 
shown model able learn simple scenarios switching lights 
alternatively edge features model background 
edge features model background motivated desire representation scene background invariant illumination changes 
foreground edges detected comparing edges new frame edge map background called background primal sketch major drawback edge features model background possible detect edges foreground objects dense connected regions result pixel intensity approaches 
fusion intensity edge information 
block approaches modeling background 
block matching extensively change detection consecutive frames 
image block fit second order bivariate polynomial remaining variations assumed noise 
statistical likelihood test detect blocks significant change 
block represented median template background learning period block standard deviation 
subsequently new frame block correlated corresponding template blocks deviation relative measured standard deviation considered foreground 
major drawback block approaches detection unit image block suitable coarse detection 
elgammal modeling nonparametric kernel density estimation visual surveillance order monitor wide areas sufficient resolution cameras zoom lenses mounted pan tilt platforms 
enables high resolution imagery obtained arbitrary viewing angle location camera mounted 
background subtraction situations requires representation scene background arbitrary pan tilt zoom combination extension original background subtraction concept stationary camera 
image mosaicing techniques build panoramic representations scene background 
alternatively representation scene background finite set images virtual polyhedron construct images scene background arbitrary pan tilt zoom setting 
techniques assume camera rotation optical axis significant motion parallax 
nonparametric background modeling section describe background model background subtraction process developed nonparametric kernel density estimation 
model uses pixel intensity color basic feature modeling background 
model keeps sample intensity values pixel image uses sample estimate density function pixel intensity distribution 
model able estimate probability newly observed intensity value 
model handle situations background scene cluttered completely static contains small motions due moving tree branches bushes 
model updated continuously adapts changes scene background 
background subtraction sample intensity values pixel 
sample obtain estimate pixel intensity pdf intensity value kernel density estimation 
observed intensity time estimate probability observation kernel function bandwidth estimate generalized color features kernel products dimensional color feature kernel function bandwidth th color space dimension 
choose kernel function gaussian density estimated fig 

background subtraction 
original image 
estimated probability image 
probability estimate pixel considered foreground pixel threshold global threshold images adjusted achieve desired percentage false positives 
practically probability estimation calculated fast way precalculated lookup tables kernel function values intensity value difference kernel function bandwidth 
partial evaluation sum usually sufficient surpass threshold image pixels image typically background 
allows construct fast implementation 
kernel density estimation general approach estimate converge pixel intensity density function 
estimate samples computation 
adaptation model achieved simply adding new samples ignoring older samples 
fig 
shows estimated background probability brighter pixels represent lower background probability pixels 
major issue needs addressed kernel density estimation technique choice suitable kernel bandwidth scale 
theoretically number samples reaches infinity choice bandwidth insignificant estimate approach actual density 
practically finite number samples computation performed real time choice suitable bandwidth essential 
small bandwidth lead density estimate proceedings ieee vol 
july wide bandwidth lead smoothed density estimate 
expected variations pixel intensity time different location image different kernel bandwidth pixel 
different kernel bandwidth color channel 
estimate kernel bandwidth th color channel pixel compute median absolute deviation sample consecutive intensity values pixel 
median consecutive pair sample calculated independently color channel 
motivation median absolute deviation pixel intensities time expected jumps different objects sky branch leaf mixtures edge passes pixel projected pixel different times 
measuring deviations consecutive intensity values pair usually comes local time distribution pairs expected come cross distributions intensity jumps 
median robust estimate affected jumps 
assume local time distribution gaussian distribution deviation gaussian distribution symmetric median absolute deviations equivalent quarter percentile deviation distribution 
standard deviation distribution estimated deviations integer gray scale color values linear interpolation obtain accurate median values 
probabilistic suppression false detection outdoor environments fluctuating backgrounds sources false detections 
false detections due random noise expected homogeneous entire image 
second false detections due small movements scene background represented background model 
occur locally example tree branch moves model generation 
occur globally image result small camera displacements caused wind load common outdoor surveillance causes false detections 
kinds false detections usually spatially clustered image easy eliminate morphological techniques noise filtering operations affect detection small occluded targets 
part background tree branch example moves occupy new pixel part model pixel detected foreground object 
object high probability part background distribution corresponding original pixel 
assuming small displacement occur consecutive frames decide detected pixel caused background object moved considering background distributions small neighborhood detection location 
observed value pixel detected foreground pixel time define pixel displacement probability maximum probability observed value belongs background distribution point neighborhood background sample pixel probability estimation calculated kernel function estimation 
thresholding detected pixels eliminate false detections due small motions background scene 
avoid losing true detections accidentally similar background nearby pixel targets constraint added detected foreground object moved nearby location pixels 
component displacement probability defined probability detected connected component displaced nearby location 
probability estimated connected component corresponding real target probability component displaced background small 
detected pixel considered part background fig 
illustrates effect second stage detection 
result stage shown fig 

example background updated seconds camera slightly displaced time interval see false detections high contrast edges 
fig 
shows result suppressing detected pixels high displacement probability 
false detections due displacement eliminated random noise uncorrelated scene remains false detections 
true detected pixels lost 
final result second stage detection shown fig 
component displacement probability constraint added 
fig 
shows results case result wind load camera shaking slightly resulting lot clustered false detections especially edges 
probabilistic suppression false detection fig 
clustered false detection suppressed small target left side image remains 
elgammal modeling nonparametric kernel density estimation visual surveillance fig 

effect second stage detection suppressing false detections 
original image 
stage detection result 
suppressing pixels high displacement probabilities 
result component displacement probability constraint 
fig 

original image 
result stage detection 
result second stage 
fig 

original image 
detection qy fa color space 
detection chromaticity coordinates working color detection shadows part foreground regions source confusion subsequent phases analysis 
desirable discriminate targets shadows 
color information useful suppressing shadows detection separating color information lightness information 
color variables chromaticity coordinates 
chromaticity coordinates detection advantage insensitive small changes illumination arise due shadows 
fig 
shows results detection space space 
shows chromaticity coordinates allows detection target detecting shadow 
noticed background subtraction technique describe section iii color space hsv yuv 
fig 

original image 
detection qy fa color space 
detection chromaticity coordinates lightness variable 
chromaticity coordinates helps suppression shadows disadvantage losing lightness information 
lightness related differences whiteness different objects 
example consider case target wears white shirt walks gray background 
case color information 
white gray chromaticity coordinates target may detected 
address problem need measure lightness pixel 
lightness measure 
consider case background completely static expected value pixel assume pixel covered shadow frame observed value pixel frame 
expected expected observed value darker normal value certain limit corresponds intuition fraction light coming pixel reduced target shadow 
similar effect expected highlighted background observed value brighter expected value certain limit 
similar reasoning 
case background static single expected value pixel 
sample values representing background certain pixel represented observed value frame select subset sample values relevant observed lightness relevant mean values sample affected shadows produce observed lightness pixel 
relevant sample subset carry kernel calculation described section iii twodimensional color space 
parameters fixed image 
fig 
shows detection results indoor scene color space color space lightness variable proceedings ieee vol 
july fig 

example detection results 
fig 

top detection result omnidirectional camera 
bottom detection result rainy day 
restrict sample set relevant values 
illustrate algorithm indoor sequence effect shadows severe outdoor environments 
target wears black pants background gray color information 
detect target suppress shadows seen rightmost parts 
example detection results technique tested wide variety challenging background subtraction problems variety setups robust adaptive 
section show example results 
fig 
shows detection results targets area tree branches move heavily target highly occluded 
technique pixel directly raw images provided cameras 
fig 
top shows detection results omnidirectional camera 
targets walking woods 
fig 
bottom shows detection result rainy day background model adapts account different rain lighting conditions 
video clips showing results downloaded ftp www umiacs umd edu pub elgammal video index htm iv 
modeling foreground modeling color blobs modeling color distribution homogeneous region variety applications object tracking recognition 
color distribution object represents feature robust partial occlusion scaling object deformation 
relatively stable rotation depth certain applications 
color distributions successfully track nonrigid bodies tracking heads hands body parts cluttered backgrounds stationary moving platforms 
color distributions object recognition 
variety parametric nonparametric statistical techniques model color distribution homogeneous colored regions 
color distribution region blob modeled single gaussian dimensional yuv space 
single gaussian model color blob restricts single color sufficiently general assumption model regions mixtures colors 
example people clothing surfaces texture usually contain patterns mixtures colors 
fitting mixture gaussians em algorithm provides way model color blobs mixture colors 
technique color tracking single blob applied tracking faces 
mixture gaussian techniques faces problem choosing right number gaussians assumed model model selection 
nonparametric techniques histograms widely modeling color objects different applications overcome previously mentioned problems parametric models 
color histograms people tracking 
color histograms tracking hands color region tracking skin detection 
major drawback color histograms lack convergence right density function data set small 
major drawback histograms general suitable higher dimensional features 
sample taken image region dimensional vector representing color estimate density function point color space directly product dimensional kernels kernel function dimension different bandwidth dimension color space 
usually color modeling color spaces 
dimensional chromaticity spaces lab color space desired model invariant illumination geometry reasons discussed section iii 
dimensional color spaces widely elgammal modeling nonparametric kernel density estimation visual surveillance better discrimination brightness information preserved 
different bandwidths kernels different color dimensions desirable variances color dimension different 
example luminance variable usually variance chromaticity variables wider kernels dimension 
kernel density estimation color modeling motivations 
histograms small number samples kernel density estimation leads smooth continuous differentiable density estimate 
kernel density estimation assume specific underlying distribution estimate converge density shape samples approach suitable model color distribution regions patterns mixture colors 
underlying distribution mixture gaussians kernel density estimation converges right density small number samples 
parametric fitting mixture gaussians kernel density estimation general approach require selection number gaussians fitted 
important advantage kernel density estimation adaptation model trivial achieved adding new samples 
color spaces low dimensionality efficient computation kernel density estimation color pdfs achieved fast gauss transform algorithm 
color body part segmentation section color modeling approach described section iv segment foreground regions corresponding tracked people upright poses major body parts 
foreground regions detected background subtraction technique described earlier 
people dressed different ways generally dressed way leads set major color regions aligned vertically people upright poses shirt shirt jacket top pants shorts bottom 
consider case people dressed top bottom manner yields segmentation person head torso bottom 
generally person upright pose modeled set vertically aligned blobs blob models major color region vertical axis person representing major part body torso bottom head 
blob represented color distribution spatial location respect body 
blob color distribution inside blob vertical location blob independent horizontal axis joint distribution pixel probability observing color location blob multiplication independent density functions color density blob densities represent vertical horizontal location blob respectively 
fig 

blob separator histogram training data 
confidence bands 
blob segmentation 
detected blob separators 
estimates color density calculated kernel density estimation 
represent color pixel vector chromaticity variables lightness variable 
variables scaled range 
sample pixels blob estimate color density calculated set samples corresponding blob initial estimates position blob pixel classified blobs maximum likelihood classification assuming blobs prior probabilities vertical density assumed gaussian distribution blobs assumed vertically horizontal density irrelevant classification 
horizontal blob separator detected consecutive blobs finding horizontal line minimizes classification error 
detected blob separators color model sampling pixels blob 
blob segmentation performed blob separators detected new frame long target isolated tracked 
adaptation color model achieved updating sample adding new samples ignoring old samples blob model 
model initialization done automatically samples pixels confidence bands corresponding head torso bottom 
locations confidence bands learned offline follows 
set training data different people upright pose genders different orientations learn location blob separators head torso respect body separators manually marked 
fig 
shows histogram locations head torso left peak torso bottom right peak training data 
separator location estimates determine confidence bands proportional height confident belong proceedings ieee vol 
july fig 

example results blob segmentation 
head torso bottom capture initial samples fig 
shows initial bands initialization segmentation result shown detected separators shown 
fig 
illustrates blob segmentation examples various people 
segmentation separator detection robust partial occlusion target rightmost result 
examples clothes uniform color 
segmentation multiple people visual surveillance systems required keep track targets move scene occluded interacting people scene 
highly undesirable lose track targets group 
important track targets interacting isolated 
problem important visual surveillance video analysis applications video indexing video archival retrieval 
section show segment foreground regions corresponding group people individuals representation isolated people section iv 
drawback representation inability model highly articulated parts hands 
main objective segment people occlusion principally concerned mass body 
correctly locating major blobs body provide constraints location hands locate segment 
assumption scenario targets visually isolated occlusion initialize models 
foreground region corresponding group people search arrangement maximizes likelihood appearance region models built individuals 
result obtain segmentation region 
segmentation result determine relative depth individual evaluating different hypothesis arrangement people 
allows construct model occlusion 
problem tracking groups people addressed literature 
hydra system tracks people groups tracking heads silhouette foreground regions corresponding group 
able count number people groups long heads appear part outer silhouette group fails 
hydra system intended accurately segment group individuals recover depth information 
groups people segmented individuals color distribution color distribution person represented histogram 
color features represented globally spatially localized approach loses spatial information color distributions essential discriminant 
segmentation likelihood maximization simplicity loss generality focus person case 
person model probability observing color location blob blobs aligned vertically assume blobs share horizontal density function person model probability normalization factor location spatial densities defined relative origin origin moves shift previous probability defines conditional density function model origin parameter density degree freedom allowed 
people occluding models dimensional hypothesis origins 
call arrangement hypothesis 
foreground region representing people foreground pixel classified classes maximum likelihood classification assuming prior probability person 
defines segmentation minimizes bayes error notice segmentation function origin hypothesis models choice targets origins defines different segmentation foreground region 
best choice targets origins maximizes likelihood data elgammal modeling nonparametric kernel density estimation visual surveillance entire foreground region 
optimal choice defined terms log likelihood function new frame time searching optimal solves foreground segmentation person tracking problems simultaneously 
formalization extends straightforward way case people group 
case classes arrangement hypothesis dimensional vector finding optimal hypothesis people search problem dimension space exhaustive search solution require tests window parameter diameter search region pixels 
finding optimal solution way exponential number people group impractical 
tracking targets targets expected move consecutive frames develop practical solution direct detection approximate solution frame solution frame choose model origin expected visible occlusion detected robust way 
example assume tops heads visible occlusion origins spatial densities 
top head shape feature detected robustly segmentation 
model origin location frame origin classify foreground pixel frame maximum likelihood targets expected significant translations frames expect segmentation frame possibly boundaries 
segmentation detect new origin locations top head summarize steps 
segmentation classify foreground pixel detection detect new origins top heads modeling occlusion occlusion modeling mean assigning relative depth person group segmentation result 
approaches suggested literature solve problem 
ground plane constraint reason occlusion cars 
assumption object motion constrained ground plane valid people cars fail contact point ground plane visible partial occlusion objects contact points field view example see fig 

visibility index defined ratio number pixels visible person occlusion expected number pixels person isolated 
visibility index fig 

original image 
foreground region 
segmentation result 
occlusion model hypotheses 
measure depth higher visibility index indicates person front 
identify person front approach generalize people 
solution ground plane constraint generalizes case people group 
hypothesis arrangement people projected locations image plane model shape construct occlusion model maps pixel tracked targets scene background 
consider case targets shown fig 

foreground region segmented section iv yields labeling pixel fig 
probable location model origins 
possible hypotheses depth arrangement people corresponding occlusion models shown fig 
assuming ellipse shape model targets 
evaluate hypotheses generally hypotheses minimizing error labeling foreground pixels error foreground pixels 
ellipse major minor axes set expected height width person estimated occlusion 
figs 
show examples constructed occlusion model occlusion situations 
fig 
shows results segmenting people different occlusion situations 
foreground segmentation people shown part segmentation 
pixels low likelihood probabilities labeled 
cases hands feet labeled misclassified modeled part representation 
constructed occlusion model case shown 
notice third fourth examples people dressed similarly colored pants 
torso blobs discriminating color 
sufficient locate person spatial model parameters similarly colored blobs head bottom segmented correctly mainly spatial densities 
misclassification noticed boundaries pants hard human segment accurately 
fig 
illustrates frames person case efficient implementation error formula achieved considering intersection region finding target appears region front 
proceedings ieee vol 
july fig 

example results 
top left original image 
top right people segmentation 
bottom left blob segmentation 
bottom right constructed occlusion model 
sequence targets tracked occlusion 
part segmentation results shown constructed occlusion model 
details experimental results 
nonparametric kernel density estimation techniques tool constructing statistical representations scene background foreground regions video surveillance 
pdf associated fig 

example results 
top original image 
middle blob segmentation 
bottom occlusion model 
background foreground necessarily follow known parametric form kernel estimation methods suitable approach applications 
background model background subtraction technique introduced 
model estimating pdf pixel intensity directly set intensity values 
model achieves sensitive detection moving targets cluttered backgrounds 
model handle situations scene background completely static contains small motions moving tree branches bushes 
model adaptive changes scene illumination 
model able suppress false detections arise due small camera displacements 
showed model color information suppress detection shadows targets 
kernel estimation techniques modeling appearance foreground regions 
showed technique general approach modeling homogeneous color regions 
introduced representation people spatially localizes color properties way corresponds clothing 
representation general probabilistic framework uses maximum likelihood estimation estimate best arrangement people group order segment foreground regions corresponding group 
method reason occlusion 
method constructs maintains model occlusion utilized segmentation framework 
scott density estimation 
new york wiley interscience 
duda stork hart pattern classification 
new york wiley 
lambert harrington harvey efficient line nonparametric kernel density estimation algorithmica pp 

elgammal modeling nonparametric kernel density estimation visual surveillance elgammal davis efficient computation kernel density estimation fast gauss transform applications segmentation tracking proc 
ieee nd int 
workshop statistical computational theories vision july 
wren azarbayejani darrell pentland pfinder real time tracking human body ieee trans 
pattern anal 
machine intell vol 
pp 
july 

von brandt moving object recognition adaptive background memory time varying image processing moving object recognition 
amsterdam netherlands elsevier 

brandt moving object segmentation images signal processing theories application 
amsterdam netherlands elsevier 
koller weber huang malik rao russell robust automatic traffic scene real time proc 
int 
conf 
pattern recognition pp 

grimson stauffer romano adaptive tracking classify monitor activities site ieee conf 
computer vision pattern recognition pp 

grimson stauffer adaptive background mixture models real time tracking proc 
ieee conf 
computer vision pattern recognition vol 
pp 

friedman russell image segmentation video sequences probabilistic approach th conf 
uncertainty artificial intelligence providence ri 
toyama krumm brumitt meyers wallflower principles practice background maintenance proc 
ieee int 
conf 
computer vision vol 
pp 

kato blake probabilistic background model tracking proc 
th eur 
conf 
computer vision vol 
pp 

ramesh paragios coetzee topology free hidden markov models application background modeling proc 
ieee int 
conf 
computer vision pp 


yang levine background primal sketch approach tracking moving objects machine vision vol 
pp 

jabri wechsler rosenfeld detection location people video images adaptive fusion color edge information int 
conf 
pattern recognition barcelona spain 
hsu nagel rekers new likelihood test methods change detection image sequences comput 
vision image process vol 
pp 

matsuyama ohya habe background subtraction nonstationary scenes proc 
th asian conf 
computer vision pp 

huttenlocher scene modeling wide area surveillance image synthesis ieee conf 
computer vision pattern recognition vol 
pp 

wada matsuyama appearance sphere background model pan tilt zoom camera th int 
conf 
pattern recognition vienna austria 
elgammal harwood davis nonparametric background model background subtraction proc 
th eur 
conf 
computer vision vol 
pp 

levine vision man machine 
new york mcgraw hill 
hall computer image processing recognition 
new york academic 

harwood davis statistical approach real time robust background subtraction shadow detection ieee frame rate applications workshop kerkyra greece 
nayar omnidirectional video camera proc 
darpa image understanding workshop pp 

comaniciu ramesh meer real time tracking nonrigid objects mean shift proc 
ieee conf 
computer vision pattern recognition vol 
june pp 

raja mckenna gong tracking color objects adaptive mixture models image vision comput pp 

terzopoulos color tracking heads objects video frame rates proc 
ieee conf 
computer vision pattern recognition vol 
pp 
june 
birchfield elliptical head tracking intensity gradients color histograms proc 
ieee conf 
computer vision pattern recognition vol 
pp 
june 
raja mckenna gong color model selection adaptation dynamic scenes proc 
th eur 
conf 
computer vision pp 

martin crowley active hand tracking proc 
rd ieee int 
conf 
automatic face gesture recognition pp 

mckenna jabri rosenfeld tracking groups people comput 
vision image understanding pp 

jones rehg statistical color models application skin detection proc 
ieee conf 
computer vision pattern recognition vol 
pp 

greengard strain fast gauss transform siam sci 
comput vol 
pp 

elgammal davis efficient nonparametric adaptive color modeling fast gauss transform proc 
ieee conf 
computer vision pattern recognition vol 
pp 
dec 
haritaoglu harwood davis hydra multiple people detection tracking silhouettes proc 
ieee int 
workshop visual surveillance pp 

koller weber malik robust multiple car tracking occlusion reasoning proc 
eur 
conf 
computer vision vol 
pp 

elgammal davis probabilistic framework segmenting people occlusion proc 
ieee th int 
conf 
computer vision vol 
pp 

ahmed elgammal received sc 
degree sc 
degree computer science automatic control university alexandria alexandria egypt respectively sc 
ph degrees computer science university maryland college park respectively 
assistant research faculty member computer vision laboratory university maryland institute advanced computer studies 
research interest includes computer vision graphics multimedia computing 
member ieee born madras india 
received tech 
degree indian institute technology bombay ph degree johns hopkins university laurel park 
research scientist institute advanced computer studies university maryland college park 
helped establish perceptual interfaces reality laboratory institute multidisciplinary research perceptual interfaces virtual reality 
broad research interests areas virtual reality computer vision scientific computing modeling human audition computational acoustics applied mathematics fluid dynamics 
proceedings ieee vol 
july david harwood graduate university texas austin massachusetts institute technology cambridge 
member university maryland institute advanced computer studies college park 
author numerous publications computer image analysis 
focused real time video analysis surveillance 
larry davis fellow ieee received degree university hamilton ny ph degrees computer science university maryland college park respectively 
assistant professor department computer science university texas austin 
returned university maryland associate professor 
director university maryland institute advanced computer studies 
currently professor institute computer science department chair computer science department 
known research computer vision high performance computing 
published papers journals supervised ph students 
associate editor international journal computer vision area editor computer models image processor image understanding 
dr davis served program general chair field major conferences workshops including fifth international conference computer vision field leading international conference 
elgammal modeling nonparametric kernel density estimation visual surveillance 
