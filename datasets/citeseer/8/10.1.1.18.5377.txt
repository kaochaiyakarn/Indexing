credit card fraud detection bayesian neural networks sam maes karl bernard manderick vrije universiteit brussel department computer science computational modeling lab como pleinlaan brussel belgium bernard arti ac discusses automated credit card fraud detection means machine learning 
era credit card fraud detection great importance nancial institutions 
apply machine learning techniques suited reasoning uncertainty arti cial neural networks bayesian belief networks problem show signi cant results real world nancial data 
directions indicated improve techniques results 
marking example society years proliferation credit card 
evolution bring forth problem credit card fraud sophisticated methods steal considerable amounts money 
discusses problem identifying detecting fraudulent behavior credit card transaction system 
reasoning uncertainty key element arti cial intelligence general machine learning particular 
formalisms developed support kind reasoning probabilistic reasoning fuzzy logic focus machine learning techniques credit card detections problem arti cial neural networks anns bayesian belief networks bbns 
central idea provide computational learner set training data consisting feature values extracted data series nancial transactions inherent system want fraud detection 
process learning program supposed able correctly classify transaction seen fraudulent fraudulent features transaction 
structure follows rst introduce reader domain credit card fraud detection 
sections brie explain machine learning techniques respectively ann bbn 
discuss experiments conducted techniques followed possible directions research 
credit card fraud detection section discuss credit card fraud speci problems arise 
focus credit card fraud properties apply real world problems cellular phone fraud calling card fraud computer network intrusion 
credit card fraud advent credit cards increasing functionality people personal comfort attracted malicious characters interested handsome rewards earned 
credit cards nice target fraud short time lot money earned risks 
crime discovered weeks date 
successful credit card fraud techniques copying credit card way getting hold secret pin code user needed 
vendors charging money agreed customer aware 
banks lose money due credit card fraud card holders partially possibly entirely pay loss higher interest rates higher membership fees reduced bene ts 
banks card holders interest reduce illegitimate credit cards reason nancial institutions started fraud detection 
fraud detection set credit card transactions process identifying transactions fraudulent classifying transactions classes class genuine class fraudulent transactions 
problems credit card fraud detection biggest problems associated fraud detection lack literature providing experimental results real world data academic researchers perform experiments 
fraud detection associated sensitive nancial data kept con reasons customer privacy 
enumerate properties fraud detection system order perform results 
system able handle skewed distributions small percentage credit card transactions fraudulent 
solve problem training sets divided pieces distribution skewed chan 
ability handle noise 
simply presence errors data instance incorrect dates 
noise actual data limits accuracy generalization achieved matter extensive training set way deal problem cleaning data 
overlapping data problem eld 
transactions may resemble fraudulent transactions legitimate 
opposite happens fraudulent transaction appears normal 
systems able adapt new kinds fraud 
successful fraud techniques decrease eciency due fact known 
fraud tries nd new ways doing job 
need metrics evaluate classi er system 
example accuracy suited evaluation skewed distribution high accuracy fraudulent transactions misclassi ed 
systems take account cost fraudulent behavior detected cost associated stopping 
example pro stopping fraudulent transaction euros 
means decision layer top fraud detection system 
decision layer decides action take fraudulent behavior detected fraud detection system account factors amount transaction quality customer doing transaction 
arti cial neural networks de nition neural networks exist ways di erent forms 
type neural network discuss feed forward multi layer perceptron 
feed forward multi layer perceptron consists di erent layers perceptrons interconnected set weighted connections 
distinguish types layers input layer receives input input stream database device 
hidden layer hidden outside world receives input input layer hidden layer 
output layer connects network outside world provides nal output network 
feed forward multi layer perceptron cycles full connectivity perceptrons consecutive layers 
signals propagated directions function signals propagated forwards input layer hidden layer output layer error signals propagated backwards output layer hidden layer input layer 
learning type learning discuss commonly called supervised learning error correction learning 
algorithm called backpropagation error signals short backprop 
iteration algorithm consists passes 
forward pass perceptron calculates weighted linear combination inputs applies result summing junction activation function 
result activation function provides perceptron output value 

backward pass output layer network calculate error respect desired output value certain pattern 
error propagated backwards network enforcing correction weights connections network 
technique observation perceptrons network shared responsibility error calculated output layer 
details concerning backprop issues concerning learning feed forward multi layer perceptron refer mae 
bayesian networks de nition bayesian network directed acyclic graph consists set random variables 
variable nite set mutually exclusive states 
set directed links arrows connects pairs nodes 
intuitive meaning arrow node node direct uence bayesian network represents dependence variables gives compact speci cation joint probability distribution 
fact bbn factorization joint probability 
node network conditional probability table cpt quanti es ect parent nodes 
iteration algorithm network certain pattern taken training set 
features pattern di erent perceptrons input layer network 
parents node nodes arrows pointing 
orphan nodes reduces prior probabilities 
learning section deals problem constructing network automatically direct empirical observations 
bayesian belief networks basic scheme knowledge representation learning task separates additional subtasks 
identifying topology network speci cally missing links directionality arrows 

learning numerical parameters prior conditional probabilities network topology 
second task trivial data concentrate learning topology network 
approaches dependency analysis chen global optimization 
opted stage boy instance 
global optimization problem nding best possible con guration large space possible con gurations 
formally instance global optimization consists state space objective function obj quality state nal solution transforming state real number 
goal global optimization nd state minimizes obj obj obj space small state evaluated obtaining exact solution trivial special knowledge problem structure exploited 
stage algorithm aims exploit observation performance local search algorithm depends state search starts 
express follows value function expected best obj value seen trajectory starts state follows local search method 
intuitively evaluates promise starting state 
seek approximate function approximation model linear regression multilayer perceptrons states encoded real valued feature vectors 
input features may encode relevant properties state including original objective function obj 
denote mapping states features approximation 
training data supervised learning may readily obtained running di erent starting points 
algorithm behaves markov chain intermediate states simulated trajectory may considered alternate starting points search training data 
insight enables get hundreds pieces training data trajectory sampled 
learned evaluation function evaluates promising starting point local search algorithm 
nd best starting point optimize simply applying stochastic hill climbing obj evaluation function 
summarize stage repeatedly alternates di erent stages local search running original local search method obj running hill climbing nd promising new starting state 
stage viewed smart multi restart approach local search 
operation stage schematically depicted 
run optimize obj optimize produces new training data retrain fitter produces new starting state stage alternates optimizing obj hill climbing optimize stage applied bayesian networks part apply stage approach previous subsection problem bayesian network structure learning 
need objective function obj return value quanti es quality bayesian network 
minimum description length mdl metric lam trades maximizing accuracy minimizing model complexity 
consider network nodes 
objective function decomposes sum nodes network obj 
complexity fitness term computes mutual information score node summing possible joint assignments variable parents log 
refers number records database match speci ed variable assignment 
complexity term simply counts number parameters required store conditional probability table node complexity arity par arity arity node bayesian network de ned number states variable associated node adopt 
constant set log number records database 
including complexity term objective function introduces occam razor natural way complexity term positive values want minimize objective function tendency simple structures 
local search method stochastic hill climbing 
directed cyclic graphs allowed bayesian networks ensure graphs visited acyclic 
done maintaining permutation nodes links graph directed nodes lower index nodes higher index 
local search begins graph identity permutation move operators probability choose random nodes network add link occam razor applies simplest structures evaluated rst followed complex structures 
link isn delete link 
probability swap permutation ordering random nodes network 
may cause multiple graph edges reversed don point nodes lower index higher index permutation 
learning stage extra features features mean standard deviation nodes features mean standard deviation complexity nodes features mean standard deviation number parents node feature number orphan nodes nodes don parents tter train method function approximation linear quadratic regression 
feedforward multi layer perceptron implementation 
experiments methodology subsection methodology describe experiment results 
data real world data provided serge international epi 
data consists set features contain useful information transaction label features specifying 
unfortunately specify agreement epi forbids 
introduce measure performance independent learning problem stake gives clear idea quality result 
purpose introduce receiver operating curve roc see 
training network ann bbn applied set features seen 
course say classi cation transactions set example transactions correctly classi ed genuine 
better percent total transactions classi ed correctly genuine 
especially interested knowing fraudulent transactions classi ed correctly fraudulent time genuine transactions classi ed incorrectly fraudulent 
rst called true positive rate false positive rate 
roc combine information graph 
plot false positives axis true positives axis 
doing get concave shaped graph contains data point graph information axis read percentage transactions classi ed incorrectly fraudulent axis read percentage transactions classi ed correctly fraudulent steeper increase respect axis values axis remain small better learned better predictions 
line dividing rst quadrant called bisection corresponds model done learning 
fraud detection arti cial neural networks wrongly assumed neural networks fast easy reliable technique obtain results di erent areas 
practice great diculty applying neural networks resides choice set pre processing operations trade di erent parameters chosen 
rst experiment shows importance pre processing 
gure see roc curves best result graph obtained performing correlation analysis features original data set 
resulted observation feature strongly correlated features 
removal feature clearly improves results 
clarity point results roc curves 
dark roc best result pre processing normalization desired values set away experiments training set train network test set calculate average mean square error perceptrons output layer validation set produce roc curves 
real desired values correlation analysis resulting removal feature percent true positives percent false positives 

light roc pre processing normalization desired values set away real desired values percent true positives percent false positives 
second experiment shows uence parameter tuning process learning 
decreasing learning rate certain intervals learning process improve speed ef ciency process 
illustrated gure 
shows corresponding roc curve experiment 
learning rate dropped epochs 
fraud detection bayesian belief networks conducted experiment dataset transaction described features fraud label 
structure received high score stage algorithm seen 
see features uence fraud fraud uences features 
depicts roc associated structure see performs 
example fraudulent transactions correctly recognized genuine transactions falsely classi ed fraudulent 
experiment conducted dataset transaction described features fraud label 
structure returned learning algorithm seen matching roc 
roc see allow fraudulent transactions incorrectly classi ed fraudulent transactions 
comparison results bbn ann compared table 
see bbn performs better ann applied fraud detection 
instance comparing ann bbn table see di erences approximately 
means cases bbn detects fraudulent transactions 
learning times go hours ann take minutes bbn 
evaluation new examples typically faster ann bbn 
experiment false pos false pos ann true pos true pos ann true pos true pos ann true pos true pos bbn true pos true pos bbn true pos true pos table table compares results achieved ann bbn false positive rate respectively 
showed results achieved applying ann bbn fraud detection 
comparison shows bayesian networks yield better results concerning fraud detection training period shorter fraud detection process considerably faster anns 
point interesting ongoing doing extensions added implementations ann bbn 
ann pruning algorithms exist cut away connections perceptrons practically training signi cantly improve performance backprop 
variations radial basis networks support vector machines svms backprop performing weight updates respect error function 
bbn extend implementation continuous variables allowed networks 
implement structure learning method dependency analysis opposed search scoring method stage compare results stage algorithm 
false positive true positive epochs error false positive true positive false positive true positive false positive true positive roc curves best result obtained performing correlation analysis 
average mean square error epoch complete pass training set network 
roc curve corresponding error curve 
structure features received high score stage algorithm 
roc associated 
structure features received high score stage algorithm 
roc associated 
bis bishop neural networks pattern recognition 
oxford university press 
boy boyan learning evaluation functions global optimization 
chan chan stolfo fan lee prodromidis credit card fraud detection meta learning issues initial results 
working notes aaai workshop ai approaches fraud detection risk management 
chan chan stolfo scalable learning non uniform class cost distributions case study credit card fraud detection 
proceedings fourth international conference knowledge discovery data mining pp 

chen cheng bell liu learning bayesian networks data ecient approach information theory 
proceedings acm cikm 
dou dougherty kohavi sahami supervised unsupervised discretization continuous features 
proceedings twelfth international conference machine learning pp 

tahoe city ca morgan kaufmann 
fawcett provost adaptive fraud detection 
data mining knowledge discovery 
fay fayyad mannila data mining knowledge discovery 
kluwer academic publishers 
hay haykin neural networks comprehensive foundation 
second edition prentice hall 
hec heckerman tutorial learning bayesian networks 
technical report msr tr microsoft research redmond washington 
jen jensen bayesian networks 
london england ucl press 
jor jordan learning graphical models 
mit press cambridge 
lam lam bacchus learning bayesian belief networks 
approach mdl principle 
computational intelligence 
mae maes machine learning techniques fraud detection 
master thesis vub 
pea pearl probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 
ree reed marks neural supervised learning feed forward arti cial neural networks 
mit press 
rus russell norvig arti cial intelligence modern approach 
prentice hall series arti cial intelligence 
englewood cli new jersey 
