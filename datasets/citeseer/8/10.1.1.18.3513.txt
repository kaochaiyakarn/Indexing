limsi broadcast news transcription system jean luc gauvain lori lamel gilles adda spoken language processing group limsi cnrs bp orsay cedex france lamel limsi fr june keywords speech recognition broadcast news transcription audio partitioning acoustic modeling language modeling lexical modeling reports limsi years directed transcription broadcast news data 
describe development moving laboratory read speech data real world speech data preparation arpa nov nov nov evaluations 
main problems needed addressed deal continuous flow data 
concern varied acoustic nature signal signal quality environmental transmission noise music different linguistic styles prepared spontaneous speech wide range topics spoken large variety speakers 
problem partitioning continuous stream data addressed iterative segmentation clustering algorithm gaussian mixtures 
speech recognizer continuous density hmms gaussian mixture acoustic modeling gram statistics estimated large text corpora 
word recognition performed multiple passes initial hypotheses cluster acoustic model adaptation improve word graph generation 
word transcription error limsi evaluation systems nov partitioned test data nov unpartitioned data nov unpartitioned data fall unpartitioned data computation time real time 
cet article les au limsi pour le un systeme de traitement automatique informations radio 
un systeme de transcription de lus nous les adaptations qui ont ete pour le traitement un flux audio continu de 
ces ont ete dans le cadre des evaluations arpa bn nov nov nov dec 
les par ce type de sont leur nature qu il de de nature environnement communication ou de nature linguistique styles des des 
la partition du flux continu est de iterative par un algorithme de eration sur des de 
le systeme de reconnaissance utilise des de markov caches continues pour la des de mots sur un grand corpus de de parole pour de langage 
la transcription en mots est en plusieurs passes de ou les hypotheses sont pour adapter les 
les avec versions de ce systeme des evaluations arpa sont nov avec partition nov nov dec de fois le temps reel 
submitted speech communication oct revised june published may dieser uber die am limsi der mit dem der von 
wir der von unter sprache zu freier sprache der der arpa nov nov und nov 
zur des von daten sind zwei probleme zu 
diese die des signals und 
und die oder sprache eine und viele sprecher 
der wird mit eines und auf der basis von gauss 
das verwendet hmms mit gauss zur modellierung und gram welche mit wurden 
die die nach und nach mit werden 
die von limsi nov nov und herbst und von als 
audio modellierung years significant advances large vocabulary continuous speech recognition focal area research serving test bed evaluate models algorithms 
tasks remain relatively artificial mainly laboratory read speech data 
report moving real world speech data order build system transcribing radio television broadcast news 
focuses developing broadcast news transcription system american english context le olive project developed systems french german languages 
radio television broadcast shows challenging transcribe contain signal segments various acoustic linguistic nature 
signal may studio quality transmitted telephone noisy channel corrupted additive noise nonlinear contain speech music pure music segments 
gradual transitions segments occur background music noise changing volume abrupt changes common switching speakers different locations 
speech produced wide variety speakers news anchors talk show hosts reporters remote locations interviews politicians common people unknown speakers new dialects non native speakers speech speaker may occur different parts broadcast different channel conditions 
linguistic style ranges prepared speech spontaneous speech 
acoustic models trained clean read speech wall street journal wsj corpus clearly inadequate process inhomogeneous data 
research aimed addressing principle types problems encountered transcribing broadcast news data related varied acoustic properties signal related linguistic properties speech 
problem resolved partitioning data homogenous segments segment classified segment type 
specific acoustic models trained different acoustic conditions 
data partitioning described section 
issues acoustic modeling discussed section 
order address variability observed linguistic properties analyzed differences submitted speech communication oct revised june published may read spontaneous speech regard lexical items word word sequence pronunciations frequencies distribution filler words respiration noises 
result analysis explicitly modeled acoustic language models described 
phone set enlarged explicitly model filler words breath noise resulting specific context dependent acoustic models 
compound words introduced means modeling reduced pronunciations common word sequences 
aspects discussed section 
section word decoder described considerations processing time 
conclude discussion issues broadcast news transcription highlight lessons learned working problem 
background broadcast news task assess improve speech recognition technology nov darpa dry run evaluation held hours marketplace data 
prior evaluations substantially transcribed broadcast news acoustic training data textual data language modeling available linguistic data consortium detail see ldc contribution issue 
nov hours transcribed data available 
data came different sources abc world news world news tonight cnn early prime headline news prime news world today washington journal npr things considered marketplace 
nov evaluation additional hours transcribed data sources available 
amount transcribed acoustic training data doubled resulting total hours data addition sources cnn early edition prime time live public policy 
details see ldc issue 
mentioned broadcast data comprised acoustic segments varied acoustic linguistic natures 
acoustic differences primarily concern different recording channels wideband telephone recording environment studio site location background music noise 
variety acoustic linguistic data types set focus conditions identified nist evaluate system performance certain specified conditions 
test data year chosen multiple sources including training material 
nov test contained minutes data taken shows 
nov nov test consisted hours audio data portions extracted broadcasts focus data types 
information see nist issue 
nov evaluation trained different acoustic model sets address different focus conditions 
wideband acoustic models trained hours sentences speakers wsj corpus hours broadcast news data distributed nist 
corpus train models british english speakers non native speakers american english may closely british speakers 
telephone speech models reduced bandwidth models trained bandlimited version wsj corpus 
resulting models adapted map estimation sentences wsj telephone speech data taken primarily corpus adapted telephone portion broadcast data 
type specific acoustic models trained different categories data defined nov partitioned evaluation high quality prepared speech high quality spontaneous speech nov evaluation components partitioned evaluation pe unpartitioned evaluation ue 
pe condition compare systems 
evaluations focus conditions assess performance different data types 
details see papers nist ldc issue 
submitted speech communication oct revised june published may telephone speech speech music speech noise non native speakers miscellaneous 
nov partitioned evaluation focus condition test segment provided nist 
limsi nov system telephone decision output gaussian segment classifier attributes taken provided segment annotation 
acoustic model sets trained broadcast quality speech conditions telephone quality speech condition speech presence music condition speech presence background noise condition non native speech condition 
total model sets conditions theta genders theta decoding passes 
dealing different model sets relatively difficult manage training decoding 
performance differences quite small development data hours taken shows word error rate resulting second decoding pass trigram language model type specific model sets compared model sets 
transcribed data available accurate acoustic models trained longer interesting focus condition specific models 
additionally transcriptions second set hours bn acoustic data background conditions annotated supervised training option part data 
probably worth looking set background acoustic conditions speech music noisy speech accurate labels automatically obtained 
transcriptions additional acoustic training data released ldc investigated various approaches build acoustic models available read speech hub training data 
acoustic model development aimed minimize word error rate eval test data 
experiments showed clear gain wsj data initialize acoustic models development carried hub data 
addition acoustic training data subsequent years textual data sources distributed ldc 
nov system language model trained words newspaper texts hub hub lm material words broadcast news transcriptions years words transcriptions acoustic training data 
training texts sources total words acoustic data transcriptions 
substantially lm training texts total words broadcast news transcripts ldc words nab newspaper texts ap texts words transcriptions acoustic training data 
limsi nov systems serves basis remainder earlier systems progress appropriate 
data partitioning need partitioning evidently possible transcribe continuous stream audio data prior segmentation partitioning offers advantages straight solution 
addition transcription said interesting information extracted division speaker turns speaker identities 
prior segmentation avoid problems caused linguistic discontinuity speaker changes 
acoustic models trained particular acoustic conditions performance significantly improved particularly cluster adaptation performed 
eliminating non speech segments dividing data shorter segments minutes long reduces computation time simplifies decoding 
various approaches proposed partition continuous stream audio data 
submitted speech communication oct revised june published may viterbi segmentation energy constraint fewer clusters change viterbi segmentation audio stream music background segments chop small segments speech music bandwidth gender identification speech partition map gmms reestimation viterbi segmentation train gmm segment gmm clustering partitioning algorithm 
approaches rely step procedure audio stream segmented attempt locate acoustic changes associated changes speaker background environmental condition channel condition resulting segments clustered usually gaussian models 
cluster assumed identify speaker precisely speaker acoustic condition 
segmentation procedures classified approaches phone decoding distance segmentations methods hypothesis testing 
partitioning approach step procedure relies audio stream mixture model 
component audio source representing speaker particular background channel condition turn modeled mixture gaussians 
segment boundaries labels jointly identified iterative procedure described 
audio stream mixture model segmentation labeling procedure introduced shown 
non speech segments detected rejected gaussian mixture models gmms 
gmms gaussians serve detect speech pure music background 
acoustic feature vector segmentation contains parameters 
recognition feature vector include energy delta energy parameters included 
gmms trained acoustic data extracted training data segmentation transcriptions 
speech model trained data types submitted speech communication oct revised june published may exception pure music segments silence portions segments transcribed speech music 
order detect speech noisy conditions second speech gmm trained segments data set 
models expected match speech segments 
music model trained portions data labeled pure music avoid mistakenly detecting speech music segments 
silence model trained segments labeled silence forced viterbi alignment excluding silences segments labeled containing speech presence background music 
test segments labeled music silence removed prior processing 
maximum likelihood segmentation clustering iterative procedure applied speech segments gmms agglomerative clustering algorithm 
sequence cepstral vectors corresponding show goal find number sources homogeneous data places source changes 
result procedure sequence segments associated segment cluster labels number segment clusters 
segment cluster assumed represent speaker particular acoustic environment 
absence prior knowledge stochastic process governing segment lengths objective function penalized log likelihood form log gamma ffn gamma fik deltaj 
fixed number parameters corresponding cluster ff fi 
terms ffn fik seen segment cluster penalties correspond parameters exponential prior distributions easy prove starting overestimates alternate viterbi reestimation agglomerative clustering gives sequence estimates non decreasing values objective function 
viterbi step reestimate increase log gamma ffn adding segment penalty ff viterbi search clustering step clusters merged long resulting log likelihood loss merge fi 
merging models reduce number segments change segment penalty taken account clustering 
algorithm stops merge possible 
constraint cluster size ensure cluster corresponds speech 
recall previously rejected non speech segments considered 
single gaussian models merging criterion easy implement log likelihood loss directly computed sufficient statistics corresponding segments 
general case gaussian mixtures sufficient statistics direct solution compute resulting mixture log likelihood loss 
envision estimating new mixture data costly procedure 
solution adopted modify objective function replacing likelihood function complete data likelihood gaussian mixtures extending maximum likelihood clustering method gaussian level 
estimate log likelihood loss gaussian mixtures simply compute sum log likelihood loss clustering gaussians mixtures get desired number gaussians 
mixture components cluster compute log likelihood loss induced merging clusters agglomerative clustering performed starting gaussians gaussians left 
process initialized simple segmentation algorithm detection spectral change similar step cmu system 
threshold set clustering criterion closely related mdl bic criterion 
submitted speech communication oct revised june published may spectrograms illustrating results data partitioning sequences extracted broadcasts 
transcript gives automatically generated segment type speech music noise 
speech segments cluster labels specify identified bandwidth telephone band wideband gender male female number cluster 
generate segments roughly times segments true speaker turns 
initially cluster set consists cluster segment 
followed viterbi training set gmms component gmm cluster 
procedure controlled parameters minimum cluster size maximum log likelihood loss merge ff segment boundary penalty fi 
merges possible segment boundaries refined set gmms additional relative energy boundary penalty interval 
done locate segment boundaries silence portions attempting avoid cutting words occurs 
speaker independent gmms corresponding wideband speech telephone speech gaussians label telephone segments 
followed segment gender identification sets gmms gaussians bandwidth 
result partitioning process set speech segments cluster gender telephone wideband labels illustrated 
partitioning results developing partitioner dev data set evaluated frame level segmentation error similar half hour shows eval test data manual segmentation transcriptions 
nist transcriptions test data contain segments scored contain overlapping foreign speech occasionally small gaps consecutive transcribed segments 
considered partitioner correctly portions relabeled excluded segments speech music background 
table top shows segmentation frame error rate speech non speech errors shows 
average frame error higher show 
due long noisy segment deleted 
averaged shows gender labeling frame error 
addition errors female speech frames deleted largely due segment male frames deleted 
bottom table shows measures submitted speech communication oct revised june published may show avg frame error error clusters coverage table top speech non speech frame segmentation error nist labels missing excluded segments manually labeled speech non speech 
bottom cluster purity best cluster coverage 
test set word error system step eval eval eval step gram manual automatic step gram manual automatic table word error manual automatic segmentations nov system data sets 
cluster homogeneity 
entry gives total number speakers identified clusters file 
general clusters speakers cluster represent speaker acoustic environment 
second measure cluster purity defined percentage frames cluster associated represented speaker cluster 
similar measure proposed segment level 
table shows weighted average cluster shows 
average data cluster comes single speaker 
clusters impure tend include speakers similar acoustic conditions 
best cluster coverage measure dispersion speaker data clusters 
averaged percentage data speaker cluster data 
average speaker data going cluster 
fact average value bit misleading large variance best cluster coverage speakers 
speakers cluster coverage close single cluster covers essentially frames data 
speakers lot data speaker covered clusters containing comparable amounts data 
investigate effect automatic vs manual partitioning recognizer performances 
table compares word error rates automatic manual nist partitions evaluation data sets 
performance loss relative decoding step 
adaptation 
higher eval data due long deleted segment show 
adaptation step relative performance loss indicating clustering process inappropriately merging splitting speakers data 
appears clustering errors detrimental performance segmentation ones 
acoustic modeling acoustic models trained available transcribed task specific training data amounting hours audio data 
august february releases ldc transcriptions 
overlapping speech portions detected transcriptions removed submitted speech communication oct revised june published may signal ms window filters cepstral mean variance normalisation mel power spectrum cep log energy idft plp frontend training data 
phone set contains units including specific phone symbols explicitly model silence filler words breath noises 
decision model specific phones desire capture possible acoustic differences similar phones phone set time avoid possible contamination phone models 
plp acoustic parameterization limsi systems 
speech features consist cepstral parameters derived mel frequency spectrum estimated khz band khz telephone data ms 
ms frame mel scale power spectrum computed cubic root taken followed inverse fourier transform 
lpc cepstrum coefficients computed 
cepstral coefficients normalized segment cluster basis cepstral mean removal variance normalization cf 

resulting cepstral coefficient cluster zero mean unity variance 
component acoustic feature vector consists cepstrum coefficients log energy second order derivatives 
feature vector fewer parameters component feature vector previously better performance hub data relative gain 
acoustic models sets tied state word position dependent triphones 
phone model tied state left right state gaussian mixture observation densities typically components 
triphones word position dependent sense different models word internal phones word boundary phones 
word boundary phones subsequently word initial word final word initial final monophone words 
triphone contexts modeled selected frequencies training data 
try predict unseen triphones backoff merging contexts infrequent triphone contexts 
try merge phones common right context common left context remaining data merged context independent model 
hub training data triphone contexts modeled resulting triphone coverage 
silence background noise word model special inserted words appear language model 
contrast filler word breath noise models explicitly represented language model 
submitted speech communication oct revised june published may nov system position dependent acoustic models decoding pass order reduce search space decoding time slightly better performance obtained position independent models 
twice acoustic training data available able model larger number contexts slight gain observed position dependent models hub data 
hmm training requires alignment audio signal phone models usually relies perfect orthographic transcription speech data phonetic lexicon 
speech segment viterbi aligned orthographic transcription produce phone transcription 
transcriptions phonetic lexicon really perfect alignment procedure may succeed 
case error manually corrected segment simply discarded 
practice errors corrected training data limited segments discarded lot training data available 
data available spent time correcting errors 
discarded segments complete viterbi alignment due beam pruning duration criteria respected maximum allowable phone duration 
example phone duration longer ms indicative error phones silence breath noise 
alignment hmm parameter estimation done em estimation procedure starting single gaussian tied state splitting gaussian maximum number gaussians state usually reached 
avoid problems due data sparseness state tying bayesian estimation procedure common prior gaussians state minimum frame count accumulated gaussian frames required keep gaussian 
alignment reestimation procedure iterated times refine acoustic models usually increasing number parameters progressively 
separate male female models obtained map estimation si seed models accurately model speech data 
wideband telephone band models estimated telephone band models trained low pass filtered version data set 
model set contains tied states total gaussians 
compared divisive decision tree clustering agglomerative clustering state tying 
approaches obtain comparable model sets divisive decision tree clustering particularly interesting large number states cluster time faster robust bottom greedy algorithm easier tune 
set questions nov system concern phone position distinctive features identities phone neighboring phones 
questions table frequently questions largest model set table 
tree constructed state phone 
tree built maximize likelihood training data single gaussian state models penalized number tied states 
unsupervised acoustic model adaptation means variances performed cluster mllr technique decoding pass 
mean vectors adapted single block diagonal regression matrix block parameter stream cepstrum delta cepstrum delta delta cepstrum diagonal matrix adapt variances 
seconds adaptation data available diagonal matrices means variances 
single regression matrix observed gain multiple regression matrices unsupervised adaptation 
submitted speech communication oct revised june published may position state position word word monophone general classes vowel consonant continuant sonorant voiced consonant voiceless fricative nasal anterior high coronal slack rounded tense syllabic fillers vowel classes high vowel low vowel rounded vowel tense vowel reduced back vowel long vowel short vowel vowel consonant classes labial dental alveolar velar individual phones delta delta delta ae filler breath silence table questions decision tree clustering concern phone position class distinctive features phone identity 
question log likelihood gain question log likelihood gain vowel phone sonorant phone sonorant front vowel phone nasal voiced consonant vowel pos high vowel nasal voiceless voiceless phone pos phone table frequently decision tree questions 
indicate question applied right left context respectively phone 
submitted speech communication oct revised june published may language modeling different approaches language model training explored tested context complete transcription system 
language model efficiency investigated aspects mixing different training material sources epoch approach mixing interpolation vs count merging class language models 
experimental results indicate judicious selection training source epoch important sufficient broadcast news transcriptions newspaper newswire texts necessary 
combined improvements text selection interpolation gram class lms led reduction perplexity lm final pass gram class interpolated word gram compared gram lm limsi nov bn system 
text normalization wordlist selection transcription american english broadcast news shows large text corpora available constructing language models 
different sources data ffl news words news texts various sources newspapers newswires 
data available ldc consist texts los angeles times new york times wall street journal washington post reuters news service associated press 
ffl bna words accurate broadcast news transcripts acoustic training data 
non lexical items breath noise word fragments transcribed 
ffl bnc words commercial transcripts various broadcast shows 
transcripts include extra lexical events 
noted small proportion lm data truly representative real data transcribed 
training texts processed clean errors inherent texts arising preprocessing tools transformed closer observed american speaking style 
cleaning consisted primarily correcting obvious systematic bugs introduced text processing tools expanding abbreviations acronyms consistent manner 
texts transformed closer observed american reading style set rules corresponding probabilities derived alignment wsj wsj prompt texts transcriptions acoustic data 
example rules probabilities shown table 
cleaning training texts reduced perplexity development data better coverage lexicon 
filler words uh mapped unique form 
training texts processed order add proportion breath markers filler words 
elegant incorporate lm interpolating lms estimated clean text noises transcripts noises adding clean texts generation model resulted lower word error rate relative 
result explained observation breath noise filler words occur random specific places 
adding places clean texts equivalent adding priori information distribution phenomena transcripts 
training texts processed treat common acronyms distinct lexical entries opposed sequence individual letters represent frequent word sequences subject reduction compound words 
submitted speech communication oct revised june published may nb 
nb 
eighth eighth 
incorporated 
dollars dollars table example transformation rules probabilities 
word error rate perplexity gram lm eval eval eval eval eval eval news bnc bna bnc bna news table word error rate perplexity lms constructed different sources news newspaper newswire words bna accurate broadcast news transcripts words bnc commercial broadcast news transcripts words evaluation data sets 
recognition vocabulary word list contains words includes words occuring minimum times bnc words twice bna data words 
lexical coverage eval eval eval test sets respectively 
combining data sources easy way combine training material different sources train gram backoff lm source interpolate 
interpolation weights directly estimated development data em algorithm 
resulting lm mixture gram backoff lms 
alternative simply merge gram counts train single gram backoff language model counts 
data sources representative task gram counts empirically weighted minimize perplexity set development data 
effective done trial error easily optimized 
addition weighting gram counts pose problems properly estimating backoff coefficients 
available data sources compared approaches hand generating interpolated gram backoff lms hand merging gram counts manually optimized weights 
results obtained word graph rescoring show eval sets approach merged gram counts slightly higher word error rate absolute compared 
strategies explored add cross sentence trigram counts trigram model add texts sentences boundaries renormalize counts add cross sentence trigrams 
strategies led similar results terms perplexity recognition error 
nov evaluation language models constructed second approach 
submitted speech communication oct revised june published may selecting appropriate lm training material evidently affects resulting lm accuracies 
conflicting need sufficient amounts text data estimate lm parameters assuring data representative task 
instance reported broadcast news transcription task available newspaper data led small decrease perplexity led small increase recognition error rate 
news texts lower perplexity eliminated 
optimize selection texts limsi nov system newspaper commercial transcription sources split non overlapping time periods proximity test epoch oct nov 
periods jan sep oct jun jul feb mar aug sep dec separate lms constructed source 
interpolation coefficient component lm optimized development data containing shows recorded oct 
lms low interpolation coefficients eliminated 
subsets comparable interpolation coefficients different sources epochs merged order decrease size resulting lm 
small variations perplexity observed process final optimization resulted interpolation gram lms constructed texts bnc words interpolation coefficient bna words interpolation coefficient news period jan sep words interpolation coefficient news period jul aug interpolation coefficient 
noted weight bna lm equal weight news lms text smaller 
experiments conducted order evaluate influence source recognition word error rate 
gram lms constructed data sets news bnc bna bnc bna news 
corresponds gram arpa evaluation 
recognition results obtained word graph rescoring lms summarized table eval data sets 
true differences models may slightly larger results word graph generated bnc news bna lm 
large reduction perplexity word error rate transcripts train lm opposed news texts 
interpolating news lm transcription lm yields small consistent reduction perplexity word error 
combination lms estimated commercially produced transcripts bnc accurate quite 
commercial transcripts available newspaper sources reasonable source language model training data lm constructed news data perplexity higher bnc bna news recognition word error rate higher 
lexical modeling lexical design entails selecting vocabulary items determining pronunciation 
word list selection discussed previous section section address pronunciation modeling 
experience systematic lexical design improve system performance 
pronunciations phone set silence filler words breath noises include standard pronunciations explicitly represent 
order better model observed speaking styles hub data phones added limsi wsj phone set explicitly model filler words breath noises phones 
phonemic representation allophonic variants predicted rules optional 
importantly continuum different phoneme decision occurred utterance subjective 
phonemic representation hard decision imposed left data period eval test set excluded 
submitted speech communication oct revised june published may delta don know delta delta dno delta dno don know dno lmi ltm lm am delta delta delta going example compound words pronunciations 
original concatenated pronunciation st line reduced forms nd line 
phones fg optional phones alternates 
acoustic models represent observed variants training data 
pronunciation graph associated word allow alternate pronunciations may depend word context 
frequently occuring inflected forms verified provide systematic pronunciations 
variety words frequent alternative pronunciation variants observed variants due allophonic differences 
common example suffix ization pronounced delta 
occurences word training data pronounced delta 
pronunciation variant context word coupon deltan vs deltan 
alternate pronunciations may reflect different parts speech verb noun words excuse record 
known fluent speech certain common word sequences subject severe reduction 
easy way model effects compound words frequent word sequences way incorporating phonological rules limited basis 
example spectrograms sentences including word sequence shown illustrate need pronunciation variants spontaneous speech 
spectrogram speaker said words clearly dy 
second speaker produced flap combined final initial 
third example sequence reduced 
recognition lexicon contains entries common acronyms training texts compound words frequent word sequences 
example compound words pronunciations table 
line corresponds original pronunciation formed concatenation component words 
second line contains reduced forms added compound word 
pronunciations american english lexicon created semi automatically pronunciation generation tool 
unknown word encountered affix rules applied entries lexicons attempt derive pronunciation 
multiple pronunciations derived selection source 
limsi master lexicon contains entries processing new set acoustic training data submitted speech communication oct revised june published may spectrograms word sequences containing 
see file wear file think file 
generally need add new words 
times proper names difficult generate automatically word fragments need included training lexicon usually recognition lexicon 
proper names appear training data pronunciations manually verified 
word decoding important problems implementing decoder design efficient search algorithm deal huge search space especially language models longer span successive words grams grams 
potential applications making broadcast news transcriptions require line processing 
batch processing offers substantial advantage data show unsupervised model adaptation resulting significant improvement recognition accuracy 
multiple pass decoders adapted broadcast news transcription decoding pass generate word hypothesis model adaptation 
approach successful acoustic model adaptation date attempts adapt language models rewarding 
baseline decoder step approach limsi nov system transmits information levels word graphs 
due memory constraints step may consist passes successively refined models 
decoding passes cross word cd triphone models 
order generate accurate word graphs cluster model adaptation carried initial hypothesis 
clear type adaptation real time system applicable batch processing data occur immediately data broadcast 
word decoding procedure shown 
prior decoding segments longer chopped smaller pieces limit memory required gram gram decoding passes 
bimodal distribution estimated fitting mixture gaussians log rms power frames segment 
distribution determine locations correspond pauses reasonable places cut segment 
cuts probable pause previous cut 
word recognition performed submitted speech communication oct revised june published may chop segments smaller segment cluster variance normalization cepstral mean audio stream final transcription word graph generation mllr adaptation gram decoding mllr adaptation initial hypotheses generate partition map word decoding 
steps initial hypothesis generation word graph generation final hypothesis generation passes 
step initial hypothesis generation step carried passes generates initial hypotheses cluster acoustic model adaptation 
pass step generates word graph small bigram backoff language model gender specific sets position tied states 
followed second decoding pass larger set acoustic models triphones tied states trigram language model trigrams bigrams generate hypotheses 
band limited acoustic models telephone speech segments 
step word graph generation unsupervised acoustic model adaptation means variances performed segment cluster mllr technique 
mean vectors single block diagonal regression matrix diagonal matrix adapt variances 
segment decoded bigram language model adapted version small set acoustic models trigram language model bigrams trigrams adapted versions larger acoustic model set 
step final hypothesis generation final hypothesis generated gram interpolated category trigram model automatically generated word classes 
pass step uses large set acoustic models adapted hypotheses step gram language model 
hypothesis adapt acoustic models prior final submitted speech communication oct revised june published may decoding step interpolated category trigram model 
test set word error system eval eval eval nov system nov system nov system table summary bn transcription word error rates 
nov system manual partition 
table reports word recognition results eval test sets years 
system development carried eval data 
results shown bold official nist scores obtained different systems 
nov system manual partition 
nov main development effort devoted moving partitioned evaluation unpartitioned 
nov system focus condition specific acoustic models nov system 
system achieved performance improvement eval test data 
nov system accurate acoustic language models achieves relative word error reduction compared nov system 
table gives word error rates nov system decoding step eval sets 
decoding step generate initial hypothesis runs xrt word error eval data eval eval sets 
word error reduction obtained second decoding step uses adapted acoustic models runs xrt 
relatively small gains obtained gram decoding pass xrt include extra acoustic model adaptation 
runs done silicon graphics origin processor running mhz gb memory 
processing times indicative effort optimize computation means fit available 
xrt decoder goal achieve comparable performance decoding time realtime 
reach goal gram single pass dynamic network decoder developed 
time synchronous viterbi decoder dynamic expansion lm state conditioned lexical trees acoustic language model lookaheads 
decoder handle position dependent cross word triphones lexicons contextual pronunciations 
various pruning techniques reduce search space computation time including hmm state pruning test set word error system step eval eval eval step gram step gram step gram gram class table word error rates decoding step nov system 
submitted speech communication oct revised june published may pass am lm time total time xrt xrt xrt xrt xrt mllr xrt xrt xrt mllr xrt xrt mllr xrt xrt table comparison decoding strategies nist hub eval set partitioning coding times included 
beams fast gaussian likelihood computations 
generate word graphs rescore different acoustic language models 
faster real time decoding obtained decoder word error running mb memory widely available platforms pentium iii alpha machines 
decoder solve problem reducing recognition time proper models order optimize recognizer accuracy decoding speed 
general better models parameters require computation 
models accurate possible tighter pruning level reducing computational load loss accuracy 
limitations available computational resources significantly affect design acoustic language models 
operating point right balance model complexity pruning level 
table gives computation time word error rates various decoding strategies hub eval 
pruning thresholds set match computing time interesting setups 
entry specifies acoustic language models pass computation time 
passes perform full decode decoding pass labelled word graph rescoring graph generated second gram pass 
results clearly demonstrate advantage multiple pass decoding approach 
comparing setups pass xrt passes xrt extra computation time needed decode mllr adaptation largely compensated reduction word error rate 
adapted acoustic models allows tighter pruning threshold computing time significantly lower word error rate 
comparing setups passes xrt passes xrt advantage extra decoding pass gram lm nd pass hypotheses mllr adaptation seen 
official result eval test set nov system decoding time xrt 
decoding pass unrestricted bn data decoded xrt including partitioning word error rate 
decoding strategy successively applied bn transcription languages french german mandarin comparable word error rates 
perspectives summarized activities aimed transcribing radio television broadcasts 
carried american english language context developing systems annual darpa benchmark tests 
framework provided submitted speech communication oct revised june published may training materials transcribed audio textual corpora training acoustic language models test data common evaluation framework 
context le olive project limsi transcription system ported french german languages required large investment data collection 
partitioning transcribing television radio broadcasts necessary steps enable automated processing vast amounts audio video data produced daily basis 
data partitioning algorithm gaussian mixture models iterative segmentation clustering procedure 
resulting segments labeled gender bandwidth 
errors occur boundary segments involve silence segments considered speech non speech influencing transcription performance 
experience appears current word recognition performance critically dependent partitioning accuracy 
acoustic training broadcast data significantly complicated read speech corpora wall street journal corpus 
divided speaker turns segments quite long minutes duration 
aligning perfect transcription signal difficult minor problem may cause alignment fail 
splitting long segments silences possible solution requires manual intervention 
explicitly modeling nist focus conditions probably worth additional effort complexity training decoding 
focus conditions quite interesting factor error analysis 
addition distinctions clearly unrealistic automatically detect distinction read spontaneous broadcast quality speech reliable detection non native speech 
wideband telephone band distinction reasonable accuracy narrow band models improves relative performance telephone data 
large amount acoustic training data available american english possible properly model different triphone contexts high coverage 
acoustic models efficient reducing number parameters estimated 
different approaches state tying investigated 
comparable model sets obtained bottom clustering top decision tree clustering approach faster shortens development cycle 
cepstral mean normalization acoustic model adaptation important techniques non homogeneous nature broadcast data 
cluster test data allowing better estimate speaker characteristics acoustic environment 
generation word graphs adapted acoustic models initial hypothesis obtained rapid decoding pass essential obtaining word graphs low word error rates 
unsupervised hmm adaptation performed prior decoding pass hypothesized transcription previous pass 
strategy leads significant reduction word error rate 
concerning language model development contributions various text sources evaluated 
determined transcriptions broadcast data detailed acoustic commercial transcripts far important sources newspaper newswire texts helpful closer sources commercial transcripts available 
potential source related texts closed captions explored context olive project 
initial experience closed captions stylized language relatively limited compared true transcripts appropriate commercial transcripts 
experimented different approaches combining data different sources count merging lm interpolation 
interpolation powerful approach allowing optimal combination component lms estimated different text sources 
word transcription error nov unpartitioned evaluation test data hours 
substantial performance improvements obtained plenty submitted speech communication oct revised june published may room improvement underlying speech recognition technology 
unrestricted broadcast news shows dev eval data word error rate nist scoring program removed overlapping speech 
rapid expansion different media sources information dissemination pressing need automatic processing audio data stream 
variety near term applications possible audio data mining selective dissemination information media monitoring services disclosure information content content indexation digital libraries 
substantial performance improvements obtained years need improve underlying speech recognition technology increase recognition accuracy reduce required processing time 
authors acknowledge participation adda decker nov system michele estimating word classes 
www fb ti uni duisburg de alert itc pc iei pi cnr echo tpd tno nl olive proc 
arpa spoken language systems technology workshop austin tx san francisco morgan kaufmann january 
proc 
darpa speech recognition workshop arden house ny san francisco morgan kaufmann february 
proc 
darpa speech recognition workshop va san francisco morgan kaufmann february 
www nist gov speech publications darpa index htm proc 
darpa broadcast news transcription understanding workshop va san francisco morgan kaufmann february 
www nist gov speech publications darpa index htm proc 
darpa broadcast news workshop va san francisco morgan kaufmann february 
www nist gov speech publications darpa index htm proc 
speech transcription workshop college park md may 
www nist gov speech publications tw index htm aubert pass cross word decoding large vocabularies lexical tree search organization proc 
esca eurospeech pp 
budapest hungary september 
chen gopalakrishnan speaker environment channel change detection clustering bayesian information criterion proc 
darpa transcription understanding workshop pp 
february 
submitted speech communication oct revised june published may clarkson rosenfeld statistical language modelling cmu cambridge toolkit proc 
esca eurospeech rhodes greece pp 
september 
gauvain adda lamel adda decker transcribing broadcast news limsi nov hub system proc 
arpa speech recognition workshop va pp 
february 
gauvain adda lamel adda decker transcription broadcast news proc 
esca eurospeech pp 
rhodes greece september 
gauvain lamel fast decoding indexation broadcast data proc 
icslp pp 
beijing china october 
gauvain lamel adda limsi hub transcription system proc 
darpa broadcast news transcription understanding workshop pp 
va february 
gauvain lamel adda partitioning transcription broadcast news data proc 
icslp pp 
sydney australia december 
gauvain lamel adda limsi hub system proc 
darpa speech recognition workshop arden house ny pp 
february 
gauvain lamel adda limsi hub transcription system proc 
darpa broadcast news workshop pp 
va february 
gauvain lamel adda decker limsi nov wsj system proc 
arpa spoken language technology workshop nj march 
gauvain lamel adda decker developments continuous speech dictation arpa wsj task proc 
ieee icassp detroit pp 
may 
gauvain lee maximum posteriori estimation multivariate mixture observation markov chains ieee trans 
sap pp 
april 
gish siu rohlicek segregation speakers speech recognition speaker identification proc 
ieee icassp pp 
may 
hain johnson woodland young segment generation clustering htk broadcast news transcription system proc 
darpa broadcast news transcription understanding workshop pp 
va february 
hermansky perceptual linear prediction plp analysis speech 
soc 
amer vol 
pp 

multilingual stochastic gram class language models proc 
ieee icassp atlanta ga pp 
may 
kannan ostendorf rohlicek maximum likelihood clustering gaussians speech recognition ieee trans 
speech audio july 
kubala jin makhoul nguyen schwartz yuan automatic recognition broadcast news proc 
darpa speech recognition workshop arden house ny pp 
february 
submitted speech communication oct revised june published may lamel adda designing pronunciation lexicons large vocabulary continuous speech recognition proc 
icslp pp 
philadelphia pa october 
liu kubala fast speaker change detection broadcast news transcription indexing proc 
esca eurospeech budapest pp 
hungary september 
woodland maximum likelihood linear regression speaker adaptation continuous density hidden markov models computer speech language pp 

ney tran improvements beam search word continuous speech recognition proc 
ieee icassp pp 
san francisco ca march 
odell valtchev woodland young pass decoder design large vocabulary recognition proceedings arpa workshop human language technology pp 
nj march 
paul baker design wall street journal csr corpus proc 
icslp banff pp 
october 
schluter ney automatic transcription verification broadcast news similar speech corpora proc 
darpa broadcast news workshop pp 
va february 
robinson foote renals british english speech corpus large vocabulary continuous speech recognition proc 
ieee icassp 
detroit mi pp 
may 
schwartz jin kubala modeling conditions proc 
darpa speech recognition workshop va pp 
february 
seymore chen rosenfeld language pronunciation modeling cmu hub evaluation 
proc 
darpa speech recognition workshop va pp 
february 
siegler jain raj stern automatic segmentation classification clustering broadcast news audio proc 
darpa speech recognition workshop va pp 
february 
stern specification arpa november hub evaluation november 
wegmann carp gillick roth yamron dragon systems broadcast news transcription system proc 
darpa broadcast news transcription understanding workshop pp 
va february 
wegmann zhan gillick progress broadcast news transcription dragon systems proc 
ieee icassp pp 
phoenix az march 
woodland whittaker language modeling htk hub lvcsr hub workshop september 
submitted speech communication oct revised june published may young adda decker aubert gauvain lamel leeuwen robinson woodland multilingual large vocabulary speech recognition european proc 
computer speech language pp 
jan 
submitted speech communication oct revised june published may 
