coulomb classifiers generalizing support vector machines analogy electrostatic systems sepp hochreiter michael mozer klaus department electrical engineering computer science technische universit berlin berlin germany department computer science university colorado boulder usa cs 
tu berlin 
de 
colorado 
edu introduce family classifiers physical analogy electrostatic system charged conductors 
family called coulomb classifiers includes best known support vector machines svms svm svm 
ics analogy training example corresponds charged conductor location space classification function corresponds electrostatic potential function training objective function corresponds coulomb energy 
electrostatic framework provides novel interpretation existing algorithms interrelationships suggests variety new methods svms including kernels bridge gap polynomial radial basis functions objective functions require positive definite kernels regularization techniques allow construction optimal classifier minkowski space 
framework propose novel svms perform simulation studies show comparable superior standard svms 
experiments include classification tasks data represented terms pairwise proximities coulomb classifier outperformed standard svms 
support vector machines svms attracted interest machine learning community considered state art classification regression problems :10.1.1.2.6040:10.1.1.117.3731
appealing property svms convex optimization problem means single minimum exists computed efficiently 
new derivation svms analogy electrostatic system charged conductors 
electrostatic framework provides physical interpretation svms gives insight seemingly arbitrary aspects svms diagonal quadratic form allows derive novel svm approaches 
focus classification input vector categories labeled 
assume supervised learning paradigm training examples available example consisting input label yi 
introduce electrostatic models directly analogous existing machine learning ml classifiers builds generalizes previous 
model describe physical system show correspondence ml classifier 
electrostatic model uncoupled point charges consider electrostatic system point charges populating space homologous 
point charge corresponds particular training example point charge fixed location charge sign yi 
define sets fixed charges 
charge point yi ci ci amount charge discussed 
briefly review elementary physics 
unit positive charge attracted charges charges 
move charge location attractive repelling forces overcome point trajectory path integral force trajectory called depend trajectory 
potential done move unit positive charge point usually infinity potential distance measure 
electrostatic systems point charges ila bll 
definition see potential negative positive neighborhood negative positive charges 
potential indicates sign amount charge local neighborhood 
turning back ml classifier propose classification rule input assigns label 
abstracting electrostatic system ci function decreases sufficiently steeply distance obtain nearest neighbor classifier 
electrostatic model coupled point charges consider electrostatic model extends previous model respects 
point charges replaced conductors metal spheres 
conductor self potential denoted pit measure charge easily hold metal sphere pit related sphere diameter 
second conductors coupled conductors 
coupling means charge free flow conductors 
technically viewed single conductor 
model initially place charge conductor allow charges flow freely assume resistance coupling polarization conductors 
charges redistribute charge tend periphery homogeneous neighborhood conductors charges repel 
charge tend boundary opposite charges attract 
see depiction redistributed charges 
shading proportional magnitude ci 
ml classifier built model decision rule classifying input model ci uniform conductors large ci greatest influence potential function 
consequently think ci weight importance example show shortly examples ci exactly support vectors svm 
coupled conductor system energy minimum 
shown zero potential charge magnitude shading 
redistribution charges electrostatic system achieved minimization coulomb energy 
imagine placing total charge magnitude dividing uniformly conductors free charge flow yields distribution charges coulomb energy minimized 
introduce coulomb energy preliminaries 
potential conductor xi denote compactly hi described terms potential pij ni pij pij potential induced conductor charge qj conductor pii pij pij 
conductor metal sphere centered radius system modeled point charge qi pij previous section 
self potential pii defined function coulomb energy defined terms potential conductors qt pq pij yi yj iz jz energy minimum reached potential ui con nected denote potential ns 
similarly ns denotes potential connected 
additional constraints system coupled conductors necessary order interpret system terms existing machine learning models 
positive negative potentials balanced ns ns 
constraint achieved introducing constant potential ns ns potential function il second conductors prevented reversing sign charge oz holding quantity charge oz requirements satisfied electrostatic model disconnecting conductor charge flow oz reaches lower upper bound subsequently freeze charge 
mathematically requirements satisfied treating energy minimization constrained optimization problem oz electrostatic system corresponds support vector machine svm constraints setting ic ci ic ci identity holds coulomb energy exactly svm quadratic objective function thresholded electrostatic potential evaluated location exactly svm decision rule 
equalization potentials coupled conductors corresponds minimization slack variables svm 
mercer condition essence nonlinear svm ory equivalent fact continuous electrostatic energy positive fg dz 
self potentials electrostatic system provide interpretation diagonal elements quadratic objective function svm 
interpretation diagonal elements allows introduce novel kernels novel svm methods discuss 
electrostatic model 
coupled point charges battery electrostatic model control magnitude charge applied 
apply charge magnitude control resulting potentials ns ns may 
compensate imbalance potential offset electrostatic model control potentials ns ns directly adding battery system 
connect positive pole battery potential negative pole potential 
battery ensures ns ns charges flow battery system systems take potential battery poles 
battery removed 
potential yi forced battery conductor total coulomb energy energy model minus done battery 
done battery ii qt oi pij yi yj oi physical system corresponds support vector machine svm :10.1.1.117.3731
svm requires ici constraint may fulfilled system described enforced slightly different system 
comparison existing novel models novel kernels electrostatic perspective easy understand svm algorithms break high dimensional spaces kernels rapid fall induce small potentials consequently conductor retains charge 
charged conductor corresponds support vector number support vectors large leads disadvantages classification procedure slow expected generalization error increases number support vectors 
kernels drop exponentially 
self potential permits kernels invalid generalization electric field xi xj xi xi pii ri radius ith sphere 
ris increased maximal values hit conductors ri kernels called coulomb kernels invariant scaling input space sense scaling change minimum objective function 
consequently kernels appropriate input data varying local densities 
depicts classification task input regions varying density 
optimal class boundary smooth low data density regions high curvature regions data density high 
classification boundary constructed svm plummer kernel xi approximation novel coulomb kernel lacks weak singularities 
class data dense region trained svm new kernel 
gray scales indicate weights support vectors dark 
boundary curves novel kernel solid best rbf kernel svm overfits high density region dashed optimal boundary dotted 
novel svm models electrostatic framework derive novel svm approaches representative examples illustrate 
support vector machine svm exploit physical interpretation pii conductor self potential 
pii determine entropy charge distribution energy minimum 
introduce parameter rescale self potential pi lid 
controls complexity corresponding svm 
modification electrostatic model call svm 
support vector machine svm minimum electrostatic energy yi vi vector labels electrostatic potentials equalize 
motivates objective function potential difference coulomb energy 
obtain optimization problem cf 
model pt mn ty subject vector ones diag 
call variant optimization problem svm 
constraint yc ensures summed potential class 
construction pt positive definite consequently formulation require positive definite kernels 
characteristic useful problems properties objects classified described pairwise proximities 
suppose representing input object explicit feature vector objects represented matrix contains real number indicating similarity object object 
interpret entries matrix produced unknown kernel operating unknown feature vectors 
matrix positive definiteness assured optimal hyperplane constructed minkowski space 
experiments uci benchmark repository 
representative models introduced perform simulations comparisons standard svm variants 
datasets uci benchmark tory preprocessed 
banana data set taken www 

grad 
de data 
fold validation data set restricting training set examples remainder examples testing 
compared standard architectures svm svm novel architectures svm svm combination svm 
svm svm con straint explored radial basis function rbf polynomial pol plu kernels 
hyperparameters determined fold cross validation training sets 
search hyperparameter intensive 
table shows results comparisons uci benchmarks 
novel architectures svm svm performed existing architectures 
anticipated svm requires far fewer support vectors 
additionally kernel appears robust hyperparameter svm choices rbf polynomial kernels 
pairwise proximity data 
applied svm generalized svm svm pairwise proximity data sets 
data set cat cor tex data matrix connection strengths cat cortical areas provided available anatomical literature determine proximity values cortical areas :10.1.1.11.2062
areas belong different coarse brain regions auditory visual somatosensory ss fl 
goal classify cortical area belonging region thyroid heart rbf pol plu breast cancer banana rbf pol plu german rbf pol plu table mean misclassification uci repository data sets 
cell table obtained replications splitting data training test sets 
comparison svms table columns kernel functions table rows 
cells bold face best result data set italicized second third best 

second data set protein data evolutionary distance se quences amino acids proteins obtained structural comparison provided :10.1.1.130.3511
proteins classes globins hemoglobin ff hemoglobin fi fi heterogenous globins gh 
goal classify protein belonging globin class 
table shows novel architecture svm beats existing architecture literature svm classification tasks ties svm loses 
cat cortex protein data reg 
ss fl reg 
gh size svm svm svm svm svm svm table mean misclassifications cat cortex protein data sets svm svm range regularization parameters indicated column labeled reg 
result obtained cat cortex data leave cross validation protein data fold cross validation 
best result classification problem printed bold face 
electrostatic framework analogy svms led important ideas suggests svm methods valid kernels positive definite 
suggested novel approaches kernels perform standard methods 
demonstrated new classification technique working minkowski space data form pairwise proximities 
novel approach treats proximity matrix svm kernel gram matrix lead excellent experimental results 
argued electrostatic framework characterizes family support vector machines characterizes techniques nearest neighbor classification 
important contribution electrostatic framework encompassing variety methods lays broad space possible algorithms 
space sparsely populated barely explored 
making dimensions space explicit electrostatic framework allows easily explore space discover novel algorithms 
history machine learning general frameworks led important advances field 
burges 
tutorial support vector machines pattern recognition 
data mining knowledge 
graepel herbrich smola bartlett 
obermayer williamson 
classification proximity data lp machines 
proceedings ninth international conference artificial neural networks pages 
hochreiter mozer 
coulomb classifiers reinterpreting svms electrostatic systems 
technical report cu cs department computer science university colorado boulder 
buhmann 
pairwise data clustering deterministic annealing 
ieee trans 
pattern anal 
mach 
intelligence 
kantorovich livshits :10.1.1.130.3511
electrostatic energy calculation interpretation scanning probe microscopy experiments 
journal physics condensed matter 
mercer 
functions positive negative type connection theory integral equations 
philosophical transactions royal society london 
tsch onoda 

soft margins adaboost 
technical report nc tr dep 
comp 
science univ london 
salmon warren 
skeletons closet 
journal computational physics 
young :10.1.1.11.2062
analysis connectivity cat cerebral cortex 
journal neuroscience 
smola williamson bartlett 
new support vector algorithms 
neural computation 
schwartz 
principles 
dover publications ny 
mcgraw hill book 
vapnik 
nature statistical learning theory 
springer ny 
