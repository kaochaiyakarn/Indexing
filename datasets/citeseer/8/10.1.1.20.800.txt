bioinformatics motivation new method finding subtle patterns sequences introduced 
approximates multiple correlations residuals pair wise correlations learning cost number training sequences length 
method suits model splicing sites human dna reported higher order dependencies 
results computational experiments prediction accuracy model shown surpass previously reported markov models prediction acceptor sites human 
availability source code available request authors 
contact aist go jp prediction splicing sites poses challenge machine learning primary nucleotide sequences 
prediction contributes gaining biological insight splicing improves accuracy gene finder gateway virtually type sequence analysis 
types splicing junctions commonly called acceptor splice site donor splice site 
donor sites gt correspond introns acceptor sites terminals ag gt ag rule 
knowledge sites vertebrates rough consensus patterns ag donors acceptors mount 
inspired apparent consensus researchers attempted predict splicing sites weight matrices shapiro neural networks brunak markov models zhang marr salzberg 
noteworthy linear chain order markov model shows high prediction accuracy salzberg 
burge investigated dependence structure ignore exceptional splicing sites obey rule 
denote cleavage cite base bases respectively 
modeling splicing sites pairwise correlations tsuda asai vol 
pages computational biology research center national institute advanced industrial science technology aist ku tokyo japan splicing sites observations 
detail readers referred review burge 
acceptor sites residuals depend adjacent positions 
donor sites fourth residual pairs exhibit significant dependence 
training set hundreds estimate transition parameters higher order markov models 
observations concluded order markov model best method clever compromise model splicing sites 
shown donors acceptors complex dependencies residuals models consider distant correlations better learning sites 
dilemma face despite significant dependencies residual pairs splicing sites introduce complex model large high quality data set 
impediment forced researchers estimate correlations limited residual pairs 
solution proposed burge maximal dependence decomposition mdd method basically decision tree influential residuals 
branching occurs statistically significant residuals detected method suppress increase model parameters compared higher order markov models considers higher order dependencies 
mdd model showed improvement previous models accuracy appearance bayes network model cai 
bayes model obtained computing correlations residuals finding maximum spanning tree linking positions high correlations computing conditional probability linked position 
number parameters linear chain markov model 
propose bahadur expansion bahadur representation probability oxford university press distribution multiple orders correlations 
truncated second order estimate original probability distribution requiring computation order markov models 
complex model markov models parameterizes pair wise correlations 
computational experiments prediction accuracy shown surpass order markov models including bayes network variant prediction acceptor sites showing complex correlations donor sites data set 
learning cost method number examples length 
model trained faster support vector machines svms require quadratic programming problem coefficient matrix 
systems methods maximum entropy modeling denote sequence length alphabet 
case dna sequence cardinality residuals coded integers respectively 
purpose probabilistic modeling obtain underlying probability distribution sequences finite number examples durbin 
simplistic model construct empirical distribution defined denotes indicator function value equation holds 
number samples close infinity gives poor estimate typically gives sparse distribution value sequences 
usually smoothed obtain better estimate 
terms information theory smoothing amounts maximizing entropy distribution 
obtain estimate important determine far maximized 
pushing limit example ends truly randomized distribution maximum entropy 
purpose add constraints prevent entropy growing large 
typically constraints derived training samples 
probabilistic modeling technique called maximum entropy modeling mem cover thomas 
moment constraints mean correlation mem 
denote mean entropy distribution defined correlation samples alphabet letters denote sequence positions 
moments constrained coincide training samples mem formulated follows find maximizing denotes sum possible 
known optimal belongs parametric family cover thomas normalization constant determined parameters determined mean correlation satisfy constraints gives maximum entropy distribution 
parametric model distribution known boltzmann machines neural network community hertz 
exact determination words training boltzmann machine takes exponential time respect sequence length hertz 
approximation necessary obtain suboptimal acceptable solution 
bahadur expansion approximated training boltzmann machines adopt bahadur expansion probability distribution bahadur humphreys titterington losee 
aim bahadur expansion expand logarithm empirical distribution multiple orders correlations fourier transformation 
expansion truncated second order trained boltzmann machine obtained gives results practice 
section expansion briefly introduced 
theoretical details readers referred literature humphreys titterington 
simplicity assume sequence including readily coded binary sequence 
sparse coding scheme coded respectively 
denote sequence binary random variables 
expected value define consider vector space real valued functions inner product defined set functions forms orthonormal bases vector space bahadur space bahadur tells function uniquely represented choose equivalent denote set subsets indices 
note null set included 
define note denotes function 
coefficient expanded 
bahadur modeling coefficient represents followings defined 
note coefficient contribution position distribution captures distant pairwise correlations position 
coefficients include sum possible assuming efficiently computed coefficients computed similarly 
define approximated expression 
general probability distribution normalized belongs parametric family boltzmann machines 
summary truncated bahadur expansion approximation boltzmann machine learning take exponential time exact learning 
give exact maximum entropy solution remaining question accuracy demonstrate result experiments 
computational costs learning bahadur expansion coefficients computed 
computational cost sequence length number examples respectively 
note cost computing log likelihood training example costs methods follows linear chain markov model takes table 
data sets splicing sites true donors false donors true acceptors false acceptors human genie reese human asai elegans kent table 
learning results positive negative donors reese 
scores averaged trials 
window size bases including gt position exon intron boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp learning testing computing log likelihood 
bayes network model takes learning testing 
learning cost method bayes network model quadratic cost testing 
quadratic cost inevitable long pair wise correlations considered meaning computational cost optimal 
ordinary situation quadratic term tolerated relatively small experiment 
number examples large term dominates computation 
note complicated learning methods may impose larger cost 
example svm zien quadratic programming problem coefficient matrix solved learning 
implementation data set performance models donor acceptor sites tested data sets reese asai kent obtained www table 
set data randomly partitioned training data test data 
loglikelihood ratio computed different models truncated bahadur expansion bayes network linear chain markov model 
results prediction accuracies methods shown tables formatted style cai cai 
tables show percentage false positives false negatives test sequences 
test data classified log likelihood computed model threshold determined ratio false negatives training data 
data sets tables bahadur model showed better separation positive negative acceptors bayes network markov models 
results models similar 
donors bahadur model provided advantage 
investigate result absolute parameter values plotted data set asai 

derived value illustrates contribution obtained probability distribution 
bahadur modeling table 
learning results positive negative acceptors reese 
scores averaged trials 
window size bases including ag position intron exon boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp table 
learning results positive negative donors asai 
scores averaged trials 
window size bases including gt position exon intron boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp figures dark dots show high contribution probability distribution 
indicate distant pairs high contribution donor sites donor sites stronger correlation diagonal direction 
tendency contributed better performance linear chain markov model donors 
acceptors hand bahadur method scored better arrested distant correlations 
large data set tables bahadur model provided advantage 
discussion splicing site prediction experiment human data false positive rates acceptors worse donors 
relative difference agreed reported result cai error rates higher report false positive rates experiment 
error rates reduced large data set elegans high error rates probably due data selection 
clear reason splicing sites base pairs gt ag signal input learning models compare performance 
size may short especially acceptors 
reported reese acceptors better learned base pairs neural network 
long region applicable bahadur model number parameters learned determination appropriate window size learning important practical application model 
expansion strategy bahadur expansion fully exercised expand real valued function 
function defined truncated table 
learning results positive negative acceptors asai 
scores averaged trials 
window size bases including ag position intron exon boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp donor sites acceptor sites fig 

absolute parameter value illustrates contribution axis correspond indices respectively 
dotted line shows boundary residuals blank part range donors acceptors corresponds fixed residuals gt ag 
form corresponds learning boltzmann machines choices possible bahadur 
classification problems definition possibility positive sample negative sample definition results simpler expansion denote positive negative samples respectively 
prediction rates better original expansion data shown formula assign theoretical meaning boltzmann machines 
theoretical drawbacks performance guarantee approximation error truncated bahadur expansion 
experiments showed result better order markov models case complex correlations empirical performance needs theoretical confirmation 
important open problem 
second theoretical problem concerns validity computing log likelihood ratio positive negative models truncated bahadur expansion truncated result probability distribution 
bahadur modeling table 
learning results positive negative donors kent 
scores averaged trials 
window size bases including gt position exon intron boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp table 
learning results positive negative acceptors kent 
scores averaged trials 
window size bases including ag position intron exon boundary 
bahadur bayes network chain markov training true test false test true test false test true test false test fn fn fp fn fp fn fp solution problems prerequisites engineering function expansion evaluating classified results 
introduced new approximation method bahadur expansion representing multiple correlations sequences 
expansion applied real valued function showed example truncation corresponds approximated learning boltzmann machine 
theoretical background incomplete method sound models probability distribution residuals 
computational experiments splicing sites bahadur model predicted acceptors better markov models acceptors exhibited multiple correlations residuals data set 
general training data known higher order correlations little reason markov models presume correlations adjacent positions 
data provided model suitable markov models biological sequences complex correlations 
strategy similar agarwal bafna agarwal bafna respect implementation easy markov models 
model directly suggest corresponding biological mechanism locating major influential correlations learned results important step elucidation hidden mechanism splicing 
application subtle signals splicing sites adds prospect bahadur method 
acknowledgments gotoh tanaka valuable discussions 
agarwal bafna 

detecting non adjoining correlations signals dna 
proceedings nd recomb conference 
acm press pp 

asai 

recognition human genes stochastic parsing 
pacific symposium biocomputing psb 
world scientific hawaii pp 

www org 
bahadur 

representation joint distribution responses dichotomous items 
solomon ed 
studies item analysis prediction 
stanford university press pp 

brunak engelbrecht knudsen 

prediction human mrna donor acceptor sites dna sequences 
journal molecular biology 
burge 

modeling dependencies pre mrna splicing signals 
salzberg kasif eds 
computational methods molecular biology 
elsevier pp 

cai delcher kao kasif 

modeling splice sites bayes networks 
bioinformatics 
cover thomas 

elements information theory 
john wiley sons 
durbin eddy krogh mitchison 

biological sequence analysis probabilistic models proteins nucleic acids 
cambridge university press 
hertz krogh 

theory neural computation 
addison wesley 
humphreys titterington 

exploration new methods learning binary boltzmann machines 
heckerman whittaker eds 
artificial intelligence statistics 
morgan kaufmann san francisco pp 

kent 

exploring introns alternative splicing elegans 
nucleic acids research 
www cse ucsc edu kent 
losee 

term dependence truncating bahadur expansion 
information processing management 
mount 

catalogue splice junction sequences 
nucleic acids research 
reese haussler 

improved splice site detection genie 
journal computational biology 
www org seq tools datasets human 
salzberg 

method identifying splice sites translational start sites eukaryotic mrna 
comput 
appl 
biol 
sci 
shapiro 

rna splice junctions different classes sequence statistics functional implications gene expression 
nucl 
acids 
res 


current status portability sequence handling software 
nucleic acids research 
zhang marr 

weight array method splicing signal analysis 
computer applications biosciences 
zien tsch mika sch lkopf lengauer ller 

engineering support vector machine ker nels recognize translation initiation sites 
bioinformatics 
