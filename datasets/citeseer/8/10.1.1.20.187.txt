learning body pose specialized maps omer rosales department computer science boston university boston ma cs bu edu stan sclaroff department computer science boston university boston ma sclaroff cs bu edu nonlinear supervised learning model specialized mappings architecture sma described applied estimation human body pose monocular images 
sma consists specialized forward mapping functions inverse mapping function 
specialized function maps certain domains input space image features output space body pose parameters 
key algorithmic problems faced learning specialized domains mapping functions optimal way performing inference inputs knowledge inverse function 
solutions problems employ em algorithm alternating choices conditional independence assumptions 
performance approach evaluated synthetic real video sequences human motion 
everyday life humans easily estimate body part locations body pose relatively low resolution images projected world viewing photograph video 
body pose estimation difficult computer vision problem 
believed humans employ extensive prior knowledge human body structure motion task 
assuming consider computer learn underlying structure infer body pose 
computer vision task usually posed tracking problem 
typically models comprised geometric primitives designed tracking specific articulated body 
frame models fitted image optimize cost function 
careful manual placement model frame required tracking subsequent frames tends sensitive errors initialization numerical drift 
generally systems recover tracking errors middle sequence 
address weaknesses complex dynamic models proposed methods learn prior specific motion walking 
strong prior substantially limits generality motions tracked 
departing aforementioned tracking paradigm gaussian probability model learned short human motion sequences 
dynamic programming calculate best global labeling learned joint probability density function position velocity body features 
approaches joint locations correspondences model initialization provided hand 
manifold human body dynamics modeled hidden markov model learned entropic minimization 
approaches models learned 
approach model dynamics argue general human motion dynamics intended learned amount training data model complexity computational resources required impractical 
consequence models large priors specific motions walking generated 
describe non linear supervised learning algorithm specialized maps architecture sma recovering articulated body pose single monocular images 
approach avoids need initialization tracking se reduces mentioned disadvantages 
specialized maps key characteristics problem trying solve different supervised learning problems 
access inverse map 
trying learn unknown probabilistic maps inputs outputs space access map general probabilistic outputs inputs 
pose estimation problem easy see artificially computer graphics cg produce visual features body silhouettes joint positions second input associated output 
features obtained silhouettes visual features ambiguous 
consider occluded arm reflective ambiguity generated symmetric poses 
observation precludes standard algorithms supervised learning fit single mapping function data 
input output spaces inverse function describe solution supervised learning problems 
approach consists generating series functions oe functions specialized map certain inputs specialized sub domain better 
example sub domain region input space 
specialized sub domain oe general just connected region input space 
learning models similar concept fitting surfaces observed data splitting input space regions approximating simpler functions regions :10.1.1.136.9119
approaches inverse map incorporated estimation algorithm considered problem definition forward model usually complex making inference learning difficult 
key algorithmic problems estimating specialized domains functions optimal way account form specialized functions knowledge inverse function formulate efficient infer computer graphics rendering general called forward kinematics ence learning algorithms 
propose determine specialized domains functions approximate em algorithm perform inference alternating fashion conditional independence assumptions specified forward inverse models 
fig 
illustrates learned forward model 
sma diagram illustrating learned sma model specialized functions mapping subsets training data subset drawn different color initializations coloring random mean output inference process observation mapped specialized functions feedback matching step performed choose best estimates 
probabilistic model training sets output input observations psi upsilon fae ae respectively 
ae define output input training pair fz zn observed training set 
introduce unobserved random variable yn 
model domain discrete set mg labels specialized functions thought function number map data point number specialized mapping functions 
model uses parameters represents parameters mapping function represents kj prior probability mapping function label map unknown point 
example jz represents probability function number generated data point number bayes rule assuming independence observations log probability data model log want maximize arg max log jae kj ae independence assumption aej ae 
equivalent maximizing conditional likelihood model 
log sum encountered problem intractable general 
exist practical approximate optimization procedures expectation maximization em 
learning em algorithm known provide derivations specific sma 
step consists finding 
note variables assumed independent 
factorizing jae jae jae undefined 
implementation described oe ae sigma parameters th specialized function sigma error covariance specialized function way interpret choice think error cost estimating know specialized function gaussian distribution mean output specialized function covariance map dependent 
led tractable derivations 
choices 
step consists finding arg max log yj 
case show equivalent finding arg min gamma oe ae sigma gamma gamma oe gives update rules sigma lagrange multipliers incorporate constraint sum 
sigma gamma oe ae gamma oe ae keeping formulation general defined form specialized functions oe find closed form solution update depends form oe example oe non linear function may iterative optimization find case oe yield quadratic form closed form update exists 
general oe ae sigma gamma gamma oe ae experiments oe hidden layer perceptron 
step approximate iterative optimization procedure 
inference learning accomplished specialized function maps different levels accuracy input space 
formally state inference process maximum posteriori map estimation interested finding output input configuration arg max hjx arg max treatment depends properties probability distributions involved 
hjx oe sigma map estimate involves finding maximum mixture gaussians 
closed form solution exists incorporated potentially useful knowledge inverse function map inverse function access forward kinematics function called inverse function allows formulate different inference algorithm 
interested finding optimal input optimal body pose features taken image 
formulated arg max hjx arg max xjh simply bayes rule marginalizing variables note distribution xjh appear solution 
important know knowledge define distribution 
solution completely general architecture assumptions form distributions algorithms 
approximate inference assume approximate set samples generated kernel function 
denote set samples fh approximate formally built normalizing condition dh consider simple forms ffi gamma arg maxh xjh ffi gamma simple manipulations reduced equivalent discrete optimization problem goal find sample arg max xjh arg min gamma sigma gamma equivalence assumption xjh sigma 
sigma spl arg maxh xjh sigma spl 
case hard practice contrary case eq 
general guarantee optimal samples 
deterministic approximation functions mean output structure inference sma choice probabilities hjx allows construct newer approximation considerably expensive compute deterministic 
intuitively idea consists asking specialized functions oe estimate observed input opinions specialized functions evaluated distribution xjh similar sampling method 
justified observation probability mean maximal gaussian distribution 
considering means oe considering output specialized function 
course cases approximation far best solution example uncertainty function estimate relatively high relative difference means 
fig 
illustrate mean output mo approximate inference process 
generating estimate body pose denoted input gray point dark contour lower plane sma generates series output hypotheses oe fh oe obtained oe illustrated points pointed arrows 
set oe accurate hypothesis mean output criteria minimizes function arg min gamma oe sigma gamma oe equation assumed xjh gaussian 
bayesian inference note cases may need simply provide point estimate terms output fact distribution inference process 
show choices respectively obtain 
hjx sigma hjx sigma spl sigma experiments described architecture tested computer graphics rendering inverse function 
training data set consisted approx 
frames human body poses obtained motion capture 
output consisted marker positions markers projected image plane perspective model linearly encoded real values principal component analysis pca 
input visual features consisted real valued hu moments computed synthetically generated silhouettes articulated 
training testing generated data points poses motion capture projected views view sphere equator 
took training rest testing 
free parameter test related sma number specialized functions set 
model selection approaches 
due space limitations show results mean output inference algorithm readers referred cs people bu edu inference multiple samples shown 
fig 
left shows reconstruction obtained single images coming different artificial sequences 
agreement reconstruction observation easy perceive sequences 
note self occluding configurations reconstruction harder estimate close ground truth 
human intervention pose initialization required 
quantitative results fig 
right shows average marker error variance body orientation percentage body height 
note error bigger orientations closer radians 
intuitively agrees notion angles side views visibility body parts 
consider performance promising complexity task simplicity approach 
choosing poses random training set rmse body height 
related quantitative performance usually ignored part due lack ground truth standard evaluation data sets 
performance regarding camera viewpoint total viewpoint left example reconstruction test sequences cg generated silhouettes 
set consists input images reconstruction th frame 
right marker root mean square error variance camera viewpoint 
units percentage body height 
approx 
test poses 
experiments real visual cues fig 
shows examples system performance real segmented visual data obtained observing human subject 
reconstruction relatively complex sequences shown 
note characteristics segmented body differ ones training performance achieved 
reconstructions visually close thought right pose reconstruction 
body orientation generally accurate 
proposed specialized mappings architecture sma 
learning algorithm developed architecture ideas ml estimation latent variable models 
inference possibility alternatively different sets conditional independence assumptions specified forward inverse models 
incorporation inverse function model allows simpler forward models 
example inverse function architectural alternative gating networks mixture experts 
sma advantages body pose estimation include iterative methods inference reconstruction obtained observing human subject th frame 
algorithm inference runs constant time scales linearly respect number specialized functions manual initialization required compared approaches learn dynamical models requirements data smaller large priors specific motions prevented improving generalization capabilities 
brand 
shadow 
iccv 
bregler 
tracking people twists exponential maps 
cvpr 
csiszar 
information geometry alternating minimization procedures 
statistics decisions 
dempster laird rubin 
maximum likelihood estimation incomplete data 
journal royal statistical society 
deutscher blake reid 
articulated body motion capture annealed particle filtering 
cvpr 
friedman 
adaptive regression splines 
annals statistics 
hinton sallans ghahramani 
hierarchical community experts 
learning graphical models jordan editor 
howe leventon freeman 
bayesian reconstruction human motion single camera video 
nips 
isard blake 
contour tracking stochastic propagation conditional density 
eccv 
johansson 
visual perception biological motion model analysis 
perception psychophysics 
jordan jacobs 
hierarchical mixtures experts em algorithm 
neural computation 
neal hinton 
view em algorithm justifies incremental sparse variants 
learning graphical models jordan editor 
dirk ormoneit sidenbladh michael black trevor hastie 
learning tracking cyclic human motion 
nips 
vladimir pavlovi james rehg john maccormick 
learning switching linear models human motion 
nips 
kanade 
model tracking self occluding articulated objects 
iccv 
rosales sclaroff 
specialized mappings estimation body pose single image 
ieee human motion workshop 
song feng perona 
detection human motion 
cvpr 
