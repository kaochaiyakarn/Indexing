appear international journal intelligent systems special issue intelligent systems plant surveillance diagnostics plant diagnostics transient classification aladdin approach davide oecd reactor project norway fax mail computer org action taken plant example response abnormal situation reaction unsafe conditions relies ability identify state dynamics operation plant 
hundreds thousands measurements plant generally events occurring 
data measurements mapped appropriate descriptions occurring event cases difficult task 
real time history scores variables displayed monitored computerized plant monitoring control systems 
simple visual inspection displayed trends generally sufficient allow operator confirm plant status normal steady state operations plant subject deviations due anomalies faults displayed trends interacting variables difficult interpret changes subtle changes fast 
describe aladdin methodology dynamic event recognition fault diagnosis combines techniques recurrent neural network ensembles wavelet line pre processing autonomous recursive task decomposition artd attempt improve practical applicability scalability type systems real processes machinery 

industrial processes characterized long periods steady state operation occasional shorter periods dynamic nature correspondence normal events minor disturbances planned interruptions transitions different operation states abnormal events major disturbances actuator failures instrumentation failures second class events represents challenge possibly threat smooth safe economical operation monitored plant 
prompt detection recognition event essence performance effective informed response challenge 
common way performing event detection recognition industrial plant rely experienced operators observing current values important plant variables history trend displays plus eventual alarms generated plant monitoring system usually quickly reliably diagnose current event perform adequate correcting actions plant control system 
plant significant transience crises occurred displayed trends interacting variables alarms easily overwhelm operator 
plant variables change different rates affected varying lags difficult human operator track recognize current situation 
changes plant variables caused occurring event subtle slow cause alarm system generate alert signals abnormal situation easily overlooked operator 
cases computerized operator support system able detect classify plant changes great value 
task dynamic event recognition approached different perspectives symptom deductive inference expert systems state classification static pattern recognition transient classification dynamic pattern recognition 
approach followed described 
basic assumption transient classification approach event fault generate time unique changes monitored plant 
discrimination changes principle lead back originating event inverse mapping process 
describes set techniques developed part internationally sponsored oecd reactor project employed design transient classification 
aladdin methodology integrates techniques unified model undergone preliminary tests basis implementation complete system dedicated recognition control system anomalies nuclear power plants cars control anomaly recognition system project sponsored electric power research institute palo alto ca 
remainder organized follows 
section presents brief overview previous focusing particular applications neural networks transient classification nuclear power plants 
central sections section describe respectively recurrent neural network technology core aladdin wavelet transform extract compact features time varying signals task decomposition algorithm tackling scaling issues large diagnosis tasks 
sections includes discussion test results substantiate effectiveness introduced techniques 
section concludes summary discussion current open issues 

previous approaches event recognition neural networks artificial neural networks anns particularly suited deal problem event recognition dynamic processes reasons general neural networks see 
anns approximate behaved function arbitrary accuracy essential advantage methods linear regression problem hand presents essential non linearities 
biggest advantage anns manifests dealing hard problems case significantly overlapping patterns high background noise dynamically changing environments absence accurate fast principles models 
focusing applications nuclear field note possibly demonstrate feasibility anns bartlett 
developed enhanced introducing modular ann architecture 
important contribution bartal recognized necessity classifier able provide don know answer transient kind contained accumulated knowledge base 
alternative way dealing temporal data implicit time measure proposed jeong 
authors proposed adaptive template matching algorithm allows describe transients dimensional continuum time severity level 
transient detection nuclear power plants include authors set specialized neural networks independently identify selected transient 
attempts published borrow techniques developed speech recognition tasks 
particularly mention dynamic time warping see application batch processes application knowledge discovery time series databases hidden markov models 

recurrent neural networks ensembles recurrent anns class anns able deal temporal input signals internal architecture recurrent feedback connections neurons 
elman recurrent network supervised ann partially recurrent architecture neurons feedback connections main characteristic array neurons record internal status network 
time step internal status fed back additional input network computes new status output vector 
advantage recurrent model discriminate event classes differences time evolution recognize events slightly different time scales compensate faster slower instances event class 
advantage comes architectural simplicity elman model compared models time delays simple time windowing speed consequent suitability real time environment 
comparative study alternative neural network designs models state transient classification 
main approaches investigated fuzzy clustering radial basis function rbf neural networks fuzzy clustering cascaded rbf neural networks self organizing map som neural networks recurrent neural networks 
main evaluation criteria adopted classification accuracy reliability correct recognition unknown event robustness noise changing initial conditions real time performance 
comparison performed small set simulated events nuclear power plant abb boiling water reactor sweden 
elman recurrent ann model came best performing model providing best accuracy results 
recurrent anns known hard train especially temporal relationships modelled span relatively long intervals 
case training problems encountered events classified generate transients relatively long similar stabilisation phases discriminating information coming early transients 
transients consideration showed behaviour simple solution cut tails transients train recurrent network relevant initial sections 
different transients relevant sections differently distributed time training problems difficult avoid 
different kind problem encountered recurrent neural network module concerns stability models generated 
observed phenomenon different runs training procedure led times models differing performance test transients 
direct expected consequence training procedures neural networks employ 
training session starts randomly initialised neural network proceeds gradient descent algorithm tries minimise classification error network training transients 
gradient descent algorithms get trapped local minima error surface 
different training sessions starting different points error surface reach different minima produce models differing performance test transients 
kind problem long term temporal dependencies approached extracting compact features long transient wavelets described detail section 
second kind problem problem local minima approached introducing ensembles neural networks 
neural network ensembles researchers field machine learning investigated proposed various techniques combining predictions multiple classifiers produce single classifier :10.1.1.32.9399
resulting model referred ensemble generally accurate original classifiers tends robust overfitting phenomena avoids instability problems associated local minima mentioned earlier 
ensemble classifier generally trained separately predicted output classifier combined produce output ensemble 
combining output classifiers useful disagreement 
obviously combination identical classifiers produces gain 
demonstrated ideal ensemble consists highly correct classifiers disagree possible effective combining scheme simply average predictions classifier 
result methods creating ensembles centre producing classifiers disagree predictions 
neural network techniques employed include methods training different topologies different initial weights different parameters different training sets 
aladdin adopt bagging method tries generate disagreement classifiers altering training set classifier sees training 
bagging ensemble method creates individuals ensemble training classifier random sampling training set forming final classification gives equal weight classifiers 
tests prototype system ensembles recurrent anns reported carried simulated data french pwr nuclear power plant transients corresponding various occurrences anomalous rapid load rejection events plant including particular malfunctions plant systems instrumentation actuators closed loop control systems 
cea france cooperation edf de france provided data 
transients initiated rapid closure main steam admission valves turbine electrical accident grid 
secondary power drops rapidly seconds 
primary temperature control reacts rapid decrease secondary power consumption inserting control rods fast possible 
reaction time slow compared decrease secondary power order minutes 
compensation temporary power resulting ensured opening steam dump valves actuated automatic control secondary steam pressure 
primary power sufficiently decreased restore primary secondary power balance steam dump valves return closed position ones 
final stable state obtained highly sensitive relative dynamic behaviour primary secondary power controls 
data provided cea consisted anomalous plus normal case 
transients training aladdin 
additionally blind test transients provided amplitudes failures differing transients training assess robustness sensitivity system 
anomalies involved component failures pumps control function failures sensor failures 
system behaved correctly classifying transients cases test case anomaly size significantly smaller training case 
completeness similar tests performed neural models described rbf classifier cascade rbf classifier som classifier 
results obtained line ones case study data confirming superior performance recurrent anns 

wavelet line pre processing order tackle long term temporal dependencies recurrent anns proposed features extracted windowed wavelet decomposition 
idea combining neural networks multiscale wavelet decomposition proposed number authors 
approaches wavelets neuron activation functions preprocessing phase extraction features time series data 
approach second kind differs earlier mainly combines wavelet feature extraction recurrent nns shows promising results obtained greatly simplified wavelet feature extraction step 
simplification particularly welcome line applications high dimensional applications applications number plant variables number transient classes considerable 
scheme proposed consists extracting time basic features moving windows monitored signal recurrent nns times number inputs lower input rate 
new input signals consecutive values features extracted haar wavelet decomposition sliding window actual signal time series mean residual signal taken highest coarser scale 
minimum wavelet coefficient scales 
maximum wavelet coefficient scales 
rationale choice capture general trend signal compact way capture important discontinuities step changes spikes severely smoothed compression process 
window size selected correspond wavelet dyadic decomposition values powers consecutive windows chosen slight overlap 
haar wavelet dyadic window don need concerned edge effects 
ability continuously applying wavelet transform sliding window transform pre processing step neural network classifier named technique wavelet line preprocessing 
better see pre processing works practice show examples application actual plant signals 
upper graph figures shows points original signal data stream 
shown upper graph overlapping windows wavelet features dynamically extracted 
examples windows patterns long overlap patterns 
means new wavelet transform applied time new patterns acquired plant 
window mean residual maximum wavelet coeff 
minimum wavelet coeff 
example application plant signal lower graph figures shows output pre processing 
generates data streams original signal rate equal original sampling rate divided window slide step size case 
example original data stream samples generates data streams samples 
look detail correspondence original signal output see practice transformation produces compact significant description original signal 
see mean residual feature reflects general trend signal 
mean residual value related average signal value analysis window chosen 
technical reasons choosing 
choice went wavelet mean residual mainly consistency outputs 
shifting attention maximum minimum wavelet coefficients notice value maximum coefficient reflects negative trends step changes negative component spikes analysis window minimum coefficient reflects positive trends step changes positive component spikes 
look example third window see big increase signal value corresponds big value minimum coefficient small decrease signal value correspondence small peaks matched small value maximum coefficient 
compared data corresponding second window notice transformation maintains correct proportions registered changes 
signal decrease second window roughly double signal increase third window 
correspondingly maximum coefficient second window roughly double minimum coefficient third window 
choice window size strike balance high level transient compression greatly improves performance recurrent anns resolution sufficient discriminate event classes 
example see small peaks third window contribute single set wavelet features 
similar transient containing peak generate practically identical output 
transient correspond different event class able discriminate 
case smaller window size smaller distance peaks necessary order outputs distinguishable 
mean residual maximum wavelet coeff 
minimum wavelet coeff 
example application plant signal example shows outputs obtained plant signal 
mean residual closely follows global behaviour signal wavelet coefficients accurately capture detail behaviour analysis window 
mean residual maximum wavelet coeff 
minimum wavelet coeff 
example application plant signal example shown interesting clearly highlights ability capturing wide range behaviours 
see big drop signal window clearly recorded big maximum wavelet coefficient component window 
wavelet coefficients capture size change steepness 
seen comparing signal signal 
cases observed drop value close drop gradual case abrupt 
reflected larger value wavelet coefficient second case compared case 
time see example captures proportionally smaller features small step changes windows 
successful tests pwr data described section followed series controlled tests conducted artificially generated multivariate time series 
aim tests demonstrate ability system base classification decision range discriminating feature low frequency high frequency features early late developing features 
shows cases transient behaviour distinct variables 
variable types behaviour distinguishable amplitude step change 
second variable types behaviour distinguished presence high frequency peak transient 
third variable types behaviour differ presence small burst middle phase transient 
fourth variable types behaviour distinguishable low frequency change stage transient 
var var var var case 
basic transient behaviour cases 
case combining transients possible ways obtains prototype transients composed samples shown 
transient classes constitute challenging task transient classification system aladdin transient class classes differ single feature forcing system optimal available discriminating features seen span range characteristic behaviours 

class prototypes 
considering transients class prototypes training set test set transients classes generated random amplitude warping delay time warping noise gaussian 
introduced variation signal amplitudes transient speeds length event class 
resulting transients varied length samples 
window size chosen samples sample overlap windows resulting compressed transients dimensional samples windows 
basic recurrent nn architecture input units hidden units output classification units trained epochs 
obtained classification accuracy shown table 
seen results satisfactory correct classification rate test set misclassification classification system classify transient classified belonging class 
training test table 
classification results 
correct 
non classif 
similar test aimed investigating discriminatory power system class differences relative timing signal features case small delay onset peak carried 
transient prototypes test shown 
window size case set samples sample overlap 
obtained classification accuracy 
class class class class class relative timing discrimination test 

autonomous recursive task decomposition artd class scaling systems techniques real world problems primary concern field soft computing industries potential users soft computing solutions inevitably pose question particular technique process live expectations full blown application developed 
dimensional window obtain features variables 
soft computing computing science includes fuzzy logic neural networks genetic algorithms research 
issues scale pattern classification task transient classification generally related basic factors 
amount data 

input dimensionality 

output dimensionality 
techniques proposed commonly tackle issues 
amount data training classifier vast training time extremely long 
case proposed solutions involve form data sampling 
promising techniques data squashing 
input dimensionality large patterns classified described large amount features techniques dimensionality reduction 
range feature sub set selection algorithms basically eliminate dimensions features classical principal components analysis pca advanced techniques non linear pca independent component analysis ica data fusion techniques try apply transformation original patterns obtain new representation space 
output dimensionality large class learning problem patterns classified belong large number distinct classes fault types adopt task decomposition approach reducing size complexity classification models 
approaches proposed task decomposition achieved construction modular architecture 
done number ways manually explicitly prior knowledge see instance mechanically predetermined fashion starting learning process example decomposing class task independent class binary tasks classifier discriminates class class tasks classes paired possible combinations autonomously task decomposition carried learning process 
category find methods hierarchical mixture experts hme jordan jacobs modular approaches 
comparative study modular neural classifiers see 
algorithm proposed section falls third category characterized recursive task decomposition process bases decomposition strategy performance partially trained classifiers 
call new method autonomous recursive task decomposition artd 
artd algorithm autonomous recursive task decomposition artd algorithm hierarchical decomposition procedure class classification tasks tasks involving large number distinct pattern classes 
artd generates hierarchy classifiers recursive way decomposing task hand set sub tasks reapplying procedure turn sub task 
decision split task sub tasks analysis classification performance classifier partially trained solve original task 
artd algorithm case neural network classifiers shown equivalent versions artd algorithm types classifiers derived 
artd algorithm cn set classes defining current task net nn classifier receives patterns input outputs class 
partially train net limited number epochs limited error goal 
simulate net training patterns collect network output patterns grouped intended class membership 
create partition set classes clustering centers corresponding sets output patterns account distribution patterns dimensional space outputs step generates set superclasses 
ss 
go back step maximum number iterations reached case fully train net return fully train net return 
build new neural network inputs net outputs superclass sj 
fully train 
superclass sj containing class build new neural network inputs net output class ci sj 

apply recursively artd 
return artd algorithm generates tree structure neural classifier node 
neural classifiers receive inputs networks receive activation signal network higher layer allowed compute classification propagate activation downwards 
example tree structure shown 
nn nn nn nn 
sample artd classification tree 
join classes centers distance comparable class distance output patterns 
classification tree shows example original class task decomposed class tasks plus class tasks 
neural classifiers receive original inputs nn outputs class superclass including superclass including nn outputs class superclass including nn outputs class class nn outputs class class class 
outputs neural classifier computed minimum actual neural network output activation value output higher level network 
values leaf nodes corresponding original classes constitute final output hierarchical classifier 
application artd number test cases discussed 
order evaluate artd separate tests performed different tasks different types classifiers 
test performed aladdin applied class transient classification task 
second test performed standard feed forward neural nets applied class letter recognition database uci machine learning repository 
aladdin tests artd algorithm developed aladdin project primarily deal scaling problems encountered number faults anomalies recognized grows levels manageable single classifier 
test reported artificial dataset composed large number variate time series time dependent trajectories dimensional space belonging separate classes 
cases transient behaviour distinct variables shown 
class prototypes obtained combining transients possible ways shown 
complete dataset generated consists examples class training testing total examples 
var var case case var var var basic transient behavior cases 
class prototypes 
example generated test data sets described section random amplitude warping delay time warping noise 
resulting transient variate time series lengths varying roughly patterns 
order test artd separate versions aladdin trained class task artd artd 
refer versions flat aladdin artd aladdin 
resulting recurrent neural network classifiers shown respectively 
rnn 
class flat aladdin classifier class task particularly hard task due dynamic nature input patterns relatively large number classes 
analysis artd aladdin result shows obtained decompositions closely reflect actual class similarities 
noted example decompositions binary 
follows fact variables time series assume slightly different types behaviour 
example neural network bottom right corner specialized discrimination class class 
difference classes fact behaviour single variable behaving exactly way 
rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn rnn 
class artd aladdin classifier 
compare training time classification performance systems see artd aladdin greatly improves original flat aladdin 
hours training flat aladdin achieve rnn rnn rnn rnn rnn rnn rnn correct classification rate artd aladdin reached correct classification rate hours training reached correct classification hours 
say case artd improved aladdin training time fold comparable classification performance 
similar tests performed class task described section showed roughly fold training speed improvement 
substantiate hypothesis artd gain linear number classes 
somewhat expected complexity neural network terms number free parameters weights biases grows linearly number outputs complexity training algorithm number weights advantage training time fact networks artd aladdin trained examples corresponding classes belonging branch classification tree 
test separate test conducted class letter recognition database obtained uci machine learning repository 
task discriminate letter categories associated vectors integer attributes extracted raster scan images letters 
database composed items equally distributed capital letters english alphabet 
data test restricted samples training testing 
classifier chosen test standard layer feed forward neural network trained back propagation algorithm 
task separate versions flat artd trained class letter recognition task 
results obtained terms training time classification performance show case significant gain artd algorithm 
hours training flat reached correct classification rate 
artd reached comparable correct classification rate hours 
speed gain obtained artd case roughly fold 
case previous tests achieved correct classification rates course improved training classifiers 
objective tests compare maximum correct classification rates achievable various approaches 
objective show level training speed achieved task decomposition algorithm artd 
comments artd decomposition strategy analysis classification performance outputs partially trained classifiers 
differentiates artd previously proposed task decomposition algorithms base decomposition strategy analysis input patterns 
represents significant advantage especially cases input patterns difficult cluster case multi variate timeseries 
type task tackled aladdin 
artd shown reduce training time significantly compared non modular classifiers separate test cases 
examples improvements training time ranged fold class static pattern classification task fold class dynamic pattern classification task 
speed appears roughly exponential number classes task hand shown 
hierarchical classification structure generated artd advantages flat architecture 
hierarchical structure provides series intermediate classification results give additional information pattern analyzed 
example artd classifier fail completely classify pattern belonging specific class leaves classification tree receives definite activation able identify set classes pattern belong giving strong activation higher level hierarchy 
classification example class counted correct output greater outputs values lower half value output fix architecture recurrent neural networks aladdin having number hidden nodes double number outputs obtain network weights flat aladdin obtain total sum weights artd aladdin networks 
artd speed number classes 
artd speed advantage modular architectures ones generated artd support incremental application development ability adding new classes existing structure need re training classifier 
want add new class existing hierarchical classifier give input current classifier set examples new class analyze network activated 
examples activate slightly different paths current structure 
appropriate level new class added correspond deepest point common activation paths examples 
neural network corresponding point replaced equivalent network extra output new class trained examples new class examples classes belonging branch 
take example structure suppose examples new class activate current structure outputs corresponding nn network nn lowest node activated examples replaced new network outputs class superclass outputs nn new class trained correspondingly 
resulting structure shown modified neural network shown shaded 
advantage generating modular architecture limited incremental application development capabilities just discussed 
application maintenance task greatly simplified modularity 
nn nn nn nn 
augmented artd classification tree 
full application developed new examples currently included classes available 
inclusion new examples compiled knowledge classifier primary maintenance task 
modular architecture inclusion difficult worst case involve re training classifier augmented database examples 
modularity clearly facilitates task 
new examples certain class available modules classification path class need maintained 
important aspect application maintenance involves direct intervention classifier correct performance problems manifest completion application development 
example performance system specific classes turn completely satisfactory 
situation calls refinement classifier extended training noise distortions examples 
application developer techniques available improve performance neural network classifiers 
modular structure clear advantage situation allowing focused intervention general greater control application 
application developer decide refine training selected modules re train new settings having worry problem unwanted side effects modules classifier performing satisfactorily 
problems internal interference typical flat classifiers clearly avoided modular architecture 

described aladdin methodology dynamic event recognition fault diagnosis developed part internationally sponsored oecd reactor project 
main focus improvement practical applicability scalability type systems real processes machinery 
core focussed description principal techniques basis aladdin recurrent neural network ensembles wavelet line pre processing autonomous recursive task decomposition artd 
utility techniques terms increased applicability scalability demonstrated series experiments 
tests way confirm encouraging results reported 
surprising find greater gains artd bigger harder tasks described point task simply intractable flat classifier 
real world applications systems aladdin complex industrial plant number possible faults anomalies considered reach hundreds believe practically possible support task decomposition techniques artd 
inclusion aladdin input dimensionality reduction techniques feature selection non linear pca step construction truly scalable system 
common problem classifiers generalization examples response predictable new previously unseen type input 
case event classification occurrence new event included design classifier lead misleading classification 
previous versions aladdin problem solved validation module concept possibilistic fuzzy clustering 
main property possibilistic fuzzy clustering membership values points falling areas input space covered constructed clusters zero 
allows detect new events classify unknown system 
problem validation technique possibilistic fuzzy clustering clustering space fixed advance events need synchronized 
limits applicability method domains trigger signal available signals event transients fixed duration 
course collides current focus increased applicability led newly introduced technique 
new validation methodology necessary 
complementary strategies proposed 
hand find ways adapting old possibilistic solution new flexible framework aladdin way similar previous transient compression algorithms replaced 
hand investigate ways combining aladdin powerful classification algorithms separate validation module principles physical models ones thermal performance monitoring system tempo developed oecd reactor project 
case neural networks aladdin 
second scenario particularly attractive combine unique strengths empirical models physical models 
systems empirical modelling recognizing discriminating fault situations poor verifying diagnostic hypothesis 
contrary systems physical modelling fitting model hypothesis current plant status difficulties formulating promising hypothesis place 
usually diagnostic system physical modelling option check fault hypotheses current plant status 
techniques appear perfectly complement combination main concern aladdin diagnostic systems general 
fundamentals artificial neural networks 
mit press cambridge 
bartlett uhrig nuclear power plant status diagnostics artificial neural network 
nuclear technology pp 

basu bartlett detecting faults nuclear power plant dynamic node architecture artificial neural network 
nuclear science engineering 
bartal lin uhrig nuclear power plant transient diagnostics artificial neural networks allow don know classifications 
nuclear technology 
jeong furuta kondo identification transient nuclear power plant neural network implicit time measure 
proceedings international topical meeting computer human support systems technology methods 
american nuclear society la park il pp 

jeong furuta kondo identification transient nuclear power plant adaptive template matching neural network 
proceedings international topical meeting nuclear plant instrumentation control human machine interface technologies 
american nuclear society pp 

hines uhrig transient detection module enhance nuclear reactor operational safety 
proceedings rd ans international topical meeting nuclear plant instrumentation control human machine interface technologies washington dc 
macgregor taylor synchronization batch trajectories dynamic time warping 
aiche journal pp 

keogh eamonn pazzani scaling dynamic time warping massive datasets 
proceedings rd european conference principles practice knowledge discovery databases 
prague 
kundu chen persons transient sonar signal classification hidden markov models neural nets 
ieee journal oceanic engineering pp 

kwon kim accident identification nuclear power plants hidden markov models 
engineering applications artificial intelligence pp 

elman finding structure time 
cognitive science pp 

soft computing tools transient classification information sciences pp 
elsevier science oxford uk 
mozer induction multiscale temporal structure 
advances neural information processing systems moody hanson lippman ed pp 

morgan kaufmann 
bengio simard frasconi learning long term dependencies gradient descent difficult 
ieee transactions neural networks pp 

wolpert stacked generalization 
neural networks pp 

breiman 
bagging predictors 
machine learning pp 

freund shapire 
experiments new boosting algorithm 
machine learning proceeding th international conference icml pp 

morgan kaufmann 
krogh vedelsby 
neural network ensembles cross validation active learning 
advances neural information processing systems touretzky leen ed vol 
pp 

mit press cambridge ma 
neural ensembles event identification proceedings th ifac symposium fault detection supervision safety technical processes budapest hu pp 

multivariate temporal classification windowed wavelet decomposition recurrent neural networks proceedings rd ans international topical meeting nuclear plant instrumentation control human machine interface technologies washington dc 
chen wang yang application wavelets neural networks diagnostic system development feature extraction 
computers chemical engineering pp 

fuzzy kohonen network classification transients wavelet transform feature extraction 
information sciences pp 

bakshi empirical neural networks solution 
han eds 
intelligent systems process engineering 
academic press pp 

wang chen yang application wavelets neural networks diagnostic system development integrated framework application 
computers chemical engineering pp 

strang nguyen wavelets filter banks 
wellesley cambridge press 
cochran sampling techniques rd ed john wiley sons 
sampling design analysis duxbury press pacific grove ca 
du johnson cortes pregibon squashing files flatter proceedings th international conference knowledge discovery data mining kdd 

blum langley selection relevant features examples machine learning artificial intelligence pp 

hall multisensor data fusion proceedings ieee pp 

jenkins simplified neural network solution problem decomposition case truck backer upper ieee trans 
neural networks pp 

anand mehrotra mohan ranka efficient classification multiclass problems modular neural networks ieee trans 
neural networks pp 

lu ito task decomposition module combination class relations modular neural network pattern classification ieee trans 
neural networks pp 

jordan jacobs hierarchical mixtures experts em algorithm neural computation pp 

kamel modular neural network classifiers comparative study journal intelligent robotic systems pp 

blake merz 

uci repository machine learning databases www ics uci edu mlearn mlrepository html 
irvine ca university california department information computer science 
hierarchical clustering art neural networks world congress computational intelligence vol 
pp 
florida usa 
de gallinari cooperation neural nets task decomposition proceedings international joint conference neural networks vol 
pp 
seattle usa 
whitehead multi stage neural network classifier proceedings world congress neural networks vol 
pp 
san diego usa 
krishnapuram keller possibilistic approach clustering ieee transactions fuzzy systems 
berg optimizing nuclear steam turbine cycles data reconciliation real time optimization proceedings rd ans international topical meeting nuclear plant instrumentation control human machine interface technologies washington dc 

