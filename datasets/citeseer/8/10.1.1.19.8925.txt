paul clough robert gaizauskas scott yorick wilks results meter measuring text reuse project aim explore issues pertaining text reuse derivation especially context newspapers newswire sources 
reuse text journalists studied linguistics aware existing computational methods particular task 
investigate classi cation newspaper articles degree dependence derivation newswire source simple level scheme designed journalists 
approaches measuring text similarity considered ngram overlap greedy string tiling sentence alignment 
measured manually annotated corpus source derived news text show combined classi er features automatically selected performs best ternary classi cation achieving average measure score categories 
topic considerable theoretical practical interest reuse existing written sources creation new text 
course reusing language old stories current technologies creating copying disseminating electronic text easier take number existing text sources reuse verbatim varying degrees modi cation 
form unacceptable text reuse received considerable attention software automatic plagiarism detection see 
clough review 
benign acceptable form text reuse encountered virtually day reuse news agency text called production daily newspapers 
question just agency copy reused extent subject transformations 
existing approaches computational text analysis investigate ability classify newspapers articles categories indicating dependency agency copy 
journalistic reuse newswire process gathering editing publishing newspaper stories complex specialised task operating speci publishing constraints short deadlines prescriptive writing practice see evans limits physical size readability audience comprehension vocabulary limitations journalistic bias political newspaper house style 
reporter editor rely news agency copy basis news story verify facts assess computational linguistics acl philadelphia july pp 

proceedings th annual meeting association importance story context appearing newswire 
nature journalistic text reuse di erences arise reused news agency copy original text 
example consider simple example illustrates types rewrite occur short sentence 
rewrite slang exaggeration capture readers attention 
deletion addition indicates event occurred 
transformations observed moving news agency copy newspaper version reported summarisation community see mckeown jing 
value information news agencies supply ease text reused commercial pressures bene cial able identify news stories appearing newspapers agency copy production 
potential uses include monitoring take agency copy identifying reused stories determining customer dependency agency copy new methods charging customers amount copy reused 
large volume news agency copy output day infeasible identify quantify reuse manually automatic method required 
conceptual framework get handle measuring text reuse wehave developed classi cation scheme indicating level newspaper story derived agency copy classi cation scheme indicating level individual word sequences newspaper story derived agency copy 
framework rests intuitions trained journalists judge text reuse explicit lexical syntactic de nition reuse presuppose setting discover 
document level newspaper stories assigned possible categories coarsely re ecting text reused news agency newspaper story news agency copy provision facts 
categories indicate trained journalist identify text rewritten news agency candidate derived newspaper article 
text newspaper article rewritten news agency copy text derived news agency sources news agency source article words may occur newspaper article news agency copy topic journalist con dent news agency 
lexical word sequence level individual words phrases newspaper story classi ed express information words news agency copy paraphrases express information agency copy 
categories judgement trained journalist text appearing word word express information text paraphrased create di erent surface appearance express information text express information appearing agency copy include verbatim rewritten text di erent context 
conceptual framework constructed small annotated corpus news texts uk press association pa news agency source british daily newspapers subscribe 
meter corpus gaizauskas collection texts words carefully selected month period areas law court reporting stories stories 
texts pa copy newspapers 
texts cover di erent stories july june newspaper stories classi ed document level 
include wholly derived partially derived non derived thought pa way 
addition classi ed lexical level scheme 
approaches measuring text similarity problems computational text analysis involve measurement 
example retrieval documents ful user information need clustering documents criterion multi aligning sentences language detecting exact near duplicates documents plagiarism detection routing documents style identifying authorship attribution 
methods typically vary depending matching method exact partial degree natural language processing techniques type problem searching clustering aligning time investigate techniques space review 
concentrated just ngram overlap measures greedy string tiling sentence alignment 
rst investigated offers simplest approach problem 
second investigated successfully plagiarism detection problem super cially quite close newspapers include papers papers 
text reuse issues investigating 
alignment treating derived text translation rst intriguing idea contrasts certainly ngram approach focusing local opposed global measures similarity 
initial straightforward approach assessing reuse texts measure number shared word ngrams 
method underlies approaches copy detection including 

measure similarity settheoretic measures containment resemblance shared trigrams separate texts written independently sucient similarity indicate form copying 
treat document overlapping word sequences initially considering word types compute similarity score 
sets ngrams set theoretic containment score measure documents ngrams length words 
source text possibly derived text represented sets ngrams respectively proportion ngrams ngram containment informally containment measures number matches elements ngram sets scaled size 
words measure proportion unique grams 
score ranges indicating newspaper copy shared pa respectively 
compare texts counting ngrams low frequency particular occurring 
grams comparing shown discriminate texts written independently lexical overlap texts high 
nd repetition pa copy drastically reduces number shared hapax inhibiting classi cation derived non derived texts 
compute containment hapax hapax containment comparing words occurring newspaper grams occur grams pa copy 
containment score represents number newspaper hapax appearing 
greedy string tiling gst substring matching algorithm computes degree similarity strings example software code free text biological subsequences wise 
compared previous algorithms computing string similarity longest common subsequence levenshtein distance gst able deal transposition tokens earlier approaches transposition seen number single insertions deletions single 
gst algorithm performs matching tokens strings token stream covered length substrings called 
problem consider newspaper text maximally covered words pa copy 
match length mml avoid spurious matches tokens resulting similarity strings expressed quantitative similarity match qualitative list common substrings 
shows result gst example section 
example gst results mml stories unfold pa release copy new previous versions story pa copy newspaper text set maximal matches similarity expressed past decade various alignment algorithms suggested aligning multilingual parallel corpora wu 
algorithms map translation equivalents di erent languages 
speci case investigate alignment map derived texts parts source texts 
pa copy may subject various changes text reuse single sentence may derive parts source sentences 
strong correlations sentence length derived source sentences guaranteed 
result sentence length statistical alignment algorithms brown gale church appropriate case 
hand cognate algorithms simard melamed ecient coping change text format 
cognate approach adopted meter task 
cognates de ned pairs terms identical share stems substitutable context 
algorithm consists principal components comparison strategy scoring function 
brief comparison works follows details may 
sentence candidate derived text sentences candidate source text compared order nd best match 
sentence allowed match possibly non consecutive sentences 
candidate pair highest score see threshold accepted true alignment 
candidate sentence assumed independent 
individual sentence alignments possibility derivation estimated score ranging tween 
score re ects proportion aligned sentences newspaper text 
note may multiple sentences aligned single sentence multiple sentences may aligned sentence 
candidate derived sentence proposed set source sentence scoring function works follows 
basic measures computed pair candidate sum lengths maximum length non overlapping shared grams number matched words sharing stems gram guring number substitutable terms mainly synonyms guring 
length candidate length candidate 
scores dice score calculated follows scores re ect di erent aspects relations candidate 
proportion shared material 

proportion shared terms 
measure prefers contain terms contain additional terms 

proportion matching ngrams shared terms 
measure captures intuition sentences sharing words word sequences related 
scores weighted combined provide alignment metric ws weighted score calculated follows psd ps weighting variables determined empirically currently set 
reuse classi ers toevaluate previous approaches measuring text reuse cast problem supervised learning task 
similarity scores attributes machine learning algorithm weka software witten frank 
small number examples tenfold cross validation repeated times combined ensure approximately proportion samples class fold cross validation 
newspaper texts domain evaluation randomly permuted generate sets 
newspaper text compared pa source texts story create results form 
results ordered set create datasets approach comparison 
data rst trained naivebayes classi ers ternary classi cation task 
feature case similarity measures described section computed texts training set 
target classi cation value reuse classi cation category corpus 
naive bayes classi er success previous classi cation tasks aware naive assumptions attributes assumed independent data normally distributed 
evaluated results measure harmonic mean precision recall equal weighting 
run calculated average score classes 
average measure scores computed runs class single accuracy measure suce weka package outputs measures 
runs standard deviation scores computed class scores approaches tested statistical signi cance way analysis variance con dence level 
statistical di erences results identi ed bonferroni analysis examining results single feature classi ers trained combined classi er correlation lter approach hall smith select combination features giving highest classi cation score correlation ltering evaluates possible combinations features 
feature selection carried fold crossvalidation features folds chosen candidates 
occurred runs formed nal selection 
tried splitting training data various binary partitions wd pd vs nd training binary classi ers feature selection see binary classi cation performed 
eskin observed cascaded binary classi ers splits data may better ary classi cation problems single way classi er 
computed cascaded classi er perform best binary classi er results 
table shows results single ternary classi ers 
baseline measure prior falling classes 
gures parenthesis standard deviations scores evaluation runs 
nal row shows results combining features selected correlation lter 
table shows result training binary classi ers feature selection select discriminating features various binary splits training data 
ternary binary classi ers feature selection produced better results spss windows 
table summary classi cation results possible features exception binary classi cation pd nd 
table nd classi er results signi cantly higher baseline di erences signi cant hapax containment alignment 
highest measure class problem combined classi er signi cantly greater obtained 
notice highest wd classi cation alignment highest pd classi cation hapax containment highest nd classi cation combined features 
hapax higher results gram containment fact provides results better complex sentence alignment gst approaches 
previous research lyon wise shown derived texts distinguished trigram overlap tiling match length respectively 
table binary classi ers feature selection results run counter highest classi cation scores obtained grams mml mml length increases scores decrease 
believe results factors characteristic reuse journalism 
nd texts thematically similar events described high likelihood coincidental overlap ngrams length quoted speech 
secondly journalists rewrite rare vary source 
intended application helping pa monitor text reuse cost di erent misclassi cations equal 
classi er mistake better wd nd texts mis classi ed pd pd wd 
di erence distribution documents classes pd contains documents classi er biased class anyway required 
table shows confusion matrix combined ternary classi er 
table confusion matrix combined ternary classi er measure score low mis classi cation wd nd nd wd low misclassi cations pd note high misclassi cation pd wd nd re ecting diculty separating class 
table nd alignment selected feature binary partition data 
highest binary classi cation achieved wd nd classes alignment highest scores show wd easiest class separate 
pd class hardest isolate re ecting mis classi cations seen table 
predict cascaded binary classi er perform reason follows 
preceding discussion see wd separated accurately choose wd versus pd nd rst binary classi er 
forces second classi er pd versus nd 
results table equation compute measure stage binary classi er measure ternary classication signi cantly higher best single stage ternary classi er 
investigated context reuse news agency copy area theoretical practical interest 
conceptual framework measure reuse meter corpus constructed 
wehave results similarity scores computed gram containment greedy string tiling alignment algorithm attributes supervised learning algorithm faced task learning classify newspaper stories wholly partially non derived news agency source 
show best single feature ternary classi er uses alignment simple hapax containment measures cascaded binary classi er combination features outperform 
results lower re ect problems measuring tic reuse stemming complex editing transformations high amount verbatim text overlapping result thematic similarity expected similarity due direct indirect quotes 
relative closeness results obtained approaches considered speculate comparison method lexical similarity probably improve classi cation results 
improved performance task may possible advanced natural language processing techniques better modeling lexical variation syntactic transformation goes journalistic reuse 
results obtained strong cases wholly derived texts identi ed accuracy exploited 
summary measuring text reuse exciting new area number applications particular limited monitoring controlling copy produced newswire 
adapting gst algorithm deal simple rewrites synonym substitution observe ects rewriting nding longest common substrings 
experimenting detailed meter corpus lexical level annotations investigate gst ngrams approaches identify reuse level 
prototype browser demo gst algorithm alignment program allowing users test arbitrary text pairs similarity available continue enhanced 
authors acknowledge uk engineering physical sciences research council funding meter project gr 
mark hepple helpful comments earlier drafts 
see 
brown lai mercer 

aligning sentences parallel corpora 
pages berkeley ca usa 
clough 

plagiarism natural programming languages overview current tools technologies 
technical report cs dept computer science university uk 
eskin 

classifying text documents modular categories linguistically motivated indicators 

evans 

london 



master thesis dept english 
university birmingham 
gaizauskas foster wilks clough 

meter corpus corpus analysing journalistic text reuse 
pages 
gale church 

program aligning sentences bilingual corpus 

hall smith 

feature selection machine learning comparing correlation lter approach wrapper 
pages 
lyon malcolm dickerson 

detecting short passages similar text large document collections 
pages 
mckeown jing 

decomposition human written summary sentences 
pages 
dan melamed 

bitext maps alignment pattern recognition 
pages 
scott 

detecting measuring text reuse aligning texts 
research memorandum cs dept computer science university 
simard foster isabelle 

cognates align sentences bilingual corpora 
pages montreal canada 
wise 

yap improved detection similarities computer programs texts 
pages philadelphia usa 
witten frank 

morgan kaufmann 
wu 

alignment 
handbook natural language processing pages 
new york marcel dekker 
