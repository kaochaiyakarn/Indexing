available cms information server cms note compact muon experiment cms note mailing address cms cern ch geneva switzerland cms data grid system overview requirements koen behalf cms collaboration july document gives comprehensive overview data grid system cms intends operate december 
cms data grid system support cms production analysis seamlessly tie resources cern international cms regional centers 
document focuses relation cms software components grid software components operating inside cms data grid system 
addition document includes overview material introduce members grid projects griphyn ppdg eu datagrid cms data handling environment 
document contains snapshot taken vision cms intended software capabilities production data grid system expected scaling 
capture expected level complexity vision worked considerable detail details adjusted 
vision captured document evolve document yield current requirements grid projects cms involved customer requirements grid components created 
major cms software milestones affecting grid projects delivery baseline core software milestone december includes choice integration grid components baseline software data challenge milestone starts january milestone completion december 
data challenge includes full range distributed operations required analysis cms data realistic conditions occurring lhc operation onwards 
primary audience document participants grid projects cms involved 
division physics mathematics astronomy california institute technology contents document brief overview cms physics cms physics analysis data handling problems opportunities cms offline hardware software systems hardware systems software systems cms data grid system software components cms data grid system storage handling data product values data replication model job model job command submission interface subjob overheads weak forms equivalence datasets requirements handling platform differences security resource sharing policies interface invocation cms executables grid sites quantitative aspects product sizes processing times cms grid hardware capacity hardware failure characteristics workload characteristics parameters expected evolution parameters requirements grid projects important cms milestones division labor appendix current cms grid needs activities large scale detector simulation efforts cms software packages physics simulation detector simulation phase reconstruction analysis phase orca appendix terminology cms data terms grid terms documents may interest document computing model represents architecture system interconnected resources computing network hardware data software people 
function effectively context physics events year physicists located institutes detector physics complexity unprecedented high energy physics 
executive summary cms computing technical proposal december 
primary audience document participants grid projects griphyn ppdg eu datagrid cms involved 
parts document useful cms physicists get overview expected capabilities limitations cms data grid system 
document read comprehensive overview cms data grid system requirements guide 
dual purpose document consists self contained sections read partially order 
note computer scientists useful read section cms physics 
material section applies high energy physics experiments 
terminology section useful reading parts document 
note cms physicists section skipped reading 
useful read section grid terminology 
document uses terms different normally internally cms 
specifically acknowledgments usual cms term document object data product editorial help preparing document provided hickey stephan 
go members cms collaboration grid projects provided comments corrections background material 
particular go organizers participants chair minute takers workshop cms grid catania cms week june 
brief overview cms physics cms cms experiment high energy physics experiment located cern start data year 
cms detector general purpose detectors lhc accelerator 
designed built world wide collaboration cms collaboration currently consists scientists institutes divided countries 
track high energy particle cms detector cutout view 
proton proton collision point center detector low energy tracks curl magnetic field cms event simulation low luminosity 
energy deposits calorimeter showers operation large number particle bunches containing circulate inside lhc accelerator 
rate times second lhc accelerator lets bunches particles coming opposite directions cross inside cms detector 
bunch crossing cms detector online system event rate real time filtering event rate hz hz mb offline system data storage reconstruction physics analysis physicists users includes cms data grid system cms online offline systems environment 
detector average collisions occur opposite bunches 
collision phenomena occur single bunch crossing called event 
shows example event collision products emanating collision point 
note picture collision products complex represents lot information cms individual detector channels 
measurements event done detector elements cms detector called raw data 
size raw data single cms event varies mb 
cms high event rate events second high energy physics experiments important phenomena physicists want observe occur low probability single event 
events second selected storage analysis 
selection done fast real time filtering system 
raw detector data selected event stored set data products 
document term data product small self contained piece data 
cms terminology section data products usually called objects 
word object heavily overloaded tried avoid document 
data analysis done cms physicists working world 
mb raw event data event analyzed directly 
stored raw event number summary data products called reconstructed data products computed 
event event raw data products ra rb ra rb aodv reconstructed data products aodv aodv 
labels picture simplified approximation expected product naming scheme 
different raw reconstructed data products exist point time events 
event fixed number raw data products variable number reconstructed data products 
shows different data product values may exist moment time different events 
event reconstructed product values computed way values raw data products events 
reconstructed data products range size kb full reconstructed tracks data product kb tag data product 
collections reconstructed data products replicated widely depending needs capacities 
original raw data stay cern central tertiary storage system may replicated 
tertiary storage robotic tape store bulk storage medium dvd 
replaced tape 
due slowness random data access tape robots access raw data severely limited 
physics analysis studying momenta directions properties collision products event physicists identify particles learn exact nature particles forces involved collision 
prime objectives cms confirm existence particle called higgs origin mass framework standard model particle physics particles acquire mass interaction higgs field 
implies existence new particle higgs theory predict mass higgs 
cms optimized discover higgs full expected mass range 
predicted higgs decays immediately creation observed directly 
possible way higgs predicted decay decay charged 
way higgs analysis effort start isolating set events charged produced 
events set correspond decay higgs physics processes produce charged 
subsequent isolation steps needed background events produced decaying higgs eliminated possible 
background events identified looking observables event data non particles produced momenta particles left collision point 
background events eliminated important properties higgs determined doing statistical analysis remaining events 
data reduction factor type cms physics analysis enormous 
final event set example may contain hundreds events selected events collisions occurred year cms detector 
gives data reduction factor reduction happens online system data stored rest happens interactive way cms offline system 
physics analysis offline system iterative collaborative process subsequent versions event feature extraction algorithms event selection functions refined effects understood 
grid jobs run process compared compile run steps iterative software development 
grid job locate higgs events calculate higgs mass highly atypical final job long analysis effort 
typical job run individual physicist analysis effort run version system am developing locate higgs events create plot parameters determine properties version 
typical class grid resource usage initiated individual physicists system operators behalf larger group 
typical system operator command grid new version standard event feature extraction algorithm physics group finished run algorithm large set events store results quick access everybody group 
workload characteristics discussed section 
data handling problems opportunities nature physics analysis implies problems opportunities physics data handling systems cms data grid 
problems opportunities extensively studied rd project 
main points follows 
data volumes huge size individual data product relatively small kb mb 
workloads dominated reading 
sufficiently powerful pervasive versioning mechanism sets data product values treated read creation 
data replication tractable application areas 
stepwise refinement algorithms event selection functions leads workload profile series jobs run exactly input dataset job series containing refined version code parameter 
obvious opportunities caching type optimizations delivering input datasets subsequent jobs 
large data reduction factor important types cms physics analysis input datasets analysis efforts represent sparse subsets set events period detector running 
sparseness increases analysis effort progresses 
important consequences data handling 
particular system uses fixed partitioning data product values large files stages data needed job staging completely large files containing needed data products inefficient 
achieve desired efficiency cms workload necessary perform actions copying sparse subset data product values files new files 
foreseeable baseline approach copying operations performed manually cms users initiated cms software components 
cms offline hardware software systems place cms data grid system grid project requirements context section gives brief overview major cms hardware software systems form cms offline system 
shows relation cms offline system cms systems 
hardware systems cms offline hardware consist computer installations arranged hierarchical structure shown 
adapted 
year offline hardware consists large central computing facility cern tier regional centers tier smaller centers tier 
institute servers tier physicist desktop workstations tier 
moment writing handful sites performing cms regional center tasks 
going number deployed centers slowly increase 
section numeric details cms hardware 
data grid boundary cms hardware installations network links centers operation expected number tier centers tier centers 
scalability requirements grid components delivered cms driven data challenge milestone effort components need scale supporting hardware configuration projected capacity 
testbed configuration data challenge exploit shared resources addition cms operated tier centers 
baseline requirement cms data grid system need manage system resources tiers 
resources tiers managed data grid system 
tier site resources common cms collaboration 
tier sites assumed cms physicist trust data stored sites labeled correctly remain labeled correctly updated 
trust certified cms software installed correctly sites software reliably run produce requested result 
trust standpoint sites interchangeable cms data grid system schedulers need take trust issues account deciding tier sites 
tier sites hand dedicated users single user generally trusted specific users perform specific tasks correctly 
tier sites common resources outside scope baseline cms data grid system 
tier sites run physics analysis tools interact cms data grid system example submitting jobs exporting data 
software systems seen highest level cms experiment long data processing chain goes detector signals way plots publications 
chain static elements developed refined physicists time 
software systems involved handling chain 
important question exactly boundaries software systems lie 
document gives baseline answer boundaries cms data grid system 
cms data grid system handles middle part cms data processing chain point raw data flows online system point intermediate results small stored handled conventional tier systems 
physics data terms boundary point things tags histograms appear 
proposed boundaries limit complexity interactions need supported cms data grid system yield fairly narrow interfaces grid components system rest cms software 
main different offline software systems cms intends operate 
combine cms non cms software components 
cms data grid system support cms production analysis seamlessly tie resources tiers 
cms data grid system important system grid projects griphyn ppdg eu datagrid cms involved 
cms software systems grid technology cms data grid system contains grid components targeted grid projects cms customer 
user physics analysis tools software systems average physicist spends time interacting 
tools run tier systems installed maintained local system administrators users 
mobile computing devices forming tier run analysis tools limited functionality 
tier devices run lightweight analysis clients connect analysis servers running tier systems 
physics analysis tools interactive analysis limited amounts physics data stored locally interactive cycle times second hour range 
tools support advanced visualization gui functions 
physicists spend time interacting physics analysis tools tools physicists text editors programmers people get doing things specific way specific tool tend resist forced switch tool 
people prefer tools guis interfaces prefer command line emacs style interfaces debates tool best vigorous 
unclear moment cms physicists monolithic analysis tool single standardized set analysis tools different overlapping sets analysis tools 
baseline vision document physicists generally interact cms data grid system special purpose modules analysis tools obtaining user interface best 
modules turn interact grid standard narrow interface 
cms idle cpu scavenger grid grid software system separate data grid 
main purpose idle cpu scavenger grid idle compute power cms tier systems cms detector online compute farm 
idle compute power tiers absorbed cms cpu scavenger grid 
case underlies cms idle cpu scavenger grid absorbing idle compute power exists widely grid community expected grid software development needs done grid projects order cms successfully build deploy cpu scavenger grid system 
time writing cms deployed comprehensive idle cpu scavenger grid system tier resources 
compared cms executables running cms data grid system executables running cpu scavenger grid written demanding terms facilities offered execution platform 
particular executables terms local files require large input datasets require access grid wide metadata repositories services 
executables upgraded infrequently months distributed form self contained auto installing packages 
cms cpu scavenger grid mainly run detector simulation codes output uploaded regular intervals cms data grid system 
cpu scavenger grid able run cms detector simulation codes need powerful services offered cms data grid system execute 
cms data grid system section describes cms data grid system cms intends operate december expected scaling 
capture expected level complexity vision worked considerable detail details adjusted 
software components cms data grid system cms data grid system contains large number software components different sources 

system contains generic shelf components operating system systems internet protocol stacks 

system contains commercial software components selected cms example commercial database component 

system contains generic grid components may standardized global grid forum ggf currently produced projects globus condor 
cms data grid system relies generic grid components primary role griphyn ppdg eu datagrid develop generic grid components 

system contains data grid components produced grid projects griphyn ppdg eu datagrid cms customer 
components specifically devoted science application requirements high energy physics grid project customers 
cms produce data grid components 
noted terms manpower deliverables cms grid component implementation effort small compared efforts grid projects layer 
grid related manpower cms available devoted interacting grid projects customer identification definition testing integration deployment common data grid components grid projects 

system contains hep specific non grid software components produced hep collaborative projects 

system contains cms specific non grid software components 
important cms physics algorithms encode cms knowledge detector way physics algorithms represent hundreds man years development effort 
important component cms software framework physics algorithms run 
currently deployed cms software framework called major version called cobra 
cms software framework isolates grid components details cms physics algorithm invocation cms physics data handling 
grid components turn isolate cms software framework details grid resource management distributed job execution wide area data handling 
main focus document exact relation data grid components cms specific software components 
interfaces components discussed considerable detail 
interface calls quantitative aspects calling frequency specified 
numbers scalability requirements grid components derived 
storage handling data product values note cms objectivity db users section describes long term data handling vision things support current objectivity product 
long term vision coupled strongly current objectivity details 
mapping section current cms data handling terminology follows section current cms data handling terminology file objectivity database file zebra file data product object record cms file catalog objectivity federation catalog file boot file local area combined metadata attached catalog object persistency layer objectivity client library parts zebra library object persistency server objectivity ams server data product value physical representation value data product 
data product values stored read memory space cms executables 
cms specific architectural vision storage handling data product values 
vision illustrated 
main points follows 
data product values stored files usually related data product values single file 
single data product data product value exist files time 
reading writing data product values files handled object persistency layer inside cms grid executable 
layer part cms software framework 
inside cms data grid system time frame cms software components responsible mapping re mapping data product values files 
grid components needs aware fact files hold subsets data product values files 
grid site combines cpu power local disk storage grid site combines cpu power local disk storage cms subjob code object persistency layer unix filesystem interface disk storage data product value file data flow cms object copier code object persistency layer unix filesystem interface cms subjob code cms subjob code object persistency layer unix filesystem interface disk storage grid file replication service grid storage local cpu disk tertiary storage storage handling data product values data grid system object persistency layer lan tcp ip object persistency server unix filesystem interface data grid software components responsible wide area data handling replication terms files 
services offered grid components provide logical grid file physical grid file abstractions 
logical grid file file exists grid location independent way 
physical grid files associated physical representation stored certain location logical grid file 
grid software components provide grid wide file replica catalog service maintains mapping logical physical files 
physical files logical file necessarily identical time due lazy replication policies physical files may date representations 
cms currently uses file types store data product values production objectivity db database files produced persistency layer objectivity zebra files produced fortran zebra library type phased 
cms expects select final object persistency solution onwards past 
time lifetime experiment external developments force motivate cms change persistency solution selected 
irrespective specific implementation object persistency layer architectural choices constraints apply storage handling data product values files cms data grid system time frame starting extending past 

data product values stored logical grid files 
logical grid file contain huge number data product values 
support file sizes larger gb grid components desirable absolutely needed time frame 

choice implementation persistency layer responsible reading objects files writing objects files complete control cms software team grid projects involved impose design constraints layer 
grid components need manipulate interpret file contents 

grid components need maintain global view logical files exist physical files 

cms components call grid components create delete logical files perform widearea replication actions sets physical files 

data import export operations cms data grid outside systems happens terms logical files 

cms executable running grid site object persistency layer cms software framework implement baseline access physical grid files local grid site 
current objectivity layer provide option implementing access physical files grid sites data transport protocol inefficient wide area 
expected option remote file access production cms grid executables 

file access cms object persistency layer performed physical grid files unix filesystem interface regular posix calls 
particular grid provided file storage layer require object persistency layer linked special grid versions posix open read calls incompatible cms architectural principles cms choose commercial software components persistency layer allow re linking special open versions 
current objectivity persistency layer allow degree re linking product cms consider 

cases file access persistency layer possible 
calls done directly executable containing cms physics algorithm filesystem mounted machine runs executable 
note mounted filesystem necessarily local disk machine need larger filesystem local site local machine 
access files large filesystem local site local machine needed particular cms case doing random type access sets events size gb tb sets simply large stage local disk machine site 
second case doing file access shown rightmost part executable connects cms provided object persistency server site lan actual filesystem calls done object persistency server filesystem mounted machine persistency server runs 
cms guarantee forms access implemented equivalent options persistency layers 
short term long term cms requires forms efficiently supported grid components cms data grid system 
supporting forms efficient way acceptable constrain choices cms evolving persistency layer 

cms strategy moving code data 
time data move location code run 
preparations running cms executable site may involve creating local physical files replicating files sites efficiency reasons invoking cms object copier tool remote site copy selected data product values new smaller logical file creating physical copy new smaller file local site 
options illustrated 
foreseeable baseline approach data product level copying operations performed manually cms users initiated cms software components 
data cms executable necessarily available locally start executable 
running cms executable executable cms object persistency server executable call grid resolve logical grid file needed executable close physical grid file 
close physical file file replication operation initiated create 
cms executable idle file replicated 
expected grid components offer services reclaim idle cpu time 
stead cms responsible making performance tradeoff file file basis dynamic staging file introduces idle time cpu allocated running cms executable pre staging file known sure executable need 
cms point seek help grid projects developing heuristic stage ahead strategies hide latency dynamic staging 

cms executables different ways mapping logical grid file names names locations physical grid files 
way doing lookup grid wide file replica catalog service 
second way requires support grid software components cms file catalog 
cms file catalog special persistent data structure existing logical grid files maintained cms software components data grid system 
apart physical grid files file catalog contain specialized indexing metadata allows fast access data product values physical grid files bypassing process generating logical grid file name having mapped physical grid file 
cms file catalogs cms data grid system 
grid components cms data grid system support requirements cms file catalogs follows 
cms file catalogs contain physical file names locations grid components need update file catalogs moving deleting physical files 
constraints data grid components expressed part cms set replication consistency management policies 
policies may imply example physical grid file deleted cms grid software component needs called ensure information physical grid file location removed cms file catalogs 
policies require new physical grid file created site automatic replication cms grid software component called register presence file cms file catalogs 
cms guarantee forms obtaining name location information needed physical files implemented equivalent options persistency layers 
short term long term cms requires forms efficiently supported grid components cms data grid system 

duration cms executable accessing particular physical file file needs pinned protected moving deleting overwriting grid components 
grid components responsible maintaining pinning status physical file 
file operations initiated grid components conflict pinning status need delayed refused 
cms executables require interface create file pins inquire file pinning status 
note multiple cms executables physical file pinned time responsibility executables grid components coordinate possible update operations file 

physical files grid exist cms set replication consistency policies allow grid components garbage collectors load automatically replicate delete files 
automatic file management actions constrained file pins performing require calls cms software components cms file catalogs types metadata updated 
data replication model mentioned grid components cms data grid system provide logical physical grid file abstractions 
grid software components provide grid wide file replica catalog service maintains mapping logical physical files 
physical files logical file necessarily identical time due lazy replication policies physical files may date representations logical file 
data replication cms data grid system done file file basis terms coherent groups files called file sets 
file set set logical grid files 
single file file sets file sets overlap contained 
grid wide file set catalog service maintain information file sets exist grid 
service provided software component grid projects 
contents catalog file sets created updated cms software components interact file set catalog service 
file set entry catalog unique name assigned cms components 
apart list logical file names file set entry records cms defined consistency management policy govern replication actions file set 
examples file sets single file private files user objectivity database files containing raw data products period detector running combined database files indexing metadata needed access raw data products files files represent particular cms file catalog 
private public file sets defined 
public file sets cms production managers physics groups create metadata file set basis 
metadata searched cms physicists find file sets need 
cms grid level metadata keeping services maintaining metadata easier 
remains responsibility cms encode manage metadata cms production managers decide extent adopt common grid metadata management services 
examples operations file sets replicate contents file set grid site export contents site outside grid clone file set contents create new private copy file set new name query site replica file set replica current concept currency defined consistency management policy file set find grid sites current copy file set available local storage 
envisaged grid level file replication service perform operations ones file sets 
service perform replication actions constraints different cms defined consistency management policies 
policies quite complex encoding specific freshness constraints replicas different files set 
examples policies file set local single grid site replicated logical files set exactly physical file associated site file set consists read files files replicated order files set read write files clearly defined master site file writes done new changed files replicated sites time master site file updates done replicas particular times cms component marks set files master site stable mutually consistent 
exact policies cms needs support defined moment examples merely indicate expected level complexity till 
theory cms components define overlapping file sets file set catalog attach mutually conflicting consistency management policies responsibility cms software components ensure happens 
cms file replication policies foreseeable share common characteristics 
policies individual logical file declared read read write single defined master site responsible writing 
note master site change time 
job model physicists get done cms data grid submitting jobs 
cms grid job generally consists subjobs 
large jobs contain hundreds thousands subjobs 
subjob consists running single cms executable run time seconds hours 
executable runs unix process 
process may multi threaded general threads cpu power single cpu 
number cpus allocated subjob execution cms supplied parameters subjob 
different types subjobs 
example subjobs execute analysis code specified physicist job submitted 
execute standard physics algorithms taken software repository create new data product values potentially shared physicists 
extract selected data products large file set smaller file set 
subjobs job necessarily run security context example subjobs contain certified data extraction code certified physics algorithms run security context allows create update file sets shared grid users 
cms subjobs communicate directly interprocess communication layer mpi 
stead data passed asynchronously file sets 
subjob generally file sets input generally create update file set store output 
subjobs add new files output file sets running 
file sets job may temporary sets files existing pass data job 
job complicated acyclic data flow arrangement subjobs 
arrangement described data flow graph file sets subjobs appear alternately 
data flow arrangement inside job known grid components particular grid schedulers grid execution services correctly schedule sequence subjob execution data movement job 
subjobs may file set input 
possible subjobs subjobs potentially run concurrently data flow constraints specified job single file set joint space place output 
general requires files file set master copies site subjobs running site 
subjobs coordinate actions contents file set concurrency management services offered cms persistency layer 
physicist grid wide application metadata physics analysis tool cms data grid job cms grid job decomposition decomposed job description subjobs input output file sets data flow graph hints constraints error recovery rules output destination query estimator grid scheduler file set catalog replication policies logical file physical file catalog grid information service grid wide execution service scheduled job description subjobs mapped sites file replication actions file sets flow graph error recovery rules boundary grid site subjob subjob subjob subjob subjob creation processing single cms data grid job data grid boundary file file file file file file file file file grid file replication service grid service output delivery shows model creation processing single cms data grid job 
job created physicist physics analysis tool submitted grid 
job description passed cms grid job decomposition service grid component provided cms 
service decomposes job subjobs creates job data flow graph 
job decomposed ways decomposition service interacts catalogs grid services determine way job decomposed achieve efficiency current state grid 
resulting decomposed job description contains logical location independent specification actions performed grid execute job 
subjobs decomposed job description mapped grid site input output data handling specified terms file sets logical grid files 
job grid scheduler optimize job decomposed job description mapping subjobs specific grid sites 
grid scheduler generates necessary file replication actions ensure subjobs access physical replicas specified input output working file sets local site storage persistency layer 
note running subjobs interact grid dynamically stage additional files identities visible decomposed job description 
decomposed job description delivered query estimator computes estimate job runtime resource usage scheduled 
expected estimation cpu resource usage fairly accurate query estimator estimates subjob cpu profiles supplied decomposed job description 
estimating wallclock runtime difficult job progress meter service ability abort pending running job useful 
submitting job user may include hints grid help optimizing resource usage 
example hint jobs input data set submitted 
grid scheduler transforms decomposed job description scheduled job description passed grid wide execution service 
important part job description set error recovery rules supplied cms part decomposed job description 
rules execution service recover automatically certain classes hardware software failure 
example error recovery rule machine running subjob point data flow graph crashes automatically roll back consistent state representing state subjob started calling cms provided cleanup script name parameters 
limited operator manpower compared number hardware software components may fail cms requires grid wide execution service able support quite complex automatic error recovery strategies 
bulk cms job output remains inside grid new updated file set 
subjobs cms grid job deliver output usually form files directly physics analysis tool started job output delivery asynchronous supported grid service 
jobs users system operators submit commands grid achieve expressed job 
example command create replica file set particular location keep month 
job command submission interface submit jobs commands cms physics analysis tools usually running local workstations outside grid grid project defined job command format call grid project defined api 
job command descriptions may include large pieces data example compiled code large algorithm parameter sets 
represented names files local filesystem process doing api call 
jobs submitted may waited interactively cms tool keeping open line grid receive information progress termination 
jobs may run batch mode progress termination monitored separate tools 
subjob overheads subjobs course startup initialization overheads generally negligible size data products read subjob larger mb 
subjob granularity generally level coarse startup overheads kept relatively low 
various potential overheads subjobs read input data product values files 
complete discussion topic scope document sources 
specific considerations follow 
desirable possible store data product values files way reading product values files produces sequential access patterns disk hardware 
large size job input data sets streaming sequential nature data product value access imply memory caching product values important optimization technique cms data grid 
overheads accessing data product values mainly determined storage system hardware 
objectivity db persistency layer introduce overheads significantly different persistency layer implementations provide cross platform format compatibility 
indexing overheads find product values inside files relatively small 
weak forms equivalence datasets overestimate cost time manpower hardware resources wrong results loss credibility result false equivalences datasets 
cases cms physicists insist byte wise equality subsequently delivered datasets 
cases weak forms equivalence dataset requested delivered permissible especially weakly equivalent dataset delivered faster 
examples cases selection random initial event sets analysis effort selection sets simulated events 
research grid projects computer support data selection weak forms equivalence requested cms 
requirements handling platform differences platform combination hardware os compiler libraries execute job algorithm code 
platform differences may result small deviations job output 
cms data grid include facilities assist physicists studying handling platform differences 
particular possible constrain job scheduling way subsequent jobs guaranteed run platform 
security resource sharing policies code data cms data grid need protected unauthorized access 
main cases 
data needs protected access people outside cms collaboration 
second doing development physicist consider intermediate results private 
private data needs inaccessible degree invisible 
results published extending access permissions group people collaboration 
access logs workload statistics gathered grid scheduling monitoring need protected unauthorized access 
facilities needed ensure grid resources shared fairly 
grid schedulers implement allocation policies ensure reasonable sharing resources concurrently running jobs 
query estimation services play important role allow users avoid unintentional abuse resources 
accurate accounting resource usage needed drive social feedback loop ensures fair sharing inside cms collaboration 
moment job submission grid need implement fine grained constraints resource usage individuals active protection needed accidental intentional execution jobs commands denial service effect 
tier centers policies reserve certain local resources subset physicists cms 
interface invocation cms executables grid sites cms subjob consists running single cms executable grid site 
executable runs unix process 
process may multi threaded general threads cpu power single cpu 
number cpus allocated subjob cpu supplied parameters subjob 
cms executable incorporate user code finished seconds submission grid job command requires code 
exact way code delivered grid needs study 
options source shared library complete cms executable identifier submitted compilation service platform identifier obtain platform specific cms executable 
cms executables occasionally dump core hang terminate nonzero exit status produce unexpected error messages standard output standard error streams 
grid components invoking executables need written cope situations supporting automatic error recovery strategies giving cms grid users operators ability diagnose decide automatic strategy applies 
cms executable crashes aborted grid components grid components need run cleanup tool example delete temporary database files release temporary database locks 
prevent accidental intentional data corruption due execution code developed dynamically user physicists cms executable incorporates code needs run sandbox type environment far unix filesystem privileges concerned 
code able read modify delete files containing private unpublished data users groups see section 
code able modify delete files containing public published data 
sandbox set grid just invoking executable 
cms object persistency server grid site ability set internal sandbox file environment executable contacts obtaining necessary information grid security layers 
server full privileges files 
cms executable generally needs invoked calling cms tool sets right runtime environment executable runs executable 
cms software runtime environment remain development lifetime experiment high flexibility setting runtime environment cms executables critical 
simple case different cms executables running time cpu require different versions standard shared libraries glibc 
cms currently uses tool called create required flexibility runtime environment dynamically configuring environment variables particular library path executable invoked 
complexity cms software environment unclear replaced possible common grid job environment management tool 
current starting point requirements grid components operation cms data grid system sites obtained 
cms needs ability configure dynamically part execution environment unix kernel kernel services 
baseline runtime environment setup tool invokes executable mirror cms production software repository available locally mounted filesystem 
software repository size gb containing elements shared libraries configuration files setup scripts 
synchronization frequency mirror day 
cms grid subjobs require availability fresh mirror repository constraints expressed part job description grid scheduler needs take account mapping subjobs sites 
quantitative aspects section provides quantitative estimates data hardware jobs 
estimates form scalability requirements cms data grid system 
estimates taken estimates year 
scalability requirements grid components delivered cms driven data challenge milestone effort components need scale supporting hardware configuration projected capacity 
product sizes processing times table gives estimated sizes processing times frequently occurring data products 
see section explanation raw data products event 
data products derived directly raw data generally called esd event summary data products cms physicists obtained esd products generally called aod analysis object data products 
frequently occurring data products expected largely similar characteristics 
time needed derive table running time algorithm product output time needed process running time job product input 
cpu power needed cpu time needed product type size derive process derive process raw products event mb si esd kb si si aod kb si si table estimates cms data product sizes processing times times seconds estimated capacity single cpu si 
starting late cms expects store raw products events year 
expects run simulations events detector storing simulated event data rate events year mb storage 
see section information scale current data handling effort cms 
creation esd aod products partly chaotic activity new products computed new algorithms parameters requested time specialized physicists 
production runs highly structured data product creation efforts run system managers 
production runs system managers usually run grid jobs compute store specific esd aod products event large set 
set generally set events taken period weeks months defined subset thereof 
production runs expected significant fraction probably half grid resources year 
years faster hardware resource constraints issue chaotic activity expected take larger larger fractions 
cms grid hardware capacity cms grid hardware consist computer installations arranged hierarchical structure shown section 
shows estimates network link capacities sites 
stressed actual link capacity available cms year estimated accurately mainly uncertainties long term developments international telecom market 
baseline requirement cms data grid need manage system resources tiers 
institute servers workstations data storage processing outside grid prepare submit grid jobs 
table gives hardware capacity estimates individual tier centers 
note tape table tertiary storage medium depending technology developments 
archival storage capacity grow time order satisfy constraint raw data needs kept forever 
tier cpu capacity nr cpus active tape archival tape disk cern si tb tb tb si tb tb tb si tb tb table estimates cms hardware capacity needs taken pages estimate numbers installed cpus needed fulfill cpu capacity needs 
disk space cache active tape included disk column count disk space 
year represents full year cms detector running estimates reflect capacity needs store process full year cms data 
obtain total installed hardware capacity needs need multiplied overhead factors take account allocation inefficiencies downtime maintenance 
tier numbers table total capacity needs cms offline data processing cern hardware failure characteristics cms data grid needs provide fault tolerance services take account 
cms expects buy grid hardware described section commodity market expects operate expensive round clock service contracts 
cpu servers easily days 
disk capacity hard disks inside cpu server boxes dedicated disk servers 
disks backups high raid level 
disks days suffer failure hope data recovery 
cms expects configure operate small amount hardware high reliability availability systems round clock operator support 
systems located tier site probably tier tier sites 
grid systems store metadata catalogs transaction state 
workload characteristics multi user physics analysis workloads complicated structure 
properties workload determined major interacting factors methodology high energy physics experimental science way physicists collaborate divide need maximize utility available computing resources 
workloads mix production analysis activities 
terminology document production activity corresponds submission grid job contains thousands subjobs creates large set output files 
completion job take days months 
analysis corresponds submission grid jobs individual physicists activity chaotic production jobs generally having runtime hours 
document takes model baseline model workload needs handled efficiently cms data grid system 
statistics workload details document refers 
workload model model terms virtual data product access model terms file sets 
workload model level file sets generated extending model simulation cms mapping data products files sets 
creation extension planned activity 
noted cms understanding strategy mapping data products files evolve considerably years experience data analysis activities individual physicists 
noted workload represents lower bound number chaotic analysis jobs submitted user physicists 
section gives lower bounds values needed support high levels chaotic interactive 
project models grid workloads 
time span covered workload generator model year number physicists submitting jobs number jobs workload day average size job input set products average size job input set tb cpu capacity needed analyze requested products jobs si raw products requested jobs year esd products requested jobs year aod products requested jobs year average number times single product requested cpu capacity needed derive requested products si different data products derived event year esd products derived derived year aod products derived derived year size raw products tb year size esd products derived derived tb year size aod products derived derived tb year exact statistics workload generated workload generator adapted 
parameters section estimates parameters important grid 
parameter value expected value needs minimally supported data grid system useful cms 
second value parenthesis expected value needed support high levels chaotic individual physicists 
number users number simultaneously active users number jobs submitted day number jobs processed parallel number events visited job job turnaround time seconds tiny jobs month huge jobs seconds months data product value size kb mb byte gb data products uploaded year year frequency bulk data upload operations day day frequency upload operations single file day day number file sets serve input subjob general cms physics analysis workloads expand fill available hardware capacity 
combining estimate jobs day available capacity estimates produced 
estimates jobs fill expected available share cpu capacity expected available share local area disk capacity 
average number data products accessed job average size data set accessed job tb gb data product computed average number times accessed workload note parameters wide value distributions mere averages meaningful taken 
output workload generator obtain indication value distributions parameters 
expected evolution parameters system requirements year evolve time track predictions hardware capacity economically available year 
year year lifetime experiment required realized system capacity definitely increase exploit price performance improvements hardware 
cms increased capacity mean increased ability study physics effects increases sought 
cms grid architecture allow scaling orders magnitude year storage cpu capacity requirements 
requirements grid projects document defines current requirements grid projects cms involved customer 
noted requirements current cms vision grid system vision certainly evolve years partly result interaction grid projects 
highest level requirement simply grid projects deliver software components cms cms construction cms data grid system 
concerning grid components created grid projects delivered cms section defines requirements importantly architectural constraints components need take account 
exact specification components delivered scope document 
creation exact grid component specifications considered joint grid projects customers grid projects lead effort 
remainder section discusses number high level requirements issues 
important cms milestones major cms software milestones affecting grid projects delivery baseline core software milestone december includes choice integration grid components baseline software data challenge milestone starts january milestone completion december 
data challenge includes full range distributed operations required analysis cms data realistic conditions occurring lhc operation 
challenge necessarily require computing capacity dedicated cms common facilities prototype center cern exploited 
connection challenge grid components delivered cms need scale supporting hardware configuration projected capacity 
division labor summarizes expands division labor cms components grid components time frame discussed section 
tasks components provided grid community grid projects 
basic management access interfaces grid resources storage systems cpus network 
queuing grid jobs grid job execution management integration local site job submission sys tems 
distributed job scheduling optimize job execution efficiently allocating subjobs sites moving code data possible account factors data location site loads generating efficient data replication actions pre stage data necessary 
error recovery services job execution configured cms provided error recovery rules scripts 
resource management monitoring accounting tools services 
query estimation decomposed job description current state grid 
efficient wide area data transfer terms files 
access cms executables physical grid files site local disk systems posix calls regular unix filesystem interface 
file catalog services mapping logical physical files 
file set catalog services 
file replication services terms file sets ability implement cms configured consistency management policies 
data management services services configure maintain backups mirrors ensure long term availability integrity precious data 
resource optimization longer term data migration user hints initiated system operator commands balance resources different grid sites 
grid wide authentication authorization services security infrastructure 

tasks cms components commercial components selected cms 
physics analysis tools provide user interfaces grid services user physicists interfaces terms high level physics application semantics 
persistency layer maintains data product values files 
optimizing strategy mapping data product values files 
local remote extraction packaging data products files 
configuration management cms data products metadata 
generation maintenance configuration meta data file set creation services allow cms physicists find data need application level queries 
efficient job decomposition subjobs 
mapping application level job description grid level description containing names input output file sets 
configuration resource usage access policies 
creation error recovery rules scripts 
making tradeoff pre staging dynamic staging files initiation dynamic file staging operations cms executables 

tasks level involvement grid projects uncertain 
management operation distributed cms software repository 
creating correct runtime environment cms executables site 

tasks needed 
computer support data set selection weak forms equivalence 
appendix current cms grid needs activities preceding sections talk cms data model data analysis needs 
section discusses current near needs activities contrasts needs 
large scale detector simulation efforts currently cms performing large scale simulation efforts physics events simulated occur inside simulation cms detector 
simulation efforts support detector design design real time event filtering algorithms cms running 
simulation efforts currently order hundreds cpu years terabytes data 
simulation efforts continue grow size lifetime experiment 
simulation efforts software cms data management seen strongly intertwined complementary activities 
addition performing grid related context projects cms grid type software production simulation efforts 
examples condor managed cpu power large scale simulation efforts globus components gdmp software system developed cms currently production replicate files simulation results wide area 
cms simulation efforts currently rely large extent hand coded shell perl scripts careful manual mapping hardware resources tasks 
grid technology available cms actively looking detector simulation efforts way save manpower means allow greater scalability 
grid side cms simulation codes inside testbeds evaluate experimental grid technologies 
sense look closely exact properties cms simulation efforts differ cms data grid 
current cms simulation runs batch nature interactive nature 
simulation run generally takes days plan people getting involved weeks execute 
tens runs progress time 
huge contrast year situation cms data processing requirements expected dominated chaotic physics analysis jobs generated hundreds physicists working independently 
contrast year workloads requests data sparse subsets simulated event datasets rare occur 
simulated event sets generated way events requested created database file set database files 
cms software packages distinct software packages currently cms detector simulation efforts described 
division corresponds phases simulation process 
physics simulation detector simulation phase fortran software takes care steps full simulation chain 
uses flat files zebra format output 
simulation run produces output file set runtime parameters 
portable run platform 
installing software major job 
phased years 
start transition oscar simulation package expected package uses date simulation codes generation physics simulation library cms object persistency layer currently objectivity data storage 
reconstruction analysis phase orca second phase full simulation chain simulated detector output constructed processed analyzed output real cms detector 
major part processing called reconstruction done orca package 
orca desktop analysis tools analyze relatively small datasets created orca desktop activities outside scope document 
orca data storage done cms object persistency layer currently objectivity database system 
step orca fz format output files read contents stored objects database 
compared inside orca complicated pattern data handling intermediate products appear 
orca software rapid development cycles months 
orca supported linux solaris currently takes considerable effort expertise install 
automated installation procedures underway 
details orca 
appendix terminology document self contained terminology defined 
cms data terms section defines cms data related terms document 
terms appear cms high energy physics documents 
documents may terms slightly different ways 
object 
smallest unit data cms referred object 
objects persistent pieces data storage 
atomic containers objects called objects 
document term data product stead object word object loaded 
event 
context storage analysis cms detector data event defined collision phenomena occur single bunch crossing 
event particular piece data database distinct real world phenomenon measured cms detector data kept database 
contexts particular detector simulations event single individual collision bunch crossing 
event id event id small piece data uniquely identifies particular event 
cms decided data type event ids 
document integers 
production cms system bit encoding numbers 
event data 
piece event data event chunk data object data product describes aspect event raw data raw object 
raw data type event data 
raw data event consists mea event detector occurrence event 
current cms data model raw data consists fixed set persistent objects called raw objects 
raw objects contains set binary readout channel values encoded zero suppression 
raw objects necessarily stored object database conceivable type data streaming binary files 
simulated data 
event data created simulations collisions inside cms detector 
simulated data generally consists components monte carlo truth records exact physics processes simulated simulated raw data records simulated detector response format similar equal real raw data format 
estimated size full simulation event mb simulated data 
fast simulation codes may produce smaller amounts data event different types studies 
reconstructed data reconstructed object reconstruction algorithm 
reconstructed data type event data 
reconstructed data event consists reconstructed objects describe event reconstructed object computed reconstruction algorithm takes input set simulated raw objects reconstructed objects belonging event 
reconstruction algorithm takes parameters influence functioning 
grid terms complete explanations grid see 
self containment document section briefly describes grid terms grid projects 
grid 
description grid adapted 
term grid coined mid denote proposed distributed computing infrastructure advanced science engineering 
real specific problem underlies grid concept coordinated resource sharing problem solving dynamic multi institutional virtual organizations 
sharing concerned primarily file exchange direct access computers software data resources required range collaborative problem solving resource brokering strategies emerging industry science engineering 
sharing necessarily highly controlled resource providers consumers defining clearly carefully just shared allowed share conditions sharing occurs 
set individuals institutions defined sharing rules form call virtual organization vo 
data grid 
original grid concept focused primarily sharing cpu resources 
term data grid created denote grid system additional strong emphasis sharing large amounts data data storage resources 
documents may interest documents contain important material hardware size details workload details covered sketchy way document 
documents combined document get complete picture cms data grid system 
documents may interest 
cms computing technical proposal written source overview material 
sources material cms physics software requirements longer version section document details hep data access patterns optimization document wide area issues scope 
estimates cms networking 
information lhc computing estimates 
www griphyn org www ppdg net www eu datagrid org cern ch foster kesselman tuecke 
anatomy grid enabling scalable virtual organizations 
published intl 
supercomputer applications 
available www globus org research papers html anatomy cafe group 
requirements physics analysis process software architecture 
cafe web cern ch cafe report steering group lhc computing review 
cern cern february 
available lhc computing review public web cern ch lhc computing review public cms collaboration 
cms computing technical proposal 
cern 
december 
orca tutorial 
cern ch orca 
cms world wide computing 
reported comprehensive review cms software computing 
october 
cern 
cern ch cms software reviews review oct project web page 
web cern ch prototyping cms storage management ph thesis eindhoven university technology may 
see home cern ch link pdf version 
ian 
cms interim memorandum understanding costs calculated 
cms note 
koen 
model virtual data grid application 
proc 
europe amsterdam springer lncs 
cms conference report 
web site home cern ch clustering reclustering hep data object databases proc 
chep chicago usa 
home cern ch chep art web html stockinger 
building large location table find replicas physics objects 
chep padova 
home cern ch long ps chep pd infn abst abs htm van der 
automatic reclustering objects large databases high energy physics proc 
ideas cardiff uk ieee 
home cern ch ideas ideas html gdmp project web page 
cern ch cms grid samar heinz stockinger 
grid data management pilot gdmp tool wide area replication 
iasted international conference applied informatics ai innsbruck austria february 
heinz stockinger samar bill allcock ian foster koen brian tierney 
file object replication data grids appear th ieee symposium high performance distributed computing hpdc san francisco california august 
van der 
mass storage systems object granularity 
proceedings eighth nasa goddard conference mass storage systems technologies maryland usa march 
home cern ch mss ps object database mass storage system physics analysis 
cern rd collaboration april 
julian harvey newman richard wilkinson 
final report globally interconnected object databases project 
october 
caltech edu pubs publications html david 
design implementation deployment functional prototype oo reconstruction software cms 
orca project 
chep padova 
chep pd infn abst abs htm 
reclustering high energy physics data 
proceedings ssdbm cleveland ohio july 

persistent atlas data structures reclustering event data 
ph thesis geneva september 
shoshani bernardo rotem sim 
multidimensional indexing query coordination tertiary storage management 
proceedings ssdbm cleveland ohio july 

developing scalable high performance terabyte distributed databases 
proceedings chep chicago usa 
cern ch cms production www html general index html cern ch asd rd index html www globus org www cs wisc edu condor cern ch cgi cmc cern ch asd html web cern ch 
