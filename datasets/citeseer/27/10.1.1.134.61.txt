bayesian graphical models adaptive filtering yi zhang september language technologies institute school computer science carnegie mellon university pittsburgh pa thesis committee jamie callan chair carnegie mellon university jaime carbonell carnegie mellon university thomas minka microsoft research cambridge stephen robertson microsoft research cambridge yiming yang carnegie mellon university copyright yi zhang personal information filtering system monitors incoming document stream find documents match information needs specified user profiles 
challenging aspect adaptive filtering develop system learn user profiles efficiently effectively limited user supervision 
order overcome challenge system needs robust learning algorithm reasonably amount training data small effective training data explore user likes satisfying user immediate information need trade exploration exploitation consider aspects document relevance novelty readability authority multiple forms evidence user context implicit feedback user interacting user handle various scenarios missing data operational environment robustly 
dissertation uses bayesian graphical modelling approach unified framework filtering 
customize framework filtering domain develop set solutions enable build filtering system desired characteristics principled way 
evaluate justify solutions large diverse set standard new adaptive filtering test collections 
firstly develop novel technique incorporate ir expert heuristic algorithm bayesian prior machine learning classifier improve robustness filtering system 
secondly derive novel model quality measure uncertainty model parameters trade exploration exploitation active learning 
thirdly carry user study real web personal news filtering system users 
data collected user study explore existing graphical modeling algorithms learn causal relationships multiple forms evidence improve filtering system performance evidence 
foremost advisor jamie callan support years 
jamie great advisor perfect combination technical advice research freedom 
learned conduct serious research provide realistic solutions real problems learned collaborate people share success learned improve technical speaking writing 
jamie guidance research topic research methodology life general 
am grateful members committee yiming yang jaime carbonell thomas minka stephen robertson 
proved thorough reviewers expected 
helped better focus dissertation kept accurate details 
yiming helpful time started life cmu 
provided useful general advise conduct research detailed support tdt evaluation useful feedback lr rocchio algorithm 
jaime provided concrete suggestions improve presentation dissertation numerous valuable comments technical details 
appreciate thomas minka ability understand important issues dissertation didn really understand 
am grateful steve helping design user study better positioning contribution dissertation information retrieval community identifying important issues missed 
am glad chance study language technology institute school computer science carnegie mellon university 
open friendly environment cmu wonderful place research 
benefit tremendously interactions faculty friends fellow students 
am grateful 
especially mention collins thompson peter spirtes jian zhang john lafferty zoubin ghahramani roni rosenfeld zhai fan li yoo bryan ma si luo jerry zhu thi truong ricardo silva scott fahlman zhang paul bennett isa rong yan yan liu weng keen wong andrew moore paul 
especially paul wonderful 
paul carefully papers including version dissertation helped improve presentations lot 
people outside cmu valuable discussions ideas related ii iii dissertation 
jose susan dumais valuable discussions 
diane kelly suggestions run user study 
david hull jimi shanahan david evans comments thesis proposal 
james allan supporting trip tdt workshop 
xi working developing news filtering system 
byron dom shivakumar vaithyanathan researchers collaborated ibm almaden research center iris eiron garg zhu alex jin philip william cody fun valuable intern experience 
am grateful ibm fellowship received years allowed focus research 
am grateful friends spent years pittsburgh 
particular want qin jin tao chen yan lu lv yong peng chang providing fun distractions school 
owe great deal parents gave life endless love worked hard provide opportunity receive best possible education china 
influenced desire learn love sharing optimistic attitude benefit forever 
am deeply indebted dear husband wei love encouragement tremendous support graduate study 
impossible finish years long journey 
wei gave motivation finish thesis dedicated 
wei parents iv contents filtering 
bayesian graphical models adaptive filtering 
goal dissertation overview solutions 
contributions dissertation 
outline 
literature review background knowledge adaptive filtering standards 
evaluation measures 
evaluation data sets 
existing retrieval models filtering approaches 
existing retrieval models 
existing adaptive filtering approaches 
bayesian graphical models 
bayes theorem 
graphical models 
algorithms structure learning 
algorithms probabilistic inference 
bayesian experimental design sequential decision problem 
integrating expert heuristics bayesian priors existing algorithms 
rocchio algorithm 
logistic regression 
new algorithm lr rocchio 
experimental methodology 
vi contents experimental results 
related discussion 
summary 
exploration exploitation trade bayesian active learning algorithm 
exploitation bayesian inference 
exploration bayesian active learning 
determining dissemination threshold logistic regression 
computational issues 
experimental methodology 
experimental results 
related contributions 
summary 
user study system description 
subjects 
data collected 
explicit user feedbacks 
user actions implicit feedback 
topic information 
news source information 
content document 
preliminary data analysis 
basic statistics 
correlation analysis 
user specific analysis 
comparison claypool user study 
summary 
combining multiple forms evidence graphical models understanding domain causal structure learning 
contents vii improving system performance inference algorithms 
experimental design 
experimental results discussions 
related discussion 

user specific models inference 
better models inference 
integrating novelty redundancy authority estimations graphical models 
summary 
contributions 
general contribution theoretical framework 
specific contributions 
contribution filtering 
limitation directions 
computationally efficient techniques 
user independent user specific cluster specific models 
temporal property adaptive filtering 
automatically testing assumptions 
appendix appendix terminologies 
appendix exit questionnaire 
list figures typical filtering system 
graphical model relevance filtering 
representation plate 
diagram left different representation graphical model right 
shorthand representation left means variables xt conditionally independent identically distributed 
graphical model representation logistic regression linear regression 
example directed acyclic graph nodes 
undirected graph cliques 
comparison performance individual profile logistic rocchio 
comparison performance individual profile logistic rocchio rocchio 
comparison trec participants 
su values different runs trec adaptive filtering task reported 
systems legend top bottom correspond bars left right 
results results trec participants directly comparable greater experience dataset 
provided give context results reported dissertation 
comparison performance different profile learning algorithms time trec adaptive filtering task 
average user profiles 
exploitation exploration relevance filtering 
step messages passed known nodes dt relevant estimate probabilistic distribution relevant 
estimate immediate utility 
step messages passed known nodes dt relevant unknown node estimate probabilistic distribution assuming know relevance feedback document dt 
estimate utility gain dt delivered probabilistic distribution parameter 
viii list figures ix comparison performance threshold learning algorithms time trec filtering data 
user study system structure 
structured information user feedback crawler statistics kept database 
content web page crawled saved news repository 
web interface user logs 
interface users provide explicit feedback current news story 
number classes user created 
histogram number documents users clicked evaluated class 
histogram number documents user clicked evaluated class truncated 
histogram different explicit user feedback 
means user didn provide feedback 
relevant novel recorded integers ranging 
readable authoritative recorded negative positive 
histogram milliseconds spent page 
histogram variables user likes topic 
multiple comparison average time milliseconds spent page different users 
users feedback entries included 
users spent seconds page average 
multiple comparison average number arrow usage page different users 
users feedback entries included 
multiple comparison average number arrow page different users 
users feedback entries included 
multiple comparison average user likes rating different users 
users feedback entries included 
prior knowledge temporal tier variables automatic structure learning 
prior knowledge informs learning algorithm causation indicated higher level lower level relevant direct indirect cause rss info relevant prohibited 
list figures user independent causal graphical structure learned pc algorithm 
learning algorithm begins tier prior knowledge 
causal graph means algorithm tell causes causes means algorithm problem 
problem may happen latent common cause chance pattern sample violations assumptions 
user independent causal graphical structure learned pc algorithm 
learning algorithm begins tier prior knowledge 
user independent causal graphical structure learned fci algorithm 
learning algorithm begins tier prior knowledge 
means direct indirect cause means common cause means algorithm determine arrowhead edge 
edge arrowhead directed means direct cause 
graph structure gm complete 
graphs rss info rss link host link topic info familiar topic topic dimensional vectors representing information news source topic table table 
actions dimensional vector representing user actions table 
user likes target variable system predicts 
graph structure gm causal 
graph structure gm inference 
comparison prediction power different models forms evidence ordered corre lation coefficient 
left right additional sources evidence testing 
rss info means values news source information rss info value relevance score topic info readability score 
comparison prediction power gm complete different missing evidence conditions forms evidence ordered user effort involved 
comparison prediction power different graphical models forms evidence ordered correlation coefficient 
user specific user independent models 
cluster user models 
list tables values assigned relevant non relevant documents filtering system deliver 
correspond number documents fall corresponding category 
ar br bn correspond credit penalty element category 
pc algorithm 
comparison different algorithms trec ohsumed data set 
comparison different algorithms trec reuter data set 
comparison different algorithms trec reuter data set old relevance judgments 
utilities submitted supervised adaptation topic tracking results reported nist 
cmu cmu runs 
teams submitted results runs 
comparison logistic regression lr logistic rocchio tdt multilingual data set 
pseudo code determining threshold 
comparison threshold learning algorithms trec filtering data reuter data set 
comparison bayesian active learning bayesian immediate learning user profile 
comparison threshold learning algorithms trec filtering data set ohsumed data topics 
samples class labels provided users number documents put class 
basic descriptive statistics explicit feedbacks 
rlo rup lower upper bounds confidence interval coefficient 
basic descriptive statistics user actions 
unit millisecond 
xi xii list tables basic descriptive statistics topics 
basic descriptive statistics news sources 
rss link number web pages link rss source 
host link number pages link server rss source 
basic descriptive statistics documents 
length document include html tags 
basic descriptive statistics user actions collected system 
corr correlation coefficient form evidence explicit feedback data 
correlation coefficient form evidence explicit feedback user likes user study data 
correlation coefficient explicit feedback 
values assigned documents different user likes ratings 
cor respond number documents fall corresponding category 
correspond credit penalty element category 
comparison effect adding user actions 
relevance score readability score rss info topic info actions added 
data entries missing value training testing 
corr correlation coefficient predicted value user likes model true explicit feedback provided users 
rlo rup lower upper bounds confidence interval coefficient 
comparison different models missing value cases coefficient measure 
rlo rup lower upper bounds confidence interval coefficient 
comparison different models cases utility measure 
deliver documents testing data user utility 
highest possible utility testing data 
comparing user specific models user independent model users 
corr correlation coefficient predicted value user likes model true explicit feedback provided users 
train number training documents learn model 
rlo rup lower upper bounds confidence interval coefficient 
chapter filtering agent working homeland security department wants alerted information related potential terror attacks customer call center representative wants phone routing system route customer call reporting specific product problem problem matches expertise student wants alerted fellowship financial aid opportunities appropriate circumstances financial analyst wants alerted information may affect price stock tracking 
examples user preferences comparatively stable represent long term information need information source dynamic information arrives sequentially time information needs delivered user soon possible 
traditional ad hoc search engines designed help users pull information comparatively static information source inadequate fulfill requirements tasks 
filtering system serve user better 
filtering system autonomous agent delivers information user dynamic environment 
opposed forming ranked list estimates piece information matches user needs soon information arrives pushes information user answer 
user alerted important information time 
typical information filtering system shown 
piece information document 
user information needs represented user profile 
profile contains classes stock music class corresponds information need 
user new information need sends system initial request query sample documents wants 
system initializes creates new online classifier user profile serve information need 
documents arrive system delivers documents classifier considered user 
user may read delivered documents provide explicit feedback filtering system serve users user shown 
information documents images videos 
dissertation focuses documents 
chapter 
identifying document bad 
user provides implicit feedback deleting document reading saving document 
filtering system uses user feedback accumulated time update user profile classifiers frequently 
standard ad hoc retrieval systems search engines user short queries pull information treat users query words 
users different describing information needs ad hoc queries 
information need user stable long period time filtering system environment learn user profiles called user models fair amount user feedback accumulated time 
words system serve user better learning user profiles interacting user information delivered user personalized catered individual user information needs automatically 
user interest drifts changes system adapt user new interest constantly updating user profile training data creating new classes automatically letting user create delete classes 
learning user profiles advantage filtering system major research challenge adaptive filtering research community 
common learning algorithms require significant amount training data 
real world filtering system soon user uses system amount training extremely small zero 
filtering system learn user profiles efficiently effectively limited user supervision filtering 
order solve problem system needs efficiently robust learning algorithm reasonably amount training data small effective training data explore user likes satisfying user immediate information need trade exploration exploitation consider aspects document relevance novelty readability authority multiple forms evidence user context implicit feedback user interacting user handle various scenarios missing data robustly 
bayesian graphical models adaptive filtering hypothesize bayesian graphical modelling bgm useful unified framework guide building filtering system desired characteristics principled way 
dissertation tests hypothesis studies customize bayesian graphical modelling approach filtering domain build filtering systems desired characteristics 
possible system needs working short user query positive instance 

bayesian graphical models adaptive filtering document stream delivered docs accumulated docs filtering system user profile binary classifiers learning user profile initialization typical filtering system 
request feedback bayesian graphical modeling bayesian decision theory graph theory successfully domains image modeling error correcting coding bioinformatics computer software user modeling social phenomena modeling 
theories complement combine nicely propose combine unified framework filtering task 
framework contains major components 
representation tools framework provides set representation tools enable researchers build personalized information filtering system combine multiple forms evidence relevance novelty readability authority explicit implicit feedback bayesian axiom framework maximizing expectation user defined utility function chapter 
decision criterion inference tools statistical inference algorithms introduced section tools enable estimate probability distributions achieve goal maximizing utility 
compared commonly text classification algorithms proposed framework major advantages 
goal system clearly defined broader way 
filtering systems optimize narrow definition topical relevance want optimize broader realistic set criteria expressed utility function 
utility function defined user likes document influenced relevance novelty authority readability document 
natural understand optimize utility function bayesian axiom 
second filtering system models uncertainty explicitly probabilities 
researchers information retrieval community estimate uncertainty relevance talk uncertainty user profiles 
uncertainty user profile modeled explicitly 
existing filtering systems usually point estimator parameter maximum likelihood estimation max posterior estimation predictions decisions 
bayesian framework uncertainty user profile modeled explicitly probabilistic distribution model parameters filtering system estimate user profile quality active learning distribution 
third framework helps understand causal relationships domain improve design filtering system 
example knowing user likes document may cause user spend time reading document help system designer decide collect time spent page implicit feedback 
understanding causal relationships help predict consequences intervention 
example may want know system gives document high score user rating document influenced 
representation tools especially causal structure learning algorithm help answer questions 
fourth framework enables combine prior domain knowledge heuristics training data 
prior domain knowledge heuristics important training data scarce expensive get 
bayes theorem natural encode information prior distribution parameter word relevant ambiguously narrow definition related matter hand aboutness broader definition having ability satisfy needs user 
second definition researchers usually studying dissertation refers user likes 
dissertation relevant defined definition phrase user likes second definition 

goal dissertation overview solutions estimated graph structure learning algorithms provide mechanism encode prior knowledge task causal discovery section 
fifth framework handles situations missing data naturally conditional dependencies encoded graph structure 
unpredictability user behaviors system glitches difficult collect information intends collect 
training data missing entries common real world robust system needs learn predictions partial observations 
bgm framework missing data means nodes hidden 
inference tools discussed detail section estimate conditional probability unknown nodes known 
advantages hypothesize bayesian graphical modelling unified framework guide developing filtering system desired characteristics solve limited training data problem 
goal dissertation overview solutions bayesian graphical modeling framework universal solution filtering problems 
set general tools design principles 
knowing functionalities provided tools understanding filtering problem domain important order build filtering system framework 
goal dissertation explore customize bayesian graphical models task filtering help solve limited user supervision problem limited training data 
approach take considering humans may solve filtering problem identifying desirable characteristics filtering system motivated humans developing solutions enable system behave desired tools principles provided bayesian graphical modeling framework 
humans may solve problem consulting domain experts heuristics 
motivated simple heuristic models developed ir expert influence learning statistical models bayesian prior 
second humans may active learning carefully picking right document ask user feedback answer provide valuable information 
motivated measure utility gain delivering document asking user feedback explicitly bayesian decision theory 
measure exploitation making user happy right exploration asking user feedback combined unified framework optimize user utility function 
chapter 
third humans may multiple forms evidence user context implicit user feedback learn user information needs 
motivated bayesian graphical models combine information available learn detailed data driven probabilistic user models filtering 
contributions dissertation time dissertation existing filtering works haven tried build filtering system desired characteristics general theoretical paradigm 
notion uncertainty user mentioned explicitly modelled filtering task 
thesis comprehensive study filtering problem date 
solutions developed thesis theoretical practical 
important contribution providing unified framework build filtering system principled way 
framework general powerful 
demonstrate power proposed framework dissertation presents examples develop novel techniques existing techniques build filtering system desired characteristics 
leads specific filtering solutions evaluate large diverse standard new data sets 
thesis develops constrained maximum likelihood estimation technique integrate expert heuristic algorithm machine learning algorithms 
assumption rocchio works better norm regularized logistic regression number training data small technique integrate ir expert rocchio algorithm bayesian prior logistic regression algorithm 
new algorithm works human sense uses ir expert heuristic algorithm learn user interests amount training data small gradually shifts complex learning algorithm update believes user interests training data available 
new algorithm automatically controls model complexity amount training data 
leads filtering system works robustly limited training data learns efficiently training data available 
initial query new algorithm better rocchio algorithm logistic regression algorithm comparable best official result trec adaptive filtering task better best official result trec adaptive filtering task 
initial query similar logistic regression best tdt supervised tracking task 
true initial user query provided user 

contributions dissertation thesis derives utility divergence model quality measure exploration exploitation bayesian decision theory 
leads filtering learning system active learning capacity choose deliver document user may system believes learn lot users feedback better long run 
importantly exploitation making user happy right exploration asking user feedback combined unified framework optimize user utility function 
experimental results demonstrate algorithm improve results favorable data set trec little effect unfavorable data set trec 
thesis explores integrate multiple forms evidence existing graphical modeling algorithms filtering 
importantly research goes relevance filtering considers criteria novelty authority implicit feedback documents models criteria explicitly hidden variables 
find system predict user preference better evidence relevance information 
furthermore graphical modelling approach handles problem missing data naturally efficiently 
information system tries collect system fail collect information individual case 
humans usually try guess missing information graphical models solve problem similar way estimating probabilistic distribution missing values known inference algorithms 
novel techniques context information filtering arising bayesian theory representation power graphical models 
developed filtering applied solve similar problems domains 
third demonstrates customize existing graphical modeling algorithms domain filtering leads new findings filtering problem 
technique filtering system robustly initially heuristics continue improve time training data 
second technique filtering system won aggressive exploring user characteristics conservative fear exploitation 
third technique filtering system goes relevance develop interesting detailed data driven user models handles various problems missing data operational environment robustly 
dissertation changes view filtering going relevance includes active learning novelty authority readability implicit user feedback user context 
dissertation changes way designing filtering solutions ad hoc inflexible methods principled way unified framework 
framework give better chapter 
algorithms provides guidance wide ranges problems 
general scientific way develop filtering solutions desired characteristics 
prior developing filtering systems desired characteristics 
early research unified theoretical framework solutions ad hoc 
aware considers problems unified framework 
outline dissertation organized follows 
chapter gives literature review including general evaluation schema adaptive filtering task standard evaluation data sets traditional ir models bayesian graphical models 
knowledge helps user understand remaining dissertation 
chapter describes integrate ir expert heuristic algorithm model building bayesian prior chapter describes trade exploration exploitation optimize utility active learning bayesian decision theory 
chapter describes combine multiple forms evidence including user study carried collect new evaluation data set data analysis graphical models 
chapter summarizes contributions thesis discusses limitation proposes directions 
chapter relatively self contained 
readers familiar information filtering bayesian graph ical models skip chapter 
readers interested general idea read chapter 
readers interested specific filtering techniques developed read chapter chapter chapter respectively 
parts thesis published conferences 
chapter published international acm sigir conference research development information retrieval chapter published international conference machine learning 
author researched important filtering issues graduate study 
filtering system receives user feedback documents delivered user causes sampling bias problem learning 
studied correct sampling bias learning user profile threshold 
identified importance novelty detection filtering proposed measures estimate redundancy novelty collected evaluation data set evaluated proposed measures 
exact efficient solution class commonly language models evaluated language models filtering task 
works included dissertation done proposal thesis scope dissertation 
readers interested works referred author papers information 
chapter literature review background knowledge order help readers better understand discussions chapters chapter provides necessary background knowledge 
introduce standard evaluation measures eval uation data sets evaluate proposed solutions section 
introduce existing information retrieval models provide theoretical motivation thesis context prior works section 
bayesian graphical modelling approach introduced help readers understand principles tools provided proposed framework solve filtering problems section 
adaptive filtering standards information filtering system monitors document stream find documents satisfy users information needs 
system filters adaptive filtering system updates knowledge user information needs frequently observations document stream periodic explicit implicit user feedback user 
major focus adaptive information filtering learn user profile 
prior area adaptive filtering 
filtering track text retrieval conference trec best known forum study adaptive filtering task important task evaluated filtering track 
chapter introduces standard evaluation measures evaluation data sets trec adaptive filtering task 
selected researchers working adaptive filtering area years benchmark performance different systems standard data sets publicly available trec nist gov reported benchmark performance experiments baselines evaluate empirical performance filtering system built bayesian graphical models 
chapter 
literature review background knowledge supervised tracking task topic detection tracking tdt workshop forum closely related information filtering 
tdt research focuses discovering topically related material streams data 
tdt different adaptive filtering aspects 
tdt topic user independent defined event activity directly related events activities 
trec style adaptive filtering information need user specific broader definition 
user information needs may topic specific subject presidential election weird stories 
tdt style topic tracking trec style adaptive filtering common especially treat topic form user information need 
study effectiveness filtering solutions developed different similar task tdt data evaluation thesis 
tdt data set introduced section 
evaluation measures text retrieval conference trec sponsored national institute standards technology nist defense advanced research projects agency darpa started held annually support research information retrieval community providing infrastructure necessary large scale evaluation text retrieval methodologies 
trec conference consists set tracks 
track area focus particular retrieval tasks defined 
filtering track 
filtering track important research task adaptive filtering task designed model text filtering process moment profile construction 
task user information need stable incoming new document stream dynamic 
user profile random sample small amount known relevant documents participating systems relevance judgments documents training set available 
new document arrives system needs decide deliver user 
document delivered user relevance judgment released system immediately simulate scenario explicit user feedback provided filtering system user 
document delivered relevance judgment released system 
system decision deliver document decision final 
strict necessary real filtering system simple reasonable implementable scenario comparison performance laboratory systems possible 
filtering track nist provides test set documents relevance judgments 
judgement filtering track run trec 
adaptive filtering standards table values assigned relevant non relevant documents filtering system deliver 
correspond number documents fall corresponding category 
ar br bn correspond credit penalty element category 
relevant non relevant delivered ar delivered br bn relevance topical relevance 
participants run filtering systems data return nist results 
different systems performance set standard filtering track evaluation data sets publicly available cross system comparison 
information retrieval community performance ad hoc retrieval system typically eval relevance recall precision certain cut ranked result 
document cut example number relevant documents top precision number relevant documents top recall relevant documents corpus cut number unknown 
order compare different algorithms specify cut mean average precision map different cut number appendix 
evaluation measures appropriate filtering 
ranking list filtering system explicit binary decision accept reject document profile 
utility function usually model user satisfaction evaluate system 
general form linear utility function trec filtering track shown 
ar br bn model corresponds assigning positive negative value element categories table correspond number documents fall corresponding category ar br bn correspond credit penalty element category 
usually ar positive negative 
assigning negative weight non relevant document delivered reasonable considering fact retrieving non relevant documents worse impact retrieving relevant ones 
bn br set zero trec avoid dominance undelivered chapter 
literature review background knowledge documents final evaluation results number undelivered documents usually extremely large user satisfaction influenced user seen 
total number relevant documents constant user profile 
non zero ar implicitly encodes influence undelivered relevant documents final evaluation measure 
trec trec trec filtering tracks utility function supervised tracking task topic detection tracking tdt utility function emphasizes recall dt utility measure directly average utilities user profiles evaluate filtering system profiles documents delivered user dominate result 
normalized version su trec su max maximum possible utility 
score simulates scenario users system performance bad 
similarly tdt track normalized version tdt utility measure 
normalized versions dt su dt nu dt dt max definitions trec 
definition tdt su evaluation measure normalized utility measure described paragraphs considers implicitly 
notice normalized version take consideration relevant documents delivered 
provides information recall system implicitly 
exactly trec thesis evaluate system filtering process 

adaptive filtering standards similar su 
major difference tdt nu tdt su profiles non relevant documents delivered user may dominate final results tdt nu measure tdt su measure 
general average user profiles evaluate filtering system view tdt micro average measures normalized utility su tdt nu tdt su macro average measures 
notice real scenario choice ar br bn depends user task 
example user reading news wireless phone may tolerance non relevant documents delivered prefer higher precision utility function larger penalty non relevant documents delivered uw user doing research certain topic may high tolerance non relevant documents delivered prefer high recall utility function penalty non relevant documents delivered monitoring potential terrorist activities missing information crucial br may big non zero negative value 
define user specific utility functions model user satisfaction evaluate filtering systems 
trec tdt benchmark results produced systems optimized different variations linear utility measures trec linear utility measure evaluate solutions dissertation 
specific utility measures different different data sets standard measure data set evaluation 
depends context 
choice evaluation measure influences decision filtering system lot optimizing measure goal system 
addition linear utility measure measures beta defined van rijsbergen det curves research community 
evaluation data sets dissertation standard new data sets test effectiveness bayesian graphical modeling approach information filtering study important aspects filtering solutions developed 
standard data sets include latest trec adaptive filtering data sets latest tdt data set 
basic information data sets provided section 
created new data set user study 
details provided section 
chapter 
literature review background knowledge trec ohsumed data ohsumed data set collection national library medicine bibliographic database 
trec filtering track 
consists derived subset journals covering years 
ohsumed queries simulate user profiles 
example user profile specification number title year old woman hormone replacement therapy description adverse effects progesterone estrogen replacement therapy relevance judgments ohsumed queries medical librarians physicians results interactive searches 
trec adaptive filtering task assumed user profile specifications arrive articles learn word occurrence statistics idf corpus statistics average document length 
participating filtering system begins profile description relevant documents zero non relevant document profile 
ohsumed profiles average number relevant articles profile testing data 
trec reuter data reuter corpus called rcv corpus provided reuter collection news stories august 
corpus trec trec filtering tracks 
trec adaptive filtering task reuter categories simulate user profiles 
documents days august august training data 
participating filtering system begins category name relevant documents zero non relevant document profile 
initial training data limited particularly representative variety large number relevant documents test data 
considered difficult data set 
average number relevant articles testing data documents profile larger standard filtering data set 
trec reuter data reuter corpus trec 
compared trec different set topics simulate user profiles 

adaptive filtering standards profiles constructed traditional trec fashion assessors nist 
example profile specification number title economic description done counter economic internationally 
relevance judgments created extensive searches multiple rounds multiple retrieval classification systems initial definition profiles 
profiles documents august september training data 
relevant documents user profile provided filtering system documents training set unlabeled 
documents september testing set 
number relevant articles testing data documents profile 
remaining profiles constructed intersections pairs reuter categories 
creation profiles experiment intersection method building profiles considerably cheaper usual assessor method 
experimental results participants indicates intersection method useful performance filtering systems differed significantly sets user profiles 
researchers think human created profiles simulate real user scenario realistic way 
intersection categories represent task similar traditional text classification task profiles dissertation focusing filtering task 
tdt multi lingual data topic detection tracking tdt darpa translingual information detection extraction summarization tides program try automatically organize news stories events discuss 
tdt includes tasks 
tdt supervised tracking task participating system topic story process incoming document stream chronological order 
story topic test pair system decision story topic relevance feedback information story may adaptation 
consider topic user profile supervised tracking task similar adaptive filtering task 
data set tdt tdt interesting data set evaluation 
corpus contains english mandarin arabic news april september 
arabic mandarin sources original language character stream english translation chapter 
literature review background knowledge produced automatically 
english translations filtering system experiments 
topics simulate user profiles 
filtering system begins labeled topic document 
compared trec adaptive filtering data sets tdt different aspects tdt system initial description topic tdt data annotation far complete 
average relevant documents profile 
formal description tdt task contains jargon 
simpler terminology section easier readers understand filtering context 
readers interested exact definition tdt data set exact definition topic tdt referred official tdt publications 
existing retrieval models filtering approaches section review existing information retrieval models information filtering 
review common filtering approaches learning user profiles explicit user feedback 
introduce existing approaches drawbacks readers get better understanding theoretical motivation thesis 
large amount literature early review concisely 
detail models readers referred 
existing retrieval models information filtering long history dating back 
created subfield general information retrieval ir field originally established solve ad hoc retrieval task 
reason early tended view filtering retrieval sides coin 
duality argument assumptions documents queries interchangeable 
dual view questioned challenging interchangeability documents queries due asymmetries representation ranking evaluation iteration history statistics 
influence retrieval models filtering large retrieval models comparatively studied tasks share common issues handle words tokens annotators fixed time allocated topic tdt 
trec annotation complete chance missing annotation trec data smaller way annotation gathered 
historically information retrieval refer ad hoc retrieval task expanded refer broader information seeking scenario includes filtering text classification question answering 

existing retrieval models filtering approaches represent document represent user query understand relevance relevance feedback 
worthwhile look various models ir relevance feedback models 
decades different retrieval models developed solve ad hoc retrieval task 
general major classes ir models boolean models boolean model simplest retrieval model concept intuitive 
drawbacks boolean model aspects users may difficulty express information needs boolean expressions retrieval system hardly rank documents matches boolean query 
boolean model widely commercial search engines simplicity efficiency 
relevance feedback user refine boolean query straightforward boolean model extended purposes 
vector space models vector space model implemented ir model built smart system 
represents documents user queries high dimensional space indexed indexing terms assumes relevance document measured similarity query high dimensional space 
vector space framework relevance feedback reformulate query vector closer relevant documents query expansion additional terms relevant documents added original query 
famous algorithm rocchio algorithm represents user query linear combination original query vector relevant documents centroid non relevant documents centroid 
major criticism vector space model performance highly depends represen tation choice representation heuristic vector space model provide theoretical framework select key terms set weights terms 
probabilistic models traditional probabilistic models binary independence model bim provide direct guidance term weighting term selection probability theory 
probabilistic models retrieval task treated category relevant vs non relevant classification problem probability relevance modelled explicitly 
rel feedback improve parameter estimation probabilistic models straightforward definition models presuppose relevance information 
decades researchers proposed ir models general explaining existing ir models 
inference networks successfully implemented inquery chapter 
literature review background knowledge retrieval system bayesian networks extend view inference networks 
models represent documents queries acyclic graphs 
unfortunately models provide sound theoretical framework learn structure graph estimate conditional probabilities defined graphs model structure parameter estimations ad hoc 
common drawback models focused relevance retrieval 
probably due task focus models proposed ad hoc retrieval nature evaluation data sets limitation computational power 
hard extend existing models model complex user scenario relevance aspect documents need consider explicit implicit relevance feedback 
common drawback estimate uncertainty relevance estimate uncertainty model 
models provide guidance solve problems exploration uncertainty model key 
third drawback provide convenient way integrate domain knowledge important building practical system 
inference networks bayesian networks potential extended avoid drawbacks model complex problems going relevance integrating domain knowledge active learning 
unfortunately researchers focused efficient algorithms simple scenarios ad hoc retrieval task due limitation computation power machines ir task hand 
researchers introduced improved models steered direction away modeling complex scenarios usually limited methods associating random variables user query terms documents 
researchers followed direction expansion relevance retrieval studied empirically theoretically 
simplification ir models reasonable early years ir community broader definition information seeking tasks 
complex ir scenarios interesting topics different training testing data sets available ir community 
addition computational power machines stronger 
researchers tried handle complex scenarios need consider multiple forms evidence retrieval 
example proposes bayesian network combine information extracted content documents terms information derived cross documents 
parameters structure network learned bayesian inference combination function manually set disjoint operation pieces evidence 
approach reasonable ad hoc scenario training data available appropriate filtering task system training data 
example linear polynomial regression models combine multiple 
existing retrieval models filtering approaches document features term frequency authorship citations 
approaches viewed special cases bayesian graphical modeling approach 
unfortunately models simplified powerful tools provided bgm discussed section ignored ir researchers 
language modeling statistical approach models document generation process active research area ir community late 
researchers tried extend model complex scenarios 
language modeling focused text document provide formal guidance model user scenarios non textual information implicit user feedback 
researchers need introduce new techniques go language modeling approach order handle complex scenarios 
summarize existing ir models inadequate modeling adaptive information filtering complex traditional ad hoc retrieval task 
existing adaptive filtering approaches early research commercial filtering systems user profile represented boolean logic 
growing computation power advance research information retrieval community years filtering systems gone simple boolean queries represent profile vector statistical distribution words 
research filtering focused learning user profile explicit user feedback likes document interacting user 
general major approaches retrieval thresholding ad hoc information retrieval extensively studied information seeking task 
typical retrieval system static information source task return ranking documents short term user request 
commonly web search engines google com lycos com altavista com examples ad hoc information retrieval systems 
influence retrieval models existing filtering systems retrieval scoring thresholding approach filtering build adaptive filtering algorithms originally designed retrieval task 
examples rocchio language models okapi pseudo relevance feedback 
filtering system uses retrieval algorithm score incoming document delivers document user score higher threshold 
setting thresholds problem retrieval task system needs return ranked list documents major research topic adaptive filtering community set dissemination thresholds 
chapter 
literature review background knowledge text classification text classification studied area similar filtering 
typical classifi cation system learns classifier labeled training data set classifies unlabeled testing documents different classes 
popular approach treat filtering text classification task defining classes relevant vs non relevant 
filtering system learns user profile classifier delivers document user classifier thinks relevant probability relevance high 
state art text classification algorithms support vector ma chine svm nearest neighbors nn neural network logistic regression winnow solve binary classification task 
ap proaches logistic regression neural network estimate probability relevance directly task setting dissemination threshold easier 
approaches focused identifying relevant documents distance measures defined document space indexed text features keywords 
simple limited view user modeling considering user context property document document authoritative novel user 
simplest filtering task hard existing filtering systems effectively 
bayesian graphical models section tutorial bayesian graphical models 
content covered 
readers familiar bayesian theory graphical modelling theory skip rest chapter 
bayesian graphical models framework bayesian axiom maximizing utility probabilistic inference tools provide general guidance goal filtering system decisions achieve goal 
enables system choose right action uncertain situations 
basic methodology underlying graphical models represent related knowledge task graph summarizes conditional independence relationships different variables 
finite mixture models factor analysis hidden markov models kalman filters hierarchical models commonly examples specific graphical models 
specific graphical model created tasks recast probabilistic inference computing conditional probability distribution values unobserved hidden nodes values observed evidence nodes 
hidden observed depends 
example train relevance model node model parameters 
bayesian graphical models graphical model relevance filtering 
hidden nodes relevant user assessment di document observed 
testing predicting document relevant node relevant hidden nodes distribution di observed 
system framework learning inference unified framework 
learning representing beliefs doing inference main goal system choose actions situations uncertainty 
example filtering system choose deliver document user 
bayesian theory says criterion maximizing expected utility decision criterion system decide action take 
estimate probability distribution variable optimize utility accordingly 
bayesian theory graph theory studied areas 
applied investigated fields computer science engineering physics neuroscience cognitive science 
published papers related section summarizes bayes theorem graph structure learning inference bayesian experimental design techniques dissertation 
important graphical field triangulation graph covered dissertation 
readers interested areas referred 
bayes theorem bayes theorem summarized simple mathematical form shown important application bayes theorem update beliefs unobservable new information 
prediction parametric inference 
ym denote people refer learning inference training testing 
chapter 
literature review background knowledge unobserved quantities xn denote observed quantities denote model parameter 
equations distribution explicitly models uncertainty model 
learn data learning system usually begins prior 
view prior belief parameters see data prior benefits aspects provides tool introducing human knowledge model building acts regularizer control model complexity avoid overfitting 
equation shows estimate posterior belief parameters seeing data cases estimating computationally expensive integration equation 
fortunately necessary 
set training data models 
goal compare different values maximize drop equation affecting final result means posterior distribution model proportional prior distribution mul data likelihood 
computationally efficient equation equation 
example formula derived equation estimate maximum posteriori map estimation estimating 
graphical models map argmax basic methodology graphical modeling represent related knowledge task graph summarizes conditional independence relationships different variables 
nodes graph random variables parameter document relevant 
missing 
bayesian graphical models arcs graph represent conditional independence variables 
graphical model includes definition graph structure collection local distributions 
graph directed bayesian networks undirected markov random fields 
dag directed acyclic graph 
focus widely dag bayesian network 
dag represented set nodes set edges graph 
represent set nodes set random variables indexed nodes graph 
refers depends context 
similarly corresponds node graph random variable indexed node 
node associated conditional probability distribution pa pa denotes parents node structure graph defines conditional independence relationships random variables 
graphical manipulation find independence relationships 
generally speaking variable independent non descendants parents 
plate represent replication graphical models 
simple graphical model illustrated xi independent xj graph represent logistic regression model xn wi logistic regression weight xi 
graph represent linear regression model xn ax ai linear regression weight xi 
exp joint probability set variables calculated product probability variable conditioned parents nodes aixi example graphical model joint probability pa chapter 
literature review background knowledge representation plate 
diagram left different representation graphical model right 
shorthand representation left means variables xt conditionally independent identically distributed 
graphical model representation logistic regression linear regression 
example directed acyclic graph nodes 
undirected graph cliques 

bayesian graphical models consider undirected graph 
represent graph corre sponding random variables edges directions 
clique fully connected subset nodes usually denoted represent collection cliques graph 
example 
undirected graph usually nonnegative potential functions conditional probability functions pa represent relationships random variables 
xc nonnegative potential function associated maximal clique joint probability variables represented graph normalized product potential functions normalization factor xc xc convert dag undirected graph treating equation special case equation 
order need force pa clique adding undirected edges parents node 
algorithms structure learning graphical model combination graph structure set local conditional probability functions potential functions 
structure learning probabilistic inference key techniques 
dissertation learn graphical models data predictions unknowns 
section section briefly cover topics 
gives bayesian network structure learning algorithms 
general major approaches learn graph structure data scoring structure learning approach algorithm assigns score likelihood training data structure candidate graph 
usually structure best score selected 
constraint structure learning approach algorithm finds constraints usu ally structure consistent constraints kept valid 
constraints au chapter 
literature review background knowledge table pc algorithm 
function derive model structure consistent data input set data set nodes graph output graphical model structure notes set adjacent nodes node number nodes set independence relationships node condition set nodes algorithm start complete undirected graph gp complete graph links removed domain experts repeat determine set exists sxy remove link graph uncoupled meeting sxy orient repeat adjacent orient directed path orient edges oriented generated algorithm person specify prior constraints domain knowledge 
graph arc node node direct cause call graph causal graph 
major goals advantages structure learning ability automatically learn causal graph encodes causal relationships variables 
help understand problem domain answer questions user liking document causes increased reading time authority page important user 
structure learning algorithms try achieve goal causal discovery directly 
new subject criticisms 
potential algorithms success domains lack causality analysis information retrieval community decided introduce important technique ir community apply task filtering thesis 
example look simple constraint causal learning algorithm section pc algorithm table 
learn causal structure pc algorithm begins complete graph removes edges 
bayesian graphical models contradict zero order conditional independence relations remove edges contradict order conditional independence relations 
algorithm finds head head links orient links producing cycles 
algorithm finds set models rejected basis data 
major step algorithm statistical tests independence relationships form data final results subject error statistical test 
algorithm computationally efficient polynomial time complexity 
assumes hidden common causes causal relationships acyclic direct causal effect variable linear distribution normal 
assumptions especially assumption hidden variables may hold real scenario 
algorithms fewer assumptions 
example fast causal inference algorithm fci handles unmeasured hidden variables 
provide extensive detailed descriptions learning structures causal meanings including hidden variables circles undirected graphs 
details causal structure discovery scope dissertation refer reader books information topic 
algorithms probabilistic inference system graphical modelling treats training testing unified framework prob inference problems 
important computation problem graphical modelling probabilistic inference computing conditional probabilities xf xe observable variables unobservable variables need estimate 
usually set variables represented graph variables 
different algorithms probabilistic inference exact algorithms sam pling algorithms variational algorithms configuration parametric approximations heuristic methods 
algorithms developed researchers working bayesian theory graph theory 
different algorithms different trade offs compu tational speed implementation complexity generality accuracy 
order statistical inference graphical model combine different algorithms 
example exact inference algorithms locally addition sampling framework 
section discusses exact inference algorithms sampling algorithms configuration approach dissertation 
large amount literature algorithms review concisely 
detail models readers refereed 
chapter 
literature review background knowledge exact inference consider graph suppose want compute marginal probability 
obtain integrating variables ma md dc mc intermediate factors mx dx defined obvious notation 
view intermediate factors messages passed variables integrated 
note elimination order important 
classical graph theoretic problem solved triangulation algorithm readers referred detail 
problem np hard arbitrary graph exact inference simple graph structure trees exhibit complexity calculating marginals 
step computationally expensive integration involved 
fortunately computation affordable certain simple graphical models 
example integration reduced simple form gaussian networks 
certain complex graphical models approximation algorithms configuration sampling algorithms variational methods parametric approximation heuristic methods discussed 
configuration doing exact inference get marginal probability integrating unobserved variables 
view intermediate factors ma md mc equation messages passed variables integrated averaging possible configurations variables 
averaging possible configurations best configuration variables pass 
bayesian graphical models message 
approach called configuration 
configuration approach widely 
maximum likelihood estimation mle maximum posteriori map special cases configuration approach estimate parameters learning 
viterbi algorithm hidden markov model decoding special case configuration approach find best label data testing 
monte carlo methods set known variables xe monte carlo methods samples values unobserved variables xf methods messages passed set nodes form samples 
commonly monte carlo methods importance sampling rejection sampling metropolis method gibbs sampling obtain sample values xn probability distribution 
samples answer virtually question distribution formulating question form dx xi example estimate function posterior probability distribution mean variance divergence equation 
monte carlo methods metropolis method gibbs sampling practical high dimensional spaces 
detail monte carlo methods please refer 
bayesian experimental design sequential decision problem tasks model estimation intermediate step process task system usually decision action take 
system chooses best action delivering delivering document user maximize expected utility function linear utility function defined equation 
decision usually current belief parameters 
comparatively formal description decision ai set alternative actions available system 
ai initial belief parameter additional information obtained observing data estimate possible consequences cij may occur action bayesian graphical modeling framework posterior distribution xf xe 
representational convenience 
chapter 
literature review background knowledge ai 
cij utility corresponding consequences action ai delivering document taken get consequence cij user likes document 
action preferred action ai cij cij ai order decide action take important part specify utility function reflects accurately purpose system 
example filtering system objective maximize immediate utility system needs decide deliver document possible consequences document relevant deliver relevant non relevant relevant non relevant uc uc uc uc 
equation action deliver preferred action deliver relevant delivered non relevant delivered relevant non relevant step assumption deliver deliver document affect relevance document 
system deliver document user probability relevance higher current belief 
online system filtering system needs sequential decisions optimize long term objective function immediate utility previous simple example 
system takes action information learned old data gets consequence 
bayesian graphical models information action 
system revises belief chooses action gets consequence information 
online process keeps final evaluation 
sequential decision problem successive interdependent decisions 
important area bayesian experimental design devoted solving problems 
bayesian decision theory approach problem summarized follows 
bayesian experimental design experiment action chosen set ai data observed 
unknown parameter parameter space 
usually estimated initial belief parameter additional information obtained action taken 
decision problems selection action selection terminal decision 
general utility function form 
action expected utility best decision function maxd dy utility function defined necessarily defined equation global objective function equation 
alternative utility functions researchers sequential decision problems 
detailed discussion various utility functions available 
section derive utility function maximize global objective function 
finite states finite horizon sequential decision problem number possible scenarios states time finite number decision nodes considered finite backward induction find global optimal action 
means know user filtering system theoretically find optimal active learning strategy 
unfortunately usually condition hold adaptive filtering task 
holds exact optimal solution may practical computation usually expensive 
filtering modeled continuous multi problem branch general optimal stopping problem 
solution described probably applied adaptive filtering task computational complexity provide useful guidance solve adaptive filtering task 
example exploration exploitation discuss section viewed special approximate solution framework 
chapter integrating expert heuristics bayesian priors mentioned filtering task shares common problems document representation query representation text classification task ad hoc retrieval task 
algorithms text classification tasks ad hoc retrieval relevant feedback task svms logistic regression models naive bayes decision trees language modeling rocchio profile updating section 
large literature algorithms exists algorithm works best 
purpose profile learning find classifier generalization error data training data available answer usually depends data set 
order understand algorithm works better kinds situations decompose generalization error learning algorithm parts bias measure closely learning algorithm able approximate best solution 
variance measure sensitive learning algorithm training sample 
noise measure inherently irreducible uncertainty problem 
example possible high variance means learning algorithm converges asymptotical classifier slowly 
high bias means asymptotical classifier far theoretically optimal classifier 
problems training samples bias dominant contributor generalization error problems training samples variance may dominant contributor 
may want learning algorithm low bias low variance 
natural bias variance trade learning algorithm 
bias variance dilemma complexity learning algorithm increases bias goes variance goes 

existing algorithms dilemma complex learning algorithms svm logistic regression may amount training data large simple algorithms naive bayesian rocchio may better amount training data small 
early stage filtering training data low variance learning algorithm better choice 
training data long term interaction user low bias learning algorithm may better 
adaptive filtering system needs consistently filtering process 
hypothesize bayesian prior combine different algorithms may solve problem 
chapter develop new technique decision boundary low variance algorithm prior knowledge set prior distribution low bias model data learn posterior distribution low bias model 
combined algorithm may get bias variance trade size training set achieving consistent performance different stages filtering 
apply proposed technique combine rocchio heuristic algorithm proposed ir expert logistic regression widely statistical machine learning algorithm 
adaptive filtering system new algorithm behaves similar rocchio early stage filtering similar logistic regression user feedback available 
user profile contains initial query proposed algorithm significantly better rocchio logistic regression compares favorably best methods trec trec adaptive filtering tasks 
tdt data set initial query available new algorithm similar logistic regression best tdt supervised tracking task 
chapter describes develop evaluate proposed solution 
organized follows section introduces definition rocchio algorithm logistic regression algorithm 
new algorithm logistic rocchio combines rocchio algorithm logistic regression introduced section 
section section describes experimental methodology results 
discussion related works provided section 
section concludes 
existing algorithms certain point adaptive filtering process suppose training documents user feedback dt xt yt xi vector represents document di dimensional space indexed keywords document relevant 
weighting schema idf convert document di vector representation xi 
chapter 
integrating expert heuristics bayesian priors core problem relevance filtering estimating posterior probability relevance document training data dt 
mentioned algorithms profile learning 
section introduces representative algorithms rocchio algorithm logistic regression 
rocchio algorithm widely profile updating methods information retrieval community different variations incremental rocchio algorithm generalized xi xi xi nr xi nr initial profile vector wr new profile vector set relevant doc uments nr set non relevant documents 
relevant non relevant documents corresponding component equation deleted 
rocchio algorithm works reasonably kind conditions 
document arrives rocchio algorithm provides score indicating document matches user profile 
score calculated measuring distance document vector user profile adaptive system needs binary decision incoming document choose action deliver deliver researchers usually module learn dissemination thresholds 
filtering system deliver document user score dissemination threshold 
corresponding decision rule deliver wr threshold wr threshold wr wr 
dimension vector dimension corresponding pseudo feature equal equation rewritten dissertation symbol bold font represent vector 
true statistical retrieval algorithms originally designed ad hoc retrieval ranking documents sufficient 

existing algorithms deliver iff rx rocchio algorithm popular reasons 
computationally efficient online learning 
second compared algorithms works empirically 
rocchio algorithm strong probabilistic framework guarantee provide optimal decision boundary high dimensional document space asymptotically infinite training data 
words rocchio algorithm simple heuristic algorithm works empirically 
logistic regression logistic regression widely statistical algorithm provide estimation posterior probability unobserved variable observed variable widely statistical machine learning community 
logistic regression model estimates posterior probability log linear function observed document yw exp yw dimensional logistic regression model parameter learned training data 
filtering bayesian learning system usually begins certain prior belief distribution logistic regression parameter section 
gaussian distribution mw vw prior distribution logistic regression weights mw mean gaussian distribution dimensional parameter space covariance matrix gaussian distribution 
obvious correlation different dimensions tell correlations diagonal values matrix usually set zero 
confident true value mw diagonal variables matrix usually set small number 
items matrix zero non informative prior values probability 
non informative prior may objective represents idea letting data speak 
classifier learned non informative prior usually fits convenience depending context represent dimensional vector dimensional vector dissertation 
chapter 
integrating expert heuristics bayesian priors data 
usually set diagonal matrix small non zero positive number diagonal act regularizer 
effect smoothing techniques building language models 
presents smoothing priors generative models regularizing priors discriminative models 
certain point adaptive filtering process update belief logistic regression parameter conditional training data dt bayesian theorem 
dt dt dt yi xi yi xi gaussian prior mw vw maximum posteriori map estimation dt yi xi log exp xi vw mw equation viewed special form regularized logistic regression vw controls strength regularizer 
closed form solution greedy search algorithms conjugate gradient descent find 
cases prior knowledge logistic regression parameter usually set small value 
get norm regularized logistic regression model log exp xi new document arrives estimate probability relevance document 
new algorithm lr rocchio new algorithm lr rocchio early stage filtering system training data simple profile learning algorithm low variance rocchio algorithm thresholding method choice 
stage filtering system training data complex profile learning algorithm low bias logistic regression may better 
get algorithm works consistently filtering process 
possible approach rocchio algorithm switch logistic regression amount training data 
approach combine rocchio algorithm logistic regression get natural smooth trade variance bias 
second approach explored section motivation new algorithm combination rocchio logistic regression bayesian prior 
mentioned bayesian priors widely tool introducing human knowledge model building regularizing tool controlling model complexity avoiding overfitting 
adaptive filtering task begins small amount training data stable prior works little training data important building filtering system 
rocchio algorithm designed researchers ir community works empirically adaptive filtering task set bayesian prior logistic regression model parameter may help achieve stable performance early stage filtering 
usually logistic regression prior gaussian distribution mw vw 
find prior mean mw rocchio 
new technique proposed solve problem 
wr wr wr wr wr profile vector calculated rocchio algorithm equation 
logistic regression representation rocchio documents set keywords weighting schema plus pseudo dimension features 
probability relevance document logistic regression model exp goal minimize classification error filtering system logistic regression model deliver chapter 
integrating expert heuristics bayesian priors equation equation similar 
threshold rocchio learner set minimize classification error algorithms trying find linear decision boundary high dimensional space indexed set keywords objective 
gaussian prior mw vw logistic regression encodes belief true decision boundary defined mw 
setting mw set mw decision boundary rocchio mw vw may better commonly non informative prior zero mean gaussian prior 
prior mw encodes rocchio suggestion decision boundary learned constrained maximum likelihood estimation mw log exp xi constraint cos wr resulting logistic regression parameter mw maximizes likelihood data equation constraint corresponds decision boundary rocchio algorithm equation 
optimization problem solution simple form calculated efficiently scalar argmax mw wr exp yi xi dimensional optimization problem solution quickly gradient descent algorithms 
rocchio algorithm tends stable early stage filtering especially initial query 
decision boundary rocchio better logistic regression 
extreme example system initial query training data rocchio provide reasonable performance learn logistic regression model 
early stage filtering amount training data small prior important influence rocchio algorithm logistic regression model strong 
system gets training data prior important logistic regression dominates 
technique automatically manages trade bias variance amount training data available 
bayesian prior estimated rocchio logistic regression parameter estimated higher bias lower variance 
experimental methodology prior 
training data available bias decreases 
asymptotically learned classifier converges optimal linear decision boundary high dimensional document space 
experimental methodology experiments carried understand proposed new algorithm compare rocchio algorithm equation norm regularized logistic regression algorithm logistic regression unscaled rocchio weights wr prior mean best methods trec trec adaptive filtering tasks 
set variance prior confidence prior distribution 
example feel confident prior mean set scaled rocchio weight wr set variance prior mean comparatively smaller number identity matrix known unit matrix 
prior means zero norm regularized logistic regression model confident close optimal set variance prior mean larger number 
rocchio weights set 
experiments follow requirements specified trec adaptive filtering tasks 
task models text filtering process moment user arrives small amount identified relevant documents natural language description information need 
documents arrive user profile construction labeled training data learn word occurrence idf statistics corpus statistics average document length initial profile representation 
remaining documents incoming documents stream testing data 
soon new document arrives system binary decision deliver user 
delivered relevance judgment document released system added training data set profile updating 
system treats initial user profile description includes title description fields corresponding topic provided nist relevant document training logistic regression models 
trec adaptive filtering run begins non relevant documents system randomly samples small number documents uses non relevant documents train logistic regression logistic rocchio models 
documents represented vectors variation inquery idf weighting 
tfi lend set xi log tfi log tfi number dfi times term occurs document lend length document average length documents processed number documents processed dfi number documents contain term chapter 
integrating expert heuristics bayesian priors table comparison different algorithms trec ohsumed data set 
rocchio lr lr lr rocchio prior mean na wr wr su precision recall doc profile different text corpora evaluated proposed algorithms experiments ohsumed data set trec filtering track section reuter data set trec filtering track section multi lingual data set tdt supervised tracking task section 
experimental results experimental results ohsumed data set table 
rocchio algorithm reasonable performance best compared filtering systems participated trec adaptive filtering task 
logistic regression prior lr little worse 
logistic regression prior wr lr bad 
indicates wr directly estimated rocchio algorithm prior mean misleading 
scaling equation setting prior wr lr rocchio get significant improvement 
confirms hypothesis combining rocchio logistic regression 
surprising low variance classifier set prior low bias classifier may provide nice trade variance bias 
experimental results reuter data set table table 
rocchio algorithm gets reasonable performance 
logistic regression prior zero mean little better 
logistic regression gaussian prior wr mean performs poorly 
scaled rocchio weight equation prior performs best 
figures compare performance new algorithm rocchio logistic regression algorithms individual profile measure get idea significant improvement query query basis 
see profiles new algorithm works values top trec participants data set 
final relevance judgments table little better old relevance judgments table section 

experimental results table comparison different algorithms trec reuter data set 
rocchio lr lr lr rocchio prior mean na wr wr su precision recall doc profile table comparison different algorithms trec reuter data set old relevance judgments 
rocchio lr lr lr rocchio prior mean na wr wr su precision recall doc profile better horizontal line 
statistical test sign test indicates new algorithm significant better rocchio algorithm logistic algorithm 
compares performance system systems participated trec adaptive filtering task 
trec participant submitted runs nist best run individual participant reported 
system delivers get su trec participating systems lower 
logistic regression rocchio algorithm best trec participants proposed algorithm logistic rocchio better best runs submitted trec adaptive filtering task participants 
section mentioned prior helps control model complexity introduce prior knowledge model building 
lr rocchio logistic regression models benefit prior control model complexity 
lr rocchio benefits prior knowledge heuristics works best 
compare accumulated performance different profile learning algorithms time trec adaptive filtering task 
rocchio works better logistic regression early stage filtering worse stages 
logistic regression rocchio prior best time 
surprising bias variance analysis 
new algorithm logistic rocchio consistently better 
study effectiveness proposed algorithm filtering solution similar different task chapter 
integrating expert heuristics bayesian priors difference utility logistic regression rocchio logistic regression comparison performance individual profile logistic rocchio 
topics difference utility logistic regression rocchio rocchio comparison performance individual profile logistic rocchio rocchio 
topics 
experimental results comparison trec participants 
su values different runs trec adaptive filtering task reported 
systems legend top bottom correspond bars left right 
results results trec participants directly comparable greater experience dataset 
provided give context results reported dissertation 
chapter 
integrating expert heuristics bayesian priors su su time trec filtering track data logistic regression rocchio prior logistic regression rocchio documents passed comparison performance different profile learning algorithms time trec adaptive filtering task 
average user profiles 

experimental results run utility tdt nu utility normalized tdt su utility scaled team run team run team run team run team run team run cmu debug cmu lr rocchio team run team run team run team run team run team run table utilities submitted supervised adaptation topic tracking results reported nist 
cmu cmu runs 
teams submitted results runs 
don knowledge characteristics data set participated supervised tracking task tdt held fall 
utilities submitted supervised adaptation topic tracking results released nist table 
run cmu lr rocchio best different utility measures 
compare logistic regression logistic rocchio tdt data set table find lr rocchio better logistic regression evaluated normalized utility measure tdt su worse evaluated unnormalized utility measure tdt 
lr rocchio better logistic regression trec trec data set obviously tdt data set 
major difference data sets trec filtering data sets initial profile description initial queries system tdt data set 
lack initial query tdt data set may hurt quality rocchio prior 
suggests major reason rocchio prior rocchio uses initial query amount training data small 
initial query lr rocchio begins prior 
initial query advantage lr rocchio big 
experimental results hypothesize lr baseline lower rocchio rocchio prior helps may help query rocchio major reason improved performance tdt workshop team reported better performance tdt su regularized logistic regression data set 
chapter 
integrating expert heuristics bayesian priors table comparison logistic regression lr logistic rocchio tdt multilingual data set 
lr lr rocchio prior mean wr tdt su tdt precision recall doc profile query ways may help 
needs careful query training example logistic regression lr unscaled rocchio prior lr help lr rocchio 
worth mentioning rocchio algorithm heuristic 
different implementations algorithm may perform differently 
rocchio algorithm provide guidance components set dissemination threshold set term weights feature selection influence final result 
trec adaptive filtering track rocchio profile learning top ranking systems lower ranking systems 
similarly logistic regression algorithm may perform differently 
may want test assumptions hold lr rocchio 
related discussion detailed analysis focused combining rocchio logistic regression proposed tech nique applied combining learning algorithms 
may ask tell algorithms combine 
words tell algorithm lower bias algorithm lower variance 
answer question 
bias variance dilemma tells complexity learning algorithm grows bias goes variance goes 
unfortunately complexity classification algorithms difficulty measure hard dilemma empirically 
order get better answer question compare general probabilistic approaches 
discriminant approach posterior distribution modeled directly 
example svm 
related discussion logistic regression popular discriminative models 
approach systems directly model boundary classes 
generative approach distributions modeled posterior distribution derived bayes rule example language models naive bayes bim popular generative models ir 
approach systems model characteristics classes derive boundary classes 
non probabilistic rocchio algorithm generative model flavor sense centroid relevant non relevant documents estimated 
early suggests generative models may low variance training data comparable discriminative models may low bias better amount training data large 
strong theoretical justification discriminative generative pairs low bias low variance pairs answer may depend empirical task combining comparable generative discriminative models technique proposed chapter give performance adaptive filtering system 
statistical models systems heuristic approaches domain knowledge decisions 
view rocchio classifier decision boundary initial query user domain knowledge proposed solution mechanism integrate domain knowledge learning algorithms 
domain knowledge integrated machine learning algorithm similar way converting domain knowledge decision boundary converting decision boundary prior distribution model parameters 
decision boundary derived domain knowledge works final classifier little training data 
technique proposed chapter flavor bayesian analysis 
strict bayesian approach prior estimated data 
similar empirical bayes methods 
research combining different text classification algorithms retrieval algorithms ir community 
picks different classifiers different categories categorical features combine output transformation output different chapter 
integrating expert heuristics bayesian priors classifiers linear combinations combines put classifiers probabilistic learning reliability indicators 
contrast previous research text classification retrieval task different aspects focus adaptive filtering task amount training data changes time 
previous combines output various text classifiers proposed techniques combines classifiers better understanding variance bias properties classifiers combined 
low variance classifier set prior low bias classifier proposed technique automatically gets nice trade variance bias size training data set 
combined classifier low variance amount training data small low bias amount training data large 
noticed independent combines generative discriminative models hybrid model significantly better generative model discriminative coun 
focused text classification adaptive filtering task 
combination technique effects algorithm different 
example classifier converge logistic regression optimal estimation amount training data goes infinity 
bayesian way domain expert knowledge heuristics prior distribution parameters learned alternative approaches encode prior 
introduce prior constraints learning classifier maximum entropy minimum divergence framework 
example regularized logistic regression regularizer derived initial user query achieve similar effect 
alternative approach explained bayesian framework equation different regularizer usually converted different prior distribution 
summary empirical filtering system needs works consistently stages filtering process 
motivated bayes theorem developed new technique combine classifiers constrained maximum likelihood approach learn bayesian prior classifier classifier 
classifier learn prior variance classifier uses prior bias proposed approach provides reasonable trade variance bias amount 
summary training data 
combined algorithm may achieve consistent performance different stages filtering 
developed new algorithm incorporate rocchio algorithm logistic regression models proposed technique 
certain assumptions new algorithm better lr rocchio better 
experimental results show performance better rocchio algorithm logistic regression algorithm comparable best trec adaptive filtering task better best trec adaptive filtering task 
algorithm best tdt supervised tracking task 
experimental results suggest original query rocchio algorithm major reason improved performance 
focused combining rocchio logistic regression proposed technique applied combine classifiers domain knowledge 
early research compares generative models discriminative models suggest generative models may lower bias higher variance discriminative counterparts 
generative model set bayesian prior discriminative counterpart may get performance 
domain knowledge available convert decision boundary document space proposed technique convert boundary prior 
chapter exploration exploitation trade bayesian active learning system filters refines knowledge user information need relevance feedback user 
delivering document effects satisfies user information need immediately helps system better satisfy user learning relevance feedback document provided user 
traditional approaches adaptive information filtering including filtering experiments previous chapter fail recognize model second effect 
goal filtering system maximize utility long run 
order traditional approaches deliver document expected immediate utility delivering greater expected utility delivering 
expected immediate utility calculated probability document relevant 
example utility function trec trec trec filtering tracks equation trec participants usually set threshold relevant document score expected utility point 
fact delivering document relevant document score written explicitly guidelines trec adaptive filtering tasks 
previous section example traditional method focuses immediate utility 
system estimates uncertainty relevant node probability relevance document 
system estimates utility credit penalty get immediately delivering document 
existing filtering approaches including done previous chapter consider possibility system improve knowledge user information need feedback user better serve user 
especially early stage filtering system knowledge user information need limited potential gain improving user model substantial 
section go study second aspect model long term benefit delivering document 
bayesian graphical modeling approach provides principled way explicit modeling uncertainty 
uncertainty related relevant node 
algorithm associated nodes parameter node 
estimate uncertainty node probability distribution model parameter 
notion uncertainty enables measure improvement user profiles learning user feedback delivered documents 
maximizing accumulated utility period time objective filtering system 
achieve goal derived new model quality measure utility divergence section help filtering measure quality user profile 
measures model quality active learning methods utility divergence advantage having scale traditional utility model adaptive filtering systems try optimize 
combine expected immediate utility expected improvement model quality get single quantity measures short term long term value document document stream 
combined measure basis deciding deliver document 
subsections describe research exploration exploitation filtering uncertainty model parameters 
section describes general theoretical framework optimizing utility trade exploration exploitation bayesian theory 
sections section describe experimental methodology results 
section discusses related section concludes chapter 
algorithm order maximize utility system propose modules system exploitation module exploration module 
exploitation module estimates immediate utility delivering new document model parameter learned exploration module estimates utility delivering new document considering improvement model parameter estimation get user feedback document 
trade exploitation exploration filtering system delivers document combined utility zero 
simplicity bayesian logistic regression learner 
assume form utility function maximize utility ar chapter 
exploration exploitation trade bayesian active learning step step relevant exploitation exploration relevance filtering 
step messages passed known nodes dt relevant estimate probabilistic distribution relevant 
estimate immediate utility 
step messages passed known nodes dt relevant unknown node estimate probabilistic distribution assuming know relevance feedback document dt 
estimate utility gain dt delivered probabilistic distribution parameter 

algorithm exploitation bayesian inference mentioned direct utility gain loss due delivering document calculated know probability relevance document 
estimating probability relevance document model parameter learned corresponds step 
chapter new document arrives maximum posteriori map estimation model parameter map estimate probability relevance 
exact inference algorithm described section 
suppose model parameterized estimate probability relevance document 
prior distribution model parameters 
seeing data xk yk posterior distribution likelihood user feedback delivered documents 
yi xi exact bayesian average immediate utility gain delivering document ay utility delivering document true label table ay ar true label relevant ay true label non relevant 
exploration bayesian active learning exploration need measure improvement learned model deliver document 
corresponds second step 
order quantify improvement measure quality learned model needed 
enable estimate improvement model know label document compared model learned delivering document 
goal estimating model help system decisions object system utility function 
reasonable measure model quality utility function 
assume relevant node known step estimate distribution node result step 
chapter 
exploration exploitation trade bayesian active learning active learning framework proposed choose model true model incur loss loss 
know exact value represents beliefs distribution evidence 
expected loss model loss ed loss loss posterior distribution different model parameters 
quality model seen data set loss loss arg min loss system decisions model minimizes lose 
smaller loss means better model 
active learning loss needs capture notion uncertainty model parameters 
commonly chosen metric kullback leibler divergence kl divergence kl log dx distribution input independent usually learned unlabeled data 
usefulness knowing label document measured potential lower loss 
information filtering ultimate goal optimize utility function long run 
unclear smaller kl divergence relates higher utility 
unnatural combine kl divergence expected immediate utility credit loss get single quantity decision deliver document 
kl divergence propose difference best possible utility actual utility call utility divergence function loss measure model quality ud expected utility choose model true model defined property system decisions differently need change accordingly 

algorithm essentially says expected utility incorrect model exceed expected utility correct model 
worth noting kl divergence proposed special case utility divergence 
choose log likelihood utility log dx shows log likelihood utility ud kl 
utility divergence loss function loss rewritten shown 
loss loss information filtering goal maximize utility equation define dx space model thinks delivering immediate positive utility 
expected reduction utility divergence due knowing label document immediate document right current loss loss discounted documents expected utility delivering document deliver document 
process bayesian graphical modeling point view summarized 
system treats node relevant unknown estimates distribution known nodes document 
estimation calculate immediate utility gain delivering document equation 
system treats nodes relevant document known assumes system change model filtering documents assumption computation complex 
chapter 
exploration exploitation trade bayesian active learning estimates probability distribution parameter node 
utility divergence derived probability distribution value parameter node measure quality new model know label relevant node 
quality new model minus quality old model expected reduction expected loss utility measure utility gain delivering document 
combined immediate utility get complete estimation utility gain equation 
determining dissemination threshold logistic regression proposed algorithm applied high dimensional space learning term weights statistical profile learning methods lr rocchio algorithm proposed 
com putational complexity proposed algorithm lr rocchio expensive considering integration equation 
may takes months process standard evaluation data years national library medicine bibliographic database single pc 
may practical real scenario choose design evaluation experiment takes long 
demonstrate effect proposed algorithm smaller problem dimensional space learn dissemination threshold filtering 
important problem informa tion filtering community threshold affects filtering system performance lot filtering research years focused solving threshold problem 
traditional retrieval thresholding approach described section assume separate module compute score document 
rocchio algorithm learning term weights query expansion experiments 
documents scores profile specific dissemination threshold delivered corresponding user 
input algorithm score document problem determine deliver document score 
choose rocchio algorithm simple widely trec adaptive filtering community distribution rocchio score modeled simple distributions easy specify functional form equation 
logistic regression model conditional probability user feedback document score exp prior distribution equals gaussian distribution 
mean gaussian covariance gaussian 

algorithm task find decision boundary dissemination threshold optimize linear utility function 
corresponds boundary equation 
quality model quantified expected utility decision boundary defines equation threshold thinks best 
calculate loss find computational issues ar exp dx loss loss solving dt computation equation loss equation involve integrating posterior distribution 
posterior distribution logistic regression simple integration calculated closed form 
strategy monte carlo method get approximate solution section 
generate random samples metropolis hastings algorithm 
loss approximated shown 
loss order generate random samples posterior efficiently apply laplace method gaussian distribution map approximate posterior map maximum posteriori estimation hessian matrix loglikelihood training data log chapter 
exploration exploitation trade bayesian active learning table pseudo code determining threshold 
function calculate dissemination threshold input xk yk output dissemination threshold loop binary search computed equation computed equation return threshold function calculate loss input xk yk output loss calculate map estimation mp calculate gaussian approximation generate samples metropolis algorithm calculate equation equation return loss loss computational complexity map gaussian approximation generate candidate values metropolis hastings method 
summarize computational procedures determining dissemination threshold table 
document delivered score threshold 
document delivered dissemination threshold recomputed scores labels delivered documents 
note previous section configuration inference computationally efficient 
section sampling algorithm inference computationally expensive appropriate exploration 
computational complexity active learning algorithm determine threshold number metropolis samples number loops searching threshold 
preset constant give guaranteed response time preferable filtering system 
exploration lr rocchio algorithm high dimensional space computational complexity number dimensions 
additionally needs extremely large order approximate high dimension integration 
computation exploration lr rocchio high dimensional space complex 

experimental methodology experimental methodology algorithm described table evaluated text corpora experiments ohsumed data set trec filtering track section reuter data set trec filtering track section 
data sets different properties described section section 
utility measured macro average normalized version su section equation equation 
normal exponential threshold setting algorithm described baseline 
uses normal distribution fit relevant documents scores exponential distribution fit non relevant documents 
algorithm component effective system tested trec filtering track 
problem generative models normal exponential model learning adaptive filtering thresholds training data assumed representative fact biased system gets relevance feedback documents delivers documents scores dissemination threshold 
proposed maximum likelihood normal exponential ml algorithm explicitly compensate sampling bias 
algorithm second experimental baseline 
straightforward bayesian approach active learning bayesian immediate learning corresponds implemented third experimental baseline 
algorithms learn threshold high documents delivered filtering system gradually decreases threshold cases 
filtering system creates initial profiles terms trec topic title description fields section 
relevant documents sampled training discriminative model 
set initial threshold allow highest scoring documents top training data pass 
system positive negative feedback testing document stream proposed algorithm set dissemination thresholds 
algorithm needs model distribution document scores 
simple exponential model fit experiments 
set number documents nnew number relevant documents delivered nnew number expected documents number filtered documents controls exploration rate 
set arbitrarily experiments lower conservative estimate experimental results normal exponential algorithm directly comparable prior results profile learning term term weight algorithms different 
chapter 
exploration exploitation trade bayesian active learning table comparison threshold learning algorithms trec filtering data reuter data set 
bayesian bayesian norm 
ml metrics active immediate exp su precision recall ave doc 
delivered profile comparison performance threshold learning algorithms time trec filtering data 
similar discounted rewards reinforcement learning 
experimental results experiment compares threshold setting algorithms trec reuter corpus 
considered relatively difficult corpus initial training data limited particularly representative variety large number relevant documents test data 
table summarize experimental results 
active learning effective compared baseline methods utility higher su utility slightly higher precision recall comparable documents delivered hurting 
experimental results table comparison bayesian active learning bayesian immediate learning user profile 
bayesian bayesian metrics active immediate su precision recall ave doc 
delivered profile table comparison threshold learning algorithms trec filtering data set ohsumed data topics 
bayesian bayesian norm 
ml metrics active immediate exp ne su precision recall ave doc 
delivered profile utility 
expected maximum likelihood normal exponential method compensates sampling bias outperforms basic normal exponential method 
sampling bias problem discriminative models bayesian active bayesian immediate methods 
bayesian active learning outperforms models times experiment 
comparing performance bayesian active immediate learning profiles active learning significantly improved performance find active learning increases recall precision table 
improvement partly due profile term term weight learning algorithm benefits additional training data generated active learner 
thresholding algorithm consider benefit improving profile suboptimal effective 
simplicity focused threshold learning section active learning algorithm section restricted problems low dimensionality higher dimensionality version algorithm incorporate profile learning 
threshold setting algorithms tested trec data set contains relatively small percentage relevant documents test data consists documents average documents profile relevant 
ohsumed topic descriptions written provides relatively accurate initial profiles 
expect data set exploitation important exploration active learning detrimental 
threshold set chapter 
exploration exploitation trade bayesian active learning low system delivers thousands non relevant documents hurting utility 
trec filtering track evaluations participants reported negative utility data set 
experimental results summarized table 
expected active learning improve utility data set 
importantly hurt utility 
consequently results rank top compared results systems participated trec adaptive filtering task 
bayesian immediate learning viewed active learner selects documents positive side decision boundary exploration bayesian active learning samples negative side decision boundary 
comparable performance bayesian active bayesian immediate learners indicates active learner recognized relatively initial profiles limited number relevant documents stream penalty delivering non relevant documents collectively exploring negative side decision boundary poor choice 
active learning hurt accuracy test exploration risky choice 
related contributions active learning machine learning ir research communities 
active learner selects data add training set learn world small amounts training data 
major approaches previous researchers related active learning 
uncertainty data uncertainty data label relevant focus approach 
filtering systems tends deliver documents labels system uncertain 
example query committee algorithm selects query principle maximal disagreement committee classifiers 
modified query committee algorithm naive bayes model unlabeled data active learning 
introduced uncertainty sampling choose instance current classifiers uncertain 
underlying assumption approach user feedback data existing model uncertain usually help reduce uncertainty model parameters 
uncertainty model uncertainty parameter distribution measure qual ity model explicitly implicitly 
model uncertainty usually better comparison intended descriptive research community greater experience data set trec participants 

related contributions system usually delivers document produce best model 
provided theo framework uses kl divergence measure uncertainty model parameters active learning applied support vector machine classifiers 
variance model parameters estimate uncertainty statistical model parameters 
utility model average utility model parameter distribution measure quality model 
model larger expected utility usually better system usually delivers documents result best model 
bayesian experimental design falls category 
define utility function major research topic area necessarily global utility system wants optimize 
unfortunately prior active learning research especially categories focused interactive retrieval tasks 
considered exploration aspect problem address trade exploitation exploration 
algorithms applied easily adaptive filtering system evaluated utilities direct cost reward delivering document exploitation important improvement model estimation exploration 
especially early stage filtering lot non relevant documents delivered user system wants explore user may feel unsatisfied system 
prior research adaptive filtering recommender systems 
order succeed practice prior focused exploitation little addressed trade exploration exploitation 
adaptive filtering community developed various algorithms setting dissemination thresholds vital system performance 
researchers consider long term effect recommendation 
proposed markov decision processes model sequential decision problem recommendation system commerce sites 
lot training needed learn model approach appropriate collaborative filtering 
information gain document model select documents task batch filtering adaptive filtering approach combining information gain immediate cost reward heuristic 
prior research related areas influenced 
bayesian framework algorithm widely bayesian statisticians 
computer scientists active learning text classification 
approach falls third category listed main focus derive utility function utility divergence 
approach matches risk minimization framework described 
described dissertation differs prior major aspects 
chapter 
exploration exploitation trade bayesian active learning research uses utility divergence measure quality model exploration 
utility divergence generalizes existing measures active learning 
example objective function classification system maximize likelihood data utility divergence kl divergence measure quality model 
adaptive filtering user satisfaction usually modeled utility table system evaluated linear utility 
algorithm uses utility divergence measure quality model optimizes utility directly bayesian framework 
research considers direct indirect cost reward delivering document 
adaptive filtering system consider immediate cost credit request gets credit ar delivering relevant document penalty delivering non relevant document 
previous active learning consider cost credit affects system performance significantly 
previous adaptive filtering focused entirely cost credit disregarding benefit 
summarize exploitation exploration combined single unified framework utility divergence 
summary filtering system tries explore users may aggressive deliver non relevant documents user system explore may conservative perform poorly long run 
filtering solution described chapter developed avoid problem 
bayesian theory model trade exploitation exploration adaptive informa tion filtering 
view step message passing process 
order optimize global utility function derived quantitative measure immediate cost reward reward delivering document 
believe study trade exploration exploitation adaptive information filtering 
experimental results demonstrated bayesian active learning combination exploration exploitation improve results favorable data set example initial profiles poor document stream contains relevant documents 
results demonstrated little effect unfavorable data set example initial profiles document stream contains relevant documents 
bayesian active learning handles situations 
summary exploring useful 
algorithm explore competing methods 
chapter answers common question people bayesian approach worth mod eling uncertainty parameters 
integration equation computationally expensive maximum posteriori map estimation map maximum likelihood estimation ml algo rithms section probably preferable bayesian averaging performance comparable 
fact researchers think ml map considering classification tasks people observe comparable performance approaches 
chapter demonstrated active learning problem modeling uncertainty parameters explicitly necessary principled solution 
existing algorithms consider exploration benefit filtering explicitly modeling model uncertainty heuristic exploration exploitation trade ad hoc way 
directions research described chapter 
utility chapter trec relevancy linear utility evaluation measure direction different utility functions utility measure discounted relevant documents criteria relevancy 
research reported applied new framework setting dissemination thresholds basic principle combining expected immediate utility utility divergence gain applicable problems higher dimensionality example learning importance features words phrases 
computational method chapter approximation sampling metropolis algorithm tailored low dimensionality problems 
high dimensionality problems approximation algorithms necessary efficiency concerns 
model expected number documents estimated far optimal additional research direction needed 
utility divergence model quality measure derived chapter general active learning tasks filtering interactive retrieval task 
chapter user study traditional adaptive filtering data sets consist documents user queries assessments document relevant user query 
hand prior research suggests forms evidence novelty readability user interests document content may useful 
traditional datasets introduced section previous chapters don support research 
chapter investigates acquire detailed adaptive filtering dataset multiple forms evidence 
chapter explores bayesian graphical models adaptive filtering research rich user information available 
sections describe efforts collecting new adaptive filtering data set 
section describes adaptive filtering system developed user study section introduces subjects participated study 
section describes data collected followed basic statistical analysis data section 
section summarizes 
system description major goals user study 
goal collect adaptive filtering data set variety users explicit feedback implicit feedback wider range information documents topics heterogeneous set documents 
second goal explore realistic relatively low cost method collecting detailed data adaptive filtering research 
achieve goals developed web news story filtering system located www yow com 
system constantly gathers recommends information users 
system major components news crawler text indexer database server adaptive filtering system web server browser 
crawler candidate rss news feeds crawl frequently 
rss format news content news sites 
adaptive filtering system learns users explicit feedback recommends documents users 
indexer parses incoming news story incrementally builds text index documents facilitate computation 
system description user study system structure 
structured information user feedback crawler statistics kept database 
content web page crawled saved news repository 
filtering system 
users special browser modified curious browser log system daily read evaluate system delivered 
special browser captures implicit explicit user feedback user sends information web server real time 
information saved central database filtering system learn user preferences 
example web interface user logs 
news left column users news right column user specific 
user specific news system recommends usually long delay user independent news real time minutes delay 
delay recommendation may issue real news filtering system goal evaluate recommendation accuracy filtering system value information drops quickly time 
serious problem task major goal study collect data 
interface provides simple search functionalities users search articles yow news archive keywords get list news search news sources keywords get list rss feeds 
chapter 
user study web interface user logs 

subjects subjects interface users provide explicit feedback current news story 
posted advertisements paid study campus carnegie mellon university subjects chosen come serve criteria 
variety programs carnegie mellon university information systems management business electrical computer engineering psy art mathematics professional writing ethics history public policy management civil engineering biological science economics mba clinical psychology industrial design chemical engi neering business social history computational finance communication design 
subjects affiliated research 
week time period selected study fit schedule funding constraints author fit schedule participants leave summer vacation right study 
expected collect data evaluation period time 
subjects required read news hour www yow com web site day provide explicit feedback page visited 
week study subjects read hours day encouraged required 
subjects informed recruitment study study month required provide user feedback study feedback logged publicly chapter 
user study available research community anonymizing identity paid hourly basis subjects unable finish weeks study paid state minimum salary 
considered reasonable subject number generate significant amount data weeks 
accepted subjects initially considering possibility dropout budget constraint 
subjects dropped days requesting salary subject dropped right second week subjects finished study weeks 
general users including author researchers interested research tried system 
users paid subjects user study including worked weeks 
data collected collected feedback entries users official participants 
entry contains different forms evidence news story user clicked assigned specific topic 
intention collect forms evidence exhaustive representative 
forms evidence saved tables inside database text files server 
roughly classified categories listed table 
explicit user feedbacks users required special browser modified 
browser developed 
finishing reading news story user required click button toolbar browser bring evaluation interface shown 
interface user provided explicit feedback current story including topics news story belongs classes user likes news story user likes relevant news related class es relevant novel news story novel news story matches readability level user readable news story authoritative authoritative 
questions designed keep feedback interface easy understand reasonably small 
chose ask user likes important reason filtering system entry document user topic time tuple 
topic usually refers class specific subject topic interchangeably class chapter 
lists candidate classes interface varies different users 
users system place didn get snapshot remote machine regenerate exact interface 
snapshot author interface 

data collected shouldn deliver document user 
chose ask relevant novel readable authoritative possible factor may influence user rating document previous experience existing literature 
user likes relevant novel recorded integers ranging 
readable authoritative recorded 
candidate answers detailed relevant novel author research focus 
user option provide partial explicit feedback system designed give flexibility formal participants asked provide explicit feedback user study 
user create new classes choose multiple classes documents 
encouraged users create classes topics interested users put non topic tags weird story evaluation interface 
user actions implicit feedback browser originally designed 
records user actions user mouse activities scroll bar activities keyboard activities table 
sends record actions addition explicit user feedback web server soon user finishes rating piece news 
definition actions milliseconds user spent moving mouse milliseconds user spent page number clicks vertical horizontal scroll bars number clicks inside browser window scroll bars left mouse button pressed browser counts click 
mouse browser window browser window focused browser capture activities 
details actions 
actions easy get implicit feedback user 
topic information participant filled exit questionnaire user study answered topic specific questions popular topics topics evaluated doc uments table section 
questions include familiar user topic participating study familiar topic user likes topic topic chapter 
user study confident user respect answers provided topic confidence 
include topic specific information evidence may collected topic created filtering 
collecting exit questionnaire affects answer needs investigation 
information exit questionnaire section 
news source information news stories crawled news sources rss 
rss feed collected number web pages link rss link number pages link server host link speed server hosts 
collected information felt may related authority news story 
content document important information source filtering system content document 
approach text content calculate representative numbers characterize document numbers evidence filtering 
example relevance score readability score authority score novelty score document estimated user history content document 
scores different explicit feedback relevant novel authoritative readable scores estimated delivering document user explicit feedback collected user reads document 
collected pieces evidence represent content document relevance score readability score number words document doc len table 
estimate relevance score documents system processes documents user put class 
documents ordered feedback time 
system adaptively learns lr rocchio relevance model class relevance feedback user provided relevance score document estimated lr rocchio model learned feedback document 
lr rocchio algorithm requires boolean user feedback value explicit feedback relevance user study ranges 
train model consider rating higher positive negative 
document rated considered document learning 
document extreme rating bigger influence relevance model 
user study score intended measure topical relevance general relevance refer user likes 
user put non relevant documents class gave low relevance score 

preliminary data analysis estimate readability score document system process documents users classes ordered feedback time adaptively learns user independent readability model logistic regression algorithm 
readability model high dimensional vector term weights 
readability score document user class time estimated readability model learned users readability feedback 
worth mentioning readability model user dependent filtering system 
example system may build different readability model kids grade college students vocabulary differs lot 
learned user independent readability model dissertation users undergraduate graduate students 
preliminary data analysis section reports preliminary statistical analysis data collected 
analysis designed address questions 
basic characteristics variable 
calculate mean standard deviation max min percentage missing data variable 
plot histogram exact value variables 
informative type evidence forms evidence available 
calcu late correlation coefficient form evidence user likes feedback 
evidence person class specific 
compare person class specific measures variables 
data collected reasonable 
compare measures forms evidence reported researchers 
basic statistics basic descriptive statistics variables collected tables table 
statistics calculated feedback entries users official participants 
minimum values maximum values means variances different variables different 
example mean variance large milliseconds means variances explicit feedback smaller ranging 
values evidence may missing user actions news source information system collect 
entries entries contain missing value 
chapter 
user study number classes user created 
missing rate form evidence reported tables 
reasons evidence missing 
example explicit feedback may missing users didn follow instructions relevance score may missing stories class topic familiar value topic may missing experimental design section 
think common missing data operational environment 
classes created users 
official participants quit weeks created classes study 
shows number classes created user 
average user created classes standard deviation 
users created large number classes 
investigation user profiles shows single user may created duplicate classes carnegie mellon univ carnegie mellon university 
possible reasons 
data generate candidate classes user feedback interface saved user local machine 
user didn follow instruction migrate class information machine changed machines server keeps copy classes created user browser uses local data generate user interface 

preliminary data analysis histogram number documents users clicked evaluated class 
histogram number documents user clicked evaluated class truncated 
chapter 
user study class label count class label count class label count default experiential charity familiar topic college court studies conducted hong kong world news diet stupid science presidential usa ebay technology subject market food news business entertainment odd stories politics design interested table samples class labels provided users number documents put class 

number classes large class name list explicit feedback interface long 
user typed class name time find existing class scroll bar 
user created class typo recreated new 
comparatively large number classes user small number documents class 
retrospective analysis suggests gui system design changes reduce amount cases entirely eliminated operational system ordinary people 
systems errors people mistakes 
histogram number documents user clicked evaluated class 
get greater details majority classes truncate axis 
shows classes document 
classes learning class specific models impossible 
classes contain documents 
class specific models relevance model larger classes accurate 
samples large middle small size classes listed table 
shows classes diverse different granularity 
class labels represent topics users class labels comments documents interested odd stories 
set class different normally seen trec data users great deal freedom create classes want profile online didn strict definition class 
suggests real scenario users may interpretations create consistent classes fly 
poses challenge filtering system learn classifiers diversity represents realistic user scenario 
label large class usa suggests big universe relevant documents 
label may accurate description user information need 
user interest related 
preliminary data analysis user domain beliefs context goal easy user describe wants exactly labels 
example world news mean user wants read world news thousands documents exist topic 
users selective read small amount stories day 
histogram variable user likes shows stories user read user may rates 
plot histogram variables relevant novel readable authoritative time spent page user likes topic topic 
figures show density distribution variables dif ferent 
distributions explicit feedback look gaussian distributions looks exponential function 
information may useful find better functional forms conditional probability potential functions developing graphical models 
correlation analysis order understand useful individual form evidence forms evidence available calculate correlation form evidence explicit feedback user likes 
correlations user likes forms explicit feedback high table 
get implicit feedback user reads document high correlations provide information system decision delivering document 
correlations user likes forms evidence interesting useful 
correlation coefficient system topical relevance score user likes highest types evidence system get delivering document 
surprising system generated topical relevance score filtering systems 
lower correlation relevant user likes 
analysis indicates correlation relevance score relevant 
correlations user likes topic information table relatively high 
suggests collecting familiar topic topic real filtering system informative collecting requires little user effort user needs provide information class level document level 
section show information forms evidence filtering system 
correlations news source information user likes weaker table 
success link algorithms authority analysis web community suggests number links news source rss link may informative wants predict authority news chapter 
user study story 
correlation coefficient rss link authoritative 
find user may identify page authoritative highly authoritative source yahoo news user identifies pages news source authoritative 
suggests successful web page authority algorithms hyper links may successful sufficient news domain 
correlations user likes user actions table lower table 
actions correlated user likes refined actions nu 
finding agrees 
user specific analysis far basic statistics correlation analysis user independent 
users different 
user actions ratings differ significantly different subjects 
answer question carried multiple comparison way anova test variable see means variable different users 
users feedback entries included users excluded 
visualized result representative variables shown 
figures line corresponds entries corresponding user 
users projections horizontal axis overlap means statistically significantly different 
see means type evidence different different users 
means randomly distributed users similar mean 
comparison claypool user study design user study affect user actions significantly 
results vary different experimental settings 
researchers get similar results similar experimental setting different group users 
hard give answers questions 
fortunately data collected user study described publicly available 
data set shares forms evidence data set 
calculate basic statistics shared evidence data set table 
comparing table table see basic statistics data different data set 
comparing corr column column find correlation coefficients individual action users explicit rating similar scale data sets 
forms evidence relevant novel authoritative readable collected compare 

preliminary data analysis table basic descriptive statistics explicit feedbacks 
rlo rup lower upper bounds confidence interval coefficient 
variable min max mean variance corr rlo rup missing user likes relevant novel authoritative readable table basic descriptive statistics user actions 
unit millisecond 
variable min max mean variance corr rlo rup table basic descriptive statistics topics 
variable min max mean variance corr rlo rup missing topic familiar topic topic confidence table basic descriptive statistics news sources 
rss link number web pages link rss source 
host link number pages link server rss source 
variable min max mean variance corr rlo rup rss link host link rss speed table basic descriptive statistics documents 
length document include html tags 
variable min max mean variance corr rlo rup missing doc length relevant score readability score chapter 
user study histogram different explicit user feedback 
means user didn provide feedback 
relevant novel recorded integers ranging 
readable authoritative recorded negative positive 

preliminary data analysis histogram milliseconds spent page 
histogram variables user likes topic 
chapter 
user study multiple comparison average time milliseconds spent page different multiple comparison average users 
users feedback number arrow usage page dif entries included 
users spent ferent users 
users seconds page average 
feedback entries included 
multiple comparison average multiple comparison average number arrow page different user likes rating different users 
users users 
users feedback feedback entries included 
entries included 

summary table basic descriptive statistics user actions collected system 
corr correlation coefficient form evidence explicit feedback data 
correlation coefficient form evidence explicit feedback user likes user study data 
variable min max mean variance corr summary chapter describes user study collect evaluation data research combining multiple forms evidence 
demonstrates build longer term learning environment collect significant amount data user interests reasonably small effort 
collected new evaluation data set contains thousands extensive implicit user feedback user mouse usage key board usage document length explicit user feedback novel relevant readable authoritative user likes document forms evidence news source information 
basic characteristics means multiple forms evidence collected diverse 
forms evidence correlated user likes 
correlation implicit feedback user likes weaker explicit feedback user likes 
compared data collected researchers data set looks reasonable 
general user study represents real world task realistic setting users choose create classes read news computers time place want 
realistic setting enables collect detailed filtering data set ordinary people relatively available tools 
data different possibly power existing filtering data sets created nist trec 
small budget including author covered fellowship 
author spent month designing user study months implementing testing system month running user study real users 
chapter 
user study data set noisy missing entries thorough evaluation document user class time tuples 
relatively easy create cleaner data set characteristics missing entries diversity variables common real world eliminated entirely operational system ordinary people 
collected data documents user clicked analysis section sections applies kind data 
general statistics correlation coefficients may different un clicked documents 
study treating un clicked data entries entries missing value forcing users provide feedback un clicked data needed study problem 
chapter combining multiple forms evidence graphical models collected thousands cases contains multiple forms evidence document user class time tuple 
combining evidence filtering challenging task need handle diversity evidence various missing data situations 
researchers identified major advantages graphical modeling approach naturally handle situations missing data conditional dependencies encoded graph structure learn causal relationships domain help understand problem predict consequences intervention easily combine prior knowledge partial information causal relationship data learning 
advantages hypothesize bayesian graphical modeling approach useful framework combine multiple forms evidence filtering 
natural approach representing filtering system belief user multiple forms evidence graphical models 
belief ways guiding system designer actions deciding collect certain evidence directly choice system action deciding deliver document user 
test hypothesis explore graphical models effectiveness directions carry experiments data collected user study described chapter 
experiments designed answer specific questions 
graphical modeling approach help better understand domain 
example algorithm tell relationships user actions relevance document authority relates user preference page usage specific keyboard key informative users differ 
information may guide design better filtering system 
graphical modeling approach help improve performance adaptive information chapter 
combining multiple forms evidence graphical models filtering system 
example document arrives predict user preference document better topical relevance model 
prediction directly deciding deliver document user 
answer questions study advantages graphical models experiments 
specifically see proposed solution help understand domain better causal graph structure learning algorithms gm advantage prior knowledge domain gm advantage derive causal relationships different user feedback actions user context 
see proposed solution help improve existing filtering system especially situation missing data statistical inference tools predict user likes document different evidence missing conditions gm advantage 
different graphical models developed evaluated different purposes understand domain improve prediction accuracy 
linear regression algorithm ways handle missing evidence situations tried alternative approaches combine multiple forms evidence 
sections describe efforts evaluating graphical models task combining multiple forms evidence filtering 
section describes existing graphical structure learning tools understand relationships various forms evidence data 
section explores improve system performance multiple forms evidence various models 
section discusses related 
section discusses limitations proposes 
section concludes chapter 
understanding domain causal structure learning correlation analysis section useful helped get brief idea data collected 
order better understand underlying truth domain need go correlation investigate potential causal relationships different variables 
specify nodes kind evidence 
graph structure learning algorithms introduced section explore causal relationships multiple forms evidence data collected 
causal discovery hard impossible due possibility hidden variables inadequacy data 
prior domain knowledge forbidden edges required edges temporal tiers may help find causal structure 
demonstrate prior knowledge help structure learning specify prior knowledge developed author temporal tier constraints variables automatic structure learning 

understanding domain causal structure learning generate temporal tier organize variables tiers manually 
level topic information topic info familiar topic news source information rss info rss link host link document length doc len level hidden variables relevant novel authoritative readable may affect user prefer ence document level system generated scores topical relevance score readability score level user explicit feedback relevant novel authoritative readable level user judgment user likes level user actions milliseconds spent page number clicks key 
assume users provided accurate judgment hidden variables explicit feedback user explicit feedback corresponding hidden variable level 
assumption merge corresponding nodes level level form tier shown 
informs learning algorithm causation indicated higher level lower level prohibited 
prior knowledge engineered author guaranteed true may help structure learning algorithms constraints search space smaller 
tried different prior organizing variables tiers user likes level forms evidence level 
moving tier prior tier prior changing prior constraints making different assumptions true causal relationships variables 
helps see algorithm learn different prior kind causal relationships sensitive choice priors 
graph structure learning packages generate graph topology data 
section reports results generated pc fci algorithms implemented tetrad 
chose algorithms basic algorithms causal discovery comparatively small number nodes tetrad package provides functionality enables specify prior knowledge constraints temporal order 
encouraging see structure learned automatically pc algorithm looks reasonable 
document novel relevant authoritative readable means direct cause chapter 
combining multiple forms evidence graphical models prior knowledge temporal tier variables automatic structure learning 
prior knowledge informs learning algorithm causation indicated higher level lower level relevant direct indirect cause rss info relevant prohibited 

understanding domain causal structure learning user independent causal graphical structure learned pc algorithm 
learning algorithm begins tier prior knowledge 
causal graph means algorithm tell causes causes means algorithm problem 
problem may happen latent common cause chance pattern sample violations assumptions 
chapter 
combining multiple forms evidence graphical models user independent causal graphical structure learned pc algorithm 
learning algorithm begins tier prior knowledge 

understanding domain causal structure learning user independent causal graphical structure learned fci algorithm 
learning algorithm begins tier prior knowledge 
means direct indirect cause means common cause means algorithm determine arrowhead edge 
edge arrowhead directed means direct cause chapter 
combining multiple forms evidence graphical models user familiar topic system familiar topic direct causes user preference document user likes 
familiar topic user participating user study familiar topic number web links news source rss link host host indirectly affect user preference page relevant authoritative 
relevant authoritative familiar topic host link influence user actions number events scroll bars 
comparing tables may ask variables correlated user likes direct links user likes 
example correlation relevance score user likes direct link 
contradict table 
answer 
direct link means relevance score direct cause result user likes 
subgraph user likes relevant relevance score means relevance score user likes share common cause relevant 
correlation relevance score user likes due indirect causal relationship 
similarly variables correlated user likes direct link node user likes section 
different structure learning algorithms pc vs fci different priors tier vs tier structures learned share common properties 
variables refined actions specific keys keyboard length shortest path variable user likes node different structures similar 
example figures node user likes directly linked authoritative relevant novel readable familiar topic 
refined actions number times page key pressed steps away user likes 
path refined action nodes user likes 
implies refined actions informative want learned model predict user likes document 
finding agrees table 
node authoritative directly linked readability score host link 
link host link authoritative confirms existing approaches web link structure estimate authority page 
links readability score readable authoritative interesting 
suggest difficulty understand page may user feel authoritative 
investigation shows percentage un authoritative news general news stories users identified difficult class labels rated authoritative 
successful web page authority algorithms hyperlinks estimation authority may improved content page 

understanding domain causal structure learning variable relevant novel authoritative readable relevant novel authoritative readable table correlation coefficient explicit feedback 
figures contain links nodes relevant novel readable authoritative 
analysis show correlation pair high table 
algorithms failed tell causal directions pairs variables disagree directions certain links suggest variables influence way 
example readability document may influence user evaluation authority document relevant may influence user evaluation novelty 
possible explanations inherent property document user rate aspect document higher aspects 
may ask structure contains link readable readability score causal relationship intuitively 
answer question needs understand causal relationships learned automatically algorithm believes evidence data assumptions prior constraints engineered 
relationships learned may contain error data noisy assumptions prior constraints may wrong 
example pc fci algorithms statistical test independence relationships variables data final results subject error statistical test 
pc algorithm assumes hidden variables 
additional relevant novel authoritative readable hidden variables document date interesting misleading may exist influence user preference document 
surprising causal relationship link readable readability score missed final graph limitation learning algorithms 
models learned merely shed light relationships variables uncovering truth 
serves starting point 
understand domain may want break variables current graph relate user document properties 
general causal discovery inherently difficult far solved 
chapter 
combining multiple forms evidence graphical models improving system performance inference algorithms previous section graphical model structure learning algorithms helped understand relation ships variables domain better 
improving system performance serve user better primary goal 
section explores graphical models 
specifically focus addressing questions 

graphical model combine multiple forms evidence handle missing data scenario 

graphical modeling approach compared straightforward ap proaches linear regression 

going topical relevance combine multiple forms evidence better traditional relevance filtering 

develop filtering system works reasonably limited user supervision 

user actions useful system information 
experimental design comparison graphical models answer questions graphical models created combine multiple forms evidence predict user preference user likes 
graphical model uniquely defined graph structure set local conditional probability functions potential functions specified manually learned data 
derive graph structure may want causal structures learned previous section 
structures inference directly hard circles mixture directed undirected links graph 
tried directed acyclic graphical models gm complete complete bayesian network graph order nodes top bottom parents node nodes 
structure order nodes important gaussian distributions 
gm causal graphical model inspired causal models manually modify causal structure directed acyclic graph 
gives causal graph structure 

improving system performance inference algorithms graph structure gm complete 
graphs rss info rss link host link topic info familiar topic topic dimensional vectors representing information news source topic table table 
actions dimensional vector representing user actions table 
user likes target variable system predicts 
chapter 
combining multiple forms evidence graphical models graph structure gm causal 
graph structure gm inference 

improving system performance inference algorithms gm inference manually modify structure directed acyclic graph result 
call gm inference structure looks inference graph 
derive local conditional probability functions need choose specific form conditional probability function associated node 
difficult find form close real distribution mathematically tractable doing inference 
simplicity gaussian distributions 
parents node nodes gaussian distribution mean covariance 
commonly distribution continuous valued nodes 
choose mathematical convenience existence efficient learning inference algorithms gaussian networks availability modeling tools 
graph structure specific form conditional probability function learning algo rithm learn parameters functions training data 
baseline algorithms answer second question tell graphical modeling approach works compared straightforward approaches tried alternative approach combine multiple forms evidence linear regression 
linear regression models handle missing values tried special methods solve problem building model evidence missing missing situation lr different mean substitution replacing missing value evidence average observed evidence lr mean 
different forms evidence system may need handle different evidence missing situations 
large number linear regression models need learned approach considering higher experiments 
building models impossible heuristic approach discussed experiments possible 
chose algorithm linear regression assumes conditional probability distribution gaussian distribution user likes vector dimension form evidence 
assumption matches gaussian network 
major difference lr models graphical models due structure functional form 
different evidence missing situations testing algorithm tested various evidence missing situations 
difficult evaluate algorithms different evidence missing situations 
design experiments follows analyze situations interest 
chapter 
combining multiple forms evidence graphical models depending property multiple forms evidence manually grouped sets relevance score readability score topic info rss info user actions explicit feedback user likes 
categories may available delivering document user system predict user preference document making filtering decisions 
answer third question tell going topical relevance combine multiple forms evidence better traditional relevance filtering rank sets evidence max correlation coefficient variables category user likes 
order relevance score readability score topic info rss info 
model predicts value user likes value evidence relevance score testing time 
forms evidence added order see prediction performance increases 
answer fourth question tell develop filtering system works reasonably limited user supervision manually rank sets evidence easy collect evidence 
order rss info readability score topic info relevance score 
model predicts value user likes value evidence rss info testing time 
forms evidence added order see prediction performance increases costly evidence available 
answer fifth question tell user actions useful system information compare model conditions actions model predicts value user likes values sets evidence actions model predicts value user sets evidence including user actions 
implementation issues develop experiments bnt toolbox 
maximum likelihood estimations parameters learned training data em algorithm junction tree inference engine graphical models 
task value variable continuous normalized variance 
model learned information available cases tested remaining cases 
cases collected user study experiments 
conducted sets experiments 
set experiments cases value user likes missing 

improving system performance inference algorithms set experiments cases evidence missing 
results set runs analyzed followed briefly discuss results second set runs 
graphical models lr mean model trained types evidence features learned models independent testing conditions 
lr different build model testing con dition features available testing condition 
set runs cases training data testing data contain cases piece evidence supposed available missing 
cases training data ignored lr different learn linear model 
ignoring cases testing data cross comparison testing conditions difficult ignored cases depend testing condition 
mean substitution approach fill required missing features testing data lr different 
evaluation measures correlation coefficient predicted value user likes users explicit user likes feedback evaluation measure 
baseline method relevance score 
linear utility measure 
commonly trec style linear utility measure equation directly focuses topical relevance defined boolean user feedback 
consider aspects document novelty readability authority 
system get credit delivering document user likes lot get penalty delivering document user dislikes relevant redundant document 
furthermore user likes document represented number binary value 
modify trec style linear utility get new evaluation measure user satisfaction follows likes measure similar linear utility measure defined equation corresponds assigning positive negative value element categories table 
experiments set 
filtering system delivers document user user feedback user likes system receives value equals 
experimental results discussions shows performance algorithms cases 
horizontal axis indicates different testing conditions 
vertical axis correlation coefficient predicted value user likes chapter 
combining multiple forms evidence graphical models comparison prediction power different models forms evidence ordered correlation coefficient 
left right additional sources evidence testing 
rss info means values news source information rss info value relevance score topic info readability score 
comparison prediction power gm complete different missing evidence conditions forms evidence ordered user effort involved 

improving system performance inference algorithms user rating delivered delivered table values assigned documents different user likes ratings 
correspond number documents fall corresponding category 
correspond credit penalty element category 
model users explicit feedback provided users 
results show gm complete performs similarly lr different 
surprising 
missing entries training data gm complete estimation conditional dis tribution user likes available evidence lr different testing case missing evidence 
lr different gm complete performs reasonably relevance score 
sur known filtering community system improve performance documents explicit feedback users old documents existing filtering systems usually measure topical relevance decision 
encouraging see go topical relevance adding topic info readability score system keeps improving improvement statistically significant 
obvious improvement adding rss info 
may feel surprised correlation coefficient negative lr mean rel score condition 
analysis shows evidence considered unimportant explicit feedback learning algorithm assigns near zero weight chance negative relevance score 
words lr mean gave explicit feedback weight overlooked evidence 
user likes bx evidence relevance score regression weights regression residual 
investigation show confidence interval correlation coefficient relevance score 
surprising rele vance score small negative weight 
testing time handle problem missing explicit feedback negative weight relevance score dominates 
gm complete gave high weights explicit feedback infer missing values available evidence testing time performed better lr mean 
lr different consider explicit feedback training overlooks evidence suffered problem 
lr mean may improve explicit variables included algorithm combine multiple forms evidence large variance informative evidence suffer similar problem strong evidence missing due reason 
gm complete builds single model handle chapter 
combining multiple forms evidence graphical models various evidence missing situations lr different builds models situation 
mentioned different possible evidence missing combinations linear regression models needed order handle situations lr different approach 
big gm complete may preferable requires computation space performs equally 
order evidence user efforts involved find adding rss info readability score topic info improves performance system performance topic info condition close relevance score condition 
experiment conducted documents user clicked seeing titles 
clicked documents somewhat relevant effect relevance score strong experiment 
experiment demonstrates impact relative impact forms evidence rss info 
interesting see topic familiarity factor influences user rating document 
fact adding rss info readability score topic info improves performance may extended un clicked documents help system better recommendations information 
degree improvement un clicked documents may different 
result demonstrates cheap information help predict user likes document clicked 
directly benefit systems personal information retrieval re little user supervision needed train model topic info condition 
far graphical model evaluated gm complete 
graphical models 
model different structure perform differently 
compares graphical models 
gm causal gm inference perform worse simple gm complete 
struc tures look causally reasonable perform simple gm complete data set 
gm complete assumes joint distribution variables multivariate gaussian 
gm causal gm inference stronger assumptions removing links variables putting independence constraints learning models 
discussed causal relationships learned automatically perfect constraints imposed gm inference gm causal may wrong 
result performed worse gm complete 
user actions useful system information 
compared model conditions user actions table 
model statistically significant difference actions added 
means forms evidence rss info topic info relevance score readability score system didn improve prediction observing actions user reads document 
mean actions useless learn user specific 
improving system performance inference algorithms comparison prediction power different graphical models forms evidence ordered correlation coefficient 
model actions added corr rup lr mean lr mean lr different lr different gm simple gm simple gm complete gm complete gm causal gm causal gm inference gm inference table comparison effect adding user actions 
relevance score readability score rss info topic info actions added 
data entries missing value training testing 
corr correlation coefficient predicted value user likes model true explicit feedback provided users 
rlo rup lower upper bounds confidence interval coefficient 
chapter 
combining multiple forms evidence graphical models model forms evidence relevance score available 
far results cases evidence may missing 
table reports results second set runs cases evidence missing 
results show performance gm causal gm inference changes lot new evaluation data significantly better table 
suggests need careful structures graphical modeling approach structure looks reasonable may poorly inference task 
couldn draw gm complete better general answer may different different conditional probability distributions different data sets better structure learning algorithm 
filtering system combines multiple forms evidence graphical models help build better practical filtering system serves user better 
higher correlation user explicit feedback user likes predicted values mean higher utility 
answer questions linear utility measure equation evaluate proposed solution 
ideally need thorough evaluation data similar trec filtering data multiple forms evidence 
unfortunately extremely hard collect kind data 
document user class time tuples user feedback 
cases training data remaining cases testing data 
system processes tuple document class time testing set ordered time decides document delivered user class time delivering documents testing data user gives utility high 
surprising considering biased evaluation data set testing data documents clicked user 
highest possible utility testing data 
compare approaches 
lr rocchio system delivers documents user estimated relevance score higher 
relevance score section 
document user class time tuple missing relevance score system deliver 
lr rocchio linear regression system corrects bias caused difference user likes relevance score 
uses linear regression predict user likes relevance score delivers documents user estimated user likes higher 
gm complete multiple forms evidence incoming document test stream sys tem uses gm complete predict user likes rss info readability score topic info relevance score 
system delivers document user estimated user likes value 
improving system performance inference algorithms model condition corr rup lr mean rss info lr different rss info gm complete rss info gm causal rss info gm inference rss info lr mean readability score lr different readability score gm complete readability score gm causal readability score gm inference readability score lr mean topic info lr different topic info gm complete topic info gm causal topic info gm inference topic info lr mean relevance score lr different relevance score gm complete relevance score gm causal relevance score gm inference relevance score lr mean actions lr different actions gm complete actions gm causal actions gm inference actions lr mean explicit feedback lr different explicit feedback gm complete explicit feedback gm causal explicit feedback gm inference explicit feedback table comparison different models missing value cases coefficient measure 
rlo rup lower upper bounds confidence interval coefficient 
chapter 
combining multiple forms evidence graphical models table comparison different models cases utility measure 
deliver documents testing data user utility 
highest possible utility testing data 
model evidence utility lr rocchio relevance score lr rocchio linear regression relevance score gm complete multiple forms evidence higher 
table shows combining multiple forms evidence achieved higher utility relevance score 
experimental setting far real evaluation data biased graphical model multiple forms evidence perform better relevance information real scenario 
encouraging see gm complete performs better delivering documents users clicked 
may feel little surprised see relevance model performs worse delivering documents user considering relevance models usually perform better delivering trec data 
reasons delivering high baseline evaluation data includes documents clicked users system estimate relevance score document user class time tuples especially documents user profile worth mentioning inference tasks considered document user class time tuples corresponds documents users clicked assigned class labels 
performance may different arbitrary tuples real system 
practical filtering system may ask users create classes manually automatically create user classes assign documents classes 
related discussion related implicit feedback information retrieval community user modeling community 
provides review classification works areas behavior category minimum scope 
prior suggested possible behaviors view listen scroll find query print copy paste quote mark type edit different scope segment object class system designers choose 
user actions collected 
early news filtering 

build personal news agent time coded feedback user learn user profile way integrating 
related discussion time feedback heuristic 
investigated implicit feedback filtering news group articles 
discovered articles readers spent viewing seconds positive feedback produce better recall precision filtering user explicit rating 
observed incompatible context noisy context incomplete query problems contextual retrieval applications developed specific models solve problems 
approach described chapter handle problems unified framework 
related implicit feedback improve web retrieval performance 
notice independent different kind graphical modeling approach dependency networks discover relationships implicit measures explicit satisfaction decision tree prediction 
focusing predicting user satisfaction web search results implicit measures gathered users conducting searches viewing results 
findings justify graphical modeling approach effectiveness web search task task close filtering 
differs previous goal task range evidence considered modeling approach took findings reached 
different graphical models bayesian networks dependency networks inference networks causal models model computer software users car drivers students social phenomena 
choosing graphical modeling unified framework combine multiple forms evidence motivated prior 
differs previous working filtering different task 
moving specific domain information filtering performed detailed user study human subjects early stage research 
stages research basic statistical analysis techniques existing graphical modeling algorithms understand data collected explore improve system performance 
specifically focused missing data problem important forms evidence added 
handle missing data 
gives overview state art 
approaches handle missing data classified categories case deletion approach simplest approach default statistical programs 
divided categories complete case analysis uses cases observed values available case analysis estimates different parameters different sets samples 
dummy variable coding variable categorical value algorithm creates new class available assign class label missing entry 
learning algorithm missing data cases longer exist 
chapter 
combining multiple forms evidence graphical models maximum likelihood estimation algorithm fills missing entry maximum likelihood estimation value 
principle approach simple actual solutions different computationally expensive depending models system model variables 
special models closed form solution ml estimation em algorithm 
multiple imputation algorithm generates multiple imputed values single missing entry basis existing data imputed values solution 
dissertation lr mean models missing variable gaussian distribution uses maximum likelihood estimation unconditional mean variable replace missing value 
lr different gm complete model joint distribution variables gaussian distribution uses maxi mum likelihood estimation conditional mean variable replace missing value 
algorithms tried dissertation approaches exist handle missing value 
example regression trees surrogate splitters split data primary splitter missing 
allows cases different data patterns including missing pattern handled differently 
gm complete may best approach task natural solution bayesian graphical modeling frame works reasonably compared lr different lr mean 
studied missing value problem solutions tried assume data missing random 
haven investigate distribution depends value missed observed data hidden variable 
different missing data situations require different approaches handle problem 
analysis data missing may help find better solution improve system performance 
possible direction model explicitly random variable graphical model 
exists studying criteria topical relevance 
studied combining query relevance information novelty retrieval summarization proposed maximal marginal relevance mmr criterion reduce redundancy 
considered incremental value piece information argued standard documents order estimated relevance appropriate 
proposed stage filtering system filter relevant redundant documents 
went independent relevance models dependent relevance retrieve documents cover different subtopics possible 
asked users read aloud think aloud doing hard copy documents selection audio taped analyzed process proposed relevance model multiple criteria personal knowledge topicality quality novelty recency authority author qualitatively 
identified criteria underlying users relevance judgments explored users employed criteria making 
evaluations asking users interpret sort criteria independent document manually 
previous word relevant ambiguously narrow definition related matter hand aboutness broader definition having ability satisfy needs user 
second definition researchers usually studying dissertation refers user likes 
dissertation relevant defined definition phrase user likes second definition 
despite vocabulary difference chapter motivated early works focused user likes 
major contributions area model user likes criteria hidden variables demonstrated quantify importance various criteria utility optimization probabilistic reasoning explored new methodology combining criteria implicit explicit user feedback 
step combining multiple forms evidence filtering graphical modeling approach 
experiments simple needed fully explore potential graphical models combine multiple forms evidence 
follows research directions user specific models inference built user independent graphical models chapter 
preliminary data analysis section shows users different 
suggests possible improvement build user specific graphical models possibly combine user independent models 
carried preliminary study compare user specific model user independent model arbitrarily selected users 
study deleted information entries user simulate scenario user starts filtering system users 
information entries users data user learn user independent gm complete model user 
data user learn user specific gm complete model 
learned models predict user likes remaining data user rss info relevance score readability score topic info actions case 
compared user independent model user specific modeling approach negative positive results works better users worse users table 
result tell user specific model help 
suggests chapter 
combining multiple forms evidence graphical models userid user independent corr rlo rup table comparing user specific models user independent model users 
corr correlation coefficient predicted value user likes model true explicit feedback provided users 
train number training documents learn model 
rlo rup lower upper bounds confidence interval coefficient 
needed explore build better user specific model results may fruitful 
general user specific model pros cons 
real world users different 
filtering system significantly training data learn user independent model user specific model 
amount training data user user specific model learned data low bias high variance 
user specific models may better user independent model asymptotically amount training data goes infinity user independent model may better initially 
choosing user specific model user independent model alternative approach combine models bayesian priors 
human learners implicitly assuming unfamiliar person similar general public 
interacting person knowing human adapts stereotypical image general public specific person 
adaptation process modeled nicely bayesian approach 
bayesian prior encode user independent model general public posterior encode user specific model adapted specific person 
possible direction 
better models inference research needed explore structures functional forms inference 
structure learned improve system inference accuracy 
poor prediction power gm causal mean structured learned useful inference task 
practical settings choosing right feature set important performance 
suggests causal interpretation feature selection formal connection causal graph feature selection markov blanket user likes may feature set 
causal feature selection 
may help improve performance classifier help decide evidence collected 
example predict user likes node need collect variables features nodes evidence part markov blanket user likes node 
useful separated user likes node 
words user likes variable conditionally independent variables markov blanket user likes 
direction see improve prediction accuracy avoid collecting useless information causal feature selection 
gm causal gm inference performs worse gm complete experiments gm complete simple may best prediction task 
alternative graph model structure learning algorithms 
bayesian approach treat structure learning model selection problem model averaging 
alternatively try undirected graphs graphs parameter nodes similar section 
choose structures functional form section mathematical convenience major concern 
conditional probability function gaussian distribution means universally best choice 
assumes joint distribution variables multivariate gaussian 
assumption marginal distribution variable gaussian 
histograms variables contradict assumption distributions variables agree assumption 
assumption wrong 
direction find better structures functional forms 
may lead better inference performance 
integrating novelty redundancy authority estimations graphical models chapter system estimated relevance score readability score document integrated models 
factors may affect user preference document novelty score authority score estimated integrated 
decision document novel depends user prior knowledge rele vant information document covered information documents delivered previously 
compared topical relevancy document independent document appears stream documents decisions redundancy novelty depend document appears 
novelty redundancy score estimation interesting challenging topic view different perspective relevance score estimation 
designed task created evaluation data set contains known novel redundant documents user study 
chapter 
combining multiple forms evidence graphical models user study feasible assumptions user reads related documents filtering system redundancy novelty new document dt depends documents user saw dt redundancy document dt depends relevant documents user seen dt arrives documents set dt redundant dt redundant 
assumptions hired undergraduate assessors read relevant documents chronological order asked identify document redundant respect documents 
controlled user study collected clean evaluation data set 
compared novelty redundancy measures effective measures novelty redundancy score estimation 
assumptions controlled user study study novelty feasible 
loosely controlled user study described chapter assumptions hold history user incomplete 
users participated yow study user study read news 
document redundant respect document user read current yow system may give document low novelty score system keeping track user activities 
didn estimate novelty score document study reported dissertation approaches proposed 
fundamental problem proposed bayesian graphical modeling approach 
done estimate novelty score combine forms evidence 
score unreliable loosely controlled experimental setting described chapter may informative environment assumptions true filtering system monitors user information seeking activities 
bayesian graphical modeling point view combining novelty score aspects filtering straightforward 
need compare bayesian graphical approach existing approach stage model mmr maximal marginal relevance model 
summary explored combine different forms evidence graphical modeling approach 
developed probabilistic user models user likes criteria hidden variables 

summary demonstrated quantify importance various criteria combine criteria implicit explicit user feedback utility optimization probabilistic reasoning 
enables system go relevance develop interesting detailed data driven user models prior research 
partly framework better theory partly advantages proposed framework matches task practical collect training data learn period time 
analyzed user study data graphical models linear regression algorithms 
experimental results show graphical modeling approach help understand causal relationships multiple forms evidence domain explain real world scenario better 
help filtering system predict user preferences accurately multiple forms evidence relevance model 
forms evidence improves system performance 
forms evidence added missing data common problem system glitches users behave desired 
real system needs handle various missing data ignoring estimating known 
graphical modeling approach addresses problem naturally 
simpler approaches linear regression designed handle missing values 
order combine multiple forms evidence extra handling missing data needed 
lr different handles problem building different models different data missing conditions 
lr different gm complete perform similarly 
types evidence lr different probably preferable simplicity 
forms evidence added powerful model gm complete may preferable computation space efficiency 
system uses user independent model combine multiple forms evidence learns user dependent models calculate types evidence relevance scores major computation system learn user specific models relevance model 
means computational complexity graphical models similar traditional filtering system 
need learn user specific graphical model inference section complexity higher 
collected data documents clicked 
investigation needed look un clicked data critical step see improvement prediction accuracy user preferences utility experimental setting described chapter help system serve user better real filtering environment 
step graphical models combine multiple forms evidence filtering 
proposed solution especially data analyzing methodology chapter chapter 
combining multiple forms evidence graphical models ir tasks filtering context retrieval 
chapter chapter conclude dissertation summarizing contributions clarifying limitations proposing directions 
contributions information filtering important research topic increasing information available electronic form 
standard ad hoc retrieval systems search engines user short queries pull information 
standard retrieval systems treat users query words 
users different describing information needs ad hoc queries 
traditional adaptive information filtering systems try solve problem letting user tell system document relevant system learns user feedback 
convenient user user tell document relevant easily accurately describing information needs 
environment filtering system learn user profile accumulate fair amount user feedback time 
real user doesn want provide large amount feedback especially initial stage filtering 
issue short query identify documents initially system provide feedback time 
develop filtering system limited user supervision major challenge filtering research community 
hand possibility large amount user interactions long period time filtering environment offers rich opportunities research community 
interesting challenging research topics systems learn sophisticated user models time develop robust learning algorithm works reasonably amount training data small effective training data trade immediate gain vs long term gain multiple forms evidence user context implicit feedback user interacting user handle various problems missing data operational environment robustly 
chapter 
solutions problems help solve limited user supervision problem 
unfortunately existing filtering research stayed simple bag word models studied topics adequately 
major contributions dissertation proposing exploring bayesian graphical models unified framework filtering solving limited training data problem utility optimization probabilistic reasoning 
significant addresses long standing issues adaptive information filtering community combination heuristics statistical learning algorithms exploitation exploration trade offs actively learning integration wider range user specific user independent evidence handling situations missing data occur operational environments 
contributions thesis summarized sections general contribution theoretical framework general contribution introducing existing general framework guide algorithm design filtering system demonstrating adapt specific filtering problem 
framework contains major components representation tools framework provides set representation tools enable researchers build personalized information filtering system combine aspects topical rele vance novelty readability authority explicit implicit feedback bayesian axiom framework maximizing expectation user defined utility function equation decision criterion inference tools statistical inference algorithms introduced section tools enable estimate probability distributions achieve goal maximizing utility 
framework provides guidance build generation adaptive filtering systems consider broader range information sophisticated existing filtering systems 
compared commonly text classification algorithms major advantages 
goal system clearly stated broader way expressed utility function defined user likes document depends criteria topical relevance novelty authority readability document 
second system models uncertainty explicitly probabilities provides principled way active learning 
third framework help understand 
contributions causal relationships domain combine multiple forms evidence improve design system 
fourth framework enables combine prior domain knowledge heuristics training data 
fifth framework uses conditional dependencies encoded graph structure handle things missing data occur operational environments 
researchers better empowered set modeling tools provide bgm clear goal expressed quantitatively utility 
furthermore benefit advantages bgm framework 
specific contributions particular developed specific techniques arising bayesian graphical modelling framework build filtering system desired characteristics 
second contribution dissertation techniques 
implemented evaluated techniques standard new data sets 
dissertation demonstrated techniques help filtering systems learn efficiently robustly limited user supervision 
specifically key techniques findings summarized follows 
developed novel algorithm combine simple models proposed ir expert complex models bayesian prior 
new algorithm uses ir expert heuristic algorithm learn user interests amount training data small gradually switches complex learning algorithm update beliefs user interests training data available 
important shows satisfy conflicting user requirements robustly initial heuristics continue improve time training data 
previous solutions required users choose heuristic approaches little training data probabilistic models offer longer term accuracy 
filtering system algorithm works comparable best trec adaptive filtering task better best trec adaptive filtering task best supervised tracking task tdt 
derived novel model quality measure utility divergence bayesian decision theory 
enables measure utility gain delivering document user 
previous adaptive filtering focused entirely immediate cost credit delivering document disregarding benefit 
prior considered benefit heuristically 
exploitation making user happy right exploration asking user feedback combined chapter 
unified framework optimize user utility function 
led filtering learning system active learning capacity choose deliver document user may system believes learn lot user feedback better long run 
believe non heuristic approach trade exploration exploitation information filtering 
experimental results demonstrate technique works favorable data sets worth exploring little effect unfavorable data sets 
demonstrated existing graphical modeling algorithms combine multiple forms evidence filtering system 
carried user study collected extensive data set various explicit feedback implicit feedback users evidence 
shown causal structure learning algorithm help understanding domain causal relationships learned automatically perfect 
developed probabilistic user models user likes criteria hidden variables 
demonstrated inference algorithms predict user preference better multiple forms evidence topical relevance information 
interacting user system may fail collect forms evidence individual case system glitches users behave desired 
demonstrated graphical modeling algorithms handle problem missing data naturally efficiently 
evaluation explanations existing techniques similar difference techniques existing ones solutions important discussed detail separately chapter chapters 
general existing filtering solutions proposed separately ad hoc 
principled way model different aspects active learning prior knowledge heuristics combining multiple forms evidence combine filtering literature 
empowered bgm specific techniques demonstrate power proposed framework guide building filtering system desired characteristics 
worth mentioning bayesian graphical modeling framework general scientific way develop filtering solutions desired characteristics 
provides guidance give better algorithms technique developed framework guaranteed best 

limitation directions contribution filtering solutions developed dissertation motivated filtering problem contributions potential applications thesis go filtering 
summarizes contributions aspects contribution user modeling built longer term learning environment study demonstrated collect significant amount data user interests 
second built user independent user specific models data 
modeled information need user utility function set broader realistic distinct criteria topical relevance novelty readability authority 
prior talking modeling users going topical relevance 
prior works usually come weighted bag words 
explicitly modeling different criteria learning importance criterion probabilistic inference algorithm data filtering system goes bag words approach combines multiple forms evidence 
broader sophisticated realistic data driven user modeling approach may lead system serves user better 
contribution machine learning online learning system usually needs consider immediate cost credit longer term rewards 
utility divergence derived chapter new model quality measure generalizes existing ones active learning 
exploration exploitation trade solution measure combines direct indirect cost reward unified framework optimizes utility explicitly enabling learning algorithm active learning conservative aggressive 
specific techniques developed restricted filtering domain 
tasks domain expert knowledge heuristics provided active learning may help multiple forms evidence available techniques applied 
limitation directions dissertation demonstrated effectiveness bayesian graphical models building intelligent filtering system desired characteristics filtering problem far solved 
discussed open questions specific techniques developed relevant chapters highlight important limitations directions 
chapter 
computationally efficient techniques demonstrated bayesian graphical modelling approach enables go relevance build complex user models 
complex models may lead higher computational cost computational complexity major limitation proposed framework 
surprisingly limitation reflected solutions developed 
example chapter applied active learning technique solve dimensional problem setting dissemination thresholds lr rocchio high dimen sional space learn term weights keywords phrases 
stops going low dimensional active learning high dimensional active learning computational complexity estimating inte equation 
metropolis sampling algorithm chapter works fine low dimensional spaces practical high dimensional space 
section chose directed acyclic graphs dag structures gaussian distri butions conditional probability functions associated node 
causal structure distributions variables learned data show dag gaussian distributions far optimal 
existence efficient learning inference algo rithms gaussian networks availability modeling tools major reasons choice 
believe computational complexity bayesian graphical models unsolvable problem 
exact algorithms section sampling algorithms section dissertation researchers bayesian theory graphical modeling area developed inference algorithms variational algorithms parametric approximations computationally efficient certain situations 
inference algorithms complex models domains 
possible direction algorithms inference filtering 
enable complex graph structure general conditional probability functional forms user modeling 
enable active learning high dimensional space 
user independent user specific cluster specific models build user model filtering problem needs solved decide system learn user specific user independent model 
handled manually dissertation 
section system learned user specific relevance models estimate relevance score document learned user independent readability model estimate readability score document learned user independent graphical models combine multiple forms evidence predict 
limitation directions user specific user independent models user preferences 
choices far optimal 
intuitively answer depends model type relevance model user specific readability model 
preliminary study suggests answer depends specific user table 
problem answered dissertation outstanding problem fundamental limitation proposed framework 
fact bayesian graphical modeling approach provides possible solutions combine models graphical models shown group similar users learn general user model user cluster models user specific models data 
system initially knows little specific user user model user similar parent model system treat general user 
interacting user system learns user feedback gradually user specific model personalized 
challenge user model node learned complex including structure parameters 
develop efficient robust algorithm learn complex hierarchical user model research direction 
temporal property adaptive filtering haven considered temporal property filtering task drifting user interests change user likes topic topic evolutionary pattern document stream utility function defined time 
example analysis evidence indicates distribution data changes time means forms evidence testing data rss link relevance score different training data 
models dissertation assume underlying statistical distributions change time may suffer chapter 
cluster user models 
problem trying learn static model data generated dynamic model 
direction explore dynamic graphical models solve problem 
automatically testing assumptions assumptions dissertation 
direction test assumptions automatically handle situations assumptions hold automatically semi automatically 
example assume rocchio algorithm works better logistic regression early stage filtering limited training data initial query 
assumption may hold rocchio algorithm may implemented perform differently depending dissemination threshold set term weights set aspects filtering system 
trec adaptive filtering tracks rocchio algorithm implemented worst system best systems components affect final performance required rocchio algorithm filtering rocchio algorithm tell 
similarly logistic regression algorithm may perform differently depending prior algorithm set user query logistic regression 
assumed variables normal distribution form symmetric bell shaped curve 
direction test normality measuring skewness tilt kurtosis peakedness distribution statistical tests shapiro wilks test kolmogorov smirnov test test assumption true 
various normalizing transformation correct skew distributions normalizing theoretical sense binary variables 
bayesian framework principled approach strong assumption 
limitation directions normality assumption 
example assume distribution falls exponential family system learn appropriate functional form data 
chapter appendix appendix terminologies 
class group documents sharing common attributes 
example set documents presidential election set documents user considered weird stories 

profile refers systems current representation user information need things related user information needs query threshold keywords vector information system acquired user information needs 
user information needs may represented classes user profile contains classes 
trec data set user profile contains class section 
new yow data set user profile contains classes chapter 

topic class specific subject 
example topic may presidential election 
topic detection tracking task topic defined event activity directly related events activities 
yow user study exit questionnaire topic refer class user created questions designed classes subjects 

event specific thing happens specific time place necessary preconditions unavoidable consequences 

mean average precision map standard evaluation measure ranked retrieval results di pr di dj retrieved relevant information retrieval community 
map document pr dj rn nj nj rank document dj number relevant documents ranked higher document dj 

ad hoc retrieval retrieval process user inputs query receives ranking list results 
query usually formed immediate problem information needs won saved reused 

appendix exit questionnaire 
prior refers information data 
prior information may domain experts knowledge data collection process model developer intuition heuristics 
priors data parameter learning structure learning graphical models 
bayesian theory bayesian prior way express modeler beliefs parameter seeing data 

relevant ambiguously literature narrow definition related matter hand aboutness broader definition ability satisfy needs user 
dissertation definition term user likes meaning described second definition 
appendix exit questionnaire subject applied filled entry questionnaire 
study finished filled exit questionnaire online 
entry questionnaire designed trec interactive track 
collected background information subject 
documentation purposes analyzed dissertation 
exit questionnaire collect user topic specific information users feedback study 
users answered topic specific questions largest topics topics explicit feedbacks 
questions exit questionnaire listed section 
exit questionnaire includes questions 
questions designed research related filtering scope thesis answers won analyzed dissertation 
questions analyzed dissertation filtering system topic topic want read news topic 
familiar topic familiar topic participating study 
topic confidence confidence respect questions related topic 
class specific questions questions asked topic 
user needs choose answer default answer 
depending question meanings answers type don want answer somewhat extremely chapter 
appendix type don want answer great deal questions corresponding answer types listed topic want read news topic 
type familiar topic participating study 
type familiar topic participating study 
type information read everyday www yow com topic 
type information read everyday web sites topic 
type information see day yow read yow 
topic 
type information see day yow read including yow 
topic 
type information see day web site read web site 
topic 
type information see day web site read 
topic 
type think guess information newly available web everyday topic 
type confidence respect response questions related topic 
type user specific questions questions answered user usually decide document relevant don want answer reading title link read article question listed original questionnaire 

appendix exit questionnaire usually decide document redundant don want answer reading title link read article usually decide document readable don want answer reading title source link read article usually decide document don want answer reading title source link read article system provide documents day press ctrl key mouse multiple choices special browser yow install internet tool bar don want change browser changing browser help am sure 
evaluations help system find documents day provide better system works press ctrl key mouse multiple choices provide evaluations day useful provide evaluations day useful provide evaluations day useful provide evaluations day useful provide evaluations day useful provide evaluations day useful provide evaluations week useful chapter 
appendix provide evaluations week useful provide evaluations week useful provide evaluations month useful provide evaluations month useful provide evaluations month useful don want provide evaluations want system find documents hate personalization privacy concerns hate personalization reasons please know read news web sites yow study don want answer lot study usually went web site news day press ctrl key mouse multiple choices yow yahoo news google news wsj cnn bbc usa today post new york times news emails tell system 
tell system 
please tell comments bibliography topic detection tracking tdt task definition evaluation plan 
www nist gov speech tests tdt tdt htm 
topic detection tracking tdt task definition evaluation 
www nist gov speech tests tdt tdt htm 
von el 
predicting protein topology hidden markov model application complete genomes 
journal molecular biology 
aliferis 
causal explorer causal probabilistic network learning toolkit biomedical discovery 
aliferis 
novel markov blanket algorithm optimal variable selection 
proceedings american medical informatics association amia annual symposium 
allan 
incremental relevance feedback information filtering 
proceedings th annual international acm sigir conference research development information retrieval pages 
allan carbonell doddington yamron yang 
topic detection tracking pilot study 
topic detection tracking workshop report 
allan papka lavrenko 
line new event detection tracking 
th annual international acm sigir conference research development information retrieval 
anderson horvitz 
montage dynamic personalized start 
th world wide web conference 
lewis neu kantor 
rutgers filtering trec adaptive batch 
proceeding eleventh text retrieval conference trec 
bibliography 
adaptive temporally dependant document filtering 
phd thesis katholieke uni nijmegen nijmegen 

score distribution threshold optimization adaptive binary clas task 
proceedings th annual international acm sigir conference research development information retrieval pages 
ardissono console torre 
adaptive system personalized access news 
ai communications september 
arnold 
geometrical methods theory differential equations 
springer 
yang 
knn rocchio metrics information filtering trec 
proceeding tenth text retrieval conference trec 
national institute standards technology special publication 
badler chellappa editors 
graphical model image processing 
academic press 
baeza yates ribeiro neto 
modern information retrieval 
addison wesley 
bartell cottrell belew 
automatic combination multiple ranked retrieval systems 
research development information retrieval pages 
jensen chowdhury grossman frieder 
evaluation filtering current news search results 
sigir proceedings th annual international conference research development information retrieval pages 
acm press 
belkin croft 
information filtering information retrieval sides coin 
communications acm 
bennett dumais horvitz 
probabilistic combination text classifiers reliability indicators models results 
sigir 
bernardo smith 
bayesian theory 
john wiley sons 
bernardo smith 
bayesian theory chapter 
john wiley sons 
billsus pazzani 
personal news agent talks learns explains 
agents proceedings third annual conference autonomous agents pages 
acm press 
bibliography 
irit trec filtering track 
proceeding eleventh text retrieval conference trec 
brafman heckerman 
recommendation stochastic sequential decision prob lem 
proceedings 
brin page 
anatomy large scale hypertextual web search engine 
computer networks isdn systems 
hidden markov model local sequence structure correlations proteins 
journal molecular biology aug 
callan 
document filtering inference networks 
proceedings nineteenth annual international acm sigir conference research development information retrieval pages 
cesa bianchi gentile goutte graepel li renders taylor 
kernel method document filtering 
eleventh text retrieval conference trec 
national institute standards technology special publication 
carbonell goldstein 
mmr diversity reranking reordering documents producing summaries 
proceedings st annual international acm sigir conference 
carreira crato gon jorge 
evaluating adaptive user profiles news classification 
iui proceedings th international conference intelligent user interface pages 
acm press 
chai ng 
bayesian online classifiers text classification filtering 
proceedings th annual international acm sigir conference research development information retrieval 
acm 

bayesian design review 

cheng greiner kelly bell liu 
learning data information theory approach 
artificial intelligence journal volume pages 
bibliography chickering 
toolkit 
technical report msr tr microsoft redmond wa 
claypool le brown 
implicit interest indicators 
intelligent user interfaces 
cohn ghahramani jordan 
active learning statistical models 
journal artificial intelligence research pages 
ai access morgan kaufmann 
collins thompson callan 
language modeling approach predicting reading difficulty 
proceedings hlt naacl conference 
collins thompson zhang callan 
information filtering novelty detection named page finding 
proceeding eleventh text retrieval conference trec 
conati vanlehn druzdzel 
line student modeling coached problem solving bayesian networks 
proceedings sixth international conference user modeling pages 
cowell dawid lauritzen spiegelhalter 
probabilistic networks expert systems 
springer 
croft allan fisher feng larkey callan lafferty yau si collins thompson turtle zhai 
lemur toolkit language modeling information retrieval 
www cs cmu edu lemur 
croft lafferty editors 
language modeling information retrieval 
kluwer 
croft allan belkin 
collaborative research supporting effective access user topic language models 
rutgers edu proposal htm 
dash yuan 
genie smile development environment building decision theoretic models 
www sis pitt edu genie 
domingue scott 
kmi planet web news server 
proceedings third asian pacific computer human interaction page 
ieee computer society 
dumais sarin robbins 
stuff seen system personal information retrieval re 
proceedings th annual international conference research development information retrieval 
bibliography maximum likelihood incomplete data em algorithm 
royal statistical soc 
franklin giles 
self adaptive user profiles large scale data deliv ery 
icde proceedings th international conference data engineering page washington dc usa 
ieee computer society 
faloutsos oard 
survey information retrieval filtering methods 
technical report univ maryland college park 
fox 
expending boolean vector space models information retrieval norm queries multiple concept types 
phd thesis cornell university 
fox dumais white 
evaluating implicit measures improve web search 
acm trans 
information systems volume pages new york ny usa 
acm press 
freund seung shamir tishby 
selective sampling query committee algorithm 
machine learning pages 
fuhr 
probabilistic models information retrieval 
computer journal volume pages 
fuhr buckley 
probabilistic learning approach document indexing 
acm transac tions information systems pages 
fung 
applying bayesian networks information retrieval 
communications acm ff 
geman bienenstock doursat 
neural networks bias variance dilemma 
proceedings eighth text retrieval conference trec pages 
neural computation 
geman geman 
stochastic relaxation gibbs distributions bayesian restoration images 
ieee trans 
pattern anal 
machine intell 
harman 
overview trec novelty track 
eleventh text retrieval conference trec pages 
national institute standards technology special publication 
bibliography heckerman chickering meek kadie 
networks inference collaborative filtering data visualization 
journal machine learning research pages 
henzinger 
chang brin 
query free news search 
www proceedings twelfth international conference world wide web pages 
acm press 
hersh buckley leone 
ohsumed interactive retrieval evaluation new large test collection research 
proceedings seventeenth annual international acm sigir conference research development information retrieval pages 
horvitz breese heckerman 
lumiere project bayesian user modeling inferring goals needs software users 
proceedings fourteenth conference uncertainty artificial intelligence july 

selective dissemination information 
editor annual review information science technology 
vol 

american information science 
hull pedersen sch tze 
method combination document filtering 
sigir 
jaakkola jordan 
bayesian logistic regression variational approach 
statistics computing pages 
jensen 
bayesian networks decision graphs 
springer 
joachims 
probabilistic analysis rocchio algorithm tfidf text categorization 
proceedings international conference machine learning icml 
joachims 
text categorization support vector machine 
proceedings european con ference machine learning 
springer verlag 
jones walker robertson 
probabilistic model information retrieval develop ment comparative experiments part 
information processing management 
jordan editor 
learning graphical models 
mit press 
jordan 
graphical models 
statistical science special issue bayesian statistics 
bibliography jordan ghahramani jaakkola saul 
variational methods graphical models pages 
mit press cambridge ma usa 
kelly 
implicit feedback inferring user preference bibliography 
sigir forum 
kleinberg 
authoritative sources hyperlinked environment 
proc 
th acm siam symposium discrete algorithms 
koller sahami 
optimal feature selection 
international conference machine learning pages 
lafferty zhai 
document language models query models risk minimization infor mation retrieval 
proceedings th acm sigir conference september 

lai 
liang ku 
customized internet news services customer profiles 
icec proceedings th international conference electronic commerce pages 
acm press 
lam 
lai 
meta learning approach text categorization 
sigir 
lang 
newsweeder learning filter news 
proceedings twelfth international conference machine learning 
larkey croft 
combining classifiers text categorization 

frei harman sch wilkinson editors proceedings sigir th acm international conference research development information retrieval pages rich ch 
acm press new york 
lavrenko croft 
relevance language models 
research development information retrieval pages 
le waseda 
curious browser implicit ratings 
www cs wpi edu claypool mqp iii 

lee 
trec experiments nii effects virtual relevant documents batch filtering 
proceeding eleventh text retrieval conference trec 
bibliography lewis 
applying support vector machines trec batch filtering routing tasks 
proceeding eleventh text retrieval conference trec 
lewis catlett 
heterogeneous uncertainty sampling supervised learning 
proceedings eleventh international conference machine learning 
morgan kaufmann 
lindley 
bayesian statistics review 
society industrial applied mathematics siam 
little rubin 
statistical analysis missing data 
john wiley sons new york ny usa 
losee bookstein 
integrating boolean queries conjunctive normal form proba retrieval models 
information processing management 
ma chen ma zhang cai 
incremental learning profile training adaptive document filtering 
proceeding eleventh text retrieval conference trec 
mackay 
learning graphical models chapter monte carlo methods pages 
mit press 

continuous multi armed multiparameter processes 
ann 
probab pages 
thrun 
bayesian network induction local neighborhoods 
advances neural information processing systems 

empirical bayes method 
chapman hall edition 
martin doddington kamm 
det curve assessment detection task performance 
proceedings eurospeech 
massey 
kolmogorov smirnov test goodness fit 
journal american statistical association 
mccallum nigam 
comparison event models naive bayes text classification 
aaai workshop learning text categorization 
mccallum nigam 
employing em pool active learning text classification 
proceeding international conference machine 
bibliography mceliece mackay cheng 
turbo decoding instance pearl belief propagation algorithm 
ieee sel 
areas comm number 
turner editors 
causality crisis statistical methods search causal knowledge social science 
university notre dame press 
mcnamee mayfield 
jhu apl trec experiments filtering arabic retrieval 
proceeding eleventh text retrieval conference trec 
mei zhai 
discovering evolutionary theme patterns text exploration temporal text mining 
merialdo lee 
automatic construction personalized tv news programs 
multimedia proceedings seventh acm international conference multimedia part pages 
acm press 
minka 
family algorithms approximate bayesian inference 
phd thesis massachusetts institute technology jan 
morita 
information filtering user behavior analysis best match text retrieval 
proceedings th annual international acm sigir conference research development information retrieval pages 
springer verlag new york 
murphy 
bayes net toolbox matlab 
computing science statistics 
murphy 
dynamic bayesian networks representation inference learning 
phd thesis univer sity california berkeley 
ng jordan 
discriminative vs generative classifiers comparison logistic regression naive bayes 
proceeding fourteenth neural information processing systems 
pearl 
probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann publishers 
pearl 
causality models reasoning inference 
cambridge university press 
petri myllymaki petri kontkanen 
course web data analysis tool 
course hiit fi 

rss 
www xml com pub dive xml html 
bibliography pynadath wellman 
accounting context plan recognition application traffic monitoring 
proceedings eleventh conference uncertainty artificial intelligence 
shen ng mccallum 
classification hybrid generative discriminative models 
nips 
theoretical basis occurrence data information retrieval 
journal documentation pages 
robertson 
theoretical argument information retrieval 
salton award lecture sigir july 
robertson 
threshold setting adaptive filtering 
journal documentation 
robertson hull 
trec filtering track report 
ninth text retrieval conference trec pages 
national institute standards technology special publication 
robertson 
trec filtering track final report 
proceeding tenth text retrieval conference trec pages 
national institute standards technology special publication 
robertson 
trec filtering track report 
proceeding eleventh text retrieval conference trec 
robertson sparck jones 
relevance weighting search terms 
journal american society information science volume pages 
robertson walker 
threshold setting adaptive filtering 
journal documentation pages 
robertson walker 
microsoft cambridge trec filtering track 
proceeding ninth text retrieval conference trec pages 
national institute standards technology special publication 
rocchio 
relevance feedback information retrieval 
smart retrieval system experi ments automatic document processing pages 
prentice hall 
rubinstein hastie 
discriminative vs informative learning 
proceedings third international conference knowledge discovery data mining pages 
bibliography salton buckley 
term weighting approaches automatic text retrieval 
information processing management volume 
salton mcgill 
modern retrieval 
mcgraw hill 
schafer graham 
missing data view state art 
psychological methods volume 
schafer olsen 
multiple imputation multivariate missing data problems data analyst perspective 
multivariate behavioral research 
schamber bateman 
user criteria relevance evaluation development mea scale 
asis annual conference proceedings october 
schapire singer singhal 
boosting rocchio applied text filtering 
proceedings st annual international acm sigir conference research development information retrieval pages 
scheines spirtes glymour meek 
www phil cmu edu projects tetrad index html 
brafman heckerman 
mdp recommender system 
proceedings uai 
shapiro 
analysis variance test concrete samples 
biometrika 
shen zhai 
active feedback uiuc trec hard experiments 
proceeding text retrieval conference trec 
national institute standards technology special pub 
silva ribeiro neto moura ziviani 
link content evidential information belief network model 
proceedings rd annual international acm sigir conference research development information retrieval pages 
acm press 
spirtes glymour scheines 
causation prediction search 
mit press 
srikanth wu srihari 
ub trec batch adaptive filtering 
proceeding eleventh text retrieval conference trec 
bibliography stricker dreyfus 
training context sensitive neural networks relevant examples trec routing 
ninth text retrieval conference trec 
national institute standards technology special publication 
sugiyama yoshikawa 
adaptive web search user profile constructed effort users 
www proceedings th international conference world wide web pages 
acm press 
tanner 
tools statistical inference 
springer edition 
thomas spiegelhalter gilks 
bugs program perform bayesian inference gibbs sampling 
bayesian statistics pages 
tong 
active learning theory applications 
phd thesis stanford university 
tong koller 
active learning parameter estimation bayesian network 
neural information processing systems nips 
turtle 
inference networks document retrieval 
phd thesis university massachusetts october 
van rijsbergen 
information retrieval nd edition 
dept computer science university glasgow 
varian 
economics search invited talk sigir 
voorhees editors 
nist special publication eleventh text retrieval conference trec 
department commerce national institute standards technology 
wang 
cognitive model document selection real users ir systems 
phd thesis university maryland 
wayne 
multilingual topic detection tracking successful research enabled corpora evaluation 
lrec 
wen lao ma 
probabilistic models contextual retrieval 
proceedings seventh annual international acm sigir conference research development information retrieval 
bibliography white jose 
implicit feedback approach interactive information retrieval 
information processing management 
wu huang niu xia feng zhou 
trec filtering web video tasks 
proceeding eleventh text retrieval conference trec 
yang 
study thresholding strategies text categorization 
proceedings acm sigir conference research development information retrieval sigir pages 
yang pierce 
combining multiple learning strategies effective cross validation 
langley editor proceedings icml th international conference machine learning pages stanford 
morgan kaufmann publishers san francisco 
yang 
margin local regression adaptive filtering 
proceedings international conference information knowledge management cikm 
acm press 
yang yoo zhang 
robustness adaptive filtering methods cross benchmark evaluation 
proceedings th annual international acm sigir conference research development information retrieval 
yedidia freeman weiss 
generalized belief propagation 
advances neural infor mation processing systems nips volume pages 
national institute standards technology special publication december 
zhai cohen lafferty 
independent relevance methods evaluation metrics subtopic retrieval 
zhai jansen stoica 
threshold calibration clarit adaptive filtering 
proceeding seventh text retrieval conference trec pages 
national institute standards technology special publication 
zhai lafferty 
study smoothing methods langauge models applied ad hoc informa tion retrieval 
proceedings th annual international acm sigir conference research development information retrieval pages september 
zhang 
bayesian priors combine classifiers adaptive 
proceedings th annual international acm sigir conference research development information retrieval 
bibliography zhang callan 
maximum likelihood estimation filtering thresholds 
proceedings th annual international acm sigir conference research development information retrieval pages 
zhang callan 
bias problem language models adaptive filtering 
tenth text retrieval conference trec pages 
national institute standards technology special publication 
zhang callan minka 
novelty redundancy detection adaptive filtering 
proceedings th annual international acm sigir conference research development information retrieval 
zhang xu callan 
exploration exploitation adaptive filtering bayesian active learning 
proceeding international conference machine icml 
