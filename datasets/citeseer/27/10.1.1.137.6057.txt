ieee transactions information theory vol 
february improved low density parity check codes irregular graphs michael luby michael mitzenmacher amin shokrollahi daniel spielman construct new families error correcting codes gallager low density parity check codes 
improve gallager results introducing irregular parity check matrices new rigorous analysis hard decision decoding codes 
provide efficient methods finding irregular structures decoding algorithms 
rigorous analysis martingales methodology constructing irregular codes demonstration irregular structure improves performance constitute key points contribution 
consider irregular codes belief propagation 
report results experiments testing efficacy irregular codes binary symmetric gaussian channels 
example belief propagation rate codes bits binary symmetric channel previous low density parity check codes correct approximately errors codes correct 
cases results come close reported results turbo codes suggesting variations irregular low density parity check codes may able match beat turbo code performance 
index terms belief propagation concentration theorem gallager codes irregular codes low density parity check codes 
low density parity check codes introduced gallager subject experimentation analysis :10.1.1.35.5754
interest codes stems near shannon limit performance simple descriptions implementations amenability rigorous theoretical analysis manuscript received april revised september 
luby supported part national science foundation operating ncr 
mitzenmacher supported part alfred sloan research fellowship national science foundation career ccr 
shokrollahi partially supported deutsche forschungsgemeinschaft sh 
spielman supported part national science foundation mathematical sciences fellowship nsf career award ccr sloan award mit school science 
material part th annual acm symposium theory computing dallas tx may 
luby shokrollahi international computer science institute berkley ca digital equipment systems research center palo alto ca 
digital fountain san francisco ca usa mail luby digital fountain com amin digital fountain com 
mitzenmacher digital equipment systems research center palo alto ca 
harvard university cambridge ma usa mail eecs harvard edu 
spielman department mathematics massachusetts institute technology cambridge ma usa mail spielman math mit edu 
communicated kschischang associate editor coding theory 
publisher item identifier 
ieee :10.1.1.35.5754:10.1.1.35.5754
connections codes turbo codes introduced berrou glavieux described framework low density parity check codes see 
turbo decoding algorithm understood belief propagation algorithm understanding belief propagation low density parity check codes may applicable turbo codes 
find helpful describe low density parity check codes terms bipartite graphs 
refer nodes left right bipartite graph message nodes check nodes respectively 
bipartite graph nodes left nodes right gives rise linear code dimension block length way 
bits codeword indexed message nodes 
binary vector codeword incidence matrix graph rows indexed check nodes columns indexed message nodes 
words codeword check node exclusive incident message nodes zero 
note methodology construct codes encoded linear time similar rate error correction threshold cascading series bipartite graphs described :10.1.1.35.5754
convenience address issue 
specific details section ii 
previously studied low density parity check codes constructed sparse regular nearly regular random bipartite graphs :10.1.1.35.5754
degrees message nodes equal degrees check nodes equal 
means parity check matrix code described contains number ones row number ones column 
call codes regular codes 
improved performance comes codes irregular graphs 
degrees nodes side graph vary widely 
terms parity check matrix weight row column uniform governed appropriately chosen distribution weights 
carefully choosing distributions achieve improved performance 
fact codes describe number largely disparate weights suggesting best distributions far produce regular codes 
irregular structure improves performance surprising light rigorously proving power irregular graphs designing erasure correcting codes :10.1.1.35.5754
irregular graphs appear rarely studied ieee transactions information theory vol 
february setting error correcting codes difficulty determining irregular structures perform 
techniques finding erasure correcting codes determined provide basis codes techniques develop :10.1.1.35.5754
offer intuition irregular graphs improve performance 
consider trying build regular low density parity check code transmits fixed rate 
convenient think process game message nodes check nodes players player trying choose right number edges 
constraint game message nodes check nodes agree total number edges 
point view message node best high degree information gets check nodes accurately judge correct value 
contrast point view check node best low degree lower degree check node valuable information transmit back neighbors 
competing requirements appropriately balanced 
previous shown regular graphs low degree graphs yield best performance 
allows irregular graphs significantly flexibility balancing competing requirements 
reason believe wide spread degrees message nodes useful 
message nodes high degree tend correct value quickly 
nodes provide information check nodes subsequently provide better information lower degree message nodes 
irregular graph constructions potential lead wave effect high degree message nodes tend get corrected message nodes slightly smaller degree line 
intuition observe experiments unfortunately provide clues construct appropriate irregular graphs 
meet challenge ways 
design rigorous analysis regular irregular graphs hard decision decoding algorithm suggested gallager 
decoders perform belief propagation expect schemes may useful practice simpler require memory 
main motivation studying model provable asymptotic statements performance hard decision decoding irregular graphs 
ideas studying random processes show section ii high probability hard decision decoding successfully corrects arbitrarily small constant fraction message bits 
number erroneous bits reduced level switch gallager algorithm spielman sipser prove section ii new hybrid method successfully finishes decoding high probability 
analysis easily extends irregular codes introduce section iii 
additionally bound probability error derive methodology improves bound derived gallager regular graphs explicitly constructed 
emphasize approach differs strongly gallager original approach assume graphs lack small cycles 
analysis applies randomly chosen graphs 
analysis develop section iii methods linear programming find irregular graph structures hard decision decoding algorithm 
corresponding degree distributions tested extensively report tests section iv 
second way meet challenge designing irregular graphs test belief propagation algorithm graphs proven effective erasure correcting codes :10.1.1.35.5754
intuitively graphs erasure correcting codes error correction codes closely related 
example improved performance rate irregular code message bits corrects random errors high probability experiments 
message bits similar code corrects random errors experiments 
contrast best regular code corrects approximately random errors message bits approximately message bits 
shannon bound rate codes 
report experiments simulations belief propagation algorithm section 
note originally appeared great deal progress area 
particular davey mackay demonstrates approach improving low density parity check performance treating small numbers bits elements appropriate finite field 
irregular graphs technique cases matched turbo code performance 
richardson urbanke richardson shokrollahi urbanke extends analysis section ii message passing systems message take finite number values 
extensions obtained nearly tight provable bounds regular irregular codes belief propagation developed techniques designing irregular graphs perform belief propagation 
ii 
analyzing message passage decoding section consider message passing algorithm round bit passed direction edge 
message passing scheme analyzed specific regular codes gallager 
new analysis extends random regular irregular graphs 
demonstrate irregular graphs greatly improve performance decoding scheme 
ease presentation detail arguments regular graphs 
regular graphs described section bipartite graph message nodes left check nodes right gives rise linear code dimension block length way bits codeword indexed message nodes 
binary vector codeword incidence matrix graph rows indexed check nodes luby improved low density parity check codes graphs columns indexed message nodes 
words codeword check node exclusive incident message nodes zero 
allow encoding linear time allow nodes right represent bits restrictions cascading series bipartite graphs described example :10.1.1.35.5754
situation know inductively correct value check nodes layer correct message nodes check nodes exclusive incident message nodes 
resulting code rate error correction threshold corresponding low density parity check code likelihood decoding error increases 
follows focus bipartite graph assume message nodes error 
analysis provide case works approaches may inductively focus just layer context cascading series graphs :10.1.1.35.5754
review hard decision decoding approach taken gallager original analysis :10.1.1.35.5754
consider regular random graph message nodes having degree check nodes having degree probability message node receives wrong bit 
decoding process proceeds rounds round message nodes send incident check node single bit check nodes send incident message node single bit 
bit sent message node check node th step decoding denoted message sent check node message node round denoted bit guess correct bit message bit round similarly guess point view check node correct value 
messages passed contain extrinsic information value depends values check nodes incident 
similarly message node remembers received bit purported correct message bit 
correct message bit probability assume zeroth round process messages sent message nodes check nodes 
subsequent round consists edges parallel update fig 

representing code tree 
passing messages check nodes message nodes back 
full detail round consists execution script bottom page 
course parallel easily simulated sequentially 
round easily coded linear number edges 
process run preset number rounds message node determine value neighbors 
check nodes satisfied codeword decoding failed 
alternatively round message node determine value check performed see codeword 
process continues decoder decides failure 
analyze decoding process consider individual edge message node check node associated tree describing neighborhood tree rooted tree branches check nodes excluding shown fig 

assume neighborhood accurately described tree fixed number rounds 
probability sends incorrect value round initially gallager determine recursive equation describing evolution constant number rounds 
consider th round consider check node node sends correct value long number including possibly message zeroth round set th round computed follows equals adjacent check nodes set set update edges set exclusive values ranges adjacent message nodes ieee transactions information theory vol 
february nodes sending wrong bit 
bit correctly sent probability easy check probability receives number errors probability received error sent correctly round similarly probability received correctly sent incorrectly round yields equation terms gallager idea find supremum values sequence monotonically decreasing converges note converges directly imply process necessarily corrects message nodes high probability 
assumption neighborhood accurately represented tree arbitrarily rounds true 
fact constant number rounds true high probability 
gallager proves block length code girth graph grow large decoding algorithm works random graphs large girth gallager introduced explicit constructions regular sparse graphs sufficiently large girth analysis hold 
shortly provide analysis shows gallager decoding algorithm successfully corrects large fraction errors randomly chosen regular graph high probability 
section ii show ensure decoding terminates successfully high probability slightly different decoding rule 
gallager notes decoding rule improved manner round universal threshold value determined depends round number 
message node neighboring check node neighbors excluding sent bit previous round sends bit round sends initial bit rest decoding algorithm 
analysis may find recursive description choose minimize compare odds right initially odds right check nodes threshold determined gallager correct choice smallest integer satisfies note increasing function intuitive decreases smaller needed get accurate assessment correct value 
note algorithm functions passing values edges keep running guess value message node passed values 
algorithm continues proposed values message nodes satisfy check nodes point algorithm terminates belief successfully decoded message fail preset number rounds 
follows simply similar argument recursive description correct high probability constant number rounds 
note similar extension proof original appeared subsequent richardson urbanke 
theorem integer constant random variable describing fraction edges set pass incorrect messages rounds algorithm 
recursion 
constant depending maximum degree sufficiently large proof number edges graph 
show equivalent assertion algorithm neighbors message node disagree received bit change message nowadays referred gallager algorithm improvement referred gallager algorithm experiments analysis apply gallager algorithm general sense predetermined values course gallager algorithm just special case 
luby improved low density parity check codes graphs considerations requiring care 
neighborhood message bit may take form tree 
show happen edge exposure martingale argument 
second assuming number small need prove tight concentration expectation message bits may wrong initially probability follows separate martingale argument exposing initial values node 
consider number edges expand neighborhood levels obtain tree 
edges say behavior show 
note number nodes tree levels exponential necessarily implies number nodes graph exponential recall statement theorem fixed constant taken sufficiently large 
easily seen constant depending maximum degree graph probability neighborhood depth stemming edge tree see consider neighborhood stemming edge expanding outward level level edge time 
fewer total nodes tree probability step edge neighborhood hits vertex neighborhood bounded union bound total probability neighborhood fails tree bounded suitable constant expected number edges fail neighborhood structure tree constant 
concretely sufficiently large value number edges neighborhood levels proper tree obtain obtain concentration result exposing edges graph edge exposure martingale applying azuma inequality sec 

particular think terms exposing permutation defines bipartite graph entry time order 
may define expected value results exposures 
particular sequence forms standard martingale consecutive values differ constant show lemma 
azuma inequality lemma bounded constant 
proof consider possible results exposing st edge 
value bounded maximum difference expectation results 
turn bounded maximum difference value permutations differ placement edges 
consider possible results correspondence remaining possibilities correspondence agree places 
expectation possibilities differs maximum difference value permutations differ placement edges 
consider pair graphs permutations differ placement edges 
case difference bounded constant placement edges affect constant number trees constant depending maximum degree 
lemma proved 
number edges edges valid tree neighborhoods levels set pass incorrect messages rounds 
clearly obtain high probability result martingale argument 
may reveal initial value received node time 
may define expected value results exposures case form standard martingale 
easy see consecutive values differ constant revealed node affect edges lies corresponding tree 
assertion follows inequalities constant corollary random regular code defined sequence converges sufficiently large message size gallager hard decision decoding correctly decodes bits constant number rounds high probability 
completing expander arguments previous section shown hard decision decoding corrects arbitrarily small constant fraction message nodes regular codes sufficiently large block lengths 
analysis sufficient show decoding process completes successfully 
section show finish decoding process high probability number errors sufficiently small slightly different algorithms 
utilizes expander arguments 
alternatively able construct similar argument approach 
note miller shows ieee transactions information theory vol 
february hard decision decoding algorithm guaranteed correct message nodes corrected sufficiently large fraction message nodes provided underlying graph sufficiently expander 
change decoding algorithm suggested section technically unnecessary include completeness 
define require terms bipartite graph represented code expander 
definition bipartite graph expansion subsets size vertices left size neighborhood right satisfies set edges attached vertices notation call message node corrupt differs correct value call check node satisfied respectively unsatisfied value sum values adjacent message nodes 
shows underlying bipartite graph code sufficient expansion sets size algorithms correct set errors message node satisfied unsatisfied neighbors flip value message node 
repeat message node remains 
message node count number unsatisfied check nodes neighbors 
flip parallel message node majority unsatisfied neighbors 
note algorithms similar gallager hard decision decoding algorithm need hold values message node check node pair 
call results show hard decision decoding correct arbitrarily small fraction message nodes finish process 
lemma follows theorems 
lemma fixed expander 
sequential parallel decoding algorithms correct errors 
sequential decoding algorithm linear time parallel decoding algorithm rounds round requiring linear amount 
standard lemma claim graph choose appropriate expander finish analysis decoding process previous lemma 
lemma bipartite graph nodes divided left right sides 
suppose degree assigned node left nodes degree right nodes degree constant suppose random permutation chosen match edge left node edge right node 
probability fixed expander 
fig 

left nodes supposed nodes correct majority tells left nodes change 
note restriction lemma left degrees appears necessary 
example entirely possible random graphs degree left fail complete proposed sequential parallel algorithms nodes corrected 
problem occurs graph small cycle 
case nodes cycle received incorrectly algorithm may fail terminate correctly see fig 

cycles constant length occur constant probability errors remain constant probability 
circumvent problem gallager designs specific regular graphs small cycles :10.1.1.35.5754
circumvent problem random graphs small change structure graph similar :10.1.1.35.5754
suppose previous analysis correct message bits high probability 
add additional check nodes constant depends construct regular random graph degree left message nodes check nodes 
decoding proceeds original random graph correcting message bits 
check nodes previously held reserve correct remaining message bits sipser spielman algorithm 
procedure works follows directly lemmas 
arbitrarily small corollary change rate code due additional structure negligible ignored sequel 
theoretically achievable error correction rate possible left degree corresponding right degree value computed analysis 
natural question ask regular code achieve largest value rate regular codes turns largest achieved left nodes degree right nodes degree case combining corollary lemma lemma shown corresponding bipartite graph chosen randomly code correct errors high probability initial fraction errors approaches regular codes run linear time sequential decoding algorithm final stage 
follows fact need run hard decision decoding constant number rounds linear time round sequential decoding algorithm fix remaining errors linear time 
luby improved low density parity check codes graphs iii 
irregular codes analyzing irregular codes describe decoding algorithm codes irregular graphs call irregular codes 
describe construction codes 
message nodes located left check nodes right 
message node certain number edges connect check nodes similarly check node certain number edges connecting message nodes 
total number edges graph random permutation chosen edge index left side identified edge index right side 
note may potentially lead nodes edges practice small cycles removed improve performance 
notation irregular bipartite graph say edge degree left right left right hand neighbor degree suppose irregular bipartite graph maximum left degree maximum right degree specify irregular graph sequences fraction edges left right degree define decoding algorithm case irregular graphs similar gallager hard decision decoding described section ii generalized take account varying degrees nodes :10.1.1.35.5754
look process point view edge consider th round consider check node node sends correct value long number including possibly message nodes sending wrong bit 
bit correctly sent probability simple check probability number errors receives expression generalization account probability distribution degree similarly section ii round message node degree passes initial value check node check nodes adjacent send value 
note threshold value node depends degree 
value changes round 
analyze decoding process consider random edge left degree probability follows argument section ii recursive description need determine minimize value best value smallest integer satisfies equation interesting interpretation 
note constant fixed equation 
value interpreted difference number check nodes agree majority number agree minority 
call difference discrepancy node 
equation tells need check discrepancy certain threshold decide value send regardless degree node 
designing irregular graphs describe techniques designing codes irregular graphs handle larger probabilities error potentially expense encoding decoding time 
analysis irregular codes goal find sequences yield largest possible value sequence decreases rate 
frame problem terms linear programs 
approach determine best sequences technique allows determine vector vector desired rate code 
proves sufficient finding codes perform significantly better regular codes 
similarly may apply technique determine vector vector desired rate explain prove useful setting 
fixed 
degree sequence real valued function defined ieee transactions information theory vol 
february variables determined 
observe condition reads right hand degree sequence interested finding degree sequence corresponding function satisfies open interval choosing set positive integers constitute range possible degrees left hand side 
find appropriate condition generate linear constraints satisfy considering different values example examining condition obtain constraint linear generate constraints form values multiples integer include constraints constraint rate code 
condition expresses fact number edges incident left nodes equals number edges incident right nodes 
linear programming determine suitable exist satisfy derived constraints 
choice objective function arbitrary interested existence feasible solutions 
solution linear programming problem check computed satisfy condition best value binary search 
due discretization usually conflict intervals solution satisfy inequality 
choosing large values tradeoff parameter results smaller conflict intervals requires time solve linear program 
reason small values binary search phase 
value larger values specific obtain small conflict intervals 
step get rid conflict intervals slightly decreasing value linear programming tool allows efficient search codes 
vector find partner vector similar fashion find partner vector experiments reveal best vector decoding algorithm nodes right degree nodes close degree possible 
natural intuition explaining phenomenon 
point view message node appears best expected number neighbors neighboring check node small possible 
seen follows 
th round probability sends correct vote small values approximately maximize probability seek minimize exactly expected number neighbors 
quantity minimized subject constraints check nodes equal degree nearly equal possible 
linear programming technique considered graphs nodes left side may varying degrees nodes right side degree 
words codes considering vectors just nonzero entry 
shall see section iv suffices find codes significantly better performance codes determined regular graphs 
remains show codes derive manner fact function expect 
vector right degree initial error probability sequence monotonically decreasing converges code obtained corresponding irregular random graph corrects fraction errors high probability 
note theorem holds irregular graphs regular graphs entirely similar proof modified take account different degrees 
hard decision decoding algorithm decrease number erroneous bits constant fraction 
finish decoding sequential algorithm section ii 
decoding time linear 
note miller shown hard decision decoding algorithm finish decoding result gorithm 
time lemma fixed suppose irregular bipartite expander maximum degree left node sequential decoding algorithm corrects linear time 
errors proof follow theorem 
show number unsatisfied check nodes decreases step sequential algorithm 
set corrupt message nodes suppose unsatisfied check nodes number satisfied neighbors corrupt variables 
expansion wehave satisfied neighbor shares edges unsatisfied neighbor shares follows message node incident check nodes unsatisfied 
step se luby improved low density parity check codes graphs table parameters codes algorithm may flip message node decrease number unsatisfied check nodes 
way algorithm fail number corrupt message nodes increases algorithm 
initially decreases course algorithm happen 
follows irregular codes derive function expect long random graphs sufficient expansion 
expansion property holds high probability choose minimum degree 
stated previously graphs message nodes smaller degree may handled small additional structure graph 
theoretically achievable error correction designed irregular degree sequences linear programming methodology described section iii 
codes describe rate codes perform practice theoretical model 
find codes perform slightly better codes techniques 
worth noting shannon upper bound entropy bound codes rate 
irregular codes designed date far limit better regular codes 
code code described fully table irregular codes designed 
code nodes right degree code nodes right degree codes minimum degree left hand side 
ensures graphs expansion needed lemma need additional structure discussed section ii 
achieve better performance considering graphs smaller degrees left 
graphs balance number edges allow node right different degree 
sufficient expansion lemma hold additional structure discussed section ii finish decoding 
code nodes right degree code nodes right degree recall best value possible regular graphs rate codes 
iv 
experimental results gallager algorithm include preliminary experimental results new codes linear programming approach 
experimental design similar results compared 
describe important details experiments implementations 
model binary symmetric channel 
accurately compare code quality introducing errors probability introduced number errors trial corresponding fraction block length 
procedure allows easier comparison codes minimizes variance experiments arise variance number errors 
encoding message trial initial message consisting entirely zeros 
code linear decoding algorithm respects linearity generality lost 
different random graph constructed trial 
effort test graphs weed potentially bad ones expect results slightly better random graphs tested best ones chosen 
ideas necessary remove graphs 
implementation simply run gallager improved decoding algorithm thresholds finishes prespecified number rounds pass success 
implementation takes input schedule determines discrepancy value round 
schedule calculated 
practice schedule determined slightly modified 
discrepancy threshold changed prematurely edges transfer correct value decoding algorithm significantly fail 
changing threshold round fails block size small variance number edges sending correct value significant 
find stretching schedule somewhat discrepancy threshold changed rounds equations suggest prevents problem expense increasing running time decoding algorithm 
experiments turns unnecessary switch modified decoding algorithm section ii additional structure described section ii experience hard decision decoding algorithm gallager finishes successfully number errors small 
worthwhile note decoding algorithm fails decode successfully rounds passed report failure back 
see decoding algorithm produce codeword satisfied constraints original message far know event possible 
ieee transactions information theory vol 
february fig 

percentage successes trials 
experiments hard decision decoding describe experiments codes rate message bits check bits 
fig 
describe performance code code introduced section iii 
data point represents results trials 
recall appropriate value approximately code code recall represents error rate expect able handle arbitrarily long block lengths expect approach grows 
asymptotically practice number nodes results show block lengths length codes appear perform extremely random fraction original message bits error 
trials code failed code failed just 
fact trials number errors code proved successful time 
probability code succeeds falls slowly error probability approaches experiments larger block lengths demonstrate performance improves number bits message expect 
codes perform better similar regular codes having linear running time 
instance mentioned best regular code rate obtained random regular bipartite graphs degree left degree right 
performance code shown fig 

value regular code approximately practice message bits regular code failed times trials fraction errors 
consider code code introduced section iii see fig 

experiments run message bits check bits trials 
experiments remove small cycles suggested 
recall appropriate value approximately code code codes perform near analysis suggests significantly outperform previous similar codes similar decoding schemes including regular codes 
summary irregular codes code code appear superior regular code practice irregular codes code code far superior regular code 
similarly irregular codes perform rates 
low density parity check codes belief propagation section review belief propagation low density parity check codes developed gallager framework mackay neal :10.1.1.35.5754
similar hard decision decoding algorithm section ii extrinsic information passed message bits check bits back 
explained algorithm runs alternating phases nonzero entry row column terms edge associated bipartite graph values iteratively updated 
quantity approximates probability th bit codeword information obtained checks similarly quantity approximates probability th check node satisfied th bit codeword message bits associated check separable distribution appropriate assume message bits independently probability calculate binary symmetric channel crossover probability initially value phase round values updated parallel second phase values updated parallel 
parallel updates simulated sequentially straightforward manner 
total amount performed round linear number edges graph 
bipartite graph defined contains cycles length luby improved low density parity check codes graphs fig 

percentage successes trials 
rounds updates algorithm produces exact posterior probabilities message bit error neighborhood diameter message node 
presence cycles graph skews probabilities practice effect algorithm appears small 
details :10.1.1.35.5754
simulation irregular graph performance belief propagation describe important details experiments implementations 
performed simulations types channels rates block lengths 
channel model binary symmetric channel 
message consisting entirely zeros introduce fixed number errors corresponding fraction block length create new random graph trial remove necessary 
second channel type model white gaussian channel binary input additive noise variance report results gaussian channel rate additive noise terms signal noise ratio expressed decibels represents average energy bit represents noise spectral density experiments allowed belief propagation algorithm run rounds 
algorithm failed converge codeword rounds failure reported 
fact failure saw experiments algorithm returned codeword differed initial message 
describe irregular graphs table ii derived irregular graphs erasure codes 
note vector construct graph approximately correct edge fractions number nodes construction method described section iii 
care taken rounding necessity number edges left equal number edges right easily handled 
table ii parameters codes binary symmetric channel table iii compares performance regular irregular codes rates results regular codes graphs nodes left degree slightly better consistent previous results reported 
differences may due fixing number errors results genuine binary symmetric channel 
course may minor differences graph construction 
table represents block length represents rate represents fraction errors introduced represents capacity binary symmetric channel crossover probability results reported terms number trials blocks decoded number errors number blocks decoding algorithm failed find solution rounds 
rate irregular codes perform slightly better regular codes block lengths bits 
fail notably higher error rates 
bits code handle half percent errors 
previously noted low density parity check codes perform better block length increases believe ieee transactions information theory vol 
february fig 

irregular codes versus regular codes turbo codes rate 
table iii comparing regular irregular graphs effect magnified irregular codes degrees nodes quite high 
example irregular rate codes nodes left degree nodes right degree rate different irregular codes lower degrees 
code greatly outperforms regular codes block lengths correct approximately errors 
block lengths bits effect dramatic irregular codes appear correct errors 
note initial experiments rates validate contention irregular codes outperform regular codes terms number errors corrected 
decoding regular irregular codes number operations required proportional product number edges corresponding graph number rounds process terminates 
irregular graphs approximately times edges regular graphs higher error rates take approximately times iterations complete 
takes approximately times operations decode higher rates 
software implementations performance worse larger graph size irregular codes may require accesses slower levels memory hierarchy 
believe slower running time dramatic light improved performance 
gaussian channel figs 
compare performance terms bit error rate ber irregular codes rate reported results turbo codes regular codes rates 
experiments block lengths bits block length data point result trials 
compare results comparable block lengths 
results available www jpl nasa gov public html 
luby improved low density parity check codes graphs fig 

irregular codes versus regular codes turbo codes rate iar 
irregular codes belief propagation algorithm terminated rounds solution 
rate codes irregular codes perform notably better regular codes greatly reducing gap performance low density parity check codes turbo codes 
gap reduced move larger block sizes codes prove perform better larger block lengths setting 
block lengths bits code failed trials db 
estimates ber trials db db better performance regular codes comparable block length 
results irregular codes rate fig 
similarly show significant improvement regular codes 
lower rate block length turbo codes appear significant edge 
edge subsequently reduced exploration experimentation 
irregular codes rate perform significantly better larger block lengths 
block lengths bits code failed trials db 
estimates ber trials db db vi 
developement offers important contributions 
demonstrate low density parity check codes irregular graphs substantially outperform similar codes regular graphs 
show asymptotic analysis hard decision decoding algorithm experimentally belief propagation 
second introduce new methods analyzing low density parity check codes concentration bounds martingales 
contributions built subsequent 
main concentration theorem martingales extended large class channel models richardson urbanke 
approach developed density evolution algorithm numerical procedure approximate threshold noise belief propagation algorithm asymptotically successful 
sequences codes constructed belief propagation algorithm performance extremely close shannon capacity beating best performing turbo codes known time 
remains done 
suggest problem particular 
concentration bounds apply asymptotic behavior low density parity check codes adequately explain behavior small codes say thousands bits 
small codes corresponding bipartite graphs necessarily small cycles complication asymptotic analysis adequately handle 
understanding small codes extremely useful designing low density parity check codes making code choice practice 
berrou glavieux near shannon limit error correcting coding decoding turbo codes proc 
ieee int 
communications conf 
miller expander graph arguments message passing algorithms ieee trans 
inform 
theory vol 
pp 
feb 

cheng mceliece high rate near capacity codecs gaussian channel th allerton conf 
communications control computing 
davey mackay low density parity check codes gf ieee commun 
lett vol 
pp 
june 
design turbo codes jpl progr 
rep 
forney jr forward backward algorithm proc 
th allerton conf 
communications control computing pp 

gallager low density parity check codes :10.1.1.35.5754
cambridge ma mit press 
decoding low density codes probl 
inform 
vol 
pp 

kschischang frey iterative decoding compound codes probability propagation graphical models ieee select 
areas commun vol 
pp 
feb 
ieee transactions information theory vol 
february luby mitzenmacher shokrollahi spielman practical loss resilient codes proc :10.1.1.35.5754
th annu 
symp 
theory computing pp 

luby mitzenmacher shokrollahi analysis random processes trees proc 
th annu 
acm siam symp 
discrete algorithms pp 

luby mitzenmacher shokrollahi spielman improved low density parity check codes irregular graphs belief propagation proc 
int 
symp 
information theory 
analysis low density codes improved designs irregular graphs proc 
th annu 
symp 
theory computing pp 

mackay 
turbo codes low density parity check codes 
online 
available www cs toronto edu mackay abstracts turbo ldpc html mackay mceliece 
cheng turbo coding instance pearl belief propagation algorithm ieee select 
areas commun vol 
pp 
sept 
mackay error correcting codes sparse matrices ieee trans 
inform 
theory vol 
pp 
mar 
mackay neal near shannon limit performance low density parity check codes electron 
lett vol 
pp 

motwani raghavan randomized algorithms 
cambridge cambridge univ press 
pearl probabilistic reasoning intelligent systems networks plausible inference 
san francisco ca morgan kaufmann 
richardson shokrollahi urbanke design capacity approaching low density parity check codes ieee trans 
inform 
theory vol 
pp 
feb 
richardson urbanke capacity low density codes message passing decoding ieee trans 
inform 
theory vol 
pp 
feb 
sipser spielman expander codes ieee trans 
inform 
theory vol 
pp 
nov 
spielman linear time encodable decodable error correcting codes ieee trans 
inform 
theory vol 
pp 
nov 
wiberg codes decoding general graphs ph dissertation dept elec 
eng univ link ping sweden apr 
wiberg 
loeliger tter codes iterative decoding general graphs euro 
trans 
vol 
pp 
sept 
pinsker estimation error correction complexity gallager low density codes russia probl 

inform vol 
pp 
jan 
english translation probl 
inform 
vol 
pp 


luby mitzenmacher shokrollahi spielman efficient erasure correcting codes ieee trans 
inform 
theory vol 
pp 
feb 

