color wavelet statistics class support vector machines lyu department computer science dartmouth college hanover nh usa steganographic messages embedded digital images ways imperceptible human eye 
messages alter underlying statistics image 
previously built statistical models higher order wavelet statistics employed non linear support vector machines svm detect steganographic messages 
extend results exploit color statistics show class svm greatly simplifies training stage classifier 
keywords 
past years increasingly sophisticated techniques information hiding steganography developing rapidly see general reviews 
developments high resolution digital images carriers pose significant challenges detecting presence hidden messages 
growing literature 
techniques target specific embedding programs algorithms techniques universal begun emerge 
review techniques may 
previous showed statistical model higher order wavelet statistics discriminate images hidden messages 
earlier considered grayscale images order simplify computations 
doubt strong statistical regularities exist color channels extend earlier statistical model capture regularities 
previous linear non linear class support vector machine svm discriminate statistical features extracted images hidden messages 
classifier required training cover stego images 
point view universal training drawback requiring exposure images broad range stego tools 
employ class svm obviates need training stego images making training easier making classifier able contend novel developed stego programs 
basic statistical model describe construction class support vector machine 
show effectiveness tools detecting hidden messages tens thousands images different stego programs 
believe brings closer realizing robust tool universal 

statistical model decomposition images basis functions localized spatial position orientation scale wavelet proven extremely useful image compression image coding noise removal texture synthesis 
reason decompositions exhibit statistical regularities exploited 
image decomposition employed separable quadrature mirror filters 
illustrated decomposition splits frequency space multiple orientations scales 
grayscale image vertical horizontal diagonal subbands scale denoted vi hi di respectively 
color rgb image decomposition applied independently color channel 

resulting subbands denoted hc dc 
shown left idealized multi scale orientation decomposition frequency space 
shown top bottom levels left right lowpass vertical horizontal diagonal subbands 
shown right magnitude multi scale orientation decomposition disc image 
image decomposition statistical model composed mean variance skewness kurtosis subband coefficients orientation scale color channel 
statistics characterize basic coefficient distributions capture strong correlations exist space orientation scale color 
example edges tend extend spatially multiple scales 
large coefficient horizontal subband left right spatial neighbors subband large value 
similarly large coefficient scale indicate large value parent scale 
order capture higher order statistical correlations collect second set statistics errors linear predictor coefficient magnitude 
purpose illustration consider vertical band green channel scale 
linear predictor magnitude coefficients subset possible spatial orientation scale color neighbors vi vi denotes absolute value wk weights 
linear relationship expressed compactly matrix form contains coefficient magnitudes strung column vector reduce sensitivity noise magnitudes greater considered columns matrix contain neighboring coefficient magnitudes specified equation weights determined minimizing quadratic error function 
particular choice neighbors motivated observations modified include non casual neighbors 
error function minimized differentiating respect de setting result equal zero solving yield 
large number constraints pixel unknowns generally safe assume matrix invertible 
linear predictor log error actual coefficient predicted coefficient magnitudes log log log computed point wise vector component 
error additional statistics collected mean variance skewness kurtosis 
process repeated scales linear predictors subbands form subbands vi vi 
similar process repeated horizontal diagonal subbands 
example predictor green channel takes form hi di 
horizontal diagonal subbands predictor red blue channels determined similar way done vertical subbands equations 
oriented scale color subband similar error metric equation error statistics computed 
multi scale decomposition scales total number basic coefficient statistics color channel total number error statistics yielding grand total statistics 
statistics form feature vector discriminate images hidden messages 

classification earlier showed effectiveness multi class classification schemes detect hidden messages 
specifically employed linear discrimination analysis non linear support vector machines svm 
techniques afforded classification accuracy required training cover stego images 
numerous stego programs techniques need trained advantageous build classifier easily obtained cover images 
shown toy example non linear svm trained black dots cover white 
shown toy examples class svm class svm hypersphere class svm hyperspheres 
case dotted line circle represents classifier 
class svm trained black dots cover white squares stego notice gray squares stego incorrectly classified including training 
class svms trained black dots notice cases classifier better able generalize white gray squares generally fall outside support bounding circle 
squares stego dashed line corresponds separating surface gray squares correspond previously unseen images different stego program 
notice explicit training gray squares classifier unable correctly classify 
contend problem employ class support vector machines oc svm 
oc svm trained data class computing bounding hypersphere projected high dimensional space encompasses training data possible minimizing volume 
example shown oc svm trained black dots 
note class svm shown panel classifier able classify reasonably types stego images white gray squares 
describe details construction oc svms 

class support vector machines consider training data points dimensional space denoted xn 
oc svm projects data higher potentially infinite dimensional space mapping space bounding hypersphere computed encompasses training data possible minimizing volume 
hypersphere parameterized center radius described parameters computed training data classification performed bounding hypersphere 
hypersphere center radius computed minimizing min parameterized constant controls fraction training data fall outside hypersphere slack variables values indicate far outliers deviate surface hypersphere 
minimization subject xi euclidean norm 
objective function equation embodies requirement volume hypersphere minimized simultaneously encompassing training data space shown corresponds result projecting original data higher dimensional space 
non linear separating surface linear 
possible 
equation forces training data lie hypersphere slack variables allow loosening constraint specific data points 
determine quadratic programming problem equations transformed dual form subject min xi xj xi xi lagrange multipliers 
note dual formulation constraints equation linear objective function constraints convex 
standard techniques quadratic programming solve unknown lagrange multipliers 
center hypersphere xi 
order computed hypersphere radius karush tucker kkt condition find data points lie exactly surface optimal hypersphere 
points xi satisfy condition 
data point lies surface optimal hypersphere satisfies 
substituting solution equation yields solution hypersphere radius xi xj xi 
hypersphere parameters decision function determines data point lies support hypersphere defined greater equal zero lies hypersphere lies outside 
note decision function requires explicit evaluation 
computationally costly maps data high dimensional space problematic space infinite dimensional 
fortunately evaluation avoided entirely 
substituting solution equation decision function yields xi xj xi 
inner products projected data points equation computation equation objective function equation replaced appropriate kernel function yield ik xi ik xi re formulated objective function takes form min jk xi xj ik xi xi :10.1.1.39.912:10.1.1.117.3731
commonly kernel functions polynomials radial basis functions see examples :10.1.1.114.4532
note objective function defined original dimensional space 
section show basic framework extended allow coverage data multiple hyperspheres 

class support vector machines multiple hyperspheres oc svm single hypersphere described previous section obviates need training classifier fully labeled training set 
case oc svm need trained cover images 
testing stage images support bounding hypersphere considered contain hidden message 
potential drawback single hypersphere may provide particularly compact support training data 
alleviate problem propose cover training data hyperspheres hypersphere encompasses non intersecting subset training data 
shown example result hyperspheres cover data shown panel 
note case support significantly compact leading improved classification 
choosing number hyperspheres need balance compactness support generalizability classifier 
specifically hyperspheres classifier tuned training data perform poorly novel data 
specified number hyperspheres training data automatically segmented non intersecting subsets 
specifically standard means clustering algorithm employed cluster original data groups 
oc svm single hypersphere independently trained groups 
compute distance data point center oc svm hypersphere 
data point hypersphere center closest determined 
data point re assigned group regardless previous assignment 
new set oc svms trained new group assignments 
process repeated single data point re assigned 
convergence algorithm proven fairly straight forward way similar proving convergence means clustering 
testing stage novel image tested oc svms 
classified cover image falls support oc svm hypersphere classified stego image 
section show efficacy oc svm multiple hyperspheres distinguishing cover stego images 

results shown cover images taken database natural images color images span range indoor outdoor scenes jpeg compressed average quality typically pixels size average kilobytes 
contend slight variations image size central region image considered analysis 
statistics described section collected constructing color channel level orientation qmf pyramid 
image feature vector color channel coefficient error statistics computed 
natural images downloaded www com images photographed range different films cameras lenses digitally scanned 

examples database color images 
false positive classification accuracy number hyper spheres number hyper spheres 
shown bottom panel classification accuracy different stego programs function number hyperspheres training oc svm 
shown top panel false positive rate cover image incorrectly classified stego function number hyperspheres 
note classification accuracy improves hyperspheres false positive rate begins increase 
collected feature vectors train class support vector machine oc svm comparison sake multiple oc svms trained hyperspheres 
case false positive rate fixed cover image incorrectly classified stego image 
stego images generated embedding messages various sizes full cover images 
messages central regions randomly chosen images image database 
messages embedded 
stego image generated quality factor original cover image minimize double jpeg compression artifacts 
statistical feature vector described computed central region stego image 
trained oc svms test previously unseen cover images stego images stego embedding programs 
shown bottom panel classification results testing stage message size oc svms trained varying number hyperspheres 
shown top panel number false positives cover image incorrectly classified stego image testing stage 
note detection libsvm radial basis kernel underlying svm algorithm 
embedding message message svm svm svm oc svm oc svm pixels class class class hs hs gray color color color color table 
classification results class class svms 
class svms trained column column 
class svm results shown column color images column images converted grayscale 
note color statistics affords considerable improvement accuracy 
shown columns results class svm 
oc svms trained hyperspheres hs 
note oc svms better able generalize compared class svm trained column 
cases reported accuracy classification testing stage 
improves increasing number hyperspheres false positive rate begins increase considerably hyperspheres 
reason multiple hyperspheres afford compact support training stage lead poor generalization testing stage 
shown table complete grayscale color classification results previous class svm trained stego images column svm trained images columns svm svm 
shown table results oc svm hyperspheres 
cases reported accuracy testing stage images unseen training svms 
note color statistics affords considerable improvement accuracy 
class svm trained generally performs better novel stego programs svm trained 
note oc svm hyperspheres affords considerably higher classification accuracy hypersphere 
expected oc svm hyperspheres generally consistent generalizing novel stego programs svm trained 
class svm fully trained stego programs certainly outperform oc svm 
training svm requires larger training set may generalize stego programs previously unseen classifier 

discussion described universal algorithm exploits inherent statistical regularities natural images 
statistical model consists higher order color wavelet statistics 
class support vector machine oc svm employed detecting hidden messages digital images 
builds earlier higher order grayscale wavelet statistics class support vector machine 
addition color statistics provides considerable improvement detection accuracy 
fully trained class svm outperform oc svm oc svm advantage generalize stego programs previously seen classifier 
addition training oc svm simplified requires training easily obtained cover non stego images 
techniques universal hold promise high throughput steganography detected 
doubt small messages relative cover medium nearly impossible detect 
possible alter cover image inserting hidden message statistical feature vector collect falls realm non stego images 
immediately obvious image manipulation performed 
expect counter measures eventually developed foil detection scheme 
development techniques turn lead better statistical models detection schemes 

kahn history steganography proceedings information hiding international workshop cambridge uk 

anderson petitcolas limits steganography ieee journal selected areas communications pp 


johnson jajodia exploring steganography seeing unseen ieee computer pp 


petitcolas anderson kuhn information hiding survey proceedings ieee pp 


honeyman detecting steganographic content internet tech 
rep citi university michigan 

jpeg images breaking algorithm th international workshop information hiding noordwijkerhout netherlands 

wu wang detection lsb steganography sample pair analysis th international workshop information hiding noordwijkerhout netherlands 

lyu detecting hidden messages higher order statistics support vector machines th international workshop information hiding noordwijkerhout netherlands 

new methodology breaking steganographic techniques spie symposium electronic imaging santa clara ca 

practical state art spie symposium electronic imaging san jose california 

lyu higher order wavelet statistics application digital forensics ieee workshop statistical analysis computer vision conjunction cvpr madison wi 

detecting hidden messages higher order statistical models international conference image processing rochester new york 

quadrature mirror filter banks band extensions perfect reconstruction techniques ieee assp magazine pp 


vetterli theory multirate filter banks ieee transactions assp pp 


simoncelli adelson subband image coding ch 
subband transforms pp 

kluwer academic publishers 

simoncelli image compression joint statistical characterization wavelet domain ieee transactions image processing pp 


duda hart pattern classification scene analysis john wiley sons 

vapnik nature statistical learning theory spring verlag 

scholkopf platt shawe taylor smola williamson estimating support high dimensional distribution neural computation pp 


fletcher practical methods optimization john wiley sons nd ed 

burges tutorial support vector machines pattern recognition data mining knowledge discovery pp 



chang 
lin libsvm library support vector machines 
software available www csie ntu edu tw cjlin libsvm 


software available ftp fi 


software available www org 


software available inf tu dresden de 

latham jpeg hide seek 
software available linux de stego 


software available sourceforge net 
