proceedings siggraph los angeles california august image rendering powerful new approach generating real time photorealistic computer graphics 
provide convincing animations explicit geometric representation 
plenoptic function adelson bergen provide concise problem statement image rendering paradigms morphing view interpolation 
plenoptic function parameterized function describing visible point space 
image rendering system sampling reconstructing resampling plenoptic function 
addition introduce novel visible surface algorithm geometric invariant cylindrical projections equivalent epipolar constraint defined planar projections 
cr descriptors computer graphics picture image generation display algorithms viewing algorithms computer graphics dimensional graphics realism hidden line surface removal image processing enhancement registration image processing feature measurement projections image processing scene analysis 

plenoptic modeling image rendering system years increased interest computer graphics community image rendering systems 
systems fundamentally different traditional geometry rendering systems 
image systems underlying data representation model composed set photometric observations geometry systems mathematical descriptions boundary regions separating scene elements rep discretely sampled space functions volumetric 
evolution image rendering systems traced different research fields 
photogrammetry initial problems camera calibration dimensional image registration progressed determination dimensional models 
likewise computer vision problems robot navigation image discrimination image understanding naturally led direction 
computer graphics progression image rendering systems cb hall chapel hill nc mcmillan cs unc edu www cs unc edu mcmillan gb cs unc edu www cs unc edu gb leonard mcmillan gary bishop department computer science university north carolina chapel hill initially motivated desire increase visual realism approximate geometric descriptions mapping images surface texture mapping 
images approximate global illumination effects environment mapping seen systems images constitute significant aspects scene description 
reason considering image rendering systems computer graphics acquisition realistic surface models difficult problem 
geometry rendering technology significant strides achieving creating accurate models nearly difficult years ago 
technological advances dimensional scanning provide promise model building 
verify worst suspicions geometry real world exceedingly complex 
ironically primary subjective measure image quality proponents geometric rendering systems degree resulting images indistinguishable photographs 
liability image rendering systems lack consistent framework judge validity results 
fundamentally arises absence clear problem definition 
geometry rendering hand solid foundation uses analytic projective geometry describe world shape physics describe world surface properties light interaction surfaces 
presents consistent framework evaluation image rendering systems gives concise problem definition 
evaluate previous image rendering methods new framework 
image rendering methodology results prototype implementation 

plenoptic function adelson bergen assigned name plenoptic function latin root meaning complete full optic pertaining vision pencil rays visible point space time range wavelengths 
function develop taxonomy evaluating models low level vision 
plenoptic function describes radiant energy perceived point view observer point view source 
postulate basic visual measurements considered characterize local change dimensions single function describes structure information light impinging observer adelson bergen formalized functional description providing parameter space plenoptic function valid shown 
imagine idealized eye free place point space vx vy vz 
select viewable rays choosing azimuth elevation angle proceedings siggraph los angeles california august band wavelengths wish consider 

plenoptic function describes image information visible particular viewing position 
case dynamic scene additionally choose time wish evaluate function 
results form plenoptic function vy vz computer graphics terminology plenoptic function describes set possible environment maps scene 
purposes visualization consider plenoptic function scene representation 
order generate view point particular direction need merely plug appropriate values vx vy vz select range constant define complete sample plenoptic function full spherical map viewpoint time value incomplete sample solid angle subset spherical map 
framework state problem definition image rendering 
set discrete samples complete incomplete plenoptic function goal image rendering generate continuous representation function 
problem statement provides avenues exploration optimally select sample points best reconstruct continuous function samples 

previous movie maps movie map system lippman earliest attempts constructing image rendering system 
movie maps incomplete plenoptic samples stored interactive video laser disks 
accessed randomly primarily change viewpoint system accommodate panning tilting zooming fixed viewing position 
characterize lippman plenoptic reconstruction technique nearest neighbor interpolation set input parameters movie map system select nearest partial sample 
movie map form image rendering interpreted table evaluation plenoptic function 
interpretation reflects database structure common imagebased systems 
image morphing image morphing popular image rendering technique 
generally morphing considered occur images 
think images endpoints path time space 
interpretation morphing method reconstructing partial samples continuous plenoptic function path 
addition photometric data morphing uses additional information describing image flow field 
information usually hand crafted animator 
glance type augmentation place outside plenoptic function domain 
authors field computer vision shown type image flow information equivalent changes local intensity due infinitesimal perturbations plenoptic function independent variables 
local derivative behavior related intensity gradient applications chain rule 
fact morphing stronger assumption flow information constant entire path amounting locally linear approximation 
blending function combine images partially flowed initial configurations point path 
blending function usually linear combination images percentage path length traversed 
morphing plenoptic reconstruction method interpolates samples uses local derivative information construct approximations 
view interpolation chen williams view interpolation employs incomplete plenoptic samples image flow fields reconstruct arbitrary viewpoints constraints gaze angle 
reconstruction process uses information local neighborhood sample 
chen williams point suggest solution key problems image rendering determining visible surfaces 
chen williams chose quadtree compressed flow field back front order geometric 
approach works partial sample images share common gaze direction synthesized viewpoints restricted stay degrees gaze angle 
image flow field allows ambiguous visibility solutions restrict flow fields fold rubber sheet local spline warps thin plate global spline warps 
problem considered general purpose image rendering system ideally done transporting image geometric rendering domain 
establishing flow fields view interpolation system problematic 
chen williams pre rendered synthetic images determine flow fields values 
general accurate flow field information samples established points mutually visible samples 
points shortcoming partial samples images seldom overlap 
morphing view interpolation uses photometric information local derivative information reconstruction process 
locally linear approximation nicely exploited approximate perspective depth effects chen williams show correct lateral motions relative gaze direction 
view interpolation adds nonlinearity allowing visibility process determine blending function frames closest take winner take fashion 
laveau faugeras laveau faugeras taken advantage fact epipolar geometries images restrict image flow field way parameterized single disparity value fundamental matrix represents epipolar relationship 
provide dimensional raytracing solution visibility problem require underlying geometric description 
method require establishing correspondences image point ray path 
laveau faugeras system uses partial plenoptic samples results shown overlapping regions views 
laveau faugeras discuss combination information views primarily terms resolving visibility 
relating views desired views homogenous transformations projections laveau faugeras compute exact perspective depth solutions 
recon proceedings siggraph los angeles california august struction process takes advantage image data local derivative information reconstruct plenoptic function 
regan pose regan pose describe hybrid system plenoptic samples generated fly geometry rendering system available rendering rates interactive rendering provided image subsystem 
instant user interacts single plenoptic sample 
allows user unconstrained changes gaze angle sample point 
regan pose discuss local reconstruction approximations due changes viewing position 
approximations amount treating objects scene placed infinity resulting loss kinetic depth effect 
partial updates combined approximation values 

plenoptic modeling claim image rendering approaches cast attempts reconstruct plenoptic function sample set function 
believe significant insights gleaned characterization 
section propose prototype system light plenoptic function framework 
call image rendering approach plenoptic modeling 
image rendering systems scene description series images 
images subsequently warped combined form representations scene arbitrary viewpoints 
warping function defined image flow field information supplied input derived images 
discussion plenoptic modeling image rendering system broken sections 
discuss representation plenoptic samples 
discuss acquisition 
third section covers determination image flow fields required 
describe reconstruct plenoptic function sample images 
plenoptic sample representation natural surface projecting complete plenoptic sample unit sphere centered viewing position 
difficulty spherical projections lack representation suitable storage computer 
particularly difficult uniform equal area discrete sampling required 
difficulty reflected various distortions arise planar projections world maps cartography 
uniform mappings exist generally ill suited systematic access data structure 
furthermore map plane consistent neighborhood relationships generally quite distorted non uniform 
set planar projections form cube suggested greene efficient representation environment maps 
representation easily stored accessed computer provides significant problems relating acquisition alignment registration real non computer generated images 
orthogonal orientation cube faces requires precise camera positioning 
wide degree field view face requires expensive lens systems avoid optical distortion 
planar mapping represent uniform sampling considerably oversampled edges corners 
greatest difficulty cube oriented planar projection set describing behavior image flow fields boundaries faces corners 
issue planar projections solely environment map adds considerable overhead image analysis 
chosen cylindrical projection plenoptic sample representation 
advantage cylinder easily unrolled simple planar map 
surface boundaries azimuth direction simplifies correspondence searches required establish image flow fields 
short coming projection finite cylindrical surface boundary conditions introduced top bottom 
chosen employ caps projections problem limiting vertical field view environment 
acquiring cylindrical projections significant advantage cylindrical projection simplicity acquisition 
acquisition equipment required video camera tripod capable continuous panning 
ideally camera panning motion exact optical center camera 
practice scene objects relatively far tripod rotational center slight misalignment offset tolerated 
planar perspective projections scene share common viewpoint related dimensional homogenous transform represent pixel coordinates image corresponding coordinates second image 
known result reported authors 
images resulting typical camera motions pan tilt roll zoom related fashion 
creating cylindrical projection need consider panning camera motions 
convenience define camera local coordinate system panning takes place entirely xz plane 
order individual image cylindrical projection determine model camera projection equivalently appropriate homogenous transforms 
different techniques developed inferring homogenous transformation images sharing common centers projection 
common technique involves establishing corresponding points image pair 
resulting transforms provide mapping pixels planar projection image planar projection second 
images composited fashion determining transform maps nth image image 
transforms form mapping image plane 
approach effect avoids direct determination entire camera model performing mappings different instances camera 
techniques deriving homogeneous transformations specific point correspondences described 
set homogenous transforms hi decomposed parts allow arbitrary manner similar 
parts include intrinsic transform determined entirely camera properties extrinsic transform ri determined rotation camera center projection ix decomposition decouples projection rotational components homogeneous transform 
appropriate choice coordinate systems limiting camera motion panning extrinsic transform component constrained function single parameter rotation matrix describing pan 
cos sin ry sin cos proceedings siggraph los angeles california august intrinsic component properties invariant images decomposition problem broken parts determination extrinsic rotation component ri followed determination intrinsic projection component step method determines estimates extrinsic panning angle image pair panning sequence 
accomplished linear approximation infinitesimal rotation angle linear approximation results substituting cosine terms sine terms rotation matrix 
infinitesimal perturbation shown reduce approximate equations apparent focal length camera measured pixels cx cy pixel coordinate intersection optical axis image plane 
cx cy initially estimated center pixel image plane 
better estimate cx cy intrinsic matrix solution 
equations show small panning rotations approximated translations pixels near image center 
require part image sequence visible successive image part final image visible image sequence 
stage cylindrical registration process attempts register image set computing optimal translation maximizes normalized correlation region center third screen 
computed pixel resolution refined subpixel grid catmull rom interpolation spline compute subpixel intensities 
translations ti computed newton method convert estimates rotation angles focal length equation number images comprising sequence 
usually converges iterations depending original estimate phase determines estimate relative rotational angles images extrinsic parameters initial focal length estimate measured pixels intrinsic parameters 
second stage registration process determines structural matrix describes various camera properties tilt roll angles assumed remain constant group images 
model projection matrix cx cy ti atan zp cx cx cy estimated center described previously skew parameter representing deviation sampling grid rectilinear grid determines sampling grid aspect ratio focal length pixels determined alignment stage 
remaining terms describe combined effects camera orientation deviations orientation perpendicular optical axis 
ideally normal optical axis manufacturing tolerances allow numbers vary slightly 
cos sin sin cos cos sin sin cos addition term indistinguishable camera roll angle represents image sensor camera rotation 
likewise combined implicit parameter represents relative tilt camera optical axis panning plane 
zero images tangent cylinder nonzero projections tangent cone 
gives unknown parameters cx cy determined second stage registration process 
notice combined parameters determined stage total parameters image consistent number free parameters general homogeneous matrix 
structural matrix determined minimizing error function correlation ii error cx cy ii ii represent center third pixels images respectively 
powell multivariable minimization method initial values parameters image width image height cx solution typically converges iterations 
point new estimate cx cy fed back stage entire process repeated 
registration process results single camera model cx cy set relative rotations sampled images 
parameters compose mapping functions image sequence image follows si images arbitrary surfaces modifying image pixel determines equation ray center projection reprojection process merely involves intersecting rays projection manifold 
determining image flow fields cylindrical projections different positions static scene determine relative positions centers projection establish geometric constraints potential 
positions computed scale factor 
intuitive argument set images determine observer looking model full sized scene 
implies measurement required establish scale factor 
measurement may taken features mutually visible images distance acquired image camera positions 
techniques little difference results 
establish relative relationships pair cylindrical projections user specifies set corresponding points visible views 
points treated rays space form proceedings siggraph los angeles california august cos xa ca da sin va ca ax ay az unknown position cylinder center projection rotational offset aligns angular orientation cylinders common frame ka scale factor determines vertical field view scanline va center projection project scene line zero elevation equator spherical map 
pair image establishes pair rays ideally intersect point space identified 
general rays skewed 
point simultaneously closest rays estimate point position determined derivation 
xa xb va vb vb coordinates cylinders respectively 
points xa xb xa ca va xb cb sdb vb det ca cb db vb da va db vb da va db vb det cb ca da va da va db vb da va db vb allows pose problem finding cylinder position minimization problem 
pair cylinders sets unknowns va vb 
general estimates terms values registration phase 
position cylinders determined minimizing distance skewed rays 
choose assign penalty shrinking vertical height cylinder order bring points closer 
penalty eliminated accepting values registration 
tested approach converges solution iterations powell method 
correlation step required process considerably faster minimization step required determine structural matrix cylindrical projection introduces significant geometric constraints point viewed projection appear second 
capitalize restrictions wish automatically identify corresponding points cylinders 
initial set established hand process far tedious establish mapping entire cylinder 
geometric constraint cylindrical projections determines possible positions point position cylinder 
constraint plays role epipolar geometries computer vision community depth stereo computations play planar projections 
intuitive argument existence invariant 
consider center cylindrical projection 
point cylinder corresponds ray space cylindrical epipolar geometry equation 
rays observed second cylinder path projects curve appears point corresponding origin cylinder constrained pass point image second cylinder 
argument obviously planar projection 
points identified virtual image camera second projection corresponding point planar projection preserve lines unique called epipolar line defined 
basis epipolar geometry identifies pairs lines planar projections point falls line image constrained fall corresponding line second image 
existence invariant reduces search corresponding points problem 
cylindrical projections preserve lines 
general lines map quadratic parametric curves surface cylinder 
surprisingly completely specify form curve information needed planar case 
paths curves uniquely determined sinusoids 
cylindrical epipolar geometry established equation 
ny sin da va formula gives concise expression curve formed projection ray surface cylinder ray specified position cylinder 
cylindrical epipolar relationship establish image flow fields standard computer vision methods 
correlation methods simulated annealing relaxation method method differences compute stereo disparities cylinder pairs 
method strengths weaknesses 
refer reader details 
plenoptic function reconstruction image rendering system takes input projected panoramic images scalar disparity images relating cylinder pair 
information automatically generate image warps map images arbitrary cylindrical planar views capable describing occlusion perspective effects 

diagram showing transfer known disparity values cylinders new viewing position description cylindrical cylindrical mappings 
angular disparity value disparity images readily converted image flow vector field epipolar relation equation position cylinder 
transfer disparity values known cylindrical pair new cylindrical projection proceedings siggraph los angeles california august arbitrary position equations 
bx vx cos vy sin ay cos bx ax sin ay cos vx ax sin cot precomputing cos sin column cylindrical image storing cot place disparity image transfer operation computed interactive speeds 
typically disparity images transferred target cylindrical projection reprojected planar image viewing 
reprojection combined disparity transfer give single image warp performs operations 
accomplish new intermediate quantity called generalized angular disparity defined follows bx ax cos ay sin scalar function cylindrical equivalent classical stereo disparity 
composite image warp image arbitrary planar projection defined da kr da kn da ks da kn ca ks ca kn ca vectors defined desired view shown 

center projection vector origin spanning vectors uniquely determine planar projection 
case constant image warp defined equation reduces simple reprojection cylindrical image desired planar view 
perturbation introduced allowing vary image allows arbitrary shape occlusions represented 
potentially cylinder transfer image warping approaches mappings 
reason consider visibility 
simple algorithm determine enumeration cylindrical mesh guarantees proper back front ordering see appendix 
project desired viewing position cylinder warped partition cylinder toroidal sheets 
sheet boundaries defined coordinates points shown 
point defined intersection cylinder vector origin eye position 
intersection vector eye origin 
projection eye position sheet sheet sheet sheet 
back front ordering image flow field established projecting eye position cylinder surface dividing toroidal sheets 
enumerate sheet projected image desired viewpoint point drawn 
simple partitioning enumeration provides back front ordering painter style rendering algorithm 
hidden surface algorithm generalization anderson visible line algorithm arbitrary projected grid surfaces 
additional details 
point plenoptic samples warped new position image flow field 
general new pixel positions lie irregular grid requiring sort reconstruction resampling 
forward mapping reconstruction approach spirit prototype 
involves computing projected kernel size current disparity value derivatives epipolar curves 
visibility method properly handles mesh folds consider tears excessive stretching produced exposure previously occluded image regions 
view interpolation simple distinguished color heuristic screen space projection neighboring pixel scanline 
approach approximates stretching small regions occlusion occluder occluded region 
large exposed occluded regions tends interpolate boundaries occluded region 
exposure events handled robustly combining pixel pixel basis results multiple image warps smallest sized reconstruction kernel 

results collected series images video camcorder leveled tripod front yard author home 
accurate leveling strictly necessary method 
data collected attempt pan camera uniform angular velocity 
autofocus features camera disabled order maintain constant focal length collection process 
frames digitized rate approximately frames second resolution pixels 
example sequential frames shown 
immediately collection data set process repeated second point approximately inches 
image sequences separately registered methods described section 
images reprojected surface cylinder resolution pixels 
results shown figures 
operating room scene constructed methods 
epipolar geometry computed specifying front house 
additional gradually added establish initial disparity image simulated proceedings siggraph los angeles california august 
cylindrical images panoramic views separated approximately inches 
image panoramic view operating room 
image epipolar curves superimposed cylindrical image annealing method differences stereo correspondence routines 
added refined epipolar geometry cylinder position estimates 
change cylinder position slight 
show cylindrical image epipolar curves superimposed 
notice curves intersect alternate camera virtual image vanishing point 
disparity images computed interactively warped new viewing positions 
images show various reconstructions 
interactively warped images provide convincing kinetic depth effect 

plenoptic function provides consistent framework imagebased rendering systems 
various image methods morphing view interpolation characterized different ways implement key steps sampling reconstructing resampling plenoptic function 
described approach steps 
method sampling plenoptic function done equipment commonly available results cylindrical samples point 
necessary parameters automatically estimated sequence images resulting panning video camera full circle 
reconstructing function samples requires estimating optic flow points view point translated 
problem difficult evidenced years computer vision photogrammetry research greatly simplified samples relatively close 
little change image samples estimation easier viewer far sample accurate estimation important 
resampling plenoptic function reconstructing planar projection key steps display images arbitrary viewpoints 
methods allow efficient determination visibility real time display visually rich environments conventional workstations special purpose graphics acceleration 
plenoptic approach modeling display provide robust high fidelity models environments entirely set projections 
degree realism determined resolution images number primitives describing scene 
difficulty producing realistic models real environments greatly reduced replacing geometry images 
acknowledgments indebted individuals contributions suggestions henry fuchs andrei state kevin arthur donna mcmillan members unc upenn collaborative telepresence research group 
research supported part advanced research projects agency contract 
dabt nsf cooperative agreement 
asc advanced research projects agency order 
national science foundation 
mip 
approved arpa public release distribution unlimited 
adelson bergen plenoptic function elements early vision computational models visual processing chapter edited michael landy anthony movshon 
mit press cambridge mass 
anderson hidden line elimination projected grid surfaces acm transactions graphics october 
barnard stochastic approach stereo vision sri international technical note april 
neely feature image metamorphosis computer graphics siggraph proceedings vol 
pp 
july 
blinn newell texture reflection computer generated images communications acm vol 
pp 
october 
bolles baker epipolar plane image analysis approach determining structure motion international journal computer vision vol 

catmull subdivision algorithm computer display curved surfaces ph 
thesis department computer sci proceedings siggraph los angeles california august ence university utah tech 
report csc december 
chen williams 
view interpolation image synthesis computer graphics siggraph proceedings pp 
july 
faugeras dimensional computer vision geometric viewpoint mit press cambridge massachusetts 
greene environment mapping applications world projections ieee computer graphics applications november 
hartley self calibration multiple views rotating camera proceedings european conference computer vision may 
heckbert fundamentals texture mapping image warping masters thesis dept eecs ucb technical report 
ucb csd june 
horn schunck determining optical flow artificial intelligence vol 

kanatani transformation optical flow camera rotation ieee transactions pattern analysis machine intelligence vol 
march 
laveau faugeras scene representation collection images fundamental matrices inria technical report february 
lenz tsai techniques calibration scale factor image center high accuracy machine vision metrology proceedings ieee international conference robotics automation march april 
lippman movie maps application optical computer graphics siggraph proceedings 
longuet higgins computer algorithm reconstructing scene projections nature vol 
september 
longuet higgins reconstruction scene projections configurations defeat point algorithm proceedings ieee conference artificial intelligence applications dec 
lucas kanade iterative image registration technique application stereo vision proceedings seventh international joint conference artificial intelligence vancouver 
mcmillan leonard list priority rendering algorithm projected surfaces department computer science unc technical report tr 
mann picard virtual constructing high quality stills video proceedings ieee international conference image processing november 
press flannery teukolsky vetterling numerical recipes cambridge university press cambridge massachusetts pp 

regan pose priority rendering virtual reality address recalculation pipeline siggraph proceedings 
szeliski image mosaicing tele reality applications dec cambridge research lab technical report crl may 
tomasi kanade shape motion image streams factorization method full report orthographic case technical report cmu cs carnegie mellon university march 
tsai versatile camera calibration technique high accuracy machine vision metrology shelf tv cameras lenses ieee journal robotics automation vol 
ra august 
footprint evaluation volume rendering siggraph proceedings august 
wolberg digital image warping ieee computer society press los alamitos ca 
appendix show occlusion compatible mappings determined local spherical frames embedded global cartesian frame projected visibility algorithm cylindrical surfaces derived reducing spherical case 
consider isolated topological multiplicity projective mapping si sj shown theorem generic case points topological multiplicity induced mapping frame origins coplanar 
proof points topological multiplicity colinear origin share angular coordinates 
second line segment connects local frame origins general lines distinct define plane space 
single affine transformation accomplish results 
translate origin rotate lie axis rotate line multiplicity xy plane scale system coordinate 
transformation consider multiplicity entirely xy plane shown 
theorem cos cos proof length sides computed terms angles law sines follows 
sin sin sin sin sin cot cos sin cot cos cos cos cot cot occlusion compatible mapping determined enumerating topological mesh defined asi order increasing cos allowing mesh facets overwrite previous ones 
mapping occlusion compatible theorem greater range values proceed lesser values multiplicities 
notice mapping procedure considers changes local frame world coordinates range information 
si sj 
