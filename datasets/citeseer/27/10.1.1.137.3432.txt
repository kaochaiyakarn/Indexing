published psychological review 
www apa org journals rev american psychological association 
reasoning fast frugal way models bounded rationality gerd gigerenzer max planck institute psychological research daniel goldstein university chicago humans animals inferences world limited time knowledge 
contrast models rational inference treat mind laplacean demon equipped unlimited time knowledge computational 
simon notion satisficing authors proposed family algorithms simple psychological mechanism reason decision making 
fast frugal algorithms violate fundamental tenets classical rationality look integrate information 
computer simulation authors held competition satisficing take best algorithm various rational inference procedures multiple regression 
take best algorithm matched outperformed competitors inferential speed accuracy 
result existence proof cognitive mechanisms capable successful performance real world need satisfy classical norms rational inference 
organisms inductive inferences 
darwin observed people facial cues eyes lids hang low infer person guilt 
male roaming night pitch rival infer size deciding fight krebs davies 
stock brokers fast decisions stocks trade invest limited information available 
list goes 
inductive inferences typically uncertain cues eyes deceive tiny deep darkness 
organism inferences unknown aspects environment 
directions look answer 
pierre laplace george boole jean piaget scholars defended classical view laws human inference laws probability statistics lesser degree logic deal easily uncertainty 
derived laws probability believed laws human reasoning 
time honored tradition contemporary research psychology behavioral ecology economics gerd gigerenzer daniel goldstein center adaptive behavior cognition max planck institute psychological research munich germany department psychology university chicago 
research funded national science foundation sbr gg 
deeply grateful people contributed article including hal leda jean lorraine ken hammond reid hastie wolfgang hell ralph ulrich albert laura geoffrey miller silvia john payne terry regier werner peter herbert simon stephen gerhard strube zeno john william werner 
article may exactly replicate final version published apa journal 
copy record 
reasoning fast frugal way assumes standard statistical tools normative descriptive models inference decision making 
multiple regression instance economist universal tool mccloskey model inductive inference multiple cue learning hammond clinical judgment bayes theorem model animals infer presence predators prey stephens krebs human reasoning memory anderson 
view probability theory human reasoning sides coin early nineteenth century remained strong psychology economics 
past years came attack proponents heuristics biases program concluded human inference systematically biased error prone suggesting laws inference quick dirty heuristics laws probability kahneman tversky 
second perspective appears diametrically opposed classical rationality appearance misleading 
retained normative kernel classical view 
example discrepancy dictates classical rationality actual reasoning defines reasoning error program 
views accept laws probability statistics normative disagree humans stand norms 
experiments conducted test validity views identifying host conditions human mind appears rational irrational 
dealt simple situations bayesian inference binary hypotheses single piece binary data necessary information conveniently laid participant gigerenzer 
real world situations multiple pieces information independent redundant 
bayes theorem rational algorithms quickly mathematically complex computationally intractable ordinary human minds 
situations views look promising 
apply classical view complex real world environments suggest mind laplacean demon carrying collected works fisher neyman simply needs memory jog slave plato 
hand heuristics biases view human lead believe humans hopelessly lost face realworld complexity supposed inability reason canon classical rationality simple laboratory experiments 
third way look inference focusing psychological ecological logic probability theory 
view questions classical rationality universal norm questions definition reasoning heuristics biases views built 
herbert simon possibly best known proponent third view proposed looking models bounded rationality classical rationality 
simon argued information processing systems typically need optimize 
satisficing blend satisfying word scottish origin simon uses characterize algorithms successfully deal conditions limited time knowledge computational capacities 
concept satisficing postulates instance organism choose object mate satisfies aspiration level intractable sequence time survey possible alternatives estimating probabilities utilities possible outcomes associated alternative calculating expected utilities choosing alternative scores highest 
stress simon notion bounded rationality sides cognitive ecological 
early administrative behavior emphasized cognitive limitations gerd gigerenzer daniel goldstein real minds opposed omniscient laplacean demons classical rationality 
early psychological review article titled rational choice structure environment simon emphasized minds adapted real world environments 
go tandem human rational behavior shaped scissors blades structure task environments computational capabilities actor simon part theories human inference focused exclusively cognitive side equating notion bounded rationality statement humans limited information processors period 
bed fashion bounded rationality synonymous heuristics biases paradoxically reassuring classical rationality normative standard biases bounded rationality discussion confusion see lopes 
simon insight minds living systems understood relative environment evolved tenets classical rationality little impact far research human inference 
simple psychological algorithms observed human inference reasoning decision making fair trial looked stupid norms classical rationality 
instance keeney raiffa discussed lexicographic ordering procedure observed practice procedure related class satisficing algorithms propose article concluded procedure naively simple rarely pass test reasonableness 
report test 
shall 
initially concept bounded rationality vaguely defined classical economics fit lot things foresight hindsight simon put 
wish oppose laplacean demon view 
strive come positive replace unrealistic view mind 
simple intelligent algorithms capable making near optimal inferences 
fast accurate 
article propose class models exhibit bounded rationality simon senses 
satisficing algorithms operate simple psychological principles satisfy constraints limited time knowledge computational classical rationality 
time designed fast frugal significant loss inferential accuracy algorithms exploit structure environments 
article organized follows 
describing task cognitive algorithms designed address basic algorithm real world environment performance algorithm tested 
report competition satisficing algorithm competes rational algorithms making inferences real world environment 
rational algorithms start advantage time information computational inferences 
study variants satisficing algorithm faster inferences get knowledge 
task deal inferential tasks choice alternatives quantitative dimension 
consider example city larger population 
hamburg cologne 
alternative choice tasks occur various contexts inferences need limited time knowledge decision making risk assessment driving reasoning fast frugal way exit highway stay treatment allocation decisions treat emergency room year old heart attack victim year old car accident victim financial decisions buy sell trading pit 
inference concerning population demographics city populations past brown siegler importance people working urban planning industrial development marketing 
population demographics better understood say stock market serve drosophila environment allows analyze behavior satisficing algorithms 
study alternative choice tasks situations person inference solely knowledge retrieved memory 
refer inference memory opposed inference givens 
inference memory involves search declarative knowledge investigated studies inter alia confidence general knowledge buckley effect repetition belief gigerenzer press hindsight bias quantitative estimates area population nations brown siegler memory time huttenlocher hedges 
studies inference givens hand involve making inferences information experimenter hammond todd 
tradition ebbinghaus nonsense syllables attempts prevent individual knowledge impacting results problems hypothetical referents actual ones 
instance celebrated judgment decision making tasks cab problem linda problem relevant information provided experimenter individual knowledge hit run accidents feminist bank tellers considered relevance gigerenzer murray 
consequence limited knowledge individual differences knowledge play small role inference givens 
contrast satisficing algorithms proposed article perform inference memory limited knowledge input show profit lack knowledge 
assume person know deduce answer hamburg cologne question needs inductive inference related real world knowledge 
inference derived 
predict choice hamburg cologne person state knowledge 
theory cognitive algorithms propose realizations framework modeling inferences memory theory probabilistic mental models pmm theory see gigerenzer gigerenzer 
theory probabilistic mental models assumes inferences unknown states world probability cues 
theory relates visions inductive inference needs studied respect natural environments emphasized simon inductive inference carried satisficing algorithms emphasized simon inductive inferences frequencies events class proposed reichenbach frequentist statisticians 
theory probabilistic mental models accounts choice confidence choice addressed article 
major thrust theory replaces canon classical rationality simple plausible psychological mechanisms inference mechanisms mind carry gerd gigerenzer daniel goldstein limited time knowledge possibly arisen evolution 
traditional models inference linear multiple regression models bayesian models neural networks try find optimal integration information available bit information taken account weighted combined computationally expensive way 
family algorithms pmm theory implement classical ideal 
search memory relevant information reduced minimum integration substitution pieces information 
satisficing algorithms dispense fiction omniscient laplacean demon time knowledge search relevant information compute weights covariances integrate information inference 
limited knowledge pmm inductive device uses limited knowledge fast inferences 
different mental models deductive inference johnson laird focus logical task truth preservation knowledge irrelevant meaning connectives logical terms pmms perform intelligent guesses unknown features world uncertain indicators 
inference objects higher value knowledge class searched example knowledge class cities germany searched 
knowledge consists probability cues ci cue values ai bi objects ith cue 
instance making inferences populations german cities fact city professional soccer team major league may come person mind potential cue 
considering pairs german cities city soccer team major league city team certain larger population 
limited knowledge means matrix objects cues missing entries objects cues cue values may unknown 
models limited knowledge person 
heard german cities represented positive negative recognition values 
knows facts cue values cities respect binary cues 
binary cue cue values positive city soccer team negative 
positive refers cue value signals higher value target variable having soccer team correlated high population 
unknown cue values shown question mark 
heard cue values object definition unknown 
people rarely know information inference knowledge limited 
model limited knowledge respects person incomplete knowledge objects class recognizes cities limited knowledge cue values facts cities 
instance person know cities soccer teams may know cities positive cue values munich hamburg certainly teams negative cue values heidelberg potsdam certainly teams cities cue values known 
take best algorithm reasoning fast frugal way 
illustration bounded search limited knowledge 
objects recognized object 
cue values positive negative missing knowledge shown question marks 
cues ordered validities 
infer take best algorithm looks cue values shaded space infer search bounded dotted space 
cue values looked 
satisficing algorithm called take best algorithm policy take best ignore rest basic algorithm pmm framework 
variants faster knowledge described 
explain steps take best algorithm binary cues algorithm easily generalized valued cues illustration 
take best algorithm assumes subjective rank order cues validities 
call highest ranking cue discriminates alternatives best cue 
algorithm shown form flow diagram 

flow diagram take best algorithm 
gerd gigerenzer daniel goldstein positive object unknown negative object positive unknown negative step recognition principle recognition principle invoked mere recognition object predictor target variable population 
recognition principle states objects recognized choose recognized object 
objects recognized choose randomly 
objects recognized proceed step 
example person knowledge state shown asked infer city city inhabitants inference city person heard city 
step search cue values objects retrieve cue values highest ranking cue memory 
step discrimination rule decide cue discriminates 
cue said discriminate objects positive cue value 
shaded knowledge states cue discriminates 
step cue substitution principle cue discriminates searching cue values 
cue discriminate go back step continue cue cue discriminates 
step maximizing rule choice 
discrimination rule 
cue discriminates alternatives positive cue value 
discriminating cases shaded 
choose object positive cue value 
cue discriminates choose randomly 
examples suppose task judging city larger 
cities recognized step search best cue results positive negative cue value reasoning fast frugal way cue step 
cue discriminates step search terminated step 
person inference city larger step 
suppose task judging city larger 
cities recognized step search cue values cue results negative cue value object cue corresponding cue value object unknown step 
cue discriminate step search continued step 
search cue results positive negative cue values cue step 
cue discriminates step search terminated step 
person inference city larger step 
features algorithm search extends portion total knowledge memory shown shaded dotted parts stopped immediately discriminating cue algorithm attempt integrate information uses cue substitution total amount information processed contingent task pair objects varies predictable way individuals different knowledge 
fast computationally simple algorithm model bounded rationality classical rationality 
close parallel simon concept satisficing take best algorithm stops search discriminating cue just simon satisficing algorithm stops search option meets aspiration level 
algorithm hardly standard statistical tool inductive inference available information non compensatory nonlinear variants violate transitivity 
differs standard linear tools inference multiple regression nonlinear neural networks compensatory nature 
take best algorithm best discriminating cue determines inference decision combination cue values override decision 
way algorithm conform classical economic view human behavior becker assumption aspects reduced dimension money exists trade commodities pieces information 
algorithm violates axiom implies multidimensional object preferred bn dominates preference reversed multiples combination bn 
discuss variants algorithm violate transitivity cornerstones classical rationality 
empirical evidence despite violation traditional standards rationality take best algorithm models framework pmm theory successful integrating various striking phenomena inference memory predicting novel phenomena confidence frequency effect gigerenzer effect goldstein goldstein gigerenzer 
theory probabilistic mental models existing process theory bias successfully predicts conditions overestimation occurs disappears inverts underestimation gigerenzer gigerenzer persson see griffin tversky 
similarly theory predicts hard easy effect occurs disappears inverts predictions experimentally confirmed 
take best algorithm explains pop gerd gigerenzer daniel goldstein ular confirmation bias explanation bias lichtenstein supported experimental data gigerenzer pp 

earlier accounts striking phenomena confidence choice algorithms pmm framework allow predictions choice individual knowledge 
goldstein gigerenzer showed recognition principle predicted individual participants choices cases participants taught information suggested doing negative cue values recognized objects 
evidence empirical validity take best algorithm tests bold prediction effect postulates conditions people little knowledge better inferences know 
surprising prediction experimentally confirmed 
instance students slightly correct inferences german city populations know little cities vice versa german students gigerenzer goldstein goldstein gigerenzer 
theory probabilistic mental models applied situations inferences limited time knowledge rumor stock market trading 
general review theory evidence mcclelland 
reader familiar original algorithm gigerenzer 
noticed simplified discrimination rule 
version search terminated object positive cue value earlier version search terminated object positive value negative cf 
gigerenzer article 
change follows empirical evidence participants tend faster simpler discrimination rule 
article attempt provide empirical evidence 
moment assume model descriptively valid investigate accurate satisficing algorithm drawing inferences unknown aspects real world environment 
algorithm simple psychological principles violate norms classical rationality fair number accurate inferences 
environment tested performance take best algorithm accurately inferences real world environment 
environment set cities germany inhabitants cities german population target variable 
model environment consisted binary ecological cues actual cue values 
full model environment shown appendix 
cue associated validity indicative predictive power 
ecological validity cue relative frequency cue correctly predicts target defined respect class german cities inhabitants 
instance checks pairs city soccer team city finds cases city team higher population 
value ecological validity soccer team cue 
validity ith cue ai positive bi negative term discrimination rule activation rule 
reasoning fast frugal way cue table cues ecological validities discrimination rates ecological validity discrimination rate national capital city national capital 
exposition site city exposition site 
soccer team city team major league 
train city line 
state capital city state capital 
license plate abbreviation letter long 
university city home university 
industrial belt city industrial belt 
east germany city east germany 
values objects target variable probability measured relative frequency ecological validity cues ranged spectrum slightly better chance certainty shown table 
cue high ecological validity useful discrimination rate small 
table shows discrimination rates cue 
discrimination rate cue relative frequency cue discriminates objects class 
discrimination rate function distribution cue values number objects class 
relative frequencies positive negative cue values respectively 
discrimination rate di ith cue elementary calculation shows 
large discrimination rate approximately larger ecological validity cue better inference 
larger discrimination rate cue inference 
environment ecological validities discrimination rates negatively correlated 
redundancy cues environment measured pairwise correlations cues ranges average absolute value 
iy instance cue value positive negative xi yi di 
increases xi yi held constant di decreases converges various measures redundancy pairwise correlation 
important point measure redundancy uses resultant value meaning algorithms 
instance counts take best algorithm proportion correct inferences second cue adds cases cue discriminate third cue adds cases discriminate 
cue discriminates search terminated degree redundancy cues included search irrelevant 
integration algorithms contrast integrate information total redundancy environment knowledge base 
instance deciding objects cue values cues matter point view take best algorithm search terminated reaching cue 
values cues affect redundancy ecological system point view integration algorithms 
lesson degree redundancy environment depends kind algorithm operates environment 
needs cautious interpreting measures redundancy algorithm 
gerd gigerenzer daniel goldstein competition question satisficing algorithm performs real world environment rarely posed research inductive inference 
simulations test simple satisficing algorithms compared standard integration algorithms require knowledge time computational power 
question important simon postulated link cognitive ecological simple psychological principles satisficing algorithms tuned ecological structures algorithms fail outright 
propose competition various inferential algorithms 
contest go algorithm scores highest proportion correct inferences shortest time 
simulating limited knowledge simulated people varying degrees knowledge cities germany 
limited knowledge take forms 
limited recognition objects class 
limited knowledge cue values recognized objects 
model limited recognition knowledge simulated people recognized german cities 
model limited knowledge cue values simulated basic classes people knew cue values associated objects recognized 
combining sources limited knowledge resulted types people having different degrees kinds limited knowledge 
type people created simulated individuals differed randomly particular objects cue values knew 
objects cue values known determined randomly appropriate constraints certain number objects known certain total percentage cue values known validity recognition principle explained paragraph 
simulation needed realistic sense simulated people invoke recognition principle 
sets cities simulated people knew carefully chosen recognized cities larger unrecognized ones certain percentage time 
performed survey get empirical estimate actual covariation recognition cities city populations 
define validity recognition principle probability class object greater value target variable cases object recognized ai positive bi negative values objects target variable recognition values probability measured relative frequency pilot study undergraduates university chicago cities recognized largest germany larger cities recognize possible comparisons 
incorporated value simulations choosing sets cities knowledge state number cities recognized known cities larger unknown cities cases 
cities known simulated individuals relationship recognition population human individuals 
look performance take best algorithm 
reasoning fast frugal way testing take best algorithm tested individuals take best algorithm answering real world questions 
city inhabitants heidelberg bonn 
simulated individuals types tested exhaustive set city pairs resulting total tests 
curves show average proportion correct inferences proportion objects cue values known 
axis represents number cities recognized axis shows proportion correct inferences take best algorithm drew 
points curves average proportion correct inferences taken simulated individuals inferences 
proportion cities recognized zero proportion correct inferences chance level 
half cities recognized performance increased levels knowledge cue values 
maximum percentage correct inferences 
striking result maximum achieved individuals knew cue values cities knew 
result shows ability algorithm proportion correct inferences percentage cue values known number objects recognized 
correct inferences population german cities alternative choice tasks take best algorithm 
inferences actual information largest cities cues population see appendix 
limited knowledge simulated individuals varied dimensions number cities recognized axis percentage cue values known curves 
gerd gigerenzer daniel goldstein exploit limited knowledge best known 
take best algorithm produces effect 
level limited knowledge cue values learning german cities eventually cause decrease proportion correct 
take instance curve cue values known point simulated participants recognized german cities 
individuals learned remaining german cities proportion correct decrease 
rationale recognition principle understood best curve reflects total cue values known 
decisions basis recognition principle guessing 
curve recognition principle comes play half cities known takes inverted shape 
half cities known recognition principle activated roughly questions 
set recognition validity advance inferences correct 
remaining half questions recognition cities recognized cities unrecognized organism forced guess guesses correct 
effective recognition validity half time guessing half time organism scores correct peak bottom curve 
mode curve moves right increasing knowledge cue values 
note person knows cue values cities states limited knowledge person accurate inferences 
going discuss conditions counterintuitive effect supporting experimental evidence see goldstein gigerenzer 
focus better integration algorithms making inferences 
integration algorithms asked colleagues fields statistics economics devise decision algorithms better take best algorithm 
integration algorithms simulated take best algorithm competition suggested colleagues 
competitors include proper improper linear models 
algorithms contrast take best algorithm embody classical principles rational inference complete search available information cue values complete integration combine pieces information single value 
short refer article algorithms satisfy principles rational quotation marks algorithms 
tallying start simple integration algorithm tallying positive evidence goldstein 
algorithm number positive cue values object tallied cues object largest number positive cue values chosen 
integration algorithms explicitly recognition principle 
reason integration algorithms strong possible allow integration algorithms recognition information positive negative recognition values see 
reasoning fast frugal way integration algorithms treat recognition cue ecological cues table 
competition number cues equal recognition included 
decision criterion tallying choose city assignments compare cities 
tallying positive cue values score points score 
tallying choose larger opposition take best algorithm infer larger 
variants tallying frequency features heuristic discussed decision literature alba payne johnson 
weighted tallying choose city guess 
ith cue value positive ith cue value negative ith cue value unknown 
tallying treats cues alike independent cue validity 
weighted tallying positive evidence identical tallying weights cue ecological validity ecological validities cues appear table 
set validity recognition cue empirical average determined pilot study 
decision rule follows choose city choose city guess 
note weighted tallying needs information tallying take best algorithm quantitative information ecological validities 
simulation provided real ecological validities give algorithm chance 
calling comparison objects assume validities recognition cues 
weighted tallying assign points points weighted tallying choose larger 
gerd gigerenzer daniel goldstein tallying algorithms treat negative information missing information identically 
consider positive evidence 
algorithms distinguish negative missing information integrate positive negative information 
unit weight linear model unit weight linear model special case linear model huber advocated approximation weighted linear models 
decision criterion unit weight integration tallying assignment differs ith cue value positive ith cue value negative ith cue value unknown 
comparing objects involve assigning points points choosing randomly 
simple linear model corresponds model weight parameter set equal 
weighted linear model model unit weight linear model values multiplied respective ecological validities 
decision criterion weighted tallying 
weighted linear model variant viewed optimal rule preferential choice idealization independent dimensions cues keeney raiffa payne 
comparing objects involve assigning points points choosing larger 
multiple regression weighted linear model reflects different validities cues dependencies cues 
multiple regression creates weights reflect covariances predictors cues commonly seen optimal way integrate various pieces information estimate hammond 
neural networks delta rule determine optimal weights principles multiple regression stone 
delta rule carries equivalent multiple linear regression input patterns targets 
weights multiple regression simply calculated full information ecological cues appendix 
multiple regression stronger competitor provided information cities simulated individuals recognized 
multiple regression ecological cues recognition cue generate weights 
weights recognition cue depend cities recognized calculated sets weights simulated individual 
algorithms regression access actual city populations reasoning fast frugal way cities recognized hypothetical person calculation weights 
quiz simulated person set weights provided multiple regression estimate populations cities comparison 
missing values problem computing sets regression coefficients simulated individuals know certain cue values instance cue values cities recognize 
strengthened performance multiple regression substituting unknown cue values average cue values person knew cue 
done creating weights weights estimate populations 
traditional procedures weights estimated half data inferences weights half regression algorithm access information appendix course unknown cue values information competitors 
competition multiple regression lesser degree weighted linear model approximate ideal laplacean demon 
speed results take best algorithm designed enable quick decision making 
compared integration algorithms faster draw inferences measured amount information searched memory 
instance take best algorithm look cue values including recognition cue values infer larger integration algorithms limited search look cue values 
shows amount cue values retrieved memory take best algorithm various levels limited knowledge 
take best algorithm reduces search memory considerably 
depending knowledge state algorithm needed search number recognition values maximum possible cue values city cue values recognition value 
instance person recognized half cities knew cue values average cue values fifth possible searched 
average simulated participants third available cue values 
accuracy searches limited amount information accurate take best algorithm compared integration algorithms 
ran competition states limited knowledge shown 
report results competition case claim integration algorithms best ones know priori small variations succeed bumpy real world environment 
example proof stage article learned regressing ranks cities slightly better regressing city populations 
key issue structures environments particular algorithms variants thrive 
single cue value known cue missing values substituted 
value chosen midpoint values stand negative positive cue values respectively 
gerd gigerenzer daniel goldstein algorithm achieved best performance cue values known shows results simulations carried way 
surprise take best algorithm drew correct inferences algorithms 
curves take best multiple regression weighted tallying tallying similar slight differences 
weighted tallying performed tallying unit weight linear model performed weighted linear model demonstrating previous finding weights may chosen fairly arbitrary manner long correct sign generalizable tallying 
integration algorithms positive negative information unit weight weighted linear models considerably fewer correct inferences 
looking lower left upper right corners see competitors equally complete lack knowledge complete knowledge 
differ knowledge limited 
note algorithms correct inferences complete knowledge demonstration effect mentioned earlier 
result competition levels limited knowledge 
table shows result level limited knowledge cue values averaged levels recognition knowledge 
table reports performance variants take best 
amount cue values looked take best algorithm competing integration algorithms see text depending number objects known percentage cue values known 
reasoning fast frugal way proportion correct inferences take best weighted tallying tallying regression weighted linear model unit weight linear model number objects recognized 
results competition 
curve take best algorithm identical curve 
results proportion correct smoothed running median smoother lessen visual noise lines 
gorithm discuss minimalist take algorithm 
values column table values averaged levels recognition 
take best algorithm correct inferences competitors weighted tallying 
fastest judged competition goes take best algorithm highest performing 
knowledge time demonstrated satisficing algorithm take best algorithm draw correct inferences realworld environment integration algorithms states limited knowledge 
dictates classical rationality led expect integration algorithms substantially better satisficing algorithm 
results simulation derived analytically 
obvious knowledge objects zero algorithms perform chance level 
second obvious objects cue values known tallying produces correct inferences unit weight linear model 
complete knowledge score tallying algorithm increasing linear function score arrived linear model 
equivalence tallying unit weight linear models complete knowledge important result 
known unit weight linear models perform proper linear models models weights chosen gerd gigerenzer daniel goldstein table results competition average proportion correct inferences percentage cue values known algorithm average take best weighted tallying regression tallying weighted linear model unit weight linear model minimalist take note 
values rounded averages computed values 
bottom algorithms variants take best algorithm 
optimal way multiple regression see 
equivalence implies complete knowledge merely counting pieces positive evidence proper linear models 
result clarifies condition searching positive evidence strategy labeled confirmation bias positive test strategy reasonable efficient inferential strategy ha walker 
unit weight weighted linear models perform markedly worse limited knowledge objects 
reason simple bold recognition principle 
algorithms exploit recognition principle environments recognition strongly correlated target variable pay price considerable number wrong inferences 
weighted linear models recognition information integrate information follow recognition principle choose unrecognized cities recognized ones 

environment negative cue values positive ones see appendix cities negative cue values positive ones 
follows recognized object compared unrecognized object weighted sum cue values recognized object smaller unrecognized object unit weight model weighted linear model 
unit weight weighted linear models inference unrecognized object larger due overwhelming negative evidence recognized object 
inferences contradict recognition principle 
tallying algorithms contrast recognition principle built implicitly 
tallying algorithms ignore negative information tally unrecognized object smaller tally recognized object tallying weighted tallying due positive value recognition cue 
tallying algorithms arrive inference recognized object larger unrecognized 
proof follows 
tallying score object number positive cue values defined 
score unit weight linear model number negative cue values 
complete knowledge number cues 
substitution formula find reasoning fast frugal way note explanation different performances puts full weight psychological principle recognition principle explicit take best algorithm opposed statistical issue find optimal weights linear function 
test explanation reran simulations unit weight weighted linear models conditions replacing recognition cue recognition principle 
simulation showed recognition principle accounts difference 
satisficing algorithms get time knowledge 
take best algorithm produced surprisingly high proportion correct inferences compared computationally expensive integration algorithms 
making correct inferences despite limited knowledge important adaptive feature algorithm right thing counts 
situations time limited acting fast important correct 
instance driving unfamiliar highway decide instant road forks problem necessarily making best choice simply making quick choice 
pressure quick characteristic certain types verbal interactions press conferences fast answer indicates competence commercial interactions having telephone service installed customer decide minutes dozen calling features purchase 
situations entail dual constraints limited knowledge limited time 
take best algorithm faster integration algorithms performs limited search need compute weighted sums cue values 
faster 
search guided recency cues memory cue validity 
take algorithm take algorithm tries cue discriminated time 
cue discriminate algorithm tries cue discriminated time 
algorithm differs take best algorithm step reformulated step step search cue values cue objects retrieve cue values cue 
judgment discrimination record available retrieve cue values randomly chosen cue 
step algorithm goes back step 
variants search principle studied effect water jar experiments solution strategy solved problem tried subsequent problem 
effect noted physicians generation diagnoses clinical cases weber hilton wallace 
algorithm need rank order cues validities needs known direction cue points 
knowledge rank order cue validities replaced memory cues 
note record built gerd gigerenzer daniel goldstein independently knowledge structure environment needs uses feedback inferences right wrong 
minimalist algorithm reasonably accurate inferences achieved knowledge 
call minimalist algorithm needs information rank ordering cue validities discrimination history cues 
ignorance algorithm picks cues random order 
algorithm differs take best algorithm step reformulated step step random search objects retrieve cue values randomly chosen cue 
minimalist algorithm necessarily speed search tries get knowledge algorithm 
speed results fast fast algorithms 
simulations showed variant algorithms relationship amount knowledge number cue values looked form take best algorithm 
integration algorithms curves concave number cues searched maximal knowledge cue values lowest 
average number cue values looked lowest take algorithm followed minimalist algorithm take best algorithm 
knowledge limited dimensions recognition cue values known difference speed smaller smaller 
reason minimalist algorithm looks fewer cue values take best algorithm cue validities cue discrimination rates negatively correlated table randomly chosen cues tend larger discrimination rates cues chosen cue validity 
accuracy price paid speeding search reducing knowledge cue orderings discrimination histories 
tested performance algorithms environment algorithms 
shows proportion correct inferences minimalist algorithm achieved 
comparison performance take best algorithm cue values known indicated dotted line 
note minimalist algorithm performed surprisingly 
maximum difference appeared knowledge complete cities recognized 
circumstances minimalist algorithm reasoning fast frugal way 
performance minimalist algorithm 
comparison performance take best algorithm shown dotted line case cue values known 
percentage points worse take best algorithm 
average proportion correct inferences percentage points best algorithms competition table 
performance take algorithm similar average number correct inferences shown table 
take algorithm faster scored slightly minimalist algorithm 
take algorithm interesting ability fooled earlier series tests systematic opposed random method presenting test pairs starting largest city pairing 
integration algorithm multiple regression find tested systematic way inferences accordingly independent sequence presentation 
take algorithm won round competition outperforming competitors percentage points 
exploit systematic testing 
recall tries cue discriminated time 
cue discriminate proceeds cue discriminated time 
doing testing systematic way described tends find city paired smaller ones group cues larger city positive value 
trying cues increases chances finding discriminating cue points right direction larger city 
learned lesson reran competition randomly ordered pairs cities 
gerd gigerenzer daniel goldstein discussion competition showed surprising result take best algorithm drew correct inferences unknown features real world environment integration algorithms 
simplifications algorithm take algorithm replacing knowledge rank orders cue validities memory discrimination history cues minimalist algorithm dispensing showed comparatively small loss correct inferences knowledge cue values high 
best knowledge inference competition satisficing rational algorithms real world environment 
result importance encouraging research focuses power simple psychological mechanisms design testing satisficing algorithms 
result importance existence proof cognitive algorithms capable successful performance real world environment need satisfy classical norms rational inference 
classical norms may sufficient necessary inference real environments 
cognitive algorithms section discuss fundamental psychological mechanism postulated pmm family algorithms reason decision making 
discuss mechanism exploits structure environments making fast inferences differ arising standard models rational reasoning 
reason decision making call reason decision making specific form satisficing 
inference decision single reason 
compensation cues 
reason decision making probably challenging feature pmm family algorithms 
mentioned design feature algorithm models depict human inference optimal integration information available implying information looked place including linear multiple regression nonlinear neural networks 
reason decision making means choice exclusively reason cue reason may different decision decision 
allows highly context sensitive modeling choice 
reason decision making compensatory 
compensation cornerstone classical rationality assuming commodities compared price 
compensation assumes 
human minds trade things supposed price elster 
instance person choose actions help get deep financial trouble involves killing amount money benefits compensate prospect hands 
takes action involve killing person differences exist options 
generally hierarchies ethical moral values true friendship military honors supposed price 
reasoning fast frugal way inference algorithms lexicographic conjunctive disjunctive rules discussed literature empirical evidence reported fishburn 
closest relative pmm family satisficing algorithms lexicographic rule 
largest evidence lexicographic processes come studies decision risk summary see lopes 
despite empirical evidence lexicographic algorithms dismissed face value violate tenets classical rationality keeney raiffa 
pmm family general specific lexicographic rule 
general take best algorithm uses lexicographic procedure cues ordered validity variant algorithms 
specific psychological principles integrated lexicographic rule take best algorithm recognition principle rules confidence judgment dealt article see gigerenzer 
serious models comprise inferences hard find 
examples breiman friedman olshen stone reported simple algorithm binary ordered cues classified heart attack patients high low risk groups accurate standard statistical classification methods variables 
practical relevance classification algorithm obvious emergency room physician quickly obtain measures variables need perform computations integration 
group statisticians constructed satisficing algorithms approach task classification estimation take best algorithm handles alternative choice 
relevance theory sperber postulates people generate consequences rules accessibility process expectations relevance met 
relevance theory formalized see stopping rule parallel take best algorithm 
optimality theory legendre raymond smolensky prince smolensky proposes hierarchical explains grammar language determines structural description input best satisfies formedness constraints 
optimality theory satisficing theory applies inferential principles pmm theory phonology morphology 
recognition principle recognition principle version reason decision making exploits lack knowledge 
fact know accurate inferences 
recognition principle intuitively plausible principle models bounded rationality 
long advantage humans animals 
instance advertisement techniques put effort making sure customer recognizes brand name effort inform product 
idea recognition strong force customers choices 
dear read colleagues seeing draft article explained inferences books worth acquiring 
finds book great topic recognize name author inference probably worth buying 
inspection recognize names concludes book worth reading 
recognition principle known rules guide food preferences animals 
instance rats choose gerd gigerenzer daniel goldstein food recognize having eaten having breath fellow rats avoid novel foods gallistel brown carey gelman keil 
empirical validity recognition principle inferences unknown city populations simulations directly tested ways 
participants pairs cities critical pairs city recognized unrecognized task infer inhabitants 
recognition principle predicts recognized city 
empirical tests participants followed recognition principle roughly cases goldstein goldstein gigerenzer 
second participants taught cue ecological validity cue values objects city soccer team 
subsequently tested critical pairs cities recognized unrecognized recognized city negative cue value indicates lower population 
second test harder test recognition principle harder cues negative cue values recognized object means 
tests second kind performed participants followed recognition principle time providing evidence empirical validity goldstein goldstein gigerenzer 
recognition principle useful heuristic domains recognition predictor target variable food contains toxic substance 
cases recognition predict target pmm algorithms perform inference recognition principle step canceled 
limited search reason decision making recognition principle realize limited search defining stopping points 
integration algorithms contrast provide model stopping points implicitly assume exhaustive search may provide rules tossing variables lengthy regression equation 
stopping rules crucial modeling inference limited time simon examples satisficing search alternatives terminates certain aspiration level met 
nonlinearity linearity mathematically convenient tool dominated theory rational choice inception mid seventeenth century gigerenzer 
assumption various components alternative add independently estimate utility 
contrast nonlinear inference operate computing linear sums weighted cue values 
nonlinear inference varieties including simple principles conjunctive disjunctive algorithms highly complex ones nonlinear multiple regression neural networks 
take best algorithm variants belong family simple nonlinear models 
advantage simple nonlinear models transparency step pmm algorithms followed fully connected neural networks numerous hidden units free parameters 
competition revealed unit weight weighted versions linear models lead equal performance consistent finding choice weights provided sign correct matter 
real world domains reasoning fast frugal way prediction sudden infant death linear combination variables carpenter gardner emery weights varied broad range decreasing predictive accuracy phenomenon known flat maximum effect von edwards 
competition addition showed flat maximum effect extends tallying unit weight weighted tallying performing equally 
performance take best algorithm showed flat maximum extend linear models inferences solely best cue accurate weighted unit weight linear combination cues 
research psychology economics preferred linear models description prediction prescription edwards lopes von edwards 
historically linear models analysis variance multiple regression originated tools data analysis psychological laboratories subsequently projected means tools theories heuristic theories mind gigerenzer 
sufficiently fit linear models judgment studies interpreted humans fact combine cues linear fashion 
taken mean humans linear models controversial hammond summers hammond 
instance certain range data generated nonlinear law falling bodies fitted linear regression 
data appendix multiple linear regression resulted means linear combination cues predict target variable quite 
simpler nonlinear take best algorithm match performance 
fit linear model rule simpler models inference 
shepard reviewed empirical evidence claim humans integrate information linear models 
distinguished perceptual transformation raw sensory inputs conceptual objects properties subsequent inference conceptual knowledge 
concluded perceptual analysis integrates responses vast number receptive elements concepts properties complex nonlinear rules done little evidence turn recombined facility shepard 
minds take account host different factors remember report doing seldom consider time shepard 
shepard view little evidence integration linear term inferences memory constraints limited time knowledge 
kind evidence support linear integration model memory inference 
people great difficulties handling correlations cues integration models multiple regression need handle 
summarize memory inference little empirical evidence view mind laplacean demon equipped computational powers perform multiple regressions 
need taken bad news 
beauty nonlinear satisficing algorithms match demon performance searching knowledge computational 
intransitivity transitivity cornerstone classical rationality 
tenets anglo american school ramsey savage shares competing franco european school fishburn 
prefer prefer linear algorithms competition produce transitive inferences ties gerd gigerenzer daniel goldstein gorithm randomly guessed city populations fact transitive 
pmm family algorithms includes algorithms violate transitivity take best algorithm minimalist algorithm 
minimalist algorithm randomly selects cue base inference result 
table shows spite intransitivities performance algorithm percentage point lower best transitive algorithms percentage points better transitive algorithms 
organism take best algorithm stricter discrimination rule original version gigerenzer forced making intransitive inferences 
stricter discrimination rule search terminated positive negative cue value positive unknown cue value encountered 
illustrates state knowledge stricter discrimination rule gives result dominates dominates dominates biological systems instance exhibit systematic intransitivities systems dimension 
imagine species species inhabits water land species inhabits water air 
compete water species defeats species species inhabits land air competes air defeated meet land element defeats linear model estimates value strength species independently species competing fail capture cycle 
inferences estimation 
limited knowledge stricter discrimination rule produce intransitive inferences 
noted unit weight model essentially estimation involved sign unit weight 
similar result holds algorithms reported 
take best algorithm need estimate regression weights needs estimate rank ordering ecological validities 
take minimalist algorithms involve essentially estimation sign cues 
note missing knowledge necessary intransitivities occur 
cue values known intransitive inferences possibly result 
algorithm stricter discrimination rule allows precise predictions occurrence intransitivities course knowledge acquisition 
instance imagine person knowledge described know value cue object person intransitive judgments comparing objects learn object negative cue value cue produce intransitive judgment 
learned piece value cue object longer produce intransitive judgment 
prediction transitive judgments turn intransitive ones back learning 
intransitivities simply depend amount limited knowledge knowledge missing 
reasoning fast frugal way fact estimation problem important consequence organism cues experienced concerned size sample experienced sufficiently large generate reliable estimates weights 
cue redundancy performance suggested unit weight models expected perform approximately proper linear models regression model moderate low range smaller predictors cues correlated 
criteria necessary sufficient explain performance take best algorithm 
take best algorithm variants certainly exploit cue redundancy cues highly correlated cue job 
seen environment high moderate low range 
mentioned earlier pairwise correlations ecological cues ranged absolute average value 
despite high moderate small correlation cues satisficing algorithms performed quite successfully 
excellent performance competition explained partially cue redundancy cues moderately correlated 
high cue redundancy sufficient necessary successful performance satisficing algorithms 
new perspective lens model ecological theorists emphasized cognitive system designed find pathways world substituting missing cues cues happen available 
labeled ability vicarious functioning saw fundamental principle science perception cognition 
proposal model adaptive process linear multiple regression inspired long tradition neo research hammond empirical evidence mental multiple regression controversial 
vicarious functioning need equated linear regression 
pmm family algorithms provides alternative nonadditive model vicarious functioning cue substitution operates integration 
gives new perspective lens model 
reason decision making lens discriminating cue passes inhibits rays passing determines judgment 
vicarious functioning consistent original examples substitution behaviors hull habit family hierarchy alternative manifestation symptoms writings see gigerenzer murray chap 

reported teachers physicians professionals claim criteria judgments grading papers making differential diagnosis experimental tests showed fact criterion shepard 
glance indicate professionals claims 
need 
experts vicarious functioning works pmm algorithms correct saying predictors decision time 
gerd gigerenzer daniel goldstein counts reasoning 
research reasoning decades assumed sound reasoning reduced principles internal consistency additivity probabilities conformity truth table logic transitivity 
instance research selection task linda problem cab problem evaluated reasoning exclusively measure internal consistency gigerenzer 
cognitive algorithms need meet important constraints internal consistency need psychologically plausible need fast need accurate inferences real world environments 
real time real environments possibility algorithm minimalist algorithm intransitive inferences mean time feature algorithm significantly hurt accuracy 
addressed article constraints human reasoning emerge fact homo sapiens social animal gigerenzer 
instance choices treat emergency room need justified 
going single best reason strategy take best algorithm immediate appeal justification convincing certainly easier communicate complicated weighting cues 
research questions need addressed research 
generalize satisficing algorithm alternative choice tasks inferential tasks classification estimation 
reported success classification regression tree models breiman form reason decision making encouraging sign shown alternative choice tasks generalizable 
second structure real world environments allows simple algorithms perform 
need develop conceptual language capture important aspects structure environments simple cognitive algorithms exploit 
traditional proposal understanding structure environments terms ecological validities defined linear correlations may adequate power nonlinear satisficing algorithms suggests 
reasoning rational psychological 
article pointed common opposition rational psychological emerged nineteenth century breakdown classical interpretation probability gigerenzer 
rational inference commonly reduced logic probability theory psychological explanations called things go wrong 
division labor nutshell basis current research judgment uncertainty built 
economist massachusetts institute technology put reasoning rational psychological gigerenzer 
reasoning rational psychological 
believe years notion bounded rationality time overcome opposition rational psychological reunite 
reasoning fast frugal way pmm family cognitive algorithms provides precise models attempt 
differ unified view rational psychological focus simple psychological mechanisms operate constraints limited time knowledge supported empirical evidence 
single important result article simple psychological mechanisms yield correct inferences time standard statistical linear models embody classical properties rational inference 
demonstration fast frugal satisficing algorithm won competition defeats widespread view rational algorithms accurate 
models inference accuracy simplicity 
mind ways 
alba 

effects frequency knowledge consumer decision making 
journal consumer research 
anderson 

adaptive character thought 
hillsdale 
nj erlbaum 


redundancy multiple cue judgments data task 
american journal psychology 
becker 

economic approach human behavior 
chicago university chicago press 


learned human judgment years policy capturing 
joyce eds human judgment view pp 

amsterdam north holland 


psychology linear judgment models 
acta psychologica 
breiman friedman olshen stone 

classification regression trees 
new york chapman hall 
brown siegler 

metrics mappings framework understanding real world quantitative estimation 
psychological review 


representative design probabilistic theory functional psychology 
psychological review 
carpenter gardner emery 

multistage scoring system identifying infants risk unexpected death 
archives disease childhood 
darwin 

expressions emotions man animal 
chicago university chicago press 
original published 

classical probability 
princeton nj princeton university press 


robust beauty improper linear models 
american psychologist 


piggybacked investor behavior probabilistic mental modeling rumor stock market trading 
unpublished doctoral dissertation temple university philadelphia 
edwards 

theory decision making 
psychological bulletin 
edwards 

dynamic decision theory probabilistic information processing 
human factors 


nonlinear models decision making 
psychological bulletin 


unit weighting schemes decision making 
organizational behavior human performance 
elster 

ulysses studies rationality 
cambridge england cambridge university press 
fischer welt fischer world 

frankfurt germany fischer 


perceived informativeness facts 
journal experimental psychology human perception performance 
fishburn 

nonlinear preference utility theory 
baltimore johns hopkins university press 
fishburn 

preferences decision theory 
journal risk uncertainty 
gallistel brown carey gelman keil 

lessons animal learning study cognitive development 
carey gelman eds mind essays biology cognition pp 

hillsdale nj erlbaum 
gerd gigerenzer daniel goldstein gigerenzer 

tools theories heuristic discovery cognitive psychology 
psychological review 
gigerenzer 

bounded rationality probabilistic mental models 
eds rationality psychological philosophical perspectives pp 

london routledge 
gigerenzer 

distinction single event probabilities frequencies relevant psychology vice versa 
wright eds subjective probability pp 

new york wiley 
gigerenzer 

taming content thoughts domains modules 
thinking reasoning 
gigerenzer 

narrow norms vague heuristics reply kahneman tversky 
psychological review 
gigerenzer 

rationality social context matters 
eds interactive minds life span perspectives social foundation cognition pp 

cambridge england cambridge university press 
gigerenzer 

improve bayesian reasoning instruction frequency formats 
psychological review 
gigerenzer 

probabilistic mental models theory confidence 
psychological review 
gigerenzer murray 

cognition intuitive statistics 
hillsdale nj erlbaum 
gigerenzer porter beatty kr ger 

empire chance probability changed science everyday life 
cambridge england cambridge university press 


limit cycles competition communities 
american naturalist 
goldstein 

effect inference 
unpublished master thesis university chicago 
goldstein gigerenzer 

reasoning recognition exploit lack knowledge 
unpublished manuscript 
griffin tversky 

weighing evidence determinants confidence 
cognitive psychology 
hammond 

psychology egon 
new york holt rinehart winston 
hammond 

integration usefully achieved 
ed insights decision making pp 

chicago university chicago press 
hammond todd 

analyzing components clinical inference 
psychological review 
hammond summers 

cognitive dependence linear nonlinear cues 
psychological review 
hammond 
eds 

realizations representative design new directions methodology social behavioral science 
san francisco bass 
gigerenzer 
press 
effect hindsight bias 
psychological review 


zur eine exploration der theorie der validity confidence judgments study theory probabilistic mental models 
unpublished doctoral dissertation universit salzburg austria 
huber 

information processing operators decision making 
montgomery eds process structure human decision making pp 

new york wiley 
huttenlocher hedges 

hierarchical organization ordered domains estimating dates events 
psychological review 
johnson laird 

mental models 
cambridge ma harvard university press 


explanation hard easy effect studies realism confidence general knowledge 
european journal cognitive psychology 


phenomenon consequence informal experimenter guided selection items 
organizational behavior human decision processes 
persson 

indicator reconstructive retrieval processes 
cognition 
kahneman tversky 
eds 

judgment uncertainty heuristics biases 
cambridge england cambridge university press 
keeney raiffa 

decisions multiple objectives 
cambridge england cambridge university press 
ha 

confirmation information hypothesis testing 
psychological review 
reasoning fast frugal way lichtenstein 

reasons confidence 
journal experimental psychology human learning memory 
krebs davies 

behavioral ecology nd ed 
oxford blackwell 
legendre raymond smolensky 

analytic typology case marking grammatical voice 
proceedings berkeley linguistics society 


evolution complex genetic systems 
ed mathematical questions biology 
providence ri american mathematical society 
lopes 

misleading assumptions customary rhetoric bias literature 
theory psychology 
lopes 

psychology economics perspectives risk cooperation marketplace 
annual review psychology 
lopes 

algebra process modeling risky choice 
hastie medin eds decision making perspective cognitive psychology pp 

new york academic press 


flat maximum effect linear scoring models prediction 
journal forecasting 


water jar experiments effects early history surveys textbook citations 
gestalt theory 
mcclelland 

calibration subjective probabilities theories models 
wright eds subjective probability pp 

chichester england wiley 


rationality dynamic choice 
cambridge england cambridge university press 
mccloskey 

rhetoric economics 
madison university wisconsin press 
payne johnson 

adaptive decision maker 
cambridge england cambridge university press 
prince smolensky 

notes connectionism harmony theory linguistics tech 
rep 
cu cs 
boulder university colorado department computer science 
shepard 

subjectively optimum selections multi attribute alternatives 
edwards tversky eds decision making pp 

baltimore penguin books 
simon 

administrative behavior study decision making processes administrative organization 
new york free press 
simon 

rational choice structure environment 
psychological review 
simon 

models bounded rationality 
cambridge ma mit press 
simon 

invariants human behavior 
annual review psychology 
simon 

economics bounded rationality cognitive revolution 
england 
buckley 

uncertain 
castellan ed individual group decision making pp 

hillsdale nj erlbaum 
sperber 

relevance theory explains selection task 
cognition 
stephens krebs 

foraging theory 
princeton nj princeton university press 
stone 

analysis delta rule learning statistical associations 
rumelhart mcclelland pdp research group eds parallel distributed processing explorations microstructure cognition pp 

cambridge ma mit press 


impact accountability judgment choice social contingency model 
ed advances experimental social psychology vol 
pp 

new york academic press 
walker 

science education cognitive psychology science 
jones eds dimensions thinking cognitive instruction pp 

hillsdale nj erlbaum 
von edwards 

costs payoffs perceptual research 
psychological bulletin 
weber hilton wallace 

determinants diagnostic hypothesis generation effects information base rates experience 
journal experimental psychology learning memory cognition 


reductionism levels organization mind body problem 
globus maxwell eds consciousness brain scientific philosophical inquiry pp 

new york plenum 
gerd gigerenzer daniel goldstein appendix environment city population soccer team state capital east ger belt licence plate inter city train line tion site national capital uni ver sity berlin hamburg munich cologne frankfurt essen dortmund stuttgart bremen duisburg hannover leipzig dresden bochum bielefeld mannheim halle chemnitz bonn magdeburg karlsruhe braunschweig augsburg rostock kiel aachen beck hagen erfurt kassel saarbr cken freiburg mainz ck oldenburg reasoning fast frugal way city population potsdam darmstadt heidelberg cottbus paderborn heilbronn ulm siegen koblenz jena witten hildesheim rth erlangen soccer team environment state capital east germany industrial belt licence plate exposition site national capital note 
city populations taken fischer welt 
starred minus values reality plus values 
transcription errors ran simulations minus values 
affect rank order cue validities noticeable effect results irrelevant theoretical argument 
university 
