determinant maximization linear matrix inequality constraints vandenberghe stephen boyd shao po wu isl stanford edu boyd isl stanford edu isl stanford edu information systems laboratory electrical engineering department stanford university stanford ca april problem maximizing determinant matrix subject linear matrix inequalities arises elds including computational geometry statistics system identi cation experiment design information communication theory 
considered generalization semide nite programming problem 
give applications determinant maximization problem pointing simple cases specialized algorithms analytical solutions known 
describe interior point method simpli ed analysis worst case complexity numerical results indicate method cient theory practice 
compared existing specialized algorithms available interior point method generally slower advantage handles wider variety problems 
submitted siam journal matrix analysis applications 
research supported part afosr nsf ecs eec muri 
associated software available url www isl stanford edu people boyd anonymous ftp isl stanford edu pub boyd maxdet 
include implementation matlab user interface matlab 
versions available url ftp site pub boyd reports maxdet ps 
consider optimization problem log subject tog optimization variable ne inequality signs denote matrix inequalities tg tf 
andf strict nonstrict respectively linear matrix inequalities lmis 
refer problem maxdet problem cases tx absent problem reduces maximizing determinant ofg subject lmi constraints 
maxdet problem convex optimization problem objective tx log convex fx jg constraint set convex 
lmi constraints represent common convex constraints including linear inequalities convex quadratic inequalities matrix norm eigenvalue constraints see alizadeh ali boyd el ghaoui balakrishnan lewis overton lo nesterov nemirovsky nn vandenberghe boyd vb 
maxdet problem solved algorithms general convex programming cient theory worst case complexity ellipsoid method nemirovsky yn shor sho 
solved general nonlinear programming methods provided modi ed handle nonsmooth lmi constraints 
describe interior point method solves maxdet problem ciently worst case complexity theory practice 
method describe shares features interior point methods linear semide nite programming 
particular computational experience limited problems moderate size variables matrices indicates method describe solves maxdet problem number iterations hardly varies problem size typically ranges iteration involves solving system linear equations 
maxdet problems arise elds including computational geometry statistics information communication theory duality theory algorithms develop wide application 
applications simple forms problem maxdet problems solved specialized algorithms cases analytically 
interior point algorithm generally slower specialized algorithms specialized algorithms 
advantage approach general handles wider variety problems 
analytical solutions specialized algorithms example handle addition convex constraints algorithm general maxdet problems 
remainder describe interesting special cases maxdet problem semide nite programming analytic centering 
describe examples applications maxdet problems pointing analytical solutions known interesting extensions handled general maxdet problems 
describe duality theory maxdet problems pointing connections semide nite programming duality 
interior point method solving maxdet problem developed 
describe variations simple short step method prove polynomial worst case complexity long step adaptive step method worst case complexity cient practice 
nish numerical experiments 
appendix contains key proofs formulas 
describe special cases maxdet problem 
semide nite programming maxdet problem reduces subject tof isknown semide nite program sdp 
semide nite programming uni es wide variety convex optimization problems linear programming subject expressed sdp diag ax 
surveys theory applications semide nite programming see ali lew lo nn vb 
analytic centering andf maxdet problem reduces minimize log subject tog call analytic centering problem 
assume feasible set fx jg nonempty bounded implies linearly independent objective log strictly convex see vb 
objective function grows bound asx approaches boundary unique 
analytic center 
analytic center lmi generalizes analytic center set linear inequalities introduced son son 
constraint active analytic center characterized optimality condition see example boyd el ghaoui 
analytic center lmi important reasons 
see analytic center computed ciently easily computed robust solution lmi 
analytic centering plays important role methods solving general maxdet problem 
roughly speaking interior point methods solve general problem solving sequence analytic centering problems 
parametrization lmi feasible set restore analytic centering problem log subject tog retaining assumption nonempty bounded linearly independent objective function strictly convex 
problem unique 
satis es optimality 

ci wehave readily computed 
feasible set conversely de nec trg gi evidently 

words correspondence 
parametrization feasible set strict parametrization related legendre transform convex function log de ned inff log jg maximal lower bounds positive de nite cone consider simple example maxdet problem 
positive de nite matrices rp lower bound maximal lower bound lower yx 
function log monotone decreasing respect positive semidefinite cone xy log log compute maximal lower solving minimize log subject tox maxdet problem variables elements 
constraints strict consider diagonal blocks single block diagonal lmi diag course maximal lower bounds replacing log monotone decreasing matrix function yield maximal lower bounds 
maximal lower obtained solving property invariant congruence transformations transformed wheret nonsingular maximal lower bound obtained examples applications section catalog examples applications 
reader interested duality theory solution methods maxdet problem skip directly 
minimum volume ellipsoid containing points earliest best known application maxdet problem arises problem determining minimum volume ellipsoid contains equivalently convex hull 
problem applications cluster analysis rosen ros barnes bar robust statistics ellipsoidal peeling methods outlier detection see rousseeuw leroy rl 
describe ellipsoid fx bk wherea volume proportional minimum volume ellipsoid contains points computed solving convex problem minimize log subject kax bk variables area andb norm constraints kax bk just convex quadratic inequalities expressed lmis ax lmis turn expressed large block diagonal lmi 
minimum volume ellipsoid containing ellipsoids interesting variations extensions problem 
example consider problem nding minimum volume ellipsoid ellipsoids minimum volume ellipsoid containing ellipsoids 
finding ellipsoid cast maxdet problem ciently solved 
ek 
problem describe ellipsoids sets convex quadratic functions ei fx jx aix ci solution solving maxdet problem andk scalar variables minimize log subject toa ici 
see details 
shows instance problem 
ellipsoid volume containing set called ellipsoid klee john ellipsoid grotschel lovasz schrijver gls 
john joh shown shrinks minimum volume outer ellipsoid convex setc center obtains ellipsoid contained john ellipsoid serves ellipsoidal approximation convex set bounds depend ambient dimension way setc 
maximum volume ellipsoid polyhedron related problem computing maximum volume ellipsoid inside polyhedron described linear inequalities fx ja lg represent ellipsoid assume loss generality 
volume proportional detc problem expressed maximize log detc subject toc constraint replaced set lmis kyk icy bi id id problem cast maxdet problem maximize log detc subject toc bi andd nesterov nemirovsky nn khachiyan todd kt describe algorithms computing maximum volume ellipsoid polyhedron described linear inequalities minimum volume ellipsoid covering polytope described vertices 
geometrical problems involving ellipsoidal approximations formulated maxdet problems 
che give examples including maximum volume ellipsoid contained intersection sum ellipsoids minimum volume ellipsoid containing sum ellipsoids 
ellipsoidal approximation problems suboptimal solutions computed maxdet problems 
ellipsoidal approximations convex sets control theory signal processing bounded noise set membership techniques 
techniques rst introduced state estimation see sch sch wit bertsekas rhodes br che che applied system identi cation fogel huang fog fh norton walter cheung signal processing del 
survey emphasizing signal processing applications see dno 
applications include method inscribed ellipsoids developed khachiyan design centering sap 
maximum volume rectangle polyhedron fx polyhedron wherea consider problem rectangle maximum volume 
componentwise inequalities xx xi optimization variables 
volume equal xi problem expressed maximize ny xi subject constraint cast set xb wherea ij maxf anda ij maxf 
compute maximum volume rectangle enclosed polytope solving maximize ny xi subject toa xb cast maxdet problem andg diag 
problem extended ways 
example require rectangle adding linear matrix completion problems positive de nite matrix completion positive de nite matrix completion problem symmetric entries xed remaining entries chosen resulting matrix positive de nite 
positions free unspeci ed entries index pairs ik jk jk ik assume diagonal elements xed ik jk 
diagonal element say th free take large row column irrelevant 
positive de nite completion problem cast sdp feasibility problem thata af mx xk ei kj ej denotes matrix elements zero element equal 
note set fx ja bounded diagonal elements xed 
maximum entropy completion analytic center called maximum entropy completion 
optimality conditions see maximum entropy completion satis es zero entry location corresponding unspeci ed entry original matrix 
useful property applications see example dempster dem ning dn 
parametrization positive de nite completions extension maximum entropy completion problem consider kj minimize log subject toa wherec 
problem form optimality conditions kj ci kj inverse optimal completion matches free entry 
gives parametrization positive de nite completions positive de nite uniquely characterized specifying elements inverse free locations problem studied bw 
contractive completion related problem contractive completion problem possibly nonsymmetric pairs ik jk nd matrix af mx spectral norm maximum singular value 
cast semide nite programming feasibility problem vb ia ti de ne maximum entropy solution solution maximizes determinant solves maxdet problem maximize log det ia subject ti see nw hw 
statistical interpretation see 
specialized algorithms cient algorithms developed certain specialized types completion problems 
known example maximum entropy completion positive de nite banded toeplitz matrix dg dd 
davis kahan weinberger discuss analytic solution contractive completion problem special block matrix form 
methods discussed solve general problem ciently slower specialized algorithms applicable 
advantage convex constraints upper lower bounds certain entries readily incorporated 
completion problems specialized algorithms computing completions discussed authors see dg johnson sa wolkowicz barrett johnson johnson lj dd dembo mallows shepp dms 
johnson gives survey joh 
interior point method approximate completion problem discussed johnson wolkowicz 
refer boyd el ghaoui el discussion additional 
risk averse linear estimation ax anda rq unknown quantity wish estimate measurement measurement noise 
assume pq full column rank 
linear rp ebx ma minimum variance unbiased estimator unbiased estimator minimizes error variance xk px largest singular value ofm 
wherea ata pseudo inverse ofa 
fact minimum variance estimator optimal stronger sense minimizes singular value separately ma applications estimation errors larger mean value costly desirable errors mean value 
capture idea risk aversion consider objective cost function log exp xk parameter called risk sensitivity parameter 
cost function introduced whittle sophisticated setting stochastic optimal control see whi 
note risk sensitive cost converges cost xk larger convexity exp jensen inequality 
gain insight rst terms series expansion log exp xk xk xk xk ez xk squared error 
large risk averse cost augments mean square error term proportional variance squared error 
unbiased risk averse optimal estimator solving minimize log exp subject toma xk expressed maxdet problem 
objective function written log exp xk log exp wt mw log det mm ifm tm log det mi unbiased risk averse optimal estimator solves maxdet problem minimize subject log det mi ma mi mi fact analytic centering problem simple analytic solution squares see express objective terms singular values ofm log det mi px log 
follows property solution ism ka problem infeasible 
whittle refers infeasible case risk averse cost nite breakdown 
simple case discussed optimal risk averse minimum variance estimators coincide certainly advantage maxdet problem formulation 
additional convex constraints added sparsity pattern triangular toeplitz structure optimal risk averse estimator including constraints maxdet problem general coincide minimum variance estimator 
experiment design optimal experiment design previous section consider problem estimating ax measurement noise 
error covariance minimum variance estimator equal toa suppose rows aq chosen possible test ai fv goal experiment design choose error covariance small 
interpret component result experiment measurement chosen xed menu possible experiments job nd set measurements maximally informative 
writea iv fraction equal ignore fact numbers integer multiples treat continuous variables justi ed practice large 
alternatively imagine designing random experiment experiment ai probability 
di erent criteria measuring size matrix proposed 
example ine optimal design minimize norm error covariance max equivalent maximizing smallest eigenvalue ofa readily cast sdp subject mx mx iv ti variables andt 
criterion isa optimality minimize tr cast sdp minimize subject px ti pm iv mx ei iti unit vector variables ind optimal design minimize determinant error covariance leads maxdet problem minimize log det mx iv subject mx derive geometrical interpretation optimal show thata determines minimum volume ellipsoid centered origin fedorov fed atkinson ad give surveys additional optimal experiment design 
extensions ofd optimal experiment design formulation ofd optimal design maxdet problem advantage easily incorporate additional useful convex constraints 
example add linear re ect bounds total cost time required carry experiments 
consider case experiment yields measurements andv matrices 
maxdet problem formulation remains constraint constraint ad optimal experiment design involving test vectors constraint 
circle origin dots test vectors experiment crosses test vectors 
constraint optimal design allocates test vectors 
constraint measurements spread vectors measurements allocated group vectors 
see 
larger 
extension useful conjunction additional linear inequalities representing limits cost time model discounts time savings associated performing groups measurements simultaneously 
suppose example cost simultaneously making measurements andv sum costs making separately 
wecan matrix assign andc associated making rst measurement second measurement simultaneously respectively 
describe detail useful additional constraint imposed certain fraction total number experiments say concentrated fraction say possible measurements 
require denotes largest ect experiment design spread measurements points cost increasing determinant error covariance 
see figures 
constraint convex satis ed andt kx constraint constraint experiment design 
curves show sum components function ofk constraint constraint 
constraint speci es sum largest components curve avoid area inside dashed rectangle 
mct mx xi xi see bv 
compute optimal design subject constraint adding linear inequalities constraints solving resulting maxdet problem variables maximum likelihood ml parameter estimation ml estimation markov chain parameters consider ann state markov chain transition pij prob jjs wheres ng denotes state 
suppose ne functions unknown pij fij maximum likelihood estimate observed state solution optimization problem maximize fa ia subject nx fij maxdet problem diagonal 
ml estimation parameters exponential distribution ben vectors drawn independently probability distribution density ny rn 
maximum likelihood estimate samples value maximizes log likelihood function log ny nx nx log easily di erentiation note problem example unconstrained maxdet problem 
add lmi constraints express prior information nx maximize subject cd ml estimation structured covariance matrices nx log related example ml estimation structured covariance matrices normal distribution 
problem long history see anderson 
ben samples normal 
ml estimate positive de nite matrix maximizes log likelihood function qn det exp xt words solving maximize log det subject nx expressed maxdet problem minimize log subject tor wheres problem straightforward analytical nonsingular 
useful impose additional structure covariance matrix anderson burg luenberger wenger sch dembo dem 
special cases circulant analytical solutions known cases constraints expressed lmis inr ml estimate obtained maxdet problem 
give simple illustration bounds variances ii expressed lmis inr ii ei rei formulation maxdet problem useful singular example number samples small consequence unbounded 
case impose constraints prior information example lower upper bounds diagonal elements ofr 
gaussian channel capacity gaussian channel water lling algorithm entropy normal constant equal log det see cover thomas ct chapter 
surprising maxdet problems arise naturally information theory communications 
example computation channel capacity 
consider simple gaussian communication channel random vectors rn xn input output additive noise independent ofx 
model parallel channels single channel erent time instants erent frequencies 
assume noise known input variable determined subject constraints limits describe 
goal maximize mutual information input output log det log log det xr see ct 
channel capacity de ned maximum mutual information input satisfy constraints 
channel capacity depends onr constraints 
simplest common constraint limit average total power input ex np information capacity subject average power constraint optimal value maximize subject log det xr see ct 
maxdet problem straightforward solution known information theory algorithm see ct cp 
letr vv eigenvalue decomposition ofr 
new variable xv rewrite problem maximize subject tr log det diagonal elements appear constraints decrease objective diagonal optimum 
lagrange multipliers show solution xii max lagrange multiplier determined xii np term water lling refers visual description procedure see ct cp 
average power constraints channel problem extended modi ed ways 
example replace average total power constraint power constraint individual channels replace ex capacity subject constraint determined solving maxdet problem maximize log xr subject tox water lling algorithm apply capacity readily computed solving maxdet problem inx 
easily add constraints power limits subsets individual channels upper bound correlation coe cient components ofx gaussian channel capacity feedback max xij suppose ofx consecutive values time series 
question knowledge past helps increasing capacity ofthe channel great interest information theory ct 
gaussian channel feedback uses ofx vector bv input channel strictly lower triangular matrix 
output channel assume average total power constraint np mutual information andy log det log maximize mutual information solving maximize log det log subject tr np strictly lower triangular matrix andx 
cast problem maxdet problem introduce new covariance ofy obtain maximize log subject tr rb br np strictly lower triangular second constraint expressed lmi inb andy maxdet problem inb andy capacity cross talk yb suppose independent covariances diagonal noise covariance depends rii ri 
model near cross talk see ac 
capacity total average power constraint optimal value maximize log ri subject cast maxdet problem maximize nx nx log ti subject ti nx ri ri lmi equivalent ri 
problem solved standard methods advantage maxdet problem formulation add lmi constraints individual power limits 
interesting possibility impose constraints distribute power channels uniformly type constraint see 
problems involving moments bounds expected values semide nite programming random real variable 
expected values called power moments distribution oft 
classical result gives characterization moment sequence exists probability distribution ifx xn xn xn xn 
xn xn easy see condition necessary moments distribution yn nx ey su ciency obvious 
proof classical convexity arguments see kn karlin ks 
similar conditions distributions nite semi nite intervals 
note condition lmi condition moments distribution expressed lmi inx 
fact cast interesting moment problems sdps maxdet problems 
random variable know distribution know bounds moments includes special case knowing exact values moments 
nt polynomial int 
expected value ofp linear moments eti ep nx compute upper lower bounds ep minimize maximize ep subject nx probability distributions satisfy moment bounds solving sdps minimize maximize nx subject xk 
gives bounds ep probability distributions satisfy known moment constraints 
bounds sharp sense distributions moments satisfy moments bounds ep takes upper lower bounds sdps 
related problem considered golub deg analytically compute bounds moments 
random variable nite interval 
semide nite programming solve general problems upper lower bounds expected value polynomials known 
application arises steady state analysis continuous time markov processes multivariable moments computed cheaply sch 
upper bound variance semide nite programming example maximize variance oft probability distributions satisfy moment constraints obtain sharp upper bound variance oft maximize subject equivalent sdp yx subject xk 
lmi equivalent generally compute upper bound variance polynomial ep ep compute upper bound variance bounds moments 
robust estimate moments interesting problem maxdet problem maximize log subject solution serve robust solution feasibility problem nding probability distribution satis es bounds moments 
sdps provide lower upper bounds ep maxdet problem provide reasonable guess ep 
note maxdet problem equivalent maximize log det ef subject ef probability distributions wheref tt interpret problem designing random experiment estimate coe cients polynomial cnt ignore numerical issues ill conditioning 
quasi newton updates quasi newton methods unconstrained minimization convex functionf newton step rf replaced rf approximation hessian matrix prior information previous gradient evaluations 
iteration algorithm moves new determined di erence gradients atx updating rule satisfy properties close toh easy compute precisely search direction rf easy compute incorporate new information obtained evaluating gradient rf 
property usually enforced imposing secant condition rf rf byrd nocedal bn proposed measure di erence andh kullback leibler divergence relative entropy log see dennis wolkowicz dw lewis lew 
kullback leibler divergence nonnegative positive de andh zero computing update satis es secant condition minimizes kullback leibler divergence maxdet problem inh minimize log subject toh rf rf fletcher fle shown solution st assuming thats wheres andg rf rf 
formula known unconstrained optimization bfgs fletcher goldfarb shanno quasi newton update 
fletcher observation opens possibility adding complicated lmi constraints maxdet problem solving resulting problem numerically 
example impose certain sparsity pattern relax secant condition kh rf rf tolerance 
solving maxdet problem obviously involve far computation bfgs update 
general maxdet problem formulation quasi newton updates interesting gradient evaluations expensive 
dual problem associate dual problem maximize log trg trf subject ci variables andz problem maxdet problem converted problem form elimination equality constraints 
andz dual feasible satisfy constraints strictly dual feasible 
refer maxdet problem primal problem primal feasible iff andg strictly primal feasible iff andg 
andd optimal values problem respectively convention thatp primal problem infeasible andd dual problem infeasible 
theorem pd strictly feasible dual optimum achieved strictly feasible primal optimum achieved 
cases theorem follows standard results convex analysis rockafellar roc prove 
show rst part holds 
primal feasible andw dual feasible 
show primal objective evaluated greater dual objective evaluated log consequence pd wehave log trg trf log log trg trf mx mx trg trf log trg log trf expression nonnegative term trf nonnegative andb sum rst terms written trg log trw log kullback leibler divergence andg 
nonnegative log tra positive de veri ed eigenvalue decomposition inequality forx 
di erence primal dual objective expression called duality gap associated andz 
theorem states duality gap nonnegative zero ifx andz optimal 
note zero duality gap andf 
gives optimality condition maxdet problem primal optimal exists az thatf ci optimality condition su cient necessary primal problem strictly feasible 
remainder assume maxdet problem strictly primal dual feasible 
theorem assumption implies primal problem bounded dual problem bounded equality optimum primal dual optimal sets nonempty 
example semide nite programming dual illustration derive dual problem sdp 
substituting gi yields maximize trf subject ci optimal value ofw dual problem reduces maximize trf subject ci dual sdp notation vb 
example optimal experiment design second example derive dual experiment design problem 
simpli cations obtain maximize log subject tow wv variables scalar 
problem simpli ed 
constraints homogeneous andz dual feasible dual feasible tz 
turns analytically optimize overt changes objective log tz maximized fort simpli cation new variable problem maximize log det subject wv problem interesting geometrical meaning constraints state determines ellipsoid fx jx centered origin contains objective maximize det minimize volume ellipsoid 
interesting connection optimal primal variables points lie boundary optimal ellipsoid note duality gap associated primal feasible dual feasible equal log det mx iv log det zero optimal pm iv optimal rp mx iv xp minimum volume ellipsoid centered origin contains fact feasible mx mx jv optimal term sum left hand side positive contains sum zero term zero iv tr mx mx iv jv mx iv geometrically nonzero ifv lies boundary minimum volume ellipsoid 
precise intuitive idea optimal experiment uses extreme test vectors 
shows optimal ellipsoid experiment design example 
dual optimal experiment design problem compute minimum volume ellipsoid centered origin contains test vectors 
test vectors nonzero weight lie boundary optimal ellipsoid 
data notation 
duality optimal experiment designs minimum volume ellipsoids extends non nite compacts sets titterington tit walter pw 
optimal experiment design problem compact setc maximize log det probability measures onc 
convex semi nite optimization problem dual tit maximize log det subject vt see dual problem computing minimum volume ellipsoid centered origin covering setc 
general methods solving semi nite optimization problems fall outside scope 
particular cases problems solved maxdet problems 
interesting example arises union nite number ellipsoids 
case dual cast maxdet problem see ciently solved duality recover dual solution probability distribution solves 
central path section describe central path maxdet problem give properties 
central path role interior point methods 
de nition strictly de ne tc log log function sum convex functions rst term positive multiple objective function second term log barrier function set fx jf 
note gradient hessian expressions tci trg gi trf fi ij gig gj trf fif fj fori shown convex function diag gi fi linearly independent bounded assume problem strictly dual feasible see appendix 
de nex 
unique minimizer 
argmin jg 
parametrized byt called central path 
dual central path 
central path characterized optimality conditions 
expression trg 
gi trf 
fi ci see matrices 



strictly dual feasible 
duality gap associated 

andz 
expression trf 

trg 

log 

shows 
converges solution maxdet problem ast 
shown pair 

lies dual central path de ned 

argmin wt ci log trg trf log close connections primal dual central path summarized theorem 
theorem strictly primal feasible andw strictly dual feasible 
equality ifx 



proof 
ifa anda log tra convexity log cone positive semide nite matrices 
applying inequality nd trg trf log log log trw log tl tl tl equality forx 


veri ed substitution 
tangent central path conclude section describing tangent direction central path computed 
log log 

onthe central path characterized tangent direction 


di erentiating respect tot 
tr 



tr 


tangent direction expressed solution squares problem see appendix di erentiating obtain tangent dual central path 


newton method mx gi 


mx fi 
section consider problem minimizing computing 
strictly feasible initial point minimize subject tog includes special case analytic centering problem andf 
main motivation studying clear section discuss interior point method minimizing sequence 
newton method line search solve problem ciently 
newton method minimizing strictly tolerance repeat 
compute newton 
compute 
compute argmin hx 
update hx quantity called newton decrement atx 
cost step line search isvery small usually negligible compared cost computing newton direction see details 
known asymptotic convergence newton method quadratic 
nesterov nemirovsky nn give complete analysis global speed convergence 
main result theorem 
theorem algorithm terminates 
log log iterations terminates 
self contained proof appendix 
note right hand side depend problem size depends problem data di erence value function initial central 

term log log quadratic convergence grows extremely slowly required accuracy practical purposes considered constant say guarantees accuracy 
quite precisely theorem says 

newton steps 
precise statement number iterations compute extremely approximation ofx 

sequel speak computing central 
really mean computing extremely approximation 
justify grounds 
possible adapt exposition account extremely small approximation error incurred terminating newton process 
steps 
errors involved certainly newton steps upper bound theorem log log number newton iterations minimize log versus log log log log 
random matrix completion problems sizes 
dotted line squares data log log 
dashed line upper bound theorem log log 
scale computer arithmetic errors complexity analysis carried precision account error 
see course proof appendix theorem holds implementable version algorithm appropriate approximate line search exact line search 
numerical experiment bound provided theorem number newton steps required compute 
starting play important role path method 
useful examine bound compares actual number newton steps required practice 

shows results numerical experiment compares actual convergence newton method bound 
test problem matrix completion problem minimize log subject toa af mx xk ei ej particular case log considered problems di erent sizes indicated indicated indicated 
point gure corresponds di erent problem instance generated follows 
constructed uu elements ofu drawn normal 
guarantees strictly feasible 
index pairs ik jk ik jk chosen randomly uniform distribution diagonal index pairs 
problem sizes instances generated 
problem instance rst starting point 
selected value uniformly interval generated bx log det log det starting point newton algorithm 
experience problems shows results family random problems quite typical 
results draw important 
quantity log det log det provides upper bound number newton iterations theorem predictor number iterations practice 
hand uence course log det log det 
average number newton iterations grow log det log det 
signi cantly smaller upper bound theorem 
summary conclude di erence 
measure theory practice ort required 
newton method starting atx computable upper bound number newton steps note 
known explicitly function oft 
toevaluate bound 
carry newton algorithm 
defeat purpose trying estimate bound number newton steps required 

bound theorem directly useful practice 
theorem follows dual feasible provides bound 

bound exact ifw 
andz 

replace bound easily computed bound provided dual feasible 
log log ub log log ub bound practice complexity analysis gives readily computed bound number newton steps required 
starting dual path algorithms path methods convex optimization long history 
book fm maccormick general properties convergence optimal point connections duality attempt give case convergence analysis renegar ren proved polynomial convergence path algorithm linear programming 
nesterov nemirovsky nn studied convergence nonlinear convex problems provided proofs polynomial worst case complexity 
see nn pp den dh historical overview 
path method maxdet problem 
short step version basically path method fm nn simpli ed self contained complexity analysis 
long step combine method predictor steps accelerate convergence 
known technique originally proposed maccormick addition new step selection rule 
general idea iteration proceeds follows 
algorithm starts 
central path 
seen duality gap associated 
isn select new choose strictly feasible starting equal tox 

serves approximation ofx 
called predictor 

starting algorithm 
newton method 
reduces duality gap step 
tox 
called outer iteration 
choice oft involves tradeo large value oft means fast duality gap reduction fewer outer iterations 
hand di cult nd newton iterations may needed compute 

method discussed impose bound maximum number newton iterations outer iteration requiring new value oft satisfy bx 
implies newton iterations required 
starting 
course exact value left hand side known carry newton minimization seen replace condition ub bx conveniently chosen dual feasible points 
parameters algorithm desired accuracy path algorithm 
repeat 
bx tand ub bx 

starting newton algorithm 
step outline completely speci ed 
sections discuss detail di erent choices 
show andt satisfy fact allows estimate total complexity method derive bound total number newton iterations required reduce duality gap algorithm starts central path atx 
initial duality gap iteration reduces duality gap byt total number outer iterations required reduce initial gap nal value log log pn log log inequality follows concavity log 
total number newton steps bounded total newton iterations pn log log log upper bound increases slowly problem dimensions grows independent 
see performance practice better 
note assume minimization step algorithm exact 
justi cation assumption lies fast local convergence newton method seen takes iterations improve solution newton decrement high accuracy 
practical implementation rigorous theoretical analysis take account fact 
computed approximately 
example stopping duality gap associated exactly central 

andz 
quite accurate ifx 
known approximately 
give suitably modi ed criterion appendix show dual feasible points easily computed centering step step newton decrement 
associated duality gap yields completely rigorous stopping criterion 
brie point modi cations develop di erent variants algorithm sections full details described appendix modi cations algorithm works 
computed approximately 
value newton algorithm 
possible extend simple worst case complexity analysis take account incomplete centering attempt analysis 
fixed reduction algorithm simplest variant 


step algorithm 
substitution condition gives ub bx trg 

trf 

log 

log 

log simple nonlinear equation variable unique call variant algorithm xed reduction algorithm uses value achieves xed duality gap reduction factor outer iteration 
outline xed reduction algorithm follows 
fixed reduction algorithm 
find log repeat 

starting atx newton algorithm 
brief convergence analysis method 
outer iteration reduces duality gap factor number outer iterations exactly log log inequality complexity analysis previous section follows fact convergence analysis reveals limitation xed reduction method number outer iterations better number predicted theoretical analysis 
upper bound total number newton iterations estimate practice provided replace constant empirically determined estimate see 
purpose section develop method worst case complexity performance practice 
xed reduction algorithm better primal dual long step algorithm possible larger values oft achieve larger gap reduction outer iteration better choice step path algorithm 
natural choice take point tangent central path bx 

tangent direction 
substitution gives nonlinear equation determined 
idea step allow vary tangent dual central path take cw 


tangent directions 
equation unknowns primal step dual step 
xed reduction update previous section uses cient method nding solution described 
outline long step algorithm follows 
primal dual long step algorithm 


find log repeat 
compute tangent central path 



parameter selection predictor step 
repeat bp bq ub px qw qz 
ub bpx bx bpx 
centering step 

starting newton algorithm 
update 


ub ub tt tt ub ub parameter selection predictor step long step algorithm alternates minimizing ub primal step dual step ub ub assume exact centering step 
practice approximate minimization works provided includes small correction formulas tangent directions see appendix step computes solution technique illustrated 
gure shows iterations inner loop step instance problem family described 
slight abuse notation write ub ub 
px 
qw 
qz start left horizontal axis 
rst curve marked ub shows function oft simpli es ub 


log see 
function equal zero fort equal short step update rst iteration inner loop step 
xed minimize function step 
produces new values bp value ub allows step 
second curve gure labeled ub shows function function oft xed intersection ub gives steps repeated xed number iterations converges example happens iterations 
note step particular nal value oft large initial short step value complexity analysis short step method applies 
practice inner loop yields value oft considerably larger short step maintaining upper bound number newton step required compute 

example shown gure nal value oft factor larger short step value general factor uncommon 
preprocessing describe cost inner loop small cases negligible compared cost computing tangent vectors 
note dual andw primal dual long step algorithm allow larger step sizes 
preliminary phases algorithm starts central 

section discuss select compute point 
feasibility strictly primal feasible point known precede algorithm rst phase solve sdp feasibility problem satis esg 
details vb 
choice consider situation strictly primal feasible known central path 
case select appropriate initial value oft compute central point newton method starting atx theory practice simple works 
hard imagine cases ine cient practice 
suppose example 
reasonable initial value oft don know 
sett expend newton iterations going backwards central path 

outer iterations newton steps nd back near started 

strictly dual feasible known start known duality gap associated andz avery reasonable initial choice maxf centering stage computes central points duality gap initial primal dual solutions 
particular preliminary centering stage increase duality gap scenario sketched 
interpret motivate initial terms function ub provides upper bound number newton steps re quired 
starting atx de nition ub log log shows minimizes ub 
value value minimizes upper bound number newton steps required preliminary centering stage 
heuristic preliminary stage initial dual duality gap known choosing appropriate initial value di cult 
practical success variation newton method adapts value step square newton decrement serves measure proximity central path 
convex function oft readily minimized 
heuristic preliminary phase preliminary centering phase strictly repeat maxf argmin 
argmin hx iteration newton decrement small possible subject condition 
cient line plane searches section describe simple preprocessing allows implement line search newton method plane search ofx ciently 
line search newton method rst consider line search newton method 
bethe generalized eigenvalues pair xn gi bethe generalized eigenvalues pair xn fi wherex newton direction write hx terms eigenvalues hx hc lx log log evaluating rst second convex function ofh requires operations generalized eigenvalues computed 
cases cost preprocessing computing generalized eigenvalues exceeds cost minimizing small compared cost computing newton direction 
function hx ciently minimized standard line search techniques 
plane search long step path method similar idea applies plane search ofx 
step primal dual long step algorithm minimize function ub px qw qz andq tangent directions central path 
reduce function convenient form ub px qw qz ub lx log lx log log log generalized eigenvalues pair generalized eigenvalues pair generalized eigenvalues generalized eigenvalues coe cients trg trf rst second derivatives function respect computed low cost minimum ub plane determined cheaply generalized eigenvalues computed 
summary cost line plane search basically cost preprocessing computing certain generalized eigenvalues usually negligible compared rest algorithm determining newton tangent direction 
implication cient line plane searches total number newton steps serves measure computing ort 
duality gap newton iterations duality gap newton iterations duality gap versus number newton steps randomly generated maxdet problems 
left 
right 
crosses results xed reduction method circles results long step method 
cross circle represents gap outer iteration 
numerical examples typical convergence rst experiment compares convergence xed reduction method long step method 
lefthand plot shows convergence methods righthand plot shows convergence 
duality gap shown vertically logarithmic scale ranging top bottom horizontal axis total number newton steps 
outer iteration shown symbol plot long step short step method 
horizontal distance consecutive symbols shows directly number newton steps required particular outer iteration vertical distance shows directly duality gap reduction problem instances generated follows chosen random positive de nite constructed asu elements ofu drawn normal fi random symmetric matrices elements drawn ci procedure ensures problem primal dual feasible primal feasible dual feasible bounded 
start central path initial duality gap 
observations 
convergence similar problem instances 
number iterations required reduce duality gap factor ranges 
expected long step method performs better xed reduction method typically converges iterations 
xed reduction method converges linearly 
duality gap outer iteration computed equation andt 
number newton iterations outer iteration cases upper bound 
remember bound combination conservative estimates theorem conservative see 
addition replaced weaker condition 
long step method takes newton iterations centering step achieves larger duality gap reduction 
convergence accelerates near optimum 
increasing large ect xed reduction method little ect long step method 
complexity versus problem size shows uence problem dimension convergence 
triplet generated problem instances 
plot number newton iterations reduce duality gap factor starting duality gap 
plot shows average number newton steps standard deviation 
top curve shows results xed reduction method lower curve long step method 
number newton iterations short step method depends 
easily explained convergence analysis seen number outer iterations grows theory practice practical behavior xed reduction method close worst case behavior 
see number iterations long step method lies weakly dependent problem size 
shows similar results family experiment design problems including constraint 
generated normal onr note dimensions corresponding con rms previous experiment shows complexity xed reduction method grows complexity long step method independent problem size 
maxdet problem quite speci convex extension semide nite programming problem includes wide variety convex optimization problems special cases 
importantly maxdet problems arise naturally areas including computational geometry linear algebra experiment design linear estimation information communication theory 
wehave described applications 
newton iterations newton iterations versus problem size family random problems 
fixed reduction method top curve long step method lower curve 

left 
middle 
right 
curves give average problem instances 
error bars indicate standard deviation 
newton iterations newton iterations versus problem size family experiment design problems including rule 
fixed reduction method top curve long step method lower curve 

curves show average problem instances 
error bars indicate standard deviation 
applications studied extensively literature cases analytic solutions cient specialized algorithms developed 
interior point algorithm solves general maxdet problems ciently 
method applied solve maxdet problems specialized algorithm known cases method exists opens possibility adding useful lmi constraints important advantage practice 
proved worst case newton iterations 
numerical experiments indicate behavior better practice method typically requires number iterations lies independently problem dimension 
total computational ort determined amount ofwork iteration computation newton directions depends heavily problem structure 
structure exploited newton directions computed squares formulas appendix operations important savings possible specialize general method speci problem class 
acknowledgments rst version people useful comments suggestions pointers applications including applications version 
henry wolkowicz pointed useful applications maxdet problem interpretation quasi newton update 
gave useful comments pointed experiment design problems system identi cation 
lennart ljung tomas pointed maximum likelihood problems arising frequency domain identi cation non uniformly spaced frequency samples 
bill pointed log det problems arising pure mathematics extremal problems laplacian operator manifolds 
erik ordentlich contributed section channel capacity 
mike harrison elisabeth brought attention moment problems arising steady state analysis continuous time markov chains 
paul algoet eric beran anders hansson hindi gave detailed comments 
indebted patrick gene golub art owen helpful discussions 
ac cio achievable information rates digital subscriber loops limiting information rates crosstalk noise 
ieee transactions communications 
ad atkinson 
optimum experiment designs 
oxford statistical science series 
oxford university press 
ali alizadeh 
interior point methods semide nite programming applications combinatorial optimization 
siam journal optimization february 
anderson 
statistical inference covariance matrices linear structure 
krishnaiah editor multivariate analysis ii 
proceedings second international symposium multivariate analysis held wright state university dayton ohio june pages 
academic press new york 
anderson 
estimation covariance matrices linear combinations inverses linear combinations matrices 
bose editors essays probability statistics pages 
university north carolina press 
bar barnes 
algorithm separating patterns ellipsoids 
ibm journal research development 
boyd el ghaoui 
method centers minimizing generalized eigenvalues 
linear algebra applications special issue numerical linear algebra methods control signals systems july 
boyd el ghaoui balakrishnan 
linear matrix inequalities system control theory volume studies applied mathematics 
siam philadelphia pa june 
barrett johnson 
formulation matrix completions associated chordal graphs 
linear algebra appl 
burg luenberger wenger 
estimation structured covariance matrices 
proceedings ieee 
bn byrd nocedal 
tool analysis quasi newton methods application unconstrained minimization 
siam numerical analysis pages 
br bertsekas rhodes 
recursive state estimation set membership description uncertainty 
ieee trans 
aut 
control ac 
bv boyd vandenberghe 
convex optimization engineering applications 
lecture notes information systems laboratory 
stanford university 
www isl stanford edu people boyd ee html 
bw 
maximum entropy elements intersection ne space cone positive de nite matrices 
siam matrix analysis applications 
che 
guaranteed estimates undetermined quantities means ellipsoids 
soviet math 
doklady 
che 
state estimation dynamic systems 
crc press boca raton florida 
cp cover 
gaussian feedback capacity 
ieee transactions information theory 
ct cover thomas 
elements information theory 
wiley 
cheung 
optimal volume ellipsoid algorithm parameter estimation 
ieee trans 
aut 
control ac 
dd 
generalized schur algorithm approximations hierarchy 
ini editor topics operator theory interpolation pages 
birkhauser verlag 
deg golub 
bounds error linear systems equations theory moments 
journal mathematical analysis applications 
del 
set membership identi cation digital signal processing 
ieee trans 
acoust speech signal processing 
dem dempster 
covariance selection 
biometrics 
dem dembo 
relation maximum likelihood estimation structured covariance matrices 
ieee transactions acoustics speech signal processing 
dg 
extensions band matrices band inverses 
linear algebra appl 
klee 
helly theorem relatives 
klee editor convexity volume proceedings symposia pure mathematics pages 
american mathematical society 
dh den 
interior point approach linear quadratic convex programming 
kluwer 
davis kahan weinberger 
norm preserving dilations applications optimal error bounds 
siam numerical anal june 
dms dembo mallows shepp 
embedding nonnegative de nite toeplitz matrices nonnegative de nite circulant matrices application covariance estimation 
ieee transactions information theory 
dn ning 
models large integrated circuits 
kluwer 
dno 
square identi cation error bounds real time signal processing control 
proceedings ieee 
dw dennis wolkowicz 
sizing change secant methods 
technical report corr department combinatorics optimization 
university waterloo 
el el ghaoui 
robustness analysis semide nite programs applications matrix completion problems 
proceedings 
fed fedorov 
theory optimal experiments 
academic press 
fh fogel huang 
value information system identi cation bounded noise case 
automatica 
fle fletcher 
new variational result quasi newton formulae 
siam optimization pages 
fm mccormick 
nonlinear programming sequential unconstrained minimization techniques 
wiley 
reprinted siam classics applied mathematics series 
fog fogel 
system identi cation membership set constraints energy constrained noise 
ieee trans 
aut 
control ac 
johnson sa wolkowicz 
positive de nite completions partial hermitian matrices 
linear algebra appl 
gls grotschel lovasz schrijver 
geometric algorithms combinatorial optimization volume algorithms combinatorics 
springer verlag 
hw 
symmetric hankel operators minimal norm extensions 
linear algebra appl 
johnson wolkowicz 
interior point method approximate positive semide nite completions 
technical report corr report university 
joh john 
extremum problems inequalities subsidiary conditions 
moser editor fritz john collected papers pages 
birkhauser boston massachussetts 
joh johnson 
positive de nite completions guide selected literature 
auslander kailath mitter editors signal processing 
part signal processing theory ima volumes mathematics applications pages 
springer 
kn 
markov moment problem extremal problems volume translations mathematical monographs 
american mathematical society providence rhode island 
ks karlin 
systems applications analysis statistics 
wiley interscience 
kt khachiyan todd 
complexity approximating maximal inscribed ellipsoid polytope 
mathematical programming 
lee lee 
constrained maximum entropy sampling 
technical report department mathematics university kentucky lexington kentucky 
lew lewis 
convex analysis hermitian matrices 
siam optimization 
lj johnson 
linearly constrained positive de nite completions 
linear algebra appl 
lo lewis overton 
eigenvalue optimization 
published numerica 
nn yu 
nesterov nemirovsky 
interior point polynomial methods convex programming volume studies applied mathematics 
siam philadelphia pa 
norton 
identi cation 
academic press 
norton 
identi cation application bounded parameter models 
automatica 
nt yu 
nesterov todd 
self scaled cones interior point methods nonlinear programming 
technical report cornell university april 
nw 
partial matrix contractions intersections matrix balls 
linear algebra appl 

optimal design experiments 
wiley 
pw walter 
minimum volume ellipsoids containing compact sets application parameter bounding 
automatica 
ren renegar 
polynomial time algorithm newton method linear programming 
mathematical programming 
north holland press 
rl rousseeuw leroy 
robust regression outlier detection 
wiley 
roc rockafellar 
convex analysis 
princeton univ press princeton second edition 
ros rosen 
pattern separation convex programming 
journal mathematical analysis applications 
sap 
programming approach problems vlsi design 
phd thesis coordinated science laboratory university illinois urbana campaign august 
sch 
recursive state estimation unknown bounded errors system inputs 
ieee trans 
aut 
control ac 
sch 
uncertain dynamic systems 
prentice hall englewood cli 
sch 
statistical signal processing 
addison wesley 
sch 
linear programming approach steady state analysis markov processes 
phd thesis graduate school business stanford university 
draft 
sho shor 
cut method space extension convex programming problems 
cybernetics 
son 
analytical centre new classes global algorithms linear smooth convex programming 
lecture notes control information sciences volume pages 
springer verlag 
son 
applications analytic centers 
golub van editors numerical linear algebra digital signal processing parallel algorithms volume nato asi series pages 

tit titterington 
optimal design geometric aspects ofd optimality 
biometrika 
khachiyan 
method inscribed ellipsoids 
soviet math 
dokl 
american mathematical society 
vb vandenberghe boyd 
primal dual potential reduction method problems involving matrix inequalities 
mathematical programming july 
vb vandenberghe boyd 
semide nite programming 
siam review march 
whi whittle 
optimization time 
dynamic programming stochastic control 
john wiley sons 
wit 
sets possible states linear systems perturbed observations 
ieee trans 
aut 
control 
walter 
estimation parameter bounds bounded error data survey 
mathematics computers simulation 
yn nemirovski 
informational complexity cient methods solving complex extremal problems 

formulas appendix contains additional computational details 
give alternative expressions newton direction dual update tangent directions primal dual central paths 
expressions valid centering step incomplete 
newton direction rst derive squares formula newton direction 
matrices satisfy gi trc fi tci andc exist assume matrices diag gi fi linearly independent 
possible choice isc andc tz andz dual feasible pair 
note andc positive de nite 
newton computed solution squares problem forj vj gi vj fi gj fj norm frobenius norm tra verify solution newton direction writing optimality conditions normal equations 
fori wehave ttr gi mx gj tci mx tr fi mx mx mx fj equation de nition newton direction newton decrement de ned mx nx gig lx mx fif generalized eigenvalues pair jv gj generalized eigenvalues pair jv fi 
dual update squares problem written set linear equations symmetric mx mx gi fi equivalence system ofm equations leastsquares problem follows optimality conditions 
obtains normal equations andz substituting 
equations rewritten mx mx gig fif observations 
equation de nition ofc andc imply satisfy equalities ci andz positive de nite newton decrement implies generalized eigenvalues matrix pairs jv gj jv fj matrices right hand side equations positive de nite 
important need exact value ofx 
obtain dual feasible points 
soon newton decrement dual feasible solutions result byproduct computing newton direction 
central path newton decrement zero dual variables reduce tow 



practice impossible 
exactly formulas 
tangent primal central path similar squares formula tangent direction central path 
letx 

andz 


solution squares problem mx vj gj mx vj fj wg zf veri ed working normal equations fori wehave ttr gi mx gj ci mx mx equal 
tr fi mx trf fif fj mx fj trg gig gj tangent dual central path tangent dual central path derived similar way dual update 
write squares problem set linear equations andv mx mx igi wg fi tf zf jg tz jf andz see andv identical 

see 
note deriving expressions primal dual tangent directions assumed andz exactly centered 
ifx andz exactly central path compute primal search direction dual search direction 
complexity newton method appendix analyze complexity newton method minimizing log log subject tof andg 
follow nesterov todd nt nesterov nemirovsky nn 
region quadratic convergence theorem newton decrement atx 
strictly feasible newton decrement atx words quadratic convergence region 
proof 
letv newton step 
write generalized eigenvalues matrix pair jv gj generalized eigenvalues matrix pair jv fj 
follows eigenvalues 
mx mx gig fif proves rst part theorem strictly feasible 
prove second part theorem note equations optimality conditions squares problem andv tg ug vf subject solution isu andv optimal value true andx respectively 
ti ti loss generality assume ti ti gig fif ti tg tg tg theorem consequence 
proof 
problem dual log log log subject tog log log trf nt subject tci duality gap associated aw andz feasible log log trf nt establish showing matrices dual feasible duality gap log 
clear satisfy equality constraint 
positive de nite 
seen wg zf mx mx gi fi eigenvalues ofg vn gig andf vn fif positive de nite 
conclude strictly dual feasible 
duality gap associated log log trf nt log mx igi mx log mx trf mx nx log log lx fi log gi fi inequality follows power series expansion log zero see vb 
number steps reach region quadratic convergence rst derive upper bound pv function ofp 
assumption necessarily newton direction atx 
generalized eigenvalues generalized eigenvalues 
max max max min min min 
pv feasible forp upper bound interval plus nity lower bound interval minus nity 
property nt 
theorem forp pv proof 
need show zt zz pv zt letr rl matrix simultaneously letr rn matrix simultaneously consequence pv andr pv 

pv ttr tr mx mx mx pv mx pv mx mx ag pv pv rt af pv pv rt mx pv mx ttr tr ttr tr zt ar pv proves upper bound theorem 
lower bound derived similar way 
integrating upper bound twice obtain upper bound onf pv pf assuming 
upper bound reaches minimum bp log ifv newton direction expressions simplify bp corresponding upper bound bp log obtain expression terms newton decrement fact thatf yields proof theorem bp log position prove theorem 
simplicity write 

prove newton algorithm terminates log log iterations 
rst consider initial stage algorithm 
know function decreases log log iteration 
number iterations required reach bounded second stage algorithm converges quadratically log log iterations 
complete proof note theorem 
log 
