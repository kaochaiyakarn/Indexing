article press pattern recognition www elsevier com locate pr svd initialization head start nonnegative matrix factorization gallopoulos computer science department rensselaer polytechnic institute troy ny usa computer engineering informatics department university patras gr patras greece received february received revised form august accepted september describe nonnegative double singular value decomposition nndsvd new method designed enhance initialization stage nonnegative matrix factorization nmf 
nndsvd readily combined existing nmf algorithms 
basic algorithm contains randomization svd processes approximating data matrix approximating positive sections resulting partial svd factors utilizing algebraic property unit rank matrices 
simple practical variants nmf dense factors described 
nndsvd suited initialize nmf algorithms sparse factors 
numerical examples suggest nndsvd leads rapid reduction approximation error nmf algorithms 
pattern recognition society 
published elsevier rights reserved 
keywords nmf sparse nmf svd nonnegative matrix factorization singular value decomposition perron frobenius low rank structured initialization sparse factorization 
nonnegative matrix factorization nmf approximation usually nonnegative matrix rm product nonnegative factors say selected useful tool large variety applications scientific literature software tools subject variants thereof rapidly expanding see refs 
description specific software packages refs 

usual denote componentwise inequality elements matrices convenience ref 
denote set nonnegative matrices 
motivation nmf dimensionality reduction sought applications underlying data ensemble nonnegative better modeled interpreted means nonnegative factors 
corresponding author 
tel fax 
mail addresses cs rpi edu gr gallopoulos 
referring nmf general approximation problem acronym nma appropriate :10.1.1.140.3037
pattern recognition society 
published elsevier rights reserved 
doi instance image collections frequently stored matrices nonnegative elements column encodes image collection 
application nmf produce dictionary basis images columns factor nonnegative coefficients linear combination images reconstructs approximation originals factor text mining vector space model document collections stored term document matrices nonnegative elements matrix column encoding document 
column corresponds basic document resulting documents additively combined coefficients reconstruct approximation document collection applications dimensional reduction clustering :10.1.1.105.9495
cases nmf provides framework learning parts images semantic features text 
area application space situational data collections consist spectral reflectance data space object containing essential information regarding materials composing 
column matrix represents spectral measurement 
nmf factor contains spectral signatures aid detecting type constituent materials space object contains coefficients help computation please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition proportional amounts materials appear object 
cases additive nature factorization proposed important aid interpretation 
target nmf problem follows natural number min compute solve minw wh wh rm rm suitable distance metric 
nmf algorithms combined initialization proposed distance metrics frobenius norm wh modifications thereof generalized kullback leibler divergence wh 
extensively literature directly related general metrics :10.1.1.140.3037
defined nmf problem general instance case demand factors product exactly equals matrix ignoring roundoff 
nonnegative decompositions central topic early treatments nonnegative matrices see ref 

general guarantee exact nonnegative factorization exists arbitrary known exists natural number called nonnegative rank nonnegative having number rank wh holds exactly cf 
ref 

furthermore nmf nonconvex optimization problem inequality constraints iterative methods necessary solution see refs 

unfortunately current nmf algorithms typically converge slowly local minima 
exist algorithms approximating matrices nonnegative factors ref 
plays pivotal role cf 
survey 
popular researchers basis developments algorithms proposed ref 

rely iterative multiplicative additive correction initial guesses pair factors 
algorithms proven converge monotonically interpreted diagonally rescaled gradient descent methods cf 
refs 

important issue addressed researchers incorporation constraints appropriate problem see 
generic constraint sparsity frequently important minimize number features reconstruction sparse linear representation case signal processing 
ref 
example uses sparsity metric describes algorithm satisfy factors 
due iterative nature nmf algorithms initialization pair factors cited literature important component design successful nmf methods 
focus issue 
exceptions see refs 
nmf algorithms literature random nonnegative initialization 
iterates converge local minimum necessary run instances algorithm different random initializations select best solution 
nmf viewed bound optimization problem suffer slow convergence 
process quite expensive 
step development faster algorithms nmf propose novel initialization strategy singular value decomposition svd features readily combined available nmf algorithms ii basic form contains randomization converges solution algorithm iii rapidly provides approximation error obtained deployment alternative initialization schemes run convergence 
call proposed initialization strategy nndsvd nonnegative double singular value decomposition underline fact svd processes create rank approximation followed small svd positive sections factors 
property iii expected especially useful application constrains maximum time interval result delivery 
nndsvd depends interesting property lemma theorem concerning behavior unit rank matrices best knowledge fact remained unnoticed interesting applications domains 
show family nonnegative matrices nndsvd returns exact nmf proposition 
basic algorithm admits interesting modification name step nndsvd potential provide initialization lower cost 
sequel vector matrix variable positive section defined vector matrix size contains values nonnegative elements 
negative section matrix 
follows immediately vector matrix written 
notation followed necessary 
notions positive negative course slight really referring nonnegative absolute value nonpositive values respectively 
prefer handling zero values clear context 
seek sparse factors refer sparse nmf 
occasionally refer dense nmf need underline seek sparsity 
organized follows section discusses initialization context related describes properties nndsvd 
section illustrates performance method variety cases 

svd initializations research papers date discussing nmf algorithms mention need investigate initialization strategies see ref 
absence additional information problem initialize elements pair nonnegative random values 
cases factors initialized random chosen satisfy certain constraints possibly obtained solving optimization problem initial values 
sequel referring initialization mean initialization factors specific necessary 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press nature underlying optimization problem repeated runs algorithms different initializations necessary lead different answers 
proceeding need clarify mean initialization strategy 
possible answers leads rapid error reduction faster convergence ii leads better error convergence 
concentrate objective noting satisfactory answer remains elusive 
nmf constrained low rank matrix approximation seek initialization strategy alternative low rank factorization schemes 
published algorithms nonrandom initialization see refs 
relies method see ref 
provides low rank approximation clustering 
specifically spherical means partition columns clusters selecting normalized centroid representative vector named concept vector cluster vector initialize corresponding column depending nmf algorithm subsequently random computed arg minh wh shown refs 
iterations clustering algorithm sufficient scheme call centroid sequel leads faster error reduction random initialization 
specifically numerical experiments ref 
showed method overhead clustering phase save expensive nmf update steps 
quest eventually led framework proposed explored initializations inspired aforementioned original ideas refs 
structured initialization 
specifically deployed svd analogue cf 
ref 
low rank approximation methods cen 
clustered columns groups initialized nonnegative left right singular vectors corresponding maximum singular value group 
existence guaranteed perron frobenius theory see ref 

results mixed svd approach outperform centroid 
motivated consider alternative approaches 

nndsvd initialization method initialization turns quite effective 
start basic property svd matrix rm rank min expressed sum leading singular factors uj nonzero singular values uj vj corresponding left right singular vectors 
optimal approximation respect frobenius norm say readily available sum factors cf 
ref 
schmidt eckart young theory gallopoulos pattern recognition arg min rank uj assume nonnegative 
approach uses modification expansion produce nonnegative approximation provide time effective initial values 
particular unit rank matrix approximated nonnegative section subsequently initialized selected singular triplets factors possess special properties play key role algorithm 
show rank set zero small rank increment property lemma 
best nonnegative approximations terms frobenius norm cf 
lemma 
exist corresponding singular vectors nonnegative readily available singular triplets uj vj cf 
theorem 
summary nndsvd described follows compute leading singular triplets ii form unit rank matrices obtained singular vector pairs iii extract positive section respective singular triplet information iv initialize 
svd steps iii motivated naming nndsvd 
hand show special properties steps ii iii implemented low cost 
notation introduced far show lemma central discussion 
lemma 
consider matrix rank write 
rank rank 
proof 
rank assumption write xy 
factors nonnegative nonzero values positive section situated locations complementary nonzeros corresponding negative section 
consequently nonzero element obtained exactly term terms right 
rank 
worth noting alternate algebraic proof write matlab notation 
note unit rank 
expression amounts decomposing xy xjy xy xjy rank :10.1.1.140.3037
result albeit simple quite remarkable tells zero negative values unit rank matrix resulting matrix rank 
call set zero small rank increment property 
worth noting easy verify matrices rank share similar property 
example consider matrix please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition xy rank rank 
rank 
nonnegative maximum left right singular vectors nonnegative perron frobenius theory 
theorem says remaining trailing singular vectors nonnegative 
furthermore special structure singular value expansion readily available 
theorem 
unit rank xy normalized positive negative sections 
unordered singular value expansions 
maximum singular triplet max 
similarly maximum singular triplet max 
proof 
construction pair vectors nonzero values complementary locations matrices orthogonal 
terms nonnegative result follows uniqueness singular value expansion 
similarly decomposition 
result establishes nonnegativity singular vectors corresponding nontrivial singular values 
immediate connection decompositions introduced theorem concept nonnegative rank mentioned section 
definition gregory 
nonnegative rank rank ofa smallest number nonnegative unit rank matrices matrix decomposed additively 
nonnegative rank difficult compute see ref 

generally holds rank rank min cf 
ref 

shown ref 
rank rank rank 
combining previous results provide precise estimates regarding nonnegative ranks 
corollary 
rank 
ii rank rank 
iii contains positive negative elements table nndsvd initialization nonnegative matrix matlab notation inputs matrix integer min 
output rank nonnegative factors rk 
compute largest singular triplets 
initialize sqrt sqrt 

xp pos xn neg yp pos yn neg 
norm xp norm yp mp 
norm xn norm yn mn 
mp mn xp yp sigma mp xn yn sigma mn 
sqrt sigma sqrt sigma call computes leading singular triplets matlab svds 
functions pos neg extract positive negative sections argument ap pos returns ap 
neg returns 

rank 
iv resp 
rank resp 
rank 
parts iii iv follow directly unit rank assumption theorem 
part ii follows aforementioned result ref 

theorem provides explicit construction decomposition suggests cheap way compute 
lemma straightforward consequence definition frobenius norm 
lemma 
rm arg min best terms frobenius norm nonnegative approximation unit rank term corresponding preceding results constitute theoretical foundation nndsvd 
method implemented table 
note method approximates terms unit rank singular factor expansion means positive sections 
new factors rank 
factors approximated maximum singular triplet initialize 
note step applied onwards leading singular triplet nonnegative readily initialize column resp 
row resp 


nndsvd approximation preceding results possible bound error corresponding initial factors obtained nndsvd specifically frobenius norm residual wh 
denote nonzero singular values nonincreasing order xj yj singular triplets 
lemma rank nontrivial triplets index please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi usual 
write rj uj article press gallopoulos pattern recognition nndsvd algorithm table selects wh 
wh measures deviation optimal unconstrained approximation eq 

singular vectors unit length 
furthermore 
lead result proposition 
pair initialized nndsvd frobenius norm wh bounded follows 
upper bound loose may larger trivial upper bound obtained initialized zero establishes residual bounded 
far greater interest practice iterations sufficient nndsvd drive initial residual magnitude close obtained applied underlying nmf algorithm random initialization iterations 
analysis helps bound error modified versions nndsvd described section 
rely initializing pair wf hf wf ew hf eh ew eh structured perturbations nonzero elements occur positions complementary respectively 
max eh ew 
columns rows unit length wf hf wh weh ew ew eh wh 
note term right side bounded proposition 
show matrices nndsvd able return exact decomposition nonnegative unit rank factors 
consider matrices admit orthogonal nonnegative factorization described refs 

category belong instance block diagonal matrices diagonal block unit rank generated nonnegative vectors 
proposition 
wa ha rk nonnegative diagonal 
wa ha orthogonal wa hah nndsvd applied compute rank factors initializes exact values wad ha ii pair returns minimum error frobenius norm proof 
construction compact svd written sum rank terms resulting product corresponding column wa row ha diagonal term nndsvd compute elements exactly terms nonnegative positive sections identical terms 
result follows optimal approximation property cf partial svd respect frobenius norm 

dense variants described feature nndsvd obtains initial columns rows leading singular vectors positive section singular factors maximum singular vectors contain positive negative elements 
initial contain number zeros commensurate 
cases seek sparse nmf cf 
ref 
discussion section fig 
desirable especially view fact nmf algorithms retain sparsity iterates initial 
dense case large number zeros may undesirable illustrated compare performance methods fig 

particular seen cases basic algorithm initially provides rapid error reductions eventually leads worse error random 
worth noting behavior observed algorithms described ref 

address problem deploy slightly modified variants basic algorithm 
perturb zero values original particular please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition table nonnegative unit rank approximation arbitrary matrix input matrix output nonnegative rm gh 
compute largest singular triplet 
set nonnegative sections 
compute ch set 
compute set variant sets zeros equal average elements denote mean 
variant sets zero element equal random value chosen uniform distribution mean 
variants incur appreciable overhead basic initialization lead error bounds eq 

user control number zero elements perturbed exercise judiciously satisfy wh wf hf 

discussion extensions discuss evaluate seemingly similar initialization option comes mind naturally svd 
set zero positions negative values uj vj pair singular value expansion multiples vectors initialize 
straightforward method interpreted framework particular uj theorem dropping simplicity index till paragraph right scalar multiple singular factor 
remind 
initialization equivalent approximating nndsvd picks depending magnitude corresponding cf 
theorem 
conclude nndsvd preferable leads equal smaller error contribution term 
aforementioned approach closely related iterative algorithm discussed ref 
nonnegative unit rank approximation arbitrary matrices 
algorithm tabulated table initializes vectors positive sections leading left right singular vectors matrix iterates certain number steps 
show input matrix unit rank terms uv corresponding algorithm progress return approximations positive sections computed step 
step uv 
follows uv final value entered change steps 
similarly new value original 
approximations returned process applied arbitrary unit rank matrix 
sketch extension nndsvd call step nndsvd especially useful difficult expensive compute leading singular triplets theorem know maximum trailing singular triplet 
deviate slightly matlab notation mean mean 
strictly nonnegative components 
nndsvd modified follows columns rows filled rank initialize column row scalar multiples maximum left right singular vectors done original algorithm 
rank columns rows initialized scalar multiples respectively 
example odd rank factors produce nonnegative initialization 
note approach singular vectors generating participate initialization reconstruction exact 
step nndsvd leads different upper bound residual 
corollary 
pair initialized step nndsvd 
initialization nndsvd readily combined existing nmf algorithm 
ones selected tabulated table 
mm ad correspond additive multiplicative updates proposed ref 

mm uses wh ah denote element element multiplication division respectively 
updates increase frobenius norm residual wh refer literature full description design update formulas remaining methods table 
mention data matrix symmetric seeking symmetric hh weighted symmetric nonnegative factorizations see ref 

noting matrix symmetry inherited positive section nndsvd adapted generate symmetric initialization 
costs lower necessary values derived eigendecomposition svd half factors need computed 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi table nmf algorithms article press gallopoulos pattern recognition name comments ref 
distance metric wh mm multiplicative wh wh ad additive wh wh multiplicative wh wh gd cls alternating sq 
wh wh sparse nmf wh wh stands constrained nmf 
stands gradient descent constrained squares 
table datasets experiments name matrix size comments classic specified ref 
tmg iris human eye iris images size cbcl faces size ref 
usgs hyperspectral spectra measured wavelengths natural images images natural scenes size shuttle shuttle images size images ref 
displayed fig 

data collected geological survey usgs digital spectral library 
see refs 
regarding spectral unmixing application 
dataset described ref 

kindly provided prof plemmons taken air force maui space center space shuttle columbia tragic final orbit re entry february 
sample images depicted fig 

datasets shuttle iris cbcl natural images vectorized column corresponds image 
table algorithm dataset combinations pointers figures results classic usgs shuttle cbcl iris natural images mm ad gd cls fig 

sample space shuttle columbia images 

computational costs major computational steps nndsvd computing largest singular triplets ii computing maximum singular triplet positive section singular factor singular expansion appropriate large sparse data assume partial svd fig 

basis images dataset shuttle algorithm mm 
computed means iterative algorithm see refs 

improvement algorithms compute steps reduce runtime nndsvd 
rough estimate cost step kmn dense hidden notation factor depends number iterations convergence unknown priori 
step performed effectively computing explicitly rank matrices specifically rank singular triplets readily available please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition objective function objective function classic iterations shuttle random centroid iterations fig 

dataset human eye iris images 
random centroid theorem cost 
cost nndsvd dense data kmn 
asymptotic cost structured centroid initialization relies kmn leading constants expressions typically smaller 
initialization method eventually linked nmf algorithm fairness measure take account initialization cost terms objective function fig 

algorithm mm datasets classic usgs shuttle iris 
objective function usgs iterations iris random centroid iterations random centroid eration equivalents ensuing nmf number iterations say factorization algorithm performed time takes initialize 
set random 
nmf algorithms update formulas written enforce sequencing operations appropriate problem dimensions 
example datasets min update formulas computed wh worth noting depending dimensions selected sequencing runtime differences significant 
design matlab implementation enforce sequencing means parentheses algebraic expression default left right 

numerical experiments ran experiments nmf algorithms fig 
datasets tabulated tables 
table shows number corresponding results specific please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition fig 

progress approximation iris dataset mm random left center nndsvd right 
rows correspond iterations 
objective function objective function cbcl random iterations usgs centroid objective function fig 

algorithm ad datasets cbcl natural images 
iterations random centroid natural images fig 

algorithm datasets usgs iris 
objective function iterations iris random centroid iterations random centroid please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition objective function objective function cbcl iterations random centroid objective function fig 

algorithm gd cls datasets cbcl natural images 
classic sw sh iterations random centroid nndsvd fig 

sparse nmf algorithm dataset classic 
algorithm dataset combinations 
plot depicts value corresponding objective function see table details vs number iterations 
displays value selected parameter measured value taken account evaluating results 
comparing residual error curves random centroid nndsvd shift appropriately particular compare errors iteration nndsvd iteration random subscript distinguishes 
similarly centroid 
comparing errors centroid nndsvd compare iteration iteration 
platform ghz pentium iv mb ram running windows 
codes written matlab 
variety methods compute partial svd 
matlab library lanczos partial provides fast alternative natural images iterations random centroid matlab native svds 
care required functions forced return nonnegative leading singular vectors matlab return entirely nonpositive leading singular vectors 
product course nonnegative 
sufficient nndsvd utilizes positive section vectors 
case nonpositive vectors return zero values 
cautious absolute values leading singular vectors 
design choice need mention centroid initialized random 
choice dictated cost intrinsic shelf mat lab functions codes ref 
solving nonnegative squares problem necessary produce specifically runtime high viable components initialization method 
furthermore internally developed implementation clustering 
initializations experiments listed 
note figures selected extensive experimentation initializations algorithms datasets selection representative results 
random initialize pair random mat lab rand 
centroid initialize ref 
random 
ran iterations 
nndsvd specified table 
perturbed nndsvd mean cf 
section 
perturbed nndsvd values mean cf 
section 
fig 
shows experiments mm 
fig 
shows progress approximation data set iris fig 
random nndsvd initializations 
displays basis images resulting columns matrix specified number iterations 
noteworthy result different initializations lead different basis images 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi objective function shuttle article press iterations gallopoulos pattern recognition random centroid nndsvd objective function classic iterations fig 

nndsvd centroid datasets shuttle classic 
figs 
show results algorithms ad gd cls respectively 
fig 
depicts results sparse algorithm 
case basic nndsvd variants justified section 
plots show selected values parameters sw sh determine desired sparsity level 
alluded section image datasets table data matrix constructed stacking columns vectorized images collection common practice nmf literature 
columns correspond basic images 
image collection column approximated linear combination basis images reconstruction coefficients elements corresponding column figs 
example show resulting basis images shuttle iris datasets 
dataset classic term document matrix benchmark text mining column encodes basis document 
dataset usgs column encodes spectral signature useful spectral unmixing cf 
refs 
information regarding similar datasets context nmf 
account aforementioned shifts iterations plots confirm nndsvd type initializations fast 
outperform random test cases generally appear better choice combined gd cls centroid 
need time reduce nmf objective function improvements dramatic iterations nmf algorithm evidenced pronounced knee shape corresponding error curves depicted figures visualization dataset iris fig 

gains computational efficiency algorithms nndsvd appear lead smaller error random centroid convergence see fig 

feature differentiates nndsvd random centroid basic method deterministic 
nndsvd appears random centroid nndsvd initialization scheme comes provable theoretical guarantees approximation error proposition 
assuming reader proceeds caution evidence entirely experimental heuristics solely sparsity structure dataset experiments provide guidance selection suitable nndsvd variant 
specifically seek sparsity constraints basic nndsvd algorithm appears suited tends generate sparse factors 
probably better 
experiments tends return somewhat superior results 
extensive experiments algorithm emerged winner final decision rests user experience variants performance data study 
fig 
illustrates performance initialization methods combined algorithm 
dataset shuttle left methods reach final error better performance pronounced knee behavior 
dataset classic right error random eventually catches 
mentioned earlier behavior motivation design nndsvd variants pronounced knee behavior results smallest final error 
conclude nndsvd provides initial values enable followup nmf algorithms significant reduction initial residual iterations low cost levels comparable residual obtained running algorithm convergence basic initializations 
mention issues submission aware ref 
including extensive experiments variants nndsvd described 
expect useful potential user double svd approach initializing nmf 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press gallopoulos pattern recognition arisen course investigation study generalization property lemma application clustering nndsvd spirit centroid performance method context distance metrics ref 
better tailored prior knowledge data :10.1.1.140.3037
worth reminding nndsvd frequently leads errors comparable superior achieved random initialization provide guarantees regarding quality local minimum reached subsequent nmf algorithm 
computed solution unsatisfactory conclude nndsvd hinders progress better local minimum basic form deterministic allow multiple runs 
extent effectiveness strategy escape local minima justified opt multiple runs randomized variant nndsvd simply repeatedly run nmf algorithm random initialization keeping track comparing results including obtained nndsvd 
clearly field open research contributions coupling deterministic initialization strategies leading smaller approximation errors 
acknowledgments discussions original experiments colleague dimitris helpful 
providing matlab code 
professors robert plemmons invaluable advice encouragement daniel comments early version manuscript petros drineas helpful observations 
grateful stefan wild providing useful details codes original papers 
reviewers insightful comments 
research supported part university patras 

dhillon sra generalized nonnegative matrix approximations bregman divergences proceedings nips vancouver pp :10.1.1.140.3037

chu plemmons optimality computation interpretation nonnegative matrix factorization unpublished preprint october 
ding li peng park orthogonal nonnegative matrix clustering proceedings th acm sigkdd international conference knowledge discovery data mining acm press new york pp 

donoho non negative matrix factorization give correct decomposition parts adv 
neural inf 
process 
syst 

eld matrix methods data mining pattern recognition siam philadelphia pa usa 
hoyer non negative sparse coding proceedings ieee workshop neural networks signal processing martigny switzerland pp 

hoyer non negative matrix factorization sparseness constraints mach 
learn 
res 

lee seung learning parts objects non negative matrix factorization nature 
kim sra dhillon fast newton type methods squares nonnegative matrix approximation problem proceedings siam conference data mining siam philadelphia pp 

matrix factorization methods application thermal ndt ndt int 

positive matrix factorization non negative factor model optimal utilization error estimates data values 
park kim sided non negative matrix factorization nonnegative centroid dimension reduction text classification berry castellanos eds proceedings text mining workshop held th siam international conference data mining sdm siam philadelphia 
berry plemmons text mining nonnegative matrix factorizations th siam conference data mining orlando fl siam philadelphia april pp 

du brown mao parra nonnegative matrix factorization rapid recovery constituent spectra magnetic resonance chemical shift imaging brain ieee trans 
med 
imaging 
berry plemmons document clustering nonnegative matrix factorization inf 
process 
manage 

xu liu gong document clustering non negative matrix factorization proceedings th acm sigir acm press new york pp 

zhang chen 
zhou dimensional non negative matrix factorization face representation recognition proceedings iccv workshop analysis modeling faces gestures lecture notes computer science vol 
springer berlin pp 

cichocki matlab toolbox nonnegative matrix factorization 
url www bsp brain riken jp html versatile tool nonnegative matrix factorization biology bmc bioinformatics 
berman plemmons nonnegative matrices mathematical sciences siam philadelphia 
berry browne langville plemmons algorithms applications approximate nonnegative matrix factorization comput 
stat 
data anal 

gregory semiring rank boolean rank nonnegative rank factorization combin 
inf 
system sci 

bertsekas nonlinear programming athena scientific belmont ma 
roweis ghahramani convergence bound optimization algorithms proceedings th conference uncertainty artificial intelligence uai morgan kaufmann los altos ca pp 

lee seung algorithms non negative matrix factorizations adv 
neural inf 
process 
syst 

liu yi existing new algorithms nonnegative matrix factorization technical report university texas austin 
elad bruckstein svd non negative variant dictionary design laine unser eds proceedings spie conference wavelets xi vol 
pp 
plemmons unmixing spectral data sparse low rank non negative matrix factorization proceedings amos technical conference maui 
liu zheng learning sparse features classification mixture models pattern recognition lett 

wild seeding non negative matrix factorizations spherical means clustering master thesis university colorado department applied mathematics 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi article press wild curry dougherty improving non negative matrix factorizations structured pattern recognition 
dhillon modha concept decompositions large sparse text data clustering mach 
learn 

gallopoulos flexible approximation scheme clustered term document matrices kargupta 
eds proceedings th siam international conference data mining siam philadelphia pp 

han neumann plemmons reduced rank nonnegative matrix factorization symmetric nonnegative matrices linear algebra appl 

stewart sun matrix perturbation theory academic press boston 
cohen nonnegative ranks decompositions factorizations nonnegative matrices linear algebra appl 

ding simon equivalence nonnegative matrix factorization spectral clustering proceedings th siam international conference data mining philadelphia pp 

piper plemmons nonnegative matrix factorization spectral data analysis linear algebra appl 

gallopoulos pattern recognition reichel implicitly restarted block lanczos method large scale hermitian eigenproblems siam sci 
comput 

berry large scale singular value decomposition int 

appl 

golub loan matrix computations third ed johns hopkins university press baltimore 
larsen software package symmetric eigenvalue problem singular value problems lanczos lanczos partial reorthogonalization 
url soi stanford edu mathworks matlab file exchange www mathworks com accessed 
tmg matlab toolbox generating term document matrices text collections gr projects tmg accessed 
cbcl face database cbcl mit edu cbcl software datasets html accessed 
university bath iris image database www bath ac uk elec eng research htm accessed 
heinrich automated gene classification nonnegative matrix factorization biomedical literature ph thesis university tennessee knoxville may 
author christos born greece august 
received bachelor degree computer science engineering university patras july 
september graduate ph student computer science department rensselaer polytechnic institute 
author gallopoulos professor university patras 
held positions uiuc ucsb 
ph 
computer science university illinois urbana champaign sc 
st class imperial college 
research scientific computing problem solving environments parallel computing 
please cite article gallopoulos svd initialization head start nonnegative matrix factorization pattern recognition doi 
