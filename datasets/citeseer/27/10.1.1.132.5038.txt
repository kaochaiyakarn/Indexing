appears ieee transactions parallel distributed systems volume august 
scalability fft parallel computers gupta vipin kumar department computer science university minnesota minneapolis mn cs umn edu kumar cs umn edu tr october revised october scalability analysis parallel fast fourier transform algorithm hypercube connected multicomputers isoefficiency metric 
isoefficiency function algorithm architecture combination defined rate problem size grow thenumber processors maintain fixed efficiency 
hypercube architecture commonly parallel fft algorithm obtain linearly increasing speedup respect number moderate increase problem size 
limit achievable efficiency limit determined ratio cpu speed communication bandwidth hypercube channels efficiencies higher threshold value obtained problem size increased rapidly 
hardware supports cut routing threshold overcome alternate parallel formulation 
scalability analysis mesh connected multicomputers reveals fft efficient large scale mesh architectures bandwidth increased function number processors 
show cost effective implement fft algorithm hypercube mesh despite fact large scale meshes construct large hypercubes 
scope limited cooley tukey fft algorithm classes architectures methodology study performance fft algorithms variety architectures simd hypercube mesh architectures shared memory architecture 
supported ist army research office ma sdi university minnesota university minnesota army high performance computing research center contract daal 
fast fourier transform plays important role scientific technical applications 
fft algorithm include time series wave analysis solving linear partial differential equations convolution digital signal processing image filtering implementing fft parallel computers 
analyze scalability parallel fft algorithm mesh hypercube connected multicomputers 
performance results processor ncube multicomputer support analytical results scalability parallel algorithm parallel architecture measure capability effectively utilize increasing number processors 
important perform scalability analysis misleading regarding performance large parallel system attempts simply extrapolate performance similar smaller system 
different measures study scalability parallel algorithms architectures 
analyze scalability fft algorithm important architectures metric developed kumar rao 
isoefficiency function combination parallel algorithm parallel architecture relates problem size number processors increase speedup proportion number processors 
isoefficiency analysis useful characterizing scalability variety parallel algorithms 
important feature isoefficiency analysis succinctly captures effects characteristics parallel algorithm parallel architecture implemented ina single expression 
performing isoefficiency analysis test performance parallel program processors predict performance larger number processors scalability analysis fft hypercube provides important insights 
hypercube architecture commonly parallel formulation fft algorithm shall refer exchange algorithm rest obtain linearly increasing speedup respect number processors moderate increase problem size surprising light fact fft computation maps naturally hypercube architecture 
limit achievable efficiency determined ratio speed communication bandwidth hypercube channels 
limit raised increasing bandwidth communication channels 
hypercubes store forward routing limit obtained problem size increased rapidly 
hardware supports cut routing threshold overcome alternate parallel formulation involves array transposition shall refer transpose algorithm rest 
transpose algorithm scalable binary exchange algorithm efficiencies threshold scalable efficiencies threshold 
scalability analysis fft algorithm efficient large architectures communication bandwidth increased function number processors 
width inter processor links maintained number processors scalability improved considerably 
addition features cut routing known worm hole routing mesh architecture improve scalability see features improve scalability characteristics fft algorithm architecture 
show cost communication network proportional tothe total number communication links cost effective implement fft algorithm ncube trademark ncube 
hypercube mesh despite fact large scale meshes cheaper construct 
single dimensional unordered radix fft algorithm binary exchange analysis obtaining experimental results 
simplest form fft efficient similar analysis performed variants algorithm 
shown nature results change ordered higher radix ffts 
organization material follows 
section introduces terminology inthe rest 
gives overview data communication models concept isoefficiency metric studying scalability parallel algorithm architecture combinations section briefly describes single dimensional unordered radix fft algorithm discusses commonly parallel formulations mimd machines 
section isoefficiency binary exchange algorithm various architectures derived 
section analyzes scalability performance transpose algorithm compares binary exchange algorithm section discuss impact improving arithmetic complexity serial algorithm parallel implementation 
section compare cost effectiveness hypercube fft computation 
section contains results implementation unordered dimensional radix fft node hypercube ncube 
performance algorithm connected machine similar hardware constants projected results 
section relate researchers performance evaluation fft various architectures 
section contains concluding remarks 
definitions assumptions parallel computer consists ensemble processing units runs speed 
inthe execution parallel algorithm time spent processor split tie time spent ti time spent performing communication load balancing idling tasks performed optimal best known sequential algorithm necessitated due parallel processing 
problem size defined total amount computation done best known sequential algorithm function input data size clearly tie computing fft input data elements problem size log 
define tio 
execution time processors tp satisfies tp tie tio 
ptp speedup ratio tp efficiency speedup divided sp ww isoefficiency function parallel algorithm solve problem instance fixed size fixed increases 
reason increases parallel algorithms fixed problem size increased efficiency higher approaches parallel algorithms efficiency maintained desired value increasing provided increased 
call algorithms scalable parallel algorithms note parallel algorithm different parallel architectures may increase different rates order maintain fixed efficiency 
rate required grow keep efficiency fixed essentially determines degree scalability parallel specific architecture 
example required grow exponentially combination poorly scalable 
reason case difficult speedups architecture large number processors problem size solved enormously large 
hand needs grow linearly algorithm highly scalable easily deliver linearly increasing performance increasing number processors reasonable problem sizes 
needs grow fe maintain efficiency thenf defined isoefficiency function efficiency tow order maintain constant efficiency proportional 
equation satisfied constant depending efficiency maintained 
known isoefficiency function determined equation simple algebraic manipulations 
parallel architectures associated data communication costs consider possible communication models message passing parallel computers 
model cap tures cost communication multicomputers store forward routing generation multicomputers ncube intel ipsc 
second model captures cost multicomputers cut routing known worm hole routing second generation multicomputers ncube intel ipsc 
machine store forward routing intermediate processor data path source destination message receives stores full message forwards processor path 
time required forthe complete transfer message containing words processors connections away processors ts th ts startup time th hop time time delay message fragment hop processor neighboring tw word transmission time equal yb bandwidth communication processors bytes second number bytes word message 
machine cut routing time required transfer message size words processors hops away data bytes sent pipelined fashion processors 
processor data path sender recipient message wait complete message arrive forwarding processor path 
bytes forwarded received 
note message passed directly connected processors time taken routing methods 
usually practical instances shall ignore th rest 
assume processor send receive ports time ports sends receives different 
fft algorithm outlines serial cooley tukey algorithm point single dimensional unordered radix 
input vector length integer fourier transform 
denotes complex number ssn 
generally primitive nth 






br binary representation 
br bl bl br bl bl br 



cooley tukey algorithm single dimensional unordered fft 
root unity thought element finite commutative ring integers 
note lth iteration loop starting line elements vector indices differ 
pattern combination elements identical butterfly network computation line independent different values processors compute values line processor computes np values 
simplicity assume power precisely integer obtain performance parallel machine important distribute elements vectors ands processors way keeps interprocess communication minimum 
discussed section main contributors data communication cost message startup time word transfer time subsections parallel formulations tukey algorithm 
analysis sections show formulations minimizes cost due constants 
binary exchange algorithm commonly mapping minimizes communication binary exchange algorithm br binary representation ands mapped processor number bd mapping processors need communicate iterations main loop starting line algorithm 
remaining iterations loop elements available processor 
lth iteration np values processor available single processor number differs lth significant bit 
transpose algorithm vector arranged pn pn dimensional array row major order 
transform performing unordered radix fft rows array followed unordered radix fft columns 
row fft corresponds iterations fft entire vector column fft corresponds remaining logn iterations 
parallel implementation pn pn mapped processors pn processor stores pnp rows array 
fft rows performed processor communication 
step array transposed fft rows transpose computed 
step requires inter processor communication transposing pn array processors 
algorithm described dimensional transpose algorithm data arranged ina dimensional array mapped dimensional array processors 
general dimensional transpose algorithm formulated lines mapping dimensional array data dimensional array processors 
binary exchange algorithm log dimensional algorithm 
confine discussion extremes transpose binary exchange sequence algorithms 
detailed discussion 
scalability analysis binary exchange algorithm single di radix unordered fft assume cost unit computation cost executing line tc 
point fft cn log discussed section parallel formulation fft atmost processors 
increased additional processors exceeds order prevent efficiency diminish increasing grow remains idle 
increases linearly cn log grow proportion tot log gives lower bound isoefficiency function fft algorithm 
independent parallel architecture function inherent parallelism algorithm 
isoefficiency function algorithm worse depending overhead factors may contribute parallel implementation fft 
significant due data communication processors 
discussed section processors communicate pairs log log iterations loop starting line 
distance communicating processors lth iteration 
distances pairs communicating processors maximum distance pair 
inthis subsection assume part various data paths coincides 
processor words total communication cost ignoring multicomputer store forward routing equation ts tw np zl source overhead parallel fft computation powers 
known factors 
sequential algorithm line executed log times 
powers 
values precomputed cost stored half values calculated half conjugates values derived array starting loop line 
shown appendix processors factor log iterations 
fft size computed repeatedly twiddle factors processor precomputed stored 
case thenthe twiddle factor computation part fft implementation shown appendix overhead log incurred due extra computations 
isoefficiency hypercube discussed section lth iteration loop line data words exchanged processors binary representations different significant bit position log 
pairs processors addresses bit position directly connected hypercube configuration equation log ts tw np ts log log increases order maintain efficiency value equal 
log grow log ts log log clearly isoefficiency function due term ts log requirement growth maintain fixed efficiency due second term 
term requires grow rate log ignored favor ofthe term 
hand term requires grow rate higher log ignored balancing second term yields ntc log log log log pk leads isoefficiency function due second term tw pk log growth log long 
soon product exceeds function equation 
binary exchange algorithm involves nearest neighbor communication hypercube total overhead scalability cut routing 
changing sign imaginary part 
efficiency threshold isoefficiency function equation deteriorates rapidly increase value ofk wt fact efficiency corresponding wt ct tw acts somewhat threshold value 
fora hypercube fixed tw efficiencies values obtained easily 
higher threshold obtained problem size extremely large 
examples illustrate effect value isoefficiency function 
example consider computation point fft processor hypercube tw tc 
function parallel fft machine pk log isoefficiency log isoefficiency function 
isoefficiency function log 
example consider computation point fft processor hypercube tw threshold efficiency 
isoefficiency function log fore log 
examples show ratio tw tc effects scalability hard obtain threshold determined ratio 
isoefficiency mesh assume point fft computed processor simple mesh rows pp columns suchthat power 
example consider processor form row processors form column 
execution algorithm processor need communicate processors 
communicating processors lie row column 
precisely log pp log steps require data communication communicating processors row remaining log steps column 
distance communicating processors row grows hop pp hops doubling log steps 
communication pattern similar case columns 
reader verify true communicating processors mesh 
equation get log pp ts tw np ts log pp tw np pp ss ts log balancing term yields equation isoefficiency function ts log balancing second term yields log tw pp logn pp growth required third term higher required small term determines isoefficiency function equation wp pp equation obvious problem size grow exponentially number maintain constant efficiency algorithm scalable simple mesh 
different mapping input vector processors reduce communication overhead 
shown mapping iteration pairs processors need communicate pp hops apart 
expression improved factor 
mesh augmented cut routing communication term expected smaller mesh due overheads resulting contention communication channels exactly equation 
shown appendix function remains unchanged addition feature offer performance improvement fft algorithm mesh 
scalability analysis transpose algorithm single dimen sional radix unordered fft discussed earlier section data communication involved algorithm transposition ofan pn pn dimensional array processors 
easily seen involves communication chunk unique data size np pair processors 
communication known communication performed executing code processor data processor number self address phi shown hypercube iteration code pair contention free communication path 
hypercube store forward routing communication take tw np log ts time 
communication term yields overhead function whichis identical overhead function binary exchange algorithm scheme offer improvement binary exchange scheme 
hypercube cut routing done time np ts leading overhead function equation ts term independent increases problem size increase second communication term 
efficiency yields isoefficiency function ts transpose algorithm mapping data processors requires pn increase processors eventually 
requirement imposes isoefficiency function log due limited concurrency transpose algorithm 
isoefficiency function due concurrency exceeds isoefficiency function due communication log isoefficiency function transpose algorithm hypercube shown mesh architecture cut routing transpose algorithm improve communication cost binary exchange algorithm mentioned section confined discussion transpose algorithm dimensional case 
generalized transpose algorithm related performance scalability 
comparison binary exchange discussed earlier isoefficiency function log realized exchange algorithm efficiency operation wt 
desired efficiency suchthat wt isoefficiency functions binary exchange transpose log 
wt transpose algorithm scalable binary exchange algorithm choice provided 
transpose algorithm described section data size arranged pn pn twodimensional array mapped linear array processors positive integer pn 
generalization method vector arranged dimensional array mapped dimensional logical array processors transpose algorithm discussed special case generalization binary exchange algorithm special case log 
comparison equations shows binary exchange algorithm minimizes communication overhead due transpose algorithm minimizes overhead due binary exchange algorithm processors concurrency transpose algorithm limited pn processors 
selecting values log possible derive communication overheads due tw intermediate values algorithms described 
certain circumstances algorithms best choice terms concurrency communication overheads 
impact variations cooley tukey algorithm scalability schemes computing dft suggested literature involve operations serial computer simple cooley tukey fft algorithm 
notable computing single dimensional ffts radix greater computing multi dimensional transforming set dimensional ffts polynomial transform method 
radix fft computed splitting input sequence size sequences size nq computing ffts combining result 
example radix fft step involves computing outputs input values total number iterations log log length course power 
shown despite reduction number iterations aggregate communication time radix fft remains radix 
example radix algorithm hypercube communication step involves processors distributed dimensions processors dimension 
hand number radix fft radix fft 
number marginally improved going higher 
total useful reduced constant factor ffts logical linear array processors physically connected hypercube network 
higher radix amount communication remains 
remain thesame order magnitude various isoefficiency functions radix fft similar radix fft somewhat higher constants described polynomial transforms reduce number arithmetic operations multidimensional ffts 
particular number multiplications reduced twodimensional fft method 
communication overheads algorithm higher asymptotic isoefficiency function better cooley tukey algorithm instructive see gain due reduction number arithmetic operations carried parallel implementation 
suppose parallel algorithm working efficiency total execution time spent performing useful time spent communication overheads 
improvement computational complexity parent serial algorithm result reduction parallel execution tp tp improvement tp tp 
improvement serial time complexity algorithm factor parallel implementation original parallel algorithm running efficiency example radix algorithm reduces number arithmetic operations radix algorithm serial machine lead increase effective throughput fft computation algorithm mega flops machine deliver performance equivalent mega flops machine running algorithm 
hand similar improvement result throughput increase parallel machine aggregate computing power efficiency 
discussed section binary exchange algorithm hard achieve efficiencies threshold ct tw hypercube 
threshold improvements obtained improving parent serial algorithm 
threshold better concentrate reducing communication computation cost performance 
cost effectiveness mesh hypercube fft computation scalability certain algorithm architecture combination determines capability processors effectively 
algorithms may scalable architectures 
situations needs consider better larger parallel computer cost wise architecture underutilized poor efficiency smaller parallel computer cost wise scalable architecture better utilized 
amount resources aim isto maximize performance proportional number processors efficiency obtained 
scalability analysis section predicted fft perform poorly mesh compared hypercube 
hand constructing mesh multicomputer cheaper constructing hypercube number processors 
show spite cost effective implement fft hypercube mesh suppose cost building communication network parallel computer directly proportional number communication links 
neglect effect length links th efficiency point fft computation binary exchange scheme tw log ptc logn processor hypercube logn 
assumed tc computers 
possible obtain similar performance computers channel mesh wide effectively word communication time choosing pp log cost constructing mesh networks log wp respectively greater log easier see pp log cheaper obtain fft computation hypercube mesh 
comparison transpose algorithm hypercube turn cost effective factor mesh channels increased match performance hypercube relative costs building mesh hypercube identical performance forthe fft computation pp log respectively 
cost network considered function bisection width network case vlsi implementations picture improves mesh 
bisection widths hypercube mesh containing processors pp respectively 
order match mesh hypercube binary exchange algorithm channels wider factor case bisection width mesh network log costs hypercube mesh networks processors yield fft functions respectively 
clearly cheaper build hypercube 
transpose algorithm relative costs mesh hypercube yielding throughput respectively 
hypercube cost effective constant factor 
analysis shows performance fft algorithm mesh improved con increasing bandwidth communication channels factor pp fully utilized pp data items transferred 
input data size ppp leads isoefficiency term log due concurrency significant improvement mesh channels constant bandwidth 
fact log best possible isoefficiency fft mesh channel increased arbitrarily number processors 
shown channel bandwidth grows px isoefficiency function due communication isoefficiency function due concurrency log 
isoefficiency communication overheads exponential 
isoefficiency determined 
best isoefficiency function log obtained 
experimental results implemented binary exchange algorithm unordered single dimensional radix fft hypercube 
experiments conducted range problem sizes range machine sizes number processors 
length input vector varied numberof processors varied 
required twiddle factors precomputed stored processor 
speedups efficiencies computed run time sequential fft running processor ncube 
unit fft computation takes approximately microseconds tc ss actual fft program written unit computation took approximately microseconds 
fft computation requires bit additions subtractions bit multiplications corresponds mega flop rating far lower obtained fft benchmarks written fortran assembly language 
due inefficient compiler 
cpu speed tremendous impact scalability fft artificially increased realistic rating mega flop 
obtained replacing actual complex arithmetic inner loop fft computation dummy loop takes microseconds execute 
linear speedup curves hypercube various problem sizes 
microseconds 
figures summarize results experiments shows speedup curves different problem sizes 
expected small problem size input vector length speedup reaches saturation point small number processors 
point increase number processors result additional speedup 
hand speedup curve nearly linear larger problem size length input vector time transfer word bytes determined microseconds timings experiments 
experimentally obtained values tc value wt exceed isoefficiency curves non linear 
selected sets data points experiment correspond approximately efficiencies plot isoefficiency curves 
order easier see relationship problem size number processor plot log axis log axis 
plot showing isoefficiency log conforms analysis third curve corresponding shows poor isoefficiency 
agreement greater break efficiency 
run times hypercube corresponding results mesh connected computer processor speed identical communication costs link projected 
shows isoefficiency curves hypercube mesh connected computers efficiency 
problem size grow rapidly mesh hypercube maintain efficiency table illustrates effect wt ratio scalability fft algorithm hypercubes 
table show slope log log curve maintaining different efficiencies different machines ratios respectively 
table predict maximum practically achievable efficiencies machines fft computation 
machine easily obtain efficiencies entry table small 
example entry machine corresponding efficiency 
obtain efficiency log log isoefficiency curves different values hypercube 
log log hypercube mesh isoefficiency curves mesh hypercube 
table scalability fft algorithm different hypercubes various efficiencies 
ratio log log input size 
processors table efficiencies function input size number processors hypercube type 
processors ss fft problem ss large 
machine entry table large obtain efficiencies small number processors 
example order maintain efficiency grow asymptotically 
words problem input data elements required get efficiency processors machine ratio equal 
discussed section grow log grow asymptotically proportion log due concurrency factors ts table shows efficiencies obtainable hypercube type function number size input 
table gives idea large problem size obtain reasonable efficiencies hypercubes various sizes type 
clearly unreasonably large problem sizes efficiencies obtained small large hypercubes having type reader note wt ratios roughly correspond available machines ncube ncube intel ipsc ipsc rx respectively 
communication channel bandwidths roughly megabytes second individual processor speeds roughly mega flops respectively fft computation 
related research due important role fourier transform plays scientific technical computations great interest implementing fft parallel computers studying performance 
briefly review authors studied scalability fft performance prediction 
jamieson describe implementation parallel fft parallel processing hypercube interconnect 
implement single dimensional unordered fft processor machines data elements processor 
measurements implementations parameters determine communication computation times 
parameters predict performance fft algorithm elements processor larger hypercubes 
time minimal analysis hypercube applicable equating ts zero 
analysis provide general performance predictions valid forany problem size number processors 
norton give comprehensive performance analysis pseudo shared memory architectures ibm rp 
consider various mappings data memory blocks case obtain expressions communication overhead speedup problem size number processors memory latency cpu speed speed communication 
methodology expressions compute scalability fft memory systems various mappings data 
chandra snir aggarwal analyze performance fft algorithms parallel computation 
model differs standard pram model remote accesses expensive local accesses 
threshold effect efficiency described shown occur pseudo shared memory systems rp doing scalability analysis lines section parallel fft algorithms implementation experimental evaluation various architectures pursued authors 
cases analysis scalability predict performance larger number processors different problem sizes 
concluding remarks shown hypercube architecture linear isoefficiency function achieved forthe fft computation efficiencies threshold determined ratio computation communication speeds desired efficiency 
threshold isoefficiency function ofthe binary exchange algorithm quite bad 
extreme sensitivity isoefficiency function hardware related constants unique algorithm 
parallel algorithms depth hardware dependent constants cpu speed communication bandwidth appear multiplicative factors isoefficiency function 
cpu speed goes factor changes communication speed goes factor changes parallel algorithms obtain similar speedups times larger problems 
seen processor speeds ncube intel ipsc ipsc rx quoted respective manufacturers fft benchmarks 
example table parallel fft factor change ratio computation speed speed causes scalability change quite drastically 
similarly improvement serial algorithm reduces amount computation result smaller improvement time parallel implementation algorithm 
effects pronounced large number processors hypercube supports cut routing possible overcome thresholding effect transpose algorithm 
scalability transpose algorithm stays higher efficiencies case binary exchange algorithm 
choice algorithms depends communication related parameters ts tw machine sizeof problem solved number processors available 
isoefficiency function parallel fft mesh architecture exponential efficiency large scale mesh connected multicomputers poor unreasonably large problem instances 
claimed adding worm hole routing feature multicomputers powerful fully connected multicomputers 
case message start time sharing data paths messages traveling simultaneously significant 
fft computation meshes offer improvement scalability 
scalability mesh improved considerably width inter processor links increased function number processors optimal isoefficiency function mesh log bandwidth communication channels increased 
reader verify function fft mesh architecture exponential derived analysis similar mesh analysis similar section performed obtain isoefficiency functions fft algorithm types architectures 
example isoefficiency analysis mimd hypercube section directly applicable simd hypercube mesh message startup time ignored 
similarly ts th considered zero tw considered latency due non local memory access hypercube applicable shared memory architecture hypercube communication occurs directly connected processors different parallel architectures mesh hypercube omega network shared memory architectures different scalability viewpoint cost 
analysis section shows computation hypercube cost effective mesh cost communication network total number communication channels taken account 
similar canbe drawn mesh 
authors wish john gustafson david bailey rao making numberof useful suggestions earlier draft 
authors sandia national labs providing access processor ncube 
aggarwal ashok chandra mark snir 
communication complexity prams 
technical report rc ibm watson research center yorktown heights ny yorktown heights ny 
aho john hopcroft ullman 
design analysis computer algorithms 
addison wesley reading ma 
akl 
design analysis parallel algorithms 
prentice hall englewood cliffs nj 
gabber 
parallel fft mimd machine 
parallel computing 
david bailey 
ffts external hierarchical memory 
journal supercomputing 
holland 
giant fourier transform 
proceedings fourth conference hypercubes concurrent computers applications volume pages 
edward thomas jamieson 
experimental application driven architecture analysis mimd parallel processing system 
ieee transactions parallel distributed systems 

performance analysis fft algorithm shared memory parallel architecture 
ibm journal development 
william dally 
vlsi architecture concurrent data structures 
kluwer academic publishers boston ma 
william dally 
wire vlsi multiprocessor communication network 
stanford conference advanced vlsi networks pages 
laurent denis 
implementing discrete fourier transform hypercube vector parallel computer 
inproceedings fourth conference hypercubes concurrent computers applications volume pages 
eager zahorjan lazowska 
speedup versus efficiency parallel systems 
ieee transactions computers 
gupta vipin kumar 
isoefficiency measuring scalability parallel algorithms architectures ieee parallel distributed technology august 
available technical report tr department computer science university minnesota minneapolis mn 
gupta vipin kumar 
scalability fft parallel computers 
proceedings third symposium onthe frontiers massively parallel computation 
available technical report tr department computer science university minnesota minneapolis mn 
gupta vipin kumar 
scalability matrix multiplication algorithms parallel computers 
technical department computer science university minnesota minneapolis mn 
short version appears proceedings international conference parallel processing pages iii iii 
gupta vipin kumar sameh 
performance scalability preconditioned conjugate gradient methods computers 
technical report tr department computer science university minnesota minneapolis mn 
short version appears proceedings sixth siam conference parallel processing scientific computing pages 
john gustafson 
reevaluating amdahl law 
communications acm 
john gustafson gary robert benner 
development parallel methods processor hypercube siam journal scientific statistical computing 
kai hwang 
advanced computer architecture parallelism scalability programmability 
mcgraw hill new york ny 
johnsson 
ho 
optimum broadcasting personalized communication hypercubes 
ieee transactions september 
johnsson mcdonald 
radix fft connection machine 
technical report cambridge ma 
ray kamin george adams 
fast fourier transform algorithm design tradeoffs 
technical report riacs tr nasa ames research center field ca 
alan karp flatt 
measuring parallel processor performance 
communications acm 
kimura 
probabilistic analysis efficiency dynamic load distribution 
memory computing conference proceedings 
vipin kumar gupta george karypis 
parallel computing design analysis 
benjamin cummings redwood city ca 
vipin kumar gupta 
analyzing scalability parallel algorithms architectures 
technical report tr department computer science department university minnesota minneapolis mn 
appear journal parallel distributed computing 
shorter version appears proceedings international conference pages 
vipin kumar rao 
parallel depth search part ii analysis 
international journal parallel programming 
vipin kumar rao 
load balancing hypercube architecture 
proceedings fourth conference concurrent computers applications pages 
vipin kumar rao 
scalable parallel formulations depth search 
vipin kumar gopalakrishnan kanal editors parallel algorithms machine intelligence vision 
springer verlag new york ny 
vipin kumar vineet singh 
scalability parallel algorithms pairs shortest path problem 
journal distributed computing october 
short version appears proceedings international conference parallel processing 
charles van loan 
computational frameworks fast fourier transform 
siam philadelphia pa 
norton 
parallelization performance analysis cooley tukey fft algorithm shared 
ieee transactions computers 
daniel anant agarwal 
scalability parallel machines 
communications acm 

fast fourier transform convolution algorithms 
springer verlag new york ny 
pease 
indirect binary cube microprocessor array 
ieee transactions computers 
michael quinn 
designing efficient algorithms parallel computers 
mcgraw hill new york ny 
brenner 
new principle fast fourier transform 
ieee transactions acoustics speech 
ranka sahni 
hypercube algorithms image processing pattern recognition 
springer verlag new york ny 
rao 
personal communication 
university central florida orlando fl 
vineet singh vipin kumar gul agha chris tomlinson 
scalability parallel sorting mesh multicomputers 
parallel programming 

multiprocessor ffts 
parallel computing 
tang guo jie li 
optimal granularity grid iteration problems 
proceedingsof international conferenceon parallel processing pages 
clark thompson 
fourier transforms vlsi 
ibm journal research development 
van catledge 
general model evaluating relative performance computer systems 
supercomputer applications 
winograd 
new method computing dft 
ieee international conferenceon acoustics speech signal processing pages 
woo sahni 
hypercube computing 
journal supercomputing 
tr department computer science university minnesota minneapolis mn 
woo sahni 
computing biconnected components hypercube 
journal supercomputing june available technical report tr department computer science university minnesota minneapolis mn 
patrick 
effect time constraints scaled speedup 
siam journal scientific statistical computing 

measuring scalability parallel computer systems 
supercomputing proceedings pages 

table binary representation various powers calculated different iterations point fft refers iteration number 
appendix refer fft algorithm 
lth iteration loop starting line algorithm computed integer obtained reversing order significant bits padded zeros right 
example binary representation powers required values shown table 
instance row evident powers required 
processor column table 
maximum number powers processor say calculates log equal 
processor columns table compute powers values 
maximum number powers computed processor point fft processors 
assume powers 
seen table defined recurrence log np solution recurrence np log total computation twiddle factors processors log cost twiddle factor 
powers computed sequential algorithm overhead log log incurred due extra computations processors 
overhead independent architecture processor interconnection network mimd machine computation 
isoefficiency due extra computations sequential algorithm line executed log times 
powers 
known twiddle factors 
values precomputed cost array starting loop line 
consider extreme case element processor processor value line 
processors execute step log times shown processors new power log iterations 
ways deal half values calculated half conjugates values derived changing sign imaginary part 
iteration iteration iteration total cost table maximum number new powers processor iteration point fft 
twiddle factors 
fft size computed repeatedly twiddle factors stored cost log memory overhead processor need store log twiddle factors 
involve computational overhead parallel implementation fft serial algorithm 
feasible twiddle factors 
example values processor needs different set twiddle factors 
published parallel fft implementations compute twiddle factors fly 
twiddle factor computation apart fft implementation overhead log incurred due extra computations total useful done point fft cn log overhead point fft processor machine due extra computations cost log cost factor 
order determine isoefficiency function need balance useful overhead satisfy equation 
problem size log cn log log satisfied 
log grows faster balancing second term overhead yields isoefficiency function log appendix scalability metrics apart isoefficiency function metrics proposed study scalability architecture combinations 
brief scalability analysis unordered radix fft metrics gustafson benner experimentally demonstrate scaling problem size obtain near linear speedup processors 
gustafson new metric called scaled speedup evaluate performance practically feasible architectures 
metric defined speedup curve obtained problem size increased linearly numberof processors 
scaled speedup curve close linear algorithm architecture combination considered scalable 
scaled speedup fft problem size grows cn log approximately tc ptc tw hypercube tc ptc mesh double 
clear algorithm attains near linear speedup hypercube speedup mesh worse karp flatt introduced experimentally determined serial fraction new metric measuring performance parallel system fix sized problem 
speedup processor system defined smaller values considered better 
increases number considered indicator rising communication overhead indicator poor scalability 
values karp flatt serial fraction tw log ptc logn logn hypercube respectively 
clearly serial fraction lower hypercube mesh 
introduce concept overhead function 
processor system scales run time tp processors satisfies tp ws 
smallest overhead function satisfies equation called systems overhead function defined tpc ws wp 
values overhead function architectures tw log ptc logn hypercube logn mesh respectively 
definition certain rate growth problem size overhead function remains constant parallel algorithm architecture scalable 
verified overhead functions constant values lead relations isoefficiency function agarwal defined scalability architecture algorithm ratio algorithm asymptotic speedup run architecture question corresponding run erew pram 
assuming speedup obtained ideal processors scalability fft algorithm agarwal definition ct tw hypercube mesh respectively 
metric suggests better scalability fft hypercube mesh 
ts th ignored 
appendix scalability analysis ffts previous section detailed scalability analysis simple unordered single fft algorithm 
section briefly describe analysis previous section adapted study scalability various variants algorithm described section 
form functions architectures studied mesh hypercube change algorithms 
isoefficiency functions ordered fft algorithm described called unordered fft elements result vector bit reversed indices 
shown ordered transform obtained communication steps log clearly unordered transform preferred applicable 
vector ordered transform part bigger computation remains invisible user 
unordered fft computation requires ordered fft roughly double unordered fft 
scalability characteristics fft similar unordered fft threshold till isoefficiency function remains log lower 
instance replacing tw tw equation yields log ordered fft hypercube 
referring example isoefficiency function ordered fft log 
isoefficiency function log worse ordered case 
isoefficiency functions multidimensional fft way computing dimensional fft dimensional data successively compute fft dimensions input data array 
example dimensional fft square grid data computed calculating fft rows input array fft columns resulting array 
isoefficiency functions multidimensional fft forms single dimen sional fft 
brief isoefficiency analysis dimensional fft 
analysis higher dimensional ffts similar 
dimensional fft hypercube assume processor hypercube 
possible map mesh hypercube row column mesh maps subcube size 
assume input array pn pn map pn pn input array pp processor mesh naturally 
processor ith row lth column elements rows columns input array phase algorithm processors row virtual mesh compute dimensional fft rows data residing processors 
hypercubes containing processors perform single dimensional fft computations pn data points 
pp groups pp processors compute dimensional fft columns data matrix 
phase pn fft computations pn data elements performed 
done phase pn cpn log pn log pn 
sum total time taken processors phases cn log fft computation 
startup hop times phase tw word communication time total number processors pnp number fft computations subcube pnp number elements processors computation processors computing pn point fft log number iterations requiring communication equal log similarly forthe second phase wn log pp 
log log pp whichis equal wn log expression corresponding expression fft 
reader fft computations ts th taken account isoefficiency function fft hypercube 
way perform fft computation multicomputer distribute data multiples columns processors perform computation rows columns transpose data perform computation columns rows 
computation phases require communication performed transposition step 
done pn 
maximum pn processors argument similar section canbe shown pn needs grow fast needs grow fast log order keep busy 
lower bound isoefficiency function implementation worse previous scalable virtue greater concurrency long 
shown results section change input array square 
dimensional fft mesh section isoefficiency analysis fft computation mesh simple 
pn pn array data elements mapped processor gets np elements assuming pn divisible pp 
communication cost phase ts log pp th tw np pand equal ts log th tw np shown previous sub section log expressions fft computations mesh isoefficiency function equation 
constants exponents improved complicated mappings data processors form isoefficiency function remains 
appendix isoefficiency mesh ct analyze scalability fft mesh cut routing study contention com munication channels source overhead 
quite possible data paths pairs communicating processors share common channel 
example consider linear array wants communicate third second fourth 
link second third processor part data paths 
multicomputer problem messages hop node way destination 
case step message sent processor go sent second processor go third 
second step messages shall reach respective destinations 
despite partially common data path communication channel messages passed common path different times 
multicomputer ct hardware situation lead contention communication channel ifthe message size large 
happen byte message sent processor reaches second processor finish sending bytes message third processor assuming small large messages time required transfer message size hops multicomputer ct hardware number messages common data channel 
reason effectively bytes transferred channel time communication cost fft multicomputer cut routing equation zl distance communicating processors lth iteration processor hasn words 
log pp ts th tw np ss ts log pp thpp tw np log yields equations isoefficiency function ts log th tw pk log mesh ct term due contention communication contributes overheads consider example section ant iteration loop starting line processors numbers differ nd bit right different communicate pairs 
link processors carry data communications row 
general processors communication cost log pp ts th tw np ss ts log pp thpp tw np pp distance communicating processors hops link carries messages 
expression case simple mesh isoefficiency function 
addition cut routing feature performance fft algorithm meshes 
mapping input vector processors different way help iteration data items cross vertical line cutting middle mesh 
pp channels crossing line communication iteration npp 
result isoefficiency function better 
appendix fft overlapped communication implementation fft described processor log computation data elements performs communication step required iteration involving data elements 
tw np greater machine beneficial message smaller chunks communication 
fraction elements communicated batch processed communication overlapped computation 
possible machines separate processors handle messagepassing ncube intel ipsc consider simplified case 
beneficial process communicate element time 
effective time communicate np data elements directly connected processors tw tc np th tw tc simply th tw tc 
case isoefficiency function hypercube due communication tw tc pk tw tc tc log case simply th log pipelining lead scalability 
long tc form isoefficiency function remains example isoefficiency function taken tw tc pk tw tc tc log log fore log shown isoefficiency function mesh pipelined implementation fft tw tc pp tw tc pp tw tc th tw tc 

