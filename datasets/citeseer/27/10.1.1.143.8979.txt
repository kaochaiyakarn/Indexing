parameter control evolutionary algorithms eiben michalewicz schoenauer smith free university amsterdam netherlands cs vu nl university adelaide australia cs adelaide edu au inria france marc lri fr uwe united kingdom james smith uwe ac uk summary 
issue setting values various parameters evolutionary algorithm crucial performance 
discuss issue values best set advance best changed evolution 
provide classification different approaches number complementary features pay special attention setting parameters fly 
potential adjusting algorithm problem solving problem 
intended survey set prescriptive details implementing ea particular type problem 
reason chosen interleave number examples text 
hope clarify points wish raise give reader feel possibilities available controlling different parameters 
finding appropriate setup evolutionary algorithm long standing grand challenge field :10.1.1.143.8979
main problem description specific ea contains components choice representation selection recombination mutation operators setting framework leaving quite items undefined 
instance simple ga stating binary representation uniform crossover bit flip mutation tournament selection generational replacement 
full specification details instance population size probability mutation pm crossover pc tournament size 
data called algorithm parameters strategy parameters complete definition ea necessary produce executable version 
values parameters greatly determine algorithm find optimal near optimal solution find solution efficiently 
choosing right parameter values hard task 
eiben michalewicz schoenauer smith globally distinguish major forms setting parameter values parameter tuning parameter control 
parameter tuning mean commonly practised approach amounts finding values parameters run algorithm running algorithm values remain fixed run 
section give arguments static set parameters having values fixed ea run inappropriate 
parameter control forms alternative amounts starting run initial parameter values changed run 
parameter tuning typical approach algorithm design 
tuning done experimenting different values selecting ones give best results test problems hand 
number possible parameters different values means time consuming activity 
considering parameters values test different setups 
performing independent runs setup implies runs just establish algorithm design 
technical drawbacks parameter tuning experimentation summarised follows parameters independent trying different combinations systematically practically impossible 
process parameter tuning time consuming parameters optimised regardless interactions 
problem selected parameter values necessarily optimal effort setting significant 
picture discouraging generally setup perform range problems problem instances 
history eas considerable effort spent finding parameter values type ea gas number test problems 
known early example determining recommended values probabilities single point crossover bit mutation called dejong test suite functions 
similar attempts noted genetic algorithms seen robust problem solvers exhibit approximately performance wide range problems page 
contemporary view eas acknowledges specific problems problem types require specific ea setups satisfactory performance 
scope optimal parameter settings necessarily narrow 
theoretical arguments quest generally ea generally parameter settings lost priori free lunch theorem 
elucidate drawback parameter tuning approach recall defined finding values parameters run algorithm running algorithm values remain fixed run 
run ea intrinsically dynamic parameter control evolutionary algorithms adaptive process 
rigid parameters change values contrast spirit 
additionally intuitively obvious empirically theoretically demonstrated different values parameters optimal different stages evolutionary process 
give example large mutation steps early generations helping exploration search space small mutation steps needed late generations help fine tune suboptimal chromosomes 
implies static parameters lead inferior algorithm performance 
straightforward way overcome limitations static parameters replacing parameter function generation counter measure elapsed time 
indicated earlier problem finding optimal static parameters particular problem hard 
designing optimal dynamic parameters functions may difficult 
possible drawback approach parameter value changes caused blind deterministic rule triggered progress time notion actual progress solving problem account current state search 
known instance problem occurs simulated annealing called cooling schedule set execution algorithm 
mechanisms modifying parameters run informed way realised quite early ec history 
instance evolution strategies changed mutation parameters fly rechenberg success rule information ratio successful mutations 
davis experimented gas changing crossover rate progress realised particular crossover operators 
common feature similar approaches presence human designed feedback mechanism utilises actual information search process determining new parameter values 
approach observation finding parameter values evolutionary algorithm poorly structured ill defined complex problem 
exactly kind problem eas considered perform better methods 
natural idea ea tuning ea particular problem 
done eas problem solving called meta ea tune 
done ea tunes problem solving problem 
introduced evolution strategies varying mutation parameters falls category 
section discuss various options changing parameters illustrated example 
eiben michalewicz schoenauer smith case study evolution strategies history evolution strategies es typical case study parameter tuning went successive steps pertaining different approaches listed far 
typical es real valued search space typically ir subset ir integer 
gaussian mutations main operator trademark es gaussian mutation adds centered normally distributed noise variables individuals 
general gaussian distribution ir multivariate normal distribution mean covariance matrix positive definite matrix probability distribution function exp determinant convenient write mutation vector ir distinguish scaling factor called step size directions gaussian distribution covariance matrix example simplest case gaussian mutation assumes identity matrix ir diagonal matrix diagonal 
case coordinates mutated independently added gaussian noise variance tuning es algorithm amounts tuning step size covariance matrix simply tuning step size simple case mentioned 
adapting step size step size gaussian mutation gives scale search 
things clear suppose minimizing dimension running es parent gives birth offspring best parent fixed step size 
average distance parent successful offspring 
consequences starting distance solution take average steps reach region close optimum 
hand hovering optimum precision hope proportional parameter control evolutionary algorithms 
arguments naturally lead optimal adaptive setting step size sphere function proportional distance optimum 
details studies called progress rate early done schwefel completed extended beyer auger gave formal global convergence proof impractical algorithm distance optimum known real situations 
piece information available algorithm success rate proportion successful mutations offspring better parent 
indirectly give information stepsize rechenberg main idea propose practical method adaptive step size called fifth rule success rate time window larger success rate step size optimal fifth step size increased algorithm making small steps hand success rate smaller step size decreased algorithm constantly missing target shoots far 
formally derived studies sphere function corridor function bounded linear function fifth rule generalized function 
fifth rule mislead 
way handle case non isotropic functions non diagonal covariance matrix mandatory 
longer today 
self adaptive es big step ess invention self adaptive mutation parameters mutation step size covariance matrix attached individual subject mutation 
personal mutation parameters range single step size leading isotropic mutation coordinates mutated independently variance non isotropic mutation vector standard deviations equivalent diagonal matrix diagonal correlated mutations full covariance matrix attached individual 
mutating individual amounts mutating mutation parameters mutating variables new mutation parameters 
details 
rationale sa es algorithm relies selection step keep population best fit individuals individuals best mutation parameters region search space 
selection acts fitness underlying idea beneath self adaptive es sa es individuals starts fitness offspring better mutation parameters reach regions higher fitness faster offspring selection keep ones mutation parameters 
eiben michalewicz schoenauer smith stated mutation parameters optimized free evolution 
sa es long state ofthe art parametric optimization 
mutation parameters 
issue discussed step size previous section similar arguments covariance matrix 
replace sphere model min xtx elliptic function min positive definite matrix 
clear mutation progress slower directions steepest descent covariance matrix proportional 
step size self adapts quasi optimal values covariance matrix learned correlated sa es actual inverse hessian 
cma es clever adaptation defect sa es relative slowness adaptation mutation parameters simple case step size initial value optimal proportional distance optimum case sphere function takes time reach optimal value start efficient 
observation led hansen propose deterministic schedules adapt mutation parameters es heading back adaptive method parameter tuning 
method limited step size addressed adaptation full covariance matrix 
complete covariance matrix adaptation cma es algorithm detailed parameters carefully tuned improvement update covariance matrix proposed 
basic idea cma es path followed algorithm deterministically update different mutation parameters simplified view suppose algorithm series steps colinear directions step size increased allow larger steps increase speed 
similar ideas undermine covariance matrix update 
clever learning method cma es proved outperform stochastic algorithms parametric optimization witnessed success contest took place cec 
lessons learned brief summary es history witnesses static parameters hard impossible tune doesn exist static value step size gaussian mutation adaptive methods information current state search information get success rate parameter control evolutionary algorithms raw information lead easy defeat fifth rule cma es uses high level information cleverly update parameters general gaussian mutation self adaptive methods efficient methods applicable available selection fitness prevent bad parameters proceeding generations 
outperform basic static adaptive methods outperformed clever adaptive methods 
case study changing penalty coefficients assume deal numerical optimisation problem minimise xn subject inequality equality constraints gi hj domains variables lower upper bounds li xi ui numerical optimisation problem may consider evolutionary algorithm floating point representation individual population represented vector floating point numbers xn previous section described different ways modify parameter controlling mutation 
components ea natural parameters parameters traditionally tuned way 
show components evaluation function consequently fitness function parameterised varied 
common option tuning mutation practised evolution variable length structures parsimony pressure may provide useful mechanism increasing performance evolutionary algorithm 
dealing constrained optimisation problems penalty functions 
common technique method static penalties requires fixed user supplied penalty parameters :10.1.1.23.8293
main reason widespread simplest technique implement requires straightforward modification evaluation function follows eval penalty objective function penalty zero violation occurs positive 
usually penalty function minimisation problems 
eiben michalewicz schoenauer smith distance solution feasible region effort repair solution force feasible region 
methods set functions fj construct penalty function fj measures violation jth constraint way fj max gj hj 
user defined weight prescribing severely constraint violations weighted 
traditional penalty approach weight change evolution process 
sketch possible methods changing value replace static parameter dynamic parameter function 
just mutation parameter develop heuristic modifies weight time 
example method proposed individuals evaluated iteration formula constants 
eval penalty penalty pressure grows evolution time provided 
second consider option utilises feedback search process 
example approach developed bean individual evaluated formula updated generation way allt allt 
formula set search points solutions set feasible solutions denotes best individual terms function eval generation avoid cycling 
words method decreases penalty component generation best individuals generations feasible increases penalties best individuals generations infeasible 
feasible infeasible individuals best individuals generations remains change 
third allow self adaptation weight parameter similarly mutation step sizes previous section 
example possible extend representation individuals xn parameter control evolutionary algorithms weight 
weight component undergoes changes variable xi gaussian mutation arithmetic recombination 
illustrate method analogous separate xi need redefine evaluation function 
introduce penalty functions constraint eq 

clearly penalties non negative zero constraints violated 
consider vector weights wm define eval function minimised extend representation individuals xn wm variation operators applied part chromosomes realising self adaptation constraint weights fitness function 
important note crucial difference self adapting mutation step sizes constraint weights 
mutation step sizes encoded chromosomes evaluation chromosome independent actual values 
eval chromosome contrast constraint weights encoded chromosomes eval fw chromosome enable evolution cheat sense making improvements minimising weights optimising satisfying constraints 
eiben investigated issue specific tournament selection mechanism neatly solves problem enables ea solve constraints 
summary previous sections illustrated mutation operator evaluation function controlled adapted evolutionary process 
case demonstrates traditionally adjusted components mutation recombination selection controlled parameters components evolutionary algorithm 
obviously components parameters changed tuned optimal algorithm performance 
general options eiben michalewicz schoenauer smith sketched mutation operator evaluation function valid parameter evolutionary algorithm population size mutation step penalty coefficient selection pressure forth 
mutation example illustrates phenomenon scope parameter 
mutation step size parameter different domains influence call scope 
xn model particular mutation step size applies variable single individual 
parameter acts component level 
xn representation scope individual dynamic parameter defined affect individuals population scope 
remarks conclude introductory examples section 
ready attempt classification parameter control techniques parameters evolutionary algorithm 
classification control techniques classifying parameter control techniques evolutionary algorithm aspects taken account 
example 
changed 
representation evaluation function operators selection process mutation rate population size 
change deterministic heuristic feedback heuristic self adaptive 
evidence change carried monitoring performance operators diversity population 
scope level change population level individual level forth 
discuss items detail 
changed 
classify parameter control techniques perspective component parameter changed necessary agree list major components evolutionary algorithm difficult task 
purpose assume components ea representation individuals evaluation function variation operators probabilities selection operator parent selection mating selection replacement operator survival selection environmental selection population size topology parameter control evolutionary algorithms note component parameterised number parameters clearly defined 
example offspring produced arithmetical crossover parents xk defined formula 
ak considered parameters crossover 
parameters population include number sizes subpopulations migration rates general case population involved 
despite somewhat arbitrary character list components list parameters component maintain aspect main classification features allows locate specific mechanism effect 
changes 
discussed illustrated earlier case studies methods changing value parameter aspect classified categories 
deterministic parameter control takes place value strategy parameter altered deterministic rule 
rule modifies strategy parameter fixed predetermined user specified way feedback search 
usually time varying schedule rule set number generations elapsed time rule activated 
adaptive parameter control takes place form feedback search serves inputs mechanism determine direction magnitude change strategy parameter 
assignment value strategy parameter may involve credit assignment quality solutions discovered different operators parameters updating mechanism distinguish merits competing strategies 
subsequent action ea may determine new value persists propagates population important point note updating mechanism control parameter values externally supplied part standard evolutionary cycle 
self adaptive parameter control idea evolution evolution implement parameters see review :10.1.1.23.8293
parameters adapted encoded chromosomes undergo mutation recombination 
better values encoded parameters lead better individuals turn survive produce offspring propagate better parameter values 
eiben michalewicz schoenauer smith important distinction adaptive self adaptive schemes mechanisms credit assignment updating different strategy parameters entirely implicit selection variation operators evolutionary cycle 
terminology leads taxonomy illustrated fig 

parameter setting run run parameter tuning parameter control deterministic adaptive self adaptive fig 

global taxonomy parameter setting eas authors introduced different terminology 
angeline distinguished absolute empirical rules correspond uncoupled tightly coupled mechanisms spears 
note uncoupled absolute category encompasses deterministic adaptive control tightly coupled empirical category corresponds 
feel distinction deterministic adaptive parameter control essential feedback search process 
acknowledge terminology proposed perfect 
term deterministic control appropriate determinism matters fact parameter altering transformations take input variables related progress search process 
example randomly change mutation probability generations deterministic process 
name fixed parameter control provide alternative covers example 
terms adaptive replaced equally meaningful explicitly adaptive implicitly adaptive controls respectively 
chosen adaptive self adaptive widely accepted usage term 
evidence informs change 
third criterion classification concerns evidence determining change parameter value 
commonly progress search monitored looking performance operators diversity population 
information gathered monitoring process feedback adjusting parameters 
parameter control evolutionary algorithms perspective distinction cases absolute evidence speak absolute evidence value strategy parameter altered rule applied predefined event occurs 
difference deterministic parameter control lies fact deterministic parameter control rule fires deterministic trigger time elapsed feedback search 
instance rule applied measure monitored hits previously set threshold event forms evidence 
examples type parameter adjustment include increasing mutation rate population diversity drops value changing probability applying mutation crossover fuzzy rule set variety population statistics methods resizing populations estimates schemata fitness variance 
mechanisms require user clear intuition steer parameter certain direction cases specified advance determine threshold values triggering rule activation 
intuition may encapsulation practical experience data mining empirical analysis previous runs theoretical considerations order examples rely implicit assumption changes appropriate search problem applicable run ea problem 
relative evidence case relative evidence parameter values compared fitness offspring produce better values get rewarded 
direction magnitude change strategy parameter specified deterministically relative performance values necessary value time 
assignment value strategy parameter involves credit assignment action ea may determine new value persists propagates population 
example consider ea crossovers crossover rates adding reset crossovers performance measured quality offspring create 
methods may controlled adaptively typically bookkeeping monitor performance user supplied update procedure self adaptively selection operator acting indirectly operator parameter frequencies association fit solutions 
eiben michalewicz schoenauer smith scope change 
discussed earlier change component ea may affect gene parameter chromosomes individuals entire population component selection evaluation function 
aspect scope level adaptation 
note scope level independent dimension usually depends component ea change takes place 
example change mutation step size may affect gene chromosome entire population depending particular implementation scheme change penalty coefficients typically affects population 
respect scope feature secondary usually depending component actual implementation 
noted issue scope parameter complicated indicated sect 

scope depends interpretation mechanism parameters 
example individual represented xn vector denotes covariances variables case scope strategy parameters individual notation suggest act level 
example illustrates parameter encoded chromosomes interpreted different ways leading different algorithm variants different scopes parameter 
spears experimented individuals containing extra bit determine point crossover uniform crossover bit standing point uniform crossover respectively :10.1.1.23.8293
interpretations considered 
interpretation pairwise operator choice parental bits corresponding operator random choice 
parameter interpretation acts individual level 
second interpretation bit distribution population example population bit probability point crossover 
parameter interpretation acts population level 
spears noted definite impact performance better results arising individual level scheme smith compared versions self adaptive recombination operator concluding component level version significantly outperformed individual population level versions 
interpretations spears scheme easily combined 
instance similar interpretation parental bits corresponding operator differ operator selected bit distribution just second interpretation 
scope level parameter interpretation individual population 
example shows notion scope parameter control evolutionary algorithms ill defined complex 
combined arguments scope level entity primarily feature parameter secondarily feature adaptation motivates decision exclude major classification criterion 
summary main criteria classifying methods change values strategy parameters algorithm execution 
component parameter changed 

change 

evidence change 
classification dimensional 
component dimension consists categories representation evaluation function variation operators mutation recombination selection replacement population 
dimensions respectively deterministic adaptive categories absolute relative 
possible combinations table 
table indicates deterministic parameter control relative evidence impossible definition self adaptive parameter control absolute evidence 
adaptive scheme options possible practice 
deterministic adaptive self adaptive absolute relative table 
refined taxonomy parameter setting eas types parameter control type evidence dimensions 
entries represent meaningless nonexistent combinations examples varying ea parameters review illustrative examples literature concerning major components 
comprehensive overview reader referred 
representation choice representation forms important distinguishing feature different streams evolutionary computing 
perspective gas eiben michalewicz schoenauer smith es distinguished historical ep gp data structure represent individuals 
group data structure linear length fixed change run algorithm 
historical ep gp hold finite state machines parse trees nonlinear structures size number states respectively nodes shape change run 
argued implies intrinsically adaptive representation traditional ep gp 
hand main structure finite state machines change search traditional ep function terminal sets gp automatically defined functions adfs 
identifies representation basic syntax plus encoding mechanism differently sized shaped finite state machines respectively trees different expressions unchanging syntax 
view consider representations traditional ep gp intrinsically adaptive 
illustrate variable representations delta coding algorithm mathias whitley effectively modifies encoding function parameters 
motivation algorithm maintain balance fast search sustaining diversity 
taxonomy categorised adaptive adjustment representation absolute evidence 
ga multiple restarts run find interim solution subsequent runs decode genes distances delta values interim solution 
way restart forms new hypercube interim solution origin 
resolution delta values altered restarts expand contract search space 
restarts triggered population diversity measured hamming distance best worst strings current population greater 
sketch algorithm showing main idea fig 

note number bits increased solution interim 
technique refined cope deceptive problems 
evaluation function evaluation functions typically varied ea considered part problem solved part problemsolving algorithm 
fact evaluation function forms bridge views partially true 
eas evaluation function derived optimisation problem hand simple transformation objective function 
class constraint satisfaction problems objective function problem definition :10.1.1.23.8293
normally posed decision problems boolean outcome denoting assignment variables represents valid parameter control evolutionary algorithms starting population genotype phenotype encoding hd run ga bits object variable od repeat global termination satisfied save best solution interim population new coding bits distance object value interim sign bit hd run ga encoding od od fig 

outline delta coding algorithm solution 
possible approach eas treat minimisation problems evaluation function defined amount constraint violation candidate solution 
approach commonly known penalty approach formalised follows 
assume constraints ci variables vj domain task find variable assignment satisfying constraints 
penalties defined follows wi ci ci violates ci 
obviously true weights specify severely violation certain constraint penalised 
setting weights large impact ea performance ideally wi reflect hard ci satisfy 
problem finding appropriate weights requires insight problem instance practicable 
stepwise adaptation weights saw mechanism introduced eiben van der improved version weight adaptation mechanism eiben rau provides simple effective way set weights 
basic idea saw mechanism eiben michalewicz schoenauer smith constraints satisfied certain number steps fitness evaluations difficult high weight penalty 
saw ing changes evaluation function adaptively ea periodically checking best individual population raising weights constraints individual violates 
run continues new evaluation function 
nice feature saw ing user seeking weight settings eliminating possible source error 
furthermore weights reflect difficulty constraints algorithm problem instance stage search 
property valuable principle different weights appropriate different algorithms 
mutation large majority adapting self adapting ea parameters concerns variation operators mutation recombination crossover 
discussed rule rechenberg constitutes classical example adaptive mutation step size control es 
showed self adaptive control mutation step sizes traditional es 
nner derived theoretically optimal schedules gas deterministically changing pm counting ones function 
suggest pm exp constants chromosome length population size time generation counter 
purely deterministic parameter control mechanism 
self adaptive mechanism controlling mutation bit string ga ck 
technique works extending chromosomes additional bits encode individuals pm 
mutation works 
decoding bits pm 
mutating bits encode pm mutation probability pm 
decoding changed bits 
mutating bits encode solution mutation probability approach highly self adaptive rate variation search parameters encoded value opposed external parameters learning rates step sizes 
smith showed theoretical predictions verified experimentally scheme gets stuck suboptimal regions search space low zero mutation rate attached member population :10.1.1.23.8293
showed robust problem solving mechanism simply achieved ignoring step algorithm fixed learning rate parameter control evolutionary algorithms probability applying bitwise mutation encoding strategy parameters second step 
crossover classical example adapting crossover rates gas davis adaptive operator fitness 
method adapts rates crossover operators rewarding successful creating better offspring 
reward propagated back operators generations back helped setting reward shift probability cost operators :10.1.1.87.3586
close spirit implicit bucket brigade credit assignment principle classifier systems 
ga method applies crossover operators simultaneously generation having crossover rate pc opi 
additionally operator local delta value di represents strength operator measured advantage child created operator respect best individual population 
local deltas updated operator adaptation mechanism recalculates crossover rates generations 
main idea redistribute probabilities biased accumulated operator strengths local deltas 
di values normalised new value pc opi old value normalised strength sum equals yielding norm pc opi pc opi norm clearly method adaptive relative evidence 
selection interesting note parent selection survivor selection replacement component ea commonly adaptive manner selection methods parameters easily adapted 
example linear ranking parameter representing expected number offspring allocated best individual 
changing parameter range selective pressure algorithm varied easily 
similar possibilities exist tournament selection tournament size provides natural parameter 
existing mechanisms varying selection pressure called boltzmann selection mechanism changes selection pressure evolution predefined cooling schedule 
name originates boltzmann trial condensed matter physics minimal energy level sought state transitions 
state chance accepting state eiben michalewicz schoenauer smith ei ej accept ei ej exp kb ei ej ei ej energy levels kb parameter called boltzmann constant temperature 
acceptance rule called metropolis criterion 
illustrate variable selection pressure survivor selection replacement step simulated annealing sa 
sa generate test search technique physical biological analogy 
formally sa envisioned evolutionary process population size undefined problem dependent representation mutation specific survivor selection mechanism 
selective pressure changes course algorithm boltzmann style 
main cycle sa fig 

current solution function generate set neighbours ni generate ni set exp random set fi fi fig 

outline simulated annealing algorithm mechanism parameter ck temperature decreases predefined scheme function time making probability accepting inferior solutions smaller smaller minimisation problems 
evolutionary point view ea increasing selection pressure 
successful example applying boltzmann acceptance smith local search part memetic algorithm ma temperature inversely related fitness diversity population :10.1.1.23.8293
population contains wide spread fitness values temperature low fitter solutions local search accepted concentrating search solutions 
parameter control evolutionary algorithms spread fitness values low indicating converged population common problem mas temperature higher making inferior solution accepted diversity offering potential means escaping local optima 
population innovative way control population size offered ga variable population size 
fact population size parameter removed entirely adjusted fly 
certainly evolutionary algorithm population size size derived measure controllable parameter 
main idea assign lifetime individual created reduce remaining lifetime consecutive generation 
remaining lifetime zero individual removed population 
things noted 
lifetime allocated newborn individual biased fitness fitter individuals allowed live longer 
second expected number offspring individual proportional number generations survives 
consequently resulting system favours propagation genes 
fitting algorithm general classification scheme straightforward explicit mechanism sets value population size parameter 
procedure implicitly determines individuals alive works adaptive fashion information status search 
particular fitness newborn individual related fitness generation lifetime allocated accordingly 
amounts relative evidence 
varying parameters simultaneously studies explicitly devoted adjusting parameters level self adaptive ga 
ga uses self adaptation mutation rate control plus adaptive control population size 
mechanism controlling mutation similar ck sect 
mutating bits encoding mutation strength bits question done universal mechanism fixed individuals generations 
words self adaptive mutation parameter genes encoding solution 
population size ga works subpopulations small medium large respectively strictly speaking authors term self adaptive ga partially correct 
contemporary terminology distinguishing dynamic adaptive self adaptive schemes published 
eiben michalewicz schoenauer smith initial sizes respectively 
populations evolved parallel number fitness evaluations epoch independently ga setup 
epoch subpopulations resized heuristic rules maintaining lower upper bound keeping medium sized subpopulation 
categories rules 
rules category activated fitnesses subpopulations converge try move populations apart 
instance fitness size doubled 
rules set activated fitness values distinct epoch 
rules aim maximising performance 
example rule performance subpopulations ranks size size size 
taxonomy population size control mechanism adaptive relative evidence 
lis lis offer parallel ga setup control mutation rate crossover rate population size run 
idea parameter possible values defined advance say lo med hi values allowed gas subpopulations evolved parallel 
epoch performances applied parameter values compared averaging fitnesses best individuals gas value 
winning parameter value 
hi gas shift level concerning parameter epoch 
med gas value concerning parameter epoch 
lo gas shift level concerning parameter epoch 
clearly adjustment mechanism parameters adaptive relative evidence 
mutation crossover population size controlled fly ga parameters ck 
self adaptive mutation sect 
adopted changes new self adaptive technique invented regulating crossover rates individuals lifetime idea sect 
adjusted steady state ga model 
crossover rates included chromosomes mutation rates 
pair individuals selected reproduction individual crossover rates compared random number individual seen ready mate pc possibilities 
individuals ready mate uniform crossover applied resulting offspring mutated 

ready mate create child mutation 
parameter control evolutionary algorithms 
exactly ready mate ready creates child mutation inserted population immediately steady state replacement put hold parent selection round picks parent 
study differs discussed explicitly compares ga variants self adaptive mechanisms ga applying 
experiments show remarkable outcomes completely self adaptive ga wins closely followed adaptive population size control gas self adaptive mutation crossover significantly worse 
results suggest putting effort adapting population size effective trying adjust variation operators 
truly surprising considering traditionally line adjustment variation operators pursued adjustment population size received relatively little attention 
subject certainly requires research 
discussion summarising number things noted 
parameter control ea purposes 
done avoid suboptimal algorithm performance resulting suboptimal parameter values set user 
basic assumption applied control mechanisms intelligent job better user approximately user doing 
way beneficial 
motivation controlling parameters thefly assumption parameter different optimal value different phases search 
holds simply optimal static parameter value ea performance vary parameter 
second thing want note making parameter self adaptive necessarily mean ea fewer parameters 
instance population size parameter eliminated cost introducing new ones minimum maximum lifetime newborn individuals 
ea performance sensitive new parameters parameter replacement things worse 
problem occurs level 
say procedure allocates lifetimes probability redistribution mechanism adaptive crossover rates sect 
function specifying values mutated es meta parameters 
fact assumption intelligently designed effect positive 
cases possibilities possibly working procedures design 
comparing possibilities implies experimental theoretical studies comparing different parameter values eiben michalewicz schoenauer smith classical setting 
case algorithm performance sensitive details meta parameter fully justifies approach 
place issue parameter control larger perspective 
years ec community shifted believing ea performance large extent independent problem instance realising words acknowledged eas need fine tuning specific problems problem instances 
ideally algorithm performs necessary problem specific adjustments 
parameter control discussed step 

aarts korst 
simulated annealing boltzmann machines 
wiley chichester uk 

angeline 
adaptive self adaptive evolutionary computations 
computational intelligence pages 
ieee press 

michalewicz 
genetic algorithm varying population size 
icec pages 

auger 
contributions optimisation continue par algorithmes 
phd thesis universit paris december 
french 

auger le bris schoenauer 
dimension independent convergence rate non isotropic es 
proceedings gecco pages 

ck 
interaction mutation rate selection self adaptation genetic algorithm 
nner manderick pages 

ck 
self adaptation genetic algorithms 
varela bourgine editors practice autonomous systems proceedings st european conference artificial life pages 
mit press cambridge ma 

ck 
optimal mutation rates genetic search 
forrest pages 
ck 
evolutionary algorithms theory practice 
new york oxford university press 

ck 
self adaptation 
ck fogel michalewicz editors evolutionary computation advanced algorithms operators chapter pages 
institute physics publishing bristol 

ck eiben van der 
empirical study gas parameters 
schoenauer deb rudolph yao lutton merelo 
schwefel editors proceedings th conference parallel problem solving nature number lecture notes computer science pages 
springer berlin heidelberg new york 

ck fogel michalewicz editors 
handbook evolutionary computation 
institute physics publishing bristol oxford university press new york 
parameter control evolutionary algorithms 
ck sch tz 
comparative study penalty function repair heuristic stochastic operators set covering problem 
proceedings evolution artificial number lncs 
springer verlag 

bean 
dual genetic algorithm bounded integer problems 
technical report university michigan 

belew booker editors 
proceedings th international conference genetic algorithms 
morgan kaufmann san francisco 

davis 
adapting operator probabilities genetic algorithms 
schaffer pages 

davis editor 
handbook genetic algorithms 
van nostrand reinhold 

de jong 
analysis behaviour class genetic adaptive systems 
phd thesis university michigan 

deb 
beyer 
self adaptive genetic algorithms simulated binary crossover 
evolutionary computation 

eiben 
evolutionary algorithms constraint satisfaction definitions survey methodology research directions 
rogers editors theoretical aspects evolutionary computing pages 
springer berlin heidelberg new york 

eiben michalewicz 
parameter control evolutionary algorithms 
ieee transactions evolutionary computation 

eiben jansen michalewicz paechter 
solving csps self adaptive constraint weights prevent eas cheating 
whitley pages :10.1.1.87.3586

eiben 
rau 
ga easy ga hard constraint satisfaction problems 
meyer editor proceedings ecai workshop constraint processing number lncs pages :10.1.1.87.3586
springer berlin heidelberg new york 

eiben 
self adaptivity constraint satisfaction learning penalty functions 
icec pages 

eiben smith 
evolutionary computation 
springer 

eiben van der 
solving sat adaptive genetic algorithms 
icec pages 

eiben van 
saw ing eas adapting fitness function solving constrained problems 
corne dorigo glover editors new ideas optimization chapter pages 
mcgraw hill london 
:10.1.1.87.3586
eshelman editor 
proceedings th international conference genetic algorithms 
morgan kaufmann san francisco 

fogel 
evolutionary computation 
ieee press 

fogel atmar 
comparing genetic operators gaussian mutations simulated evolutionary processes linear systems 
biological cybernetics 

forrest editor 
proceedings th international conference genetic algorithms 
morgan kaufmann san francisco 
eiben michalewicz schoenauer smith 

optimisation genetic algorithms genetic algorithms 
albrecht reeves steele editors artifical neural networks genetic algorithms pages 
springer berlin heidelberg new york 

goldberg 
genetic algorithms search optimization machine learning 
addison wesley 

grefenstette 
optimisation control parameters genetic algorithms 
ieee transaction systems man cybernetics :10.1.1.87.3586

hansen mller 
reducing time complexity derandomized evolution strategy covariance matrix adaptation cma es 
evolution computation 

hansen 
adapting arbitrary normal mutation distributions evolution strategies covariance matrix adaption 
icec pages 
ieee press 

hansen 
completely derandomized self adaptation evolution strategies 
evolutionary computation 

hansen 
adaptation arbitrary normal mutation distributions evolution strategies generating set adaptation 
eshelman pages :10.1.1.87.3586

manner 
optimal mutation genetic algorithms 

schwefel nner editors proceedings st conference parallel problem solving nature number lecture notes computer science pages 
springer berlin heidelberg new york 

michalewicz eiben 
adaptation evolutionary computation survey 
icec 

michalewicz 
self adaptive genetic algorithm numeric functions 
voigt pages :10.1.1.23.8293

proceedings ieee conference evolutionary computation 
ieee press piscataway nj 

proceedings ieee conference evolutionary computation 
ieee press piscataway nj 

proceedings ieee conference evolutionary computation 
ieee press piscataway nj 

jain fogel 
case studies applying fitness distributions evolutionary algorithms 
ii 
comparing improvements crossover gaussian mutation simple neural networks 
yao fogel editors proc 
ieee symposium combinations evolutionary computation neural networks pages 
ieee press 


non stationary penalty functions solve nonlinear constrained optimisation problems ga icec pages 


done lately adapting operator probabilities steady state genetic algorithm 
eshelman pages :10.1.1.87.3586

suzuki 
adaptive search strategy genetic algorithms additional genetic algorithms 
nner manderick pages 

kirkpatrick gelatt vecchi 
optimization simulated 
science 
parameter control evolutionary algorithms 
smith 
memetic algorithm self adaptive local search tsp case study 
whitley pages 

smith 
emergence profitable search strategies simple inheritance mechanism 
spector pages 

lee takagi 
dynamic control genetic algorithms fuzzy logic techniques 
forrest pages 

lis 
parallel genetic algorithm dynamic control parameter 
icec pages 

lis lis 
self adapting parallel genetic algorithm dynamic mutation probability crossover rate population size 
editor proceedings polish evolutionary algorithms conference pages 
warsaw 

mahfoud 
boltzmann selection 
ck pages 

nner manderick editors 
proceedings nd conference parallel problem solving nature 
north holland amsterdam 

mathias whitley 
remapping hyperspace genetic search canonical delta folding 
whitley editor foundations genetic algorithms pages 
morgan kaufmann san francisco 

mathias whitley 
changing representations search comparative study delta coding 
evolutionary computation 

michalewicz 
genetic algorithms data structures evolution programs 
springer berlin heidelberg new york rd edition 

michalewicz schoenauer 
evolutionary algorithms constrained parameter optimisation problems 
evolutionary computation 

schaffer editor 
proceedings rd international conference genetic algorithms 
morgan kaufmann san francisco 

schaffer caruana eshelman das 
study control parameters affecting online performance genetic algorithms function optimisation 
schaffer pages 

schaffer eshelman 
crossover evolutionarily viable strategy 
belew booker pages 

schlierkamp voosen hlenbein 
strategy adaptation competing subpopulations 
davidor 
schwefel nner editors proceedings rd conference parallel problem solving nature number lecture notes computer science pages 
springer berlin heidelberg new york 


schwefel 
numerische optimierung von computer modellen mittels der evolutionsstrategie volume isr 
basel stuttgart 


schwefel 
numerical optimisation computer models 
wiley new york 

smith 
self adaptation evolutionary algorithms 
phd thesis university west england bristol uk 

smith 
modelling gas self adaptive mutation rates 
spector pages 

smith 
appropriate adaptation levels learning gene linkage 
genetic programming evolvable machines 

smith 
parameter perturbation mechanisms binary coded gas mutation 
rowe poli dejong editors foundations genetic algorithms pages 
morgan kaufmann san francisco 
eiben michalewicz schoenauer smith :10.1.1.87.3586
smith fogarty 
adaptively parameterised evolutionary systems self adaptive recombination mutation genetic algorithm 
voigt pages :10.1.1.23.8293

smith fogarty 
recombination strategy adaptation evolution gene linkage 
icec pages 

smith fogarty 
self adaptation mutation rates steady state genetic algorithm 
icec pages 

smith fogarty 
operator parameter adaptation genetic algorithms 
soft computing 

smith 
adaptively resizing populations algorithm analysis results 
complex systems 

spears 
adapting crossover evolutionary algorithms 
mcdonnell reynolds fogel editors proceedings th annual conference evolutionary programming pages 
mit press cambridge ma 

spector goodman wu langdon 
voigt gen sen dorigo garzon burke editors 
proceedings genetic evolutionary computation conference gecco 
morgan kaufmann san francisco 

stephens garcia vargas 
evolving systems 
artificial life 

syswerda 
study reproduction generational steady state genetic algorithms 
rawlins editor foundations genetic algorithms pages 
morgan kaufmann san francisco 


voigt ebeling rechenberg 
schwefel editors 
proceedings th conference parallel problem solving nature number lecture notes computer science 
springer berlin heidelberg new york 

whitley goldberg cantu paz spector parmee 
beyer editors 
proceedings genetic evolutionary computation conference gecco 
morgan kaufmann san francisco 

whitley mathias 
delta coding iterative search strategy genetic algorithms 
belew booker pages 

wolpert macready 
free lunch theorems optimisation 
ieee transactions evolutionary computation 

zhang 
balancing accuracy parsimony genetic programming 
evolutionary computing 
