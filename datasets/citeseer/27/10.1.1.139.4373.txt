scalability multicast delivery non sequential streaming access jin computer science department boston university boston ma cs bu edu serve asynchronous requests multicast categories techniques stream merging periodic broadcasting proposed 
sequential streaming access requests uninterrupted object techniques highly scalable required server bandwidth stream merging grows logarithmically request arrival rate required server bandwidth periodic broadcasting varies logarithmically inverse start delay 
sequential access model inappropriate model partial requests client interactivity observed various streaming access workloads 
analytically experimentally studies scalability multicast delivery non sequential access model requests start random points object 
show required server bandwidth protocol providing immediate service grows square root request arrival rate required server bandwidth protocol providing delayed service grows linearly inverse start delay 
investigate impact limited client receiving bandwidth scalability 
optimize practical protocols provide immediate service non sequential requests 
protocols utilize limited client receiving bandwidth near optimal required server bandwidth close lower bound 

streaming media delivery presents formidable strain server network capacity 
demand large electronic artifacts stored internet servers ranging demand servers software repository servers multicast emerges promising scalable delivery technique content 
multicast demand driven closed loop fashion data centered open loop fashion 
closed loop approaches service starts soon request 
time goes possible service delegated ex supported part nsf ani ani 
jin supported ibm ph research fellowship 
azer bestavros computer science department boston university boston ma best cs bu edu multicast stream 
example consider scenario clients download hour video second client starting minute 
service second client starts immediately dedicated delivery minute video client remaining minutes obtained buffered playout minute joining client multicast channel 
open loop approaches server multicasts object segments object periodically clients simply join multicast channels 
server interactively responding request arrivals clients may wait service start 
closed loop open loop approaches studied including early batching piggybacking stream tapping patching techniques stream merging broadcasting protocols :10.1.1.26.267:10.1.1.45.1022:10.1.1.137.6897
particular techniques stream merging periodic broadcasting shown highly scalable 
stream merging originated eager vernon zahorjan 
stream merging server bandwidth grows logarithmically request arrival rate average number clients requesting object simultaneously 
periodic broadcasting introduced viswanathan imielinski 
periodic broadcasting clients may observe small start delay required server bandwidth grows logarithmically inverse start delay 
stream merging periodic broadcasting techniques built assumptions clients higher receiving bandwidth object playback rate local storage keep prefetched portions object temporarily 
scalability stream merging periodic broadcasting rests assumption sequential access 
clients request object play interruption 
unknown techniques scale non sequential access environment clients may request segments object 
studies characterization streaming access workloads revealed client access seldom sequential due frequent client inter activity 
studies tried minimize bandwidth requirement non sequential access video demand servers unknown potentials limitations multicast delivery non sequential access environment 
give example applications non sequential access characteristics 
example interactive video demand remote learning educational environment press releases corporate environment example 
potentially large number clients may request object short period time lecture released press release put may settle continuous playout 
specifically clients may jump frequently vcr functionality pause fast forward skip rewind 
clearly desirable server able support large number simultaneous requests minimizing start delay requests 
second example real time large software distribution applications 
large number clients may need download new software release simultaneously short period time possibly reaction cyber threat fix software vulnerability 
entire large software package viewed streaming object served multicast 
different clients may require different components software due customized installations example 
translates jumps process accessing object 
contributions overview considers problem multicast serve nonsequential requests 
simple non sequential streaming access model derive tight lower bound required server bandwidth protocols providing immediate delayed service 
lower bound validated simulation 
appears lower bound holds general cases 
results indicate scalability multicast delivery non sequential access model logarithmic scalability achievable sequential access model 
specifically show non sequential access required server bandwidth protocol providing immediate service grows fast square root request arrival rate required server bandwidth protocol providing delayed service grows linearly inverse start delay 
study limited client receiving bandwidth may impact scalability 
propose practical simple delivery protocols require server bandwidth close lower bound 
protocols provide immediate service clients assume limited client receiving bandwidth 
organized follows 
section presents background knowledge related stream merging periodic broadcasting techniques 
section derive lower bounds required server bandwidth simple non sequential access model 
section presents simulation results validate analytical results realistic non sequential access models 
section study impact limited client receiving bandwidth 
section optimized multicast delivery protocols non sequential access 
conclude section summary directions 

background related section briefly describes previous techniques stream merging periodic broadcasting utilize multicast delivery serve streaming media objects 
results previous scalability techniques streaming accesses sequential 
addition introduce non sequential access model notations thereof 
stream merging stream merging server immediately delivers object response client request 
means server initiates stream client 
assuming client joins joins joins joins joins example hierarchical stream merging 
client receiving bandwidth twice object playback rate 
client receiving bandwidth times playback rate 
ing bandwidth higher object playback rate assumed client receive streams time possible client listen second ongoing stream object initiated earlier client 
time goes possible stream longer necessary content prefetched second stream 
client able join ongoing multicast session virtue making content missed session dedicated stream 
process merging multicast sessions started earlier process pruning sessions started repeated times giving rise hierarchical stream merging opposed stream tapping patching techniques merging occurs client 
gives example clients request object times respectively 
assumes clients receiving bandwidth twice object playback rate 
server initiates stream client 
client listens stream prefetches data 
time stream initiated longer necessary prefetched keep prefetching data stream point starts listen stream notice starts listen stream earlier 
virtually joins time joins time 
notice time stream initiated longer necessary retrieve segment object 
server may initiate stream simply stream units time joins shown 
case client receiving bandwidth twice object playback rate 
bandwidth skimming protocols case 
stream divided substreams fine grained interleaving positive integer 
substream transmitted channel rate equal times object playback rate 
stream merging possible clients receive substreams time 
gives example time interval receives substreams prefetches substream time interval need receive substream prefetches substreams eventually joins time 
similarly joins time joins time 
salient feature bandwidth skimming client receiving bandwidth slightly higher object playback rate required server bandwidth comparable unlimited receiving bandwidth assumption 
channel channel channel channel channel channel channel schedule skyscraper broadcasting segments 
transmission plans clients shown shaded segments 
client receives segments time continuously play object start delay smaller duration segment 
shown unlimited limited receiving bandwidth assumptions required server bandwidth increases logarithmically request arrival rates 
stream merging substantially outperforms stream tapping patching techniques required server bandwidth increases square root request arrival rate :10.1.1.45.1022
periodic broadcasting periodic broadcasting schemes long object divided series segments increasing sizes 
segment periodically broadcasted dedicated channel 
client playing earlier segment segments prefetched client local buffer 
possible client higher receiving bandwidth object playback rate 
stream merging assumed clients receive streams segments time 
segment size progression way client starts playing segment object played continuously 
important performance metrics periodic broadcasting protocols required server bandwidth start delay 
required server bandwidth proportional number segments fixed independent request arrival rate 
maximum start delay equal duration segment 
desirable property periodic broadcasting protocols small segment permits small start delay larger segments allow total number segments remain small 
achieve best tradeoffs metrics broadcasting protocol needs find quickest segment size progression 
various periodic broadcasting protocols proposed literature 
understand general idea protocols suffices describe example skyscraper broadcasting protocol 
skyscraper broadcasting assumes client receiving bandwidth twice object playback rate 
series segment sizes broadcast schedule segments shown 
shows clients starting time interval respectively served delay unit time henceforth continuously play object 
clients different transmission schedules shown shaded segments needs receive segments time 
segment size progression skyscraper broadcasting time property size doubled steps 
different broadcasting protocols may different segment size progressions geometric series fibonacci series common size increases exponentially 
total number segments proportional required server bandwidth logarithmic function inverse segment size proportional start delay 
notation assumptions notation listed table 
length object bytes 
assuming object played constant bit rate byte unit time duration units time 
consider simple model non sequential accesses 
request arrivals follow poisson process arrival rate request segment size starts random point object 
sume simplicity assume object cyclic means access may proceed past object cycling object 
parameters uniquely specify workload 
ease presentation introduce quantities derived basic parameters denote average number clients serviced time 
little law follows assess scalability multicast delivery protocol customary find server bandwidth grows function similarly denote average number requests period time follows notice definition helps understand example denote maximum delay service request started 
immediate service assumption immediate service special case delayed service 
clarity analysis section consider immediate service consider general delayed service 
denote client receiving bandwidth units object playback rate 
example means client receive streams unit playback rate simultaneously 
assume unlimited derivation lower bound required server bandwidth 
section simulations show client receiving bandwidth limited required server bandwidth increases slightly 
considering storage expensive assume clients large buffers keep prefetched data buffers 
scalability multicast delivery sequential access sequential access requests start object continue 
eager derived tight lower bound required server bandwidth protocol including stream merging provides immediate service 
lower bound notation definition object duration length bytes assuming byte unit time client request arrival rate duration request average number clients serviced time 
quantity equal average number requests arrived quantity equal required server bandwidth units object playback rate maximum start delay request client receiving bandwidth units object playback rate bound derived considering arbitrarily small portion object offset portion multicasted 
requests may join multicast request time missed portion 
average server needs multicast portion time bound extended adding start delay follows table notations 
periodic broadcast protocols assume arbitrary large lower bound summary sequential access lower bound required server bandwidth protocol providing immediate service grows logarithmically request arrival rate lower bound required server bandwidth protocol providing delayed service grows logarithmically inverse start delay 
results provide basic scalability arguments multicast delivery sequential access model 

multicast delivery non sequential access section consider non sequential access derive tight lower bounds required server bandwidth protocol providing immediate service delayed service 
assume client receiving bandwidth unlimited 
scalability immediate service protocols consider protocols provide immediate service simple non sequential access model described section 
consider arbitrarily small portion object say byte 
assume time byte multicasted 
question need multicasted 
consider random variable time elapsed byte multicasted latest point time request delayed byte multicasted 
clearly time byte immediately needed request multicasting byte waited definition case 
request initiated time byte retrieved multicast time 
ultimate goal compute frequently byte served expectation suffices derive probability density function denoted 
consider arrival process event playout byte request 
obvious arrival process poisson process arrival rate average byte played times explained earlier playout byte request moment necessarily mean multicast byte precise moment 
interested arrival process arrivals necessitate byte multicasted 
denote arrival process denote arrival rate process 
arrivals clearly subset arrivals specifically arrival retrieved byte time excluded arrival require re multicasting byte time assume ar occurs time probability event certainly probability event arrival rate function arrival time observation clear illustration 
time certainly event increases increases linearly event certainly event ready derive marginal density functions random variable compute expected number events time bandwidth linear scale bandwidth log scale lower bound required server bandwidth immediate service protocols varying number simultaneous requests segment request arrival rate notice probability arrival time interval equal arrivals independent 
marginal distribution function arrival interval consequently probability density function remainder derivation straightforward 
compute expectation follows incomplete gamma function obtain average required server bandwidth substituting lows obtain fol seemingly complex result greatly simplified 
incomplete gamma function approaches complete gamma function approaches zero fast insignificant 
fast 
means order required server bandwidth order lower bound higher bandwidth linear scale bandwidth log scale lower bound varying fixed 
logarithmic bandwidth requirement stream merging sequential requests 
generally increases increases 
example compute lower bound comparable required server bandwidth unicast service 
increasing results diminishing advantage multicast delivery especially multicast overhead taken consideration 
general case easy numerically solve equation 
done varying varying results shown 
observe required server bandwidth increases fast increases decreases 
eventually close unicast service 
notice sequential access stream merging techniques required server bandwidth lower bound bottom plot shown 
shows plot axes log scale 
observe log value lower bound approximately linear power law relationship lower bound bandwidth order close increases order lower bound increases order better illustrate lower bound behavior plotted fixing values varying note fixed increasing means increasing observed small required server bandwidth increases linearly large required server bandwidth bounded constant note analysis section assumes constant segment sizes 
general case segment size variable difficult derive lower bound analytically 
details appendix 
scalability delayed service protocols focus general case protocols provide service fixed delay 
non sequential access model described section 
requests satisfied slightly different way 
client tolerates waiting interval time units bytes plays requested segment object 
interval client joins streams retrieve bytes played 
client starts play object continues retrieving bytes available 
client initiates stream bytes retrieved ongoing streams 
obvious imme bandwidth bandwidth bandwidth bandwidth lower bound required server bandwidth delayed service protocols varying typical values 
delay set service model special case delayed service model assume arbitrary byte multicasted time 
denote time byte multicasted 
compared immediate service case expectation increases derive lower bound required server bandwidth lower bound consistent equation 
small compared lower bound close immediate service 
generally increases lower bound decreases 
rate lower bound decreases higher inverse suggests delayed service effective nonsequential access model sequential access model 
recall sequential access periodic broadcasting techniques reduce bandwidth requirement linearly increasing service delay logarithmically 
varying straightforward numerically solve equation 
done varying choosing typical values 
results shown 
observe small example lower bound bandwidth close immediate service shown 
increases lower bound decreases 
cases lower bound larger important notice larger lower bound approaches faster increase 
increases result higher bandwidth requirement 
bandwidth linear scale bandwidth log scale required server bandwidth immediate service protocols obtained simulation varying number simultaneous requests segment request arrival rate 
simulation results lower bounds previous section derived ideal non sequential access model assuming independent arrivals constant segment sizes 
validate lower bounds establish robustness realistic conditions performed extensive simulations describe section 
immediate service written simulator protocol provides immediate service 
assuming unlimited client receiving bandwidth client retrieves bytes ongoing streams possible 
byte obtained way time play multicasted late possible time play clients fully utilize 
varied number simulation pa rameters results shown 
obtain point ran simulator times took average bandwidth 
clarity confidence interval shown 
comparing find cases average required server bandwidth obtained simulation close numerical analysis 
expected derived lower bound tight 
shows average bandwidth special cases 
shows required server bandwidth obtained simulation lower bound required server bandwidth obtained simulation sequential access comparison purposes 
bandwidth non sequential simulated non sequential lower bound sequential simulated bandwidth non sequential simulated non sequential lower bound sequential simulated comparison scalability multicast delivery immediate service protocols sequential nonsequential access models 
non sequential requests generated request starts random point media object 
bandwidth uniform distribution 
bandwidth pareto distribution 
required server bandwidth immediate service protocols obtained simulation varying number simultaneous requests segment request arrival mean segment size rate particular shows case client randomly requests segment size equal fourth object 
shows case observe required server bandwidth non sequential access increases quite fast 
results simulation lower bound higher sequential access 
compared required server bandwidth sequential access theoretical value shown match 
sequential access required server bandwidth increases logarithmically request arrival rate 
non sequential access required server bandwidth increases square root addition observed required server bandwidth roughly twice obtained consistent fact lower bound approximately increases square root effect variable segment size note analysis section simulations assumed segment size constant equal realistic workloads segment size vary distribution 
question lower bound holds various distributions answer question generated segment sizes follow uniform distribution pareto distribution respectively 
mean segment size uniform distribution segment size vary pareto distribution set shape parameter computed scale parameter ensure mean segment size performed simulations values shown corresponding effects required server bandwidth negligible 
shows results obtained simulations variable segment sizes 
comparing results obtained constant segment size assumption shown lower bounds shown differences negligible 
results lead conclude variable segment sizes required server bandwidth increases square root request arrival rate 
bandwidth forward jumps 
bandwidth jumps backward 
required server bandwidth immediate service protocols obtained simulation varying number simultaneous requests segment request arrival rate requests generated model 
segment request duration segment jump distance follow pareto distribution 
effect request correlations simulations far obtained assumption requests correlated start object 
set simulations describe assumptions removed 
generated requests exhibit characteristics observed real streaming access workloads 
adopt model client inter activity 
client starts session object 
receiving segment object segment client skips portion object segment 
process repeats request jump goes object 
prior studies characterized streaming access workloads observed distributions segments tend heavy tailed 
particular pareto distribution close fit 
simulations generated requests exhibited properties 
periods pareto distribution parameter set scale parameter achieve average segment size pe pareto distribution parameter set scale parameter achieve average jump distance results simulations shown 
simulation experiments shown changed average jump distance parameters 
results suggest required server bandwidth appears sensitive variations 
shows results forward jumps allowed 
client requests segment skips segment continue object 
shows results jumps backward jumps 
comparing results lower bound simulation results required server bandwidth close 
comparing backward jumps required server bandwidth decreases slightly 
estimated difference 
explained follows 
simulation assumed client large buffer keep segments object played 
backward jumps possible client plays portion object kept buffer 
equivalent introducing start delay request 
bandwidth bandwidth non sequential simulated non sequential lower bound sequential lower bound non sequential simulated non sequential lower bound sequential lower bound bandwidth bandwidth non sequential simulated non sequential lower bound sequential lower bound non sequential simulated non sequential lower bound sequential lower bound required server bandwidth immediate service protocols obtained simulation varying number simultaneous requests set values 
requests generated model 
reduces required server bandwidth 
presence backward jumps change asymptotic square root lower bound 
observe small required server bandwidth appears lower figures 
expected 
smaller average request duration closer clients start retrieve object requests tend sequential 
understand clearly zoom plot 
show special cases note smaller average request duration case ac cess closer sequential required server bandwidth closer lower bound sequential access 
evident 
increases access sequential resulting required server bandwidth accurately predicted lower bound non sequential access 
evident 
summarize jumps time complete object playout required server bandwidth increases square root request arrival rate 
delayed service simulations validate required server bandwidth delayed service protocols 
varied simulation parameters varied chose typical values simulation run generate sequence requests 
request delayed time delay bytes fetched ongoing streams possible 
client playing object bytes retrieved ongoing streams 
byte obtained manner retrieved server directly late possible clients fully utilize 
bandwidth bandwidth bandwidth bandwidth required server bandwidth obtained simulation varying values 
delay set typical results simulations shown 
comparing results ones anticipated find cases average required server bandwidth obtained simulations close obtained analysis 
shows required server bandwidth varies de lay choose request retrieves fourth object 
shows results representing popular object shows case representing highly popular object 
case plot lower bound non sequential access obtained simulations 
addition comparison purposes plot bandwidth delay relationship sequential access 
particular plot minimum required server bandwidth periodic broadcasting equation required server bandwidth measured simulation stream merging assuming unlimited client receiving bandwidth 
observations summarized follows 
required server bandwidth non sequential access model higher sequential access model 
difference pronounced popular objects 
notice lower bound required bandwidth non sequential access model close higher lower bound sequential access model 
second sequential access model stream merging techniques achieve lower required server bandwidth broadcasting delay small 
obvious popular objects 
stream merging lower bound broadcasting techniques lower bound required server bandwidth broadcasting higher 
fact simulation results stream merging sequential access model close bound equation 
bandwidth non sequential simulated non sequential lower bound broadcasting eqn sequential simulated delay unit bandwidth non sequential simulated non sequential lower bound broadcasting eqn sequential simulated delay unit required server bandwidth varying 
impact limited bandwidth far assumed clients unlimited receiving bandwidth 
section uses simulations study limited client receiving bandwidth affects scalability multicast delivery immediate service protocols 
order multicast delivery possible client receiving bandwidth hold 
context sequential access advanced techniques scheduling client requests multicast streams 
eager proposed hierarchical multicast stream merging techniques progressively merge asynchronous client requests larger larger groups 
problem addressed relates scheduling mergers 
heuristic policies proposed 
particular assuming closest target policy requires client join initiated earlier stream alive 
simulations showed policy performs close line optimal algorithm known client request arrivals advance obtained solving dynamic programming problem 
non sequential access model modify closest target merging policy key point define closest target client 
requests may start object closest target necessarily initiated stream 
define closest target client multicast stream played client nearest 
intuition choice critical client prefetch portion data soon played 
addition closest target redefined target merged terminated 
modify bandwidth skimming technique 
straightforward adaption bandwidth skimming technique described section 
multicast stream divided substreams positive integer 
substream multicasted rate equal times object playback rate 
client assumed capable receiving substreams simultaneously 
closest target policy applied substreams client idle bandwidth listens substreams data played nearest 
client may listen substreams 
developed simulator stream merging bandwidth skimming technique 
shows required server bandwidth obtained simulations varied number concurrent clients value varied set request fourth object 
set bandwidth infinite bandwidth infinite required server bandwidth immediate service protocols client receiving bandwidth limited 
observe client receiving bandwidth limited required server bandwidth slightly higher 
example client bandwidth prefetching simulations indicate required server bandwidth times required unlimited client receiving bandwidth assumption 
simulations indicate required server bandwidth close unlimited client receiving bandwidth assumption 
estimate difference large values results suggest limited client receiving bandwidth possible protocol required server bandwidth quite close lower bound 
section study practical multicast delivery protocols achieve goal 

practical multicast delivery protocols considered previous sections assume unlimited client receiving bandwidth sophisticated practical 
example modified closest target merging policy client may join leave multicast streams frequently 
behavior may incur high overhead servers 
section describe practical multicast delivery protocols optimize minimizing required server bandwidth 
protocols consider protocol provides immediate service clients server multicasts object interval length client joins temporally closest multicast stream 
missed portion requested segment immediately server 
protocol simple request client need join multicast stream 
protocol readily usable client receiving bandwidth twice object playback rate multicast unicast streams sent playback rate 
assuming client requests segment multicasted units time ago client receives unicast stream length concurrently prefetching data multicast stream 
notice straightforward generalize protocol clients lower receiving bandwidth capitalize ideas bandwidth skimming techniques 
stream unicast multicast divided substreams fine grained interleaving positive integer 
substream sent rate equal times playback rate 
clients receive substreams 
assume client requests segment multicasted units time ago 
client receives unicast substreams immediately server prefetches data multicast substream 
units time client need receive unicast substreams prefetch multicast substreams 
units time client need receive prefetch multicast substreams 
eventually unicast substream needed 
protocol optimization optimize protocol determine value controls frequency multicasting object 
assume request segment constant length compute average cost unicast 
assume client requests segment multicasted units time ago 
description protocols difficult find total duration unicast substreams assuming average equal sending rate times playback rate number bytes period time requests bytes average 
addition period time object multicasted times bytes multicasted average 
ready optimize protocol minimizing total cost protocol period time cost difficult find optimal solution yields required server band width required server bandwidth approximately times lower bound equation 
means simple protocol needs twice server bandwidth required impractical protocols assumed simulations 
increases approaches unity required server bandwidth simple protocol increases square root example client bandwidth prefetching required server bandwidth times lower bound 
possible decrease required server bandwidth sophisticated protocols fine tuning simple protocol described payoff exercise fairly limited 
recall section simulation results shown sophisticated earliest target merging algorithm discussed requires server bandwidth roughly equal times lower bound allowing limited room improvement times lower bound achieved protocol described 

analytically derived tight lower bounds required server bandwidth protocols multicast environment access streaming objects sequential 
particular shown systems required server bandwidth protocol providing immediate service grows square root request arrival rate required server bandwidth protocol providing delayed service inversely proportional maximum allowable start delay 
robustness analytical results confirmed extensive simulations realistic workloads 
impact limited client receiving bandwidth investigated 
findings proposed practical near optimal multicast delivery protocol results server bandwidth requirement fairly close lower bound abundant limited client receiving bandwidth assumptions 
findings suggest non sequential access multicast delivery panacea scalability 
large scale content delivery applications require non sequential access large electronic artifacts example interactive video delivery real time software distribution seek alternative complementary techniques increase scalability streaming delivery mechanisms 
techniques include caching buffering replication 
acknowledgments authors mark crovella providing streaming access workload characterization 
authors grateful anonymous reviewers insightful helpful comments 
appendix variable segment size analysis assume segment size random variable distribution general density function mean segment size hope follow steps section compute lower bound required server bandwidth 
defined section 
need compute arrival rate assume arbitrary occurs time probability event computed expression explained follows 
probability density event occurs client requests segment length note occurs result longer request 
certainly event event case gives cumulative probability 
probability event event case gives cumulative probability 
difficult verify deterministic model section special case 
general case equation solved 
considered special cases variable segment sizes including uniform distribution ii exponential distribution able compute equation exact expression proceed section derivation lower bound increasingly complex 
shin 
providing unrestricted vcr functions multicast video demand servers 
proceedings june 
aggarwal wolf yu 
optimal piggybacking merging policies video demand systems 
proceedings sigmetrics may 
aggarwal wolf yu 
permutation pyramid broadcasting scheme video demand systems 
proceedings 
almeida krueger eager vernon 
analysis educational media server workloads 
proceedings nossdav june 
almeroth ammar 
multicast delivery provide scalable interactive video demand service 
ieee journal selected areas communications 
bar noy ladner tam 
comparison stream merging algorithms media demand 
proceedings mmcn january 
bar noy ladner 
competitive line stream merging algorithms media demand 
proceedings symposium discrete algorithms january 
cai hua 
efficient bandwidth sharing technique true video demand systems 
proceedings acm multimedia november 
cai hua vu 
optimizing patching performance 
proceedings mmcn 
carter long 
improving video demand server efficiency stream tapping 
proceedings icccn september 
carter long paris 
efficient implementation interactive video demand 
proceedings mascots august 
wolman voelker levy 
measurement analysis streaming workload 
proceedings usits march 
chiueh lu 
periodic broadcasting approach video demand service 
proceedings mmcn 
coffman 
provably efficient stream merging 
proceedings web caching workshop june 
dan sitaram 
dynamic batching policies demand video server 
acm multimedia systems journal 
eager vernon 
dynamic skyscraper broadcasts video demand 
proceedings mis 
eager vernon zahorjan 
minimizing bandwidth requirements demand data delivery 
proceedings mis 
eager vernon zahorjan 
optimal efficient merging schedules video demand servers 
proceedings acm multimedia november 
eager vernon zahorjan 
bandwidth skimming technique cost efficient video demand 
proceedings mmcn january 
eager vernon zahorjan 
minimizing bandwidth requirements demand data delivery 
ieee transactions data knowledge engineering 
gao towsley 
efficient schemes broadcasting popular videos 
proceedings nossdav june 
gao towsley 
supplying instantaneous video ondemand services controlled multicast 
proceedings june 
liu muntz 
reducing demand video demand storage servers 
proceedings sigmetrics 
liu muntz 
adaptive piggybacking novel technique data sharing video ondemand storage servers 
acm multimedia systems journal 
harel chervenak abowd ramachandran 
workload media enhanced classroom server 
proceedings workshop workload characterization 
hu 
video demand broadcasting protocols study 
proceedings infocom april 
hua cai sheu 
patching multicast technique true video demand services 
proceedings acm multimedia 
hua sheu 
skyscraper broadcasting new broadcasting scheme metropolitan video demand systems 
proceedings sigcomm september 
tseng 
harmonic broadcasting demand service 
ieee transactions broadcasting 
lau liu 
merging video streams multimedia storage server complexity heuristics 
acm multimedia systems journal 
li liao qiu wong 
performance model interactive video demand systems 
ieee journal selected areas communications 
liao li 
split merge protocol interactive video demand 
ieee multimedia 
eager vernon sundaram 
scalable demand media streaming packet loss recovery 
proceedings sigcomm august 
padhye kurose 
empirical study client interactions continuous media courseware server 
proceedings nossdav june 
paris 
interactive broadcasting protocol video ondemand 
proceedings april 
paris carter long 
efficient broadcasting protocols video demand 
proceedings mas cots july 
paris carter long 
low bandwidth broadcasting protocol video demand 
proceedings icccn 
paris carter long 
hybrid broadcasting protocol video demand 
proceedings mmcn 
paris carter long 
reactive broadcasting protocol video demand 
proceedings mmcn january 
paris long 
zero delay broadcasting protocols video demand 
proceedings acm multimedia november 
sen gao rexford towsley 
optimal patching schemes efficient multimedia streaming 
proceedings nossdav june 
sen gao towsley 
frame periodic broadcast fundamental resource tradeoffs 
proceedings april 
viswanathan imielinski 
pyramid broadcasting video demand service 
proceedings mmcn 
zhao eager vernon 
efficient delivery techniques variable bit rate multimedia 
proceedings mmcn january 
