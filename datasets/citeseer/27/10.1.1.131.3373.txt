finding frequent items data streams moses charikar kevin chen martin farach colton princeton university moses cs princeton edu uc berkeley cs berkeley edu rutgers university google martin google com 
pass algorithm estimating frequent items data stream limited storage space 
method relies novel data structure called count sketch allows estimate frequencies items stream 
algorithm achieves better space bounds previous best known algorithms problem natural distributions item frequencies 
addition algorithm leads directly pass algorithm problem estimating items largest absolute change frequency data streams 
knowledge problem previously studied literature 
basic problems data stream hrr ams finding frequently occurring items stream 
shall assume stream large memory intensive solutions sorting stream keeping counter distinct element infeasible afford pass data 
problem comes context search engines streams question streams queries sent search engine interested finding frequent queries handled period time 
wide variety heuristics problem proposed involving combination sampling hashing counting see gm section survey 
solutions clean bounds amount space necessary produce approximate lists frequent items 
fact algorithm theoretical guarantees available straightforward sampling algorithm uniform random sample data kept 
algorithm space bound depends distribution frequency items data stream 
main contribution simple algorithm theoretical bounds space requirements beats naive sampling approach wide class common distributions 
done author google done author google details result need introduce definitions 

qn data stream qi 
om 
object oi occur ni times order oi nm 
fi ni consider notions approximating frequent elements problem input stream integers output list elements frequent elements occur list 
note general input distribution may hard solve 
suppose example nk nl kth frequent element frequency st frequent element 
impossible find elements top elements 
define variant input stream integer real 
output list elements element list ni nk 
somewhat stronger guarantee output item oi ni nk output list 
algorithm fact achieve stronger guarantee 
err boundary cases 
summary final results follows introduce simple data structure called count sketch give pass algorithm computing count sketch stream 
show count sketch reliably estimate frequencies common items directly yields pass algorithm solving 
sampling algorithm give bounds version problem 
special case zipfian distributions give bounds algorithm solve ck constant beat bounds sampling algorithm reasonable values addition count sketch data structure additive sketches streams directly added subtracted 
streams compute difference sketches leads directly pass algorithm computing items frequency changes streams 
previous algorithms adapted find max change items 
problem practical motivation context search engine query streams queries frequency changes consecutive time periods indicate topics people currently interested goo 
defer actual space bounds algorithms section 
section survey previous approaches problem 
algorithm constructing count sketches section section analyze space requirements algorithm 
section show algorithm adapted find elements largest change frequency 
conclude section short discussion 
background straightforward solution problem keep uniform random sample elements stored list items plus counter item 
object added simply increment counter adding new object list 
refer algorithm sampling algorithm 
size sample counting repetitions ensure element frequency fk appears sample need set probability included sample log nk log fk 
guarantees top elements sample gives solution log fk 
variants basic sampling algorithm gibbons matias gm 
concise samples algorithm keeps uniformly random sample data assume know length data stream 
begins optimistically assuming include elements sample probability 
runs space lowers element evicted sample continues process new lower invariant algorithm point item sample current threshold probability 
sequence chosen arbitrarily adapt input stream processed 
algorithm final threshold algorithm gives output sampling algorithm inclusion probability 
value depends input stream complicated way clean theoretical bound algorithm available 
counting samples algorithm adds optimization observation long setting aside space count item sample anyway may keep exact count occurrences item added sample 
change improves accuracy counts items change get included sample 
fang consider related problem finding items data stream occur frequency fixed threshold call iceberg queries 
propose number different heuristics involve multiple passes data set 
propose heuristic pass multiple hash scheme similar flavor algorithm 
directly connected algorithm draws quite substantial body data stream algorithms gg hrr ind 
particular alon matias szegedy ams give lower bound space complexity algorithm estimating frequency largest item arbitrary data stream :10.1.1.102.5483
lower bound brittle applies problem relaxed versions problem consider achieve huge space reduction 
addition give algorithm estimating second frequency moment idea random hash functions algorithm see ach 
count sketch algorithm give algorithm brief discussion intuition 
intuition recall data structure maintains approximate counts high frequency elements stream compact 
consider simple algorithm finding estimates ni 
hash function objects counter 
processing stream time encounter item qi update counter qi 
counter allows estimate counts items qi ni 
obvious couple problems scheme variance estimate large elements estimates wrong variance 
natural attempt fix algorithm select hash functions 
st keep counters ct process item qi need set cj sj qi note ci si qi ni 
take mean median estimates achieve estimate lower variance 
collisions high frequency items spoil estimates lower frequency elements important elements ok having element update counter replace counter hash table counters items update different subsets counters hash table 
way arrange matters element get high confidence estimates untainted collisions high frequency elements estimate frequency sufficient precision 
hi nq 
show making large decrease variance tolerable level making large approximately logarithmic sure estimates desired variance 
algorithm parameters values determined 
ht hash functions objects 
st hash functions objects 
countsketch data structure consists hash functions array counters interpreted array hash tables containing buckets 
data structure supports operations add hi si 
estimate return hi si 
take median mean 
answer final scheme eliminated problem collisions highfrequency elements spoil subset estimates 
mean sensitive outliers median sufficiently robust show section 
data structure algorithm straightforward simple implement 
element countsketch data structure estimate count keep heap top elements seen far 
formally data stream qn 
add qj 
qj heap increment count 
add qj heap estimate qj greater smallest estimated count heap 
case smallest estimated count evicted heap 
algorithm solves choice depend 
notice sketches share hash functions add subtract 
algorithm takes space tb 
section bound analysis notation easier read drop subscript qi simply write ambiguity 
abuse notation index assume hash function hi si pairwise independent 
functions hi si independent 
note amount randomness needed implement hash functions log 
log algorithm fails probability 
total randomness needed log log consider estimation frequency element position input 
nq number occurrences element position 
ai set elements hash bucket ith row ai hi hi 
elements ai frequent elements hi hi 
vi ai 
lemma 
variance hi si bounded vi 
lemma 

define analogously small event markov inequality pr small event ai contain top elements 
pr small event union bound hi si nq var hi si 
pr small 
pr small small express error estimates terms parameter defined follows lemma 
probability 
median hi si nq proof 
prove high probability indices hi si nq imply median hi si error bound claimed lemma 
observe index events small small occur hi si nq 
fixed pr hi si nq expected number indices 
chernoff bounds number indices probability eo setting log log lemma follows 
lemma 
probability median hi si nq element occurs position 
lemma 
max nk estimated top ele ments occur nk times sequence elements frequencies nk occur estimated top elements 
proof 
lemma estimates number occurrences elements additive factor true number occurrences 
elements true number occurrences differ estimates correctly identify frequent element 
setting nk ensure elements replace true frequent elements estimated top list elements true number occurrences nk 
nk nk nk combined condition prove proves lemma 
conclude summarization theorem 
count sketch algorithm solves space log nk log analysis zipfian distributions note algorithm ordered list estimated frequent elements frequent elements preceded elements number occurrences nk 
keeping track estimated frequent elements algorithm ensure frequent elements list 
happen chosen nl nk 
distribution zipfian parameter fact 
algorithm allowed pass true frequencies elements algorithms list determined allowing selection frequent elements 
section analyze space complexity algorithm zipfian distributions 
zipfian distribution parameter nq qz scaling factor 
omit calculations compare space requirements algorithm sampling algorithm problem 
bound lemma setting constant high probability algorithms list elements guaranteed contain frequent elements 
note log substituting bound lemma setting constant get bounds correct constant factors 
total space requirements obtained multiplying log 
case case case log compare bounds space requirements random sampling algorithm 
size random sample required ensure frequent elements occur random sample probability nk log 
measure space requirement random sampling algorithm expected number distinct elements random sample 
note size need constant turns occurrences cancel calculations ease presentation omit 
random sample larger number distinct elements due multiple copies elements 
furthermore sampling algorithm stated solves number distinct elements sample 
constitute solution algorithm 
reporting bounds sampling bounds 
gives sampling algorithm advantage 
analyze space usage sampling algorithm 
turns zipf parameter expected number distinct elements constant factor sample size 
analyze number distinct elements zipf parameter 
items placed random sample probability log pr log nq nk distinct elements pr log nq nk min nq log nk min kz log log bounds algorithms compared table 
zipf parameter random sampling count sketch algorithm log log log log log log log log log log table 
comparison space requirements random sampling vs algorithm nk finding items largest frequency change object sequence ns number occurrences streams find items values ns ns largest items adapt algorithm finding frequent elements problem finding elements frequencies change 
passes data 
pass update counters 
second pass identify elements largest changes number occurrences 
pass perform step hi si 
pass doing hi si 
second pass 
nq median hi si 

maintain set objects encountered largest values nq 

item maintain exact count number occurrences 
note change items removed added back 
accurate exact counts maintained currently 
report items largest values ns ns items give guarantee similar lemma nq replaced 
final note comparing count sketch algorithm sampling algorithm 
far neglected space cost storing elements stream 
different encodings yield different space 
algorithms need counters require log bits keep objects stream sampling algorithm keeps potentially larger set items stream 
example space object zipfian sampling algorithm uses log log space count sketch algorithm uses log space 
log practice give count sketch algorithm large advantage sampling algorithm 
max change problem note open problem finding elements max percent change objective functions balance absolute relative changes 
ach dimitris achlioptas 
database friendly random projections 
proc 
th acm symposium principles database systems pages 
ams noga alon yossi matias mario szegedy :10.1.1.102.5483
space complexity approximating frequency moments 
journal computer system sciences 
joan feigenbaum kannan martin strauss mahesh viswanathan 
approximate difference massive data streams 
proc 
th ieee symposium foundations computer science pages 
joan feigenbaum kannan martin strauss mahesh viswanathan 
testing spot checking data streams 
proc 
th acm siam symposium discrete algorithms pages 
min fang narayanan shivakumar hector garcia molina rajeev motwani jeffrey ullman 
computing iceberg queries efficiently 
proc 
nd international conference large data bases pages 
gg anna gilbert sudipto guha piotr indyk yannis kotidis muthukrishnan martin strauss 
fast small space algorithms approximate histogram maintenance 
appear proc 
th acm symposium theory computing 
gm phillip gibbons yossi matias 
new sampling summary statistics improving approximate query answers 
proc 
acm sigmod international conference management data pages 
gm phillip gibbons yossi matias 
synopsis data structures massive data sets 
proc 
th annual acm siam symposium discrete algorithms pages 
sudipto guha nina mishra rajeev motwani callaghan 
clustering data streams 
proc 
st ieee symposium foundations computer science pages 
goo google 
google search patterns trends surprises google 
www google com press html 
hrr monika henzinger prabhakar raghavan sridhar rajagopalan 
computing data streams 
technical report src tr dec 
ind piotr indyk 
stable distributions pseudorandom generators embeddings data stream computation 
proc 
st ieee symposium foundations computer science pages 
