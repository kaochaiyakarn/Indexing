modeling tcp latency neal cardwell stefan savage thomas anderson cardwell savage tom cs washington edu department computer science engineering university washington seattle wa usa analytic models describe steady state throughput bulk transfer tcp flows function round trip time packet loss rate 
models describe flows assumption long sustain packet losses 
tcp transfers today internet short see losses consequently performance dominated startup effects connection establishment slow start 
extends steadystate model proposed order capture startup effects :10.1.1.143.9137
extended model characterizes expected value distribution tcp connection establishment data transfer latency function transfer size round trip time packet loss rate 
simulations controlled measurements tcp transfers live web measurements show earlier steady state models tcp performance extended model describes connection establishment data transfer latency range packet loss conditions including loss 
today popular internet applications including world wide web mail file transfer usenet news remote login tcp transport protocol 
consequence tcp controls large fraction flows packets bytes travel wide area internet paths 
researchers proposed number analytic models characterize tcp performance terms round trip delay packet loss rate 
achieving better understanding sensitivity tcp performance network parameters models helped inform design active queue management schemes tcp friendly multicast protocols 
analytic models proposed date split broad classes models steady state bulk transfer throughput models short flows suffer packet loss 
majority models fit class focus characterizing bulk transfer throughput 
models successful predicting steady state throughput studies noted majority tcp flows traveling wide area internet short mean sizes kb median sizes kb 
flows short spend entire lifetime tcp slow start mode suffering single loss 
steady state models assume flows suffer loss undefined common case 
second class models focuses short flows suffer packet losses 
models consider delayed acknowledgments sender receiver buffering limitations alternative initial congestion windows losses connection establishment dramatic performance impact 
proposes new model tcp performance integrates results classes models 
particular extend steady state results deriving new models aspects dominate tcp latency connection establishment way handshake slow start :10.1.1.143.9137
simulation controlled measurements live web traces show new slow start model works tcp flows length suffer packet losses model works flows length suffer packet losses :10.1.1.143.9137
combined approach integrates models appropriate predicting performance short long flows varying packet loss rate conditions 
addition suggest technique estimating distribution data transfer latencies 
rest organized follows 
section ii describes new model relates models descended 
section iii compares connection establishment model simulations section iv compares data transfer model simulations tcp measurements traces 
section summarizes 
assumptions ii 
model extended model develop exactly assumptions endpoints network steady state model :10.1.1.143.9137
section describes assumptions detail including assumptions stated explicitly details large impact latency short tcp flows :10.1.1.143.9137
presentation model terminology notation :10.1.1.143.9137
assumptions endpoints assume sender congestion control algorithm tcp reno family refer readers details tcp reno style congestion control 
describe model terms simpler common tcp reno algorithm apply just newer tcp implementations newreno sack fack :10.1.1.41.2559
previous measurements suggest model faithful sophisticated algorithms resilient bursts packet losses 
focusing tcp performance general client server performance model sender re delays due scheduling buffering limitations 
assume duration data transfer sender sends full sized segments packets fast congestion window allows receiver advertises consistent flow control window 
similarly account effects nagle algorithm silly window syndrome avoidance minimized prudent engineering practice 
assume receiver typical delayed acknowledgment implementation sends acknowledgment ack data segments delayed ack heartbeat timer expires whichever happens 
linux example uses adaptive implementation delayed acks short flows technique modeled longer flows effect approach shave round trips 
failures active opener connection effectively established syn syn ack ack passive opener failures fig 

tcp connection establishment example 
assumptions network model tcp behavior terms rounds round starts sender begins transmission window packets ends sender receives acknowledgment packets 
assume time send packets window smaller duration round duration round independent window size 
note tcp reno congestion control true flow fully utilizing path bandwidth 
assume losses round independent losses round losses round correlated sense time packet lost packets round lost 
assumptions idealizations observations packet loss dynamics paths fifo drop tail queuing may hold links red queuing paths packet loss largely due link errors congestion 
assume probability packet loss independent window size hold flows fully utilizing link 
modeling data transfer assume packet loss happens direction sender receiver 
assumption acceptable low levels ack loss small effect large windows network paths congested direction data flow direction ack flow 
packet loss far drastic result connection establishment model packet loss directions considering connection establishment 
assumptions transfer share assumptions endpoints network relax key assumptions data transfer :10.1.1.143.9137
allow transfers short suffer packet losses zero losses dominated connection establishment delay initial slow start phase 
model overview model describes aspects tcp performance 
derive expressions expected value distribution time required connection establishment handshake begins tcp connection 
second derive expression expected latency transfer amount data describe methodology extrapolating distribution transfer latency 
separating connection establishment latency data transfer latency allows apply model applications establish single tcp connection independent data transfers 
connection establishment successful tcp connection begins way handshake endpoints exchange initial sequence numbers 
shows example 
initiating host typically client performs active open sending syn segment initial sequence number server performs passive open receives syn segment replies syn segment containing initial sequence number ack active opener initial sequence number 
active opener receives syn ack packet knows connection successfully established 
confirms sending ack passive opener initial sequence number 
stage process party receive ack expecting syn timeout initially seconds retransmits syn waits twice long response 
model process presence packet loss direction define forward packet loss rate path passive opener active opener forward usually primary direction data flow reverse packet loss rate 
average round trip delay hosts 
model way handshake consists stages 
active opener transmits syn times unsuccessfully th syn arrives successfully passive opener 
passive opener ignore dis syns active opener repeatedly retransmits syn ack receives response 
general send syn ack times unsuccessfully th syn ack arrives successfully active opener 
purposes model consider connection established point application protocols immediately sending ack active opener sends data segment passive opener contains redundant ack probability having way handshake episode consisting exactly failures transmitting syns followed successful syn followed exactly failures transmitting syn acks followed successful syn ack 
process latency data transfer 
deduce time spent slow start final congestion window slow start expected cost loss recovery 
steady state throughput approximate cost sending remaining data 
add extra cost delayed acks 
discuss aspects turn 
initial slow start assume transfer transfer connection transfer connection experienced losses 
circumstances tcp begins slow start mode quickly increases congestion window detects packet loss 
expected latency initial slow start phase depends structure slow start episode 
important cases 
case continuously detects packet loss 
second case cb eventually bounded maximum window sender sz imposed sender receiver buffer limitations 
determine case appropriate need sender sz 
probability latency way handshake episode tcp implementations abort connection establishment attempts failures 
loss rates low handshakes succeed tcp gives shown approximation expected handshake time jkl aed vu vu model assumes tcp implementation complies tcp specification 
model non compliant implementations current versions linux achieve slightly better performance responding retransmitted syn segments retransmitted syn ack segments 
vu vu ts data transfer defined data transfer begins application places data send buffer ends tcp receives acknowledgment byte buffer 
assume transfer sending application places data send buffer quickly sending tcp send fast window allows 
seg decompose data latency transfer ments aspects initial slow start phase resulting packet loss transfer remaining data added delay delayed acknowledgments 
calculating amount data expect send initial slow start phase encountering packet loss finishing number data segments expect sender send losing segment 
window expect tcp achieve slow start maximum window constraint 
window limitation effect simply time sender din exponential ifr growth mode slow start 
ddc andr hand dis time sender slow start send remaining data segments rate ifr segments round 
number data segments expect send initial slow start phase loss occurs including lost segment 
data dfe segment loss rate 
expect able send segments slow start hand assume loss rate independent sender behavior sor ally mln qi tio deduce time spent slow start 
slow start round sender sends data segments 
receiver sends ack th data segment receives round sender get pf acks 
sender slow start ack receives increases segment 
denote sender congestion window round denote rate exponential growth slow start ofz sender starts amount data sent slow start round xy segments li ip qi pf qit pw closely approximated geometric series solving number slow start rounds transfer data arrive loss tcp flows initial slow start phase ends detection packet loss 
slow start ends packet loss flow loss probability occurrence ways tcp detects losses retransmission timeouts rtos triple duplicate acks 
gives derivation probability sender congestion avoidance io window tcp achieves segments unconstrained slow start follows py detect packet loss rto function packet loss rate window size :10.1.1.143.9137
denote probability typical parameters equation implies put way reach congestion window flow needs send approximately ofx 
interestingly implies reach full utilization bandwidth delay product mbps ms kbytes tcp flow need transfer kbytes quantity larger wide area tcp flows transfer 
easy see internet flows spend lifetimes slow start observed 
calculate window size expect slow start constrained determine constrained slow start 
slow start proceeds phases 
flow send ln dxe probability sender detect loss triple qi tcp cate acks simply derived assumption sender congestion avoidance mode unbounded amount data send experience shown equally applicable slow start senders limited amount data 
largely quite insensitive rate growth senders limited amount data high risk rtos usually small windows 
practice suspect fast recovery strategy sender far greater impact senders sack fack newreno able achieve behavior predicted reno senders difficulty achieving performance encounter multiple losses single round 
expected cost rto derived average duration timeout sequence successive timeouts cb ud af cg fq segments phase :10.1.1.143.9137
take rounds 
second phase flow sends remaining data rate round take rounds 
combining case simpler case time segments slow start approximately 
expected cost fast recovery period depends number packets lost fast recovery strategy sender tcp implementation receiving tcp implementation returning selective acknowledgment sack options 
best case single loss sender sack information fast recovery takes single worst case newreno require lost packet 
experience indicates possibilities occurs usually important model predictions model sake simplicity assume fast recovery takes single combining results expected cost rtos fast recovery happens initial slow start phase jn xl ifr ej transferring remainder order approximate time spent sending data remaining slow start loss recovery estimate amount remaining data apply steady state model :10.1.1.143.9137
amount data left slow start loss recovery approximately approximation actual amount data remaining depend window loss luk occurs segments lost size congestion window loss time recovery algorithm 
model accurate cases simplification sake simplicity equation 
segments de left send approximate time transfer data steady state throughput model 
model gives throughput denote function loss rate round trip time average rto maximum window constraint ej 
expected congestion window time loss events congestion avoidance source error derives fact model slow start retransmission timeouts rtos 
loss rates error introduces small loss rates congestion avoidance throughput similar slow start rtos 
lower loss rates rtos uncommon 
occur long delays may overwhelm details growth 
rto durations vary widely 
average rto model duration specific short tcp flow introduce significant error 
ofz delayed acknowledgments delayed acknowledgments comprise final component tcp latency consider model 
number circumstances delayed acknowledgments cause relatively large delays short transfers 
common delay occurs sender sends mss 
case receiver waits vain second segment delayed ack timer fires sends ack 
bsd derived implementations delay uniformly distributed ms ms windows windows nt delay distributed uniformly ms ms 
delayed acks may lead large delays sender sends small segment nagle algorithm prevents sending segments sender sends segments full sized receiver implementation waits full sized segments sending ack 
simulations measurements senders mss model expected cost delayed ack expected delay reception single segment delayed ack segment ms bsd derived stacks ms windows 
ip combining results model expected time data transfer sum expected delays components including delayed ack cost results expected throughput approxi de mate expected time send remaining data model steady state throughput characterize cost transferring remaining data introduces errors 
sender detects loss initial slow start phase larger steady state combining analysis sender detect roughly loss indications value slow start steady state value loss rates higher sender exits slow start nearly steady state win vc dow value error approach small 
loss rates take loss indications corresponding megabytes data reach steady state approach overestimate latency transfers 
ls ls modeling distributions ls model prediction latency particular parameters experienced particular flow 
experience set transfers size high bandwidth delay path important determinants latency number losses average timeout duration cost delayed acks 
result approximate distribution latency set flows consider range possible loss rates delayed ack costs estimate likelihood scenario latency expected scenario 
section iv apply method simulations bernoulli loss model delayed ack costs uniformly distributed ms 
segments bandwidth bytes sec proposed kb proposed kb proposed kb proposed kb cumulative fraction simulated cdf modeled cdf simulated mean modeled mean approximate model frequency loss indications time sec fig 

comparing throughput predicted steady state models throughput predicted proposed model varying transfer sizes 
fig 

distribution mean connection establishment times model approximate 
model ns simulations sec mbytes 
segment comparison earlier models proposed model generalization previous approaches 
case packet losses reduces model time slow start mode 
special case corresponds closely simpler models derived 
case large total time dominated time transfer data loss 
case behavior corresponds closely underlying throughput model :10.1.1.143.9137
explores relationship proposed model models :10.1.1.143.9137
gives throughput predicted proposed model transfer sizes steady state throughputs predicted expression :10.1.1.143.9137
mentioned earlier expected loss proposed model agrees closely shown flows suffer losses :10.1.1.143.9137
hand losses proposed model predicts short flows suffer time reach steady long flows fv steady state value 
time sec simulated modeled approximate model forward loss rate fig 

expected connection establishment latency ns simulations trials loss rate model approximate model 
model comparing ns trials scenarios full model fits simulations approximate model diverges sharply approaches assumption unbounded wait times fails 
bytes ms iii 
verifying connection establishment model compares mean distribution connection establishment times mean approximate model mean distribution ns simulations ms bernoulli packet losses simulations implementation modeled closely bsd tcp implementation 
model approximation fit 
results similar scenarios 
summarizes performance full approx iv 
verifying data transfer model simulations flows loss simulated tcp flows suffer packet loss expression describes tcp behavior closely shows 
depicts simulated modeled latency tcp transfers simulated ns 
simulation sender transfers data gbit link receiver 
link buffers provisioned prevent packet loss 
trials consisted cross product modeled transfer time rtt modeled time simulated time simulated transfer time rtt fig 

simulated latency tcp data transfers experienced packet loss compared modeled latency equivalently 
cumulative fraction time sec simulated cdf simulated mean proposed proposed cdf fig 

distribution mean latencies experiment described 
bandwidth bytes sec simulated proposed bandwidth bytes sec simulated proposed frequency loss indications fig 

scatter plot simulated performance model predictions overlaid 
kbyte transfers bytes ms frequency loss indications fig 

scatter plot simulated performance model predictions overlaid 
mbyte transfers bytes ms delayed bytes segments segments ms model agrees quite closely acks simulations average error average relative error 
outliers correspond trials window just segments throughput hurt ms delayed ack timer recipient mis aligned ms ack clocking employed sender 
flows suffering losses figures illustrate match performance flows suffer moderate high levels loss :10.1.1.143.9137
shows scatter plot depicting bandwidth loss rate experienced simulated flows model predictions overlaid 
flow transferred cumulative fraction simulated cdf simulated mean proposed proposed cdf time sec fig 

distribution mean latencies experiment described 
mbytes segment mbytes segment ms ms transfer time sec measured proposed slow start proposed full data transferred bytes fig 

measured modeled latencies transfers university washington uc davis 
kbytes path synthetically generated bernoulli losses average loss rate proposed model fits trials experience packet loss provide reasonable fit trials experience loss :10.1.1.143.9137
shows distribution latencies trials 
capture average latency modeled distribution derived technique described section ii provides reasonable characterization distribution latencies :10.1.1.143.9137
considerable variance latency case flows completing half average time flows half long average time 
experience technique yields approximation latency distribution packet losses provide fit average latency :10.1.1.143.9137
figures provide corresponding view long transfers mbyte paths low loss rates 
proposed model captures average latency latency experienced half flows see loss 
predicts performance seen flows experience single loss flows enter congestion avoidance az larger steady state value :10.1.1.143.9137
preliminary results characterizing dynamics converges steady state value slow start 
possible capture aspects behavior long flows suffer losses approach lines 
ofz controlled internet measurements order examine proposed model fits tcp behavior internet performed number tcp transfers linux sender university washington internet sites 
shows example 
depicts latency transfers varying sizes university california davis predictions average packet loss rate trials :10.1.1.143.9137
average loss rate cumulative fraction proposed model error rtt fig 

error modeled measured proposed model measurements flows suffered packet losses 
note normalized error model actual time flows 
cumulative fraction proposed model relative error fig 

relative error models measurements flows suffered triple duplicate acks rtos 
consequence flows suffered losses fits quite :10.1.1.143.9137
live measurements order various tcp models describe typical tcp data transfers compared set traces 
traces consist client side packet level traces tcp flows transporting single get operations wget web clients connected universities university washington seattle university california berkeley duke university web servers spread 
servers chosen web popular sites determined analysis web proxy logs 
remaining servers chosen random yahoo database web sites 
get operation fetched index html object site average size cumulative fraction proposed model relative error fig 

relative error models measurements flows suffered rtos 
objects kbytes 
flow extracted total data transfer time defined period starting data segment arrived client data segment arrives client minus delay due delayed acks 
extracted mss initial window size estimated receiver oriented techniques described 
estimate number fast retransmit events observing data segments arriving corresponding triple duplicate acks 
estimate number average duration timeouts heuristics including arrival duplicate data segments arrival data segments fill sequence space hole ms old arrival order data segments arrive idle period second 
split flows classes character losses suffered 
flow examine error measured latency predictions models observed flow :10.1.1.143.9137
shows normalized error latency predictions flows suffered packet loss 
show proposed model models undefined cb model predictions actual transfer times :10.1.1.143.9137
turning relative error median relative error cases meaning flows suffered loss actual transfer latency 
shows relative error latency predictions flows suffered losses able recover losses fast retransmit fast recovery 
models provide similar predictions 
similarly shows relative error latency predictions flows suffered retransmission timeouts 
model fits poorly assumes timeouts occur 
models significant error :10.1.1.143.9137
note presence packet loss provide similar predictions :10.1.1.143.9137
new models tcp connection establishment tcp slow start 
models extend steady state model assumes packet loss characterize latency tcp flows suffer packet losses :10.1.1.143.9137
simulation measurement connection establishment model promising new extended data transfer model characterizes flows varying lengths varying loss conditions 
furthermore described technique estimating distribution latencies tcp transfers showed simulations suggesting method approximate wide distribution data transfer latencies range conditions 
acknowledgments arnold kim suggesting technique derive sally floyd neil spring providing comments earlier drafts jitendra padhye providing analysis scripts robert morris providing traces john zahorjan anna karlin providing advice encouragement 
mark allman vern paxson 
estimating network path properties 
sigcomm august 
mark allman vern paxson stevens 
tcp congestion control 
rfc april 
hari balakrishnan venkata padmanabhan srinivasan seshan randy katz mark stemm 
tcp behavior busy internet server analysis improvements 
infocom april 
hari balakrishnan mark stemm srinivasan seshan randy katz 
analyzing stability wide area network performance 
sigmetrics june 
thomas gross urs 
bandwidth modelling network aware applications 
infocom march 
bolot turletti 
experience rate control mechanisms packet video internet 
computer communications review january 
bolot vega garcia 
control mechanisms packet audio internet 
infocom march 
braden 
requirements internet hosts communication layers 
rfc october 
claudio meo 
new approach model stationary behavior tcp connections 
infocom march 
claffy greg miller kevin thompson 
nature beast traffic measurements internet backbone 
proceedings inet july 
carlos cunha azer bestavros mark crovella 
characteristics www client traces 
technical report bu cs boston university july 
sally floyd 
connections multiple congested gateways networks part way traffic 
computer communications review october 
sally floyd kevin fall 
promoting congestion control internet 
ieee acm transactions networking august 
sally floyd tom henderson 
newreno modification tcp fast recovery algorithm 
rfc april 
sally floyd van jacobson 
random early detection gateways congestion avoidance 
ieee acm transactions networking august 
steven gribble eric brewer 
system design issues internet middleware services deductions large client trace 
usits december 
john heidemann 
performance interactions tcp implementations 
computer communications review april 
john heidemann katia obraczka joe touch 
modeling performance transport protocols 
ieee acm transactions networking october 
www hot com 
van jacobson 
congestion avoidance control 
sigcomm august 
anurag kumar 
comparative performance analysis versions tcp local network lossy link 
ieee acm transactions networking august 
lakshman madhow 
performance tcp ip networks high bandwidth delay products random loss 
ieee acm transactions networking june 
bruce mah 
empirical model network traffic 
info com april 
jamshid mahdavi 
tcp performance tuning 
www psc edu networking slides april 
sam 
implications transport layer network dimensioning 
phd thesis ecole polytechnique de lausanne 
mathis mahdavi 
forward refining tcp congestion control 
sigcomm august 
mathis semke mahdavi ott 
macroscopic behavior tcp congestion avoidance algorithm 
computer communications review july 
matt mathis jamshid mahdavi sally floyd allyn romanow 
tcp selective options 
rfc april 
greg yasushi saito jeffrey mogul ben verghese 
application performance pitfalls tcp nagle algorithm 
workshop internet server performance may 
misra ott 
window distribution idealized tcp congestion avoidance variable packet loss 
infocom march 
ucb lbnl vint network simulator ns version 
ott lakshman larry wong 
stabilized red 
infocom march 
jitendra padhye victor firoiu don towsley 
stochastic model tcp reno congestion avoidance control 
technical report university massachusetts 
jitendra padhye victor firoiu don towsley jim kurose :10.1.1.143.9137
modeling tcp throughput simple model empirical validation 
sig comm september 
craig partridge timothy shepard 
tcp ip performance satellite links 
ieee network pages september october 
vern paxson 
internet packet dynamics 
sigcomm september 
jon postel editor 
transmission control protocol darpa internet program protocol specification 
rfc september 
lili qiu yin zhang keshav 
individual aggregate tcp performance 
technical report tr cornell university may 
stefan savage 
sting tcp network measurement tool 
usits october 
www ens fr html december 
kevin thompson gregory miller rick wilder 
wide area internet traffic patterns characteristics 
ieee network november 
rizzo crowcroft 
tcp congestion control layered multicast data transfer 
infocom april 
yahoo 
random yahoo 
link 
random yahoo com bin 
maya yajnik sue moon jim kurose don towsley 
measurement modelling temporal dependence packet loss 
infocom march 
