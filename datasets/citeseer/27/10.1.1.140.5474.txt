interior point method semidefinite programming christoph franz rendl robert vanderbei henry wolkowicz january program statistics operations research princeton university princeton nj january revised october propose new interior point method minimize linear function matrix variable subject linear equality inequality constraints set positive semidefinite matrices 
show approach efficient graph bisection problems max cut 
applications include max min eigenvalue problems relaxations stable set problem 
key words semidefinite programming interior point methods max cut relaxations max min eigenvalue problems 
ams subject classification primary secondary technische universit graz institut mathematik graz austria 
research support christian doppler optimierung 
technische universit graz institut mathematik graz austria 
research support christian doppler optimierung 
research support afosr afosr 
department combinatorics optimization university waterloo waterloo ont canada 
author department civil engineering operations research princeton university support stay research leave 
national science engineering research council canada support 

continuously rising success interior point techniques applied linear programming stimulated research various related fields 
possible line generalization consists looking linear programs non polyhedral cones 
type generalization studied 
specific mn denote vector space symmetric matrices 
suppose mn mn linear operators mn study optimization problem sdp maximize tr cx subject 
semidefinite linear program optimize linear function subject linear inequality equality constraints positive semidefinite matrices note inequality constraints transformed equality constraints introducing slack variables 
case replaced direct sum matrices corresponding slacks 
main motivation study kind problem comes applications discrete optimization 
particular investigate new powerful tractable relaxation max cut problem graph bisection problems 
max min eigenvalue problems affine parameter space fall framework handled approach 
main contribution propose primal dual interior point algorithm problem sdp 
discuss implementation details computational experiments indicating approach highly efficient practice 
close section describing research related 
alizadeh overton consider problem similar :10.1.1.35.4131
algorithmically authors interior point techniques solve problem 
alizadeh proposes potential reduction method shows polynomial running time find optimal solution 
uses barrier approach works directly dual 
overton studies problem nonlinear equality constraints 
formulations form easy exercise transform model :10.1.1.35.4131
vandenberghe boyd study primal dual potential reduction algorithms semidefinite programs see 
monotone linear complementarity problem symmetric matrices investigated 
authors interior point approaches type semidefinite program 
general framework interior point methods applied convex programs monograph 
preliminaries collect preliminary results notation 
mainly space mn symmetric matrices endowed inner product tr uv 
curly inequality symbol refers partial order induced cone positive semidefinite matrices means positive semidefinite positive definite respectively 
contrast usual inequality symbol refers partial order induced cone nonnegative vectors 
maximum eigenvalue denoted max 
matrices uij vij size denotes hadamard product 
ij uij vij 
associated linear operator mn linear operator denote defined adjoint relation mn angle bracket inner product mn convex cone denote dual cone 
slight abuse notation real function defined real domain vector occasionally write 
vn 
usually logarithm power function 
mn diag denote vector consisting diagonal elements analogously vector diag denote diagonal matrix mn diagonal elements obtained duality general duality theory problems sdp thoroughly studied see 
derive dual sdp directly lagrangian methods 
denote optimal objective value sdp 
introducing lagrange multipliers equality inequality constraints respectively see max min min max tr cx tr note inner maximization bounded 
case maximum occurs complementarity holds get weak dual dsdp 
dsdp tr 
minimize subject 
duality gap interchanging max min vanishes additional assumptions lagrangian 
tacitly assume problems feasible solutions 
constraint qualification holds shown problems form pair dual problems strong duality holds minimum attained sdp coincides maximum attained dsdp see 
sufficient condition strong duality hold existence strictly feasible interior points primal dual problem 
weak duality max equal min holds construction 
applications focus special case diag case diag 
developing algorithm sdp show section type problem provides strong machinery deriving tight bounds basic np hard optimization problems 
applications max cut problem max cut problem problem partitioning node set edge weighted undirected graph parts maximize total weight edges cut partition 
tacitly assume graph question complete edges weight complete graph 
mathematically problem formulated follows see 
graph weighted adjacency matrix define matrix diag ae vector ones 
matrix called laplacian matrix associated graph 
cut represented vector xi depending get formulation max cut problem 
mc equivalent maximize xt lx subject maximize tr lx subject diag rank 
dropping rank condition obtain problem form sdp inequalities diag 
relaxation max cut known studied 
goemans williamson shown optimal value relaxation value maximum cut provided negative edge weights exist 
variable interpreted defined edge set complete graph 
add linear constraints satisfied edge vectors representing cuts 
class constraints obtained trivial observation 
consider arbitrary triangle vertices graph partition cuts edges 
translated model leads xij xik xjk 
note model edge cut xixj xij constraint states edges cut 
constraints state edge cut edge lie cut 
collect constraints triangles operator leads dim vector 
get stronger relaxation max cut proposed maximize tr lx subject diag 
dropping constraint obtain ordinary linear program relaxation max cut 
relaxation usually called metric relaxation polyhedron diag referred metric polytope see 
point lp variables roughly sparse constraints 
polyhedron turns highly degenerate considered computational challenge optimize arbitrary linear function polytope say 
graph planar metric relaxation provides max cut see 
graph bisection graph bisection similar max cut problem seek partition node set sets prespecified cardinalities say important special case occurs 
case looks partition node set sets equal size minimize weight cut problem usually formulated minimization maximization problem 
additional cardinality constraint translates xi 
bs minimize xt lx subject xi 
analogy max cut obtain relaxation minimize tr lx subject diag tr xj 
ee matrix ones 
note constraint tr jx obtained squaring cardinality constraint tr jx 
relaxation studied treated min max eigenvalue problem nonsmooth optimization techniques 
theoretical investigation bound boppana 
maximum cliques graphs semidefinite programs conjunction stable set clique problems graphs see 
suppose graph vertices edge set define eij eje ej column identity matrix size ee matrix ones size semidefinite program introduced provides upper bound largest clique optimal objective function program usually denoted 
maximize tr jx subject tr tr 
ij note number equality constraints 
small dimension dual may quite large 
min max eigenvalue problems min max eigenvalue problem studied min max 
mn mn linear operator 
overton considers general case allowing nonlinear 
known problem reformulated sdp problem dual minimize subject 
maximize tr cx subject tr 
note complementary slackness optimality implies zx 
dual feasibility implies eigenvectors optimal eigenvalue columns strict complementary slackness holds rank rank rank equals multiplicity optimal eigenvalue 
applications combinatorial optimization problems described :10.1.1.35.4131
interior point method sdp section develop primal dual interior point method solves sdp dsdp simultaneously 
nature approach requires exists strictly satisfying inequalities primal problem 
furthermore assume loss generality equality constraints linearly independent rank apply operators nonsymmetric matrices extend definition mapping skew symmetric part zero 
implies 
follow usual derivation primal dual interior point methods linear programming introduce associated barrier problem dsdp call dual barrier problem dbp minimize log det log subject 
positive real number called barrier parameter 
corresponding lagrangian bt log det log bt 
order optimality conditions saddle point lagrangian obtained easily adjoint identity xl yl tl zl 
strict concavity log det log ti implies exists unique solution optimality conditions 
parameter family called central trajectory 
point central trajectory easy determine associated value tr zx tt tr zx tt 
note point feasible solution primal dual problem tr zx gap primal dual objective value 
shall associate values quadruples quadruples don belong central trajectory 
interior point algorithm derived follows 
start quadruple arbitrary 
point estimate current value divide tr zx tt 
experience linear programming indicates simple heuristic performs guarantee monotonic decrease see 
attempt find directions new point lies central trajectory value 
defining equations linear possible solve system directly 
fact nonlinear 
written equivalent forms form giving rise different linearization 
give detailed discussion possibilities section restricted 
algorithm linearization form zx 
simplicity notation rewrite function bt zx fd fp 
solution satisfies karush kuhn tucker conditions optimal solution barrier problem 
find direction newton method says satisfy 
direction solution system fd fp zx 
linear system solved 
solve obviously symmetric terms substitute expression get fd fdx 
evidently symmetric general 
substituting expression get equation linear operators defined vector substitute get linear operators defined vector fdx 
fdx 
operators self adjoint operator adjoint operator 
equations form symmetric linear system fact system positive definite 
show define new operator maps mn adjoint operator adjoint identity system written having component ti 
summand get 
observe second summand adds positive coefficients main diagonal entries corresponding inequality constraints 
fact increment main diagonal difference inequality equality constraints 
second summand clearly forms positive semidefinite operator positive definite vectors tr 
positive definite equality constraints linearly independent equality possible ti 
follows system positive definite 
solved efficiently 
observe equivalent representation operator tr 
tr ak mx ai appropriately chosen symmetric matrices 
ij th element matrix describing reads tr ajx 
solution yields quadruple necessarily symmetric 
symmetric part xt 
summarize solve quadruple solving substituting solve substituting solve take symmetric part 
section show yields descent direction 
having determined desired quadruple directions step new quadruple violate nonnegativity positive definiteness property required matrices 
perform line search find constants strictly positive positive definite 
step new point update repeat 
algorithm continues current quadruple satisfies primal feasibility dual feasibility duality gap sufficiently small 
completes description interior point algorithm 
descent direction modified newton direction optimality conditions 
shed light quality direction prove forms descent direction respect appropriately defined merit function 
measure progress algorithm merit function 
type merit function 
log det xz log fp fd feasible points merit function difference objective values dual primal barrier functions 
convex set feasible points 
minimum log attained function bounded log 
note log 
continuously differentiable interior grows infinity boundary 
lemma prove defined page descent direction 
lemma directional derivative direction satisfies equality holding 
sf proof 
prove xf yf tf zf partial derivatives xf yf tf tfp zf summing directional derivative partial derivatives fp get tfp fp fp fp third line follows fourth 
analogously get fd step observe symmetric matrix skew symmetric part orthogonal symmetric matrices 
tr zx tr zx tr zx zx zx zx positive definite eigenvalues zx strictly positive 
expression equal zero equals zero zx 
quite manner get strictly positive expression equal zero equals zero 
summing fp fd zx zx equality holding holds 
inaccurate line search respect merit function feasible starting point sufficient guarantee convergence elementary proof :10.1.1.140.5474:10.1.1.140.5474
need true arbitrarily chosen infeasible starting points 
computational evidence claim contained :10.1.1.35.4131
strong results rate convergence obtained tightly restricting choice stepsize 
independent kojima hara propose framework semidefinite complementarity problem 
framework give variants algorithms leading polynomial convergence 
methods close setting give details 
complementarity problem asks point lies dimensional affine subspace satisfies complementarity condition tr zx find pair lcp tr xz 

denote eigenvalues xz 
tr zx horn neighborhood central trajectory introduced 
width neighborhood controlled 
neighborhood convenient property theorem reducing factor newton step 
furthermore new value new point smaller old value factor 
algorithm yields sequence 
tr tr 
require tr algorithm log tr iterations 
practical applications strict requirements choice violated benefit efficiency 
give short discussion linearization stemming equivalent formulations condition zx 
ease notation restrict investigation equality constraints drop inequality operator possibilities 
xz zx zx xz zx xz 
linearizations popular linear programming case diagonal matrices 
forms really involve matrix square roots 
semidefinite programming case involve matrix square roots computationally attractive 
linearization third form leads algorithm 
case equation reads note information primal variable contained equation 
pure dual approach 
resulting direction primal variable poor 
confirmed practical experiments 
analogously linearization leads xa xa fp formulation 
time step mainly primal variable 
linearization considered pure primal approach 
linearization choice 
easy see results step 
linearization just transpose algorithm 
cases direction contains information primal dual variables equal degree 
linearizations especially suited mehrotra lp predictor corrector method described 
statements apply linearization discussed :10.1.1.35.4131
advantage linearization preserves symmetry 
furthermore alizadeh overton evidence numerical properties 
system difficult solve computation time iteration considerably higher 
computational results interior point approach max cut section show max cut relaxation section implemented efficiently framework 
look relaxation triangle inequalities 
resulting program simple solved quite large fast see table 
cost matrix laplacian weighted adjacency matrix graph 
sdp forming relaxation reads maximize subject diag 
diag adjoint diag dual sdp reads starting point minimize subject diag 
diag abs diag feasible interior 
look equation get diag diag diag 
means iteration solve system computing diag diag zx 
emphasize simplicity ease implementation approach include section matlab function solves relaxation 
problems sizes efficient code reader encouraged test 
numerical results table computed mhz pc encoded version algorithm 
point number iterations depend significantly tables hh gives number hours mm number size iterations hh mm ss table sdp relaxation max cut computed mhz pc minutes ss seconds 
instances generated random unweighted graphs edge probability 
set stopping condition digits accuracy matlab routine appendix 
second experiment looked max cut relaxation formed intersection triangle inequalities constraints see section 
included triangle constraints turned favorable mehrotra predictor corrector approach closely investigated 
case system solved twice factorization different right hand sides 
right hand side chosen minimize objective 
second step computes centering direction predicted point estimate previous iteration 
triangle inequalities included successively amount violation detailed description algorithm reader referred :10.1.1.140.5474
results random graphs table 
time best cut relaxation triangles improved 
constructed rounded rows giving initial cut 
applied local improvement strategy cut considering swapping single node side side cut 
swap improved cut chose swap highest gain 
stopped improvement obtained way 
note semidefinite programs equality inequality con straints dual program 
final solution satisfies constraints 
number iterations necessary obtain results small see column table 
explicit solution problems satisfies inequality constraints 
approach depend structural properties underlying graph 
significantly extends purely polyhedral techniques maxcut 
substantial computational results approach applied max cut :10.1.1.140.5474:10.1.1.140.5474
function section give computational results function defined section 
convenience reader give corresponding primal dual pair semidefinite random graphs edge weights 
size cut upper bnd hh mm ss iterations random unweighted graphs edge probability size cut upper bnd hh mm ss iterations table solutions max cut relaxation triangle inequalities 
number nodes graph cut refers best cut upper bnd value relaxation percentage gap relaxation best cut 
column gives computation times decstation 
note number iterations independent gap closed 
programs maximize tr jx subject tr ij tr 
starting point feasible interior point yij ij minimize subject ij yij ij tested code random graphs class gn graphs vertices edge ij set probability order reader able reproduce graphs include source code written generate pseudo random graphs 
generating adjacency matrix called random number generator parameters seed prob 
double double seed int int fmod prob results choices seed prob displayed table 
code employed predictor corrector approach separate primal dual stepsizes 
program written executed dec station 
number primal constraints dual variables number plus 
computing times strongly depend number independent long number iterations quite independent number constraints 
min max eigenvalue problems consider min max eigenvalue problem minimize max diag subject 
seed prob size hh mm ss iterations table function random graphs 
objective function differentiable multiplicity largest eigenvalue exceeds 
fact singleton eigenvalue characterizes differentiability 
largest eigenvalue convex function subgradient approaches solve see 
shown newton algorithms local quadratic convergence exist see local convergence depends correctly identifying multiplicity largest eigenvalue 
computational experiments showing interior point method robust presence high multiplicity 
minimizing set diag substituting see special case general problem minimize subject diag 
matlab code appendix applies problem 
test code problem instances exhibit multiplicity optimal solution developed special generator describe 
generate positive semidefinite programs generate elements uniformly interval nonnegative half line primal problem clearly infeasible component negative 
experiments described generate follows 
generate random matrix apply row scaling squared row norms equal corresponding elements diag aa 
denote columns 
vm 
construct additional random vm 
vn apply gram schmidt 
vn produce time hh mm ss bt ip table statistics problems multiplicity 
bt refers bundle trust method ip refers interior point method 
time hh mm ss comments bt ip num 
trouble bt sig 
fig 
bt sig 
fig 
bt attempt bt table statistics problems higher built multiplicity 
bt refers bundle trust method ip refers interior point method 
orthogonal matrix columns span space 
vm 
set diagonal matrix entries set max constant chosen arbitrarily remaining diagonal entries generated uniformly interval strictly smaller max 
matrix claim aa diag optimal 
follows feasible primal clear feasible dual 
optimality follows absence duality gap tr zx tr maxi aa equality follows fact columns eigenvectors associated maximal eigenvalue 
table shows comparison bundle trust method see interior point method optimal eigenvalue singleton 
problems bundle trust method times faster computing times silicon graphics indigo workstation 
situation arises practice 
construction see requiring vector ones maximal eigenvector clearly event real applications 
table shows comparisons higher multiplicities 
results look better interior point method 
fact clear bundle trust method completely breaks rapidly multiplicity increases 
matlab implementation matlab function solves semidefinite programming problem described diag inequality constraints 
include emphasize simplicity interior point approach 
assume matlab version available positive definiteness test matlab built function 
program run older versions matlab 
somewhat arbitrarily set stopping condition digits accuracy 
successful termination return primal dual feasible solutions objective values agree approximately digits 
practical experiments proved unnecessary check decrease merit function 
feature included algorithm 
mention case large steps select new value 
function phi psd ip solves max trace lx psd diag ones min diag psd unconstrained input symmetric matrix output phi optimal value primal phi trace lx optimal primal matrix optimal dual vector call phi psd ip digits significant digits phi size problem size ones works just diag initial primal matrix pos 
def 
sum abs initial chosen diag initial dual slack pos 
def 
phi initial dual psi primal costs mu initial complementarity iter iteration count disp iter gap lower upper phi psi max abs phi digits iter iter start new iteration zi inv inv needed explicitly zi zi zi dy zi mu diag zi solve dy dx zi diag dy mu zi back substitute dx dx dx dx line search primal initial dummy dx test pos def dummy dx stay away boundary line search dual dz handled implicitly dz diag dy dummy diag dy dummy diag dy update dx dy diag dy mu mu mu speed long steps phi psi display current iteration disp iter phi psi psi phi main loop 
anonymous referees associate editor constructive comments earlier versions 
critical remarks helped improve 
anstreicher 
vial 
convergence infeasible primal dual interior point method convex programming 
technical report universit de gen switzerland 
alizadeh 
combinatorial optimization interior point methods semidefinite matrices 
phd thesis university minnesota 
alizadeh :10.1.1.35.4131
interior point methods semidefinite programming applications combinatorial optimization 
appear siam optimization 
alizadeh overton :10.1.1.35.4131
title primal dual interior point methods semidefinite programming 
programming 
technical report 
barahona 
max cut problem graphs contractible 
operations research letters 
boppana 
eigenvalues graph bisection average case analysis 
proceedings th annual symposium computer science ieee 
carpenter lustig mulvey shanno 
higher order predictor corrector interior point methods application quadratic objectives 
siam optimization 
cullum donath wolfe 
minimization certain nondifferentiable sums eigenvalues symmetric matrices 
mathematical programming study 
delorme poljak 
laplacian eigenvalues maximum cut problem 
mathematical programming 
rendl wolkowicz 
computational study graph partitioning 
technical report corr department combinatorics optimization waterloo ont 
appear math 
programming 
goemans williamson 
approximation algorithm max cut max sat 
technical report mit 

finding maximum cut planar graph polynomial time 
siam computing 
:10.1.1.140.5474
interior point method semidefinite programming max cut bounds 
phd thesis graz university technology oct 

interior point method minimizing maximum eigenvalue linear combination matrices 
siam control optimization 

interior point methods self concordance relative lipschitz condition 
university march 
kojima hara 
interior point methods monotone linear complementarity problem symmetric matrices 
technical report department information sciences tokyo institute technology apr 
laurent poljak 
metric polytope 
proceedings ipco balas kannan eds 
lov sz 
shannon capacity graph 
ieee transactions information theory 
mohar poljak 
eigenvalues combinatorial optimization combinatorial graph theoretic problems linear algebra klee eds ima volumes mathematics applications vol 
springer verlag 
nesterov nemirovskii 
interior point polynomial methods convex programming theory algorithms 
siam publications 
siam philadelphia usa 
overton 
minimizing maximum eigenvalue symmetric matrix 
siam matrix analysis applications 
overton 
large scale optimization eigenvalues 
siam optimization 
overton 
second derivatives optimizing eigenvalues symmetric matrices 
technical report computer science department nyu 
poljak rendl 
relaxations graph bisection problems 
technical report university technology graz 
appear siam optimization 
rendl vanderbei wolkowicz 
max min eigenvalue problems primal dual interior point algorithms trust region subproblems 
technical report corr department combinatorics optimization waterloo ont appear proceedings nato conference nonlinear programming il italy 

version bundle idea minimizing nonsmooth function conceptual idea convergence analysis numerical results 
siam optimization 
vandenberghe boyd 
primal dual potential reduction method problems involving matrix inequalities 
technical report electrical engineering department stanford university stanford ca 
appear mathematical programming series vanderbei carpenter 
symmetric indefinite systems methods 
mathematical programming 

vial 
computational experience primal dual interior point method smooth convex programming 
appear optimization methods software 
wolkowicz 
applications optimization matrix theory 
linear algebra applications 

