address translation storage management persistent object stores vinod kakkad dissertation faculty graduate school university austin partial ful llment requirements degree doctor philosophy university texas austin december copyright vinod kakkad address translation storage management persistent object stores approved dissertation committee wife mattered acknowledgments getting ph incredibly hard done help support people 
foremost advisor paul wilson originally encouraged transfer master program doctoral program 
years learned lessons academic paul helped steer right problems issues 
iwould members dissertation committee particularly don batory source constant encouragement helped administrative obstacles life graduate student 
iwould past members oops research group particular mark johnstone scott kaplan directly indirectly contributed dissertation 
fortunate vivek singhal je thomas close friends helped di erent ways including providing moral support hard 
years sta members department computer sciences life easier particular fletcher best systems administrator known gone way help resolve problem hand continue making progress helpful friendly graduate secretary lost student ask done 
special acknowledgment goes motorola nancial support year especially colleagues somerset design center austin understanding patient dissertation requirements con duties times 
parents laws brother mona bala trust faith abilities giving am deeply grateful love positive energy showed hard bottom heart 
friends particularly sanjay dave maria supporting ambitions believing achieve goals 
owe debt gratitude wife best friend un love support years 
put erratic seemingly crazy behavior needed friendly shoulder hug 
dissertation possible orts dedicate courage shown years 
vinod kakkad university austin december vi address translation storage management persistent object stores publication 
vinod kakkad ph university austin supervisor paul wilson common problem software engineering ciently saving state application data structures non volatile storage program executions 
accomplished normal le systems programmer forced explicitly save data les stream uninterpreted bytes losing pointer semantics object identity 
better approach object storage natural extension virtual memory allows heap data saved automatically disk maintaining topology data structures explicit programmer intervention 
persistent object stores replace functionality normal le systems able address large volumes data ciently standard hardware 
highperformance address translation techniques necessary important supporting large address spaces stock hardware 
pointer swizzling page fault time ps coarse grained address translation scheme suitable purpose demonstrate building persistent storage system called texas persistent store 
discuss alternative approaches portably incorporating ne grained address translation texas situations coarse grained swizzling insu cient 
part performance results detailed analysis various components coarse grained address translation technique including comparison costs 
pointer swizzling requires run time knowledge memory object layouts locate pointers objects 
developed implemented run time type description rttd purpose implementation strategy portable novel compiler generated debugging information extracting necessary type description 
rttd useful applications data structure browsing advanced pro ling tracing 
vii part research interaction systems similar ps operating systems particularly regarding virtual memory management issues 
suggest areas operating system implementations open improve performance extensibility 
brie discuss storage management issues speci cally log structured storage disk prefetching compressed memory storage provide directions research area 
viii contents acknowledgments list tables list figures vii xiv xv chapter scope dissertation thesis motivation cost orthogonal persistence overview contributions advanced issues organization dissertation chapter design issues persistence background persistence types persistence approach address translation taxonomies eager vs lazy swizzling node marking vs edge marking schemes general classi cation persistence granularity choices persistence address translation address mapping data fetching data caching checkpointing fine grained address translation ix basic costs object replacement discussion survey related persistent programming languages external libraries approaches chapter pointer swizzling page fault time motivation algorithm description mistaken dirty pages problem bug feature 
observations discussion handling large objects avoiding address space exhaustion smaller page sizes address space reuse fine grained mixed granularity translation sharing compatibility data formats sharing machines linking existing code interfacing languages compilers fine grained mixed granularity translation smart pointers fine grained address translation mixed granularity address translation chapter design implementation texas persistent store goals features basic design implementation details heap management caching virtual memory abstraction layer run time type description handling virtual function table pointers disk storage management chapter performance texas persistent store experimental design benchmarks methodology hardware operating systems instruction count pro ling results performance linux large database results small database results analysis performance solaris large database results small database results large database results raw small database results raw large database results bigger memory size analysis comparison address translation granularities discussion basic argument impact operating system implementations indirect costs pointer swizzling benchmarking limitations synthetic benchmarks common problems oo oo benchmarks summary chapter run time type description rttd issues motivation rttd vs rtti type descriptor records preprocessors vs debugging information adapting compiler support rttd generation manipulation generating type descriptor records associating type descriptor records objects compilation linkage model rttd multiple compilation units xi rttd overview implementation details handling multiple compilation units type names added flexibility complications enhancements storage model hierarchical format flat format performance characteristics compile time costs run time costs making decoding costs negligible current status related chapter interactions operating systems background virtual memory basic terminology virtual memory allocation storage space vs address space allocation virtual memory primitives performance virtual memory primitives issues swap space allocation ps swap space allocation survey existing implementations discussion pointer swizzling virtual memory management control memory management discussion operating system features exception handling virtual memory page size sub page protections support raw chapter storage management log structured storage system adaptive prefetching compressed memory storage xii advanced issues chapter address translation granularity choices persistence run time type description operating system interactions storage management issues final words appendix hierarchical type graph bibliography vita xiii list tables estimated instruction counts cost handling access protection violation xiv list figures node marking edge marking schemes node marking proxy objects bootstrap state swizzling incremental faulting swizzling incremental faulting swizzling cont wavefront address space reservation basic design texas logging mechanism timer placements run time measurements times traversals large database linux times traversals large database log scale linux times traversals large database linux times traversals large database linux times traversals large database linux times traversals large database linux times traversals large database linux times traversals large database linux page faults traversals large database linux overhead percentage time large database linux overhead percentage total time large database linux times traversals small database log scale linux times traversals small database linux times traversals small database linux times traversals small database linux times traversals small database linux page faults traversals small database linux overhead percentage time small database linux overhead percentage total time small database linux times traversals large database solaris page faults traversals large database solaris benchmark time traversals large database solaris xv overhead percentage time large database solaris overhead percentage total time large database solaris times traversals small database log scale solaris page faults traversals small database solaris overhead percentage time small database solaris overhead percentage total time small database solaris times traversals large database raw solaris page faults traversals large database raw solaris benchmark time traversals large database raw solaris times traversals small database raw log scale solaris overhead percentage time small database raw solaris overhead percentage total time small database raw solaris times traversals large database solaris large memory overhead percentage time large database solaris large memory overhead percentage total time large database solaris large memory cpu time translation granularities large database solaris sparc elc cpu time translation granularities small database solaris sparc elc compilation linkage process type graph flat format type descriptor records simple flat format type descriptor records complex address space process performance virtual memory primitives linux performance virtual memory primitives zoom linux performance virtual memory primitives solaris performance virtual memory primitives zoom solaris pages swizzled reserved traversals large database solaris cpu times traversals mmap large database solaris cpu times traversals mmap large database zoom solaris cpu times traversals sbrk large database solaris cpu times traversals sbrk large database zoom solaris full hierarchical type graph xvi chapter desirable support virtual address space larger speci ed directly word size available hardware 
applications persistent object stores abc am operating systems single shared address space distributed shared memories li bene large address spaces 
example persistent object stores provide sharable recoverable heap storage eliminate les purposes operating systems single shared address spaces provide common addressing model processes machines distributed shared memory models provide single address space applications span multiple machines 
systems typically emphasize simpli ed programming preserving pointer semantics data structures 
words inherently support notion object identity maintaining programmer default view data heap objects interconnected pointers 
object identity de ned property virtue object uniquely identi ed collection objects object compared determine identify object 
de nition object identi er reused object deleted 
detailed study various forms object identity isavailable kc 
necessary send data host save application data structures stable storage operated possibly applications recovering application state case crash 
systems support large shared address spaces usually necessary write routines atten data structures low level linear manually reconstruct 
general procedure tends tedious error prone programmer intervention coding required appropriate data structure conversions 
addition linear representations bypass type systems lose pointer semantics object identity leave burden maintaining data structure consistency programmer 
persistent objects ability outlive execution program creates contrast transient objects disappear termination program created 
persistent object store repository persistent objects typically allow programmers save complex pointer linked data structures directly automatically non volatile storage requiring additional code intervention convert representations 
persistent object store strongly supports notion object identity type information topology data structures preserved objects saved stable storage allowing object uniquely identi ed 
dissertation propose implement storage mechanism coarse grained address translation technique exploits existing virtual memory hardware operating system facilities achieve high performance increased portability 
basic idea load pages persistent storage memory demand translate persistent pointers local hardware supported virtual memory pointers guaranteeing running program see pointer values 
data loaded memory various pointers translated absolutely overhead accesses data 
referents corresponding newly translated pointers memory marked operating system virtual memory protection facilities attempt access protected data raise exception handled loading data persistent store translating pointers necessary 
address translation mechanism advantages traditional approaches terms performance portability 
show chapters dissertation performance overhead system zero application operating data loaded memory faulting 
situations new data loaded memory persistent store overhead system low usually percent run time 
show smaller costs incurred loading data memory 
indirect costs approach inadvertent interaction underlying virtual memory system costs avoided improving operating system implementations provide better memory management interface 
regarding improved portability persistent storage system compatible standard shelf compilers ported variety modern operating systems sunos solaris linux mach ultrix os relatively easy port modern operating systems windows nt 
scope dissertation dissertation high performance address translation techniques implementing orthogonal persistence 
orthogonal persistent systems require arbitrary object persistent regard type 
persistence storage class object orthogonal type 
basic approach relies coarse grained address translation performance portability reasons 
order support claim analyze various costs coarse grained ne grained techniques cost model shows page wise address translation implemented ciently achieve performance standard hardware 
thesis address translation important issue considered implementing orthogonal persistence 
resolved ectively related issues resolved independently ecting address translation 
thesis stated follows high performance address translation orthogonal persistence ectively realized coarse grained translation schemes 
pointer swizzling page fault time coarse grained scheme implemented ciently stock hardware exploiting existing virtual memory hardware protection facilities ered modern operating systems requiring special system privileges 
pointer swizzling page fault time uses standard capabilities operating system easily ported modern operating systems support functionality 
basic approach exploits user level virtual memory protection facilities avoid expensive software checks pointer formats works standard theshelf compilers 
motivation variety factors motivate need exible cient persistence mechanism 
applications operate large amounts data represented complex data structures 
application terminates execution data volatile memory saved stable storage 
persistent storage system designed save restore data reliably ciently automatically preferable ad hoc mechanism implemented application 
underlying persistent object store able support large volumes data essentially acting eventual replacement normal le system 
important realize applications persistent programming language programming language raw speed computation usually important 
fact orthogonally persistent programming languages object oriented database systems largely motivated combination performance expressiveness considerations relative traditional database systems 
intended applications rich heap allocated data structures cient algorithms manipulate data structures 
traditional database systems designed largely optimize intensive applications persistent programming languages allow programmers optimize computation cpu intensive applications cad tools simulation programs 
desirable programs able transparently traverse pointers large amounts disk resident data majority execution time usually spent operating persistent data previously loaded memory 
furthermore applications usually operate extensively transient data 
typically large majority transient objects constitute temporary data die fairly young wil wjnb 
total execution costs cpu intensive application dominated operations transient objects memory persistent objects 
highperformance persistent system allow operations executed fast possible imposing minimal overheads performance 
need address translation mechanism incurs extremely low overheads cpu bound operations low overheads bound operations overhead operations transient data 
ideally mechanism best available high performance compilers requiring signi cant changes special support compilers 
cost orthogonal persistence cost orthogonal persistence application divided major components cost incurred accessing data disk cost incurred referencing data disk persistence 
cost associated loading persistent data secondary storage memory 
represents costs incurred performing normal cpu bound operations data memory 
important reducing cost bene cial cpu intensive applications maintaining computation performance higher priority 
general de ne cost orthogonal persistence cost making distinction transient persistent data access transparent programmer cost incurred persistence mechanism 
traditional ne grained address translation mechanisms implemented persistent programming languages incur signi cant overhead fundamental performance limitations normal cpu intensive applications 
schemes typically incur continual overhead checking pointer formats pointer memory data validity check necessary dereferenced compiled code know pointer appropriate format 
furthermore techniques require sophisticated custom compilers generate additional code checking translating pointer values necessary 
major downside approaches resources extensively develop distribute support custom compilers 
fact cost compilers poor code generation typically higher cost address translation defeating original purpose building high performance implementation 
resources available compiler development continual costs validity checks approach attractive 
overview pointer swizzling page fault time satis es requirements outlined earlier highperformance address translation scheme 
incurs zero overhead normal cpu bound operations data loaded memory small overhead roughly percent depending underlying hardware operating system data possible compiler optimizations similar self system cha infer information data reduce excessive checking overhead 
optimizations fairly hard implement inherent distinctions object types object residency 
faulted virtual memory persistent storage disk 
technique incur small space overhead storing meta data necessary facilitating address translation small compared amount persistent data supported 
expect overheads incurred loading data disk reduced cpu speeds improve faster relative disk speeds 
pointer swizzling page fault time works existing high performance shelf compilers requiring additional support compilers 
possible approach require extending language syntax relying run time system implementing necessary checks translation 
addition basic approach portable di erent operating systems requires minimal support underlying virtual memory system 
support larger bit address space bit machine pointer swizzling page fault time general purpose address reconciliation layer 
time advantages hardware address reconciliation may necessary 
cases sharing data multiple machines di erent native formats 
persistent data maintained common data format independent hardware word size di erent machines operating data translated appropriate local addresses necessary 
key idea approach layering mechanisms 
rely operating system compiler jobs usual strategically intervene appropriate points mapping level abstraction techniques suchas non traditional virtual memory hardware particular translation lookaside bu er tlb extraction object layout information compiler generated debugging information 
believe approaching problem right level abstraction helps resolving various issues independent ofeach 
part dissertation implemented coarse grained address translation pointer swizzling page fault time provide cient persistence mechanism 
doing essentially implemented form re ection back door language provide builtin support 
approach simple elegant complexities albeit hidden average user implementation due lack language features 
mechanism general easier implement improved language support re ection 
contributions dissertation useful contributions novel address translation technique independent underlying operating system implementation implemented ciently stock hardware re ection loosely de ned ability manipulate change internal behavior system modifying implementation outside 
provide support re ection notably operator overloading capability normal classes 
falls short complete support builtin types including pointers treated di erently user de ned classes 
new classi cation scheme granularity important design choices implementing orthogonal persistence detailed performance analysis various components coarse grained address translation mechanism notion run time type description providing implementation level information object layouts run time persistent storage system technique dynamically resolving method dispatch tables virtual function tables applications persistent storage nally analysis interactions operating system implementations recommendations improving implementations provide better support system extensions persistence garbage collection novel address translation technique pointer swizzling page fault time novel address translation mechanism exploits existing virtual memory hardware operating system features ciently implement orthogonal persistence 
approach highly portable uses standard features provided modern operating system compatible existing high performance compilers languages 
pointer swizzling page fault time classi ed coarse grained address translation technique granularity translation virtual memory page 
new classi cation scheme various researchers put forth di erent taxonomies address translation approaches di erences pointer swizzling techniques mos kk ms whi 
unfortunately classi cations unclear contradictory 
attempting clarify taxonomies new classi cation scheme design choices consider important implementing orthogonal persistence 
classi cation terms granularity design choices believe granularity selection fundamental issue implementing persistence 
performance analysis detailed performance analysis various components coarse grained address translation technique evaluate overhead page wise address translation costs incurred benchmark operation 
part performance results describe benchmarking philosophy contends standard database benchmarks accurately model real world applications exible con gurable 
benchmarks appropriate controlled measuring performance individual components persistence mechanism deriving qualitative system comparative analysis multiple systems 
run time type description address translation techniques require knowledge structural layouts data objects memory run time 
necessary order locate translate addresses pointer elds object loaded memory 
introduce term run time type description rttd describe implementation level type information data objects available address translation mechanism run time 
sophisticated provide builtin support rttd implemented rttd mechanism compiler generated debugging information 
persistent storage system pointer swizzling page fault time scheme texas persistent storage system provide persistence 
texas ported modern operating systems highly suitable prototype framework research 
system comprises lines source design modularized code distinct functionalities example address translation mechanism operating system interaction separated individual modules 
system available anonymous ftp source form gnu library general public license 
technique dynamically resolving method dispatch tables implements dynamic binding virtual functions lip pointers functions stored virtual function tables 
object particular class instantiated pointer corresponding vft automatically inserted object dynamic method dispatch implemented indexing virtual function table object method originally invoked 
unfortunately data pointers vft pointer object points code segment tightly coupled application 
actual value pointer usually varies applications di erent versions application 
obviously problem persistent objects related speci application 
dynamically resolve vft pointers specially special token values identi ed swizzled actual values valid current application 
ect equivalent simpli ed dynamic linker resolves vft pointers persistent objects appropriate values current application 
details exact mechanism described chapter 
analysis operating system interactions describe various issues related interaction low level systems persistent stores garbage collectors underlying operating system implementations 
analysis di erent aspects virtual memory management provide recommendations changes operating system implementations improve coupling low level system extensions contribute making portable 
discuss relevant operating system features virtual memory protection fault handling advanced issues addition various contributions described advanced issues scope dissertation addressed 
issues schema evolution currently support schema evolution texas independent address translation implemented top necessary 
course language support re ective techniques helpful implementation security address security issues access data persistent object store easy imagine implementation lines protection domains opal areas objectstore just unix style owner group privileges supported opal distribution fault tolerance issues need carefully designed architected implemented interface basic address translation mechanism 
impossible task aware project texas persistent store ported fujitsu ap multicomputer bs 
organization dissertation rest dissertation organized follows 
chapter describes important design issues implementing orthogonal persistence mechanism 
new classi cation scheme persistence mechanisms granularity choices di erent issues address translation address mapping data fetching data caching checkpointing 
persistent system issue resolved granularity independent granularity choice issue 
addition discuss granularity choices design issue implementation pointer swizzling page fault time mechanism texas persistent store 
chapter contains detailed description pointer swizzling page fault mechanism 
describe basic algorithm discuss various related issues address space management sharing compatibility existing systems code 
coarse grained approach works cases situations lack locality application data structures requires coarse grained approach address translation 
discuss ne grained mixed granularity address translation techniques portably implemented basic coarse grained technique 
argument pointer swizzling page fault time incurs zero overhead data loaded memory cpu bound operations small overhead loading data persistent storage bound operations 
chapter describes design implementation texas persistent store cient persistent storage system uses pointer swizzling page fault time mechanism key component high performance address translation 
describe basic design implementation texas implementation details include information virtual memory le system abstraction layers designed interactions underlying operating system easy implement 
noted texas relies virtual memory caching simply implementation choice completely orthogonal address translation mechanism 
intend texas research platform studies issues related cient orthogonal persistence implementation 
current context gathering detailed performance results pointer swizzling page fault time technique 
chapter presents detailed results performance texas pointer swizzling page fault time oo database benchmark traversal operations 
performance results chapter empirically validate basic competitive argument pointer swizzling page fault time 
measured performance linux solaris popular operating systems show total overhead texas usually percent situations platforms 
addition empirical results describe philosophy benchmarking speci cally argue widely standard benchmarks inappropriate quantitative performance comparison di erent persistent systems acceptable controlled measurements qualitative analysis single system 
benchmarks represent real applications take advantage persistent storage system 
believe applications typically sophisticated data structures perform signi cant cpu bound computations data structures benchmarks er rich data structures include minimal computation behavior 
chapter tackles issue providing implementation level information types run time 
call run time type description rttd distinguish introduced run time type identi cation rtti feature 
rttd constitutes information types memory layouts data objects necessary correct operation pointer swizzling page fault time 
contrast rtti supports information run time type equivalence checks obviously insu cient object layout information 
rttd may useful systems garbage collectors advanced pro ling tracing tools bene detailed object layout information 
describe basic strategy uses compiler generated debugging information special purpose preprocessors arguments approach preferable 
chapter presents details rttd implementation currently texas real time garbage collector 
describe expected performance characteristics approach preliminary measurements show additional overhead negligible compared typical compilation linkage costs 
chapter devoted discussion various issues important portability interaction various operating system implementations 
suggests directions improving operating system implementations easy integrating low level system extensions persistence mechanisms garbage collectors mainly interested interaction virtual memory system pointer swizzling page fault time primarily dependent existing virtual memory hardware protection facilities supported operating system 
important point highlighted discussion systems pointer swizzling page fault time require advanced capabilities operating system designed exploit capabilities exist improved performance 
brie describe operating system features particularly virtual memory protection violation handling improved performance gains 
chapter contains brief sketch research directions appear promising study high performance address translation techniques extensions texas persistent storage system 
issues related development competitive storage management technique cient checkpointing stable storage capabilities 
reiterate advanced issues mentioned scope current discussion 
summarize ndings conclude chapter 
chapter design issues persistence chapter provide general background persistence including description di erent types persistence commonly implemented various persistent systems 
approach designed implement orthogonal persistence provides cleanest implementation model separating persistence property object type 
brie describe existing taxonomies address translation mechanisms show unclear general usage 
choose granularity operation metric classifying di erent persistence mechanisms 
identify set basic design issues considered implementing persistent system de ne classi cation terms granularity choices design issues 
argue classi cation better existing taxonomies primarily concerned issue address translation 
interesting part chapter brief discussion ne grained address translation measures coarse grained mechanism 
show ne grained translation schemes incur basic costs inherent general implementations 
believe ne grained approaches avoided cases features consistency implemented ner granularity 
provide background survey research persistence relevant current discussion 
background file systems traditionally save data temporary storage program executions general long term storage 
unfortunately le systems ciency drawbacks parallel memory hierarchies disk ram data moved 
situations data exists memory caches disk areas poor resources 
le system normal view data stream bytes associated structure type information dissertation terms ram main memory interchangeably referring physical memory computer system 
memory representation data structures terms pointer linked objects 
creates fundamental impedance mismatch cm representations 
persistent systems designed solve impedance mismatch volatile non volatile storage alleviate ciency problems associated le systems 
section provide general background persistence including descriptions various types persistence brie discussing approach designed implement persistence high level languages 
persistence data created manipulated normal applications usually transient nature lifetime bounded execution process created 
contrast persistent data outlive execution process creates 
persistent object stores repositories storing arbitrarily complex persistent data structures maintaining pointer semantics just virtual memory 
essence persistent object store viewed long lived virtual memory persists applications complete execution accessed di erent applications run 
types persistence classify persistence implementation mechanisms di erent kinds type persistence supported speci approach 
general persistence broadly divided kinds class persistence orthogonal persistence reachability persistence 
simplest persistence mechanism incorporated applications relies classbased persistence 
basic idea requires type class may instantiated create persistent objects inherit top level persistence class 
special class de nes interface saving restoring data persistent object store 
derived class inherits top level class required implement speci ed interface possibly serialization methods save restore objects particular derived class 
obviously cumbersome programmer carry burden implementing persistence mechanism making process extremely tedious highly error prone 
problem approach promotes code duplication usual case 
type may potentially create persistent objects requires de nitions normal transient objects derived special class persistent objects 
result transient persistent objects logical application type equivalent terms physical actual type code operates kind object operate 
obvious solution derived class multiply inherit actual type class add problems related multiple inheritance 
approach builtin types de nitions changed easily languages 
class persistence orthogonal persistence abc am decouples lifetime object type 
words persistence viewed storage class property object type 
name derives requirement type object independent orthogonal storage class 
words persistence property individual objects classes types object persistent regardless type 
persistence decoupled type system approach supports clean implementation model transparent application programmer need major modi cations application code persistence mechanism 
reachability persistence abc general form orthogonal persistence 
basic principle approach requires objects reachable awell de ned persistent root roots automatically persistent 
orthogonal persistence type object relevant making persistent reachability property 
implementation ease approach depends support available programming language 
general believe orthogonal persistence derivatives reachability persistence preferable class persistence ad hoc mechanisms 
approach historically implementations persistence mechanisms slow due di erent cost factors 
direct fairly signi cant cost actions checking pointer formats maintaining bookkeeping information software 
indirect cost related specialized compilers implementing persistence language extensions 
typically lack resources extensive development specialized compilers result code generated compilers times slower generated widely available high performance optimizing compilers 
addition believe fundamentally slow approaches implementing traditional address translation techniques potential source performance problems 
example pointer wise translation techniques require format pointer checked time dereferenced transient pointer 
solve problems designing novel implementation strategy compatible code generated existing shelf compilers requiring special modi cations sacri cing optimization opportunities 
reduce overheads minimum ectively existing hardware check pointer formats avoiding software checks usually expensive 
ect removing major obstacles acceptance general purpose languages persistent applications performance compatibility stock hardware existing compilers 
storage class describes object stored 
example storage class automatic variable corresponds stack space object typically allocated data stack lifetime bounded scope itwas allocated 
approach focused implementing mainly orthogonal persistence languages designed compatible reachability persistence 
current implementation texas support reachability persistence 
primary obstacle implementing lack language support identifying type information arbitrary data stack transient heap 
essentially problem faced garbage collectors languages 
believe straightforward solutions similar applicable domain done 
aware project pointer swizzling page fault time techniques extending texas implement reachability persistence modula hn 
address translation taxonomies persistence active research area decade researchers put forth taxonomies pointer swizzling techniques mos kk ms whi 
section describe important details taxonomies highlights various similarities di erences 
addition provide motivation general classi cation persistent systems granularity issues 
eager vs lazy swizzling moss mos describes rst studies di erent address translation approaches associated terminology developed classifying techniques 
primary classi cation terms eager lazy swizzling address translation performed 
typically eager swizzling schemes swizzle entire collection objects size collection bounded 
words need checking pointer formats associated overhead avoided performing aggressive swizzling 
contrast lazy swizzling schemes follow incremental approach dynamic checks unswizzled objects 
predetermined bounded collection objects swizzled 
execution dynamically locates new objects depending access patterns application 
researchers kemper kk solomon ms classi cations similar lines studies 
consider classi cation ambiguous general clearly identify fundamental issue granularity address translation important context 
example consider pointer swizzling page fault time classi cation 
de nition swizzle pointers virtual memory page loaded memory applications allowed see pointers 
need explicitly check format pointer pointer swizzling page fault time eager swizzling scheme 
hand basic approach incremental typically conservative garbage collectors operate scanning stack treating value appears pointer 
format checking done implicitly hardware virtual memory 
nature swizzling performed page time demand making lazy swizzling scheme original de nition 
general scheme lazy granularity eager granularity 
example page wise swizzling mechanism lazy granularity pages page time 
scheme considered eager swizzling scheme granularity multiple objects entire page worth time 
fundamental issue granularity address translation performed 
node marking vs edge marking schemes addition eager lazy swizzling moss describes classi cation strategy distinguishing resident non resident data case lazy swizzling incremental approach 
persistent heap various data structures viewed directed graph data objects represent nodes pointers objects represent edges connect nodes 
view address translation mechanisms classi ed node marking edge marking schemes 
resident node non resident node marked node marked edge persistent pointer node marking edge marking transient pointer boundary node marking edge marking schemes pictorially shows basic technique node marking edge marking schemes 
name suggests edge marking schemes mark edges graph pointers objects indicate translated local format resident objects 
contrast node marking schemes guarantee resident objects translated graph nodes marked resident non resident 
words edges guaranteed valid local referents may non resident 
shows classic implementation node marking scheme non resident nodes marked proxy objects pseudo objects stand non resident persistent objects contain corresponding persistent identi ers 
object loaded database contained object swizzled de nition node marking pointers resident objects swizzled normally resident node non resident node proxy object persistent pointer transient pointer boundary node marking proxy objects pointers non resident objects swizzled proxy objects 
application follows proxy system loads referent fin gure database updates proxy newly resident object 
alternatively proxy overwriting old pointer newly resident object proxy may eventually reclaimed system 
note compiled code check presence proxy object pointer dereference general pointer may proxy object 
adds continual checking overhead pointers directly data objects intervening proxy objects 
pointer swizzling page fault time essentially node marking scheme swizzled pointers correspond valid virtual memory addresses referents distinguished basis residency 
di ers important way classic scheme explicit pseudo objects non resident nodes 
access protected virtual address space pages act proxy objects 
biggest advantage approach need reclaim proxy objects exist application progresses data loaded database consequently indirections dealt compiled code continual checks necessary 
general classi cation persistence shown existing classi cations describe address translation techniques constitute design issues considered implementing persistence 
ed set design issues believe fundamental cient implementation persistence mechanism 
contend speci combination issues characterize particular persistence implementation 
ect proposing classi cation scheme granularity fundamental design issues 
described earlier classi cation eager lazy swizzling ambiguous attack problem right level abstraction 
notice real issue lazy vs eager swizzling distinction size unit storage address translation performed 
range small single moss called pure lazy swizzling approach virtual memory page pointer swizzling page fault time large entire database called pure eager swizzling approach moss terminology 
observation believe better consider address translation design issues perspective choice ad hoc classi cation confusing translation semantics 
fact ambiguity described arises classi cations clearly identify granularity choices unnecessarily adhere single predetermined granularity 
believe addressing design issues terms granularity choices enables uniform process identifying consequence design issue performance exibility resulting persistence mechanism 
preferable ambiguous classi cations eager lazy swizzling scheme eager lazy di erent granularities 
granularity choices persistence address translation issues resolved implementing orthogonally persistent system 
ed set design issues relevant implementation persistence mechanism 
issues resolved making speci granularity choice independent issue 
combination granularity choices issues characterize persistent system 
speci design issues describe section granularities address translation address mapping data fetching data caching checkpointing 
de ne discuss issue detail rationale granularity choices issues implementation orthogonal persistence texas persistent storage system 
rst approximation basic unit granularity choices texas virtual memory page pointer swizzling page fault time relies heavily virtual memory facilities especially trigger data transfer address translation 
choice virtual memory page basic granularity unit allows exploit conventional virtual memories avoid expensive run time software checks compiled code advantage userlevel memory protection facilities modern operating systems 
necessary change granularity choice particular issue accommodate special needs unusual situations 
explain issues addressed di erent granularity integrates gracefully general framework texas 
address translation granularity translation smallest unit storage pointers translated persistent long format virtual memory short format 
general spectrum possible values range single pointer entire page 
granularity address translation texas typically virtual memory page coarse grained translation implemented pointer swizzling page fault time 
rationale choice advantages ered virtual memory pages terms ciency virtual memory hardware check residency referents 
addition rely application spatial locality amortize costs handling protection faults swizzling entire pages 
describe chapter possible implement ne grained address translation mechanism special situations coarse grained approaches unsuitable poor locality application 
texas designed perform ne grained translation individual pointers granularity address translation cases single pointer 
address mapping related choice granularity address mapping de ned smallest unit addressed data persistent store mapped independently area virtual address space 
rst approximation virtual memory page texas page persistent data mapped arbitrary page virtual address space process 
major bene page wise mapping savings table sizes need maintain tables contain mappings persistent virtual addresses vice versa page wise basis larger tables recording locations individual objects 
reduces space time costs maintaining address translation information 
granularity address mapping bigger page case large objects 
pointer large object swizzled virtual address space reserved pages large object overlaps 
reservation multiple pages necessary ensure normal indexing pointer arithmetic works expected objects cross page boundaries 
granularity address mapping equivalent number pages occupied large object 
data fetching name suggests granularity data fetching smallest unit storage loaded persistent store virtual memory 
granularities virtual memory page purpose current implementation texas 
primary motivation making choice simplicity ease implementation fact correlated default granularity choices design issues implementation 
possible change granularity fetching ecting granularity choices 
essence implement prefetching preload data persistent store 
discuss chapter may desirable applications raw ered normal le raw typically bypass le system cache order avoid double caching problem see chapter doing lose bene le system readahead prefetching mechanism 
depending access characteristics application dataset size cost reduced prefetching consecutive pages single faulted page 
granularity fetching closely tied exact strategy selected implementation 
data caching granularity data caching de ned smallest unit storage cached virtual memory 
texas granularity caching single virtual memory page relies exclusively virtual memory system caching persistent data 
describe chapter persistent page usually cached virtual memory page far texas concerned 
underlying virtual memory system determines page resides main memory disk swap space intervention texas 
quite di erent persistent storage systems directly manage physical memory control mapping persistent data main memory 
general texas moves data persistent store virtual memory regard distinction virtual pages main memory disk 
course possible change behavior texas directly manages ram physical memory 
believe unnecessary may undesirable applications fact texas behaves normal application respect virtual memory replacement may bene cial purposes prevents particular application system resources physical memory case 
discuss chapter additional control memory management possible depending support available underlying operating system 
checkpointing consider granularity checkpointing de ned smallest unit storage written non volatile media purpose saving recovery information protect failures crashes 
similar address translation strategy texas uses virtual memory protections detect pages modi ed application checkpoints 
default unit checkpointing usual case virtual memory page 
texas employs simple logging scheme support checkpointing recovery 
checkpoint time modi ed pages written log stable storage actual database updated 
granularity checkpointing re ned sub page logging 
approach relies page di ng technique originally proposed brie describe chapter dissertation 
basic idea save clean versions pages modi ed application original clean modi ed dirty versions page compared detect exact sub page areas updated application di logged stable storage 
technique reduce amount checkpoint time subject application chapter provides details checkpointing recovery support texas 
locality characteristics 
granularity case equivalent size di units storage saved stable storage 
enhancement checkpointing mechanism maintain log compressed format 
checkpoint related data streamed disk perform inline compression specialized algorithms tuned heap data 
research initiated area preliminary results indicate cost reduced factor compression ratio 
reduction costs possible improved compression algorithms adaptive techniques 
fine grained address translation obvious foregoing discussion granularity choices pointer swizzling page fault time inherently coarse grained address translation mechanism 
factors motivated develop implement coarse grained mechanism approach 
obviously primary motivation related fact wanted exploit existing hardware avoid expensive software checks 
believe factors ne grained address translation 
section discussion ne grained address translation techniques believe practical high performance implementations terms ciency complexity 
ne grained address translation techniques incur various hidden costs measured quanti ed previous research 
general current ne grained schemes appear slower pointer swizzling page fault time terms basic address translation performance 
basic costs fine grained address translation techniques usually incur inherent costs due basic implementation strategy 
costs divided usual time space components tangible components related implementation complexity 
believe costs order tens percent engineered systems custom compilers ne tuned run time systems 
typical costs incurred ne grained approach follows major component total cost attributed pointer validity checks 
checks include swizzling checks residency checks 
swizzling check verify swizzled translated valid local format residency check veri es referent resident accessible 
checks conceptually independent typically combined implementations ne grained schemes 
important component cost related implementation custom object replacement policy required physical memory basic di ng technique implemented context whi preliminary results encouraging investigation required 
example swizzled pointers texas contain valid virtual memory address values 
directly managed mechanism implements persistence 
cost usually directly proportional rate execution requires read barrier implementation approach 
cost component discussed subsection 
resident objects evicted memory course replacement proportional cost usually incurred invalidating evicted objects necessary maintaining referential integrity avoiding dangling pointers 
cost directly proportional rate execution locality characteristics application 
de nition ne grained translation techniques permit di erent formats application execution 
requires pointers checked ensure right format simple equality checks 
may necessary check transient pointers depending underlying implementation strategy 
continual pointer format checking cost dependent rate execution pointer 
possible incur costs exist mainly unusually constrained object pointer representations system 
example accessing object indirection proxy object require additional instructions 
example increased complexity required handling languages features pointers 
note cost factors described necessarily contribute performance penalty ne grained address translation mechanism 
basic costs usually form systems 
object replacement fine grained address translation schemes typically require persistence mechanism directly manage physical memory persistent data usually loaded memory object basis 
usually necessary implement custom object replacement policy part persistence mechanism 
ects cost implementation complexity 
part replacement policy read barrier typically implemented object resides memory 
usual action read barrier set bit object maintaining recency information object aid object replacement policy 
read barrier may implemented software preceding object read call routine sets special bit object 
compiled code contains extra instructions usually inserted compiler implement read barrier 
alternatively term read barrier borrowed garbage collection research wil denote trigger activated read operation 
corresponding term write barrier denote triggers activated write operation 
interior pointers point inside bodies middle parts objects heads 
data usually read persistent store bu er terms pages minimizing overhead 
objects required copied bu er memory 
may implemented specialized hardware checks routines 
read barrier typically expensive stock hardware usual case read requests intercepted recorded 
known instructions pointer store write pointer lisp systems support compilation 
read actions common write actions estimate percent total instructions application usually correspond read pointer 
exact number obviously varies application importantly source language example higher heap oriented languages 
may possible data ow analysis compilation read barrier optimized away object analysis hard implement 
object replacement policy interferes general swizzling especially edge marking technique 
cases object evicted memory rst invalidating edges 
obviously requires knowledge object evicted 
kemper kk solved object data structure known reverse list rrl maintain set backpointers objects object 
solomon ms di erent data structure called swizzle table xed size hash table maintains list swizzled pointers system 
approaches generally favorable increase storage requirements essentially doubling number pointers minimum implementation complexity 
discussion problems evaluating di erent ne grained translation mechanisms lack measurements system costs related costs implementations 
measurements exist correspond interpreted systems system usually underestimate costs high performance language implementation 
example overhead slow interpreted implementation may acceptable system certainly unacceptable overhead implementation sped factor 
cost factor ne grained techniques generally overlooked cost maintaining mapping tables translating persistent local pointer formats 
ne grained schemes typically translate pointer time mapping tables contain entry pointer 
signi cantly increase size mapping table making harder manipulate ciently 
believe system rc scd probably fastest ne grained scheme comparable coarse grained address translation scheme falls short terms performance 
results whi slower transient hot traversals oo database benchmark cat cs 
fairly signi cant overhead considering overhead system zero hot traversals smaller 
generous estimates performance improvements say double performance costs reduced hot traversals ideal purpose represent operations data faulted memory avoiding performance impacts related di erences loading patterns total costs incurred transient application 
number quite high cult general acceptance mainstream applications 
believe reasons quite di cally reduce overheads ne grained techniques 
basic costs outlined ne grained translation scheme changed reduced easily 
example pointer validity format checks integral part ne grained address translation optimized away 
general performance penalty maintaining searching large hash tables mapping information typically independent checking cost 
mapping tables get larger expensive probe update especially locality ects enter picture 
fancy data ow analysis code generation techniques required compiler optimize costs associated read barrier implementation 
furthermore extra optimizations probably cause unwanted code bloat excessive loop unrolling 
residency property treated type self style optimizations cha applied eliminate residency checking quite easy types residency changes procedure calls depending dynamic run time state 
ect residency check elimination fundamentally non local problem depends complex analysis control ow data ow 
necessary check residency object 
di erent unique objects referenced application cost initial residency checking incurred 
example application may traverse list containing objects 
compiler access entire collection full residency checking cost incurred list element 
arguments believe ne grained translation techniques attractive high performance implementations persistence mechanisms 
side argument certainly said mechanisms advantages 
primary potential savings traditional ne grained schemes fetch data necessary 
bene ts coarse grained approaches ne grained schemes support reclustering objects pages checks required ne grained address translation may able support ne grained features transactions little extra cost 
principle ne grained schemes data short intervals time compared coarse grained schemes 
clustering algorithms interesting topic hash tables known extremely poor locality nature scatter related data di erent buckets 
research studies necessary conclusive proof 
observation ne grained techniques attractive unusually sophisticated systems supporting ne grained concurrent transactions 
attractive ne grained checking supported hardware early lisp machines 
survey related persistence active research area early eighties various approaches proposed developed implementing di erent types persistence 
approaches range special languages language extensions builtin support persistence general purpose languages support persistence help kind external mechanism 
section survey representative persistence mechanisms respect proposed classi cation di erent granularity choices 
persistent programming languages start looking approaches incorporate persistence part programming language implementation 
important ones describe ps algol napier loom ps smalltalk 
ps algol napier rst persistent languages implemented ne grained orthogonal persistence 
ps smalltalk implemented extending existing popular non persistent languages smalltalk respectively loom virtual memory system smalltalk implements persistence side ect providing large virtual memory 
brie describe salient features language implementation approach 
focus exclusively advanced languages support object oriented data models discuss database programming languages pascal extend relational programming techniques relevant research 
ps algol ps algol acc abc abc rst truly persistent programming language contributed development cient persistent systems 
notion orthogonal persistence pioneered implementation ps algol supports full reachability orthogonal persistence 
ps algol built adding functional extensions top algol high level algol teaching university st andrews 
basic goal implement persistence transparent manner minimal impact existing code programming styles 
language syntax left unchanged run time system modi ed recognize support collection procedures opening closing databases committing aborting transactions embodied persistence facilities 
pointers ps algol dynamically typed full type checking usually necessary run time 
explicit residency check piggy backed type check run time system ensure referent resident located loaded database 
persistent implemented object identi ers oids granularity address translation individual pointers 
granularities address mapping data fetching individual objects loaded database heap run time system 
napier napier mbc successor ps algol ps algol uses dynamic typing napier attempts strong typing cases 
special situations run time dynamic type checking necessary type determined statically 
basic implementation strategy terms environments treated rst class objects 
environment encapsulation variables storage bindings 
expressions evaluated context speci environment information encapsulated environment 
persistence implemented top level environment associates persistent objects corresponding values persistent store 
ps algol napier implements reachability persistence run time type information available variables corresponding environment 
various granularity choices persistence individual objects loaded database demand oids non resident objects traversed application 
loom loom kk kae large object oriented memory virtual memory system designed support large address spaces early smalltalk implementations machines bit hardware word size 
persistent stored bit oids translated bit oids persistent objects fetched disk bit oids index resident object table holds actual object locations memory 
loom attempts provide transparent persistence objects loaded memory contain bit elds just non persistent smalltalk implementation 
objects working set loaded memory loom behaves similarly normal smalltalk implementation distinction transient objects resident persistent objects 
obvious question system maintains non resident objects bit elds resident objects 
loom accomplishes mechanisms leaves lambdas 
leaf proxy persistent object disk resident occupies entry object table 
words leaf objects proxy objects implement 
leaf contains bit oid corresponding non resident object easily leaf traversed 
hand lambda bit oid special value zero distinct values bit oids 
equivalent edge marking approach tagged invalid 
need proxy object entry object table corresponding lambda 
lambda mechanism maintain bit similar invariant maintained pointer swizzling page fault time objects loaded memory contain hardware supported virtual addresses 
oid original object order load object corresponding lambda value current object system rst read current object disk locate bit value non resident object corresponding lambda load object disk overwriting lambda newly generated bit oid object table 
interpreter implements explicit checks non resident objects leaves lambdas triggers loading necessary di erent mechanisms depending leaf lambda processed 
termed object faulting drawing similarity paged virtual memory systems 
granularity address translation individual object granularities address mapping data caching individual objects 
noted loom provide support transactions saving recovery data case crash failure primarily designed implement virtual memory system persistence storage system 
programming language programming language rc scd developed university wisconsin persistent extension 
persistence implemented adding special database types objects types persist 
necessary su cient condition persistence 
order persist object database types allocated specially persistent heap 
approach breaks orthogonal persistence model persistent objects tied special type associated type hierarchy 
basic strategy implemented extending gcc gnu compiler support database types generate special residency checks triggering address translation object faulting necessary 
addition persistent virtual machine epvm interpreter accessing persistent objects 
code generated compiler invokes interpreter load persistent objects translate pointers necessary 
exodus storage manager esm car object storage management layer language implementation 
persistent pointer represented byte oid storage manager swizzled word size local hardware 
rst implementation interpreter epvm interfaced esm explicitly manage client bu er pool pinning physical memory pages necessary 
new architecture epvm implemented improve performance copying data virtual memory translating oids virtual memory addresses original page memory wd :10.1.1.143.3812
copying virtual memory done terms individual objects entire pages containing objects 
applications manipulate data directly virtual memory overhead incurred oid translation pinning required copying 
granularity choice address translation terms individual pointers compiler generated residency checking code inserted appropriate points code 
address mapping data caching handled storage manager explicitly manages client bu er pool 
case epvm granularity caching varies depending individual objects entire pages copied bu er pool virtual memory 
granularity terms individual objects system updates database corresponding copies virtual memory 
ps smalltalk ps smalltalk hos designed implement persistence smalltalk 
basic architecture system similar epvm object caching architecture wd underlying storage manager mneme mos :10.1.1.143.3812
objects copied mneme bu er pool virtual memory demand translating mneme oids virtual memory address values 
mneme implements reachability persistence garbage collection objects reachable persistent root 
basic mechanism relies user supplied callback routines nd object contained objects 
essence pushes type description responsibility programmer supply callback routines 
system uses node marking supporting object faulting 
implementation uses fault blocks proxy objects non resident objects hold corresponding persistent addresses 
object corresponding non resident objects converted valid virtual memory addresses corresponding fault blocks maintaining invariant required node marking 
note similar pointer swizzling page fault time ectively uses protected virtual memory pages fault blocks 
address translation done object faults generated application attempts dereference pointer fault block 
actual object loaded memory bu er pool swizzled necessary including generation fault blocks available application 
fault block called indirect block contains actual memory object 
extra level indirection indirect blocks periodically cleaned garbage collector 
method invocation smalltalk usually done sending message receiver object method invoked 
approach residency checks usually piggy backed normal message sends check intended receiver resident load necessary 
recall data copied virtual memory demand address translation done automatically objects loaded memory 
granularity translation individual object 
granularity caching single object far data copied bu er pool virtual memory concerned 
mneme uses segments collections objects fetching data stable storage bu er pool 
external libraries apart implementing persistence part run time system persistent programming language possible support persistence external mechanisms class libraries shared object modules modifying language implementation 
approaches typically designed implemented exploit existing features general purpose language operating systems achieve goals 
section describe approaches implements persistence 
absolute requirement virtual memory protection facilities implement persistence outside language run time system approaches described similar texas respect 
note similarity ps smalltalk fault blocks loom leaf objects 
vaughan dearle hybrid approach vaughan dearle vd developed scheme similar utilizes virtual memory protections residency checking di ers way actual swizzling performed 
approach pointers swizzled directly valid virtual memory addresses scheme performs swizzling incremental fashion described 
newly loaded pointer considered swizzling rst step check residency referent 
referent loaded memory pointer translated corresponding virtual address 
referent resident pointer translated object table entry contains bit oid non resident object 
referred partial swizzling actions required referent accessed pointer 
object table entry access protected attempt dereference pointer trigger protection fault 
fault handled locating object disk information object table entry loading memory translating partially swizzled pointer virtual memory address corresponding new object location 
primary goal approach reduce consumption virtual memory swap space avoiding allocation backing storage objects accessed application 
accomplished partially swizzling pointers time full swizzling completed allocating memory referent translating pointer appropriately 
right idea principle believe implementation strategy adversely ected authors misunderstood approach 
discuss chapter reserve virtual address space actual memory swap space pages accessed application 
unfortunately modern operating systems provide exible control memory management 
defer discussion issue chapter describe interactions operating systems 
problems associated incremental swizzling approach 
pointers swizzled steps system handle pointers di erent formats partially swizzled fully swizzled 
similar pointer format checking problem ne grained address translation mechanisms 
basic scheme standard operating systems shelf compilers pointer dereferenced fully swizzled nal virtual memory address actual object necessary overwrite old partially swizzled pointer value new fully swizzled pointer value 
fault handler update saved machine state may allowed special system level privileges 
believe extra bene scheme added overhead handling partially swizzled pointers 
note similarity protected object table entries fault blocks ps smalltalk leaves loom 
pointer swizzling page fault time problem translate pointers valid virtual addresses need changed 
objectstore objectstore commercial system uses pointer swizzling page fault time primary address translation mechanism implement persistence 
texas objectstore underlying address translation mechanisms developed independently uence systems di er ways 
texas designed provide simple persistence small run time code footprint objectstore full edged object oriented database system 
texas designed compatible existing shelf compilers uses compiler generated debugging information object les extract type object layout information chapter 
contrast objectstore uses special preprocessor extract information application source code 
chapter enumerates reasons chose debugging information special purpose preprocessor 
signi cant di erence systems strategy performing pointer swizzling 
objectstore designed avoid swizzling far possible attempting map page virtual address time mapped memory 
done successfully referents pointers page swizzling necessary 
order implement strategy additional information regarding previous mappings maintained persistent page consulted mapping page memory 
furthermore page mapped memory scanned ensure pointers swizzled correctly referents mapped location time 
addition application modify arbitrary data page similar scanning necessary dirty pages checkpoint time regenerate mapping information referents pointers page 
believe avoiding swizzling mapping pages locations simply optimization basic pointer swizzling mechanism 
clear optimization provides signi cant performance improvement measurements chapter indicate major component cost usually cost actual cost translating pointer smaller comparison 
small advantages usually negated cost maintaining additional mapping information page persistent store 
relatively easy incorporate similar optimization texas done far appear provide major bene ts 
wd whi research system similar objectstore terms implementation strategy 
uses pointer swizzling page fault time approach address translation objectstore maintains additional mapping information avoid swizzling far possible 
interesting di erence exodus storage manager 
implementation allows system directly manage physical memory client bu er pool explicitly moving data hierarchies 
area checkpointing saving recovery information uses page di ng technique similar idea rst proposed 
results whi indicate di ng perform depending locality characteristics application 
observation line original projections expected performance characteristics 
study necessary area research storage management techniques persistent object stores 
approaches addition various systems described approaches supporting persistence designed implemented various researchers 
provide brief overview interesting systems 
recoverable persistent virtual memory recoverable persistent virtual memory system cs promotes extension virtual memory support recoverable persistent update model realizing wide range recovery services 
model essentially supports mechanism implementing persistence primary focus ensuring state virtual memory recovered 
classic persistence mechanism explicit pointer swizzling address translation system 
database memory mapped virtual address space mach equivalent 
model de nes mechanisms control propagation virtual memory pages stable storage 
particular system allows ush locks placed virtual memory pages 
ush locked page pinned virtual memory propagated database 
model de nes page ush rules specify partial order pages propagation database 
page ush policies de ned database guarantee database recoverable persistent state 
implemented modifying mach kernel incorporate support page ush policies 
speci cally user processes add remove ush locks rules specify appropriate policies database 
granularity address translation applicable swizzling performed granularities address mapping data fetching correspond entire database mapped memory single step 
cricket cricket sz uses memory management primitives supported mach implement single level persistent object store 
primary strategy relies mach external pager facilities locate load persistent data disk memory 
cricket supports transparent concurrency control recovery facilities 
basic architecture distributed centralized server primary interface clients accessing persistent object store disk 
clients communicate note pages pinned virtual memory physical memory ush locked page paged swap space necessary 
cricket server rpc interface 
server acts external pager treats persistent store memory object maps directly client virtual address space 
client access persistent data virtual memory 
cricket implement kind pointer swizzling mechanism 
maps database range virtual addresses automatically validated 
means size database restricted maximum address space supported operating system 
granularity address translation obviously applicable case granularities address mapping data fetching correspond entire database 
dali dali storage manager optimized main memory databases situations persistent store resides memory 
perform address translation uses memory mapping techniques map database les virtual address space user process 
collection database les forms single database persistent object store 
persistent maintained database pointers 
typically represented le identi er example full path database le set le 
system supports indirect object identi ers known 
address translation typically done ne grained manner database pointer dereferenced 
virtual address calculated adding set base address corresponding database le mapped granularity address translation typically single pointer special database pointers 
granularity mapping order database le entire le usually mapped memory 
checkpointing crash recovery implemented physical data logging operation logging 
granularity checkpointing usual case terms predetermined checkpointing units chunks de ned system 
developed suzuki persistent variant language 
system introduces describes notion reservation residency context object faulting 
term reservation refers action reserving local identi er corresponding persistent identi er preparation upcoming load referent memory term residency refers state referent including information data loaded persistent store 
similar residency checks part pointer validity tests ne grained address translation mechanisms 
implemented modifying gnu compiler generate additional code appropriate points code 
address translation performed granularity objects non resident objects translated special surrogate values similar loom lambda 
compiler automatically inserts extra instructions reservation mach supports abstraction memory objects allow external memory management level processes 
checking incremental translation 
exodus storage manager underlying persistent storage speci storage manager dictated design choice system 
presents performance comparison software approach systems including pointer swizzling page fault time oo database benchmark 
results show coarse grained address translation generally superior approaches situations 
variation outperforms pointer swizzling page fault time non standard benchmark traversal locality data structures eliminated arti cially 
result surprising coarse grained address translation techniques implicitly rely locality amortize higher costs faulting swizzling entire pages 
primary goal chapter identify basic design issues important implementing persistence mechanism 
part exercise provided basic de nition persistence described di erent types persistence popularly implemented current systems 
believe orthogonal persistence right approach system designed compatible approach 
existing classi cations primarily concerned address translation mechanisms approach problem right level abstraction 
believe fundamental issue granularity address translation performed 
new classi cation scheme persistent systems granularity choices basic design issues described approach ts hierarchy 
identifying fundamental design issues implementing persistence important useful understanding impact performance exibility persistent systems 
granularity main factor general classication mechanism constrained unclear 
believe issues identi ed chapter form core set fundamental design issues implementing persistence 
scheme primarily coarse grained address translation mechanism special situations changed ner granularity 
coarse granularity allows exploit existing hardware reduce total overheads maintaining compatibility existing compilers operating systems 
hand ne grained schemes incur basic costs inherently slower cases require ne grained control mechanisms transactions locking provided survey related area persistence implementation variety systems 
broadly divided groups persistence facilities provided part language implementation 
persistent programming languages ps algol fall rst category contains special persistent languages 
category includes mechanisms implemented outside language usually object code library take advantage existing features language compiler operating system job 
chapter pointer swizzling page fault time persistent object stores designed manipulate large volumes data implementing virtual address spaces larger hardware supported address spaces 
early schemes supporting large virtual addresses normal hardware loom kk kae wd typically incurred signi cant overhead due traditional ne grained address translation techniques :10.1.1.143.3812
basic approaches commonly implementing large address spaces software 
object table indirect object object table translating object identi ers table sets objects loaded memory 
object identi ers marked translated lazily necessary 
second approach called pointer swizzling indirect object table object identi ers converted actual hardware supported addresses virtual memory pointers incremental fashion 
chapter describe approach variation basic pointer swizzling mechanism 
conventional pointer swizzling schemes perform translation running program tries particular persistent pointer 
part translation process object loaded virtual memory 
unfortunately translating individual pointers may involve checking pointer determine valid address increasing overhead 
alternatively possible swizzle pointers object rst time object referenced mos 
approach requires pointers checked ensure swizzled necessary 
toavoid extra costs programs access persistent data pay cost checking programs access persistent objects multiple times incur additional costs access 
ideally scheme operate ciently standard hardware requiring special purpose hardware mushroom project 
approach called pointer swizzling page fault time ps load pages virtual memory demand swizzling persistent pointers normal hardware supported virtual memory addresses page fault time 
pointer swizzling page fault time novel address translation mechanism relies standard virtual memory hardware check referents memory trigger swizzling necessary 
scheme entire pages time translating pointers corresponding virtual addresses extra hardware required continual checking overhead swizzled pointers dereferenced normal memory speeds 
strategy exploiting locality access amortizing cost swizzling multiple accesses data 
addition take advantage fact costs typically higher swizzling costs swizzling entire page faulted add signi cant overhead compared costs loading page disk 
remainder chapter organized follows 
start discussing motivation designing page wise address translation scheme section 
describe basic algorithm section brie discuss indirect costs pointer swizzling section 
related details handling large objects section address space exhaustion section issues regarding sharing compatibility pointer swizzling page fault time section described 
discuss ne grained mixed granularity address translation schemes section concluding section 
motivation pointer swizzling page fault time inherently page wise address translation scheme 
decision implement coarse grained scheme motivated factors 
potential advantage ne grained pointer wise object wise address translation savings costs typically data required application loaded 
today disks high latencies argument savings truly applicable data fetched remote host fast network local disk 
application locality accesses objects page advantage ne grained loading swizzling quickly lost 
furthermore experimental network protocols achieved surprisingly performance tl widely available current networks order magnitude slower reducing potential bene ts ne grained schemes 
addition cost cost maintaining meta data address translation ect performance ne grained scheme 
speci cally table hold mappings persistent virtual addresses get signi cantly large 
page wise swizzling requires entry page mapping table ne grained swizzling require entry object pointer increasing table size 
larger table size ects cost actual address translation time persistent pointer swizzled mapping table probed check exists new created necessary 
research garbage collection techniques shown typically pointers application unique wil 
means mapping table lookup fail 
table sizes increase cost probing inserting new mappings tends increase adding costs translation 
general table size access characteristics coupled addi tional overhead associated translation impact performance ne grained schemes 
objects page referenced application ne grained schemes mapping swizzling objects eventually creating entries table 
contrast pointer swizzling page fault time create single entry entire page swizzle objects page loaded memory 
fine grained schemes preferable application objects page threshold exact value depends factors size average number pointers objects pages mapping table implementation compared object wise pointer wise address translation schemes page wise approach allows additional exibility usual case 
exploit existing virtual memory hardware memory protection mechanism ered modern operating systems 
scheme compatible stock hardware shelf compilers requiring special features support operating system 
believe swizzling page fault time especially attractive scales systems large main memories 
memories get larger average number instructions executed page faults goes cost pointer swizzling proportionally smaller 
conventional pointer swizzling schemes usually property checking translation overheads tied directly rate program execution 
algorithm description pointer swizzling page fault time coarse grained address translation scheme load translate entire pages time 
di erent schemes ner granularity load swizzle entire objects individual pointers 
basic approach incremental pages faulted virtual memory required application address translation done entire page loaded persistent store disk 
address translation involves translating pointers persistent long format actual hardware supported virtual memory address short format 
incremental faulting scheme detect objects persistent memory loaded virtual memory operated 
choose existing virtual memory hardware page wise access protection capability operating system purpose 
avoids continual overhead software works modern operating systems standard hardware 
scheme relocates objects virtual memory somewhat sooner straightforward software pointer swizzling scheme load entire page object page accessed 
allows preserve essential invariant application allowed see pointers persistent address space 
pages containing persistent pointers access protected application attempts access page trap handler invoked relocate page persistent store virtual memory 
trap handler translates persistent pointers page transient recall residency checks part general pointer validity checks described chapter 
pointers reserving address space referents needed 
page unprotected application may continue interruptions accesses objects page 
entry pointer virtual memory persistent store page virtual memory page reserved vm page entry pointer persistent store bootstrap state swizzling figures illustrate pointer swizzling page fault time mechanism 
application access persistent store request pointers special persistent roots retrieved name 
roots act entry pointers data stored persistent store 
rooted object requested name rst step relocate page referenced entry pointers 
allows entry pointers translated hardware supported virtual address format application execution 
shows bootstrap state system 
note relocate page page gure simply reserve access protect page virtual address space page gure loading data persistent store 
virtual memory address object returned entry pointer application 
application attempts dereference pointer access protected page page example access protection violation generated 
provide handler intercepts violation locates corresponding page page example persistent store loads memory predetermined reserved location convert pointers persistent address format virtual address format maintain aforementioned invariant 
pointers swizzled correctly corresponding virtual memory address values known 
referents may entry pointer virtual memory persistent store page virtual memory page reserved vm page entry pointer persistent store incremental faulting swizzling memory system may need reserve access protect pages virtual address space pages 
completed successfully done actions swizzling control returned application 
shown process repeats pointer page traversed application 
swizzling mechanism ensures exists mapping page new created 
example application traverses pointer page causing loaded persistent store swizzled address space page need reserved 
pointers page swizzled appropriately point page course address space page reserved page example allocated access protected usual 
approach analogous appel ellis li incremental copying garbage collection scheme ael turn variation incremental copying scheme described baker bak bak 
appel ellis li model incrementally relocates objects space space scheme relocates pages objects persistent memory transient memory 
reduces size tables required hold mappings persistent transient addresses page numbers addresses recorded individual objects 
meshes page faulting mechanisms caching pages attractive faulting objects memories small sta wil wd 
technique reserves virtual address space step ahead access pattern application essentially forming read barrier page wise wavefront extended just past pages referenced application 
shown pictorially entry pointer virtual memory persistent store page virtual memory page reserved vm page entry pointer persistent store incremental faulting swizzling cont 
wavefront formed access protected pages allows maintain invariant application persistent unswizzled pointers 
pages referenced application contain hardware supported virtual addresses may point protected pages 
guaranteed pointer protected page dereferenced resulting fault intercepted handled fault handler 
page part group pages referenced application wavefront extended include newly protected pages created result swizzling 
mechanism ensures application pages unswizzled pointers 
application encounters pointers virtual address format pointers dereferenced normal way single machine instruction extra overhead page faults 
exploit locality application similar normal virtual memory systems operate 
take advantage fact huge disparity cpu speeds disk speeds swizzling pages faulted disk add signi cant overhead faulting cost 
addition application exhibits usual locality incur additional cost accesses swizzled page avoiding lot overhead typically encountered pointer wise object wise swizzling 
emphasized consume virtual address space virtual memory swap space reserved access protected pages 
swizzled loaded pages reserved unloaded pages persistent store pages wavefront address space reservation pathological cases data structures high fanout approach may consume address space quickly 
section discuss problem address space exhaustion describe di erent ways solve maintaining compatibility basic swizzling mechanism 
mistaken dirty pages problem pointer swizzling page fault time ectively uses virtual memory hardware expensive software approaches residency checking 
chapter presents performance results show basic costs approach small compared costs 
unfortunately inadvertent interaction virtual memory system operating systems support advanced memory management interface leading indirect costs related pointer swizzling 
section describe basic issue important observations indicate costs fundamental problem approach address translation 
possible solutions deferring detailed discussion chapter 
brie describe page loaded persistent store virtual memory pointer elds page swizzled corresponding virtual memory addresses 
typically actions occur page loaded memory application de ne fanout number pointer elds outgoing pointers object 
data page 
page clean application perspective modi ed data page 
virtual memory system considers page dirty act swizzling modi ed page application may 
unfortunately inthe usual case virtual memory system automatically distinguish modi cations done system pointer swizzling done application 
call mistaken dirty pages problem pages clean application point view mistakenly marked dirty virtual memory system 
note mistaken dirty pages really issue application exhibits paging behavior 
page evicted main memory virtual memory system choices 
page clean exists unmodi ed copy disk simply discarded 
hand page marked dirty rst paged written backing store discarded 
current scenario obvious mistaken dirty pages paged virtual memory system evicted memory 
certain conditions page outs mistaken dirty pages may considered unnecessary corresponding data exists persistent store albeit unswizzled form 
memory reclaimed simply discarding data removing virtual physical mapping page 
virtual address space page retained accesses page intercepted normal swizzling mechanism cause data reloaded persistent store 
essence paging persistent store local swap space 
narasayya originally raised issue swizzled pages erroneously marked dirty bythe virtual memory system corresponding page outs unnecessary paging persistent store 
classi ed virtual memory overhead pointer swizzling resulting cost additional actions necessary pages mistakenly considered dirty virtual memory system 
bug feature 
issue mistaken dirty pages appears major problem rst glance argue factors related general con guration contribute ultimate classi cation issue problem expected behavior 
consider di erent con gurations context 
traditional relational database style setup dedicated database servers typically con gured large amounts main memory 
persistent store maintained equipped servers mistaken dirty pages problem server side caching mechanism designed explicitly exploited 

con guration persistent store local storage servers networks involved 
case mistaken dirty pages undesirable unnecessary copies persistent store backing store clean page 

third con guration persistent store maintained remote centralized le server explicitly designated le service normal applications allowed server 
important kind situation current implementation persistent object store designed described observations client caching 
observations argued problem mistaken dirty pages problem depending con guration application usage patterns 
important observations basic issues observations indicate problem bad rst glance fundamental shortcoming pointer swizzling approach default behavior intended behavior normal applications mechanism incorporate basic persistence 
costs 
rst observation note costs related unnecessary mistaken dirty pages continual costs costs page 
swizzled page considered dirty virtual memory rst time loaded persistent store swizzled 
referenced having paged locally virtual memory system load swap space swizzling necessary 
page marked clean need paged evicted 
words page ectively cleaned virtual memory system paged 
ect locality paging 
mistaken dirty pages problem strongly tied locality characteristics paging behavior application 
paging application execution obviously additional overhead virtual memory system need evict pages 
mistaken dirty pages harmless case reclaimed operating system program execution 
spectrum working set application larger available main memory 
case expect performance dominated heavy paging behavior cost page outs due mistaken dirty pages small fraction paging costs 
middle spectrum characterized light moderate paging favorable pointer swizzling unnecessary page outs larger fraction paging costs depending access characteristics application working set size 
research including detailed studies actual applications necessary quantifying costs general 
client caching 
nal observation importance client caching basic run time environment 
imagine situation cheaper page local swap space persistent store 
example persistent store resides centralized le server slow network costs local paging may set costs loading page persistent store swizzling 
furthermore possible centralized le servers con gured prohibit general paging 
situations local paging preferred paging persistent store page outs due mistaken dirty pages typically issue pages written local swap space regardless swizzled 
designed persistent object store texas persistent store chapter incorporate persistence normal applications just database style applications 
stated earlier traditional database context dedicated servers large amounts main memory improved performance server side caching 
normal computing environment con gurations di erent 
texas implemented library archive provides interface allow applications manipulate persistent object stores may stored remotely nfs le server 
file servers commonly centrally administered provide reliable le service act servers provide backing storage virtual memory clients 
fact environments paging central le server allowed 
texas avoid mistaken dirty pages problem evicting pages persistent store persistent store nfs mounted central server amount paging server 
current approach client side local caching right situations 
texas default applications unintentionally violate server usage policies possibly ect general network performance simply linking texas library 
course persistent store stored locally user right dedicated server client side caching best approach 
discussion obvious mistaken dirty pages problem associated page outs de nitely source additional overhead con gurations ecting performance depending factors memory size locality characteristics emphasized fundamental costs pointer swizzling page fault time technique 
classify costs indirect costs pointer swizzling indirectly responsible due interactions virtual memory system 
depending operating system features available mistaken dirty pages problem solved ways 
brie sketch chapter contains discussion interactions pointer swizzling virtual memory management 
solutions desirable ones usually require features currently available production operating systems 
portable solutions require ability mount new le system designed manage paging persistent store 
obvious solution pointer swizzling approach similar systems directly map entire persistent store memory sz 
usually limits amount persistent data accessed time 
importantly ects portability mappings virtual address ranges di erent operating systems 
slightly better alternative approach similar objectstore wd speci environment example situation 
systems administrators typically tend software arbitrarily changes application paging behavior adversely ects general performance networked environments 
cally approach page mapped old address 
approach limitations general case resolve basic problem 
narasayya suggest special system call clear dirty status bit page 
idea generalized implement extended primitive communicate variety information application virtual memory system 
better approach modify operating systems support external memory management mechanisms 
operating systems support models exist mach microkernels lie exploited 
example mach supports external pagers pointer swizzling servers swizzle pages loading memory appear clean virtual memory system 
solution require external memory management support kernel modi cations exploiting virtual le system vfs vnode interface provided operating systems 
interface special le system implemented handle paging persistent store le system designed handle pointer swizzling mechanism virtual memory system receives clean swizzled pages avoiding mistaken dirty pages problem 
elaborate solution chapter 
ultimately solution improve operating system implementations provide better separation concerns components address mapping virtual memory management 
discussion related issues deferred chapter 
handling large objects description basic algorithm pointer swizzling page fault time implicitly assumed objects smaller virtual memory page objects single page 
potential problem scheme need ensure object crosses page boundaries persistent store corresponding pages adjacent transient virtual memory 
object page boundary relocated contiguous object indexing access elds properly 
resolve problem large objects handling slightly di erently pages necessary large object reserved page object faulted rst time page accessed loaded memory 
words address space reserved entire object parts object referenced application faulted 
lazy copying data particularly helpful address space reserved object need physical memory ram disk unreferenced pages 
support incremental copying faulting large objects language implementation support operations locating object boundaries maintaining mapping tables track pages belong large objects 
requirements similar garbage collected systems perform page wise card wise operations ael wm example object large array spans multiple pages size individual element may smaller page 
heap 
major di culty supporting operations ciently languages lisp ml slightly conservative versions schemes languages derived pointers limited pointer arithmetic way conservative garbage collectors operate languages bw 
main modi cations allocation deallocation routines provide headers groupings alignment restrictions allow objects identi ed 
large objects pose potential problem system terms exhaustion virtual address space 
page touched holds pointers large multi page objects address space reserved objects pages touched 
programs deal large objects may bene larger hardware address space decreasing frequency address space reuse 
think serious problem applications machines worth considering 
discussed section possible integrate machines require large hardware addresses sharing data 
avoiding address space exhaustion potential problem basic scheme transient memory ll relocated pages long time 
pages ll virtual memory causing excessive paging 
problem process swizzling nearly orthogonal issues levels storage hierarchy inactive page paged backing store normal virtual memory 
may paged swap space temporarily may unswizzled evicted back persistent store 
real problem exhaustion hardware memory exhaustion hardware supported virtual address space 
mentioned previous sections just problem programs millions pages touching page may cause reservation pages address space 
worst case page contains pointers may referenced causing reservation pages pointers current system times pages may touched 
programs conceivable fact near fetched pages holding multi way index tree nodes may approximate worst case 
avoid exhausting virtual address space strategies 
rst smaller pages reduce ective page size slow rate address space 
strategy may entirely ective devised algorithm reclaiming virtual address space incrementally reusing 
describe ways implement ne grained mixed granularity schemes may useful situations programmer control data structures 
smaller page sizes rate address space consumption directly proportional number objects pointers page obvious smaller page sizes favor scheme reducing number pointer swizzled 
ways page sizes reduced discuss 
reduce ective page size part virtual page allocating objects large numbers pointers 
example fourth kb page reduce fanout factor 
naive implementation strategy wasteful desirable avoid actual ram disk storage sparsely 
better strategy fraction virtual page arrange fragments complementary pattern virtual pages share physical ram disk page 
example suppose wanted implement kb fragments kb pages map virtual pages single physical page di erent quarter virtual page data 
physical page aliases virtual page numbers non overlapping pattern allocation ensure object cache block aliased 
solution entirely satisfactory reasons 
deal large objects 
second wastes little physical storage decreases ectiveness translation lookaside bu ers partially virtual page requires virtual physical page mapping virtual memory system 
defers exhaustion address space sense delaying discovery swizzling pointers increases total address space usage long run decreasing usable size virtual page 
hardware operating system provide facility sub page protections possible fault full pages swizzle partial pages reducing amount new address space reserved 
sub page protection produces ect smaller page sizes terms address translation page loaded rst time faulted 
defer discussion issue chapter 
address space reuse easy approach dealing exhaustion address space simply occasionally evict pages virtual memory throw away existing mappings faulting pages 
pages longer faulted current working set restored quickly 
new mappings built pages address space old mappings new mappings reused 
unfortunately method incurs unnecessary bursty tra transient memory persistent store mappings rebuilt working set faulted immediately faulted back 
avoid take advantage fact address translation data caching essentially orthogonal 
really write data reclaim corresponding pages virtual address space 
evicting pages virtual memory easy clean pages simply discarded dirty pages unswizzled written back persistent store 
note just evict page virtual address space keep track pointer assignments page virtual address space assumed pointers pages address space 
reuse page rebuild mappings rst traverse graph pointers rebuild mappings nd pages 
writing simply invalidate incrementally rebuild virtual memory mappings 
pretend write data leave cached locally just access protect pages 
incrementally fault build new set mappings 
page faulted local storage ram disk better pointers simply current mappings way page originally faulted 
obsolete mappings consulted re cases 
page dirty faulted transient memory contains pointers pages previously contain pointers 
reclamation pages application run recreate revalidate mappings current working set 
candidates reclamation pages referenced mass invalidation directly reachable pages 
reclamation policy probably favor evicting pages directly reachable pages touched long time 
increase ciency systems page faults expensive virtual memory system recency information consulted accessible operating system pages assumed part current working set 
pages addresses recomputed immediately access protected avoid access protection faults immediately mass invalidation 
note address space reuse implemented system currently applications requiring expect 
fine grained mixed granularity translation strategy dealing address space exhaustion ne grained pointer wise address translation mechanism speci data structures high fanout 
scheme coarse grained address translation default ne grained address translation selected data structures provide bene additional overhead 
ne grained address translation smart pointer idiom str ede 
smart pointers allow implementation pointer wise address translation behaves standard page wise pointer swizzling scheme requiring additional hardware support 
details mixed granularity address translation discussed section 
sharing compatibility pointer swizzling page fault time general purpose reconciliation layer distinct systems little performance cost 
example support data formats allow sharing data machines bit bit addressing 
course applications truly require huge address space example applications need array indexing multi gigabyte arrays executed bit machines 
sharing pages nodes distributed system costly straightforward scheme pointers unswizzled transmission re swizzled prevailing mappings receiving machine 
cost probably small relative basic trapping messaging costs shared virtual memory 
costs pointer swizzling optimized away cases needed 
network bit machines larger address space unnecessary pages permanently assigned virtual addresses nodes 
data shared format translation costs whatsoever 
pointer swizzling page fault time signi cant advantage serve layer resolve con icts di erent address spaces heterogeneous network containing machines di erent hardware word sizes 
world purely bit hardware desirable 
example consider case merging local area networks shared address space la 
pointer swizzling resolve con icts address spaces renaming process nature pointer swizzling page fault time allows di erent machines sub nets map data di erent local virtual addresses 
requires part system administrators ensure con icts arise systems eventually merged organization restructured acquires 
remaining concern complexity added having memory system rely ability locate pointer elds heap data 
believe avery small cost discussed chapter interface require modifying compiler 
true higher level languages smalltalk ei el modula easier interface memory system 
data formats sharing machines compatibility di erent machines may asingle data format irrespective address word size machine operating data 
particularly attractive shared persistent store distributed virtual memory 
easy accomplish pointer swizzling adjust pointer sizes 
pages transferred machine necessary translate pointers page native format receiving machine 
pointer swizzling requires easy nd pointers page easy convert large persistent pointer hardware supported format 
done translating high order bits page number shorter bit pattern virtual page number adjusting low order bits represent set page 
simplest way ensure persistent data format transient format set part pointer change 
done multiple pointer sizes simply leaving room largest hardware supported pointer size needed machines 
bit pointer eld bit machines bit machines half eld transient pointers bit machines 
half eld goes waste space cost relatively small especially languages elds pointers 
similar approach mg operating system object identi ers disk swizzled actual pointers data loaded memory 
page wise swizzling incurs high overhead checking unswizzled pointers 
object identi ers persistent addresses translations expensive 
linking existing code pointer swizzling page fault time requires changes objects data formats code manipulates allows swizzled unswizzled objects freely programs restrictions may interact 
discussed chapter pointer swizzling page fault time implement orthogonal persistence am 
orthogonal persistence model allows transient persistent objects treated exactly way 
allows existing code typically object code libraries linked application requiring recompilation long libraries need create persistent objects 
transient objects may hold pointers persistent objects vice versa long follow simple rules 
persistent objects saved store transient objects persistent object stale system ensure cleared persistent object accessed 
interfacing languages compilers pointer swizzling page fault time obviously applicable languages lisp smalltalk tagged pointers strongly typed languages modula ml slight restrictions 
main restriction avoidance untagged unions pointers variant part 
untagged unions anyway attractive object oriented features 
success conservative garbage collectors shows programs require little modi cation meet necessary constraints 
unfortunately conservative pointer identi cation done conservative garbage collectors bw su cient pointer swizzling 
precise information object layouts necessary run time accurately locate swizzle pointers 
need mechanism facilitates run time type description rttd simple run time type identi cation rtti designed supporting queries language level information 
chapter describes design rttd mechanism detail description implementation 
debugging information object les extract necessary object layouts 
allows interface existing compilers format debugging information typically independent source language compiler 
implemented pointer swizzling page fault time texas persistent store chapter existing shelf compilers 
rttd conjunction allocator modi cations maintain information object layouts swizzle pointers heap allocated persistent data structures 
fine grained mixed granularity translation pointer swizzling page fault time usually provides performance applications locality 
certain applications exhibit poor locality especially large sparsely accessed index data structures may produce best results coarse grained translation mechanisms 
applications access big multi way index trees example usually applications sparsely access index tree paths followed tree root 
tree nodes large size high fanout rst access node cause pointers swizzled possibly reserve pages virtual address space swizzling probably unnecessary pointers dereferenced 
solution provide ne grained address translation mechanism translates pointers individually doing page time 
coarse grained mechanism swizzling triggered access protection violation translation pointer may triggered events dereferenced 
ways implementing ne grained pointer wise address translation mechanism 
selected implementation strategy remains consistent goals maintaining portability compatibility existing shelf compilers smart pointer abstraction str ede 
section rst brie explain smart pointers abstraction describe smart pointers implementing ne grained translation texas 
discuss ne grained coarse grained schemes coexist single application create mixed granularity environment 
smart pointers smart pointer special parameterized class instances class behave regular pointers 
smart pointers support standard pointer operations dereference cast indexing implemented classes overloaded operators support pointer operations possible execute arbitrary code part operation 
smart pointer class declaration typically form template class class ptr public ptr null ptr operator operator operator 
constructor destructor dereference dereference cast operator cast declaration smart pointer class follows pointer location known 
similar notion swizzling discovery described wd :10.1.1.143.3812
class node node node ptr node node sp node method node sp method assume previously defined regular pointer node object smart pointer node object invoke method regular pointer invoke method smart pointer obvious code fragment declaration smart pointer di erent regular pointer usage identical 
note shown operators declaration smart pointer 
describing private data members smart pointer interface important internal representation 
words necessary ensure smart pointer instance support standard pointer operations matter class structured long interface implemented correctly 
fact clear discussion variations ne grained address translation mechanisms smart pointer need implemented di erently di erent situations implementation choices 
smart pointers originally garbage collectors implement write barriers wil wil pointer updates application called mutator tracked easily allowing garbage collector job 
smart pointers suitable implementing address translation persistence overloaded pointer dereference operations operators implemented translate persistent pointers transient pointers necessary 
smart pointers designed goal transparently replacing regular pointers declarations providing additional exibility arbitrary code executed pointer operation 
essence attempt introduce re ection builtin data types pointers 
described ede impossible truly replace functionality regular pointers completely transparent fashion 
part problem stems inconsistencies language de nition implementation dependence 
advocate smart pointers arbitrary usage board useful certain situations 
fine grained address translation interested building ne grained address translation mechanism smart pointers 
idea swizzle individual pointers entire pages time reduce consumption virtual address space sparsely accessed data structures high fanout 
smart pointers programmer easily choose data structures swizzled pointer basis requiring inherent changes implementation basic swizzling mechanism 
note pointers swizzled individually granularity data transfer units pages individual objects avoid excessive costs 
describe provides limited re ective capabilities form operator overloading user de ned types classes 
possible ways handle 
ne grained address translation discuss fine grained swizzling straightforward way implementing ne grained address translation cache translated address value pointer eld call ne grained swizzling pointer value cached translated 
follow approach problems basic technique 
ne grained swizzling incurs checking overhead pointer dereference rst dereference check swizzle pointer dereferences check nd swizzled virtual address available directly 
signi cant problem equality checks smart pointers compared comparison ensuring pointers representation persistent addresses virtual addresses 
worst case scenario pointers di erent representations swizzled equality check complete 
simple equality check average expensive desired 
obvious solution pointer eld large store persistent virtual address values implemented rc scd 
current context smart pointer internal representation extended hold pointer elds 
technique avoids overhead equality checks carried simply comparing persistent addresses regard swizzling existence corresponding virtual address 
unfortunately serious problem ne grained swizzling peculiar interaction checkpointing 
persistent pointer swizzled virtual address cached pointer eld style modify pointer 
virtual memory protections detect updates initiated application checkpointing purposes updating smart pointer cache swizzled address clash approach generating false positives updates causing unnecessary checkpointing 
course problem rst resetting permission virtual memory protection page swizzling caching pointer restoring protection page 
solution slow requires kernel intervention change page protections modern operating systems optimized actions 
translations described simple ne grained swizzling mechanism unusual interactions operating system underlying virtual memory system reducing attractiveness 
slightly modify basic technique overcome disadvantages losing bene ts 
term swizzling implies translated address cached opposed discarded 
idea implement smart pointers translated avoid caching translated value 
words smart pointers hold persistent addresses translated time dereferenced virtual addresses cached 
equality checks incur additional overhead pointer elds representation hold persistent addresses compared directly 
pointer dereferences incur additional checking overhead 
cost translating add large overhead cost usually amortized done application application may dereference smart pointer computations resulting target object dereferencing smart pointer 
advantage approach translated address values cached pointer elds need modi ed unwanted interactions checkpointing virtual memory system avoided 
approach unsuitable general purpose swizzling mechanism compared costs incurred pointer swizzling page fault time 
mixed granularity address translation possible implement mixed granularity address translation scheme consists coarse grained pointer swizzling ne grained address translation 
interaction swizzling data structures trees handled compiler intervention smart pointer abstraction 
details ne grained address translation scheme hidden abstraction making approach partially re ective 
system con gured ne grained address translation need examine swizzle objects page fault time know data pointers smart pointers translated 
words virtual memory access protections required trigger transfer data pointer swizzling pointer operations user de ned code smart pointers 
access protections access protection violations generated application 
fully ne grained approach may introduce strange interaction virtual function table vft pointers 
virtual functions dynamic dispatch implemented incorporating vft pointer eld points table virtual functions object 
vft pointer inherently pointer eld needs swizzled pointer elds object 
di erence pointer code segment data segment compiler de ned means representation changed user words implement smart pointer 
virtual memory access protections impossible detect vft pointer special compiler generated code 
ict default behavior ne grained address translation needs resolved 
general mixed granularity approach ne grained address translation speci data structures solve problem vft pointers 
novel address translation technique supporting large address spaces stock hardware standard compilers operating system features 
approach designed take advantage fact applications exhibit spatial temporal locality exploit locality way normal virtual memory gaining desirable performance characteristics especially trend larger main memories 
swizzling page fault time add signi cant overhead cpu speeds higher compared disk speeds 
implementation uses conventional virtual memory hardware operating system memory protection facilities check residency persistent data trigger address translations necessary 
avoids need software checks expensive general 
time indirect cost associated pointer swizzling due interaction underlying virtual memory system 
fortunately fundamental limitation technique external overhead due lack interaction operating system resolved operating system support 
pointer swizzling page fault time highly portable uses standard features supported modern operating systems 
furthermore continual checking pointer format unnecessary persistent address translated address format translated value cached locally 
data access proceeds full memory speeds initial faulting swizzling completed 
approach compatible existing shelf compilers special code generation necessary incorporate address translation mechanism 
basic technique coarse grained scheme default unit translation virtual memory page 
situations coarse grained address translation appropriate data structures poor locality characteristics developed portable ne grained mixed granularity address translation schemes 
believe pointer swizzling page fault time wide variety applications 
described chapter provide portable cient persistence mechanism mainstream languages essence providing support bit larger address spaces standard bit hardware 
general suitable reconciliation layer incompatible system components abstractions 
chapter design implementation texas persistent store texas persistent storage system providing high performance emphasizing simplicity modularity portability 
key component design pointer swizzling page fault time default address translation technique implementing persistence large address spaces standard hardware 
chapter describe basic design complete implementation details texas persistent store 
texas designed support orthogonal persistence underlying persistence model 
scheme compatible reachability persistence implemented top approach 
orthogonal persistence allows texas support standard shelf compilers emit code usual way having distinguish transient persistent objects 
standard compilers provides added bene ciency compatibility 
current implementation ers simple checkpointing capabilities basic logging mechanisms storage management data recovery 
described chapter modules independent parts system replaced better algorithms necessary 
currently implementation allows persistent store saved regular le le system directly raw disk partition 
le system abstraction layer designed allow advanced storage management logging strategies change underlying implementation transparently 
similarly implemented virtual memory abstraction layer simplify portability di erent operating systems 
discussed earlier pointer swizzling page fault time ciently support large address spaces standard hardware 
intend texas addressing scheme extensible scalable networked systems single address space machines large amounts data apiece 
space 
despite fact live hilly area name texas intended suggest large goals features texas designed speci goals features mind portability texas compatible shelf compilers standard operating systems 
requires minimal support operating system virtual memory protection access protection violation handling capabilities 
modern operating systems provide features 
addition texas require special system privileges user link texas application superuser intervention 
transparency texas allows application access transient persistent objects way distinguishing 
words persistent objects manipulated code manipulates transient objects persistent objects reside virtual memory 
client code need distinguish transient persistent objects forced 
types persistent corresponding transient objects systems persistence implemented deriving top level persistence class adhering speci interface reading writing objects 
ciency cases access persistent objects fast access transient objects 
overhead associated persistent object access initial cost translating persistent pointers swizzled pointers page brought virtual memory 
accesses persistent object memory occur full memory speed additional checks 
addition overhead imposed access transient objects 
robustness texas uses simple logging techniques provide checkpointing crash recovery facilities 
system designed compatible advanced storage management logging facilities achieving improved performance exibility 
scalability repeated touches page incur extra overhead address translation page swizzled unprotected accesses cause access protection violations 
addition costs incurred page fault time decrease memory sizes increase number instructions faults increases 
compatibility implementation designed compatible existing code libraries manipulate persistent transient objects alike 
recompilation necessary library needs create persistent objects 
user interface simple minimal source code modi cations necessary application take full advantage texas persistent storage recovery facilities 
address translation scheme reconcile data formats sharing data heterogeneous machines merging distinct address spaces 
modularity texas composed set largely orthogonal modules address translation caching checkpointing handled nearly disjoint code 
system contains abstractions operating system interaction respect virtual memory le system facilities 
development simpler facilitates easier experimentation enhancements 
pay go costs pointer swizzling costs incurred programs feature programs 
parallels usual policy language implementations pay features 
basic design driving requirement basic design maintain simplicity modularity inthe system 
achieve texas divided modules designated speci responsibility 
note algorithms implementations straightforward easily replaced modules better suited speci applications 
example texas currently supports easily adapted languages replacing language speci modules 
compiler language dependent language independent type descriptor generator binary code debugging information type descriptors open pstore close pstore checkpoint manipulate pstore application language interface memory manager get heap page malloc new free delete memory allocation mapping swizzling module file recovery find objects page compile time run time storage recovery manager basic design texas shows main modules system interactions 
obvious language interface memory manager language dependent need interact actual data objects application 
contrast caching storage recovery management done terms uninterpreted blocks data 
currently implemented language interface trivial extend making minimal changes especially memory manager require modi cations 
mapping pointer swizzling module independent speci language needs interact memory manager locate data objects memory 
addition needs information layouts objects run time locate swizzle pointers 
kind run time type description rttd captured compile time provided swizzling mechanism run time type descriptor records 
implementation type descriptor generator debugging information typically language independent 
complete details rttd case study implementation discussed chapter 
noted various modules shown designed orthogonal 
example swizzling mapping manager interact storage recovery manager speci ed published interface 
orthogonality allows easy replacement speci modules ecting modules rest system 
implementation details implemented texas library client applications linked library create manipulate persistent objects texas persistence mechanism 
texas relatively small terms implementation code size lines run time footprint kb making suitable applications operate small memory constraints 
code ported variety operating systems sunos solaris linux mach ultrix os ports possible modern operating systems nt 
texas works gnu compiler unix platforms sun compiler sunos solaris ibm visualage compiler os 
remainder section describe implementation details various components system implement features mentioned section 
note algorithms straightforward easily replaced similar algorithms better suited speci applications 
texas currently implemented modi ed adapt languages replacing user interface languages modules heap management run time type description languages similar 
heap management texas allows applications access multiple persistent stores heap addition applications may create transient objects normal transient heap 
naive memory manager create separate heap areas persistent transient objects 
persistent heap start di erent arbitrary address heap grow shrink independently 
obviously design requires ad hoc static partitioning process virtual address space may possible desirable di erent platforms 
memory manager avoids statically partitioning address space unnecessary restrictions number pages particular heap 
avoid static partitioning limitations memory manager manages heap space non contiguous sets pages 
page holds objects belonging exactly heap pages belonging heaps may interleaved order memory 
large objects single page allocated contiguous pages allow normal indexing pointer arithmetic expected pages agged part large object ensure correct swizzling behavior 
heap allocation system texas memory manager maintains data structures record free heap space 
transient persistent objects reside page separate free lists maintained heap 
free lists persistent heaps stored data structures appropriate persistent store free space partially lled persistent pages re allocated subsequent program runs 
currently texas uses segregated storage allocation policy memory allocation transient persistent objects 
describe basic algorithm memory manager discuss abstractions plug arbitrary memory manager segregated storage allocation model 
algorithm description name implies segregated storage allocator allocation objects speci criteria 
current implementation objects segregated basis size 
virtual memory page split uniformly sized chunks holds single object 
possible arbitrarily large number unique object sizes allocator maps di erent sizes limited number size classes allow easy memory management 
size class de ned simply representation small range object sizes objects allocated free chunks memory large hold actual objects possibly wasted space exact approach object size allocated page containing chunks correspond object size class 
typical scheme size classes powers example 
compute size class object size nding number value closest power higher object size 
words size class derived rounding object size closest value power computing log base value 
obvious approach generate chunk sizes byte bytes bytes bytes bytes bytes corresponding powers series starting 
note small chunk sizes example bytes may suitable actual allocation due memory alignment constraints storage requirements allocator meta data 
scheme works fairly quite easy implement practice 
unfortunately subject potentially severe external fragmentation rk attempt split coalesce blocks order satisfy requests size classes 
tradeo expected internal fragmentation external fragmentation 
spacing chunk sizes gets large larger number di erent object sizes fall size class allowing space sizes reused 
hand powers series generate larger internal fragmentation size classes get bigger space potentially wasted 
reduce fragmentation ects interspersed series chunk sizes normal powers series starting powers times series starting 
resulting chunk sizes bytes producing twice chunk sizes compared typical approach allowing ner granularity control object allocation 
free list heap structured vector separate free lists di erent size class 
object allocated free list appropriate size class empty new storage allocated operating system heap immediately divided uniform sized chunks corresponding required size class linked free list 
special handling required allocate large objects size classes larger object sizes automatically ensure multiple pages allocated necessary 
splitting page uniform sized chunks object identi cation extremely easy 
need examine header rst object page size class size class objects page determined header 
alignment objects headers follows trivially 
special exception case objects large single page 
recording actual size class pages page marked part large object object boundaries stored special table starting addresses type descriptors 
allocator abstraction layer allocator expends little ort attempting coalesce split free blocks larger smaller blocks coalescing splitting potentially ect locality fragmentation 
simple segregated storage allocator quite fast usual case especially objects size repeatedly freed reallocated short periods time 
policy coalesce split free blocks done object freed subsequent allocations size quickly satis ed removing block free list 
general segregated storage policies known prone higher fragmentation joh 
chose implement memory manager policy primarily study memory allocation policies research focus needed fast implementation simple allocation policy 
desirable approach de ne allocator abstraction layer speci es basic functionality required texas memory allocation policy 
possible replace underlying allocator simply plugging implementation di erent policy adheres interface abstraction layer 
texas uses virtual memory page granularities persistence chapter allocator ensure page belongs single heap 
addition allocator provide mechanism store type information chapter persistent object allocated 
memory manager requires allocator able locate type information object pointer interior object 
virtual memory page possible nd objects exist page 
abstractions easy arbitrary policy best memory allocation texas long implementation policy provides appropriate functionality dictated abstraction layer 
caching pointer swizzling page fault time implements address translation top abstraction conventional virtual memory exploit fact underlying virtual memory caching mechanism 
page loaded virtual memory persistent store may paged paged back necessary intervention swizzling mechanism 
pages containing swizzled pointers may paged independently transfer pages virtual memory persistent store 
texas explicitly manage physical memory relies virtual memory caching usual way 
texas take advantage protection features provided modern virtual memory system look beneath virtual memory abstraction se distinguish pages cached main memory ram backing store disk 
approach appropriate applications typical cad databases simply replacing conventional les normal applications 
paging swizzled data locally avoids unnecessary communication persistent store avoids smaller cost pages 
applications preferable page directly persistent store 
avoid redundant storage pages persistent store local disk swap space 
reduce possibility pages paged backing store subsequently paged back written persistent store 
naturally evicting pages directly back persistent store especially appropriate diskless clients 
texas easily modi ed evict pages back persistent store control page outs 
approach achieving similar mach external pager facility system somewhat complex portable 
discuss issue detail chapter 
possible implement persistent store normal le le system see section 
virtual memory system caching important avoid caching persistent storage le le system cache 
page loaded current implementation uses hidden header eld allocator meta data 
believe problem addressed satisfactorily writing dirty pages back persistent store early ect cleaning describe section 
persistent store virtual memory implicitly cached caching page le system bu er waste resources 
persistent storage le stored uncached area disk avoid double caching 
virtual memory abstraction layer implemented virtual memory interactions intermediate abstraction layer allowing away virtual memory facilities required system getting involved low level details facilities implemented di erent operating systems 
greatly helped ort required port texas multiple operating systems experiment di erent virtual memory primitives single operating system 
texas requires minimal interactions underlying virtual memory system 
basic operations required texas supported modern operating systems follows ability allocate page virtual address space ability set unset memory access protections access read read write virtual memory page generation prede ned signal application access protection violations ability specify user de ned signal handlers catch signals generated due violations 
abstraction layer de nes interfaces allow texas communicate underlying virtual memory system involved actual implementation details 
chapter contains detailed discussion various interactions texas pointer swizzling page fault time underlying operating system 
run time type description de nition pointer swizzling needs know exact locations pointer elds various persistent objects swizzled 
traditionally run time support systems garbage collectors tend conservative approach value appears pointer assumed pointer 
unfortunately su cient pointer swizzling techniques precise information pointer locations required order function swizzle pointers correctly 
solve problem necessary access implementation level information object layouts run time pointer elds identi ed accurately 
introduced run time type identi cation rtti facility su cient provides language level information 
notion run time type description rttd facility designed speci goals providing implementation level information run time 
chapter provides description rttd approach including details implementation texas 
handling virtual function table pointers common implementation dynamic binding virtual functions lip 
minimize performance impacts dynamic binding virtual functions implemented virtual function tables 
vft class virtual function pointer appropriate vft stored object instantiated class virtual functions 
implementation adds instructions overhead typically index table load virtual function invocation 
poses challenge pointer swizzling schemes vft pointers usually executable code normal data pointers swizzled unswizzled usual 
modi ed normal swizzling algorithm adapt virtual function table pointers 
basic idea convert vft pointer pointer string representing name corresponding table executable 
conceptually string implemented persistent object converted vft pointer handled automatically normal swizzling mechanism 
practice implement converting vft pointer index persistent table contains names executable 
actual conversion done performing lookup table maps vft addresses names vice versa 
swizzling vft pointer reverse process vft name look corresponding address current executable replace index actual address 
disk storage management texas allows persistent store implemented normal le standard le system raw disk partition explicitly managed le system 
implemented abstraction layer contains standard le operations open read write interacting underlying storage management module 
abstraction layer porting di erent le systems di erent interfaces relatively easy 
example interface raw disk partition easily implemented abstraction layer higher level code completely unaware actual details 
remainder section brie discuss issues regarding storage management 
chapter provides details important issues related storage management persistent object stores general 
checkpointing recovery persistent store distinction conventional heap les lost explicit checkpointing take place saving changes le 
texas useful persistent store supports checkpointing recovery 
pointer swizzling virtual memory access protections determine pages modi ed application save pages persistent store actual checkpointing triggered programmer controlled language level interface 
typically vft pointers virtual function tables corresponding speci executable 
texas conducive undo redo undo redo logging strategies described hr 
current implementation uses phase write ahead logging mechanism provide atomic checkpoints 
implement undo redo strategy shown 
virtual memory phase phase log recovery phase persistent store logging mechanism basic idea ensure dirty modi ed copies pages safely stored log persistent store updated 
application requests checkpoint action modi ed pages checkpoint rst saved log phase persistent store modi ed phase crash second phase leave store inconsistent state cient information log redo updates persistent store recovery phase consistent state undoing partial changes 
crash recovery phase requires repeating phase succeeds 
recovery process idempotent repeated writes due retries produce result 
write ahead logging mechanism implement undo strategy 
undo redo basic idea retain clean unmodi ed copies pages modi ed application 
copies stored log side time application attempts update pages modi ed 
strategy phase ensures unmodi ed pages saved log phase started crash second phase leave persistent store inconsistent state cient information log undo updates persistent store 
recovery phase guaranteed idempotent ensuring crashes recovery actions 
sub page logging coarse grained page wise pointer swizzling attractive cases designed exploit spatial locality 
short transactions transactions poor locality characteristics page wise checkpointing ine cient save unmodi ed data example single write page transaction cause entire page written disk page wise checkpointing 
system designed primarily applications relatively long transactions cad applications provide support small transactions 
sub page logging originally proposed attractive short transactions checkpoint areas memory smaller pages 
writing entire dirty pages write parts page changed di ng clean copy page 
ect trading cpu cycles disk costs expending cpu cycles reduce amount data written 
advantageous huge disparity cpu disk speeds 
log structured storage system re ning simple write ahead logging scheme replace log persistent storage le log structured storage system lss supports checkpointing recovery directly ciently 
lss essentially lower levels logstructured le system ro manipulates single large uncached le typically raw unix disk partition 
log structured store entire disk le log log acts nal repository data pages 
blocks single home location disk 
logical blocks migrate current version block simply written log 
blocks indexing information treated similarly 
changes le committed top level indexing information updated point new versions modi ed blocks 
design implementation texas persistent storage system uses pointer swizzling page fault time primary address translation mechanism support large address spaces standard hardware 
enumerated main goals features texas designing implementing system 
basic design philosophy ensure system divided independent modules interacted published interfaces 
important details corresponding implementation texas 
discussed issues heap management caching abstraction layers implemented interacting memory allocator underlying virtual memory system 
implementation abstraction layers line general design philosophy dictates orthogonal modules easily replaceable similar modules implement published interface 
noted issues particularly virtual memory caching simply implementation choices independent address translation strategy 
discussed various factors related le system interaction permanent storage management 
speci cally described logging techniques implementing simple checkpointing recovery facilities texas 
current implementation incorporates simple write ahead logging advanced mechanisms sub page logging feasible certainly impossible implement 
implemented advanced storage management techniques detail focus high performance address translation schemes 
brie discuss issues storage management research directions chapter 
implementation texas lines code system fairly robust real applications commercial providing fast inexpensive persistence 
basic system di erent avors unix non unix system os believe easily ported modern operating systems technical obstacles 
chapter performance texas persistent store previous chapters entire theory pointer swizzling page fault time address translation texas persistent store 
noted overhead texas small compared costs data loaded memory persistent store zero data loaded memory faulting 
chapter discuss various issues regarding performance texas pointer swizzling page fault time results support original assertions performance 
standard oo database benchmark cat minor variations workload performance measurements 
note oo benchmark synthetic benchmark designed speci cally purpose measuring performance object oriented database systems persistence facilities 
oo similar benchmarks necessarily suitable quantitative comparisons di erent systems validated real applications domain represented benchmark 
results interpreted qualitative results quantitative performance real applications 
speci cally important remember results obtained empirically ultimately derived synthetic benchmark mapping benchmark behavior real applications 
discussion benchmarking limitations available section 
oo crude benchmark strongly correspond real application performance measurements reasons 
oo simple measuring raw performance pointer traversals interested fairly amenable modi cations di erent address translation granularities 
synthetic benchmark opposed real application appropriate situation performance cases zero overhead faulting dependent rate faulting usually minimal overhead compared costs cases 
crude benchmarking practical way measure performance di erent components system easy separate costs underlying benchmark usually di cult real application 
course cautioned earlier careful interpret results qualitative terms 
rest chapter organized follows 
section presents experimental design gathering actual results sections followed discussion section 
part performance results data benchmark runs popular operating systems linux section solaris section highlight impact operating system implementation performance 
section discuss issues related limitations benchmarking focusing mainly oo oo database benchmarks 
concluding remarks section 
experimental design interested measuring performance pointer swizzling page fault time implemented texas speci overheads various subcomponents system 
addition interested studying impact variations basic scheme example changing address translation granularity general performance 
section describe experimental design methodology followed gathering experimental results 
rst brie examine di erent benchmarks available discuss reasons motivated choice oo benchmark described detail 
describe experimental methodology performance analysis measurements including issues strategies raw vs le system precise timing requirements 
describe hardware operating systems gathering results 
benchmarks popular object database benchmarks de facto standard oo object operations benchmark cs 
oo rst widely database benchmarks followed abm oo cdn benchmarks 
oo benchmark designed successor oo benchmark supports advanced data structures complex operations structures represent hypothetical cad application 
oo performance measurements fundamental reasons 
oo simple interested measuring raw performance pointer traversals calculate basic overhead coarse grained address translation mechanism 
results obtained benchmark interpreted carefully 
pointer traversal performance traversal results qualitative indicators quantitative performance real applications 
believe oo oo benchmarks unsuitable performance measurements orthogonally persistent systems general discussed section 
rest section describes oo benchmark primary workload measure performance various subcomponents pointer swizzling page fault time texas 
oo benchmark database oo benchmark database set part objects representing parts hypothetical engineering database application interconnected 
benchmark speci es database sizes number parts stored database small database containing parts large database containing parts 
rationale specifying database sizes allow performance measurements system entire database small main memory compare situations database larger available memory 
parts indexed unique part numbers associated part 
part connected direct link exactly parts chosen partially randomly produce locality 
particular connections nearby parts nearness de ned terms part numbers part considered near parts parts part numbers numerically close number part 
remaining connections uniformly randomly chosen parts 
direct connections referred forward connections 
addition part maintains set reverse connections containing pointers parts forward connections part 
forward connections implemented direct pointers part objects 
part xed size array pointers represent forward connections number forward connections xed benchmark speci cation 
addition part data elds integers strings benchmark operations 
oo benchmark operations oo benchmark suite comprises di erent types operations just single test 
operations broadly classi ed types lookup locate predetermined number randomly chosen parts parts index invoke empty procedure part traversal perform depth rst traversal connected parts starting part traversing levels deep total parts including possible duplicates invoke empty procedure visited part insertion allocate insert new parts database criteria making forward connections 
oo operations designed phases engineering database application 
example lookup operation measure performance indexed object retrieval database system 
contrast traversal operation concentrates benchmark speci cation de ne data structure index tree experiments 
raw performance pointer traversals interested measuring performance pointer swizzling page fault time 
insertion operation suitable measuring performance checkpointing updates modi es database disk 
approach variation traversal operation described wd basic idea similar traversal addition invoking empty procedure visited parts allows updates predetermined probability :10.1.1.143.3812
clear variation benchmark tightly coupled randomized interconnections cause scattered updates entire database poor locality 
believe approach caution page wise checkpointing look unnecessarily bad making page wise di ng whi look unrealistically attractive 
randomized interconnection scheme exhibits locality connections close disastrous ects locality simple algorithms operating data average tenth pointer traversal accesses randomly chosen part close 
oo designers aware degree specify traversals executed times starting di erent root part 
rst traversal cold cache database cached memory subsequent traversals cache getting warmer 
addition traversals executed hot cache contains data traversed 
accomplished starting hot traversals root warm traversal essentially repeating warm traversal exactly guaranteeing visited parts memory 
methodology oo benchmark traversal operation performance measurements 
traversal set contains total traversals split follows rst traversal cold traversal data cached memory warm traversals data cached memory nally hot traversals data cached memory 
note di erent standard benchmark speci cation contains traversals split cold warm hot traversals 
chose run warm traversals believe traversals su cient provide meaningful results especially large database case 
describe section oo benchmarks necessarily indicators general application behavior unsuitable quantitative comparisons di erent systems 
random number generator ensure warm traversal selects new root part initial starting point visiting di erent set parts traversal 
course warm traversals visit parts visited previous traversal randomized interconnections data structures 
run entire traversal set traversals multiple times interspersed chill program memory runs ensure cold traversals truly cold 
average runs discarding outliers obtain nal performance results 
program allocates data available memory size writes le disk reads back clearing memory le system bu ers process 
remainder section describes methodology measure basic performance system study various granularities address translation impact performance pointer swizzling system 
discuss issues related precise timing presenting empirical results starting section 
basic performance measurements basic performance analysis primarily interested measuring overhead pointer swizzling page fault time various phases benchmark execution 
accomplish placing timers various strategic points code measurements timers accurately identify costs di erent components system 
basic timers setup pictorially depicted 
total time start traversal traversal protection fault access protected page fault handler load swizzle page load page pstore swizzling swizzling return handler timer placements run time measurements gure shows imaginary time line single traversal 
total time traversal including faulting swizzling may necessary measured starting timer traversal stopping 
possible benchmark access objects protected pages traversal violation called protection fault generated rst access protected page 
pointer swizzling module texas services fault loading swizzling corresponding page database 
calculating time spent di erent parts system traversal record time various events occur faulting swizzling page 
shown gure individual timers measure time reading page disk total time reading page swizzling swizzling total time handling single protection fault user level including swizzling swizzling 
summing timer values entire traversal gives total time component system traversal 
simple arithmetic subtraction calculate time spent pointer swizzling corresponding overhead compared benchmark costs 
time component accurately measure approach time taken kernel service fault time point fault generated fault handler gains control shown jagged edge 
similarly return fault handler timed minor equivalent function call return 
estimate values measuring stand test program generates protection faults tight loop 
measure total time entire loop divide number faults get average time required kernel service fault transfer control user level fault handler return handler 
believe estimation acceptable get underestimate lower bound cost due caching ects 
details general exception handling performance modern operating systems discussed chapter 
oo benchmark traversal characteristics basic oo traversal set comprised traversals described earlier broadly divided phases 
overhead system typically varies phase depending behavior access patterns benchmark phase 
phase may thought representing applications exhibit behavior similar particular phase 
phases characterized follows hot traversals correspond situation activity benchmark operating data faulted memory 
similar cpu intensive applications rst load xed amount data memory operate exclusively data execution applications typically want simple persistence mechanism data forced roll ad hoc techniques 
pointer swizzling page fault time imposes absolutely overhead applications new data faulted existing pointers swizzled major part execution 
cold traversal rst warm traversals typically represent spectrum 
data accessed benchmark traversals fetched disk phase characterized lot faulting requests traversal parts seen 
phase corresponds applications largely intensive equivalent amount computation 
applications overheads smaller cost usually dominates performance 
third phase characterized moderate faulting behavior interspersed general computation representing middle ground faults generated tight test program kernel code data structures fault handling cached possibly second level cache rst iteration 
actual application bene caching normal faulting behavior 
phases 
applications generally phase going intensive phase loading large amounts data 
overhead system phase vary signi cantly depending application behavior faulting patterns 
performance results sections show empirical data supports classi cation benchmark traversal set 
file vs raw operating systems normal circumstances reads writes regular kernel example seg map driver svr systems 
read system call invoked data rst read le kernel space copied user space user speci ed bu er 
addition operating systems implement sequential readahead mechanism akin simple lookahead prefetching read data requested disk seek minimizing costs 
prefetched data stored le system cache transferred user space application requests data evicted memory 
le system readahead caching works favorably normal applications read write data disk 
purposes obviously ine cient access patterns unsuitable caching 
speci cally know data cached virtual memory causing unnecessary double caching caching user space kernel space 
particularly undesirable le system cache competes available physical memory reducing ective ram available virtual memory caching 
solution avoiding le system caching raw device provides direct interface raw partition disk involving le system 
read write raw device causes actual operation data copied directly user space 
avoids double caching le system reads data requested prefetching 
usually known raw distinguish le done normal le system 
currently linux provide user level support raw normal le local disk attached test machine storing benchmark databases 
ects le system caching readahead typically evident small database results database ts easily available ram readahead pays entire database accessed traversal set 
large database results linux aggressive le system bu er management reducing adverse ects virtual memory caching performance 
situation quite di erent experiments solaris 
linux solaris support raw device allowing avoid unwanted caching readahead 
section results solaris corresponding le raw loading data database highlight important di erences strategies 
believe feature development writing 
le go address translation granularities addition performance overheads interested comparing various address translation granularities described chapter 
standard pointer swizzling page fault time strategy corresponds coarse grained address translation approach pointers page swizzled page loaded memory regardless accessed application 
pure ne grained scheme falls spectrum realized smart pointers normal language de ned pointers persistent data structures 
scheme performs pointer wise address translation translating persistent pointers virtual memory addresses time persistent pointers dereferenced 
extremes mixed granularity address translation approach uses combination smart pointers normal pointers persistent data structures mix coarse grained ne grained address translation granularities 
modi ed data structures basic traversal oo benchmark implement di erent address translation granularities 
pure coarse grained ne grained approaches implemented normal pointers smart pointers respectively benchmark data structures 
implemented mixed granularity approach modifying parts index structure smart pointers maintaining normal pointers rest data 
believe tree data structure implement parts index appropriate conversion sparsely accessed data structure high fanout typical access characteristics topological properties data structures suitable ne grained address translation 
precise timing experiments described far need highly precise timing mechanism accurately measure overheads system di erent situations 
furthermore show empirical results overheads system extremely small placing additional requirement high resolution timers 
unfortunately commonly available timers modern operating systems poor resolution order milliseconds 
modern operating systems provide various system calls measure cpu time real wall clock time event application 
cpu time time spent processor execution real time total wall clock time event including time spent waits paging context switches cpu time split user system components corresponding time spent executing processor user mode kernel mode respectively 
typically best resolution real time timers modern operating systems special hardware support order microseconds 
resolution tends lower cpu time timers added overhead maintaining appropriate data structures tracking kernel boundary crossings execution 
example resolution cpu timer mhz intel pentium pro processor running solaris approximately milliseconds coarse considering fact processor execute instructions time frame 
millisecond resolution equivalent time required execute approximately instructions 
obviously resolutions coarse purposes low overheads system especially compared costs 
fortunately platforms compatible intel pentium architecture contain special hardware allows high resolution timing measurements granularity processor clock cycles 
basic idea exploits bit register pentium architecture register counts number processor clock cycles reboot providing true ne grained mechanism precise timing 
instruction mnemonic read time stamp counter read current value stored register 
counter register associated instruction relatively easy build timer precise measurements various low overhead events terms clock cycles 
relatively minor downside cycle timers measure real time additional support operating system measuring cpu time granularity 
order minimize ects arbitrary swings real time measurements due transient events run benchmark suite multiple times unloaded machines average results discarding signi cant outliers 
experimented solaris high resolution time system call 
timer measures real time typical resolution microseconds actual resolution depends underlying hardware 
platforms described resolution microseconds 
call cially supported arbitrary hardware obviously portable clock cycle timer described usable pentium compatible processors 
cycle timer provides better granularity experiments run pentium platforms cpu time measurements address translation granularity comparisons run sparc platforms 
hardware operating systems ran various benchmark operations linux solaris platforms gain insight behavior popular widely operating systems 
able derive qualitative operating systems interesting di erences potential improved 
operating systems identical hardware setup di erences component manufacturers relevant study 
test machine equipped mhz intel pentium pro processor kb cache mb ram 
operating system versions linux current major stable release linux solaris current major release solaris 
course gathering results sparc platforms performance measurements solaris 
results correlated pentium platform useful sanity check 
modi ed version timer originally developed mark johnstone 
approaches preprocessor macros inline procedures containing assembly code access special register suggested various usenet newsgroups devoted linux 
writing current minor stable release version 
addition standard solaris measurements needed access solaris platform main memory big completely large database ram 
describe setup needed validate theory speci behavior solaris workloads involving databases bigger available memory size 
purpose test machine upgrading memory mb su ciently large purposes 
comparison di erent address translation granularities necessary measure cpu time variation costs typically di er terms cpu execution 
overheads relatively small cpu time timers coarse granularity di cult accurately measure cpu time modern processors 
older mhz sparcstation elc experiments processor machine slow set coarse granularity cpu time timer 
believe controlled older slower processor acceptable results reported relative performance compared variations executed processor 
instruction count pro ling results part results rst analysis instruction count pro ling various key components pointer swizzling page fault time mechanism implemented texas 
qpt bl instruction count pro ling tool purpose measured costs swizzling single pointer swizzling entire page 
qpt similar unix pro ling tool gprof important distinction 
gprof reports results terms absolute time procedure qpt capable calculating number instructions procedure analyzing instrumenting basic blocks executable code 
useful pure overhead measurements output qpt terms number instructions procedure absolute result independent procedures application 
contrast gprof suitable general pro ling comparative analysis highlights problem areas bene optimization compared parts application 
feature instructions translate single pointer decode type descriptor record swizzle page normal decoding swizzle page optimized decoding table estimated instruction counts table shows cost important components system 
basic result cost translating value single pointer approximately instructions 
bulk cost attributed hash table lookup address value pointer eld translated 
note estimate untuned hash table implementation highly optimized data structures algorithms 
optimizations possible reduce translation cost half current amount 
note cost translating single pointer measured isolation excludes costs actions may necessary swizzling directly related actual translation 
example swizzled value new page seen reserve page allocating virtual address space operating system access protecting new space 
necessary ensuring swizzling works correctly course application directly involved translation single pointer excluded measurements 
important cost accounted pointer swizzling cost decoding single type descriptor record locating various pointer elds object described record 
average oo benchmark type descriptor record contains information data pointers virtual function table vft pointer cost decoding atype descriptor record approximately instructions 
apart measuring costs speci routines isolation equally important measure costs higher level abstraction study ect swizzling performance 
purpose measured number instructions required swizzling entire page including costs supporting actions reserving new pages address space decoding type descriptor records shown table approximately instructions necessary average swizzle page oo traversal operation 
cost reduced optimizing decoding type descriptor records 
size type descriptor record objects calculate objects virtual memory page 
cost decoding type descriptor records page approximately instructions third total cost swizzling entire page 
chapter describe optimization reduce cost decoding type descriptor record single procedure call reducing page swizzling cost approximately instructions 
today commonly available processors rated instructions second equivalent twentieth millisecond 
obviously insigni cant compared typical costs incurred application fetching data disk 
performance linux hot traversals small large database experiments linux correspond rst cpu intensive phase traversal set described earlier 
general large database better suited second intensive phase database relatively big warm traversals pages seen keeping activity 
hand small database results typically highlight third phase database loaded memory rst traversals due benchmark locality characteristics le system readahead 
type descriptor records objects maintain run time type information chapter 
rst detailed results large database followed corresponding set results small database 
mentioned highlights di erent characteristics access patterns corresponding behavior texas 
set results database size split parts comprising raw performance data measure real activity traversal set lastly overhead texas pointer swizzling percentage time total benchmark time 
section brief analysis basic results database sizes 
large database results start raw performance numbers oo forward traversals large database 
database contains parts approximately mb size roughly third available ram test machine 
basic performance shows run time entire traversal set traversals large database 
data plotted log scale additional detail traversals 
gures gures performance results contain multiple plots corresponding di erent component system 
total time traversal labeled total gures obvious measure 
addition gures include costs di erent components plotted cumulative manner starting cost 
particular plots labeled short swizzling fh short swizzling correspond measurements timers placed various strategic points code see 
generate plot includes estimated time required operating system trapping protection faults labeled fh short fault swizzling 
alternatively plot labeled texas sum components fault swizzling ectively total overhead texas pointer swizzling page fault time 
term real indicate actual disk including disk seek performed request satis ed cache 
clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database log scale linux individual plots di erent components discernible time largest component cold warm traversals texas overhead comparatively small 
observation supported fact lines various plots close log scale see 
low overhead pointer swizzling page fault time evident results figures show cold warm traversals traversals 
shows performance hot traversals traversals expected absolutely costs texas overhead traversals zero 
clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database linux clock cycles traversal total fh fh traversal number times traversals large database linux figures note cost dominates traversals overhead texas comparatively minimal 
recall texas overhead essentially di erence plots labeled fh fact traversals hard distinguish individual plots corresponding components texas various gures 
measuring real activity results obvious oo benchmark traversals large database exhibit characteristics intensive application rst traversals 
speculated earlier behavior occurs database large randomized interconnections cause new pages referenced faulted warm traversals 
obvious way con rm hypothesis measuring number real requests traversal entire traversal set 
note di erent number reads issued texas loading pages database memory read requests translate real due le system caching readahead 
unfortunately operating systems provide convenient way precisely measure real activity 
count number major page faults incurred traversal get approximation 
reasonable major page fault kernel fault requires real disk serviced 
words kernel wait request satis ed reading writing disk le system cache 
major page faults indicator real activity reads writes le system implemented internal kernel page faults modern unix variants 
major page faults texas read requests number pages traversal number page faults traversals large database linux presents measure number reads issued texas traversals 
note correspondence number reads issued texas number protection faults number pages swizzled fault protected page texas rst issues read request load page persistent store 
obvious number new pages read memory gradually decreases cache gets warmer 
real activity decreases proportionately reaches zero warm traversals 
percentage overheads results far conclude direct overhead pointer swizzling page fault time texas minimal presence zero shows empirical data supports large database traversals 
fh fh percentage time traversal number overhead percentage time large database linux plot costs various components pointer swizzling mechanism percentage time traversal 
plot labeled fh represents total overhead pointer swizzling page fault time implemented texas 
clear gure average overhead cost maximum just 
obviously small compared costs incurred running application 
phrases number protection faults number reads issued number pages swizzled interchangeably depending context usage 
number major faults higher number reads issued texas gure 
may unusual okay major page faults include faulting behavior required memory replacement policy 
note include indirect cost pointer swizzling related unnecessary page outs mistaken dirty pages issue current experiment paging large database 
texas percentage total time traversal number overhead percentage total time large database linux interesting metric overhead texas percentage total run time actual benchmark traversal including may necessary traversal excluding costs texas 
measure gives approximation overhead imposed ordinarily non persistent application modi ed texas persistence layer 
plots metric traversals large database 
addition gure plots time percentage total time traversal determine fraction benchmark time typically spent overhead 
note texas overhead low cold warm traversals reinforcing earlier performance pointer swizzling page fault time 
comparison cost majority benchmark run time traversals 
expected overheads drop zero hot traversals de nition cause faulting swizzling 
small database results results large database unequivocally shown pointer swizzling page fault time techniques impose major overhead run time application presence activity 
results oo benchmark traversals small database highlights important situations 
database contains objects small tenth size large database mb easily main memory 
basic performance texas valid quantitative variations related interactions locality characteristics operating system 
basic performance figures performance entire traversal set small database 
shows run time entire traversal set traversals log scale rest linear scale di erent traversals 
clock cycles traversal total fh fh traversal number times traversals small database log scale linux clock cycles traversal total fh fh traversal number times traversals small database linux clock cycles traversal total fh fh traversal number times traversals small database linux clock cycles traversal total fh fh traversal number times traversals small database linux clock cycles traversal total fh fh traversal number times traversals small database linux consider plots performance results various components traversals compare corresponding plot large database 
major di erences sets plots partly due size database poor locality benchmark traversals interaction le system caching readahead mechanism operating system 
plots look di erent traversals small database structure conforms phases described earlier divided qualitative regions follows intensive region consisting cold traversal rst warm traversals left including traversal figures texas overhead obviously small compared cost typically dominates run time cpu intensive region consisting hot traversals right traversals texas overheads zero mixed behavior region consisting rest warm traversals middle part traversals little complicated overheads vary signi cantly number faults requests traversal 
rst regions obviously support drawn large database results discussed 
focus third mixed behavior region corresponds phase exhibits moderate faulting activity interspersed computation 
unusual behavior region related fact entire database small memory loaded memory prefetched le system cache rst traversals poor locality randomized interconnections 
result warm traversals pay cost real disk seeks requests satis ed le system cache 
note traversals speci cally traversals mixed behavior region cost fairly high clock cycles texas overhead small comparison 
requests traversals satis ed le system cache require real activity 
contrast sixteen traversals speci cally traversals intermixed mentioned incur cost cycles equivalent microseconds test machine mhz clock rate 
fact typical disk latencies order milliseconds impossible number represents cost real request 
requests satis ed le system cache involving moving parts paying software costs 
traversals texas overhead appears signi cant clock cycles masked costs 
problem actual execution performance typically swamped cost real requests traversals 
measuring real activity foregoing discussion argued traversals intensive region traversals non zero costs mixed behavior region real activity 
con rm hypothesis measuring number real requests major page faults described earlier 
presents measure number reads issued texas entire traversal set 
major page faults texas read requests number pages traversal number page faults traversals small database linux note plots visually similar coincide 
number real requests exactly number pages read texas due operating system readahead mechanism 
correlating number real requests gure overhead results con rm real activity corresponds higher costs performance 
conversely major page faults real traversals exhibit low costs 
percentage overheads plot texas overhead percentage time percentage total benchmark time traversal traversal set 
plots shown figures respectively 
plots fraction total benchmark time spent traversal 
corresponding plots large database shown figures respectively 
fh fh percentage time traversal number overhead percentage time small database linux texas percentage total time traversal number overhead percentage total time small database linux may startling rst see overhead texas cost warm traversals 
closer inspection note traversals sixteen traversals real activity 
correlating gures clearly shows texas overhead small presence real activity exactly derived large database results 
terms actual numbers conclude texas overhead real costs 
note small database traversals real activity le system caching readahead real tends dominate run time benchmark usually accounting total time 
analysis broadly divided oo benchmark traversal results qualitative regions representing applications di erent mix computation phases discussed overhead various situations 
results small large databases shown overhead texas pointer swizzling page fault time minimal presence real zero furthermore texas overhead high absence real especially small database performance actual execution ected activity occur tends swamp rest costs 
fact calculated cumulative overhead texas percentage total benchmark time including cold warm traversals small database slightly large database 
numbers obviously small compared costs incurred benchmark 
performance results linux correspond normal le loading data benchmark database 
described earlier means operating system usually prefetches data requested read minimize costs prefetched data stored le system cache satisfy requests possible 
clearly seen ects action small database results mixed behavior region contains traversals costs small real possible avoid operating system readahead caching raw device normal le le system storing database 
linux currently support feature heuristics operating system balance le system virtual memory caches favorable usage patterns performance results appear adversely ected 
see solaris bu er management policies favorably usage patterns 
performance solaris ran performance experiments oo benchmark solaris compare contrast results obtained linux 
basic derived linux results valid solaris quantitative variations raw data 
section performance results obtained solaris brie discuss factors responsible various di erences impact benchmark measurement 
important di erence linux solaris supports raw mechanism allowing measure performance system absence le system caching readahead 
results corresponding le raw highlight important di erences strategies 
large database results earlier format rst results obtained benchmark traversals large database 
split results parts raw performance data measure real activity overhead texas percentage time total benchmark time 
basic performance shows run time entire traversal set traversals solaris 
plot cumulative costs di erent components starting time 
comparing results corresponding plots linux note cost various components qualitatively similar linux sets plots similar features 
speci ed results normal le clock cycles traversal total fh fh traversal number times traversals large database solaris obvious di erence solaris linux results total benchmark time solaris exhibits unusual spiky behavior warm traversals 
particular plot represents total time measured entire traversal including costs pointer swizzling components see 
obvious gure time traversal component benchmark measured subtracting cost components total time quite high varying times larger rest costs 
unusual traversal component cpu intensive expected add big overhead execution time 
believe unusually high total time traversal due excessive virtual memory paging database larger available main memory accessed poor locality 
randomized interconnections average tenth pointer visits randomly chosen part nearby referenced causing data faulted swizzled 
interaction access characteristics operating system bu er management policies indirectly leads paging insu cient memory available virtual memory system result benchmark execution spends time waiting paging 
cycle timer measure real wall clock time time spent paging mistakenly traversal component 
measuring real activity con rm observation paging measuring real requests traversal comparing number read requests issued texas 
linux results number major page faults ideal getting approximation real activity 
shows result number reads issued texas traversals 
plot time traversal component total time entire traversal cumulative time components including major page faults texas read requests number pages traversal number page faults traversals large database solaris clock cycles traversal traversal number benchmark time traversals large database solaris note gures plot respective data log scale 
rst thing notice number page faults remains relatively high cold warm traversals gradually decreasing cache gets warmer 
quite di erent downward trend number pages read swizzled cache gets warmer 
contrast corresponding plots linux 
interesting observation plots corresponding major page faults benchmark time exhibit identical visual characteristics warm traversals starting traversal 
observation strongly supports theory high traversal time due excessive paging 
number page faults indicates heavy paging behavior benchmark interval visual tracking features benchmark time page faults con rms run time directly ected paging 
percentage overheads plot texas overhead percentage cost traversal shown 
expected overhead di erent components small compared cost 
unusual features plot 
particular overhead user level kernel fault handling plots labeled fh fh respectively varies signi cantly warm traversals traversals overhead swizzling plot labeled remains low stable 
reasons behavior unclear especially user level fault handler actions account large fraction described detail section believe due interaction paging approach measuring overheads di erent timers 
percentage time fh fh traversal number overhead percentage time large database solaris texas percentage total time traversal number overhead percentage total time large database solaris shows overhead texas overhead percentage total benchmark time traversals 
gure plot costs percentage total benchmark time 
obvious time typically signi cant portion total benchmark run time especially early traversals pointer swizzling page fault time relatively inexpensive 
note costs percentage case reduces faster compared corresponding results linux higher total benchmark time due paging 
small database results seen large database results solaris qualitatively similar corresponding results linux unusual quantitative variations raw data 
performance results support derived far low overhead texas pointer swizzling page fault time 
small database traversal results solaris show basic valid small database 
basic performance start presenting performance entire traversal set small database shown log scale 
surprisingly looks similar small database results linux modulo minor details 
variations due di erences operating system readahead policy implementation operating systems 
clock cycles traversal total fh fh traversal number times traversals small database log scale solaris arguments corresponding results linux applicable 
divide plot qualitative regions di erent faulting characteristics 
linux results mixed behavior region current data contains traversals speci cally traversals appear exhibit real activity 
measuring real activity shows number reads issued texas corresponding page faults real requests traversals 
compare corresponding plot linux draw regarding performance texas presence real con rm higher costs directly related real activity represented major page faults 
similarly traversals low costs correspond real activity 
major page faults texas read requests number pages traversal number page faults traversals small database solaris percentage overheads completeness results texas overhead plotted percentage costs percentage total benchmark time traversal set 
plots shown figures respectively 
includes plot time percentage total benchmark time traversals 
corresponding results linux figures respectively 
fh fh percentage time traversal number overhead percentage time small database solaris texas percentage total time traversal number overhead percentage total time small database solaris note texas overhead consistently traversals real associated small traversals real zero pointer swizzling overhead high speci traversals execution ected proportionately usually swamped real activity traversals 
calculated texas percentage total benchmark time including cold warm traversals 
higher corresponding overhead measured linux reasonable compared overheads individual traversals measured 
large database results raw large database results earlier correspond le loading data database 
obviously includes ects le system caching readahead mechanism operating system 
ran oo benchmark traversal raw loading data memory 
achieved storing database raw disk partition le system 
subset results experiments brie discuss di erences compared results le clock cycles traversal total fh fh traversal number times traversals large database raw solaris shows run time entire traversal set large database raw corresponding plot le shown 
gure see overhead various components system small compared costs 
note total traversal time warm traversals unusually high attributed paging behavior 
earlier results le paging behavior start traversal raw plots number major page faults entire traversal set 
obvious gure major page faults traversal indicating paging start 
plot time benchmark traversal component 
major page faults texas read requests number pages traversal number page faults traversals large database raw solaris clock cycles traversal traversal number benchmark time traversals large database raw solaris match number page faults time traversals 
expected nd strong correlation run time directly proportional number page faults incurred starting traversal 
comparing file raw results general performance results raw correspond basic results normal le interesting di erences paging behavior 
apart obvious di erence couple issues highlighted 
compare total run time le raw notice little lower case rst traversals 
involves additional attributed le system readahead increasing run time 
interesting di erence number pages involved paging behavior strategy 
le page faults plot indicates pages involved paging traversal gradually reducing warm traversal 
contrast raw number remains warm traversals 
readahead mechanism le case prefetches additional pages earlier traversals stabilizes cache gets warmer 
extra pages involved increase total benchmark run time le small database results raw benchmark traversals poor locality le system caching readahead mechanism operating system cause small database loaded prefetched le system bu ers disk rst traversals 
described earlier le system caching avoided raw loading data database 
results oo benchmark traversals small database raw database access 
clock cycles traversal total fh fh traversal number times traversals small database raw log scale solaris format far performance results entire traversal set shown log scale 
notice di erences gure corresponding results normal le 
part results interesting comparison mixed behavior region qualitative regions described earlier comprises traversals 
notably time traversals exception traversal region clock cycles milliseconds compared low number clock cycles observed earlier 
higher time raw con guration line expectation real activity traversal 
enforcing real traversal essentially transformed small database traversal benchmark intensive benchmark large database traversals 
performance results qualitatively similar large database results texas overhead situations minor compared costs incurred traversal traversal set 
course current con guration see paging behavior normally occurs traversals large database small database easily ts memory 
order get qualitative approximation various overheads pointer swizzling page fault time plot overhead individual component percentage time traversals entire traversal set corresponding results plotted cumulative fashion 
plot overhead texas percentage total benchmark time 
gure includes fraction total benchmark time spent overhead purpose comparison 
percentage time fh fh traversal number overhead percentage time small database raw solaris time traversal half lowest time traversal order milliseconds 
possible request satis ed cache track bu er disk 
texas percentage total time traversal number overhead percentage total time small database raw solaris gures conclude texas overhead small fraction cost usually average maximum excluding traversal 
average overhead linux high signi cantly ect performance 
comparison cost major fraction benchmark run time dominates costs 
cumulative overhead texas calculated separately percentage total benchmark time including cold warm traversals 
slightly overhead reported normal le traversals raw little expensive due cost extra disk seeks 
large database results bigger memory size le raw results large database total benchmark run time shown unusual behavior marked spikes plots 
avoiding ects caching readahead raw able delay spiky behavior traversals 
speculated due excessive paging occurs database larger memory size typically accessed poor locality 
verify hypothesis upgraded memory test machine mb mb reran benchmark traversal new con guration 
new memory size big easily entire large database expect paging general behavior similar small database results 
raw new con guration le acceptable mb large avoid unwanted contention le system virtual memory caches 
clock cycles traversal total fh fh traversal number times traversals large database solaris large memory presents results large database traversals new large memory con guration 
important features noted 
expected unusually high run time longer safely conclude paging 
interesting observation strong similarity gure large database results linux 
similarity especially interesting linux results correspond le database access solaris results raw plot overhead texas percentage time percentage total benchmark time 
shows overheads di erent components texas percentage time traversal 
obvious overhead texas plot labeled fh small percentage time average warm traversals large database little paging database ts memory 
fh fh percentage time traversal number overhead percentage time large database solaris large memory texas percentage total time traversal number overhead percentage total time large database solaris large memory shows overhead texas percentage total benchmark time 
note overhead smaller compared fraction total time spent note remarkable similarity results corresponding linux results 
terms raw numbers texas overhead slightly higher solaris linux 
analysis performance measurements solaris ran benchmark database sizes le raw corresponding results database size 
general results con rm basic assertion overhead added texas relatively small compared typical costs incurred loading data memory 
analysis large database results results strategies con rm assertion texas overhead relatively small compared costs 
quantitative variations unusual 
example plot shows actual swizzling overhead relatively small warm traversals unexpected spikes fault handling user level kernel level costs 
believe transient ects possibly due paging re ection faulting overhead 
reasons led 
observed spikes shift traversals di erent runs experiment discernible pattern variation occur warm traversals 
addition height spikes varied di erent runs indicating overhead transient nature 
number pages swizzled traversal know usually protection faults warm traversals possible large overheads handling just faults 
believe measurements ected spurious ects paging behavior incorrectly faulting 
shown ects paging behavior disappear move bigger memory size database ts memory 
general performance texas solaris raw larger memory avoid paging similar linux le smaller memory 
indication bu er management linux aggressive solaris 
raw vs file main di erence raw le strategies le system caching readahead implicitly performed underlying operating system case 
bypass behavior simply storing data raw disk partition raw data access 
turning le system caching usually idea applications running texas problem double caching avoided 
illustrated may may bene cial turn caching depending application characteristics 
example consider small database results le raw cases figures respectively compare absolute costs initial region traversals sets results 
speci cally times traversals le uniformly lower raw course client side local caching important multiple distinct runs applications input data le system caching may bene cial 
request case results actual disk request incurs cost extra disk seeks 
contrast normal le prefetches data real disk avoids cost extra disk seeks corresponding prefetched pages readahead pays sooner 
consider absolute times large database results di erent strategies figures 
case times raw traversals lower le rst traversals 
le system prefetches paying soon competition le system cache virtual memory cache reduces ective memory size causing paging behavior turn increases number requests quickly advantages gained due prefetching 
turning readahead mechanism may unexpected ects performance various applications depending access characteristics amount data accessed 
may bene cial perform readahead applications access characteristics favorable prefetching ectively avoid extra disk seeks 
may pay cost readahead bene 
unfortunately operating systems currently provide independent user level control readahead le system caching support raw course implement prefetching possibly raw avoids unnecessary interference le system virtual memory caches ords control readahead mechanism 
comparison address translation granularities results far concentrated performance pointer swizzling page fault time coarse grained address translation mechanism 
results oo benchmark traversals corresponding di erent address translation granularities data structures traversals 
recall smart pointer idiom chapter implementing ne grained mixed granularity address translation requiring additional support compiler operating system 
particular interested di erent address translation granularities coarse grained mixed granularity ne grained strategies described chapter 
table describes types pointers granularity corresponding key performance results plots 
granularity type pointers key coarse grained raw language supported pointers raw mixed granularity smart pointers index raw smart index ne grained smart pointers smart performance results sections presenting results address translation granularities important cpu time real time di erence performance primarily due di erences faulting swizzling allocating address space reserved pages 
unfortunately discussed section cpu time timers operating systems coarse granularity impossible measure reasonable di erences performance due change address translation granularity overheads small 
older slower sparcstation elc slow set coarse granularity timers 
cpu time traversal milliseconds raw smart index smart traversal number cpu time translation granularities large database solaris sparc elc presents cpu time traversals entire traversal set run large database 
expected cost coarse grained address translation raw case highest rst traversals 
unusual coarsegrained address translation scheme pointers faulted pages reserves pages may application 
exacerbated poor locality benchmark traversals pages database accessed initial traversals causing large number pages reserved 
number new pages swizzled decreases cache see corresponding reduction cpu time 
note cost ne grained address translation smart case lowest rst traversals 
expected address translation scheme swizzle pointers page faulted smart pointers translated 
cpu time mixed granularity address translation smart index case falls cases rst traversals 
reasonable parts index structure contains smart pointers traversal uses index select root part traversal 
cost slightly raw case tree implementation generated tree levels deep reducing number smart pointers translated traversal 
consider hot traversals 
rst thing note cpu time smart case higher cases 
smart pointers impose continual overhead pointer dereference cost incurred target object resident 
contrast raw case zero overhead hot traversals 
expect smart index results identical raw results index lookup hot traversals smart pointers need translated 
attribute small di erence hot results cases caching ects 
cpu time traversal milliseconds raw smart index smart traversal number cpu time translation granularities small database solaris sparc elc shows corresponding results small database 
case rst traversals contain faulting swizzling 
phenomenon similar large database results seen current results 
particular cpu time highest rst traversals raw case lowest smart case 
hot traversals granularities swap positions smart case expensive continual translation overhead raw smart index results identical hot traversals index pointers dereferenced 
discussion results performance pointer swizzling page fault time implemented texas persistent store 
standard oo benchmark traversals measuring cost various components system compared costs 
measured performance benchmark traversals small large database sizes 
results benchmark runs popular operating systems linux solaris 
solaris results raw le database access study ects le system caching readahead performance 
empirical results qualitatively similar linux solaris quantitative variations raw data depending combination speci experiment operating system 
variations signi cant ect results adversely 
section basic argument performance texas discuss impact operating system implementations 
basic argument shown pointer swizzling page fault time imposes absolutely overhead data loaded memory minimal overhead faulting presence activity 
basic idea exploits locality application amortize cost swizzling page fault time 
processors faster disks cost swizzling entire pages fault time small compared costs 
existing virtual memory hardware incur overheads compiler operating system support 
various results earlier correspond benchmark database stored local disk 
database may stored main memory remote host faulted fast network involving disk access 
example distributed system data stored centralized data server fetched network di erent clients 
networks faster disks network costs smaller disk costs 
result overheads pointer swizzling page fault time hide costs 
counterarguments 
fast networks experimental research state widely available near second fast networks ubiquitous expect corresponding improvement hardware operating systems combine reduce overheads 
impact operating system implementations run benchmark experiments linux solaris identical underlying hardware setup 
results conformed qualitative terms unusual quantitative variations especially solaris 
particular linux appears aggressive solaris terms kernel memory usage 
test machines amount ram mb amount main memory available user applications solaris megabytes linux approximately mb vs mb 
normally di erence signi cant impact performance 
large database results split happens just right terms total data faulted memory database 
result see paging behavior solaris extra megabytes memory combined aggressive bu er management su cient avoid unnecessary paging linux 
course depending bu er management algorithms solaris performance may suboptimal slightly larger memory size 
interesting di erence solaris linux cost handling protection fault 
speci cally focus time taken point protected page accessed application till point user level fault handler gains control 
number times larger solaris linux 
higher faulting cost obviously ects performance texas especially cold early warm traversals protection faults generated handled 
details exception handling including measurements fault handling costs provided chapter 
indirect costs pointer swizzling separately measure account indirect cost swizzling performance measurements 
reasons 
benchmark traversals small large database sizes correspond situations paging heavy paging respectively 
recall indirect costs pointer swizzling major issue situations 
important reason indirect costs ected heavily locality characteristics application 
obvious performance results far oo benchmark exhibits extremely poor locality characteristics data structures consequently traversal operations 
measurements indirect costs oo benchmark arti cially skewed useful drawing meaningful 
benchmarking limitations years new systems implementing persistence full edged object oriented database capabilities proposed implemented studied academic research groups commercial database vendors 
period benchmarks developed measuring performance new systems 
oo cs oo cdn benchmarks popular widely measuring performance various systems isolation comparing systems 
canonical application domain object oriented databases oodbs computer aided design cad domain 
posit oo oo benchmarks representative typical applications cad domain 
results benchmarks necessarily indicative typical cad application behavior 
section discuss issues benchmarking methodology views limitations synthetic benchmarks particularly oo oo benchmarks 
especially interested object database benchmarks benchmarks measuring orthogonally persistent systems 
discussed rest section believe benchmarks unsuitable roles 
large database results linux appear correspond paging situation 
synthetic benchmarks performance measurements analysis persistent object systems oodb systems done synthetic benchmarks lieu real applications 
reasons rst large realistic applications exercise persistence mechanisms underlying system exist available general second typically extremely hard adapt large piece code persistence mechanism having detailed understanding application 
synthetic benchmarks provide useful solution problems 
usually benchmarks smaller real applications hopefully designed ported di erent systems requiring large modi cations 
underlying assumption benchmarks designed model behavior real applications results benchmark studies extrapolated wide variety applications 
true results synthetic benchmarks interpreted extreme caution 
synthetic benchmarks re ect designers intuitions program behavior intuitions may exactly right 
worse benchmarks may implicitly incorporate unrealistic assumptions underlying common analytic models 
apparently empirical nature experimental results lull people relying results appropriate 
benchmark may resemble real applications certain ways relevant certain aspects system design ways synthetic benchmarks indicate little behavior real applications 
benchmark validated respect certain issues may quite inappropriate purpose validated 
say synthetic benchmarks useful 
fact synthetic benchmarks advantage varied systematically parameters allows experimentation range possible behaviors 
course results interpreted cautiously ensure drawn results valid real application behaviors 
oo oo benchmarks 
oo benchmark cs rst benchmarks performance measurements oodbs designed model applications engineering cad domain 
benchmark database schema simple network biased random interconnections part objects manipulated simple benchmark operations 
oo benchmark cdn developed university wisconsin successor oo benchmark 
benchmark retains cad application model data structures enhanced add hierarchy additional complexity incorporated tuning various benchmark parameters 
oo widely oodb developers measure performance systems researchers benchmark compare performance various persistence mechanisms 
best knowledge oo validated real applications cad domain ensure represents realistic workload 
believe oo representative cad applications researchers reached similar 
common problems oo oo benchmarks primarily interested behavior oo oo benchmarks speci cally performance measurements orthogonally persistent systems 
particular believe benchmarks typically measure performance measuring costs address translation orthogonal persistence primary focus 
obviously problem oodbs persistent programming languages usually intended cpu intensive applications 
applications exhibit intensive behavior may preferable traditional relational databases optimized improve performance 
purpose discussion de ne terms normal program behavior database program behavior categorize behaviors di erent applications 
normal program behavior denotes typical cpu intensive applications spend execution time performing computation persistence mechanism save nal results 
applications majority objects need saved stable storage constitute transient data live long wil wjnb joh 
situations execution costs dominated operations transient data persistence mechanism interfere operations making fast possible 
contrast database program behavior denotes applications usually intensive perform signi cant computation execution 
traditional relational database systems better suited stable storage management applications 
oodb systems persistent programming languages targeted applications exhibit normal program behavior enabling persistence technology incorporated normal applications operate primarily memory data 
discuss common problems identi ed benchmarks focus oo benchmark issues applicable oo benchmark 
meant exhaustive compilation problems believe issues important especially context coarse grained persistent system 
separation costs benchmarks specify way separate costs costs including necessitated architectural choices implementation persistent system 
example particular system aggressively prefetches data majority persistent store loaded memory early traversals warm traversals closer hot traversals 
contrast system prefetches little warm traversals comparatively 
results warm traversals represent loading caching costs overhead persistence mechanism 
measure warm traversals fundamental costs architecture 
recall costs orthogonal persistence include costs incurred persistence facilities example accessing transient data persistent data loaded memory 
designers oo appear recognized issue specify cold hot performance measurements 
hand oo requires results reported cold warm performance omitting hot performance measurements 
problem hot performance essentially represents baseline information possible judge performance persistent system regardless caching working 
particularly important approach incurs absolutely overhead hot traversals accessing memory persistent pointers transient pointers 
result hot performance equal best case performance fully transient con guration 
words cost orthogonal persistence zero system 
evident hot performance reported part benchmark results 
locality issue benchmarks regarding locality 
randomized interconnection scheme oo exhibits locality connections local disastrous ects locality simple algorithms operating data 
average tenth pointer randomly chosen object 
oo benchmark extraordinarily poor locality 
cold hot performance represents extremes behavior bad locality locality roughly assess performance system di erent kinds 
unfortunately guidance terms expected mix behaviors 
unusually poor locality matter purposes may crucial purposes 
example ne grained systems incur instructions overhead pointer dereference pointer comparison coarse grained schemes incur thousands instructions overhead page faults zero 
frequency pointer traversals orders magnitude higher frequency page faults coarse grained techniques obviously cient 
true normal applications achieve cpu utilization usually greater 
recall modern processor program incurs fault instructions probably paging heavily 
object databases clear 
relational databases designed applications tend intensive objectoriented databases cpu intensive tasks cad applications 
lack locality oo raises questions regarding appropriateness general benchmark arbitrary systems 
useful information graph part objects connectivity biased random distribution interconnections 
ensures strong correlation static structure graph dynamic locality ofthe benchmark traversals 
furthermore means locality characteristics consistent especially respect relative heat links 
object link hot traversal hot traversal encounters 
oo benchmark designed support better locality characteristics ne grained systems usually incur costs pointer dereference including memory persistent pointers transient pointers 
clear goal achieved 
aware studies measures factor closest appears indicate oo unsuitable generic cad workload 
preliminary analysis oo dissertation shown oo database connectivity exhibits poor locality characteristics 
computation behavior oo oo benchmarks specify minimal computation behavior persistent object visited benchmark operations traversal 
oo new object visited empty procedure invoked object represent computation performed real application 
direct ect benchmark operations data intensive cpu intensive 
representative real applications usually data compared just invoking empty procedure 
oo assumes uniform workload behavior unrealistic real application usually exhibits di erent phases single execution 
intensive nature benchmark traversals coarse grained address translation techniques look unnecessarily bad basic premise locality data access page faults interspersed long periods computation violated 
addition persistent pointer dereferenced traversal 
unrealistic cad applications example oo reused pointers times frequently cad visualization application 
furthermore transient pointer traversal included benchmarks 
unfairly ects results coarse grained address translation scheme relies high pointer reuse performance bene ts ne grained scheme adds overhead pointer dereference regardless persistent transient pointer 
data structures algorithms point benchmarks failure exactly specify data structures algorithms benchmark schema various benchmark operations 
example original oo speci cation specify exact structure parts index 
similarly oo benchmark specify kinds containers sets bags lists various collections objects benchmark schema 
quite undesirable especially comparison di erent systems performance di erences systems signi cantly ected due ne tuning speci data structures 
benchmarks specify transient data structures required benchmark operations 
similar vein oo oo benchmarks specify important algorithms may ect connectivity graph corresponding traversals 
example default implementations standard pseudo random number generator available underlying operating system 
algorithm pseudo random number pointer said reused application traverses dereferences 
generation vary di erent operating systems di erent versions operating system 
random number generator integral piece oo benchmark initial connections building original connectivity graph root part traversal selected randomly di erences implementation may signi cantly ect performance system 
summary common problems oo oo popular database benchmarks studying performance various oodb systems persistent object stores 
believe benchmarks unsuitable performance measurements orthogonal persistent systems general object database benchmarks 
independent evidence benchmarks emulate characteristics behavior cad applications typically represent kind applications exploit oodb systems 
oo oo benchmarks identi ed issues especially poor locality characteristics lack computation behavior representative normal application behavior 
general believe benchmarks designed measure address translation costs interested measure cost loading caching persistent data 
furthermore randomization data unclear results meaningful real applications exhibit locality distinctive phase behavior 
believe oo oo suitable studying issues clustering 
characteristics benchmarks fairly random little opportunity sophisticated clustering scheme exploit regularities successfully exploit real applications 
furthermore interconnections database structures oo discourage static clustering 
course ects clustering performance scope dissertation 
various performance results chapter supported basic argument pointer swizzling page fault time zero costs faulting persistent store 
major cost system incurred page loaded memory pointers swizzled virtual memory addresses 
overhead small compared costs incurred fetching page disk 
basic idea takes advantage locality application access patterns higher page costs swizzling page fault time set avoiding unnecessary overhead subsequent accesses object 
networks get faster persistent stores stored main memory remote data server local disk client host 
reduces places hide overheads potential coarse grained address translation look unattractive 
believe major issue expect signi cant improvements processor speeds operating systems ectively reduce swizzling overheads 
experimented di erent granularities address translation studying general applicability granularities 
mixed granularity schemes may appropriate cases speci cally data structures high fanout accessed sparsely 
example data structure parts index oo benchmark 
structures may preferable pointer wise address translation reduce rate address space consumption 
depending application characteristics mixed granularity approach situations 
process measuring performance pointer swizzling page fault time mechanism di erent components learned interesting lessons operating system implementations 
example cost handling protection faults solaris times higher linux identical hardware 
exact reasons slowdown clear ect performance texas especially rst traversals 
addition bu er operating systems played important roles results 
aggressive bu er management linux frees extra megabytes appears just su avoid unnecessary paging activity actual traversals 
cient chapter run time type description access information data object layouts run time necessary clean cient implementation various families run time support software 
texas chapter persistent object stores abc am wd pointer swizzling techniques swizzling page fault time need know locations pointers data objects run time order nd manipulate pointers correctly 
similarly precise garbage collectors wj information locate pointers objects tracing reachability graph reclaiming garbage 
applications bene knowledge low level layout information data structure browsing data structure pickling data format conversion sharing machines opposite parameter marshaling distributed communication including remote procedure calls advanced foreign function call interfaces cient cross language data sharing advanced pro ling tracing debugging 
ability run time type queries data objects available high level languages smalltalk gr clu lab modula nel 
term run time type identi cation rtti sl represent language level semantics ability support operations allow application ask type subtype type 
standard added rtti support operations downcasts circumventing type system 
unfortunately standard rtti information insu cient purposes describe traditional garbage collectors languages conservative bw 
data value looks pointer treated tracing reachability graph 
contrast precise garbage collectors typically real time applications conservative need exact pointer information honor necessary correctness performance guarantees 
implementation level information necessary run time support systems 
introduce term run time type description rttd denote low level object layout descriptions implementation dependent information available run time 
chapter describe portable general purpose high performance mechanism generating manipulating rttd mechanism designed applicable various high level programming languages compatible conventional compilers 
fundamental idea compiler generated debugging information extract information necessary rttd 
believe portable approach variety applications argue compiler generated debugging information preferable preprocessors preprocessors hard develop maintain incompatible preprocessors portable 
note portability 
term portable levels portability approach portability implementation 
approach relies heavily compiler providing object layout information debugging output 
reasonable expect modern compiler supports debugging provide information 
approach works standard compilers operating systems 
level portability related implementation system 
mean system portable compile box run sense relatively easy port implementation rely unusual compiler operating system features 
words system portable ansi program portable say portable compiler operating system 
scope approach 
focus mainly dynamically allocated objects interact allocator locate record type information object su cient applications 
extensions handle statically allocated instances possible link information object les scope dissertation 
stack allocated objects may pose greater di culties topic 
debugging information su cient purposes may require enhancements compiler generated debugging information contain required low level information 
current status availability 
system multiple platforms leveraging code gnu debugger gdb source publicly available gnu general public license gpl ftp ftp cs utexas edu pub garbage texas 
currently system texas chapter real time garbage collector wj 
system tested avors unix sunos solaris ultrix linux gnu compiler os ibm visualage compiler previously known cset compiler 
code link application code application fall scope gpl 
addition output type information embodied type descriptor records generated system covered gpl 
system commercial applications royalty licensing restrictions 
structure chapter 
remainder chapter organized follows 
section provides rttd motivation need 
discusses techniques generating rttd including preprocessors compares approach debugging information 
section discusses details rttd generation manipulation including steps necessary providing rttd high level language 
provide detailed description case study implementation section followed description storage model section sketch expected performance characteristics section 
sections describe current status related research nally conclude section 
rttd issues section discusses fundamental issues concerning rttd provides motivation design general purpose mechanism provide implementation level type information 
addition introduce approach debugging information rttd generation compare seemingly obvious problematic scheme specialpurpose preprocessors 
believe preprocessors suitable rttd generation fundamental impedance mismatch preprocessors operate language level example parsing language constructs primarily interested implementation level semantics example exact locations pointers objects 
preprocessor integral part compiler infer compiler actions information available language level source code 
contrast debugging information allows ask compiler exact behavior relevant purposes 
motivation primary motivation portable rttd mechanism support development cient powerful language extensions shelf high performance conventional compilers languages ada 
shelf compilers typically directly support low level object layout information required implement extensions 
addition want ensure rttd language compiler provides necessary debugging information 
goals design achieve ciency performing complex steps compile time minimizing run time space time overheads ease requiring minimal changes source programs elegance providing graceful integration appropriate steps usual compilation linkage process portability relying standard compilers debugging information formats 
rttd vs rtti current draft standard wc describes proposal run time type identi cation rtti part language 
similar features available languages 
typically information provided rtti mechanism useful language level semantics run time type equivalence checks safe downcasts 
contrast rttd designed provide implementation level information actual memory layout data objects including sub objects layout dictated inheritance hierarchy 
described standard language implementation provide class called type info objects class run time represent type information application types 
object class returned result applying typeid expression application data object 
operations permitted object type type info equality checks compare objects type name function returns null terminated string containing unique implementation de ned value represents name corresponding type 
compared rtti schemes rttd mechanism described signi cantly powerful allows application ask various questions object layout 
example possible query types sets elds explicitly determine locations pointer elds object run time 
general rttd equivalent rtti speci ed java 
provides extensive lowlevel information required applications persistent stores precise garbage collectors schema evolution mechanisms type descriptor records type descriptor records form integral part rttd represent object layout descriptions run time 
generate type descriptor record corresponding type rttd desired record contains low level layout information objects type 
section provides details di erent formats storing type information type descriptor records 
preprocessors vs debugging information consider main approaches generating type descriptor records 
special purpose preprocessors 
debugging information 
argue second approach 
possible techniques include requiring signi cant programmer intervention extending language syntax custom compilers 
believe methods unsuitable expensive exible place unnecessary demands programmer 
example building high quality compiler complex task practice described section require minor amount programmer intervention implementation 
worth ort implementing features 
addition porting maintaining compiler various platforms prohibitively expensive 
preprocessors obvious technique building type descriptor records provide preprocessor parses source extracts necessary information 
rst glance allowing portable source source translation preprocessor simple ective solution rttd 
believe right approach reasons 
preprocessors typically hard simple preprocessors provide clean syntax complete syntactic error checking errors reported inconsistently may confuse programmer hard develop sophisticated preprocessors gracefully extend language syntax exhaustive syntactic error checking reporting duplicate signi cant amount done compiler 
ect just preprocessors 
compilers evolve di cult keep preprocessors consistent hard maintain languages asc undergoing standardization 
preprocessors hard maintain unrelated changes syntax language require modi cations preprocessor parse changes usually incompatible preprocessors relying preprocessors leads trend providing speci preprocessor solving problem 
eventually results sequence pipeline preprocessors usually incompatible confused constructs understood preprocessors series 
problem exacerbated nested constructs require repeated applications preprocessor speci order preprocessor invocation acceptable 
general constructs implemented di erent preprocessors sequence interact properly portable preprocessors compiler dependent respect issues compiler speci language extensions 
compilers may extend language additional keywords syntactic variations structural alignment padding 
di erent compilers operating systems may impose di erent alignment padding restrictions objects component order 
languages specify placement order elds objects hidden elds 
language features may require implementation de ned elds generally exposed source code level 
believe arguments preprocessors valid rttd purposes 
example usual implementation virtual functions virtual function table pointers inserted compiler 
general preprocessors reduce exibility advocate rttd generation situations 
contrast approach similar postprocessor rely actual information generated compiler inferring examination source code 
debugging information compilers emit debugging information includes description layout types application source level debugger examine data structures running program 
debugging information included object les application source compiled compiler speci debug option 
possible extract information format type descriptor records provide rttd 
approach requires minimal compiler cooperation extent existing capabilities modern compilers major advantages solutions independent source language format debugging information speci platform typically depend details source language compiler independent compiler cooperation required debugging information generated standard formats 
noted method impose space time penalty production version application debugging information stripped object les type descriptor records generated 
alternatively application may recompiled debugging additional optimization 
approach usable compilers prohibit reduce optimization producing debugging information 
unaware compilers change layout objects presence absence debugging information level optimization compilation 
general compilers anyway complicates normal library linkage libraries linked applications compiled di erent optimizations nal result disastrous object layout varied degree optimization 
situation exacerbated mechanisms persistence objects stored persistent store may suddenly di erent layouts expected application accessing objects compiled di erent optimization created objects 
adapting compiler support compilers may eventually provide form implementation level type information 
currently standards format methods information available expect standardized full featured low level type information available soon 
information available code may course type descriptor records need stored cost negligible compared cost retaining debugging information 
recompilation easily automated standard les 
written transform non standard information type descriptor records 
technique require preprocessor debugging information 
hope standards programming interfaces implementation level type information emerge making trivial write adaptor code 
rttd generation manipulation basic goal rttd provide mechanism obtain low level object layout information address object 
problems solved accomplishing constructing type descriptor records describe layouts objects various types associating type descriptor records actual instances appropriate types run time 
type descriptor records stored table indexed type names 
generate records debugging information application source rst compiled compiler speci debug ag 
resulting debugging information object code parsed extract layout information formatted type descriptor records 
type descriptor generation easily accomplished compile time additional action object le generated corresponding source le 
second problem challenging need mechanism identify concrete types instantiated allocation site information look corresponding type descriptor record associate newly allocated instance 
unfortunately conventional languages provide direct support associating compile time information run time instances 
languages parameterized nested types concrete types easily identi ed source 
ada provide complex type systems sophisticated approach necessary may involve minor system dependencies 
problems solved mapping object type descriptor record available run time 
accomplish providing step mapping object type identi er type identi er type descriptor record 
conceptually single mapping su cient uses rttd chose step mapping added implementation exibility ciency 
explain extra level indirection inexpensive useful linking separately compiled modules 
type identi er typeid short token uniquely represents concrete type application 
note representation may type identi er long provides key uniquely identi es associated type descriptor record 
current implementation type identi er simply integer set table type descriptor records 
unique type identi er allows eliminate duplicate type descriptor records separately compiled modules described section 
concrete type basic type character aggregate type instantiation parameterized type concrete type instantiated create actual instance 
generating type descriptor records basic approach generating type descriptor records parse debugging information object les build table maps type names concrete types corresponding object layout information embodied type descriptor records 
table available running programs application program interface api 
debugging information format varies platform platform di erent operating systems representative formats translated common type descriptor record format 
implementation type descriptor generator divided parts platform speci part extract debugging information object les platform independent part build type descriptor records extracted debugging information 
generalize implementation part di erent avors unix systems leveraged code gnu debugger gdb parse extract debugging information various object les formats understood gdb 
di cult implement functionality directly version os ibm visualage compiler implemented line module gdb code 
gdb platform speci part implementation type descriptor generator highly portable systems gdb enhanced understand variety debugging information formats di erent systems 
note reliability debugging information order 
correctness code generated compiler obviously critical correctness debugging information compilers released incomplete broken debugging support 
possible problem approach 
fortunately system relies subset standard debugging information layout information reliable debugging information mapping line numbers program counter variables registers 
occasionally version compiler may broken relevant way cases di erent version problem 
associating type descriptor records objects mentioned earlier associating type descriptor records actual objects somewhat di cult generation 
divide problem smaller parts solved individually identify concrete types allocation sites record type descriptor record instance 
recall table type descriptor records generated compile time maps type names corresponding object layout information 
locate type descriptor records type descriptor records linked data structure represents type graph application 
retrospect module general necessary probably half long 
ports easier reuse code module avoid excessive generality 
example releases gnu compiler ected system serious problem general 
corresponding concrete types unique type names 
type information passed allocator performs table lookup retrieves corresponding type descriptor record recorded instance 
type identi cation type names may tricky languages necessary information directly available allocation site 
language easy capture type name allocation site implementing allocator call preprocessor macro takes type name argument converts string representation 
acceptable language provide advanced type system actual type names directly available allocation sites 
languages ada viable solution type name directly available allocation sites macro expansion occurs early compilation process parameterized nested types resolved unique concrete types capture type name 
determine concrete types code compiled types allocation sites resolved concrete types 
approach requires mechanism backpatching allocation sites 
plug concrete type identi er allocation site compiled concrete types resolved 
describe detail backpatching easily implemented adding extra level indirection leveraging linker name resolution 
introduce special backpatching variables hold type identi ers type variables corresponding allocation sites 
application compiled generate code initialize variables appropriately linker resolves variables normal way initialized values available allocation sites 
allocator simply stores type identi er hidden header object 
allocators attach header object bookkeeping data augment data include type information rttd 
addition allocator support mapping pointers interior object header object 
especially necessary pointers may point beginnings objects due pointer arithmetic standard implementation multiple inheritance implicitly uses pointers sub objects 
compilation linkage model gracefully integrate generation type descriptor records association actual instances appropriate steps normal compilation linkage process 
allows build type descriptor records corresponding debugging information available generate code create initialize backpatching variables hold type information link object modules initialization code libraries manipulating type descriptor records 
describe compilation linkage process speci cally noting steps required integration rttd 
source code application typically divided multiple les 
application executable built compile link model source les usually compiled individually generate corresponding object les compile phase linked create single executable application link phase 
designed rttd generation mechanism similar model type descriptor generator extracts type information individual object les build corresponding mapping tables phase merged produce single table corresponding application executable phase 
foo cc cc foo foo td foo tni bar cc cc bar bar td bar tni cc cc link app exe app td compilation linkage process shows compilation linkage process 
basic steps involved rttd generation particular application follows 
compile source les debugging option enabled generate object les standard compile phase 

generate type descriptor records debugging information object le phase 
done stand program supplied system 

merge type descriptor records multiple modules linked single table type descriptor records application eliminate duplicates phase 
terms denote phases type descriptor records generation distinguish standard compile link phases 
done utility provided system 

generate auxiliary object le containing initializations backpatching variables hold information concrete types 
auxiliary source le containing initialization code generated standalone utility 
source le compiled compiler compile application source les 
section provides full details backpatching variables describing case study implementation 

link object les including previous step support library accessing type descriptor records generate nal application executable standard link phase 
noted phase follows standard compile phase object les generate type descriptor records 
contrast phase precedes standard link phase generates auxiliary source code compiled linked nal executable 
steps easily automated straightforward les 
large applications les automate standard compile link phases easy extend providing additional targets actions rttd generation 
rttd multiple compilation units languages compilation unit usually refers object le typically generated distinct source le 
compilation units put generate single application executable 
seen compilation linkage model designed conducive supporting rttd multiple compilation units 
type descriptor records generated compilation unit linked single set type descriptor records entire application 
allows regenerate type descriptor records selectively compilation units modi ed 
les regenerate object les source les change simple modi cation le cause new type descriptor records generated new object le created 
backpatching variables type identi ers favorable providing rttd multiple compilation units 
usually type descriptor generator local knowledge type information object le processed current execution 
possible assign unique type identi ers types particular execution maintaining global knowledge type information object les processed earlier 
type identi ers stored backpatching variables initialized separately standard compile phase relatively trivial assign unique type identi ers types utility generates initialization code ensure type assigned unique type identi er value 
compilation linkage model facilitates elimination duplicates 
types may di erent modules application type information may duplicated various object les mapping tables generated les 
utility performs duplicate elimination merges type descriptor records multiple modules single table application 
duplicate elimination done name equivalence structural equivalence 
names imply name equivalence considers entities types equivalent name structural equivalence uses structure entities compare 
rttd section discussed high level issues involved generating manipulating rttd conventional source language avoiding elaborate discussion issues implementation backpatching variables 
section describe case study implementation rttd 
currently implementation texas persistent store real time garbage collector wj 
described earlier type descriptor generation relies existence debugging information object les directly depend source language 
contrast associating type descriptor records appropriate instances requires modi cation allocation sites obviously language dependent involves language interface 
rst provide high level overview system section describing implementation details section 
discuss issues handling multiple compilation units section types names added exibility applications section 
brie discuss possible complications enhancements section 
overview approach exploits common features minimizing dependencies speci compiler implementation 
goal provide language interface requires minimal changes existing source order facilitate ease complex processing performed providing simple front user 
recall basic strategy provide mechanism associate type descriptor records corresponding objects instantiated accomplished modifying allocation site type identi ers available allocator turn stores newly created object 
implementation main mechanism modifying allocation site underlying allocator change new operator overload operator expect type identi er additional argument store header object 
addition provide macro interface encapsulates slightly awkward syntax overloaded new operator 
languages concrete type information directly available allocation site literal type identi er may passed allocator 
supports nested parameterized types information concrete type instantiated available directly source level literal type identi er provides new operator dynamically allocate objects application memory 
allows programmer overload function operator providing di erent implementation name long function signatures distinguish implementations 
passed allocator 
type information usually available source compiled compiler resolved concrete type allocation site 
need mechanism overloaded new operator call sites provide appropriate type identi er value compilation 
want toavoid object code modi cation purpose 
implement backpatching introducing extra level indirection leveraging compiler type processing linker natural name resolution follows 
special backpatching variables literals type identi ers allocation site source compiled compiler generates unde ned variables object code 
appropriate concrete type information extracted object code type descriptor generator generate auxiliary source code initialize variables appropriate type identi er values 
initialization code compiled linked application object code linker resolves unde ned appropriately 
ect achieves desired backpatching requiring object code modi cation 
note backpatching variable holds type identi er single type allocation site instantiate type time 
words mapping type corresponding backpatching variable 
observation allows backpatching variable type allocation site type instantiated allocation site variable allocation site introducing errors 
simple approach providing backpatching variables general case ensure type instantiated special class variable plays role backpatching variable 
approach handle builtin types example int float language allows de nition class variables aggregate types 
addition requires modi cation user de ned types add class variable burden application programmer 
get essentially ect modifying solution slightly 
ensure unique type instantiated exists wrapper class contains mentioned class variable variable wrapper class hold type identi er corresponding instantiated type 
order maintain mapping instantiated type corresponding class variable wrapper class parameterized unique wrapper class created type instantiated overloaded new operator 
ect added mapping wrapper class associated type 
wrapper class provides bene ts rttd allows easy automatic creation class variables non aggregate types 
separate class hold class variable approach works builtin types require modi cation user de ned types 
allows easy generation class variables overloaded new operator 
macro interface simply refer class variable wrapper class member operator compiler automatically resolves 
avariable associated class instances class known class variable 
instantiation parameterized wrapper class create concrete wrapper class occurs compile time run time class variable wrapper class fast 
ensures debugging information generated compiler types allocated overloaded new operator 
compilers may optimize away generation debugging information prede ned types types may certain ways 
wrapper class forces inclusion type information instantiated type wrapper class 
allows easy identi cation types type descriptor records need tobe generated 
new concrete wrapper class instantiated interesting type type rttd desired instantiated overloaded new operator type descriptor generator information generate type descriptor records selected types 
readers familiar advanced object oriented languages rst class classes may recognize wrapper class type acts class metaobject holding information instances type 
note parameterized wrapper class instantiated interesting type create concrete wrapper class resulting concrete wrapper class need instantiated create unnecessary instances 
backpatching variable class variable associated speci instances directly referenced class name 
implementation details previous section provided general overview approach implement rttd mechanism 
section describes important components actual implementation operator new overloading macro interface overloaded new operator 
rst describe background information new operator overloaded moving explain associate type identi ers appropriate objects run time 
new operator normal behavior new operator may described conceptually distinct steps code generated particular compiler may explicitly distinguish 
compiler de ned operator new function called obtain storage object 
constructor type called initialize object appropriately 
important note distinction new operator operator new function description 
new operator calls operator new function constructor type 
allows programmer overload new operator providing additional arguments operator new function 
note overloading new operator di erent operator overloading entire behavior operator rede ned rst step overloaded constructor type invoked normal behavior 
referred overloading new operator terminology overloading operator new function changing constructor invocation semantics new operator 
overloading new operator rttd recall need associate type identi er object allocated application 
achieve storing type identi er part bookkeeping information maintained allocator object corresponding type descriptor record referenced 
overload new operator operator new function called placement syntax pass type identi er additional argument underlying allocator store appropriate bookkeeping information 
syntax new operator call follows obj new typeid constructor arguments constructor arguments optional depending default constructor provided type expression typeid backpatching variable contain corresponding type identi er value run time 
macro interface overloaded new operator burdensome require programmers remember exact syntax required overloaded new operator including backpatching variable 
de ne preprocessor macro encapsulates syntax overloaded new operator call provide simple interface programmer 
evident sections scheme generating backpatching variable result complicated syntax 
purpose macro interface entire mechanism providing type identi er transparent programmer 
additional bene macro allows modify underlying implementation providing type identi er requiring modi cations existing application source 
normal syntax calling new operator remainder chapter phrase new operator refer operator operator new refer storage allocation function 
excellent discussion new operator semantics overloading lip 
term originally provide placement information object additional argument underlying allocator 
misnomer syntax pass additional arguments allocator 
constructor takes arguments called default constructor automatically generated class constructors declared class 
obj new constructor arguments note constructor arguments optional number arguments predetermined 
shown earlier corresponding syntax calling new operator placement arguments obj new typeid constructor arguments expression typeid corresponds placement arguments new operator current description shorthand actual expression backpatching variable evaluates type identi er value type run time 
general number placement arguments restricted predetermined de ning overloaded new operator 
provide macro rttd new encapsulates unusual placement syntax 
de nition form define rttd new type new typeid type expression typeid derived way type argument provided macro 
de nition syntax calling macro obj rttd new constructor arguments note similar quite syntax call standard new operator placement arguments 
speci cally extra set parentheses required type name 
necessary macro preprocessor semantics weak support macros variable number arguments arguments enclosed parentheses 
de nition macro expects argument type name variable number constructor arguments part macro de nition 
note macro de nition matches initial rttd new part statement 
constructor arguments provided example prede ned part macro ect right place macro expansion function expected 
constructor type require parameters user may provide empty set parentheses provide place constructor arguments example 
macro de nition handles cases correctly additional user intervention 
ect simulate macro variable number arguments trivial case arguments transformed processed way macro expansion macro de ned recognizes rst argument type macro expansion call resembles placement syntax call 
note special processing required preprocessor de nition scheme works correctly regardless constructor arguments provided 
wrapper class template facility parameterized wrapper class automatically instantiated unique type calling rttd new macro create corresponding unique concrete wrapper class 
form template wrapper class de nition template class class private public static int typeid type instantiated rttd new macro corresponding concrete wrapper class created instantiating template class member typeid hold type identi er run time data member may selectively generate type descriptor records types rttd desired instantiated macro 
associate typeid class instances class mapping type corresponding wrapper class 
static data members implement represent mechanism implementing class variables 
mentioned earlier concrete wrapper class instantiated access static data member normal instance variables 
parameterized wrapper class de nition simpli ed version rttd new macro de nition static data member appropriate concrete wrapper class accessing typeid follows define rttd new type new type typeid type type macro expansion automatically instantiates template type user intervention mapping type type guarantees static data member hold type identi er correct type ensure static data members de ned initialized correctly 
necessary static data members considered declared de ned speci ed class de nition 
described section generate auxiliary source le containing de nitions initializations 
le compiled linked application object code 
type generate line form auxiliary source le int typeid typeid instantiate template providing actual arguments type value arguments template arguments concrete type created parameterized template type 
expected class variables static data members accessed referring speci instance 
expression typeid represents actual type identi er value type wrapper class explicitly identify types rttd desired section similar way generate appropriate initializations 
handling multiple compilation units multiple sets type descriptor records di erent compilation units merged generate single set corresponding application need perform duplicate elimination avoid making nal table large 
implementation name equivalence purpose 
need structural equivalence standard linkers consider types name distinct object les type 
words object les linked generate single executable linker resolves types names structure 
execution type descriptor generator creates mapping table maps type name tokens type descriptor records 
link time single mapping table generated eliminating duplicates type name tokens keys 
type identi er speci type index corresponding type descriptor record nal mapping table static data member initializations generated performing table lookup replacing expression typeid actual type identi er value 
note value type name token long uniquely identi es type compilation units 
current implementation fully quali ed type names exhibit exact property required tokens 
choice easy access fully quali ed type names provide added exibility applications persistence described section 
type names added flexibility conceptually fully quali ed type names type identi ers integer values 
string manipulation slow integer type identi ers optimization 
initially fully quali ed type name look type descriptor record type descriptor mapping table 
performed lookup integer index type descriptor record cached type identi er avoiding expensive table lookup type instantiated 
pay cost string manipulation rst time type instantiated rttd new instantiations application cached type identi er value 
described section wrapper class ideal candidate caching type identi er due correspondence wrapped type 
addition integer type identi ers allow quickly look corresponding type descriptor record simple array indexing 
fully quali ed type names useful persistent object storage system provide robust mechanism resolve type information single persistent note type names include structural information way classes composed scoping name 
fully quali ed name type string representation name template instantiations performed nested class namespace scope information completely resolved 
store multiple applications 
primary goal ensure application accesses objects persistent store types objects application point view persistent store point view 
type descriptor records corresponding types persistent store saved mapping table similar generated application 
depending locations type descriptor records type mapping tables integer type identi er value application side call transient typeid di erent type identi er value persistent store side persistent typeid 
perform type equivalence test types persistent store types application solely value type identi ers 
fully quali ed names types better choice tables independent locations type descriptor records 
general standard linkers consider types identical name structure 
rely name equivalence standard linkers persistent store may manipulated applications may potentially names types di erent structures semantics 
deferring type identi er lookup caching run time described allows exibility fully quali ed type names search mapping tables name equivalence locate appropriate type descriptor records compare structural equivalence resolve types application persistent store 
application type descriptor records table built type descriptor generator table persistent store built incrementally objects di erent types allocated persistent store 
fully quali ed type name allocation site look corresponding persistent typeid 
typeid look corresponding transient typeid copy relevant information mapping table persistent store creating new persistent typeid 
hand persistent typeid initial lookup stored object performing type equivalence tests described 
generating fully quali ed type names important devise general purpose scheme generate fully quali ed types names described 
obvious approach general case simply string representation type name time instantiation 
idea standard preprocessor cation operator de nition rttd new macro capture fully quali ed type name macro expansion 
solution works languages support parameterized types fully quali ed name type trivially available source 
parameterized nested types cation general solution macro expansion cation happen preprocessing stage compiler instantiated templates resolved scoping fully quali ed type names generated templates instantiated scoping resolved 
words preprocessor cation early compilation process extract fully quali ed type names 
choose type descriptor generator generate fully quali ed type names general purpose tool building type descriptor records indexed fully quali ed type names provide natural extension save fully quali ed type names part process 
recall type descriptor generator relies debugging information extracted object les created compiler instantiated templates resolved scoping 
type names encountered debugging information fully quali ed 
described section type descriptor generator selectively generates type descriptor records interesting types rttd desired 
extend model selectively generate separate table containing fully quali ed names types 
trivial fully quali ed concrete wrapper class names nd interesting types simply discard wrapper speci part name obtain fully quali ed name instantiated type 
manner similar duplicate elimination merging mapping tables object les section generate single table fully quali ed type names types application rttd desired 
table saved le name su xed tni shown accessing fully quali ed type names fully quali ed type names generated object les available application run time static data members similar ones type identi ers 
extend template wrapper class contain additional static data member typename holds fully quali ed name type 
de nition rttd new macro updated type name passed additional argument typeid overloaded new operator define rttd new type new type typename type type typeid change de nition macro ect programmer interface way 
consider code fragment earlier example allocate object type obj rttd new constructor arguments new macro de nition code fragment expanded preprocessor follows obj new typename typeid constructor arguments recall motivations providing macro interface allow freedom changing underlying mechanism ecting existing user source code 
typeid ensure static data members type names initialized correctly 
generated single table type names interesting types application saved tni le trivial generate appropriate de nitions initializations corresponding static data members auxiliary source le information 
type initialization code int typeid typeid char typename expression typeid may replaced index corresponding type descriptor record nal mapping table 
added cost defer table lookup initializing typeid run time described earlier section provides bene ts applications persistence 
cases typeid data member initialized invalid value signal run time environment perform appropriate table lookup 
complications enhancements implementation described fairly portable robust mechanism generating manipulating type descriptor records applications 
complexity language impossible provide completely elegant interface lowlevel features 
complications related implementation describe possible enhancements 
forcing generation debugging information compilers may optimize away generation debugging information type type instantiated create actual objects objects 
may especially problematic template wrapper class generate concrete types instantiated create actual objects 
solution problem follows 
fool compiler thinking may instantiate concrete wrapper class run time modifying de nition rttd new macro 
include expression conditionally instantiates concrete wrapper class create object calls dummy method object define rttd new type new type typename type typeid dummy test condition 
new type nop type de nition code fragment earlier example expanded follows obj new typename typeid dummy test condition 
new nop constructor arguments expression macro expansion compiler thinking concrete wrapper class may instantiated create actual object method nop invoked object 
ensure dummy condition expression false run time create unnecessary objects 
compiler predict outcome condition compile time optimize away instantiation 
simple way ensure value global variable condition initializing variable false separate compilation unit 
forces compiler generate debugging information concrete wrapper class consequently generate type descriptor record appropriate type application type example 
interaction template repository mechanisms complex template handling schemes template repository mechanisms may source problems 
template repository implementations actual code generation template methods typically deferred link phase 
linker automatically detects missing template instances generates necessary invokes compiler 
purpose mechanism ensure single copy template code instantiated included nal executable avoiding code bloat duplication 
implementations need way generate type descriptor records templates instantiated compiled nal linking done 
possible solution template repository mechanisms provide hooks additional actions calls type descriptor generator may inserted template code instantiated compiled object code 
aware template repository mechanisms currently provide capability 
possible solution compiler generate debugging information normally object les templates defer instantiation code template methods link time 
general propose type published contract compiler debugger regarding contents debugging information 
compiler follows pre speci ed guidelines debugging information generation contents tools type descriptor generator implemented portably guidelines 
note pass value expression zero additional argument overloaded new operator 
additional argument harmless side ect solution ignored overloaded new operator 
handling nested types classes nested types pose special di culty generating auxiliary source le contains de nitions initializations class variables backpatching 
consider de nition initialization auxiliary source char typename language requires auxiliary le le forward declaration actual de nition type de nition initialization shown 
necessary compiler recognizes name valid type generate error 
typically forward declaration su cient information size structure behavior type required 
full de nition may provided lieu addition forward declaration necessary 
auxiliary initialization le forward declaration usually su cient type instantiated fashion 
unfortunately allow forward declarations nested types 
result generate de nitions initializations backpatching variables nested types user intervention provide de nition nested types 
currently system requires programmer cooperation solve problem programmer provide list header les contain de nitions nested types 
les included auxiliary source le forward declarations generated compiler recognize names valid type names de nition initialization 
right solution problem modify language semantics allow forward declarations nested types way non nested types 
believe provide mechanism signi cant impact rest language de nition 
handling virtual function tables applications persistence need treat virtual function table pointers specially 
normal data pointers application virtual function table pointers point code representing executable program 
pointers point load image executable data heap 
data may operated multiple programs recompiled versions program need symbolic representation virtual function table pointer values 
achieve translating pointer values indexes table name strings data saved translating indexes back swizzling addresses corresponding virtual function tables new process reloads data 
term nested types refer classes non aggregate types may nested classes 
virtual function represents mechanism implementing dynamic method dispatch run time polymorphism 
instance class de nes virtual functions contains virtual function table pointer table function pointers generated automatically compiler 
storage model described earlier low level type information extracted application object executable les maintained type descriptor records 
various utilities need access type information manipulate type descriptor records loading disk memory decoding run time 
depending application requirements type information stored formats 
default type descriptor records generated maintained hierarchical format resembles type graph containing complex aggregate types interior nodes basic types leaf nodes 
possible convert hierarchical format format speci requirements application 
remainder section describe formats detail motivation developing formats 
focus primarily formats core storage basic discussion applies disk storage 
choice core storage format directly ects performance characteristics run time discussed section 
hierarchical format name implies hierarchical format maintains type information hierarchy implemented essentially type graph 
basic types represented leaf nodes graph composed form aggregate types form interior nodes 
hierarchies typically created language semantics object contained inside inheritance relationships object oriented programming domain 
representation maintains notion hierarchies maps natural type structures enforced language 
describe hierarchical format simple example 
consider type de nitions user application struct pet short tag char name struct owner char name void short pet pets type descriptor records generated de nitions conceptually represented type graph shown 
node type graph essentially represents type descriptor record speci type leaf nodes represent type descriptors basic builtin types short char interior nodes represent complex aggregate types 
node labels top label name actual data structures type descriptor generator lower label name type represented 
directed edges indicate source node node edges originate represents aggregate type destination nodes nodes sake simplicity syntax basic idea applicable languages aggregate types 
pet owner tag name name pets short char void pet char void type graph edges terminate represent types elds aggregate type 
actual names elds edge labels 
note pointers arrays treated complex types composed types char pet respectively example undirected unlabeled edges graph denote type composition 
note type graph shown highly simpli ed purpose allow easier explanation basic concepts 
speci cally excluded information type sizes eld sets obviously necessary fully describe type structure 
actual data structures represent hierarchical type graph complex contain necessary information fully describe types run time see appendix detailed description structures 
flat format evident foregoing discussion hierarchical type descriptor format contains possible information type application necessarily complex 
complexity justi able need maintain generality possible uses 
depending speci application requirements subset information maintained hierarchical format may 
example implementing pointer swizzling page fault time primarily interested locating pointer elds objects disregarding information various types 
possible decode hierarchical type descriptor records obtain required information ignoring rest 
interest run time performance may preferable transform hierarchical format format front reducing decoding ort required run time 
essence compile time complexity cost format conversion traded run time ciency performance faster decoding 
pointer swizzling page fault time convert hierarchical format format essentially contains list eld sets corresponding pointer elds objects 
actual data structure slightly complex consists parts xed part variable part 
necessary support commonly memory model programs default language check bounds violations possible allocate chunk larger size object additional memory object extension object 
technique typically allocate inline array object array 
terms implementation array usually declared component object dynamic allocation allocate reallocate chunk memory object excess memory past language de ned object part array changing extending size 
heuristic de ned cial language speci cation support programs rely behavior 
note heuristic realized repeating xed sub structure structure element array known 
format type descriptor record contains xed part variable part integer maintains statically declared size inline array 
part contains pointer array represents pointer set values object 
addition integers maintain count array compiler determined size corresponding part 
parts identical structure semantics quite di erent xed part maintains information components type change size run time variable part maintains information element repeated sub structure object 
variable part maintain information single element inline array irrespective original statically declared size maintained separately 
recall type de nitions provided part example previous section 
type descriptor record memory object layout type pet shown 
type contain variable sized arrays xed part type descriptor record applicable 
shows object bytes size contains pointer set 
information matches memory layout sample object shown gure 
note byte padding automatically added compiler maintain alignment constraints 
consider type owner example 
type variable sized array pets contain valid information xed variable parts shown 
information xed part similar described matched memory object layout shown gure 
interested variable part seen information variable part type owner identical information xed part type pet 
corresponds de nition variable parts requires contain information single element repeated substructure type pet example 
note eld type descriptor record maintains statically declared size array 
eld necessary situations array said inline contained object arrays typically xed size size containing object xed determined compile time 
assume word size bytes size short integers half word usual alignment constraints requiring word size elds aligned word size boundaries 
struct pet short tag char name type definition fixed part variable part size fields size fields null type ptr offset flat type descriptor record byte offset tag pad name object layout memory flat format type descriptor records simple objects type owner variable part object cases layout rules dictate pets array owners variable sized decoded statically declared array size 
performance characteristics performance rttd mechanism measured terms space time costs system 
divide costs compile time component run time component cost incurred 
describe costs detail sketch performance characteristics system preliminary results 
compile time costs name suggests compile time component includes costs incurred compilation application executed 
compile time component time cost typically time required run type descriptor generator application object le generate type descriptor records 
space required store type descriptor records typically disk constitutes corresponding compile time component space cost 
long compile time cost components reasonable limits usually important corresponding run time cost components 
obvious comparison point establishing reasonable limits corresponding costs compiling linking application 
rttd compile time costs comparable cost term compilation loosely indicate steps running application 
example compiling linking application generating type descriptor records object les examples actions belong compilation phase 
struct owner char name void short pet pets type definition fixed part variable part size fields size fields type ptr offset type ptr offset type ptr offset flat type descriptor record byte offset name pad object layout memory pets flat format type descriptor records complex compiling individual application object les linking build executable 
practice costs signi cantly actual compilation linking costs terms space time costs 
measured costs building oo benchmark including type descriptor generation actions steps shown 
normal compilation linking time benchmark took roughly seconds wallclock time mhz pentium pro processor running linux type descriptor generation included build process total time went approximately seconds increase 
type descriptor generation actions included runs run 
runs examined generated hierarchical type graph types types instantiated persistently eventually saved disk 
linking duplication elimination total types type information saved hierarchical formats 
terms space costs benchmark executable le approximately kb debugging information preserved kb recompiling ags speci ed debugging additional optimization 
contrast nal format type descriptor records required roughly kb storage executable size 
course actual generation process multiple object les maximum storage requirement higher kb amounted size executable debugging information included type descriptor generation 
emphasized report storage cost percentage executable size comparison point general number type descriptor records space requirements directly proportional number corresponding sizes types run time type description desired 
general conclude system impose signi cant overhead compile time generating storing type descriptor records arbitrary user application 
run time costs de nition run time costs incurred application executed 
runtime component time cost usually includes time load type descriptor records memory time access information stored type descriptor records 
actual memory usage data structures maintain type descriptor records memory part run time component space cost 
respect time cost initial loading type descriptors considered part startup costs relatively minor compared startup costs dynamically linking loading libraries handling shared objects cost decoding memory type descriptor records important cost run time 
approach access information type descriptor records dependent onthe data structures represent records memory 
section described various formats store type information 
estimate cost aggregate type temporarily ignoring variable part interest simplicity 
recall xed part figures contains integers pointer array eld sets 
type pointer elds approximate storage cost xed part sizeof integer sizeof pointer sizeof integer bytes 
variable part consideration cost estimation little trickier 
recall variable part maintain information single element repeated sub structure overhead including variable part type descriptor record top level aggregate type equivalent cost xed part element 
making decoding costs negligible pointer swizzling page fault time type descriptor records described earlier maintain information locations pointer elds various objects 
due nature structure representation decoding highly optimized allowing direct access pointer elds sets recorded xed parts 
decoding variable parts slightly complex requires iterating relevant portion object type information variable part iteration iterating add signi cant overhead compared cost actual decoding 
decoding mechanism relatively fast adds tens instructions object run time costs type descriptor records 
ort minimize costs developed approach reduces decoding costs negligible levels order cost procedure call 
basic idea explained analogy 
type descriptor records viewed bytecodes runtime decoding process thought bytecode interpretation 
bytecodes usually compiled native binary code allowing execution full speed requiring run time interpretation 
similarly described compile type descriptor records generated code require run time decoding 
described section generate auxiliary source containing initializations backpatching variables 
similar vein hierarchical type descriptor records converted format generate code procedure corresponding type 
procedure embodies run time decoding type descriptor records eld interest generate invocation callback function responsible handling speci actions eld 
auxiliary code containing procedures compiled linked application initialization code 
type information object required run time top level procedure object type invoked decoding corresponding type descriptor record 
note result decoding type descriptor record run time run time interpretation compiled type descriptor record reducing decoding costs single procedure call 
type descriptor record compilation compatible variable sized object actual size objects known run time 
compilation process described xed part type descriptor record 
variable part easily handled 
de nition variable part type descriptor record describes single element variable sized array simply generate loop callback function invocations corresponding compiled variable part loop termination condition actual run time object size guaranteeing correct behavior 
approach add overhead compared run time decoding type descriptor record 
minor disadvantage type descriptor record compilation described 
basic approach works long entire objects manipulated starting object 
suitable objects partially processed large objects static ordering imposed callback function invocations 
situations basic approach augmented allow additional control callback functions 
course simple workaround just fall back run time decoding type descriptor records 
pointer swizzling page fault time basic swizzling unit page problem arise large objects cross page boundaries objects smaller page swizzled entirety 
current status implemented type descriptor generator mechanisms described chapter 
texas persistent store chapter real time garbage collector wj 
currently versions type descriptor generator available modern unix systems os di erence platform speci code parse debugging information 
debugging information format di erent unix systems varies signi cantly leveraged code gnu debugger gdb extract debugging information 
approach portable gdb understands di erent kinds object le formats debugging information formats various architectures compilers 
gdb platform speci operations type descriptor generator instantly portable architectures supported gdb 
code uses standard gdb routines parse debugging information types application memory data structures data structures transformed type descriptor records 
note necessary gdb purpose feasible implement platform speci code extracts debugging information directly object les 
approach adapting type descriptor generator os ibm visualage compiler 
course compiler provides low level object layout information form adaptor code written transform compiler speci information type descriptor records 
code modules implementations debugging information relatively small 
example new code added gdb type descriptor generator executable lines 
similarly os version approximately executable lines 
source code versions publicly available gnu gpl ftp ftp cs utexas edu pub garbage texas 
system designed easily portable compilers platforms 
major ort required porting providing platform speci code parse debugging information object les 
intend system ported variety pc operating systems compilers 
believe relatively easy pc compilers usually generate debugging information format choosing representative formats providing speci code parse formats possible support multiple compilers 
related techniques proposed implemented providing rttd 
techniques speci source language incur signi cant additional run time overheads provide cient general purpose mechanism generate manipulate rttd 
systems similar developed knowledge independently unfortunately published descriptions exist 
marc shapiro collaborators inria developed type description facility code gdb 
appears object design 
odi developed similar facility object store persistent object storage system details proprietary system available 
odi provides preprocessor supporting extensions 
researchers proposed special purpose preprocessors conjunction user intervention provide support rttd 
ede proposes precompiler automatically augment source program additional rttd information garbage collection 
underlying idea smart point tom ibm austin implementing platform speci part os 
count excludes blank lines comments source lines get compiled executable code 
marc shapiro personal communication may 
ers ede class objects emulate normal raw pointers 
precompiler performs tasks necessary safe garbage collection nding root set accurately identifying internal pointers objects 
system uses smart pointers identify roots rst task precompiler parse source code de ne appropriate smart pointer classes raw pointers root set 
second task precompiler parse type de nitions emit member function garbage collected type identify internal pointers type 
detlefs det describes modi ed scheme smart pointers 
scheme extends smart pointer de nition constrains programmer interface garbage collected objects 
extended smart pointer de nition provides additional actions performed standard pointer operations invoked smart pointer objects 
garbage collection implemented extended functionality smart pointers 
schemes require placing additional restrictions user incur additional run time overheads manipulating smart pointers 
addition precompiler quite similar preprocessor needs parse type de nitions source code susceptible problems described earlier preprocessors 
linton il proposed dossier class standard interface runtime type information 
preprocessor style dossier generator create dossier objects source code 
linton propose language extended automatically generate virtual function class access appropriate dossier object 
feature provided part language programmers provide information manually class 
scheme requires preprocessor closely dependent language implementation features virtual functions 
introduced term run time type description rttd denote availability low level object layout information run time contrast run time type identi cation rtti access language level information run time 
described portable general purpose mechanism generating manipulating rttd high level languages ada provide information language feature 
approach require special compiler cooperation allows programmer shelf high performance conventional compilers 
type descriptor records representing low level layout information run time 
developed novel approach build type descriptor records debugging information generated modern compilers 
debugging information format typically depend speci source language compiler approach works combinations di erent languages normal compilers 
implemented type descriptor generator illustrate issues involved providing rttd speci language 
unix systems leveraged code application maintain entry pointers various data structures pointers known roots collectively referred root set 
gnu debugger gdb provide platform speci part type descriptor generator 
approach portable gdb understands di erent debugging information formats various architectures 
aversion type descriptor generator os visualage compiler uses non gdb code parsing debugging information available 
described storage model various formats store type descriptor records memory run time 
depending application requirements possible convert full edged hierarchical type descriptor records simpler format allow faster decoding 
approach ectively reduce run time decoding costs zero 
preliminary performance results untuned implementation shown compile time run time costs rttd mechanism excessive 
general believe facility accessing implementation level type information run time useful possibly quite necessary avariety system extensions 
rttd mechanism described chapter provides framework implementing run time type description variety high level languages er standard builtin language feature 
believe approach debugging information highly portable preferable techniques depend knowledge source language speci compilers 
chapter interactions operating systems evident earlier discussion texas interacts strongly low level features provided operating system 
interaction stems virtual memory protection access protection violation handling implementing coarse grained address translation 
addition texas useful system level extensions libraries example garbage collectors ael wil distributed shared virtual memory systems li lh virtual memory tracing compression facilities advanced pro ling closely interact operating system 
believe operating system implementors take interactions lowlevel systems libraries consideration designing new systems 
modern operating system provide su cient hooks allow various extensions implemented ciently outside kernel able exploit low level features 
greatly improve portability systems maintaining general high performance characteristics 
chapter discuss areas operating system interactions important ciently implementing system level extensions 
discussion experience implementing pointer swizzling page fault time texas issues applicable systems mentioned earlier 
primarily interested interactions virtual memory system memory allocation protection replacement 
operating systems allow degree exibility area control desirable achievable 
brie describe related issues cient handling access protection violations generated attempts access protected memory 
focus unix operating systems basic ideas applicable modern operating systems 
background virtual memory virtual memory den originally designed simply manage distinct levels memory hierarchies main memory secondary storage giving applications illusion single level storage larger size available physical memory 
today virtual memory essential smooth operation computer hardware software 
modern operating systems provide various primitives allow application programs interact exploit virtual memory system interactions range simple allocation deallocation model advanced interfaces shared memory li lh memory inheritance supported mach 
absence virtual memory system application program size available memory programmer responsibility manually split code overlays explicitly controlled 
contrast virtual memory system provides seamless program execution automatically handling data transfer main memory secondary storage necessary involving programmer 
basic terminology virtual memory typically implemented allowing process virtual address space distinct processes 
pages virtual address space mapped physical address space main memory application accesses data pages 
application allowed access data virtual addresses aware actual physical location data main memory 
pages easily relocatable depending availability physical memory 
job operating system memory manager maintain current mappings virtual physical addresses automatically translate necessary 
collection pages accessed roughly time application usually called working set 
application continues execution di erent phases working set changes pages longer accessed new pages referenced accessed 
order maximize main memory utilization memory manager implements page replacement policy pages main memory 
name suggests old pages longer removed main memory replaced newer pages 
usually accomplished follows 
page virtual address space referenced application typically corresponding page backing store associated backing store lazily necessary page stored replaced main memory 
special disk partition called swap space paging space usually con gured secondary storage serve asthe backing store certainly possible conventional le main memory secondary storage remote host network purpose 
process transferring data memory backing store maximize memory utilization known paging remote paging backing store di erent host 
virtual memory allocation fundamental principle virtual memory allocation allow applications allocate memory physically available machine 
theoretically possible allocate virtual memory addressable hardware word size 
practice varies operating system implementation usually limited maximum secondary storage con gured swap space system 
phrase virtual memory allocation quite loosely chapter 
usual connotation refers allocation virtual address space corresponding backing store 
interested allocation address space having physical memory associated highlight distinction necessary rest chapter 
section discusses various issues related virtual memory allocation including di erences storage space address space allocation various primitives available purpose 
speci cally describe standard unix primitives virtual memory allocation performance characteristics major operating systems linux solaris 
section contains details primitives swap space allocation 
storage space vs address space allocation distinction typically exposed normal users believe important system implementors distinguish allocation virtual storage space allocation virtual address space 
distinction relevant pointer swizzling page fault time possibly low level system algorithms bene additional control virtual memory mechanisms 
de ne virtual storage space allocation allocation virtual address space corresponding backing store address space 
contrast virtual address space allocation simply allocates address space assign backing store chunk address space 
allocated space needs application page backing store allocated assigned operating system application address space referenced 
alternatively lazy approach reserve page backing store allocate page ready written approach page ready evicted 
pointer swizzling page fault time functions correctly address space storage space allocation strategies preferable pages reserved access protected normal course operation 
reserved pages may referenced application requiring data loaded pages allocating backing storage pages obviously wasteful 
contrast virtual address space allocation strategy works basic swizzling mechanism 
pages referenced application cause protection fault handler invoked handler assigns backing store faulted page loads data persistent store returning control back application 
approach backing storage assigned pages application 
virtual memory primitives primarily interested low level primitives example sbrk primitive available various unix systems allocate virtual memory operating systems 
interested high level standard library routines malloc free represent implementation allocation policy rst best wjnb top low level primitives 
course exibility features underlying virtual memory primitives guide implementation choices high level allocation mechanisms 
modern unix avors provide standard primitives sbrk mmap virtual memory allocation 
historically unix variants supported sbrk form mmap newer feature originally existed bsd appeared variants decade gms 
currently popular avors unix workstations pcs support mmap albeit minor di erences interface 
exact behavior primitives may slightly di erent variants basic functionality remains 
classify sbrk mmap class primitives purposes current discussion interface implementation details vary signi cantly compared 
brie describe comparing respect exibility features 
note rest section focuses primarily primitives provided unix operating systems basic ideas applicable virtual memory primitives modern operating systems windows nt os 
sbrk primitive high level allocation mechanisms commonly sbrk underlying virtual memory primitive provides simple mechanism extend data region application 
interface simple caller requests allocation number bytes request satis ed allocating bytes necessary normal swap space backing store allocated address space 
shows classic view process virtual address space 
typically divided regions called segments text data heap stack 
text region maintains code segment process data segment contains initialized uninitialized data process 
heap segment represents dynamically allocated data shown gure starts data segment grows upwards address space increasing address values 
contrast stack segment usually starts high address grows downwards 
allocated position address space represented break point shown gure 
sbrk actions closely related notion break point 
memory dynamically allocated operating system sbrk break point appropriately maintain invariant de nition 
note break point moves monotonically upwards address space memory allocated operating system 
typical general unix programming deal minor tedious incompatibilities di erent variants 
usual approach preprocessor directives ifdef customize application source variant 
emphasized segment context refers mapping process address space backing store segmented addressing 
stack high address virtual address space unallocated region heap data text break low address address space process mmap primitive sbrk mmap exible provides additional features 
basic interface allows applications map le parts le virtual address space le acts backing store address space 
data le available directly corresponding virtual address space requiring explicit requests le 
le eventually unmapped memory inthe usual case modi ed data virtual memory automatically updated le 
addition mapping facility mmap ers features memory protection mapping le copy write features useful immediately relevant current discussion ignored moment 
operating systems example linux aix provide additional features allow applications map anonymous regions les 
anonymous region usually just chunk normal swap space backing store le le system 
anonymous regions allows essentially semantics sbrk additional capabilities mmap 
note mmap actions directly related break point shown 
mmap map le heap segment address space 
ways selecting address range mapping 
default operating system selects address range heuristics existing mappings 
term anonymous backing store swap space referenced le name 
systems sbrk may implemented terms mmap kernel fact generally apparent exposed user 
addition implementation allow programmer override default explicitly specify exact address range mapping typically map fixed option mmap 
call may fail speci ed address unsuitable reason example page aligned 
option usually discouraged results code 
general preferable operating system select address range order avoid con icts allocated data 
facility applications may require bene explicit user selection address range 
comparing sbrk mmap obvious discussion sbrk provides simple functionality interface mmap provide semantics ering additional capabilities 
believe mmap preferable general provides additional control allocated memory 
control desirable systems especially pointer swizzling page fault time interact extensively operating system 
operating systems provide primitive complements functionality purpose primitive memory previously mapped mmap 
words breaks association backing store le anonymous region speci ed range virtual address space 
backing store represented anonymous region excellent unused swap space application return operating system 
similar primitive corresponding sbrk convenient reclaim swap space corresponding memory allocated sbrk application nishes execution 
prefer mmap sbrk necessarily advocating persistent store mapped directly virtual memory 
fact may advisable persistent store may stored compressed storage cached network making unsuitable direct mapping mmap 
favor mmap allocating virtual address space better control backing storage 
performance virtual memory primitives far discussed di erences sbrk mmap terms functionality exibility orded di erent features primitive 
describe results experiments conducted measuring performance primitive 
primitives allocate address space operating system call primitive causes control cross kernel boundary turn causes execution switch normal user mode privileged mode 
obviously expensive non kernel calls operate unprivileged mode 
solution reduce performance penalty amortize cost multiple calls batching requests single large request 
batching implemented simple application level bu ering described 
application maintains batch contiguous virtual address space pages batch bu er predetermined size batch size 
batch bu er empty startup rst allocation request invokes chosen primitive allocate pages address space selected batch size batch bu er full 
original request satis ed removing pages batch bu er control returns application 
allocation requests arrive rst check pages available batch bu er 
request satis ed batch bu er need switch kernel mode 
request satis ed batch bu er batch bu er empty full cost invoking primitive incurred 
choice batch size involves tradeo space time costs 
larger batch size memory preallocated part batch bu er application may 
hand smaller batch size frequent need cross kernel boundary switch execution modes ecting performance 
studied various choices batch size relatively small batch sizes pages provide signi cant bene ts batching moderate batch size usually provides bene batching approaching diminishing returns larger sizes 
experimental design results detail 
experimental design benchmark suites measuring performance virtual memory primitives ect batching 
set microbenchmarks designed speci cally measure absolute performance primitives di erent batch sizes ranging 
comprises standard oo benchmark forward traversal operations extensively measure performance texas chapter 
results microbenchmarks select set interesting batch sizes oo benchmark traversal operation experiments 
microbenchmarks relatively simple designed measure performance primitives isolation 
run benchmark repeatedly calls speci primitive consideration tight loop measures time entire loop nally divides total time number iterations obtain average time invocation primitive 
iteration loop requests single page virtual address space batch sizes greater implemented batching mechanism described earlier group multiple small requests single large 
iterate total times record time clock cycle timer get accurate measurement 
microbenchmark run multiple times batch size larger previous run starting batching maximum 
results microbenchmarks select set interesting batch sizes speci cally primitives total possible note bu er address space allocation virtual addresses actual contents virtual memory traditional bu ering techniques 
batching ects system time reducing kernel boundary crossings real time cycle timer resolution signi cantly better cpu time timer 
expect real time close approximation cpu time case microbenchmarks incur system user level overhead primitives 
combinations allocating virtual address space oo benchmark traversal operation 
combinations generated unique version texas uses speci primitive batch size allocating new address space 
version linked benchmark code giving suite benchmark traversal operations 
ran benchmark small large databases measured time traversal 
hardware mhz intel pentium pro processor mb ram operating systems linux solaris texas performance measurements chapter 
rst results microbenchmarks presenting results oo benchmark traversals representative set batch sizes 
experimental results microbenchmarks addition plots sbrk mmap primitives labeled accordingly microbenchmarks results include third plot labeled 
corresponds variant mmap primitive allows programmer explicitly specify address range mapping map fixed option 
note provide performance results xed map variant sake comparison 
variant isnot practical places additional restrictions application results code 
speci cally portable way determine safe address range di erent operating systems operating system di erent platforms map fixed usually discouraged 
shows performance primitives xed map variant 
axis represents average cost clock cycles calling primitive di erent batch sizes enumerated axis 
note relatively small batch sizes reduce average call cost factor 
expected cost decreases batch size increased exponentially reaching point diminishing returns 
zooming lower part curves notice costs primitives similar making mmap preferable sbrk added exibility 
sbrk mmap clock cycles batch size performance virtual memory primitives linux sbrk mmap clock cycles batch size performance virtual memory primitives zoom linux results solaris note surprisingly unusual behavior primitives 
shows performance di erent batch sizes 
rst thing notice gure batching mmap extremely expensive solaris cost approximately times sbrk xed map variant 
batch size small su cient reduce high cost factor cost sbrk batching 
results compared linux results clearly show solaris uniformly slower far pure performance virtual memory primitives concerned 
believe probably due gross ine ciency kernel implementation di cult overcome 
sbrk mmap clock cycles batch size performance virtual memory primitives solaris sbrk mmap clock cycles batch size performance virtual memory primitives zoom solaris zoom lower part curves 
linux results notice unusual behavior plot corresponding performance sbrk 
particular batch sizes sudden jumps average cost call primitive forming sawtooth shapes plot 
quite unusual feature believe closely related internal data structure particular algorithm implementation primitive 
access kernel sources related implementation details relatively easy con rm hypothesis 
useful piece information derived results 
speci cally notice variants mmap eventually converge approximately average cost call moderately large batch size 
quite reassuring indicates normal mmap usage performance equivalent faster xed map variant suitable practical 
time sbrk continues twice expensive batch size large 
believe observations justify position mmap selected primitive choice virtual memory allocation 
experimental results oo benchmark traversal operations microbenchmarks results clearly shown batching multiple allocation requests provides signi cant improvement performance virtual memory primitives 
section results oo benchmark forward traversal operations batched variants primitives address space allocation 
particular results traversal large database solaris di erent batch sizes primitive 
showing actual traversal results brie revisit characteristics oo benchmark kept mind comparing performance virtual memory primitives batched variants 
recall average tenth pointer benchmark database arbitrary part object randomized interconnections 
causes pages address space reserved initial traversals lot new data loaded memory swizzled 
execution progresses warm traversals nd pages corresponding newly swizzled pointers reserved loaded memory earlier traversal action necessary 
new address space reservation happens rst traversals pointers new pages seen swizzled 
plots number pages swizzled number pages reserved traversal traversal set run large database 
clear gure new pages swizzled entire set warm traversals address space reservation occurs rst traversals 
early traversals obviously relevant performance comparison virtual memory primitives batched variants 
reserved swizzled number pages traversal number pages swizzled reserved traversals large database solaris background traversal results primitives 
various gures axis represents di erent traversals cold warm hot iterations single traversal set axis represents cpu time milliseconds traversal 
plot cpu time total real time batching ects system time minor extent user time primarily reduces number switches user kernel mode 
unfortunately operating systems provide high resolution timer measuring cpu time typical resolutions order milliseconds isvery coarse purposes overheads fairly small 
severe rst interested initial traversals contain lot swizzling new address space reservation cumulative times large ected coarse granularity timers 
shows cpu time traversals oo benchmark forward traversal set large database mmap di erent batch sizes allocating virtual address space swizzling 
obvious mmap batching expensive batch size small improves performance factor 
observation line earlier results obtained microbenchmarks 
refer sum user system time cpu time 
note real time microbenchmarks su cient situation traversal contains computation components interfere performance measurements primitives 
cpu time seconds batching batch size batch size batch size traversal number cpu times traversals mmap large database solaris cpu time seconds batching batch size batch size batch size traversal number cpu times traversals mmap large database zoom solaris zooming lower part curves con rms increasing batch size reduces cost expected eventually reaching diminishing returns 
recall rst traversals relevant new address space reservation meaningful comparison performance improvements due batching 
batching batch size batch size batch size cpu time seconds traversal number cpu times traversals sbrk large database solaris cpu time seconds batching batch size batch size batch size traversal number cpu times traversals sbrk large database zoom solaris figures show corresponding traversal results sbrk mmap allocating virtual address space reserved pages 
note sbrk batching expensive batching small pages 
corresponds results obtained corresponding microbenchmarks 
performance improvement sbrk factor smaller absolute numbers mmap 
surprising know microbenchmarks results performance mmap batching extremely bad compared sbrk 
evident plots labeled figures rst traversals mmap version consistently expensive sbrk version factor 
results traversals small database reported reasons 
show interesting behavior obvious results large database second rst traversals small database relevant performance comparisons traversals new address space reservation actions making harder measure signi cant performance improvements 
vein linux results showed similar behavior important distinction 
linux results sbrk mmap show di erence results obtained solaris results similar primitives 
course line derived microbenchmarks results earlier 
discussion empirical results clearly show bene batching multiple small requests single larger request measurable performance improvement individual requests 
notice batch sizes large ective 
speci cally batch size pages usually provides bene batch size provides bene batching quickly approaches point diminishing returns larger sizes 
cost batching amount memory wasted due preallocation application uses part preallocated memory 
typical virtual memory page size kb current systems batching kb pages kb pages backing store 
numbers smaller compared today typical main memory sizes mb mb swap space sizes range hundreds megabytes 
conclude batching useful provide substantial performance improvements equivalent increases cost 
note high level allocation library routines malloc free may variation batching technique described 
general useful provide batching directly virtual memory primitives implementation tightly coupled operating system 
interesting derived empirical results regarding performance solaris 
seen virtual memory primitives solaris times slower linux identical hardware setups 
argued fair comparison solaris implements layered vm architecture gms ords cleaner abstractions better portability impact performance 
believe allowing layering abstractions solaris slower linux ported di erent architectures factor 
user level protection fault handling area solaris performance worse expected 
issues swap space allocation described earlier actively distinguish allocation virtual address space allocation virtual storage space application backing store associated allocated address space 
user applications know care distinction typical requires swap space allocated 
basic nature pointer swizzling page fault time warrants additional control virtual memory allocation lazy allocation backing store 
naive approach allocate swap space soon page address space allocated irrespective application referenced page data page call eager allocation swap space 
contrast smarter approach recognize unnecessary save page backing store long page referenced application 
heuristic swap space allocation deferred page referenced read written called lazy allocation 
potential problem lazy allocation may cause resources case swap space 
applications may fail attempt access allocated memory su cient swap space available provide required backing storage 
section discuss additional control backing storage allocation bene cial purposes speci cally pointer swizzling page fault time useful general low level algorithms interact virtual memory system 
describe existing implementations virtual memory primitives various modern operating systems handle allocation swap space 
suggestions possible improvements useful various applications 
ps swap space allocation described chapter virtual memory protection techniques access protect address space corresponding reserved pages 
memory protection ensures application attempt data pages causing access protection violation 
violation handler locates loads corresponding data persistent store 
guaranteed reserved pages application handler receiving noti cation access 
follows pages reserved course swizzling necessary allocate backing store pages 
need allocate virtual address space reserved pages consuming real memory swap space unused pages 
guaranteed fault handler gain control attempt access data protected page arrange necessary backing store assigned time 
easy way associate backing store faulted page mmap anonymous region page 
lazy allocation swap space particularly useful pointer swizzling page fault time coarse grained swizzling done worrying wasted swap space unused pages 
virtual address space consumed reserved pages recall reserved pages pages referenced swizzled pages placeholders data loaded persistent store 
address space scarce resource compared swap space 
furthermore swap space allocated lazily mmap similar potentially reclaim similar pages longer application 
course swap space reclaimed address space retained may referenced application data structures 
address space guard get noti cation attempts access data space 
survey existing implementations wide variety operating systems currently available market 
implements standard virtual memory primitives provide basic functionality described earlier minor variations compared 
brief survey implementations virtual memory primitives respect swap space allocation popular modern operating systems 
sunos solaris ultrix virtual memory primitives operating systems allocate swap space lazily 
actual allocation done required swap space reserved eagerly 
page address space allocated operating system sets aside corresponding swap space generate physical virtual mapping entry page table 
eager reservation swap space designed avoid problem associated lazy allocation swap space 
reserving swap space time page allocated operating system guarantees su cient swap space allocated pages 
purposes ect eager swap space allocation waste swap space pages application 
solaris de nes new option map speci ed mmap 
name suggests ag lets application indicate operating system swap space reserved allocated newly mapped address range application responsible ensuring adequate backing storage available address space accessed 
exactly ciently implementing coarse grained pointer swizzling mechanism 
useful control sbrk situations mmap 
aix aix default swap space allocated lazily application uses reads writes page 
systems users allowed dynamically modify behavior cause early allocation swap space speci sessions 
done setting user environment variable special value early 
applications executed environment variable set default eager allocation swap space 
addition exists special signal sent running processes available swap space falls certain threshold 
signal designed allow graceful handling swap space exhaustion far possible processes ignore signal operating system eventually kill processes avoid complete 
certainly debatable having signal arbitrarily killing processes design decision general 
believe having mechanism allows process noti cation controlling memory usage useful idea principle 
unfortunately heuristics selecting processes amenable termination 
example current heuristic selects processes largest memory allocation 
rst glance reasonable getting rid largest processes provide biggest bene possible large processes critical longrunning processes terminating ectively wastes cpu utilization devoted execution 
believe extremely di cult nd process selection strategy acceptable situations 
course helpful programmers better educated existence behavior applications implemented gracefully handle signal reducing need drastic actions operating system 
minor quirk aix highlighted 
operating system divides bit process address space sixteen segments mb size 
application classi ed supporting small allocation model large allocation model 
default applications fall category restricts maximum virtual address space allocation single segment 
possible build applications support large allocation model providing special option linker increasing upper limit address space allocation gb segments 
os warp default swap space allocation model eager allocation 
aix possible explicitly control behavior achieve lazy allocation 
operating system supports lazy allocation model request basis possible select lazy allocation special ag allocation request 
selection ect particular allocation request 
note quite di erent aix environment variable ects allocation requests applications executed variable set 
linux linux appears unusual regarding swap space allocation model compared operating systems described 
default model completely lazy allocation normal lazy allocation scheme swap space allocated page referenced rst time linux defers allocation swap space waiting classic segmented addressing applications aware segments direct virtual addresses operating system internally uses segment register addressing locate data larger bit hardware supported address space 
page ready swapped 
essence swap space treated extension main memory backing store 
approach allows con gurations swap space long running processes consume total available main memory 
note linux provides mechanisms turn lazy allocation model 
discussion evident discussion standard heuristics swap space allocation operating system implements virtual memory primitives di erently provides variant mechanism con guring lazy eager allocation swap space 
believe lazy allocation model preferable general long applications aware willing handle situations possible backing store occur 
ideal situation default lazy allocation application con gurable option switching eager allocation 
setup applications truly need eager allocation ensure backing storage allocated address space 
unmapped address space addition inherent lazy allocation supported sbrk mmap implementations possible way toachieve ect unmapped address space virtual address space mapped consequently corresponding entries page table 
approach applications unmapped address space access protected address space handle unmapped memory violations access protection violations detect accesses protected region 
main advantage approach supports true lazy allocation address space mapped accessed 
naive implementation scheme simply select range addresses reserving address space involving operating system selection process 
rst glance reasonable de nition address ranges known operating system unmapped 
obvious problems approach 
modules application may allocating memory cooperation operating system possible operating system may accidentally select address ranges clash reserved addresses know ranges 

portable way safe address ranges multiple operating systems single operating system di erent hardware platforms kernel versions ranges clash normal allocation 
problem face map fixed option mmap 
basic solution disallow operating system adding new mappings reserved area 
example operating system map le dynamically linked possibly shared library memory may select address range partially overlaps completely pages reserved part pointer swizzling process 
potentially serious problem simple mmap ed persistent storage systems pointer swizzling actual persistent object store tightly coupled speci virtual address ranges mapped 
clear order solve problems ectively operating system involved address space reservation process 
approach provide new virtual memory primitive say inform operating system certain address range application backing store needs allocated 
alternatively primitive designed ask operating system unmapped address range behalf application 
implementation primitive fast part minimal actions required implement simple functionality 
fast primitive reduce overhead reserving address space swizzling currently sbrk mmap purpose adversely impacts performance system 
pointer swizzling virtual memory management pointer swizzling page fault time uses existing virtual memory hardware protection facilities supported operating system detect non resident object trigger loading swizzling pages containing objects 
page faulted persistent store cached virtual memory distinction page memory secondary storage 
words virtual memory system free move swizzled pages main memory swap space ecting normal operation texas 
systems enforce pages corresponding persistent memory pinned ram 
general pointer swizzling page fault time independent page replacement policies underlying virtual memory system 
course necessary exploit additional control may ered operating system la mach style external pagers 
default texas plays nice applications running system impose special considerations virtual memory system 
section discuss various issues related interactions virtual memory system pointer swizzling page fault time context control memory management 
rst revisit mistaken dirty pages problem described earlier chapter arises due extremely loose coupling pointer swizzling page fault time virtual memory system 
example describe possible spectrum interactions application virtual memory system provide directions additional application level control memory management including paging 
control memory management recall mistaken dirty pages problem arises virtual memory system distinguish modi cations texas pointer swizzling application batching mechanism simple way amortize cost crossing kernel boundaries 

result pages erroneously marked dirty virtual memory system paged necessary 
basic resolution problem lies providing mechanisms allow additional interactions virtual memory system application regarding access characteristics status pages 
general solution allow applications complete control virtual memory management operating system 
necessary extensive control simpler virtual le system interface exploited purpose expense operating implementation 
possible imagine spectrum di erent levels interaction application virtual memory system ranging simple interaction complete application control various virtual memory management policies 
default situation falls spectrum application exert control virtual memory system cooperates applications 
spectrum situation application full control virtual memory system including replacement policy mechanism 
case application special privileges compared applications system performance adversely ected actions privileged application 
example application pins pages ram memory available applications ectively reduced possibly causing extra paging activity 
general situation resources exclusively assigned single privileged process adversely ect privileged processes 
extremes variety levels ord di erent degrees interaction virtual memory system 
brie describe approaches discuss applied solve mistaken dirty pages problem 
special purpose virtual memory primitive narasayya originally identi ed mistaken dirty pages problem propose special system call allows application clear dirty status bit page 
idea system call pages modi ed application pages need evicted memory simply discarded unnecessary page outs 
corresponding virtual address space space intercepted normal fault handling mechanism 
solution generalized provide new special purpose primitive application communicate various types information underlying virtual memory system 
primitives paging policy mistaken dirty pages easily con gured local paging remote paging persistent store depending current application speci conditions virtual memory system behavior controlled accordingly 
operating systems solaris aix support primitive essentially simpler version full edged primitive communicating virtual memory system 
currently memory mmap ed supports limited amount information communicated 
possible extend functionality generalize arbitrary pages address space 
external memory management envision external memory management mechanism allows user level code control various memory management operations paging address mapping operating systems mach choices rus chorus arg provide form external memory management 
mach allows user level tasks act external pagers fully control memory process address space 
pager may control part address space multiple pagers coexist managing di erent part address space 
external pagers handle page page requests generated kernel free save restore data arbitrary mechanism 
mach provides default pagers called internal pagers external pagers con gured 
external page facility combined pointer swizzling mechanism create intermediate loading swizzling module executes separate thread handles requests load data persistent store 
job module locate page swizzle load memory 
pages modi ed loaded memory virtual memory system erroneously consider page dirty due swizzling 
provides general solution allows pointer swizzling page fault time coexist virtual memory system 
virtual file system builtin operating system supported external page facility dedicated swizzling module similar mechanism implemented exploiting virtual le system vfs interface provided modern operating systems expense requiring system speci implementation superuser privileges mounting new le system 
essence implement simpli ed external pager facility virtual le system 
basic idea implement simple special purpose le system manages speci les 
acts backing store data loaded heap persistent store pseudo le communicate information application special le system 
term le system module code implements actual le system mechanism interacting vfs interface 
contrast term le system instance corresponds unique set special les managed le system module 
le system module loaded mounted specially kernel new virtual le system multiple le system instances persistent store manipulated application 
words mapping persistent stores le system instances manage 
apart managing paging particular persistent store le system instance acts swizzling server persistent store swizzling data necessary maintaining information required mapping persistent virtual addresses 
application opens persistent store rst step mmap page virtual address space special backing storage le loading data persistent store 
de nition page corresponds rst page persistent store persistent store entry pointers swizzled corresponding virtual addresses page 
current implementation concludes bootstrap phase 
application attempts dereference entry pointer normal virtual memory kernel fault generated data rst page available 
virtual memory system transfers control special le system loading data memory 
le system locates loads page actual persistent store stored regular le system appropriately maintaining necessary mappings persistent virtual addresses provides swizzled page virtual memory system nishes handling virtual memory fault making data available application 
notice page delivered virtual memory system swizzled ensuring considered clean virtual memory system 
pages need reserved swizzling handled mapping address space special backing storage le making corresponding entries mapping table 
virtual memory system needs evict pages part page replacement policy simply discard clean swizzled pages intervention le system 
application page new kernel fault generated handled loading page persistent store swizzling special le system 
hand pages modi ed application truly dirty pages opposed mistaken dirty pages need evicted paged le system write local swap space normal virtual memory paging 
alternatively depending checkpointing logging mechanism truly dirty pages may written directly log may uni ed persistent store log structured storage system 
notice avoid mistaken dirty pages problem completely providing swizzled pages virtual memory system 
implementing le system handle backing storage persistent store able intervene right level abstraction similar external pager requiring extensive modi cations operating system 
referring back system architecture shown chapter ectively migrated swizzling mapping module separate entity special le system 
course type descriptor information communicated swizzling module requiring additional communication handled pseudo le application special le system 
bene approach user level fault handling longer required implementing pointer swizzling page fault time 
manage loading swizzling entirely normal kernel level faults generated virtual memory system 
pages modi ed application distinguished easily truly dirty pages paged le system clean pages directly discarded virtual memory system 
approach avoids traditional similar current bootstrapping mechanism 
optimization may batching currently implemented mmap multiple pages address space time individual pages demand 
similar normal kernel level faults loading data les mapped memory 
database system strategy wiring chunk ram managing explicitly 
similar current faulting swizzling approach texas plays nice applications terms virtual memory management 
approach works modern operating systems achieve high degree portability ensuring actions terms known le interface reads writes les 
operating system speci implementation required interacting virtual le system interface speci operating system 
issue need superuser privileges mount special le system appropriately kernel recognizes valid module 
necessary mount single le system module running normal application implicitly interacts le system instances require special privileges 
believe minor disadvantages acceptable costs portability performance bene ts gained avoiding mistaken dirty pages problem 
discussion address mapping virtual memory management separate issues managed separately 
unfortunately current operating systems combine implementations leading unexpected interactions low level mechanisms pointer swizzling page fault time compressed virtual memory 
mistaken dirty pages problem associated additional page outs follow provide excellent example unexpected unnecessary interactions 
right solution improve operating system implementations provide better separation concerns additional control programmer 
modern operating systems provide extended memory management model separates fundamental issues allows programmers externally control behavior various operating system components 
seen earlier discussion issues resolved order provide exible mechanism user level applications interact control 
approach implements basic operating system functionality microkernel core layers rest top external modules probably best way handle interactions 
envision exible external memory management mechanism similar mach style external paging supporting additional user level control operating system functionalities 
actual mechanics page ins page outs paging policy important aspect virtual memory paging 
paging policy virtual memory system select pages replaced replaced 
mach supports user level pagers handling mechanics actual paging control paging policy retained operating system external pagers typically ect policy decisions 
wide spectrum applicability corresponding di erent levels control virtual memory system behavior 
applications having control paging mechanism su cient may necessary 
contrast special purpose applications full custom replacement policy complete control probably signi cant win default policies 
important approach resolve problem right level abstraction achieve cleanest solution 
example easy solve mistaken dirty pages problem simply mach style external pagers requiring complete control arbitrarily changing replacement policies virtual memory system diving deep low level implementation issues 
course disadvantages allowing user level control operating system functionalities 
speci cally performance may signi cantly ected user level code bad decisions 
bene ts appear outweigh potential performance problems 
ideal setup provide su cient hooks various operating systems facilities default processing applications truly need additional control aware consequences relatively easily 
course centralized control certain critical issues ensure fairness 
operating system features discussion point concentrated issues related virtual memory system existing features exploited ciently portably implementing coarse grained address translation 
section brie discuss operating system features useful implementation low level system extensions 
particular discuss need cient exible exception handling issues selection virtual memory page sizes extended page protection facilities 
brie discuss raw allows ered access block devices applications special characteristics 
exception handling term exception kind fault signal occurs program execution 
exceptions may classi ed types asynchronous synchronous 
asynchronous exceptions may generated due external events application control example user types ctrl interactive programs preset alarm goes hand synchronous exceptions triggered events directly related execution program example divide zero operation performed 
historically exception handling permit graceful handling serious error conditions encountered application execution 
example interactive application may choose handle user interrupts releasing resources terminating cleanly useful error code 
similarly oating point exception typically generated divide zero operation handled helpful error message printed execution terminated 
usual response exception termination execution operating system implementations consider ciency important factor exception handling 
current day usage exception handling advanced signi cantly unix system generate signal user types ctrl 
simple graceful error handling usage model 
obvious example pointer swizzling page fault time technique uses virtual memory access protection violations avoid software overhead checking pointer formats 
examples applications include garbage collectors distributed shared virtual memory systems compressed virtual memory 
wide variety non traditional uses exceptions increasingly necessary operating system implementors recognize need cient exception handling improve implementations appropriately 
experimental design measured performance access protection violation handling solaris linux clock cycle timer 
speci cally measured time elapsed point signal raised application attempts access protected page point user level protection fault handler gains control execution 
approximates overhead imposed operating system servicing exception transferring control user speci ed handler 
purpose microbenchmark set follows 
attempt access single page access protected generating appropriate signal sigsegv handled user level signal handler 
handler simply increments counter originally initialized zero returns changing protections page 
faulting instruction restarted immediately generates signal page access protected sequence events occurs 
eventually counter reaches prede ned maximum microbenchmark fault handler faulted page returns allowing application successfully complete original access generating signals 
measure total time entire sequence starting rst attempt access protected page page unprotected divide total number faults obtain time taken operating system servicing single fault 
note approach really gives lower bound operating system cost handling single access protection violation loop nature microbenchmark 
large number faults generated quick succession iterations loop see ects caching particular relevant kernel data structures fault handling code may cached second level cache rst fault 
application generating protection faults heavily bene caching consequently may incur higher overhead fault 
experimental results ran microbenchmark linux solaris systems identical underlying hardware mhz intel pentium pro processor mb ram systems 
table shows actual cost operating system 
results clearly show exception handling linux times faster solaris 
sunos solaris implement vm architecture gms substantially di erent bsd memory management architecture 
particular modular requires operating system cost cycles linux solaris table cost handling access protection violation function calls indirected function table lookup 
obviously impact performance chen cbl shown layering components adds overhead fault handling 
empirical results obtained indicate slowdown factor de nitely larger accounted extra penalty 
discussion researchers recognized problem slow exception handling various operating systems 
thekkath levy tl contend easier improve performance handling synchronous exceptions asynchronous exceptions information needed servicing available user space process 
describe hardware architectural changes software approaches kernel changes purpose encouraging results software approach 
implemented modifying dec ultrix kernel approach requires microseconds handling null exception compared microseconds taken unmodi ed kernel 
great example fast exception handling mechanism subsequently microkernel lie lie full cost kernel call microkernel cycles lie microsecond modern mhz processor 
extremely impressive result best performance linux order magnitude slower 
anderson discussed interaction hardware architecture operating systems including virtual memory fault handling 
virtual memory page size sub page protections pointer swizzling page fault time generally bene ts smaller page size reduces amount swizzling required page faults 
addition address space consumption rate reduced fewer pointers swizzled page loaded disk 
general virtual memory page size plays important role implementation performance systems exploit virtual memory features implement new abstractions 
unfortunately opposing forces usually page size needs selected hp 
hand larger sizes preferable perspective reducing hardware costs page tables translation lookaside bu ers tlbs smaller improving ciency data transfer memory secondary storage larger units transfer reduce ect latency 
hand smaller sizes provide additional exibility terms allocation memory protection reducing internal fragmentation 
possible approach resolving page size selection con ict choose size provides balance opposing forces considering pointer swizzling page fault time systems support operations mainly page protections signal handling sub page granularity systems bene smaller page sizes 
approach minimal impact normal operation virtual memory system page sizes selected relevant trade time works coarse grained address translation sub page protections parts reserved pages swizzled ectively providing bene pages smaller 
believe little hardware support operating systems able provide sub page protection facilities relatively easily 
fact arm processor provides support sw facilitating easy implementation sub page protections apple newton 
prototype risc machine incorporated support protections sub page granularity cm 
thekkath levy tl shown little kernel support emulate sub page protections simple manner higher level abstraction 
support raw computer system disk usually slower compared performance components notably cpu 
typical disk latencies order milliseconds orders magnitude slower main memory speeds 
advisable minimize number disk operations avoid major impact general performance 
unix systems implement providing le system caching known bu er cache 
cache basic idea store accessed disk blocks fast storage speculating data read soon 
operating systems implement readahead mechanism prefetch additional data cache hope expensive disk seeks avoided prefetched data accessed soon 
traditional unix implementations typically xed size independent area memory specially designated bu er cache 
modern systems integrate bu er cache virtual memory system dynamically control fraction memory assigned component 
read issued kernel rst maps speci ed part le protected address space faults data copies user speci ed bu er 
procedure handling write follows similar model performing extra copy user space kernel space 
specialized application understood possibly unusual behavior extra copy bu er cache may adversely ect performance time space 
example database style applications transfer large amounts data disk bene bypassing bu er cache usually implement caching mechanisms 
case texas data fetched disk subsequently cached virtual memory 
bu er cache undesirable situation compete virtual memory system real memory ectively reducing memory available application 
unix systems provide facility called raw direct allows ered access block device avoiding extra copy data faulted directly user space 
interface normal read write system calls requests appropriate character device corresponding block device kernel internally handles requests di erently 
alternative eliminating extra copy mmap standard le system read write interface attractive reasons mmap portable presents semantics di erent read write system calls 
operating system implementations open extremely useful application con gurable disk characteristics 
particular applications able perform normal bu ered direct arbitrary les normal le system speci le access characteristics semantics 
appears various operating system implementations moving direction 
example irix silicon graphics supports special ag direct speci ed opening le open system call notify operating system direct reading writing le 
similarly new solaris release supports new library routine dynamically switch access characteristics speci ed le 
alternatively operating system allows le system mounted les le system direct 
chapter described various aspects operating system interactions relevant implementing low level system extensions distributed shared virtual memory pointer swizzling page fault time 
system relies heavily virtual memory hardware discussion primarily focused interaction virtual memory system brie discussed useful features operating system 
sbrk mmap virtual memory primitives commonly allocation di er signi cantly terms features interface performance 
exibility respect additional control swap space allocation reclamation provide major bene sbrk 
believe mmap basic primitive implementing high level allocation policies 
discussed issues regarding external memory management control virtual memory paging related pointer swizzling page fault time 
context described various levels interactions virtual memory system possible depending capability underlying operating system kernel 
emphasized pointer swizzling page fault time exploit additional support virtual memory system normal correct operation general 
virtual memory system interactions brie described related issues operating system development 
important support example solaris name dev dsk represents block device corresponding raw device named dev 
gavin personal communication july 
cient exception handling 
measured exception handling costs linux solaris shown slower factor potential improved 
believe fast microkernel implementations winners category 
important issue support virtual memory protections extensions allow protections sub page granularity 
useful various systems rely virtual memory facilities bene smaller page sizes 
case providing additional control programmer respect le ability le system caching 
operating system implementations open re ective allowing responsible user level applications control key features suit needs 
words operating systems provide basic building blocks assembled user level facilities implement useful extensible systems ciently 
bene cial operating systems separation concerns allowing systems approach solve problems right level abstraction getting distracted tedious irrelevant implementation issues 
evidence researchers similar goals improving operating system implementations klm 
chapter previous chapters described design implementation texas portable persistent storage mechanism high performance coarse grained address translation pointer swizzling page fault time 
texas actual system commercial non commercial systems intend research testbed exploring various avenues address translation advanced storage management issues 
chapter describe research directions concentrating mainly storage management brie discussing related extensions texas 
storage management current design texas exible terms implementation underlying storage management 
implemented abstraction layer implement di erent kinds storage mechanisms disturbing functionality 
current implementation storage mechanism designed persistent store saved regular le le system raw disk partition 
possible implement log structured storage system simpli es checkpointing recovery mechanism improving exibility performance 
interested studying prefetching compressed memory storage issues important storage management 
prefetching viewed way performance reducing time spent waiting complete 
contrast compressed memory storage way avoid attempting keep data memory 
discuss adaptive techniques prefetching compressed memory storage 
log structured storage system described chapter texas currently implements simple checkpointing recovery mechanism 
replace simple logging mechanism exible log structured storage system supports additional functionality 
log structured storage system lss essentially lower levels log structured le system ro 
storage system typically manages single raw disk partition normal le 
choose implement le system complexity needed simple persistent storage management 
storage functionality implemented lowest layer upper layers may build additional facilities les directories access permissions choose 
log structured storage system entire disk le managed log log acts nal repository data pages persistent store 
words separate entities corresponding persistent store log checkpointing 
de nition blocks pages log structured store single xed home location disk 
logical blocks system allowed migrate simply writing new version block di erent location managed disk current version block written log 
blocks xed location changes le committed updating index structures point new data 
easy see log structured storage system maintain persistent data support necessary checkpointing 
fact multiple versions data exist disk save multiple checkpoints support rollback older checkpoints 
write strategy log structured systems writes clustered related data stored consecutively disk improving read latency bandwidth access 
original texas describes details log structured storage system including description data structures 
adaptive prefetching modern computer memory systems hierarchical composed levels memory hp 
lower levels magnetic disks tapes inexpensive large slow higher levels ram caches expensive small fast 
memory systems hierarchical growing downward persistent object stores increasingly important decisions data fast memory time 
commonly policy current systems demand prefetching combined approximation lru replacement 
demand prefetches occur conjunction demand fetches real page faults 
choices selecting prefetching policy 
policy pages prefetch pages prefetch long prefetched pages retained memory immediately referenced program 
common prefetching rule block lookahead page block faulted consecutive page prefetched 
example page number faulted page number brought memory 
block lookahead attractive policy easy implement consecutively numbered pages usually consecutive disk brought memory additional seek 
prefetch fool rule believe horspool huberman prefetching hh interesting reasons intended 
experimented variation block lookahead designed easy simulate ciently 
interpretation data inadvertently simulated adaptive prefetching policy interesting attempting approximate 
horspool huberman modi ed block lookahead preserve inclusion property property allows simulation memory sizes pass trace 
inclusion known property guarantees pages memory size subset pages memory larger size misses memory subset misses smaller size 
cient simulation single queue pages maintained trace analyzed memory arbitrarily large 
queue shows recency ordering pages touched independent memory size 
lru inclusion means moving page head queue interpreted hit particular memory size larger sizes smaller memories 
horspool huberman innovation devise prefetching scheme similar conventional block lookahead preserving inclusion property 
policy reorders pages queue ways independent particular memory size 
reordering interpreted prefetches sizes memory reordering memory pages larger sizes memory 
particular ordering rule pages touched brought head queue lru queue lookahead page memory brought head queue nearer head queue page touched 
details scheme hh 
horspool huberman surprised nd algorithm outperformed conventional block lookahead 
believe preserving demand prefetch policy horspool huberman inadvertently simulated adaptive prefetching policy approximates call fool rule page prefetched referenced application prefetched time 
unfortunately details horspool huberman algorithms introduce unexpected anomalous properties 
particular policies properly timescale relative events occurring timescale matter sizes memory adversely ect replacement decisions memories di erent sizes 
describe slight changes algorithms restore timescale relativity better behaved 
prefetch horspool huberman policy decides prefetch previous observations behavior 
equally interesting prefetch 
possibility dynamically reorganize small pages larger units disk transfer 
program accesses di erent pages ordering accesses recorded 
pages eventually paged written disk new order re ects access ordering 
access orderings correlated past orderings enables convenient form prefetching 
mid baer sager bs simulated prefetching policy relied reorganizing pages disk order initial accesses program 
unfortunately results disappointing preliminary measures locality indicated previous page fault orderings subsequent access patterns policy simulated unsuccessful improve performance 
believe negative result due subtle interacting aws design experiment data quite encouraging properly interpreted 
example baer sager reorganization policy lru queue ordering pages determine order pages written 
problem policy lru ordering order pages question page fault ordering originally brought pages 
grouping principles probably strongly correlated identical 
believe research analysis area necessary yield interesting results 
compressed memory storage current trends hardware con gurations indicate huge gap performance orders magnitude main memory latencies disk latencies 
cost ective approach bridge gap introduce new level memory hierarchy 
compressed memory storage uses part main memory cache compressed pages wil wlm wil dou divides main memory partitions uncompressed pages compressed pages 
compressed memory storage improve system performance paging compression cache may faster paging disk 
performance scheme depends relative costs processor cycles disk transfers ciency compression algorithm 
consider fact currently reasonable expect machines execute instructions second average disks millisecond latencies 
means time takes perform single disk operation processor execute instructions 
long instructions compression saves disk seek worthwhile compression cache 
disk speeds lag processor speeds compressed memory storage increasingly attractive 
novel compression techniques avoid common trap adapting text oriented compression algorithm compress inmemory data 
aim domain speci compression algorithms heap data take advantage knowledge data representation memory 
memory data typically show di erent kinds regularities character data les 
due demands computer architectures favor word sized elds aligned word double word boundaries 
words basic unit matching re ned discriminating high order bits stable low order bits di er 
quite ective integers pointers integers small similar small integers pointers similar nearby pointers 
tailor techniques compress oating point data usually show regularities exponent high order bits mantissa 
discussion preliminary experiments shown compression factor time cost third millisecond compress kb page mhz pentium pro processor running linux 
re ned experiments wider selection test programs required believe early results promising 
expect reduce time cost factor ne tuning basic implementation 
furthermore virtual memory trace gathering tool extended gather compressibility information simulators modi ed evaluate adaptive compressed paging techniques information traces 
noted compression memory management schemes primary goal increase available disk storage increase system throughput reducing average memory latency increasing ective performance 
system give bene ts similar le compression schemes cg 
research currently underway detailed results upcoming 
advanced issues chapter brie mentioned advanced issues scope dissertation 
speci cally discussed issues related distribution concurrency control fault tolerance schema evolution security 
emphasized issues fundamentally con ict basic pointer swizzling page fault time technique implementation orthogonal persistence texas 
fact resolved speci cally context texas related systems 
particular interest issue distribution concurrency control 
current implementation texas support aware system mc texas bs implemented fujitsu ap multicomputer precursor developing architecture distributed persistence 
blackburn stanton report encouraging results regarding scalability texas modulo couple situations related false sharing implementation meta data relatively easy resolve 
persistent storage popular data security increasingly important persistent data protected unauthorized access 
previous done area various solutions possible protection domains opal areas objectstore 
chapter coarse grained address translation techniques disregarded past viable alternative traditional ne grained address translation techniques building cient persistence mechanisms general purpose languages 
goal dissertation set record straight regarding performance exibility coarse grained translation techniques potential high performance address translation mechanisms 
part research implemented texas high performance persistence storage system uses pointer swizzling page fault time coarse grained address translation technique 
foregoing chapters described various aspects building systems provide cient orthogonal persistence general purpose languages 
particular discussed pros cons di erent address translation approaches new classi cation scheme persistent systems granularity issues introduced concept run time type description rttd accessing implementation level type information run time discussed lessons learned interacting operating systems 
provided research directions storage management persistent object stores including log structured storage strategy compressed memory storage 
address translation shown coarse grained approach address translation necessarily constrain performance requirements applications incorporate orthogonal persistence 
exploiting virtual memory facilities modern operating systems existing virtual memory hardware modern computers implemented coarse grained address translation scheme runs stock hardware minimum overheads usual case 
rely locality usually exhibited applications amortize cost translating entire page repeated accesses page incur overhead 
empirically validated competitive argument coarse grained swizzling techniques controlled measurements existing benchmarks 
speci cally wehave demonstrated direct cost approach iszero normal cpu bound operations manipulate memory data small percent bound operations data loaded memory stable storage 
general address translation costs smaller corresponding costs incurred loading data 
expect overheads decrease cpu speeds typically improve faster speeds 
direct costs pointer swizzling page fault time minimal indirect costs related unexpected interactions virtual memory system leading unnecessary page outs swizzled pages 
directly related pointer swizzling costs may ect total performance application extra paging accounted measurements 
fortunately costs bounded incurred swizzled page 
ways avoid problem altogether operating system provides additional virtual memory management support external pagers mach 
granularity choices persistence identi ed set design issues believe fundamental implementation persistent system 
choice granularity design issue forms classi cation scheme persistence implementation 
design issues identi ed granularities address translation address mapping data fetching data caching checkpointing 
believe combination granularity choices design issues provides better classi cation mechanism existing ad hoc taxonomies 
basic unit texas virtual memory page 
pointer swizzling page fault time page wise translation scheme implementation relies heavily virtual memory facilities underlying operating system 
necessary possible temporarily change granularity ner level example implement pointer wise address translation situations pure coarse grained approach provide best bene run time type description important contribution dissertation notion run time type description rttd making implementation level type information accessible run time 
useful detailed information layouts data objects memory run time variety applications 
example addition applicability address translation persistence detailed run time object layout information useful applications garbage collection advanced tracing pro ling rttd mechanism designed generate layout information compile time application run time 
shown rttd mechanism implemented portably compiler generated debugging information basis extracting necessary information rttd 
chose debugging information seemingly obvious approach special purpose preprocessors reasons portability compatibility approach portable multiple compilers operating systems compatible di erent source languages debugging information format usually independent factors 
case study implementation gnu debugger fully operational currently texas real time garbage collector 
operating system interactions course implementing porting pointer swizzling page fault time texas persistent store di erent operating systems wehave learned interesting lessons interacting di erent operating systems subtle di erences related features 
interaction concentrated areas virtual memory management protection fault handling important features relevant implementation texas 
discussed aspects interactions virtual memory systems 
comparison virtual memory allocation primitives performance characteristics linux solaris described study heuristics swap space allocation di erent operating systems discussed advanced facilities external memory management additional control paging 
protection fault handling signi cant room performance improvements terms operating system support cient exception handling 
part analysis suggestions believe important improving operating system implementations consequently interactions systems texas 
general argue implementations open re ective provide basic building blocks assembled higher level user facilities tailor system speci needs 
believe microkernel approaches additional layering functionality top provide performance characteristics desirable general usage 
storage management issues discussion dissertation concentrated implementation highperformance address translation mechanism 
issues related storage management persistent object stores important implementing persistence 
current implementation texas incorporated simple undo redo write ahead logging strategy provide simple checkpointing crash recovery support 
discussed alternative approaches ranging simple page di ng sub page logging techniques advanced log structured storage management entire persistent store 
described issues related storage management speci cally adaptive prefetching compressed memory storage 
designed improve performance attempts minimize amount necessary 
compressed memory storage increasing ective memory size part main memory store compressed pages 
preliminary results shown promise research currently underway 
final words orthogonal persistence increasingly important applications get sophisticated manipulate complex heap allocated data structures 
dissertation shown problem addressing large amounts data standard hardware operating systems resolved ectively coarse grained address translation techniques compromising issues performance portability compatibility 
hope enable wider acceptance persistence useful important feature generalpurpose programming languages 
appendix hierarchical type graph chapter section described storage model hierarchical formats type descriptor records rttd implementation 
discussing hierarchical format simpli ed structure type graph ease explanation basic concepts 
actual data structures maintained type descriptor complex contain necessary information fully describe various types run time 
describe full hierarchical graph data structures detail 
recall sample type de nitions chapter describe storage model struct pet short tag char name struct owner char name void short pet pets shows structure full hierarchical type graph representing type de nitions 
compare simpli ed structure shown obvious actual data structures store information types 
application type classi ed simple type basic builtin type short char complex type pointer aggregate type represented unique type descriptor record hierarchical type graph 
type descriptor record object instantiated special rttd type represents speci application type 
rttd type names follow simple convention name parts predetermined pre td su type middle component depends application type 
rttd type instantiated generate type descriptor record maintains information struct class application 
naming convention note boxes labeled represent type various type descriptor records hierarchical type graph 
token boxes labeled type descriptor phrase rttd type distinguish types de ned system types various type descriptor record objects types application represented type descriptor records 
records just auxiliary data structures described 
type descriptor record maintain set information common application types corresponds rst sub components type descriptor record shown gure 
terms implementation accomplished ensuring rttd types inherit single superclass common information 
information includes size application type bits size eld information inheritance hierarchy application type structure elds track information parents application type 
addition pointer types considered complex types system type descriptor record maintains type descriptor record represents pointer type application type represented type descriptor record eld 
example type descriptor record represents type char type descriptor record represents type char turn may type descriptor record represents type char 
addition common information rttd type contains additional information depending requirements application type represented 
example type maintains tag predetermined enumerated values describe speci builtin type represented types contain pointer type descriptor record represents pointed type array type 
contrast type additional elds necessary fully representing aggregate type 
apart name need maintain information eld aggregate type done auxiliary type maintain information name size eld bits type descriptor record represents type eld set eld aggregate type 
note necessary maintain size set eld deriving set size previous eld compiler may insert padding elds comply speci layout alignment requirements language operating system 
summary described details type descriptor record structure various interconnections full hierarchical type graph created type descriptor generator 
obvious addition common set information necessary describing application type rttd type maintain additional information speci cally geared representing particular application type may complex 
wehave brie described structure behavior important rttd types represent type structures builtin type pointers arrays aggregate types common applications 
null size null name pet fields null size null name owner fields size name tag type offset size name name type offset size name name type offset size name type offset size name type offset size name pets type offset null size null tag null size null type null size null type null size null type size null tag size null tag full hierarchical type graph bibliography abc malcolm atkinson peter bailey ken chisholm paul cockshott ron morrison 
approach persistent programming 
computer journal december 
abc malcolm atkinson peter bailey ken chisholm paul cockshott ron morrison 
ps algol language persistent programming 
proceedings th australian national computer conference pages melbourne australia 
abm acc ael anderson arne harry porter bruce schneider 
benchmark 
proceedings international conference extending database technology pages venice italy 
malcolm atkinson ken chisholm paul cockshott 
ps algol algol persistent heap 
acm sigplan notices july 
malcolm atkinson ken chisholm paul cockshott richard marshall 
algorithms persistent heap 
software practice experience march 
andrew appel john ellis kai li 
real time concurrent garbage collection stock multiprocessors 
proceedings sigplan conference programming language design implementation pages atlanta georgia june 
acm press 
andrew appel kai li 
virtual memory primitives user programs 
fourth international conference architectural support programming languages operating systems asplos iv asp pages 
thomas anderson henry levy brian bershad edward lazowska 
interaction architecture operating systems design 
fourth international conference architectural support programming languages operating systems asplos iv asp pages 
am antonio albano ron morrison editors 
fifth international workshop persistent object systems san italy september 
springer verlag 
am malcolm atkinson ron morrison 
orthogonally persistent object systems 
vldb journal 
arg marc rozier michel 
virtual memory management chorus 
proceedings workshop progress distributed operating systems distributed systems management berlin germany april 
springer verlag 
chorus systemes tr cs tr 
asp bak fourth international conference architectural support programming languages operating systems asplos iv santa clara california april 
henry baker jr list processing real time serial computer 
communications acm april 
bak henry baker jr treadmill real time garbage collection motion sickness 
oopsla workshop garbage collection object oriented systems october 
position 
appears acm sigplan notices march 
bc yves jacques cohen editors 
international workshop memory management number lecture notes computer science st malo france september 
springer verlag 
michael burrows charles butler lampson timothy mann 
online data compression log structured file system 
fifth international conference architectural support programming languages operating systems asplos pages boston massachusetts september 
joseph david alan susan 
programming mach 
addison wesley reading massachusetts 
bl thomas ball jim larus 
optimal pro ling tracing programs 
conference record nineteenth annual acm symposium principles programming languages pages 
acm press january 
bs bs bw jean baer gary sager 
dynamic improvement locality virtual memory systems 
ieee transactions software engineering se march 
stephen blackburn robin stanton 
multicomputer object stores multicomputer texas experiment 
scott nettles richard connor editors seventh international workshop persistent object systems cape may new jersey may 
morgan kaufmann 
hans juergen boehm mark weiser 
garbage collection uncooperative environment 
software practice experience september 
car michael carey 
exodus extensible dbms project overview 
stanley zdonik david maier editors readings object oriented databases 
morgan kaufmann 
cat cbl cdn cg cattell 
engineering database benchmark 
jim gray editor benchmark handbook database transaction processing systems pages 
morgan kaufmann 
danny chen ronald barkley paul lee 
insuring improved vm performance fault policies 
proceedings usenix winter technical conference pages berkeley california january 
usenix association 
michael carey david dewitt je rey naughton 
oo benchmark 
proceedings acm sigmod international conference management data pages washington dc june 
acm press 
vincent cate thomas gross 
combining concepts compression caching level file system 
fourth international conference support programming languages operating systems asplos iv asp pages 
cha craig chambers 
design implementation self compiler optimizing compiler object oriented programming language 
phd thesis stanford university march 
je rey chase henry levy edward lazowska baker harvey 
lightweight shared objects bit operating system 
andreas paepcke editor conference object oriented programming systems languages applications oopsla pages vancouver british columbia october 
acm press 
published acm sigplan notices october 
cm george copeland david maier 
making smalltalk database system 
proceedings acm sigmod international conference management data pages boston massachusetts june 
acm press 
acm sigmod record 
cm cs cs albert chang mark mergen 
storage architecture programming 
acm transactions computer systems february 
chew reddy theodore romer abraham silberschatz 
kernel support recoverable persistent virtual memory 
inproceedings rd symposium mach pages santa fe new mexico april 
usenix association 
rick cattell skeen 
object operations benchmark 
acm transactions database systems march 
chew abraham silberschatz 
recoverable persistent virtual memory paradigm 
technical report tr university texas austin austin texas march 
available ftp ftp cs utexas edu pub techreports tr ps den peter denning 
virtual memory 
acm computing surveys september 
det david detlefs 
garbage collection run time typing library 
usenix conference 
dou fred douglis 
compression cache line compression extend physical memory 
proceedings winter usenix conference pages san diego california january 
ede ede gms gr hh alan dearle gail shaw stanley zdonik editors 
implementing persistent object bases principles practice proceedings fourth international workshop persistent object systems martha vineyard massachusetts september 
morgan kaufmann 
daniel 
garbage collection 
cohen bc 
daniel ross 
smart pointers re smart re pointers 
usenix conference pages 
technical report ucsc crl university california santa cruz center computer engineering information sciences june 
robert joseph moran william shannon 
virtual memory architecture sunos 
usenix summer technical conference pages phoenix arizona june 
usenix association 
adele goldberg david robson 
smalltalk language 
addison wesley reading massachusetts 
nigel horspool ronald huberman 
analysis development policies 
journal systems software 
hn antony hosking aria 
copying reachability orthogonal persistence 
oopsla workshop memory management garbage collection october 
hos hp hr antony hosking 
lightweight support fine grained persistence stock hardware 
phd thesis university massachussetts amherst amherst massachussetts february 
john hennessy david patterson 
computer architecture quantitative approach 
addison wesley reading massachusetts 
nd edition 
theo andreas reuter 
principles transaction oriented database recovery 
acm computing surveys december 
il john mark linton 
run time access type information 
usenix conference berkeley california 
usenix association 
joh kae kc jagadish daniel rajeev rastogi avi silberschatz sudarshan 
dali high performance main memory storage manager 
twentieth international conference large data bases santiago chile 
mark johnstone 
non moving memory allocation real time garbage collection 
phd thesis university austin austin 
texas december 
ted 
virtual memory narrow machine object oriented language 
conference object oriented programming systems languages applications oopsla proceedings oop 
george copeland 
object identity 
conference object oriented programming systems languages applications oopsla proceedings oop pages 
gregor kiczales jim des rivieres daniel bobrow 
art metaobject protocol 
mit press cambridge massachusetts 
edwards sumner 
level storage system 
siewiorek bell newell editors computer structures principles examples pages 
mcgraw hill new york ny 

originally appeared ire transactions ec april kk ted glenn krasner 
loom large object oriented memory smalltalk systems 
glenn krasner editor smalltalk bits history words advice pages 
addison wesley 
kk klm lab lh li kemper donald kossmann 
adaptable pointer swizzling strategies object bases design realization quantitative analysis 
vldb journal july 
gregor kiczales john lamping chris maeda david keppel dylan mc 
need customizable operating systems 
proceedings fourth workshop workstation operating systems iv october 
barbara liskov russell atkinson toby bloom eliot moss craig schaffert robert er alan snyder 
clu manual 
number lecture notes computer science 
springer verlag berlin germany 
kai li paul hudak 
memory coherence shared virtual memory systems 
acm transactions computer systems november 
kai li 
shared virtual memory loosely coupled processors 
phd thesis yale university new haven connecticut 
lie jochen liedtke 
improved ipc kernel design 
proceedings fourteenth symposium operating systems principles pages asheville north carolina december 
acm press 
published operating systems review 
lie jochen liedtke 
microkernel construction 
proceedings fifteenth symposium operating systems principles pages copper mountain resort colorado december 
acm press 
lie jochen liedtke 
real microkernels 
communications acm september 
lip stanley lippman 
primer 
addison wesley reading massachusetts 
nd edition 
mbc charles lamb gordon landis jack orenstein dan weinreb 
object store database system 
communications acm october 
ron 
morrison alfred brown ray richard connor alan dearle malcolm atkinson 
napier type system 
rosenberg koch editors third international workshop persistent object systems pages newcastle australia september 
springer verlag 
mg jose alves marques paulo 
extending operating system support object oriented environment 
conference object oriented programming systems languages applications oopsla proceedings oop pages 
mos ms nel mattson traiger 
evaluation techniques storage hierarchies 
ibm systems journal 
eliot moss 
working persistent objects swizzle swizzle 
ieee transactions software engineering august 
available technical report university massachusetts amherst massachusetts may 
mark marvin solomon 
simulation pointer swizzling techniques 
proceedings international conference database engineering pages taipei taiwan march 
ieee 
greg nelson editor 
systems programming modula 
prentice hall englewood cli new jersey 
vivek narasayya tze sing eugene ng dylan mcnamee henry levy 
reducing virtual memory overhead swizzling 
proceedings workshop object orientation operating systems seattle washington october 
ieee press 
oop oop conference object oriented programming systems languages applications oopsla proceedings 
acm press october 
published acm sigplan notices november 
conference object oriented programming systems languages applications oopsla proceedings new orleans louisiana 
acm press 
rc joel richardson michael carey 
persistence language issues implementation 
software practice experience december 
rk brian randell 
dynamic storage allocation systems 
communications acm may 
ro mendel rosenblum john ousterhout 
design implementation log structured file system 
proceedings thirteenth symposium operating systems principles pages paci grove california october 
acm press 
published operating systems review 
rus russo 
object oriented operating system 
phd thesis university illinois urbana champaign champaign urbana illinois january 
scd daniel schuh michael carey david dewitt 
persistence revisited implementation experiences 
dearle 
suzuki masaru kitsuregawa takagi 
cient pointer swizzling method navigation intensive applications 
antonio albano ron morrison editors sixth international workshop persistent object systems pages france september 
springer verlag 
vivek singhal kakkad paul wilson 
texas cient portable persistent store 
albano morrison am pages 
sl bjarne stroustrup dmitry 
run time type identi cation revised 
usenix conference 
sta james william stamos 
large object oriented virtual memory grouping strategies measurements performance 
technical report scg xerox palo alto research center palo alto california may 
str bjarne stroustrup 
evolution 
usenix workshop pages 
usenix association 
sw walter smith robert 
model address oriented software hardware 
proceedings th hawaii international conference system sciences 
ieee january 
sz eugene shekita michael 
cricket mapped persistent object store 
dearle pages 
tl tl thekkath henry levy 
limits low latency high speed network 
acm transactions computer systems may 
thekkath henry levy 
hardware software support cient exception handling 
sixth international conference architectural support programming languages operating systems asplos vi pages san jose california october 
vivek narasayya henry levy 
evaluation oo system application benchmark 
oopsla workshop object database behavior benchmarks performance austin texas october 
usenix association 
usenix conference portland oregon august 

unix internals new frontiers 
prentice hall upper saddle river new jersey 
vd francis vaughan alan dearle 
supporting large persistent stores conventional hardware 
albano morrison am 
thorsten von eicken anindya basu vineet 
low latency communication atm networks active messages 
ieee micro february 
wc iso wg ansi committee 
working draft proposed international standard information systems programming language december 
document numbers wg iso ansi 
current public draft available www cygnus com misc wp 
wd wd whi seth white david dewitt :10.1.1.143.3812
study alternative object faulting pointer swizzling strategies 
th international conference large data bases vancouver british columbia october 
morgan kaufmann 
seth white david dewitt 
high performance mapped object store 
proceedings acm sigmod international conference management data pages minneapolis minnesota may 
acm press 
seth white 
pointer swizzling techniques object oriented database systems 
phd thesis university wisconsin madison madison 
wil paul wilson 
issues strategies heap management memory hierarchies 
oopsla ecoop workshop garbage collection object oriented systems october 
appears acm sigplan notices march 
wil wil wil wj wjnb paul wilson 
operating system support small objects 
international workshop object orientation operating systems pages palo alto california october 
ieee press 
paul wilson 
uniprocessor garbage collection techniques 
cohen bc pages 
paul wilson 
garbage collection 
acm computing surveys 
expanded version wil 
draft available ftp ftp cs utexas edu pub garbage ps 
revision appear 
paul wilson mark johnstone 
truly real time non copying garbage collection 
oopsla workshop memory management garbage collection december 
available ftp ftp cs utexas edu pub garbage gc 
paul wilson mark johnstone michael neely david boles 
dynamic storage allocation survey critical review 
international workshop memory management scotland uk 
springer verlag lncs 
paul wilson scott kaplan 
compressed paging 
preparation 
paul wilson scott kaplan 
current research compressed virtual memory 
preparation 
paul wilson scott kaplan kakkad 
virtual memory tracing user level access protections 
preparation 
wlm paul wilson kakkad mukherjee 
anomalies adaptation analysis development policies 
journal systems software november 
paul wilson michael lam thomas moher 
ective static graph reorganization improve locality garbage collected systems 
proceedings sigplan conference programming language design implementation pages toronto ontario june 
acm press 
published acm sigplan notices june 
wm paul wilson thomas moher 
design opportunistic garbage collector 
conference object oriented programming systems languages applications oopsla proceedings oop pages 
williams mario wolczko trevor hopkins 
dynamic grouping object oriented virtual memory hierarchy 
european conference object oriented programming pages paris france june 
springer verlag 
michael young 
exporting user interface memory management communication oriented operating system 
phd thesis carnegie mellon university pittsburgh pennsylvania november 
available technical report cmu cs 
vita vinod kakkad born india june son kakkad vinod kakkad 
completing rajkumar college entered university bombay bombay india 
received degree bachelor engineering university bombay july 
years employed lecturer institute technology new bombay software engineer overseas software limited bombay 
august entered graduate school university austin 
received degree master science computer sciences may 
permanent address austin texas dissertation typeset atex author 
latex extension latex 
latex collection macros tex tex trademark american mathematical society 
macros formatting dissertation written dinesh das department computer sciences university austin 

