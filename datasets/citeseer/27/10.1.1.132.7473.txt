proceedings neural information processing systems nips monaural speech separation hu wang biophysics program department computer information ohio state university science center cognitive science columbus oh ohio state university columbus oh hu osu edu cis ohio state edu monaural speech separation studied previous systems incorporate auditory scene analysis principles 
major problem systems inability deal speech highfrequency range 
psychoacoustic evidence suggests different perceptual mechanisms involved handling resolved unresolved harmonics 
motivated propose model monaural separation deals low frequency highfrequency signals differently 
resolved harmonics model generates segments temporal continuity cross channel correlation groups periodicity 
unresolved harmonics model generates segments amplitude modulation am addition temporal continuity groups am repetition rates derived sinusoidal modeling 
underlying separation process pitch contour obtained psychoacoustic constraints 
model systematically evaluated yields substantially better performance previous systems especially high frequency range 
natural environment speech usually occurs simultaneously acoustic interference 
effective system attenuating acoustic interference greatly facilitate applications including automatic speech recognition asr speaker identification 
blind source separation independent component analysis sensor arrays spatial filtering require multiple sensors 
situations telecommunication audio retrieval monaural microphone solution required intrinsic properties speech interference considered 
various algorithms proposed monaural speech enhancement 
methods assume certain properties interference difficulty dealing general acoustic interference 
monaural separation studied decomposition statistical learning limited evaluation 
speech enhancement remains challenge auditory system shows remarkable capacity monaural speech separation 
bregman auditory system separates acoustic signal streams corresponding different sources auditory scene analysis asa principles 
research asa inspired considerable build computational auditory scene analysis casa systems sound separation 
systems generally approach speech separation main stages segmentation analysis grouping synthesis 
segmentation acoustic input decomposed sensory segments originate single source 
grouping segments come source grouped periodicity 
casa model wang brown segments formed basis similarity adjacent filter responses cross channel correlation temporal continuity grouping segments performed global pitch extracted time frame 
situations model able remove intrusions recover low frequency khz energy target speech 
model handle high frequency khz signals loses target speech high frequency range 
fact inability deal speech high frequency range common problem casa systems 
study monaural speech separation particular emphasis high frequency problem casa 
voiced speech note auditory system resolve harmonics low frequency range 
suggested different perceptual mechanisms handle resolved unresolved harmonics 
consequently model employs different methods segregate resolved unresolved harmonics target speech 
specifically model generates segments resolved harmonics temporal continuity cross channel correlation segments grouped common periodicity 
unresolved harmonics known corresponding filter responses strongly amplitude modulated response envelopes fluctuate fundamental frequency target speech 
model generates segments unresolved harmonics common am addition temporal continuity 
segments grouped am repetition rates 
calculate am repetition rates sinusoidal modeling guided target pitch estimated characteristics natural speech 
section describes system 
section systematic results comparison wang brown system 
section concludes 
model description model multistage system shown fig 

description stage 
initial processing acoustic input analyzed standard cochlear filtering model bank gammatone filters subsequent hair cell transduction 
peripheral processing done time frames ms long ms overlap consecutive frames 
result input signal decomposed group units 
unit contains response certain channel certain frame 
envelope response obtained lowpass filter mixture peripheral mid level processing initial segregation pitch tracking unit labeling final segregation resynthesis 
schematic diagram proposed multistage system 
segregated speech khz kaiser window ms mid level processing performed computing correlogram autocorrelation function individual responses envelopes 
autocorrelation functions reveal response periodicities am repetition rates 
global pitch obtained summary correlogram 
clean speech autocorrelations generally peaks consistent pitch summation shows dominant peak corresponding pitch period 
acoustic interference global pitch may accurate description target pitch reasonably close 
harmonic extends period time frequency changes smoothly target speech activates contiguous units 
instance temporal continuity principle 
addition adjacent channels overlap resolved harmonic usually activates adjacent channels leads high correlations 
initial segregation model forms segments merging units temporal continuity cross channel correlation 
segments grouped foreground stream background stream comparing periodicities unit responses global pitch 
similar process described 
fig 
fig 
illustrate segments foreground stream 
input mixture voiced utterance cocktail party noise see sect 

intrusion strongly structured segments correspond target speech 
addition segments low frequency range 
initial foreground stream successfully groups major segments 
pitch tracking presence acoustic interference global pitch estimated mid level processing generally accurate description target pitch 
obtain accurate pitch information target pitch estimated foreground stream 
frame autocorrelation functions units foreground stream 
pitch period lag corresponding maximum summation plausible pitch range ms ms 
employ constraints check reliability 
accurate pitch period frame consistent periodicity units frame foreground stream 
frame represent estimated pitch period autocorrelation function uij unit channel uij agrees frequency hz time sec time sec 
results initial segregation speech cocktail party mixture 
segments formed 
segment corresponds contiguous black region 
foreground stream 
threshold lag corresponding maximum ms ms 
considered reliable half units foreground stream frame agree 
second pitch periods natural speech vary smoothly time 
stipulate difference reliable pitch periods consecutive frames smaller pitch period justified pitch statistics 
unreliable pitch periods replaced new values extrapolated reliable pitch points temporal continuity 
example suppose consecutive frames reliable 
channels corresponding units agreeing selected 
obtained summation autocorrelations units frame selected channels 
re estimated pitch verified second constraint 
details see 
fig 
illustrates estimated pitch periods speech cocktail party mixture match pitch periods obtained clean speech 
unit labeling estimated pitch periods provides criterion label units target speech dominates unit responses 
criterion compares estimated pitch period periodicity unit response 
referred periodicity criterion 
works resolved harmonics label units segments generated initial segregation 
periodicity criterion suitable units responding multiple harmonics unit responses amplitude modulated 
shown fig 
filter response strongly amplitude modulated fig 
target pitch corresponds local maximum indicated vertical line autocorrelation global maximum fig 

observe filter responding multiple harmonics harmonic source response envelope fluctuates rate 
propose new criterion labeling units corresponding unresolved harmonics comparing am repetition rates estimated pitch 
criterion referred am criterion 
obtain am repetition rate entire response gammatone filter half wave rectified band pass filtered remove dc component possible pitch period ms time sec 
estimated target pitch speech cocktail party mixture marked 
solid line indicates pitch contour obtained clean speech 
time ms lag ms 
am effects 
response filter center frequency khz 
corresponding autocorrelation 
vertical line marks position corresponding pitch period target speech 
harmonics component 
rectified filtered signal normalized envelope remove intensity fluctuations original signal envelope obtained hilbert transform 
pitch natural speech change noticeably single frame model corresponding normalized signal unit single sinusoid obtain am repetition rate 
specifically ij ij argmin jt sin hz hz square error measure 
normalized filter response fs sampling frequency spans frame ms progressing period frame 
equation fij gives am repetition rate unit uij 
note discrete case single sinusoid sufficiently high frequency match samples perfectly 
interested finding frequency plausible pitch range 
solution reduce degenerate case 
appropriately chosen initial values optimization problem solved effectively iterative gradient descent see 
am criterion label units belong segments generated initial segregation segments discussed earlier tend unresolved harmonics 
specifically unit uij labeled target speech final square error half total energy corresponding signal am repetition rate close estimated target pitch 
ij psychoacoustic evidence suggests separate sounds overlapping spectra requires difference 
accordingly choose 
final segregation resynthesis adjacent channels responding unresolved harmonics responses may quite different exhibit similar am patterns response envelopes highly correlated 
units labeled target speech segments generated cross channel envelope correlation addition temporal continuity 
spectra target speech intrusion overlap result segments generated initial segregation contain units target speech dominates intrusion dominates 
unit labels generated stage divide segments foreground stream sf units segment label 
streams adjusted follows 
segments speech usually ms long segments target label retained sf shorter ms second segments intrusion label added background stream sb shorter ms remaining segments removed sf undecided 
units grouped streams temporal spectral continuity 
sb expands iteratively include undecided segments neighborhood 
remaining undecided segments added back sf 
individual units belong stream grouped sf iteratively units labeled target speech neighborhood sf 
resulting sf final segregated stream target speech 
fig 
shows new segments generated process speech mixture 
fig 
illustrates segregated stream mixture 
fig 
shows units target speech stronger intrusion 
foreground stream generated algorithm contains units target speech stronger 
addition small number units intrusion stronger incorrectly grouped 
speech waveform resynthesized final foreground stream 
foreground stream works binary mask 
retain acoustic energy mixture corresponds reject mixture energy corresponding details see 
evaluation comparison model evaluated corpus mixtures composed voiced utterances mixed intrusions collected cooke 
intrusions considerable variety 
specifically khz pure tone white noise noise bursts cocktail party noise rock music siren telephone female speech male speech female speech 
decomposition input signal units suggest ideal binary mask ground truth target speech 
ideal binary mask constructed follows unit assigned target energy corresponding unit greater intrusion energy zero 
theoretically speaking ideal binary mask gives performance ceiling binary masks 
illustrates ideal mask speech cocktail party mixture 
ideal masks suit situations target need segregated target changes dynamically 
ideal masks supported auditory masking phenomenon critical band weaker signal masked stronger 
addition ideal mask gives excellent resynthesis variety sounds similar prior mask asr study yields excellent recognition performance 
speech waveform resynthesized final foreground stream evaluation denoted 
speech waveform resynthesized ideal binary mask denoted 
furthermore denote signal missing signal missing 
relative energy loss rel relative noise residue rnr calculated follows frequency hz el nr time sec 
time sec time sec 
results final segregation speech cocktail party mixture 
new segments formed final segregation 
final foreground stream 
units target speech stronger intrusion 
table rel rnr proposed wang brown intrusion model model rel rnr rel rnr average results model shown table 
value represents average intrusion voiced utterances 
average intrusions shown table 
average system retains target speech energy relative residual noise kept 
comparison table shows results wang brown model performance representative current casa systems 
shown table model reduces rel significantly 
addition rel rnr balanced system 
compare waveforms directly measure form signal noise ratio snr decibels resynthesized signal ideal binary mask ground truth snr log 
snr intrusion averaged target utterances shown fig 
results wang brown system snr original mixtures 
model achieves average snr gain db db improvement wang brown model 
discussion main feature model lies different mechanisms deal resolved unresolved harmonics 
result model able recover target speech reduce noise interference high frequency range harmonics target speech unresolved 
proposed system considers pitch contour target source 
possible track pitch contour intrusion harmonic structure 
pitch contours label unit accurately comparing periodicity consistent 
method expected lead better performance speaker situation 
indicated fig 
performance gain system intrusions relatively limited 
model limited separation voiced speech 
view unvoiced speech poses biggest challenge monaural speech separation 
grouping cues onset offset timbre demonstrated effective human asa may play role grouping unvoiced speech 
addition consider acoustic phonetic characteristics individual unvoiced consonants 
plan investigate issues study 
snr db intrusion type 
snr results segregated speech 
white bars show results proposed model gray bars wang brown system black bars mixtures 
acknowledgments brown wu helpful comments 
preliminary versions ieee ieee icassp 
research supported part nsf iis afosr 
bregman auditory scene analysis cambridge ma mit press 
comparing fundamental frequencies resolved unresolved harmonics evidence pitch mechanisms acoust 
soc 
am vol 
pp 

monaural separation independent acoustical components proc 
ieee symp 
circuit systems 
cooke modeling auditory processing organization cambridge cambridge university press 
cooke green robust automatic speech recognition missing unreliable acoustic data speech comm vol 
pp 

darwin auditory grouping hearing moore ed san diego ca academic press 
ellis prediction driven computational auditory scene analysis ph dissertation mit department electrical engineering computer science 
helmholtz sensations tone braunschweig vieweg son 
ellis english trans dover 
hu wang monaural speech segregation pitch tracking amplitude modulation technical report tr ohio state university department computer information science 
available www cis ohio state edu hu hyv rinen karhunen oja independent component analysis new york wiley 
levelt speaking intention articulation cambridge ma mit press 
meddis simulation auditory neural transduction studies acoust 
soc 
am vol 
pp 

moore psychology hearing th ed san diego ca academic press 
speech communications human machine nd ed new york ieee press 
patterson smith rice efficient auditory filterbank gammatone function apu report mrc applied psychology unit cambridge 
ear frequency analyzer ii acoust 
soc 
am vol 
pp 

roweis microphone source separation advances neural information processing systems nips 
wang brown separation speech interfering sounds oscillatory correlation ieee trans 
neural networks vol 
pp 

weintraub theory computational model auditory monaural sound separation ph dissertation stanford university department electrical engineering 

