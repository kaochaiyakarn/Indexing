machine learning 
boostexter boosting system text categorization schapire research att com labs shannon laboratory park avenue room florham park nj singer research att com labs shannon laboratory park avenue room florham park nj 
focuses algorithms learn examples perform multiclass text speech categorization tasks 
approach new improved family boosting algorithms 
describe detail implementation called boostexter new boosting algorithms text categorization tasks 
results comparing performance boostexter number text categorization algorithms variety tasks 
conclude describing application system automatic call type identification unconstrained spoken customer responses 

text categorization problem classifying text documents categories classes 
instance typical problem classifying news articles topic textual content 
problem automatically identify type call requested customer instance customer says charge call visa want system recognize calling card call process call accordingly 
speech categorization problem apply text system passing spoken responses speech recognizer 
introduce machine learning technique called boosting problem text categorization 
main idea boosting combine simple moderately inaccurate categorization rules single highly accurate categorization rule 
simple rules trained sequentially conceptually rule trained examples difficult classify preceding rules 
approach new improved family boosting algorithms described analyzed detail companion schapire singer 
new family extends generalizes freund schapire adaboost algorithm freund schapire studied extensively shown perform standard machine learning tasks breiman drucker cortes freund schapire maclin opitz dietterich quinlan schapire schapire freund bartlett lee :10.1.1.31.2869
purpose current describe ways boosting applied problem text categorization test performance relative number text categorization algorithms 
text categorization problems usually multiclass sense usually possible categories 
applications may large number categories focus case small moderate number categories 
common text categorization tasks multi label meaning categories mutually exclusive document may relevant category 
instance bibliographic medical articles routinely multiple medical subject index mesh categories entered medline national bibliographic searchable archive contains documents 
machine learning systems designed handle multiclass data common systems handle multi label data 
numerous categorization algorithms nearest neighbor adapted multilabel categorization problems machine learning approaches applied text categorization problems common technique decompose multiclass multi label problem multiple independent binary classification problems category 
adopt different approach extensions adaboost specifically intended multiclass multi label data 
extension goal learning algorithm predict correct labels 
learned classifier evaluated terms ability predict approximation set labels associated document 
second extension goal design classifier ranks labels correct labels receive highest ranks 
describe boostexter system embodies versions boosting extensions discuss implementation issues arise multilabel text categorization 
voluminous done text categorization including techniques decision trees neural networks nearest neighbor methods rocchio method machines linear squares naive bayes rule methods 
see instance apt damerau weiss fuhr lustig cohen singer field fuhr pfeifer koller sahami lewis ringuette moulinier ra ganascia ng goh low yang 
impossible compare algorithms previous methods 
compare different methods believe representative effective techniques available report results different tasks 
experiments show number evaluation measures system performance generally better algorithms wide margin 
compare algorithm methods tested performance standard benchmark problem performance compared directly large body results reported literature 
specifically focus study yang conducted experiments benchmark surveyed results reported authors 
boostexter performance places top methods included yang study 
discuss application boostexter automatic speech categorization task compare performance system previous algorithm specifically designed task 

preliminaries section describe formal setting study multi label text categorization 
denote domain possible text documents finite set labels classes 
denote size traditional machine learning setting document assigned single class goal typically find classifier minimizes probability newly observed example multi label case document may assigned multiple labels example multiclass news filtering problem possible classes finance sports document may belong 
labeled example pair set labels assigned single label case special case observations 
define primarily interested classifiers produce ranking possible labels document hope appropriate labels appear top ranking 
formal goal learning produce function form interpretation instance labels ordered label considered ranked higher associated label set successful learning algorithm tend rank labels higher precise evaluation measures discussed sec 

simplify notation predicate holds 

boosting algorithms multi label multiclass problems companion schapire singer introduced analyzed new boosting algorithms multiclass multi label classification problems 
review algorithms discuss versions algorithms describe efficient implementation algorithms problem text categorization 
purpose boosting find highly accurate classification rule combining weak base hypotheses may moderately accurate 
assume access separate procedure called weak learner weak learning algorithm computing weak hypotheses 
boosting algorithm finds set weak hypotheses calling weak learner repeatedly series rounds 
weak hypotheses combined single rule called final combined hypothesis 
simplest version adaboost single label classification boosting algorithm maintains set importance weights training examples 
weights weak learning algorithm goal find weak hypothesis moderately low initialize pass distribution weak learner 
get weak hypothesis choose update normalization factor chosen distribution 
output final hypothesis 
algorithm adaboost mh 
error respect weights 
boosting algorithm weights force weak learner concentrate examples hardest classify 
see multiclass multi label problems appropriate maintain set weights training examples labels 
boosting progresses training examples corresponding labels hard predict correctly get incrementally higher weights examples labels easy classify get lower weights 
instance news classification problem easy classify document news item hard determine belongs finance section 
boosting progresses weight label news document decreases weight increases 
intended effect force weak learning algorithm concentrate examples labels beneficial goal finding highly accurate classification rule 

adaboost mh boosting algorithm multiclass multi label classification problems called adaboost mh shown fig 

sequence training examples instance described adaboost mh maintains set weights distribution examples labels 
initially distribution uniform 
round distribution training sequence passed weak learner computes weak hypoth output weak learner hypothesis interpret sign prediction label assigned prediction value 
magnitude prediction interpreted measure confidence prediction 
precise goal weak learner described weak learners experiments 
parameter chosen distribution updated 
discuss choice 
typical case positive distribution updated manner increases weight example label pairs misclassified differ sign 
final hypothesis ranks documents weighted vote weak hypotheses 
algorithm derived natural reduction multiclass multi label data binary data 
reduction example mapped binary labeled examples form instance document part derived example formally pair binary label associated instance words think observed label set specifying binary labels depending label included apply binary adaboost derived binary data 
algorithm results reduction equivalent adaboost mh 
view adaboost mh leads simple analysis 
specifically proved schapire singer bound empirical hamming loss algorithm fraction examples labels sign differs showed hamming loss algorithm normalization factor computed round upper bound guiding choice design weak learning algorithm 
choices geared round minimization sec 
describe methods choosing implementation weak learning algorithm text categorization 
note space time round requirements adaboost mh including call weak learner 

adaboost describe second boosting algorithm called adaboost ada boost mh designed minimize hamming loss adaboost designed specifically find hypothesis ranks labels manner hopefully places correct labels top ranking 
respect labeled observation focus relative ordering crucial pairs classification rule crucial pair fails rank goal find function small number labels ranked labels put way goal minimize average fraction crucial pairs quantity call empirical ranking loss initialize train weak learner distribution get weak hypothesis choose update 
normalization factor chosen distribution 
output final hypothesis 
algorithm adaboost 
assume empty equal instance 
instances training set simply discard ranking problem solved case carry information 
adaboost shown fig 

maintain distribution denote weight instance pair distribution zero relevant triples crucial pair relative weak hypotheses form think providing ranking labels described 
update rule bit new 
crucial pair relative recall zero cases 
assuming momentarily rule decreases weight gives correct ranking increases weight 
hamming loss shown schapire singer empirical ranking loss algorithm goal choosing minimization defer description technique purpose sec 

initialize train weak learner distribution defined eq 
get weak hypothesis choose update output final hypothesis 
efficient version adaboost round boosting example running time linear number labels 
algorithm somewhat inefficient labels naively need maintain weights training example weight updated round 
space complexity time round complexity bad fact algorithm implemented space time round 
nature updates show schapire singer need maintain weights maintain condition crucial pair relative times 
recall zero triples pseudocode implementation shown fig 

note space requirements round computations possible exception call weak learner discussed section 

weak hypotheses text categorization far left unspecified actual form implementation weak learner choice parameter section describe implementations weak learners adaboost mh adaboost system multilabel text categorization called boostexter methods described 
boosting meant general purpose method combined classifier practice instance decision trees neural nets 
focus boosting simple classifiers 
specifically methods weak hypotheses basic form level decision tree 
test root tree simple check presence absence term document 
words pairs adjacent words potential terms 
outcome test weak hypothesis outputs predictions confidences label associated document 
example going back news categorization example possible term bill clinton corresponding predictor term bill clinton appears document predict document belongs news high confidence finance low confidence belong high confidence 
hand term appear document predict belong classes low confidence fig 
shows weak hypotheses version adaboost datasets tested 
formally denote possible term define mean occurs document term interested weak hypotheses predictions form real numbers 
weak learners describe adaboost mh differ respect possible restrictions place values numbers 
weak learners search possible terms 
term values chosen described score defined resulting weak hypothesis 
terms searched weak hypothesis lowest score selected returned weak learner 
adaboost mh score exact calculation defined eq 
noted sec 
minimization reasonable guiding principle design weak learning algorithm 
adaboost know analytical solution problem minimizing approximation described 

adaboost mh real valued predictions weak learner permit unrestricted real valued predictions experiments call version real adaboost mh 
round term earn acq com econ vs oil cts agriculture shares trade dividend money market 
weak hypotheses real adaboost mh sec 
run entire reuters dataset described sec 

weak hypothesis form interpretation term associated weak hypothesis occurs document output row values output second row values 
value represented graphically bar gives output weak hypothesis classes 
instance weak hypothesis round boosting tests term vs positive value output earn negative values output classes 
weakly negative values output classes 
minimization mind values calculated follows term current distribution calculate possible label readability notation abbreviate subscripts writing words weight respect distribution documents partition labeled shown schapire singer minimized particular term choosing setting settings imply choose term value smallest 
fact may happen small zero case defined eq 
large infinite magnitude 
practice large predictions may cause numerical problems may theoretical reasons suspect large overly confident predictions increase tendency overfit 
limit magnitudes predictions implementation smoothed values experiments set effect bounding roughly 
adaboost mh real valued predictions abstaining bounded method described assigns confidence values term appears document 
employs tacit assumption absence term carries information possible classes document may belong 
intuitive knowledge problem may wish reject assumption force weak hypothesis abstain term appear document 
accomplished simply forcing weak hypothesis output confidence value zero documents contain term 
experiments call version real abstaining adaboost mh 
term weak learner chooses predictions documents con tain exactly 
implementation smooth values 
rest documents prediction values set zero 
term influence classification appear document 
set weight document contain shown schapire singer round choose term value smallest 
advantage weak learner improvement running time need consider documents include term computing typically number documents include non trivial term small fraction training data version practice faster previous 
furthermore experiments described sec 
performance versions comparable 

adaboost mh discrete predictions weak learner forces predictions weak hypotheses standard setting predictions carry confidences 
call version discrete adaboost mh 
restriction range weak hypotheses minimize term method 
notation defined sec 
set viewed weighted majority vote examples block label shown schapire singer purposes minimizing choose giving 
adaboost discrete predictions describe weak learner adaboost noted sec 
minimize defined eq 

unfortunately exact minimization quantity straightforward adaboost mh 
consider discrete predictions approximation score exact computation 
call discrete adaboost hypothesis similar analysis discrete adaboost mh shown choose know efficiently minimize exactly find weak hypothesis minimizes upper bound upper bound score choosing best weak hypothesis 
efficiency important note quantity computed efficiently terms weights defined eq 

shown schapire singer particular term choose gives choose term maximizes quantity assign predictions correspondingly 
parameter set eq 

search weak hypothesis time consuming training corpus large 
inverted list stores term word bigram table 
summary properties weak learners multiclass multi label text categorization 
version loss prediction real mh hamming real abstaining mh hamming discrete mh hamming discrete ranking defined eq 
defined eq 
sparse gram list documents appears 
round searching weak hypothesis scan inverted list term evaluate prediction confidences version adaboost 
straightforward implementation require scanning entire collection term 
precomputing certain values save significant amount time 
adaboost mh instance compute round values find term values summing documents term appears inverted list 
set proceed find corresponding values amount time spent round searching weak hypothesis proportional total number occurrences terms training collection 
weak hypothesis takes time update distribution system multi label text categorization called boostexter implementations weak learners described 
brief summary different implementations tab 

evaluation measures evaluating performance boosting algorithms evaluation measures 
error simple generalization classification error multiclass multi label problems 
error directly related training error schapire singer 
evaluation measures measures information retrieval evaluate performance various classification algorithms terms label rankings 
noted earlier assume multi label system induces ordering possible labels instance 
output learning system function ranks labels label considered ranked higher exception ripper classification systems tested viewed way ordering defined assigning real number possible instance label pair find convenient refer rank label instance denote rank formally rank mapping rank rank error 
measure evaluates times top ranked label set possible labels 
goal multiclass system assign single label document error measures times predicted label call measure error hypothesis measures probability getting labels correct 
denote error hypothesis define classifier assigns single label err document setting set labeled documents error err note single label classification problems error identical ordinary error 
coverage 
error evaluates performance system top ranked label goal coverage measure assess performance system possible labels documents 
coverage measures far need average go list labels order cover possible labels assigned document 
coverage loosely related precision level perfect recall 
formally define coverage respect coverage rank single label classification problems coverage average rank correct label zero system classification errors 
average precision 
measures complete multi label classification problems achieve low coverage suffer high error rates vice versa 
order assess label ranking multiclass system non interpolated average precision performance measure frequently evaluation information retrieval ir systems salton 
note non interpolated average precision typically ir systems evaluate document ranking performance query retrieval 
contrast experiments average precision evaluating effectiveness label rankings 
formally define average precision ranking respect training set denoted short rank rank rank words measure evaluates average fraction labels ranked particular label note system ranks perfectly labels documents document label ranked higher label 
text categorization experiments section describe analyze experiments performed boosting algorithms text categorization described previous sections 
experiments performed sgi challenge mips processors running mhz 
timing information give section respect single cpu 

test corpora reuters 
documents collection collected reuters newswire 
modified apte modapte split contains documents 
cleaned version dataset called reuters publicly available web www research att com lewis david lewis originally compiled collection 
performed pre processing prior experiments words converted lower case punctuation marks removed function words standard list removed 
average length document pre processing words 
corpus divided categories turn sub divided sub categories 
reuters corpus served benchmark text categorization studies various partitions corpus 
see yang overview common partitions versions corpus summary text categorization algorithms tested corpus 
considered partitions reuters corpus broad topics top hierarchy details see tabs 
anda 
fold cross validation experiments partitions 
compare algorithm previously published performed experiments partition includes topics reuters relevant documents training 
collection includes topics studied extensively yang 
yang referred partition version compared results previously studied text categorization algorithms 
devote separate section sec 
description experiment widely tested partition reuters 
ap titles 
corpus ap newswire headlines lewis gale lewis catlett 
reuters corpus previous concentrated binary classification tagging documents relevant irrelevant topics federal budget ratings total number documents corpus 
headlines average words long total vocabulary words 
preprocessing text done convert words lower case remove punctuation marks 
performed sets experiments corpus different labeling schemes available corpus 
usenet data 
dataset consists usenet articles collected lang different newsgroups 
articles collected newsgroup articles entire collection 
data originally treated single labeled see instance joachims 
people tend post articles multiple newsgroups examining headers articles articles multi labeled 
furthermore identical articles posted group 
total number articles relabeling data headers labels 
description dataset tab 

fold cross validation experiments newsgroup data 

algorithms mentioned immense text categorization different algorithms 
impossible implement evaluate previously published algorithms chose algorithms comparison boosting algorithms ripper 
cohen rule learning system adapted text categorization problems cohen singer 
ripper classifies document applying set boolean tests check absence presence words documents 
ripper capable dealing multiple labels 
ripper learns classifier form boolean combination simple terms 
provide ranking possible labels document 
performance measure comparison error rate 
rocchio 
implemented version rocchio algorithm rocchio adapted text categorization ittner 
modified multiclass problems 
rocchio represent data training test documents vectors numeric weights 
weight vector th document number indexing terms 
single words terms 
followed tf idf weighting salton defined weight number documents number documents indexing term appears 
weight number occurrences indexing term document set class build prototype vector average weight vector documents formally prototype vector class test documents classified calculating dot products weight vector representing document prototype vectors 
dot products induce ranking possible labels 
ranking evaluate performance classifier measures discussed sec 

sleeping experts 
algorithm originally proposed blum studied freund 
applied text categorization cohen singer 
briefly algorithm classifies document thresholding score weighted combination experts word grams appearing text 
score rank labels 
algorithm easily adapted multiclass multi label settings assigning mini experts possible pair class sparse word gram 
words word pairs set experts experiments 
naive bayes probabilistic tf idf 
probabilistic classifiers assign document probability vector belonging possible labels 
algorithms probability vectors viewed rankings evaluating performance respect measures discussed sec 

algorithms available part publicly available rainbow text categorization system experiments 
system includes classification methods experiments performed naive bayes probabilistic tf idf performed better methods available rainbow 
description naive bayes probabilistic tf idf text categorization mitchell joachims 
handle multi label data mapped single label case simply repeating document assigned labels 

experiments single label corpora set experiments partitioned reuters corpus disjoint classes 
classes roughly constitute top categorization hierarchy 
discarded articles belong classes articles belong class 
detailed description subset tab 

total number articles experiment fold cross validation experiments 
results report averaged folds 
subsets dataset ran real adaboost mh real abstaining adaboost mh rounds discrete adaboost mh adaboost performed experiments varying numbers classes 
selected subsets data top classes decreasing number documents instance took documents classes earn acq com 
created different splits training test data ran various text categorization algorithms splits 
summary results experiments dataset tab 
graphically fig 

performance different multiclass versions adaboost comparable data set small advantage real valued versions ada boost mh abstaining 
versions adaboost multi label problems clearly outperform classification algorithms 
error ada boost mh smaller error rate best competing algorithm dataset naive bayes 
similar behavior observed coverage average precision 
error coverage average precision real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes error coverage average precision real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes 
left comparison various boosting algorithms text categorization single label subset reuters 
right comparison real adaboost mh naive bayes probabilistic tf idf sleeping experts rocchio subset 
set experiments single label datasets ap titles corpus 
subset ap titles headline possibly labeled single topic possible classes 
extracted documents belong exactly classes 
description subset ap titles tab 

subsets dataset ran real valued version adaboost mh abstaining rounds discrete adaboost mh adaboost rounds 
tested performance algorithms extracting subsets growing numbers classes ordered classes decreasing number documents class 
results summarized tab 
graphically fig 

different boosting algorithms real adaboost mh exhibits best performance slightly better real abstaining adaboost mh significantly better discrete adaboost mh discrete adaboost worst performer boosting algorithms 
main reason rounds simply discrete versions 
discrete adaboost adaboost mh training error monotonically decreasing reached maximal number rounds 
improved performance decreasing training error real valued versions adaboost vivid large datasets show subsequently 
best competitor algorithm dataset sleeping experts 
fact slightly outperforms adaboost mh number classes 
subsets classes adaboost mh significantly outperform respect performance measures 
note interesting fact contrast results previous dataset probabilistic tf idf outperforms naive bayes algorithms clearly inferior adaboost mh 
set experiments single labeled multiclass problems entire ap titles collection 
addition partial partition specific topics corpus divided general categories article falls exactly category 
removed articles belonging categories 
number articles remained labeling scheme results large corpus cross validation experiments 
lewis chronological split training test sets 
training set split contains headlines test set description classes tab 
summary results tab 

rainbow allocates different file article dataset large converted format required rainbow 
compared real ada boost mh discrete adaboost mh discrete adaboost sleeping experts rocchio ripper 
main focus experiment dataset performance different boosting algorithms function number rounds 
fig 
show training test error algorithms function number rounds 
see version adaboost mh uses real valued predictions dramatically outperforms methods predictions training error took real adaboost mh rounds reach training error fold speed 
rounds discrete adaboost mh reaches previous experiments discrete adaboost mh consistently outperform discrete adaboost partially due approximation lieu direct minimization 
fortunately observe overfitting adaboost algorithms better performance decreasing training error results lower error rates test data 
best competitor algorithm dataset sleeping experts 
takes rounds adaboost mh reach test error rate sleeping experts rounds test error significantly lower 
sleeping experts faster dataset finishing minute roughly long takes run boosting rounds 
error coverage average precision real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes error coverage average precision real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes 
left comparison various boosting algorithms text categorization single label subset ap titles 
right comparison real adaboost mh naive bayes probabilistic tf idf rocchio dataset 

experiments multi label corpora set experiments multi labeled corpora reuters dataset 
time partitioned classes topics constituting top hierarchy 
discarded documents belonging topic articles belonging topic assigned multiple labels 
total number articles partition number different labels articles labeled label 
performed experiments selecting subset classes corresponding articles 
subsets selected choosing error discrete adaboost discrete adaboost mh real adaboost mh number rounds error ripper rocchio sleeping experts discrete adaboost discrete adaboost mh real adaboost mh number rounds 
comparison training left test right error boosting methods second single label subset ap titles classes largest number articles difficulty classification problem increases description dataset tab 

experiments data fold cross validation 
ran versions real valued prediction rounds discrete versions rounds 
summary results averaged folds tab 
fig 

results multi label dataset similar previous single label datasets 
different boosting methods comparable performance 
adaboost slightly worse error average precision 
real adaboost mh outperforms competitor algorithms respect performance evaluation measures 
furthermore clear winner algorithms sleeping experts best subsets small number classes naive bayes best large classification problems 
ada boost mh clearly outperforms methods subsets 
second set multi label experiments reuters partitioned dataset classes constituting leaves hierarchy topics 
chose classes include articles 
subset includes different classes sum documents labeled different labels 
full subset classes articles label 
performed experiments subsets growing size classes detailed description dataset tab 

fold cross validation estimate performance 
ran real valued version rounds discrete summary results tab 
fig 

see comparable performance different boosting algorithms 
real adaboost mh better competitor algorithms especially respect error average precision 
dataset rocchio best alternative 
fact achieves coverage values comparable real adaboost mh subsets 
experiment multi labeled text data performed newsgroup articles 
followed experimental methodology previous studies dataset 
fold cross validation 
fold held test set fixed varied size error coverage average precision real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes error coverage average precision real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes 
left comparison various boosting algorithms text categorization multi label subset reuters 
right comparison real adaboost mh naive bayes probabilistic tf idf sleeping experts rocchio right dataset 
training set sub sampling full training set fold 
ran different algorithms training sets size thirds total number articles available dataset 
compared real ada boost mh methods previous studies achieved best results dataset naive bayes probabilistic tf idf 
allowed weak hypotheses features naive bayes probabilistic tf idf single words word pairs 
set number rounds adaboost mh twice number training documents 
ran adaboost mh little rounds rounds 
error coverage average precision real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes real adaboost mh real abstain adaboost mh discrete adaboost mh discrete adaboost number classes error coverage average precision real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes real adaboost mh sleeping experts rocchio naive bayes prtfidf number classes 
left comparison various boosting algorithms text categorization second multi label subset reuters 
right comparison real adaboost mh naive bayes probabilistic tf idf sleeping experts rocchio dataset 
results comparing real adaboost mh probabilistic tf idf naive bayes evaluation measures function training set size shown fig 

training sets size smaller real adaboost mh clearly inferior probabilistic tf idf naive bayes 
performance adaboost mh especially poor training sets size smaller 
training set large see adaboost mh outperforms probabilistic tf idf naive bayes respect measures 
difference performance significant previous datasets 
possible explanation results contrast probabilistic tf idf naive bayes adaboost mh incorporates little error coverage average precision real adaboost mh naive bayes prtfidf number training examples real adaboost mh naive bayes prtfidf number training examples real adaboost mh naive bayes prtfidf number training examples 
comparison real adaboost mh naive bayes probabilistic tf idf function number training examples usenet data prior knowledge 
adaboost mh minimizing hamming loss training set generalization error poor implied theoretical studies 
examples prior knowledge incorporated term weights probabilistic tf idf naive bayes crucial adaboost mh better job driving training error generalization error decreases 
results suggest new boosting algorithms text categorization best utilized complex multiclass problems large number training examples 

experiment large number classes conclude section text categorization experiments multi label categorization experiment dataset contains large number classes 
experiment error number rounds train test precision adaboost mh knn ripper sleeping experts recall precision 
left error training test data reuters partition classes 
right precision recall curve adaboost mh test collection dataset 
partition reuters prepared apt 
experiments swap rule learner 
reuters corpus partitioned training set documents test set containing document 
partition includes classes documents training set document test set 
classes 
yang refers partition reuters version performed extensive comparisons various algorithms evaluated partition 
compare adaboost mh classification algorithms achieved best performance results yang nearest neighbor knn classifier linear classifier squares fit term weights class labels llsf 
processed text described sec 

document labeled subset possible classes 
average number labels document problem requires vast amount memory maintain distribution need table size amounts numbers 
previous experiments ran adaboost mh rounds took days cpu time complete 
smoothing value set fold cross validation training set 
note default value yielded slightly worse results 
instance point average precision default value compared cross validation determine left hand side fig 
plot error training test data function number rounds 
note error training set reaches minimal value close zero rounds boosting test error continues decrease rounds apparently overfitting 
behavior observed experiments boosting algorithms partially motivated theoretical analysis schapire 
results dataset comparable previously published results evaluation measures yang point interpolated average precision salton mcgill van rijsbergen micro averaged break point 
third performance measures asses general quality label ranking second measure evaluates classification quality 
details evaluation measures see yang 
recall table 
summary results obtained reuters classes 
threshold adjusted data threshold avg 
algorithm pt avg 
precision bep adaboost mh knn llsf measure need set threshold label rankings decide labels associated document 
evaluated performance thresholds zero threshold threshold adjusted maximize training data adaboost mh completed rounds 
tab 
summarize results compare best results obtained yang 
note brought attention final weiss 
report break point reuters dataset 
give right hand side fig 
precision recall graph adaboost mh break points classification algorithms evaluated dataset 
performance adaboost mh state art achieves highest point interpolated average precision break point comes close best value obtained partition reuters 
difficult asses statistical significance results performance measures highly nonlinear non additive 
performance ada boost mh studied dataset provides empirical evidence boosting algorithms serve viable alternative existing algorithms text categorization 

speech categorization experiments final set experiments tested system call classification task 
purpose task automatically identify type call requested response greeting may help instance response charge call visa card call classified calling card call 
fourteen call types plus category 
calls type instance call collect person person 
task previously studied gorin gorin riccardi wright gorin parker sachs riccardi gorin riley wright gorin riccardi data collection training utterances test utterances 
training test utterances transcribed humans actual spoken responses 
test utterances available form produced automatic speech recognizer course form available real system 
worked dataset results form roc curve 
algorithm needs produce confidence predictions 
curve produced varying reject threshold specifies 
results call type identification task 
correct classification rate roc curves test sentences mar baseline text baseline speech boostexter text boostexter speech false rejection rate examples confidence threshold rejected task mean call handled human operator 
plot accuracy classifier non rejected examples function false rejection rate fraction examples incorrectly rejected 
classification system considered equivalent rejection 
get confidence level predictions adaboost mh difference final scores second ranked labels 
final classifier produced adaboost mh confidence assigned prediction test example second ranked labels trained real adaboost mh data rounds boosting allowing sparse word trigrams terms forming weak hypotheses 
compared system best previous published dataset wright gorin riccardi 
results shown fig 
set roc curves 
top set curves algorithms tested human transcribed test data 
bottom set curves test data generated automatic speech recognizer spoken utterances 
solid curves adaboost mh dashed curves wright gorin riccardi 
performance algorithms strikingly similar reject levels 
adaboost mh significantly better transcribed data moderately large reject levels 
results indicate slightly half examples adaboost mh produce predictions certainly correct 
note training set test manually transcribed automatically recognized data 
adaboost mh learning algorithms attempts minimize classification error training data employs tacit assumption test data generated source training data 
clearly true automatically transcribed data testing 
believe improve performance system training data automatically generated speech recognizer 
acknowledgments allen gorin david lewis andrew mccallum fernando pereira amit singhal jerry wright useful discussions help experiments 
notes 
arbitrary long sparse grams restrict words word bigrams comparison purposes 

function words include high frequency words 
list lewis lewis 

www cs cmu edu afs cs project theo www naive bayes html 
categories contain articles 
discarded categories corresponding articles articles 
apt damerau weiss 

language independent automated learning text categorization models 
proceedings th annual international acm sigir conference research development information retrieval pp 

fuhr lustig 

automatic indexing system air phys research application 
proceedings th annual international acm sigir conference research development information retrieval pp 

blum 

empirical support winnow weighted majority algorithms results calendar scheduling domain 
machine learning 
breiman 

arcing classifiers 
annals statistics 
cohen 

fast effective rule induction 
proceedings twelfth international conference machine learning pp 

cohen singer 

context sensitive learning methods text categorization 
proceedings th annual international acm sigir conference research development information retrieval pp 

drucker cortes 

boosting decision trees 
advances neural information processing systems pp 

field 

automatic indexing automatic assignment indexing classification free indexing 
journal documentation 
freund schapire 

experiments new boosting algorithm 
machine learning proceedings thirteenth international conference pp 

freund schapire 

decision theoretic generalization line learning application boosting 
journal computer system sciences 
freund schapire singer warmuth 

combining predictors specialize 
proceedings ninth annual acm symposium theory computing pp 

fuhr pfeifer 

probabilistic information retrieval combination abstraction inductive learning probabilistic assumptions 
acm transactions information systems 
gorin parker sachs 

may help 
proceedings interactive voice technology telecommunications applications pp 

gorin riccardi wright 

may help 
speech communication 
ittner lewis ahn 

text categorization low quality images 
symposium document analysis information retrieval pp 
las vegas nv 
univ nevada las vegas 
joachims 

probabilistic analysis algorithm tfidf text categorization 
machine learning proceedings fourteenth international conference pp 

koller sahami 

hierarchically classifying words 
machine learning proceedings fourteenth international conference pp 

lang 

newsweeder learning filter netnews 
proceedings twelfth international conference machine learning pp 

lewis 

representation learning information retrieval 
tech 
rep computer science dept university massachusetts amherst 
phd thesis 
lewis catlett 

heterogeneous uncertainty sampling supervised learning 
machine learning proceedings eleventh international conference 
lewis gale 

training text classifiers uncertainty sampling 
seventeenth annual international acm sigir conference research development information retrieval 
lewis ringuette 

comparison learning algorithms text categorization 
third annual symposium document analysis information retrieval pp 

maclin opitz 

empirical evaluation bagging boosting 
proceedings fourteenth national conference artificial intelligence pp 

dietterich 

pruning adaptive boosting 
machine learning proceedings fourteenth international conference pp 

mitchell 

machine learning 
mcgraw hill 
moulinier ra ganascia 

text categorization symbolic approach 
fifth annual symposium document analysis information retrieval pp 

ng goh low 

feature selection perceptron learning usability case study text categorization 
proceedings th annual international acm sigir conference research development information retrieval pp 

quinlan 

bagging boosting 
proceedings thirteenth national conference artificial intelligence pp 

riccardi gorin riley 

spoken language understanding automated call routing 
proceedings ieee international conference acoustics speech signal processing pp 

rocchio 

relevance feedback information retrieval 
salton 
ed smart retrieval system experiments automatic document processing pp 

prentice hall englewood cliffs nj 
salton 

developments automatic text retrieval 
science 
salton mcgill 

modern information retrieval 
mcgraw hill 
schapire 

output codes boost multiclass learning problems 
machine learning proceedings fourteenth international conference pp 

schapire freund bartlett lee 

boosting margin new explanation effectiveness voting methods 
annals statistics 
schapire singer 

improved boosting algorithms confidence rated predictions 
proceedings eleventh annual conference computational learning theory pp 

appear machine learning 
van rijsbergen 

information retrieval 
butterworths london 
weiss apte damerau johnson oles goetz 

maximizing text mining performance 
ieee intelligent systems 
wright gorin riccardi 

automatic acquisition salient grammar fragments call type classification 
proceedings th european conference speech communication technology pp 

yang 

expert network effective efficient learning human decisions text categorization retrieval 
proceedings th annual international acm sigir conference research development information retrieval pp 

yang 

evaluation statistical approaches text categorization 
information retrieval 
appear 
appendix description text datasets summary results table 
description classes constituting single label subset reuters 
class docs cum 
docs earnings earnings forecasts earn mergers acquisitions acq commodity codes com economic indicator codes econ general articles energy codes table 
results single label subset reuters tab 

real adaboost mh naive bayes rocchio sleeping experts ripper error cover prec 
error cover prec 
error cover prec 
error cover prec 
error table 
description classes constituting single label subset ap titles 
class docs cum 
docs class docs cum 
docs japan bush israel yugoslavia gulf ireland german weather bonds hostages budget table 
results single label subset ap titles tab 
real adaboost mh naive bayes rocchio sleeping experts ripper error cover prec 
error cover prec 
error cover prec 
error cover prec 
error table 
description classes constituting second single label subset ap titles class docs train docs test domestic international financial washington political entertainment table 
error rates different algorithms second single label subset ap titles tab 
rounds rounds real adaboost mh discrete adaboost mh ripper sleeping experts rocchio table 
description classes constituting multi label subset reuters cum 
avg 
class docs docs labels docs earnings acquisitions commodity economics interest energy money fx shipping currency table 
results multi labeled subset reuters tab 
real adaboost mh naive bayes rocchio sleeping experts error cover prec 
error cover prec 
error cover prec 
error cover prec 
table 
description classes constituting second multi label subset reuters cum 
avg 
cum 
avg 
class docs docs labels docs class docs docs labels docs money fx grain sugar crude coffee trade gnp interest oil ship gold wheat soybean corn gas dlr bop supply table 
results second multi labeled subset reuters tab 
real adaboost mh naive bayes rocchio sleeping experts error cover prec 
error cover prec 
error cover prec 
error cover prec 
table 
list newsgroups number articles posted newsgroups 
article may posted multiple groups 
group docs group docs alt atheism rec sport hockey comp graphics sci crypt comp os ms windows misc sci electronics comp sys ibm pc hardware sci med comp sys mac hardware sci space comp windows soc religion christian misc talk politics guns rec autos talk politics mideast rec motorcycles talk politics misc rec sport baseball talk religion misc 
