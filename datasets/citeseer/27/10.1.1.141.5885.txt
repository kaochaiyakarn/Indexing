improving search retrieval performance shortening documents detecting garbage throwing jargon scott submitted faculty college fulfillment requirements distinguished honors computer science college faculty committee approves distinguish honor thesis improving search retrieval performance shortening documents detecting garbage throwing jargon submitted scott april kontostathis advisor department mathematics computer science april kontostathis committee member department mathematics computer science richard committee member department mathematics computer science ben coleman external reviewer department computer science college roger coleman chair department mathematics computer science approval date thesis describes development new search retrieval system index process queries different data sets documents 
thesis describes trec legal data set particular new algorithms designed improve recall precision rates legal domain 
applied novel normalization techniques designed slightly favor longer documents assuming documents equal weight 
created set rules detect errors text caused optical character recognition software 
developed new method reformulating query text background information provided information request 
queries judgment data released trec query pruning cube root normalization results average recall improvement average precision improvement compared cosine normalization query reformulation 
queries extremely high performance improvements different kinds power normalization recall precision improving top rankings 
chapter find age information overload 
day hundreds web pages posted new books published new papers written 
infeasible manual searches hand trying find information 
field information retrieval aims solve problem 
consider development internet search engines 
automatic web search systems developed forced online directories users sites wanted sifting virtual folders 
example user wanted find web pages cows need find directory animals folder need find subdirectory mammals reaches folder containing known web pages pertaining cows 
idea may acceptable pages available web widely manual searches quickly far cumbersome tedious average user perform automatic search engines rushed scene implementing algorithms developed research information retrieval 
course led today number competing online retrieval systems promising lives cyberspace easier faster 
purpose thesis report findings research field information retrieval 
start providing background information field followed description custom built retrieval system 
system google focus system retrieving legal documents 
thesis go detail data sets testing particularly trec legal track collection 
include description new algorithms developed system review improvements performance rates algorithms introduce 
chapter background overview information retrieval science automatically searching documents information large collection textual data 
search retrieval system piece software perform searches quickly 
systems usually loading set documents called corpus user entered query input attempting query find documents collection user find relevant 
may number different ways accomplish task retrieval systems index corpus organize information documents fast processing 
term weighting applied order words index important depending frequencies documents 
index built term weighting decided user queries processed possible matches 
performance system measured different metrics help standard list queries relevance judgments 
indexing feasible load search original text data set time user enters query 
index data set works solve problem 
index organized matrix number unique terms data set number documents 
ij th element corresponds weight term document documents contain small subset terms entire data set entries matrix 
reason index usually stored sparse matrix format 
term weighting term weighting determine important term document 
term may important appears times document 
term important appear documents collection rare term 
simplest approach term weighting may set term weight document denoted wij frequency term document denoted fij 
common useless terms scored important documents method 
approach take account rare term may collection documents 
log entropy weighting scheme better algorithm measuring term weights 
algorithm calculate term local weight important term specific document term global weight important term data set 
local weight term document defined formula lij log fij fij frequency term document way importance term kept relatively constant frequency document large 
global weight term defined formula gi fij fi log fij fi log number documents collection fi total frequency term documents data set 
scheme term appears frequency document global weight 
term appears just document global weight 
cases term global weight 
due difficulties implementation large collections local weight experiments 
runs plan include global term weighting part system 
query processing goal query processing find documents closely related user information needs 
treat query document 
terms index documents removed query 
way query expressed vector length term weights decided log entropy weighting scheme described 
determine similarity query document take dot product query vector th column sparse matrix 
documents highest dot product assumed relevant query 
perform product document sort documents highest lowest similarity return list user 
list terms common virtually useless performing searches potentially great deal hard disk space slowing system adversely affecting term weights 
example words appear nearly document collection times document 
list list terms retrieval system ignore building index processing query 
standard english list contains words 
normalization major problems information retrieval way large documents natural advantage shorter documents processing queries simply opportunities term matches longer documents 
goal document normalization reduce advantage small relevant documents probability returned large relevant documents 
cosine normalization standard method document normalization cosine normalization 
document normalization factor calculated 
normalization factor defined expression wi weight term document number unique terms document 
original term document weight divided normalization factor get final normalized term document weight 
applied document collection document vector length 
stemming indexing data set may find term eats collection 
may find word eating corpus 
words different word eat na retrieval system terms completely different 
may beneficial system assume eats eating eat fact word 
way terms share weights document considered matches word eat appear query 
stemming solution problem program detects unimportant words removes leaving root term 
explain thesis stemming system increased running time significantly improve retrieval performance 
performance measurement people need find websites topic internet search engine 
web search engines available google yahoo msn user perform search different engines may find return different websites 
additionally engines may return useful matches 
clearly retrieval systems better way quantify performance system 
recall precision commonly metrics measuring performance search retrieval system recall precision 
recall proportion relevant documents retrieved total number relevant documents collection 
precision proportion relevant documents retrieved number documents retrieved 
example user may enter query apple system 
suppose know exactly documents data set relevant apples 
suppose system retrieves documents truly relevant apples 
case recall precision 
rank useful give recall precision rates certain number documents retrieved 
rank limit number documents returned search system 
example system retrieves documents may want look top documents 
determine top documents relevant query documents find recall precision 
denominator precision number documents retrieved lesser rank total number documents retrieved 
documents top relevant total relevant documents collection recall rank precision rank 
mean average precision recall precision useful metrics trying measuring performance specific ranks metrics measuring system works 
mean average precision metric measure performance system measuring highly ranked relevant documents average 
average precision searching list matched documents highest ranking lowest ranking 
time find relevant document position list measure record precision rank relevant documents take average recorded precision rates average precision query 
multiple queries run mean average precision average average precisions measured query 
gold standard collections developing new algorithms retrieval system recall precision mean average precision determine change retrieval performance 
calculate metrics need know documents corpus relevant query 
typically multiple queries achieve better estimate performance 
size data sets extremely large cases exceeding hundreds thousands documents take long time decide documents corpus relevant queries 
solve problem standard list queries relevance judgments released collections 
set relevance judgments list pairs query numbers document numbers 
say qi query number referring th standard query dj document number referring th document collection 
pair qi dj set relevance judgments known document dj relevant query qi 
information easily system automatically measure recall precision performance run 
text retrieval conference text retrieval conference trec annual international conference focus information retrieval 
trec hosts number tracks year track concentrates specific subfield information retrieval 
november trec organized sixteenth conference 
tracks hosted year blog track enterprise track genomics track legal track query track question answering track spam track 
track research groups different universities attempt develop best systems achieve goal particular track 
example groups participating query track build systems accept extraordinarily large number queries limited judgment data 
participated legal track 
trec legal problems people legal profession face finding precedence cases 
preparing cases trial search hundreds thousands documents 
legal domain recall considered important precision increase precision top ranks prevent expert wasting time irrelevant materials 
response need text retrieval conference started new legal track 
trec legal data set large collection legal documents approximately documents gb data 
trec released set topics queries data set 
queries corresponding relevance judgment data provided 
average documents judged queries low high 
average rated relevant nonrelevant 
wide range relevant documents queries 
queries relevant document relevant documents 
summer trec released new set queries legal track 
offer judgment data runs october 
research groups different universities retrieval systems search algorithms run new queries 
group sent list matched documents trec organizers measured precision recall certain rankings 
team allowed submit results maximum different runs 
group system performed best considered winner competition 
research groups participated trec legal competition 
submitted results different automated runs judges 
total teams competed runs submitted 
run appeared th place 
precise retrieval performance system trec legal data discussed thesis 
optical character recognition optimal character recognition technology allows user scan physical document 
attempts read image retrieve text document saving file 
trec legal data set large infeasible documents hand computer 
necessary documents trec legal scanned ocr software 
ocr technology imperfect creates errors documents 
example word wonderful may read ocr software 
comes graphic image ocr software generates garbage strings 
possible solution problem thesis 
chapter search system research project designed implemented custom search retrieval system 
system capable different data sets inputs index running list queries index relevance judgments calculating average recall average precision mean average precision list matches 
data sets data sets system index listed 
data sets testing performance search retrieval algorithms 
due larger size trec disks trec legal collections interest trec disks held document sets text retrieval conference trec legal corpus legal documents compiled legal track explained 
table summary collections tested identifier docs terms queries med cisi cacm cran ohsumed trec disks trec legal large data sets data sets need index large exceeding gigabytes size 
limited memory machine develop algorithm split data set system index run queries piece separately produce results system processed entire set 
algorithm works follows split original data set number smaller pieces indexing trec legal machine gb ram required split pieces approximately mb size 
index piece separately data set 
piece index large reasonable assume terms appear times single probably important collection terms removed 
save document id actual text term global frequency term current data set local frequencies document term 
calculate log local weight term document 
data set indexed list queries processed simply running queries separately sub index keeping running list top scoring documents query 
chapter improving retrieval performance developed new search algorithms improve performance retrieval system 
significant algorithms power normalization works shrinking effective vector lengths documents 
second contribution optical character recognition ocr error detection system finds removes garbage terms caused ocr software index 
final addition system automatic query uses outside information dynamically generate list legal jargon terms remove terms query text 
new methods normalization trec legal data set extremely high variance document lengths compared data sets interested collection determine changes performance different normalization algorithms 
problem cosine normalization assumes probability relevance completely independent document length 
long documents slightly higher chance truly relevant query content 
account developed document normalization schemes penalty longest documents 
related widely normalization method cosine normalization basis comparison experiments 
alternate normalization techniques include pivoted document length normalization maximum tf normalization byte length normalization :10.1.1.50.9950
pivoted document length normalization tackles similar problem stated problem long documents requiring somewhat greater advantage short documents 
pivoted document length normalization shown effective compared cosine normalization collections :10.1.1.50.9950
algorithm exceptionally complex requires extensive training am interested designing easy understand algorithms require little training achieve improvement 
maximum tf weighting schemes largest term weight document normalization factor 
byte length normalization uses size document bytes determine normalization factor shown effective collections ocr errors corrected collections simulated ocr errors 
describe thesis system attempts remove ocr errors possible correcting remaining ocr errors real simulated 
log normalization log function normalize documents 
total number terms document 
log normalization factor defined expression log original term document weight divided normalization factor find final normalized term document weight 
chose log function slow growth higher 
way documents shortened somewhat long documents penalized shorter documents 
power normalization experimented different powers normalization factor 
total number terms document 
square root normalization factor defined expression cube root normalization factor defined expression fourth root normalization factor defined expression powers reasons similar log normalization 
functions grow slowly large values large documents advantage 
biggest difference log normalization power normalization simply rate growth normalization factor functions 
power functions grow faster log function meaning length advantage extremely large documents diminished 
table recall precision comparisons small collections log norm vs cos norm collection rank metric ohsumed cos recall ohsumed log recall ohsumed cos precision ohsumed log precision cacm cos recall cacm log precision cacm cos recall cacm log precision cisi cos recall cisi log recall cisi cos precision cisi log precision med cos recall med log recall med cos precision med log precision cran cos recall cran log recall cran cos precision cran log precision results compared log normalization cosine normalization 
tests shown log normalization recall precision rates consistently higher cosine normalization small data sets especially top ranked documents 
data sets shown table 
tested system stemming porter stemming algorithm appear improve recall precision rates data sets 
reason stemming experiments 
shown table rank log normalization improves precision recall data sets 
med improvement increase recall increase precision 
log normalization data sets showed greater improvements 
queries processed ohsumed data set rank increase recall improvement precision 
cacm showed improvement recall improvement precision 
cisi log normalization increased recall precision 
doc length doc length trec legal document lengths normalization doc lengths norm document trec legal document lengths log normalization doc length log norm document table shows recall precision rates log normalization method dropped approximately values cosine normalization data sets rank 
exception ohsumed set improvements recall precision rankings 
performance top rankings important systems especially web search engines drop scores critical 
reasons explained trec collections omitted table 
doing tests smaller data sets log normalization tested trec legal data set log normalization 
documents trec legal far longer small data sets 
log normalization gave advantage longer documents 
figures data plots displaying vector lengths judged documents trec legal queries normalization 
documents sorted ascending vector length normalization document referring document document graph document lengths cosine normalization applied horizontal straight line 
graphs meant show different normalization schemes affect lengths documents doc length doc length trec legal document lengths square root normalization doc length sqrt norm document trec legal document lengths cube root normalization doc length cube root norm document collection 
higher document lengths graph imply higher advantages short documents 
see original document lengths normalization sorted shortest document longest document 
see document lengths log normalization applied 
shape curve log normalization similar original document length curve meaning log function little effect 
prompted try power normalization techniques trec legal 
see figures power functions greater effect curve 
shows square root function heavy graph somewhat downward sloping 
cube root fourth root normalization graphs act precisely intended slight upward slope original document sizes longer 
table see effect normalization scheme number terms documents returned search system top ranks 
expected normalization results large documents useful 
log normalization large effect long documents trec legal average term length returned documents order magnitude normalization 
cosine normal doc length trec legal document lengths fourth root normalization doc length root norm document table average number terms different normalization schemes norm cosine log sqrt rank rank rank ization square root normalization return short documents term lengths 
cube root normalization fourth root normalization average term counts cosine square root normalization log normalization 
shown table cube root fourth root normalization show table recall precision comparisons normalization techniques trec legal queries rank normalization cosine recall log recall sqrt recall recall recall cosine precision log precision sqrt precision precision precision performance improvements cosine normalization particularly top rankings 
performances ranking bold face table 
rank cube root normalization provides improvement recall improvement precision fourth root normalization creates increase recall increase precision 
rank cube root normalization improvement recall improvement precision fourth root normalization increase recall decrease precision 
ranks higher power normalization functions recall precision rates equivalent rates cosine normalization 
fact power normalization methods provide improvement performance top important rankings supports hypothesis longer documents relevant decreasing penalty normalization improves recall precision rates 
ocr error detection discussed earlier mistakes ocr scanning software adversely affect weighting terms documents size index larger 
help alleviate problem system automatically detect ocr errors remove 
began mimicking garbage detection rules system added additional rules order find items 
changes done order remove terms liberally shrinking index 
detection rules rules decide string garbage example follows rule string characters length garbage 
rule taken shortened characters 
example number punctuation characters string greater number alphanumeric characters garbage 
rule taken 
example la ignoring characters string different punctuation characters string garbage 
rule taken 
example bjk table number terms removed pruning methods num terms removed prune ocr detect prune prune extended identical characters row string garbage 
rule taken shortened characters 
example number uppercase characters string greater number lowercase characters number uppercase characters total number characters string garbage 
new rule developed saw ocr errors created excessive numbers uppercase characters normally english usually uppercase character term 
real english words appeared uppercase characters acceptable added condition term completely uppercase considered garbage 
example characters string alphabetic number consonants string greater times number vowels string vice versa garbage 
rule taken threshold shortened 
example consecutive vowels string consecutive consonants string garbage 
new rule developed noticed real english words traits rare appeared ocr errors 
example characters string lowercase character uppercase garbage 
rule taken 
example results difference recall precision significantly different ocr error detection turned size index far smaller feature 
removing garbage terms helps improve weighting terms performance decrease small number real words deleted algorithm 
table lists number terms pruned different methods 
numbers count repeated terms example misspelled term appears times counted times 
total number terms entire collection pruning done 
estimate full index trec legal pruning uses gb hard drive space 
ocr error detection saves gb space 
query reformulation problem faced trec legal project deciding queries 
past research done expanding queries methods thesaurus expansion automatic manual query relevance feedback expansion 
expanding queries longer wanted way queries shorter specific better results 
topics released trec short problem summary longer overview problem 
problem summary similar standard web query simple sentence description user wants find 
example documents referencing efforts groups specifically refer cartoons 
standard english list terms removed 
terms documents referencing specifically refer jargon absolutely trying document search 
fact terms queries negative effect recall precision documents matches just terms probably relevant 
solve problem needed custom list prune legal jargon queries 
short length problem summaries information automatically generate list 
decided look longer problem descriptions 
descriptions directly queries large exceeding couple pages length extra information sharply lowered recall precision rates 
filled technical jargon automatically generate list high frequency legal terms 
program read file containing topics 
system kept record running total term frequency query topics 
term appeared times query file added legal term list 
chose threshold manually inspecting file human judgment 
legal terms added list 
table recall comparisons trec legal features queries rank features cos norm prune cos norm prune log norm prune log norm prune sqrt norm prune sqrt norm prune norm prune norm prune norm prune norm prune table precision comparisons trec legal features queries rank features cos norm prune cos norm prune log norm prune log norm prune sqrt norm prune sqrt norm prune norm prune norm prune norm prune norm prune results test query pruning method reran queries different normalization techniques 
shown tables query pruning improved recall rates tested rankings normalization schemes 
runs tables ocr error detection turned feature cause significant difference retrieval performance 
particular high increases recall top rankings cube root normalization 
rank cube root normalization query pruning cube root normalization query pruning resulted recall table recall comparisons trec legal features rank features cos norm root cube root table precision comparisons trec legal features rank features cos norm root cube root improvement precision improvement cube root query pruning cosine normalization query pruning showed improvement recall improvement precision 
recall precision rates rank power normalization query pruning similarly showed high improvement compared query pruning advantage power normalization cosine normalization steep rank 
rank cosine normalization query pruning sharp increase recall precision rates improvement recall cosine query pruning 
higher ranks cosine normalization square root normalization query pruning performed similarly higher recall rates schemes 
trec results trec sent results runs trec legal competition october 
runs done ocr error detection turned query pruning turned 
shown precision rates power normalization runs higher precision rates cosine normalization run 
runs table query pruning turned 
rank improvement precision improvement recall root normalization 
root normalization cosine normalization precision improvement recall 
large improvements precision performance seen rankings 
table comparing cos norm pow norm optimal power trec disks legal legal med cacm cos norm power norm power optimization early experiments power normalization outperforms cosine normalization power 
decided investigate find optimal power new normalization scheme 
built program take data set standard queries run search system data set power normalization number times changing power value run 
system start power equivalent normalization run power increased increments 
done times reached power 
step program record mean average precision returned retrieval system 
mean average precision looking performance system particular rank performance system 
finding mean average precision power graphed plots find maximal point 
power optimization graphs seen figures 
mean average precision optimal point data set power normalization compared mean average precision cosine normalization table 
trec legal queries see optimal power 
trec legal queries optimal power 
trec disks optimal power med optimal power cacm optimal power 
mean average precision power normalization consistently better mean average precision cosine normalization 
interestingly optimal power different data set 
data sets optimal power lies 
curiously optimal power trec legal queries considerably higher optimal power queries 
precise optimal power related characteristics data sets may determined features queries 
range optimal powers narrow finding optimal power data set difficult 
map map map optimal power trec legal trec legal power optimal power trec legal trec legal power optimal power trec disks trec disks power map map optimal power med med power optimal power cacm cacm power chapter albert schweitzer stated acquire knowledge things comprehensible mysterious 
way efficiently organize growing volume human knowledge learning discovering new things quickly impossible 
feasible way access information effectively useless 
thesis detailed number ways improve performance search systems greatly assist retrieval information 
shrinking documents reasonable degree allow long documents small advantage short documents 
time highly relevant short documents chance returned top list matches 
ocr error detection help improving recall precision shrink physical size index 
external information prune useless terms queries find improvement performance significant 
bibliography anderson albert schweitzer 
schweitzer album 
harper row 

user centred evaluation ranking algorithms interactive query expansion 
sigir proceedings th annual international acm sigir conference research development information retrieval pages new york ny usa 
acm press 
susan gauch john smith 
search improvement automatic query reformulation 
acm trans 
inf 
syst 
jing bruce croft 
association thesaurus information retrieval 
proceedings riao th international conference recherche information par ordinateur new york 
allen condit tom julie 
automatic removal garbage strings ocr text implementation 
th world multi conference systemics cybernetics informatics 
porter 
algorithm suffix stripping 
pages 
gerard salton chris buckley 
term weighting approaches automatic text retrieval 
technical report ithaca ny usa 
amit singhal chris buckley mandar mitra :10.1.1.50.9950
pivoted document length normalization 
research development information retrieval pages 
amit singhal gerard salton chris buckley 
length normalization degraded text collections 
technical report ithaca ny usa 
daniel april kontostathis 
text mining operations library environment 
sigcse bull 

