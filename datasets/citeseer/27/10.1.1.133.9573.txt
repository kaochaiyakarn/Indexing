circuits wide window superscalar processors dana henry bradley gabriel loh rahul sami yale university departments computer science electrical engineering dana bradley samir cs yale edu ee yale edu program benchmarks simulations novel circuits indicate large window processors feasible 
redesigned superscalar components large window processor implemented today technology achieve increase geometric mean program speed compared today processors 
processor operates clock speeds comparable today processors achieves significantly higher ilp 
measure impact large window clock speed design simulate new implementations logic components limit critical path large window processor schedule logic wake logic 
log depth cyclic segmented prefix csp circuits reimplement components 
layouts simulations critical paths circuits indicate large window processor clocked frequencies exceeding mhz today technology 
commit logic rename logic run speeds 
measure impact large window ilp compare microarchitectures instruction window wide fetch unit wide issue integer branch multiply float memory units second instruction window wide fetch unit comparable today processors 
simulate different window reuse bypass policies 
simulations show large window processor achieves significantly higher ipc 
performance increase comes despite fact large window processor uses wrap window small window processor uses compressing window effectively increasing number outstanding instructions 
furthermore large window processor pays extra clock cycle bypassing 

difficult design high speed wide issue superscalar processor processor makers abandoning idea 
problem appears logic decode rename analyze schedule instructions clock cycle slows clock cycle result net performance decrease compared processor issues fewer instructions clock 
examples trend include ibm power includes issue processors chip single wider issue processor intel itanium relies vliw techniques reduce amount analysis scheduling done runtime 
countering trend compaq announcement alpha ev include window instructions peak issue rate instructions clock support threads 
clear performance characteristics ev 
give example sort performance mean consider alpha ev uses small windows entries integer float big window see description issue logic ev 
integer window statically assigns instruction group functional units 
requires extra clock cycle data move instructions happen placed far apart compared placed near 
collective effect ev paying large window size cost apparently acceptable spec benchmarks 
expect ev pay relatively window bigger functional units 
ev gain tremendous advantage today technology copper low dielectric constant soi process year making difficult compare study relies aluminum technology available today 
power itanium ev described microprocessor forum 
outlines core processor fetch instructions clock issue instructions clock window instructions 
processor designed technology mid aluminum critical path competitive today processors critical path ns substantially higher ilp program speed compared today processors 
processor relies novel design wake logic multi unit scheduler 
designs enable cyclic reuse reordering buffer new instructions continually entering buffer place oldest retiring ones having circuitry compress instructions reordering buffer 
concentrated redesigning processor compo instruction time ns wake ns schedule instruction send alu wake ns execute broadcast results schedule ns send alu execute steps taken execute dependent arithmetic instructions dependencies 
nents limit execution time dependent arithmetic instructions reordering buffer 
shows steps taken order execute dependent arithmetic instructions bypassing 
example instruction depends result instruction instruction wakes instruction successfully scheduled 
instruction requests scheduled waiting result spice simulations layouts wakeup logic runs ns scheduler logic runs ns 
circuit designs viewed stake ground 
earlier study mips alpha showed circuit implementations superscalar components scale large buffer sizes 
subsequent processors amd begun scalable implementations reimplement components 
may possibly better designs processor components described 
knowledge designs published 
new scalable designs processor components processor components addressed 
redesigned processor data paths control paths 
redesigned logic bypassing results numerous functional units 
program performance study measure system bypasses 
addressed problems scaling memory subsystem 
program study assume entry memory buffer comparable functionality alpha buffer 
believe buffer feasible designed 
redesigned superscalar components draw underlying idea 
exploit sequential ordering instructions wrap reordering buffer attach cyclic segmented prefix csp circuits reordering buffer 
illustrates instruction wrap reordering buffer 
instructions stored buffer wrap sequence 
oldest instruction buffer instruction pointed head pointer 
youngest fetched instruction pointed pointer 
partly motivated previous theoretical results asymptotically optimal superscalar processors 
contrast focuses understanding engineering problems wide issue processors near 
broadcast results shows linear gate delay implementation csp circuit 
csp circuit linear gate delay consists ring operators muxes 
attach ring wrap reordering buffer different associative operators th entry buffer attached input output segment bit csp circuit 
circuit applies operator successive inputs assigns result accumulated far known prefix output 
circuit stops accumulating encounters high segment bit 
example circuit produce defined values instruction typically oldest set segment bit high order cyclic accumulation inputs 
general instructions raise segment bits leading circuit accumulate inputs multiple non overlapping adjacent segments 
shows linear gate delay implementation csp circuit logarithmic gate delay implementations exist 
figures illustrate implementations 
csp implementations identical interfaces functionality logarithmic implementations lead dramatically faster circuits 
rest describes novel circuits vlsi layouts simulations analyzes benefits processor utilizing circuits 
section describes designs wakeup schedule commit rename logic terms linear gate delay csp circuits 
section converts linear gate delay csp circuits faster logarithmic csp circuits compares alternative designs 
section describes analyzes vlsi implementations wakeup schedule commit logic 
section describes program performance study analyzes results 
section discusses implications building wide window processor technologies 

csp circuits superscalar components section shows different superscalar components redesigned csp circuits 
csp circuits redesign commit logic wakeup logic schedule logic rename logic commit logic traditional superscalar processor 
simplify explanation show component redesigned linear gate delay csp circuits 
section convert designs faster logarithmic gate delay csp circuits 
consider commit logic 
commit logic informs instruction earlier instructions buffer tail head cyclic reordering buffer cyclic segmented prefix tail head initial input set cyclic reordering buffer done done done done done done done done done 
oldest 
commit logic previous done entry wrap reordering buffer adjacent linear gate delay cyclic segmented prefix csp 
associative operator commit logic csp 
committed 
shows linear gate delay implementation commit logic attached instruction wrap reordering buffer 
commit logic consists single bit wide csp circuit operator 
gates accumulate successive answer earlier instructions committed multiplexer passes accumulated answer successive instructions stops oldest 
includes example 
example wires carrying high signals displayed bold instructions committed commit logic informed instructions earlier instructions committed 
instructions act output commit logic status 
instructions retire instruction instruction 
wake logic uses csp circuits determine instruction arguments ready latched broadcast bus 
latched arguments remain window entry entry scheduled 
wake logic uses csp circuit logical register defined processor instruction set architecture 
csp circuit operates independently informs buffer instructions readiness logical register 
shows wake logic processor logical registers 
instruction reordering buffer receives ready bits indicating readiness register 
instruction uses multiplexer shown arguments select ready bits corresponding registers needs 
illustrates linear gate delay implementation wake logic register register 
shows values passing wake csp circuit 
wires carrying high signals displayed bold 
operator csp circuit simply wire passes old value 
instruction reordering buffer sets segment bit high writes 
sets input bit high value 
instruction computed value set input bit high instruction 
result instruction informed ready instruction 
schedule logic uses single csp circuit addition operator illustrates scheduler assigns functional units oldest requesting instructions wrap reordering buffer 
buffer entry scheduler simply returns sum older instructions requesting scheduled 
sum saturate number functional units 
requesting entry scheduled functional unit number functional units 
example instructions scheduled functional units respectively 

alternative csp circuits simplicity figures show linear prefix circuits logarithmic gate delay implementations significantly reduce critical path delay 
section describes contrasts different implementations csp circuits logarithmic gate delay window size 
section discuss simulations layouts superscalar components built csp circuits 
csp circuits described section implement function circuit 
linear gate delay csp circuit applied operator order successive inputs logarithmic gate delay csp circuits rely associativity operator applying operator parallel contiguous subsets inputs 
delays due gates varying areas delays due wires 
circuits binary tree ary tree trees prefix postfix 
binary tree circuit shown 
binary tree consists collection binary tree nodes shown grey backgrounds compute segmented prefix way described 
circuit different circuit modified root node tree implement cyclic segmented prefix acyclic segmented prefix 
reordering buffer instructions gate delay binary tree implementation consists operator delays plus mux delays 
delays thought operators muxes going tree followed operators muxes going tree 
write log base tail head done done done done done done cyclic done done reordering buffer wake logic tail head cyclic wake cyclic reordering buffer logic reordering buffer done done done done done done done done done 
writes 
head instruction initializes ready 
ready 
request request tail request head request request request requesting 
head 
scheduler logic request granted 
entry wrap reordering buffer adjacent wake logic processor logical registers 
wake logic logical 
asserted signals shown bold 
scheduler logic scheduling functional units 
faster version tree circuit implemented building ary tree shown 
details ary tree node shown binary root node shown 
delays going ary tree binary tree shall see section compound gate implement ary mux speed circuit 
delays going tree halved 
values going tree arrive precompute values shown bold 
value coming tree arrives passes switched operator bottom ary tree node 
gate delay consists operator delays mux delays 
ary trees implement acyclic prefix known see example scheduler logic seen ary trees implement cyclic prefix 
ary tree idea generalized widths 
example ary node produces circuit gate delay operator mux delays ary node produces circuit operator mux delays 
third approach build trees described exercise 
illustrates method 
main difference circuit literature circuit implements cyclic prefix operation 
gate delay implementation consists operator mux delays 
area increases substantially savings gate delay partly offset increased wire delays traverse area 
disadvantage signals travel way bottom circuit top circuit way back 
consider example scenario segment bits low window entry 
highlights resulting path circuit 
value window entry travel way top circuit stage way nearly bottom circuit subsequent stages 
address doubled wire length problem circuit developed call prefix postfix 
prefix postfix shown combines outputs acyclic segmented prefix acyclic segmented postfix order generate csp 
example highlights datapath computes assuming segment bit high 
prefix circuit computes postfix circuit computes prefix segment bit low root node combines outputs prefix postfix circuits correct order generating answer example illustrates prefix postfix computes output signal traversing height reordering buffer 
requires area trees 
tree area grows height layout width layout 
tree layout get area tree assuming window entries layed linear array study 
area grows log depth cyclic segmented prefix csp binary tree nodes binary root node 
ary tree node ary tree node binary root node csp circuit binary tree 
ary tree binary root node 
ary tree node 
binary root node 
switched operators 
binary tree implementation csp 
ary tree binary root node 
node ary tree 
binary root node 
switched operators 
csp circuit wrap longest path highlighted 
window entries height layout width stage wires move bottom half circuit top half 
advantage half gate delays binary tree 
ary tree slightly greater area gate delays binary tree 

implementation performance having enumerated logarithmic depth prefix circuits describe evaluate vlsi implementations wake schedule commit rename logic circuits compare different implementations 
avoid having long thin reordering buffer assume implementations reordering buffer layed columns buffer entries see 
buffer entry assumed high 
believe overestimate height possibly factor 
decided larger necessary buffer height critical path length estimate high low 
various broadcast circuits connecting window entries functional units run vertically entries commit wake prefix root nodes postfix csp circuit acyclic prefix acyclic postfix root nodes combine results acyclic 
wires particular reduction shown thick lines 
entry entry entry entry entry entry entry entry entry 
entry layout register window ary wakeup logic tree shown 
schedule circuits run columns entries 
circuits wire lengths reflect layout 
include vertical wire lengths traverse height reordering buffer horizontal wire lengths traverse circuits columns 
having settled buffer layout designed superscalar components section csp implementations section 
designs metal layer aluminum cmos technology 
design considered number alternative implementations static domino transmission gate logic 
considered different sizes gate circuit critical path 
consider size ratio transistors compound gate 
different size ratios yield circuits faster ones report 
sized transistors circuits maximum speed program wrote 
program assumes inputs minimum sized includes needed step inverters 
outputs drive minimum sized gates 
program models delay transistor wire piecewise quadratic approximation function fitted match spice simulations technology 
program input consists set allowed sizes gate level description circuit critical path annotated wire lengths 
program starts assigning random size gate computes critical path delay iterates genetic search algorithm reassign sizes 
takes program minutes converge circuit 
estimates choose promising circuits implement 
layed critical paths circuits magic extracted circuits model distributes rc long wires series resistors capacitors 
ran spice circuits sizing program estimates delays consistently spice results 
summarizes table results best de tree tree pre post delay ns area delay ns area delay ns area delay ns area est spice est spice est spice est spice commit wakeup gates schedule circuit delays areas including step wire costs 
circuits rows gates row domino logic 
circuits gates row transmission gates 
signs 
assumes processor logical registers entry wrap reordering buffer layed columns 
processor wake logic includes csp circuits plus multiplexer argument reordering buffer 
processor schedule logic assigns functional units oldest requesting instructions reordering buffer 
column table uses different csp implementation section 
circuits table implemented domino logic driving inverters 
exceptions 
muxes wake logic implemented transmission gates 
row labeled gates describes faster implementations wake logic multiplexers built transmission gates 
table shows critical path delay area estimate best commit wake schedule designs 
designs table reports estimated delays generated sizing program 
table includes delays reported spice circuits critical paths layed magic simulated spice 
table gives estimate component area accounts gates wires 
area estimates metal layers route signals 
layers overestimates area existing aluminum technologies metal layers 
area estimates may somewhat high optimally sized gates outside critical paths remainder section describes implementations logic component greater detail analyzes performance 
wake logic description wakeup logic section simplified view 
wake logic compute readiness argument 
propagates number functional unit producing result 
woken instruction functional unit number read argument unit result bus 
actual prefix circuit simulated passes bit values ready bit plus bits identifying sixteen result generating functional units multiplexers 
circuit csp circuit described values traveling prefix bits wide bit wide 
confirms wake logic components 
fortunately implementations ary tree fastest 
wire area dominates gate area limiting possible overestimate 
resulting wake logic width logical registers fourth height column buffer 
transmission gates domino logic implement multiplexer wake logic speed design 
sized layed simulated spice wake logic critical path transmission gates implement muxes trees implement csp tree node consists transmission gate multiplexer driving inverters 
binary tree implementation runs ns ary tree implementation runs ns spice simulation 
ary tree implementation speeds binary tree implementation ary transmission gate mux fast ary select bits ready advance 
scheduler logic scheduler schedules functional units illustrated 
reordering buffer entries request unit 
oldest requesters receive positive number unit assigned 
rest receive negative 
surprisingly scheduler slowest component 
minimize delay layed critical path scheduler prefix postfix implementation csp unary encoding sum propagating 
spice simulations critical path yielded worstcase delay ns sizing program predicted ns 
study instruction level parallelism separate schedulers schedule integer alus branch units memory units integer multiply units floating point units 
schedulers implemented prefix postfix require total area wakeup logic implemented ary tree 
schedulers width half height reordering buffer 
account width computing wire delays circuits 
scheduler speed compares favorably described palacharla 
palacharla synthetic process extrapolated technologies 
process parameters 
palacharla account wire delays 
linear interpolation delay conclude palacharla predicts scheduler delays ns window 
comparison scheduler circuit functional unit delay ns assume wires length 
assume windows high circuit incurs delay ns assume windows high circuit ns 
palacharla shows schedule functional units type fp adders chaining schedulers give delay ns windows 
scheduler twice functional units windows delay ns 
commit logic layed critical path prefix postfix computes commit bits ns 
commit csp bit wide vlsi area prefix postfix negligible 
rename logic instruction instruction set architecture generates result implement rename logic way wake logic 
pass logical register csp bit address bit functional unit number ready bit 
rename logic supplies entry entire buffer physical register numbers arguments 
physical register numbers implementation reordering buffer addresses instructions write 

performance impact preceding sections show strategy redesigning superscalar components operate large reordering buffer 
circuits implement reordering buffer times larger reordering buffers today commercial processors reaching comparable clock speeds comparable technology 
program performance just depend clock speeds instruction level parallelism ilp uncovered processor 
section try quantify effect larger reordering buffers ilp processors 
simulation environment studies ilp simos instruction level simulator alpha instruction set architecture 
measure instruction level parallelism added timestamping mechanism simos order simulator 
attach time stamp architected register 
example simulating instruction set time stamp ofr plus maximum time stamps ofr andr 
program counter time stamp executing branch zero branches forward instructions zero max time stamp stamp program counter 
executing memory instruction example keep single time stamp memory system effectively serializes store instructions load instruction depend store instruction store different location 
simulation rules compute critical path processor infinite window infinite number functional units memory parallelism branch speculation 
turns modify time stamping rules handle interesting variations 
implemented time stamping rules model delays induced limited fetch width infinite instruction trace cache hybrid branch predictor misprediction penalties limited window size different window policies wrap compressing flushing limited number specialized pipelined functional units assigned oldest requesting instructions order load store unit 
maintaining multiple time stamps state resource simulate number different processors concurrently simulation run 
time stamping allowed model little time overhead processor features 
simulation results assume memory hit cache cache 
developing simulation models cache behavior 
difficult accurately model cache time stamping process instructions serial execution order order executed order processor 
reason difficult accurately model non pipelined functional unit divider 
efficient way model effect limited number functional units window instruction scheduled ready instruction lowest numbered window entry window wrap scheduler 
believe existing processors scheduler 
scheduler worse pure wrap scheduler usually preferable schedule older instruction younger instruction retired sooner 
problem non wrap scheduler wrap window exhibit non monotonic behavior 
difficult write compilers processors exhibit non monotonic behavior 
earliest time stamping processor simulator know implemented tagged token dataflow architecture 
aware time stamping simulation developed independently intel pentium pro processor 
simulated processors simulated different processors time stamping simulator 
processors implement instruction set 
processor called resembles today commercial processors provides baseline study 
instruction fetch width single instruction reordering buffer shared instructions 
processor fetches unaligned block statically adjacent instructions time 
issue instructions non monotonicity processor situation adding instruction inner loop program speed program 
common hybrid branch predictor see characteristics predictor selection bit counters kb local predictor bit counters kb global predictor gshare bits bit counters kb entry jump prediction stack entry load store unit instruction latencies integer alu non multiplication cycles integer multiply branch memory floating point non division fp single precision division fp double precision division entry window wide fetch fetch taken branch integer alus branch units memory ports integer multiplier floating point units time 
functional units numbers latencies described 
second processor simulated called approximates processor believe built redesigned superscalar components advances 
processor wakes schedules issues instructions single instructions reordering buffer 
trace cache processor fetches unaligned dynamic sequence instructions time 
fetching instructions incurs delays mispredicted branch encountered branch 
issue instructions time 
functional units numbers latencies described 
processors share number characteristics 
processors hybrid branch predictor dynamically chooses branch predictors incurs cycle penalty branch misprediction 
branch predictor tables size processors 
may larger branch predictor sense larger processor 
fully pipelined functional units infinite size caches 
processors differ important aspects structure reordering buffer bypasses 
processor uses compressing reordering buffer uses wrap reordering buffer 
compressing reordering buffer better entries 
clock cycle compressing buffer retires instructions finished executing compresses remaining entries pushing top buffer 
clock cycle unused entries ready new instructions 
contrast wrap buffer refill unused entry older instructions processor characteristics entry window wide fetch fetch mispredicted branch integer alus branch units memory ports integer multiplier floating point units finished 
circuits described operate compressing buffer just wrap know compress instruction reordering buffer quickly 
reason assumes wrap buffer 
suffers lack bypassing 
today processors bypass paths allow dependent instructions issue back back 
functional units assume require additional clock cycle certain types dependent instructions 
assume instructions multiple cycle execution latencies overlap execution results paths allowing dependent instructions issue delay 
instructions cycle execution latencies precharge results paths dependents scheduled 
result cycle instructions effectively cost cycle delay 
simulation results ran number simulations order better understand performance performance loss associated wrap buffer lack bypassing 
figures shows results simulations 
shows average instruction level parallelism spec cpu benchmarks measured time stamping simulator 
benchmarks compiled alpha processor digital compiler invoked cc migrate std ifo om fact schedule commit logic run faster compressing buffer eliminating segment bits 
minimum latency minimum latency ev fetch wrap compress flush wrap compress flush ipc int go gcc compress li ijpeg perl vortex fp tomcatv swim su cor hydro mgrid applu turb apsi fpppp wave benchmarks instructions measured instructions 
standard vendor supplied compiler option compiling spec 
order processor code optimized order features 
highlighted figures correspond described processors despite limitations buffer substantially outperforms buffer benchmarks relatively lit tle parallelism wide window processor shows significant performance gain 
remaining columns vary structure reordering buffer bypassing policy 
columns labeled wrap compress report performance wrap reordering buffer compressing reordering buffer respectively 
columns labeled flush strawman architecture window fills instructions retire instruction run 
compressing window buys small amount additional performance flushing window slower 
columns labeled minimum latency force instructions latency clock cycle order model lack bypassing processor 
increasing latency integer unit incurs fairly significant overhead outweigh benefit large reordering buffer 
comparison report right column average instruction level parallelism achieved real machine alpha gs mhz ev rightmost column 
derived numbers measuring number instructions executed spec benchmark dividing clock speed published runtimes 
ipc estimate published cpu results compiled newer compiler simulated ipc processor variations 
instruction counts different 
ipc resemble ipc processor 
comparing ev conclude simulation reasonably model performance benchmarks gcc compress ijpeg predicts higher ipc benchmarks go swim su cor achieved 
expect variables contribute inaccuracy 
processors differ number significant ways 
integer window instructions fp window instructions clustering mechanism increase latencies 
hand window instructions 
example showed performance go program sensitive window size holding constant entry window may better split entry window 
ipc numbers match fairly closely go 
general fpu fp adder fp multiplier general purpose memory ports window pipelined divider 
addition fails model cache misses including traffic 
isolate impact trace cache performance ran spec benchmark small processor trace cache big processor non trace cache 
shows impact trace cache 
surprisingly trace cache responsible relatively small part speedup 

studies done aluminum process obsolete 
scaled layout copper low technology process spice time ns scheduler 
minimum latency minimum latency ev fetch wrap compress flush wrap compress flush int go gcc compress li ijpeg perl vortex fp tomcatv swim su cor hydro mgrid applu turb apsi fpppp wave benchmarks instructions measured instructions 
simulated ipc processor variations 
minimum latency minimum latency gs gcc gcc wrap compress flush wrap compress flush spec base gcc gcc benchmarks instructions measured instructions 
impact trace cache 
runs labelled gcc traditional cache runs trace cache model 
conclude processors wide windows functional units may soon practical 
architectural ideas clustering smt trace caches largely orthogonal results 
example processors clustered size windows larger 
patt arguing years best chip transistors build single large uniprocessor 
results suggest processor built 

thomas cormen charles leiserson ronald rivest 
algorithms 
mit electrical engineering computer science series 
mit press cambridge ma 
james farrell timothy fischer 
issue logic mhz order execution microprocessor 
ieee journal solid state circuits may 
dana henry bradley vinod viswanath 
processor asymptotically scalable superscalar microarchitecture 
twentieth anniversary conference advanced research vlsi ar vlsi pages atlanta ga march 
ee yale edu papers 
ps gz 
kessler 
alpha microprocessor 
ieee micro march april 
nathaniel 
performance case study ultrasparc processor 
master thesis massachusetts institute technology department electrical engineering computer science june 
ftp theory lcs mit edu pub cilk man ms thesis ps gz 
bradley dana henry gabriel loh 
comparison scalable superscalar processors 
eleventh acm symposium parallel algorithms architectures spaa pages st malo france june 
early version available memo january yale university computer architecture engineering group prospect street new haven ct ee ale edu papers ps gz 
scott mcfarling 
combining branch predictors 
technical note tn digital western research laboratory university avenue palo alto ca june 
nikhil hicks 
id world manual lisp machines 
technical report massachusetts institute technology laboratory computer science computations structures group 
supersedes id world user manual computations structures group memo june 
palacharla norman jouppi smith 
complexity effective superscalar processors 
proceedings th annual international symposium computer architecture isca pages denver colorado june 
acm sigarch ieee computer society 
www ece wisc edu jes papers isca ss ps 
see 
palacharla norman jouppi james smith 
quantifying complexity superscalar processors 
technical report cs tr university wisconsin madison november ftp ftp cs 
wisc edu sohi complexity report ps sanjay patel daniel holmes friendly yale patt 
critical issues regarding trace cache fetch mechanism 
technical report cse tr computer science engineering university michigan may 
www eecs umich edu hps hps html 
yale patt sanjay patel marius daniel friendly jared stark 
transistors uniprocessor chip 
computer september www computer org computer abs htm 
mendel rosenblum edouard bugnion scott devine stephen alan herrod 
simos machine simulator study complex computer systems 
acm transactions modeling computer simulation january 
eric rotenberg quinn jacobson jim smith 
trace processors 
proceedings th annual international symposium microarchitecture micro pages research triangle park north carolina december 
ieee society tc micro acm 
spec standard performance evaluation 
spec cpu performance benchmarks 
drive suite va www org 
dean tullsen susan eggers henry levy 
simultaneous multithreading maximizing chip parallelism 
proceedings nd annual international symposium computer architecture isca pages santa margherita ligure italy june 
acm sigarch ieee computer society 
computer architecture news may 
ben verghese 
simos alpha www ch digital com wrl projects simos february 
neil 
principles cmos vlsi design systems perspective 
vlsi systems series 
addison wesley 
