intrinsically motivated reinforcement learning promising framework developmental robot learning andrew stout george andrew barto department computer science university massachusetts amherst stout barto cs umass edu primary challenges developmental robotics question learn represent increasingly complex behavior self motivated open ended way 
barto singh barto singh singh barto algorithm intrinsically motivated reinforcement learning strives achieve broad competence environment manner incorporating internal reward build hierarchical collection skills 
suggests emphasis task general self motivated hierarchical learning intrinsically motivated reinforcement learning obvious choice organizing behavior developmental robotics 
additional preliminary results gridworld abstraction robot environment advocate layered learning architecture applying algorithm physically embodied system 
primary challenges developmental robotics question learn represent increasingly complex behavior self motivated open ended way 
argue equipped advances pertaining temporal abstraction hierarchy reinforcement learning rl provides promising framework learning representing hierarchical skills 
engaged ongoing research intrinsically motivated reinforcement learning approach introduced barto singh primary reinforcement signal generated agent allowing develop broad competence environment open ended fashion 
applied na robotic tasks rl methods struggle continuous high dimensional state action spaces insufficient learning experience 
cases simpler elegant solution layer learning rl takes place raw sensor space instance learned economical representation space facilitates rl 
copyright american association artificial intelligence www aaai org 
rights reserved 
advocate layered approach learning architectures developmental robotics advocate intrinsically motivated rl barto singh singh barto especially promising approach developmental learning preliminary results applying intrinsically motivated rl gridworld abstraction robot domain 
section briefly review rl layered learning 
review success integrating rl behavior robotics distributed topological map intermediary layer 
review algorithm intrinsically motivated rl simple gridworld experiment illustrating potential 
discuss benefits approach advocate layered architecture bringing approach bear embodied systems directions 
background reinforcement learning reinforcement learning sutton barto aims solve problem behaving agent learning approximate optimal behavioral policy interaction environment 
generally takes form learning maximize numerical reward signal time environment 
reward signal learning feedback obtained environment rl falls unsupervised learning signal supervised learning signal indicating correct action suited developmental robotics 
rl algorithms adapt dynamic programming methods focus relevant parts value space behavioral trajectories 
state state action values estimated experience backed compute approximately optimal policies actions maximize expected long term reward 
markov decision process popular formalism rl stage agent set possible states chooses set available actions action presumably stochastically influences agent subsequent transition state receiving reward process 
policy maps states probabilities executing action state 
options options precup sutton precup singh principled framework temporal abstraction rl 
briefly option roughly analogous subroutine initiation set states invoked internal policy mapping states actions probabilities execution termination condition mapping states probability option terminating state 
option invoked follows internal policy termination allows option considered temporally extended action freeing agent needing choose action step 
option policy may call option creating elegant mechanism behavioral hierarchy 
options framework solid theoretical foundation extending markov decision processes semi markov decision processes barto mahadevan components options framework particularly important algorithm option models probabilistic descriptions effects executing option 
approximately learned experience allow stochastic planning extended primitive step actions higher levels abstraction 
intra option learning methods allow internal policies options updated simultaneously regardless option executing 
options options hand designed engineer advance 
clear dynamically creating learning options desirable ability researchers proposed methods doing 
im sek barto mcgovern 
falls category unique creating options tailored specific task algorithm creates options intrinsic motivation 
layered learning attractive properties researchers added rl capabilities robots 
applying rl directly robot large sensor space leads convergence problems due violations markov assumption sheer space 
solution layered learning provide suitably problem space rl solve efficiently 
widely accepted layered incremental approach designing robot control systems brooks works practice interaction layered parallel control elements produce interestingly complex adaptive behavior pfeifer scheier 
token argue learning elements layered robot control system way static control elements 
examples layering rl top behavioral basis 
huber grupen 
natural extension add additional learning layers 
layered learning stone utgoff means lowerlevel learning elements learn useful structures discretizations behavior help higherlevel learning feasible allows interaction learning elements generate complex adaptive behavior 
example approach described layered distributed asynchronous reinforcement learning model developed hayes 
rl layered top learned topological map layered top reactive behavioral substrate robot perform puck foraging artificial arena 
reactive behavioral substrate created conditions topological map learned easily topological map served keep state space small task relevant 
coupled asynchronous parallelizable updates took advantage fact computation faster action embodied domains allowed robot rl element converge real time decisions 
worked learning dynamics displayed traditional rl task specific externally imposed reward function achieve certain behavior additional learning took place 
elegance layered architecture dynamics addressed level rl layer lower behavioral topological levels granted turn attention rl system designed display task general open ended learning dynamics emphasized developmental robotics approach 
intrinsically motivated reinforcement learning barto singh introduce model intrinsically motivated reinforcement learning employing options framework 
model grounded elaboration traditional conception rl environment factored external environment environment internal agent 
internal environment provides reward signal rl system 
note elaboration allows rewards external environment simply internal environment 
principle 
recognize practice things rarely quite simple 
traditional approach rl reward function tailored specifically task hand navigating maze winning backgammon example crafting reward function require significant ingenuity 
notion intrinsically motivated rl critic internal environment includes agent motivational system motivational system sophisticated general need redesigned specific task agent undertakes 
driven task general intrinsic motivation agent builds hierarchical collection skills effect achieving broad competence environment 
skills applied specific task agent finds called learn 
possibilities source intrinsic motivation including surprise novelty huang weng learning progress kaplan 
far neuroscience dopamine neurons horvitz stewart jacobs direct inspiration implemented model intrinsic motivation barto singh singh barto experiments follow path plan explore sources intrinsic motivation 
emphasis task general self motivated hierarchical learning intrinsically motivated rl obvious choice developmental robotics 
experience intrinsic motivation hierarchical rl preliminary experimental results date gridworld 
presents application approach domain intended stepping stone environment barto singh real robotic domain 
discrete deterministic domain robot prior intrinsically motivated rl believe appropriate support layers learning architecture learned topological map approach adaptable real robotic applications 
describe specifics intrinsically motivated rl algorithm closely algorithm singh barto describe experiment illustrating behavior 
algorithm algorithm intrinsically motivated rl departs traditional rl intrinsic reward learn collection useful skills 
respects algorithm combination established algorithms hierarchical rl 
description organized differently similar singh barto details 
saliency implementations depend hardwired salience certain stimuli events agent environment bears repeating larger idea intrinsically motivated rl depend particular model intrinsic motivation 
example experiments described changes light sound intensity considered salient 
consider notions saliency roughly analogous saliency certain stimuli smell food movement potential threat hardwired evolution nervous systems animals nature 
stimuli necessity specific animal ecological niche general respect specific settings niche respect specific tasks skills animal undertakes 
skills time agent experiences salient event creates initializes option bring event 
event option initiation set initialized include state just prior salient event termination probability state event occurred initialized 
addition option model initialized event option estimating probability option terminating state cumulative reward executed state 
agent gains experience option initiation set grows include states lead states current initiation set agent experiences salient event novel state termination probability option event set 
algorithm updates option policies option models options simultaneously intra option learning 
initialized option available action options behavioral top level policy provides elegant natural way building hierarchy skills 
intrinsic reward implementation intrinsic reward associated salient stimuli inspired response dopamine neurons novelty horvitz stewart jacobs 
intrinsic reward occurrence salient event proportional prediction error event learned option model event 
event occurs occurs previously context intrinsic reward initially high surprising interesting 
event option policies updated respect extrinsic reward signal hardwired reward successfully terminating option behavioral policy incorporates intrinsic reward update 
surprise drives agent try bring event 
agent repeatedly better bringing predicting occurrence event 
event predictable rewarding agent gets bored 
algorithm naturally handles extrinsic reward importantly depend 
aspect algorithm similar schmidhuber early curiosity schmidhuber 
behavior agent behaves greedy policy respect behavioral action value function 
behavioral action value function learned combination learning smdp planning maps states actions initially primitive actions options included available expected long term reward 
experiment preliminary experimental results demonstrating performance algorithm 
assume existence lower layers learning sufficient supporting high level representation state action spaces 
assumption allows test ideas simple gridworld focus high level behavior wish demonstrate 
believe layered approach successfully demonstrated hayes discussed gives cause believe temporary abstraction justified recognize danger assumptions 
integrating intrinsically motivated rl layered learning architecture physically embodied robot inevitably challenges addressed believe detracts promise intrinsically motivated rl layer driving learning developing robots 
experimental setup gridworld abstraction environment built aibo scale colleagues experimentation ideas aibo robots 
world consists rooms door 
push panels walls pushed turn lights open close door 
second room contains charger 
robot perceives location orientation assume provided topological map instance list visible objects light intensity various sounds 
move forward rotate clockwise counterclockwise approach object see push push panel charge 
changes light sound hardwired salient events 
robot starts random location left room dark 
see push panel see push panel door turned light pushing push panel 
pushing push panel open door causing alarm ring 
facing charger may charge causes bell ring earns extrinsic reward 
small extrinsic punishment time step cost living 
steps robot kidnapped experiment reset initial conditions robot placed random location left room 
world designed include objects engaged varying levels difficulty 
engaging light gridworld environment 
switch easy engaging charger requires number intermediate steps 
clearly robot learned skills turn light open door learning engage charger 
results barto singh results applying intrinsically motivated rl algorithm smaller gridworld 
show expected designed agent gains competence learning achieve easy salient stimuli building skills achieve difficult stimuli 
agent encounters salient stimulus receives high intrinsic reward learns predict event level intrinsic reward drops encounters event unexpectedly 
ongoing results report similar preliminary nature 
shows record salient event occurrences course experiment 
robot quickly discovers learns predict turning light 
learns open close door soon learns charge ringing bell behavior persists rewarding 
plots number steps initiation testing period achievement salient events 
initial period exploration visible steps due optimistic initial values 
steps robot starts consistently achieve light events roughly steps discovers open door ring bell 
second period exploration ensues experiment see robot learned consistently turn light open door ring bell efficiently 
note learns turning light closing door worth effort 
discussion believe intrinsically motivated reinforcement learning features appealing approach developmental robotics clear remains done demonstrate viability light light open door close door bell intrinsic reward salient events time steps light light open door close door bell intrinsic reward salient events time steps records intrinsic rewards occurrence salient events 
left plot shows steps experiment illustrating exponential drop intrinsic reward salient events predictable 
right plot shows full steps experiment detail small intrinsic rewards predicted salient events indicating sustained charging behavior 
regular occurrence light event due periodic reset experiment 
approach 
step thoroughly demonstrate algorithm performance gridworld 
accomplished hope adapt algorithm suitable application real robot 
propose adopting layered approach discussed order provide intrinsically motivated rl layer tractable problem space 
challenges applying rl real world issue efficiency 
consideration efficiency far respect intrinsically motivated rl obvious improvements eligibility traces 
discussed mismatch computation time rl update time generally takes robot take action changes efficiency dynamic dramatically may possible perform dynamic programming point convergence decisions hayes 
directions specific particular challenges developmental robotics 
shortcoming current model intrinsic motivation intrinsic reward failure predict salient event 
kaplan schmidhuber schmidhuber observed lead undesirable behavior environments involving areas dynamics difficult impossible predict 
argued better approach note learning fruitful zone proximal development areas learnable predictable learned unpredictable impossible learn 
mentioned briefly just sources intrinsic motivation hope explore 
worth considering level primitive actions engineered considered innate 
assumes relatively high level behavioral basis developmental robotics community concentrates developing lowerlevel sensorimotor coordination 
clear built nature mammals walk hours born clear learning takes place refine sensorimotor coordination berthier rosenstein barto moving learning hierarchy removes engineer bias blank kumar leaves room online adaptation 
extent intrinsic motivation important low level learning open important question hope address 
discussed algorithm intrinsically motivated reinforcement learning argued characteristics appealing developmental robotics 
intrinsic motivation drives system learn gain broad competence task general manner hierarchical rl framework provides steps stimulus time steps light door open charge bell door closed light steps achievement salient event tested steps 
achievement occurred steps graphs upper limit 
progressive learning increasingly complex skills seen 
elegant means building previous learning open ended fashion 
intrinsically motivated rl suited situated learning currently formulated suited learning directly high dimensional continuous problem space physical embodiment involves 
advocated layered approach learning architectures developmental robotics lower layers learning provide tractable space upper layers 
remains done believe ingredients hold great promise developmental robot learning 
acknowledgments supported part subcontract rutgers university computer science department award number hr darpa 
stout gratefully acknowledges college lockwood fellowship 
barto mahadevan 
advances hierarchical reinforcement learning 
discrete event dynamic systems 
barto singh 
intrinsically motivated learning hierarchical collections skills 
proc 
inter 
conf 
developmental learning 
berthier rosenstein barto 
approximate optimal control model motor learning 
psychological review 
blank kumar 
bringing robot fundamental mechanisms creating self organizing architecture 
proc 
growing artifacts live workshop simulation adaptive behavior 
brooks 
robust layered control system mobile robot 
ieee journal robotics automation 
im sek barto 
relative novelty identify useful temporal abstractions reinforcement learning 
proc 
st inter 
conf 
machine learning 
horvitz stewart jacobs 
burst activity ventral dopamine neurons elicited sensory stimuli awake cat 
brain research 
huang weng 
novelty reinforcement learning value system developmental robots 
proc 
nd inter 
workshop epigenetic robotics modeling cognitive development robotic systems 
huber grupen 
learning coordinate controllers reinforcement learning control basis 
proc 
th int 
joint conf 
artificial intelligence 
kaplan 

motivational principles visual know development 
prince kozima bullock eds proc 
rd inter 
workshop epigenetic robotics modeling cognitive development robotic systems 
kaplan 

maximizing learning progress internal reward system development 
pfeifer steels kuniyoshi eds embodied artificial intelligence 
springer verlag 
hayes 
architecture behavior reinforcement learning 
adaptive behavior 
mcgovern 
autonomous discovery temporal abstractions interactions environment 
ph dissertation massachusetts amherst 
pfeifer scheier 
understanding intelligence 
mit press 
precup 
temporal abstraction reinforcement learning 
ph dissertation massachusetts amherst 
schmidhuber 
curious model building control systems 
proc 
international joint conference neural networks singapore volume 
ieee 
schmidhuber 
possibility implementing curiosity boredom model building neural controllers 
meyer wilson eds proc 
international conference simulation adaptive behavior animals animats 
mit press 
singh barto 
intrinsically motivated reinforcement learning 
advances neural information processing 
stone 
layered learning multiagent systems winning approach robotic soccer 
mit press 
sutton barto 
reinforcement learning 
cambridge ma mit press 
sutton precup singh 
mdps semi mdps framework temporal abstraction reinforcement learning 
artificial intelligence 
utgoff 
layered learning 
neural computation 
