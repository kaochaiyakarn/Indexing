stacked generalization david wolpert complex systems group theoretical division center non linear studies ms lanl los alamos nm tweety lanl gov 
performed auspices department energy 
la ur introduces stacked generalization scheme minimizing generalization error rate generalizers 
stacked generalization works deducing biases generalizer respect provided learning set 
deduction proceeds generalizing second space inputs example guesses original generalizers taught part learning set trying guess rest output example correct guess 
multiple generalizers stacked generalization seen sophisticated version cross validation exploiting strategy sophisticated cross vali dation crude winner takes combining individual generalizers 
single generalizer stacked generalization scheme estimating correcting error generalizer trained particular learning set asked particular ques tion 
introducing stacked generalization justifying presents numer ical experiments 
demonstrates stacked generalization improves set sepa rate generalizers nettalk task translating text phonemes 
second demonstrates stacked generalization improves performance single surface fitter 
ex evidence literature usual arguments supporting cross validation ab justifications real world gener alization problem version stacked generalization minimize general ization error rate 
ends discussing variations stacked generalization touches fields chaos theory 
key words generalization induction combining generalizers learning set pre processing cross validation error estimation correction 
concerns problem inferring function subset subset parent function set samples function learning set 
subset input space subset output space 
question input space vector value 
algorithm guesses parent function basing guess learning set vectors read parent function called generalizer 
generalizer guesses ap output question parent function infers learning set 
simplicity analysis holds positive integer explicitly indicated oth take 
am usually assuming noiseless data 
means best guesses inputs elements learning set known provided learning set 
building system guess properly elements learning learning set trivial achieved simply building look table 
difficulties arise insists look table implemented odd way feedforward neural net 
questions interest outside learning set 
examples generalizers back propagated neural nets rumelhart land holland classifier system holland rissanen minimum description length principle rissanen schemes attempt exploit oc cam razor analyzed wolpert 
important examples memory reason ing schemes stanfill waltz regularization theory poggio similar schemes overt surface fitting parent function learning set wolpert wolpert wolpert farmer omohundro 
primarily interested generalizers capable guessing output number occur output value learning set 
conventional classi id quinlan bayesian classifiers schlimmer stagger system dietterich don flexibility respects valid examples gen 
introduces stacked generalization technique purpose achieve generalization accuracy opposed learning accuracy high possible 
central idea better simply list guesses parent function con sistent learning set done pac style learning dietterich valiant example 
sample sample techniques try find best guesser par ent functions try find best combination parent functions 
creating partition learning set training part partition observing behavior part try deduce correct biases generalizers respect learning set 
loosely speaking addition finding theories consistent set data means partitions data construct best theorist whichever theory prefers 
different ways implement stacked generalization 
primary implemen tation technique combining generalizer single generalizer technique improve single generalizer 
real world learning set possible generalizers extrapolate 
implicitly problem address multiplicity possible generalizers 
algorithmic schemes addressing problem including particular non parametric statistics techniques cross validation efron stone generalized cross validation li bootstrapping efron winner takes strategies 
schemes viewed mappings take arbitrary generalizer learning set input give output estimate average generalizing accuracy generalizer unknown parent function generated learning set 
mapping simply picks highest estimated gener alization accuracy mapping uses generalize 
contrast stacked generalization provides strategy situation winner takes 
loosely speaking strategy combine choose 
done example output guesses input components points new space generalizing new space 
see 
winner takes strategies shown special case stacked generalization manner doing generalization new space means global fit highly restricted hyperplane 
accordingly stacked generalization viewed sophisticated version non parametric statistics techniques cross tion 
particular usual arguments supporting techniques apply strongly stacked generalization argued generalization classi fication problem invariably generalizer applied problem maximize generalization accuracy stacked generalization single generalizer 
addition viewing extension concepts cross validation stacked general ization viewed means collectively estimate generalizing biases respect particular learning set filter biases 
description particularly apt variation stacked generalization appropriate single generalizer 
situation stacked generalization overtly scheme esti mating errors generalizer working particular learning set correcting errors 
see 
section presents rigorous definition stacked generalization discusses expected improve generalization accuracy 
section ii presents experimental examples stacked generalization 
improve formance single generalizer explicit surface fitting algorithm 
second improve individual performance generalizers modified version text phoneme data set went making nettalk stanfill waltz wolpert jones sejnowski rosenberg 
section iii discusses myriad variations extensions stacked generalization ways approached theoretically heuristics concerning scheme behavior 
impossible investigate great depth theoretical empirical concerning stacked generalization single 
intended serve broad idea stacked generalization variations 
stacked generalization works full rigor provide mathematical definition generalizer 
de fine process stacked generalization giving rigorous definition cross validation way 
unfortunately nature stacked generalization presenting full generality full rigor appear complicated really section examples provided mitigate effect 
example way stacked general ization multiple generalizers second example way single gen 
generalizers generalizer mapping learning set pairs question guess 
full generality guess applications replace generalizer making guesses cartesian product separate generalizers making guesses accordingly taken equal 
see wolpert 
mapping equivalent count ably infinite set functions function possible value takes arguments learning set input learning set output question takes arguments see wolpert 
implicitly defined definition generalizer algorithm 
case back prop example 
strictly speaking back propagation aren single valued depend random initial choice weights 
difficulty little consequence avoided explicitly averaging set initial choices weights example 
generalizers generalizers explicitly fitting surface possible write directly 
colloquially says generalizer pro vided argument list taught trained element learning set consisting elements asked question guesses corresponding output 
generalizer returns appropriate equal learning set say generalizer reproduces learning set 
scenario considered learning set elements living space set generalizers re set separate sequences functions 
example learning set consist elements form output integers 
correct generalization guess parent function output sum input components 
example id back propagation global fitting polynomial variables minimal order local surface fitting technique 
classifier see know id gen correctly parent function attached de pre processor 
similar difficulties affect back propagation see wolpert 
course known certainty provided learning set entire par ent function 
follows bit free symbols write example really mean output generalizer th function number elements provided learning set argument list enumerated ele ments followed question similarly components dimensional vector refer input space projection point full input output space input component point 
refer nearest neighbor point space 
really mean nearest neighbor point measured input space projection full space 
cases context meaning clear 
ii partition sets cross validation step employing stacked generalization choosing set partitions splits usually disjoint sets 
label set partitions ij 
set partitions called partition set 
example cross validation partition set cvps consists single element corresponding consists rest 
requirement distinctness means set covers 
pair cvps illustrated figures 
define bootstrap partition set similar way cvps roughly speaking elements chosen randomly way ex cover duplications 
example partition set xiang dong divisor consists elements cvps 
form disjoint cover partition sets type particularly useful takes long time train 
winner takes technique cross validation straight forward way cvps map generalizer learning set estimate generalization error rate generalizing 
intuitively estimates generalization accuracy seeing generalizer guess part full learning set taught rest 
rigorously works cvps calculating average error guessing output corresponds input component taught remainder cross validation error estimate respect defined input component output component technique minimal cross validation error says set candidate generalizers learning set generalize generalizer simplicity rest consider cvps set con sists element 
iii stacked generalization define space inhabited original learning set level space 
generalizer generalizing directly level space called level generalizer original learning set called level learning set 
partitions look set numbers determined subset working partition 
typically numbers things guesses taught question input component element input component input component element vector input space connecting input component nearest neighbor take set numbers view input component point space corresponding output value point calculated output component corresponding input component 
space called level space 
partitions points level space 
points known reduced level learning set 
figures level learning set 
wish generalize operating generalizer level space 
ways 
common idea take question level space pass transformations produced input components level learning set get level question level input space answer level question generalizing level learning set 
level guess transformed back level guess 
said trans formation determined output components calculate put components level learning set 
generalizing process form known stacked generalization 
process iterated resulting levels mul tiple 
ll just concerned levels stacked generalization described 
important note aspects stacked generalization black art 
example currently hard fast rules saying level generalizers level generalizer numbers form level input space practice usually content rely prior knowledge hopefully intelligent guesses set details 
course black art occurs rest machine learning 
example practice researchers currently rely prior knowledge problem domain hopefully intelligent guess generalizer configure 
iv example stacked generalization case multiple generalizers example stacked generalization assume element learning set points living set generalizers question mentioned fore re restricting cvps 
partition set gives sets different subset elements remaining element 
numbers construct input components element level learning set guesses taught particular input component corresponding question 
words particular point level learning set components input projection set numbers input component 
see figures 
output component point level learning set directly output component corresponding partitions elements level learning set just level learning set 
point level learning set dimen sional input component 
guess level question convert level question 
way level learning set find guess response question taught full learning set 
guesses give input coordinates question level space answer ques tion simply run generalizer level learning set ask level question 
guess level output correspond level question taken guess entire stacked generalization process level output correspond original level question 
procedure sounds complicated 
really isn example take parent function output sum input components mentioned section 
learning set consist input output pairs sampled noise parent function 
label input output pairs example consists pairs 
level generalizers single level generalizer 
level learning set input output pairs input components input components output component possible values 
level space dimensions input output 
example member level learning set corresponding output component input component 
level question 
answer guess answer training asking question guesses level generalizers trained asked question guess implementation stacked generalization determined com guesses original 
combined depends level general 
example consider level generalizer fit level learning set single global hyperplane form output value input dimension 
global hyperplane fits possible values choose hyperplane fit smallest rms euclidean error fitting level learning set 
language pattern recognition generalizer rule find single feature input space component greatest correlation correct answer guess 
level generalizer re sults winner takes strategy 
determination finding minimal rms error predicting part level learning set rest 
error calculated cross validation partition set 
fact moment thought shows stacked generalization simple minded level generalizer exact generalizing process technique minimal cross validation 
mentioned cross validation seen just relatively uninteresting special case stacked generalization corresponding extraordinarily dumb level generalizer 
naive example level generalizer independent level learn ing set guess level question averaging components question 
extraordinarily dumb level generalizer 
guesses common currently scheme second winner takes schemes combining generalizers stacked generalization level generalizer exactly equiva lent simply averaging guesses 
marginally sophisticated way combining generalizers form weighted average guesses 
equivalent having level generalizer scheme fit level learning set single global hyperplane 
view various commonly schemes combining generalizers simply special cases stacked generalization 
schemes implicitly confronted level learning set decide generalize 
problem generalize level learning set just normal generalization problem principle different 
just generalization problem sense dumb generalizers generalize level learning set 
noticeable feature commonly schemes combining level generalizers precisely lack level generalizers 
just generalization problem expect improved performance extremely improved performance dumb level generalizers replaced sophisticated generalizers 
example stacked generalization case generalizer priori reason numbers level input space guesses set generalizers 
priori reason output compo nents level learning set directly output components illustrated example stacked generalization set consists single element example stacked generalization improve behav ior single generalizer opposed means combining set generalizers 
example illustrated 
similar example illustrated 
cvps level input space dimension 
numbers defining level input space coordinates level question input components input coordinates vector connecting nearest neighbor question level learning set nearest neighbor question 
single generalizer doesn way contribute level input space values 
comes indirectly level space outputs output compo nent point level space error estimate thereof case trying guess output corresponds associated level question 
example forming level learning set set output value corresponding particular partition input component output component 
guess output correspond question constructed level learning set train ask store resultant guess call feed level input space vector connecting nearest neighbor level space level input coordinates 
generalizing level space get guess level output correspond level question get estimate difference correct guess 
subtract half error estimate get number final guess output correspond original question procedure multiply constant half just conservative 
note multiplicative constant gives knob determining re stacked generalization 
constant equals guessing equivalent level generalizer straight 
value constant increased guessing stacked tion 
intuitively implementation stacked generalization single generalizer means estimating actual error just average value errors provided gen particular question particular learning set 
works seeing generalizer errs taught part learning set asked question remainder learning set information serves level learning set level generalizer generalizes information estimate error original level generalizer taught entire level learning set 
error estimate usually fraction subtracted level generalizer guess arrive im proved guess 
information send level input space determines error estimates allowed vary 
example addition depending strongly level question re assuming errors level generalizer strongly dependent nearest neighbor question elements learning set 
rationale varying nearest neighbor question pronounced affect generalization accuracy level generalizer especially level generalizer local surface fitter 
interesting note special case single generalizer stacked generalization ex equivalent running level generalizer 
level input values simply level question input component case 
furthermore level outputs level outputs transformation output component output components level space identity mapping 
note level generalizer 
fact entire stacked generalizer structure exactly equivalent running level generalizer directly level learning set level question 
just stacked generalization corresponds extension cross validation multiple generalizers single generalizer stacked generalization corre sponds extension generalizer directly 
ii 
experimental tests stacked generalization section reports results numerical experiments indicate stacked generalization improve generalization accuracy 
experiments relatively con toy problems 
idea pedagogical heuristic tools toy problems rumelhart mcclelland 
noted appears little degradation performance stacked generalization applied messy real world problems 
example gustafson reported amounts stacked generalization beats back propagation hydrodynamics problems gustafson 
similarly number researchers reported efficacy simply averaging set generalizers example aspects problem predicting protein struc ture schulz 
reported efficacy amounts stacked generalization variant partition set radial basis function generalizer time series prediction 
progress alan lapedes rob farber suggests stacked generalization combine id author metric wolpert problem predicting splice junctions dna sequences gives accuracy better techniques preliminary evidence indicates implementation stacked generalization best known generalization method problem 
experiment simpler numerical experiments involved stacked generalization im prove performance single generalizer 
level input space experiment dimensional 
problem explicitly surface fitting parent functions simple high school math type functions level generalizer linearly connect dots learning set input output surface serves guess parent function local linear technique farmer 
see illustration level generalizer 
experiment stacked generalization architecture exactly ex ample section augment performance single generalizer see 
equals problem level input space dimensional 
level generalizer metric described wolpert wolpert 
works returning normalized weighted sum outputs nearest neighbors question learning set 
weighting factor nearest neighbors reciprocal distance neighbor question 
normalization means weighted sum divided sum weighting factors guess question input components nearest neighbors learning set corresponding outputs metric taken euclidean metric 
input space symbolic conven tional hamming metric euclidean metric 
see wolpert 
metric simplest generalizers 
addition example farmer local linear technique metric necessarily reproduce learn ing set exactly see wolpert wolpert 
parameters stacked generalization chosen ad hoc manner presumably cross validation get better values 
phase experiment stacked generalization run times 
time new rd order polynomial created coefficients chosen randomly interval 
random means flat sampling distribu tion 
polynomial parent function point learning set chosen randomly separate point testing set input space values chosen randomly 
sets input space values restricted interval 
learning set train stacked generalization structure described errors structure guess outputs elements testing set recorded compared errors level generalizer run level post processing 
average difference square error level generalizer run square error stacked generalizer 
estimated error average stacked gener alization improved generalization confidence standard deviations 
magnitudes guessing errors level generalizer run straight stacked generalization structure ranged orders magnitude number isn particularly meaningful 
ratios error magnitudes misleading advantage simple differences error magnitudes aren skewed loga broad distributions 
average ratio square error level gener run square error stacked generalizer 
ed error average stacked generalization improved generalization factor average 
problem investigated parent functions polynomials order 
level input space consisted numbers question elements learning set local linear guess re nearest neighbor nearest neighbor lives opposite side nearest neighbor 
scenario average ratio error magnitudes ranged depending precise parameters 
hard understand behavior 
polynomials order turns error local linear technique independent question 
fact propor tionality constant exactly 
scenario level generalizer learn simple surface output constant times product input coordinates paraboloid dimensional version original parent surface 
cardinality level learning set range input values learning set density input space elements level learning set means values values level learning set density input space elements level learning set assumption 
level points lie dimensional version level parent surface stacking generalizer effectively allowed run original generalizer learning set chosen original surface density times original level learning set 
multiplier effect 
way understanding exceptional behavior order polynomial parent surfaces average output space magnitude points level learning set rs average error level generalizer run straight 
measures efficacy gen general fairly close 
average output space magnitude points level learning set rs 
points lie surface points level learning set generalizer expect average error guesses level space rs rs 
just argument preceding paragraph output space argument says polynomials order level gen inputs results multiplier effect diminishing average guessing error polynomially 
addition polynomials simple transcendental parent functions investigated 
level input space dimensional input coordinates error estimate level generalizer multiplied 
random con chosen level inputs chosen runs random point learning sets random point testing sets 
level level generalizers polynomial tests 
par ent functions sum sine waves exponential functions 
amplitudes functions determined random constants phases sine waves introducing cosines frequencies exponentials 
frequencies sine waves sine function interpreted arguments ra 
average difference square error level generalizer run square error stacked generalizer 
estimated error av erage stacked generalization improved generalization dence standard deviations 
average ratio square error level gener run square error stacked generalizer 
error average stacked generalization improved generalization factor average 
results intended constitute definitive investigation stacked generalization improve accuracy local linear generalizing technique 
variations schemes outlined investigated involving example different level generalizers different values parameters different mappings partitions level space different dimensionalities level input space results simply tended indicate stacked generalization improve generalization local linear technique smooth non volatile parent functions investigated 
worth commenting choose variations scheme algorithmic manner 
obvious way cross validation 
cross validation run level learning set parameters dealing level generalizer varied 
parameters dealing construct level space example fixed 
scheme re trying estimate generalization accuracy level space information improve entire structure generalization level learning set 
scheme equivalent simply introducing level level stacking generalizers 
way run cross validation treat en tire stacked generalization process generalizer level learning set different gen corresponding different set parameter values 
scheme re exam parameters including example dealing map level space level space 
run cross validation set generalizers 
way re cross validation directly estimate generalization accuracy level space re ultimately interested 
second scheme output information going level learning set coming level learning set level learning set 
ii experiment numerical experiment nettalk reading aloud problem 
parent function problem suitably encoded letters input 
output parent function phoneme voiced english speaker encountering middle letter letters occurred midst text speaker reading aloud 
see stanfill waltz wolpert jones sejnowski rosen berg 
data set experiment reported standard jones modified wolpert force consistency speakers record ed 
wolpert sejnowski rosenberg generalizers guess di rectly letter fields phonemes 
possible phoneme decomposed vector dimensional space components relate physical process speech 
nettalk example neural net takes suitable encoding letter input field input guesses vector dimensional space 
vector guess convert ed phoneme guess finding legal phoneme vector making smallest angle dimensional space guessed vector 
metric problem wolpert component phoneme vec tor space 
output neurons nettalk guesses metric passed post processor combines form dimensional guess turn specifies phoneme guess 
specified rest section term metric really meant set combining manner discussed guess legal phoneme 
separate generalizers combined exact manner example section level generalizer metric nearest neighbors 
level generalizers looked exclusively different input letter slots full hamming metric metric fixed value 
level generalizers differed letter slot looked different 
effective ly means level generalizers different dimensional input space er dimensional variations th slot effect guess ing corresponding generalizer 
level generalizers looked exclusively rd letter slot letter input field second looked exclusively th letter slot third looked th letter slot 
example section cvps guesses level generalizers formed inputs level space outputs level level spaces identical level output space wasn error space 
help level generalizer dimensional output vectors level generalizer fed level input space simplicity full level generalizers single integer representing closest phoneme dimensional vector fed level input space 
words level inputs symbolic real valued 
level generalizer metric full hamming metric dimensional level input space 
usual fact making dimensional guess turn specified phoneme guessed entire stacked generalizer 
level learning set looking successive letter windows words jones consisted elements 
testing set constructed successive letter windows words jones consisted elements level generalizers got total correct respectively testing set 
guess correct incorrect numbers suffice determine exactly expected error associated esti mates average guessing accuracies generalizer average generalizing accuracy generalizer average generalizing accuracy general average accuracy 
expect generalizer looking middle letter input field guesses best phoneme correspond middle letter 
stacked generalizer got correct average accuracy 
cross validation level generalizer worked globally fitting surface form level output level inputs chosen generalizer 
improvement cross validation resulted better level generalizer approximately generalizer standard deviations 
surface fitting experiment earlier pre construct stacked generalizer text phoneme problem formed better 
done varying parameters stacked generalizer different level generalizer purpose text phoneme experiment wasn beat performance reported wolpert metric having access input letters beat performance back propagation nettalk data 
test stacked gen particular test stacked generalization combine separate pieces incomplete input information 
letter slots important oth ers determining correct phoneme output experiment demonstrates stacked tion ability distinguish properly exploit relevant relatively irrelevant level input information 
iii 
discussion stacked generalization number subtle issues involved stacked generalization 
section 
potential shortcomings stacked generalization ad dressed heuristic discussion behavior stacked generalization extensions variations technique discussed 
multi learning set reproduction consider example section stacked generalization involving set 
process outlined example generalizer takes level learning sets level questions maps guesses 
sen sible ask process agrees theoretical properties required individual level generalizers 
things notices possible level learning set multi valued level learning set contain pair points identical input components different output components 
partitions par set result guesses different practice occurs rarely especially data takes continuum values 
level generalizer tries hard reproduce learning set deal gracefully multi multi reason concern 
level generalizer marked lack grace conditions level input space enlarged include level question input space projection case level learning set single valued problems arise 
example peculiar property stacked generalization concerns issue re producing level learning set 
conventional generalizers reproduce learning set strive 
isn necessarily case process stacked generalization viewed generalizer level learning set regardless constituent level level generalizers necessarily reproduce learning sets 
lack reproducing learning set problem 
example noisy data exact reproduction learning set rarely desirable 
behavior stacked gener large learning sets means determining data noisy 
non noisy data case learning set large learning set reproduced approximation 
cases enforce exact reproduction learning set 
ways achieve 
obvious simply place filter questions fed stacked generalizer level question exists level learning set bypass generalizers answer question directly learning set 
af ter purpose stacked generalization improve guessing questions outside learning set provide complicated means implementing look table question input projection learning set guess corresponding output 
elegant scheme devised gustafson 
require level surface guessed level generalizer contains line runs reals diagonal vector vector coordinate projections identical non zero dimensionality level input space 
scheme long level generalizers reproduce level learning set entire stacked gener 
reason level question contained level learning set level generalizers guess output component corresponding element level learning set level generalizer guess 
ways ensure reproduction learning set don restrict level generalizer 
example speak teach level generalizer reproduce level learning set 
set don simply create single element level learning set corresponding create points level space possible values allow range just 
modulo issues multi level learning set long individ ual level level generalizers reproduce learning sets scheme entire stacked generalizer 
criteria require generalizer addition reproduction learning set 
example require generalizer invariant euclid symmetry operations level space see wolpert 
practice generalizers commonly reproduce learning sets meet additional gen criteria despite reasonableness criteria 
result modifying stacked generalization necessarily obey criteria non trivial exercise practice constituent generalizers violate 
full discussion related issues con stacked generalization generalization criteria scope 
ii heuristics concerning behavior stacked generalization sub section cursory heuristic examination properties individual lev el level generalizers particularly pronounced effects efficacy stacked generalization 
generalizers explicitly local meaning guess overtly dependent strong manner nearest neighbors question learning set 
generalizers explicitly local act locally 
example back propagation behaves locally see lapedes farber discussion wolpert back propagation try generalize parity input output function 
care taken local generalizer cvps especially generalizer generalizer level general 
reason values element elements lie closest level question 
trying determine correct biases level generalizer generalizing full learning set training done learning sets different nearby elements nearby elements full learning set 
generalizing local generalizer strongly dependent set nearby elements learning set hypothesis 
accordingly information level learning set extremely misleading implies level generalizer err answering level question full level learning set 
natural way get problem level input space contain infor mation nearby elements level learning set 
way dependence nearby el ements learning set learned 
exactly strategy followed ex ample section experiment section ii 
exist situations care exercised stacked generalization 
example level inputs outputs level generalizers example section poor choice level generalizer result tion performance worse level generalizers run 
full tion desirable traits level generalizers situation isn hand broad observations 
context level generalizer explicitly surface fitter best behavior accrues usually generalizer relatively global non volatile smooth overly concerned exact reproduction level learning set 
example ongoing lapedes farber mentioned section ii level input space dimensional 
best level generalizers far operate forming essentially uniformly weighted average nearest neighbors level question 
extreme example stacked zation level generalizer global hyperplane fitter cross validation 
simplistic analysis shows reasonable relatively global smooth level generalizers perform 
imagine single level generalizer level input space guess level outputs level outputs 
simplicity level level output spaces discrete valued values 
level generalizer assume fairly generalizer parent function consideration 
precisely assume independent guess guess correct exactly time 
furthermore assume way fooled guess guesses particular correct guess particular number determined uniquely look level input space value 
assume points level learning set input coordinate 
define probability elements output meaning guessed correctly output 
independent value guess probability independent level input value 
correct time absence additional information guess output 
level generalizers question guess 
especially true case evidence guess thing 
assume behavior 
small level input space projections level learning set sizable pro level learning set 
result relatively large fraction level learning set input space projections relatively large fraction times question exists level learning set learning set lead guess guess stacked generalization feeding lev el generalizer lead worse guesses simply directly average 
type problem occur level input space multi dimensional 
simple way modify implicitly estimate guessing accuracy estimate 
estimate level generalizer examine large number elements level learning set run cross validation type procedure measure fit hyperplane output guess elements 
preferably examined elements nearby elements level question don worry fact general guessing accuracy depend value guess toy example 
putting requirements get level generalizers relatively global non volatile smooth overly concerned exact reproduction level learning set 
level generalizers viewed systems effect boost number times observed right number times observed wrong examining nearby elements level learning set 
boosted way small problem rectified 
generically level inputs outputs level generalizers wants generalizers loosely speaking span space generalizers mutually orthogonal space 
example imagine level generalizers guesses directly give level inputs see 
say generalizer parent function particularly generalizer function 
possible advantage stacked generalization structure adds information provided correlation correct output pair guess guess greater correlation correct output guess 
isn case simply red herring guess redundant best 
kinds reasons level generalizers mutually orthogonal 
similar reasoning justifies statement wants level generalizers span space 
usually desirable level generalizers types just simple variations want surface turing machine builders statistical 
way possible ways examining learning set trying exploited 
part meant saying level generalizers span space 
spanning important stacked generalization isn just way determining level generalizer works best cross validation linear combination works best gustafson scheme stacked generalization means non linearly combining generalizers new generalizer try optimally original generalizers say learning set 
gen say isn duplicated generalizer say better resultant stacked generalization 
aspect span space means clear discussion sub section concerning heuristics stacked generalization single local generalizer output values level generalizers give sa information concerning nearby elements level learning set 
generalizers collectively tell important level learning set mapping level space level space involved loss important information 
stacked generalization applying non linear transformation elements learning set generalizing level generalizer 
non linear transformation determined level generalizers map level space saying generalizers mutually orthogonal span space essentially means hand non linear transformation preserve important information learning set time preserve re irrelevant information mapping level space level space 
iii extensions variations interesting implementations basic idea stacked generalization 
note idea having level output error estimate level generalizer applied level generalizers addition feeding level input space 
case outputs generalizers providing formation concerning error generalizing 
number ad schemes level output isn interpreted guess es error guess 
example scheme dimensionality level input space reduced losing information 
need longer feed level space get information concerning guess information comes subtract estimated error guess 
scheme allows conservative multiply error estimate fraction subtracting guess 
way directly control parameter multiplicative fraction determines extent stacked generalization extent simply 
interesting implementation stacked generalization structure generalizer thing stacked combined network structure 
usual net games back propagation applied network structure 
interesting variation level generalizers similar relatively dumb systems example system generalizer guess output value point learning set input component lies closest vector sum fixed input space vector question 
different level generalizers different fixed input space vector 
fixed input space vector recover traditional nearest neigh bor generalizer 
non linear time series analysis delay embedding farmer casdagli example stacked generalization set similar dumb level generalizers 
examples kind implementation stacked generalization fan generalizers wolpert extension non linear time series analy sis multiple input dimensions 
variations interesting tools theoretical investigations stacked tion 
example number generalizers equal dimension level input space partition set multiple stacking level space inputs outputs level generalizers exactly example section 
implementation stacked generalization producing learning set lev el generalizer matter level working reduces single unique function argument dimensional question element learning sets input space dimensional 
result explicitly analyze behavior sys tem stacking levels added 
example consider case level single learning set learning sets feed serially set level exact rules 
structure multi layer net node learning set exists node layer information fed node generalizers 
scenario successive levels act learning set sive iterations iterated map 
usual non linear analysis questions apply get periodic behavior 
get chaotic behavior 
dimensions attractors 
answered questions presumably help determine levels stack system 
interesting theoretical scenario arises mappings learning set reduced single function guessing ques tions outside learning set 
full reduction usually doesn obtain due fact cardinality cardinality full question goes different vs 
conundrum arises trying provide theoretical justifications techniques cross validation 
obvious way diffi culty fixed example define chosen cvps 
averaging done uni form weighting numbers numbers weighted ac cording error value input component output component 
way analysis generalizing behavior stacked generalization relation con generalizers cast terms behavior single function 
interesting note authors investigated amounts stacked generalization context improving learning improving reproduction learning set improving generalization 
context allowed run en tire learning set 
example scheme investigated 
level generalizer back propagation standard feed forward neural nets level output space error level generalizer 
level input space identical level input space 
level generalizer back propagation standard feed forward neural nets restricted non zero resolution output 
evidence indicating scheme achieves lower learning error single back propagation generalizer time 
noted partition set type implicitly dep help learning entails major disadvantages far generalization concerned 
example partition set noise level generalizers guesses perfectly questions trained far level generalizer tell level surface fitter guesses perfectly questions 
accord ingly reasonable level generalizer simply say level generalizer directly ignore level information 
general partition set generalizing generalize generalizing learn level space contains information level generalizers learn gener 
stacked generalization generic term referring scheme feeding information set generalizers forming final guess 
distinguishing feature stacked generalization information fed net generalizers comes multiple partitionings original learning set split learning set subsets 
pair subsets glean information biases generalizing havior original generalizer respect learning set 
note biases learning behavior original generalizer 
bias information fed net stacked generalization means estimating correcting biases constituent generalizer respect provided learning set 
stacked generalization single generalizer case explicitly scheme estimating correcting errors generalizer 
surface fitting experi ments reported indicate quite effective correcting errors 
multiple generalizers feed single back generalizer certain special cases stacked generalization exactly equivalent cross validation certain exactly equivalent forming linear combination guesses constituent generalizers special cases correspond assumption particular invariably dumb back generalizer 
generalizing problem sophisticated generalizers expected give improved results 
case nettalk type experiments re ported experiments reported 
generalization problems stacked generalization expected reduce generalization error rate 
footnotes strictly speaking amount information learning set number bits ing set parent functions consistent learning set see 
extra information implicit stacked generalization comes assumption sample sample techniques accurate indicators generalization behavior entire learning set 
assumption implicit non parametric statistics techniques non parametric statistics techniques discussed 
guarantees course 
non cross validation schemes choosing set generalizers parsimony random choice certain circumstances result choosing generalizer lower generalization error rate generalizer chosen cross validation 
similarly certain circumstances scheme stacked generalization just straight outperform stacked tion 
non universality inevitable holds generalizing scheme whatsoever due fact guessing parent function finite number samples ill posed problem hadamard sense see 
addition stacked generalization ways embedding central idea cross validation sophisticated framework 
cross validation error simply means choosing set generalizers 
constructs gener scratch requiring zero cross validation error 
construction unique impose constraints see wolpert 
coming set generalizers observing behavior takes ap proach specifying desired behavior solving inverse problem calculating generalizer desired behavior 
approach called self guessing 
similar spirit regularization theory loosely speaking regularization done space generalizers opposed space input output functions 
gustafson don view terms scheme essentially cross validation finding single best generalizer re finding best restricted linear combination generalizers cvps determine combination 
language stacked generalization scheme cvps level input space consisting outputs level generalizers 
level output space correct outputs level space level generalizer restricted global hyperplane fitter 
level generalizers scheme variations local hyperplane 
difference scheme straight cross validation restrictions gustafson imposes lev el generalizer lax 
generalize level space fitting global hy allows arbitrary hyperplanes form level input space coordinates arbitrary real valued constants restricted 
con trast cross validation adds extra restriction equal 
implemented viewed partition set called partition set ranges single pairs just cvps level generalizers identical non overlapping subsets train 
usually restricted divisor 
example level generalizer surface fitter fits surface group elements second level generalizer surface fitter fits surface second group elements 
scheme consists feeding level generalizers level space generalizing 
sophisticated versions metric replace pre fixed metric restrictive 
example metric reported wolpert input space dimensional coordinates input value scaled distinct weighting factor conventional metric applied 
weighting vector determined learning set cross validation 
general scheme weighting matrix weighting vector 
scheme mul input space vectors weighting matrix applying conventional metric 
weighting vector special case scheme weighting matrix diagonal 
practice cross validation find matrix 
space possible matrices large trial error approach wolpert probably want employ gradient descent space cross validation error find optimal weighting matrix 
pre multiplying weighting matrix equivalent linearly transforming input space doing generalizing 
transfor mation allows cross talk various input space coordinates occur determination distances input space vectors 
jump weighting vector weighting matrix metric loosely equivalent jump percep vector synaptic weights feedforward neural net single hidden layer matrices synaptic weights 
mapping input layer hidden layer neural net linear transformation original input vectors 
essentially done wolpert genetic evolution process create feedback net generalizers 
wolpert output feedback net generalizers fed generalizer get final guess 
final generalizer learning set constructed original level learning set reproduced 
learning sets generalizers determined evolutionary development net 
fitness function evolution cross validation error entire system 
interesting aspect nets generalizers environment generalizer 
nodes net reserved generalizer input output function serves purpose input lines conventional architectures 
example di input environment say brightness vs angle function 
discretize independent variable function feed resultant numbers input nodes number node get conventional way feeding data net 
finds learning set generalized surface fitter say gives environment function insert generalizer learning set environment function envi ronment generalizer node net 
scheme different environments don correspond different values input lines correspond different environment generalizers appro priate nodes net 
scheme advantages allows net actively query environment allows environment arbitrary size 
properties hold conventional process discretizing environment feeding input nodes 
see wolpert details 
conventional univariate non linear time series analysis provided sequence values single dimensional variable set times real valued con stant 
try generalize sequence assumes value time determined value set delays 
exploit assumption embeds original sequence learning set space dimensions input dimension output 
element delay space learning set input components set values sequence values chosen provided time series output value element value point read time series 
points delay space learning set sequences consecutive points time series 
prediction values simply generalizes delay space guesses output correspond delay space question basing guess delay space learning set 
viewed terms stacked generalization embedding procedure set level generalizers feeding level generalizer 
level learning set dimensional input space time series 
constituent level generalizers predicated assumption time series periodic 
differ period assume series level generalizer assumes period assumes period way assumption period 
order gen predicting predicting question th level generalizer conventional non linear time series analysis guess completely independent elements level learning set quite dumb generalizer 
perspective stacked generalization imme see obvious way try improve performance non linear time series analysis replace level generalizers rigidly assume exact periodicity periods generalizers aren quite pig headed 
example ers assume set set level generalizers conventional generalizer metric entire 
time series estimate set set scheme simply having th level generalizer predict exactly pro vided question generalizer guesses answer correspond 
interesting examine fan generalizers point view discussion earlier spanning space generalizers 
producing inputs level learning set exclusively outputs level learning set fan generalizers preserve salient information input space geometry level learning set 
fan consists entirely level input space information crucial construction input components elements level learning set 


ability neural networks perform generalization induction 
biological cybernetics 
jones 

informal speech 
university california press los 
casdagli 

non linear prediction chaotic time series 
physica 
dietterich 

machine learning 
annual review computer science 


hierarchical training neural networks prediction chaotic time series 
institut fur theoretische physik und sfb universitat frankfurt ger 
report number 
efron 

computers theory statistics thinking siam review 
farmer 

exploiting chaos predict reduce noise los alamos report la ur gustafson little simon 

neural network interpolation extrapolation 
report number university dayton research institute dayton ohio 
holland 

adaptation natural artificial systems 
university michigan press 
lapedes farber 

neural nets proceedings ieee denver conference neural networks published neural information processing systems ander son ed published american institute physics 
li ker chau 
stein unbiased risk estimates method generalized cross val annals statistics 


methods solving incorrectly posed problems 
springer verlag 
omohundro 

efficient algorithms neural network behavior 
report university illinois urbana champaign computer science department 
poggio staff mit ai lab 
mit progress understanding images 
ed proceedings image understanding workshop 
mclean va quinlan 

induction decision trees 
machine learning 
rissanen 

stochastic complexity modeling 
annals statistics 
rumelhart mcclelland 

explorations microstructure cognition volumes ii 
mit press cambridge ma 
schulz 

comparison predicted experimentally determined secondary structure kinase nature 
sejnowski rosenberg 

nettalk parallel network learns read aloud report 
jhu eecs johns hopkins university electrical engineering computer science dept stanfill waltz 

memory reasoning 
communications acm 
stone 

asymptotics cross validation biometrika 
valiant 

theory learnable 
communications acm 
wolpert 

benchmark neural nets generalize 
biological cybernetics 
wolpert 

relationship occam razor convergent guess 
complex sys tems 
wolpert 

constructing generalizer superior nettalk mathematical theory generalization 
neural networks 
wolpert 

mathematical theory generalization part complex systems 
wolpert 

mathematical theory generalization part ii 
complex systems 
cross validation special case property self guessing described 
wolpert 

improving performance generalizers time series pre process ing learning set report 
la ur los alamos national laboratory nm 
submit ted ieee pami 
zhu 
nonlinear time series modeling self organizing methods 
report department mechanics university beijing prc 
report number 
guess 
correct output full learning set guess element error guess input 
full learning set element input nearest neighbor output 
input output 
input output 
input input output 
input input creating level learning set 
contains elements partition level partition set 
level learning set 
partition set ij generalizers 
guessing level learning set 
generalizer 
question 
level learning set 
generalizers 
question 
output input 
level question 
final guess outputs inputs output 
parent function element level learning set error level generalizer guessing curve level generalizer connect dots surface fitter 
level question input output 
parent function left element level learning set level generalizer guessing curve input left element level learning set guessing error input component left point level question 
guessing error forms corresponding level output 
guessing error level output 
level question identical level question see 
element level learning set level input equals level input captions 
example stacked generalization combine generalizers 
combining generalizers learning set represented full ellipse 
question lying outside indicated 
partition portions indicated portion consists single input output pair contains rest partition train half 
ask generalizers question guesses general general haven trained pair differ just learned guesses guesses correct answer formation cast input output information new space single point dimensional input output 
choosing partitions gives points 
taken points constitute new learning set 
train ask question take pair guesses feed pair question third generalizer trained 
third generalizer guess final guess output corresponds assuming strong correlation guesses hand correct guess implementa tion stacked generalization 

example stacked generalization improve single generalizer 
single generalizer learning set represented full el question lying outside indicated partition portions shown 
partition train portion 
ask question note guess vector nearest neighbor 
general hasn trained pair differ just learned question vector nearest neighbor learning set correct answer differs guess 
information cast input output information new space single point dimensional input output 
choosing partitions gives points 
taken points constitute new learning set 
train ask question take pair vector nearest neighbor feed pair ques tion third generalizer trained 
third generalizer guess guess error guessing output corresponds adding estimated error fraction thereof back guess gives final guess 
assuming strong correlation question vector nearest element learning set hand general error implementation stacked generalization 

schematic depiction level learning set level question 
learning set consists points indicated solid circles 
question indicated question mark precisely question input projection question mark indicated inter section associated dotted line input axis 
example input space dimensional 

schematic depiction pairs cvps level learning set 
consists solid circles fifth element level learning set depicted open square solid circle 
pairs making cvps simply change element level learning set square 

schematic depiction elements level learning set 
determine level inputs running level generalizers level learning set question pair 
cvps indicated generalizers taught solid cir cles asked guess level output correspond input value square 
guesses form input components solid circle ed dotted lines 
output level space output level space output value single circle indicated identical output val ue square 

level learning set pairs level cvps indicated solid circles 
clarity points level learning set shown 
learning set constructed level generalizers taught full level learning set asked level output think correspond level ques tion 
guesses determine level question indicated input projection question mark 
generalizer trained level learning set guess level question 
guess serves full system guess level output correspond level question level learning set 

stylized depiction stages involved implementation stacked gener alization described section iv 
stage level learning set created level partition set ij set level generalizers 
second stage exact architecture create create level question level question 
final guess training level generalizer asking new level question 
note entire procedure twice parallelizable partitions level generalizers 

figures geometric depiction stacked generalization improve guessing single generalizer 
figures assume stacked gen architecture level inputs dimensional consisting solely level input 
illustrates parent function part learning set noise free samples parent function 
elements learning set exist outside range 
level generalizer simple connect dots generalizer guessing shown learning set explicitly depicted 
particular question indicated task estimate correct error level generalizer guessing output correspond achieved second level generalizer 

see 
perform stacked generalization need form level learning set 
done cvps original level learning set 
partition pair cvps illustrated 
point learning set corresponding hatched circle level generalizer trained points level learning set error guessing output corresponds input component corresponds tabulated 
error output point level learning set corresponding level input level input 
see figures 
depicts elements level learning set algorithm described 
full stacked tion scheme works generalizer guess level output correspond level question identical level question input output pairs level learning set 
guess finds level generalizer guess output corresponds level question subtracts level guess level guess multiplied just conservative 
gives final guess output corresponds level input 
particular example errors level generalizer strongly correlated level question reasonable level generalizer error full stacked generalization scheme significantly lower error level general straight 
