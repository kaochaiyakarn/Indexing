source language features maximum correlation training machine translation evaluation propose new features mt evaluation source sentence constrained gram precision source sentence reordering metrics discriminative unigram precision method learning linear feature weights directly maximize correlation human judgments 
aligning hypothesis sentence achieve better correlation human judgments previously proposed metrics 
improve performance combining individual evaluation metrics maximum correlation training shown better classification framework 
evaluation long stumbling block development machine translation systems due simple fact correct translations sentence 
commonly metric bleu correlates large test sets human judgments papineni perform sentence level evaluation 
approaches improve sentence level evaluation performance summarized falling types metrics common loose sequences mt outputs lin och liu gildea 
metrics ding liu daniel gildea department computer science university rochester rochester ny shown better fluency evaluation performance metrics grams bleu nist doddington 
metrics syntactic similarities head word chain metric liu gildea 
metrics try improve fluency evaluation performance mt heavily depend automatic parsers designed formed sentences generate robust parse trees mt outputs 
metrics word alignment mt outputs banerjee lavie 
metrics adequacy evaluation fluency evaluation unigram basis liu gildea 
combination metrics machine learning 
shieber svms combine metrics 
method assumption higher classification accuracy discriminating human machine generated translations yield closer correlation human judgment 
assumption may hold particularly classification difficult 

proposed log linear model combine features preliminary experiments features 
track previous improve evaluation performance propose new metrics find effective ways combine metrics 
explore approaches 
done computing mt scores proceedings naacl hlt pages rochester ny april 
association computational linguistics pair mt output aim investigate information mt evaluation source sentences 
propose types source sentence related features feature part speech 
new types feature summarized follows source sentence constrained gram precision 
overlapping grams mt hypothesis necessarily indicate correct translation segments correspond different parts source sentence 
constrained gram precision counts overlapping grams mt hypothesis aligned words source sentences 
source sentence reordering agreement 
alignment information compare reorderings source sentence mt hypothesis 
comparison considers aligned positions source words mt hypothesis oriented evaluating sentence structure 
discriminative unigram precision 
divide normal gram precision part speech pos 
division gives flexibility train weights sub precision frameworks svm maximum correlation training introduced 
motivation differentiation different sub precisions different importance mt evaluation nouns verbs adjectives important evaluating adequacy sub precision determiners conjunctions mean evaluating fluency 
direction feature combination indirect weight training svms reducing classification error yield performance train weights directly optimizing evaluation performance maximizing correlation human judgment 
type direct optimization known minimum error rate training och mt community essential component building stateof art mt systems 
logical apply similar methods mt evaluation 
maximum correlation training mct enables train weights human fluency judgments adequacy judgments respectively possible fluency oriented adequacy oriented metric 
surpasses previous mt metrics approach single metric evaluates fluency adequacy 
rest organized follows section gives brief recap gram precision metrics introduces extensions section introduces mct mt evaluation section describes experimental results section gives 
new features mt evaluation source sentence constrained gram precision discriminative unigram precision derived normal gram precision worth describing original gram precision metric bleu papineni 
mt hypothesis bleu computes fraction grams appear sentences brevity penalty 
formula computing bleu shown bleu bp nx ngram ngram ngram count ngram denotes set mt hypotheses 
ngram denotes clipped number grams candidates appear 
bp formula denotes brevity penalty set accumulated length mt outputs longer arithmetic mean accumulated length set ratio 
sentence level evaluation bleu compute score pair mt hypothesis 
approaches described section different ways manipulate morphological similarity mt hypothesis 
nist consider words mt hypothesis long words mt hypothesis appear difference metrics 
nist computes grams weights logarithm ratio gram frequency word lower gram frequency 
experiments nist generally better bleu reason conjecture differentiates grams frequency estimated evaluation corpus reliable 
section describe strategies differentiating grams uses alignments source sentence constraint differentiates gram precisions pos 
source sentence constrained gram precision quality mt sentence independent source sentence translation considering current metrics shallow morphological similarity mt outputs really understanding meaning sides source sentences useful information differentiating mt outputs 
consider chinese english translation example source wo bu hypothesis hardly clear word mt output exist word hardly maintaining meaning source sentence 
metrics mentioned prevent counted evaluation due simple reason compute shallow morphological similarity 
source sentence help example 
reveal alignment source sentence mt output chinese word bu aligned hardly mt output respectively leaving word mt output aligned word source sentence 
find alignments source sentence mt output smarter selecting overlapping words counted metrics meteor rouge sia liu gildea positions words difference word 
grams wi wi mt hypothesis max val sentences grams rj rj current sentence val wi equals rj equals val val max val max val val hit count max val hit count return length penalty algorithm computing constrained gram precision metric select words aligned source words 
question comes find alignment source sentence mt hypothesis evaluation data set usually contain alignment information 
approach uses giza construct alignments source sentences mt hypothesis respectively 
giza generate alignments source sentence mt hypothesis case word mt hypothesis aligned set words source sentence reverse direction case word mt hypothesis aligned exactly word word source sentence 
case denote positions words source sentences aligned word mt hypothesis word respectively algorithm computing source sentence constrained gram precision length described 
source sentence constrained gram precision sscn precision metric vari giza available www com giza html refined alignments got source hypothesis mt system source manual proof reading automatic alignment 
doing requires mt system cooperation costly human labor 
able length penalty avoid assigning short mt hypothesis high score computed way bleu 
note algorithm computing precision grams longer word words grams satisfy source sentence constraint 
reason high order grams sparse sentence level evaluation 
differentiate source mt ref toone alignments mt ref source alignments sscn sscn denote respectively 
naturally combine constraint sscn sscn union combined constrained satisfied satisfied intersecting combined constrained satisfied constraints satisfied 
sscn sscn denote sscn unioned constraints intersected constraints respectively 
apply stochastic word mapping proposed sia liu gildea replace hard word matching corresponding metrics denoted number denoting different constraints 
metrics source word reordering previous mt metrics concentrate cooccurrence mt hypothesis words 
metrics source sentence reorderings contrary take words identities account compute similarly source words reordered mt output 
simplicity consider pairwise reordering similarity 
source word pair wi wj aligned positions mt hypothesis order call consistent word pair 
pairwise reordering similarity prs metric computes fraction consistent word pairs source sentence 
gives formal description prs 
denote aligned position source word wi mt hypothesis kth respectively denotes length source sentence 
criterion evaluating reordering source sentence mt hypothesis maintains original word order word pair wi wj source sentence sentences rk count break return count compute pairwise reordering similarity word pair wi wj source sentence count return count compute source sentence monotonic reordering ratio source sentence 
know time alignment source sentence mt hypothesis monotonic 
idea leads metric monotonic pairwise ratio mpr computes fraction source word pairs aligned positions mt hypothesis order 
described 
discriminative unigram precision pos discriminative unigram precision pos decomposes normal unigram precision sub precisions pos 
algorithm described 
sub precisions carry information standard unigram precision provide opportunity better combined metric normal unigram precision mct introduced section 
unigram mt hypothesis mt hypothesis length pos compute gram length division theory generalized higher order grams doing grams pos set sparse 
preprocessing step metric tagging mt hypothesis pos 
elicit worries robustness pos tagger noise containing mt hypothesis 
problem reasons 
compared preprocessing steps parsing pos tagging easier higher accuracy 
second counts pos accumulated correctness single word pos affect result 
maximum correlation training machine translation evaluation maximum correlation training mct instance general approach directly optimizing objective function model ultimately evaluated 
case model linear combination component metrics parameters weights component metric objective function pearson correlation combined metric human judgments 
reason linear combination metrics component metrics usually similar order magnitude optimization problem easy solve 
denote weights denote component metrics combined metric computed hi denote human judgment combined metric sentence respectively denote number sentences evaluation set objective function computed pearson pn ihi pni pni hi pn pn pn hi task find weights component metric correlation combined metric human judgment maximized 
formulated argmax pearson function pearson differentiable respect vector compute derivative analytically perform gradient ascent 
objective function convex easily create non convex function setting human judgments individual metrics particular value 
guarantee starting random get globally optimal optimization techniques gradient ascent 
easiest way avoid bad local optimum run gradient ascent starting different random points 
experiments difference run small starting different random initial values similar values pearson correlation 
experiments experiments conducted evaluate performance new metrics proposed mct combination framework 
data experiments mt evaluation workshop acl 
sets mt outputs contains english sentences translated set chinese sentences 
sets human scores mt hypothesis 
human score set contains fluency adequacy score range 
create set human scores averaging human fluency adequacy scores 
evaluating automatic metrics compute pearson correlation automatic scores averaged human scores sets available human scores score fluency adequacy 
alignment source sentences mt hypothesis computed giza trained combined corpus evaluation data parallel corpus chinese english newswire text 
parallel newswire corpus contains sentence pairs english words chinese words 
stochastic word mapping trained french english parallel corpus containing sentence pairs liu gildea keep top similar words english word 
performance individual metrics evaluate source sentence metrics evaluate mt outputs sets human 
sentence level pearson correlation human judgment computed mt output averaged results shown table 
comparison show results bleu nist meteor rouge wer 
meteor rouge word net porter stemmer enabled sia decay factor set 
number brackets bleu shows gram length counts sscn shows length gram uses 
table top results column marked bold best result underlined 
results show sscn metrics better sscn metrics adequacy score 
understandable sscn metrics need words source sentence aligned gram mt hypothesis 
directly modeled alignment sscn 
get information reverse alignment sscn indirect way contain noise 
interesting sscn gets better fluency evaluation results sscn 
sscn metrics unioned constraint sscn combining strength sscn sscn get better results aspects 
see sscn metrics stochastic word mapping get significantly better results relatives bleu indicates source sentence constraints difference 
sscn sscn competitive state art mt metrics meteor sia 
best sscn metric achieves best performance testing metrics adequacy second best performance fluency just little bit worse best fluency metric sia 
reordering metrics prs mpr testing metrics terms fluency adequacy rouge rouge meteor sia nist wer prs mpr bleu bleu bleu sscn sscn sscn sscn sscn sscn sscn sscn table performance component metrics individual performance 
surprising totally different kind metrics count overlapping grams consistent monotonic word pair reorderings 
long capture property mt hypothesis able boost performance combined metric mct framework 
performance combined metrics test mct works scheme set mt outputs evaluated mct trained sets mt outputs corresponding human judgment averaged correlation sets mt outputs human judgment taken final result 
discriminative unigram precision pos mct combine discriminative unigram precisions 
reduce sparseness unigrams pos original pos set generalized combining pos tags letter different verb forms vbn vbd vbz transformed 
unified pos set contains pos tags 
give fair comparison bleu length penalty added component 
results shown table 
denote trained human fluency adequacy judgment respectively 
shows achieves obvious improvement bleu unigrams length penalty gets best result fluency adequacy evaluation showing mct able fluency metric 
putting interesting question metrics mt evaluation 
answer question put metrics described mct framework combined metric evaluate mt outputs 
note speed training process directly components combined metrics 
metrics shown table total metrics 
table shows results final combined metric 
see mct trained fluency adequacy human judgment get best results testing metrics fluency adequacy evaluation respectively 
test fisher transform combined results individual results see significant difference combined results adequacy significantly better confidence best results individual metrics combined result fluency significantly better confidence best individual metric sia 
give upper bound evaluation aspect training mct testing mt outputs train mct evaluate 
upperbound best mct linear combination 
linear framework classification svm combine testing metrics 
mct neat comparison rule experiments 
svmlight joachims org fluency adequacy mct mct mct upper bound mct mct mct table combination testing metrics testing scheme mct mt hypothesis positive samples training computed scores 
slack parameter chosen maximize classification accuracy heldout set negative positive samples randomly selected training set 
results shown table 
see mct number sentences better 
note resources required mct different 
mct uses human judgments adjust weights needs extra human produce positive training samples 
rough idea component metrics contribute final performance mct incrementally add metrics mct descending order evaluation performance results shown 
see performance improves number metrics increases rough sense 
major improvement happens rd th th th th metrics meteor sia prs 
interesting note metrics highest individual performance 
interesting observation metrics belonging series beneficial metrics indicating get better combined metrics individual metrics showing different sentence properties preferred 
describes types new approaches mt evaluation includes making correlation human fluency adequacy judgements number metrics adequacy fluency performance function number interpolated metrics source sentences discriminating unigram precisions pos 
testing metrics including bleu nist meteor rouge sia new metric source sentence constrained bigrams achieves best adequacy evaluation results second best result fluency evaluation 
improve performance combining individual metrics mct framework shown better classification framework svm 
examining contribution component metric find metrics showing different properties sentence combined metric 
acknowledgments supported nsf iis iis iis 
banerjee alon lavie 

meteor automatic metric mt evaluation improved correlation human 
proceedings acl workshop intrinsic extrinsic evaluation measures machine translation summarization ann arbor michigan 
john erin fitzgerald george foster cyril goutte alex alberto nicola 

confidence estimation machine translation 
technical report center lan guage speech processing johns hopkins university baltimore 
summer workshop final report 
doddington 

automatic evaluation machine translation quality gram occurrence statistics 
hlt human language technology conference san diego ca 
alex stuart shieber 

learning approach improving sentence level mt evaluation 
proceedings th international conference theoretical methodological issues machine translation tmi baltimore md october 
chin yew lin franz josef och 

automatic evaluation machine translation quality longest common subsequence skip bigram statistics 
proceedings th annual conference association computational linguistics acl barcelona spain 
monica alon lavie 

blanc learning evaluation metrics mt vancouver 
ding liu daniel gildea 

syntactic features evaluation machine translation 
acl workshop intrinsic extrinsic evaluation measures machine translation summarization 
ding liu daniel gildea 

stochastic iterative alignment machine translation evaluation 
sydney 
franz josef och 

minimum error rate training statistical machine translation 
proceedings acl 
kishore papineni salim roukos todd ward wei jing zhu 

bleu method automatic evaluation machine translation 
proceedings acl philadelphia pa 
