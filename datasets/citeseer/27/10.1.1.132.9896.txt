appears proceedings ieee intnl 
symposium high performance distributed computing hpdc adaptive communication algorithms distributed heterogeneous systems bhat viktor prasanna department ee systems university southern california los angeles ca prasanna usc edu heterogeneous network systems emerging attractive computing platforms hpc applications 
discusses fundamental research issues addressed enable network aware communication application level 
uniform framework developing adaptive various collective communication patterns 
schedules developed run time network performance information obtained directory service 
illustrate framework developing communication schedules total exchange 
algorithm develops schedule computing series matchings bipartite graph 
heuristic algorithm completion time twice optimal 
algorithm open shop scheduling problem 
simulation results show performance improvements factor known homogeneous scheduling techniques 

advances high speed networks metacomputing emerged viable attractive computational paradigm 
metacomputing system consists geographically distributed supercomputers visualization devices 
interconnected heterogeneous collection local wide area networks 
high performance applications executed networked virtual supercomputer distributed computational resources coordinated way part single computer system 
potential metacomputing demonstrated global information infrastructure gii testbed sc 
testbed linked dozens high performance supported darpa ito quorum program naval postgraduate school subcontract number 
site raghavendra aerospace box los angeles ca raghu aero org local network mb site site multistage interconnection network mb ibm sp high bandwidth long haul links oc mb workstations 
typical metacomputing system 
computers visualization machines existing highbandwidth networks telephone systems 
leading metacomputing research projects globus legion mshn name 
discussed section 
shows example small scale metacomputing system 
compute nodes system located different sites 
nodes high supercomputing systems workstations 
example shown kinds interconnection networks multi stage interconnection network ibm sp ii local networks site iii high bandwidth long haul atm links sites 
network computing platforms offer significant advantages high performance computing effective resources major challenge 
computational communication resources typically shared different applications 
computational tasks may preempted higher 
network conditions change continuously run time loads determined apriori 
applications capable adapting changing system conditions 
develop communication techniques enable applications adapt variations network conditions 
focus collective communication patterns application processes executing heterogeneous network 
goal develop efficient applicationlevel implementations communication routines 
assume availability send receive communication routines invoked pair nodes 
details network topology routing flow control policies hidden application 
efficient algorithms various collective communication patterns developed tightly coupled parallel architectures homogeneous networks 
algorithms incorporated communication libraries implementations mpi 
techniques perform poorly metacomputing systems due heterogeneity network bandwidths 
static algorithms provision adaptivity network conditions 
section introduce approach developing network aware communication techniques 
key components approach directory service provides information current network performance ii communication model estimates time individual communication events iii timing diagrams abstractly represent communication pattern network performance iv scheduling algorithms reduce communication time appropriately positioning communication events timing diagram 
approach general different collective communication patterns variety network architectures 
section scheduling framework personalized communication pattern typical metacomputing environment 
develop different scheduling algorithms problem 
algorithm matching algorithm 
constructs bipartite graph edge weights equal communication costs processor pairs 
series maximum weight complete matchings graph computed 
communication schedule derived matchings 
second algorithm greedy approximation matching algorithm 
third algorithm heuristic open shop scheduling problem 
evaluate performance algorithms simulation compare known scheduling technique homogeneous scenarios 
results show excellent improvements performance 
represents early efforts formalize research problems related network computing 
section discuss fundamental research issues motivated need network aware applications 
consider enhancements communication model techniques reduce complexity scheduling algorithm 
discuss communication scheduling presence qos constraints 
rest organized follows section discusses related research projects metacomputing 
section introduces approach communication techniques describes components detail 
section formulates heterogeneous data communication problem presents scheduling algorithms communication pattern 
section presents simulation results algorithms 
section discusses research directions network aware communication scheduling 
section concludes 

related research projects developing software infrastructure defining api functionality network computing systems 
believe complement software development efforts 
scheduling techniques section incorporated software systems tool kits 
projects investigating performance related issues 
globus project anl usc isi developing set low level core services called globus tool kit 
includes modules resource location allocation communications authentication process creation data access 
higher level systems software applications build functionality provided tool kit 
nexus communications library component globus tool kit 
globus incorporates directory service called metacomputing directory service mds 
applications query mds information current loads processing nodes network performance node pairs 
legion project university virginia uses object oriented approach metacomputing system design 
philosophy hide complexity resource scheduling load balancing application developer 
object oriented properties encapsulation inheritance software reuse fault containment reduction complexity achieve goal 
virtual distributed computing environment syracuse university aims develop complete framework application development configuration execution 
gui allows library routines user developed routines combined application task graph 
task graph interpreted configured execute currently available resources 
carnegie mellon remos resource monitoring system project developing portable api allows applications obtain informa tion network status capabilities 
architectures generate information network hardware software system specific format 
remos provides standard interface format independent details particular type network 
remos explicitly accounts resource sharing applications 
management system heterogeneous networks mshn project naval postgraduate school usc purdue university designing implementing resource management system rms distributed heterogeneous shared environments 
mshn assumes heterogeneity resources processes qos requirements 
processes may different priorities deadlines compute characteristics 
goal assign resources individual applications qos requirements satisfied 
mshn addresses uncertainty due unpredictable loads operating environment 
various task mapping scheduling algorithms developed 
research part mshn effort 
communication performance presence multiple heterogeneous networks investigated 
experiments performed local cluster workstations interconnected atm ethernet fibre channel networks 
performance characteristics networks evaluated measuring time sending messages various sizes particular network 
characteristics choose suitable technique data communication 
performance path selection technique selects networks communication event depending size message 
aggregation technique uses multiple networks time breaking message multiple parts sending parts different networks 
research considered pointto point communication pair nodes system 
collective communication patterns studied 
collective communication patterns typically occur parallel applications 
distributed heterogeneous computing important military applications 
battlefield awareness data dissemination program darpa aims develop operational distributed data communication system 
goal deliver accurate timely consistent picture battlefield provide access key transmission mechanisms worldwide data repositories 
considers important data staging problem arises heterogeneous networking environments data items moved initial locations requester nodes 
data request time deadline priority associated 
heuristic multiple source shortestpath algorithm find communication schedule data staging problem 
section mention collective communication pattern communication model timing diagrams scheduling techniques communication schedules network characteristics directory service 
communication scheduling approach 
related problems 

approach uniform framework communication scheduling shows approach developing adaptive communication techniques essential applications 
communication scheduling framework consisting key components directory service ii analytical communication model iii timing diagrams iv scheduling algorithms 
directory service provides information current network performance 
information application communication pattern communication model compute time node node communication event 
represented timing diagram 
scheduling algorithm uses timing diagram input appropriately schedules events reduce communication time 
discuss components detail 

directory service network load shared environments varies time directory service provides information current network performance essential 
suitable directory infrastructure key component framework developing adaptive communication techniques 
ames anl ind usc isi ncsa ames anl ind usc isi ncsa table 
latency ms gusto sites 
ames anl ind usc isi ncsa ames anl ind usc isi ncsa table 
bandwidth kbits gusto sites 
information provided directory possible develop communication schedules adaptive changes network performance 
run time applications query directory service application programming interface 
example metacomputing directory service mds globus provides current information start costs bandwidths pair processors 
remos api developed cmu example api independent details network hardware 
table examples information provided directory service gusto testbed globus 
directory provides current values network latency bandwidth pair computing sites 
tables show gusto sites nasa ames argonne national lab university indiana usc isi ncsa 
directory service takes account current network load including load imposed application 
paths distinct node pairs share common link bandwidth common link divided communicating pairs 

communication model communication model analytically represent network performance 
information application communication pattern performance parameters provided directory service communica tion model estimate time node communication events 
consider typical metacomputing system shown 
path compute nodes typically includes links multiple networks different bandwidths 
example message node site node site pass local network sites long haul link interconnects geographically distributed sites 
communication model represents network formance processor pair parameters start cost data transmission rate time sending byte message nodes parameters abstractly represent total time traversing links path model ignores negligible delays incurred contention intermediate links nodes path model focuses effective network performance application layer 
assume availability endto send receive communication routines invoked pair processor nodes 
details network topology routing flow control policies visible application model incorporate parameters 
similar communication model widely tightly coupled distributed memory systems results 
metacomputing systems typical values start cost range ms typical values bandwidth range kb hundreds mb model assumes node allowed simultaneously participate send receive operation 
node multiple messages send performs send operations 
current hardware software easily enable multiple messages transmitted simultaneously 
software support nonblocking multithreaded communication allow applications initiate multiple send receive operations 
operations eventually serialized single hardware port network 
model accurately represents phenomenon 
multiple nodes simultaneously send node say node contention occurs model assumes messages received assumption seen examining events involved message transmission control message transmitted actual data sent control message acknowledged busy receiving different node sends completing previous receive operation 

timing diagrams timing diagrams represent communication schedules network characteristics communication pattern 
examples timing diagrams personalized communication processors shown figures 
diagram consists columns processor 
vertical axis represents time 
communication events column represent messages sent processor rectangle labeled column represents message sent height rectangle denotes time communication event message sizes values processor pairs known heights rectangles determined 
timing diagram inherently absorbs heterogeneity network parameters message lengths 

scheduling algorithms communication scheduling algorithms determine positions individual events timing diagram completion time minimized 
valid communication schedule satisfy conditions node send multiple message simultaneously rectangles column overlap time 
similarly multiple simultaneous receive events permitted processor rectangles label mutually disjoint time intervals 
consider indirect schedules messages different sources combined intermediate nodes forwarded common destinations 
combine forward schemes increase volume traffic communicated 
data metacomputing applications extremely voluminous lead large communication costs 
allow messages partitioned 
start overhead incurred message transmission partitioning increase start overheads 
section presents scheduling algorithms personalized communication pattern 

scheduling algorithms total exchange section develop communication scheduling algorithms total exchange personalized communication 
briefly describe known communication algorithm problem 
section shows perfor receive schedule similarly constructed communication events column represent messages received processor width rectangle significance 
mance improvements achieved new algorithms algorithm 

communication pattern scheduling complexity personalized communication occurs frequently hpc applications 
example consider twodimensional matrix initially distributed rows processors 
matrix transposed final distribution columns processor resulting communication pattern personalized communication 
compute node distinct message node system 
processor system communication pattern consists communication events 
message sizes pairs nodes necessarily 
network heterogeneous individual communication events timing diagram different lengths 
communication events timing diagram efficiently scheduled 
goal reduce completion time communication schedule time communication event completed 
observe completion time schedule summation send times receive times processor whichever larger 
lower bound completion time 
analyze complexity communication scheduling problem state decision problem 
tot exch distributed heterogeneous system processors deadline communication matrix time communication event communication schedule completion time equal theorem tot exch np complete proof theorem proved transformation open shop scheduling problem 
problem consists machines jobs 
machine performs task job execution time tasks matrix 
dependences tasks job 
restrictions sequence tasks executed 
machine job time job processed machine time 
goal schedule tasks machines minimize finish time 
problem known np complete 
details proof 

baseline algorithm total exchange communication scheduling problem np complete developed heuristic algo time 
example problem 
rithms 
baseline algorithm performance comparison heuristic algorithms shall caterpillar algorithm widely tightly coupled homogeneous systems 
generates schedule steps 
step compute node sends message 
schedule incur node contention homogeneous system message sizes network bandwidths uniform 
communication events duration rectangles timing diagram height 
important disadvantage baseline algorithm derives fixed schedule adaptive variations message lengths network performance 
illustrate scheduling techniques running example 
shows example communication problem represented timing diagram formalism 
unscheduled communication events processor shown increasing order destination processor number 
examples assume diagonal entries zeroes 
valid time local memory copy operation negligible comparison time sending messages heterogeneous network 
baseline algorithm schedule shown derived 
observe longer communication events earlier steps cause communication steps delayed 
theorem performance bound baseline algorithm 

completion time baseline schedule times lower bound 
bound tight exist instances baseline schedule takes times lower bound 
time 
schedule generated baseline algorithm 
proof introduce notion dependence graph dg schedule 
directed graph nodes communication event 
directed edge node node exists sequential dependency corresponding communication events schedule 
shows dependence graph baseline schedule processors 
column contains communication events sent processor order appear schedule 
observe edges dg kinds vertical edges adjacent nodes column ii diagonal edges nodes adjacent columns 
correspondence exists graph dg communication matrix node dg corresponds entry vertical edge exists nodes correspond entries column diagonal edge nodes correspond entries row path dg baseline schedule contains nodes edges 
completion time equal weight longest path graph 
nodes longest path 
adjacent nodes path belong row column definition rewrite eq 
dependence graph baseline schedule 
eq eq prove tightness bound consider communication matrix element 
case dependence path consists elements 
element diagonal 
adjacent elements path row column 
case element path immediate left element immediately critical path contains unit time entries takes units time 
lower bound arbitrarily small numer 
element 
example 
matching scheduling techniques matching scheduling techniques total exchange problem 
technique finds series maximum weight matchings bipartite graph 
consider variation minimum matchings 
algorithm partitions communication events independent steps graph matching algorithms 
node system construct bipartite graph vertices side 
edge left side right side assigned weight equal time communication event edges bipartite graph 
complete matching graph consists edges corresponds permutation matching represent valid communication step contention processor 
known algorithms exist finding maximum weight complete matching 
identical linear assignment problem 
complexity algorithm algorithm consists finding maximum weight complete matching graph deleting edges matching graph repeating process matchings 
total complexity schedule finds communication events step step communication phase impose synchronization processors step 
communication event sending receiving processors ready 
theory completion time matching techniques times lower bound 
prove result similar part theorem 
practice performance significantly better bound tight 
fixed schedule derived baseline algorithm matching schedule adaptive 
lengths communication events change variations network performance algorithm finds different schedule low completion time 
section presents simulation results 
example adaptive maximum matching algorithm derives schedule shown 
matching technique groups communication events similar length reducing idle cycles 
optimal schedule example exists processor busy entire schedule 

greedy technique greedy technique approximation matching technique lower computational complexity 
initially communication events processor time 
schedule generated series maximum matchings 
rank ordered decreasing order communication time 
series communication steps composed 
composing step traverse rank ordered list processor goal finding destination processor 
destination processor processor list selected processor previous step destination processor step 
list reached finding destination processor step proceed processor 
due incom plete steps total number steps larger ensure fairness processor idle step pick destination processor step 
idle processor step processor step step 
greedy algorithm computational complexity description clear greedy algorithm adaptive lengths communication events 
previous example communication schedule derived greedy algorithm shown 

open shop technique communication problem similarities open shop scheduling problem developed scheduling algorithm heuristic derived open shop problem 
approximate algorithms open shop problem 
processor considered independent entities sender receiver 
data structures maintained algorithm sender set receivers maintained 
initially consists receivers send message 
communication time 
schedule generated greedy algorithm 
event scheduled appropriate receiver deleted receiver set 
element arrays contain information availability corresponding senders receivers 
example element specifies earliest time sender participate send operations 
elements arrays initialized 
algorithm proceeds follows sender available time sen receiver set scanned earliest available receiver selected 
communication event scheduled time max 
assigned value sender receiver busy time 
fur ther deleted multiple senders available time example time processed arbitrary order 
senders available time processed senders available time 
algorithm maintains list senders increasing order time availability 
sender finished operations deleted list 
senders deleted 
total number communication events sched scheduling event takes time 
schedule generated open shop algorithm 
time elements corresponding receiver set scanned 
algorithm runs time observe algorithm greedy 
time sender free heuristic assigns communication event elements receiver set 
idle cycles inserted sender schedule potential receivers available 
schedule derived heuristic shown 
theorem open shop heuristic algorithm guaranteed find communication schedule completion time twice lower bound 
proof assume loss generality sender finish transmissions receiver sends message 
deduced idle cycles sender schedule receiver busy 
case algorithm scheduled communication event time 
conclude sum idle cycles sender schedule bounded total time communication events having receiver sum elements row completion time sum total time send events sender sum elements column idle cycles sender completion time sum row column communication matrix twice lower bound 

experimental results developed software simulator executes scheduling algorithms discussed section calculates completion time 
simulator accepts processor count communication times input generates schedules techniques 
simulation tool evaluate baseline maximum matching minimum matching greedy open shop scheduling techniques 
simulator generates random performance characteristics pairwise network performance information gusto directory service guideline 
communication matrix generated fixed message size 
selected message sizes kb mb random mix sizes 
experiments assume diagonal entries zeroes 
valid time local memory copy operation comparison time sending messages heterogeneous network 
scheduling techniques applied communication matrix 
results different message sizes shown figures 
systems processors considered 
considers scenario processors designated servers 
message sizes servers client processors assumed large 
message sizes servers client processors small 
typical multimedia applications images video clips reside servers accessed processors 
experiment processors assumed servers 
data assumed partitioned servers load servers balanced 
seen baseline algorithm performs poorly scenarios 
algorithms perform times faster baseline examples 
graphs clearly show performance improvements achieved communication scheduling techniques 
open shop algorithm finds schedules close lower bound 
maximum minimum matching techniques find schedules comparable completion times 
lower bound 
schedules generated greedy algorithm lower bound 
schedules generated baseline algorithm take upto times longer lower bound 
results open shop algorithm achieves best performance 

enhancements research previous sections approach developing communication scheduling techniques adaptive network performance variations 
best knowledge early efforts formalizing communication problems relevant network computing 
exciting research issues remain explored 
section discuss research di time milliseconds time milliseconds communication times small message sizes kb left right lowerbound heuristic maximum matching minimum matching greedy algorithm baseline number processors 
simulator results personalized communication small message sizes 
communication times large message sizes mb left right lowerbound heuristic maximum matching minimum matching greedy algorithm baseline number processors 
simulator results personalized communication large message sizes 
time milliseconds time milliseconds communication times mixed message sizes kb mb left right lowerbound heuristic maximum matching minimum matching greedy algorithm baseline number processors 
simulator results personalized communication mixed message sizes 
communication times client server scenario left right lowerbound heuristic maximum matching minimum matching greedy algorithm baseline number processors 
simulator results personalized communication processors servers 
servers send large messages clients 
motivated need network aware communication scheduling 

enhancing model scheduling algorithms developed simple effective communication model 
section mentioned assumptions model validity assumptions 
enhanced versions model formulated relaxing assumptions 
example restriction processor send receive message time 
restriction relaxed ways 
multiple messages arrive node assume messages received interleaved fashion 
example multithreading allows multiple simultaneous communication events nexus 
additional parameter introduced overhead incurred context switching multiple receiving threads 
times messages total time receiving simultaneously assumed finite buffer space available nodes receive messages 
multiple messages arrive node messages received application queued buffer 
sending nodes wait receive operation complete message stored buffer 
buffer full sender wait adequate free space created buffer 

incremental dynamic scheduling communication schedules section computed run time information obtained directory service 
sensor applications series continuously arriving data sets processed identical manner 
cases overhead repeatedly calculating communication schedule run time expensive especially number processors large 
necessary develop scheduling techniques significantly lower computational costs 
incremental approach way reduce complexity deriving dynamic communication schedules 
communication schedule computed compile time run time occurrence 
subsequent invocation incremental algorithm refine communication schedule find new communication schedule 
algorithm query directory service regarding changes bandwidths 
context research problem developing fast algorithms refining existing communication schedule 

enhancing adaptivity schedules scenarios lengths communication events may known communication started 
happen variations network performance rapid significant changes occur duration communication schedule 
cases initial communication schedule derived estimates communication times 
schedule modified intermediate checkpoints 
checkpoints processors decide difference estimated time actual time large require rescheduling 
checkpoints defined different ways communication event complete checkpoints half remaining communication events complete checkpoints 

scheduling critical resources qos constraints discussed communication schedules goal minimize completion time 
scenarios cost measures important 
example processors heterogeneous system critical resource expensive supercomputer 
schedule complete communication events processor early possible delays processors 
quality service qos requirements applications introduce variations problem formulation 
example data forwarding data staging problems arise project 
qos parameters associated message deadlines priorities 
communication schedule ensure data items reach destinations specified real time deadlines 
multiple communication events contend communication link scheduling algorithm sequence respective deadlines priorities 

developed uniform framework communication scheduling heterogeneous networkbased systems 
framework consists directory service communication model timing diagrams scheduling algorithms 
discussed approach design adaptive communication techniques applied problem personalized communication 
problem thoroughly researched homogeneous systems showed known algorithms perform poorly presence network heterogeneity 
developed algorithms bipartite graph matching heuristic algorithms open shop scheduling 
showed algorithms performed significantly better known homogeneous communication scheduling algorithm 
algorithms adaptive execute run time network performance information obtained directory service 
best knowledge early efforts formalizing communication problems distributed heterogeneous computing environment 
discusses new research problems related communication scheduling network systems arise due unique features environments 
include communication scheduling qos constraints techniques reduce complexity scheduling algorithm 
acknowledgments roy jonker optimization public domain program solve linear assignment problem 
routine find matchings algorithms 
craig lee paul aerospace members mshn project helpful technical suggestions 
armstrong hensgen kidd 
relative performance various mapping algorithms independent sizable variances runtime predictions 
proc 
heterogeneous computing workshop pages march 
bala cypher ho 
ho snir 
ccl portable tunable collective communication library scalable parallel computers 
ieee trans 
parallel distributed systems february 
bhat prasanna raghavendra 
adaptive communication algorithms distributed heterogeneous systems 
manuscript dept ee systems university southern california may 
werner 
constructive heuristic algorithms open shop problem 
computing 
brucker 
scheduling algorithms 
springer 
darpa iso web page program 
https www iso darpa mil wd cgi get iso office information system home frames 
dewitt gross lowekamp miller steenkiste sutherland 
remos resource monitoring system network aware applications 
cmu cs school computer science carnegie mellon university dec 
fitzgerald foster kesselman von smith tuecke 
directory service configuring high performance distributed computations 
proc 
th ieee intnl 
symp 
high performance distributed computing pages 
foster kesselman 
globus metacomputing infrastructure toolkit 
intl 
journal supercomputer applications 
globus web page 
www globus org 
gonzalez sahni 
open shop minimize finish time 
journal acm oct 
grimshaw wulf 
legion view feet 
proc 
fifth ieee intl 
symp 
high performance distributed computing august 
jamieson mueller siegel 
fft algorithms simd parallel processing systems 
journal parallel distributed computing march 
kim lilja 
exploiting multiple heterogeneous networks reduce communication costs parallel programs 
proc 
workshop pages april 
kim lilja 
utilizing heterogeneous networks distributed parallel computing systems 
proc 
sixth ieee intl 
symp 
high computing 
brown eds 
virtual environments distributed computing sc gii testbed hpc challenge applications way 
acm ieee supercomputing 
lawler 
combinatorial optimization networks matroids 
holt rinehart winston 
legion web page 
legion virginia edu 
lim bhat prasanna 
efficient algorithms block cyclic redistribution arrays 
algorithmica appear 
maheswaran siegel 
dynamic matching scheduling algorithm heterogeneous computing systems 
proc 
heterogeneous computing workshop pages march 
mshn web page 
www cs nps navy mil mshn 
shmoys stein wein 
improved approximation algorithms shop scheduling problems 
siam comput june 
catlett 
metacomputing 

acm june 
tan siegel beck 
mathematical model heuristic simulation study basic data staging problem environment 
proc 
heterogeneous computing workshop pages march 
valente ra kim kim bing ye 
software architecture virtual distributed computing environment 
proc 
sixth ieee intl 
symp 
high performance distributed computing 
web page 
www atm syr edu projects vm index html 

wang bhat prasanna 
highperformance computing vision 
proceedingsof ieee july 
