interactive locality optimization numa architectures tao mu jie tao lehrstuhl und department informatics technische universit nchen optimizing performance shared memory numa programs remains black art requiring application writers possess deep understanding programs behaviors 
difficulty represents remaining widespread adoption deployment cost efficient scalable shared memory numa architectures 
address problem developed performance monitoring infrastructure corresponding set tools aid visualizing understanding subtleties memory access behavior parallel numa applications large datasets 
tools designed general interoperable easily portable 
give detailed examples particular tool set 
memory access visualization tool profitably range applications improving performance average 
cr categories programming techniques concurrent programming parallel programming software engineering testing debugging diagnostics keywords performance visualization interactive locality optimizations numa architectures distributed systems motivation shared memory machines numa non uniform memory access characteristics increasingly attractive high performance computing 
architectures combine cost efficiency scalability traditional massive parallel processor systems programmability smps symmetric multiprocessors 
commodity building blocks usually smps connected scalable interconnect fabric capable transporting memory requests 
interconnects introduce explicit numa property shared memory systems differences local remote memory access latencies orders magnitude 
shared memory applications transparent data distributions nodes incur high overheads due excessive remote mail mu tum de mail tao tum de mail schulz csl cornell edu mail sam csl cornell edu martin schulz sally mckee computer systems laboratory school electrical computer engineering cornell university memory accesses 
minimizing number remote accesses crucial performance turn usually requires suitable application specific data distribution 
general choosing data distribution remains challenge 
existing approaches rely compile time optimizations deduce suitable data distribution 
known example split compiler krishnamurthy yelick capable analyzing cyclic dependencies interfering accesses eliminating communications data reuse 
example optimized fortran compiler navarro zapata developed university malaga 
compiler finds efficient iteration data distributions newly defined locality communication graph uses reduce number accesses remote memory locations 
compiler schemes limited static program information 
complex implementation integrated compilers 
automating data distribution disallow user interaction generally fail exploit user knowledge application structure 
addition incorporate dynamic run time information 
limitations restrict accuracy compile time analysis resulting suboptimal data placement decisions 
alternative approach comprehensive visualization tool 
tool depict run time data locality shared memory applications numa environments mapping behavior individual data structures data elements 
provides user concrete visual description data access patterns exhibited application impact data locality 
combined programmer knowledge application information helps direct programmer choose appropriate data distribution implemented source code annotations os distribution primitives 
optimizations sample codes shown average benefit improvement execution time 
tool acquires performance data suitable global monitoring facility numa system 
presents data form graphical views 
views provide spatial resolution show memory accesses respect corresponding addresses 
enables tool directly extract locality addressed memory cell map information appropriate data structures source code 
tool views transform source related information appropriate visualizations projecting performance data top graphical representations data structures arrays array elements 
tool provides ability visualize changing behavior program phases allowing easier identification changing access patterns 
remainder discuss locality problems numa systems 
introduce tool environment give detailed description visualization tool showing example find data placement 
global process local access thread thread thread thread system bus cpu cache memory remote access nic numa interconnection fabric system bus memory cpu cache nic hw dsm sample configuration numa machine 
locality numa systems high scalability ease programming afforded numa architectures increasingly popular high performance parallel computing 
problems lack accepted shared memory programming standards potential difficulty identifying addressing performance bottlenecks class architectures slowed adoption 
focus instance problem identifying beneficial data distributions memory performance 
approach uses tools creation determine data locality large datasets 
locality distribute data nodes global memory system 
depicts typical numa system 
individual building blocks nodes containing memory systems associated cpus constituting smp 
building blocks communicate interconnection fabric relays memory transactions nodes 
distributed memory machine provide coherence mechanisms coordinate memory accesses nodes 
range hardware schemes cc numa machines archibald hybrid solutions relaxed consistency models schulz 
top hardware capabilities os appropriate run time layer creates global process abstraction 
abstraction provides threads identical virtual memory spaces 
numa systems exist tightly coupled single vendor machines commodity clusters special system interconnect scalable coherent interface sci ieee computer society 
academic research projects focused shared memory numa architectures example toronto numa machine stanford flash heinrich 
machines combine scalability traditional message programming abstraction shared memory multiprocessors 
opens systems wider class applications suffering typical smp scalability problems 
traditional shared memory machines uniform memory access uma numa machines introduce distinction local remote memories order gain scalability 
difference slow fast access latencies orders magnitude codes exhibiting remote memory accesses incur huge memory overhead costs 
reducing overheads optimize application performance requires data distributed machine accesses satisfied local memories 
data distribution may effected annotations added source code location hints os run time system responsible global data allocation compiler optimizations appropriate code restructuring automatic data thread migration schemes 
locality optimization approach describe independent distribution mechanism 
unfortunately optimizing data locality complex task 
requires extensive knowledge application dynamic access behavior 
static approaches application independent run time mechanisms generate optimal solution 
generating solutions usually requires exploiting programmer knowledge application behavior 
built interactive graphical tool allows user visualize dynamic line access behavior applications 
tool gives user necessary information choose appropriate data distribution improve application performance 
tool design implementation section describes design goals support provided hardware target platform middleware layer exploits capabilities 
components adhere online monitoring interface specification omis making retargetable systems offering required monitoring capabilities making interoperable tools working concurrently application 
design requirements built toolset defined set design requirements adjustable level detail 
tool provide users overview complete application access behavior views detailed behavior specific execution regions single loop nest data segments individual memory page 
telescoping allows user high level behavioral view successively refine focus study observed hotspots bottlenecks 
ability correlate behavior data structures 
visualization tool map gathered behavioral data back instructions data structures source code 
memory addresses statically visible application program precisely correlation allows user achieve toolset goal allowing explicitly stated appropriate data placement specification source code 
multiple phase analysis 
behavior changes different phases application visualization cumulative behavior may hide differences 
tool needs show access patterns different program phases may explicitly specified may identified barriers locks synchronization mechanisms 
allows user detect specific locality requirements execution phase enables comprehensive optimization strategies 
online data processing 
avoid need storing performance data trace files usually necessary post mortem systems visualization tool able process acquired data online 
means monitoring data delivered visualizer time point execution target application 
addition avoid large trace files advantage online approach allows user monitor current status memory operations having wait execution complete 
sense visualization tool interactive allowing user issue requests processing visualizing monitoring data produced 
interactivity enables user choose appropriate various graphical views phase execution 
architecture independence 
useful visualization tool general independent specific target architecture 
tool top parallel numa system equipped adequate monitoring facilities 
addition cooperation simulation platforms allows user study performance greater detail replay executions study behavior numa systems 
tool interoperability 
performance visualization tool part set tools required users efficiently exploit numa architectures 
addition tools debuggers load check pointers need coexist cohesive performance optimization environment 
tool infrastructure requirements specifically need online processing architectural independence interoperability satisfied monolithic tool require comprehensive monitoring infrastructure 
smile schulz omis projects developed implemented infrastructure toolset parallel distributed programming 
overview infrastructure shown 
composed modules hardware monitors layers execution environment tool middleware data aggregation interoperability issues performance tools capable steering execution parallel programs 
section briefly outlines components 
tool middleware omis ocm toolset visualization tool adaptive runtime system load balancer high level layers hardware monitors node local resources execution environment tool environment memory performance tuning 
numa monitor 
prerequisite performance tuning respect memory system access information memory transactions system 
generally performance data acquired instrumenting program code source object level 
shared memory system hardware monitors needed shared memory traffic implicit occurring run time transparently issued load store operations 
addition shared memory communication finegrained normally word level 
renders code instrumentation infeasible necessary record global memory operation 
slow execution significantly distort final monitoring point unusable accurate performance analysis 
viable alternative deploy minimally intrusive hardware monitoring facility observing actual link traffic numa interconnection network 
designed hardware monitor 
capable snooping synchronous local bus network interface memory transactions processor nodes transferred 
information carried transactions extracted stored set counter arrays diverted ring buffer main memory 
monitor information available processing higher software layers 
addition hardware monitor reset restarted program execution 
enables acquisition phase information analyze applications dynamic access patterns 
monitoring information purely physical addresses 
property renders useless direct evaluation application level parameterization programmable logic run time 
layers execution environment needed order transform physical addresses collect information synchronization operations generally critical performance impact shared memory applications 
middleware 
performance data gathered processor node comprises memory operations originating node 
tools need provide user global view monitored system require combined data nodes 
monitoring interface needed distributed data globally accessible tools 
addition shared memory tools operate top system 
desirable run concurrently attached application raises issues regard interoperability 
context interoperability means line tools observe possibly modify target system 
omis ocm monitoring system interface tools low level execution monitoring environment 
omis line monitoring interface specification specification interface programmable line monitoring system distributed computing tools reside top 
offers interfaces interaction different tools interaction program run time system layers 
ocm ller omis compliant monitoring system adhering omis 
implemented series loosely coupled environments including clusters initially designed message passing tools 
structured core extensions 
designed independent programming model paradigm immediately reused shared memory monitoring 
monitor remote memory accesses synchronization additional extensions added recognize special constructs shared memory programming including regions memory synchronization structures coherence information 
interoperable toolset 
top tool middleware comprehensive toolset shared memory applications developed deployed retrieve process display information acquired system 
tools potentially interoperate exchange information coordinate interaction application prevent mutual disturbances 
instance dynamic load balancer requires permission adaptive runtime system automatically migrates data locality decides move parallel process node 
toolset currently includes tools message passing pvm ller tools shared memory paradigms ars transparently migrate pages achieve better load locality distribution tao dlv visualize locality behavior tao 
simple predecessor tool 
lacks ability map information data structures display information separated phases showed initial promise approach 
visualizing access behavior satisfy requirements set forth developed new locality visualization tool provides comprehensive information application access patterns 
project builds experience dlv project 
section describe architecture views behavioral data gathers 
software architecture visualization tool uses client server infrastructure coordinate interoperation target system users visualization facilities 
shown infrastructure contains graphical user interface gui server visualizer 
online gui view selection execution control online steering gui execution control user input monitoring facility parallel system numa system simulation monitoring information server monitoring middleware performance data control visualization infrastructure 
visualization gui execution control view selection online steering 
consists different parts part allows user specify commands parameters executing simulating application second part allows user select graphical view interest 
control information execution delivered target systems visualization requests transfered server 
components connected tcp ip links allowing physical distribution system 
means machine running application observation operate separately machine running actual visualization tools advantages 
visualization tools compute intensive heavily machine resource interfering performance target application studied appropriate special rendering equipment may exploited happens available 
core infrastructure server receives user view selections 
requests monitoring middleware performance data initiates visualizer preparation generating specified graphical view 
server handles user requests concurrently processing delivered monitoring data 
built top server visualizer shows user required information easily understood representations 
source data usually correct form specific view visualizer component performs appropriate data filtering aggregation 
noted performance data visualization gathered monitoring facilities numa architectures 
hardware monitor project initial phases date focused types monitors realized working hardware 
order study locality optimization approaches described kinds data optimization techniques numa architectures implemented flexible simulation platform called tao 
initial motivation model hardware monitor resulting simulation system comprehensive toolkit serves performance predictor system modeling tool experimenting new designs application optimizer 
model large range numa systems varying numbers processors different memory hierarchies access latencies data distributions 
accurately models hardware monitor described section provides information hardware monitor 
data passes omis ocm infrastructure compressed preprocessed way real system 
simulation models infrastructure enables full testing validation visualization tool hand tool full functionality optimize applications 
sample views visualization tool offers set views show various aspects memory accesses performed parallel system 
includes initial views tao virtual addresses higher level representations concerning data structures dynamic accessing patterns 
sample views illustrate tool functionality come splash benchmark suite woo 
fourier transformation program fft working set data points molecular dynamics water code computes body problem molecules 
model cluster pcs distributed shared memory 
node modeled timing properties intel pentium ii processor running mhz 
processors contains direct mapped cache kbytes way set associative cache kbytes 
caches cache line size bytes 
accesses satisfied cache assumed consume cycle accesses data cache cycles accesses memory local remote accesses respectively 
system uses protocol archibald maintain consistency caches separate nodes 
experiments sections node cluster configuration 
overview 
visualization tool provides diagram giving overview memory accesses complete working set 
illustrates sample diagram generated simulating fft node system 
summary diagram presents accesses virtual pages processors 
line diagram represents page number left location implied color page number 
corresponding page number accesses performed node highlighted nodes specified colors 
pages example accesses performed multiple nodes node red issued accesses 
note pages accessed single node unfortunately local 
indicates pages allocated local node reduce number remote memory accesses 
overview memory accesses fft 
accesses data structures water 
data structure correlation 
summary diagram sufficient generating optimized data distribution 
shows user overview highlights potential places locality improvements 
concrete optimizations data structure view suitable directly shows memory accesses performed working arrays program 
data structure view uses forms adapt different dimension arrays 
arrays single dimension higher dimensions uses small squares show dominating accesses performed element array 
elements placed diagram order arrays 
diagrams may required large arrays containing elements single diagram hold 
dimensional arrays matrix 
small squares represent array elements placed diagram represent actual order dimensional array 
provides user natural intuitive mapping actual array organization source code 
illustrates sample view accesses individual molecules water evaluates forces potentials system water molecules 
block diagram represents individual molecule 
color blocks indicates node performs accesses corresponding data structure accesses time phases water 
node accesses 
diagram helps direct users allocate data dominating nodes 
correlations memory access patterns data structures done support target systems 
purpose mapping table virtual addresses corresponding data structures 
table initialized annotations introduced source code symbol tables executables 
case translation part services offered monitoring middleware hidden user 
phases 
addition set views visualization tool provides views exhibit phase access behavior temporal information 
phases identified barriers locks synchronization mechanisms 
sample view water shown 
seen views show memory accesses performed program phase 
phase graph shows accesses virtual pages program 
page represented colored bar showing accesses nodes 
higher bar accesses performed corresponding nodes 
enables easy detection dominating node virtual page 
addition view rotated enabling change focus individual phase observation changes access behavior phases 
gives example different access patterns different phases 
pages accessed red node phase nodes active second phase 
indicates applications special allocation performed phase 
initial data placement static views potentially generate best performance 
accumulated view phases failed show behavior led incorrect 
addition multi phase views tool allows restriction views particular phases enabling user examine hotspots bottlenecks phase basis 
optimization sample code goal visualization tool help user analyzing run time data layout applications optimizing source code respect data locality 
section demonstrate easy follow sample code go data structure view find correct location working data 
tasks 
lu program splash benchmark suite 
lu performs lu decomposition dense matrices 
primary data structure matrix decomposed 
matrix divided blocks user specified size processor assigned subset blocks 
program executed processor pc cluster connected scalable coherent interface sci state art numa interconnection technology low latency high bandwidth 
code spmd programming model shared data distributed round robin system 
initial application performance poor achieves slight parallel speedup sequential version 
example speedup gained processors matrix 
find cause performance problems simulated parallel execution lu code configuration cluster 
tool visualize memory access behavior analyze run time data layout information optimize source code 
steps explain process detail 
static optimization step examine overview diagram see data accessed local nodes 
turns accesses occur remote memories cases clearly dominating node exists 
initial observation suggests profitably data structure view detect predominant accesses individual elements matrix 
shows matrix elements accessed blocks subsequent lines predominantly accessed node 
example lines predominantly node lines accessed node lines node zero 
pattern strict universally applicable array cells experience different access behavior 
coarse grained optimization necessary address special cases 
observed block characteristics reallocate lu matrix lines dominating nodes 
run optimized code cluster time achieving speedup 
view analyze allocation requirement different program phases 
phase information static optimization parallel speedup low compared number processors 
motivates examine phase information view showing memory accesses virtual page 
shows phase wise view lu code 
memory access behavior lu differs greatly program phase 
instance pages accessed node zero phase deduced fact host node case node zero performs data initialization computation starts 
phases significant distinction seen pages required node required nodes 
view demonstrates lu code optimized phases account 
data structure views 
example shows accesses matrix second phases 
view matrix elements needed node zero phase allocated node 
second phase nodes predominantly accessing matrix line change significantly requiring memory reallocation data migration 
phases analyzed similarly phase specific data distribution chosen 
run fine tuned lu code time realizing speedup 
summary optimization lu code demonstrates feasibility approach 
optimized splash applications kernels manner 
experiments show applications regular access patterns significant improvement achieved static optimizations 
applications dynamically changing access behavior phase optimizations determined studying views example may necessary 
conducting initial investigations framework toolset case far succeeded choosing memory layouts experience visualization tool introduce better data locality deliver higher performance 
accesses lu matrix top second phase bottom 
related visualization tools widely supporting programmers understand execution memory behavior applications 
representative examples paragraph ips paradyn pablo 
paragraph heath example early class trace dynamic visualization tools emphasize optimization message passing codes display communication network topologies 
paragraph supports levels system representation detecting tracking performance bottlenecks 
level profile data complete program execution 
level possible evaluate system performance identify processor states nodes cause performance losses 
level process processor states interaction displayed detail time axis 
allows identify sequence actions program causes efficiency losses detected 
early performance visualization tools paragraph design assumption application execution model maps directly programming model 
addition paragraph restricted number nodes due trace files 
ips miller performance instrumentation visualization tool developed university wisconsin relies hierarchical approach 
hierarchy represented tree root represents program branches represent machines processes 
allows look data complete system individual nodes processes procedures 
paradyn miller direct descendant ips performance measurement tool large scale parallel distributed programs 
builds ips exploratory model bottleneck identification supporting dynamic notion performance instrumentation measurement 
provides simple interface visualize search bottlenecks performance data collected instrumented execution program 
ips paradyn provide single graphical interface simple views allowing detailed analysis performance bottlenecks 
addition detections causes performance loss inaccurate predefined notion lacks dynamic information analysis 
pablo research group university illinois developed performance analysis tools including pablo reed derose 
pablo extensible performance instrumentation analysis toolkit 
design focus pablo performance analysis graphical data flow programming model 
originally developed support parallel systems distributed memories portions pablo infrastructure augmented support analysis applications written variety languages executing sequential parallel systems 
effort derived joint project university illinois rice center research parallel computation resulted 
language independent performance analysis visualization system 
relies single interface performance instrumentation visualization 
interface supports hierarchy performance displays ranging color coded routine profiles detailed data behavior source code line single processor 
performance data related application source code compile time program transformations 
software instrumentation systems results slowdown program execution necessity store large trace files 
lack ability show key performance issues communication bottlenecks system hot spots 
bosch visualization tool included evolving system analysis visualization parallel application performance shared memory multiprocessors 
detailed views application memory system behavior 
composed views providing detailed information memory system behavior application 
code view displays memory stall times relation source code 
simple bar charts indicate total percentage memory stalls attributed source file 
memory view shows memory stall times physical virtual addresses 
histograms drawn physical code virtual memory addresses 
process utilization argus process time shown process view 
strip chart drawn process indicating fraction time process spent doing useful waiting requests local remote memories 
summary existing systems described instrumentation data collection simulation 
paragraph instruments message passing subsystems distributed memory multiprocessors pablo paradyn perform instrumentation applications 
systems try minimize perturbation caused data collection behavior applications study affected instrumentation 
order avoid problem relies hardware monitors allow non intrusive access machines program states 
visualization goal systems focus utilization system resources cpu processes 
kind pre sentation aims directing users improve task scheduling result better load balancing 
visualization tool described focuses memory system goal improving run time data locality 
point view memory system visualization done similar 
provides information memory stall times specify correct placement data 
contrast visualization tool presents arbitrary aspects application memory access behavior able direct user detect correct communication hot spots bottlenecks 
data locality optimizations core goal visualization tool closer profiling tool developed sgi 
samples program execution records program memory access information histogram file 
histogram manually plotted gnuplot allowing detect regions virtual memory thread program accesses direct explicit placement specific virtual memory range particular nodes 
report statistical sampling record 
addition numbers memory accesses shown page granularity allowing detailed understanding accesses single page 
restricts accuracy memory behavior analysis prohibits proper specification optimal data layout 
importantly integrate graphical representations presenting memory performance data 
programmers external tools create understandable diagrams 
contrast approach provides user comprehensive visualization toolkit enabling observation memory access pattern detection access hot spots 
continuing optimizing performance shared memory numa programs extremely difficult interactions parallel nodes layers system complex subtle 
performance tuning black art 
mitigating problem help remove remaining barriers adoption class architectures attractive sharedmemory numa machines easy program optimize cost efficient scalable smp cousins 
developed performance monitoring infrastructure corresponding set tools aid visualizing understanding subtleties memory access behavior parallel numa applications large datasets 
tools designed general interactive interoperable portable 
articles explain details underlying hardware monitoring support software components experimental system ller schulz schulz generate data shown 
detailed examples tool display different views dynamic memory access behavior running application 
range views provide overview total application behavior views map performance data individual data structures elements 
views provide adjustable level detail restricted individual program phases 
memory access visualization tool profitably range applications 
succeeds conveying information required user optimize application data layout 
fact just relatively straightforward locality visualizing capabilities described achieve impressive performance improvements averaging speedups applications study 
encouraging result motivates continue research direction 
extensions tool include support dynamic data structures lists trees special graphics hardware 
allow user better comprehend large data sets precisely steer evaluation 
ll extend scope toolset memory performance numa systems memory systems general including cache performance memory access scheduling 
result comprehensive versatile memory performance toolset 
archibald 
cache coherence approach large multiprocessor systems 
proceedings international conference supercomputing 
bosch stoll rosenblum hanrahan 
performance analysis visualization parallel systems simos rivet case study 
proceedings sixth international symposium high performance computer architecture 
ller 
omis compliant monitoring system mpi applications 
proceedings rd international conference parallel processing applied mathematics 

sgi products servers supercomputers sgi origin 
www sgi com origin dec 
origin onyx performance tuning optimization guide 
silicon graphics incorporation ch 

available sgi com library manuals pdf pdf 
derose 
approach immersive performance visualization parallel wide area distributed applications 
proceedings international symposium high performance distributed computing 
brown stumm 
design implementation multiprocessor 
proceedings conference design automation 
heath 
visualizing performance parallel programs 
ieee software may 
heinrich heinrich si moni gharachorloo chapin baxter horowitz gupta rosenblum hennessy 
stanford flash multiprocessor 
proceedings st international symposium computer architecture 
eds 

sci scalable coherent interface architecture software high performance computer clusters vol 
lecture notes computer science 
springer verlag 
karl schulz gonzales torralba 
design implementation aspects smile hardware monitor 
proceedings sci europe held conjunction euro par 
ieee computer society 

ieee standard scalable coherent interface sci 
ieee std ieee east th street new york ny usa august 
krishnamurthy yelick 
analyses optimization shared space programs 
journal parallel distributed computation 
miller clark hollingsworth lim 
ips second generation parallel program measurement system 
ieee transactions parallel distributed systems april 
miller callaghan hollingsworth kara 
paradyn parallel performance measurement tools 
ieee computer november 
navarro zapata 
automatic iteration data distribution method access descriptors 
proceedings th international workshop languages compilers parallel computing 
reed noe roth shields schwartz 
scalable performance analysis pablo performance analysis environment 
proceedings scalable parallel libraries conference 
schulz tao karl 
improving scalability shared memory systems relaxed consistency 
proceedings second workshop caching coherence consistency wc 
schulz tao karl 
smile integrated multi paradigm software infrastructure sci clusters 
proceedings ieee acm international symposium cluster computing grid cc grid 
tao karl schulz 
visualizing memory access behavior shared memory applications numa architectures 
proceedings international conference computational science iccs vol 
lncs 
tao schulz karl 
improving data locality dynamic page migration memory access histograms 
proceedings international conference computational science iccs vol 
lecture notes computer science 
tao schulz kar 
simulation tool evaluating shared memory systems 
proceedings th annual simulation symposium 
appear 
ller ludwig bode 
toolset project integrated tool environment parallel programming 
proceedings second german workshop advanced parallel processing technologies verlag dietmar koblenz germany 
ller 
interoperability support distributed monitoring system ocm 
proceedings rd international conference parallel processing applied mathematics 
woo singh gupta 
splash programs characterization methodological considerations 
proceedings nd annual international symposium computer architecture 
interactive locality optimization numa architectures color plates tao mu jie tao technische universit nchen martin schulz sally mckee cornell university accesses data structures water 
view analyze allocation requirement different program phases 
accesses time phases water 
top accesses lu matrix phase 
data structure view find correct location working data 
bottom accesses lu matrix second phase 
