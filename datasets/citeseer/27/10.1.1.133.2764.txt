top query evaluation probabilistic guarantees martin theobald gerhard weikum ralf max planck institute computer science germany weikum mpi sb mpg de top queries ranking elements multidimensional datasets fundamental building block kinds information discovery 
best known general purpose algorithm evaluating top queries fagin threshold algorithm ta 
user goal top queries identify relevant novel data items intriguing approximate variants ta reduce run time costs 
introduces family approximate top algorithms probabilistic arguments 
scanning index lists underlying multidimensional data space descending order local scores various forms convolution derived bounds employed predict safe high probability drop candidate items prune index scans 
precision efficiency developed methods experimentally evaluated large web corpus structured data collection 

motivation top queries multidimensional datasets compute relevant interesting results partial match query similarity scores attribute values regard elementary query conditions score aggregation function weighted summation 
fundamental building block information discovery arises important application classes web intranet search engines scores word occurrence statistics possibly combining criteria relevance link authority recency multimedia similarity search feature vectors images music video preference queries structured semistructured data product catalogs customer support data having major text component 
best known general purpose method top queries fagin threshold algorithm known ta independently proposed 
method assumes attribute multidimensional data space index list access data items descending order local score permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment proceedings th vldb conference toronto canada attribute regard elementary query condition tf idf score text keyword condition trumpet ontological similarity categorical attribute conditions genre jazz absolute distance numerical attribute conditions year 
ta method conservative stops scanning index lists certain top results 
believe overly conservative concept top query heuristic anyway 
hardly user interested looking exactly best matches similarity query 
rationale top ranking users typically find relevant novel data items top results 
inherent unavoidable risk missing truly best results subjective judgment user anyway 
turn justifies relaxing concept top query approximate notion query processor occasionally tolerate errors false positives false negatives regard top idea approximate top queries literature see 
terms analyzing lost relaxation prior introduced control parameters difficult tune homogeneity assumptions multidimensional data distributions 
main focus earlier image similarity search color texture contour feature spaces assumptions may justified 
furthermore relaxation control parameters distance slack factor models difficult translate user perceived guarantees 
contrast presents principled approach approximate top queries probabilistic guarantees error relative exactly top queries translatable guarantees query result precision recall 
approach cope heterogeneous distributions score variability may radically differ different text terms attributes semistructured dataset 
concentrate algorithms process index lists sorted access aiming high dimensional data spaces web xml documents queries need access potentially large number long index lists random accesses expensive 
approach allows aggressive index list pruning compared original ta method sorted access 
presents comprehensive experimental results demonstrate performance gains 
related state art top queries defined seminal threshold algorithm ta :10.1.1.55.2172
ta scans query relevant index lists interleaved manner aims compute global scores encountered data items means monotonic score aggregation function weighted sum max algorithm maintains worst score current top results best possible score candidates items encountered 
serves threshold stopping index scans candidate exceed score th ranked result 
algorithm comes variants 
ta random eagerly looks local scores encountered item knows full score immediately encounters item 
random accesses may expensive depending application setting infeasible alternative ta sorted method coined nra stream combine maintains worstscore best score bounds data items partially computed global scores stopping test compares worst score th ranked result best score candidates 
obviously ta random effective pruning index scans avoids expensive random accesses 
variants ta studied multimedia similarity search ranking query results structured databases distributed preference queries heterogeneous internet sources digital libraries restaurant reviews street finders 
marian particularly investigated deal restrictive sources allow sorted access index lists widely varying access costs 
heuristic scheduling approaches developed threshold condition stopping algorithm conservative ta style test 
top query algorithms literature include nearest neighbor search methods tree multidimensional index mapping techniques multidimensional range queries evaluated traditional database indexes 
context probabilistic estimators selection cutoff values developed applied multidimensional nearest neighbor queries 
ta centric studied ta random variant 
ta sorted hand regarded attractive variant resort specific circumstances 
large number potentially long index lists ta sorted method choice 
small number papers considered minimize random access costs ta random data sources vary speed selectivity 
simple histogram probabilistic estimators developed making scheduling decisions deciding source dimension random access 
prior attempted principled approach probabilistic score prediction result guarantees 
efficient processing index lists ranked retrieval old topic information retrieval ir research 
context sorted access rule game 
pruning techniques considered see heuristic nature trade loss result quality effectiveness ir jargon speed able predict control resulting effects experimentation 
special important case global score weighted sum tf idf text relevance link query independent authority additional pruning heuristics developed 
contribution approach predicting total score candidate item know partial score sum local scores elementary conditions total score conditions 
doing avoid overly conservative best score worstscore bounds original ta sorted method calculating probability total score exceeds threshold item interesting top result 
probability sufficiently low drop data item candidate list 
probabilistic prediction involves computing convolution score distributions different index lists 
explore variety techniques including histograms efficiently evaluable poisson estimations convolutions moment generating functions generalized chernoff hoeffding bounds resulting tail probabilities 
overhead techniques crucial details bookkeeping candidate testing strategies straightforward explore range strategies different setups priority queues 
best knowledge presents method probabilistic top queries 
note probabilistic guarantees query run times query result quality run time bounds hold high probability derived 
approach confused probabilistic methods deriving local global scores probabilistic ir techniques handle wide variety scoring functions building blocks notion probabilistic guarantees refers approximation top ranks completely scored exactly ranked result set 

computational model consider cartesian product space dm domains dm dataset dm data points 
data points records structured domains product catalog entries text documents domains capture weights text terms high dimensional ir feature space 
case queries dataset partial match queries form tuples qm qi di qi meaning care th dimension value 
text document ir case usually qi values set query keywords set approaches 
results query qm necessarily match non zero qi values non zero components di retrieve approximate matches condition similarity measures 
assume domain di similarity function si di di 
numerical domains year price similarity function simply absolute difference categorical domains model cars genre movies books similarity function needs explicitly defined value pairs 
domain specific similarity functions aggregated global similarity function dm dm aggr si xi yi aggr aggregation function 
widely aggregation function purpose summation yielding xy si xi popular alternatives include weighted summation product probabilistic interpretation maximum 
result top query data points sim highest values similarities data points 
framework processing top queries sorted access data descending order similarity scores dimension 
especially processing ir index lists lists frequent text terms may long random lookups lists incur extra disk ios orders magnitudes expensive sorted access step memory occasional asynchronous sequential disk reads 
ta sorted operates lists li query value qi return data values yi descending order si qi yi 
implementation uses tree indexes scans inverted index lists sorted order scores individual keys looks keys exactly match condition merges results forward backward scan neighboring keys numerical attribute values small absolute distance query value 
computational model ta sorted algorithm baseline written compact pseudocode form shown 
note ta random algorithm requires remembering candidates memory 
come back implementation details section original follow research discuss concrete bookkeeping data structures despite strong performance impact 
query specified values qm assume loss generality dimensions specified equivalently consider subspace dimensions query specifies values 
maintain index list li current scan position posi current score highi si qi document current scan position li 
maintain record document encountered li set dimensions computed score si partial score worstscore aggr si qi si qi summation aggr 
ta sorted top dummy dummy min candidates scan lists parallel round robin merged descending order si values consider item position posi li candidates candidates candidates highi si qi current score li bestscore aggr aggr aggr high worstscore aggr worstscore min top remove worstscore top top candidates candidates add top min min worstscore top bestscore min candidates candidates threshold max bestscore candidates threshold min exit pseudocode ta sorted algorithm algorithms invariant worstscore bestscore bestscore aggr worstscore aggr highi case sum aggregation function high suppose items currently top results query mink min case items fully evaluated mink min worstscore 
prune documents remainders index lists documents upper bound exceed value mink document dismissed candidate set aggr worstscore aggr highi min case say threshold test fails 
consideration unnecessarily conservative expected remainder score document lower sum highi bounds 
course expectations pruning give guarantees missing true top results 
expect sum si scores remainder set lower sum highi bounds high probability 
interested estimating probability document encounter position posi index list li holds qualifies top results aggr worstscore aggr si qi mink probability threshold percent may decide disregard computing full score 
choose summation aggregation function expression si si mink equivalently min si pd si ed refer condition probabilistic threshold test 
compute query execution know upper bounds highi unknown scores 
precisely equation read si si highi 
probabilistic score prediction section develop details estimating probability document non empty remainder set may qualify top results 
estimate depends assumptions distribution unknown scores si obtain 
subsections discuss various cases interest application viewpoint 
concentrate important case summation score aggregation discuss generalizations section 
note summation standard choice ir keyword query processing tf idf style weights precomputed stored index lists 
guarantees uniform distributions absence information occam razor suggests simplest assumption distribution unknown partial scores uniform distribution 
specifically assume document dimension evaluated score si uniformly distributed highi currently known upper bound true score assumed lower bound 
may lowest value occurs li provided stored information index metadata having scan li 
continuous distributions discrete ones simplifies subsequent calculations 
assume random variables si independent reconsidered 
treating unknown si value random variable si predict isi random variables densities high high requires computing convolution dz 
account fact factor non zero certain intervals high high equivalently max high min high solving integral leads cases assuming high high loss generality high high high high high high high high high high high high high corresponding cumulative distribution efficiently evaluable closed form 
unfortunately heterogeneous uniform distributions kind computation albeit simple principle leads rapidly increasing number cases regarding integration boundaries fairly awkward handle 
treat convolution terms moment generating functions ss sx fi dx random variables si densities fi 
independent variables convolution moment generating function mi 
uniform distributions fi plugged yields function easily infer density convolution 
apply chernoff hoeffding bounds tail probability tion isi inf infimum right hand side minimum chernoff bound function computed finding roots derivative limit approaching 
computation automated computer algebra tools maple programming interface 
great advantage approach generalized incorporate distributions uniform ones 
easily handle heterogeneous distributions say scores si uniformly distributed example hyperexponential zipf distributions 
results handle dependent random variables corresponding generalized chernoff hoeffding bounds may strong standard case 
assume sm random variables interest 
construct set independent random variables tm ti distribution marginal distribution si 
partitioning tail quantile interest consider chernoff bounds ti 
shown isi inf 
max 
difficult determine best choice partitioning values heuristic choice guaranteed yield correct bounds set high highi choose values proportion highi values index lists 
computing generalized bounds programmed procedures 
guarantees poisson distributions computation convolutions bounds incurs non negligible overhead interested approximations computationally cheaper 
form distribution nice theoretical properties efficiently evaluated reasonable fit realistic score distributions tf score distributions terms large web corpora poisson distribution 
fitting real distribution assume si discrete random variable ni equidistant values vj highi ni ni ni number object ids index list li 
probability object having local score vk ps vk parameter fit 
actual distribution 
particularity poisson distribution convolution distributions parameters poisson distribution parameter distribution convenient property 
highi values change index scans need predict si si highi largest value smaller relevant virtual value discretization 
lower bound probability follows si si highi si si highi si si highi si highi si si highi computing values cumulative distribution efficient numerical method incomplete gamma function 
guarantees histograms real score distributions may impossible capture basic distribution functions parameter fitting 
cases remaining method explicitly track distribution form compact histogram 
histogram construction exactly inexpensive precompute histogram score distribution index list 
query time compute convolution query relevant histograms possibly subsets 
simplicity consider equi width histograms approach easily generalized sophisticated histogram variants higher run time costs 
conservative probabilistic predictions assume values histogram cell coincide upper bound cell 
choose number cells basic histogram covering score range cells convolution histogram basic histograms width basic histograms covering range 
cell tn covers interval lb ub lb ub cell stores frequency freq cumulative frequency cum scores fall interval 
convolution basic histograms ht computed freq freq freq 
freq cum 
convolution histograms compute query capture complete distribution possible global scores partial scores unevaluated dimensions compute convolution basic histograms unevaluated dimensions 
index scans proceed interested conditional probabilities form si si highi highi values reflect current positions index scans 
obviously dynamically rebuilding histograms sorted access question 
ways addressing point 
option conservatively bound conditional probability analogously poisson approximation model si si highi si si highi directly looked precomputed histograms 
second option start full convolution histograms dynamically undo terms contribute freq highi values change query execution 
suppose changes value ub ub 
modify freq values vi highi follows freq freq 

freq 
ht 
freq precomputed additionally stored cell histogram index list lj 
computational overhead dynamic maintenance tn index scans crosses histogram cell boundary critical precomputation cost space histogram increase considerably space tn 
third way periodically recompute histograms sorted accesses order 
time convolution histogram rebuilt precomputed basic histograms current highi values taken account recomputation cheaper histogram smaller index scans proceed lower local scores 
extensions generalizations framework probabilistic predictions extended ways classes score distributions correlated local scores general score aggregation functions summations 
score distributions accommodate wide variety distributions chernoff hoeffding bound approach discussed subsection 
example straightforward incorporate zipf distributed scores si vk equidistant values vk proportional cumulative distribution corresponds harmonic series easily handle heterogeneous mixes different distributions say uniform index lists zipf highly skewed ones 
histogram approach subsection general distributions non issue histograms approximations arbitrary distributions 
correlations local scores different index lists generalized chernoff hoeffding bounds provide approach 
histogram approach hand multidimensional histograms capture joint distributions 
convinced practically viable specialized settings 
multidimensional histograms index lists may space consuming sparse inaccurate subspace relevant query known query time histogram building part user perceived response time 
fitting parameterized multidimensional distribution multivariate normal distribution data promising decision particular type distribution function carefully justified 
monotonous score aggregation functions simple sums supported large extent framework 
large class aggregation options simply cast precomputation local scores actual aggregation step simple summation 
example weighted summation weights dimension factored local scores ir style tf idf scores type idf values viewed dimension weights 
note cosine similarity ir usually reduced summation scalar products document query vectors pre normalizing norm vector lengths 
maximum score aggregation simpler summation computing convolution si distributions merely compute maxi si ip si 
query evaluation algorithms query processing algorithms probabilistic models predictors global scores data objects fully evaluated seen index scans far 
central building block developed algorithms differ selection candidates apply probabilistic predictions actions take threshold test candidate fails candidate able qualify top result 
algorithms maintain set current top objects set candidates organized hash table object ids 
conservative algorithm naive algorithm simply predict scores candidate objects step index scans drop candidates probabilities qualifying top result sufficiently low 
incur high overhead probabilistic threshold tests score prediction object recomputed highi values set changes 
better way group candidates values placing objects set evaluated dimensions partition bestscore priority 
suffices test best object group highest predicted score 
object dominates candidates group terms probability qualifying top result 
groups top objects directly comparable 
observation conservative algorithm maintains priority queue group queues query specified conditions 
note smaller dimensionality data space keyword queries text document space 
priority queues merely contain pointers hash table entries candidate objects 
item evaluated current scan position posi index list li conservative algorithm deletes obsolete queue worstscore fails threshold min inserts queue updated bestscore priority insertion possible cost log binomial heap amortized cost fibonacci heap 
completely evaluated dropped candidate list 
periodic index pruning index scanning steps top elements queues probabilistically tested current threshold mink top element fails test elements queue dropped candidate list 
algorithm proceeds fewer candidates eventually stops queues empty 
note queue single virtual element capturing predicted score object seen far 
advancing scan pointer index list may affect priorities candidates possibly reducing highi value dimension 
queue change affects elements way simply track highi queue space time 
aggressive algorithm aggressive algorithm extreme opposite conservative algorithm 
considers candidate object probabilistic testing virtual element current scan positions 
score prediction object falls threshold min algorithm stops immediately 
prediction unknown object high scores current scan positions 
item bestscore yields upper bound unseen documents probabilistic pruning algorithm typically stops truly best candidate fail min threshold yields approximate result 
strength aggressive algorithm minimal overhead expect perform terms result precision 
progressive algorithm overly eager behavior aggressive algorithm substantial overhead conservative algorithm progressive algorithm maintains single priority queue candidate objects 
queue elements ordered bestscore values 
step priority current candidate fetched index list updated queue accordingly maintained 
algorithm conservative immediately track bestscore changes result reduced highi values step leaves bestscore values higher 
queue elements updated amount rebuilding entire queue 
additional implementation trick employ queue periodically traversed index scanning steps tentatively compute date bestscore values queue element current highi values 
elements longer pass threshold test dropped queue 
priorities surviving elements updated avoid massive batch queue operations 
periodic removal unneeded queue elements seen kind garbage collection having rebuild entire queue 
conjunction periodic garbage collection progressive algorithm invokes probabilistic predictor element queue date bestscore 
objects fail probabilistic threshold test dropped queue 
algorithm stops queue empty top element bestscore falls threshold min 
smart algorithm progressive algorithm earlier reconsidered elements priority queue changing highi values reflected step 
smart algo rithm periodically rebuild entire priority queue current candidates currently known highi values taken consideration 
default queue rebuilt steps 
rebuilding amortized cost queue elements fibonacci heap log binomial heap 
online algorithm operating large index lists cost may question 
smart algorithm maintains bounded priority queue 
rebuilt best elements kept order 
newly encountered data objects admitted enlarge queue rebuild maximum size rebuild truncates size back priority queue fully date rebuild smart algorithm take aggressive actions progressive method regard candidate pruning 
top element rebuilt queue pass probabilistic threshold test smart algorithm immediately stops index scans terminates 
common framework algorithms share algorithmic skeleton illustrated pseudocode 
refer code prob sorted family algorithms 
note addition probabilistic predictions corresponding probabilistic threshold tests algorithms include original fagin test compare maximum bestscore candidates worstscore current topk objects 
test fails index scans stopped immediately extra test light weight include 
prob sorted scan lists parallel code ta sorted queue management priority queues relevant insert priority bestscore periodic clean step number mod dropping queues multiple unbounded queues strategy conservative priority queues prob top qualify top drop elements garbage collection single unbounded queue strategy progressive queue elements best bestscore current high values best min drop prob qualify top drop rebuild single bounded queue strategy smart queue elements update bestscore current high values rebuild bounded queue best elements prob top qualify top exit queues greedy threshold approximation strategy aggressive prob virtual element qualifies top exit queues empty exit fig 
pseudocode prob sorted family algorithms comment implementation ta sorted baseline algorithm 
original papers ta specify concrete data structures candidate set determine best candidate step 
decided implement aspects analogously progressive prob sorted algorithm maintaining single priority queue bestscore values priorities 
update queue elements highi values changes update element currently encountered index scan perform periodic garbage collection tentative updates 

guarantees top results probabilistic predictions query processing strategies immediately lead probabilistic guarantees user viewpoint restrict action failed threshold test dropping candidates entire algorithm run candidates 
situation conservative progressive algorithms 
case probability missing object true top result erroneously dropping candidate error call bounded probability probabilistic predictor assessing candidate 
recall top result fraction truly top objects approximate method returns means recall precision denoting number correct results approximate top efficiently compute chernoff hoeffding bounds binomial distribution 
note probabilistic guarantee holds precision returned top result simply recall precision denominator predicted expected precision precision 
kp precision strategies test top elements priority queues failed probabilistic threshold test entire algorithm carrying candidate error probability argument recall precision guarantees sophisticated 

experiments setup strategies framework implemented comprehensive testbed java oracle 
performed experiments ghz dual pentium pc gb memory 
index lists stored oracle database fetched large blocks cached java program 
different datasets different workloads experiments 
gov setting uses data trec web track uses gov data collection 
consists documents html pdf large crawl gov internet domain 
original queries web track topic distillation task keyword queries keywords 
examples lewis clark expedition injuries death 
systematic experimentation studied variations local scores index lists original scores computed tf log idf tf idf normalized maximum tf value document maximum idf value corpus respectively randomly assigned scores uniform distribution randomly assigned scores zipf distribution starting low scores low scores frequent expanded gov setting wanted study impact number query relevant index lists modified queries adding synonyms strongly related terms keywords query 
additional terms taken synonym entries descriptions wordnet thesaurus manually identified original keyword relevant word sense 
query expansion typically doubled number keywords query longest query contained keywords drug abuse pot smoke 
imdb setting data internet movie database www imdb com study methods performance combination text structured attributes 
data contains movies persons actors prepared attribute object relational table schema movies title genre actors description title description text attributes genre actors set valued categorical attributes 
genre typically contains genres actors limited appeared different movies 
similarity scores genre values actors precomputed dice coefficient pair genre values pair actors appeared movies 
similarity genres actors set movies containing movies movies index list contains entries similar values 
typical query title space genre actors harrison ford description robot war 
compiled queries kind asking colleagues 
note similarity scoring require match satisfy conditions 
algorithms compared experiments prob sorted methods section prob con conservative algorithm prob agg aggressive algorithm prob pro progressive algorithm prob smart smart algorithm 
considered different options probabilistic prediction 
baseline compare methods ta sorted threshold algorithm sorted access implementation discussed section 
algorithms access index lists round robin manner cache large index blocks memory 
evaluation metrics efficiency comparison collected measures accesses sorted access index lists altogether time wall clock elapsed time memory peak level working memory priority queues 
assessing quality approximate top query results collected measures precision fraction top results approximate result belongs true top result recall fraction top results true result returned approximate top query rank distance footrule distance ranks approximate top results true ranks exact top result spearman 
rank correlation wanted assess top ranks approximate result ranks spearman measure requires comparing permutations sets possible ranks 
score error absolute error approximate vs exact top scores approx exact score score 
note precision recall identical values setup denominator baseline precision recall top result exact ta sorted algorithm 
results baseline experiment baseline experiment probabilistic predictors histograms cell width bins basic histogram 
convolution histograms precomputed query initiation time impact changing highi values taken consideration periodically sorted access steps rebuilding remaining parts convolution histograms 
set probabilistic prediction confidence level percent set 
smart strategy bounded priority queue queue size set entries 
measured top queries 
figures show performance results algorithms comparison gov imdb settings respectively 
gov chart original tf idf derived scores 
efficiency metrics terms benchmark totals queries result quality metrics queries 
gov setting microaveraged values heavily biased long running queries queries performance gains prob sorted ta sorted significantly higher macro averaged values indicate 
shows corresponding results setting posed stress test queue management 
sorted accesses elapsed time max queue size precision rank distance score error ta sorted prob con prob agg prob pro prob smart fig performance prob sorted vs ta sorted gov sorted accesses elapsed time max queue size precision rank distance score error ta sorted prob con prob agg prob pro prob smart fig performance prob sorted vs ta sorted imdb sorted accesses elapsed time max queue size precision rank distance score error ta sorted prob con prob agg prob pro prob smart fig prob sorted vs ta sorted efficiency 
results demonstrate significant cost savings prob sorted family algorithms achieve compared ta sorted 
terms number sorted accesses conservative algorithm prob con gains factor smart algorithm achieves factor gov terms run times probabilistic algorithms reduce cost order magnitude 
note run time simply linear function sorted accesses reflects cache queue management costs 
gov imdb settings prob con temporarily created larger queue ta sorted baseline periodic garbage collection prob con dropped large queue quickly initialization distributed remaining candidate items multiple small queues 
interestingly progressive algorithm prob pro expected capabilities early pruning limited queue management required insert delete operations significant cost factor 
aggressive method prob agg outperformed competitors expected result quality poor really consider winner 
individual queries especially involve long index lists savings impressive 
example gov query weather hazard extremes prob con prob smart needed sorted accesses run times seconds ta sorted required accesses ran seconds precision resp 
imdb setting reductions sorted accesses high gov run time reductions reached factor high macroaveraged precision 
typical query genre western actor john wayne katherine description marshall required sorted accesses prob con prob smart run times seconds ta sorted performed accesses time seconds precision 
queries keywords query overhead queue management probabilistic predictions truly decisive issue 
methods acceptable precision prob con performed best terms sorted access savings run time gains modest overhead maintaining queues 
prob pro clear winners terms run time acceleration factors compared ta sorted 
interestingly methods save sorted accesses benefited greatly efficient queue management 
result quality 
measurements result quality show results prob con prob pro acceptable results prob smart 
prob con prob pro achieved nearly percent precision recall gov setting 
imdb setting precision figures worse reason genre scores major influence ranking small number different values led fairly discontinuous score distribution big gaps ties causing inaccuracy probabilistic predictions 
discuss influence various predictors subsection 
result quality metrics show user perceived loss approximate result tolerable 
average rank distance prob pro 
higher acceptable particular consider average rank distance dominated outliers high rank distance 
terms score error loss negligible 
large objects returned prob sorted algorithms nearly exact top results 
results imdb setting quite gov manually inspected fair number results cases results considered matches human user 
example query genre actor arnold description robot returned top results terminator th day total recall die hard star wars iv 
recall top results necessarily satisfy query conditions 
prob con pro pro prob smart showed precision rank distance score error values 
sensitivity studies studied influence parameters performance prob sorted algorithms probabilistic prediction confidence level result size top queries number bins basic histogram maximum size bounded priority queue smart algorithm 
shows results varying parameter vertical dashed line baseline setting 
curves show percent progressive smart algorithms achieve marginal savings 
percent hand methods offer excellent benefit cost ratios 
conservative method performs best theory probabilistic guarantees 
small values percent lead significant cost savings values large percent results sorted access savings factor yield percent precision 
aggressive method exhibits great cost savings expense precision values percent 
may possibly preferred method applications tight response time demands 
compared measured precision expected precision predict function formulas section 
prob con prob pro prediction model fairly accurate 
absolute difference predicted measured precision percent values increases larger prediction conservative lower bounds measured precision 
sorted accesses macro avg 
precision prob con prob pro prob smart prob agg performance function space limitation include charts sensitivity studies regarding parameters briefly discuss main insights 
increasing varied methods exhibit linearly increasing sorted access costs different gradients 
large gains prob con prob pro prob smart compared ta sorted higher baseline setting time precision approximate top results better high performance different numbers histogram bins fairly stable wide range settings 
bins relative performance different algorithms change bins prob smart method anymore prob con prob prog remain robust show consistently performance bins histogram 
similarly maximum queue size parameter prob smart algorithm largely 
queue size limits low worked 
impact probabilistic predictions compared different approaches probabilistic prediction histograms vs poisson approximations vs chernoff bounds assumption uniform distributions vs chernoff bounds considering term correlations 
limit presentation results prob con algorithm gov setting 
due high overhead computing chernoff bounds removed expensive queries web tracks topic distillation task consumed percent run time queries 
shows performance comparisons original tf idf scores 
dashed line predicted precision prob con simply 
similar experiments run artificially generated uniform zipf distributed scores gov index lists 
macro avg 
precision prediction tfidf histograms tfidf poisson tfidf chernoff tfidf chernoff corr macro avg 
precision prediction uni histograms uni poisson uni chernoff corr macro avg 
precision prediction zipf histograms zipf poisson zipf chernoff corr precision probabilistic predictors tf idf uniform zipf distributed scores charts show histograms provide accurate score predictions 
comparison uniform zipf distributed scores shows flexible solution capture different score distributions low buckets 
poisson estimator particularly chernoff bound method assuming uniform distributed scores overly conservative overestimate score probabilities tf idf zipf case 
difference chernoff bound methods independence assumption really significant gov data different settings 
scores chernoff bounds fairly accurate wide range expected poisson estimators uniform case underestimate tail probability 
zipf distribution closer original tf idf score distribution longer tail low scores poisson estimator works better chernoff bounds behave overly conservative 
advantage poisson approximation method little overhead overhead histogram method increases dimensionality 
note higher dimensional workload algorithms achieved major run time gains histograms dynamic convolutions 
chernoff bound predictors largely independent dimensionality suffer huge startup costs invoking 
practically viable solution hand code maple computations involve differentiation finding roots numerically 
model precision guarantees developed section works prob con algorithm 
prob pro prob smart algorithms deviate basic statistical model merge candidates single queue prob smart bounds queue heuristically stops testing top item 
predictions reasonably accurate small degraded overly conservative higher percent 
improving subject 
discussion comprehensive experiments shown algorithms achieve major performance gains terms sorted accesses actual run time time provide probabilistic guarantees result precision recall 
competing algorithms prob con prob smart turned interesting ones 
prob con closest theory probabilistic guarantees best terms result quality prob smart offers best benefit cost ratio 
methods achieve run time gains order magnitude compared ta sorted 
prob sorted methods fairly robust regard parameter settings need sophisticated tuning 
score predictions believe histograms best choice engineering viewpoint methods showed results certainly deserve studies 

concluding remarks novel prob sorted family algorithms introduced major cornerstones probabilistic score predictions trading small amount top result quality drastic reduction sorted accesses intelligent management priority queues efficient implementation 
believe experiments convincingly demonstrated significant benefits approach 
plan continue studies efficient memory management top algorithms includes applying techniques ranked retrieval xml data integrating xxl search engine 
agrawal chaudhuri das gionis automated ranking database query results 
cidr allen probability statistics queueing theory computer science applications 
academic press amato region proximity metric spaces approximate similarity search 
tois anh de moffat vector space ranking effective early termination 
sigir beyer nearest neighbor meaningful 
icdt hm searching high dimensional spaces index structures improving performance multimedia databases 
acm comput 
surv 
brin page anatomy large scale hypertextual web search engine 
www conf 
bruno chaudhuri gravano top selection queries relational databases mapping strategies performance evaluation 
tods bruno gravano marian evaluating top queries web accessible databases 
icde carmel static index pruning information retrieval systems 
sigir 
chang 
hwang minimal probing supporting expensive predicates top queries 
sig mod chaudhuri gravano marian optimizing top selection queries multimedia repositories appear tkde 
ciaccia patella pac nearest neighbor queries approximate controlled search high dimensional metric spaces 
icde ciaccia patella searching metric spaces user defined approximate distances 
tods cormen leiserson rivest stein algorithms 
mit press croft lafferty language modeling information retrieval 
kluwer ramakrishnan probabilistic optimization top queries vldb fagin combining fuzzy information multiple systems comput 
syst 
sci 
fagin optimal aggregation algorithms middleware 
comput 
syst 
sci 

fellbaum editor wordnet electronic lexical database mit press fuhr vert retrieval quality vs effectiveness relevance oriented search xml documents 
tr univ duisburg optimizing multi feature queries image databases 
vldb efficient multi feature queries heterogeneous environments 

samet distance browsing spatial databases 
tods samet index driven similarity search metric spaces 
tods 
ioannidis history histograms abridged 
vldb kendall gibbons rank correlation methods 
oxford university press long suel optimized query execution large search engines global page ordering 
vldb marian evaluating top queries web accessible databases 
tods moffat zobel self indexing inverted files fast text retrieval 
tois supporting incremental join queries ranked inputs 
vldb nelson probability stochastic processes queueing theory springer ramakrishna query processing issues image multimedia databases 
icde press numerical recipes cambridge univ press siegel usable theory chernoff bounds heterogeneous partially dependent random variables 
tr courant inst new york univ tao faloutsos papadias power method comprehensive estimation technique multi dimensional queries 
cikm theobald weikum index xxl search engine querying xml data relevance ranking 
edbt yu database selection processing nearest neighbors queries distributed environments 
jcdl 
