ieee transactions computers vol 
june performance analysis ary cube interconnection networks vlsi communication networks wire limited 
cost network function number switches required function wiring density required construct network 
analyzes commu nication networks varying dimension assumption constant wire bisection 
expressions latency average case throughput hot spot throughput ary cube networks constant bisection derived agree closely experi mental measurements 
shown low dimensional networks tori lower latency higher hot spot throughput high dimensional networks binary cubes bisection width 
index terms communication networks concurrent comput ing interconnection networks message passing multiprocessors parallel processing vlsi 
william dally member ieee critical component concurrent computer communication network 
algorithms communication processing limited 
fine grain concurrent programs execute instructions response message 
efficiently execute programs communication network latency greater instruction times throughput sufficient permit large fraction nodes transmit simultaneously 
communication critical support code sharing garbage collection nodes 
grain size concurrent computers continues decrease communication latency important factor 
diameter machine grows messages sent frequently fewer instructions executed response message 
low latency difficult achieve fine grain machine available wiring space grows slowly expected traffic 
machine constructed dimensions bisection area grows traffic grows fast number nodes 
manuscript received september revised march 
supported part defense advanced research projects agency contracts part national science foundation presidential young investigator award matching funds general electric 
preliminary ver sion appeared proceedings stanford confer ence advanced research vlsi lo 
author intelligence laboratory laboratory computer science massachusetts institute technology cambridge ma 
ieee log number 
vlsi systems wire limited 
cost systems predominantly connecting devices perfor mance limited delay interconnections 
achieve required performance network efficient available wire 
topology network map physical dimensions messages required double back way allows messages available bandwidth path 
considers problem constructing wire efficient communication networks networks give op performance wire density 
compare networks holding wire bisection number wires cross ing cut evenly divides machine constant 
compare low dimensional networks wide communication channels high dimensional networks narrow chan nels 
investigate class ary cube interconnection networks show low dimensional networks outperform high dimensional networks bisection width 
remainder describes design wire efficient communication networks 
section describes sumptions 
family ary cube networks described section 
restrict ary cubes dimension net important details topology 
section introduces wormhole routing low latency rout ing technique 
network cost determined primarily wire density measure terms bisection width 
section introduces idea bisection width dis delay models network channels 
performance model networks derived section 
expres sions network latency function traffic agree closely experimental results 
assump tion constant wire density shown low dimensional networks achieve lower latency better hot spot throughput high dimensional networks 
ary cubes oo ieee 
preliminaries different network topologies proposed concurrent computers trees net works sorting networks shuffle exchange net works omega networks indirect binary cube flip networks direct binary cubes 
binary cube special case family ieee transactions computers vol 
june fig 

binary cube embedded plane fig 

ternary cube embedded plane 
ary cubes cubes dimensions nodes dimension 
concurrent computers built networks ary cubes isomorphic ary cubes rings meshes tori direct indirect binary cubes omega networks 
restrict atten tion ary cube networks 
refer dimension cube radix 
dimension radix number nodes related equation log 
dimension network important details topology 
node ary cube identified digit radix address ao 
ith digit address represents node position ith dimension 
node forward messages upper neighbor dimension address ao 
mod 

assume ary cubes uni directional simplicity 
see results change appreciably bidirectional networks 
actual machine compelling reasons networks bidirectional 
importantly bidirectional networks allow exploit locality communication 
object sends message object high probability sending message back tional network roundtrip short placing close 
unidirectional network roundtrip involve completely circling machine dimension 
figs 
show ary cube networks order de dimension 
fig 
shows binary cube nodes 
ary cube nodes shown fig 

ary cube nodes torus shown fig 

line fig 
represents communication channels direction line figs 
represents single communication channel 
wormhole routing fig 

ary cube torus 
consider networks wormhole store forward routing 
storing packet completely node transmitting node wormhole routing operates advancing head packet directly incoming outgoing channels 
flow control digits flits buffered node 
flit smallest unit information queue channel accept refuse 
soon node examines header flit message selects channel route begins forwarding fits channel 
flits forwarded message spread channels source destination 
possible flit message arrive destination node flit message left source 
flits contain routing information flits message remain contiguous channels network interleaved flits messages 
header flit message blocked flits message advancing block progress message requiring channels occupy 
method similar wormhole routing called virtual described 
virtual cut differs wormhole routing buffers messages block removing network 
wormhole routing blocked messages remain network 
fig 
illustrates advantage wormhole routing 
components latency distance message aspect ratio 
distance number hops required get source destination 
message aspect ratio message length normalized channel width number channel cycles required transmit message channel 
top half shows forward routing 
message entirely transmitted node node ni ni 
store forward routing latency product 
tsf bottom half fig shows wormhole routing 
soon flit arrives node forwarded node 
wormhole routing latency reduced sum 
dally ary cube interconnection networks equations channel cycle time amount time required perform transaction channel 
vlsi complexity vlsi computing systems wire limited com plexity constructed limited wire density speed machine run limited wire delay majority power consumed machine drive wires 
machines organized logically physically keep wires short exploiting locality possible 
vlsi architect organize computing system form physical organization fits function logical organization networks traditionally analyzed sumption constant channel bandwidth 
assump tion channel bit wide unit delay 
constant bandwidth assumption favors networks high dimensionality binary cubes low dimensional networks tori 
assumption consistent properties vlsi technology 
net works dimensions require longer wires low dimensional networks 
high dimensional networks cost run slowly low dimensional networks 
realistic comparison network topology take wire density wire length account 
account wire density bisection width measure network cost 
bisection width network minimum number wires cut net divided equal halves 
comparing networks constant channel width com pare networks constant bisection width 
compare low dimensional networks large high dimensional networks small delay wire depends length 
short wires delay limited charging capacitance wire varies logarithmically wire length 
log kl thn ti fig 

latency store forward routing top versus wormhole routing bottom 
fig 

folded torus system 
inverter delay constant depending capacitance ratios 
long wires delay limited speed light 
ti 
consider delay models constant delay independent length logarithmic delay cx log linear delay cx main result latency mini mized low dimensional networks supported models 

performance analysis section compare performance tional ary cube interconnection networks fol lowing assumptions 
networks embedded plane 
dimensional packaging technology available comparison changes slightly 
nodes placed systematically embedding log ical dimensions physical dimensions 
assume integers 
long connections shown fig 
avoided folding network shown fig 

ieee transactions computers 
vol 
june networks number nodes wire density held constant 
network constructed bisection width total number wires crossing midpoint network 
keep bisection width constant vary width communication channels 
normalize bisection width bit serial binary cube 
networks wormhole routing 
channel delay function wire length 
considering channel delay constant 
comparison performed logarithmic linear wire delays cx log channels crossing midpoint network highest dimension 
fl rows network channels direction total fik channels 
bisection width ary cube bit wide communication channels binary cube bisection width wn 
set equal normalize binary cube unit width channels 
channel width ary cube bisection width follows fig 

loo position wire density versus position row binary cube 
peak wire density greater bisection width networks lower dimensions contribute wire density 
maximum density bounded dr plot wire density function position row binary cube shown fig 

density low edges cube quite dense near center 
peak density row position 
compare density bisection width row 
contrast dimensional torus wire density independent position 
advantage high radix networks uniform wire density 
full available area 
processing node connects channels input output bits wide 
number nodes dimension 
fig 

pin density versus dimension nodes 
pins processing node nk 
plot pin density function dimension nodes shown fig 

low dimensional networks disadvantage requiring pins processing node 
dimensional network nodes shown requires pins clearly unrealizable 
number pins decreases rapidly dimension increases 
nodes dimension node pins 
configurations give low latency give reasonable pin count 
latency latency ti sum latency due network latency due processing node concerned techniques reduce described 
select processing nodes pi random average number channels traversed send message pi lm 
dally ary cube interconnection networks average latency ary cube calculated approximately equal zz assertion statement precise 
assertion minimum latency occurs dimension dimension proof differentiating respect gives nodes dt log log dn log 
substituting gives dimension 
log nk log fig 

latency versus dimension nodes constant delay 
substituting derivative gives log log log dt 
derivative monotonically increasing 
minimum latency fig 
shows average network latency function dimension ary cubes nodes left data point corresponds torus rightmost data point corresponds binary cube 
assumes constant wire delay message length bits 
choice message length analysis number fine grain concurrent programs 
occurs 
empirically networks integral valued minimum latency occurs chosen id minimized 
longest wire system bottleneck determines rate channel operates 
length wire constant wire delay unrealistic illustrates ignoring dependence wire delay wire length low dimensional networks achieve lower latency high dimensional networks 
latency tori left side fig 
limited entirely distance 
latency binary cubes fl 
wires sufficiently short delay depends logarithmically wire length 
channels longer limited speed light delay depends linearly channel length 
substituting gives right side graph limited entirely aspect ratio 
bit serial channels cubes take log logarithmic delay cycles transmit messages single channel 
application exploits locality communication linear delay 
distance communicating objects reduced 
situation latency low dimensional networks dominated distance left side fig 
reduced 
substitute get network latency high dimensional networks hand take advantage locality 
latency dominated message length remain high 
cases log applications send short messages component latency due message length reduced resulting lower latency high dimensional networks right side fig 

cases shown fig 
minimum latencies achieved respectively 
general lowest latency achieved component latency due distance component due message length ti logarithmic delay linear delay 
sake comparison allow radix take values 
dimensions considered integer radix gives correct number nodes 
fact limitation overcome constructing cube 
fig 
shows average network latency function dimension ary cubes nodes assuming logarithmic wire delay message length 
fig 
shows data assuming linear wire delays 
figures leftmost data point corresponds torus rightmost data point corresponds binary cube 
ieee transactions computers vol 
june lzo oo noda leo dimension 
fig 

latency versus dimension nodes logarithmic delay 
ooooo oo loo nodes nodes dimension fig 

latency versus dimension nodes linear delay 
linear delay case fig 
torus gives lowest latency 
torus offers highest bandwidth channels direct physical route processing nodes 
linear delay assump tion latency determined solely bandwidth physical distance traversed 
advantage having long channels 
logarithmic delay assumption fig 
torus lowest latency small networks 
larger networks lowest latency achieved slightly higher dimensions 
lowest latency oc lm lowest latency achieved 
interesting assuming constant wire delay change result 
recall unrealistic constant wire delay assumption fig 
minimum latencies achieved dimensions respectively 
results shown figs 
derived compar ing networks assumption constant wire cost binary cube 
small networks pos sible construct binary cubes wider channels large networks nodes may possible construct binary cube 
available wiring area grows bisection width binary cube grows case small networks comparison actual machine dimension restricted integer 
binary cubes wide channels performed expressing message length terms binary cube channel width effect decreasing message length purposes comparison 
net result lower dimensional networks give lower latency 
perform node comparison binary cube torus gives lowest latency logarithmic delay model dimension network gives minimum latency constant delay model 
large networks avail able wire assumed effective message length increased making low dimensional networks look favorable 
comparison assumed single bit information transit wire network time 
assumption delay nodes equal period node 
network long wires possible bits transit 
case channel delay function wire length channel period remains constant 
similarly network short wires may allow bit ripple channels sending bit 
case 
separating coefficients net effect allowing changing length factor change results significantly 
wire cost considered low dimensional networks tori offer lower latency high dimensional networks binary cubes 
tori outperform binary cubes better match form function 
logical physical graphs torus identical messages travel minimum distance source destination 
binary cube hand fit form function 
message binary cube embedded plane may traverse considerably minimum distance source destination 
throughput throughput important metric network perfor mance defined total number messages network handle unit time 
method estimating put calculate capacity network total number messages network 
typically maximum throughput network fraction ca 
network capacity node total bandwidth node divided average number channels traversed message 
ary cubes bandwidth node average number channels traversed network capacity node dally ary cube interconnection networks dimension dimension ii dimension fig 

contention model network 
ae ti fig 

contention model single dimension 
network capacity independent dimension 
con stant wire density constant network capacity 
throughput capacity contention causes channels block 
contention increases network latency 
simplify analysis contention assumptions 
messages routed cube routing order decreasing dimension 
message node ao 
destined nodes bo 
bn routed dimension reaches node ao 
bn 
message routed dimension reaches node 
bn bn 
shown fig 
assumption allows consider contention dimension separately 
traffic node generated poisson process arrival rate 
message destinations uniformly distributed inde pendent 
arrival rate bits cycle corresponds xe messages cycles 
destination flit ser soon arrives service time sink starting calculate service time seen entering preceding dimension 
convenience define quantities illustrated fig 
probability message skips route dimension xr ass xe rate traffic skips previous messages dimension ifl cycle rate traffic routes previous dimension cycle messages rate traffic skips previous dimension current messages dimension cycle xsr rate traffic skips previous dimension routes messages current dimension cycle xe rate traffic routes pre vious dimension skips messages current dimension cycle rate traffic routes previous dimension cur rent dimension messages cycle 
consider single dimension network shown fig 

messages incur latency due contention entering dimension 
messages routed incur additional latency tr due contention routing 
rate xe message stream entering dimension composed components rate stream skipped previous lst dimension rate xr stream routed previous dimension 
streams turn split components skip ith dimension ass components routed ith dimension xsr arr 
entering latency seen component say ass multiplying probability collision case xr expected latency due collision case ti 
components require routing add latency due contention routing tr 
adding components appropriate weights gives equation ti term latency seen entering dimension 
second term accounts routing latency tr incurred messages routing dimension xsr arr 
entering latency due contention routing streams merge third term 
final term gives entering latency messages skip dimension 
large small latency approximated ti ti tr 
binary cubes tr 
calculate routing latency tr model shown fig 

messages enter dimension rate xr route number stages denoted boxes exit dimension 
latency due contention stages sums tr 
message routed dimension expected number channels traversed message entering channel continuing channels 
average message rate channels continuing dimension xc tar 
average message rate calculate latency approximation 
symmetry network assures traffic physical channels uniform 
virtual channels cube routing results logical channels form spiral 
traffic jth channel spiral hc 
uniform physical message rate results slightly pessimistic estimate latency contention physical channel occurs flit boundaries contention logical channel occurs message boundaries 
compute tr backwards output 
service time continuing channel dimension ti ti 
know service time jth channel ti additional service time due contention st channel multiplying probability collision xrt expected waiting time collision ti 
repeating calculation times gives tio 
equation valid hc ti 
message rate higher limit steady state solution latency infinite 
solutions 
consider smaller latencies 
larger solution corresponds state encountered normal operation network 
fig 

contention model routing latency 
ieee transactions computers vol 
june calculate tr need consider possibility collision entering channel 
sufficient queueing added network node ser vice times increase latency ti ti tri 
effective total queueing source destination greater expected increase latency due blocking 
flits queueing stage sufficient 
longer messages result longer service time require additional queueing 
analysis pessimistic assumes queueing 
determine maximum throughput network network latency increases traffic 
figs 
show latency increases function applied traffic node node ary cubes 
vertical axis shows latency cycles 
horizontal axis traffic node 
figures compare mea network simulator points latency predicted lines 
simulation agrees pre diction percent network approaches sat 
networks ary cube gives low est latency 
networks ary cube gives low est latency 
latency increases slowly dimensional networks ary cube gives lowest latency 
left side graph latency 
traffic applied dally ary cube interconnection networks 


oc traffic fraction capacity fig 

latency versus traffic node networks ary cube ary cube binary cube bits 
solid line predicted latency points measurements taken simulator 
traffic capacity fig 

latency versus traffic node networks ary cube ary cube ary cube ary cube binary cube bits 
solid line predicted latency points measurements taken simulator 
network latency increases slowly due contention net saturation reached 
saturation occurs depending network topology 
net works designed operate flat portion curve 
network saturates throughput levels shown figs 

figures show traffic delivered vertical axis nodes attempt inject amount traffic horizontal axis 
curve linear actual attempted saturation reached 
point actual traffic constant 
plateau occurs cause network source queued messages encounter contention blocked aborted 
net works contention resolved dropping messages throughput usually decreases saturation 
find maximum throughput network source service time set equal reciprocal message rate xe solved xe 
offered traffic fraction capacity fig 

actual traffic versus attempted traffic node networks ary cube ary cube binary cube bits 
offered traffic fraction capacity fig 

actual traffic versus attempted traffic node networks ary cube ary cube ary cube ary cube binary cube bits 
table maximum throughput fraction capacity blocking latency cycles parameter nodes nodes dimension radix max throughput 



latency 




latency 





operating point network accept traffic 
mes sages offered fast network deliver 
maximum throughput fraction capacity ary cubes nodes tabulated table shown total latency bit messages message rates 
table shows additional latency due blocking significantly reduced dimension decreased 
networks constant bisection width latency low dimensional networks increases slowly applied traf fic latency high dimensional networks 
ieee transactions computers vol 
june ary cube latency binary cube 
point additional latency due contention ary cube compared binary cube 
low dimensional networks handle contention better fewer channels higher bandwidth get bet ter queueing performance 
shorter service times networks results lower probability collision lower expected waiting time event collision 
blocking latency node reduced ically increased 
low dimensional networks require hops higher rate con channels xc messages travel contin channels frequently entering channels contention lower rate channels 
having fewer channels higher bandwidth improves hot spot throughput described 
hot spot throughput situations traffic uniform con hot spots 
hot spot pair nodes accounts disproportionately large portion total net traffic 
described pfister shared memory computer hot spot traffic degrade performance en tire network causing congestion 
hot spot throughput network maximum rate messages sent specific node pi specific node pj 
ary cube de routing hot spot throughput just bandwidth single channel assumption constant wire cost 
low dimensional networks greater channel bandwidth greater hot spot throughput high dimensional networks 
low dimensional networks operate better nonuniform loads re source sharing 
interconnection network resources wires 
high dimensional network wires assigned particular dimensions shared dimen sions 
example binary cube possible wire saturated physically adjacent wire assigned different dimension remains idle 
torus physically cent wires combined single channel shared messages traverse physical distance spanned channel 

assumption constant wire bisection low dimensional networks wide channels provide lower la tency contention higher hot spot throughput higher dimensional networks narrow channels 
minimum network latency achieved network radix di chosen components latency due distance aspect ratio approximately equal 
minimum latency occurs low dimension nodes 
low dimensional networks reduce contention hav ing high bandwidth channels results resource sharing better queueing performance hav ing low bandwidth channels 
network ity worst case blocking latency independent di low dimensional networks higher maximum throughput lower average blocking latency high dimensional networks 
improved resource sharing gives low dimensional networks higher hot spot throughput high dimensional networks 
results assumption constant channel delay independent channel length 
main result low dimensional networks give minimum latency change appreciably logarithmic linear delay models considered 
choosing delay model consider delay switching node compares delay wire 
current vlsi routing chips delays tens nanoseconds time drive meters wire 
systems constant delay model adequate 
chips get faster systems get larger linear delay model accurately reflect system performance 
fat tree networks shown universal sense efficiently simulate network volume 
analysis net works considered latency 
ary cubes appro chosen radix dimension universal sense 
detailed proof scope 
intuitively better fill physical dimensions wires place switches ev ery point intersection 
point point network embedded mesh constant increase wiring length 
considered direct networks 
results apply indirect networks 
depth switch degree indirect network analogous di radix direct network 
bisection width indirect network independent switch degree 
indirect networks exploit locality pos sible trade diameter bandwidth 
wire density limiting resource high bandwidth direct network indirect network 
low dimensional ary cube provides gen eral communication media digital systems 
networks developed primarily message passing concur rent computers 
place bus indirect network shared memory concurrent computer place bus connect components tial computer connect subsystems special purpose digital system 
vlsi communication chips cost implementing network node comparable cost shared bus performance network considerably greater performance bus 
networks described demonstrated laboratory incorporated commercial sors 
torus routing chip trc vlsi chip designed implement low dimensional ary cube interconnection networks 
trc performs wormhole routing arbi ary cube interconnection networks 
single trc provides bit data channels dimensions dally ary cube interconnection networks cascaded add dimensions wider data channels 
trc network deliver message node ary cube average latency ps order magnitude better performance achieved cube bit new routing network design frame improves latency fz ps 
uses ary cube 
id connections interconnection network 
communication networks reduced microseconds latency processing nodes dominates latency 
efficiently low latency communication network need pro cessing node interprets messages little overhead 
design message driven processor currently underway ll 
real challenge concurrent computing software 
development concurrent software strongly influenced available concurrent hardware 
hope providing machines higher performance internode communication encourage concurrency exploited finer grain size system application software 
acknowledgment seitz caltech helpful suggestions early stages research 
product announcement 
sorting networks applications pm 
afips vol 
pp 

flip network pm 
int 
conf 
parallel processing pp 

mathematical theory connecting networks telephone traffic 
new york academic 
agrawal generalized hypercube structures computer network ieee trans 
comput vol 
pp 
apr 
browning tree machine highly concurrent computing environment dep 
comput 
sci california 
technol rep 
dally vlsi architecture concurrent data structures 
ma kluwer 
dally seitz deadlock free message routing multiprocessor interconnection networks ieee trans 
comput vol 
pp 
may 
torus routing chip distributed syst vol 
pp 

dally wire efficient vlsi multiprocessor communication networks proc 
stanford conf 
advanced res 
vlsi ed 
cambridge ma mit press mar pp 

ill dally architecture message driven processor proc 
th symp 
comput 
architecture june pp 

dally song design self timed vlsi multicomputer communication controller proc 
ieee int 
conf 
comput 
design 
kleinrock virtual cut new communication switching technique comput 
networks vol 
pp 
lawrie alignment access data array processor ieee trans 
comput vol 
pp 
dec 
leiserson fat trees universal networks hardware efficient supercomputing ieee trans 
comput vol 
pp 
oct 
mead conway vlsi systems 
reading ma addison wesley 
pease indirect binary cube microprocessor array ieee trans 
comput vol 
pp 
may 
pfister norton hot spot contention combining multistage interconnection networks ieee trans 
comput vol 
pp 
oct 
seitz concurrent vlsi architectures ieee trans 
cornput vol 
pp 
dec 
seitz hypercube communications chip dep 
comput 
sci california inst 
technol display file df mar 
sequin single chip computers new vlsi building block proc 
caltech conf 
vlsi seitz ed jan pp 

siegel interconnection network simd machines ieee comput 
mag vol 
pp 
june 
stone parallel processing perfect shuffle ieee trans 
comput vol 
pp 
feb 
sullivan large scale homogeneous ma chine proc 
th ann 
symp 
comput 
architecture pp 

tanenbaum computer networks 
englewood cliffs nj prentice hall 
thompson complexity theory vlsi dep 
com put 
sri carnegie mellon univ tech 
rep cmu cs aug 
william dally received degree electrical engineering virginia poly institute blacksburg de gree electrical engineering stanford univer sity stanford ca ph degree computer science caltech 
worked bell telephone laboratories contributed design microprocessor 
worked consultant area dig systems design 
research assistant research fellow caltech 
currently associate professor computer science massachusetts institute technology 
research interests include concurrent computing computer architecture computer aided design vlsi design 
