comparing clusterings marina de gt ll mmp stat washington edu october proposes information theoretic data set 
criterion called variation information amount information lost gained changing criterion assumptions generated applies soft hard basic properties vi discussed point view comparing 
particular vi positive symmetric transitive surprisingly true metric space 
non trivial task different erin data set 
reasons la best method 
additional reasons space set 
structure ple address iii posedness search best criterion presents properties variation information discusses meaning point view comparing 
check properties new criterion reasonable desirable generic setting 
reader particular task mind properties precise description criterion behaviour 
starts previously clustering criteria section exposing criticisms received 
variation information introduced section properties section 
section presents extensions criterion data sets non uniform weighting soft 
discussion section 
related term 
data set sets 
cf called clu sters comparing clusterings counting pairs class fall unde cases described 
number cluster number point different clusters number pairs cluster number point pairs cluster counts satisfy wr 
obtained contingency table example see details 
wallace proposed asymmetric criteria wi wii 
represent cluster ely cluster 
fowlkes introduced criterion mean fowlkes base line serious pr obl value near criterion varies xim lte base line ad rand index varies criterion varies domain clusterings wonder linearity assumed range appropriate normalization 
words value baseline value baseline 
note values normalization yield theoretically qual 
problem baseline expectation null hypothesis 
null hypothesis clusterings sampled independently clusterings sampled set partition pairs fixed nk points cluster 
practice assumptions normally violated 
clusterings independent usually obtained clustering algorithms data set 
algorithms take number clusters input know take number points cluster 
number points result execution rithm 
data analysis situa tions unnatural assume know cluster 
know uses indices violate lls 
pos ed statistical rewritten rand index 
ted form comparing clusterings set second criteria may ge nel ated 
uses klk larsen asymmetric criterion identical heckerman computed criterion best match 
done scanning elements contingency table ll decreasing order 
largest entails match ca second largest row column entails second match min matches 
denote index matches cluster ck index asymmetric takes value identical 
criteria difficulties raised 
take example situation obtained clusters initial cluster obtained small fraction cluster cluster obtained fraction cluster equally clusters 
closer aj clustering 
identical clusterings strictly smaller 
criteria suffer problem matching discuss 
way find best match cluster add contributions matches 
doing criteria completely ignore happens unmatched part cluster 
things clear look example depicted 
suppose clustering equal clusters 
clustering obtained moving fraction points ck cll ster clustering obtained fraction points ck evenly clusters 
contradicts intuition ct version variation information re asc 
introduce variation criterion propose dl ic call associated rl nn takes value cluster 
measured bits 
bit 
note depend number points relative proportions clusters 
want define information clusterings information clustering 
denote 

random variables associated clusterings introduce distribution represents probability point belongs ck clustering define mutual information clusterings equal mutual information random variables induced cluster way vl variation information related quantities 
obtained merging clusters clusterings equal propose comparison criterion clusterings quantity vi closer examination sum positive terms total variation function 
call clus terms conditional en term measures amount se cond vai variation information metric property positivity property symmetry 
number clusters bounded constant derive bound dependent property triangle inequality 
cl property cl vi 
properties imply vi metric distance clusterings 
note space clusterings metric necessarily bounded 
comparison criterion metric important advantages 
properties metric mainly symmetry triangle inequality criterion understandable 
human intuition ease metric arbitrary function variables 
second triangle inequality tells elements metric space clusterings close third far apart 
property extremely useful designing efficient data structures algorithms 
metric move simply comparing clusterings set ala means cluster set ch lst ering construct ball trees efficient estimate search simulated type move away initial upper vi fixed bound approached arbitrarily limit large attained case exact multiple 
shows large clusterings different data sets different numbers data points bounded numbers clusters really scale metric vi 
consequence extremely important goal compare clustering algorithms clusterings data set 
previous properties imply equal distances obtained data sets different sizes comparable 
example ran clustering algorithm parameters data sets produced generative process compare clusterings obtained algorithm gold standard data sets average distances obtain average error algorithm 
restrictive possible done results re caution 
sense consider data sets equi sense compare vi distances spaces data local pr 
ob point property splitting tained new nk vi product 
addition reasonable expect obtained small changes concerned question changes small vi distance 
property splitting cluster ass splitting ck clusters 
cluster probabilities lk ck 
splitting point represents lowest entropy split follows splitting point smallest results nearest nearest neighbors clustering vi metric splitting merging small clusters prove 
definitions 
shall say clustering refine cluster unique ck ck words refinement obtained splitting clusters original ifc refines easy see equality define pr kl xc fll lj ll li associ ated splitting ck product ering formed nonempty intersections 
note refinement 
vi property collinearity ofthe product tr tangle holds qj tl ll cx ing attained smallest distance decreases total number points increases 
words space clusterings larger diameter finer granularity 
allows clusterings possible smaller 
multiply integer obtaining new data set points point easy see clusterings possible respective distances preserved metric 
addition clusterings possible interspersed clusterings property pertaining computation time variation information 
property vi kk time 
computed surprising completely determined contingency table lv 
term formula second represents vi 
extensions re nn ort nc 
remain nr nn prt upper non uniform entropy smaller upper bound may bound similar holds may non uniform lower bound distance distinct clus note data needs known time ch consistent obtain clusterings 
soft clusterings equally easy define variation information distance soft clusterings 
soft clustering clustering data point belongs certain probability clusters ied pr distribution ied assume uniform need redefine joint distribution marginals 
definitions straightforward com follows weighted data points thee soft current context 
case model base distributions estimated represent posterior data generated distribution corresponding implicit assumption choice independent 
case compare obtained independent runs em algorithm data set assumption justified 
discussion new criterion comparing data set derived information theoretic principles 
criterion discriminative previously introduced criteria set matching 
particular example vi vi implying 
contrast pair count 
variation concerned points say variation information direct advantage 
ag criteria intrinsic context 
note normalize variation information order distance varies 
convenient limit comparison data set 
recommended compa bel en distances obtained different data sets 
possibility normalize upper bound log number bounded constant 
ci log ki normalization contrast previous preserve comparability distances data sets independently number data points set 
recommend simplification criterion 
shown vi metric 
ex lly fortunate allows see pac lt simple comparisons structure space metric entails existence turn allows vast array obtained different tool results summarization far existent nri values effect due different ation information pn sej understand vi represent think space way nearer intuition 
owe proofs proof property conditional tween defined vi ic cic prove cj shorthand notation 
inequality true conditioning decreases entropy second joint entropy larger marginal entropy 
detail see swapping indices inequalities obtain information 
proof property variation jeffrey banfield adrian raftery 
modelbased gaussian non gaussian clustering 
ics september 
asa ben hur 
andre elisseeff isabelle guyon 
method discovering structure clustered data 
pacific pages 
thomas cover joy thomas 
elements information theory 

fowlkes 
mallows 
method comparing hierarchical clusterings 
american stat ist ical association 
lawrence hubert arabie 
comparing classification 
larsen acme 
fast effective text linear time document di lj data 

