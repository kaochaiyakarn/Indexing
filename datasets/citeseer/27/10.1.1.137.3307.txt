chimaera high performance architecture tightly coupled reconfigurable functional unit zhi alex ye andreas scott hauck banerjee electrical computer engineering northwestern university ye banerjee ece nwu edu reconfigurable hardware potential significant performance improvements providing support application specific operations 
report experience chimaera prototype system integrates small fast reconfigurable functional unit rfu pipeline aggressive dynamically scheduled superscalar processor 
chimaera capable performing input output operations integer data 
discuss chimaera compiler automatically maps computations execution rfu 
chimaera capable collapsing set instructions rfu operations converting control flow rfu operations supporting powerful fine grain data parallel model supported current multimedia extension instruction sets integer operations 
set multimedia communication applications show simple optimizations chimaera compiler able map instructions rfu average 
variety computations mapped rfu operations ranging simple add sub shift pairs operations instructions including branches 
timing experiments demonstrate way order superscalar processor chimaera results average performance improvements assuming aggressive core processor design pessimistic rfu latency model communication overheads rfu 
traditionally instruction set architectures isas designed provide primitives facilitate low cost low complexity implementations offering high performance broad spectrum applications 
cases offering specialized operations tailored specific application domains result significant performance benefits 
unfortunately easier said done deciding operations support challenging 
operations specialized allow significant performance benefits time general useful variety applications 
electrical engineering university washington hauck ee washington edu importantly decide current performance benefits justify risks associated introducing new instructions isa 
instructions may software evolves may adversely impact hardware implementations 
reconfigurable hardware potential providing convenient way address aforementioned concerns 
may significantly improve performance tailoring operation application basis 
type specialized operations fixed isa reconfigurable hardware potential evolve applications 
increasingly higher levels chip resources anticipated reconfigurable capable systems provide potentially fruitful way utilizing resources 
furthermore increasing popularity multimedia applications provides excellent target reconfigurable hardware :10.1.1.21.5165
potential materialize need reconfigurable hardware way converting software exploit 
possible hand map applications exploit reconfigurable hardware writing working software complicated 
reason automated process highly desirable 
discuss experience designing chimaera reconfigurable hardware architecture experience providing compiler support 
particular review design chimaera explain integrated modern dynamically scheduled superscalar pipeline describe compiler optimizations exploit chimaera study resulting performance tradeoffs 
chimaera tightly couples processor reconfigurable functional unit rfu 
rfu small fast field programmable gate array fpga device implement application specific operations 
example rfu operation rfuop efficiently compute data dependent operations tmp tmp conditional evaluations multiple sub word operations half word long 
chimaera rfu capable performing computations input registers produce single register result 
rfu tightly integrated processor core allow fast operation contrast typical fpgas build discrete components relatively slow 
information chimaera architecture section 
chimaera potential advantages 
rfu may reduce execution time dependent operations 
tailoring datapath specific operations rfu may perform dependent operations time takes execute operations individually 

rfu may reduce dynamic branch count collapsing code containing control flow rfu operation 
case rfu speculatively executes branch paths internally selects appropriate 

rfu may exploit sub word parallelism 
bit level flexibility rfu sub word operations performed parallel 
similar typical multimedia instruction set extensions rfu approach general 
operations combined fixed isa definition 
example rfu operation combine byte adds byte subtracts 
combine byte wide conditional moves 

rfu may reduce resource contention instructions replaced single 
resources include instruction issue bandwidth writeback bandwidth reservation stations functional units 
exploit aforementioned opportunities developed compiler chimaera 
compiler uses simple cut optimizations effectively map computations rfu 
computations mapped diverse 
study performance chimaera variety timing rfu mapping assumptions ranging optimistic pessimistic 
demonstrate programs performance sensitive latency rfu aggressiveness synthesis process synthesis map set instructions rfu operation construct rfu datapath 
programs chimaera offers significant performance improvements pessimistic assumptions 
models approximate current prototype chimaera core rfu observe average speedups somewhat optimistic somewhat pessimistic 
rest organized follows section review chimaera rfu architecture discuss integrate rfu typical superscalar pipeline 
section discuss compiler support 
section review related 
section experimental results 
section summarize findings 

chimaera architecture chimaera architecture show detailed information rfu comprises components reconfigurable array ra shadow register file srf execution control unit ecu configuration control caching unit 
ra operations executed 
ecu decodes incoming instruction stream directs execution 
ecu communicates control logic host processor coordinating execution rfu operations 
responsible loading caching configuration data 
srf provides input data ra manipulation 
core rfu lies ra 
ra collection programmable logic blocks organized interconnected rows prototype 
row contains number logic blocks bit largest supported register data type case 
show implementation logic block 
logic block configured lookup table lut luts lut carry computation 
single row logic blocks share fast carry logic implement fast addition subtraction operations 
organization arithmetic operations addition subtraction comparison parity supported efficiently 
routing structure chimaera optimized operations 
register file host pipeline result bus ecu cache interface shadow register file reconfigurable array ra overview chimaera architecture input data supplied shadow register file srf physical partial copy actual register file 
organized single row containing copies logical registers 
allows single register write access host processor allows ra read registers 
physically registers srf organized bit interleaved fashion 
cells column ra access corresponding bit registers 
register cell accesses determined configuration explain 
different cells array choose registers access independently 
program execution ra may contain configurations multiple rfu operations rfuops 
configuration collection bits appropriately loaded ra implements desired operation 
long sufficient space ra need reload rfuop configuration time corresponding rfuop executed 
managing set rfuops loaded ra responsibility ecu 
loads configurations ra provides fast access evicted configurations caching provides interfaces necessary communicate rest memory hierarchy 
ecu decodes instruction stream 
detects rfuops guides execution ra necessary notifies currently unloaded configurations 
point time multiple rfuop configurations ra provided space 
assume program modify configuration data execution 
write traffic writes configuration space 
write detected exception raised ra flushed updated 
rfuop instruction associated configuration id id serves identify appropriate configuration 
mux bs xs ds carry tree logic cell structure compiler generates configurations ids 
linker places configurations program address space generates vector table pointing generated configuration 
run time detection rfuop ecu initiates trap load appropriate configuration place 
configuration loaded execution stalled 
prototype implementation row requires bits configuration 
working set rfuops relatively small show case benchmarks studied configuration overhead amortized multiple executions rfuop 
cache configurations maintained reduce configuration loading latency 
rfuop instruction format shown 
consists rfuop identifying opcode id destination register number 
notably input operand information provided 
recall configuration routes appropriate input data 
identities input registers required order scheduling 
implementation information provided configuration data layout shown 
consists bit vector records source operands number rows required actual configuration bits 
order scheduling ecu maintains record entries input vectors rfuops currently loaded ra 
interface order core allow order execution rfuops provide separate small rfuop scheduler 
scheduler follows ruu model 
operates follows encountering rfuop ecu allocates dummy entry scheduler ooo core 
entry maintain order commits support control speculative execution ooo notifies rfuop scheduler speculations dummy entry 
input vector data ecu allocates entry rfuop scheduler marking location desired input register done maintaining shadow register renaming table allows single cycle access entries 
mux lut lut reg reg mux lut mux lut lut lut lut mux bits bits bits rfuop opcode destination register rfuop number bits bits bits 
bits input register vector rows row configuration 
row configuration rfuop instruction format 
rfuop configuration data layout 
single target register rfuop renamed ooo core 
having marked input dependences having renamed single output register rfuop scheduling proceeds fashion regular instruction scheduling 
experiments assume single issue capable rfuop scheduler significantly simplifies design allows easy integration current ra prototype 
standalone prototype ra fabricated tested 
chip fabricated um layer cmos process 
noted actual system ra implemented technology processor core 
worst case path single logic block current prototype consists transistor levels 
modern microprocessors exhibit great variety number transistor levels operating single clock cycle 
example aggressive implementation allows transistor levels clock cycle input gates design allows transistors levels clock cycle input gates 
utilizing delay model estimated worst case delay ra row cycles implementations transistor levels respectively 
row capable implementing single integer instructions typical isa addition logic operations shifts multiplication loads stores 
logic blocks capable performing complex computations 
table shows mapping timing set common bit computations 
row reports critical path length ra transistor levels 
second row shows required number ra rows 
third row reports height equivalent dataflow graph 
fourth row shows latency computation function processor cycle assuming aggressive processor transistor levels clock cycle 
seen rfu introduces overheads implementing single instruction 
combined operations rfu offers competitive better latency 
detailed description rfuop latency models section 
compiler support developed compiler chimaera automatically map groups instructions rfuops 
compiler built widely available gcc framework version 
introduced rfuop specific optimizations instruction combination control localization simd register swar 
provide overview optimizations 
information provided 
core optimization instruction combination extracts rfuops sequence instructions intermediate control flow 
works analyzing dfg extracting subgraphs consist multiple rfu efficient int step delta step delta step delta step delta step 
nodes 
rfu efficient nodes correspond instructions mapped rfu adds logic operations shifts 
sub graph single register output intermediate outputs allowed provided outside sub graph 
recall rfuop produce single register result 
subgraphs mapped rfuop 
increase opportunities instruction combination compiler performs optimizations 
control localization transforms branch containing sequences temporary aggregate instructions treated single unit instruction combination 
swar optimization identifies sub word operations executed parallel 
current implementation searches opportunities pack bit operations single word operation 
cases pattern exists loops unit stride 
unfortunately due lack alias analysis phase current prototype apply optimization correctness 
reason disabled optimization experiments 
shows example compilation process adpcm decoder function appears adpcm dec benchmark see section description benchmarks 
part original source code shown part 
code control localization shown 
sn notation refers temporary instruction source operands sn destination shown statements converted temporary instructions forming single entry single exit instruction sequence 
instruction combination phase maps instructions single rfuop shown part 

related numerous reconfigurable hardware architectures proposed 
roughly divide categories target coarse loop level optimizations target fine grain instruction level optimizations 
approaches complementary 
critical path transistors ra rows dataflow graph height latency processor cycles table critical path rfu ra operations assuming transistor levels processor cycle 
int step delta step temp delta step temp delta step temp delta step 
int step delta rfuop delta step 
example chimaera optimizations 
original code 
code control localization 
code instruction combination 
example taken adpcm dec mediabench benchmark 
loop level systems capable highly optimized implementations pipeline loops 
garp napa piperench rapid raw examples systems :10.1.1.22.3767:10.1.1.21.5165
success approach lies compiler ability perform extensive loop memory disambiguation analysis typically required decide loop pipelined parallelized 
systems utilize large amounts parallelism coarse grain provided parallelism exists target application 
instruction level systems target fine grain specialization opportunities 
capable building functional units implement operation instructions 
chimaera prisc disc instruction level systems :10.1.1.43.1041:10.1.1.47.1042
implementation details chimaera differs systems primarily supports input output instruction model 
restricted forms optimizations similar chimaera capable existing architectures 
architectures provide support collapsing small number data dependent operations single combined operation 
example dsps provide multiply add instructions 
ibm power architecture isas 
phillips vassiliadis proposed interlock collapsing alu capable input complex expressions 
vassiliadis smith analyzed performance potential collapsing data dependent operations single cycle equivalents 
current isas added support simd subword operations supporting operations tailored multimedia applications saturating arithmetic 
chimaera provides general model subword parallelism model operation restricted isa 
chimaera combine subword operations single word wide operation operations different adds xors 
strictly speaking simd mimd aggregate instruction 
number input registers large 
component configuration branch predictor gshare chimaera map code containing control flow single operation 
similar effect possible predicated execution :10.1.1.13.7848
internally rfu computes possible paths selects appropriate 
similar effect possible general multiple path execution models 

evaluation section experimental analysis model chimaera architecture 
section discuss methodology 
discuss various rfuop latency models experiments 
section analysis rfuops generated 
section provide statistics working set rfuops 
significant execution stalled loading configuration newly encountered rfuop 
section measure performance impact rfu optimizations aggressive dynamically scheduled superscalar environment 
methodology benchmarks mediabench honeywell benchmark suites 
table provides description benchmarks 
honeywell benchmark suite extensively testing performance reconfigurable systems 
benchmarks default input data set 
cases resulting instruction count appears relatively small note due nature short runs indicative program behavior 
compiled benchmarks chimaera compiler modified version gcc version 
profiling identify candidate functions superscalar core scheduler order issue operations cycle entry re order buffer ruu entry load store queue lsq functional units integer alus integer mult fp adders fp mult div functional unit latencies integer alu integer mult integer div fp adder fp mult fp div load store instruction cache kb direct mapped byte block cycle hit latency data cache kb direct mapped write back write allocate non blocking byte blocks cycle hit latency cache unified way set associative byte cycles hit latency main memory infinite size cycles latency fetch mechanism instructions cycle reconfigurable functional unit scheduler entries 
entry corresponds single rfuop single issue single write back cycle 
rfuop issue inputs available instance rfuop currently executing 
functional unit ra rows 
rfuop occupies rows instructions original program replaced pessimistic single instance rfuop active point time 
configuration loading st level configuration cache configuration rows bytes 
configuration loading modeled injecting accesses rest memory hierarchy 
execution stalls duration configuration loading 
rfuop latency various model simulated 
see section 
table base configuration timing experiments 
optimization 
performance measurements execution driven timing simulation 
build simulator widely available simplescalar simulation environment 
instruction set architecture isa extension mips isa embedded rfuops 
appropriately choosing opcode rd field rfuop format rfuops appear mips isa 
experiments benchmark description inst 
count mediabench benchmarks mpeg encoder enc ccitt voice encoder dec ccitt voice decoder adpcm enc speech compression adpcm dec speech decompression key generation 
pegwit public key encryption authentication application 
pegwit encryption pegwit decryption honeywell benchmarks comp image compression decomp image decompression table benchmark characteristics 
base configuration shown table 
models aggressive way dynamically scheduled superscalar processor 
experiments model way processor derived way configuration doubling issue width appropriate stages instruction window size 
rfu configuration shown table 
rfu place maximum number instructions pass decode fetch write back commit limited including rfuops 
furthermore single rfuop issue cycle 
modeling rfuop latency study performance necessary express rfuop execution latencies terms processor cycles 
latencies modeled accurately specific processor rfu implementation synthesis rfu configuration algorithm 
valuable utility model limited specific configuration synthesis algorithm 
goal understand performance tradeoffs exist chimaera architecture experimented rfuop latency models summarized table 
original instruction models model cpu cycles transistor level models model cpu cycles table rfuop latency models 
critical path length original dataflow graph rfuop replaces 
number original instructions replaced rfuop 
number transistor levels rfuop 
tiered approach 
utilize latency models original instruction sequence rfuop replaces 
models provide insight latencies rfu able sustain fruitful approach 
reported original instruction models table 
models model rfuop latency function critical path equivalent original program computation 
provide additional insight modeled fixed rfu latencies cycles number original program instructions mapped rfuop 
cycle models offer upper bounds performance improvements possible current chimaera compiler 
utilize transistor level models 
hand mapped rfuop efficient rfu configuration measured number transistor levels appearing critical path 
calculated latencies various base processor configurations 
published data number transistor levels clock cycle modern processors developed timing models 
models assume designs transistor levels cycle 
corresponds design input gates clock cycle 
assumes aggressive base processor pipeline input gates clock cycle 
model possibility extra delays interconnect rfu include models include additional cycle latency respectively 
model optimistic model pessimistic 
rfuop analysis section analysis rfuop characteristics 
goal provide insight type computations current prototype chimaera servicing 
measure total number instructions mapped rfuops distribution rfuop sizes terms number type original instructions replace 
measurements critical path computation rfuops replace 
take close look internals rfuops 
results number transistor levels implement rfuops ra 
table shows statistics number instructions mapped rfuops 
ic columns report dynamic instruction count chimaera optimized program 
expressed percentage original instruction count shown table 
report fraction original instructions mapped rfuops red column 
remaining columns provide instruction type breakdown mapped instructions 
shown percentage instructions type original program orig columns portion percentage opt columns mapped rfuops chimaera optimized program 
example instructions mapped rfuops resulting reduction dynamic instruction count 
original program branches instructions mapped rfuops 
observe significant fraction instructions mapped rfuops average 
actual percentage varies little 
importantly significant fraction branches eliminated average 
branches foil gshare predictor 
relatively large fractions shift operations mapped rfuops compared instruction types 
bench ic red 
branch add sub logic shift opt 
orig 
opt 
orig 
opt 
orig 
opt 
orig 
opt 
enc dec average table global instruction count statistics 
take closer look computations mapped rfuops 
measure distribution terms number original instructions replace height original dataflow graph critical path implement 
measurements shown table table respectively 
measurements weighted dynamic execution count rfuop 
focusing table observe exception half 
enc dec average table rfuop distribution terms original instruction count 
range shown instructions columns rows 
op op op op executed rfuops replace instructions 
usually correspond input output operations form dest src op src op src 
rfuops replace original instructions quite common 
input output alu type operations statements including hammock control flow behavior 
cases find rfuops replaced original instructions 
cases correspond chained branch sequences 
extreme cases compiler able generate rfuops replace instructions 
rfuop operations comprise multiple branch statements series operations result multiple input single output statements 
critical path measurements shown table provide additional insight computations mapped rfuops 
resources typical order processor limited primarily computation critical path 
rfuops critical path equivalent original instructions 
includes rfuops replace original instructions critical path instruction branch 
includes rfuops map original instructions 
rfuops critical path equivalent instructions 
rfuops map original instructions respectively demonstrate significantly shorter critical paths enc dec average table rfuop distribution terms critical path original dataflow graph 
range shown instructions 
op op op op op op op op op op op rfuop instruction type composition 
left 
right rfuops rfuops instruction types shown addition subtraction logical operations shifts branches moves 
add sub logic shift branch move instructions respectively 
note small differences tables result rounding errors 
better understanding take closer look internal composition individual rfuops 
clarity restrict attention applications 
shows measurements 
chose benchmarks contain small number rfuops 
bar rfuop shown axis 
bar divided sub bars axis representing instruction type breakdown original instructions 
split instructions addition subtraction bit logic operations shifts branches moves 
rfuops included graph 
actual instruction count type shown numbers sub bars 
seen chimaera compiler capable mapping variety computations 
addition subtraction shift operations quite common types operations mapped 
example computation comprising additions subtractions branches mapped single rfuop 
op computes equivalent branches shifts logic add sub instructions 
report statistics number transistor levels rfuops mapped actual ra configurations 
purposes experiment hand mapped rfuops 
current ra implementation add sub operations relatively slow requiring transistor levels 
operations efficient requiring transistor benchmark transistor levels critical path inst 
transistor levels rfuop avg 
min max avg 
min max enc dec table rfuop transistor level statistics 
levels 
furthermore possible collapse original instructions efficient transistor level implementations 
example add shift operation requires transistor levels 
table reports rfuop transistor level statistics benchmarks 
clarity aggregate metrics 
report average minimum maximum number transistor levels rfuop benchmark rightmost columns 
variation average number levels relatively large 
complex operations require transistor levels simple require 
number may discouraging important pay attention original instruction sequence replace 
accordingly report average minimum maximum number transistor levels rfuop amortized critical path original instruction sequence replaced rfuop 
perspective worst case transistor levels required level original dataflow graph 
hand optimized configurations shown expect possible generate comparable better results automated method 
working set rfuops measure performance impact various models chimaera architecture provide measurements working set rfuops 
important execution stalled configuration loading 
having large working set may adversely impact performance result thrashing configuration array ra requiring frequent accesses memory 
measured working set rfuops amount storage required avoid excessive accesses memory configuration loading 
reports working set measurements 
shown rate cache contains encountered rfuops 
vary 
programs maintaining record rfuops results virtually misses 
worst case entries sufficient 
measure rate assuming rfuop requires configuration rows bits number original instructions replaces 
pessimistic assumption actual implementation single row map instructions 
simulated caches various sizes 
range shown configuration rows bytes 
programs just rows sufficient 
cases rows required 
prototype ra capable holding rows simultaneously 
results experiment indicate working set rfuops relatively small amount configuration storage rfu sufficient prevent thrashing 
performance measurements section study performance varies chimaera introduced aggressive dynamically scheduled superscalar processor 
consider way base configuration original instruction timing models transistor level models 
consider way base configuration 
rate adpcm enc adpcm dec mpeg enc enc dec pegwit key pegwit enc pegwit dec honey enc honey dec cache size rfuop working set 
cache size number rfuops coexist rfu 
rate cache size adpcm enc adpcm dec mpeg enc enc dec pegwit key pegwit enc pegwit dec honey enc honey dec rfuop configuration size working set 
cache size number rows rfu 
shows performance varies way configuration include rfu 
note rfu included issue write back commit bandwidth limited instructions cycle including rfuops 
furthermore single instance rfuop active rfu point time 
seen part model chimaera offers speedups average way base configuration 
cases speedups exceed 
hand observe slowdowns benchmarks 
model performance improvements double average 
note speedup model 
model performance enc enc dec dec relative performance way base configuration 
original instruction timing models adpcm dec bars truncated 
measurements 
transistor level timing models adpcm dec bars truncated 
measurements left right 
improves benchmark 
expected cycle model shows radical performance improvements benchmarks having rfuops replaced original instructions 
notably model performance improves benchmarks 
case decreased branches reduced resource contention primarily impact performance 
programs studied branches mapped rfuops foil gshare predictor 
results experiment suggest way superscalar processor programs studied chimaera offer performance improvements rfuop latencies order 
part shows performance variation transistor level models 
notably chimaera performs context highly aggressive assumptions base processor cycle 
conservative model observe improvement average 
shown model performance improve average absence additional communication overheads 
expected models show greater improvements 
performance models close upper bound measured cycle model part 
reports performance variations way base configuration 
part report experiments original instruction timing models part report performance transistor level timing models 
original instruction models performance improves models 
relative improvements smaller compared way processor 
model slowdowns observed 
results suggest way host processor rfuop latencies better model average average required improve performance 
factors explain relatively lower performance impact chimaera way base processor configuration compared way configuration 
limit rfuop execution single instance rfuop time different rfuops active simultaneously 
limits amount inter rfuop parallelism exploited 
impacts performance way configuration way configuration twice large instruction window 
result inability exploit inter rfuop parallelism instances rfuop 
second rfuops map original instructions consume issue slot base processor 
result single rfuop effectively allows issue corresponding original instructions single issue slot 
greatly improve performance issue resources limited way vs way configuration 
part reports performance variations transistor level models 
case way configuration performance improves significantly pessimistic model 
performance differences models greater way configuration 
strong correlation exists performance fraction branches replaced rfuops 
shown table enc dec demonstrate lowest fractions reduced branches lowest performance improvements 
comparison performance improves largest amount removed branches 
results section suggest relatively pessimistic assumptions rfu latency chimaera results significant performance improvements way way highly aggressive superscalar processors 
enc enc dec dec relative performance way base configuration 
original instruction timing models adpcm dec bars truncated 
measurements respectively 
bar truncated 
number 
transistor level timing models adpcm dec bars truncated 
measurements left right 

summary described chimaera micro architecture integrates reconfigurable functional unit pipeline aggressive dynamically scheduled superscalar processor 
described chimaera compiler automatically generates binaries rfu execution 
chimaera micro architecture capable mapping sequence instructions single rfu operation provided aggregate operation reads input registers generates single register output 
chimaera capable eliminating control flow instructions way similar possible predicated execution 
chimaera capable general sub word data parallel model offered current multimedia oriented isa extensions 
set multimedia communication applications simple optimizations chimaera compiler able map instructions average 
variety computations mapped rfu operations simple add sub shift pairs operations instructions including branch statements 
studied performance chimaera variety configurations 
studied chimaera performance number timing models ranging pessimistic optimistic 
experiments demonstrate way order superscalar processor performance approach results average performance improvements pessimistic transistor level timing model 
actual performance variation range 
way superscalar processor observed speedups average 
actual performance variation range 
different timing model matches existing high performance processor designs chimaera average average improved performance average way way base configurations respectively 
performance varied respectively 
results demonstrate potential chimaera approach pessimistic rfu latency assumptions 
encouraging performance improvements obtained automatic compilation 
similar higher performance improvements observed multimedia applications specialized instruction set extensions cases result careful hand optimizations 

acknowledgments reviewers helpful comments 
project supported darpa contract dabt 
august connors mahlke cheng eaton hwu integrated predicated speculative execution impact epic architecture proceedings th annual international symposium computer architecture 
august eaton connors hwu impact epic architecture instruction set manual technical report impact university illinois urbana il feb 
doug burger todd austin bennett evaluating microprocessors simplescalar tool set computer sciences technical report cs tr university wisconsin madison 
franklin berg ebling specifying compiling applications rapid proceedings ieee workshop fpgas custom computing machines 
vivek de shekhar borkar low power high performance design challenges technologies proceedings th great lakes symposium vlsi mar 
ebcioglu altman daisy dynamic compilation architectural compatibility proceedings th annual ieee acm international symposium computer architecture jun 
machine organization ibm risc system journal research development vol 
jan 
goldstein schmit moe budiu taylor laufer :10.1.1.21.5165
piperench coprocessor streaming multimedia acceleration proceedings th annual acm ieee international symposium computer architecture may 
hauck fry kao chimaera reconfigurable functional unit ieee symposium fpga custom computing machines apr 
hartenstein weber machine paradigm application digital signal processing acceleration international conference parallel processing 
tim gary ultrasparc iii designing third generation bit performance ieee micro may june 
honeywell technology center adaptive computing system benchmarking www honeywell com projects 
john hauser john wawrzynek garp mips processor reconfigurable coprocessor proceedings ieee workshop fpgas custom computing machines apr :10.1.1.22.3767
heil smith selected dual path execution university madison wisconsin technical report may 
killian mips extension digital media microprocessor forum oct 
grunwald selective eager execution architecture proceedings th annual international symposium computer architecture jun 
schlansker rau hpl architecture specification version technical report hpc hewlett packard laboratories feb 
lee barua frank babb sarkar amarasinghe 
space time scheduling instruction level parallelism raw machine proceedings th international conference architectural support programming languages operating systems oct 
lee subword parallelism max ieee micro vol aug 
lee potkonjak william mangione smith mediabench tool evaluating synthesizing multimedia communications systems proceedings th annual ieee acm international symposium microarchitecture dec 
thomas tu powerpc microprocessor high performance superscalar risc processor compcon technology information mar 
stuart greg favor fred weber amd dnow 
technology architecture implementations ieee micro mar apr 
phillips vassiliadis high performance interlock collapsing alu ieee transactions computers mar 
peleg wilkie weiser intel mmx multi media pcs communications acm jan 
smith high performance microarchitectures hardware programmable functional units proceedings th annual ieee acm international symposium microarchitecture nov 
prisc programmable reduced instruction set computers ph thesis harvard university division applied sciences 
holt arnold gokhale napa adaptive processing architecture ieee symposium fpgas custom computing machines apr 
sohi instruction issue logic high performance interruptible multiple functional unit pipelined computers ieee transactions computers mar 
vassiliadis james smith 
performance potential data dependence speculation collapsing th annual ieee acm international symposium microarchitecture dec 
tremblay michael connor venkatesh narayanan liang vis speeds new media processing ieee micro vol aug 
wittig chow fpga processor reconfigurable logic proceedings ieee symposium fpgas custom computing machines apr 
wallace calder threaded multipath execution proceedings th annual ieee acm international symposium computer architecture dec 
michael brad hutchings dynamic instruction set computer ieee symposium fpgas custom computing machines apr :10.1.1.43.1041
taylor sarkar lee lee kim frank finch barua babb amarasinghe agarwal software raw machines ieee computer sep 
principles cmos vlsi design systems perspective addison wesley publishing 
zhi alex ye shenoy banerjee compiler processor fpga architecture proceedings th acm internation symposium field programmable gate arrays feb 
