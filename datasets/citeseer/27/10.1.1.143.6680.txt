face detection video sequence temporal approach mikolajczyk choudhury schmid inria rh ne alpes cnrs av 
de europe montbonnot france mikolajczyk choudhury cordelia schmid inrialpes fr presents new method detecting faces video sequence detection limited frontal views 
novel contributions accumulation probabilities detection sequence 
allows obtain coherent detection time independence thresholds 
prediction detection parameters position scale pose 
guarantees accuracy accumulation continuous detection 
way pose represented 
representation combination detectors frontal views profiles 
face detection fully automatic method developed schneiderman 
uses local histograms wavelet coefficients represented respect coordinate frame fixed object 
probability detection obtained image position scales detectors 
probabilities detection propagated time condensation filter factored sampling 
prediction zero order model position scale pose update uses probability maps produced detection routine 
experiments show clear improvement frame detection results 
context video structuring indexing visual surveillance faces important basic units 
application example identify actor video clip face detection required step 
existing approaches detect faces frame temporal information detect face frame track face sequence separate algorithm 
presents novel approach integrates detection tracking unified probabilistic framework 
uses temporal relationships frames detect human faces video sequence detecting frame independently 
proposed algorithm detects regions interest potentially contain faces detection probabilities 
probabilities propagated time condensation filter factored sampling prediction updating 
predict detection parameters position scale pose 
information predicted face location scale significantly accelerate algorithm narrowing search area scale 
accumulation probabilities allows continuously detect faces frames probability detector fails 
prediction helps obtain stable detection time independent scale dependent thresholds 
pose representation allows handle plane rotations considered challenging task tracker 
handle appearance disappearance faces updating probabilities produced detection routine 
experiments carried various video sequences multiple faces occurring different sizes 
addition faces disappear sequence get occluded pose face changes 
applied proposed algorithm sequences 
experimental results show clear improvement frame detection results 
related past concentrated detection exploiting temporal aspect form face tracking 
detection feature statistical model colour geometric shape motion information 
features may convey complete information face 
model approaches suffer drawbacks specific model skin colour susceptible changes lighting conditions motion information may distracted alternate motion video 
order incorporate face changes time terms changes scale position localize search face essential exploit temporal information inherent videos 
face tracking exploits temporal content image sequences 
variety trackers proposed faces general objects 
involve feature tracking contours points information contour colour 
birchfield combines approaches obtain tracker ex elliptical contour fitted face colour information enclosed 
handle plane rotations occlusions unable handle multiple faces 
tracking categorized basis face model shape colour statistical models 
involves prediction update filters kalman filter condensation filter 
tracking requires initialization done manually 
furthermore handle appearance new targets scene 
approaches combine tracking detection mainly detection initializing tracker track detected features sequence 
may difficult features pupils difficult detect 
liu propose method incorporates non frontal faces updating 
pose variation handled detection 
framework track multiple faces permit addition new faces 
survey highlights contribution approach integrate detection temporal aspect video sequence 
propose procedure face detection robust changes scale pose 
detection initialization detection information integrated time step propagated parameters 
addition detection probabilities provide information new faces incorporated appear 
overview organized follows 
section briefly describe approach 
section describes detection algorithm pose representation 
followed description temporal propagation section 
section presents results approach compares results obtained frame frame detection 

temporal approach face detection proposes method identifying multiple faces video sequence 
initially detector local histogram wavelet coefficients associate detection probability pixel 
probability value computed different scales different views 
pose mean frontal profile views positions face views 
parameters characterize face position scale pose 
parameters computed frame detection detector response decrease due different reasons occlusions lighting conditions face pose 
additional information responses easily rejected indicate presence face 
due fixed threshold 
lowering threshold increases number false detections see example results 
furthermore frame detection continuous time 
propose temporal approach detection avoids problems 
idea propagate detection parameters time condensation filter 
prediction zero order model position scale pose 
update stage uses probability map generated detection routine 
proposed procedure divided phases 
phase detection produces probabilities image location scale viewpoint 
described section 
second phase prediction update stage predicts detection parameters uses probabilities track face sequence 
temporal propagation described section 
face detection face detection algorithm method developed schneiderman kanade 
local implementation detector 
briefly explain detector computation probability score temporal approach 
furthermore give implementation details explain represent pose 
detection algorithm detector uses statistics face nonface appearance 
statistics joint probabilities visual attributes 
visual attributes referred obtained combining quantized wavelet coefficients different sub bands 
obtain visual attributes representing different orientations frequencies 
visual attributes computed different positions experiments 
histograms represent joint statistics visual attributes 
probability score response detector weighted combination visual attribute probabilities face non face model 
weights estimated training data order minimize classification error 
responses normalized associate face probabilities pixel 
probability corresponds location scale 
probabilities computed image positions different scales 
ratio consecutive scale levels chosen empirically 
order detect frontal profile views detectors cf 

probabilities frontal profile detectors pf 
varying face pose 
frame numbers 
cross indicates location local maxima frontal detector circle location local maxima profile detector 
pp respectively 
coordinates position detector applied scale 
obtain probability map image location local maxima correspond potential face locations 
frame frame approach face detected maximum threshold 
maxima scales merged collision removal 
frame number pose sequence 
probability scores frontal profile detectors 
sequence frame numbers face pose correspond 
implementation details probability pattern estimated training data 
frontal face profile face model built different faces 
faces normalized respect size orientation 
increase training set created face smoothed rotated versions 
profile faces training set included images faces angles degrees 
non face model initially learnt images containing faces 
reapplied detection procedure non face images updated non face model locations gave highest detection responses 
training set face non face images collected internet test video sequences included training set 
pose representation order detect faces viewpoint detectors 
trained detect frontal views detect profiles 
note profile detector applied mirror reversed image 
keep higher response probability profile 
see detectors sufficient detect intermediate views 
shows probabilities detectors varying pose 
corresponding pose images displayed 
see probability frontal view detector decreases face turns sideways vice versa 
combination detectors allows approximatively estimate pose 
approximation sufficient prediction update 
detectors predict face turning disappearing case decreasing probability 
note maximal response detectors applied intermediate face poses slightly different 
estimated displacement vector training set 

temporal propagation developed framework prediction update propagates probabilities detection detection parameters time 
condensation conditional density propagation algorithm proposed isard blake 
probability distribution detection parameters represented random samples 
distribution evolves time input data observations change 
condensation filter kalman filter represent non gaussian densities handle multiple modes alternate hypotheses 
addition state detection parameters conditional past state estimated data sequence filter 
factored sampling helps propagating time samples higher associated weights 
required scenario faces higher probability score need propagated time 
condensation filter combined factored sampling appropriate purpose 
adaptation condensation detection parameters need predict position 
position ranges entire image 
scale face occurs 
discrete range scales empirically chosen cf 
section 
parameter indicating pose 
take value degrees indicates angle 
indicates frontal face profile 
note distinguish profiles left right 
state time st defined vector parameters st xt yt st 
observations stage probability values computed detector section 
probability xt yt st value associated pixel image associated particular scale 
different probabilities associated poses head pf corresponding frontal face detector pp corresponding profile detector 
observation zt zt pf pp probability values indicate likelihood observations 
conditional probability zt st probability observation zt state st conditional probability distribution discrete representation entire probability distribution constructed possible states 
proposed algorithm divided steps 
note probabilities denoted suffixes frontal side views need distinguish 
step initialization initialize local maxima detection initial frame video sequence 
maxima propagated separately 
note threshold case detection 
maxima corresponding non faces eliminated time 

pick gaussian random sample maxima 
keep scale fixed initial sampling consolidate maxima scale 
pick samples maxima 

pick probabilities corresponding samples respective positions frontal profile faces 
initialize pose pp pf pp corresponding total probability pf pp set probabilities normalized produce weights wi total number pi pi samples propagated 
sample states weights predict probability distribution time instant 
stages set new probability distribution time distribution time 
step ii selection factored sampling sample states stage 
propagated time instant depending associated weights 
step iii prediction zero order temporal model prediction new state xt xt yt yt st st round note scaling factor empirically chosen 
shown give best results scale 
experiments set parameters 
prediction approximates conditional probability state previous state 
step iv updating probabilities predicted states obtained weighting responses pf pp difference predicted observed pose 
combined response associated state xt yt st max pf pp pp predicted pose pf pp observed pose time linear function decreases difference increases 
aim maintain high response predicted pose direction observed pose response decrease prediction incorrect 
lower response causes sample rejected stage 
consolidate propagated samples stage find weighted mean mean variance ar wis mean states si xi yi si 
mean value indicates position scale face 
allows stabilization time 
variance stable time faces increases non faces gets diffused time 
incorporating appearance new faces handle situation new faces appear scene update set local maxima nth frame equal experiments 
allows incorporate new faces appear sequence 
faces lost ones get diffused image variance increases 

experimental results experiments carried different video sequences multiple faces occurring various sizes positions 
furthermore faces may disappear sequence fig 
frame 
compare frame frame detection method temporal 
column frame frame detector 
second column temporal detector 
frame numbers marked images 
detection 
fig 
fig 
show results sequences 
column displays frame frame detection results second column gives results temporal detector 
frame frame detection detection algorithm section applied frame video sequences 
occurrence local maximum indicates presence face 
face detected maximum fixed threshold 
results individual frames shown columns fig 
fig 

scale face detected determines size bounding box 
previously observed results sensitive threshold 
shown missing detection false detection rate vary significantly depending threshold 
temporal detection temporal framework applied video sequences 
strongest local maxima associated frame sequence initialize procedure 
loss generality strongest maxima experiments 
maxima propagated temporal sequence 
weighted mean variance computed frame samples 
mean value position scale display position face draw corresponding bounding box 
smoothes size eliminates discontinuities frame detection 
results shown second columns 
shows results pose detection applied sequence 
combination detectors frontal profile shown 
response frontal detector rapidly diminishes face turns away camera profile detector responses indicated triangle embedded square increases 
combined temporal approach give integrated response 
observations face man detected simple detector frame fig 

local maximum low probability location man case temporal detector maximum picked initialization propagated increased time 
frame frame detection fails probability score detection threshold 
frame fig 
maxima initialization non faces 
probability non faces goes zero subsequent frames eliminated 
faces continue tracked case head movement plane rotation frame frame detection loses faces associated probability score drops threshold cf 
fig 
frame 
occluded faces reappear sequence detected simple detector compared temporal detector fig 
frames 
evaluation applied frame approach temporal approach images various video sequences 
frame approach gave false detections missing detections 
temporal approach able remove false detections faces continuously detected video sequence 
experiments show temporal detector clearly improves results frame detection results 

perspectives novel approach temporal face detection gracefully integrates detection individual frames temporal aspect 
allows improve individual detection results time track sequence 
propose include motion model incorporate alternate cues colour investigate gain obtained additional third detector intermediate views degrees 
supported french project european fet open project vibes 
acknowledge institut national de giving permission video material 
sequence occluded faces 
column frame frame detector 
second column temporal detector 
frame numbers marked images 
displayed figures 
birchfield 
elliptical head tracking intensity gradients color histograms 
cvpr pp 

comaniciu ramesh meer 
real time tracking non rigid objects mean shift 
cvpr pp 

decarlo metaxas 
deformable model face shape motion estimation 
fg 
edward taylor cootes 
learning identify track faces image sequence 
fg pp 

de campos junior 
detection tracking facial features video sequences 
lecture notes ai pages 
gelb editor 
applied optimal estimation 
mit press 
hager toyama 
vision portable substrate real time vision applications 
cviu 
isard blake 
condensation conditional density propagation visual tracking 
ijcv 
liu wang 
face detection tracking video dynamic programming 
icip 
maccormick blake 
probabilistic exclusion principle tracking multiple objects 
iccv pp 

mckenna gong collins 
face tracking pose representation 
bmvc pp 

raja mckenna gong 
tracking segmenting people varying lighting conditions color 
fg pp 


results pose detection 
face turns response frontal detector square decreases profile detector triangle embedded square increases 
displayed detector maximum response obtained 
schneiderman kanade 
statistical method object detection applied faces cars 
cvpr volume pp 

crowley 
robust face tracking colour 
fg pp 

sung poggio 
example learning viewbased human face detection 
pami 

shirazi akamatsu 
comparative performance different skin chrominance models chrominance spaces automatic detection human faces color images 
fg pp 

yang waibel 
tracking human faces real time 
tr cmu cs cmu 
yow cipolla 
feature human face detection 
tr university cambridge 
