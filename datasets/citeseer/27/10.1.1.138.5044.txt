hardware acceleration unit mpi queue processing keith underwood scott arun rodrigues richard murphy ron sandia national laboratories box ms albuquerque nm sandia gov heavy reliance modern scientific applications mpi standard critical implementation mpi capable fast possible 
led fastest modern networks introduce capability offload aspects mpi processing embedded processor network interface 
important capability come significant performance implications 
notably time process long queues posted receives unexpected messages substantially longer embedded processors 
presents associative list matching structure accelerate processing moderate length queues mpi 
simulations compare performance embedded processor augmented capability baseline implementation 
proposed enhancement significantly reduces latency moderate length queues adding virtually overhead extremely short queues 

mid message passing dominant mechanism programming massively parallel processor systems 
late majority message passing programs leveraged mpi standard 
intervening years billions dollars invested developing application codes mpi 
critically important insure new systems implement mpi efficiently possible 
approaches taken characterizing efficiency mpi 
common useful evaluate ping pong latency bandwidth net sandia laboratory operated sandia lockheed martin united states department energy national nuclear security administration contract de ac 

necessary order measures models logp useful 
early models indicates important thing applications minimize overhead time application processor involved communication 
result highest performing networks chosen offload sending receiving mpi messages network interfaces :10.1.1.143.4625
unfortunately second largest impact application performance gap inverse message rate 
indicated applications tend traverse significant number entries primary queues managed mpi posted receive queue unexpected message queue 
networks embedded processors traverse queues traversing long queues increases gap 
compromise decrease overhead increasing gap scenarios 
proposes unique hardware structure augment microprocessor accelerate list traversal matching 
proposed hardware uses associative matching structures similar concept ternary content addressable memories perform high performance parallel matching 
structures enhanced list management capabilities support unique combination ordering semantics high list entry turnover needed support mpi point point message passing 
better understand basic properties design prototype created fpga hardware 
prototype provides idea clock rate achieved timing expected 
serves avenue explore refine issues control interface 
unfortunately implementation difficult integrate real environment 
system level simulation demonstrate usefulness proposed hardware 
mpi implementation created leverages hardware acceleration unit 
simulation mpi implementation compared baseline implementation embedded processor benchmarks discussed 
section provides background information semantics mpi discusses related research activities 
software interface hardware design described sections respectively 
mpi implementations simulator described section 
results comparison section section 
background conceptually mpi implementation message queues contains list outstanding receive requests posted receive queue contains list messages arrived match previously posted requests early arrival unexpected queue 
incoming messages traverse posted receive queue possible match unexpected queue match 
request added posted receive queue unexpected queue searched possible match 
search unexpected queue add entry posted receive queue atomic operation insure matching message arrive time unexpected queue searched receive posted 
mpi messages matched fields context identifier source rank message tag 
context identifier represents mpi communicator object 
message tag provides safe message passing context messages context interfere messages contexts 
source rank represents local rank sending process communicator message tag user assigned value message selection particular context 
posted receive explicitly match context identifier may wildcard source rank message tag values match value 
addition matching criteria mpi mandates ordering constraint 
messages nodes context arrive order corresponding sends initiated 
mpi implementations described published literature represent posted receive unexpected queues linear lists 
method time traverse queues grows linearly length list 
length list grow linearly number processes parallel application 
networks time spent traversing arbitrarily long queue may impact entire system network interface may unable service requests search 
lead situation poorly written erroneous application affect performance applications system 
order reduce search cost approaches hash tables explored 
hash tables significantly reduce time needed find matching entry significantly increase time needed insert entry list 
unfortunately increase insertion time prohibitive 
increase insertion time hash relative list especially noticeable ping pong latency test high performance networks judged 
hashing complicated need support wildcard matching maintain ordering semantics 
unfortunately mpi implementation priori knowledge wildcard values application specific approach taken 
wildcard matching appears widespread 
initial analysis applications sandia revealed large number wildcards 
mpi source source incoming message known prevalent 
mpi tag rarely occurs message tags intended differentiating specific types messages 
re coding applications eliminate source wildcards non trivial 
semantic equivalent post receive possible source cancel receives unused 
strategy inefficient processing memory resources 
propose hardware scheme network interface accelerate mpi matching 
previous explored approaches network interface hardware specifically mpi 
quadrics network general purpose processor network interface allows running user context thread process incoming messages 
approach allows protocol processing needed support mpi occur network interface 
thread implements mpi implements queues linear lists 
network interface sandia cray red storm machine implements portals programming interface provides protocol building blocks support general network functionality mpi efficiently 
portals allows incoming messages traverse linear list specific hardware accelerate matching 
significant amount previous network interface implement mpi collective operations efficiently 
similarly approaches focus protocol optimizations efficient data movement operations list traversal 
hardware acceleration explore closely associated techniques accelerate lookups internet protocol ip routers 
ip routers need efficiently solve longest prefix match lpm problem incoming packet needs routed network closely matches destination address 
wildcard values mpi network masks cover entire range addresses 
ip router incoming message generates table lookup closest matching destination ultimately resulting selection outgoing port 
mpi incoming message causes table lookup closest matching posted receive resulting selection destination buffer message 
variety software hardware approaches explored allow quickly solving lpm problem see summary appropriate mpi due need support temporal ordering semantics frequent table updates required mpi semantics 

hardware acceleration unit proposed integration hardware network interface chip nic architecture shown typical network interface send receive tx rx dma capabilities shown logically separate coupled network logical fifo interfaces provide buffering capability 
processor local sram manages transactions network various housekeeping tasks local bus 
proposed new components shown dashed lines 
accelerate posted receive queue copies header information provided associative list processing unit alpu added fifo 
separate command result fifo provided enable decoupled asynchronous interactions processor 
similarly copies new receives posted fed alpu handles unexpected messages 
details alpu shown 
hardware broken levels hierarchy individual cell block cells associative matching unit 

basic matching cell lowest level individual cells match unit 
single cell match unit posted receive queue shown 
cell contains storage set bits matched mpi matching information corresponding set mask bits wildcard bits mpi 
set match bits range pair bits fields mpi full width mask needed portals interface 
addition valid bit indicating entry valid tag prototype design supports single process extending support limited number processes straightforward 
fifo network data fifo fifo network header processor fifo fifo fifo associative list processing unit posted recv fifo fifo associative list processing unit msg fifo fifo fifo rx dma engine local sram tx dma engine high performance connection host memory 
proposed nic architecture leveraging associative list matching unit new features shown dashed lines field discretion software stored 
implementation tag value bit pointer local ram points directly matching entry 
provide matching unexpected message queue cell changed slightly shown 
storing mask bits cell mask bits inputs 
respects cells 
stored data passed cell 
compare logic factoring set mask bits indicate don care locations produces single match bit 
basic cell additional outputs feed higher level block 
single bit logical match bit valid bit invalid data produce valid match 
second tag priority logic select right match 
final output valid bit allow higher level block manage flow control 

block cells higher level group cells combined cell block 
addition set cells cell block contains registered version incoming request facilitate timing logic control flow data logic correctly prioritize tags logic generate match location 
control flow logic drives separate enable signal cell 
transfer data cell enabled scenarios match occurs new items inserted 
successful match mpi semantics require matched item deleted match location broadcast cell blocks 
cells match location enabled cells effectively deleting matched cell leaving lowest priority cell empty 
request previous cell enable match location insert mode previous block request request reg 
cell match bits tag match cell mask bits compare logic match priority logic mask request cell previous cell enable cells delete enable logic tag match 
cell tag match cell tag space available block tag match match bits compare logic match tag request fifo control fifo cell block cell block cell block cell block control logic address match tag 
cell containing single match unit posted receive queue cell containing single match unit unexpected message queue block cells associative match engine inserts cells enabled space available compact possible holes space available loosely defined 
implementation discussed space available means higher cell current block lowest cell block empty 
maximize clock frequency fpga prototype sufficient real cases 
space available easily expanded include cell higher block cell higher block timing constraints permitted 
number cells cell block restricted power simplify task prioritizing correct tag generating correct match location 
prioritization logic uses match signal select correct tag output 
highest order cell furthest right highest priority 
explanation mpi semantics require matching item list considered correct match 
associative matching struc holes occur inserts time new elements inserted 
holes occur deletion data deletion point shifted upward part delete 
priority logic cell result fifo ture list items inserted left progress right 
level prioritization higher cell pair cells selects tag matched partner tag 
match bits encoded lowest order bit match location 
second level logical highest order pair match bits forms select line mux encoded second lowest order bit match location shown 
pattern continues levels cells 
result output highest order matching tag encoded match location 
obviously structure easily collapsed larger muxes muxes improved placement regularity fpga prototype 

associative list processing unit associative list processing unit alpu chains cell blocks adds control logic interface rest network interface 
cell block outputs combined prioritized manner cell cmd ef insert match clear valid flags reset cmd ef cmd ef wait command read insert insert read command start insert cmd ef insert insert start insert cmd ef insert match fail insert match cmd ef insert command read insert insert 
controlling state machine cmd ef puts combined cell block 
effectively cell blocks combined create large virtual array cells 
modularization cell blocks simplifies timing particularly compaction logic simplifies exploration design space 
control logic highest level controls interaction rest nic 
control logic determines new data taken header input matches data written output data read control input space available alpu 
governing state machine shown 
state machine begins state 
match state alpu accepts new match time match completes 
successful failed matches output result fifo 
new command arrives command fifo empty completion current match state machine enters read command state 
point start insert commands valid reset clears valid flags returns matching state 
start insert puts device insert mode 
insert mode implies change matching behavior insert commands accepted matching continues match fails 
matches stopped temporarily insert maintain correctness processor fill command fifo quickly alpu drain inserts matches allowed continue 
successful matches output result fifo failed matches held retry 
described detail section 
insert command returns operation standard match mode 
commands discarded empty command fifo valid command causes transition back match state 

software interface referencing provides insight proposed hardware fits software architecture 
traditional nic red storm system header data separated logically physically 
processor performs list matching functions header information instructs dma 
proposed hardware header data replicated associative list processing unit 
purpose alpu quickly provide index match list match occurs 
match occur processor needs decide non matching message described processor receives copy header information 
general purpose fifos provide hardware level decoupling enable asynchronous operation 

processor interface alpu requires limited set commands see table 
pair commands start insert insert instruct alpu enter exit insert mode mode safe inserts reset clear alpu insert new items 
parameters match bits mask bits needed user defined tag 
responses expected alpu shown table 
acknowledge returned response start insert command indicates number free slots alpu match success match failure responses expected normal alpu operation 
general operation device proceeds follows 
start insert response start acknowledge occur insert performed 
inserts may performed insert match success occur time match failure occur start acknowledge insert 

list management manage mpi queues alpu microprocessor develop appropriate set heuristics 
previously shown queues grow tens hundreds items times queues quite short 
alpu incur certain amount overhead software queue adequately long 
addition software recognize inserting elements alpu requires certain overhead attempt conglomerate insertions list 
command description inputs start insert instruct alpu enter insert mode insert insert new entry alpu match bits mask bits optional tag insert instruct alpu exit insert mode reset clear entries alpu table 
associative list processing unit command set response description outputs start acknowledge alpu entered insert mode number free entries match success input matched list item tag list item matched match failure input match list item alpu automated highperformance matching processor maintain copy list 
copy list allows alpu return simple pointer list entry entire entry 
entries matched deleted alpu processor copy entry deleted 
furthermore processor may entries entered alpu 
pointer start portion list entered alpu maintained proper handling responses discussed section 

match entry insertion hardware initialized alpu empty 
matching enabled matches succeed hardware designed processor disable delivery duplicate information headers new posted receives alpu initialized 
new entries queue arrive new posted receives unexpected messages processor build appropriate queue memory 
queue length crosses threshold defined heuristics enable best performance processor sends insert command alpu 
avoid potential race condition match pipeline fails processor performing insert inserts irrevocable processor wait insert acknowledge response 
response insert command alpu enters safe state matches occur matches fail held retry inserts complete 
waiting insert acknowledge processor may receive match success table 
associative list processing unit responses match failed responses 
handled correctly described section 
insert acknowledge include field indicating processor number entries safe insert 
optimal implementation processor track number insure attempt start inserting little space available 
having received acknowledge processor perform desired number inserts quickly possible send insert command 
number inserts performed large processor may need periodically clear result fifo successful matches occur insert process prevent filling 
insert includes information matched optionally set mask bits posted receives tag 
tag value returned successful match recommended store pointer position local ram corresponding queue entry stored 

result handling alpu processor retrieve response alpu header received 
processor retrieve copy data provided retrieve response 
response success failed 
success returned tag point directly matching list item processor copy list 
failed match processor local copy data search portion list loaded alpu 
match data handled correctly 
data header match item posted receive queue inserted unexpected message queue 
data new posted receive match item unexpected message queue needs added posted receive queue 

methodology aspects research 
benchmark exposed significant problem modern network interfaces cards nics leverage embedded processors 
behavior replicated simulation environment reproduces modern system environment provides platform research potential nic improvements 
simulated nic enhanced proposed associative list processing unit alpu mpi implementation modified leverage feature 
independent hardware prototype created provide insight performance proposed design 

benchmarks primary motivation design reduce latency messages long posted receive queues long unexpected message queues 
magnitude problem revealed earlier study newly designed benchmarks 
benchmarks study impacts associative list processing unit 
benchmark designed measure impact changes pre posted receive queue length provides degrees freedom length pre posted receive queue portion pre posted receive queue traversed size message 
enables user measure impacts receive queue length impact actual queue traversal 
benchmark created assess impact unexpected message queue length message latency allows length unexpected message queue size message varied 
deviates traditional way measuring latency includes time post receive latency measuring message part latency 
better reflects way mpi applications typically number iterations post receives iteration 

simulation environment system level simulation matching structure simulator component discrete event simulation framework 
simulate cpu parameter cpu nic processor fetch issue width commit width ruu size integer units memory ports caches way way cache clock speed ghz mhz lat 
main memory ns ns isa powerpc powerpc network wire lat 
ns table 
processor simulation parameters nic processors sim simplescalar tool suite integrated framework 
components representing simple network dma engines memory controller dram chips added 
memory hierarchy modeled include contention open rows dram chips 
main processor parameterized similar modern high performance processor amd opteron 
nic processor parameterized similar processor higher network cards powerpc see table 
simple bus nic connected main processor dma engine sram matching structure 
bus simulated ns delay 
sram modeled ns delay 

mpi implementations prototype mpi implements subset mpi 
exception mpi barrier basic point point communication basic support functions implemented 
support basic mpi datatypes included mpi comm world group 
mpi implemented roughly lines compiled gnu primary data structures series linked lists contain requests state required advance 
posted receive buffers incoming messages match 
active receive requests require processing rendezvous requests send reply requests waiting dma engine gcc version apple computer build mpi comm rank mpi comm size mpi finalize mpi init mpi mpi barrier mpi mpi recv mpi send mpi wait mpi 
subset mpi implemented 
indicates functions built mpi functions 
list unexpected messages arrived 
receive match 
active unexpected messages advanced unexpected messages requiring dma transfer 
queue message send requests processing 
primary data structures reside nic memory 
processing occurs nic 
main processor required dispatch message requests nic wait request completion 
nic continually executes loop performs actions checking network new incoming messages checking new requests main processor advancing active requests updating alpu 
network polled new incoming messages 
new message detected message headers stripped compared posted receive buffers 
match receive request moved active list set dma send rendezvous reply 
match message entered matched receives 
active send requests advanced allocating network dma resources performing send 
send completed resources freed 
receive requests try match see message arrived 
match added await incoming header match 
matched perform required dma transfers informing main processor completion 
alpu requires minimal modification basic structure 
iteration nic loop updates posted receive alpu unexpected alpu 
pointer kept indicate portions transfered alpu 
portions lists added alpu nic attempt insert 
nic sends insert message drains alpu result fifo match results start acknowledge received 
attempts insert remaining headers updating pointer indicate portions queue inserted 
inserts send insert command 
new incoming messages arrive headers automatically sent alpu 
nic detects messages checks alpu output queue see matched 
relevant request removed 
match portion alpu checked 
match message headers added inserted widget 
similarly receive requests arrive unexpected alpu checked see match occurred 
widget returns match failure portion alpu checked 

fpga prototype provide reasonable estimate size operating frequency alpu prototype implementation created targeting xilinx virtex virtex pro fp gas 
alpu designed structural design tool provides fine grained control placement logic fpga 
final design parameterized allow different match tag widths different combinations total number cells number cells block 
designing unit top priorities small area high speed regularity placement 
regular placement constraint arose need create placement scheme adaptable different combinations match tag widths 
allow higher operating frequencies alpu pipelined 
pipelining design allow execution overlap final implementations process new match clock cycles depending total number cells alpu block size 
pipeline stages broken follows 
fanout global signals blocks cells block registers copy signals 

produce match match cell 

perform priority block 

perform blocks determine match 
match stage produces matched tag address highest priority cell matched 
stage cycles depending circuit parameters 

fanout delete signals 
block registers copy signals 

delete matched cell 
desired possible overlap execution stages new match data distributed blocks match deleted 
simulation results assume cycle pipelining latency overlap execution 
current pipelining scheme allows inserts happen clock cycle 

results sets experiments performed 
fpga prototype explore size performance issues design 
second experiment simulated performance nic associative list processing unit alpu posted receive queue 
final experiment alpu applied management unexpected message queue 
results experiments indicate alpu small fast provides sufficient benefits practical 

fpga prototype section details sizes speeds alpu prototypes 
prototypes list units accelerating posted receives unexpected messages created 
xilinx fpga tool chain map prototypes virtex ii pro fpga speed grade chose test units total cells block sizes 
test match width set tag width 
widths adequate support mpi implementation supporting full specification node system 
addition mask bit match bit sizes speeds prototypes tables 
size speed numbers taken reports generated xilinx tools 
sizes include number input lookup tables luts number flip flops ffs number slices speeds obtained constraining clock ns 
prototypes block sizes run higher frequencies 
alpu quite large fpga entry posted receive consume approximately fpga asic size similar commercially available ternary 
estimate move standard cell asic technology pro slowest speed grade micron process 
providing mask bit match bit increases configurability supports protocols mpi portals 
configuration worst case size speed 
slice luts ffs densely 
total block size speed cells size luts ffs slices mhz latency table 
sizes speeds posted receives alpu prototypes 
total block size speed cells size luts ffs slices mhz latency table 
sizes speeds unexpected messages alpu prototypes 
vide increase clock frequency 
means prototypes run mhz equivalent core logic speed asc red storm network interface 
implied size speed alpu asic candidate addition network interface offload engine 

latency impacts compares performance baseline nic similar nature red storm system nic enhanced entry alpu entry alpu 
left full surface shown configuration right shows projections lines graph 
graphs interesting traits 
baseline nic parts low graph shows entry traversed adding average ns latency 
comparison quadrics elan nic entry traversed adds ns latency 
performance improvement surprising nic modeled significantly faster clock dual issue integers floating point get separate kb instruction increase fpga standard cell asic extremely conservative estimate 
larger 
latency microseconds latency microseconds latency microseconds receives receives receives latency percent traversed latency microseconds receives receives receives receives receives receives latency percent traversed latency microseconds percentage queue traversed receives receives receives receives receives receives latency percent traversed latency microseconds percentage queue traversed receives receives receives receives receives receives percentage queue traversed 
growth latency standard posted receive queue growth latency entry alpu manage posted receive queue growth latency entry alpu manage posted receive queue latency microseconds unexpected messages baseline entry alpu entry alpu 
growth latency unexpected queue length data caches 
queue long fit cache average time entry traversed grows ns 
overhead shows entire list traversed 
example time traverse entire entry list time traverse entry list 
incorporating alpu yields significant advantages shown 
dramatic advantage flat latency curve portion posted receive queue traversed crosses size alpu 
penalty ns increase baseline latency posted receive queues processor incurs overhead forced interact alpu 
entries posted receive queue alpu breaks 
entirely possible mpi library optimized alpu list entries long 
second advantage provided alpu reduction usage cache 
alpu processor required traverse entries queue alpu find match 
storage required alpu relatively small entire queue entry stored 
entry alpu contains matching data processor stores pieces data queue entry 
number cache lines processor retrieve memory dramatically reduced search entries 

unexpected message impacts contrast impacts queue measurements show advantage alpu applications extremely short unexpected message queues 
short unexpected message queues alpu appears show small loss latency performance tens nanoseconds 
seen unexpected queue reaches length entries alpu begins offer clear significant advantage 
interesting phenomenon seen line cache processor nic exhausted latency rises dramatically 
mirrors behavior seen management queue alpu able delay point rapid growth latency occurs 
missing graphs real advantage alpu 
benchmark written conservatively possible attempting demonstrate limitations long unexpected queue 
time post receive allowed overlapped time transfer messages 
real life long posted receive queue created pre posting receives consecutively matches arriving 
receive take progressively longer impact application execution time directly 
case alpu offer greater benefit 

posted receive queue unexpected message queue significant bottlenecks processing mpi messages 
presents novel feature integrated network interface accelerate processing critical queues mpi 
associative list processing unit alpu prototyped fpga small fast integrated modern network interface 
assess performance impact proposed accelerator system simulator simulate baseline nic nic enhanced proposed feature 
addition alpu add minimal overhead extremely short queues 
queue length grew addition alpu demonstrated dramatic drops impacts queue length latency 
queue length grows size alpu addition alpu inexpensive way decrease pressure cache processor nic 

optimization mpi broad ongoing effort 
focus areas include techniques accelerate queue traversal techniques traverse queues quickly fewer hardware resources 
area research focus offload significant portions portals interface enable support mpi run time software alexandrov schauser 
incorporating long messages logp model 
journal parallel distributed computing 

red storm 
invited talk hot interconnects august 
underwood 
preliminary analysis mpi queue applications 
submitted may 
hudson maccabe 
portals message passing interface 
technical report sand sandia national laboratories december 
maccabe 
portals protocol building blocks low overhead communication 
proceedings workshop communication architecture clusters april 
maccabe 
design implementation performance mpi portals 
international journal high performance computing applications spring 
underwood 
analysis nic resource usage offloading mpi 
proceedings workshop communication architecture clusters santa fe nm april 
panda 
nic reduction myrinet clusters beneficial 
proceedings san workshop conjunction hpca february 
panda sadayappan 
fast barrier myrinet gm 
proceedings international parallel distributed processing symposium april 
burger austin 
simplescalar tool set version 
simplescalar llc 
culler karp patterson schauser santos von eicken 
logp realistic model parallel computation 
proceedings th acm sigplan symposium principles practice parallel programming pages 
hutchings hawkins nelson 
cad suite high performance fpga design 
pocek arnold editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
ieee computer society ieee 
martin vahdat culler anderson 
effects communication latency overhead bandwidth cluster architecture 
proceedings th annual international symposium computer architecture june 
message passing interface forum 
mpi message passing interface standard 
international journal supercomputer applications high performance computing 
moody fernandez panda 
scalable nic reduction large scale clusters 
proceedings acm ieee sc conference november 
myrinet express mx high performance low level message passing interface myrinet july 
chun feng coll 
quadrics network high performance clustering technology 
ieee micro january february 
plattner varghese turner waldvogel 
scalable high speed prefix matching february 
rodrigues 
discrete event simulation framework 
technical report tr university notre dame 
wyckoff panda 
emp zero copy nic driven gigabit ethernet message passing 
proceedings conference supercomputing nov 
underwood 
impact mpi queue usage message latency 
proceedings international conference parallel processing icpp montreal canada august 
