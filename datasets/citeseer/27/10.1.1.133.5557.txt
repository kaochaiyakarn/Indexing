fast stage algorithm computing pagerank extensions chris pan chi lee stanford university stanford edu fast stage algorithm computing pagerank vector :10.1.1.31.1768:10.1.1.31.1768
algorithm exploits observation homogeneous discrete time markov chain associated pagerank subset nodes dangling nodes 
time convergence fraction required standard algorithm employed google :10.1.1.31.1768:10.1.1.31.1768
data webpages convergence achieved time 
algorithm replaces common practice general incorrect 
practice ignoring dangling nodes stages computation necessarily accelerate convergence :10.1.1.31.1768:10.1.1.31.1768:10.1.1.31.1768
comparison algorithm provable generally applicable achieves desired speedup 
ends discussion possible extensions generalize divide conquer theme 
describe variations incorporate multi stage algorithm 
variation ordinary pagerank vector computed 
second variation algorithm computes generalized version pagerank webpages divided classes incorporating different personalization vector 
represents major modeling extension introduces greater flexibility potentially refined model web traffic 
keywords pagerank link analysis dangling nodes power method eigenvector computation limiting distribution statespace reduction state aggregation markov chains 
aside commercial success pagerank approach ranking webpages generated significant interest research community 
markov chain interpretation gives explicit model surfer behavior web traffic computation poses numerically daunting challenge 
billions webpages existence computing pagerank vector time consuming procedure takes days 
webpages constantly updated added removed pagerank vector needs re computed main scientific computing computational mathematics program department computer science division operations information technology graduate school business gene golub stanford university golub stanford edu zenios stanford university stanford edu tain timeliness relevance 
web search personalized multiple pagerank vectors need computed reflect varying preferences surfers :10.1.1.160.9478
clearly demand high fast algorithms 
pagerank vector regarded limiting distribution homogeneous discrete time markov chain transitions webpage webpage 
fast algorithm computing vector 
algorithm exploits markov chain proceeds stages 
stage compute limiting distribution chain dangling nodes combined super node second stage compute limiting distribution chain nodes combined :10.1.1.31.1768:10.1.1.31.1768:10.1.1.31.1768
terms node state page interchangeably 
limiting distributions concatenated recover limiting distribution original chain pagerank vector 
shall see approach dramatically reduce computing time conceptually elegant 
number papers discuss acceleration pagerank computation numerical linear algebra techniques 
gauss seidel algorithm discussed component values pagerank vector computation 
periodically subtracts away approximation subdominant eigenvectors accelerate convergence 
noted sorted url google matrix block structure pagerank vector computed separately block results pasted yield starting iterate entire matrix 
components pagerank vector converge different rates observes skipping components converged computation time shortened 
contributes growing literature number ways 
adopting characteristically markov chain view able achieve performance gains utilizing powerful techniques statespace reduction cf 

stage algorithm stage distinctly different reduction technique 
stage states combined lumping second stage combining aggregation 
reduction aggressive performance gains significant 
second approach analyzable 
previous methods rely intuitive approximate arguments procedure analyzed great precision leading concrete results 
addition show common practice ignoring dangling nodes stages computation cf 
necessarily accelerate convergence replaced algorithm :10.1.1.31.1768
lastly algorithm simultaneously applied acceleration methods achieve greater speedup 
discuss possible multi stage generalization 
variations 
variation standard pagerank vector computed multi stage algorithm 
second variation introduce modeling extension personalization vector replaced collection personalized class vectors 
vectors incorporated transition probability matrix 
transition probabilities markov chain components component induced link structure component induced webpage class 
class division general may association criteria host topic language 
incorporation classes permits greater granularity modeling potentially refine pagerank model web traffic 
multistage algorithm applied generalized model pagerank vector computed moderate increase overhead relative standard model number classes overwhelming fewer 
knowledge proposal kind 
notation notation follows 
vector denotes th element matrix denotes element th row th column denotes elements rows columns denotes entire th row 
subscripts may different meanings depending context meaning clear 
un transposed vector column vector transpose superscripted sum absolute values vector 
example 
notation en means dimensional vector 
pagerank review idea pagerank regard web surfing markov chain 
imagine collection webpages indexed suppose personalization vector signifies generic surfer preference page 
specifically personalization vector assumed componentwise positive normalized 
generic surfer currently page assume time step surfer move probability nl outlink 
definition nice interpretation 
th page outlinks surfer move equal probability outlinks exist surfer move page probabilities preference 
page outlink called dangling page 
time step assume surfer transitions page page 
gives rise homogeneous discrete time markov chain 
simply transition probability matrix markov chain 
denote probability distribution surfer initial time step distribution th time step idea pagerank importance conferred webpages defined limiting probability associated 
limiting distribution interpreted proportion time surfer spends webpage 
unfortunately definition far guarantees convergence 
resolve consider closely related markov chain slightly shifted cq 
en simply matrix row constant closely approximates close 
typical value 
shown controls convergence rate pagerank algorithm 
positive matrix row sums 
markov chain associated irreducible aperiodic positivity ensures direct positive probability path pages cf 
pp 

perron frobenius theorem power method cf 
pp 
pp 
guarantee existence unique limiting distribution regardless initial distribution 
pagerank vector defined limiting distribution 
known google matrix 
sd denote subset containing dangling nodes snd sd subset containing nodes 
nl ut snd sd 
rows correspond dangling nodes identically rows correspond non dangling nodes separable components 
component consists contribution actual outlinks second component give standard algorithm computing pagerank vector :10.1.1.31.1768:10.1.1.31.1768
algorithm proceeds arbitrary vector multiplying repeatedly convergence 
implementation power method takes advantage sparseness algorithm pagerank 
form nl snd sd 
select cx du notice completely dense enumerated 
matrix formed 
comprised contribution extremely sparse 
webpages handful outlinks zeros 
multiplication step implemented efficiently 
contribution subsequently added back du step 
approach iteration loop performed operations 
comparison explicitly enumerated iteration require operations prohibitive year number webpages order 
see 
emphasize feasibility pagerank algorithm rests critically separating sparse matrix plus dense vector multiplication done separately components added subsequently 

markov chain algorithm improves algorithm markov chain associated cf 

general markov chain transition probabilities satisfy properties allow disjoint subsets states combined blocks super nodes 
block level transitions yield markov chain transition probabilities easily calculated 
conventional state aggregation cf 
lumping doesn require prior computation aggregation weights effective reducing dimensionality statespace 
definition 
suppose transition probability matrix homogeneous discrete time markov chain states 
sp disjoint subsets states sl 
markov chain said respect partition sp sl sm right hand side constant depends transition probability matrix lumped chain 
think sp block nodes requires node block depart block identical probability 
high degree symmetry block 
lumping markov chain exploit symmetry discarding block details focusing block transitions 
great reduction achieved claim markov chain associated pagerank respect partition dangling nodes lumped block non dangling node singleton block 
proposition 
snd define sk 
homogeneous discrete time markov chain associated respect partition consisted sk snd sd 
proof 
construction true snd 
addition sd sm snd 
see 
states original chain 
lumped markov chain irreducible aperiodic transition probability matrix necessarily positive 
perron frobenius theorem power method guarantee existence unique limiting distribution 
limiting distribution vector card snd components card snd components identical components corresponding snd remaining component equals sum components corresponding sd 
benefit lumping typically card sd times larger card snd 
crawl stanford webbase project contains pages total :10.1.1.24.8162
non dangling 
lumping reduce dimensionality transition probability matrix enables dramatic speedup computing limiting distribution 
done limiting probabilities dangling nodes sd computed little effort 
construct second markov chain non dangling nodes combined block dangling node singleton block total card sd states 
lumping particular partition 
states combined traditional state aggregation 

stage algorithm propose algorithm outlined follows 
construct transition probability matrix chain dangling nodes lumped block 
see proposition 

compute limiting distribution gives snd 
computation iterative similar algorithm 
step constitutes bulk total 

compute aggregation weights snd results step 
nd 
construct transition probability matrix chain non dangling nodes aggregated block weights computed step 
compute limiting distribution yields sd 
amount involved negligible compared step ll show 

concatenate results step step get gives limiting distribution pagerank vector 
follows detail efficient implementation steps discuss performance issues 
discussion divided stages 
stage amounts constructing solving lumped chain steps stage performs remaining steps focuses aggregated chain 
simplify notation ll assume loss generality snd sd 
parti tioned accordingly lumping dangling nodes block obtain markov chain just card snd states compared card snd card sd blocks respectively en ku en ku 
rows columns associated non dangling nodes rows columns associated dangling nodes 
likewise partition personalization vector note follows 
formalizing stage proposition transition probability matrix lumped chain en ken 
matrix 
matrix positive row sums 
recall critical step standard pagerank algorithm separate sparse matrix dense vector 
multiplication done parts separately subsequently added 
brought number operations quadratic linear 
need 
arbitrary componentwise non negative vector unit norm cx cx ek ek uk kek 
extremely sparse multiplication requires operations 
representation formalize algorithm stage algorithm stage 
form select cx cx stage converges limiting distribution yields components pagerank vector 
formalizing stage denote aggregation weights 
weights construct transition probability matrix aggregating non dangling nodes ek 
en en ku matrix 
row matrix sums 
aggregation weights positive cf 
perron frobenius theorem positive 
markov chain associated irreducible aperiodic unique limiting distribution 
addition rank matrix rows starting second identical 
properties allows compute limiting distribution little storage 
split sparse dense parts 
arbitrary non negative vector unit norm cx cx kx pn en 
multiplication implemented just summing vectors extremely efficient 
representation formalize algorithm stage algorithm stage 
suppose computed aggregation weights 
form select cx cx perform aitken extrapolation contrary stage stage requires iterations 
iterations convergence occurred aitken extrapolation performed extract limiting distribution 
case limiting distribution available just iterations guaranteed 
related matrix rank 
ll supply proof 
algorithm extremely efficient 
shown entirety stage amounts iteration stage 
take iterations converge negligible 
furthermore storage requirement mild 
rank vectors stored 

convergence analysis address issues section 
analyze performance standard pagerank algorithm comparison focuses strictly stage stage comparatively negligible 
supply proof validates stage 
convergence stage show stage converge fewer iterations standard algorithm 
lemma 

define identity matrix 
con en sider sequences iterates 

en proof 
suppose claim true 
en en en claim hold 
induction completes proof 
proposition 
defined lemma 

proof 
lemma 
nx nx nx shows standard pagerank algorithm applied starting iterate related iterate constructed stage converges fewer iterations respect tolerance 
addition virtues working matrices vectors smaller fewer nonzeros iteration stage requires significantly roughly opposed 
shown amount entire stage algorithm roughly required standard algo rithm 
difference dramatic typically fraction lastly stage algorithm explicitly enumerates entire transition probability matrix small part stage 
consequently systems insufficient memory store entire transition probability matrix advantage stage algorithm pronounced disk access avoided 
practice memory limited 
example modest dataset pages requires gb comparison addressable memory bit machine confined gb 
convergence stage prove algorithm stage computes unique limiting distribution shown limiting distribution fact left eigenvector associated suffices prove algorithm computes eigenvector 
lemma 
simplify notation denote 


dominant eigenvalue algebraic geometric multiplicity 
eigenvalue geometric multiplicity 

distinct eigenvalue words sequence converged exactly left eigenvector associated eigenvalue null vector 
proof 
positive rank rows sum 
perron frobenius theorem cf 
pp 
pp 
establishes claim 
suppose third distinct eigenvalue 
algebraic multiplicity necessarily 
jordan canonical form establishes second claim 
see pp 
pp 

proposition 

exists eigenvalue 
addition constants 
proof 
part follows directly lemma 
examination geometric multiplicities reveals existence full set eigenvectors span writing combination eigenvectors establishes second part 
proposition rephrased follows 
consider arbitrary vector repeatedly multiplied exact convergence occurs iterations doesn subsequent iterates contained span sector eigenvectors 
enables extract eigenvector limiting distribution subtracting away component second eigenvector aitken extrapolation 
log norm error log error iteration standard stage iteration log error iteration 

numerical experiment preceding analyses stage algorithm ought take fraction time converge 
demonstrate numerical experiment 
results subset webpages sampled crawl stanford webbase project 
number dangling nodes roughly 
experiment conducted ghz dual xeon workstation gb ram gb raid hard disk system 
amount memory ample dataset complications disk access results 
table summarizes dimensionality number non zero elements dims nnz values tried 
fast converging example slow converging example 
tolerance set value total time stage algorithm just standard pagerank algorithm time sec 
iterations step step step step step total standard case stage steps constituted bulk total time 
error stage iteration consistently lower gap eventually diminished 
cases algorithms terminated number iterations predicted proposition 
see 
amount time needed stage steps negligible comparison 
results stages concatenated obtained entire pagerank vector 
norm difference vector produced standard algorithm 
log norm error log error iterations standard stage iteration blow iterations 
treatment dangling nodes practice webpage considered dangling outlinks outlinks unknown 
arise webpage referenced linked webpage crawl crawled 
typical scenario vast rapidly changing web complete crawl impossible :10.1.1.31.1768:10.1.1.31.1768
treatment dangling nodes philosophical issue 
times left computation completely 
amounts computing limiting distribution just defining pagerank vector 
conversely accounted inserting personalization vector 
see 
adopted model number reasons shown effective way managing dangling nodes 
computation time proportional number non dangling nodes 
usually large number dangling nodes ignore discard enormous amount information 
majority pages turns crawl dangling 
ignoring dangling nodes means ranked 
second information lost consisted legitimate links substantial probability mass important classes webpages urls design dangling including pdfs images movies inserting personalization vector place dangling nodes intuitive sensible modeling perspective 
simply says outlinks move page preference 
directly entering url 
realistic 
incorporating dangling nodes way recognize markov chain model pagerank effectively hybrid model structure links behavior surfer preferences 
common practice include dangling nodes model ignore completely final stages computation 
limiting distribution computed padded additional elements initial vector suggested believed accelerates convergence :10.1.1.31.1768:10.1.1.31.1768
approach great intuitive appeal accelerates convergence particular cases 
experimentation method accelerate convergence personalization vector uniform fail vector biased 
shown general limiting distribution may bear relations 
see appendix 
theory complementation shows components limiting distribution normalized coincide limiting distribution matrix known stochastic complement 
nearly completely decomposable matrix diagonal blocks contain negligible probability mass close method 
general nearly completely decomposable respect partition 
significant probability mass block 
algorithm described renders common practice relevant 
roughly amount solving entire pagerank vector obtained 
importantly algorithm generally applicable 
unaffected biased personalization vector example 
claim superior model incorporate dangling nodes sense producing better rankings 
question open 
stated compelling reasons incorporating dangling nodes 
insofar model adopted algorithm replaces common practice 

extensions algorithm takes principally markov chain view 
true terms methods reduction lumping aggregation techniques solving reduced problems limiting distributions 
derivation non markov chain parallel stresses algebraic structure probabilistic interpretation 
example reduction lumping alternative form derived means neumann expansion 
re indebted amy langville north carolina state university pointing 
resulting form superficially different computationally equivalent 
differences variations merely stylistic 
markov chain interpretation great intuitive appeal 
possible directions extension obvious 
high level stage algorithm viewed sequentially alternating parts statespace 
time focus part state level details remaining part obscured collapsing states block 
conceivably divide conquer theme recursively applied yield multi stage algorithm 
mention variations theme 
outline possibilities leave substantiate claims 
multi stage extension give stage example computing pagerank vector 
consider nodes dangling point dangling nodes 
moment refer weakly dangling 
node dangling weakly dangling 
suppose nodes belong category 
symmetric permutations form analogous nodes moved top part matrix ek weakly dangling nodes occupy rows bottom 
denote subsets nodes respectively 
entire statespace divided disjoint subsets sd dangling weakly dangling 
stage algorithm successively collapses pairs subsets compute pagerank vector 
invoking condition manner slightly modified proposition consider markov chain sd lumped block 
gives rise transition probability matrix 
limiting distribution computed iterative procedure akin gorithm 
convergence obtained 
stage 
stage consider second markov chain lump sd block aggregating yield single block 
resulting matrix rank 
virtually cost free procedure akin algorithm compute limiting distribution 
snd 
stage problem looks identical second stage original stage algorithm 
algorithm compute remaining components 
stage algorithm may substantially improve stage variant smaller note permutations loss generality 
practice permutations costly depending sparse storage scheme need explicitly performed 
need identify subsets nodes 
requires 
analysis needed ascertain conditions speedup outweighs cost 
differentiating webpages class traditionally personalization vector associated customization surfer preferences 
multi stage extension algorithm enable customization respect classes webpages moderate increase computational overhead number classes large 
invoking markov chain interpretation row amounts transition probabilities corresponding page 
rows simply collection conditional distributions parameterized page index 
analogously personalization vector replaced collection vectors representing conditional distribution corresponding webpage class 
vectors ll refer personalized class vectors conditional distributions parameterized webpage class index presumably ordinary pagerank regarded special case 
represents major modeling extension usefulness self evident 
natural ways form associations webpages 
possible associations domain host topic language file type blog versus non blog 
reality webpages belonging class similar conditional distribution approximating class single vector justified 
example association language 
webpages belonging language class traffic 
consequently parameterization class vectors language may high weight traffic low weight transitions remotely related languages 
compound classes enumerated combinations elementary classes conceivable 
introducing class dependent component transition probabilities pagerank model web traffic potentially refined 
transition probabilities link induced component class induced content related component 
emphasize personalized incorporates surfer preferences 
modeling aspects topic explore 
discuss efficient algorithm computing pagerank vector generalized model 
generic model classes stage algorithm 
suppose webpages divided classes denote 
cm 
vector rhs replaced class dependent vector 
permuted form rank portion lower part matrix rank 
denote dangling nodes belonging class cm sd 
stage lump cm sd single block 
resulting matrix compute limiting distribution implementation power method 
differs algorithm power step replaced sparse matrix vector multiplication plus vector addi tions 
convergence obtain snd cm 
th stage markov chain cm sd lumped block 
resulting blocks aggregated snd form single block 
states cn sd collapsed 
obtain card cn sd card cn sd matrix rank 
limiting distribution efficiently computed procedure similar algorithm 
yields cn sd 
entire pagerank vector available stages 
practice stages re collapsed probabilities stages nearly additional elements need computed constructing matrices 
exploiting rank property limiting distribution obtained handful vector operations 
stages minimal 
grow number classes 
example dangling nodes divide evenly number classes stage requires operations 

comes primarily stage 
small stage dominated sparse matrix vector multiplication 
comparable algorithm 
increases burden tilts vector additions eventually overwhelming greater magnitude sparse matrix density 

concluding remarks fast stage algorithm computing pagerank vector 
stage focus markov chain dangling nodes lumped block stage chain non dangling nodes aggregated 
limiting distributions give pagerank vector 
bulk computing lumped chain total proportional number non nodes 
numerical experiment showed practice stage algorithm finish fraction time normally required case little 
furthermore part transition probability matrix enumerated time memory requirement accordingly mild 
machines memory limited relative size problem practice true performance gap wider 
examined common practice ignoring dangling nodes stages computation 
expected accelerate convergence general 
hand algorithm described provable generally applicable achieves desired speedup 
markov chain view stage algorithm strong divide conquer theme clearly extended 
gave variations multi stage generalization 
variation showed standard pagerank vector may computed multi stage algorithm 
second variation applied multi stage algorithm generalized version pagerank model personalization vector replaced collection personalized class vectors 
class vector represents contribution webpage probability arising association underlying class webpages 
resulting model allows greater flexibility defining accounting transition probabilities 
multi stage algorithm pagerank vector computed moderate increase overhead provided number classes overwhelming 

acknowledgments authors hector garcia molina andreas paepcke sriram raghavan gary wesley stanford webbase project assisting access data kamvar wang lam amy langville sebastiano vigna helpful comments 

additional authors additional author stephanie leung computer science department stanford university 
email stanford edu 

arasu novak tomkins tomlin 
pagerank computation structure web experiments algorithms 
proceedings eleventh international world wide web conference poster track 
berman plemmons 
nonnegative matrices mathematical sciences 
siam press pennsylvania 
cao stewart 
iterative aggregation disaggregation techniques nearly uncoupled markov chains 
journal association computing machinery pages 
stewart 
quasi lower bounding coupling matrices nearly completely decomposable markov chains 
siam journal matrix analysis applications vol 
pages 
golub loan 
matrix computation 
john hopkins university press 
third edition 
haveliwala kamvar 
second eigenvalue google matrix 
technical report stanford university 
hirai raghavan garcia molina paepcke :10.1.1.24.8162
webbase repository web pages 
proceedings ninth international world wide web conference 
horn johnson 
matrix analysis 
cambridge university press cambridge 
jeh widom :10.1.1.160.9478
scaling personalized web search 
proceedings twelfth international world wide web conference 
kamvar haveliwala golub 
adaptive methods computation pagerank 
technical report stanford university 
kamvar haveliwala manning golub 
exploiting block structure web computing pagerank 
technical report stanford university 
kamvar haveliwala manning golub 
extrapolation methods accelerating pagerank computations 
proceedings twelfth international world wide web conference 
kemeny snell 
finite markov chains 
van new york 
meyer 
stochastic complementation uncoupling markov chains theory nearly reducible systems 
siam review vol 
pages 
moler 
world largest matrix computation 
matlab news notes pages october 
page brin motwani winograd :10.1.1.31.1768
pagerank citation ranking bringing order web 
technical report stanford digital library technologies project 
simon ando 
aggregation variables dynamic systems 
econometrica pages 
appendix small counter example 
demonstrates common practice including dangling nodes stages computation doesn accelerate convergence 
take link matrix 
take verified limiting distribution leading submatrix entire matrix 
bottom line limiting distribution yields worse starting iterate uniform vector desired acceleration observed 
details see 

