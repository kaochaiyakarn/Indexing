theory comput 
systems theory computing systems springer verlag new york experimental analysis parallel sorting algorithms blelloch leiserson maggs plaxton smith zagha carnegie mellon university pittsburgh pa usa mit cambridge ma usa university texas austin tx usa pilot software cambridge ma usa silicon graphics mountain view ca usa 
developed methodology predicting performance parallel algorithms real parallel machines 
methodology consists steps 
characterize machine enumerating primitive operations capable performing cost operation 
analyze algorithm making precise count number times algorithm performs type operation 
methodology evaluate parallel sorting algorithms proposed literature 
selected promising bitonic sort parallel radix sort sample sort similar reif valiant implemented connection machine model cm 
analyzes algorithms detail discusses issues led particular implementations 
cm predicted performance algorithms closely matches observed performance methodology tune algorithms optimal performance 
programs designed cm merits algorithms apply parallel machines 
research supported part thinking machines part defense advanced research projects agency contracts 
cm connection machine cm lisp paris trademarks thinking machines 
blelloch 
sorting arguably studied problem computer science substep applications simple combinatorial problem interesting diverse solutions 
sorting important benchmark parallel supercomputers 
requires significant communication bandwidth processors supercomputer benchmarks efficient sorting algorithms communicate data irregular patterns 
parallel algorithms sorting studied 
early advance parallel sorting came discovered elegant bitonic sorting network sorts keys depth lg lg 
lg denotes log 
certain families fixed interconnection networks hypercube shuffle exchange bitonic sorting technique provides parallel algorithm sorting numbers lg time processors 
question existence lg depth sorting network remained open ajtai koml szemer di provided optimal lg depth sorting network unfortunately construction leads larger networks bitonic sort practical values leighton shown lg depth family sorting networks sort numbers lg time node fixed connection network domain 
surprisingly optimal lg time node fixed connection sorting networks implied aks construction impractical 
reif valiant proposed practical lg time randomized algorithm sorting called 
parallel sorting algorithms proposed literature including parallel versions radix sort quicksort variant quicksort called column sort sahni sort parallel merge sort 
reports findings project undertaken thinking machines develop fast sorting algorithm connection machine supercomputer model cm 
primary goals project 
implement fast sorting algorithm possible integers floating pont numbers cm 

generate library sort cm concerned memory stability performance wide range problem key sizes addition running time 

gain insight practical sorting algorithms general 
step achieving goals analyze evaluate parallel sorting algorithms proposed literature 
analyzing algorithms selected promising alternatives implementation bitonic sort radix sort sample sort 
compares running times algorithms versions radix sort shown 
typically number keys larger number processors apparent number keys processor large sample sort fastest sorting algorithm 
hand radix sort performs reasonably entire range deterministic simpler code stable faster small keys 
experimental analysis parallel sorting algorithms fig 

actual running times sorting bit keys connection machine cm 
running times divided number keys processor permit extrapolation machines different numbers processors 
term processor bit wide called sprint node cm 
determine total running time sort involving keys multiply time key processor bitonic sort slowest sorts large space efficient algorithms represents fastest alternative small 
various pragmatic issues radix sort selected library sort fortran available cm 
modeled running times sorts equations problem size number processors set machine parameters time point topoint communication hypercube communication scans local operations 
equations serve purposes 
easy analyze time spent various parts algorithms 
example ratio computation communication algorithm quickly determined affected problem machine size seen 
second easy generate estimates running times variations algorithms having implement 
third determined various improvements architecture improve running times algorithms 
example equations easy determine effect doubling performance message routing 
fourth case radix sort able equations analytically determine best radix size function problem size 
equations allow reasonable estimates running times algorithms machines 
example radix sort implemented analyzed cray mp thinking machines cm differs significantly cm 
cases appropriate values machine parameters equations accurately predicted running times 
similar equations stricker analyze running time bitonic sort hightower analyze running time maspar mp 
remainder studies implementations bitonic sort radix sort sample sort 
case describes analyzes basic algorithm blelloch enhancements minor modifications introduced optimize performance 
describing primitive operations algorithms section sections studies bitonic sort radix sort sample sort respectively 
section compare relative performance sorts terms running time respect criteria stability space 
appendix presents brief analysis algorithms considered implementation 
appendix presents probabilistic analysis sampling procedure sample sort algorithm 

primitive operations section describes set primitive parallel operations implement parallel sorting algorithm 
operations parallel computer possible exception cube swap operation applies hypercube machines 
algorithms described terms operations 
costs operations cm analysis applied machines substituting appropriate costs 
classes operations arithmetic local arithmetic logical operation processor 
included global operations involving front machine processors broadcasting word front processors 
cube swap processor sends receives message dimensions hypercube 
send processor sends message processor routing network 
types sends single destination send send queue 
single destination send radix sort messages sent particular address particular processor messages may destination 
send queue sample sort messages sent particular processor placed queue order received 
scan parallel prefix suffix computation integers processor 
scans operate vector input values associative binary operator integer addition 
operator employed algorithms addition 
output scan returns vector position sum operator input values lesser positions 
example plus scan integer addition operator vector yields result scan 
describe algorithms english precision required parallel vector pseudocode 
generally assume variable refers number keys sorted number processors machine 
experimental analysis parallel sorting algorithms parallel vector pseudocode assume data stored kinds variables element vectors scalars 
vectors identified capitalized variable names scalar variable names 
parallel arithmetic operations vectors performed elementwise fashion 
special vector self refers vector coordinate indices self 
cube swaps dimension hypercube performed vector operation cube swap returns vector ith coordinate ifthe jth bit binary ifthe jth bit 
cube swaps dimensions simultaneously described english 
single destination send accomplished operation send dest returns vector ith coordinate dest scan operations performed procedure scan returns plus scan vector 

primitive operations cm cm single instruction multiple data simd computer 
full configuration viewed sprint nodes configured dimensional hypercube 
dimensional hypercube network nodes node bit label nodes neighbors labels differ precisely bit position 
sprint nodes capability dimensions hypercube time 
sprint nodes controlled front processor typically sun vax 
illustrates organization sprint node consists chips processor chips containing bit processors bit bidirectional wire neighboring nodes hypercube hardware routing support 
dram chips containing total bytes bytes error corrected memory depending configuration 
machines contain bytes memory node 
floating point chip fpu capable bit bit floating point arithmetic bit integer arithmetic 
fig 

organization cm sprint node 
blelloch table 
time required operations connection machine cm 
operation symbolic time actual time arithmetic cube swap send routing scan parallel prefix value number processors sprint nodes total number elements operated 
operations bit words scans bit words 
times microseconds 
sprint chip serves interface memory floatingpoint chip 
sprint chip contains bit registers capability convert data bit serial format bit processors bit word format floating point chip 
view sprint node single processor considering bit processors fully configured cm separate processors 
point view easier extrapolate results cm hypercube machines typically bit processors 
furthermore closer way viewed machine implementing sorting algorithms 
programs cm written connection machine assembly language paris high level microcode 
table gives estimated running times classes primitives cm 
assume processors contains elements total elements 
times bit data scans operate bit data 
respect operation times generally simplified expressions ignoring fixed overheads small concentrating throughput 
scans fixed overhead substantial included explicitly 
simplifications analyses accurately model performance number elements processor small 
large accurate approximately 
data cm originates bit processors typically 
practical matter sorting applications involve larger 
discuss somewhat detail time estimates classes operations 
time arithmetic operations nominally chosen microsecond 
example cost summing integer values including costs loading storing data local memory incrementing counter assuming operation loop 
indirect access different processors access potentially different memory locations requires time 
computing maximum minimum values require time operations involve compare followed conditional memory move 
coefficients obtained empirically 
radix sort sample sort instrumented code calls real time clock provides accurate deterministic experimental analysis parallel sorting algorithms timings 
constant coefficient reported bitonic merge determined fitting curve timing data 
cm time cube swapping processor sends message just dimension hypercube messages dimensions hypercube 
exploit communication bandwidth provided hypercube fully desirable course dimensions simultaneously 
time send routing messages randomly message equally go processor 
time types sends single destination send queue approximately long send queue number messages received processor approximately balanced 
variation time send occurs routing patterns take longer 
long congestion receiving processor known pattern takes longer 
processor receiving approximately number messages congestion avoided injecting messages router pseudorandom order 
cm supports combining sends 
consider cost single scan operation cm number elements processor large 
case running time fixed overhead safely ignored 
case multiple independent scans element processor fixed overhead taken consideration 
operations cube swap send fixed overheads negligible comparison 

bitonic sort bitonic sort parallel merge sort efficient technique merging called bitonic sequences 
bitonic sequence increases monotonically decreases monotonically circularly shifted 
earliest sorts bitonic sort considered practical parallel sorting algorithm years 
theoretical running time sort lg constant hidden small 
bitonic sort simple fixed communication pattern maps directly edges hypercube general routing primitive need invoked bitonic sort implemented hypercube 
section discuss implementation bitonic sort 
basic algorithm runs efficiently hypercube architecture uses dimension hypercube wires time 
cm hypercube capability pipelining algorithm possible efficient hypercube wires 
optimization results fold speedup communication fold speedup total running time algorithm 
optimization algorithms implemented outperform bitonic sort number keys processor large 
small bitonic sort fastest uses considerably space 
illustrates bitonic sort algorithm 
key step operation called bitonic merge 
inputs operation pair sequences sorted opposite directions ascending order descending order blelloch fig 

illustration bitonic sort procedure 
arrow represents sequence keys sorted direction arrow 
unsorted input sequence keys shown top sorted output sequence shown bottom 
bitonic merge operation shaded 
dth step algorithm lg merges performed producing sorted sequence length sorted sequences length form bitonic sequence 
bitonic merge takes bitonic sequence forms single sorted sequence 
fact bitonic merge form sorted sequence bitonic sequence 
moment assume input keys sorted processors key 
integer lg algorithm performs merges merge produces sorted sequence length sorted sequences length key step bitonic sort merge operation described pseudocode bitonic merge key downto opposite cube swap key self self key min key opposite key max key opposite line operator denotes exclusive function expression self means jth bit integer representing position key input vector 
self significant bit 
self determines keys sorted increasing decreasing order 
operation algorithm understood help shows sorted sequences single bitonic sequence merged single ascending sequence 
vertical line represents processor hypercube initially contains input keys 
time moves downward diagram sorted input sequences top final single sorted sequence bottom 
single step algorithm keys communicated experimental analysis parallel sorting algorithms fig 

viewing bitonic merge procedure hypercube algorithm 
vertical line represents hypercube processor 
horizontal line segment represents communication keys hypercube wire processors 
single dimension hypercube 
keys communicated dimensions hypercube hypercube processors contain output sorted ascending order 
iteration loop bitonic merge represented collection horizontal line segments shaded region 
horizontal line segment represents communication keys processors hypercube wire corresponds cube swap line 
algorithm self tells producing ascending descending order self tells processor left right side wire 
example sorting ascending order self pair keys swapped smaller replaces key processor left larger kept right 
prove correctness known algorithm interested reader referred 
point assumed number input keys equal number processors 
practice important sorting algorithm able cope unequal values happens best hypercube algorithms date substantially different techniques cases project focuses entirely development sorting algorithms frequently occurring case handle multiple keys processor view key address composed processor address high order bits corresponding physical hypercube dimensions index processor low order bits corresponding virtual hypercube dimensions 
bitonic merge communication occurs successive dimensions descending order 
physical dimension communication realized set cube swaps 
processing physical dimensions remains performed amounts bitonic merge processor 
keys blelloch processors cm time bitonic merge lg lg lg coefficient determined empirically fitting data 
lg bitonic merges occur entirely processors coefficient 
bitonic sort algorithm calls bitonic merge subroutine dimension 
bitonic sort key lg bitonic merge key time taken algorithm lg lg lg lg lg lg lg 
examine formula closely 
times table indicate times larger lg times larger lg enormous volumes data 
term corresponding communication time dominates arithmetic time practical values problem naive implementation single port algorithm communication occurs dimension hypercube time 
dimensions virtually time improve algorithm performance significantly 
idea version bitonic merge pipelines keys dimensions hypercube 
version call form bitonic merge key implemented follows 
step processors cube swap keys dimension second step cube swap keys dimension simultaneously cube swapping second keys dimension continuing pipelining manner total number steps move keys lg physical dimensions lg 
algorithm essentially equivalent pipelined bitonic merge butterfly network 
pipelining improves time bitonic merging lg merge lg lg 
summing time entire bitonic sort bitonic lg lg lg lg lg lg lg 
experimental analysis parallel sorting algorithms fig 

bitonic sorting bit keys cm 
predicted single port communication approximately times predicted communication time 
measured performance bitonic sort closely matches predicted performance contains fixed overhead 
compare formula single port result 
running times differ constant factor 
lg coefficient lg times smaller case 
total communication time considerably reduced pipelining large 
number arithmetic operations affected pipelining 
shows communication computation components running time single port versions bitonic sort 
times generated 
computation component equivalent algorithms 
shows predicted total time single port bitonic measured performance implementation algorithm 
difference predicted measured times small values due fact equations ignore constant overhead 
difference high due overhead implementation caused additional memory moves effectively increasing cost cube swap 
overhead eliminated improved implementation resulting algorithm competitive sample sort large values bitonic sort improved linear time serial merge bitonic merge order execute merges occur entirely blelloch processor 
estimated time processor merge sorted sequences length form single sorted sequence length approximately 
constant large indirect addressing required implementation 
case time merge lg merge lg lg 
variation yields final running time bitonic lg lg lg lgp lg 
large formula reduces term factor relative 
improvement yield algorithm close performance sample sort decided implement 
furthermore local merges executed place algorithm lose major advantages longer require fixed amount additional memory 

radix sort second algorithm implemented parallel version counting radix sort section 
contrast bitonic sort radix sort comparison sort comparisons determine relative ordering keys 
relies representation keys bit integers 
floating point numbers sorted radix sort 
simple bit manipulations floating point keys converted integer keys ordering key size 
example ieee double precision floating point numbers sorted inverting mantissa exponent bits sign bit inverting sign bit 
keys sorted integers 
optimized version radix sort quite fast simplest code sorting algorithms implemented 
basic radix sort algorithm serial parallel examines keys sorted bits time starting significant block bits key 
time loop sorts keys bit block currently considered key 
fundamental importance intermediate radix sort stable output ordering preserve input order keys bit blocks equal values 
common implementation intermediate radix sort counting sort 
count determine rank key position output order permute keys respective locations 
pseudocode describes implementation radix sort key rank counting rank key key send key rank experimental analysis parallel sorting algorithms algorithm requires passes total time parallel sort time taken counting rank 
interesting part radix sort subroutine computing ranks called line 
consider simple algorithm underlying original connection machine library sort programmed years ago 
implementation counting rank vector block holds bit values sorting 
simple counting rank block offset flag block flag index scan flag flag rank offset index offset offset sum flag return rank pseudocode statement executes body processors condition evaluates true 
simple counting rank procedure operates follows 
consider ith key assume block rank ith key number offset keys block plus number index keys block 
offset value offset kth iteration loop 
code iterates possible values taken bit block sorting 
value algorithm uses scan generate vector index updates value offset reflect total number keys block value equal compute running time simple counting rank refer running times cm operations table 
cm sum function computed product scan function additional time required compute 
assuming processors keys total time rank coefficient term line determined empirically instrumenting code 
term represents time perform scans term represents cost remaining operations initializing vector flag computing vector rank 
total time version radix sort call simple radix sort uses simple counting rank bit blocks bit keys radix rank 
blelloch 
library sort runs somewhat slower small values large fixed overhead 
notice formula increasing reduces number routings proportionally increases arithmetic scans exponentially 
determine value minimizes radix differentiating right hand side respect setting result equal yields lg lg ln 
large optimal value lg lg ln 
analysis borne practice cm library sort runs fastest large 
consider improved version parallel radix sort 
idea algorithm johnsson 
describe new algorithm counting ranks terms physical processors terms keys 
view length input vector block length vector element length array stored single processor 
maintain length vector index element length array stored single processor 
describe operation algorithm giving pseudocode counting rank block index increment index block offset count sum index index scan index offset offset offset count rank index block increment index block return rank basic idea algorithm follows 
block values lines determine times value appears processor 
consider ith processor particular value lines determine final rank key processor block value algorithm calculates rank computing number offset keys block values adds number keys block value equal processors 
values placed vector index 
having computed rank key processor block value final phase algorithm experimental analysis parallel sorting algorithms lines computes rank key 
algorithm requires indirect addressing processors index local arrays independently 
total time counting rank constants determined empirically 
note sum index line product scan index line single scan suffices 
comparing result obtained simple counting rank find terms additive multiplicative 
time radix sort 
breaks running time radix sort function 
seen increases send time diminishes scan time grows 
determine value minimizes total time algorithm differentiating right hand side respect setting result equal 
large numbers keys processor value obtain satisfies lg lg ln lg lg lg 
suggests set comes close minimizing total running time 
marginally better value obtained solving numerically 
fig 

breakdown total predicted running time radix sort send time scan time sorting bit keys 
total running time indicated top curve 
shaded areas represent scan time send time 
increased scan time increases send time decreases 
arithmetic time negligible 
parameters chosen optimal value 
blelloch fig 

predicted measured performance radix sort bit keys 
measured performance cm uses empirically determined optimal values predicted performance calculated 
choice dictated analysis simple radix sort optimal choice radix sort grows consequently large numbers keys processor number passes radix sort smaller simple radix sort 
substitute choice back obtain lg lg lg lg implementation radix sort optimal values determined empirically 
compares performance predicted actual running time implementation 

sample sort third sort implemented sample sort 
sorting algorithm fastest large sets input keys beating radix sort factor 
complicated implement 
sort randomized sort uses random number generator 
running time independent input distribution keys high probability algorithm runs quickly 
assuming input keys sorted machine processors algorithm proceeds phases 
set splitter keys picked partition linear order key values buckets experimental analysis parallel sorting algorithms 
values keys sent appropriate bucket ith bucket stored ith processor 

keys sorted bucket 
necessary fourth phase added load balance keys buckets typically exactly equal size 
sample sort gets name way splitters selected phase 
input keys sample ps keys chosen random parameter called oversampling ratio 
sample sorted splitters selected keys sample ranks sample sort algorithms choose oversampling ratio choice results relatively large deviation bucket sizes 
choosing larger value suggested reif valiant huang chow guarantee high probability bucket contains keys average 
reif valiant algorithm differs uses buckets corresponding lg processor subcubes hypercube 
time phase algorithm depends maximum number call keys single bucket 
average bucket size efficiency oversampling ratio maintains small bucket sizes measured ratio referred bucket expansion 
bucket expansion gives ratio maximum bucket size average bucket size 
expected value bucket expansion depends oversampling ratio total number keys denoted 
extremely bucket expansion significantly greater expected value 
oversampling ratio probability bucket expansion greater factor pr ne 
bound proved appendix graphed 
example oversampling ratio keys probability largest bucket times large average bucket shall see shortly running time sample sort depends linearly oversampling ratio bucket expansion 
apparent oversampling ratio increases bucket expansion decreases 
oversampling ratio carefully adjusted order obtain optimal performance 
ready discuss implementation sample sort algorithm 
executing phase algorithm little preprocessing 
reason basic sample sort algorithm assumes input keys distinct 
keys happen value failure break ties consistently result uneven distribution keys buckets 
consequently phase sample sort begins tag key address guaranteeing tagged keys distinct values 
phase selecting splitters 
phase sample sort begins processor randomly selecting set tagged keys stored local memory 
call keys candidates 
implement method partitioning blelloch fig 

bucket expansion sample sorting keys function oversampling ratio 
dashed curves theoretical upper bounds setting probability bound lower dashed curve upper dashed curve 
solid curves experimental values bucket expansion 
upper solid curve shows maximum bucket expansion trials lower solid curve shows average bucket expansion trials 
practice oversampling ratios yield bucket expansions 
processor keys blocks ps keys choose key random block 
selection process differs processor selects tagged keys randomly entire set done reif valiant huang chow algorithms 
methods yield small bucket expansions 
cm distributed memory machine local choice method advantage performance global choice methods global communication required select candidates 
implementation typically pick depending number keys processor input 
candidates selected sorted machine simple version radix sort described section 
radix sort stable tags need sorted remain attached corresponding keys 
sample contains fewer keys input step runs significantly faster sorting keys radix sort 
splitters chosen keys ranks actual extraction splitters sample implemented part phase 
dominant time required phase time sorting candidates rs ps rs ps time required radix sort ps keys processors 
radix sort original cm paris library notice time phase independent total number keys selection process processor need look keys order select randomly 
notice implemented global choice sampling strategy term containing expression 
experimental analysis parallel sorting algorithms phase distributing keys buckets 
local choice method picking sample choice algorithm sort oversampled keys phase follows reif valiant huang chow algorithms 
phase follow huang chow closely 
key determine bucket belongs performing binary search sorted array splitters 
implemented part phase straightforward fashion front reads splitters broadcasts processor 
processor determines bucket keys performing binary search array splitters stored separately processor 
determined bucket key belongs throw away tagging information key unique route keys directly appropriate buckets 
allocate memory buckets guarantee high probability accommodating maximum bucket size 
event bucket overflow excess keys discarded route algorithm restarted new random seed 
time required phase separated time broadcast time binary search time send search lg constants determined empirically instrumenting code 
evident description inspection formula reading broadcasting splitters front serial bottleneck algorithm 
sample sort really reasonable sort large 
particular costs due binary search outweigh costs due reading broadcasting splitters lg equivalently lg cm preceding inequality holds number input keys processor 
number particularly large processor cm full megabyte memory machine configured megabit drams 
phase sorting keys processors 
third phase sorts keys locally bucket 
time taken phase equal time taken processor keys bucket 
expected bucket expansion expected size largest bucket 
standard serial radix sort pass implemented passes counting sort see example section 
radix sort significantly faster comparison sorts quicksort 
serial radix sort requires time sort number bits key radix sort 
term coefficient corresponds serial scan computations histogram blelloch fig 

breakdown sample sort various choices oversampling ratio graph shows measured running time sorting bit keys keys processor cm height labeled region indicates time corresponding component sort 
oversampling ratio increased effects may observed time candidate sort increases candidates sort ii time local sort decreases maximum bucket expansion diminishes 
parameters total time minimized 
shown negligible 
key values second term corresponds needed count number keys bit value put keys final destinations 
determine value minimizes sort differentiating right hand side respect setting result equal 
yields lg large selection cost term equation small relative second term 
typically yields sort 
discussion 
main parameter choose algorithm oversampling ratio larger distributes keys evenly buckets speeding phase algorithm 
larger means larger sample sorted causing phase algorithm take longer 
shows tradeoff obtained experimentally 
seen choosing optimal case 
obtain arithmetic expression describes total running time sample sort sum formulas phases results expression search sort lg dropped inessential terms 
shows experimental breakdown times various tasks accomplished algorithm closely match equation 
experimental analysis parallel sorting algorithms fig 

breakdown actual running time sample sort function input size graph shows actual running times bit keys cm 
key cost broadcasting splitters decreases increases total cost broadcast independent key cost candidate sort decreases keys processor point increase oversampling ratio order reduce time local sorting 
local sort improves slightly higher values bucket expansion decreases key times send binary search remain constant 
look closely formula large 
terms correspond sorting candidates broadcasting splitters insignificant 
cm terms grow proportionally 
specifically terms correspond send local sort take time third term binary searching takes half time 
large entire algorithm runs times cost single send 
close time single send sorting algorithm cm outperform 
variations sample sort algorithm considered implementing 
discuss 
splitter directed routing 
broadcasting splitters binary searching sending phase splitter directed routing method reif valiant 
idea send key hypercube destination bucket dimensions hypercube fixed order 
hypercube node key chooses leave node comparison key splitter value stored node 
key follows path network bucket lg comparisons dimension network 
cm algorithm pipelined cube wires way similar pipelined version bitonic sort 
local processing required step routing quite involved 
requires managing queues variable number messages arrive node 
analysis indicated communication costs splitter directed routing take time blelloch communication costs required simply route messages network advantage exploited bookkeeping arithmetic costs dominate 
splitter directed routing may reasonable option supported special purpose hardware 
lacking cm scheme chose implement faster simpler code 
original hightower implemented version splitter directed routing toroidal mesh number keys processor large splitter directed routing outperform sample sort maspar mp 
smaller sets keys 
implemented sample sort suitable number keys processor large especially broadcast splitters front 
way improve algorithm processor contains relatively input keys execute passes phases 
pass generate splitters assign group processors bucket 
key sent random processor processor group corresponding bucket 
second pass group generates splitters locally broadcast subcubes keys sent final destinations 
algorithm fewer splitters need distributed processor twice number sends required 
variation implemented felt outperform bitonic sort small values load balancing 
phases algorithm complete processors number keys 
applications sorting implementing combining send heuristic clustering require processor loads exactly balanced 
sorting load balancing performed scanning determine destination sorted key routing keys final destinations 
dominant cost load balancing extra send 
implemented version sample sort load balancing 
large numbers keys processor additional cost algorithm outperforms sorts 
key distribution 
randomized sample sort algorithm insensitive distribution keys unfortunately cm message router mentioned section 
fact certain patterns routing take half times longer normally expected 
difficulty overcome randomizing location buckets 
algorithms require output keys canonical order processors extra send required small amount additional routing scan load balancing performed canonical order 
send load balancing 

goal project develop system sort connection machine 
goal raw speed concern 
issues included space stability portability simplicity 
radix sort notable advantages respect experimental analysis parallel sorting algorithms table 
summary sorting algorithms assuming bit keys 
time algorithm stable load balanced memory rank bitonic radix sample loaded balanced column specifies final result balanced processors 
time column time sort processor machine cm 
memory column ratio large space taken algorithm space taken original data 
rank column approximate ratio time rank time sort 
rank operation returns key rank attain vector sorted 
criteria 
radix sort stable easy code maintain performs reasonably entire range requires memory sample sort performs short keys 
sorts domains applicability concluded radix sort suitable system sort 
table compares sorting algorithms 
paragraphs examine quantitative differences algorithms 
running time 
graph actual running times sorts time original system sort 
keys processor sample sort approximately times faster sorts pure performance sample sort clear winner 
informative raw running times equations running times show running time affected number keys number processors various machine parameters 
assume large approximate equations algorithms lg lg lgp 
known equations give rough estimates running times algorithms machines 
caution running times predicted fashion err factor 
terms equations accurate constants derived empirically cm depend highly local capabilities processors 
equations give idea gained sorting algorithm improving various aspects cm 
example analyze effect improving time send 
equations see radix sort benefit running time dominated send currently cm 
space 
second important concern space required sorting algorithm 
blelloch bitonic sort executes place requires small constant amount additional memory processor storing certain temporary variables 
radix sort keys consisting bit words requires bit words space processor 
term needed storing keys send send executed place second term needed holding bucket sums 
term space required sort twice required original data 
number table corresponds case bits lg set minimize running time 
sample sort requires maximum bit words space processor 
second terms needed local radix sorting third term needed storing splitters processor 
number table corresponds case lg set minimize running time determined experimental values 
ranking 
practice rank useful operation sort 
vector keys rank operation returns key rank attain vector sorted 
operation allows user rank keys send larger block auxiliary information associated key final sorted position 
algorithms implemented implemented version generates ranks final sorted order 
implement rank operation terms sort original index vector tagged key carried sort 
sorted final index sent back location specified tag key original position 
radix sort implementation rank operation cost additional send avoided omitting send radix sort sending rank directly back index specified tag 
furthermore block key radix sort block thrown away shortening message length subsequent sends 
time radix rank marginally expensive radix sort 
sample sort bitonic sort carrying tag slows algorithm factor 
stability 
radix sort stable sorts 
bitonic sort sample sort stable tagging key initial index done rank 
case tag carried sends comparisons 
sorting extra tag cause slowdown factor 
key length 
issue sorting short keys keys significant bits 
sorting short keys problem arises reasonably cm applications 
short keys time required bitonic sort improved bit time 
time required sample sort marginally improved cost local radix sort reduced 
time required radix sort essentially proportional key length 
typically range sorting bits requires passes bits bits 
experimental analysis parallel sorting algorithms acknowledgments people involved project 
particularly mark bromley steve heller bradley kevin thinking machines helping various aspects cm including implementation send needed sample sort 
john thinking machines rita rita support inspiration 
appendix sorts sorts algorithms developed sorting hypercube related networks butterfly cube connected cycles shuffle exchange 
considered number algorithms deciding implement bitonic sort radix sort sample sort 
purpose section discuss sorting algorithms considered particular indicate alternatives selected implementation 
quicksort 
relatively easy implement parallel version quicksort cm segmented scans 
pivot chosen random broadcast scans 
pivot partitions keys small keys large keys 
scans small key labeled number small keys precede linear order large key labeled number large keys precede plus total number small keys 
keys routed locations specified labels 
new linear order broken segments small keys large keys algorithm recursively applied segment 
expected number levels recursion close lg level algorithm performs route approximately scans 
algorithm implemented high level language lisp runs half fast original system sort 
believed speed significantly scan route operations performed hardware 

algorithm outlined follows 
hypercube node sorts keys locally 
hypercube nodes broadcasts median key nodes 
key pivot 
node partitions keys smaller larger 
hypercube nodes exchange keys dimension edges hypercube 
node address begins sends keys larger neighbor address begins 
neighbor sends back keys smaller arrive node merged sorted sequence keys sent node 
algorithm recursively applied node subcubes addresses respectively 
communication cost comparable fully pipelined version bitonic sort 
expected cost qn lg algorithm uses lg dimensions time dimension node expects send half keys neighbor 
cost bitonic sort lg lg see section 
blelloch main advantage bitonic sort performance affected initial distribution keys sorted 
relies random initial distribution ensure processor reasonably balanced 
may perform arithmetic bitonic sort best case uses indirect addressing relatively expensive cm 
sparse enumeration sort 
sahni sorting algorithm referred sparse enumeration sort number items sorted smaller number processors 
special case sparse enumeration sort simple algorithm 
records initially stored processor lowest numbered processors viewing processors hypercube forming dimensional array input records occupy row array 
sparse enumeration sort proceeds performing set parallel column broadcasts topmost entry column followed parallel row broadcasts diagonal position processor row column array contains copy ith jth items 
point pairs items simultaneously compared constant time prefix operations rows compute rank item 
ith row route copy item column corresponding output rank 
set parallel column routes move item sorted output position row 
values strictly sparse enumeration sort proceeds exactly fashion processors remaining processors idle 
sparse enumeration sort runs lg time spares enumeration sort generalizes preceding algorithm elegant manner obtain smooth tradeoff lg performance lg performance performance bitonic sort 
range sparse enumeration sort structured way merge sort 
ith set parallel merges items organized sorted lists length 
initially lists length 
ith set merges performed lg time constant number bitonic merges prefix operations monotone routes 
monotone routes special class routing operations performed deterministically line collision free manner 
cm monotone routes implemented cube swaps entire implementation sparse enumeration sort cm router 
straightforward computation shows time complexity sparse enumeration sort lg lg time 
sufficiently large values ratio expected sparse enumeration sort perform better sorts looked 
unclear parallel computer required solve small problems better times achieved solving problem single processor reducing column sort 
leighton column sort elegant parallel sorting technique theoretical applications 
column sort sorts keys primitive operations 
primitive operation sort separate sets called columns keys 
depending particular application sorting primitive may accomplished recursive call typically sorting algorithm 
experimental analysis parallel sorting algorithms second primitive operation route keys fixed permutation 
alternating sorts routes times suffices sort elements 
column sort runs quite efficiently 
sorting primitive executed local sort fixed permutations required column sort straightforward implement greedy collision free manner 
terms cm implemented simple sequence cube swaps invoking router 
implementation optimization standard column sort algorithm pipelined lg fraction cm wires give time 
lg speedup achieved pipelining approaches worthy consideration 
approach partition data processor lg equal sized sets interleave lg column sorts merge resulting lg sorted lists 
second approach pipeline routing operations single application column sort 
main drawback column sort degree depending ratio recursion necessary order perform sorting primitive sets items occupy single processor 
chose implement column sort appeared condition satisfied cases interest close analysis critical sections potential code indicated recursive version column sort provide little improvement radix sort sample sort 
furthermore relative performance column sort tend degrade quite severely small values ratio asymptotic performance column sort best understood considering arithmetic communication costs separately 
assume denotes arbitrary positive constant implies bounded depth recursion 
assumption total arithmetic cost column sort lg optimal comparison sort 
pipelining communication cost column sort optimal sorting algorithm 
summarize felt column sort turn competitive unusually high loads mediocre performance high loads poor performance low moderate loads alternatives attractive 
column sort useful component hybrid sorting scheme automatically selects appropriate algorithm depending values 
column sort algorithm cypher sanz gives scheme sorting items number rounds round data partitioned sets size set sorted 
successive partitions data determined simple fixed permutations routed just efficiently column sort 
main advantage column sort wide range values requires asymptotically fewer rounds column sort 
particular column sort applied recursively uses lg lg rounds lg uses lg lg lg lg rounds 
cost implementing round essentially case 
implemented recursion requires rounds opposed column sort 
column sort applied recursively 
sufficiently smaller blelloch sufficiently large aforementioned asymptotic bounds imply eventually outperform column sort 
practical values crossover performance occurs appears occur point column sort poor performance relative algorithms low moderate loads 
nonadaptive 
variants algorithm described 
practical variant interest nonadaptive version algorithm 
structure algorithm referred simply similar column sort 
algorithms progress ensuring certain partitioning data subcubes distribution ranks items subcube similar 
benefit performing balancing operation subcubes recursively sorted items immediately routed close correct position final sorted order subcubes approximately merged oblivious fashion 
effectiveness algorithm determined close terms number processors item guaranteed come correct sorted position 
turns column sort amount error decreases load processor increased 
noted preceding section column sort applied recursion 
due fact merging balanced subcubes item routed correct processor routed processors 
sort completed performing local sorts followed merge split operations odd pairs adjacent processors 
simple optimization efficient sort ith largest set items processor ith largest standard gray code processor permits merge split operations performed adjacent processors 
main difference column sort balancing operation performed cost related column sort small constant factor guarantees asymptotically smaller degree error 
reason applied recursion larger range values lg interestingly balancing operation simple variant merge split merge operation 
essentially best way guarantee similarity distribution ranks items pair adjacent processors merge sets items assign odd ranked items resulting sorted list processor say ranked items processor effect precisely merge operation 
balancing operation amounts performing lg sets merge operations hypercube dimensions 
case column sort ways pipeline balancing operation order take advantage cm ability communicate hypercube wires 
high loads felt turn competitive sample sort 
column sort performance degrades relative algorithms low moderate loads overriding factor decision implement 
un experimental analysis parallel sorting algorithms usually high loads column sort slightly outperform small constant factor advantage running time balancing operation cm 
mentioned asymptotic performance column sort terms arithmetic communication 
outperforms column sort smaller values 
detailed analysis running time reader referred 
theoretical results 
subsection summarizes theoretical sorting results algorithms optimal near optimal asymptotic performance remain impractical due large constant factors nonconstant costs accounted model computation 
certain instances significant additional penalty paid order port algorithm particular architecture provided cm 
algorithms developed sorting parallel random access machines prams 
fastest comparison sort cole parallel merge sort 
algorithm requires optimal lg time sort items processor exclusive write erew pram 
way sort lg time emulate aks sorting circuit 
case constants hidden notation large 
interested emulating pram algorithm fixed connection network hypercube butterfly cost emulation taken account 
emulation schemes routing 
cost sample sort times cost single routing operation direct emulation pram sorting algorithm lead competitive solution 
hypercube related networks butterfly cube connected cycles shuffle exchange asymptotic improvements deterministic randomized settings 
deterministic lg lg lg time algorithm case described 
lg time algorithm admits efficient bit serial implementation improves asymptotic failure probability reif valiant algorithm 
unfortunately algorithms quite impractical 
reader interested theoretical bounds consult aforementioned papers previous 
appendix probabilistic analysis sample sort appendix analyzes sizes buckets created sample sort algorithm section 
recall buckets created method call method processors partitions keys groups ps selects candidate random group 
total exactly ps candidates 
candidates sorted sth candidate sorted order chosen splitter 
keys lying successive splitters form bucket 
theorem shows method assigns keys average bucket 
proof theorem uses lemmas known literature 
due hoeffding 
blelloch lemma 
xi random variable equal probability qi probability qi xi implies qi 
sum random variables equal probability probability note qn 
qn integer pr pr 
second lemma chernoff bound due angluin valiant 
lemma 
consider sequence bernoulli trials success occurs trial probability random variable denoting total number successes 
pr rq rq third lemma shows method analyzed terms simpler method call method method key keys independently chooses candidate probability ps method expected number candidates ps 
lemma shows upper bounds method apply method lemma 
set keys denote arbitrary subset yp yi denote number candidates chosen methods respectively 
integer ps pr yp pr yi 
proof 
si partition keys method ps si si ps 
define ti si ps 
ti si ps method set ti contributes candidate probability ti ps candidates 
define random variables follows 
nonempty ti define ti random variables random variable equal probability ti ps remaining ti random variables 
call resulting set random variables order unimportant yp random variable defined yp xi 
consequently ps yp xi ti ps ps yp random variable corresponding number candidates chosen set method experimental analysis parallel sorting algorithms define yi sum ps biased bernoulli trials 
note yi random variable corresponding number candidates chosen set method substituting yp yi lemma pr yp pr yi yp yi ps 
lemmas hand prepared prove bound 
theorem 
number keys sample sort algorithm number processors oversampling ratio 
probability method causes bucket contain ne proof 
prove bucket receives keys suffices show distance key splitter sorted order looking single key 
fewer keys sorted order candidates 
denote set keys 
yp denote number candidates chosen method pr pr yp 
obtain upper bound pr yp analyzing method method lemma upper bound derived pr yi applies pr yp long ps holds ifthe candidates chosen method number candidates set keys binomial distribution pr yi number independent bernoulli trials ps probability success trial yi number successes 
probability fewer successes occur expected bounded chernoff bound pr yi rq rq holds 
substituting ps wehave pr pr yp pr yi blelloch probability distance keys splitter sum individual probabilities bounded keys probability distance key splitter greater ne proves theorem 
ajtai koml szemer di 
sorting log parallel steps 
combinatorica 
akl 
parallel sorting algorithms 
academic press toronto 

sorting networks applications 
proceedings afips spring joint computing conference volume pages 
baudet stevenson 
optimal sorting algorithms parallel computers 
ieee transactions computers 
blelloch 
vector models data parallel computing 
mit press cambridge ma 
cole 
parallel merge sort 
siam journal computing 
cormen leiserson rivest 
algorithms 
mit press cambridge ma mcgraw hill new york 
cypher plaxton 
deterministic sorting nearly logarithmic time hypercube related computers 
proceedings nd annual acm symposium theory computing pages may 
cypher sanz 
parallel algorithm sorting data items 
journal algorithms 

sampling approach minimal storage tree sorting 
journal association computing machinery 
hagerup rub 
guided tour chernoff bounds 
information processing letters 
hightower prins reif 
implementations randomized sorting large parallel machines 
proceedings symposium parallel algorithms architectures june 
huang chow 
parallel sorting data partitioning sampling 
proceedings ieee computer society seventh international computer software applications conference pages november 
johnsson 
combining parallel sequential sorting boolean cube 
proceedings international conference parallel processing pages 
leighton 
tight bounds complexity parallel sorting 
ieee transactions computers 
leighton plaxton 
fairly simple circuit usually sorts 
proceedings st annual symposium foundations computer science pages october 
sahni 
parallel permutation sorting algorithms new generalized connection network 
journal association computing machinery 
plaxton 
efficient computation sparse interconnection networks 
technical report stan cs department computer science stanford university september 
reif valiant 
logarithmic time sort linear size networks 
journal association computing machinery 
seidel george 
hypercubes port communication 
proceedings third conference hypercube concurrent computers applications pages 
acm new york january 
stricker 
supporting hypercube programming model mesh architectures fast sorter tori 
proceedings symposium parallel algorithms architectures june 
smith 
improved supercomputer sorting benchmark 
proceedings supercomputing pages november 
experimental analysis parallel sorting algorithms 
fast sorting algorithm hypercubes 
heath editor hypercube multiprocessors proceedings second conference hypercube multiprocessors pages 
siam 
philadelphia pa 
won sahni 
balanced bin sort hypercube multicomputers 
journal supercomputing 
zagha blelloch 
radix sort vector multiprocessors 
proceedings supercomputing pages november 
received april final form june 
