bayesian models human sentence processing srini narayanan daniel jurafsky university california berkeley 
university colorado boulder cs berkeley edu jurafsky colorado edu human language processing relies kinds linguistic knowledge sensitive frequency including lexical frequencies tyler marslen wilson simpson burgess idiom frequencies phonological neighborhood frequencies luce subcategorization frequencies trueswell tanenhaus kello thematic role frequencies trueswell tanenhaus pearlmutter myers 
know knowledge sources probabilistic know little exactly probabilistic knowledge sources combined 
proposes bayesian decision trees modeling probabilistic evidential nature human sentence processing 
method reifies conditional independence assertions implicit sign linguistic theories describes interactions features requiring additional assumptions modularity 
show bayesian approach successfully models psycholinguistic results evidence combination human lexical idiomatic syntactic semantic processing 
modern psychological models language processing line interaction kinds linguistic knowledge clifton abney ferreira clifton macdonald spivey knowlton trueswell tanenhaus trueswell tyler 
exact time course different knowledge sources fully understood clear processing knowledge sensitive frequency lexical frequencies tyler marslen wilson simpson burgess idiom frequencies phonological neighborhood frequencies luce subcategorization frequencies trueswell thematic role frequencies trueswell 
probabilistic versions linguistic knowledge common linguistics resnik jurafsky 
know knowledge sources probabilistic fact preliminary probabilistic models specific linguistic levels know little exactly probabilistic knowledge sources combined 
particularly true higher level knowledge association probabilities sophisticated linguistic structural representation re begun 
coherent probabilistic interpretation problem language interpretation different levels 
kinds conditional independence assumptions combining knowledge represent assumptions 
sophisticated linguistic structural knowledge combined probabilistic augmentations 
automatic speech processing asr natural language processing nlp literature bahl jelinek mercer fujisaki jelinek cocke black charniak goldman hobbs bear argued language processing evidential bayesian 
proposes bayesian decision trees address issues modeling probabilistic evidential nature human sentence processing 
basic result idea lexical access parallel accepted widely assumed aspects syntactic processing parallel macdonald 
similarly accepted role frequency plays lexical marslen wilson simpson burgess idiomatic syntactic trueswell thematic processing trueswell 
jurafsky argued bayesian model posterior probabilities frequencies able account number effects explainable frequentist model including intuitions results idiom access luce 
results similarity neighborhoods insight tanenhaus lucas psycholinguistic evidence top effects common phonology rarer syntax 
complete probabilistic models syntactic semantic processing harder build 
example number studies focused main verb mv reduced relative rr ambiguity frazier rayner macdonald macdonald pearlmutter seidenberg spivey knowlton trueswell tanenhaus trueswell spivey knowlton 
cases mv rr ambiguity resolved favor main clause reading leading garden path analysis 

horse raced past barn fell 
proponents constraint satisfaction model argued accounted different lexical morphological frequencies participial forms verb raced macdonald simpson burgess 
cases constraints verb subcategorization permit rr interpretation 
verb example transitive doesn cause strong garden path rr interpretation gibson 
horse carried past barn fell 
bird room died 
studies probabilistic effects verb subcategorization preferences jurafsky trueswell 
example jurafsky suggested garden path effect caused combination lexical syntactic verb subcategorization probabilities 
studies suggested semantic context thematic fit impact disambiguation 
instance trueswell 
showed strong thematic constraints able ameliorate garden path effects rr mv ambiguities subjects experienced difficulty phrase lawyer examples 
witness examined lawyer turned unreliable 
witness examined lawyer turned unreliable 
evidence examined lawyer turned unreliable 
assorted previous argued various probabilistic knowledge sources play role processing exactly probabilities combined 
model assumptions linguistic knowledge represented probabilistically multiple interpretations maintained parallel probabilities interpretations computed belief net probabilistic independence net 
probabilities bayes formalism model explains number psychological results 
section explains mean assigning probabilities linguistic structure 
introduce probabilistic independence net formalism combining different probabilities 
examine model stands various psychological results 
prior probabilities assume linguistic knowledge represented collection signs constructions represents original study ferreira clifton semantic effects trueswell 
stronger manipulation thematic constraint 
pairing meaning form represented signs typed unification augmented context free rules pollard sag fillmore 
words morphological structures ed past tense morpheme syntactic constructions passive construction represented constructions 
constructions associated prior probability computed relative frequencies corpora studies 
example order compute probability simplified stochastic context free grammar scfg rule penn treebank marcus get frequency nps np consist det 
conditional probability 
np det similarly verb subcategorization probabilities computed treebank studies 

thematic probabilities computed normalizing verb bias norms example 

table shows lexical probabilities verb examine including morphological subcategorization thematic probabilities 
thematic probabilities computed psychological studies trueswell quantify degree fit specific filler witness specific argument slot agent theme predicate verb examined 
information obtained semantic database wordnet done resnik resnik 
see jurafsky details probability computations 
table lexical thematic fit probabilities examined 
note refers agent examined ev evidence witness theme 
past pp trans construction processing belief nets bayesian belief networks data structures represent probability distributions collection random variables 
basic network consists set variables directed edges variables 
variable take finite set states 
variables edges form directed acyclic graph dag 
variable node graph parents bn attached conditional probability table ajb bn importantly network structure reflects conditional indepen see roland jurafsky merlo gibson pearlmutter comparisons experimental corpus frequencies 
discourse context syntactic support lexical thematic support joint causal influence construction 
diagnostic influence orthographic evidence phonetic evidence sources evidence access belief network representing role top bottom evidence 
dence relations variables allow decomposition joint distribution product conditional distributions 
theorem sets basic chain rule computing joint distribution conditional distribution 
theorem jensen belief network fa amg joint probability distribution product local conditional probability distributions specified ai pa ai parent set ai crucial insight belief net model view specific constructions values latent variables render top bottom evidence conditionally independent separate pearl 
syntactic lexical argument structure contextual information acts prior causal support construction interpretation bottom phonological perceptual information acts likelihood evidential support 
shows computational realization idea 
belief nets model human sentence processing allows quantitatively evaluate impact different independence assumptions uniform framework directly model impact highly structured linguistic knowledge sources local conditional probability tables known algorithms updating belief net jensen compute global impact new evidence develop line interpretation algorithm partial input corresponds partial evidence network update algorithm appropriately unobserved nodes 
evidence comes incrementally different nodes instantiated posterior probability different constructions changes appropriately 
comprehensive exposition see pearl jensen 
arg tense arg tense mv thm examine ed type subj witness tense past sem fit agent rr thm ty subj ty subj semantic fit arg trans tense pp sem fit theme belief net represents lexical support interpretations input 
input data table 
apply model line disambiguation assume set constructions cn consistent input data 
different stages input compute posterior probabilities different interpretations top bottom evidence seen far 
apply beam search algorithm jurafsky prune constructions posterior probability certain ratio best construction highest posterior 
refer ratio threshold confidence ratio tcr 
prune best tcr 
modeling lexical thematic support model requires conditional probability distributions specifying preference verb different argument structures preference different tenses 
compute semantic fit possible fillers input different conceptual roles predicate 
shows general structure organization lexical thematic information sources 
thematic probabilities method computation shown table 
shown mv rr interpretations require conjunction specific values corresponding tense semantic fit argument structure features 
note rr interpretation requires transitive argument structure 
modeling syntactic support conditional probability construction top syntactic evidence cje relatively simple compute augmented stochastic context free formalism parse trees shown 
recall focus support thematic syntactic features reduced relative rr main verb mv interpretations different stages input examples saw earlier 
constructions je mv je rr examples reported set tcr prune rr interpretation mv rr 
role features voice aspect access disambiguation studied methods developed 
np np 
vp vp witness examined np np xp np np vp witness np examined main verb reduced relative syntactic parse trees mv rr interpretations assuming scfg generating grammar 
det np 
vp np vp mv syn witness np np vp det np 
np np xp examined belief network corresponding syntactic support 
scfg prior probability gives conditional probability right hand side rule left hand side 
particular parser operates left right top probability probability evidence left expands context free grammar nonterminal left expands nonterminal derivation tree root leftmost leaf illustrates belief network representation corresponds syntactic parse trees 
note context freeness property translates conditional independence statements entailed network 
computing joint influence posterior ratio requires propagating conjunctive impact syntactic lexical thematic sources model 
shows belief net architecture combining sources 
belief net embodies assumption syntactic thematic influences dependent value specific construction case main verb mv reduced relative rr construction 
words inter source dependencies explicitly captured specific constructions 
furthermore computing conjunctive impact lexical thematic syntactic support compute mv rr model pearl exact technical details including automatic network construction technique refer narayanan lexical thematic type subj arg tense sem fit mv rr thm thm mv det syntactic np 
vp np vp mv syn rr rr syn np 
np np vp det belief net combines thematic syntactic support specific construction 
combining conjunctive sources assumed inhibits specific source syntactic indicating support construction independent mechanisms inhibit sources lexical indicating support construction 
called assumption exception independence widely respect disjunctive noisy conjunctive sources 
model results number psycholinguistic results argue bayesian model sentence processing 
see jurafsky example summary argument conditional probabilities appropriate metric frequencies 
main result discuss evidence line disambiguation studies shows bayesian implementation probabilistic evidence combination accounts garden path disambiguation effects 
tested model ambiguous region input example sentences earlier computing ratio mv posterior different stages input 
rr note partial input belief net inference automatically values unseen input 
case subject input horse examples thematic influence minimal mv ratio basically result syntactic rr support 
data taken macdonald marcus 
shows relevant posterior probabilities examples horse raced past barn fell replacement raced carried different stages input 
shown model predicts mv rr ratio exceeds threshold immediately verb raced accessed mv rr leading pruning rr interpretation 
cases mv rr ratio temporarily rising overshoots threshold allowing mv rr interpretations active ambiguous region 
show mv rr ratio different log mv rr raced mv rr tcr carried horse ed past barn disambiguation lexical probabilities showing mv rr posterior ratio raced falls threshold rr interpretation pruned 
carried interpretations active disambiguating region 
mv rr ratio witness control evidence tcr examined lawyer role thematic fit mv rr ratio 
data shown animate np subject position witness inanimate np strong semantic fit evidence unambiguous control 
stages examined examples 
information thematic fit culled typicality ratings psychological study trueswell 
illustrated processing input phrase witness examined rr interpretation preferred pruned 
leads limited processing difficulty limited approaches tcr exceeds encountering phrase lawyer syntactically semantically incompatible mv interpretation 
reassignment roles unambiguous control processing difficulty predicted 
model garden paths example horse raced past barn fell garden path example horse carried past barn fell example horse past barn fell 
model explains correlations trueswell thematic fit processing difficulty 
furthermore able explain garden graded effect processing difficulty chance garden depends strongly input favors interpretation 
computational model proposed combines basic ideas language processing 
idea multiple sources linguistic knowledge conceptual perceptual interact access disambiguation 
idea manifest psychological literature lexical access sentence processing pdp dynamical systems models language processing tanenhaus 
second idea linguistic knowledge highly structured hierarchically organized exemplified syntactic argument structure knowledge 
probabilistic nets allows compute joint distribution multiple correlated features structural relationships minimize number inter feature interactions 
dual advantages compact representation clarity model 
hypothesis linguistic structures coded partially independent dimensions allows model wide array psycholinguistic results offers computational method systematically investigate modularity non modularity hypothesis 
jerry feldman stuart russell nancy chang valuable comments various aspects 
bahl jelinek mercer 

maximum likelihood approach continuous speech recognition 
ieee transactions pattern analysis machine intelligence 


comprehension idioms 
journal memory language 
charniak goldman 

logic semantic interpretation 
proceedings th acl buffalo ny 
clifton jr abney 

parsing arguments phrase structure argument structure determinants initial parsing decisions 
journal memory language 
ferreira jones clifton frazier 

verb frame preference descriptive norms 
journal psycholinguistic research 


comprehension semantic interpretation idioms 

eds idioms processing structure interpretation pp 

lawrence erlbaum associates new jersey 
ferreira clifton jr 

independence syntactic processing 
journal memory language 
fillmore 

mechanisms construction grammar 
proceedings bls pp 
berkeley ca 
frazier rayner 

resolution syntactic category ambiguities eye movements parsing lexically ambiguous sentences 
journal memory language 
fujisaki jelinek cocke black 

probabilistic parsing method sentence disambiguation 
tomita 
ed current issues parsing technology pp 

kluwer boston 
pearlmutter myers 

contributions verb bias plausibility comprehension temporarily ambiguous sentences 
journal memory language 
gibson 

computational theory human linguistic processing memory limitations processing breakdown 
ph thesis carnegie mellon university pittsburgh pa gibson pearlmutter 

corpus analysis psycholinguistic constraints preposition phrase attachment 
perspectives sentence processing pp 

erlbaum hillsdale nj 


establishing loci serial parallel effects syntactic processing 
journal psycholinguistic research 
hobbs bear 

principles parse preference 
proceedings th international conference computational linguistics coling pp 
helsinki 
jensen 

bayesian networks 
springer verlag 
jurafsky 

probabilistic model lexical syntactic access disambiguation 
cognitive science 
luce 

similarity neighborhoods spoken words 
altmann 
ed cognitive models speech processing pp 

mit press cambridge ma 
macdonald 

interaction lexical syntactic ambiguity 
journal memory language 
macdonald 

probabilistic constraints syntactic ambiguity resolution 
language cognitive processes 
macdonald pearlmutter seidenberg 

syntactic ambiguity resolution lexical ambiguity resolution 
perspectives sentence processing pp 

erlbaum hillsdale nj 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
marslen wilson 

activation competition frequency lexical access 
altmann 
ed cognitive models speech processing pp 

mit press cambridge ma 
merlo 

corpus analysis verb continuation frequencies syntactic processing 
journal psycholinguistic research 
narayanan 

graphical models stochastic grammars 
tech 
rep tr icsi berkeley ca 
pearl 

probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufman san mateo ca 
pollard sag 

information syntax semantics volume fundamentals 
university chicago press chicago 


garden path phenomena grammatical basis language processing 
language 
resnik 

probabilistic tree adjoining grammar framework statistical natural language processing 
proceedings th international conference computational linguistics pp 
nantes france 
resnik 

selection information class approach lexical relationships 
ph thesis university pennsylvania 
institute research cognitive science report ircs 
roland jurafsky 

verb subcategorization frequencies affected corpus choice 
submitted acl 


interaction knowledge sources spoken word identification 
journal memory language 
simpson burgess 

activation selection processes recognition ambiguous words 
journal experimental psychology human perception performance 
spivey knowlton 

resolving attachment ambiguities multiple constraints 
cognition press 
spivey knowlton trueswell tanenhaus 

context effects syntactic ambiguity resolution discourse semantic influences parsing reduced relative clauses 
canadian journal experimental psychology 


lexical access sentence comprehension re consideration context effects 
journal verbal learning verbal behavior 
tanenhaus 

parsing dynamical system 
language cognitive processes 
tanenhaus lucas 

context effects lexical processing 
cognition 
trueswell tanenhaus 

tense temporal context syntactic ambiguity resolution 
language cognitive processes 
trueswell tanenhaus 

framework constraint syntactic ambiguity resolution 
perspectives sentence processing pp 

erlbaum hillsdale nj 
trueswell tanenhaus 

semantic influences parsing thematic role syntactic ambiguity resolution 
journal memory language 
trueswell tanenhaus kello 

constraints sentence processing separating effects lexical form garden paths 
journal experimental psychology learning memory cognition 
tyler 

structure initial cohort evidence gating 
perception psychophysics 
tyler 

role lexical representations language comprehension 
marslen wilson 
ed lexical representation process pp 

mit press cambridge ma 


locus effects context spoken word processing 
cognition 
