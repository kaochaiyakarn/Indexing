learning segmentation random walks marina jianbo shi carnegie mellon university fmmp cs cmu edu new view image segmentation pairwise similarities 
interpret similarities edge flows markov random walk study eigenvalues eigenvectors walk transition matrix 
interpretation shows spectral methods clustering segmentation probabilistic foundation 
particular prove normalized cut method arises naturally framework 
framework provides principled method learning similarity function combination features 
successful methods image segmentation combine global optimality segmentation criterion local similarity features 
similarity pixels defined positive function sij depending local image properties pixels color texture edge flow 
local features computationally convenient supported neurological evidence human perception shapes 
global segmentation criterion formulated energy functions weighted graph cut :10.1.1.160.2324
cases optimizing chosen criterion turns computationally extremely difficult 
connected graph cuts problems set techniques called spectral methods segment eigenvectors eigenvalues certain transformations similarity matrix sij 
demonstrated methods capable delivering impressive image segmentation results simple low level image features 
computational efficiency achieved sparse multiscale matrix techniques amounts parallel local computations 
spite practical successes spectral methods incompletely understood 
significance similarity matrix precisely way combine various types lower level image features single matrix interest introduce high level knowledge examples definition similarity connections sij 
interpret local connections describing random walk 
interpretation achieve ffl better understanding spectral methods 
give simple probabilistic interpretation normalized cut ncut segmentation show strong connections spectral methods 
ffl similarity matrix learned principled way 
image segmentation pairs optimize similarity measure combination features ffl framework inspires introduce new feature depicts relationship main concepts 
starting similarities sij define weighted graph set pixels nodes sij graph edge weights 
image segmentation formulated graph partitioning problem seeks find small cuts ncut graph 
computationally discrete dy ncut similarity feature random matrix target segmentation relationships similarity matrix sij markov random walk spectral segmentation ncut image segmentation 
key properties markov random walk ncut offers principled way learning feature similarity matrix sij probabilistic framework 
optimization ncut achieved computing generalized eigenvectors gamma dy diagonal real valued space 
variant spectral segmentation called ncut algorithm works practice 
similarity matrix define markov random walk transition matrix pij normalization 
interesting properties markov random walk mixing rate conductance rate walks entire space 
conductance depends sets states random walk tends trapped high probability 
image sets seen segmented regions 
turns conductance measured ncut criterion low conductivity sets exactly results ncut 
described detail section 
probabilistic interpretation ncut markov random walk sheds new lights spectral methods segmentation 
particular offers principled way learning weights sij 
segmented image provide target transition matrix learning algorithm matches kl divergence learned transition probabilities 
output model function set features measured training image 
described section 
test theory show experiment segmenting objects smooth rounded shape 
section show training synthetic images learn segment real images 
markov random walks spectral clustering normalized cut section describes view spectral segmentation framework markov random walks 
view provides new better motivation spectral segmentation clustering methods 
core learning algorithm section 
sake brevity outline relationship ncut algorithm criterion rest treated longer version 
low conductivity cuts studied spectral graph theory consequences pertaining segmentation propositions relationship ncut learning model new 
assume similarity function sij concern partition image 
rest devoted opposite task learning similarity function segmented images 
ideal cases demonstrate spectral methods expected 
show ncut criterion algorithm fall naturally representation ideal cases solved exactly ncut algorithm 
www cs cmu edu mmp papers segment long ps obtaining markov chain similarity matrix analogy graph adjacency matrix call di pj sij degree node subset nodes volume vol pi di 
diagonal matrix consisting node degrees 
normalizing similarity matrix obtains stochastic matrix gamma row sums 
known theory markov random walks pij represents probability moving node step eigenvalues gamma gamma gamma eigenvectors called eigenvalue 
proposition 
disconnected gif graph connected components eigenvalues equal eigenvalues 
call type 
eigenvectors indicator functions respective connected components 
fact represents fundamental idea spectral segmentation 
number unit tells number segments 
gamma indicator functions simply project pixels space spanned vectors 
pixels segment project point rk close noise 
means known simple clustering algorithm separate segments 
call segmentation method ncut algorithm 
experiments show ncut works graphs disconnected :10.1.1.160.2324
results motivate behavior 
proposition 
connections assume admits segmentation segments pixels segment correspond equal rows call type 
pss segments pss js 
gamma yk gamma eigenvalues vectors eigenvalues gamma eigenvalues 
ii eigenvector corresponding non zero eigenvalue xi xj pixels belong segment 
iii xl eigenvector corresponding non zero eigenvalue xli pixels belonging segment proposition 
linear combination multiplication assume stochastic matrices admit partition types respectively 
nonzero eigenvalues gamma corresponding eigenvectors gamma 
convex combination ffp gamma ff stochastic matrix ff gamma gamma ff gamma eigenvalues eigenvectors 
ii products type matrices eigenvalues vectors equal gamma gamma 
intuitively proposition says spectral segmentation group pixels neighbors 
proposition says spectral segmentation successful criteria disconnection neighbors combined linearly multiplication 
results motivate practical usage spectral clustering methods general ncut algorithm particular 
normalized cut criterion graph theoretical criterion segmenting image minimizing expression subsets cut pi sij sij xi ij vol vol ncut measures weight cut normalized volumes segments :10.1.1.160.2324
shown second eigenvector piecewise constant propositions cut gamma :10.1.1.160.2324
easy see cut pa aa 
ncut natural probabilistic interpretation framework random walks quality cut indicated 
practical solution ncut np hard generalized eigenvalue vector problem gamma show full problem identical solutions gamma ncut algorithm described essentially identical original ncut algorithm :10.1.1.160.2324
random walks provide simple natural learning pi modell pi human labeled segmentation 
general framework learning image segmentation 
alternative interpretation ncut algorithm criterion 
ncut algorithm strongly related graph theoretical problem low conductivity sets spectral clustering methods documents web 
discuss light markov random walks full 
framework learning image segmentation previous section stressed connection ncut criterion image segmentation searching low conductivity sets random walk 
exploit connection develop framework supervised learning image segmentation 
goal obtain algorithm starts training set segmented images set features learns function features produces correct segmentations 
idea sketched 
simplicity assume training set consists image correct segmentation 
easy obtain ideal target transition probabilities lambda ij ae jaj segment jaj elements predefined set features measure similarity pixels different criteria values examples features euclidean distance pixels difference color presence edge crossing connecting line pixels feature associates pair pixels value fij 
model part framework subject learning 
takes features qij inputs outputs global similarity measure sij 
experiments simple model sij model advantage sij positive 
intuitively represents set independent experts factors qf voting probability transition values account features relative importance scaling 
additive model limited representation power 
particular model contextual changes dependencies features 
goal learning find optimal sij form function features 
framework fact segmentation equivalent random walk optimality defined minimization conditional kullback leibler kl divergence target probabilities lambda ij transition probabilities pij obtained normalizing sij 
lambda fixed minimization equivalent maximizing conditional distributions max jij xj lambda ij log pij kl divergence distributions log 
ic edge ii features segmenting objects smooth rounded shape 
edge strength provides cue region boundary 
biases random walks direction orthogonal edge 
edge orientation provides cue object shape 
induced edge flow bias random walk edge transitions circular edge flows encouraged 
edge flow bump 
note flow reverses directions sides edge 
edge contrast lambda ic image intensity range lambda cl bump images training 
contrast gradually reduced 
shows relation image edge contrast learned value ic demonstrating automatic adaptation dynamic range ic 
shows dependence image contrast cl importance linear circular cl feature remains relatively constant image contrast low 
low image contrast cl important 
interpret factor jij uniform distribution states ss criterion equivalent kl divergence distributions transitions kl lambda lambda ss lambda ij 
maximizing done gradient ascent parameters 
obtain jij ij lambda gamma ij gradient parameter measures difference means corresponding feature fq target current distribution 
optimal parameters attained means equal 
note optimum corresponds solution maximum entropy problem max jji ij ss ij ss lambda jji convex optimization problem convex constraints unique optimum 
simple model problem local maxima avoided 
knowing values may grow indefinitely learning shall parameters growing reach certain upper bound 
segmentation shape region information section exemplify approach set synthetic real images features carrying contour shape information 
set local filer banks edge choose minimize criterion kl lambda pij ss converges ss converges lambda criteria asymptotically equivalent prefer weight contribution pij kl divergence image statistics represented ss 
testing real images test images canny edges computed matlab edge function ncut segmentation computed weights learned image 
system learns prefer contiguous groups smooth boundary 
canny edge map indicates simply looking edges gives brittle meaningful segmentations 
detectors 
capture edge strength orientation 
basic information construct features intervening contour ic linearity circularity cl 
feature assumption pixels separated edge belong 
random walk interpretation walk direction perpendicular edge 
intervening contour computed maxk edge line connecting pixel edge edge strength pixel ic provides cue region boundaries edge orientation provides cue object shape :10.1.1.17.8935
human visual studies suggest shape object boundary strong influence objects grouped 
example convex region perceived single object thinking segmentation random walk provides natural way exploiting knowledge 
discrete edge image induces edge flow neighborhood 
bias random walks non edge pixels direction edge orientation 
favor convex regions bias random walk enhancing transition probabilities pixels circular edge flow 
define cl feature gamma cos ffi gamma cos ffj gamma cos ff gamma cos ffi ffj gamma cos ffi ffj defined 
training constructed set bump images varying image contrast shown 
shows learned ic cl check system able pick relevant features introduced cue called rand assigns random connections pixel pair 
learned value rand gamma negligible ic cl real images simple synthetic bump image 
segmentation knowledge learned synthetic images transfer real images 
shows segmentation results weights trained bump image 
see feature local computed small image neighborhoods ncut algorithm built notion contiguity segmentations able produce large contiguous regions smooth boundaries 
suitably chosen local features able achieve meaningful global effects 
numerous efforts area focused grouping discrete edge elements smooth curves 
question remains transfer shape information image region segmentation 
discussion main contribution showing spectral segmentation methods probabilistic foundation 
framework random walks give new interpretation ncut criterion algorithm better understanding motivation 
probabilistic framework allows define principled criterion supervised learning image segmentation 
see supervised learning feasible traditionally unsupervised domain proposing learn combination fixed features 
relatively simple model expect require proportionally little training data 
local features training set may consist synthetic images reproduce feature statistics real images want segment 
arguments supported preliminary experiments theta synthetic noisy image sufficient 
learning alternative current lack principled approach constructing similarity functions 
domains medical imaging cell biology relative importance features clear learning strong potential automatic segmentation 
fan chung 
spectral graph theory 
american society 
drineas ravi kannan alan frieze santosh vempala vinay 
clustering large graphs matrices 
proc 
th acm siam symposium discrete algorithms 
geman geman 
stochastic relaxation gibbs distributions bayesian restoration images 
pami november 
hofmann buhmann 
hierarchical pairwise data clustering mean field annealing 
international conference artificial neural networks 

today early processing visual contours surfaces 
behavioural brain research 
leung malik 
contour continuity region image segmentation 
european conference computer vision 
mumford shah 
optimal approximations piecewise smooth functions associated variational problems 
comm 
pure math pages 
perona freeman :10.1.1.17.8935
factorization approach grouping 
european conference computer vision 
sharon brandt basri 
fast multiscale image segmentation 
ieee conference computer vision pattern recognition 
shi malik :10.1.1.160.2324
normalized cuts image segmentation 
pami 
weiss 
segmentation eigenvectors unifying view 
international conference computer vision 
williams 
comparison measure detecting natural shapes clutter backgrounds 
european conference computer vision 
werman gdalyahu weinshall 
randomized algorithm pairwise clustering 
nips 
