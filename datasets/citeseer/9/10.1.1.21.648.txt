
immersive telepresence virtualized reality constructing virtual worlds real scenes new visual medium virtualized reality viewers virtual reconstruction real world events 
virtualized reality world model consists real images depth information computed images 
stereoscopic reconstructions provide sense complete immersion users select viewpoints view time independent actual camera positions capture event 
different visual media today share shortcomings director decided viewpoints twodimensional views 
virtualized reality immersive visual medium lets viewer select possibly time varying viewing angle view time freely moving virtualized event ways mobile camera event site 
viewer equipped stereo viewing system immersed stereoscopic reconstruction live recorded event 
viewers watch virtualized basketball game seat center court viewpoint moving ball 
virtualized reality virtual reality vr viewer virtual environment 
differ virtual world models constructed 
vr environments typically created simplistic cad models lack fine detail 
virtualized reality contrast automatically constructs virtual model images real world preserving visible detail real world images 
possible ieee takeo kanade peter carnegie mellon university narayanan centre artificial intelligence robotics create realistic virtualized environments complex environments surgery basketball game 
environments lie scope current vr systems 
virtualized reality process involves phases transcribing visual event recovering structure generating synthetic viewpoints 
transcribe visual event cameras surrounding scene 
compute structure event cameras multi camera stereo method 
views compute structure called transcription angles 
stereo process generates depth map encodes scene depth image point corresponding transcription angle 
call combination image aligned depth map scene description 
virtualized model time instant consists collection scene descriptions instant different transcription angle 
time varying event represented collection successive time instants 
scene descriptions translate easily computer graphics models depth maps providing scene geometry images providing scene texture 
novel views virtualized event synthesized easily models graphics hardware 
possible applications virtualized reality include realistic training virtualized space true telepresence imaginative uses entertainment 
example surgical training enhanced virtualizing rare heart surgery 
students observe operation virtualized operating room potentially standing position actual surgeon 
achieve telepresence reconstruction display remote scene occurs simultaneously actual event 
entertainment virtualized reality possible new medium allow viewers watch ballet performance seated edge stage basketball game standing court running particular player 
view synthesis visual reconstruction arbitrary viewpoints important component virtualized reality 
view synthesis view transfer considers visual reconstruction image image mapping designed generate novel views scene real images 
additional knowledge scene imaging process may contribute synthesis 
class view synthesis techniques requires image flow pixel correspondence knowledge points image move image 
information tseng described codec similar mpeg efficiently transmit set discrete viewpoints construct novel views 
view interpolation image rendering technique interpolates image flow vectors images pixel generate intermediate views viewpoint line connecting original viewpoints 
chen williams werner linear interpolation approximation perspective viewing simplicity speed implementation 
seitz dyer demonstrated yields physically valid images source images rectified 
current view interpolation algorithms restrict synthetic view linear space defined viewpoints synthesize views arbitrary viewpoints 
laveau faugeras developed method allows arbitrary viewpoints viewpoint specified terms epipolar geometry respect original viewpoints 
mcmillan bishop kang szeliski constructed cylindrical panoramic images planar images synthesizing new views implicit structure 
existing real time cylindrical imaging systems approach currently extended time varying imagery 
multiple perspective interactive mpi video attempts give viewers control see different approach 
method computes environments view generation combining priori environment models dynamic motion models recovered intersecting viewing pixels indicate motion 
second class view synthesis techniques eliminates need pixel correspondences densely sampling viewing space possibly interpolating missing views 
katayama demonstrated possible generate images arbitrary viewing positions dense set images plane 
satoh property develop prototype image display system motion parallax 
similar methods proposed lightfield rendering levoy hanrahan lumigraph gortler methods convert views dimensional field representing light rays passing surface 
new view generation posed computing correct cross section field 
methods require full calibration input view generate correct synthetic views viewpoint outside convex hull scene 
introduced virtualized reality preliminary results earlier 
article presents results virtualizing facility provides coverage presently consisting cameras mounted geodesic dome meters diameter 
dome virtualizing studio virtualizing studio facility making virtualized models 
studio dome events angles capture scene structure 
studio provide accurate scene structure video field th second ntsc time varying event 
structure recovery studio captures frame video stream maintaining synchronization images taken time instant different cameras 
synchronization crucial correctly virtualize time varying events stereo structure extraction process assumes images different viewpoints correspond static scene 
section provides brief overview actual system 
detailed discussion setup synchronous multi camera image acquisition system 
studio setup shows conceptual virtualizing studio shows dome studio built geodesic dome meters diameter 
cameras placed nodes centers bars dome providing views angles surrounding scene 
currently monochrome cameras equipped mm lens wide view degree 
virtualized reality studio conceptual dome 
january march 
captured images compute scene descriptions 
ieee multimedia horizontal field view dome 
color cameras provide realistic virtualization higher costs 
synchronous multi camera image acquisition synchronous digital acquisition video streams difficult task single monochrome camera providing images second image captured digitally contain bit pixels represents bandwidth mbytes second 
sustained bandwidth store video streams secondary storage device exceeds capabilities typical image capture digital storage systems best lossless compression technology available today 
example current system sun sparc workstation standard gbyte hard drive digitizer capture store kbytes second 
specialized hardware improve throughput cost level unsuitable replication 
overcome limitations perform digital acquisition steps real time recording line digitization 
recording system uses standard ccd cameras consumer grade vcrs 
cameras electronically synchronized common sync signal 
field camera video output time stamped common vertical interval time code recorded video tape 
hardware part system runs real time allowing con capture long motion sequences 
tapes digitized individually line 
computer program interprets time code field real time tape plays 
list frames capture digitizing program captures list 
tape goes past required frame computer starting frame replays tape repeats process 
realtime interpretation helps identify frames missed previous passes guaranteeing capture unique frames repetition 
experience passes suffice capture frame transfer fourth frame video stream computer memory 
time code field captured image serves synchronize fields frames different cameras 
shows frame seen cameras virtualizing studio digitized setup described 
separate report gives details synchronous multi camera recording digitizing setup 
computing scene descriptions scene descriptions analogous sketch marr paradigm encodes geometric photometric structure surfaces visible specific location 
stereo technique compute geometric structure location coincides location camera stereo computa tion 
images limited field view geometric extent scene description limited viewing frustum camera 
transcription angle include orientation position 
clearly distribution transcription angles important quality virtualized reconstruction event 
distribution transcription angles rendering strategy uses scene description precisely textured triangle mesh model derived description fundamental unit structure 
transcription angle specifies location orientation scene description 
model scene description synthesize appearance surfaces arbitrary viewing positions 
virtual camera moves away corresponding transcription angle quality reconstruction decreases occlusion errors recovered structure 
minimizing distance desired viewpoint real camera maximize quality synthesized images 
behavior implies transcription angle density uniform high maximize output quality 
fact high density eliminates need correspondences allowing direct interpolation images algorithms lumigraph light field rendering 
problem techniques density camera views easily extremely high 
example levoy hanrahan images compute light field single scene 
dynamic scenes require views captured simultaneously amount hardware strategy impractical 
way trade number transcription angles quality reproduction 
number cameras sets upper limit number transcription angles angle requires real view scene 
cameras provide transcription angles camera distribution satisfy constraints transcription angle distribution 
factor determining camera distribution stereo usually fewer mistakes cameras moved closer 
expected cameras obtain transcription angles selected number cameras meet criteria 
initial experiments described article transcription angles view synthesis process intend investigate economy representation 
camera clusters compute stereo cameras cameras providing baselines required multi baseline stereo mbs 
cameras improves extent accuracy stereo long features camera successfully matched features cameras 
matching gets increasingly difficult viewing angle differs 
arbitrarily adding cameras provides little improvement stereo accuracy increasing computational cost 
immediate neighbors depending specific camera setup camera stereo computations 
neighbors camera available directions 
modified original formulation mbs handle cameras 
free place cameras orientation 
camera calibration stereo programs require fully calibrated cameras extract structure metric units 
calibrate intrinsic extrinsic camera parameters tsai approach modified implemented reg 
steps arrangement cameras adapt simultaneous calibration procedure involving cameras calibration parameters 
calibrate camera intrinsic parameters affect projection points camera coordinates image plane individually movable planar calibration object 
calibration process estimates intrinsic parameters focal length image center parameters aspect ratio radial lens distortion parameter 
place cameras positions dome calibrate extrinsic parameters rotation translation relative world coordinate frame set dots floor visible cameras 
world coordinate frame rooted floor case 
multi baseline stereo adapted mbs algorithm developed okutomi kanade general camera configuration cameras incorporating tsai camera model 
factors january march ieee multimedia 
scene description image 
intensity image 
aligned depth map 
primarily motivate choice mbs 
mbs recovers dense depth maps depth estimate pixel intensity image 
second mbs takes advantage large number cameras improve depth estimates 
understand mbs algorithm considering camera stereo parallel cameras focal length perpendicular distance scene point related disparity difference image locations scene point bf baseline distance camera centers 
precision estimated distance increases baseline cameras increases 
increasing baseline increases likelihood matching points incorrectly 
correctness correspondence depends image aperture problem difficult localize features parallel camera baseline 
mbs attempts improve matching computing correspondences multiple pairs images different baseline 
disparities meaningful pair images reformulate equation relate correspondences multiple image pairs bf search correspondences performed respect inverse depth meaning image pairs camera independent disparities baselines 
resulting correspondence search combines correct correspondence narrow baselines precision wider baselines 
effect image features orientation respect baselines mitigated baselines oriented multiple directions 
popular method compute correspondences pair images compares small window pixels image corresponding windows image 
correct position window second image constrained camera geometry lie epipolar line position image 
matching process pair images involves shifting window line function computing match error normalized correlation sum squared differences window position 
mbs combines error estimates camera pair computing sum finding minimum error 
inverse depth minimum 
window correspondence searches localize matches regions low image texture depth discontinuities incorporated interactive depth map editor process structure extraction 
step roughly compared movie editing critical virtualizing process 
currently exploring improvements stereo algorithm step unnecessary 
shows edited depth map computed mbs aligned image images shown 
farther points depth map appear white 
view generation virtualize event number scene descriptions 
part virtualized reality deals synthesizing scene angle scene descriptions 
translate scene description textured triangle mesh 
synthesize new views rendering mesh create novel views scene 
process takes advantage capabilities graphics workstations specialized hardware render texture map polygon meshes 
silicon graphics workstations onyx re render texture mapped triangles second rendering platform suffice 
describe new views synthesized single scene description view generated single scene description lower quality virtual viewpoint moves pixel grid triangle vertex texture coord vertex texture coord vertex texture coord away transcription angle corresponding scene description 
describe scene descriptions improve quality synthesized image 
method traversing virtualized space directions transcription angles 
synthesizing views scene description aspects view generation scene description object definition occlusion handling 
object definition process converting scene description textured triangle mesh model 
simple method object definition construct large surface passes points depth map 
real scenes frequently contain independent objects may occlude introduce method handle occlusions 
object definition 
steps defining object scene description converting depth coordinates constructing triangle mesh coordinates describe surfaces visible transcription angle 
converting depth coordinates simple transformation depth values give coordinates coordinate system surface points pixel 
compute coordinates camera intrinsic parameters determine viewing ray ray emanating camera center passing pixel intersect ray plane distance read depth map 
apply camera extrinsic parameters convert camera centered position position common world coordinate frame 
convert points sur coordinates point coordinates image point triangle triangle triangle vertex texture coord vertex texture coord vertex texture coord face representation 
treat points vertices triangle mesh changes task selecting connectivity points 
general problem solutions case know just locations vertices know project image plane 
local connectivity points corresponding projections image plane 
task reduces selecting local connectivity image plane simpler problem general 
addition exploit regular pixel grid guide connectivity process image projections points lie exactly pixel grid 
information apply simple pixel connectivity rule convert pixel area triangles adding diagonal shown 
remaining question approach diagonal select decision affects local surface properties mesh 
mesh sampled extremely finely visible impact decision small select diagonal 
texture apply triangle easily obtained pixel coordinates triangle vertices 
simple strategy object definition important features 
coordinates quickly easily extracted depth map calibration parameters 
second resulting model little surface interpolation data points faithfully reproduces exact structure inherent depth map 
fact implies model essentially specialized rendering hardware efficient way perform geometrically correct view synthesis fundamentally eliminating 
triangle mesh texture coordinate definition 
january march 

phantom surfaces depth discontinuity 
holes appear phantom surfaces removed 
merged view scene description fill holes 
ieee multimedia geometric distortions may exist purely correspondence view interpolation 
major drawback method generates triangles depth map size resulting object simple regular making suitable efficient rendering graphics workstations 
addition resulting mesh simplified easily applying standard mesh decimation algorithms 
experiments reduction factor achieved significant loss quality 
occlusion handling 
scene description encodes structure scene visible transcription angle 
object definition method just discussed implicitly assumes continuous surface visible transcription angle 
assumption violated model contain additional phantom surfaces bridge depth discontinuities real surfaces seen 
model perfect phantom surfaces cause rendered view visually unrealistic viewing angle moves farther transcription angle 
avoid phantom surfaces eliminating triangles large depth discontinuities edge 
results holes seen 
holes correspond areas visible transcription angle 
behavior desirable scene description encodes information visible scene structure 
merging multiple scene descriptions holes views synthesized single scene description correspond physically regions occluded transcription angle 
cases regions visible scene descriptions transcription angles 
scene descriptions fill holes improve visual realism synthetic views 
rendering strategy uses additional scene descriptions purpose 
complete approach uses scene descriptions construct synthetic image 
scene description corresponds transcription angle closest desired synthetic viewpoint 
scene descriptions hole filling called supporting scene descriptions 
develop number methods merge multiple scene descriptions 
example merge different views single model 
goal construct synthetic image developed simpler merging strategy works renderings objects defined scene descriptions 
strategy requires merging making faster simpler merging 
synthesize desired view scene description 
identify hole pixels render separately triangles eliminated large depth variation 
synthetic view re rendered supporting scene descriptions rendering limited hole pixels 
example shows results filling holes supporting view 
notice background right shoulder person filled properly 
holes remaining image correspond portion scene occluded supporting transcription angles 
insightful compare algorithm simpler identifies hole pixels finding pixels touched rendering objects scene description 
strategy appealing simplicity eliminated triangles need rendered 
certain conditions strategy avoids filling regions obviously incorrect 
example scene description see person right shoulder synthesized view fills region pixels background 
simpler merging strategy allow supporting view correct pixels resulting obvious error synthesized output 
selecting transcription angle 
view generation strategy exhibits highly desirable property synthesized view exact hole free desired view coincides transcription angle arbitrary errors calibration depth estimation 
addition general scene quality view synthesized single scene description deteriorates viewing angle moves away transcription angle 
happen ideal models foreshortening 
virtual camera viewpoint tr tr consider example scene containing single receding plane viewed transcription angle 
foreshortening image scene texture resolution far parts plane near parts 
structure scene recovered perfectly texture provided single scene description forced expand virtual camera moves view plane 
properties suggest transcription angles synthesize virtual image close possible desired viewpoint 
despite simplicity finding definition close general highly complex problem possibility occlusion 
intuitively expect usefulness transcription angle increase virtual camera moves closer physical space 
transcription angle limited field view intuitive metric insufficient 
direction gaze clear problems 
potentially serious problems due occlusion arise combine metrics 
example virtual camera close real transcription angle oriented direction desired viewpoint lie visible surfaces scene description desired viewpoint lie region occluded transcription angle 
result transcription angle poor choice synthesizing image 
metric evaluate closeness virtual viewpoint transcription angle assumptions distribution placement orientation field view transcription angles general regions interest typical scene 
viewing direction virtual camera specified terms eye point target point 
virtual camera situated eye point oriented line sight passes target point 
measure closeness angle line sight line connecting tr tr transcription angle virtual camera viewpoint tr target point tr target point position transcription angle shown 
measure works virtual viewpoint transcription angles point general region space 
system assumption transcription angle true design tends focus user attention region 
selecting supporting transcription angles 
supporting angles compensate occlusion description 
general problem covering occlusions transcription angles relates convex covering problem general solutions 
configuration transcription angles possible construct scene certain surfaces occluded transcription angles 
frequently possible obtain adequate coverage occluded regions concentrating neighbors transcription angle especially transcription angles densely distributed 
consider triangles formed locations transcription angle adjacent pairs neighbors 
transcription angle neighbors 
selecting transcription angle 
angle virtual camera line sight line joining target point position transcription angle tri 
select transcription angle tri smallest angle transcription angle 
tr target point 
selection supporting transcription angles 
transcription angle determine supporting angles enumerating neighboring angles tri forming triangles containing transcription angle neighbors 
triangle line sight virtual camera determines supporting angles 
january march 
baseball bat swing baseball point view 
ieee multimedia hit 
ball high away triangles 
determine triangles line sight virtual camera 
non transcription angles form triangle selected supporting transcription angles 
approach supporting views surround desired viewpoint essentially reducing view synthesis process interpolation intermediate viewpoint real views 
experimental results examples real data including static dynamic scenes 
earlier sections computing scene descriptions generating new views discussed static scene analysis extension dynamic scenes straightforward 
recall video simply sequence images sampled displayed fast give illusion continuous motion 
exploiting phenomenon environment apply static scene analysis sample time varying event create illusion continuous scene ball approaches time motion continuous user controlled viewpoint 
note examples nature best seen movie 
find movies project web page www cs cmu edu groups 
ball eye view virtual camera move virtualized environment interfering scene possible maneuver camera paths impossible real world 
demonstrate capability reconstructed flight virtual baseball thrown hit 
real images images explain various components virtualized reality come dynamic sequence person swinging baseball bat 
collected image sequences initial hardware configuration cameras recall camera views time instant appear 
distributed cameras clusters cameras computed stereo single camera cluster resulting transcription angles 
virtual images show trajectory ball pitched hit bat knocked high hit baseball terms popup 
transcription angles mm mm away baseball bat point virtual camera closest approach image labeled hit virtual camera approximately mm away bat 
images demonstrate synthetic output qualitatively correct large change depth 
distortions example result sources 
fundamentally real images limit texture resolution virtual camera moves scene texture mapping may zoom available resolution 
second scene structure limited quality camera calibration correspondence estimation available image resolution affects stereo 
movement camera deep scene highlights inaccuracies computed scene structure 
system transcription angles viewpoints physically separated meters representing rotation nearly degrees person 
having views leaves holes synthetic output wide separation views requires accurate surface reconstruction maintain consistency structure transcription angles 
virtual camera versus real camera virtualized reality seeks provide believable views scene times requires internal consistency necessarily consistency real world 
example explores difficult case requiring faithful accurate reconstruction 
compare virtual view generated virtualized reality real camera placed location sees frames golf swing 
scene captured transcription angles cameras cluster located world coordinate frame units millimeters 
person approximately mm away transcription angles 
shows virtual real camera views located near middle transcription angles 

comparing generated views views located near middle transcription angles 
views real camera top row 
views generated positions virtualized reality bottom row 
january march 
comparing generated views real camera views located far transcription angles 
views real camera top row 
views generated positions virtualized reality bottom row 

views path static scene 
ieee multimedia virtual real camera position significantly far transcription angles directions 
gap back person neck corresponds region occluded transcription angles 
virtual camera view quite faithful real camera view errors recovering structure show prominently virtual camera far transcription angles 
note scene processed full image frames contains image fields taken different times clearly visible real images golf club example 
compensation effect recovered struc ture sufficient produce realistic output 
view noted examples early setup studying virtualized reality consisted transcription angles 
subsequently expanded setup transcription angles virtualize event directions 
expected increase number transcription angles improve synthetic image quality ways 
views expected hole filling better select transcription angles render scene 
second cameras closely spaced reducing space transcription angle required assist rendering 
cameras surrounded scene viewer move nearly scene see reasonable reconstruction 
demonstrate updated system simple static scene person sitting table 
shows views scene virtual camera winding dome 
expected number unfilled pixels dropped significantly 
remaining holes occur virtual camera moved real transcription angles requires extrapolation interpolation scene descriptions supporting transcription angles 
significant errors detectable output 
ghosting effect shadow person 
occurs holes rendering scene description 
results inconsistencies video gain offset levels camera 
bright camera supporting angle dark camera correctly matched regions exhibit significant differences apparent brightness 
problem compounded absolute intensity received real surface usually varies viewing angle system currently model effect 
second error really discernible set static renderings inaccuracies reproducing motion parallax 
virtual camera moves static scene viewer expects see continuous motion virtual image sequence actual virtual image motion exhibits occasional discontinuities 
occurs transcription angle switches may reveal inconsistencies structures recovered angles 
combining virtual virtualized environments virtualized environment metric description world introduce virtual objects 
virtual ball example introduced virtualized baseball scene shown 
note rendering virtual object performed synthesis virtual camera image objects concurrently virtual objects 
approach extend uses fixed background color segment region interest real video stream insert video stream 
depth perform keying combines multiple streams depth color 
fact simulate shadows virtual object virtualized scene vice versa improving output image realism 
examples prove useful interesting applications virtualized reality just corner 
intend pursue possibilities coming months 
plan integrate stereoscopic display head tracking give viewers feeling true immersion scene 
open issue concerns combined effect imperfect calibration correspondence finding mesh generation 
experiments reveal clear need improve rendering system resilient inaccuracies 
affect filling holes motion parallax synthesized output dynamic property received attention view synthesis community past 
addition clear systems cameras require synthesis algorithms capable handling images varying brightness prevent ghosts holes image synthesized transcription angle 
research effort currently way involves creating object centered models scene merging scene descriptions 
approach merging scene description voting presence absence surfaces world depth map transcription angle 
contribution depth map providing significant degree robustness presence noise depth maps 
final model recovered triangulating isosurface extracted merged voxel space providing model scene 
introducing virtual ball virtualized scene 
january march 
model right computed merging depth maps shown aligned actual camera view left 
ieee multimedia 
recovered structure possible accumulate texture intensity images 
virtualizing facility opens possibilities interesting research areas 
example view generation strategies image rendering view interpolation particular studied compared depth map view generation 
extend capabilities virtualized reality viewer interact virtualized world 
instance modeling scene collection distinct objects lets viewer manipulate position appearance independently 
intend pursue directions near 
mm 
okutomi kanade multiple baseline stereo ieee trans 
pattern analysis machine intelligence vol 
pp 


tseng video coding mpeg compatibility ieee trans 
circuits systems video technology vol 
aug pp 


chen williams view interpolation image synthesis proc 
siggraph acm press new york pp 


werner rendering real world objects view interpolation proc 
ieee int conf 
computer vision ieee cs press los alamitos calif pp 


seitz dyer physically valid view synthesis image interpolation ieee workshop representation visual scenes ieee cs press los alamitos calif pp 


laveau faugeras scene representation collection images proc 
th int conf 
pattern recognition ieee cs press los alamitos calif vol 
pp 


mcmillan bishop plenoptic modeling image rendering system proc 
siggraph acm press new york pp 


kang szeliski scene data recovery omnidirectional stereo proc 
ieee computer vision pattern recognition cvpr ieee cs press los alamitos calif pp 

appear int computer vision 

jain multiple perspective interactive video proc 
ieee conf 
multimedia computing systems ieee cs press los alamitos calif pp 

katayama viewpoint dependent stereoscopic display interpolation images spie proc 
vol 
stereoscopic displays virtual reality systems ii spie bellingham wash pp 

satoh ohta image display motion parallax camera matrix stereo proc 
ieee conf 
multimedia computing systems ieee cs press los alamitos calif pp 

levoy hanrahan light field rendering proc 
siggraph acm press new york pp 

gortler lumigraph proc 
siggraph acm press new york pp 

kanade narayanan virtualized reality concept early results proc 
ieee workshop representation visual scenes ieee cs press los alamitos calif pp 

narayanan kanade synchronizing capturing frame multiple cameras tech 
report cmu ri tr robotics institute carnegie mellon univ 
tsai versatile camera calibration technique high accuracy machine vision metrology shelf tv cameras lenses ieee robotics automation vol 
ra aug pp 

kanade stereo machine video rate dense depth mapping new applications proc 
ieee computer vision pattern recognition cvpr ieee cs press los alamitos calif pp 

takeo kanade helen whitaker professor computer science robotics director robotics institute carnegie mellon university 
received phd electrical engineering kyoto university japan 
fellow ieee founding fellow american association artificial intelligence founding editor international journal computer vision 
received marr prize joseph award served government industry university advisory committees including aeronautics space engineering board national research council 
peter phd candidate electrical computer engineering carnegie mellon university 
received bee university detroit ms carnegie mellon 
research interests include computer vision computer graphics virtual reality 
received award best applications international conference multisensor fusion integration intelligent systems 
narayanan scientist centre artificial intelligence robotics cair bangalore india 
received bs iit phd computer science university maryland 
faculty member robotics institute carnegie mellon 
research interests include computer vision virtual reality computer graphics parallel processing 
contact robotics institute carnegie mellon university smith hall pittsburgh pa mail cs cmu edu 
