modeling combining rendering dynamic real world events image sequences peter saito takeo kanade robotics institute carnegie mellon university virtualized reality creates model time varying real world events image sequences 
model manipulating combining events rendering new virtual images 
enhancements virtualized reality 
model enhanced stereo mes method widely separated images iteratively improve quality local stereo output multi camera system 
show example virtualized reality models different events integrated synthetic virtual model 
addition develop new calibration method allows simultaneous calibration large number cameras visibility problems 
method goes capturing real image sequences integrating events static time varying virtual model virtual image sequence generation 
methods obtaining graphics models real objects studied 
large amount focused recovery dimensional shape models range images obtained direct range scanning hardware image shape reconstruction techniques 
image modeling seen significant development set real images implicitly represent object scene 
developing algorithms build static models relatively small objects 
goal reconstruct dynamic models larger objects real events represented virtual world 
modeling dynamic events requires multi camera video capture system typical setup including turntable single camera modeling small static objects 
virtualized reality system demonstrated ability recover dynamic dimensional geometric models scene multiple human sized objects 
early versions system stereo manual intervention compute structure dimensional image rendering method synthesize novel views 
incorporated volumetric integration algorithm create unified model scene 
due inaccuracies calibration stereo matching models contained errors recovered geometry 
presents enhancements system model refinement enhanced stereo ability integrate multiple events virtual reality model improved calibration method 
propose model enhanced stereo mes iteratively uses dimensional model obtained merging range images cameras improving stereo depth estimates camera 
show example virtualized reality models different events integrated synthetic virtual model 
addition improve accuracy camera calibration developed calibration system densely spaced calibration points spread volume interest simultaneously viewed cameras 
show precise silhouette information refine shape model 
system overview multi camera system virtualized reality shown 
designed imaging human sized dynamic event omni directionally distributed video cameras 
time instant run multi baseline stereo camera obtain set range images 
range images merged volumetric model iso surface extraction run resulting model produce polygonal mesh 
mesh texture mapped lets synthesize virtual images arbitrary viewpoints 
explains detailed dataflow system 
processing cameras calibrated relate coordinates image plane camera coordinates scene 
system including produces full virtualized reality dome camera configuration cameras distributed hemispherical structure meters diameter model scene imaged needs strong calibration method knowledge exact mapping scene image coordinates 
calibrating volume cubic meters accurately respect cameras directions poses challenges volumetric integration volumetric integration cam cam 
cam multi baseline stereo range image merging volumetric data sequence iso surface extraction triangle mesh sequence image sequences range image sequences re projection reprojected range image sequence improved stereo range image merging refined range image sequence refined volumetric data sequence iso surface extraction refined triangle mesh sequence re projection reprojected range image sequence masking fg bg mask image sequence free space carving block diagram dataflow system carved volumetric data sequence iso surface extraction carved triangle mesh sequence tri mesh smoothing decimation texturing textured triangle mesh sequence ity constraints 
standard calibration patterns markers viable solution need cameras simultaneously view marked points 
volume space calibrated cubic meters large bound create problems visibility cameras 
known inaccuracies calibration affect subsequent stereo matching process search typically limited epipolar line 
merging range images euclidean model affected neighboring cameras vote differently location point scene 
global texture mapping process affected inaccuracies similar fashion 
overcome challenges new large volume calibration method 
calibrated bar markers known positions swept space grid points defined calibrate cameras 
built thin meter horizontal bar leds mounted cm apart 
floor calibrated markers cm apart dimensions vertical motion bar mounted 
bar swept vertically perpendicular length precise coordinates points known 
points imaged cameras image locations determined simple dot detection bar thin visibility problem 
addition availability dimensional calibration data earlier systems allows combine extrinsic intrinsic calibration steps 
grid points corresponding image locations available known nonplanar calibration algorithm tsai estimates radial distortion addition extrinsic intrinsic parameters implementation robust 
model refinement enhanced stereo silhouette information multi baseline stereo searches matches neighboring images different levels disparities yields range images 
volumetric model obtained sensor fusion somewhat noisy range images 
inaccuracies model incorrect stereo results problems insufficient texture object may result identical matches widely separated disparity values 
second algorithm uses window match regions images best match result window position partially overlaps silhouette object 
method refine volumetric model limiting errors enhanced iteration stereo process 
model converted polygonal mesh representation projected virtual cameras corresponding location original cameras 
gives approximation silhouette object depth value pixel 
projected depth iterate multi baseline stereo process imposing tighter bounds range disparity values searched pixel 
iteration produces accurate depth estimates addition eliminating large number false matches initial individual stereo may contain 
contour bounding projection gives estimate exact silhouette object ensure stereo window overlap edges object iteration matching process 
call method limiting search space depth window bounds model enhanced stereo mes 
shows result initial stereo depth viewpoint shows depth estimated mes 
see estimates depth accurate far noisy 
results mes various viewpoints merged yield significantly accurate volumetric model 
procedure may repeated improve accuracy model 
mes helps segment model objects environment dome floor volumetric merging range images mes gives euclidean coordinates 
knowing approximate location bounds objects easy eliminate volumes outside bounds discontinuous objects 
methods lumigraph voxel coloring able plane background chroma key technique image space separate foreground objects background 
separation propagated model 
chroma key usually fairly accurate fails omnidirectional imaging system uniform lighting impossible lights visible cameras 
range image initial multi baseline stereo range image model enhanced stereo volumetric model obtained merging mes results cameras volumetric model carving exact silhouettes implementation silhouettes carve free space volumetric model directly post processing stereo algorithm 
refined volumetric model projected input camera get approximation actual silhouette 
snake algorithm lock exact contour approximation template human operator modify silhouette visual accuracy 
shows volumetric model obtained result merging multiple mes range images 
shows model refined knowledge exact contour 
exact silhouettes need specified images example find specifying silhouettes original images suffice 
combining multiple dynamic virtualized reality events virtual sets possible combine volumetric models multiple events spatial temporal manner events recorded separately possibly different locations 
models transformed single unified ordinate system temporal components matched ensure combined model correct length sequence 
show example events humans laboratory dribbling passing ball integrated virtual basketball court produce virtual basketball play sequence 
integration volumetric models texture mapped intensity images various cameras 
volumetric models discretized metric descriptions surface texture maps manipulated way traditional graphics models added vr system uses polygon rendering 
virtualized reality models textured cad models interact natural manner 
volumetric model frame event players volumetric model second event player volumetric model obtained combining events spatially create event players combining multiple events single virtualized reality representation convert virtualized reality models different events single representation combined aligned spatially 
achieve rotation translation applied models origin local ordinate space mapped location world origin desired orientation 
models typically triangle mesh list vertex coordinates texture coordinates polygon connectivities 
vertex coordinates models defined independently respect local coordinate system 
hand temporal integration model sequences involves deter sequence combined volumetric models time instant superimposed effect motion seen similar time lapse photograph mining sequences related time 
sequences modeled frame rate desired virtual sequence sequences need subsampled appropriately 
non integral multiples temporal interpolation models called 
done time frame motion sequence needs mapped frame global time scale 
mapping component image sequences global time scale component events overlapped concatenated 
addition individual frames sequence may reverse 
example separate events recorded 
event shown involves players player bounces basketball passes side attempts block pass 
second event shown involves single player receives basketball ball 
free choose frames reverse recorded second event having player dribble throw ball side easier 
events recorded separately camera sees players 
events combined final model contains motion sequence player passes ball third player second player attempts block pass 
done spatial transform places ball frame event coincide position ball second event concatenation events time 
polygonal model frame event modified ball removed 
edit prevents balls appearing scene 
result combining events shown 
shows number volumetric models combined events superimposed pass happens 
effect produced similar seen time lapse photograph scene moving objects 
combining virtualized reality representation virtual model virtualized reality representation metric description event introduce virtual models representation 
virtualized reality models combined section sequence polygonal meshes textured introduced cad model virtual basketball court generate unified geometry texture representation 
shows sequence rendered images combined model simulate 
virtual camera spirals players pointed 
sequence virtual images captures spatial motion virtual camera dynamic event 
case virtual model basketball court static imagine case virtualized reality model combined timevarying virtual event 
enhancements virtualized reality system 
model enhanced stereo iteratively improves accuracy stereo correspondence model built initial stereo results 
improvement achieved fact images obtaining stereo correspondences camera 
showed real events combined virtual space 
improve accuracy camera calibration developed new calibration system allows simultaneous calibration cameras visibility problems 
virtualized reality system provides new capability creating virtual models dynamic events involving large free form objects humans 
addition modeling capability produce synthetic video varying virtual viewpoint 
sys separate dynamic events players single player combined cad model virtual basketball court 
sequence images seen virtual camera moves spiral trajectory players upwards 
notice event dynamic camera motion happens course play tem goes capturing real image sequences creating virtualized reality models observed sequences integrating events static time varying vr model virtual image sequence generation 
involves development abstractions represent recovered geometry image modeling representations 
representations projective shape models depth correspondence maps local virtual viewpoint facilitate rendering virtual views explicitly recovering full volumetric model 
chen williams 
view interpolation image synthesis 
proc 
siggraph pp 
curless levoy 
volumetric method building complex models range images 
proc 
siggraph pp 
gortler grzeszczuk szeliski cohen 
lumigraph 
proc 
siggraph pp 
hilton 
reliable surface reconstruction multiple range images 
proc 
eccv 
kang szeliski 
scene data recovery omnidirectional stereo 
international journal computer vision pp 
kass witkin terzopoulos snakes active contour models international journal computer vision pp 
laveau faugeras 
scene representation collection images 
proc 
icpr pp 
levoy hanrahan 
light field rendering 
proc 
siggraph pp 
liedtke koch shape adaptation modeling objects natural scenes proc 
cvpr pp 
lorensen cline 
marching cubes high resolution surface construction algorithm 
proc 
siggraph pp 

okutomi kanade 
multiple baseline stereo ieee trans 
pattern analysis machine intelligence 
pami pp 
narayanan kanade recovery dynamic scene structure multiple image sequences 
proc 
ieee multisensor fusion integration intelligent systems pp 

narayanan kanade virtualized reality constructing time varying virtual worlds real world events 
proc 
ieee visualization pp 
seitz dyer view morphing proc 
proc 
siggraph pp 

seitz dyer photorealistic scene reconstruction voxel coloring proc 
ieee cvpr pp 
tsai 
versatile camera calibration technique high accuracy machine vision metrology shelf tv cameras lenses 
ieee trans 
robotics automation ra pp 

werner 
rendering real world objects view interpolation 
ieee international conference computer vision boston pp 
wheeler sato ikeuchi consensus surfaces modeling objects multiple range images darpa image understanding workshop pp 

