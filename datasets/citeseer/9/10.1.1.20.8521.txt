machine learning kluwer academic publishers 
manufactured netherlands 
selective sampling query committee algorithm yoav freund yoav research att com labs florham park nj sebastian seung seung bell labs com bell laboratories lucent technologies murray hill nj eli shamir naftali tishby shamir tishby cs huji ac il institute computer science hebrew university jerusalem israel editor david haussler 
analyze query committee algorithm method filtering informative queries random stream inputs 
show member committee algorithm achieves information gain positive lower bound prediction error decreases exponentially number queries 
show particular exponential decrease holds query learning perceptrons 
keywords selective sampling query learning bayesian learning experimental design 
research theory learning random examples paradigm learner trained tested examples drawn random distribution 
paradigm learner passive control information receives 
contrast query paradigm learner power ask questions 
learner gain additional power 
study queries learning valiant angluin concentrated algorithms exact identification target concept 
type analysis concentrates worst case behavior algorithm probabilistic assumptions 
contrast interested algorithms achieve approximate identification target analysis probabilistic assumptions 
assume examples target concept chosen randomly 
particular show queries help accelerate learning concept classes learnable just unlabeled data 
question previously studied eisenberg rivest pac learning framework 
give negative result show natural set concept classes call dense queries essentially useless 
show giving learner ability ask membership queries questions type label point context enable learner significantly reduce total number labeled examples needs observe 
reason learner observes small number examples passively actively sensitive freund seung shamir tishby slight changes target concept underlying distribution 
adversary alter distribution target way cause learner change hypothesis increase error hypothesis significant way 
show concept classes dense learned efficiently allow learner access random unlabeled examples 
added capability enables learner maintain sensitivity input distribution reducing number labels needs know 
baum baum proposed learning algorithm uses membership queries avoid intractability learning neural networks hidden units 
algorithm proved networks hidden units experimental evidence baum lang works larger networks 
baum lang tried algorithm train network classifying handwritten characters encountered unexpected problem baum lang 
problem images generated algorithm queries contain recognizable character artificial combinations character images natural meaning 
learning algorithm analyzed uses random unlabeled instances queries way may avoid problem encountered baum algorithm 
lines described queries explicitly constructed 
contrast derived query filtering paradigm 
paradigm proposed cohn atlas ladner learner access stream inputs drawn random input distribution 
learner sees input chooses query teacher label 
giving learner easy access unlabeled random examples reasonable assumption real life contexts 
applications speech recognition case collecting unlabeled data highly automatic process finding correct labeling data requires expensive human 
algorithm uses unlabeled examples way overcomes problems pointed rivest eisenberg 
learning interactive process requesting human label examples advance computer choose examples labels informative 
initially examples informative learner process continues prediction capabilities learner improve discards examples non informative saving human teacher large amount 
cohn atlas ladner suggestions query filters empirical tests performance simple problems 
seung opper sompolinsky authors suggested filter called query committee qbc analytically calculated performance perceptron type learning problems 
problems prediction error decreases exponentially fast number queries 
complete general analysis query committee show exponential decrease guaranteed general class learning problems 
problem selecting optimal examples learning closely related problem experimental design statistics see 
fedorov atkinson 
experimental design analysis methods selecting sets experiments correspond membership queries context learning theory 
goal selective sampling query committee design select experiments way outcomes correspond labels give sufficient information constructing hypothesis maximizes criterion accuracy 
natural criterion accuracy parameters define hypothesis estimated lindley 
context bayesian estimation general measure quality query reduction entropy posterior distribution induced answer query 
similar suggestions perceptron learning literature 
different experimental design criterion accuracy outcome experiments chosen constrained domain predicted hypothesis 
criterion similar criteria learning theory 
criteria important 
show general case necessarily related related case query committee algorithm 
relation prove efficiency algorithm specific concept classes 
results restricted limited set learning problems 
main restriction concepts assumed deterministic noiseless 
summary list think natural extensions analysis 
organized follows 
section bayesian framework learning analyze algorithm 
section simple learning problems demonstrate case information gain query relevant criterion interested prediction quality 
section describe query committee algorithm 
section prove close relation information gain prediction error qbc 
relation show section prediction error decreases exponentially fast number queries natural learning problems 
section give broader view unlabeled examples accelerating learning section summarize point potential directions 

preliminaries bayesian model concept learning haussler kearns schapire 
pac model denote arbitrary sample space distribution defined 
concentrate case euclidean space concept mapping concept class set concepts 
bayesian model differs pac model assume target concept chosen prior distribution distribution known learner 
shall notation pr denote probability event chosen random assume learning algorithm access oracles sample label 
call sample returns unlabeled example chosen unknown distribution call label input returns label target concept 
making calls oracles learning algorithm required output hypothesis 
define expected error learning algorithm probability probability taken respect distribution choice distribution choice freund seung shamir tishby random choices part learning algorithm calculation hypothesis shall usually denote number calls algorithm sample number calls label goal give algorithms achieve accuracy making calls sample log calls label 
analysis find convenient view finite number instances observed learning algorithm initial segment infinite sequence examples drawn independently random shall denote sequence unlabeled examples 
denote sequence labeled examples generated applying denote sequence elements terminology mitchell define version space generated sequence labeled examples set concepts consistent denote version space corresponds labeled examples 
initial version space equal version space representation information contained set labeled examples observed learning algorithm 
natural measure progress learning process rate size version space decreases 
instantaneous information gain ith labeled example particular sequence examples defined log pr pr 
summing instantaneous information gains complete sequence examples get cumulative information gain defined 
log pr pr log pr 
natural measure information expect gain label unlabeled example expected instantaneous information gain taken respect probability labels occurs 
probability label xm vm version space results label xm 
define corresponding way case 
define expected information gain log pr pr log pr pr log log denotes shannon information content binary random variable probability shall log base definition measure expected information gain bits 
maximal information gain single label bit 
information gain attractive measure gain expected asking label label example 
show section measure sufficient guaranteeing large reduction expected prediction error algorithm 
gibbs prediction rule predict label new example picking hypothesis random version space labeling 
random selective sampling query committee choice prior distribution restricted version space 
simple observation see haussler kearns schapire expected error prediction error twice larger expected error optimal prediction rule bayes rule 
shall assume learning algorithm access oracle denoted gibbs compute gibbs prediction example version space time gibbs called hypothesis chosen random distribution restricted label returned 
note calls gibbs result different predictions 
main result simple algorithm learning queries uses gibbs prediction rule learn important concept classes accuracy exponentially small number calls label 

simple learning problems section discuss simple learning problems 
goal give examples concepts defined previous section show constructing queries solely expected instantaneous information gain method general 
consider concept class 
associated probability distribution uniform distribution 
concept class consist functions form 
define prior distribution concepts generated choosing uniformly 
space defined examples 
isomorphic segment max min 
denote ratio probabilities version space observing ith example pr pr instantaneous information gain example log unlabeled example expected instantaneous information gain 
examples fall outside segment zero expected information gain example divides segment equal parts obtains highest possible expected information gain bit 
agrees intuition labels examples fall outside segment completely determined previous labeled examples label example falls middle version space interval predictable 
easy show probability prediction error gibbs prediction rule equal length segment divided 
learner asks label example located middle segment guaranteed halve error gibbs prediction rule 
case see asking oracle label label example maximizes expected information gain guarantees exponentially fast decrease error gibbs prediction rule 
contrast expected prediction error asking labels randomly chosen examples 
freund seung shamir tishby version space examples achieve highest information gain 
version space examples achieve maximal information gain threshold learning problem defined 
question constructing queries expected information gain method general guarantees prediction error decreases exponentially fast zero 
answer question negative see case consider slightly complex learning problem 
sample space set pairs element second element real number range 
distribution defined picking independently uniformly random 
concept class set functions form prior distribution concepts generated choosing uniformly random case example corresponds horizontal vertical half plane version space stage learning rectangle see 
examples achieve maximal information gain horizontal vertical 
labeling examples reduces volume version space factor 
probability gibbs rule incorrect prediction proportional perimeter rectangular version space volume 
learner constructs queries type dimensions rectangle reduced perimeter length stays larger constant 
implies prediction error stays larger constant 
conclude expected information gain unlabeled example sufficient criterion constructing queries 
essential problem distribution selective sampling query committee examples completely ignored criterion 
easily find specific solution learning problem general method sensitive distribution examples guaranteed wide variety problems 
section method 

query committee learning algorithm seung opper sompolinsky authors devise algorithm learning queries called query committee shall refer qbc algorithm 
algorithm uses queries examples expected information gain high constructing examples filters informative examples random unlabeled examples gets oracle sample 
discuss simplest case committee size 
algorithm proceeds iterations 
iteration calls sample get random instance calls gibbs twice compares predictions label predictions equal rejects instance proceeds iteration 
predictions differ calls label input adds labeled example set labeled examples define version space 
proceeds iteration 
seung opper sompolinsky authors treat query committee algorithm line learning algorithm analyze rate error gibbs learners reduces function number queries 
prove general bounds number queries number random examples algorithm tests 
order consider batch learning scenario learning algorithm tested finished observing training examples fixed prediction hypothesis 
define termination condition iterative process described 
algorithm reaches state fulfills condition stops calling sample label uses gibbs oracle predict labels instances receives test phase 
termination condition satisfies large number consecutive instances supplied sample rejected 
measure quality predictions algorithm way similar valiant pac model 
define expected error algorithm probability prediction label random instance disagrees true underlying concept 
probability taken respect random choice instance underlying concept 
allow algorithm small probability failure account fact sequence instances observes training atypical 
say learning algorithm successful expected error small trained typical sequence instances 
precisely define parameters accuracy parameter confidence parameter 
term training history describe specific sequence random instances random coin flips learning specific hidden concept 
choice hidden concept allow set training histories probability marked atypical training histories 
requirement expected error set typical training histories smaller freund seung shamir tishby input maximal tolerable prediction error 
desired reliability 
gibbs oracle computes gibbs predictions 
sample oracle generates unlabeled examples 
label oracle generates correct label example 
initialize counter calls label set initial version space complete concept class repeat consecutive examples rejected 
ln number examples queries far 

call sample get unlabeled example drawn random 
call gibbs twice get predictions label 
predictions equal reject example return loop 
step 
call label get increase set concepts 
output prediction hypothesis gibbs 

query committee 
parameters provided learning algorithm input define termination criterion 
gives formal description algorithm 
important notice termination condition depends properties concept class 
performance algorithm depend properties algorithm prior knowledge properties 
easy show qbc stops error resulting hypothesis small high probability 
algorithm stops probability error larger proof lemma 
harder question qbc stops calls sample label stopping 
shall show sections large class learning problems algorithm high probability log calls sample log calls label 
committee filter tends select examples split version space parts comparable size parts contains version space selective sampling query committee probability hypotheses disagree small 
normalize probability version space assume example partitions version space parts probabilities respectively 
probability accepting example query information gain example 
functions maximized decrease symmetrically zero increased decreased zero 
clear queries qbc higher expected information gain random examples 
true general expected information gain queries larger constant seen section queries high information gain guarantee fast decrease prediction error general 
proof performance qbc consists parts 
part section show lower bound information gain queries guarantee fast decrease prediction error qbc 
second part section show expected information gain queries qbc guaranteed higher constant important cases 

relating information gain prediction error query committee section prove expected information gain queries qbc high prediction error algorithm guaranteed exponentially small number queries asked 
shall define exactly mean high information gain give theorem proof 
analysis treat runs algorithm initial segments infinite runs generated termination criterion execution main loop qbc 
denote infinite sequence unlabeled examples generated calls sample 
infinite sequence integer numbers refer sequence indices examples filtered qbc queries label 
set examples denoted denote sequence integers xm denote examples denote elements indicates examples queries indicates queries chosen unlabeled examples 
probabilistic structure underlying query process 
point sample space triple 
probability distribution space defined follows 
target concept chosen component infinite sequence chosen independently fixing define distribution elements probability algorithm qbc calls oracle label iterations indexed easy see distributions defined different values consistent define distribution limiting distribution 
denote distribution defined triplets pr indicate probability expectation taken respect distribution 
freund seung shamir tishby define formally mean say queries qbc informative 
definition 
say expected information gain queries qbc learning problem concept class concept distribution input distribution uniformly lower bounded holds 
distribution generated qbc expected instantaneous information gain st query sequence previous queries answers larger notation write requirement conditional expectation larger pr somewhat intuitive terms uniform lower bound information means version space reached qbc non zero probability expected information gain query qbc larger section shall prove uniform lower bounds information gain qbc important learning problems 
give theorem relates bound information gain qbc expected prediction error 
theorem concept class vc dimension expected information gain queries qbc uniformly lower bounded bits holds probability larger random choice target concept sequence examples choices qbc number calls sample qbc smaller max max ln 
number calls label qbc smaller ln words exponentially small fraction number calls sample 
probability gibbs prediction algorithm uses final version space qbc mistake prediction smaller 
proceed prove theorem give brief intuitive sketch argument see 
idea concept class learnable observing labeled examples conditional distribution labels new examples highly biased labels 
means information gained knowing selective sampling query committee cumulative information gain expected cumulative information gain random examples cumulative information queries gap examples accepted queries number random examples 
tag axis denotes random example specific typical sequence 
symbol tag denotes fact example chosen query 
label random example small 
turn means increase cumulative information sequence random examples slower slower sequence gets longer 
hand information gained queries qbc lower bounded constant cumulative information gain sequence queries increases linearly number queries 
clear information labels queries smaller information labels examples returned sample 
way rates increase hold violating simple inequality number examples rejected consecutive queries increases number queries 
result termination criterion qbc hold algorithm output final prediction rule reasonably small number queries 
prediction rule output gibbs prediction rule final version space defined labeled examples seen far 
probability making prediction error rule definition equal probability disagreement hypothesis randomly chosen prior distribution restricted version space concept independently chosen distribution 
probability equal probability accepting random example query version space 
termination condition fulfilled large number random examples accepted queries implies probability accepting query making prediction mistake final version space small 
shall prove theorem lemmas 
lemma expected instantaneous information gain query algorithm uniformly lower bounded bits pr proof definition uniform lower bound expected information gain means sequence queries excluding possibly set freund seung shamir tishby measure zero expected information gain st query lower bounded put way means random variables form sequence sub martingale differences 
instantaneous information gain bounded get hoeffding bound tails bounded step sub martingales mcdiarmid know pr setting logs get pr gn exp ln ln exp ln gn choosing get bound 
lemma probability predictions qbc wrong main loop terminated smaller probability larger 
proof assume probability wrong prediction larger 
discussed informal part proof implies probability accepting random example query final version space larger 
remains show probability qbc stops probability accepting query larger smaller 
termination condition qbc examples tested nth query rejected 
probability accepting random example larger probability smaller definition get ln ln summing probability possible values zero infinity get statement lemma 
haussler kearns schapire shown vc dimension concept class expected information gain random examples bounded log 
show probability information gain larger small 
lemma assume concept chosen random concept class vc dimension fix sequence examples recall xm denotes examples 
selective sampling query committee pr xm xm log em em 
proof sauer lemma sauer know number different labelings created examples em expected cumulative information gain equal entropy base distribution labels maximized possible labelings equal probability 
gives upper bound log em expected cumulative information gain 
labelings cumulative information gain larger expected value probability smaller labels equipartition case 
number possible labelings remains total probability concepts give rise labelings choosing log em get bound 
proof theorem consider randomly chosen element event space 
analysis involves random examples qbc xm queries qbc filter halts denote number queries qbc examples 
claim theorem probability algorithm halts testing st example number queries smaller hypothesis outputs halting error smaller 
shall enumerate list conditions guarantee events occur particular random choice examples internal randomization qbc 
showing probability conditions fail small get statement theorem 
conditions 
cumulative information content queries gn 
lemma get order condition hold probability larger sufficient require ln 

cumulative information content examples log em 
lemma get order condition hold probability larger sufficient require 

number queries examples smaller condition follows conditions xm xm freund seung shamir tishby information gained queries asked examples larger total information gained examples impossible 
order hold sufficient require log em 

number consecutive rejected examples guarantees algorithm stops testing st example 
notice threshold increases consecutive examples examples rejected algorithm guaranteed halt reaching st example 
rejected examples length shortest run rejected examples 
require expression larger fact condition holds facts sufficient require ln 

gibbs prediction hypothesis output qbc probability smaller making mistaken prediction 
lemma get probability happen smaller 
see equations hold probability conditions fails smaller remains shown choices guarantee equations hold 
combining equations get sufficient require ln plugging choice equation get requirement ln ln ln 
simple algebra check choice satisfies equations max max ln equations guarantee conditions hold probability 
selective sampling query committee 
concept classes efficiently learnable qbc theorem query committee yields high information gain yields rapidly decreasing generalization error 
discuss geometric concept classes uniform lower bound information gain exists theorem applicable 
main analysis learning problem concepts intersections halfspaces compact convex subset case concept class represented compact convex subset example partitions concept class dimensional hyperplane 
section sketch proof uniform lower bound information gain qbc depend dimension case uniform 
proof detailed appendix variational analysis geometry version space 
section result extended case non uniform input distribution prior applied perceptron learning problem 

uniformly distributed half spaces subsection prove lower bound information gain simple geometric learning problem shall refer parallel planes learning problem 

dimensional concept class defined equation 
shaded area corresponds typical convex version space defined set half spaces corresponding examples 
version space bisected new unlabeled example defined define domain set pairs form vector length refer direction example real number range refer offset see 
words denotes unit sphere origin section assume distribution uniform 
concept class defined set binary functions parameterized vectors defined follows freund seung shamir tishby 
assume prior distribution uniform unit ball radius origin 
concept class similar class defined perceptron variable threshold 
note case threshold part input parameter defines concept 
concept class bit strange shall see results prove extended natural concept classes perceptron 
information gain random examples vanishes goes infinity 
reason high dimension volume sphere concentrated near equator 
typical random example cut sphere distance away equator case sphere fall pieces unequal volume 
piece containing equator contain volume 
geometric example illustrates query algorithms especially important high dimensions 
query committee solves problem choosing random points sphere 
points near equator example separates near equator 
reason query committee attain information gain remains finite high dimensions 
proof uniform lower bound expected information gain qbc properties version spaces concept class 
property example cuts version space plane orthogonal direction offset origin 
uniformly distributed planes cut version space fixed direction uniformly distributed offset spans width version space direction 
second property version spaces generated learning concept class bounded convex sets defined intersection ball number half spaces 
discussed section expected information gain example probability example accepted qbc quantities depend ratio probabilities parts version space created example 
observations reduce problem dimensional problem 
fix particular direction fraction version space side plane defined pr pr 
call volume function version space 
probability qbc accepts example expected information gain example 
uniformly distributed expected information gain examples direction dt dt 
selective sampling query committee result lower bound value 
proof finding convex version space produces smallest value 
body constructed isomorphic cones connected bases call body cone 
theorem analyzes similar problem 
finds convex body achieves minimal value functional min dt 
analysis minimum functional simpler interestingly finds body achieves minimum achieves minimum functional theorem functional defined volume functions convex bodies assumes unique minimum cones body defined 
value minimum ln bits dimension theorem gives lower bound expected information gain single query qbc parallel planes learning problem defined section 
section shall theorem prove qbc effective query algorithm learning perceptrons 
proof give main part proof 
technical details formulated lemmas proofs appendix proof variational analysis functional shall show volume function corresponds cones minimizes functional 
shall show volume function convex body slightly altered way decreases value maintains correspondence convex body 
shall bound value independently direction bound depends fact version space bounded convex set distribution uniform 
drop subscript 
loss generality extend definition defining zero 
redefine integrals definition equation 
easy check 
loss generality support volume function 
consider right half body set points coordinate 
take union half symmetric reflection plane 
similarly generate symmetric body left side original body 
resulting bodies reflection symmetric usually convex 
volume functions easy see 
order prove lower bound convex bodies sufficient prove lower bound volume functions correspond reflection symmetric bodies half freund seung shamir tishby convex 
variational manipulations apply half symmetric body say carry reflection half 
shall show minimum half obtained cone base 
symmetric reflection cone body happens convex body 
cone body gives minimum convex bodies 
goal find volume function right half convex body minimizes functional dx dx 
find convenient define functions 
easy verify equation written dt dt 
changes induced small changes function approximated linear functional called derivative follows dt dt derivative function value function point derivative calculated formally differentiating functional respect 
ds ds ds ds consider behavior sum terms square brackets 
denote direct calculation shows strictly increasing function range range 

third term range sum terms 
decreasing positive follows point function 
parameter critical importance rest shall refer pivot point 
terms volume function increases decreases vice versa 
variation non negative points selective sampling query committee pivot point non positive points pivot point dt sufficiently small desired 
shall construct suitable variations proving lemma 
convex body volume function 
consider functions defined follows df dt volume dimensional unit ball 
function equal total volume body range dimensional volume slice call radius function body revolution obtained rotating planar graph function axis volume functions correspond 
lemma characterizes radius functions convex bodies lemma 
radius function convex body concave 

body revolution generated concave radius function convex 
proof lemma appendix search minimum convex bodies restricted bodies revolution created rotating concave radius function 
proof theorem concluded proving lemmas details appendix lemma convex body volume function cone base hyperplane exists admissible variation 
lemma minimum convex bodies achieved 
lemmas follows minimum achieved cone body 
simple calculation gives lemma value cone body ln dimension concludes proof theorem 

perceptrons section apply theorem problem learning perceptrons 
perceptron concept class defined set binary functions unit ball freund seung shamir tishby 
prior distributions constants uniform distributions respective sets 
point surface dimensional sphere initial version space isomorphic unit sphere 
section organized follows 
start stating extension theorem 
discuss technical issue regarding initial phase learning procedure required order theorems apply 
prove main result section shows mild assumptions prediction error qbc algorithm learning decreases exponentially fast number queries asked 
theorem generalized cases prior input distributions exactly uniform 
definition definition 
say density measurable set pr pr 
definition get extension theorem theorem value functional parallel planes learning problem prior distribution uniform input distribution uniform ln bits independent dimension proof appendix theorem prove qbc efficient query algorithm perceptron concept class prior distribution distribution examples close uniform 
shall prove exists lower bound information gain queries qbc 
proof technique requires initial version space complete unit sphere restricted cone 
words exist unit vector dot product larger constant 
condition annoying 
hard guarantee condition holds initial learning phase prior qbc filtering queries random instances supplied sample 
results blumer bound number training examples needed guarantee prediction error arbitrary consistent hypothesis small high probability 
distribution instances close uniform small prediction error implies hypothesis vector small angle vector corresponds target concept 
details argument lemma 
lemma assume distribution instances uniform distribution unit ball 
suppose random instances chosen labeled find hypothesis consistent labeled instances 
max log log cos selective sampling query committee probability choice random instances 
proof angle larger cos 
examples incorrect vectors unit ball 
defines subset unit ball constructed wedges volume cos volume ball 
distribution instances uniform distribution probability set cos 
hand vc dimension dimensional perceptron classical uniform convergence bounds blumer 
theorem blumer guarantees hypothesis consistent labeled examples chosen independently random arbitrary distribution error smaller probability max log log combining arguments get statement theorem 
assuming initial phase learning unfiltered instances guarantee bound maximal angle vectors get theorem 
theorem dimensional perceptron concept class defined equation restricted concepts unit vector prior distribution uniform input distribution uniform 
expected information gain queries qbc larger proof version space perceptron region dimensional unit sphere bounded set great circles 
shall transform problem special case parallel planes learning problem defined section 
assume existence vector define mapping version space bounded convex subset assume loss generality 

assume instances length smaller mapped changing label assigned concepts 
distribution surface unit sphere created way uniform 
case mapping concepts defined transforming vector 
lies unit sphere dimensional vector 

corresponding mapping instances maps instance 
lies unit sphere pair 
easy see condition defines perceptron equivalent condition defines corresponding parallel plane concept 
condition case equivalent 
easy check examples transformed concept space labeled freund seung shamir tishby spherical version space projection region larger sphere maximal angle projection segment plane 
transformation maps spherical version space hyperplane 
concept 
implies increase volume infinitesimal part instance space factor distribution instances surface unit sphere uniform distribution transformed instance space uniform 
bound distance prior distribution uniform consider mapping infinitesimally small region version space sphere plane 
illustrates transformation dimensional perceptron 
transformation maps region larger region hyperplane 
factor volume increased seen separating transformation steps 
step region unit hypersphere mapped region larger hypersphere 
radius larger hypersphere increase volume factor second step region large hypersphere mapped hyperplane region infinitesimally small approximated linear region 
increase volume region step factor multiplying factors get prior distribution sphere uniform distribution hyperplane generated mapping uniform 
special case parallel plane learning problem close uniform distributions 
theorem get statement theorem 

incorrect prior distribution point assumption learning algorithm correct prior distribution concept space section show assumption weakened 
definition 
say distribution dominated distribution event pr pr 
selective sampling query committee suppose qbc uses distribution dominates uniform lower bound expected information gain qbc respect theorem replaces theorem case 
theorem concept class vc dimension expected information gain queries qbc prior uniformly lower bounded bits dominated holds probability larger random choice target concept respect sequence examples choices qbc number calls sample qbc smaller max max ln 
number calls label qbc smaller ln words exponentially small fraction number calls sample 
probability gibbs prediction algorithm uses final version space qbc mistake prediction smaller 
note number calls sample increases factor number queries increases additive term log sketch proof clear arguments proofs lemmas theorem hold replaced 
implies high probability error gibbs prediction algorithm uses final version space qbc smaller ed pr assumption dominated implies ed pr increasing factor get statement theorem follows 
freund seung shamir tishby 
learning unlabeled examples membership queries qbc algorithm uses unlabeled examples order reduce number labeled examples needs know 
qbc simple algorithm way information provided random unlabeled examples 
section observation learning framework defined general scheme query filtering 
scheme potentially computationally intensive qbc applicable generality qbc 
main observation oracles sample gibbs defined section allow learning algorithm estimate expected error prediction rule 
way algorithm calculate expected improvement making particular query 
prediction rule qbc select random consistent hypothesis gibbs label instance 
general prediction rule defines conditional distribution label instance 
error prediction rule instance concept probability prediction assigns incorrect label 
expected error prediction rule defined selecting random random oracles sample gibbs generate random selections respectively 
disregarding computational complexity approximate expected error prediction rule sufficiently large samples instances hypotheses 
dependence prediction rule generated qbc labeled instances seen past defined version space general learning algorithm defines mapping sets labeled instances prediction rules 
estimate error prediction rule defines measure quality set labeled examples 
unlabeled instance estimate distribution label instance gibbs 
way estimate expected reduction prediction error result knowing correct label instance 
reasonable heuristic filtering queries select instances cause largest reduction prediction error 
observing set labeled instances learning algorithm find instance reduces expected prediction error constant multiplicative factor prediction error decreases exponentially fast number queries asked 
course instances cause reduction exist exist problem finding efficiently potentially hard 
algorithm analyzed qbc efficient variant heuristic 
general heuristic described large number calls oracles sample gibbs algorithm qbc fewer calls 
specifically dependence number calls sample desired error dependence achieved algorithm query instance gets sample 
algorithm twice calls gibbs sample 
clear close optimal certainly smaller number calls suggested heuristic described 
exponential decrease error qbc function number queries established restricted family parameterized concept classes 
establishing effectiveness qbc general selective sampling query committee concept classes proving effective general families concept classes interesting open problem 
general heuristic described section efficient applicable general situations qbc 
example outcomes binary discrete relation inputs stochastic deterministic 
finding learning algorithms learn efficiently general frameworks interesting open problem 

summary proved query committee algorithm efficient query algorithm perceptron concept class distributions close uniform 
gives rigorous proof results seung opper sompolinsky obtained replica method statistical mechanics 
generalizes results relaxing requirements distribution examples prior distribution 
addition show exact knowledge prior distribution required 
sufficient ratio assumed prior actual prior bounded constant factor 
proved general queries filtered query committee algorithm high expected information gain prediction error guaranteed decrease rapidly number queries 
proving case perceptron learning problem achieved main result 
hope lower bounds expected information gain qbc proven concept classes 
useful context generalize theorem allow cases expected information gain small occur small probability 
issues discuss 
know results extended concept classes perceptrons 
second great practical importance analyze general scenarios 
noisy case learner observes corrupted label different correct label associated instance 
related case probabilistic case relationship instance label described conditional distribution 
general case agnostic scenario assumption joint distribution instances labels examples drawn independently random 
extending analysis general cases open problem important making analysis relevant practical applications 
theoretical results models lacking empirical evidence extensions learn noisy probabilistic models hidden markov models dagan engelson 
believe general agnostic learning scenario noisy learning problem related 
useful context extend size committee refined definitions disagreement committee members 
freund seung shamir tishby explored power algorithms learning queries access random unlabeled instances membership queries 
model learning natural contexts unlabeled instances cheaper labeled instances 
interesting theoretical open question powerful model learning queries standard model membership queries statistical learning 
acknowledgments part research done hebrew university jerusalem 
freund shamir tishby israel binational science foundation bsf support 
yossi azar shlomo manfred opper helpful discussions regarding 
appendix proofs lemmas proof lemma denote convex body defined slice convex body clearly volume define linear combination bodies immediate result convexity terminology theory convex bodies say set bodies parameterized parameter concave family bodies 
brunn minkowski theorem states bodies th root volume bodies linear concave family concave function family parameters fenchel subsection 
case family concave family single parameter 
get statement lemma special case brunn minkowski theorem 
proof lemma value functional positive exist infimum set values achieve set convex bodies 
denote infimum show achieved minimum 
words exists volume function corresponds convex body sequence convex bodies corresponding sequence volume functions lim lemma may assume bodies selective sampling query committee table 
notation table symbol definition meaning section equation sample space sample distribution 
unlabeled examples drawn number examples number queries labeled examples 
xm examples concept class target concept vn 
version space labeled examples bayesian prior distribution hypothesis log pr vm cumulative information gain log log binary entropy function expected information gain example version space fractional reduction version space 
xm 
xm examples 
sequence indices examples queries 
elements 
sequence query examples 
examples queries lower bound expected information gain vc dimension expected information gain functional variation uniformity parameters prior input distributions divergence correct incorrect priors freund seung shamir tishby bodies revolution correspond concave radius functions 
need show exists concave radius function limit 
functional defined terms integrals radius functions continuous bounded constant depends dimension converges pointwise value sequence bodies revolution corresponding converges value body corresponding 
prove lemma showing subsequence radius functions pointwise limit 
diagonalization argument pick subsequence indexed converges pointwise rational value easy see limit function defined rationals concave continuous 
get concave extension real values limit rationals lub rational clearly concave continuous pointwise limit radius function concave body assumes minimum proof lemma radius function corresponds cone body max compute fixed solving integral equation follows 
case find convenient integral negative half line defined equation 
volume function range ds 
plugging equation get dt dt df df shown direct calculation decrease 
gives general lower bound df df log 
proves statement lemma 
proof lemma shall keep notation defined proof theorem 
volume function come cone construct variation decreases 
selective sampling query committee describe variations terms adding variation function radius function 
restricting volume functions define 
enumerate requirements radius variation function corresponding volume variation function ds 

need volume function 
hold require positive concave function nonzero bounded segment 

need guarantee dt 
hold require non positive non negative pivot point volume function see equation discussion 

able find radius variation function change corresponding volume function small desired dt 
describe families variational functions 
radius function corresponds volume function equal max variations applies showing exists 
variations constructed geometrically 
list constructions read alongside 
basic idea transformations move volume place place projection direction way point particular range volume moved right points left vice versa 
easy check conditions holds transformations 
descriptions shall refer volume changes caused increasing decreasing radius function note changes dimensional volume revolution body volume function corresponds radius function dimensional area described changes graph 
transformations depend dimension actual body qualitative form transformation remains dimensions 
transformation takes parameter positive number set small condition holds 

linear range transformation see point select point curve defined left volume decrease caused changing curve chord equal 
point select point slightly connect unique point curve curve concave 
choose volume increase caused changing curve line 
set small construction possible freund seung shamir tishby tangents transformation transformation transformation chords 
variational transformations selective sampling query committee note point conditions hold volume removed right volume added left implies volume function increases range 
amount volumes removed added equal change outside range 
implies condition holds 

decrease linearly zero transformation see select curve right volume decrease caused changing 
point curve meets horizontal axis 
select slightly right connect point curve curve concave 
choose volume increase caused changing 
set small construction possible argument similar transformation holds case 
condition holds slopes linear segments equal transformation see point slightly chosen 
point slightly chosen net change volume changing 
point slightly right chosen net change volume changing 
movement chosen change volume caused changes equal case volume function changed sides pivot point 
arguments similar transformation shows condition met 
radius functions transformations apply finishing proof lemma 
appendix proof theorem prove dependence uniformity input distribution measured general distribution uniform distribution freund seung shamir tishby written weighted sum form distribution 
fix version space prior distribution distribution examples expected information gains examples generated respectively 
get expected information gain uniform times expected information gain uniform 
analysis dependence involved 
go back analysis arbitrary projection convex body proof theorem 
main idea show transformations increase decrease volume function particular ranges way decreased expected information gain 
transformation involved changing shape body 
transformation changes density prior distribution inside version space 
fix convex body direction body projected 
denote average density slice body defined example 
relation volume function radius function ds search density distribution points body uniform distribution minimizes expected information gain uniformly distributed examples direction note symmetrization argument proof theorem holds case restrict functions defined positive reals 
variational derivative computed equation know decreases increased decreased allow deviations uniform prior distribution change changing form convex body 
shall give variation changes range way decreases 
variation applied specific step form range get step form achieves minimal value fixed body uniform 
similar argument show stepwise form range assume exist 
add variation function chosen ds ds selective sampling query committee insures volume function change outside range 
easy check corresponds density distribution uniform distribution 
changing density distribution decreases range change 
change decreases 
easy check variation applied exists argument similar argument range get density function minimizes form 
simple variational argument determining exact value shall see lower bound information gain explicit knowledge 
form density function minimizes information gain specific body specific projections 
suppose fix function vary shape body radius function going construction variational functions proof theorem see construction steps hold verbatim special attention needs meaning expression volume decrease equal volume defined terms non uniform distribution specified 
combination arguments shows smallest value attained radius function specified equation average density function remains compute lower bound facts 
done bounding ratio values uniform prior non uniform prior cases 
change integration variable equation dx df df dx df df 
written form dependence enters equation derivative dx df bounding ratio values derivative attains uniform non uniform cases bound ratio values attains uniform non uniform prior distributions 
volume function corresponds uniform prior distribution unif 
volume function corresponds prior distribution defined non unif defined matching definitions 
freund seung shamir tishby derivatives unif non unif get equation ratio dx df non unif dx df unif facts bound ratio derivatives cases 
range get dx df non unif dx df unif 
range get fact monotone non decreasing implies range dx df non unif dx df unif 
range get implies dx df non unif dx df unif combining bounds equations plugging equation get dx df non unif dx df unif bound equation get non unif unif 
completes proof theorem 
selective sampling query committee notes 
log denotes logarithm base ln denotes logarithm base 
analysis extended larger committees improvement performance minor 

example consider case version space contains disconnected sets far assume random example separate sets 
suppose sets probability probability 
examples separate sets rejected fraction accepted dominate examples 
expected information gain close 
set arbitrarily small expected information gain arbitrarily close zero 
type version space occur rarely know necessary conditions 

note number calls sample blumer instances queries label 

bound appears mcdiarmid martingales 
easily checked true super martingales 
reversing sign get equivalent theorem sub martingales 

assume distribution offset uniform direction assumption needs regarding distribution 
perceptron concept class defined set binary functions unit sphere 
discussion ignore distinction concepts parameterization refer concept simply vector 
details derivative defined calculated standard books variational analysis smith 

definition sided version notion closeness defined definition 

ignoring log factors 

definition convex family bodies see fenchel subsection 

denote line segment points denote segment curve connects shorthand denote concatenation line segment curve segment line segment 

dana angluin 
queries concept learning 
machine learning april 

atkinson 
optimum experimental designs 
oxford science publications 

ian 
ideas learning directional feedback 
master thesis university california santa cruz june 

baum 
neural net algorithms learn polynomial time examples queries 
ieee transactions neural networks 

baum lang 
query learning poorly human oracle 
international joint conference neural networks beijing china 

blumer ehrenfeucht haussler warmuth 
learnability vapnik chervonenkis dimension 
acm 

fenchel 
theory convex bodies 
bcs associates moscow idaho usa 

david cohn les atlas richard ladner 
training connectionist networks queries selective sampling 
touretzky editor advances neural information processing systems san mateo ca 
morgan kaufmann 
freund seung shamir tishby 
ido dagan sean engelson 
committee sampling training probabilistic 
russel editors xii international conference machine learning pages 
morgan kaufmann 

bonnie eisenberg ronald rivest 
sample complexity pac learning random chosen examples 
proceedings workshop computational learning theory pages 

fedorov 
theory optimal experiments 
academic press new york 

david haussler michael kearns robert schapire 
bounds sample complexity bayesian learning information theory vc dimension 
machine learning 


improving network generalization ability selecting examples 
europhys 
lett 

lindley 
measure information provided experiment 
ann 
math 
statist 

mcdiarmid 
method bounded differences 
survey combinatorics th british combinatorial conference 

mitchell 
generalization search 
artificial intelligence 

sauer 
density families sets 
combinatorial theory 

seung opper sompolinsky 
query committee 
proceedings fifth workshop computational learning theory pages san mateo ca 
morgan kaufmann 

peter smith 
convexity methods variational calculus 
research studies press john wiley sons 

valiant 
theory learnable 
communications acm november 
received august accepted august final manuscript december 
