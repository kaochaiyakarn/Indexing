th international conference computer vision july vancouver canada vol pp 

motion segmentation subspace separation model selection kanatani department information technology university japan kanatani suri ac jp reformulating costeira kanade algorithm pure mathematical theorem independent tomasi kanade factorization robust segmentation algorithm incorporating techniques dimension correction model selection geometric aic median fitting 
doing numerical simulations demonstrate algorithm dramatically outperforms existing methods 
involve parameters need adjusted empirically 

segmenting individual objects backgrounds important computer vision tasks 
important clue provided motion humans easily discern independently moving objects simply seeing motions knowing identities 
costeira kanade algorithm segmentation image point motions captured feature tracking 
associated method tomasi kanade factorization close examination reveals underlying principle simple fact linear algebra pointed gear alternative method 
state principle subspace separation intention applying wider range problems limited motion segmentation computer vision 
fact wiles pointed principle applies separating illumination sources observing multiple images 
biggest drawback costeira kanade algorithm essentially equivalent method gear performance severely deteriorates presence noise 
segmentation decision particular elements matrix computed data zero 
presence noise small error datum affect elements matrix complicated manner finding suitable threshold difficult noise known gaussian known variance 
avoid difficulty needs analyze original data matrix derived 
robust segmentation algorithm working original data space incorporate geometric aic median fitting 
doing numerical simulation demonstrate method dramatically outperforms existing methods 
derive bound accuracy method compared 
algorithm notable feature parameters need adjusted empirically 
motion subspaces suppose track rigidly moving feature points images 
ff ff image coordinates point th frame 
stack image coordinates frames vertically dimensional vector form ff ff ff ff ff mff image motion point represented single point ff dimensional space 
regard xy camera coordinate system world coordinate system axis optical axis 
fix arbitrary object coordinate system object fi respectively origin orthonormal basis th frame 
ff ff ff coordinates point respect object coordinate system 
position th frame respect world coordinate system ff ff ff ff assume orthographic projection ff ff ff ff ff dimensional vectors obtained respectively chopping third components 
stack vectors frames vertically dimensional vectors respectively way eq 
vector ff form ff ff ff ff points fp ff belong dimensional subspace spanned vectors fm fact holds affine camera models including weak perspective 
motion planar object translates directions rotates axis vector vanishes take directions respectively 
means points fp ff belong dimensional subspace spanned fm follows motions feature points segmented independently moving objects grouping points distinct dimensional subspaces general motions distinct dimensional subspaces planar motions 

subspace separation theorem fp ff points belong dimensional subspace ae define fffi fffi ff fi denotes inner product vectors matrix gives information lengths vectors fp ff mutual angles call metric matrix eigenvalues fv vn orthonormal system corresponding eigenvectors 
define interaction matrix fffi divide index set ng disjoint subsets dimension subspace defined ith set fp ff ff subspaces linearly independent theorem fffi element zero fith points belong different subspaces fffi ff fi theorem essence principle costeira kanade algorithm relies 
costeira kanade described result tomasi kanade factorization proved purely mathematically follows 

vectors fp ff exist infinitely sets numbers fc zero ff ff ff points fp ff belong subspaces set annihilating coefficients fc ff null space precise generated ff ff ff ff ff ff 
formal proof appendix 

separation procedure greedy algorithm presence noise elements fffi nonzero general 
straightforward method successively group points ff fi jq fffi large 
progressively interchange corresponding rows columns ends approximate block diagonal matrix 
formally define similarity measure ith subspace jth subspace ij max ff fi jq fffi repeatedly merge subspaces ij large 
costeira kanade adopted type strategy known greedy algorithm 
ff fi jq fffi experience choice measure affect result 
noise exists data fp ff elements information available magnitude nonzero elements difficult obtain appropriate criterion 
gear formulated problem graph matching solved greedy algorithm difficult weigh graph edges appropriately 
gear complicated statistical analysis result successful 
applied discrimination criterion thresholding 
dimension correction theorem existence locally closed annihilating coefficients 
presence noise coefficients exist create 
dimension subspaces separated general motions planar motions 
soon points grouped optimally fit dimensional subspace replace points projections fitted subspace recompute interaction matrix effectively reduces noise data local grouping correct 
continuing process exact block diagonal matrix model selection fundamental criterion data space residual sum square distances data points fitted subspace 
reasonable merge groups points resulting residual large compared sum residuals separately fitting subspaces 
large residual judgment 
general residual increases groups points merged single subspace fewer degrees freedom adjust subspaces 
follows balance increase residual decrease degree freedom 
purpose geometric aic 
similar idea motion segmentation torr approach different 
candidate subspaces dimension merge respective numbers points 
corresponding residuals computed course dimension correction 
assume point perturbed true position independent gaussian noise mean zero standard deviation ffl referred noise level residual result fitting single dimensional subspace points 
dimensional subspace degrees freedom geometric aic form aic ffl dimensional subspaces fitted points points separately degree freedom sum individual subspaces 
geometric aic follows aic ffl merging reasonable aic aic criterion information provided interaction matrix ignored 
mix criteria define similarity measure subspaces ij aic aic max ff fi jq fffi subspaces largest similarity merged successively number subspaces specified number resulting subspaces may contain elements violates assumption 
prevent take subspaces elements candidates merged long exist 
evaluating geometric aic need estimate noise level ffl 
done note vectors fp ff constrained dimensional subspace absence noise md 
residual fitting dimensional subspace fp ff ffl subject specified points move subspace directions 
degree freedom dn distribution degrees freedom 
obtain unbiased estimator ffl ffl robust fitting point misclassified course merging process leaves class 
attempt remove outliers resulting classes lm points near origin may easily misclassified select class half elements large norms 
fit dimensional subspaces select class half elements distances closest subspace large 
fit dimensional subspaces allocate data point closest 
fit dimensional subspaces resulting point sets median precise median squares method 
data point reallocated closest 
accuracy bound method reach accuracy long noise exists data 
objective evaluation algorithm compare performance ideal method 
suppose know oracle true subspaces lm observed data perturbed independent identically distributed gaussian noise 
evidently point grouped closest subspace 
course real data simulations true solution known regard performance oracle method bound accuracy 

examples fig 
shows consecutive images points background points object 
background object independently moving dimensions object wireframe ease visualization 
added gaussian noise mean standard deviation ffl coordinates points independently classified groups 
fig 
plots average error ratio independent trials different ffl compared method greedy algorithm method dimension correction added method model selection addition method robust fitting added 
see added technique reduces error 
image sequence points planar motion 
error ratio segmenting planar motion fig 


greedy algorithm 

dimension correction 

model selection 

robust fitting 

greedy algorithm 

method 

method 

lower bound 
fig 
greedy algorithm method techniques combined method uses discrimination criterion compared bound oracle method 
observe method slightly better greedy algorithm inferior method 
criterion classifies elements squares sense nonzero elements jq fffi close zero judged zero presence noise 
fig 
shows consecutive images points background points object 
background object independently moving dimensions 
fig 
shows classification results corresponding fig 

see method dramatically improves classification accuracy 
fig 
shows sequence projected images manually selected feature points 
data set correctly separate independent motion background motion greedy algorithm method method failed 
added independent gaussian noise mean standard deviation ffl 
pixels coordinates feature points applied method times ffl different noise time 
greedy algorithm method caused misclassifications method correct ffl pixels image sequence captures motion regard planar motion greedy algorithm method detect correct motion method fails 
greedy algorithm fails random noise ffl added method works ffl pixels 

concluding remarks reformulated costeira kanade method pure mathematical theorem independent tomasi kanade factorization robust segmentation algorithm incorporating techniques dimension correction model selection geometric aic median fitting 
numerical simulations compared performance method bound accuracy 
real image examples shown 
conclude algorithm dramatically improves classification accuracy existing methods 
practical segmentation incorporate multiple features brightness color texture shape motion 
algorithm solely feature point motion may sufficient 
reason fundamental elucidates mathematical structure segmentation problem 
algorithm involve parameters need adjusted empirically 
notable feature stark contrast today intelligent systems lot parameter tuned 
image sequence points motion 
error ratio segmenting motion fig 


greedy algorithm 

dimension correction 

model selection 

robust fitting 
greedy algorithm 

method 

method 

lower bound 
costeira kanade multibody factorization method independently moving objects int 
comput 
vision 
gear multibody grouping motion images int 
comput 
vision 
motion segmentation factorization method discriminant criterion proc 
th int 
conf 
comput 
vision september greece pp 

kanatani statistical optimization geometric computation theory practice elsevier amsterdam 
kanatani geometric information criterion model selection int 
comput 
vision 
wiles constraint surface reconstruction multiple light sources proc 
th euro 
conf 
comput 
vision june july dublin ireland vol pp 

meer mintz rosenfeld robust regression methods computer vision review int 
compute 
vision 
threshold selection method gray level histograms ieee trans 
sys 
man cyber 
kanade factorization method shape motion recovery ieee trans 
pat 
anal 
mach 
intell 
rousseeuw leroy robust regression outlier detection wiley new york 
tomasi kanade shape motion image streams orthography factorization method int 
comput 
vision 
torr geometric motion segmentation model selection phil 
trans 
roy 
soc 
appendix proof theorem number elements set sufficient prove theorem proof 
suppose fp ff aligned subspace dimension matrix rank defines linear mapping rank dimensional space dimensional space null space dimension fn arbitrary orthonormal basis dimensional vector 
similarly matrix defines linear mapping rank null space dimension fn arbitrary orthonormal basis dimensional vector 
dimensional vectors defined padding fn fn zero elements follows result vectors orthonormal system belonging null space observation matrix matrix rank assumption null space dimension 
orthonormal basis null space real images moving objects selected feature points 
eq 
equivalent see orthonormal system eigenvectors eigenvalue 
fv vn arbitrary orthonormal system eigenvectors eigenvalue exists orthogonal matrix related vn consider matrix fffi element inner product fith rows matrix vn observe vn vn cc 

submatrices respectively 
implies fith rows matrix vn mutually orthogonal ff fi belong different subspaces 
fv arbitrary orthonormal system eigenvectors matrix nonzero eigenvalues 
combining fv vn obtain orthonormal system eigenvectors matrix eigenvalues 
follows matrix vn orthogonal 
rows pair wise orthogonal 
ffi element vector fith rows matrix ff ffn fi fin respectively 
follows ff fi ff fi ffr fir ff fij ffn fin shown ff fi ffn fin ff fi belong different subspaces 
means ff fi belong different subspaces ff fi ffr fir implies ff fi belong different subspaces fith rows matrix mutually orthogonal 
matrix fffi element inner product fith rows matrix fffi element interaction matrix zero ff fi belong different subspaces 
far assumed easy see theorem holds arbitrarily permute ff fi interchanged fith rows fith columns matrix simultaneously interchanged 
result fith eigenvectors interchanged fith columns matrix interchanged 
follows fith rows fith columns interaction matrix simultaneously interchanged 
permutation generated pair wise interchanges theorem holds arbitrary permutation 
theorem straightforwardly extended subspaces 

