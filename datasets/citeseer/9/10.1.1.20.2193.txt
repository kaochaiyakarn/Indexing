analysis user behavior error conditions spoken dialogs shin narayanan laurie gerber abe byrd university southern california integrated media systems center speech analysis interpretation laboratory sail usc edu recordings asr system heard provided input dialog system 
focus developing account user behavior data collection procedure described detail error conditions working annotated data real 
communicator dialogs experimental human machine mixed initiative dialogs 
particular subjects interacted different travel agent systems 
examine categories error perception user behavior possible dialogs empty contain error effect user strategies error recovery role user participation 
worked total user initiative error situations 
conditional probability dialogs consisted turn 
average length model smoothed weighted asr error rate proposed 
dialogues exchanges 
amount data results show users discovering errors implicit comparable data considered similar study confirmations get back track succeed take longer time doing forms error aberdeen 
discovery system reject 

tagging successful user error recovery strategies included rephrasing contradicting tendency terminate error episodes cancel attempt repairing chain errors 
review analysis human computer dialogs devised tagging scheme consisting tags monitor dimensions dialogs user behavior system behavior task status 

goal quantitative analysis disruptive modeling human machine spoken dialog interactions gaining lot attention deployment complex dialog systems :10.1.1.112.2951
important aspect problem understanding modeling user behavior enable realistic optimization dialog strategies 
known underlying components state art dialog systems automatic speech recognition understanding rely data driven statistical models general prone errors varying types extent 
addition possible systems user induced errors 
targets user behavior modeling error conditions context human machine spoken dialogs 
darpa communicator spoken dialog systems implemented sites represent advances design mixed initiative spoken language systems 
availability transcripts realistic spoken dialogs systems provides excellent opportunity investigate behavior human machine interactions mixed initiative dialogs 
set understand dynamics user behavior system errors combination system errors user reactions affect ultimate success dialog 
preparation study annotated portion june communicator dialogs features including categorization user system behavior 
data extended annotation scheme described section 
results study described section 
concludes summary discussion results section 
data annotation effect errors existing tagging schemes instructive directly applicable 
automatic analysis error conditions asr word error rate difficult aid manual tagging 
manual tagging necessary 
example keep track subtask error occurred distinguish dialog acts 
user utterances communicator data short averaging words 
circumstances attempt labeling disfluencies projects dealing longer open ended utterances done 
detailed tag set usage conventions examples application provided sail usc edu dialog model tags 
briefly tag set purposes included system tags explicit confirmation implicit confirmation help system repeat reject non sequitur user tags repeat rephrase contradict frustrated change request scratch clarify hang task tags error recognized utterance back track task success 
error segments locate beginnings errors place generic error tag asr output resulted error note standard asr word error rate turn calculated 
error segments focus phenomena system utterances exhibit system reaction error user utterances react try correct error means user aware error 
user aware error system rejection sorry couldn understand verbatim repetition system prompt information 
times implicit data orthographically transcribed travel confirmations non system utterances alert arrangement dialogs darpa communicator project user presence error case user recorded june 
dialog consists number try system aware error 
exchanges computer travel agent human scenarios conducted paid subjects arranging represented line triple consisting hypothetical travel particular data collection system utterance user utterance manually transcribed users tendency errors proved difficult correct change nature travel request response repeated recognition errors 
deviations original plan marked 
tag point dialog gets back bot marking system utterance user reasonably discover portion task error successfully understood 
dialog indicate arrangements successfully completed ended hang error 
tagging done annotators showed inter annotator agreement 
tagging conventions allow assignment applicable tags dialogs 
agreement measure number identically tagged lines divided number lines reviewed tagged 
measure conservative counts agreement cases identical tagging appears exactly line annotators 
include partial overlap positional offset 
tagging analyzed dialogs user histories perspectives seeking patterns user behavior correlations user behavior length severity error segments 

results discussion firstly useful get general sense presence errors dialogs 
data dominated errors various types 
roughly turns tagged consists dialogs conducted paid subjects 
dialogs contain error segments 
note definition error segment getting back track bot complete success abort nested error segment 
segments got back track 
provides distribution error segment length number turns data 
turns turns 
average length error segments eventually get back track recover 
numbers know length errors represents system user represents threshold user tolerance error resolution users simply hang continue 
normalized histogram length error segments number turns 
analysis results points categories error perception user behavior error including user initiative error vs non error situations 
categories error perception see manner user discovered error affects time get back track 
case system prompt repetition system rejection user explicitly aware error perspective 
case implicit confirmation system non sequitur user notice error occurred draw system attention 
table error segments grouped way user aware error see way error discovered affects time recover success recovery 
roughly divide error discovery types high frequency system rejection implicit confirmation system prompt repeat low frequency explicit confirmation non sequitur 
high frequency error discovery types striking implicit confirmation results longer time get back track exchanges vs lower rate getting back track compared high frequency errors 
error perception err segments avg err length bot avg err length bot ot reject implicit repeat explicit non seq table lengths error segments get track bot didn percentage errors eventually got back track 

user behavior error examine distribution user behaviors coping errors 
shows distribution user behavior immediately error previous turn 
user behavior error error segment 
rephrasing frequent user behavior hang frequent user behavior 
tables show distribution user strategies segments eventually get back track got back track frequency normalized user strategy length errors errors got back track repeat rephrase contradict system start ask change request scratch error table prevalence user strategies error segments eventually got back track 
observe users successful error recoveries see table significantly anova rephrasing errors contradictions am pm table 
start scratch features terminate error episodes trying repair chains errors 
users successful error recoveries system weaknesses changing travel plans 
apparently got dialog back track viable strategy real travel arrangements 
frequency normalized user strategy length errors non back track repeat contradict system rephrase hang start ask scratch error change request table prevalence user strategies error segments get back track degree error user behavior errors spoken dialogs merely binary valued critical incorporate degree error modeling 
illuminate user behavior error considered user response conditioned system strategy estimate probability user behavior system behavior 
accepted field asr word error rate wer correlate dialog performance 
approximation smoothed probability mass exponentially weighted wer measure wer maps wer infinity range 
calculations chose vary system system 
results shown 
common user behavior rephrasing repeating previous request contributing user responses error 
canceling changing previous request starting relatively rare user behaviors error 
exemplified shows conditional smoothed distribution system repeat corresponding highly popular system strategy system cognizant error 
user behavior system behavior smoothed exponentially weighted wer 
smoothed conditional probability user behavior th turn weighted wer system repeat system behavior th turn 
similarly interesting look user behavior system necessarily cognizant error implicit confirmation strategy 
shows smoothed distribution implicit 
surprisingly user contradict erroneous system behavior 
smoothed conditional probability user behavior th turn weighted wer implicit confirm system behavior th turn 
user initiative error non error environments look user tendency initiative course dialog 
considered user initiative cases user simply respond system prompts attempted guide dialog 
part dialog looks user initiative fails response open prompt dialogs 
free form answer open question tagged initiative 
clear table user initiative behavior significantly error segments 
user initiative tag frequency error segments ask contradict general initiative table frequency normalized dialogs 
summary frequency segments modeling user behavior challenging problems spoken dialog systems research 
empirical analysis modeling real user data helps illuminate user behavior patterns 
analysis reported represents preliminary attempt understanding user behavior error uncertainty spoken dialogs 
results show users discovering errors implicit confirmations get back track succeed take longer time doing forms error discovery system reject 
successful user error recovery strategies included rephrasing contradicting tendency terminate error episodes cancel attempt repairing chain errors 
frequent user behavior get back track error segments system signals errors rephrase repeat 
user discovers error say implicit confirmation user tends contradict cancel action rephrase repeat 
open confounding issues 
key issue relates incorporating user behavior priors probabilities model 
example observe users better able avoid get trouble 
authors observe specific experimental setup subjects paid participants real stake successful task completion users simply careless 
process tagging transcribed data additionally observed participants trouble getting usable asr output 
table looks users participated scenarios 
table users particularly successful 
appear higher numbers errors dialog probably give highest rates recovery relatively short error episodes 
users successful 
low percentage back errors experience inordinately long error episodes 
looked strategies users adopted error users tried repeating 
successful users frequently hung dialog started dialog sequence successful users 
user id dials errs dial 
bot avg length err table error proneness users bot percentage error episodes got back track 
types prior user information need learnt incorporated models 
ongoing focuses questions user model interacts system model optimization framework 

ward cu communicator system ieee pp 

levin narayanan pieraccini di eckert lee walker darpa communicator mixed initiative spoken dialog system proc 
icslp beijing china pp 

zue seneff glass polifroni pao hazen jupiter telephone conversational interface weather information ieee trans 
speech audio proc pp 

levin pieraccini eckert stochastic model human machine interaction learning dialog strategies ieee trans 
speech audio proc pp 

walker aberdeen boland bratt garofolo hirschman le lee narayanan papineni polifroni potamianos prabhu rudnicky sanders seneff stallard whittaker darpa communicator dialog travel planning systems june data collection proc 
eurospeech 
aberdeen doran bayer hirschman finding errors automatically semantically tagged dialogues proceedings hlt 


walker dialog act tags qualitative dialog metrics spoken dialog systems 
proceedings hlt 

characterizing recognizing spoken corrections human computer dialogue proceedings coling acl 
allen core draft dialog act markup layers 
october 
langkilde walker wright gorin litman automatic prediction problematic human computer dialogues may help 

narayanan investigator darpa communicator project june collection 
authors grateful darpa communicator team participants sharing data 
