comparison classifiers document representations routing problem hinrich sch david hull jan pedersen xerox palo alto research center rank xerox research center coyote hill road de palo alto ca usa france parc xerox com hull xerox fr url ftp xerox com pub sigir ps compare learning techniques statistical classification traditional methods relevance feedback document routing problem 
consider classification techniques decision rules derived explicit error minimization linear discriminant analysis logistic regression neural networks 
demonstrate classifiers perform better relevance feedback rocchio expansion trec trec routing tasks 
error minimization difficult high dimensional feature spaces convergence process slow models prone overfitting 
different strategies latent semantic indexing optimal term selection reduce number features 
results indicate features latent semantic indexing effective techniques linear discriminant analysis logistic regression way protect overfitting 
neural networks perform equally set features take advantage additional information available feature sets input 
overview document routing described problem statistical text classification 
documents assigned categories relevant non relevant large sample judged documents available training 
compare traditional relevance feedback approaches routing classification explicit error minimization 
central problem routing high dimensionality native feature space exists potential dimension unique term collection typically hundreds thousands 
standard classification techniques deal large feature set computation solution tractable results unreliable due lack sufficient training data 
solution reduce dimensionality subsets original features transforming way 
approach attempt dimensionality reduction employs learning algorithm explicit error minimization 
relevance feedback rocchio expansion widely ir example approach 
examine different forms dimensionality reduction latent semantic indexing lsi optimal term selection order investigate form dimensionality reduction effective routing problem 
routing system uses query list documents identified relevant relevant construct classification rule ranks unlabeled documents likelihood relevance 
examine number different methods generating document classifier relevance feedback query expansion qe linear discriminant analysis lda logistic regression lr linear neural networks lnn non linear neural networks nnn 
mathematical description classification rule generally expressed function vector feature variables 
traditional approach relevance feedback defines feedback query weighted combination original query vector vectors relevant non relevant documents 
methods functional form qe lda lr lnn known linear classifiers 
look nnn investigate adding non linear component basic model improves performance 
classification techniques proposed significant query expansion 
perform explicit error minimization underlying model generality take full advantage information contained large sample relevant documents 
contrast query expansion uses limited probabilistic model features model parameters fit heuristic manner term frequency information corpus 
demonstrate directly improved retrieval performance routing problem 
tipster collection trec trec routing tasks test classifiers representations 
risks associated general models relevant document space 
surface expect learning algorithms parameters larger feature space easier time capturing distinction relevant non relevant documents cf 
buckley experiments show better performance increasing number terms 
improved performance guaranteed training data simply sample underlying population relevant documents may adequately characterize true distribution 
general model effort expend fitting specific features training documents generalize full relevant population 
classification technique said suffer overfitting training applied new documents compared method 
fundamental trade large fea ture space restrictive learning algorithm fewer features general learning algorithm 
past evidence suggested weak learning rule query expansion high dimensional feature space terms optimizes performance 
demonstrate alternative approach prove superior long run 
sections describe motivate dimensionality reduction strategies classification techniques 
sections experimental set experimental results 
section analyzes results detail section states 
dimensionality reduction examine major approaches dimensionality reduction loosely described feature selection reparameterization 
feature selection subset important features selected full feature space learning algorithm 
previous classification ir relied exclusively method dimension reduction 
reparameterization process constructing new document representation combinations transformations original feature variables 
experiments important features assessed applying measure dependence contingency table containing number relevant non relevant term occurs nr nn respectively number relevant non relevant documents term doesn occur nr gamma nn gamma respectively 
nr nn gamma gamma nr gamma nn nr nr gamma nn nn gamma nr nn nr gamma nn gamma query documents local region considered see 
settled statistic selection criterion initial experiments comparing term selection raw frequency occurrence ratio relevant non relevant documents term occurs 
alternative measures effective test 
underlying assumption test features frequency depends heavily occur relevant non relevant document defined high score constant total frequency useful measuring distinction categories 
reparameterization latent semantic indexing lsi technique represents features documents lowdimensional linear combination orthogonal indexing variables :10.1.1.108.8490
lsi differs important aspects :10.1.1.108.8490
compute separate representation terms documents query focusing documents relevant 
refer technique local lsi applied region document space neighborhood query 
second innovation lsi representations construct query analyzed vector space model 
input parameters learning algorithm 
lsi works applying matrix decomposition term document matrix collection generates large number orthogonal lsi factors 
small number important factors selected approximate covariance structure full collection 
sparse svd algorithm computations 
algorithm need calculate orthogonal factors difficult compute lsi solution trec collection contains terms documents 
proper model full trec collection probably require hundreds lsi factors far successfully modeled learning algorithms 
furthermore factors capturing structure document collection tuned particular queries 
previous shown lsi applied local region query specific basis 
dumais applies lsi routing task uses judged documents queries generate reduced representation method corresponds roughly union local lsi regions query 
compute separate lsi representation query documents contained local region defined section retaining important factors 
factors capture important local structure crucial separating relevant documents nearby non relevant documents 
approach differs local region contains relevant non relevant documents effective relevant documents 
discussion lsi captures theme latent semantic structure document analyzing patterns cooccurrence terms :10.1.1.108.8490
focusing theme document addresses problems near synonymy term representation scheme documents theme describe different vocabulary represented way hides thematic similarity 
difficult obtain accurate measurement relevance 
lsi avoids problem representing theme document specific terms 
sight synonymy minor problem routing context training set available 
classifier trained recognize different ways expressing particular theme indicates relevance 
terms provide reliable evidence estimating relevance lsi necessary 
example consider mail filter trec topic hubble space telescope 
excellent job relying single term hubble lsi analysis difficult classifier get correct information presence absence term hubble 
great number terms contribute small amount critical information combination evidence major problem term classifier 
consider example trec query topic alternatives traditional cancer therapies 
articles different alternative cancer therapies tipster collection gene therapy immunization therapy blood therapy terms unique joint vocabulary relevant terms large learning algorithm error minimization small number positive examples typical tipster 
terms contribute helpful information example ill ranks respectively 
lsi serves means data compression capturing important information contained large number terms smaller number factors 
particularly useful eliminating redundancy word features due term dependence lsi factors constructed orthogonal 
creating compact representation documents lsi reduces overfitting modeling important structure contained heterogeneous queries topic just described 
computations took minutes query 
theme topic avoid confusion trec queries called topics 
difficult assess intuition useful term example perfectly correlated term higher list case contribute information 
non linear term classifiers detect dependencies alternative particular analysis term correlations performed lsi 
amount training data comparatively small general classifier may fail model nonlinear 
experiments complicated models tested don achieve gain performance compared lsi 
disadvantage lsi full discriminatory power underlying terms may lost queries crucially depend particular highly informative terms 
term methods excel kind query example mentioned trec topic hubble space telescope 
experiments compare performance features variable selection generated latent semantic indexing determine effective learning algorithms 
learning algorithms previous approaches routing text categorization classification trees bayesian networks bayesian classifiers rules induction nearest neighbor techniques logistic regression square methods discriminant analysis neural networks 
majority algorithms require number feature variables restricted way 
issue best accomplish dimensionality reduction research learning algorithms information retrieval 
compare different classification algorithms linear discriminant analysis logistic regression neural networks baseline constructed query expansion 
baseline classification vector vector sum relevant documents conventional term weighting document normalization strategies 
equivalent rocchio expansion assigns weight zero query non relevant documents 
previous experiments evidence negative feedback improved performance 
obtained error minimization explicit underlying model different models optimization techniques 
lda derived normal model distribution relevant non relevant documents feature space derived feature dependence explicitly covariance matrix document class 
closed form solution obtained inversion covariance matrix described 
logistic regression linear nn binomial model document relevance iterative solution obtained numerical optimization 
logistic regression uses newton raphson technique neural networks rely backpropagation gradient descent linear discriminant analysis linear discriminant analysis lda group problem derived follows 
suppose sample data groups members mean vectors covariance matrices respectively 
goal find linear combination variables maximizes separation groups 
reasonable optimization criterion maximize separation vector means scaling reflect structure pooled covariance matrix 
words choose stands transpose arg max gamma sa maximized gamma gamma gamma positive definite define cholesky decomposition ra formula arg max gamma gamma maximized gamma gamma means gamma gamma gamma 
dimensional space defined cause group means separated 
approach generalized groups extended create non linear classifier modeling separate covariance matrix group 
lda applied routing problem hull 
order produce non linear classifier estimate separate covariance matrix group pooled estimate covariance matrix approach known quadratic discriminant analysis qda 
qda effective number elements significantly larger number feature variables case routing problem relatively rare 
behaved alternative known regularized discriminant analysis rda 
rda uses pair shrinkage parameters create general family estimators group covariance matrices 
choosing pooled lda qda covariance matrices looks weighted combination 
rda selects optimal values shrinkage parameters cross validation training set 
previous experiments benefit applying rda routing problem 
logistic regression logistic regression statistical technique modeling binary response variable linear combination predictor variables logit link function log gamma modeling variance binomial random variable dependent variable log gamma modeled linear combination independent variables 
model form fi estimated response probability case probability relevance feature vector document fi weight vector estimated matrix feature vectors 
optimal value fi derived maximum likelihood newton raphson method numerical optimization 
logistic regression text retrieval previous experiments 
approach similar feature variables query specific general properties common queries collection 
document routing problem large quantities training documents available query information limited value 
neural networks neural network nn network units designated input output units 
neural networks trained backpropagation activation input pattern propagated forward network error produced backpropagated parameters changed reduce error 
strength neural networks robust ability fit wide range distributions accurately 
example member exponential family modeled output unit lsi representation term representation hidden unit block terms hidden unit block lsi output unit lsi representation term representation linear neural network non linear neural network linear non linear neural network 

unfortunately capacity leads danger overfitting 
neural networks produce model fits training data precisely generalize full population 
previous experiments logistic regression performed poorly large numbers features variables culprit overfitting 
neural networks protect overfitting validation set 
thirds training data model selection remaining third set apart validation 
iteration parameters model updated error validation set computed 
training continues error validation set goes indicates overfitting set 
procedure establishes number iterations training improve generalization 
final parameters model computed training entire training set iterations 
chose procedure systematic crossvalidation computationally expensive 
validation procedure described useful optimization strategy changes parameters small amounts iteration overshoot optimal point overfit training data 
backpropagation gradient descent implemented neural networks acts just fashion 
architectures neural networks experiments shown 
output unit activation models probability relevance 
linear network consists input output units 
non linear network additionally blocks hidden units connected input output units 
shows network architectures dual input lsi terms 
architectures input realize corresponding half architectures 
architectures input units directly connected output unit 
relevance document computed setting activations input units document representation propagating activation network output unit propagating error back network gradient descent algorithm 
chose sigmoid activation function units network shown case backpropagation minimizes error logistic regression cross entropy error gamma log gamma log gamma table confirms result precision logistic regression decreases features added 
relevance document estimated relevance activation output unit document definition sigmoid equivalent log gamma logit link function 
means linear neural networks architecture logistic regression perform maximum likelihood estimation model 
main difference lies optimization algorithm newton raphson logistic regression backpropagation neural networks 
apart gradient descent difference logistic regression neural networks non linear extension architecture hidden units 
hidden units interpreted feature detectors estimate probability feature input 
estimate propagated output unit contribute better estimate relevance 
focus learning aspect neural networks particular explicit error minimization 
contrast neural networks ir closely related vector space model relevance feedback 
kwok bears similarity approach 
apart standard learning algorithm input consists reduced representations feature selection reparameterization 
representational scheme substantially reduces training time prone overfitting fewer parameters 
interesting innovation kwok approach planning integrate model non random initialization weights reflects prior knowledge terms documents 
summary reasons neural networks statistical technique routing 
protect overfitting 
linear neural networks logistic regression probabilistic model validation combined gradient descent train neural networks better suited avoid overfitting 
secondly explore non linear classifiers routing 
analogy way nonlinear rda generalizes linear lda linear neural networks simple non linear extension neural networks hidden units corresponding feature detectors 
experimental set tipster corpus experiments 
consists gigabytes text documents different sources newswire patents scientific abstracts federal register 
tipster queries detailed statements information need called topics 
corpus tdb system performing document parsing tokenization including stemming twolevel finite state morphology terms word list 
terms consisted single words word phrases occur times corpus phrase defined adjacent word pair including words 
process produced terms 
break documents chunks terms called text tiles 
tile highest proximity topic highest correlation vector space model selected subsequent experiments training test 
routing runs replicate routing setup second third trec conferences 
disks gigabytes training set run disk gigabyte test set 
combination classifier input representation run sets topics corresponding routing task trec corresponding routing task trec 
goals experiments demonstrate classification techniques better query expansion find effective classification technique classifier input precision topics precision topics average average change average change change baseline expansion lsi terms lsi terms logistic lsi regression terms lsi terms lda lsi terms lsi terms linear lsi network terms lsi terms non linear lsi network terms lsi terms table non interpolated average precision precision documents improvement expansion routing runs trec data 
routing problem sure comparison lsi term methods idiosyncrasies particular learning algorithm 
query specific screening collection sheer size trec collection difficult apply learning methods full training set purely computational standpoint 
furthermore documents equal value training 
relevant documents relatively rare means valuable training non relevant documents 
considerations motivate initial screening documents applying classification algorithms 
query apply initial screening process designed identify documents clearly relevant excluded analysis 
define local region query nearest documents similarity measured inner product score rocchio expansion initial query vector corresponding baseline feedback algorithm 
documents local region training set learning algorithms 
documents region relevance judgements exist treated relevant 
number advantages training local region 
size training set substantially reduced possible attack problem computationally intensive learning algorithms 
second density relevant documents higher local region collection 
third non relevant documents selected training difficult distinguish relevant documents 
non relevant documents clearly valuable ones training data learning algorithm 
screening process applied test set evaluation avoid extrapolating region defined training set 
threshold derived training set applied documents test set 
documents query correlation higher threshold automatically ranked ahead fall outside local region 
highest weighted terms may partly explain performance 
experimental results table presents routing results different classifiers different representations 
representations relevance feedback query expansion lsi factors query specific local lsi terms highest ranking terms test lsi terms lsi factors terms 
classifiers baseline vector space model documents ranked proximity query vector lsi terms lsi terms proximity expanded query vector expansion logistic regression linear nn architecture non linear nn architecture lda linear discriminant analysis run expansion tf idf weighted terms baseline runs idf weighted 
inverse document frequency idf weights derived entire training set local region 
runs terms weighted input term occurred document 
strategy motivated poor results runs terms weighted frequency occurrence desire learning algorithms select proper weight term 
experimental results analyzed anova friedman test measure statistical significance 
anova determines method significantly better average difference performance large compared variability correcting differences queries 
friedman test conducts similar analysis uses ranking methods query 
table draw classification vs expansion 
advanced learning algorithms increase performance percent query expansion 
lda neural significantly better baseline experiments regardless representation 
logistic regression performs better lsi representation significant difference 
lsi vs selected terms 
lda logistic regression significantly better lsi features term features 
neural networks equally lsi term features significantly better combination lsi term features significant difference 
logistic regression vs classifiers 
lsi features logistic regression effective learning algorithms friedman test magnitude difference small 
word combined features logistic regression performs lot worse lda neural networks 
linear vs non linear neural networks 
results suggest advantage adding non linear components neural network 
see section discussion lda vs neural networks 
lsi features lda neural networks perform 
neural networks superior lda representations 
best neural network performance combined features slightly better best lda performance lsi features statistically significant 
sharp observer note magnitude significant difference changes depending experiment 
occurs variability learning algorithms greater variability representations 
comparisons experimental runs learning algorithm detect significance smaller average difference 
important advanced learning algorithms capture structure feature data obtained query expansion 
interesting linear neural network works better logistic regression exactly model 
indicates logistic model overfitting training data ability neural network training convergence important advantage 
nn benefit additional information available combining word lsi features classification techniques 
evidence overfitting logistic regression observing performance decreases going lsi term features combined representation 
general feature space increase performance training set hurts performance final evaluation 
price better protection overfitting neural networks slower speed convergence backpropagation gradient descent requires time converge newton raphson 
linear discriminant analysis suffers overfitting explains works successfully compact lsi representation 
able improve performance features applying regularized discriminant analysis uses cross validation adjust problem 
conduct experiment due prohibitive computational cost cross validation large ir problems 
previous suggests rda improve performance applied lsi representation 
best knowledge results lda neural networks best routing results published trec trec 
selection best routing technique operational system may depend efficiency ir performance 
computed sparc neural network solution requires hours query logistic regression requires minutes query lda requires minutes query expansion limited terms requires considerably minute 
include time compute lsi solution minutes 
important factors 
generally assumes routing query standing profile computed advance subject time constraints apply search problems 
experimental set trec routing problem unusual relevance judgements training set initially coming gradually time 
iterative algorithms query expansion equipped deal new training data new solution computed previous optimal setting parameters convergence times reduced 
exist updating algorithms compute revised solution linear discriminant analysis 
lsi solution recomputed scratch unclear neural networks protect overfitting context 
query analysis average performance scores previous section quite informative provide complete picture experimental results 
similar average scores conceal large differences performance individual queries 
section examine experimental results detail query query basis order gain better understanding observed differences methods representations 
focus specific issues 
classification techniques perform better worse relevance feedback query expansion 
second optimal choice representation depend characteristic query 
third linear non linear neural networks perform equally average individual queries non linearity helpful 
query expansion vs linear neural network 
table examines difference query expansion linear neural network terms input presents queries largest differences methods 
neural network performs better expansion queries average improvement 
note despite high standard deviation average difference expansion neural network lda significant anova friedman test 
hypothesized queries expansion successful learning algorithms ones feature selection resulted loss information 
tested hypothesis looking baseline scores queries word features 
correlation performance neural networks poor performance feature selection algorithms 
far unable find patterns indicate characteristics query relevant documents amenable learning algorithms 
lsi vs term features 
table compares performance linear neural network lsi terms 
queries largest differences methods 
average precision lsi better queries worse queries ties 
virtually difference average performance differences individual topics large topics difference 
analyzed top documents topics representations determine possible reasons large individual differences 
topic airbus subsidies specifies relevant articles describe government assistance dispute european american manufacturer 
term method better job capturing condition decision rule 
ranked trec topic delta expansion terms human genome project political impact protect farmers 
health hazards fine diameter fibers demographic shifts boundaries international military equipment sales management problems united nations israeli role iran contra affair hubble space telescope airbus subsidies mean topics std 
dev 
topics table query expansion vs linear network terms input 
topics greatest differences non interpolated average precision 
trec topic delta lsi terms human genome project demographic shifts alternatives traditional cancer therapies diversification pacific machine translation mcdonnell douglas contracts military aircraft management problems united nations israeli role iran contra affair hubble space telescope airbus subsidies mean topics std 
dev 
topics table linear network input lsi vs selected terms 
topics marked differences non interpolated average precision 
trec topic delta non linear linear israel iran contra new cancer fighting drugs control insider trading management problems united nations iran revolution iranian support hostage takers merit pay vs japanese regulation insider trading alternatives traditional cancer therapies mean topics std 
dev 
topics table linear vs non linear neural networks 
topics marked differences non interpolated average precision 
relevant articles higher lsi method contained indicators subsidies trade conflicts 
examples documents highly weighted terms indicating subsidies trade conflicts ap manufacturer competitive advantage aircraft airbus 
conversely classifier ranked non relevant documents high government involvement precise kind involvement required topic subsidies 
examples include ap ap corruption charges concerning airbus deals india taiwan government talks mcdonnell douglas 
apparently exact term features succeeded differentiating different kinds government involvement 
relevance topic hubble depend small number highly weighted terms hubble telescope defect articles hubble defective mirror 
theme features don capture helpful information case lsi disadvantage example 
topic demographic shifts economic impact 
condition economic impact shift expressed different ways 
particular numbers text indication economic data 
articles ranked higher lsi scheme population growth san francisco bay area ap job growth california 
general top ranked terms included term representation insufficient topic 
example highly relevant sentence contain terms nation grew people americans left industrial agricultural south west 
consequently lsi classifier ranked relevant document ap contains high 
topic non relevant articles ranked high term classifier mention economic consequences 
articles don cover economic implications receive high ranks massachusetts loses seat montana loses seat california san francisco bay area 
clues pool terms reliable decisions article covered economics 
insufficient coverage relevant vocabulary explain poor performance term classification topic human genome project 
example document zf donation microsoft university washington 
due passing human genome initiative contains indicators mislead term classifier gives rank 
lsi representation captures medical theme article gives rank 
summary small number terms reliably indicate relevance term methods superior lsi lsi classifier infer presence individual terms indirectly lsi features linear combinations terms 
contrast number indicators large lsi superior integrate information terms 
linearity vs non linearity 
table looks difference performance linear non linear neural networks 
non linear network performs better linear network queries ties average difference methods basically zero 
standard deviation differences extreme differences relatively small 
differences distributed fashion suggests result noise 
obtain evidence examined extreme topics bit closely 
topic relevant documents local region 
non linear network ranks higher ties 
topic relevant documents local region 
linear network ranks higher ties 
results close statistically significant sign test 
difference query performance extreme topics safe conclude non linear component neural network provides absolutely advantage individual queries 
large numbers input variables advantage modeling non linearity insufficient training data ir context 
compare approaches document routing relevance feedback query expansion statistical classification error minimization 
show advanced classification algorithms perform better relevance feedback tipster document collection 
learning algorithms error minimization numerical optimization computationally intensive prone overfitting high dimensional feature space necessary apply method dimensionality reduction 
examine different approaches latent semantic indexing feature selection terms test 
experiments indicate latent semantic indexing effective classification techniques linear discriminant analysis logistic regression way protect overfitting 
neural networks perform equally set features take advantage additional information available terms lsi factors input 
provide evidence non linear extensions classifiers rda non linear neural networks improve performance probably tipster data collection accurately learn complex models 
past evidence suggested weak learning algorithm relevance feedback high dimensional feature space terms optimizes performance 
interpret results evidence alternative approach complex learning algorithms reduced feature space practical beneficial routing problem 
acknowledgments 
indebted michael berry marti hearst implementing text tiling algorithm jerry friedman advice regularized discriminant analysis john tukey helpful comments 
sigir reviewer excellent comments 
apte damerau weiss 
language independent automated learning text categorization models 
proc 
th int conference ir sigir pages 
rik belew 
adaptive information retrieval connectionist representation retrieve learn documents 
proceedingsof sigir pages cambridge ma 
michael berry 
large scale sparse singular value computations 
international journal supercomputer applications 
chris buckley gerard salton james allan 
effect adding relevance information relevance feedback environment 
proceedings sigir pages 
wm 
cooper chen 
full text retrieval probabilistic equations coefficients fitted logistic regression 
pages 

croft callan broglio 
trec routing adhoc retrieval evaluation inquery system 


douglass cutting jan pedersen kristian 
object oriented architecture text retrieval 
conference proceedings riao intelligent text image handling barcelona spain pages april 
available xerox parc technical report ssl 
deerwester dumais furnas landauer harshman :10.1.1.108.8490
indexing latent semantic analysis 
journal american society information science 
susan dumais 
latent semantic indexing lsi trec 
second text retrieval conference trec pages 

friedman 
analysis 
journal american statistical association 
norbert fuhr 
optimum polynomial retrieval probability ranking principle 
acm transactions information systems 
norbert fuhr pfeifer 
probabilistic information retrieval combination abstraction inductive learning probabilistic assumptions 
acm tois jan 

methods statistical data analysis multivariate observations 
john wiley sons new york 
donna harman 
overview trec conference 
proceedings sigir 
donna harman editor 
proceedings nd text retrieval conference trec 
donna harman editor 
proceedings rd text retrieval conference trec 
appear 
marti hearst 
multi paragraph segmentation expository discourse 
proceedings nd meeting association computational linguistics june 
david hull 
statistical testing evaluation retrieval performance 
proc 
th acm sigir conference pages 
david hull 
improving text retrieval routing problem latent semantic indexing 
proceedings sigir pages 
david hull 
information retrieval statistical classification 
phd thesis stanford university 
kwok 
experiment component theory probabilistic information retrieval single terms document components 
acm transactions information systems 
david lewis marc ringuette 
comparison learning algorithms text categorization 
symposium document analysis information retrieval 
university nevada las vegas 
david lewis 
evaluation phrasal clustered representations text categorization task 
sigir pages 
david lewis philip hayes 
special issue text categorization 
guest editorial 
acm transactions information systems 
masand gordon david waltz 
classifying news stories memory reasoning 
sigir pages 
mccullagh nelder 
generalized linear models chapter pages 
chapman hall nd edition 
robertson walker jones 
okapi trec 
text retrieval conference 
rumelhart hinton williams 
learning internal representations error propagation 
david rumelhart james mcclelland pdp research group editors parallel distributed processing 
explorations microstructure cognition 
volume foundations 
mit press cambridge ma 
david rumelhart richard durbin richard golden yves chauvin 
backpropagation basic theory 
yves chauvin david rumelhart editors back propagation theory architectures applications 
lawrence erlbaum hillsdale nj 
gerard salton chris buckley 
term weighting approaches automatic text retrieval 
information processing management 
gerard salton chris buckley 
improving retrieval performance relevance feedback 
journal american society information science 
hinrich schutze jan pedersen marti hearst 
xerox trec report combining exact fuzzy predictors 

appear 
richard tong lee 
machine learning knowledge routing trec experiment 
pages 

erik wiener jan pedersen andreas weigend 
neural network approach topic spotting 
fourth annual symposium document analysis information retrieval las vegas nv 
appear 
ross wilkinson philip 
cosine measure neural network document retrieval 
sigir pages chicago 
yiming yang 
expert network effective efficient learning form human decisions text categorization retrieval 
proceedings sigir pages 
