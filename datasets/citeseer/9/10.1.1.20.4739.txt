efficient kernel calculation multirelational data stefan cs department ai unit university dortmund dortmund germany mail ls cs 
de 
today data business applications stored relational database systems data warehouses built top relational database systems 
data available processed standard learning algorithms reasonable time 
presents extension kernel algorithms compact relational representation data usual attribute value representation significantly speed kernel calculation 
keywords 
support vector machines efficiency today data business applications stored relational database systems data warehouses built top relational database systems 
relational databases built defined theoretical model data stored retrieved deal questions revolve data real world settings efficiency effectiveness storage queries security data usability handling meta data 
cheap storage space efficiency modern database systems storing querying data led creation large databases contain complete business information large companies 
task knowledge discovery databases find hidden knowledge data may helpful better understand optimize companies businesses 
task knowledge discovery requires process extremely large amounts data useful machine learning algorithms applied developed smaller data sets scale deal gigabytes data 
case sampling hope generate subset data small processed learning algorithm reflects original data close give acceptable results 
increase performance flexibility data mining applications research currently done move data mining database avoid costly transport data database servers application machines 
targets especially step data preprocessing clean transform data 
step complex final learning task 
worse preprocessing steps taken order apply result new examples 
kietz describe efforts real world application knowledge discovery spent finding appropriate pre processing data 
meta data framework re kdd applications centered keeping data data operations database possible 
learning representation relational data model specifies data kept relations 
relation set tuples attribute value tuple member fixed domain 
practice relations stored database tables table row defines tuple relation table column defines attribute relation attribute domain fixed column type 
ideally relation stands certain real world concept split meaningful sub concepts bank customer name address customer number banking customer number account number credit limit account transaction account numbers amount money 
trick multirelational data tables taken combined query data complex ways 
relational algebra describes semantics database queries implemented standard query language sql main operators selection projection join 
selection selects tuples relation respect different criteria 
projection selects attributes relation 
join combines data different relations equality specified attributes 
selection projection decreases size data join tables size produce table size 
problem data mining 
notable exception inductive logic programming learning algorithms deal multirelational data attribute value representation data 
generate representation information necessary learning compiled single relation means building complex query possibly joins 
think combining personal account information bank transactions build data set detect fraud 
concise usually natural multirelational representation large redundant representation 
size data learner handle increased 
algorithmic solution allows certain types learning algorithms learning algorithms kernel functions multi relational structure attributevalue representation increase efficiency training 
discussion restricted case joining tables 
extension case constructing attribute value representation selection projection straight forward 
chapter give support vector machines svms prominent representative class kernel machines 
especially problem efficiently solving svm problem discussed 
chapter introduce idea kernel evaluation joined data chapter give experimental results 
kernel machines support vector machines principles support vector machines statistical learning theory known give short parts important context 
particular discuss support vector machines classification 
see detailed svms svms regression 
support vector machines try find function wx minimizes expected risk dp yjx dp learner minimizing regularized risk reg weighted sum empirical risk remp respect data complexity term jjwjj reg jjwjj optimization problem efficiently solved dual formulation 
min resulting decision function shown svm solution depends support vectors fx 
kernels support vector machines allow nonlinear decision functions kernel function replace inner product 
inner product high dimensional feature space 

decision function popular kernel functions radial basis kernel exp jjx yjj polynomial kernel neural net kernel tanh 
kernel function practically function linear product euclidian distance examples jjx yjj 
svm implementations practical implementations support vector machines turns solving quadratic optimization problem standard algorithms efficient algorithms require quadratic matrix computed stored main memory 
tricks speed calculation svm solution dramatically 
working set decomposition improve efficiency svm calculation osuna suggest split problem sequence simpler problems fixing variables optimizing rest called working set 
procedure iterated variables satisfy optimality conditions global problem 
optimality conditions kuhn tucker conditions quadratic optimization problem essentially conditions gradient target function lagrangian multipliers 
joachims proposes efficient effective method selecting working set 
shrinking joachims proposes improvements optimization problem 
usually variables lie boundaries tend stay early optimization process 
case usually rough location decision boundary early time spent find exact location 
examples lie far away decision boundary spotted easily 
exploited idea shrinking optimization problem variables optimal certain number iterations fixed position re examined iteration 
kernel caching third trick improve svm efficiency involves caching kernel functions 
selection working set check optimality conditions require computation gradient 
th component gradient 
values computed updated variable changes variable updated kernel row 
xn needed incrementally update gradient 
certain subset variables gets working set caching kernel rows significantly improve performance 
usually cache strategy 
optimization support vector machines important observation calculating kernel function expensive part training support vector machines 
kernel machines trick replacing linear product kernel function increase hypothesis space learning algorithm greater class non linear functions applied learning support vector machines example principal component analysis kernel fisher discriminant analysis algorithms performance arguments evaluation kernel function apply svms 
efficient kernel joined data said compilation multirelational data single relation concise multirelational representation considerably 
joining tables worst case row table joined row second table 
means piece information row original table final single table 
original data large final data 
important observation inner product dimensional points calculated sum dimensional inner product 

similar observation holds euclidian distance jj jj jjx jj jjx jj means kernel matrix size 
suffices compute matrixes size inner products euclidian distances vectors respectively calculate kernel values 
case kernel caching trick allows far efficient organization kernel cache independent caches 
see example data set 
consists dimensional examples hold entire kernel matrix kernel rows cached 
data set viewed join tables table contributes attributes fx second tables contributes attributes fx 
tables shown 
hold respective kernel matrixes tables total rows cached 
example data set 
join subsets example data set 
reconstruct data set need information combine individual tables 
altogether storage complete table requires store values data plus kernel rows dimension storage decomposed join requires store values data kernel rows dimension respectively 
compute kernel row 
xn compute rows inner products squared euclidian distances case subspaces attributes rows corresponding example subspaces cached avoid re computation original examples may projection subspaces think bank transaction example examples belonging customer projected customer information different transaction information 
final kernel row calculated row row join information example data set 
kernel rows adding entries rows eventually applying kernel specific function values see section 
needs known combine single kernel rows joined kernel row mappings map index example join table indexes components component tables shown 
mapping easily computed query generate join data 
mapping generated query just data corresponding index values 
cache strategies assuming learning algorithm may maximal amount cache memory different strategies memory split different kernel caches 
easiest cache strategy split available cache memory evenly caches 
clever way possible split cache memory depending size data kernel 
ensure sub kernels cache fraction rows 
assuming kernel rows need cached distributed evenly kernel rows sub kernels optimal cache strategy equal probability cache kernel 
distribute available cache memory sub kernels dynamically 
new kernel row computed space left cache cache row sub kernel caches moved cache 
useful case limited number kernel rows sub kernel kernel rows sub kernels needed 
situation interesting link feature selection svms important features kernel rows kernel needed iterations values features example lie far away decision boundary recognized easily early optimization process 
computation kernel row rows sub kernels trivial may idea level caching approach available memory cache rows sub kernels cache additional rows kernel 
especially high dimensional data performance gain needing recompute cache rows exceed overhead having maintain cache structures far 
test cache kb test cache kb cache size kb tests 
experiments experiments artificial data set generated consisted examples drawn cartesian product tables examples dimension 
examples classified linear decision function noise correspondingly linear kernel 
svm implementation experiments 
high dimensionality examples chosen calculation inner product examples costly cache misses high impact runtime 
results valid regardless dimension examples size kernel matrix caching process independent dimension examples 
terms runtime influence examples dimension linear factor inner product calculated 
final svm solution examples ended support vectors 
experiment standard svm compared svm caching sub kernels fixed evenly split cache size 
cache size varied mb mb see table 
quick calculation shows caching complete kernel matrix level joined data need mb cache caching kernel rows corresponding support vectors need mb cache 
average runtime svm implementations compared 
line labeled global cache shows runtime usual svm implementation caches kernel rows attributes 
see small cache sizes runtime increases dramatically kb cache hours 
large cache sizes mb runtime stays constant 
case cache large contain kernel matrix kernel values re computed 
line labeled local cache shows performance svm uses cache inner products attributes part join 
runtime stays constant tested cache sizes 
means test 
local cache global cache comparison average runtime local global caching approach 
smaller cache sizes large hold complete sub matrixes 
case runtime dramatically reduced compared global cache svm 
experiments local cache svm slightly slower global cache full cache compared 
small difference result statistical error expected getting kernel row local cache svm involves combining kernel rows returned single row means addition example training set 
global cache svm row read cache done constant time 
combined caching strategies 
saw cache sizes full small compared complete kernel cache 
means small total cache sizes space cache kernel rows global level 
compares runtime approaches 
runtime combined cache approach half third runtime local approach depending total size cache 
caching algorithm kernel machines relational structures data 
allows efficient compact calculation kernel values compared usual attribute value representation 
cache algorithm tested svms kernel algorithms 
test 
local cache local global cache comparison average runtime local combined global local caching approach 
acknowledgments financial support deutsche forschungsgemeinschaft sfb reduction complexity multivariate data structures gratefully acknowledged 

burges 
tutorial support vector machines pattern recognition 
data mining knowledge discovery 

pete chapman julian clinton thomas thomas wirth 
crisp dm process model 
technical report dm consortium ncr systems engineering copenhagen daimlerchrysler ag integral solutions en bank march 
project partially funded european commission esprit program 

joachims 
making large scale svm learning practical 
scholkopf burges smola editors advances kernel methods support vector learning chapter 
mit press cambridge ma 

jorg uwe kietz regina zucker 
mining mart combining case reasoning multi strategy learning framework reuse kdd application 
brazdil editors proceedings fifth international workshop multistrategy learning msl portugal may 

sebastian mika gunnar ratsch jason weston bernhard scholkopf klaus robert muller 
fisher discriminant analysis kernels 

hu larsen wilson douglas editors neural networks signal processing ix pages 
ieee 

stephen muggleton editor 
inductive logic programming 
academic press 

osuna freund girosi 
improved training algorithm support vector machines 
principe giles morgan wilson editors neural networks signal processing vii proceedings ieee workshop pages new york 
ieee 


data preparation data mining 
morgan kaufmann publishers 

stefan 
manual 
universitat dortmund lehrstuhl informatik viii 

cs uni dortmund de software 

bernhard scholkopf robert williamson alex smola john shawe taylor 
sv estimation distribution support 
solla leen 
muller editors neural information processing systems 
mit press 
forthcoming 

alex smola bernhard scholkopf 
tutorial support vector regression 
technical report neurocolt technical report series 

vapnik 
statistical learning theory 
wiley chichester gb 
