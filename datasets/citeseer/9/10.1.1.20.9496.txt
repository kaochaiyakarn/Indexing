optimal control squares support vector machines suykens vandewalle de moor katholieke universiteit leuven department electrical engineering esat leuven heverlee belgium tel fax email johan suykens esat kuleuven ac corresponding author johan suykens running title optimal control ls svm neural networks pp research carried esat laboratory interdisciplinary center neural networks icnn katholieke universiteit leuven framework fwo project learning optimization interdisciplinary approach belgian programme poles attraction initiated belgian state prime minister oce science technology culture concerted action project mips flemish community 
johan suykens postdoctoral researcher national fund scienti research fwo flanders 
optimal control ls svm support vector machines successful pattern recognition function estimation problems 
introduce squares support vector machines ls svm optimal control nonlinear systems 
linear neural full static state feedback controllers considered 
problem formulated way incorporates stage optimal control problem squares support vector machine approach mapping state space action space 
solution characterized set nonlinear equations 
alternative formulation constrained nonlinear optimization problem unknowns method imposing local stability control scheme 
results discussed support vector machines radial basis function kernel 
advantages ls svm control number hidden units determined controller centers speci ed gaussian kernels applying mercer condition 
curse dimensionality avoided comparison de ning regular grid centers classical radial basis function networks 
expense trajectory state variables additional unknowns optimization problem classical neural network approaches typically lead parametric optimization problems 
svm methodology number unknowns equals number training data primal space number unknowns nite dimensional 
method illustrated stabilization tracking problems including examples swinging inverted pendulum local stabilization endpoint tracking problem ball beam system 
keywords 
neural optimal control support vector machines radial basis functions 
optimal control ls svm backpropagation time werbos dynamic backpropagation narendra parthasarathy area neural optimal control focusing gradient approaches backpropagation type solutions dynamical systems involving neural networks 
modelbased approaches stage optimal control problem bryson ho studied combination structures neural controller 
example nguyen widrow applied backpropagation problem backing trailer truck neural network emulator plant 

full static state feedback controller studied context optimal control relating lagrange multiplier sequence backpropagation algorithm 
assumed linear structure preserving principle state tracking problem application control space robot 
studied case optimal nal time 
suykens 
problem swinging inverted pendulum double inverted pendulum stabilization endpoint formulated parametric optimization problem unknown weights feedforward recurrent neural controllers 
discuss stage optimal control squares support vector machines ls svm 
support vector machines introduced solving pattern recognition function estimation problems vapnik sch olkopf 
method maps data higher dimensional input space constructs optimal separating hyperplane space 
exploits mercer theorem avoids explicit formulation nonlinear mapping 
solution written weighted sum data points 
original formulation solves quadratic programming problem yields zero weights 
data points corresponding non zero weights called support vectors 
kernel function parameters chosen bound generalization error minimized expressed terms vc dimension 
possibility polynomials splines radial basis function networks multilayer perceptrons kernels 
preferably applies mercer condition absolutely necessary shown suykens optimal control ls svm vandewalle standard multilayer perceptron classi ers xed number hidden units trained svm methodology 
structural risk minimization principle capacity concept pure combinatorial de nitions quality complexity svm solution depend directly dimensionality input space 
svm control method squares version support vector machines 
originally vapnik epsilon insensitive loss function employed function estimation problem 
squares interpretation hand saunders 
function estimation problems suykens vandewalle classi cation uller 
time series prediction 
case problem formulation involves equality inequality constraints support values proportional errors data points simpli es problem 
sparseness gets lost function estimation corresponds form ridge regression imposed doing pruning support value spectrum suykens 
optimal control method ls svm stage optimal control problem optimization problem related ls svm controller incorporated problem formulation 
model assumed available plant controller designed model applied plant assuming certainty equivalence principle holds similar nguyen widrow emulator approach 
solution characterized set nonlinear equations 
set nonlinear equations typically contain large number unknowns 
alternative formulation ls svm control unknowns 
formulation enables incorporate local stability constraints 
main di erence standard neural network approaches mlp rbf ls svm control solves parametric optimization problem unknown interconnection weights state vector sequence part unknown parameter vector optimization problem 
standard methodologies su er problems choice number hidden units needed order accomplish control task 
speci cally optimal control ls svm case rbf networks curse dimensionality de nes regular grid centers hidden units state space explained method 
ls svm control case centers follow optimal trajectory seeks 
furthermore standard neural network approaches primal weight space svm methodologies computations done dual space number unknowns equals number training data points number weights primal space nite dimensional 
illustrate ls svm control method number simulation examples including swinging inverted pendulum local stabilization endpoint tracking problem ball beam system 
suykens 
methods realizing transition states local stabilization target point discussed 
illustrated swinging inverted pendulum local stabilization endpoint 
full static state feedback case linear quadratic regulator lqr franklin designed balancing pole upright position 
result order impose set constraints interconnection weights multilayer perceptron controller 
drawback approach number hidden units neural controller chosen ad hoc 
solution svm control takes account lqr design ls svm control rbf kernel 
number hidden units determined number stage optimal control problem formulation 
local linear lqr design possibility apply robust linear control methods boyd control theory order take account uncertainties parametric uncertainties unmodelled dynamics noise 
example ball beam system hauser tracking problem svm control discussed 
lqr design incorporated order impose local stability origin autonomous closed loop system 
imposing robust local stability closed loop system successful application neural control theory introduced suykens 
control reallife ball beam system 
theory sucient conditions optimal control ls svm global asymptotic stability input output stability nite gain available employed order impose robust local stability origin closed loop system 
similar approach followed ls svm control ball beam system robust local stability realized 
organized follows 
section formulate stage optimal control problem 
section review support vector machines 
section discuss optimal control squares support vector machines 
section discuss alternative formulation stability constraints 
section examples 
stage optimal control problem stage optimal control problem aims solving problem bryson ho min jn subject system dynamics 

positive de nite functions 
typical choice quadratic cost qx ru qx 
functions 


assumed twice continuously di erentiable 
denotes state vector input system 
methods discussed restricted single input systems 
order nd optimal control law constructs lagrangian ln jn lagrange multipliers conditions optimality fletcher optimal control ls svm ln adjoint equation ln xn xn adjoint nal condition ln variational condition ln system dynamics case quadratic cost function subject linear system dynamics nite time horizon optimal control law represented full static state feedback control 
general optimal control law represented state feedback optimal control law may depend state 
interested nding suboptimal control strategy form 
context neural control 
considered addition 
parametrized neural network architecture discussed link backpropagation algorithm 
consider control law form relating support vector machines 
svm methodology parametric modelling approach straightforward comparison standard neural networks mlp rbf 
support vector method function estimation section review basic ideas support vector method function estimation essential neural control problem considered sequel 
details svm refer vapnik vapnik 
sch olkopf 
smola 
cherkassky haykin 
optimal control ls svm consider regression set functions training data fx denotes number training data input data output data 
nonlinear mapping maps input data called high dimensional feature space nite dimensional support vector method aims minimizing empirical risk emp subject elements structure de ned inequality loss function employs vapnik insensitive model estimation problem formulated optimization problem min subject constraints slack variables positive real constant 
obtains obtained solving quadratic program lagrange multipliers related rst second set constraints 
data points corresponding nonzero values called support vectors 
typically values equal zero 
obtains model dual space optimal control ls svm kernel function corresponds mercer condition 
possibilities choice kernel function including linear polynomial splines rbf 
sequel focus rbf kernels 
uence number support vectors generalization performance theoretically studied vapnik 
extension studied context insensitive loss function corresponds 
general convex cost functions investigated smola 
furthermore links loss functions regularization theory studied smola 

sequel employ squares version support vector method investigated saunders 
suykens vandewalle function estimation classi cation problems respectively 
corresponds form ridge regression golub van loan min ls subject equality constraints de nes lagrangian ls ls lagrange multipliers positive negative due equality constraints follows kuhn tucker conditions fletcher 
optimal control ls svm conditions optimality lls lls lls lls written solution set linear equations elimination xm ym ij support values proportional errors data points case values equal zero 
sparseness lost squares case imposed pruning support value spectrum suykens 
norms huber loss function appropriate concerning robustness smola squares norms applications identi cation control theory context prediction error algorithms ljung 
restrict squares case equality constraints problem formulation tractable svm version inequality constraints order introduce svm context optimal control 
optimal control ls svm optimal control support vector machines relate training data fx state space action space fx state stage optimal control problem min jn subject system dynamics control law jn de ned 
number hidden units nite dimensional 
actual control signal applied plant assumed 
linear control case sequel employ radial basis function rbf kernels 
support vector method originally introduced exploits mercer condition doesn construct 
kernel function preferred evaluate 
explicitly demonstrated suykens vandewalle multilayer perceptron classi ers 
rbf case exp kx chosen centers chosen constant 
take example set fc equal fx order avoid additional unknown parameters centers motivated regularization networks poggio girosi 
standard svm theory static function estimation problems selected minimize upper bound generalization error 
bounds applicable context svm control due fact input patterns activation function independent 
chosen hoc number hidden units ls svm kernel function optimal control ls svm typically avoid values small taken additional unknown cost function order nd optimal control law construct lagrangian jn conditions optimality adjoint equation xn xn adjoint nal condition variational condition support vectors support values system dynamics svm control rbf kernels exp kx set nonlinear equations form xn optimal control ls svm numerically solved unknown variables 
appendix formulation variables 
comparison function estimation classi cation problems looses advantage solving quadratic program linear squares problem 
able exploit interesting svm features 
svm theory mercer condition applied replacing equations 
kernels satisfying mercer condition impose rbf kernels takes vapnik exp kx positive real constant 
sees doesn contain centers 
elimination set nonlinear equations form xn obtained 
speci cally exploiting mercer condition xn rbf kernels exp kx optimal control ls svm actual control signal applied plant fx obtained solving set nonlinear equations actual state vector time data fx support vector data control signal 
furthermore note taken equal zero 
alternative formulation local stability section give alternative formulation ls svm control approach unknowns method imposing local stability origin autonomous closed loop system 
consider optimization problem min jn subject formulation state vector considered taken respect 
regularization term included see smola positive real constant 
solving set nonlinear equations solves constrained nonlinear optimization problem unknowns approaches previous section 
formulation di erence standard neural network controllers ls svm control clear 
solves parametric optimization problem unknown interconnection weights state vector sequence part unknown parameter vector optimization problem 
furthermore standard neural network approaches primal weight space svm methodology computations done dual space number unknowns equals number training data points number weights primal space nite dimensional 
optimal control ls svm rbf kernels parameter taken additional unknown cost function 
applying optimization method constraints hold certain tolerance 
small numerical errors may lead di erences state vectors solution simulation closed loop system ls svm control especially control unstable systems 
control stable systems problem critical 
simulation closed loop system ls svm control needed order validate results fx obtained solution 
order impose local stability xed equilibrium point eq locally linearizes autonomous closed loop simulation model evaluating eq ls svm control design local stability constraint formulated min jn eq subject eq eq pa eq denotes negative de nite symmetric matrix 
imposing robust local stability closed loop system successfully applied context neural control theory suykens 
theory sucient conditions global asymptotic stability input output stability nite gain available employed order impose robust local stability origin closed loop system 
stability criteria dynamic backpropagation modi ed imposing matrix inequality constraints 
robust local stability imposed 
optimal control ls svm simulation examples example illustrate ls svm optimal control method section example reported narendra mukhopadhyay 
nonlinear system consider state vector tracking problem ru trajectory tracked 
aim tracking rst state variable choose sin cos 
initial state 
control law taken results slight modi cation 
fig simulation results shown method mercer condition 
set nonlinear equations solved matlab optimization toolbox function unknowns variables eliminated 
unknowns randomly initialized zero mean standard deviation 
plots show simulation results closed loop system rbf kernel 
controller generalizing respect initial conditions origin trained time horizon 
method mercer condition gave similar results centers fc equal fx example inverted pendulum example illustrate ls svm control method section problem swinging inverted pendulum local stabilization endpoint investigated suykens 

optimal control ls svm nonlinear state space model inverted pendulum fig system mlx mg sin ml sin state variables respectively position velocity cart angle pole vertical rate change angle 
input signal force applied cart center mass symbols denote respectively mass pole total mass cart pole half pole length acceleration due gravity 
take 
autonomous case pole pole equilibrium points 
linearized system target equilibrium point origin ax bu mg suykens 
neural controller linear quadratic regulator lqr controller franklin boyd designed rst linearized model eventually robust linear controllers designed control theory additional robustness respect noise uncertainties needed 
done order impose set constraints choice interconnection weights multilayer perceptron controller 
result swinging neural control obtained ensures pole remains locally stabilized upright position 
optimal control ls svm order solve swinging problem ls svm control follow somewhat similar approach ls svm control case 
continuous time model design lqr controller lqr cost function qx ru dt matlab function lqr 
continuous time model discretized fourth order runge kutta integration rule constant step discrete time model form assumed constant time intervals kh zero order hold 
control law taken lqr 
svm svm lqr resulting feedback matrix lqr design 
svm modi cation ls svm control law locally origin controller acting lqr controller continuous time sense 
mixture continuous time lqr result discrete time svm control law may look surprising rst sight convenient way design ls svm controller continuous time model 
approach complicated due runge kutta integration rule 
rbf kernel function expression applied order compute 
resulting closed loop simulation model lqr 

fx solution constrained optimization problem 
cost function de ned jn kx optimal control ls svm 
time horizon taken seconds 
constrained optimization problem solved matlab optimization toolbox sqp sequential quadratic programming function constr 
values initialized small random values 
parameter rbf kernel taken additional unknown optimization problem starting point 
order emphasize equations constraints multiplied factor 
needed due fact system controlled unstable small di erences solution simulation model may cause large di erences 
simulation results closed loop simulation model shown fig 
example ball beam discuss ls svm control method section ball beam system described hauser 

continuous time system description ball beam system fig sin ball position beam angle mass moment inertia radius ball respectively 
control input mgr cos denote torque applied beam acceleration gravity moment inertia beam respectively 
control objective consider tracking ball position input cos 
inverted pendulum example lqr design incorporated ls svm control law 
impose local stability autonomous closed loop system motivated application neural control theory suykens optimal control ls svm control real life ball beam system 
proceed similar way inverted pendulum system 
continuous time state space description linearized origin lqr controller designed lqr cost function 
continuous time model discretized fourth order runge kutta integration rule constant step discrete time model form 
rst component state vector derived step size 
control law taken lqr 
svm svm lqr resulting feedback matrix lqr autonomous closed loop system 
svm note depends zero intial state taken 
sqp applied constrained nonlinear optimization similarly chosen initial unknown parameter vector inverted pendulum example 
simulation results closed loop simulation model shown fig 
introduced support vector machines solving optimal control problems 
stage optimal control problem formulated nonlinear state feedback controller consisting support vector machines 
squares version svm considered leading equality constraints inequality constraints result example vapnik epsilon insensitive loss function 
sparseness lost squares case svm features applicable mercer condition fact centers determined rbf optimal control ls svm kernels 
order keep optimal control problem formulation tractable equality constraint formulation svm preferred motivating ls svm 
cost function control problem squares svm formulated objective function 
solution characterized set nonlinear equations 
drawback approach problem contains unknowns equality constraint case ls svm 
alternative formulation ls svm optimal control unknowns 
imposing local stability control law discussed 
main di erence ls svm control neural speci cally rbf controllers case state vector sequence considered time horizon supporting control signal obtained solution constrained nonlinear optimization problem solves parametric optimization problem unknown interconnection weights 
number hidden units ls svm rbf kernel control law equals considered number points discrete time evolution primal weight space number parameters nite 
special attention paid closed loop simulation models ls svm controllers result di er solution constrained optimization problem especially control unstable systems 
examples ls svm control swinging inverted pendulum local stabilization upright position tracking ball beam system 
optimal control ls svm bishop 

neural networks pattern recognition oxford university press 
boyd 

linear controller design limits performance prenticehall 
bryson ho 

applied optimal control waltham ma 
cherkassky 

learning data concepts theory methods john wiley sons 
fletcher 

practical methods optimization chichester new york john wiley sons 
franklin powell 

digital control dynamic systems reading ma addison wesley 
gill murray wright 

practical optimization london academic press 
golub van loan 

matrix computations baltimore md johns hopkins university press 
hauser sastry 

nonlinear control approximate inputoutput linearization ball beam example ieee transactions automatic control vol pp 
haykin 

neural networks comprehensive foundation macmillan college publishing englewood cli nd edition 
ljung 

system identi cation theory user prentice hall 
uller smola sch olkopf kohlmorgen vapnik 
predicting time series support vector machines icann proc 
int 
conf 
arti cial neural networks eds 
gerstner 
nicoud lncs spinger berlin pp 
optimal control ls svm narendra parthasarathy 

gradient methods optimization dynamical systems containing neural networks ieee transactions neural networks vol pp 
narendra mukhopadhyay 

adaptive control neural networks approximate models ieee transactions neural networks vol pp 
nguyen widrow 

neural networks self learning control systems ieee control systems magazine pp 


neural networks feedback feedforward nonlinear control systems ieee transactions neural networks vol pp 


optimal control terminal processes neural networks ieee transactions neural networks vol pp 
poggio girosi 

networks approximation learning proceedings ieee vol pp 
renders 
bersini 

neural controllers backpropagation algorithm 
ieee press book intelligent control theory practice gupta sinha eds ieee press 



gaussian networks direct adaptive control ieee transactions neural networks vol pp 
saunders gammerman vovk 

ridge regression learning algorithm dual variables proceedings th international conference machine learning icml madison wisconsin 
sch olkopf sung burges girosi niyogi poggio vapnik 

comparing support vector machines gaussian kernels radial basis function classi ers ieee transactions signal processing vol pp 
optimal control ls svm sch olkopf burges smola 
eds 
advances kernel methods support vector learning mit press cambridge ma 


robust stability discrete systems international journal control vol pp 
smola sch olkopf uller 

connection regularization operators support vector kernels neural networks vol 
smola sch olkopf 

kernel method pattern recognition regression approximation operator inversion 
algorithmica pp 
smola 

learning kernels phd thesis published gmd birlinghoven 
suykens de moor vandewalle 

static dynamic stabilizing neural controllers applicable transition equilibrium points neural networks vol pp 
suykens vandewalle de moor 

arti cial neural networks modelling control non linear systems kluwer academic publishers boston 
suykens de moor vandewalle 

nl theory neural control framework global asymptotic stability criteria neural networks vol pp 
suykens vandewalle 

training multilayer perceptron classi ers modi ed support vector method ieee transactions neural networks vol pp 
suykens vandewalle 

squares support vector machine classi ers neural processing letters vol pp 
suykens vandewalle 
sparse approximation squares support vector machines ieee international symposium circuits systems iscas geneva switzerland may pp ii 
optimal control ls svm suykens vandewalle 
sparse squares support vector machine classi ers th european symposium arti cial neural networks esann bruges belgium pp 
vapnik 

nature statistical learning theory springer verlag newyork 
vapnik smola 

support vector method function approximation regression estimation signal processing advances neural information processing systems mit press 
vapnik 

statistical learning theory john wiley new york 
vapnik 

support vector method function estimation nonlinear modeling advanced black box techniques suykens vandewalle 
eds kluwer academic publishers boston pp 
van acker suykens de moor vandewalle 

application neural control theory ball beam system european journal control pp 
werbos 

backpropagation time proceedings ieee pp 
optimal control ls svm formulation error variables variation problem variables jn subject gives lagrangian jn conditions optimality xn xn note support values directly related lagrange multipliers set nonlinear equations form xn mercer condition applied yielding set equations form xn elimination optimal control ls svm captions figures fig top optimal control squares support vector machine rbf kernel application mercer condition 
full line rst state variable tracked dashed line actual state variable closed loop simulation system 
data training controller origin initial state 
bottom simulation result randomly chosen initial state ls svm controller shows generalization performance respect initial states time horizon 
fig swinging inverted pendulum ls svm controller local stabilization upright position 
target point controller behaving lqr controller 
top inverted pendulum system bottom simulation result visualizes pole positions time 
fig continued top state variables respect time closed loop simulation model ls svm controller 
state vector data vertical line training process support vector data rbf kernel bottom control signal fig continued top middle bottom 
initial state marked square target state fig tracking control ball beam system ls svm controller top ball beam system bottom input position ball 
state vector data vertical line training process support vector data rbf kernel 
shown closed loop simulation result 
optimal control ls svm fig 

optimal control ls svm fig 

optimal control ls svm fig 

optimal control ls svm fig 

optimal control ls svm fig 

