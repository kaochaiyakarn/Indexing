journal parallel distributed computing article id available online www com dynamic mapping class independent tasks heterogeneous computing systems maheswaran department computer science university manitoba mb canada mail cs ca ali howard jay siegel purdue university school electrical computer engineering west lafayette indiana mail ecn purdue edu hj ecn purdue edu debra hensgen department computer science naval postgraduate school monterey california mail hensgen cs nps navy mil richard freund russ boulevard suite san diego california mail home com received december revised may accepted july dynamic mapping matching scheduling heuristics class independent tasks heterogeneous distributed computing systems studied 
types mapping heuristics considered immediate mode batch mode heuristics 
new heuristics batch mode immediate mode introduced part research 
simulation studies performed compare heuristics existing ones 
total immediate mode heuristics batch mode heuristics examined 
immediate mode dynamic heuristics consider varying degrees different ways task affinity different machines machine ready times 
batch mode dynamic heuristics consider factors aging tasks waiting execute 
simulation results reveal choice dynamic mapping heuristic heterogeneous environment depends parameters structure heterogeneity tasks machines arrival rate tasks 
academic press research supported darpa ito quorum program nps subcontract numbers gsa subcontract number gs bh 
equipment donated intel microsoft 
copyright academic press rights reproduction form reserved 
maheswaran key words batch mode mapping dynamic mapping mapping heuristics meta task mapping immediate mode mapping 

general heterogeneous computing hc coordinated different types machines networks interfaces maximize combined performance cost effectiveness 
hc important technique efficiently solving collections computationally intensive problems 
machine architectures advanced obtain higher peak performance extent task exploit architectural feature depends task computational requirements match machine advanced capabilities 
applicability strength hc systems derived ability match computing needs appropriate resources 
hc systems resource management systems rmss govern execution tasks arrive service 
describes compares heuristics rms dynamically assigning independent tasks machines 
general hc system schemes necessary assign tasks machines matching compute execution order tasks assigned machine scheduling 
process matching scheduling tasks referred mapping 
dynamic methods operate tasks arrive 
contrast static techniques complete set tasks mapped known priori mapping done prior execution tasks time available compute mapping :10.1.1.41.5581
hc environment considered tasks assumed independent communications tasks needed 
scenario instance independent users submit jobs collection shared computational resources 
dynamic scheme needed arrival times tasks may random machines suite may go line new machines may come line 
dynamic mapping heuristics investigated study nonpreemptive assume tasks deadlines priorities associated 
mapping heuristics grouped categories immediate mode batch mode heuristics 
immediate mode task mapped machine soon arrives mapper 
batch mode tasks mapped machines arrive collected set examined mapping prescheduled times called mapping events 
independent set tasks considered mapping mapping events called meta task 
meta task include newly arrived tasks ones arriving mapping event ones mapped earlier mapping events execution 
immediate mode heuristics consider task mapping batch mode heuristics consider task mapping mapping event task begins execution 
trade offs immediate mode batch mode heuristics studied experimentally 
mapping independent tasks hc suite known np complete problem throughput optimization criterion 
dynamic mapping independent tasks heuristics discussed maximization throughput primary objective performance measure common production oriented environments 
new heuristics batch mode immediate mode introduced part research 
simulation studies performed compare heuristics existing ones 
total immediate mode heuristics batch mode heuristics examined 
immediate mode heuristics consider varying degrees different ways task affinity different machines machine ready times 
batch mode heuristics consider factors aging tasks waiting execute 
section describes related 
section defines optimization criterion discusses mapping approaches studied 
simulation procedure section 
section presents simulation results 
research part darpa ito quorum program project called mshn pronounced mission management system heterogeneous networks 
mshn collaborative research effort includes naval postgraduate school purdue university southern california 
builds smartnet implemented scheduling framework system managing resources hc environment developed 
technical objective mshn project design prototype refine distributed resource management system leverages heterogeneity resources tasks deliver requested qualities service 
heuristics developed derivatives may included scheduling advisor component mshn prototype 

related related literature examined select set heuristics appropriate hc environment considered perform comparative studies 
section sampling related literature meant exhaustive 
literature mapping tasks machines referred scheduling 
researchers worked dynamic mapping problem areas including job shop scheduling distributed computer systems 
heuristics concerned mapping independent tasks heterogeneous machines completion time finishing task minimized 
problem recognized np complete worst case performance bounds obtained heuristics 
heuristics designed general hc environment rest target heterogeneous machine system general homogeneous system 
heuristics designed general hc environment schedule schedule schedule heuristics simply variations minimum completion time heuristic 
min min heuristic benchmark batch mode mapping schedule heuristics implemented smartnet 
scheme representative techniques mapping communicating subtasks hc suite considering data dependency graphs communication times machines 
environment different set maheswaran independent tasks considered 
heuristics developed different environment appropriate hc environment considered 
dynamic mapping approaches distributed policy centralized policy developed 
heuristic distributed policy uses method similar minimum completion time heuristic node 
mapper node considers local machine highest communication bandwidth neighbors map tasks local queue 
mapper distributed strategy assigns task best machine machines 
centralized heuristic referred global queue equalization algorithm similar minimum completion time heuristic benchmark 
simulation results provided show centralized heuristic performs better distributed heuristic 
minimum completion time heuristic represents better heuristics 
survey dynamic scheduling heuristics job shop environments provided 
classifies dynamic scheduling algorithms approaches knowledge approach conventional approach distributed problem solving approach 
heuristics knowledge approach take long time execute suitable particular dynamic environment considered 
classes heuristics grouped conventional distributed problem solving approaches similar minimum completion time heuristic considered 
problem domains considered involve precedence constraints tasks priorities deadlines differ domain 
distributed computer systems load balancing schemes popular strategy mapping tasks machines 
performance characteristics simple load balancing heuristics hc distributed systems studied 
heuristics consider task execution times making decisions 
survey dynamic scheduling heuristics distributed computing systems provided 
heuristics schedule tasks different machines load sharing techniques considering task execution times 
heuristic load sharing employs deadlines schedule tasks falls problem domain discussed 
load balancing heuristic research representative load balancing techniques 
smartnet rms hc systems employs various heuristics map tasks machines considering resource task heterogeneity 
smartnet heuristics appropriate hc environment considered included comparative study minimum completion time min min max min 

overview 
mapping heuristics expected execution time ij task machine defined amount time taken execute load assigned 
expected completion time ij task machine defined wall clock dynamic mapping independent tasks time mj completes ti having finished previously assigned tasks 
total number machines hc suite 
set containing tasks test set evaluating heuristics study 
arrival time task ti ai time ti begins execution bi 
definitions cij ij 
completion time task ti equal cij machine mj assigned execute task ti complete schedule defined 
makespan measure throughput hc system measure quality service imparted individual task 
performance metric considered 
immediate mode heuristics task considered matching scheduling mapping changed computed 
arrival rate low machines may ready execute task soon arrives mapper 
may beneficial mapper immediate mode task need wait mapping event execution 
recall section immediate mode mapper assigns task machine soon task arrives mapper batch mode set independent tasks need mapped mapping event called meta task 
systems term meta task defined way allows inter task dependencies 
batch mode ith mapping event meta task mi mapped time 
initial meta task consists tasks arrived prior time tj aj 
meta task mk fork consists tasks arrived mapping event tasks mapped started executing mk tj aj tj aj bj 
batch mode mapper considers meta task matching scheduling mapping event 
enables mapping heuristics possibly better decisions immediate mode heuristics 
batch heuristics resource requirement information meta task know actual execution times larger number tasks tasks complete waiting mapping event 
task arrival rate high sufficient number tasks keep machines busy mapping events mapping computed 
assumed study running time mapping heuristic negligibly small compared average task execution time 
immediate mode batch mode heuristics assume estimates expected task execution times machine hc suite known 
assumption estimated expected times known commonly studying mapping heuristics hc systems 
approaches doing estimation task profiling analytical benchmarking discussed 
estimates supplied task submitted execution time submitted 
ready time machine earliest wall clock time machine going ready completing execution tasks currently assigned 
heuristics dynamic expected maheswaran machine ready times combination actual task execution times tasks completed execution machine estimated expected task execution times tasks assigned machine waiting execute 
assumed time task completes machine report sent mapper ready time updated necessary 
experiments section model situation simulated actual values execution times tasks finished execution 
heuristics examined operate centralized fashion map tasks dedicated suite machines mapper controls execution jobs machines suite 
assumed mapping heuristic run separate machine 
heuristics studied functioning dynamically heuristics static environment discussed 

line mode mapping heuristics immediate mode heuristics described 
minimum completion time ii minimum execution time iii switching algorithm iv percent best opportunistic load balancing 
heuristics switching algorithm percent best proposed part research 
minimum completion time mct heuristic assigns task machine results task earliest completion time 
causes tasks assigned machines minimum execution time 
mct heuristic variant fast greedy heuristic smartnet 
mct heuristic benchmark immediate mode performance heuristics compared mct heuristic 
task arrives machines hc suite examined determine machine gives earliest completion time task 
takes time map task 
minimum execution time met heuristic assigns task machine performs task computation amount execution time heuristic known lba limited best assignment user directed assignment :10.1.1.54.4093
heuristic contrast mct consider machine ready times 
heuristic cause severe imbalance load machines 
advantages method gives task machine performs amount execution time heuristic simple 
heuristic needs time find machine minimum execution time task 
switching algorithm sa motivated observations 
met heuristic potentially create load imbalance machines assigning tasks machines mct heuristic tries balance load assigning tasks earliest completion time 
tasks arriving random mix possible met expense load balance threshold mct smooth load machines 
sa heuristic uses mct met heuristics cyclic fashion depending load distribution machines 
purpose heuristic desirable properties mct met 
dynamic mapping independent tasks maximum latest ready time machines suite max minimum earliest ready time min 
load balance index machines min max 
parameter value interval 
load evenly balanced machines 
machine assigned task 
threshold values low high ratio chosen 
initially value set 
sa heuristic begins mapping tasks mct heuristic value load balance index increases point time sa heuristic begins met heuristic perform task mapping 
causes load balance index decrease 
decreases sa heuristic switches back mct heuristic mapping tasks cycle continues 
example functioning sa lower upper limits respectively particular rate arrival tasks sa switched met mct times mct met mct assigning tasks mct 
task arrival rate sa switched times mct assign tasks 
percentage tasks assigned mct gets progressively smaller larger 
larger larger number tasks waiting execute machine larger ready time machine 
turn means arriving task execution time impact machine ready time rendering load balance index sensitive load assignment 
task arrival sa heuristic determines load balance index 
worst case takes time 
step time taken assign task machine order sa uses met perform mapping mct 
sa heuristic takes time irrespective heuristic mapping task 
percent best kpb heuristic considers subset machines mapping task 
subset formed picking best machines execution times task 
task assigned machine provides earliest completion time subset 
kpb heuristic reduced mct heuristic 
kpb heuristic reduced met heuristic 
value maps task machine subset formed computationally superior machines 
purpose match current task computationally matched machine avoid putting current task machine suitable arrive tasks 
foresight task heterogeneity missing mct assign task poorly matched machine immediate marginal improvement completion time possibly subsequently arriving better matched tasks machine eventually leading larger makespan compared kpb 
noted kpb sa combine elements mct met operation kpb task assignment attempts optimize objectives mct met simultaneously 
cases fixed subset machines best maheswaran tasks kpb cause machine idle time compared mct result poorer performance 
relative performance kpb mct may depend hc suite machines characteristics tasks executed 
task log time spent ranking machines determining subset machines examine 
subset machines determined takes time time determine machine assignment 
kpb heuristic takes log time 
opportunistic load balancing olb heuristic assigns task machine ready considering execution time task machine 
multiple machines ready time machine arbitrarily chosen 
complexity olb heuristic dependent implementation 
implementation considered mapper may need examine machines find machine ready 
takes find assignment 
implementations may require idle machines assign tasks accessing shared global queue tasks 
example workings heuristics consider simple system machines currently loaded expected ready times table 
consider performance heuristics simple case tasks andt arriving order 
table shows expected execution times tasks machines system 
time values discussion expected values 
met finds tasks minimum completion time heavily loaded assigns tasks 
time andt completed units 
olb assigns expected idle 
similarly assigns respectively 
time andt completed units 
mct determines minimum completion time achieved assignment execution time twice completion time slightly larger 
mct goes assign time andt completed units 
sa determines current value load balance index 
assume 

sa chooses mct assignment 
assignment table initial ready times machines arbitrary units table expected execution times arbitrary units 
sa continues mct second assignment 
third assignment 
sa met fourth arriving task 
time completed mct 
value kpb kpb choose fastest executing machines assign task 
machines 
machines minimum completion time achieved assigned 
major difference working mct loaded minimum completion time machines 
step saves arrive tasks may run slowly machines 
task mct assigned kpb assigned 
time completed kpb units 
smallest heuristics 

batch mode mapping heuristics dynamic mapping independent tasks batch mode heuristics described min min heuristic ii max min heuristic iii sufferage heuristic 
sufferage heuristic proposed part research 
batch mode heuristics mapped predefined intervals 
intervals defined study strategies proposed 
regular time interval strategy maps meta tasks regular intervals time 
occasion mapping redundant new tasks arrived mapping tasks finished executing mapping machine ready times unchanged 
conditions checked redundant mapping events avoided 
fixed count strategy maps meta task soon mutually exclusive conditions met arriving task larger equal predetermined arbitrary number tasks set arrived task completes number tasks larger equal 
strategy length mapping intervals depend arrival rate completion rate 
possibility machines idle waiting mapping event depend arrival rate completion rate 
arrival rates experiments strategy operates reasonably actual system may necessary tasks maximum waiting time mapped 
maheswaran fig 

min min heuristic 
batch mode heuristics considered study discussed paragraphs 
complexity analysis performed heuristics considers single mapping event meta task size assumed equal average meta task sizes performed mapping events 
average meta task size min min heuristic shown fig 
heuristics implemented smartnet 
fig 
denote expected time machine ready execute task finishing execution tasks assigned point time 
ij entries computed ij values 
task machine gives earliest expected completion time determined scanning ith row matrix composed ij values 
task minimum earliest expected completion time determined assigned corresponding machine 
matrix vector updated process repeated tasks assigned machine 
min min begins scheduling tasks change expected machine ready time status amount 
tasks contending particular machine min min assigns task say change ready time 
increases probability earliest completion time shall assigned 
machine finishes task earliest executes fastest thereon minmin heuristic changes machine ready time status amount assignment percentage tasks assigned choice basis expected execution time higher min min batch mode heuristics described section verified examining simulation study data 
expectation smaller makespan obtained larger number tasks assigned machines complete earliest execute fastest 
initialization matrix line line fig 
takes sm time 
loop min min heuristic repeated times iteration takes sm time 
heuristic takes time 
dynamic mapping independent tasks max min heuristic similar min min heuristic heuristics implemented smartnet 
differs min min heuristic fig 
machine provides earliest completion time task task maximum earliest completion time determined assigned corresponding machine 
line fig 
minimum changed maximum 
max min heuristic complexity min min heuristic 
max min better min min heuristic cases shorter tasks longer tasks 
example long task max min execute short tasks concurrently long task 
resulting makespan just determined execution time long task case 
min min finishes shorter tasks may evenly distributed machines executes long task increasing makespan compared max min 
sufferage heuristic shown fig 
idea better mappings generated assigning machine task suffer terms expected completion time particular machine assigned 
sufferage value task difference second earliest completion time machine earliest completion time machine 
result best completion time second best 
fig 

sufferage heuristic 
maheswaran initialization phase lines fig 
similar ones min min max min heuristics 
initially machines marked unassigned 
iteration loop lines pick arbitrarily task meta task 
find machine gives earliest completion time task tentatively assign unassigned 
mark assigned remove meta task 
machine previously assigned task choose task higher sufferage value assign chosen task remove chosen task meta task 
task considered execution statement shall considered iteration loop line 
iterations loop completed execution statement completed update machine ready time machine assigned new task 
perform iteration loop line tasks mapped 
table shows scenario sufferage outperform min min 
table shows expected execution time values tasks machines initially idle 
case min min heuristic gives makespan sufferage heuristic gives makespan 
gives pictorial representation assignments case table 
pseudo code fig 
observed execution statement line takes sm time 
number task assignments execution statement depends total number machines hc suite number machines contended different tasks number tasks meta task mapped 
worst case task assignment execution statement 
meta task size decrease statement execution 
outer loop iterated times map meta task 
worst case time taken map meta task size sm 
best case machines tasks meta task contention tasks 
tasks assigned table example expected execution time matrix illustrates situation sufferage heuristic outperforms min min heuristic dynamic mapping independent tasks fig 

example scenario table sufferage gives shorter makespan min min bar heights proportional task execution times 
execution statement sm 
number quantifying extent contention tasks different machines 
complexity sufferage heuristic sm seen equal worst case best case values numerically equal number iterations loop line worst best case respectively 
batch mode heuristics cause tasks starved machines 
subset meta task consisting tasks mapped part mapping event time execution mapping event 
subset included 
due expected heterogeneous nature tasks meta task may mapped tasks arriving may executing tasks set 
possible tasks may included 
probability increases number new tasks arriving increases 
general tasks may remapped successive mapping event execution task starving machine 
impacts response time user sees examined sharing penalty 
reduce starvation aging schemes implemented 
age task set zero mapped time incremented time task remapped 
constant adjusted empirically change extent aging affects operation heuristic 
aging factor age computed task 
experiments study arbitrarily set aging factor task increases task 
aging factor enhance probability older task tasks 
min min heuristic task completion time obtained line fig 
multiplied corresponding value 
age task increases age compensated expected completion time determine maheswaran mapping gets increasingly smaller original expected completion time 
increases probability selected line fig 

max min heuristic completion time task multiplied 
sufferage heuristic sufferage value computed line fig 
multiplied 

simulation procedure mappings simulated discrete event simulator 
task arrivals modeled poisson random process 
simulator contains expected time compute matrix contains expected execution times task machines tasks arrive service 
matrix entries simulation studies represent ij values seconds heuristic operation 
actual execution time task different value matrix 
variation modeled generating simulated actual execution time task sampling truncated gaussian probability density function variance equal times expected execution time task mean equal expected execution time task 
sampling results negative value value discarded probability density function sampled 
process repeated positive value returned sampling process 
matrix numbers row indicate estimated expected execution times corresponding task different machines 
average variation rows referred machine heterogeneity 
similarly numbers column matrix indicate estimated expected execution times machine different tasks 
average variation columns referred task heterogeneity 
classification heterogeneity divide high heterogeneity low heterogeneity 
idea categories proposed matrix high task heterogeneity high machine heterogeneity high task heterogeneity low machine heterogeneity low task heterogeneity high machine heterogeneity low task heterogeneity low machine heterogeneity 
matrix classified classes consistent inconsistent orthogonal previous classifications 
consistent matrix machine lower execution time machine task true task matrices consistent inconsistent matrices 
inconsistent matrices occur practice variety different machine architectures hc suite parallel machines workstations variety different computational needs tasks readily parallelizable tasks difficult parallelize tasks tasks floating point intensive simple text formatting tasks 
way task needs correspond machine capabilities may differ possible pairing tasks machines 
addition consistent inconsistent classes class defined 
matrix characterized consistent sub matrix 
matrices tasks machines define consistent submatrix 
furthermore assumed particular task execution times fall consistent submatrix smaller fall 
assumption justified way machines perform consistently better tasks faster tasks machines 
matrix max rows max columns 
random matrices belong different categories generated manner 
arbitrary constant quantifying task heterogeneity smaller low task heterogeneity 
nt number picked uniform random distribution range 

arbitrary constant quantifying machine heterogeneity smaller low machine heterogeneity 
nm uniform random distribution range 
number picked 
sample nt tmax times get vector tmax 

generate matrix max max algorithm max max pick new value endfor endfor raw matrix generated matrix generated sorting execution times random subset machines task random subset tasks 
inconsistent matrix obtained simply leaving raw matrix 
consistent matrices considered study arise current intended mshn environment 
experiments described values low high task heterogeneities respectively 
values low high machine heterogeneities respectively 
heterogeneous ranges type expected environment mshn 

overview dynamic mapping independent tasks 
experimental results discussion experimental evaluation heuristics performed parts 
part immediate mode heuristics compared various metrics 
second part involves comparison batch mode heuristics 
third part comparison batch mode immediate mode heuristics 
stated valid experiments described 
number maheswaran machines held constant experiments performed 
heuristics evaluated heterogeneity environment inconsistent cases correspond currently expected mshn environments 
value tasks mapped different poisson arrival rates value chosen empirically high allow tasks completed task set arrives 
tasks execute new tasks arriving 
may correspond situation tasks submitted day night 
contrast chosen low allow tasks completed task set arrives 
tasks execute new tasks arriving 
may correspond closely situation tasks arrive continuously 
difference considered represent difference burstiness 
experiments performed third arrival rate high ensure tasks completed task set arrived 
mct heuristic basis percentages 
stated task arrival rate set example comparisons discussed subsections 
data point comparison charts average trials trial simulated actual task execution times chosen independently 
makespan trial heuristic normalized respect benchmark heuristic mct immediate mode heuristics min min batch heuristics 
min min serves benchmark experiments batch heuristics compared immediate mode heuristics 
bar benchmark heuristic comparison charts gives confidence interval shown top bars mean normalized value 
occasionally upper bound lower bound entire confidence interval distinguishable mean value scale graphs 
general heuristics performance section 

comparisons immediate mode heuristics stated immediate mode heuristics investigated conditions 
kpb heuristic equal 
particular value give lowest makespan kpb heuristic conditions experiments 
sa lower threshold upper threshold load balance index respectively 
values give optimum values makespan sa 
fig 
immediate mode heuristics compared normalized makespan inconsistent heterogeneity 
fig 
noted kpb heuristic completes execution finishing task earlier heuristics slightly better mct 
kpb heuristic forces task choose machine subset machines 
machines lowest execution times task 
dynamic mapping independent tasks fig 

makespan immediate mode heuristics inconsistent heterogeneity 
chosen machine give smallest completion time compared machines set 
compares normalized makespans different immediate mode heuristics heterogeneity 
shown figs 
relative performance different immediate mode heuristics impacted degree consistency matrices 
kpb performs best closely followed mct 
type heterogeneity machines particular subset perform tasks lie particular subset faster machines 
fig 
observed matrices met heuristic performs worst 
matrices simulations met heuristic maps half tasks machine considerably increasing load imbalance 
kpb considers fastest machines task particular value happen machines half tasks performance differ fig 

makespan immediate mode heuristics semi consistent heterogeneity 
maheswaran inconsistent case 
additional experiments shown kpb performance quite insensitive values long larger minimum value kpb heuristic reduced met heuristic 
example doubled minimum value makespan decreases factor 
doubling brings makespan factor 

comparisons batch mode heuristics compares batch mode heuristics normalized makespan 
comparisons stated regular time interval strategy employed schedule meta task mapping events 
time interval set value empirically optimize makespan values 
fig 
noted sufferage heuristic outperforms min min max min heuristics makespan slightly better min min 
sufferage heuristic considers loss completion time task assigned choice making mapping decisions 
assigning choice machines tasks highest sufferage values contending tasks sufferage heuristic reduces completion time 
furthermore noted makespan max min larger makespans obtained heuristics 
reasoning similar subsection explaining better expected performance min min seen max min assignments change machine ready time status larger amount min min assignments 
tasks contending particular machine max min assigns task say increase ready time 
decreases probability earliest completion time shall assigned 
experimental data shows percentage tasks assigned minimum execution time machine lower maxmin batch mode heuristics 
expected larger fig 

makespan batch mode heuristics regular time interval strategy inconsistent heterogeneity 
dynamic mapping independent tasks fig 

makespan batch mode heuristics regular time interval strategy aging inconsistent heterogeneity 
makespan result larger number tasks assigned machines best execution times tasks 
shown results makespan similar inconsistent 
impact aging batch mode heuristics shown fig 

min min aging normalize performance heuristics 
max min benefits aging scheme 
recall min min performs better max min aging 
aging modifies maxmin operation tasks smaller completion times scheduled prior larger completion times reducing negative aspects technique 
discussed 
shows result repeating experiments fixed count strategy batch size 
particular batch size give optimum value makespan min min heuristic 
min min fig 

comparison makespans regular time interval strategy fixed count strategy inconsistent heterogeneity 
maheswaran regular time interval strategy interval normalize performance heuristics 
compares regular time interval strategy fixed count strategy basis normalized makespans different heuristics inconsistent heterogeneity 
seen fixed count approach gives similar results min min sufferage heuristics 
max min heuristic benefits considerably fixed count approach makespan drops compared makespan regular time interval strategy 
possible explanation lies conceptual element similarity fixed count approach aging scheme 
value resulted batch sizes smaller regular time interval strategy 
small tasks waiting execute fewer tasks compete chance delayed larger task 
shown results case show compared inconsistent case regular time interval approach gives slightly better results fixed count approach sufferage min min 
max min cases gave similar results 
noted results inconsistent heterogeneity 
types heterogeneity results different 
example inconsistent heterogeneity performance max min identical min min 

comparing immediate batch mode heuristics fig 
immediate mode heuristics mct kpb compared batch mode heuristics min min sufferage 
comparison performed poisson arrival rate set noted high arrival rate batch heuristics superior immediate mode heuristics 
number tasks waiting execution larger circumstances considered turn means fig 

comparison makespan batch mode heuristics regular time interval strategy immediate mode heuristics inconsistent heterogeneity arrival rate dynamic mapping independent tasks fig 

comparison makespan batch mode heuristics regular time interval strategy immediate mode heuristics inconsistent heterogeneity arrival rate 
rescheduling improve mappings system 
immediate mode heuristics consider task try optimize machine assignment reschedule 
recall mapping heuristics combination expected actual task execution times compute machine ready times 
immediate mode heuristics approach performance batch ones low task arrival rates classes heuristics comparable information actual execution times tasks 
example certain low arrival rate th arriving task find previously arrived tasks completed 
higher arrival rate tasks completed th task arrives 
observation supported graph fig 
shows relative performance difference immediate mode batch mode heuristics decreases decrease fig 

comparison makespan batch mode heuristics regular time interval strategy immediate mode heuristics inconsistent heterogeneity arrival rate maheswaran arrival rate 
observation kpb sufferage perform similarly low arrival rate better kpb heuristic smaller computational complexity 
shows performance difference immediate mode batch mode heuristics faster arrival rate seen batch mode heuristics outperform immediate mode heuristics larger margin 
shown results makespan values heuristics larger lower arrival rate 
attributable fact lower arrival rates typically machine idle time 

new previously proposed dynamic matching scheduling heuristics mapping independent tasks hc systems compared variety simulated computational environments 
immediate mode heuristics batch mode heuristics studied 
immediate mode inconsistent types heterogeneity kpb heuristic outperformed heuristics kpb slightly better mct 
relative performance olb met respect makespan reversed heterogeneity changed inconsistent 
olb better met case 
batch mode inconsistent types heterogeneity sufferage performed best sufferage slightly better min min 
batch mode heuristics shown give smaller makespan immediate mode ones large high task arrival rate 
smaller values lower task arrival rates improvement makespan offered batch mode heuristics shown nominal 
study quantifies relative performance dynamic mapping heuristics depends consistency property matrix arrival rate tasks 
choice heuristic best heterogeneous environment function factors 
important include set heuristics resource management system hc heuristic appropriate situation done scheduling advisor mshn 
researchers build evaluation techniques results efforts considering nonpreemptive dynamic heuristics preemptive ones 
furthermore studies tasks characterized complex ways inter task communications deadlines priorities environmental factors task arrival rates degrees heterogeneity number machines hc suite impact changing variance simulating actual task execution times 
studies illustrate evaluation techniques examine important heuristics provide comparisons act framework research 
dynamic mapping independent tasks acknowledgments preliminary version portions th ieee heterogeneous computing workshop hcw april 
authors taylor kidd tracy braun valuable comments suggestions 

hensgen kidd relative performance various mapping algorithms independent sizable variances run time predications th ieee heterogeneous computing workshop hcw pp 


investigation effect different run time distributions smartnet performance thesis department computer science naval postgraduate school 
hensgen advisor 
braun siegel beck maheswaran robertson yao taxonomy describing matching scheduling heuristics heterogeneous computing systems ieee symposium reliable distributed systems pp 


braun siegel beck maheswaran robertson yao freund hensgen comparison study static mapping heuristics class meta tasks heterogeneous computing systems th ieee heterogeneous computing workshop hcw pp 


buss tutorial discrete event modeling simulation graphs winter simulation conference wsc pp 


ed heterogeneous computing artech house norwood ma 

foster kesselman eds grid blueprint new computing infrastructure morgan kaufmann san fransisco ca 

freund campbell hensgen keith kidd lima moore rust siegel scheduling resources multiuser heterogeneous computing environments smartnet th ieee heterogeneous computing workshop hcw pp 


freund siegel heterogeneous processing ieee comput 
june 

yang distributed heterogeneous supercomputing management system ieee comput 
june 

hensgen kidd st john siegel braun maheswaran ali 
kim irvine levin freund godfrey kidd prasanna bhat overview mshn management system heterogeneous networks th ieee heterogeneous computing workshop hcw pp 


ibarra kim heuristic algorithms scheduling independent tasks processors acm apr 

iverson dynamic competitive scheduling multiple dags distributed heterogeneous environment th ieee heterogeneous computing workshop hcw pp 


jain art computer systems performance analysis wiley new york 

ahmad optimal task assignment heterogeneous distributed computing systems ieee concurrency july sep 

potter scott dynamic task mapping algorithms distributed heterogeneous computing environment th ieee heterogeneous computing workshop hcw pp 

maheswaran 
maheswaran ali siegel hensgen freund comparison dynamic strategies mapping class independent tasks heterogeneous computing systems technical report school electrical computer engineering purdue university west lafayette preparation 

maheswaran braun siegel heterogeneous distributed computing encyclopedia electrical electronics engineering webster ed wiley new york vol 
pp 


towsley stankovic adaptive load sharing heterogeneous distributed systems parallel distrib 
computing aug 

papoulis probability random variables stochastic processes mcgraw hill new york 

scheduling theory algorithms systems prentice hall englewood cliffs nj 

wall discrete event simulation practical approach crc press boca raton fl 

taxonomy dynamic task scheduling schemes distributed computing systems iee proc 
comp 
digital techn 
jan 

singh youssef mapping scheduling heterogeneous task graphs genetic algorithms th ieee heterogeneous computing workshop hcw pp 


suresh chaudhuri dynamic rescheduling survey research internat 
production econom 
aug 

tang yew zhu impact self scheduling performance multiprocessor systems rd international conference supercomputing pp 


wang siegel roychowdhury task matching scheduling heterogeneous computing environments genetic algorithm approach parallel distrib 
comput 
nov 
maheswaran assistant professor department computer science university manitoba canada 
received sc 
degree electrical electronic engineering university sri 
received degree ph degree school electrical computer engineering purdue university 
held fulbright scholarship tenure student purdue university 
research interests include computer architecture distributed computing heterogeneous computing internet world wide web systems metacomputing mobile programs network computing parallel computing resource management systems metacomputing scientific computing 
authored coauthored technical papers related areas 
member eta kappa nu society 
ali pursuing ph school electrical computer engineering purdue university currently research assistant 
main research topic dynamic mapping meta tasks heterogeneous computing systems 
held teaching positions aitchison college institute management sciences pakistan 
teaching assistant purdue 
received degree electrical electronic engineering university engineering technology pakistan 
received school electrical computer engineering purdue university 
research interests include computer architecture parallel computing heterogeneous computing 
howard jay siegel professor school electrical computer engineering purdue university 
fellow ieee fellow acm 
received degrees electrical engineering management mit ph degrees department electrical engineering computer science princeton university 
professor siegel coauthored technical papers volumes wrote book interconnection networks large scale parallel processing chief journal parallel distributed computing editorial boards ieee transactions dynamic mapping independent tasks parallel distributed systems ieee transactions computers 
program chair chair conferences general chair chair conferences chair chair workshops 
international keynote speaker tutorial lecturer consultant government industry 
debra hensgen associate professor computer science department naval postgraduate school 
received ph area distributed operating systems university kentucky 
currently principal investigator darpa sponsored management system heterogeneous networks quorum project mshn investigator server active agent management saam generation internet project 
areas interest include active modeling resource management systems network rerouting preserve quality service guarantees visualization tools performance debugging parallel distributed systems methods aggregating sensor information 
published numerous papers concerning contributions toolkit automatically generating safe efficient concurrent code graze parallel processing performance debugger saam path information base smartnet mshn resource management systems 
richard freund founder ceo san diego start distributed computing technology 
freund early pioneers field distributed computing written authored number papers 
addition founder heterogeneous computing workshop held year conjunction international parallel distributed processing symposium 
freund won civilian service award career government scientist 

