tool massively replicating internet archives design implementation experience katia obraczka university southern california information science institute admiralty way marina del rey ca usa katia isi edu peter danzig yuan tsai university southern california computer science department los angeles ca usc edu reports design implementation performance scalable efficient tool replicate internet information services 
tool targets replication degrees tens thousands weakly consistent replicas scattered internet thousands autonomously administered domains 
main goal replication tool existing replication algorithms scale today exponentially growing internetworks 

internet services provide large rapidly evolving highly accessed autonomously managed information spaces 
achieve adequate performance services www replicate data thousands autonomous networks 
example highly replicated service take internet news 
manages dynamic flat gigabyte database responds queries seconds 
contrast popular www ftp servers constantly overloaded provide reasonable response time users 
www ftp internet information services popular databases highly replicated performance 
existing replication mechanisms scale today exponentially growing autonomously managed internets 
implemented tool efficient replication internet research funded part arpa contract number dabt afosr award number nsf nyi award ncr nsf small scale infrastructure number cda 
katia obraczka currently supported arpa contract number fbi 
information services 
target replication degrees thousands tens thousands weakly consistent replicas scattered internet thousands administrative domains 
tool consists components mirror 
mirror propagates updates logical topologies computed flood 
flood aggregates replicas multiple replication groups analogous way internet partitions autonomous routing domains 
having multiple replication groups preserves autonomy administrative decisions group connectivity split affect groups 
insulates groups topological rearrangements neighboring groups network traffic associated group membership 
replication group flood automatically builds logical topology updates travel 
lampson global name service gns flood logical update topologies restricted hamiltonian cycle 
automating process building update topologies replicas service flood system administrators having logical topology decisions 
argue efficient replication algorithms flood data replicas 
note flooding scheme propose differs network level flooding routing algorithms flooding network level simply follows network physical topology flood updates physical links network 
replicas flood data logical neighbor peer replicas 
word flooding sounds inefficient claim application level flooding scheme propose network bandwidth efficiently 
flood employs network topology estimator logical topology calculator 
group member measures available bandwidth propagation delay group members 
estimates logical topology calculator builds topologies group connected resilience low total edge cost efficient underlying network low diameter limit update propagation delays 
illustrates relationship logical topologies underlying physical network 
lefthand shows overlapping replication groups logical update topologies 
right hand shows physical network topology logical update topology built top replication groups left hand 

current algorithms lack existing naming services distributed file systems demonstrated problem replicating data partitioned autonomously managed subspaces known solutions 
naming services domain name service dns grapevine organize name space hierarchically defined administrative boundaries 
administrative boundaries partition name space domains need replicated handful servers meet adequate performance 
fact results report second level domains dns hierarchy replicated times domains replicas 
study shows dns second level domains store entries 
limited domain sizes small number replicas dns primary copy replication scheme performs quite adequately 
similarly distributed file systems organize file space hierarchically intermediate nodes directories leaf nodes files 
locus coda distributed file systems locality partition file space directory subtrees 
file servers replicate subset files directory subtree 
locus andrew provide read file replication coda uses distributed updates keep writable replicas weakly consistent 
layered network protocols hide network topology application programs replicas select flooding peers optimize network 
grapevine commercial successor clearinghouse ignore network update topology 
gns assumes existence single administrator hand configures topology updates travel 
gns administrator places replicas hamiltonian cy andrew name research project carnegie mellon university 
afs andrew product marketed supported transarc 
cle reconfigures ring replicas added removed 
number replicas grows replicas spread single administrative boundaries frequently reconfiguring ring gets prohibitively expensive 
netnews employs flooding distribute updates thousands replicas 
gns nntp site administrators hand configure logical flooding topology 
obtaining current physical topology information difficult today internet system administrators frequently confer plan changes logical flooding topology 
try keep dynamics underlying physical topology specially internet scale complexity increase 
main contribution replication tool built gns services scale today exponentially growing autonomously managed internetworks 
describe experience designing implementing deploying measuring replication tool performance 

design harvest resource discovery system designed implemented solve scalability efficiency problems early resource discovery services 
availability response time harvest relies massive replication servers 
particular harvest directory stores information available servers expected highly accessed massively replicated adequate performance 
flood designed support harvest servers replication built independent service allow applications 
existing internet information services network news ftp archives www servers flood propagate updates efficiently timely reducing burden system administrators 
replication tool implemented consists separate services flood mirror name expresses reliance known ftp mirror package 
flood estimates underlying physical network load measuring available bandwidth round trip time rtt members replication group 
estimates flood computes fault tolerant low cost logical update topology group 
mirror weakly consistent replicated file uses logical topologies propagate updates timely efficiently 
simplify replicating harvest brokers mirror uses master copy replication scheme 
updates performed master site replicas read copies 
replica version number determines replica needs updated 
replicas pull data neighbors having neighbor push data 
physical topology logical topology group member group member non group member group member corner member 
replication groups showing logical versus physical topologies 
avoids problem multiple concurrent updates 
replica completes update sends notification neighbors new version number 
neighbor receives notification checks local version date 
invokes mirror update local copy 
relatively cheap send update notifications mirror ds request periodically ensure local copies date 
works replicas crash lose update notifications interrupted midway update process 
design decision anonymous ftp file propagation mechanism 
complicates installation mirror advantage system administrators familiar anonymous ftp 
additionally anonymous ftp widely supported done eliminate security holes 

consistency groups consistency replication groups maintained easily members group 
representative individual replicas corner replicas belong multiple groups 
replicas flood updates neighbors logical topology updates group way groups 
network node link failures may result network partitions permanent node failures group membership changes may introduce temporary inconsistencies eventually resolved long flood topologies keep nodes connected 

updating logical topologies network nodes links may fail temporarily may permanently removed service 
replicas may join leave flooding group 
group membership protocol physical topology estimation eventually detect changes reflected new topology graph computed group 
replication tool uses flooding propagate topology updates members replication group 
topology update messages carry sequence number corresponding topology identifier replicas order topology updates detect duplicates 
topology update messages contain new group membership 
replica receives topology update floods new topology current topology committing new topology 
topology update process generates additional traffic associated propagating topology update messages participating replicas 
resulting overhead terms total number messages generated proportional number participating replicas frequency topology updates occur 
highly replicated service copies spread large internets topology update overhead may prohibitively expensive 
number replicas increases overhead associated maintaining group membership information estimating communication costs excessive 
hierarchical approach helps limit overhead 
grouping replicas located physically close restricts scope changes topology updates 
limits scope resulting topology updates local group restricts topology update traffic expensive long haul physical links 
aggregate cost topology estimation grows size group 
hand estimates collected adaptive network server load changes group hand higher estimation frequency greater impact network utilization 
section presents estimation traffic measurements collected replication groups different sizes 

flood daemon flood replica computes bandwidth rtt estimates replicas group 
single designated site group master generates topologies group 
flood handles group membership replication groups 
topology group master generates new member joins new member time perform bandwidth rtt estimates group members 
topology get better estimates improve 
flood written fast robust 
consequently written unix daemon fork uses non blocking communication 
interface flood interface queried telnet conveniently www browser speaks 

membership multiple groups new site joins group sends join request existing group member 
soon replica receives join request site adds new site list known sites starts collecting network estimates site 
replica receives join request floods replicas group 
site part group master distributes new topology contains site 
naturally gives master control group membership 
protocol leaving group 
sites leave replication group silently pre determined period time site heard simply dropped group 
silence period configurable currently set hour 
setting silence period take account group parameters rtt time bandwidth estimation periods estimate reporting period 
flood replica member group 
case replica 
estimate collection flood replica periodically performs rtt bandwidth estimation members group 
avoid synchronous group behavior add random offset estimation frequency 
time site builds estimates rtt available bandwidth members group 
rtt estimates replica sends udp packet containing timestamp randomly selected group member 
flood receives packet simply sends packet back originator 
returned packet estimate rtt flood ds 
similarly rtt estimation flood replica estimates bandwidth periodically choosing random site sending block data site 
default block size kbytes 
available bandwidth defined bandwidth bytes sent time byte gamma time byte times destination replica received bytes time byte time byte respectively 
order build base statistics quickly bandwidth measured data sent received 
bandwidth estimation performed data transfer meets exceeds bandwidth block size 
means collecting statistics admittedly precise serve purposes 
section report available bandwidth estimates different data block sizes 
computing actual estimates report group master previous history taken account 
prevents adapting transient changes 
damping effect computed follows new estimate ff old estimate gamma ff current estimate old estimate previously reported estimate current estimate estimate just measured 
damping rate ff set weight past history 
currently set ff 
build group estimates quickly possible periodic estimation algorithm fast starts performing frequent estimates flood starts 
time estimation process slows reduce impact bandwidth rtt estimates network utilization 
obvious tradeoff ability system adapt network conditions amount overhead incurred bandwidth rtt estimation 
large groups need perform estimation small groups 
difference linear replica group performs estimates 
bandwidth rtt estimates take account actual load servers involved 
measurements done network level accurate terms actual network statistics reflect actual delay bandwidth seen application 
instance fact server tends heavily loaded just important network congestion far applications concerned 
master collects estimates reported group members cost matrix group compute group current logical update topology 
entry cost matrix corresponds communication cost nodes estimated bandwidth rtt respectively 

topology calculation flood generates logical update topologies invoking topology generator 
current topology generator uses input estimated cost matrix connectivity requirement computes minimum cost spanning tree extra edges provide redundancy event link failure decrease graph diameter 
algorithm computes minimum spanning tree connecting nodes node degree required connectivity adds current cheapest edge currently 
original topology generator produced low cost low diameter connected topologies group simulated annealing optimization technique 
experiments demonstrated sophisticated algorithm produced moderate reductions total edge cost 
consequently practice simpler faster optimal algorithm 
simulated annealing algorithm tries lower total edge cost diameter may select expensive links cheaper ones 
instance testing environment contained ppp links 
frequently replica attempt replicate slow link replica available local ethernet 
notice phenomenon topologies generated minimum spanning tree algorithm 

mirror daemon mirror replicated archive consists master copy read replicas 
replica contains file system hierarchy replicated associated version number 
master site updated issues command mirror creates new version number 
sends update notifications neighbors logical topology flood generates 
update notification contains version number name host replica sending update resides information required access archive ftp template containing parameters package 
read replica mirror responsible determining replica local copy date 
replica receives update notification checks update version local version 
places notification notification set 
receiving notifications mirror selects notification set update notification came neighbor best bandwidth delay metric local flood 
update notification mirror builds ftp mirror configuration file ftp mirror template starts ftp mirror process 
mirror process succeeds local version updated redundant notifications purged notification set 
update fails mirror selects notification ftp mirror process repeats 
mirror determines neighbors querying local flood extracting list neighbors corresponding logical link cost metrics 
fact neighbors different replication groups transparent mirror 
mirror applications know existing replication groups 
easily hand configured pre defined neighbors 
lose elegance automatic topology calculation applications useful mirror independent flood 
mirror neighbors case receive update notifications 
mirror implementation acts immediately update notifications waits minute allow time multiple update notification arrive 
orders update notifications highest bandwidth lowest delay neighbor 
avoids situation mirror mirror link local ethernet 

performance measurements conducted preliminary performance measurement experiments replication tool 
goal set experiments evaluate overhead flood generates second experiment tries assess impact message size estimated available bandwidth 

flood overhead recall replicas group periodically estimate rtt available bandwidth group members 
experiment time rtt bandwidth estimation set minutes hour respectively 
time time replicas report estimates group master uses compute new logical topology time minutes time minutes 
replica group replica group replica group 
total estimation traffic replica groups 
group 
estimate reporting period experiment set minutes 
master floods topology group members 
time topology updates set hour 
replicas send rtt probes rtt probe replies udp 
estimating bandwidth sending estimates master propagating topology tcp 
shows total overhead traffic bytes packets generated replica group 
experiments groups created having replicas join 
recorded hour traffic traces replicas running locally laboratory 
measurements taken minutes 
reason observe traffic minutes due fact replicas fast start start execution 
words replica starts performs estimates frequently replica view group builds faster 
notice amount traffic stabilizes significantly lower value group membership stable 
replica group flood generates mbytes overhead traffic approximately minutes 
overhead traffic oscillates mbyte 
shows dynamic membership affects overhead traffic flood generates 
experiment replicas join hour replica leaves re joins group 
observe additional traffic generated replica re joins group considerable 
additional traffic generated time minutes time minutes 
replica group replica group replica group 
total estimation traffic replica groups dynamic membership 
due fast start re joining replica 

message size available bandwidth experiment set wide area replica group evaluate impact bandwidth estimation message size estimated available bandwidth 
table shows bandwidth estimates taken replica usc ventura usc edu members group 
notice sites kbyte message size resulted lower bandwidth estimates 
probably due fact kbyte message large open tcp window 

experience building flood mirror enlightening experience 
experience gained practical sort hope pass contemplating type 
items attempt highlight lessons learned 
ffl problems encountered directly related sheer volume data large number objects replicated 
flood originally designed small objects relatively small updates mbytes update 
fortunately replica name available bandwidth kbytes sec kbytes kbytes kbytes kbytes usc edu cse psu edu powell cs colorado edu casino su edu au cs arizona edu table 
bandwidth estimates collected ventura usc edu different message sizes 
system designed modular ability interface variety components handle data management 
consequently relatively easy redesign data management portion project handle archives required harvest 
ffl needs widely implemented standard threads 
flood written entirely standard unix system calls 
allows flood portable lightweight process gives great flexibility dealing network problems 
drawback non blocking difficult 
obvious solution threads package 
unfortunately portable threads packages discovered deal wide variety multiple platforms 
ffl interpreters nice rapid prototyping 
application written perl 
perl elegant scripting language generate portable prototype quickly 
side perl rarely installed correctly construe portability problem 
fortunately relatively simple solve 
major drawback perl lack precise memory management 
perl tendency grow time 
try prevent perl growing 
writing daemon process problematic 
perl tends grow large eventually swamp machine 
incredibly ugly hack solution perl application restart periodically 
elegant effective 
ffl ftp small file transfers 
ordinarily problem transferring files bytes size overhead non trivial 
obvious solution aggregate smaller files large files tcp get slowstart phase send data reasonable rates 
ffl moving files multiple mirror site chosen dynamically issue time important 
existing ftp daemons return file timestamps local time return time gmt 
despite best efforts host software combinations refuse return time gmt 
helpful notion time incorporated anonymous ftp file timestamps returned standard allow user discover utilized remote site 
ffl memory cheap 
application point run normal machine 
goes assumption memory cheap perspective quickly lost memory utilization accounted 
machine mbytes memory easy mbytes memory assumes memory cheap 
best assume memory limited resource 
said disk space 
aim efficiency 
space sure 
ffl assumptions network connectivity 
experience assumption internet connectivity probability sites disconnected non zero 
working live internet connectivity problems 
period time network connectivity usc colorado boulder network lost depressing regularity 
moving large amounts data mbytes mbytes sort problems cause major headaches 
helpful able start transfer point 
distributing large archives assume atomic updates assume update incremental 
ffl user interfaces far best 
incredibly easy way write lightweight remote interface program 
done simple matter find www browser front 
may constrain type interaction application provides portable interface purposes 
ffl care taken generating data bandwidth estimation 
modern modems wonderful ability automatically compress data 
textual data non random data modem likelihood reasonable compression job 
getting reports second dialup links non random data random data 

reported design implementation performance scalable efficient replication tool internet information services 
primary goal replication tool existing replication algorithms scale today exponentially growing autonomously managed internetworks 
replication tool consists independent services flood mirror 
flood generates fault tolerant low cost low delay logical flooding topologies mirror uses maintain weakly consistent ftp archives 
flood designed independent service allow internet services www servers ftp archives internet cache hierarchy 
preliminary performance measurements indicate flood overhead behaves expected stabilizes time 
measuring network server resources flood logical update topologies save fully evaluate benefits 
goal wide area experiment currently setting replicate commonly accessed internet archives 
experiment hope demonstrate flood logical update topologies reduce mirror load popular internet archives time efficient network reduce update propagation time 
longer term investigate ip multicast bulk data distribution 
ip multicast best effort protocol reliable transport mechanism built top applications require reliable delivery 
efforts building reliable multicast transport protocol 
focusing efforts building flow control mechanism bulk data distribution conjunction protocols 
berners lee cailliau 
groff 
world wide web information universe 
electronic networking research applications policy spring 
bowman danzig hardy manber schwartz 
harvest information discovery access system 
proceedings second international world wide web conference october 
danzig obraczka kumar 
analysis wide area name server traffic study domain name system 
proc 
acm sigcomm baltimore maryland august 
howard kazar menees nichols satyanarayanan sidebotham west 
scale performance distributed file system 
acm transactions computer systems february 
kantor lapsley 
network news transfer protocol proposed standard stream transmission news 
internet request comments rfc february 
lampson 
designing global name service 
proceedings th 
acm symposium principles distributed computing pages august 

ftp mirror software 
available ftp src doc ic ac uk computing archiving mirror january 
mockapetris 
domain names concepts facilities 
internet request comments rfc november 
obraczka 
massively replicating services widearea internetworks 
phd thesis computer science department university southern california december 
oppen dalal 
clearinghouse decentralized agent locating named objects distributed environment 
acm transactions office information systems july 
popek walker chow edwards kline ang thiel 
locus network transparent high reliability distributed system 
proc 
th 
symposium operating systems principles pages december 
satyanarayanan 
scalable secure highly available distributed file access 
computer magazine may 

