article submitted computer speech language learning visually grounded words syntax scene description task deb roy media laboratory massachusetts institute technology cambridge usa spoken language generation system developed learns describe objects computer generated visual scenes 
system trained show tell procedure visual scenes paired natural language descriptions 
learning algorithms acquire probabilistic structures encode visual semantics phrase structure word classes individual words 
structures planning algorithm integrates syntactic semantic contextual constraints generate natural unambiguous descriptions objects novel scenes 
system generates syntactically formed compound adjective noun phrases relative spatial clauses 
acquired linguistic structures generalize training data enabling production novel word sequences observed training 
output generation system synthesized word concatenative synthesis drawing original training speech corpus 
evaluations semantic comprehension human judges performance automatically generated spoken descriptions comparable human generated descriptions 
motivated long term goal developing spoken language processing systems grounds semantics machine perception action 

growing number applications require translation perceptual sensory data natural language descriptions 
automatic sports commentators video games map spatial relations dynamic events virtual players speech 
car navigation systems generate spoken directions map routes geographical position data 
envision assistive aids translate visual information speech visually impaired 
current approaches class language generation problems rely manually created rules encode domain specific knowledge 
rules aspects roy learning visually grounded words syntax generation process including example lexical selection sentence frame selection 
develop learning approach creating spoken language generation systems 
ultimate goal develop trainable systems learn domain specific rules language generation examples produced directly domain experts 
implemented system called represents step direction 
consider problem generating spoken descriptions visual scenes form language grounding 
grounding refers process connecting language referents language user environment contrast methods rely symbolic representations semantics grounded representations bind words sequences words directly perceptual features crucially bottom sub symbolic structures available influence symbolic processing 
symbolic representations ultimately encoded terms representations machine environment available machine directly perceptual system 
grounded system learns generate contextualized spoken descriptions objects visual scenes 
input consists visual scenes paired naturally spoken descriptions transcriptions 
set statistical learning algorithms extract syntactic semantic structures link spoken utterances visual scenes 
acquired structures generation algorithm produce spoken descriptions novel visual scenes 
concatenative synthesis convert output generation subsystem speech 
evaluations semantic comprehension human judges performance automatically generated spoken descriptions comparable human generated descriptions 

related problem generating referring expressions text multimedia environments addressed previous computational systems including dale reiter andr rist 
dale system epi cure addresses problem generating anaphoric referring expressions 
planner maps communicative goals surface text making models discourse hearer world state 
dale reiter examined computationally efficient methods generating expressions minimal set attributes distinguish intended referent set competitor referents 
andr rist designed generation system combines text image output refer objects 
previous generation systems may contrasted significant ways 
emphasis grounding symbols physical world may argued lay foundation representing large range concepts levels abstraction analogical metaphorical reasoning 
semantics may grounded terms actions language user performs environment 
aspect grounding considered 
roy learning visually grounded words syntax learning necessary linguistic structures training data 
second take notion grounding semantics sub symbolic representations critical aspect linking natural language visual scenes 
third limit scope generating referring expressions solely information available static visual scenes 
discourse history system 
visual translator system natural language generation system grounded directly perceptual input 
generates natural language descriptions dynamic scenes multiple domains including automobile traffic soccer games 
semantic representations extracted video image sequences 
detailed domain knowledge categorize spatial relations objects dynamic events 
higher level propositions formed representations mapped natural language rule text planner 
imaginary listener predicts listener understand proposed description 
disagreements predicted message intended message fed back text planner expected ambiguities minimized 
contrast designed learning system 
porting new domain presumably arduous labor intensive task 
jordan walker machine learning train system generates nominal descriptions objects 
nominal expression consists attributes 
learning system trained automatically select subset attributes referring expression choice sixteen possible combinations attributes 
decision process set dialog context features example assumed known hearer attributes object 
learning algorithm acquires optimal set rules map context features attribute selections turn generate referring expressions 
comparison jordan walker approach uses richer set features encode dialog context 
encode history interaction relies solely features extracted static visual scene 
scope learned significantly broader 
addition attribute selection syntactic structures visual semantics words acquired 
learning grounded representation spatial terms studied regier 
designed set psychologically motivated perceptual features underlie spatial concepts wide range languages 
example represent static spatial relations pair relative angles take account center mass points closest proximity objects proposed 
employed features system described 
regier system acquired spatial terms connectionist learning methods 
input consisted synthetic images pairs objects labels 
regier demonstrates importance choosing perceptual features carefully ensure efficient concept acquisition 
related siskind roy learning visually grounded words syntax proposed visual primitives encode notions support contact attachment ground semantics events verb learning 
previous modeled early stages word acquisition sensor grounded speech visual signals 
demonstrated utility learning algorithms cross modal mutual information discovering words visual associations speech paired images dimensional everyday objects 
implemented system able learn object names corpus spontaneous infant directed speech 
focus discovery segmentation word acoustic units spontaneous speech driven cross modal analysis 
acquired lexicon visually grounded words served basis small vocabulary speech understanding generation system 
system able process single word phrases referred color shape objects 
language processing system integrated interactive robot 
person able issue verbal commands red ball robot actively search best matching referent 
system able verbally describe novel objects word phrases 
system extends prior addresses problem syntactic structure acquisition grounded learning framework 

learning problems consider learning problems training example comprised natural language word sequence vector real valued features represents semantics word sequence 
assume prior knowledge lexical semantics word classes syntactic structures 
basic problem establish semantics individual words 
bootstrap acquisition word associations utterances treated bags words 
word utterance may potentially label subset occurring visual features 
consider situation measure features object potential grounding adjective terms height area brightness 
person looks object says big red apple 
bag words model word sentence including refer subset measured features 
possibilities include associations learner big area countless associations undesirable red height brightness 
problem facing language learner feature selection choosing subset potential features bound word 
feature assignments statistical learning methods train classifiers map words ranges values features 
example dark select brightness feature prefer small values feature 
second problem cluster words word classes semantic syntactic constraints 
assume word classes necessary step roy learning visually grounded words syntax acquiring rules word order 
example language learner learn english rule adjectives precede nouns primitive notion adjective noun word classes presumably needs place 
word classes derived strictly distributional analysis word occurrences 
alternatively semantic associations group words 
hybrid method combines distributional semantic cues 
third problem learning word order 
address problems learning adjective ordering large blue square vs blue large square phrase ordering generating relative spatial clauses 
semantics phrase order needs learned difference meaning ball block vs block ball 
statistical bigram language model learned terms acquired word classes generate compound word descriptions objects thin dark green rectangle 
statistical bigrams phrases employed model syntactic structures necessary generating relative spatial clauses 
semantic implications phrase order captured grounding spatial lexical items terms relative spatial visual features 
problems outlined addressed system disposal grounded language model enables map novel visual scenes natural language descriptions 
language generation problem treated search problem probabilistic framework syntactic semantic contextual constraints integrated 

outline begins outlining experimental task training corpus created development test bed 
algorithms learning generate natural language expressions refer single objects 
second set algorithms enables system generate expressions include relative spatial clauses 
clauses help listeners disambiguate similar objects visual scene 
evaluation system system performance semantic understandability compared original human produced training corpus 

visual description task experiments reported rectangle description task 
program created generate images consisting set colored rectangles set black background 
typical image generated program shown fig 

width height position rgb color rectangle randomly generated 
placement rectangles constrained overlap may touch 
data collection described image augmented indicator arrow selects rectangles target object 
example fig 
blue rectangle right target 
roy learning visually grounded words syntax typical image rectangle task 
synthetic image consists rectangles random height width color non overlapping position 
description task consists generating phrases best describe target objects 
generation process context sensitive best choice words depend objects scene 
descriptions evaluated semantic understandability measuring reliably human listeners select intended target object scene provided verbal description 
task chosen manageable starting point experiments 
variation objects limited shape color size position 
syntactic structure required generate descriptive phrases relatively simple modeled statistical grams 
computer generated images visual feature extraction greatly simplified compared camera images 
challenges raised task substantive lead useful new algorithms 
results task form basis explorations complex language learning tasks richer contexts 

visual features lexical semantics grounded terms visual features 
table lists set visual features generated image synthesis program represent object image 
refer back features remainder names listed left column table 
features selected language learning task mind 
example expect color terms grounded combination features 
spatial terms leftmost highest grounded features 
words bright thin roy learning visually grounded words syntax table visual features extracted objects 
name description red component rgb color green component rgb color blue component rgb color hw ratio height width ratio area surface area position upper left corner position upper left corner mm ratio ratio maximum dimension minimum dimension obvious 
features normalized feature zero mean unit variance 

data collection preparation collected speech corpus male speaker undergraduate student unfamiliar project 
instructed speak naturally describe target objects images displayed computer screen 
asked produce descriptions listener select target identical scene target unmarked 
data collection program written displays images records spoken responses 
preparation data collection set images generated line randomly selected target object 
speaker wore noise canceling headset microphone 
presentation program displayed image recorded speaker spoken response 
line speech point detection algorithm hidden markov models speech silence segment incoming speech utterances 
segmented utterance saved separate speech file 
file automatically tagged identity image target object display time 
speaker participated minute recording sessions resulting utterances spoken utterance manually transcribed word level 
divided training utterances types simple utterances complex utterances 
simple utterance contain exactly object complex utterances objects 
classification utterances text keyword spotting 
transcript containing multiple instances words rectangle square classified complex remainder simple 
table lists representative utterances type corpus 
total utterances simple complex 
mean utterance length corpus words 
mean utterance length simple utterances words 
initial histogram analysis corpus indicated insufficient exemplars images generated data collection 
images randomly chosen set 
roy learning visually grounded words syntax color spatial terms 
second speaker asked provide additional set descriptions focused color spatial terms 
speaker instructed produce simple utterances 
new random images generated collection 
additional simple utterances collected single recording session 
put data speaker training corpus consisted utterances simple complex 
table typical utterances rectangle task corpus 
simple utterances contain exactly object 
complex utterances refer multiple objects 
type utterance simple pink square simple light blue square simple biggest grey rectangle simple large white rectangle simple long flat purple rectangle simple brightest green rectangle complex narrow purple rectangle right blue square complex green rectangle rectangle complex purple rectangle left pink square complex orange rectangle blue rectangle complex yellow rectangle left large green square complex vertical rectangle directly smallest blue rectangle complication learning data complex utterances contain multiple objects 
bag words model word considered label occurring observation 
simplify problem truncated transcription complex utterance instance rectangle square 
truncated transcripts stages learning described section 
learning utterances addressed section 
truncation procedure knowledge task hand fact object phrase refer target object necessarily generalize situations 
plan develop methods avoid simplification 
appendix contains histograms word occurrences original truncated training corpora 
full training corpus contains instances unique words token types 
truncated corpus draws token types 
manual speech transcription process labor intensive aspect training process 
explore speech recognition automate step initially preferred error free transcripts 

learning grounded language models objects section describes set algorithms developed acquiring structures necessary produce simple utterances defined roy learning visually grounded words syntax previous section 
order presentation algorithms corresponds stages processing system 
section describes structures employed generating visually grounded object description phrases 

word class formation stage learning cluster words classes 
classes serve roles 
determine visual features associated word 
members word class required grounded set features 
second word classes form basis learning class bigram language model 
class bigrams enable system generalize knowledge training data novel word combinations 
ideally words semantically syntactically similar clustered 
example color terms clustered separated size spatial terms 
treated part word class learning differentiate large blue ball vs blue large ball impossible 
knowledge preprogrammed goal develop extensible system form word classes absence manually encoded structure 
investigated approaches forming word classes 
relies distributional patterns words training corpus ignores visual information 
second approach searches associations words visual features groups words similar feature associations 
third approach effective hybrid method combines approaches 

distributional clustering distributional method rests basic assumption words belonging class mutual exclusion 
assumption follows words occur utterance belong different word classes 
utterance large blue square lends evidence placing large large square word pair class 
assumption similar mutual exclusion bias proposed mechanism children language acquisition 
young children initially resist learning labels concept poodle dog 
bias leads efficient learning limited examples 
denote corpus utterances 
um 
vocabulary corpus set unique token types denoted 
wv vocabulary size wi word vocabulary 
occurrence indicator variable defined wi wj occur wi wj roy learning visually grounded words syntax wi wj detects words occur utterance obtain occurrence matrix elements computed wi wj wi wj wi wj count number times words wi wj occur utterance accumulated utterances corpus 
goal partition vocabulary word classes words class occur infrequently words class 
clustering procedure partition vocabulary disjoint classes cj nj words 
th word word class cj 
word classes partition original vocabulary cj specifying clustering algorithm define distortion metric word classes dd ci cj ni nj ci cj ni ci nj cj ci count number times word class occurred training corpus 
subscript dd reminds distortion metric distributional cues 
numerator equation accumulates cooccurrences pair words drawn class denominator normalizes sum total number occurrences word classes training corpus 
greedy clustering algorithm iteratively merge clusters smallest inter cluster distortion stopping criterion met 
algorithm consists steps 
clusters initialized word 
find ci cj dd ci cj minimized 
dd ci cj stopping threshold 
merge elements ci cj 
go step value stopping threshold determines number word classes produced 
developed automatic method determine optimal value possibility adapt value reinforcement learning framework 
currently value set manually 
clustering algorithm applied training corpus 
avoid estimation problems due small sample sizes words occurring times roy learning visually grounded words syntax corpus removed vocabulary processing 
removal infrequent words experimental corpus consisted unique word types 
table lists word classes formed distributional analysis merges 
examination word classes reveals mutual exclusion bias approximately separates color terms class shape descriptors class size descriptors class 
errors evident classes 
color terms grey salmon included non color terms class spatial terms leftmost rightmost highest lowest clustered 
table word classes created merges distributional analysis utterance word occurrences 
word class class members light grey white dark bright leftmost salmon highest pink blue yellow green purple red brown orange colored horizontal vertical square largest rectangle small large thin smallest lowest tall olive rightmost 
clustering semantic feature associations investigated second method clustering ignores occurrence patterns words utterances focuses semantic associations words visual referents 
goal approach cluster words grounded similar sets visual features 
principle errors introduced distributional analysis resolved factoring semantic constraints 
problem establishing semantic associations words natural language provide exhaustive labels referents scene 
consider image object red 
asked describe object relative person say effect red 
various possible descriptions object size location absent description 
learning natural language descriptions assume absence label indicates absence corresponding property 
person didn word large unable conclude object large 
problem lack negative training recall training described section corpus utterances truncated instance keywords rectangle square 
roy learning visually grounded words syntax examples known context grammar acquisition children cf 
arises case lexical acquisition 
approach visual feature treated random variable modeled univariate gaussian distribution 
quantifying effect presence word distribution feature 
semantic distortion metric operates word pairs defined terms individual feature effects 
distortion metric incorporated word clustering algorithm 
recall utterance ui training corpus paired target object 
object visual features extracted current experiments 
dimensional feature vector extracted object paired utterance ui referred xi 
refer feature xi xi 
model effect word wn distribution feature observations occur presence utterance containing wn obtain unbiased estimates gaussian parameters word conditional model xi wn ui wn wn wn ui wn ui xi wn wn ui summations utterances contain word wn 
note denominator equation may smaller wn count multiple instances word utterance wn 
terms equal wn occurs utterance 
remaining observations occur wn estimate parameters background model xi wn wn wn ui wn ui wn ui xi wn wn ui wish quantify distortion word conditioned background distributions feature measure degree association word feature 
kullback leibler kl divergence roy learning visually grounded words syntax provides asymmetric measure dissimilarity probability distribution functions kl ln extension kl divergence provides symmetric distance distributions kl kl kl refer equation symmetrized kl distance 
symmetrized kl distance compare unconditioned word conditioned distribution feature kl xj wi xj wi wi wi wi wi wi wi wi symmetrized kl distance positive zero distributions equal provides measure association words individual visual features 
wish define semantic distortion metric place distributional distortion equation order form word classes 
word wn compute corresponding semantic association vector collection feature wise kl distances kl wn wn kl wn wn wn kl xf wn xf wn comparisons words semantic association vectors linearly scaled largest element vector smallest value 
semantic association vector may thought semantic profile word gorin developed similar concept quantify semantic associations words phrases relation discrete actions call routing task 
shows scaled semantic association vectors words training corpus 
word blue associated strongly color features 
dark light associated color channels light associated red feature dark rightmost associated strongly expected feature horizontal position 
square associated height width min max features 
surprisingly thin associated strongly area wi roy learning visually grounded words syntax blue dark light hw ratio area mm ratio rightmost square thin hw ratio area examples semantic association vectors words 
weakly hw ratio mm ratio 
fact speaker corpus usually labeled small objects thin 
semantic association vectors distortion words defined negative dot product corresponding semantic association vectors wi wj denotes transpose operator 
semantic distortion greatest word pairs orthogonal semantic association vectors 
word pair distortion computed pair wise combination words word classes obtain semantic distortion pairs word classes ds ci cj ni nj ci cj mm ratio clustering algorithm previous section rerun roy learning visually grounded words syntax corpus dd replaced ds 
resulting word classes merges listed table 
contrast classes table distributional analysis semantically driven classes display different groupings 
example leftmost rightmost clustered kept separate lowest highest 
semantically related words separated syntactic roles ignored 
rectangle placed word class shape size adjectives 
table word classes created merges semantic associations 
word class class members horizontal large vertical rectangle square bright largest light grey red green purple colored dark blue brown pink yellow salmon orange white small thin smallest tall olive leftmost rightmost lowest highest 
hybrid clustering word occurrences semantic associations clearly important cues forming word classes 
sources information combined computing linear combination distortion metrics dds ci cj dd ci cj ds ci cj stopping threshold obtained word classes listed table 
large value interpreted favouring dd ds 
compensates fact range values dd smaller ds 
seen comparison tables grouping words dds significantly effected semantic syntactic constraints 
semantically related words grouped syntactically distinct words kept apart 
example square grouped rectangle semantically square similar vertical horizontal terms associated ratios height width 
words tall olive grouped semantic association vectors sharp cluster words 
due insufficient consistent training data words 
word classes listed table final generation system 
roy learning visually grounded words syntax table word classes created merges linear combination distributional semantic association distortion metrics 
word class class members light white dark pink yellow salmon orange grey red green purple colored blue brown horizontal vertical bright rectangle square small thin large largest smallest tall olive leftmost rightmost lowest highest 
feature selection feature selection proceeds assigning features word individual basis 
features word class defined conjunction features selected members class 
features individual word selected maximize symmetrized kl distance word conditional distribution background unconditioned distribution 
previous section feature considered time 
consider multivariate distributions multiple features 
multivariate extension symmetrized kl distance kl tr full covariance matrix mean vector 
feature selection achieved greedy algorithm 
starts selecting single feature leads highest symmetrized kl distance conditioned unconditioned distributions equation 
search iteratively finds best feature maximally increases equation 
kl distance normalized number selected features number dimensions 
feature added increase normalized kl distance computed 
search stops increase obtainable 
feature search algorithm lead interesting behavior words reliably associated visual features olive tall corpus kl distance maximized features selected 
consistently distinct distribution subset features 
modeling features data overfit 
observation added check words features selected marked ungrounded 
ungrounded words words occur frequently semantics unknown 
remaining words features successfully selected referred grounded words 
roy learning visually grounded words syntax word class inherits conjunction inclusive logical features assigned members 
table shows features selected word class 
convenience members class listed 
inspection assignment features matches intuitively expect 
choice adjective partitions driven jointly semantic similarity occurrence patterns 
word bright placed class horizontal vertical due largely influence occurrence counts 
grounded due unusually high frequency word 
background distribution equations estimated far fewer observations word conditioned model 
due imbalance feature selection procedure able find stable assignment features separates models 
table word class feature selection 
word class class members features hw ratio mm ratio light white dark pink yellow salmon orange grey red green purple colored blue brown horizontal vertical bright hw ratio mm ratio rectangle square mm ratio small thin large largest smallest area hw ratio tall ungrounded olive ungrounded leftmost rightmost ungrounded lowest highest area 
modeling word semantics grounded word gaussian model estimated observations occur word 
achieved multivariate form equations 
word conditional model specifies probability density function pdf subset visual features selected corresponding word class 
example grounding member cluster modeled dimensional gaussian distribution features plots mean contours equal probability density words word classes 
classes simpler visualize assigned visual features 
class left side find significant overlap distributions associated light white clear separation dark 
word class involves distributions features area mm ratio ratio larger dimension rectangle smaller 
shape equal probability ellipse thin feature roy learning visually grounded words syntax dark word class feature light white feature mm ratio smallest thin small word class large feature area gaussian distributions associated words word classes 
indicates term refers objects high values mm ratio expected small areas 
interesting problem grounding semantics morpheme est 
distinction small versus smallest large versus largest primarily matter degree area dimension 
actual semantic distinction word pairs represented concepts relative ordering property comparison necessary ground est supported 
principle possible provide basis grounding est adding higher order features compare sequence visual attributes 

class statistical bigram model final component grounded language model necessary generate noun phrases syntactic component encodes word order constraints 
class bigram statistical language model purpose 
word training corpus mapped corresponding word class label 
probability class ci follows cj estimated relative counts ci cj cj ci cj largest probability utterance word ci estimated ci st art number times ci start utterance similarly probability utterance word ci estimated number times ci utterance roy learning visually grounded words syntax class small thin large largest smallest tall class horizontal vertical bright start class light white dark class pink yellow salmon orange grey red green purple colored blue brown class leftmost rightmost olive class rectangle square class lowest highest word class statistical bigram simple utterances 
turing smoothing optionally estimates numerator 
discuss sections language generation smoothing desired 
bigram language model estimated training corpus shown 
transition probabilities unsmoothed transitions shown 
nodes double outlines indicate start utterances 

summary far set algorithms building language model utterances sequences words paired objects visual feature vectors 
components model word classes clusters words grouped distributional occurrence patterns semantic associations 
class mem roy learning visually grounded words syntax mutually exclusive word belong classes 
word class features subset visual features associated word class 
feature may linked multiple word classes 
visually grounded word models multivariate gaussian models associated word model expected word conditional distribution visual features 
word models capture visual semantics word 
specify distribution features associated word class 
class bigrams class bigram transition probabilities model word order constraints 
components provide basis generating utterances describe single objects embedded visual scenes 

generating spoken language descriptions objects wish generate natural language phrases objects sense optimal grounded language model 
generation problem treated constrained search problem 
types constraints integrated search 
syntactic constraints wish generate words consistent natural language syntax 
second constraint semantic 
semantics phrase describe features target object 
third constraint context 
phrase describe features object minimize ambiguity relative objects scene 
semantic contextual constraints 
consider scene 
phrase large green rectangle choice respect semantic constraints target fits description 
utterance poor choice context factored objects fit description 
proceed describing search constrained syntax incrementally introduce semantic contextual constraints 

syntactic constraints determining word utterance generated class bigrams 
denote output sequence qt element qt integer index word class qt log probability word class sequence log cq st art log log roy learning visually grounded words syntax visual scene difficult describe target object 
sequence length maximizes total probability utterance arg max bigrams estimated training corpus optimal word class sequence utterances increasing length rectangle square pink yellow 
rectangle square small thin 
pink yellow 
rectangle square additional constraint avoid repetition words classes due loops bigram networks 
utterances word class sequences shown eliminated constraint 

mapping word classes words visual grounding word class ci output utterance may mapped word choosing roy learning visually grounded words syntax arg max ci ni ci ci ci choose word ci class ci maximizes probability target object equation standard bayes classifier gaussian models associated ci competing models 
class conditional word probabilities relative word counts ci ci ci ni cj applying equation scene target object obtain phrases rectangle green rectangle large green rectangle large light green rectangle large vertical light green rectangle descriptions combine semantic syntactic constraints 
word class sequences chosen bigram probabilities 
word choices determined best fit visual features target object 
search process implemented exhaustive search possible paths 
longest utterances word classes words total utterances need evaluated 
pentium ghz single processor machine takes approximately seconds 

contextual constraints simple utterances generated method described ambiguous 
non target objects scene accidentally match descriptions 
address problem developed measure ambiguity target object description context set competing objects 
start defining fit utterance object ignoring context product word conditional pdfs evaluated features object log qt fit denominator term normalizes effect length ambiguity referring phrase defined roy learning visually grounded words syntax fit max fit measures fit utterance target object relative best competing object scene 
best competing object defined object best described syntactic contextual constraints combined defining new score interpolation constant 
equation find utterance length maximizes order generate descriptions objects 
generated new set descriptive phrases scene target object 
choice imply bias ambiguity constraint compensates differences scale inherent way computed 
table shows resulting utterances value table utterances generated combining syntactic contextual constraints 
utterance rectangle highest rectangle highest green rectangle highest vertical green rectangle highest green vertical green rectangle comparison descriptions contextual constraints reveals effect including generation process 
bigram syntactic constraints common color green size large descriptors preferred 
looking back see objects scene described large green 
contextual considerations bias system select highest vertical ambiguous terms 
bigram influences context sensitive phrases phrases syntactically formed 
semantic constraints effect word classes mapped words equation assures semantic accuracy 
point reached goal generating object descriptions integrate syntactic semantic contextual constraints 
focus previous section describing single objects equivalent simple utterances training corpus 
sections describe process learning generate complex utterances 
roy learning visually grounded words syntax 
learning relative spatial clauses original training corpus utterances contained simple utterances recall defined simple utterances utterances refer exactly object 
remaining utterances complex referred objects 
section describe methods acquiring models enable generation utterances relative spatial clauses rectangle left red square 
specific problems addressed parsing complex utterances training corpus identify subsequences words refer objects 
establishing phrase object correspondences 
example utterance rectangle left red square learning system decide object descriptions rectangle red square refers target object non target objects serves referent remaining phrase 
acquiring visually grounded models spatial words 
new visual features introduced measure relative angles distances pairs objects 
learning phrase bigram models syntax complex utterances 

parsing complex utterances acquired bigram language model bigrams described section estimated truncated utterances 
bigrams basis probabilistic parser identifies object phrases embedded complex utterances 
refer set bigrams object phrase bigrams 
second set general bigrams trained entire training corpus 
set bigrams may thought stochastic finite state automata word represented state bigram transition probabilities form arcs states 
sets bigram transition probabilities may thought pair 
order construct parser combine larger network 
simplified pair networks depicted 
general word states utterance terminal nodes st 
object phrase network consists subset words general network vocabulary truncated corpus contains subset full corpus 
dotted arcs indicate new transitions added connect 
outgoing node general network terminates word part object phrase network new link added transition probability 
similarly state general network incoming arc word part object phrase network receives new transition equal weight 
transitions added weights rescaled insure proper probabilities 
roy learning visually grounded words syntax general network object phrase network stochastic finite state automata models object phrases complex utterances combined create probabilistic phrase parser 
phrase parser viterbi algorithm find path network utterance 
constant word insertion penalty inserted transition general network object phrase network 
word insertion penalties inserted transitioning object phrase network transitions st endo 
configuration biases viterbi algorithm align subsequences input object phrase possible 
output parser sample complex utterances 
parentheses indicate groups words aligned phrase 
dark green rectangle light blue rectangle 
purple rectangle left pink square 
sea green rectangle right red rectangle 
olive rectangle touching green rectangle 
tall green rectangle directly left large blue rectangle 
purple rectangle red blue rectangles 
green rectangle right big pink rectangle errors examples due new words complex utterances sea rectangles acquired phrase model 
example big new word parser able segment remainder object phrase 
majority complex utterances corpus parsed successfully 
errors introduced roy learning visually grounded words syntax stage probabilistic algorithms operate output parser able acquire useful structure 
total parser complex utterances training corpus contained exactly object description phrases 
parsed utterances served basis stage processing 

establishing phrase object correspondence recall input learning system utterance visual scene visual features extracted object scene identity target object elicit utterance 
utterance selected parser object phrases implying distinct referent objects 
relational terms may acquired learning system decide phrases refers original target object remaining objects scene linked remaining phrase 
refer second referent landmark object simply landmark 
denote phrases extracted utterance qp qp 
correspondence problem solved steps 
select target phrase 
fit qp fit qp decide qp qp 
remaining unassigned phrase default assigned landmark phrase 

select landmark object arg max objects scene fit choose object scene best described landmark phrase 
point target landmark objects identified setting basis acquiring visually grounded models spatial relation words phrases 

phrase tokenization illustrate need phrase tokenization rewrite sample training utterance target landmark phrases tokenized previous step determined object phrase 
target phrase landmark phrase 
target phrase left landmark phrase 
sea target phrase right landmark phrase 
target phrase touching landmark phrase roy learning visually grounded words syntax proximal distance landmark center mass orientation target proximal orientation visual features ground spatial semantics 

target phrase directly left landmark phrase 
target phrase right big landmark phrase utterances contain spatial phrases left right 
text filter developed detect stable phrases tokenize 
token encodes original word sequence required generation 
simple iterative procedure applied training utterances looks bigram transition probabilities preset threshold experiments 
wi wj greater threshold subsequences wi wj replaced token wj wi 
procedure applied reverse bigrams probability word word 
threshold applied reverse bigrams 
stable word pairs tokenized tokenizer rerun corpus iteratively pairs 
run training corpus phrases identified left right left 

grounding spatial terms regier analysis chose visual features ground spatial semantics 
illustrates features 
proximal distance prox dist distance landmark target points objects closest 
dotted line segment connecting corners objects proximal distance 
angle line horizon second feature proximal orientation prox orient 
third feature center mass orientation com orient 
line drawn center mass objects center mass orientation angle line relative horizon 
roy learning visually grounded words syntax training examples spatial features corresponding target landmark pair computed 
target landmark phrases removed training utterances grounded 
remaining words utterance paired spatial terms processed learning procedures described learning object phrase acquisition 
words word class formation feature selection word conditional density estimation new features bigram models constructed 
target landmark phrases bigram estimation 
table lists word classes acquired training corpus 
grounded terms clustered class visual features 
words terms listed cluster associated threedimensional gaussian distribution models expected values spatial features 
words automatically tagged ungrounded 
table word feature selection spatial terms 
word class class members features right prox orient com orient prox dist left touching ungrounded directly ungrounded horizontal vertical bright ungrounded due small number words involved decided estimate word bigrams word class bigrams 
shows word transitions probabilities larger 
point important connection word order utterance semantics established model 
visual grounding object phrases mapped target landmark phrase tokens 
bigram language model shown differentiates phrases semantic role phrase refers spatial landmark target 
connection syntax semantics necessary generate complex utterances 

generating relative spatial clauses describing spatial clause generation process address question decide generate complex versus simple utterance 
training corpus collected speaker utterances complex 
approach require generation system generate complex utterances frequency 
system generate complex simple utterances system confidence best possible simple utterance low 
accomplished object phrase generation system produce simple utterances set novel scenes 
roy learning visually grounded words syntax left directly target object landmark object start right touching word class phrase statistical bigram complex utterances relative spatial clauses 
utterance generated system evaluated context sensitive score utterance equation 
scores accumulated histogram 
threshold score threshold simple utterance scores lie 
threshold denoted 
training corpus 
novel scene system generates simple utterance system outputs final output 
complex utterance generated method 
goal generating relative spatial clauses touching pink rectangle reduce ambiguity target object 
target object system select landmark easy describe grounded object language models learned lies location easy describe acquired spatial language 
selection landmark achieved generating simple utterances object scene target 
context sensitive score computed utterance 
threshold defined select potential landmarks unambiguously described simple utterance 
objects describable sufficient confidence objects roy learning visually grounded words syntax relative clause generator fails system forced generate simple utterance 
assuming potential landmarks described spatial features extracted candidate relative target 
potential landmark best fitting spatial term selected 
candidate landmark highest selected landmark 
point system sequences words simple utterance describing landmark spatial term describes target landmark relation simple utterance describing target 
components dynamic programming algorithm uses phrase level bigrams find order sequence words form complex utterance 
shows representative output final system randomly generated scenes part training corpus 
target object specified system indicated images arrow 
targets system decided generate simple utterances 
cases unable generate unambiguous simple utterances opted complex utterance 

text speech conversion text output generation system synthesized word concatenation 
corpus speech recordings training corpus basis concatenative speech synthesis 
words training corpus acquired system able words synthesis units 
support concatenative synthesis speech corpus automatically aligned text transcripts viterbi algorithm context dependent triphone acoustic models phonetic dictionary full coverage training corpus vocabulary 
output alignment process set word indices specify start samples word source speech recordings 
synthesis novel utterance consists finding set speech segments corpus minimizes number jumps point speech recording 
viterbi algorithm efficiently solve search problem 
attempt smooth points concatenation final output subjects evaluations reported spoken utterances usually highly intelligible lacking natural prosody 
clearly existing techniques may applied improve quality synthesis task hand simple approach sufficient 
roy learning visually grounded words syntax lowest yellow rectangle rectangle left large purple rectangle leftmost green rectangle vertical orange rectangle vertical dark pink rectangle large green rectangle left vertical brown rectangle large red rectangle small dark blue rectangle large brown rectangle touching light purple rectangle large green rectangle dark brown rectangle thin light blue rectangle green horizontal green rectangle lowest green rectangle sample output generation system 

evaluation roy learning visually grounded words syntax evaluated spoken descriptions original human generated training corpus output generation system 
human judges unfamiliar technical details generation system participated evaluation 
evaluation program written presents images computer screen paired spoken descriptions heard speakers 
evaluation forced choice task 
judges asked select rectangle best fit description clicking object mouse pointer 
play option provided interface allowed judges listen spoken descriptions multiple times desired making selection 
goal evaluation measure level semantic accuracy ambiguity descriptions 
explicitly evaluate naturalness synthetic speech 
implicitly intelligibility synthesis evaluated low intelligibility result low understandability 
judge evaluated human generated machine generated spoken descriptions 
judges evaluated sets utterances 
responses evaluated comparing selected object image actual target object selected order produce verbal description 
table shows results human generated machine generated results 
table results evaluation human machine generated descriptions 
judge human generated machine generated correct correct average averaged listeners original human generated descriptions correctly understood time 
result reflects inherent rectangle task 
analysis errors reveals difference intended versus inferred referents subtle differences speaker listener conception term 
example terms pink dark pink purple light purple red lead comprehension errors 
cases appears speaker consider second object scene matched description produced 
average listener performance machine generated descriptions difference compared results set 
analysis errors reveals causes errors human set play machine data 
differences intended versus inferred meaning single descriptive terms 
cases object labeled descriptive term chosen mainly effect reducing ambiguity description accuracy 
roy learning visually grounded words syntax lead times confusions listeners 
addition system acquired incorrect grounded model spatial term left lead generation errors 
easily resolved providing additional training examples exemplify proper phrase 
results section demonstrate effectiveness learning algorithms acquire apply grounded structures visual description task 
semantics individual words stochastic generation methods able produce natural spoken utterances human listeners able understand accuracies lower original utterances spoken training corpus 

discussion language gains power generative capacity 
finite vocabulary words may combined form vast numbers unique word sequences 
language learning perspective key challenge develop algorithms generalize training examples novel word sequences may generated needed 
achieves goal 
able describe scenes encountered training choose sequences words occurred training data 
generative capacity result formation word classes phrase structure 
consider role acquired word classes 
statistical rules word order acquired observation words mapped words basis shared class membership 
example sequence large blue square observed sequence small red rectangle generated appropriate word classes acquired 
word classes formed partially basis semantic similarity bottom visual grounding directly influences application syntactic rules words 
rules symbol manipulation influenced subsymbolic visually grounded structure 
scope current results limited ways respect long term goal creating domain independent trainable systems 
limitations highlight challenging problems addressed goal achieved 
visual scenes processed synthetic highly constrained 
objects rectangular constant color guaranteed non overlapping 
scenes computer generated visual features derived scenes noise free 
operation complex real world input derived computer vision system robustness various sources perceptual ambiguity noise addressed 
syntactic structures acquired recursive 
layered markov model structures extended higher levels embedding represent arbitrary levels recursion 
statistical context free grammars functional equivalents need roy learning visually grounded words syntax introduced 
acquisition recursive structures require exploration different learning strategies 
training process simplified utterance truncation focus initial learning simple object descriptions optional relative spatial phrases 
complex training utterances including relative spatial clauses introduced second phase 
stage procedure system failed learn available number training examples 
avoid domain specific simplification model attention required focuses learning simple examples considering complex input 
turn requires automatic domain independent classification simple versus complex training examples 
output learning algorithms depends small number parameters set manually 
include hybrid word class creation bigram transition probability threshold tokenizing phrases balance syntactic contextual constraints generation 
parameters manually adjusted optimal system performance 
desirable difficult extension automate optimization parameters 
optimization process require performance reinforcement feedback 
essence system attempt put linguistic knowledge environmental feedback adjust parameters 

directions goal developing explore learning algorithms infer scene language mappings show tell input 
underlying algorithms implementation evaluation system generates natural spoken descriptions objects visual scenes 
learning algorithms process training examples images paired natural language descriptions acquire structures link linguistic visual representations 
visually grounded language learning occurs stages 
part described acquisition structures referring single objects 
showed distributional analysis word occurrence patterns combined semantic associations form word classes 
feature selection algorithm assigns visual features word classes information theoretic analysis 
semantics individual words grounded terms selected features estimating gaussian word conditional probability density functions 
word class bigram language model acquired model word order 
components generation algorithm integrates syntactic semantic contextual constraints produce optimal natural language descriptions objects 
sections described methods parsing complex training utterances acquired class language models 
parsed ut roy learning visually grounded words syntax automatically brought semantic correspondence objects training images 
correspondence process leverages grounding models acquired stage learning 
grounded semantics acquired spatial terms phrase level bigram language model complex utterances learned 
new structures modified generation system able generate complex utterances include expression referring target object relative spatial clause automatically selected landmark 
context sensitive score utterance ambiguity drives decision generate simple versus complex verbal descriptions 
system evaluated listeners 
listener asked select target visual scene verbal description 
procedure repeated listeners subset original training utterances 
human produced utterances led correct object selections time machine generated utterances led correct selections time 
system able communicate intent natural language near human level precision 
result demonstrates viability learning approaches grounded language generation 
directions plan pursue extend 
task chosen initial investigation highly nature underlying algorithms applied numerous practical applications 
replace synthetic visual features features derived video images experiment tasks involving complex linguistic constructions 
experiment inverting acquired linguistic structures enable visually grounded speech understanding 
began motivating method developing language generation systems applications sports commentators navigation systems 
represents steps direction 
significant challenges remain believe example approach feasible ultimately flexible approach visually grounded language generation 
author grateful janet cahn peter kai hsiao yuri ivanov tony jebara patel owen rambow anonymous reviewers helpful comments helped shape presentation 
roy learning visually grounded words syntax appendix vocabulary training corpus table vocabulary token counts complete transcriptions rectangle task corpus unique token types 
grey rectangle rectangles closest green white longest blue tall narrow purple olive long large thin biggest pink directly gold rightmost smaller square leftmost near brown highest light salmon skinny horizontal small colored sky vertical tan dark lower furthest left yellow faded orange sea violet red big surrounded brightest right cream touching black bright larger smallest uppermost bark lowest tiny shorter largest flat roy learning visually grounded words syntax table vocabulary token counts truncated transcriptions rectangle task corpus unique token types 
olive biggest rectangle rightmost gold green white blue leftmost purple highest smaller large colored pink salmon horizontal left light faded vertical sea small brightest right square tan brown black lower dark larger yellow violet orange uppermost red flat cream bright lowest longest smallest rectangles skinny largest narrow grey tiny shorter tall big thin long roy learning visually grounded words syntax elisabeth andr thomas rist 
generating coherent presentations employing textual visual material 
artificial intelligence review 
lawrence barsalou 
perceptual symbol systems 
behavioural brain sciences 
martin 
types models internalization grammars 
editor grammar 
academic press 
thomas cover joy thomas 
elements information theory 
wiley interscience new york ny 
robert dale 
generating referring expressions constructing descriptions domain objects processes 
mit press 
robert dale ehud reiter 
computational interpretations gricean maxims generation referring expressions 
cognitive science 
irving 
population frequencies species estimation population parameters 
biometrika 
allen gorin 
automated language acquisition 
journal acoustic society america 
harnad 
symbol grounding problem 
physica 
gerd herzog peter 
visual translator linking perceptions natural language descriptions 
artificial intelligence review 
pamela jordan marilyn walker 
learning attribute selections expressions 
proceedings acl 
george lakoff mark johnson 
metaphors live 
university chicago press chicago 
ellen markman 
categorization naming children 
mit press cambridge ma 
lawrence rabiner 
tutorial hidden markov models selected applications speech recognition 
proceedings ieee 
roy learning visually grounded words syntax terry regier 
human semantic potential 
mit press cambridge ma 
deb roy 
grounded speech communication 
proceedings international conference spoken language processing 
deb roy 
learning visually grounded words syntax natural spoken language 
evolution communication 
deb roy 
grounded spoken language acquisition experiments word learning 
ieee transactions multimedia 
deb roy alex pentland 
learning words sights sounds computational model 
cognitive science 
jeffrey siskind 
grounding lexical semantics verbs visual perception force dynamics event logic 
artificial intelligence review 
charles 
decision estimation classification 
wiley 
benjamin yoder 
spontaneous speech recognition hidden markov models 
master thesis massachusetts institute technology cambridge ma 
