intrinsic dimension estimation packing numbers department computer science operations research university montreal cp succ 
centre ville montr canada iro umontreal ca propose new algorithm estimate intrinsic dimension dam sets 
method geometric properties data requires parametric assumptions data generating model input parameters set 
method compared similar algorithm family geometric techniques 
experiments show method robust terms data generating distribution reliable presence noise 
high dimensional data sets unfortunate properties hard analyze 
phenomenon computational statistical efficiency statistical techniques degrade rapidly dimension referred curse dimensionality 
particular characteristic high dimensional spaces volumes constant diameter neighborhoods large exponentially points needed reliable density estimation 
important problem data dimension grows sophisticated data structures constructed speed nearest neighbor searches rapidly come inefficient 
fortunately meaningful real life data uniformly fill spaces represented 
data distributions observed concentrate nonlinear manifolds low intrinsic dimension 
methods developed find low dimensional representations high dimensional data including principal component analysis pca self organizing maps som multidimensional scaling mds local linear embedding lle isomap algorithm 
algorithms require intrinsic dimension manifold explicitly set little effort devoted design analyze techniques estimate intrinsic dimension data context 
principal areas estimate intrinsic dimension useful 
mentioned estimate set input parameters dimension reduction algorithms 
certain methods lle isomap algorithm require scale parameter determines size local neighborhoods algorithms 
case useful dimension estimate provided function scale see intuitive example intrinsic dimension data depends resolution 
nearest neighbor searching algorithms profit dimension estimate 
complexity search data structures kd trees trees increase exponentially dimension methods inefficient dimension 
shown complexity increases intrinsic dimension data dimension embedding space 
intrinsic dimension different resolutions 
small scale data looks zero dimensional 
scale comparable noise level intrinsic dimension larger expected 
right scale terms noise curvature 
large scale global dimension dominates 
novel method intrinsic dimension estimation 
estimate geometric properties data requires parameters set 
experimental results artificial real data show algorithm able capture scale dependence intrinsic dimension 
main advantage method existing techniques robustness terms generating distribution 
organized follows 
section introduce field intrinsic dimension estimation give short overview existing approaches 
proposed algorithm described section 
experimental results section 
intrinsic dimension estimation informally intrinsic dimension random vector usually defined number independent parameters needed represent practice informal notion defined meaning formally ambiguous due existence space filling curves 
informal notion turn classical concept topological dimension define intrinsic dimension topological dimension support distribution definition need introduce notions 
topological space covering subset collection open subsets union contains 
refinement covering covering set contained set definition observation dimensional set covered open balls point belongs maximum open balls 
definition subset topological space topological dimension drop known lebesgue covering dimension covering point belongs dtop sets dop smallest integer 
main technical difficulty topological dimension computationally difficult estimate finite sample 
practical methods various definitions intrinsic dimension 
common categorize intrinsic dimension estimating methods classes projection techniques geometric approaches 
projection techniques explicitly construct mapping usually measure dimension variants principal component analysis 
set xl xn data points drawn independently dis tribution probably obvious way estimate intrinsic dimension looking covariance matrix 
approach pca defined number eigenvalues larger threshold 
disadvantage technique requirement threshold parameter determines eigenvalues discard 
addition manifold highly nonlinear pca characterize global intrinsic dimension data local dimension manifold 
pca overestimate drop difference depends level nonlinearity manifold 
pca covariance matrix calculated aj lia 
section consider euclidean data sets certain applications distance metric li matrix pairwise distances dij xi xj 
sommer approach circumvent second problem 
doing pca original data cluster data construct optimally topology preserving map cluster centers carry pca locally nodes 
advantages method works non linear data produce dimension estimates different resolutions 
time threshold parameter set pca parameters number nodes decided user 
technique similar spirit way dimension parameter lle set 
algorithm runs time number points embedding dimension slightly worse complexity fast pca algorithm roweis computing bpc general scheme family projection techniques turn dimensionality reduction algorithm embedding technique probabilistic generarive model optimize dimension parameter cross validation maximum likelihood setting 
main disadvantage approach dimension estimate depends generarive model particular algorithm model fit data algorithm particular problem estimate invalid 
second basic approach intrinsic dimension estimation geometric properties data projection techniques 
methods family usually require explicit assumption underlying data model input parameters set 
geometric methods correlation dimension family dimensions due computational simplicity estimation 
formal definition observation dimensional set number pairs points closer proportional definition set sn cn metric space indicator function event countable set 
correlation integral defined 
limit exists correlation dimension defined lira log log finite sample zero limit achieved estimation procedure usually consists plotting log versus log measuring slope og linear part curve 
formalize intuitive procedure definition 
definition scale dependent correlation dimension xl xn corr rl log log rl log log rl finite set sn known tribution manifold nearly uniform 
non uniform distribution manifold correlation dimension severely underestimate topological dimension 
overcome problem turn capacity dimension member fractal dimension family 
formal definition need introduce concepts 
metric space distance metric covering number set minimum number open balls xo cld xo definition observation covering number dimensional set proportional definition capacity dimension subset ofa metric space dcap lim log log principal advantage dca dca depend data distribution manifold 
cap op exist certainly case machine learning applications known dimensions agree 
spite dca usually discarded practical approaches due high computational cost estimation 
main contribution efficient intrinsic dimension estimating method capacity dimension 
experiments synthetic real data confirm method robust terms data distribution methods correlation dimension 
algorithm finding covering number finite set data points computationally difficult 
tackle problem redefine dca numbers covering numbers 
metric space distance metric set said separated distinct 
packing number set defined maximum cardinality separated subset 
proposition follows basic inequality packing covering numbers 
proposition dcap lim log log finite sample zero limit achieved similarly correlation dimension need redefine capacity dimension scale dependent manner 
definition scale dependent capacity dimension set xl xn log log rl bcp rl log log rl finding data set xl xn equivalent finding cardinality maximum independent vertex set mi gr graph gr vertex set edge set xi xj ld xi xj results show general graph approximation mi factor ofn np hard 
positive side shown geometric graphs mi approximated arbitrarily polynomial time algorithms :10.1.1.26.4235
approximating algorithms kind scale exponentially data dimension terms quality approximation running time little practical 
algorithms apply greedy approximation technique 
data set start empty set centers iteration add data points distance centers lines 
estimate cardinality point visited 
procedure designed produce packing certainly underestimates packing number manifold finite sample second general place definition 
see observe estimate cap estimate constant multiplicative bias independent formal proof bias change simple greedy procedure described practice 
bias affect estimation cap long change variance distort dimension estimate 
main source variance dependence order data points visited 
eliminate variance repeat procedure times random permutations data compute estimate average logarithms packing numbers 
number repetitions depends preset parameter determines accuracy final estimate set experiments 
complete algorithm formally 
running time algorithm nm min rl 
smaller scales comparable 
hand variance estimate tends smaller smaller scales algorithm iterates accuracy 
experiments main objectives experiments described demonstrate ability method capture scale dependent behavior intrinsic dimension underline robustness terms data generating distribution 
experiments estimate compared correlation dimension estimate 
dimensions measured consecutive pairs sequence rm resolutions estimate plotted halfway parameters ri ri plotted ri ri experiments manifold known approximated easily 
experiments sided multivariate power distribution density xg typically computation independent vertex set size ami requires time 
rl cx permute randomly il ifd cj ffj log jl log log gr return algorithm returns packing dimension estimate rl data set accuracy times 
different exponents generate uniform non uniform data sets manifold 
synthetic data 
generated points spiral shaped manifold small uniform perpendicular noise 
curves reflect scale observed 
distribution uneven severely underestimates drop remains stable 
spiral hypercube intrinsic dimension spiral shaped manifold hypercubes different dimensions 
curves reflect scale dependency observed 
uneven distribution cor underestimates top remains relatively stable 
second set experiments designed test methods estimate dimension data points generated hypercubes dimensions fig ure 
general underestimates op 
negative bias grows dimension probably due fact data sets equal cardinality sparser higher dimensional space 
compensate bias general data set propose correct estimate bias observed uniform generated data set cardinality 
experiment shows case calibrating procedure fail distribution highly non uniform 
hand technique reliable due relative stability 
tested methods sets image data 
sets contained images gray levels 
images normalized distance black white image 
set sequence snapshots hand turning cup cmu database 
sequence images sweeps curve dimensional space informal intrinsic dimension 
shows small scale methods find local dimension 
slightly higher scale intrinsic dimension increases indicating relatively high curvature image sequence curve 
test distribution dependence estimates constructed polygonal curve connecting consecutive points sequence resampled points power distribution 
constructed lattice data set drawing approximately equidistant consecutive points polygonal curve 
results confirm varies extensively generating distribution manifold remains remarkably stable 
real datasets 
sequence snapshots hand turning cup 
faces database isomap 
final experiment conducted faces database isomap 
data set contained images faces generated free parameters vertical horizontal orientation light direction 
indicates estimates reasonably close informal intrinsic dimension 
turning cup isomap faces intrinsic dimension image data sets 

ri 
cmu 
edu idb html mot ion hand index 
html experiments small scale orr tends higher tends stable scale grows 
data contains little noise generated uniformly manifold orr closer real intrinsic dimension 
hand data contains noise case small scale estimating dimension noise dimension manifold distribution manifold non uniform reliable 
new algorithm estimate intrinsic dimension data sets 
method estimates packing dimension data requires parametric assumptions data generating model input parameters set 
method compared widely technique correlation dimension 
experiments show method robust terms data generating distribution reliable presence noise 
kohonen self organizing map springer verlag nd edition 
cox cox multidimensional scaling chapman hill 
saul nonlinear dimensionality reduction locally linear embedding science vol 
pp 

tenenbaum de silva langford global geometric framework nonlinear dimensionality reduction science vol 
pp 

navarro baeza yates searching mec spaces acm computing surveys appear 
sommer intrinsic estimation optimally topology preserving maps ieee transactions pattern analysis machine intelligence vol 
pp 

em algorithms pca spca advances neural information processing systems 
vol 
pp 
mit press 
bishop svens williams gtm topographic mapping neural computation vol 
pp 

saul hinton global coordination local linear models advances neural information processing systems 
vol 
mit press 
grassberger procaccia measuring strange attractors physica vol 
pp 

estimating intrinsic dimension data fractal approach ieee transactions pattern analysis machine intelligence appear 
faloutsos spatial join selectivity estimation fractal concepts acm transactions information systems vol 
pp 

hastad hard approximate proceedings th annual symposium foundations computer science focs pp 

jansen seidel polynomial time approximation schemes geometric graphs proceedings th acm siam symposium discrete algorithms soda pp :10.1.1.26.4235

