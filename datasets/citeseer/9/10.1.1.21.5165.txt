appears proc 
th annual international symposium computer architecture may atlanta georgia 
piperench coprocessor streaming multimedia acceleration seth copen goldstein herman schmit matthew moe mihai budiu srihari reed taylor ronald laufer school computer science department ece carnegie mellon university pittsburgh pa seth cs cmu edu herman moe rt rel ece cmu edu computing workloads emphasize architecture ability perform relatively simple calculations massive quantities mixed width data 
describes novel reconfigurable fabric architecture piperench optimized accelerate types computations 
piperench enables fast robust compilers supports forward compatibility virtualizes configurations removing fixed size constraint fabrics 
time explore bit width processing elements affects performance show piperench architecture optimized balance needs compiler realities silicon 
demonstrate extreme performance speedup certain versus modern risc processor analyze acceleration translates application speedup 

workloads computing devices rapidly changing 
desktop integration digital media real time media processing primary challenge architects 
embedded wireless computing devices need process data streaming sensors receivers 
changes emphasize simple regular computations large sets small data elements 
important respects need match processing strengths conventional processors 
size data elements processor wide datapath 
second instruction bandwidth higher needs perform regular dataflow dominated computations large data sets 
problems addressed processor architecture 
isas multimedia instruction set extensions allow wide datapath switched simd operation 
instruction bandwidth issue created renewed interest vector processing 
fundamentally different way addressing problems configure connections programmable logic elements registers order construct efficient highly parallel implementation processing kernel 
interconnected network processing elements called reconfigurable fabric data set program interconnect processing elements configuration 
configuration loaded reconfigurable fabric instruction bandwidth required perform computation 
furthermore operations composed small basic elements size processing elements closely match required data size 
approach called reconfigurable computing 
despite reports amazing performance reconfigurable computing accepted mainstream computing technology previous efforts inspired commercial fpgas fail meet requirements marketplace 
problems inherent standard fpgas include 
logic granularity fpgas designed logic replacement 
granularity functional units optimized replace random logic perform multimedia computations 

configuration time time takes load configuration fabric called configuration time 
commercial fpgas configuration times range hundreds microseconds hundreds milliseconds 
show performance improvement start latency amortized huge data sets limits applicability technique 

forward compatibility fpgas require redesign recompilation gain benefit generations chip 

hard constraints fpgas implement ker nels fixed relatively small size 
part reason compilation difficult fit 
causes large unpredictable discontinuities kernel size performance 

currently synthesis placement routing phases designs take hundreds times longer compilation kernel take general purpose processor 
describes piperench reconfigurable fabric designed increase performance computing workloads 
piperench realizes performance promises reconfigurable computing solving problems outlined 
piperench uses technique called pipeline reconfiguration solve problems reconfiguration time forward compatibility 
architectural parameters piperench including logic block granularity selected optimize performance suite kernels balancing needs compiler design realities deep process technology 
piperench currently attached processor 
places significant limitations types applications realize speedup due limited bandwidth piperench main memory processor 
believe represents evolution reconfigurable processors 
just floating point computation migrated software emulation attached processors coprocessors full incorporation processor isas reconfigurable computing eventually integrated cpu 
section examples illustrate advantages architectural requirements reconfigurable fabrics 
introduce idea pipeline reconfiguration section describe technique solves practical problems faced reconfigurable computing 
section describes class architectures implement pipelined reconfiguration 
evaluate architectures section 
cover related section section summarize discuss research 

reconfigurable computing 
attributes target kernels functions reconfigurable fabric provide significant benefit exhibit features 
function operates bit widths different processor basic word size 

data dependencies function allow multiple function units operate parallel 
int int taps 
code fir filter pipelined version tap filter 

function composed series basic operations combined single specialized operation 

function pipelined 

constant propagation performed reducing complexity operations 

input values reused times computation 
functions take forms 
stream functions process large data input stream produce large data output stream custom instructions take inputs produce outputs 
presenting simple example type function illustrate reconfigurable fabric improve performance discuss ways fabric integrated complete system 

stream function fir reconfigurable fabric effective implement entire pipelines applications 
investigate simple prototypical pipeline implementing finite impulse response fir filter 
fir filter exhibits feature requirement list section 
shows code hardware implementation 
fir mapped reconfigurable fabric general purpose multipliers shown hardware description implemented constant multipliers constants values 
results hardware fewer cycles general purpose multiplier 
compares bit fir bit coefficients running particular instance piperench implementations xilinx fpga parallel distributed arithmetic shown xilinx pda bit serial distributed arithmetic shown xilinx dda 
piperench chip xilinx fpga implemented mm silicon micron process 
second piperench xilinx pda xilinx dda ti dsp fir filt er taps 
performance bit fir filters piperench xilinx fpga parallel serial arithmetic texas instruments dsp 
int unsigned int sum sum return sum 
code hardware implementation population count 
fpga runs approximately mhz applications piperench clock mhz 
piperench outperforms xilinx implementations broader range filter sizes 
similarly piperench outperforms texas instruments tms commercial dsp runs mhz contains bit integer multipliers filters larger taps 
piperench exhibits high level performance fpga 
due support hardware virtualization described section piperench exhibits graceful degradations performance dsp 

custom instructions population count instruction processors exception vector supercomputers include native population count instruction implemented software see 
reconfigurable fabric implemented custom instruction giving raw performance improvement order magnitude 
function exhibits qualifying features memory bus mb sec bus mb sec gb sec gb sec cpu main memory tightly coupled functional unit loosely coupled attached processor reconfigurable fabric 
possible locations reconfigurable fabric memory hierarchy 
bandwidth figures typical mhz sun ultrasparc ii 
section 
reconfigurable computing solution replaces loop adder tree height log 
furthermore adders significantly narrower adders processor 
circuit pipelined executed vector retires result cycle 
evaluating reconfigurable fabric important take account configuration time communication latency bandwidth processor fabric 
called little sense configure fabric perform operation time configure larger savings obtained executing fabric 
outside loop data dependencies require result immediately computed fabric needs direct access processor registers 
hand loop immediate dependencies results performance better fabric directly access memory 
concentrate case 

fabric place reconfigurable fabrics provide computational datapath flexibility 
utility applicability influenced manner integrated datapath 
recognize basic ways fabric may integrated system attached processor memory bus coprocessor functional unit main cpu 
see 
attached processor systems pam splash disc direct access processor :10.1.1.43.1041:10.1.1.43.1041
controlled bus 
primary feature attached processors easy add existing computer systems 
due bandwidth latency constraints imposed bus enhance computations high computation memory bandwidth ratio 
suited stream functions require little communication host processor 
coprocessor architectures low latency highbandwidth connection processor reconfigurable fabric increases number functions profitably run fabric 
examples systems include garp napa :10.1.1.22.3767
specialization occurs fabric main processor data path functional unit architectures risc chimaera :10.1.1.47.1042:10.1.1.47.1042
allow custom instructions executed 
reconfigurable unit processor datapath access registers 
implementations restrict applicability reconfigurable unit disallowing state stored fabric cases disallowing direct access memory essentially eliminating usefulness stream processing 
describe pipelined reconfigurable architectures fashions described 
order describe system currently building limit describing apply attached processor system 
natural evolution fabric coprocessor function unit enhance applicability 

pipelined reconfigurable architectures previous section described applicationspecific configurations reconfigurable fabrics accelerate certain applications 
computation embedded single static configuration sequence instructions reducing instruction bandwidth 
static nature configurations causes significant problems 
computation may require hardware available 
second hardware way single hardware design exploit additional resources inevitably available process generations 
section review technique called pipeline reconfiguration allows large logical design implemented small piece hardware reconfiguration hardware :10.1.1.47.1042
technique compiler longer responsible satisfying fixed hardware constraints 
addition performance design improves proportion amount hardware allocated design process technology transistors available hardware designs achieve higher levels performance 
pipeline reconfiguration method virtualizing pipelined hardware application designs breaking single static configuration pieces correspond pipeline stages application 
configurations loaded cycle fabric 
possible perform computation configuration fabric time 
shows stage pipeline virtualized fabric 
top portion shows application state stages pipeline consecutive cycles 
bottom half shows state physical stages fabric executing application 
effective metaphor procedure scrolling text window 
pipeline full cycles generates results pipeline 
general stage application virtualized device capacity stages throughput implementation proportional throughput linear function capacity device performance improves due increases clock frequency decreases feature size redesign applications performance continues gain increased clock speed 
configuration stages happens concurrently execution stages loss performance due reconfiguration 
pipeline filling data stages computation configured ahead data 
virtualization configuration time equivalent pipeline fill time application reduce maximum throughput application 
order virtualization process state pipeline stage function current state stage current state previous stage 
words cyclic dependencies fit stage pipeline 
interconnect directly skips stages allowed connections stage previous stage 
fortunately computations streaming data pipelined constraints 
furthermore including structures call pass registers possible create virtual connections distant stages 
primary challenge facing pipeline reconfiguration configuring computationally significant pipeline stage clock cycle 
connect wide chip configuration buffer sram dram nearby fabric allowing pipeline stage configured cycle 
word stripe describe physical stages stripes configuration words written virtual stripes 
virtual stripe written physical stripe 
physical stripes identical functionality cycle stage stage stage stage stage stage stage stage virtual legend physical configuring executing 
pipeline reconfiguration 
diagram shows process virtualizing stage pipeline stage device 
interconnect 
physical stripe reconfigured new virtual stripe state resident virtual stripe stored outside fabric 
conversely virtual stripe returned fabric stored state stripe restored physical stripe 

piperench section describe class pipeline reconfigurable fabrics called piperench devices define critical architectural parameters class fabrics 
architectural parameters subject performance evaluation described section 
view piperench architectural class shown 
device composed set physical pipeline stages stripes 
stripe composed interconnect processing elements pe contain registers alus 
alu composed look tables luts extra circuitry carry chains zero detection pes access global bus 
interconnect network pes access operands registered outputs previous stripe registered unregistered outputs pes stripe 
busses go previous stripe required hardware virtualization discussed long feedback loops impossible feedback contained stripe 
global busses busses pe stripe stripe register file pe register file interconnect network 
register file pe alu register file pe stripe alu alu register file pe interconnect network alu 
pe alu register file alu 
piperench architecture pes interconnect 
required pipeline stages application may physically located stripes fabric inputs outputs application global bus get destination 
piperench devices global busses 
storing restoring hardware virtualization 
input output 
combinational logic implemented set nb bit wide alus 
alu operation static particular virtual stripe located physical stripe 
carry lines piperench alus may cascaded construct wider alus 
furthermore alus may chained interconnect network build complex combinational functions 

pass register file organize stripe array processing elements pes 
pe contains alu pass register file 
described section unregistered interconnect stripes 
furthermore state caused registered feedback stripe saved restored 
pass register designed provide efficient pipelined registered connections 
pass register file dedicated register intra stripe feedback state stored restored 
illustrated output alu written registers pass register file 
register written alu value pass register loaded value corresponding pass register previous stripe 
reduces amount state contained pass register file single register data travels pipeline limiting set physical stripes may hold particular virtual stripe eliminate global busses 
reduces utilization may increase clock frequency sufficiently worthwhile 
busses alu read port stripe stripe alu write port 
pass register file 
pass register interconnect 
global busses bits pe output previous stripe interconnect network 
barrel shifter barrel shifter alu control carry bits interconnect network pass registers control carry bits bits pe global output bus 
complete architectural class 
need saved restored 
pass register file provides way route intermediate results computed stripe stripe pipeline wasting alus interconnect network stripe 
alu operation specific registers written read pass register file static virtual stripe resident different pes read write different registers registers particular pe accesses change different virtual stripe configures physical stripe 

interconnect network pass register file provides pipelined interconnect pe stripe corresponding pe subsequent stripes 
data values need move laterally stripe interconnect network illustrated horizontal bar 
stripe interconnect network accepts pes stripe registered values previous stripe 
alu operations pass register files interconnect network programmed configuration remains unchanged lifetime virtual stripe 
interconnect evaluate section full crossbar 
expensive terms hardware design easily compiler 
furthermore rich network necessary achieve utilization reconfigurable fabric 
fact fabrics available area interconnect 
shown section full crossbar area interconnect 
full crossbar connects pes pes bit wide nxn crossbar opposed crossbar 
key making interconnect useful pe barrel shifter shift inputs bits left see 
allows architecture data alignments necessary word arithmetic described 

physical implementation currently planning design system mm silicon micron process 
half area reconfigurable fabric half memory store virtual stripes control chip square millimeters silicon provides approximately kb virtual configuration storage adequate large applications 

architectural parameters summarizes pes stripe parameterized architecture 
section explore architectural parameters number pes stripe width bits pe number bit wide registers pass register file pe 

evaluation section explore design space pipelined reconfigurable 
compiler cad tools look kernels perform implementations fabric differ parameters described section 

kernels applications performance utilization data gathered piperench implementations various kernels 
kernels chosen demand applications near recognition industry performance benchmarks ability fit computational model 
atr implements kernel sandia algorithm automatic target recognition 
algorithm find instance template image larger image distinguish images contain different templates 
cordic stage implementation honeywell timing benchmark cordic vector rotations 
vector rectangular coordinates rotation angle degrees algorithm finds close approximation resultant rotation 
dct dimensional point discrete cosine transform 
dct dimensional dct important algorithm digital signal processing core jpeg image compression 
fir described section 
implement fir filter taps bit coefficients 
idea implements complete round international data encryption algorithm key compiled configuration 
idea heart phil zimmerman pretty privacy pgp data encryption 
evaluator problem board 
coordinates chess queens chessboard determines queens attack 
implements porter duff operator 
method joining images mask transparency values pixel 
described section section 
performance piperench complete applications jpeg pgp 
applications assume piperench integrated system pci bus peak memory bandwidth mb sec 

methodology approach cad tools synthesize stripe parameters andp join automatically synthesized layout custom layout interconnect 
final layout determine number physical stripes fit silicon budget mm mm mm delay components stripe luts carry chain interconnect 
delay number registers compiler create configurations architectural instances yielding design certain number stripes particular frequency 
determine speed kernel terms throughput architectural instance 
cad tool flow synthesizes design point automatically places routes final design 
automatic tool flow yield optimal design assume various points equally non optimal allowing compare designs 
preliminary analysis showed cad tools doing quite interconnect hand optimize 
kernels written single assignment language dil intended programmers intermediate language high level language compiler targets reconfigurable architectures 
dil compiler automatically synthesizes places routes largest designs seconds 
parameterizable generate configurations pipelined reconfigurable described section 

fabric main constraints determine parameters generate realizable fabrics width stripe number vertical wires pass stripe 
width stripe influenced size number pes number registers allocated pe 
limit width stripe mm order allow placed side side 
second constraint accomodate number vertical wires pass stripes metal layers 
wires include global busses pass registers configuration bits 
explore region space bounded pe bits stripe widths bits bits registers 
shows computational density area time realizable parameters registers allocated pe 
interestingly result essentially independent stripe width 
reason stripe width increases amount area stripe devoted interconnect increases total number stripes decreases constant amount total area devoted interconnect 
fact total area devoted interconnect area devoted fabric 
total delay output stripe pe stripe remains approximately constant wire capacitance interconnect mm long cases dominates transistor delays 
computational density monotonic relationship pe width 
counter virtualization requires data allowed flow stripes including physical physical 
obtain consistent routing delay times arrange stripes columns column data flows flows 
avoids long path physical stripe 
wider stripes registers 
megabit operations mm sec register computational density pe bit width stripe width intuitive pe size increases overhead configuration decreases ability optimize pe increases 
computational density increase 
delay metric includes delay associated carry chain pe increases pe width 
increased carry chain delay counters reduction size bit wider pes causing computational density remain relatively constant 
hand logical operations measure delay observe near linear increase computational density pe size increases 
registers consume substantial area density goes number registers increases compare graphs 
fact registers mainly implement pipelined interconnect contribute little computational density 
see extremely useful compiling kernels fabric 
effect examine size configuration word 
configuration word size approximately halves pe widths double 
hand width stripe increases configuration word increases slightly 
bit stripes configuration bits stripe range bits bit pe bits bit pe 

compiler compilation process maps source written dataflow intermediate language dil particular instance piperench 
dil single assignment language operators type system allows bit width variable specified 
compiler converts source dataflow graph transformations creates final configuration 
important transformations study operator decomposition operator megabit operations mm sec 
computational density 
register computational density pe bit width stripe width recomposition fitting place route 
operator decomposition pass breaks operators execute target cycle time 
example wide adder needs broken smaller adders due carry chain delays 
decomposition create new operators handle routing carry bits partial sums 
operations require carry bits decomposed version significantly larger additional routing constraints 
pe size decreases penalty decomposition increases 
currently interaction operator decomposition place route requires stripe pes 
naive decomposition operator routes carry signal interconnect 
results single carry bit size smaller adders 
compensate operator recomposition pass uses pattern matching find subgraphs mapped parameterized modules designed take advantage architecture specific routing pe capabilities 
importantly study slightly reduces overhead decomposed carry operations 
fitting pass matches wire operator widths size pe 
require insertion operators increase width wires multiples pe width 
pe width increases causes underutilization pes larger percentage sign extension pes 
furthermore routing operations complex extracting bits wires pe aligned involves extra pe 
place route key compiler 
places routes operators graph stripes timing constraint imposed target cycle time 
clock rate delay pe increases utilization stripe decrease kernel inputs second atr number registers pe cordic dct dct fir idea 
harmonic mean throughput fabric parameters function registers 
sufficient parallelism independent operators placed stripe 
particularly true stripes pes 
addition assigning operators pes wires interconnect place route pass assigns wires pass registers 
insufficient pass registers compiler time multiplex wires registers 
slows circuit order allow multiple values reside single registers 
example wires assigned single register register holds wire odd cycles ones 
time multiplexing increase circuit size significantly reduce throughput constant factor 
architectures registers severe penalty time multiplexing factors may required 
goals dil compiler compilation speed 
achieves high speed compilation part trading result quality faster compilation 
affects results introducing time necessary 

compiler fabric interaction real question course raw hardware performance available utilized 
parameterizable compiler compiled configurations kernel 
evaluating effects width number pes number bits pe narrow design space effect pass registers 
stripe width bits pe number registers increase computational density decreases 
pass registers important component interconnect reducing number pass registers increases routing pressure decreases stripe utilization causes compiler time multiplex values registers 
shows best balance computation density achieved registers 
average time multiplexing factor kernels average fabrics ranges registers sixteen registers 
idea higher factors registers kernels 
rest evaluation occurs pass registers pe 
shows throughput achieved various stripe widths pe sizes registers pe 
seen wider pe sizes create fabrics higher computational density natural data sizes kernels smaller causing bit pes underutilized 
spectrum bit pes competitive due increased times arithmetic operations lack raw computational density increased number configuration bits needed application 
examine performance individual kernels see see characteristics kernels greatly influence parameters best 
example dct needs pes stripe ruling bit pes widest stripe 
peak bits occurs sufficient number pes eliminate time multiplexing 
wider stripes utilized sufficient parallelism dct algorithm 
fir operates bit wider numbers 
bit pes due carry chain delay associated crossing pes 
parallelism keep wider stripes busy 
stripes fewer registers increases number stripes implementation reducing throughput 
idea takes wide inputs stripes bits require substantial time multiplexing 
dct fir parallelism utilize wider stripes 
summary need choose fabric bits wide 
want pes stripe 
kernels sufficient parallelism utilize wide stripes want choose narrowest stripe kernels compiled 
choose bit wide fabric bit pes registers 

performance versus general purpose processors bit pe bit stripe registers compare performance piperench general purpose processor ultrasparc ii running mhz 
shows raw speedup kernels 
performance hard achieve piperench pes required transpose data dimensional dct 
millions inputs second millions inputs second throughput idea pe bit width stripe width bits speedup mhz ultrasparc ii throughput dct pe bit width stripe width bits millions inputs second millions inputs second throughput fir pe bit width stripe width bits harmonic mean throughput pe bit width stripe width bits 
throughput various kernels mhz piperench 
kernels registers 
atr cordic dct dct fir idea 
speedup eigth bit pe registers pe bit wide stripe 
connected bus large fraction raw speedup achievable 
table shows speedup piperench versus application input size mb speedup pgp jpeg table 
speedups pgp jpeg mhz bit stripe piperench bit mhz pci bus compared mhz ultrasparc ii 
doing entire application main processor 
pgp replace code idea accounting application invocations piperench reducing time portion code zero yielding average speedup 
jpeg running dimensional dct kernel piperench obtain average improvement 
find pci bus imposes serious bottlenecks performance applications 

related numerous architectural research efforts focused efficiently harnessing huge numbers transistors media centric computing workloads 
lineage systems derives fpgas existing computer architectures 
fpgas termed reconfigurable computing systems include prisc disc napa garp chimaera chip raw rapid :10.1.1.22.3767:10.1.1.43.1041:10.1.1.43.1041:10.1.1.47.1042:10.1.1.47.1042
reconfigurable computing systems support architectural abstraction virtual hardware 
case compiler aware system constraints violates constraint failed 
compilation difficult slow unpredictable 
furthermore facility architectures forward compatibility application needs compiled new chip 
piperench offers hardware virtualization forward compatibility easier compilation 
aforementioned architectures piperench differs fp gas basic word size bits interconnect general efficient computation 
piperench addresses problems faced computer architectures 
focus uniprocessor systems piperench exploits fine grained parallelism 
insightful comparisons mmx vliw vector machines 
mismatch application data size native operating data size addressed extending isas microprocessors allow wide data path split multiple parallel data paths intel mmx 
obtaining simd parallelism utilize parallel data paths nontrivial works regular computations cost data alignment overwhelm gain parallelism 
piperench rich interconnect provide alignment allows pes different configurations parallelism need simd 
vliw architectures designed exploit dataflow parallelism determined compile time 
extremely high instruction bandwidth demands 
single piperench stripe similar vliw processor small simple functional units 
piperench stripe configured perform computation large data set amortizing instructions data 
instruction bandwidth issue addressed vector microprocessors iram 
problem vector architectures vector register file physical logical bottleneck limits scalability 
allocating additional functional units vector processor requires additional port vector register file 
physical bottleneck register file ameliorated providing direct forwarding paths allow chained operations bypass register file 
places large demands issue hardware 
logical bottleneck caused limited namespace register file 
addressed implementing register renaming avoid false dependencies 
vector microprocessors subject complexities issue control hardware design modern superscalar processors 
connections piperench local central logical physical bottleneck 
number functional units grow increasing complexity issue control hardware 

described new reconfigurable computing architecture piperench emphasizes performance computing workloads 
piperench uses pipelined reconfiguration overcome difficulties faced previous attempts reconfigurable computing tackle important applications 
piperench enables fast robust compilers supports forward compatibility virtualizes hardware removing fixed size constraint fabrics 
result designer base broadened development cycles shortened application developers amortize cost development multiple process generations 
examined computational density fabric automatically synthesizing hardware number architectural parameters including size pe number pes number registers 
raw computational density relatively flat space architectures 
architectural parameters tuned retargetable compiler measure amount exploitable computational power fabric 
compiler hardware synthesis flow tandem pes bit widths best compromise flexibility efficiency broad range kernels 
pes arranged moderately wide stripes bits wide obtain significant performance improvements generalpurpose processors cases achieving improvement orders magnitude 
performance numbers conservative 
hardware performance compiler efficiency significantly optimized 
currently building pci board include piperench chips 
piperench currently built system attached processor examining move closer processor 
expect just computing demands past decades forced floating floatingpoint units computing workloads near cause piperench move attached processor reconfigurable unit 

authors wish reviewers helpful comments 
supported darpa contract dabt 
received financial support altera technical support 
bertin touati 
pam programming environments practice experience 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca apr 
blinn 
fugue mmx 
ieee computer graphics applications pages march april 
budiu goldstein 
fast compilation pipelined reconfigurable fabrics proceedings acm sigda seventh international symposium field programmable gate arrays fpga ca feb 
buell arnold athanas 
splash fpgas custom computing machine 
aw 
goldstein schmit thomas 
managing pipeline reconfigurable fpgas 
proceedings acm sigda sixth international symposium field programmable gate arrays february 
lewis datapath oriented architecture fpgas 
second international acm sigda workshop field programmable gate arrays 
nix rodman 
vliw architecture trace scheduling compiler 
proceedings asplos ii pages mar 
franklin berg ebling 
specifying compiling applications rapid 
pocek arnold editors proceedings ieee fpgas custom computing machines pages napa ca apr 
ieee computer society ieee computer society press 
dehon 
reconfigurable architectures general purpose computing 
phd thesis massachusetts institute technology september 

multimedia workloads change processor design 
ieee computer september 
hauck 
roles fpgas reprogrammable systems 
proceedings ieee pages apr 
hauck fry kao 
chimaera reconfigurable functional unit 
ieee symposium fpgas custom computing machines fccm pages april 
hauser wawrzynek 
garp mips processor reconfigurable coprocessor 
ieee symposium fpgas custom computing machines pages april 
patterson anderson cardwell keeton thomas yelick 
scalable processors transistor era iram 
ieee computer pages september 
kumar sensitivity 
technical report honeywell january 
www honeywell com projects 

practical fast dct algorithms multiplications 
proc 
international conference acoustics speech signal processing icassp pages 
peleg wilkie weiser 
intel mmx multimedia pcs 
communications acm 
smith 
high performance microarchitecture hardware programmable functional units 
micro pages november 
holt arnold gokhale 
napa adaptive processing architecture 
ieee symposium fpgas custom computing machines fccm april 
schmit :10.1.1.47.1042
incremental reconfiguration pipelined applications 
arnold pocek editors proceedingsof ieee fpgas machines pages napa ca apr 
schneier 
idea encryption algorithm 
dr dobb journal december 
schoner chia zapata 
configurable computing solutions automatic target recognition 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca apr 
taylor software raw machines 
ieee computer pages september 
wawrzynek kingsbury beck johnson morgan 
ii vector microprocessor system 
ieee computer march 
hutchings :10.1.1.43.1041
dynamic instruction set computer 
athanas pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca apr 
wittig chow 
fpga processor reconfigurable logic 
ieee symposium fpgas custom computing machines 
