incremental document clustering web page classification wai chiu wong ada wai chee fu department computer science engineering chinese university hong kong hong kong 
mail cse cuhk edu hk motivated benefits organizing documents web search engines consider problem automatic web page classification 
employ clustering techniques 
document represented feature vector 
analyzing clusters formed vectors assign documents cluster class automatically 
contributions propose feature extraction suitable web page classification 
introduce tree structure called dc tree clustering process incremental sensitive document insertion order 
show experiments set internet documents yahoo 
proposed clustering algorithm classify web pages effectively 
keywords incremental update tree document clustering web classification popularity internet caused continuous massive increase amount web pages web documents information explosion led growing challenge information retrieval systems internet search engine efficiently effectively retrieve information 
document classification important process helping information retrieval systems organize vast amount data 
instance internet search engines divide indexed web documents number classes users limit search scope 
document classification retrieved results easier browse 
search engines return large amount results simple query words submitted 
difficult users find documents want 
results returned internet search engine classified groups descriptions users choose interesting group continue browsing 
traditionally document classification task carried manually 
order assign document appropriate class people analyze contents document 
large amount human effort required 
research conducted automatic text classification 
approach learn text classifiers machine learning techniques :10.1.1.55.3252
algorithms set positive negative training examples learning text classifiers 
quality resulting classifiers highly depends fitness training shall terms web pages web documents documents interchangeably 
examples 
terms classes world wide web just web new terms concepts created everyday 
quite impossible domain experts identify training examples learn classifier text class manner 
order document classification process automatic clustering techniques employed 
attractiveness cluster analysis find clusters directly data relying predetermined information training examples provided domain experts 
document commonly represented feature vector 
typically feature corresponds key word phrase appearing set documents 
entry vector stores numeric weight corresponding feature document 
extracting feature vectors documents apply clustering algorithm set vectors conventional high dimensional data clustering 
resulting document clusters representative features key words phrases document support cluster reported user 
clustering algorithms introduced high dimensional data mining example means clarans birch cure clique enclus :10.1.1.13.4395
existing clustering algorithms general suitable solve document clustering problem 
means clarans birch require supply number clusters 
unfortunately number clusters classes document set usually unknown user 
major issue document databases facing high rate update 
researchers existing clustering algorithms suitable maintaining clusters dynamic environment identified problem updating clusters frequently performing complete re clustering 
propose tree structure incremental document clustering 
introduce tree structure called dc tree document clustering tree cluster documents training set 
dc tree incoming data object forced inserted lower level exist child node similar data object 
prevents dissimilar data put 
result clustering algorithm sensitive doc ument insertion order tolerant noise documents 
feature selection major problem related document clustering 
find traditional feature extraction methods suitable web domain 
feature extraction methods select highest weighted terms features 
term weighting scheme commonly term frequency tf term frequency combined inverse document frequency tf idf 
discover experiments see section ii web page usually contains small number words words appear times 
term frequency word indicate actual importance word 
method ignores coverage features extracted 
coverage important want tiny clusters appear 
propose feature extraction algorithm suitable problem domain 
believe method useful number ways preprocessing web page classification users choose suitable class searching helps search focused efficient 
online classification large number results returned search technique classify results provide better guidance user searching 
incremental web page classifications updating repository 
organized follows 
section ii gives background information introduces feature extraction method 
section iii dc tree structure corresponding insertion algorithm described detail 
section iv reports experimental evaluation proposed feature extracting method web document clustering algorithm 
ii 
feature extraction document clustering task identify feature extracting method suitable web environment 
section propose method 
document document cluster representation described 
describe alternatives measuring similarity document feature vectors 
clustering quality evaluation method 
statistical analysis web domain order study traditional term weighting suitable web document clustering carried experiment analyze number distinct words average word frequency web pages 
stratified random sampling technique collecting document set experiment 
topics arts humanities business economy computers internet entertainment government health recreation sports science social science society culture chosen yahoo 
search engine 
coverage percentage documents contain extracted features 
randomly collect documents topic 
collecting web documents number valid words pages counted 
discard document contains zero valid word 
totally web pages collected yahoo 
search engine 
statistics words web documents shown table standard deviation 
average distinct words word freq 
mean median maximum minimum table statistics words web documents study number distinct words web documents 
notice web documents contain words 
statistics documents contain equal distinct words documents contain equal distinct words documents contain equal distinct words 
documents average word frequency fig 

document distribution average word frequency table average word frequency term frequency documents means words web document rarely appear times 
traditional term frequency weighting scheme designed longer documents may useful web domain 
document feature extraction luhn proposed frequency word occurrences article furnishes useful measurement word significance 
order words frequency occurrences resulting rank order 
zipf law see product frequency valid word define remaining words page word removal word stemming process 
words rank order approximately constant 
traditionally document represented feature vector form dn numeric weight th feature total number features 
feature corresponds word appearing training corpus stemming words removal words 
common feature extracting method number occurrences particular terms documents eliminate common function words document texts consulting special dictionary list containing list high frequency function words 
compute term frequency tf ij remaining terms document specifying number occurrences method combines term frequency inverse document frequency tf idf 
document frequency df number documents collection documents term occurs 
typical inverse document frequency idf factor type log df 
weight term document ij tf ij theta log df 
terms highest weights documents chosen features 
experiments find feature extracting methods suitable web document clustering algorithm due reasons shown section ii web document usually contains small number words words 
term frequency key word may higher non key word 
usually users want clusters clustering result 
tf idf method may extract features relatively low document frequency lower document frequency give higher weight feature 
features lead clustering result containing small clusters 
methods ignore coverage features extracted 
coverage features defined percentage documents containing feature features extracted 
methods choose best terms guarantee terms cover high percentage documents 
coverage low documents represented feature vector zero weight entries 
propose feature extracting method web document clustering algorithm depend term frequency 
method balances trade coverage number features document representation 
problem domain clustering aims aid information retrieval web searching narrowing search scope 
scenario user may want clusters result 
large clusters small clusters desirable 
large clusters help narrow search scope 
small clusters increase total number clusters may caused noise 
parameter set approximate number cluster size 
number clusters approximately total number documents 
proposed method involves steps 
randomly select subset documents size corpus 

extract set words appear documents 
remove words combine words root stemming technique 

count document frequency words extracted step 
set lower upper 
select words document frequency range lower upper 
check coverage words larger predefined threshold 

set lower lower gamma upper upper goto step 
document set usually large inefficient carry feature extraction process entire document set 
order extract representative features documents randomly select set sample documents feature extraction step 
carried experiments show feature extraction method extract set features web document clustering 
word list remove meaningless words suitable represent concept class 
stemming technique combine words similar form 
shorter feature vectors lead shorter clustering time steps try minimize number features obtain reasonable coverage features 
assume user wants resulting cluster contain documents 
ideal case feature cluster appear cluster document frequency feature select features document frequency equal setting lower upper step 
range lower upper enlarged repeatedly step ensure sufficient coverage resulting feature set 
see rough guideline actual number clusters clustering result may method coverage threshold ensure features selected sufficient coverage 
experiments see section find coverage threshold value 
document representation algorithm document represented form id id document identifier retrieve document feature vector document 
number extracted features ij weight th feature ng 
algorithm binary weighting scheme 
ij equal contains th feature 
ij equal 
mentioned section ii web page typically contain words term frequency word indicate actual importance word 
binary weighting scheme suitable problem domain 
document cluster dc document cluster value dc triple storing information maintain set documents cluster number documents set document identifiers feature vector cluster 
definition dc definition documents cluster fd dn document cluster dc entry node defined triple dc id number documents cluster id set document identifiers documents cluster id fid id dn feature vector document cluster wn ij number extracted features 
triple summarizes document frequency inside cluster measure closeness clusters 
lemma gives flexibility combine clusters gives dc value combined cluster 
lemma dc additivity dc id dc id dc entries disjoint document clusters disjoint means document belong cluster time 
new dc entry cluster formed merging disjoint clusters id id number extracted features 
considered alternatives measuring similarity document feature vectors classical vector space model 
measure called cosine correlation commonly measure similarity feature vectors documents 
larger cosine value indicates similar 
second similarity measuring method uses euclidean distance common similarity measuring method high dimensional data clustering :10.1.1.13.4395
third alternative manhattan distance 
performed experiments manhattan distance gives similar better results uses computation time compared methods 
chosen manhattan distance similarity measurement 
evaluation techniques order evaluate quality clustering result adopt measure evaluation technique introduced see :10.1.1.16.3103
details evaluation methodology described 
hand labeled topic document set suppose cluster corresponding topic formed 

documents topic cluster 
documents cluster total 
documents topic precision recall measure topic defined pr respect topic consider cluster highest measure cluster measure score topic fmeasure tree clustering result weighted average measure topic measure jt theta jt set topics jt number documents topic measure topic iii :10.1.1.16.3103
dc tree section propose web document clustering algorithm means document cluster tree dc tree 
dc tree node considered document cluster 
tree structure guide incoming document object appropriate document cluster dc leaf nodes 
similar tree index records leaf nodes contain pointers data objects height balanced tree :10.1.1.13.4395
structure designed assigning document cluster requires visiting small number nodes 
dc tree tree parameters branching factor similarity thresholds minimum number children node 
non leaf node contains entries form dc child child pointer th child node document dc dc entry sub cluster represented th child document 
non leaf node represents cluster sub clusters represented entries 
dc leaf node contains entries entry form dc doc bg doc pointer document set documents dc dc entry corresponding sub cluster 
call set documents pointer document leaf node distinguish tree leaf node dc leaf node see 
dc leaf node represents cluster sub clusters represented dc entries 
dc tree allows incoming document entry inserted new document leaf node different levels tree 
dc tree height balanced tree 
shows sample dc tree height 
note tree balanced 
tree construction thresholds 
threshold order prevent poor document clustering result documents different classes assigned subtree cluster caused document insertion order determine single document combined documents dc dc dc dc dc dc dc dc dc dc dc dc leaf nodes document leaf nodes fig 

dc tree example incoming document entry passed level insertion process 
exists child entry current node similarity value entry incoming entry higher incoming entry passed corresponding child node 
incoming entry added current node new document leaf node 

threshold dc tree document clustering indexing necessary force leaf entry point single document 
order reduce insertion time incoming document entry combined leaf entry similarity value higher entry combination merging described lemma save node insertion splitting operations insertion time reduced 
dc tree compact representation dataset entry leaf node single data point cluster data points leaf node absorbs data points threshold allows 
dc tree definition tree size function threshold values general tree height increases tree size increase set zero number larger dc tree similar balanced tree tree tree 
insertion algorithm inserting document object dc tree 
document object single document cluster documents represented dc entry 
document object single document encapsulated dc entry contains document 
insertion algorithm proceeds steps shown 
identifying appropriate leaf node starting root recursively descends dc tree choosing closest child node similarity value higher child node exist inserted new document leaf node empty entry node 
empty entry node splitting required see section iii 

modifying leaf node reach dc leaf node find closest leaf entry say tests combined violating similarity threshold requirement dc entry updated reflect combination 
note dc entry new cluster computed dc entries lemma 
added leaf node 
space leaf node new entry fit done split leaf node 
section iii discuss node splitting algorithm detail 

modifying path leaf node root inserted leaf node update non leaf entry path root leading leaf node 
absence split simply involves adding dc entries reflect addition leaf node split requires insert new non leaf entry parent node points newly created leaf node 
parent node space entry fit higher levels need update dc entries reflect addition general may split parent node root 
root split height tree increased new root created 
node splitting order add new entry full node containing entries necessary divide collection entries nodes 
division done way similarity new nodes minimized similarity documents node maximized 
turn algorithms partitioning set entries groups new node 
straightforward way find optimal node split generate possible groupings choose best 
number possibilities large approximately gamma 
node splitting algorithm dc tree insertion algorithm 
node splitting algorithm similar method considered tree 

pick seed group pair entries compute similarity 
choose pair lowest similarity value elements groups 
resolve ties choosing pair largest number documents 

check done entries assigned 
group entries rest assigned order minimum number assign 

select entry assign entry group calculate similarity seed entry group 
assign entry highest similarity value corresponding group 
goto step 
splitting algorithm attempts find node split quadratic time terms guaranteed find optimal solution 
deletion node merging data deletion algorithm similar tree 
number remaining entries larger equal minimum entries number parameter removing entry deletion operation done 
node merge operation carried 
underflow node merged sibling 
node merge operation needed entry underflow phenomenon occurs parent node 
operation propagated root node height tree may reduced necessary 
identifying interesting clusters cluster identifying process starts root tree 
breath search algorithm applied discover interesting clusters 
interesting cluster defined cluster contains representative features size predetermined range 
lower upper values proposed feature extracting method see section ii determine cluster size range 
lower bound upper bound cluster size range determined equations lower theta upper theta data set size size sample data set feature extraction 
range adjusted manually obtain clustering result 
identified interesting cluster sub clusters descendent nodes scanned 
representative feature defined feature support cluster 
document frequency representative features greater user defined threshold 
call threshold representative threshold 
features represent cluster 
iv 
experimental results section list experimental results proposed feature extracting method web document clustering algorithm 
complete set results 
applied algorithm synthetic data real data studying performance relationship parameters proposed algorithms 
find behaviour similar real data synthetic data 
experiments run sun ultra mb ram 
programs compiled gnu executed solaris operating system 
synthetic data generation synthetic datasets generated generator developed 
data generation controlled parameters number document feature vectors number features number clusters similarity level ranged 
feature vectors clusters cluster set features randomly represent cluster 
document generated features chance set gamma set 
features chance gamma set 
higher similarity level similar documents cluster 
yahoo 
web page collections collected sets web pages yahoo 
search engine 
contains non correlated topics contains correlated topics 
web pages indexed yahoo 
search engine classified 
construct non correlated document set selected sub topics author credit bank internet game wine film disease organization job opportunity soccer astronomy organization psychology department 
topics collected web pages 
totally web pages dataset 
correlated topic web document set selected sub topics location dir yahoo com computers internet programming languages yahoo 
search engine cobol fortran java lisp pascal perl python smalltalk visual basic 
topics collected web pages 
totally web pages dataset 
comparing dc tree tree experiment want comparison effectiveness document clustering web domain dc tree tree 
real data sets web documents correlated topics non correlated topics 
feature sets experiment converting document feature vector experiment 
set contains features 
dc tree parameters previous experiment 
employ binary weighting schemes construct document vectors apply document clustering algorithms cluster document vectors 
compare effectiveness terms measure value clustering result precision value 
non correlated correlated topics topics 
clusters cluster size range representative threshold clustering time sec sec measure value table ii real data clustering results representative thresholds dc tree method cases shown table ii chosen trial error 
table shows experimental measurements 
experimental results terms fmeasure non correlated topic document set correlated topic document set shown figures iv respectively 
figures show dc tree gives better clustering result tree real data sets terms measure 
ns ns ns ns ns data set measure dc tree tree fig 

measure non correlated topic cs cs cs cs cs data set measure dc tree fig 

measure correlated topic document set precision cluster calculate document support known topic number documents containing topic 
choose topic highest document support topic cluster 
tables iv iii show precision values clusters algorithms 
show dc tree gives better clustering result tree terms precision resulting clusters 
results quite high compared results reported terms average precision 
precision best precision results shown 
compare directly data sets different results encouraging 
table table vi lists representative features cluster 
classification automatic simple title topic clusters guess topic clusters representative features 
representative features words indicate users cluster 
precision cluster topic dc tree tree author internet game wine credit bank soccer astronomy organization psychology department job opportunity film disease organization average table iii precision clusters non correlated topic document set precision cluster topic dc tree tree cobol fortran java javascript lisp pascal perl python smalltalk average table iv precision clusters correlated topic incremental updates real data set order study impact incremental updating clustering result non correlated topic document set experiment insert additional documents existing dc tree observe change clustering quality 
seconds convert documents feature vectors 
table vii shows changes clustering quality additional documents added existing clustering result 
table notice measure value decreases 
clustering quality decreases terms measure value documents added existing document set 
note update document set involve small amount computation clustering 
document clustering algorithm suitable incremental updating web pages 
cluster topic features author book story year internet game best free game review wine wine credit bank credit service union soccer report soccer team astronomy astronomy union organization psychology psychology university department job opportunity career experience job location film film star disease organization disease health medical organization table clusters non correlated data cluster topic features cobol cobol procedure fortran fortran java applet class event javascript active document javascript lisp lisp object pascal define interface pascal perl module perl port python kendall python thread smalltalk browse develop message smalltalk basic click item visual table vi classification result correlated topic web page collection wai lam chao yang ho generalized instance set automatic text categorization proceedings st annual international acm sigir conference research development information retrieval melbourne australia august 
david lewis william gale sequential algorithm training text classifiers proceedings th annual international acm sigir conference research development information retrieval dublin ireland july :10.1.1.16.3103
david lewis robert schapire james callan ron papka training algorithms linear text classifiers proceedings th annual international acm sigir conference research development information retrieval zurich switzerland august 
se slattery mark craven combining statistical relation methods learning hypertext domains proceedings th international conference inductive logic programming madison wisconsin usa july :10.1.1.55.3252
yiming yang expert network effective efficient learning human decisions text categorization retrieval proceedings th annual international acm sigir conference research development information retrieval dublin ireland july raymond ng jiawei han efficient effective clustering methods spatial data mining proceedings th vldb conference santiago de chile chile september :10.1.1.13.4395
documents measure value table vii incremental update results tian zhang raghu ramakrishnan miron livny birch efficient data clustering method large databases proceedings acm sigmod conference management data montreal canada june 
guha rajeev rastogi kyuseok shim cure efficient clustering algorithm large databases proceedings acm sigmod conference management data seattle washington usa june 
agrawal johannes gehrke dimitrios gunopulos prabhakar ra automatic subspace clustering high dimensional data date mining proceedings acm sigmod conference management data seattle washington usa june 
chun hung cheng ada wai chee fu yi zhang subspace clustering mining numerical data proceedings acm sigkdd international conference knowledge discovery data mining san diego ca usa august 
ii incremental clustering dynamic document databases proceedings symposium applied computing 
moses charikar chandra chekuri tomas feder rajeev motwani incremental clustering dynamic information retrieval proceedings ninth annual acm symposium theory computing el paso texas usa may 
van rijsbergen information retrieval butterworth publishers 
clement yu weiyi meng principles database query processing advanced applications morgan kaufmann publisher :10.1.1.13.4395
yahoo search engine www yahoo com 
oren zamir oren etzioni web document clustering feasibility demonstration proceedings st annual international acm sigir conference research development information retrieval melbourne australia august 
luhn automatic creation literature abstracts ibm journal research development 
zipf addison wesley human behavior principle effort cambridge massachusetts 
empirical hyperbolic distributions mandelbrot description prediction journal documentation 
gerard salton addison wesley publishing automatic text processing 
transformation analysis retrieval information computer 
gerard salton mcgill mcgraw hill modern information retrieval new york 
gerard salton mcgill mcgraw hill modern information retrieval new york 
larsen aone fast effective text mining linear time document clustering proceedings acm sigkdd international conference knowledge discovery data mining san diego ca usa august 
gerard salton mcgill mcgraw hill modern information retrieval new york 
guttman proceedings acm sigmod tree dynamic index structure spatial searching 
wai chiu wong ada fu incremental document clustering web page classification manuscript full version 
