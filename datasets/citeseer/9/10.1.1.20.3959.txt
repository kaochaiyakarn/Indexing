leading best response strategies repeated games michael littman peter stone labs research park avenue florham park nj research att com april repeated general sum games agent best response strategy maximizes payo assuming behavior ect opponent 
notion best response requires degree learning determine xed opponent behavior 
unchanging opponent best response agent performs optimally thought follower adapts opponent 
pairing best response agents repeated game result suboptimal behavior 
demonstrate suboptimality di erent games variants learning example best response strategy 
examine leader strategies induce better performance opponent followers threats 
high stakes simultaneous multi commodity auctions ongoing fcc spectrum auctions weber human bidders shown bid strategically threaten opponent bidders retaliation market opponent compete di erent market 
threats threatening agent convince agent willing execute threat agent able understand allowing threat executed best interest 
fcc spectrum auctions threats responses coordinate strategic demand reduction lead substantial bene ts participants 
weber described importance threats auctions follows sustain tacit agreement bidders concerning allocation licenses binding agreements legal 
force threats serve stabilize agreement 
bidders licenses subsequent attempt violate agreement immediately met response raising prices licenses held 
consider agents issue respond threats context repeated bimatrix games player general sum 
bimatrix games dicult challenges agent learning planning 
zero sum games agents objectives diametrically opposed agents participating general sum games concessions opponents ultimately improve payo result 
behavior agent important just damage cause bene ts confer ally 
standard approach learning games apply best response strategy learning sen 
learning bene ts simple providing guarantee optimal response xed opponent watkins dayan 
sense best response strategies learning followers attempt maximize payo assuming behavior ect opponents 
unchanging opponent best response agent learns perform optimally 
pairing followers repeated game result suboptimal behavior 
explore simple strategies act leaders behave way maximizes payo factoring responsive behavior opposing agent 
sections describe bimatrix games learning 
describe leader strategies experimental results number simple games show leaders improve payo followers 
bimatrix games bimatrix game de ned pair matrices size number rows number columns 
stage players choose actions row row player column column player 
row player receives payo column player receives payo 
objective players maximize average payo unbounded number stages 
example consider game 
row player selects action column player selects action row player receives payo column player receives payo auction example understand intuitive connection auctions repeated games imagine scenario 
day players engage simultaneous auction items bidding starts go high 
player drops bidding particular item place bid 
player values item 
player bids item bidder get leading net payo 
players continue bidding item price go awarded randomly leading expected payo player 
example imagine row player bid item items column player bid item items allowing combinations bids change example substantial way 
imagine players deciding bid item day continue bidding bid declared winner limit reached removing assumption change example substantial way 
scenario leads payo player bids just item bidding items leads best possible payo item contested item 
bid items expect payo 
hand coordinate demand bid item achieve payo 
alert readers recognize version classic game prisoner dilemma 
delve game detail section 
strategies behavior strategy bimatrix game speci es method choosing action 
general form behavior speci es probability distribution action choices conditioned full history past actions taken agents 
justi able choice behavior bimatrix game player maximize payo assuming opponent maximum small possible 
strategy called minimax security level strategy 
security level expected payo player guarantee minimax strategy 
strategy computed linear programming von neumann morgenstern 
nash equilibrium player adopts strategy best response incentive unilateral deviation nash 
shortcoming players adopting minimax strategies need nash equilibrium 
example consider game called chicken minimax strategy take action agent get 
agents action nash equilibrium agent improve changing action 
agent action action nash equilibrium game 
pareto optimal behavior pair player improve payo hurting opponent 
shortcoming players adopting minimax strategy result necessarily pareto optimal strategy pairs bene cial parties 
example consider prisoner dilemma minimax strategy take action 
agents payo 
hand better agree take action 
show agents issue respond threats ect agree play mutually bene cial strategies 
learning learning reinforcement learning algorithm best justi ed stationary single agent fully observable environments 
performs environments violate assumptions 
general form learning agent state nite set states choose action nite set 
keeps data structure represents estimate expected payo starting state action behaving payo maximizing manner 
time agent transition state state action receives payo table updated max parameters range 
learning rate parameter close table changes rapidly response new experience 
discount rate close interactions play substantial role de ning total payo values 
repeated game context choice state space learner 
studied choices 
approach uses just single state state transitions 
approach attempts learn memoryless thing strategy best response opponent strategy bowling claus boutilier 
contrast approach uses action choice previous stage state 
possible principle learner detect punished action stage lead reduced payo stage 
learning agents choose actions greedy policy state choose random action probability argmax 
random actions exploration actions give learner opportunity nd action looks may better current preferred action choice 
learner faces xed opponent share history features learner faces markov decision process papadimitriou 
learning converge optimal behavior type opponent 
leader strategies section describes strategies bully godfather action choices assuming opponents best response strategy learned learning 
general strategies apply repeated bimatrix games concepts generalize naturally competitive scenarios 
bully bully deterministic state free policy consistently plays action de ned argmax argmax 
leader payo matrix follower 
bully chooses action maximizes reward opponent playing best response 
example bully choice game chicken equation choose action opponent best response behavior choose action resulting payo bully 
type strategy known leader fudenberg levine oligopoly literature 
result playing bully style follower nash bully chooses action maximizes payo assuming opponent execute memoryless best response choice follower chooses action maximizes payo assuming opponent action choice xed 
godfather godfather nite state strategy opponent er refuse 
call pair deterministic policies pair playing results player receiving security level 
godfather chooses pair plays half action pair rst stage 
opponent plays half pair stage godfather plays half stage 
plays policy forces opponent achieve security level 
godfather issues threat play half pair ll force get security level matter 
godfather generalization tit tat prisoner dilemma fame axelrod 
member general class nite state strategies uses threat security level outcome maintain mutually bene cial outcome littman stone 
bully godfather achieves nash outcome paired style learner 
experiments illustrate importance leader strategies compared bully godfather di erent repeated games 
representative best response strategies 
experiments strategies parameters 
experiment ran stages average payo computed nal stages 
reported results re ect mean standard deviation experiments identical conditions 
variance experiments due stochastic strategies random exploration strategies 
games reported bimatrix games diagonal payo upper left lower right 
call action cooperate action defect 
mutual cooperation payo mutual defection payo analogy prisoner dilemma equation 
addition players payo structure 
varying diagonal payo games di erent dynamics created 
names games common usage game theory community 
deadlock obvious choice deadlock straightforward game regardless opponent choice player better cooperating bully chooses cooperate game godfather cooperates uses defect threat 
average payo strategy bully godfather basically players cooperate receive payo close mutual cooperation 
exploration average payo slightly lower 
assurance suboptimal preference assurance game important match player choice cooperate chance opponent defect better defect 
better defect minimax perspective making safest alternative 
game learners typically coordinate choices particular bias coordination point chosen 
result expected score high variance 
pair learners perform game bully godfather bully choosing cooperate invites learner cooperate achieve maximum score 
similarly godfather threatening defection time opponent defects teaches mutual cooperation best response 
godfather able teach lesson remember previous action rewarded punished 
worth noting changing value payo matrices changes probability pair learners cooperate 
value decreases mutual cooperation equilibrium easier nd learners part expected payo defecting random opponent decreases 
hand value increases nding mutual cooperation equilibrium harder 
value exceeds mutual cooperation payo game changes prisoner dilemma described 
prisoner dilemma incentive defect regardless opponent choice player prisoner dilemma better defecting deadlock learners sensitive dominance choice quickly converge 
case payo suboptimal 
bully strategy game defect 
godfather strategy tit tat cooperate opponent cooperates defect leading results bully godfather combination godfather pair achieves mutual cooperation payo game 
interestingly godfather able lure higher paying policy short periods time 
chicken incentive exploit chicken player better choosing opposite action opponent game suggestive game highway chicken cars approach high speed 
moment drivers decide veer away cooperate keep going straight defect 
driver doesn chicken low payo player gets high payo 
player result extremely low score 
chicken trickier game reason prisoner dilemma 
minimax perspective best strategy cooperate 
player notices opponent consistently cooperates incentive defect 
player defects result stable 
chicken incentive act stupid convince opponent defect matter opponent eventually back cooperate maximizing score 
smart opponents try convince won back resulting kind meta game chicken hold learning possible moment 
addition argue prisoner dilemma tit tat best player reasonably expect score way imagine inducing opponent repeatedly accept payo tit tat chicken marginally attractive stable option defecting opponent cooperation 
results illustrate complexity game bully godfather successful strategy game bully repeatedly defects waits learner cooperate response 
godfather combination able nd mutual cooperation payo surprisingly combinations follower vs follower result payo approximately high variance learners randomly choose asymmetric equilibria 
unexpected outcomes results combinations godfather 
suggested low variance high score combinations consistently settle mutual cooperation 
cooperation counterintuitive represent threatening strategy respond 
fact mutual cooperation completely stable players 
preliminary investigation indicates learning agents learning cooperate temporarily periodically exploring result defection unable remember negative ect doing 
time defect works rst 
eventually opponent re adapts punishes defecting agent agent remembers better cooperate switches back cooperation period time forgetting exploring 
cycle repeats order dozen stages 
illustrates importance strategies lead best response agents repeated games 
showed combination basic learners results suboptimal payo games studied type result explored ctitious play literature 
described simple stationary leading strategy bully complex state strategy godfather 
bully godfather general strategies apply range games 
godfather attempts stabilize mutually bene cial payo punishing opponent deviates assigned action 
showed state learner remembers immediately previous action learns respond consistently godfather threats 
conclude agents need go straight best response strategies ective broad range scenarios necessary resort complicated strategies achieve 
experiments combination godfather settled mutual cooperation game 
combination led highest score attained games chicken bully able learning agents achieve higher score 
chicken godfather safer strategy godfather godfather achieve mutual cooperation bully bully result mutual defection 
results leader strategies playing case result suboptimal performance due fact assume opponents adapt strategies 
successful pairings explored leader follower 
faced unknown opponent clear role agent adopt 
natural approach mix leader qualities follower type qualities function opponent behavior 
human agents high stakes multi commodity auctions example shown issue respond threats need arises 
case results suggest agent interacting agents competitive game environment consider agents best response strategy 
agent look ways apply bully godfather strategy 
going research agenda involves creating agents issue respond threats detailed simulator fcc spectrum auctions 
taken rst step understanding implement agents perform important type reasoning 
robert axelrod 
evolution cooperation 
basic books 
michael bowling 
convergence problems general sum multiagent reinforcement learning 
proceedings seventeenth international conference machine learning pages 
caroline claus craig boutilier 
dynamics reinforcement learning cooperative multiagent systems 
proceedings fifteenth national conference arti cial intelligence pages 
michael littman satinder singh peter stone 
fcc spectrum auction simulator autonomous bidding agents 
preparation 
drew fudenberg david levine 
theory learning games 
mit press 
michael littman peter stone 
polynomial time algorithm computing nash equilibria repeated bimatrix games 
research note 
sandip sen evaluating concurrent reinforcement learners 
proceedings fourth international conference multiagent systems pages 
ieee press 
nash 
non cooperative games 
annals mathematics 
christos papadimitriou 
players bounded number states 
games economic behavior 
von neumann morgenstern 
theory games economic behavior 
princeton university press princeton nj 
christopher watkins peter dayan 
learning 
machine learning 
robert weber 
making strategic demand reduction fcc spectrum auctions 
journal economics management strategy 

