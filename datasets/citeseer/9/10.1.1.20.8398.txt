scientific computation javaspaces michael noble harvard smithsonian center astrophysics boston university 
javaspaces provides simple expressive mechanism distributed computing commodity technology 
discuss suitability javaspaces implementing different classes concurrent computations low level metrics null messaging array performance results parametric algorithms 
inefficient communication intensive problems javaspaces yields speedups parametric experiments relative sequential java outline dynamic native compilation technique short compute intensive codes boosts performance compromising java portability extensive algorithm recoding 
discussion empirical results context public benchmark suite 
date study java high performance computation grouped broad categories lifting language constraints optimizing communication extending numerical capability various forms native compilation 
related contributions demonstrate clearly java platform numerical large retain research orientation performance gains obtained highly specialized means custom jvms compilers pre compiled native binaries 
notwithstanding increasing need computational power complexity parallel distributed programming tools related costs deployment administration hinders broader adoption scientific community 
attempts bridge gap high performance java research utilization research community investigating commodity tuplespace implementations high performance computation 
gelernter thoroughly described literature exist wide variety implementations :10.1.1.53.2540
central idea generative communication processes communicate directly adding removing tuples ordered collections data code space process independent storage shared memory characteristics accessed associative lookup 
communication model defined adding handful primitives noble write read take eval base language gives rise distinctive properties time uncoupled anonymous communication sender receiver need know identity need exist simultaneously networked variable sharing tuples may viewed distributed semaphores 
simplicity clean semantics allow natural expressions problems awkward difficult parallelize models 
focus javaspaces general purpose implementation investigated tspaces contrast briefly metrics discussion 
low level metrics experiments conducted machines described table 
communication machines required hop mbps ethernet lan 
packets subnet node bu sgi origin traveled hops mbps campus network packets bu final harvard cfa machines traveled hops local internet segment 
space hosted mhz server available memory offer concurrent jvms javaspaces combined user interaction 
order client machines listed reflects computations single mhz solaris workstation sequential java tests second mhz host added workers win host forth 
intermediate speed hosts sequential testing reflect typical network containing machines varying speed expressly avoided dedicated hardware 
benchmark numbers peak times culled successive invocations javaspaces jdk native threads gcc optimization 
table 
summary testbed cluster platform processors memory java 
hosts sol mhz mb sol mhz mb windows mhz mb linux mhz mb sol mhz mb sgi mhz mb sol mhz mb beta sol mhz mb beta canonical null message benchmark directly implemented javaspaces java null value wildcard matching fields tuple prohibited residing space scientific computation javaspaces tuple 
best create empty subclass jini javaspaces entry interface 
avoid excess serialization snapshot template write take operations 
means tuples fully serialized series write take client side space proxy essentially informing space nd nth calls new tuple duplicates existing space 
retrieval benchmark tests approaches result space take null 
result space take snapshot 
method shows contrast writing tuples may retrieved matching null object 
lines entry table indicate fastest technique arguably space manager avoid costly field matching operations simply return available tuples 
suggest second approach demonstrates cost field matching space object casting client necessary tuples returned entry objects subclass instances small objects lengthen retrieval 
table 
peak null tuple rates nobj writes sec sec takes sec sec mhz space server mhz client mhz space server win client dual mhz sparc ultra hosting space client interesting note best lan round trip time exceeds ms triple ms latency reported years ago linda 
aware comparison completely apt testbed loosely coupled cluster linda result generated tightly coupled bus net multicomputer javaspaces uses centralized space linda distributed efficient communication achieved linda kernel compiler optimizations option javaspaces linda takes advantage connectionless udp protocol javaspaces due current jini rmi implementations heavier connection oriented tcp 
despite differences comparison dismissed 
mhz mhz hosts yielded peak ethernet result noble faster mhz net nodes peak net bus bandwidth quoted fast ethernet 
space client live user processes dual mhz cpu host crossbar switch reported yield gb sec peak memory bandwidth completely avoiding ethernet null latency doubled linda 
fact fastest client subnet produced greatest throughput suggests higher rates may achieved hosting space faster server 
netperf tool determined byte messages peak tcp send receive rate lan transactions sec greater null tuple throughput 
estimate null tuple size sizeof class written instantiates object initiates mock serialization count number bytes wire transferred 
classes objects serialize roughly bytes respectively despite empty subclass empty interface 
sending messages orders magnitude greater size bytes able obtain tcp request response rate neighborhood peak tuple rate 
similar tests conducted array tuples various sizes 
double array tuples null template retrieval elem writes sec sec kbytes sec takes sec sec mhz server win client fast ethernet localhost communication multiple mhz cpu ultra sults shown table 
second line entry represents cost transmitting strided arrays employed algorithms portions array need communicated red black sor nodes scientific computation javaspaces exchange stripes alternating elements 
benchmarks indicate savings communicating smaller arrays worth extra sender byte throughput lower tuple throughput observably higher 
benchmark suggests alternative simple iteration useful overload java system method support 
effort focused javaspaces perform cursory review tspaces ibm 
tspaces easier configure added overhead null tuple ca 
bytes lead lower individual rates writes sec null tuples writes sec array tuples 
tspaces batch operators yielded significantly higher throughput writes sec null tuples writes sec array tuples double elements 
parallel algorithms carriero gelernter provide linda master slave prime number generator indicate problem size primes speedup achieved ibm rt nodes loosely connected mbps ethernet 
workers search primes grain sized chunks consecutive integers 
chunk worker writes new batch primes space retrieved en masse stored master prime list serially rewritten back space tuple distinct distributed array element worker may update local table primes 
series calls equivalent javaspaces write effectively prohibits identical javaspaces implementation 
firstly javaspaces tuple adds minimum ca 
bytes transmission prime parts overhead part data byte int 
peak write performance operations sec minimum sec required populate distributed javaspaces array equal size 
lastly memory exceptions consistently occurred writing roughly null tuples 
launching space jvm confirmed minutes needed write tuples space client hosted dual cpu ultra ethernet execution quite bit longer ca 
minutes 
contrast sequential invocation prime finder needed seconds mhz solaris host java implementation sieve seconds find primes 
iterative grid solvers provide example poor communication performance javaspaces prevents efficient solutions 
class problems domain discretized dimension intervals yielding multidimensional mesh grid approximation computed mesh point 
efficient implementations similar algorithms reported java linda 
example consider dimensional laplace equation approximated finite difference neighborhood gamma gamma gamma noble iteratively evaluated mesh point sufficiently small discrepancy seen successive calculations 
neighboring points straddle processors adjacent processors exchange boundary information messaging costs incurred iteration create performance bottleneck 
compare javaspaces sequential tested jacobi relaxation times java ranging sec sec iterations mesh sec sec iterations mesh 
account space access times table clear javaspaces version inefficient mesh workers need exchange array tuples ca 
seconds testbed factor times slower sequential javaspaces lacks broadcast gather reduce communication operators heavily message passing mesh implementations implemented limited versions test jacobi relaxation resulting performance order magnitude slower sequential parametric experiments results far show benefits javaspaces communication improved performance simplicity uncoupling communicating agents space time 
concurrent computations loosely coupled high computation communication ratios stand gain javaspaces 
illustrative example pi digit finding discretization subintervals 
worker takes space tuple containing discretized algorithm total number tasks rank current task completion writes partial sum tuple back space master performing generate final result 
performance figures table gathered timestamps master include cost tuple instantiation task distribution results collection 
note sets figures reported workers represents partitioning tasks workers second represents finer decomposition tasks workers permits faster machines consume results superlinear speedups relative sequential java ensured worker consumed task 
optimum tuple decomposition granularity established apriori automatically runtime trial error 
workers run single subnet host workers distinct processes node cfa machines workers processes nodes sgi 
approach compute pi applied large class problems known parametric experiments 
parametric computations task executed repeatedly different inputs parameters 
case pi function distinct parameter 
node executes self contained algorithm runtime behavior entirely determined inputs avoiding need scientific computation javaspaces table 
pi estimation runtimes seconds subintervals sequential times gcc jdk jdk mips javaspaces times mips openmp pragma processors na tasks tasks tasks tasks communicate nodes computation 
discuss parameterized monte carlo algorithms particle shielding light propagation multilayer tissue 
shielding experiment simulates collision particles unit thick shield constructed material density model assumes particle say neutron collide times atoms shield time bouncing random direction retaining percentage incident momentum 
horizontal distance traveled collisions deltax inversely related material density constant proportionality coded algorithm body follows deltax deltax momentum cos deltax momentum penetrated break break momentum example contrived illustrative purpose dissimilar degree kind simulations regularly conducted 
host worker allocation experiment followed pi computation yielded favorable results table 
ensure cross language experiments traced computation avoided ansi rand function java random class yields different sequences favor defining function linear congruential method vol 
knuth art computer programming 
simplify evaluation held parameters constant increased varied ceil 
second parametric simulation light prior subsequent launch example thousands ray trace experiments conducted cfa simulate behavior chandra ray telescope optics instrumentation 
noble table 
shielding light propagation photons runtimes sequential times sec particle shielding light propagation gcc jdk jdk gcc jdk jdk javaspaces times sec na tasks tasks tasks tasks propagation multilayer tissue real algorithm published oregon medical laser center 
parameters number photons scattering coefficient thickness tissue layer absorption coefficient results table held constant trial 
dynamic compilation describe method extends code delivery parallelization mechanisms javaspaces boost worker performance native compilation 
idea generalizes longstanding observation compute intensive algorithms spend time concise regions code seek demonstrate short codes better advantage native architecture outweigh compilation jni costs executed machines sufficient power 
computations flow described earlier tasks contain sourcecode 
workers continue retrieve execute tasks oblivious inner algorithmic details case include compilation invocation jni 
emphasis short codes important decrease time needed compiler build shared library enhance portability increasing likelihood code compile sans error potentially unknown target system short numerical codes tend avoid exotic system calls graphics routines sources platform incompatibilities 
distributing code textual form dynamically generating platform specific libraries precompiled binaries avoid compromising java portability aspect jni maintain heterogeneity criterion 
programmer brings existing code table effort recode algorithms java cases avoided 
help short utility script example took minutes wrap light propagation code java class suitable jni invocation 
intend investigate runtime conversion java bytecodes native binary pursued due lack wide availability scientific computation javaspaces open tools fact tend support newer java features needed javaspaces 
overhead dynamic compilation measured executing dynamic task photons typically ranged seconds ca 
seconds consumed compilation rest accounted jni java overheads 
results table show overheads small yield sharp performance increase relative pure javaspaces small numbers workers 
table 
dynamic compilation photon light propagation workers execution time shown javaspaces exacerbates known problems java platform notably communication latency renders javaspaces unsuitable algorithms including efficient linda implementation 
gave evidence parametric experiments yield speedups relative sequential java novel approach speedup native compilation described utilizes jni avoids compromising portability java invoking code compiled target platform runtime 
results significance pi light propagation java light propagation dynamic compilation particle shielding fig 

speedups javaspaces algorithms versus sequential implementation compiled gcc workers 
computer science research community reasons 
employed commodity software exclusively commodity hardware 
second young benchmark package readily available provides computation framework complements simplicity javaspaces noble may quickly assess performance javaspaces tspaces network hardware platform adapted development 
benchmarks utilize vanilla functionality avoiding event notification custom jini services java aware compilers believe fields historical complexity parallel programming models find java alternative 
include detailed comparisons tspaces exploration role java virtual 

freeman arnold javaspaces principles patterns practice addison wesley 
moreira midkiff gupta standard java array package technical computing proc 
ninth siam conf 
parallel processing scientific computing march 
wu midkiff moreira gupta efficient support complex numbers java proc 
acm java grande conference june 
carriero gelernter distributed data structures linda proc 
acm symp 
principles prog 
languages 
carriero gelernter write parallel programs guide acm comput 
surv 
sep 
efficient serialization rmi java concurrency practice experience may 
yelick pike miyamoto krishnamurthy hilfinger graham gay colella aiken titanium high performance java dialect acm workshop java high performance network computing 
van maassen bal wide area parallel computing java proc 
acm java grande conference 
welsh culler jaguar enabling efficient communication java concurrency practice experience december 
jacques welch monte carlo model light propagation tissue spie proceedings laser radiation medicine biology vol 

lehman wyckoff tspaces wave hawaii intl 
conf 
system sciences hicss jan 
noble distributed services java fourth science data centers symposium www sci org march 
noble tonic benchmark package scientific computation java hea www harvard edu tonic doc 
