pergamon special issue coding properties spiking neurons reverse cross correlations gerstner swiss federal institute technology lausanne laboratory computational neuroscience di ch lausanne epfl switzerland received march accepted march meaning single spike 
spike triggered averaging reverse correlations yields typical input just spike 
similarly cross correlations describe probability ring output spike additional presynaptic input spike 
analytically calculate reverse cross correlations spiking neuron model escape noise 
uence neuronal parameters membrane time constant noise level mean ring rate form correlation function illustrated 
calculation done framework population theory reviewed 
relation population activity equations population density methods discussed 
indicate role cross correlations spike time dependent hebbian plasticity 
elsevier science rights reserved 
keywords spiking neurons integrate re model reverse correlations cross correlations population equations population activity rate model hebbian learning spike time dependent plasticity noise 
problem neural coding phrased questions berry bialek rieke de van de van strong bialek hertz richmond ko nig engel singer richmond rieke de van bialek miller rolls treves 

encoding 
effect single presynaptic spike activity postsynaptic neuron stimulation cause output spike 

decoding 
learn stimulus observation single output spike 
rst question addressed cross correlation experiments see fig 

neuron spontaneously active background activity receives time additional presynaptic input spike 
averaging presynaptic spike arrivals synapse estimate probability generating output spike input spike cross correlation cross ut evaluated peri stimulus time histogram triggered presynaptic spike 
systematic experiments lines example mail address gerstner ep ch gerstner 
neural networks see front matter elsevier science rights reserved 
pii neural networks www elsevier com locate performed powers binder continuation earlier models experiments gustafsson kirkwood sears moore segundo 
second question addressed information theoretic measurements bialek de van richmond simplest form reverse correlation measurements de boer 
reverse correlation approach neuron stimulated time dependent stimulus di 
time output spike occurs time course di just ring time recorded 
averaging ring times yields typical input ki rev reverse correlation function rev de ned spike triggered average fig 

linear rate model output spikes generated inhomogeneous poisson process rate di ds known de boer reverse correlation function determined lter auto correlation di input see appendix review argument 
particular white noise input di rev vout spiking neurons form reverse correlation function relation elementary model parameters membrane time constant remained unclear 
apart occasional simulation results systematic study undertaken 
oddly progress theory population dynamics abbott van vreeswijk amit brunel brunel hakim gerstner gerstner van hemmen knight knight sirovich allows calculate coding properties single neurons pawelzik tsodyks brunel chance abbott herrmann gerstner see knight 
fact typical behavior single neuron identical population independent neurons coupling 
organized follows 
brief discussion dynamics single spiking neuron section review section population equations describe dynamics pool neurons 
linearization population equations allows analytically calculate reverse correlation function case input gerstner neural networks fig 

neuron driven noisy background input receives time extra input spike 
extra input trigger output spike 
scenarios top noisy input output spike closer mean membrane potential thick solid line threshold dashed horizontal line 
ring probability increases postsynaptic potential caused input pulse arrow bottom noise membrane potential reach threshold rst time rising phase postsynaptic potential 
fig 

reverse correlation technique schematic 
stimulus top trace caused spike train shown immediately 
time course stimulus just spikes dashed boxes averaged yield typical time course ki bottom 
low amplitude uctuations di 
reverse cross correlations topic section 
discussion section indicate correlation function enters formalism spike time dependent hebbian learning 
formal mathematical arguments moved appendices 
spike response model section review spike response model srm specify particular somewhat simpli ed version 

general framework immediately action potential membrane potential neuron follows cases stereotyped trajectory 
srm trajectory described function moment spike triggered 
form function chosen reproduce closely possible time course action potential 
short current pulse applied immediately action potential membrane potential deviate slightly standard time course 
difference actual time course time course described response kernel ds note response kernel depends time spike 
order emphasize dependence introduce refractory variable rewrite eq 
form ur ds spike occurred long time back past stimulation neuron rest 
case response small current pulse described lim typically time course characterized passive membrane time constant milliseconds action potential response current pulse quite different sodium potassium channels open normally closed rest 
dependence refractory variable takes care effect kistler gerstner van 
noiseless model neuron spikes generated threshold process resets refractory variable eq 
graphically speaking simply add paste action potential standard shape membrane potential reaches threshold time noise induced adding stochastic component input current 
stochastic contribution noise motivated stochastic spike arrival 
usually noise taken white ki noise noise 
call diffusive noise model 
noisy input generates distribution membrane potentials standard deviation measured experiments pare 
noise model far reality suffers disadvantage renders analytical calculation inter spike interval distributions dif cult 
convenient albeit somewhat realistic introduce noise replacing deterministic threshold noisy threshold 
precisely neuron may re time step dt probability membrane potential reached threshold hazard ring depends momentary distance membrane potential threshold possibly slope du dt call escape rate 
suitable function vanish increase rapidly turns gerstner neural networks fig 

spike response model 
neuron red vertical line passes phase refractoriness described kernel exp ms solid line 
presynaptic current pulse arrow causes response exp ms membrane potential sum refractory kernel total effect input current dashed line 
inter spike interval distribution piecewise linear escape rate 
neuron stimulated constant current adjusted mean interval ksl sp ds ms addition require rate vanishes rst milliseconds correspond duration spike 
standard integrate re neurons diffusive noise model introduced replaced high degree accuracy escape rate form herrmann gerstner gerstner su erfc normalized gaussian standard deviation vanishing mean erfc complementary error function parameter 
integrate re model variance membrane potential directly related usually known variance noise current fact free parameter escape rate diffusive noise model 
optimization large ensemble periodic aperiodic stimuli yields opt private communication 
note xed escape rate increases linearly major advantage escape rate models fact statistical quantities interval distribution calculated analytically 
fact choice escape rate probability neuron res spike time spike zt pi tu rr exp rr dt cf 
eq 

constant input get stationary interval distribution tu arbitrary time dependent input call tu input dependent interval distribution 
eq 
generalization standard renewal theory cox moore case time dependent input 

speci model framework noisy srm de ned eqs 

shown optimal choice kernels srm correctly predict ring times hodgkin huxley model time dependent input kistler 
srm offer framework general capture essential aspects neuronal dynamics 
keep arguments transparent focus simpler model framework eq 
take exponential kernels exp exp 
heaviside step function cf 
fig 

eq 
form action potential reduced dirac function simply marks ring time spike 
heaviside function eq 
assures membrane potential trajectory restarts spike initial condition lim 
speci choice parameters ms ms cf 
fig 

escape rate take piecewise linear function value corresponds medium noise level cf 
fig 

note obtain standard integrate re neuron special case 
fact derivative eq 
exponential kernels common time constant yields spikes dt ring membrane potential reset integration restarts value 
ring occurs immediately crosses threshold 
words limit tm recover noise free integrate re neuron 
hand choice tm allows separate time scale refractoriness time scale set membrane time constant possible case standard integrate re model 

population equations studying single neuron averaging long experiment trials measure reverse correlations consider population independent neurons study behavior single short trial 
denote spike train neuron sj tj tj ring times neuron quantity interested gerstner neural networks population activity lim dt dt zt dt sj dt tj number spikes occur population neurons time window dt divided number neurons length window 
population activity units rate called population rate space rate ger 
order get rst intuitive understanding relation population activity single neuron dynamics consider population stimulated stimulating pulse duration say ms neurons population happen close threshold moment input switching put threshold stimulation emit action potential 
neurons refractory period close rest stay quiescent 
single neuron level response stimulus completely different depending internal state neuron 
calculating population activity average internal state way repetition stimulus random intervals 
section review population dynamics spiking neurons derive population equation form gerstner gerstner van hemmen zt tu tu input dependent interval distribution introduced eq 

particular discuss relation integral equation membrane potential density approach abbott van vreeswijk brunel hakim 

review density methods turn srm short detour start known integrate re model cf 
eq 

state individual integrate re neurons fully characterized membrane potential state large population integrate re neurons described membrane potential density 
normalization rq du du probability randomly chosen neuron time membrane potential 
dynamics membrane potential density expressed continuity equation abbott van vreeswijk brunel hakim ux voltage coordinate population activity 
term eq 
describes reset ur ring 
neurons stochastic input power velocity ow 
second term eq 
arises due noise component called diffusion term 
population activity ux threshold cf 
fig 

threshold acts absorbing boundary stationary input eqs 
solved analytically brunel hakim riccardi arbitrary timedependent input integrated numerically 
ends discussion integrate re neurons diffusive noise 
return neurons srm type 
interval state srm neuron characterized time output spike 
introduce refractory density normalization dr rr dr probability randomly chosen neuron time refractory variable 
analogy eq 
continuity equation srm neurons gerstner van hemmen rr gerstner neural networks fig 

state transitions discretized implementation membrane potential density equation integrate re neurons stimulated constant current diffusive noise 
ux drift drives membrane potential ri stochastic spike arrival diffusive noise leads ux diff upwards excitation downwards inhibition 
ux threshold activity reset potential schematic 
population dynamics srm neurons escape noise 
top membrane potential neuron red spike membrane potential trajectory ends neuron res 
instantaneous ring rate 
middle ow constant speed axis 
trajectory refractory variable ends neuron res restarts immediately 
bottom discretized state diagram activity consists rings neurons different refractory variables activity 
ux axis velocity refractory variable constant equal 
term eq 
describes reset refractory variable 
note contrast diffusive noise escape noise enter ux equation directly sink term right hand side eq 

magnitude sink calculated escape rate ur eq 

population activity dr neurons refractory variable contribute rate activity 
schematic graph refractory dynamics fig 

show appendix integrate re neurons escape noise similarly noiseless neurons continuity equation membrane potential density continuity equation refractory density 
fact transition eq 
eq 
simple coordinate transformation 
advantage formulation refractory densities partial differential equation solved analytically 
ux simple form eq 
may switch moving coordinate frame 
new frame partial differential equation reduced ordinary differential equation integrated cf 
appendix result gerstner van hemmen zt zt rt exp rt dt form population equation input dependent interval distribution eq 

correct normalization population activity follows eq 
zt 
linearization zt exp rt dt subsection linearize population equation constant activity level 
activity result stimulation constant current due spontaneous activity neurons 
assume addition bias current apply time dependent input di 
population activity respond change da da linearization population equation yields gerstner zt da da dt di rst term right hand side eq 
describes effect previous perturbations da past 
perturbations occurred interspike interval earlier reappear time smoothed interval distribution 
perturbations past rst term vanishes 
second term eq 
linear lter describes immediate effect input variations di 
aspects important understanding lter properties generated second term eq 

firstly integral dh di ds interpreted contribution membrane potential caused input di 
call dh input potential 
secondly input potential convolved lter 
escape rates escape rates depend voltage slope lter gerstner zx dj dj exp zs dj membrane potential trajectory neuron constant stimulus 
see fig 
high noise lter exhibits low pass characteristics lter extends broad time window averaging low noise sharper 
limit noise approaches function 
thirdly eq 
combines integral lter temporal derivative 
high noise derivative cancels convolution low pass lter gerstner neural networks fig 

filter srm neuron exponential kernels piecewise linear escape rate noise level solid line dotted line long dashed line 
bias current mean interval ms mean ring rate hz 
parameters membrane time constant ms refractory time constant ms immediate response da change input proportional input potential high noise da dh di ds low noise immediate response proportional derivative input potential low noise da dh di ds dt dt advantage analytical expressions study extreme cases intermediate noise levels 
illustration section determine reverse crosscorrelation functions 

results section apply linearized population equation problem neuronal coding calculate reverse cross correlation functions 
fourier transform eq 
yields iv lter iv inverse fourier transform eq 
yields di ds population activity stimulation constant bias current 
lter ivs dv eq 
form linear rate model cf 
eq 

repeat arguments appendix show rev central point approach lter predicted eq 
shape interval distribution response kernel lter 
eqs 
establish relation neuronal parameters reverse correlation function rev 

reverse correlations consider srm neuron de ned section 
response kernels exponential kernels time constant ms kernel ms refractory kernel neuron driven current di bias current adjusted neuron red mean rate hz 
noise current generated procedure 
time step ms apply probability input pulse amplitude input characteristics 
estimate reverse correlation function build histogram average input ki preceding spike see fig 
main characteristics reverse correlation func gerstner neural networks fig 

reverse correlations 
srm neuron stimulated constant bias current plus stochastic input current 
time output spike triggered time course input current recorded 
average input ki function averaged output spikes 
averaged spikes 
simulation result compared time reversed linear lter predicted theory smooth line 
noise model linear escape rate 
tion visible spikes 
average spikes time course cleaner reproduces high degree accuracy time course time reversed lter predicted theory 
oscillation period ms re ects intrinsic ring period neuron 
shown clearly fig 
bias current changed mean interval shorter ksl ms longer ksl ms 
oscillations reverse correlation lter change accordingly 
increase noise level suppresses oscillations cf 
fig 


cross correlations preceding subsection input di random current white noise characteristics cf 
eq 

subsection focus scenario somewhat closer real synaptic input 
keep things simple model presynaptic spike arrival current injection conductance change 
precisely assume presynaptic spike arrives time generates exponential current pulse syn tin exp 
heaviside step function 
postsynaptic fig 

reverse correlations interval distribution neuron fig 
bias current changed mean interval dotted line solid line ms long dashed line 
linear escape rate 
potential psp generated pulse syn ds suppose study neuron spontaneously active low rate 
presynaptic spike arrives evokes psp 
depending internal state neuron extra psp may may suf cient drive membrane potential threshold 
intuitively cross correlation function cross tut describes probability generating output spike input 
intuition precise take population approach 
neurons population ring spontaneously rate 
time neurons receive presynaptic input spike generates modulation da population activity 
change neuronal ring rate caused presynaptic input spike cross tut da 
linearized population equations estimate cross correlation cross tut da zt da dt dx interval distribution spontaneous activity spontaneous rate 
eqs 
conclude main peak cross gerstner neural networks fig 

reverse correlations interval distribution neuron fig 
noise level changed solid line dotted line long dashed line 
correlation cross sut high noise ds low noise high noise cross correlation proportional psp low noise proportional derivative abeles gustafsson herrmann gerstner kirkwood sears moore 
intermediate noise levels calculate cross tion cross sut exp ds result shown fig 

high noise time course cross correlation comparable psp cf fig 

low noise sharp initial rise followed trough second peak inter spike interval 
pattern dominated oscillations fig 


discussion 
correlations spike time dependent plasticity correlations pre postsynaptic neurons fig 

cross correlations 
input consists synaptic current pulse time constant syn ms neuron model fig 
noise levels solid line dotted line long dashed line 
medium low noise cross correlations exhibit oscillations intrinsic ring period ms case high noise solid line cross correlation similar time course postsynaptic potential dotted line 
postsynaptic potential scaled approximately amplitude cross eminent importance synaptic plasticity 
standard hebbian learning weight wij presynaptic neuron postsynaptic neuron changes neurons active time 
hebb original formulation slightly precise explicit causal relation pre ring 
states change occur presynaptic neuron contributes ring postsynaptic hebb 
learning occur cross correlations pre postsynaptic activity 
generally call plasticity rule hebbian 
depends locally available information pre postsynaptic spike times current weight value ij 
depends correlations pre postsynaptic rings plasticity due pre postsynaptic activity 
example hebb type learning rule gerstner kempter van hemmen wagner kempter gerstner van hemmen kistler van hemmen roberts bell tsodyks song miller abbott dt wij wij wij wij corr wij zt dt corr wij zt dt tj pre tj postsynaptic spike train 
contributions describe change spikes presynaptic spikes postsynaptic spikes 
called non hebbian terms describe adaptation processes terms may vanish included eq 
sake generality 
parameters corr may depend current weight value wij 
correlations pre postsynaptic spikes taken care learning window tj gerstner gerstner ritz van hemmen 
learning window phases depending relative timing pre postsynaptic neurons bell han sugawara bi poo ga thompson lu zhang tao holt harris poo 
phase learning windows useful detect temporal variations neuronal ring patterns postulated theoretical grounds gerstner 
see clearly correlations enter learning equation assume learning slow compared typical inter spike intervals 
expected evolution gerstner neural networks weights slow time scale learning dt ij ks ks ds corr ks term ks identi ed presynaptic rate similarly ks postsynaptic rate 
integral learning window driven correlations pre postsynaptic spikes 
presynaptic ring described poisson process constant rate correlations separated correlations pre postsynaptic rates additional spike spike correlations 
nal result kempter dt wij corr ds corr cross ij sut ds cross correlation cross ij sut enters expected learning equation 
previously cross correlation function cross sut evaluated particularly simple stochastically ring neuron model kempter 
simple model cross correlations follow time course postsynaptic potential 
results allow analysis hebbian plasticity extended realistic spiking neuron models 
seen cross correlation linearly ltered version postsynaptic potential time course cross correlation function depends noise level mean ring rate neuron 

extensions calculated reverse cross correlations spiking neuron models 
framework srm introduced section general illustrated results far speci somewhat simpli ed neuron model piecewise linear escape rate 
extensions come directions 
redo analysis interesting realizations srm herrmann gerstner kistler 
second kernels tted real neurons try explain experimental cross correlation reverse correlation measurements 
third far analysis restricted independent neurons 
results extended cross correlations connected networks 
sake notational simplicity suppress wij dependence parameters 
appendix reverse correlations linear lter appendix want show reverse correlation function rev proportional lter linear rate model di ds mean output rate di part input 
eq 
describes relation known deterministic input di rate 
adopt statistical point view assume input di drawn statistical ensemble stimuli mean 
angular brackets denote averaging input ensemble equivalently nite input sequence 
interested correlation vi lim zt di dt kv di input di activity da 
linear rate equation nd vi di ds 
correlation function depends lter autocorrelation di input ensemble 
sake simplicity assume input consists white noise input autocorrelation di case eq 
reduces vi correlation function proportional lter 
order relate correlation function reverse correlation rev think rate intensity inhomogeneous poisson process generates spike events rate estimated average large number repetitions experiment large number independent neurons ti correlation function limt di ti ki rev second equality sign expected gerstner neural networks number spike events interval length mean rate 
equality follows de nition reverse correlation function cf 
eq 

combination eqs 
yields rev vout reverse correlation function proportional linear lter section calculate lter spiking neurons 
appendix 
integrating partial differential equation appendix integrate eq 
describes dynamics refractory densities 
neurons red time form group moves constant speed cf 
fig 

solve eq 
turn frame moves group 
formally replace variable de ne new density temporal derivative dr dt dr dt 
insert eq 
right hand side eq 

result rt partial differential equation transformed ordinary differential equation 
solution eq 
starting integration zt exp rt dt initial condition integration 
interpret eq 

variable fact ring time evaluating eq 
limit yields zt exp rt dt tq follows term eq 

hand eq 
insert eq 
eq 
nd zt zt rt exp rt dt population equation escape noise 
insert eq 
normalization condition variable rt dt arrive normalization equation activity zt zt exp rt dt eq 
starting point theory population dynamics gerstner 
fact eq 
derived eq 
temporal derivative 
appendix 
membrane potential densities refractory densities appendix study population integrate re neurons escape noise 
want show membrane potential trajectory integrate re model exp zt exp dt de ne transformation voltage refractory variables turns nal equations simpler take new variable consider transformation start calculate derivatives eq 

derivative respect yields expected integrate re neurons 
derivative respect ri exp exp function de ned eq 

densities variable denoted 
density normalized coordinate transformation respect du yields taken function cf 
eq 

want show differential equation density derived eq 
rt equivalent continuity equation membrane potential densities 
insert eq 
gerstner neural networks eq 
nd rpf integrate re neuron furthermore ri 
divide eq 
rewrite eq 
form ur abbott van vreeswijk 
asynchronous states network pulse coupled oscillators 
phys 
rev 
abeles 
cambridge cambridge university press 
amit brunel 
model spontaneous activity local delay activity delay periods cerebral cortex 
cerebral cortex 
bell han sugawara 
synaptic plasticity cerebellum structure depends temporal order 
nature 
berry 
refractoriness neural precision 
neurosci 
pawelzik tsodyks 
noise signal neuronal populations submitted 
bi poo 
synaptic modi cations hippocampal neurons dependence spike timing synaptic strength postsynaptic cell type 
neurosci 
bialek rieke de van 
reading neural code 
science 
brunel hakim 
fast global oscillations networks integrate re neurons low ring rates 
neural computation 
brunel chance abbott 
effects synaptic noise ltering frequency response spiking neurons 
physical review letters 
cox 
renewal theory london methuen 
ga thompson 
long term synaptic plasticity pairs individual ca pyramidal cells rat hippocampal slice cultures 
physiol 
de boer 
triggered correlation 
ieee trans 
biomedical engineering 
de van strong bialek 
reproducibility variability neural spike trains 
science 
pare 
impact network activity integrative properties neocortical pyramidal neurons vivo 
journal neurophysiology 
gustafsson 
relation shapes postsynaptic potentials changes ring probability cat 
physiol 

collective behaviour networks linear vlsi integrate re neurons 
neural computation 
gerstner 
time structure activity neural network models 
phys 
rev 
gerstner 
population dynamics spiking neurons fast transients asynchronous states locking 
neural computation 
gerstner van hemmen 
associative memory network spiking neurons 
network 
gerstner van hemmen 
coding information processing neural networks 
domany van hemmen schulten models neural networks ii pp 

new york springer verlag 
gerstner kempter van hemmen wagner 
neuronal learning rule sub millisecond temporal coding 
nature 
gerstner ritz van hemmen 
spikes 
hebbian learning retrieval time resolved excitation patterns 
biol 
cybern 
hebb 
organization behavior new york wiley 
herrmann gerstner 
understanding response synaptic input 
icann arti cial neural networks vol 
pp 

iee conference publication 
herrmann gerstner 
noise response current transients 
computational neuroscience press 
herrmann gerstner 
noise current transients 
computational neuroscience press 
kempter gerstner van hemmen 
hebbian learning spiking neurons 
phys 
rev 
kirkwood sears 
synaptic connexions revealed average common excitation potential 
physiol 
kistler van hemmen 
modeling synaptic plasticity conjunction timing pre postsynaptic potentials 
neural comput 
kistler gerstner van hemmen 
reduction hodgkin huxley equations single variable threshold model 
neural comput 
hertz richmond 
decoding cortical neuronal signals network models information estimation spatial tuning 
computational neuroscience 
knight 
dynamics encoding population neurons 
gen physiology 
knight 
relationship ring rate single neuron level activity population neurons 
gen physiology 

cross correlation functions neuronal model 
biophys 

ko nig engel singer 
integrator coincidence detector 
role cortical neuron revisited 
tins 
ger 
model fast analog computation unreliable synapses 
neural computation 
lu 
regulation synaptic ef cacy coincidence postsynaptic ap epsp 
science 
gerstner neural networks moore segundo 
statistical signs synaptic interaction neurons 
biophys 
journal 

population density approach facilitates large scale modeling neural networks analysis application orientation tuning 
computational neuroscience 
knight sirovich 
simulation large population neurons 
computational neuroscience 
richmond 
temporal encoding twodimensional patterns single units primate inferior temporal cortex 

information theoretic analysis 
neurophysiol 
moore 
neuronal spike trains stochastic point processes 
single spike train 
biophys 

gerstner 
noise integrate re models stochastic input escape rates 
neural computation 
powers binder 
functional identi cation input output transforms cat 
physiology 
riccardi 
diffusion processes related topics biology berlin springer verlag 
rieke de van bialek 
spikes exploring neural code cambridge ma mit press 
roberts bell 
computational consequence temporally asymmetric learning rules sensory image cancellation 
computational neuroscience 
miller 
assessing performance neural encoding models presence noise 
computational neuroscience 
tsodyks 
algorithm modifying neuro transmitter release probability pre postsynaptic spike timing 
neural computation 

simple codes versus ef cient codes 
current opinion neurobiology 
song miller abbott 
competitive hebbian learning spike time dependent synaptic plasticity 
nature neuroscience 
rolls treves 
information responses single neurons primate visual cortex 
neurophysiol 
zhang tao holt harris poo 

critical window cooperation competition developing synapses 
nature 
