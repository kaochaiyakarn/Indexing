latent semantic indexing lsi trec report susan dumais bellcore south st morristown nj std bellcore com 
reports developments latent semantic indexing lsi retrieval method trec 
lsi uses reduced dimension vector space represent words documents 
important aspect representation association terms automatically captured explicitly represented improve retrieval 
lsi trec routing adhoc tasks 
routing tasks lsi space constructed training documents 
compared profiles constructed just topic words training profiles constructed average relevant documents topic words 
surprisingly centroid relevant documents better topic words 
simple feedback method quite compared routing performance systems 
various combinations information topic words relevant documents provide small additional improvements performance 
adhoc task compared lsi keyword vector matching dimension reduction 
small advantages obtained lsi long trec topic statements 

overview latent semantic indexing latent semantic indexing lsi variant vector retrieval method salton mcgill dependencies terms explicitly taken account representation exploited retrieval 
done simultaneously modeling interrelationships terms documents 
assume underlying latent structure pattern word usage documents statistical techniques estimate latent structure 
description terms documents user queries underlying latent semantic structure surface level word choice representing retrieving information 
advantage lsi representation query similar document share words 
latent semantic indexing lsi uses singular value decomposition svd technique closely related eigenvector decomposition factor analysis cullum model associative relationships 
large term document matrix decomposed set typically orthogonal factors original matrix approximated linear combination 
representing documents queries directly sets independent words lsi represents continuous values orthogonal indexing dimensions 
number factors dimensions smaller number unique terms words independent 
example terms similar contexts documents similar vectors lsi representation 
svd technique capture structure better simple document document correlations clusters 
lsi partially overcomes deficiencies assuming independence words provides way dealing synonymy automatically need manually constructed thesaurus 
lsi completely automatic method 
appendix provides brief overview mathematics underlying lsi svd method 
deerwester furnas additional mathematical details examples 
interpret analysis performed svd geometrically 
result svd vector representing location term document dimensional lsi representation 
location term vectors reflects correlations usage documents 
space cosine dot product vectors corresponds estimated similarity 
retrieval typically proceeds terms query identify point space documents ranked similarity query 
term document vectors represented space similarities combination terms documents easily obtained 
lsi method applied standard ir collections favorable results 
tokenization term weightings lsi method equaled outperformed standard vector methods variants case better cases deerwester 
standard vector method differential term weighting relevance feedback improve lsi performance substantially dumais 
lsi applied experiments relevance feedback dumais schmitt filtering applications foltz dumais 
system described gallant 
similar lsi 
systems model relationships terms looking similarity contexts words exploit associations improve retrieval 
systems reduced dimension vector representation differ term document query vectors formed caid dumais gallant press 
number groups developed corpus association similarity thesauri automatic query expansion jing croft phrasefinder strzalkowski trec conceptual hierarchy qui frei similarity thesaurus 
lsi idea systems discover exploit corpus specific inter item associations improve retrieval 

lsi trec previous trec conferences opportunity scale tools explore lsi dimension reduction ideas rich corpus word usage 
pleased able existing lsi svd tools large trec collection 
see dumais details 
able compute largest singular triples docs words matrices numerical convergence problems standard sparc workstation 
limits size matrices handle divided documents separate subcollections trec computed svd sample documents trec 
trec sampling approach tried year 
pre processing smart system pre processing documents queries 
markups delimiters removed hand indexed entries removed wsj ziff collections 
upper case characters translated lower case punctuation removed white spaces delimit terms 
smart list words smart stemmer modified lovins algorithm modification strip words endings 
phrases proper noun identification word sense disambiguation thesaurus syntactic semantic parsing spelling checking correction complex controlled vocabulary manual indexing 
result pre processing thought term document matrix cell entry indicates frequency term appears document 
entries term document matrix transformed ltc weighting 
ltc weighting takes log individual cell entries multiplies entry term row idf weight term normalizes document col length 
began processing documents cd cd 
minimal pre processing described unique tokens unique stems non zero entries term document matrix 
documents contained term 
decrease matrix size thought handle removed tokens occurring fewer documents 
resulted unique tokens unique stemmed words non zero entries 
resulting document term matrix starting point results reported 
ltc weights computed matrix 

smart system version available smart group cornell university 
chris buckley especially generous consultations get software somewhat non standard things 
svd analysis ltc matrix described input svd algorithm 
svd program takes ltc transformed term document matrix input calculates best reduced dimension approximation matrix 
result svd analysis reduced dimension vector term document vector singular values 
number dimensions experiments 
representation retrieval 
cosine term term document document term document vectors measure similarity 
runs submitted sample documents matrix 
appropriate documents sampled folded reduced dimension lsi space 
cases weights matrix recompute samples 
routing experiments subset documents relevance judgements 
unique documents relevance judgements 
relevant non relevant documents 
svd analysis computed relevant document term subset ltc matrix containing non zero cells 
reduced dimension approximation took hrs cpu time compute sparc workstation 
dimension representation matching profiles new documents routing experiments 
adhoc experiments took random sample documents 
reduced dimension svd approximation computed document term matrix non zeros 
dimension approximation computed retrieval 
documents included sample folded dimension lsi space adhoc queries compared documents 
folded documents located weighted vector sum constituent terms 
vector new document computed term vectors terms document 
documents matrix derived vector corresponds exactly document vector svd 
new terms added analogous fashion 
vector new terms computed document vectors documents term appears 
adding documents terms manner assume derived semantic space fixed new items fit 
general space obtain new svd calculated original new documents 
previous experiments sampling scaling documents folding remaining documents resulted performance indistinguishable observed documents scaled 
trec scaling total corpus 
queries retrieval queries automatically processed way documents 
queries derived topic statement began full text topic topic fields stripped sgml field identifiers 
feedback queries full text relevant documents 
query vector new document case routing indicating frequency term appears query automatically generated topic 
query transformed smart ltc weighting 
note boolean connectors proximity operators query formulation 
implicit connectives ordinary vector methods fall ors ands additional kind fuzziness introduced dimension reduced association matrix representation terms documents 
terms query identify vector lsi space recall term vector representation space 
query simply located weighted vector sum constituent term vectors 
cosine query vector document vector computed documents ranked decreasing order similarity query 
fewer dimensions standard vector retrieval entries non zero inverted indices useful 
means query compared document time consuming large databases 
straightforward split matching machines parallel hardware documents independent 
important note step lsi analysis completely automatic involved human intervention 
documents automatically processed derive term document matrix 
matrix decomposed svd software resulting reduced dimension representation retrieval 
svd analysis somewhat costly terms time large collections need computed create reduced dimension database 
svd takes minutes sparc matrix time increases hours matrix 
trec routing experiments routing queries created filter profile training topics 
submitted results sets routing queries 
lsir submission judged 
case filter just topic statements treated routing queries adhoc queries 
filter located vector sum terms topic 
call routing topic lsir results 
method training data representing topic adhoc query 
case information relevant documents training set 
filter case derived vector sum centroid relevant documents 
call routing lsir results 
average relevant documents topic range topic topic 
note method topic words 
cooper chen gay trec described method minimal query terms feedback available 
somewhat unusual variant relevance feedback replace combine original topic relevant documents terms appear non relevant documents 
implemented lsir method thought kind massive query expansion groups quite useful trec routing tasks 
recall lsi document located weighted average constituent terms 
lsir routing vector centroid relevant documents centroid terms relevant documents 
topic filters provide extreme baselines compare methods combining information original query feedback relevant documents 
cases filter single vector 
new documents matched filter vector ranked decreasing order similarity 
new documents documents cd automatically processed described section 
important note terms cd cd training collection indexing documents 
new document located weighted vector sum constituent term vectors dimension lsi space just way queries handled 
new documents compared routing filter vectors cosine similarity measure dimensions 
best matching documents filter submitted nist evaluation 
lsir run judged 
results main routing results shown table 
submitted runs lsir lsir differ profile vectors created weighted average words topic statement lsir routing topic weighted average relevant documents training collection cd cd lsir routing 
surprisingly lsir profile vectors take advantage known relevant documents better lsir profile vectors simply topic statement measures performance 
improvement average precision vs 
users get average additional relevant documents top returned lsir method filtering vs 
suspect noticeable improvement users provide starting place feedback methods 
note difference lsir lsir probably overestimate benefits lsir lsir documents judged top lsir documents judged 
performed routing experiment trec amazingly similar results 
trec lsir better lsir vs compared systems lsir better median topics 
lsi method representing routing profile information centroid known relevant documents appears quite robust useful 
noted centroid method related massive query expansion method successfully buckley cooper relevance associated stems 
document represented vector lsi space implementation quite efficient involve explicit term expansion done creating lsi representation 
table trec lsi routing results lsir lsir best topic rel docs best sum sum sum rel ret prec prec avg prec prec lsi median lsi table lsi routing results 
comparison topic words lsir vs relevant documents lsir routing filters 
indicates judged run 
compared trec systems lsi quite especially routing lsir run run discussed 
case lsir lsi median performance pr topics best score topics 
lsir results especially low recall 
lsi performs average routing topic lsir run information training set forming routing vectors case 
examined best vectors 
query chose vector depending best average precision query 
fourteen topics represented lsir vector remaining lsir vector 
results shown third column table labeled best 
average precision best better lsir 
scores median performance topics best topics 
lsir lsir runs provide baselines various combinations query information relevant document information measured 
tried simple combination lsir lsir profile vectors components equal weight 
took sum lsir lsir profile vectors topic new profile vector 
results analysis shown fourth column table labeled 
combination somewhat better centroid relevant documents total number relevant documents returned average precision 
returned fewer documents topic documents returned method judged relevance suspect performance improved bit 
examined combinations varying contributions individual vectors 
combination average 
results shown columns table 
methods combines query vector vector representing centroid relevant documents kind relevance feedback 
unusual variant relevance feedback words relevant documents words nonrelevant documents weighted query terms re weighted 
interestingly method produces improvements comparable obtained buckley 
trec traditional relevance feedback methods 
average precision method better lsir topic words vs somewhat better improvement reported buckley 
trec richest routing query expansion method vs 
combination methods described query vector combinations 
cases filter single vector 
started look combination methods multiple filters query results report time 
method involves data fusion results lsir lsir matches combined various ways 
related method involves query splitting 
previously conducted experiments relevance density method information separate vectors query apply trec 
see kane foltz dumais discussion multi point interest profiles lsi 
look detail successes failures lsi system 
lsi quite queries japanese regulation insider trading japanese measures new space satellite applications economic impact international terrorism anti smoking actions government iranian support hostage takers political impact quite poorly find innovative companies impact immigration law industrial entirely clear distinguishes topics 
examine misses false alarms detail 
preliminary examination topics suggests lack specificity main reason false alarms highly ranked irrelevant documents 
surprising lsi designed recall enhancing method added precision enhancing tools easy 
trec adhoc experiments submitted sets adhoc queries mf mw 
mw run judged 
svd analysis runs 
svd random sample documents cd cd 
svd computed sample remaining documents folded 
mf run baseline 
mw run omits documents fewer characters returned list 
results runs shown columns table 
difference runs large 
omitting short documents hurt performance improved substantially topics 
terms absolute levels performance runs little average 
performance deviate median 
compared lsi runs smart run exactly pre processing 
run term document matrix lsi begins dimension reduction 
results shown third column table 
advantage lsi table trec adhoc results mf mw smart rel ret avg prec pr pr prec median table lsi adhoc results 
indicates judged run 
traditional vector matching queries 
smaller advantages observed test collections 
previously noted dumais jing croft lu trec voorhees trec topics quite long smaller advantages query expansion methods expected 
average trec query content words 
trec results expect larger advantages keyword matching queries shorter real adhoc queries typically 
trec trec smart runs worse reported buckley fuhr voorhees 
slightly different pre processing options non optimal weightings ltc ltn documents phrases words occurring documents comparability lsi analyses 
trec example average precision worse voorhees baseline lnc document weights worse baseline lnc phrases 
believe improve absolute level performance conditions phrases selecting optimal document weights 
addition lsi adhoc analysis dimensions probably performance large diverse corpora see section 

improving performance improving performance speed lsi svd system built research prototype investigate different information retrieval interface issues 
retrieval efficiency central concern wanted assess method worked worrying efficiency initial applications lsi involved smaller databases documents 
effort went re designing tools efficiently large trec databases 
svd svd algorithms get faster time 
sparse iterative algorithm times faster method initially berry 
usual speed memory tradeoffs svd algorithms time probably decreased different algorithm memory 
parallel algorithms help little probably factor 
calculations done double precision time memory decreased single precision computations 
preliminary experiments smaller ir test collections suggest decrease precision lead numerical problems svd algorithm 
important note preprocessing svd analyses time costs relatively stable domains 
retrieval lsi retrieval query vectors compared document 
fewer dimensions standard vector retrieval entries non zero inverted indices useful 
process linear number documents know practical efficient algorithms finding nearest neighbors dimension vector spaces 
methods kd trees dimensions helpful dimensions 
exploring methods speed retrieval 
document clustering reduce number comparisons accuracy probably suffer 
explored heuristics clustering particularly effective high levels accuracy maintained 
hnc system gallant uses approach reduce number alternative documents matched 
initial keyword match eliminate documents calculate reduced dimension vector scores subset documents meeting initial keyword restriction 
may reasonable alternative long queries trec believe recall reduced substantially short queries 
addition data structures need maintained 
query matching improved tremendously simply machine parallel hardware 
pe maspar attempt optimize data storage sorting decreased time required match dimensional query vector document vectors sort factor 
improving performance accuracy begun look large number parametric variations improve lsi performance 
number dimensions important variable lsi retrieval number dimensions reduced dimension space 
previous experiments performance improves number dimensions increased dimensions decreases slowly level observed standard vector method dumais 
examined trec routing performance fewer dimensions reported consistently worse performance total number relevant documents returned average precision measures dimensions dimensions dimensions easily improve performance simply increasing number dimensions 
true adhoc runs dimensions improved substantially increasing number dimensions lsi space 
term weighting need experiment different term weighting methods 
routing adhoc experiments smart ltc weighting documents queries ltc ltc 
buckley alternative weightings lnc documents lnc ltc effective trec standard vector method 
suspect lsi benefit optimal weighting 
document sampling size svd compute standard workstations limited 
computing svd matrix takes hours cpu time meg memory 
larger svd analyses just practical time 
approaches overcome limitation trec divided collection subcollections trec trec computed svd sample documents 
routing task sample chosen training data worked quite 
adhoc task chose small random sample successful 
sample represents documents may sufficient accurately represent variability topics encountered adhoc queries 
try larger samples 
retrieval failures order better understand retrieval performance examine kinds retrieval failures false alarms misses 
false alarms documents lsi ranks highly judged irrelevant 
misses relevant documents top returned lsi 
examined retrieval failures topics far 
false alarms 
common reason false alarms lack specificity 
highly ranked irrelevant articles generally topic interest meet restrictions described topic statement 
topics required kind detailed processing fact finding lsi system designed address 
precision lsi matching increased standard techniques proper noun identification syntactic statistically derived phrases pass approach involving standard initial global matching followed detailed analysis top documents 
try methods focus general purpose completely automatic methods modified new domain query restriction 
reason false alarms appears result inappropriate query pre processing 
negation best example problem 
routing queries adhoc queries contain negation topic statement 

fact include negated terms query 
logical connectives example inappropriate query processing 
lsi handle boolean combinations words returned articles covering subset anded topics 
aspect query appears dominate typically described terms high weights 
limiting contribution term similarity score help problem 
trec routing tasks additional sources false alarms minimal real routing applications 
lsi returned documents topic judged relevant 
real routing application get immediate feedback particular topic interest presumably subsequent similar documents returned 
addition topics appears lack correspondence judgements training test documents 
documents appear topic judged relevant training set relevant test set 
may result different people making relevance judgements points time may simply reflect slightly changing criteria time 
misses 
analysis examine random subset relevant articles top returned lsi 
relevant articles groups fairly highly ranked lsi notable failures seen persistent readers 
misses represent articles primarily different topic query contained small section relevant query 
documents located average terms lsi space generally near dominant theme desirable feature lsi representation 
kind local matching divisions documents smaller sections help identifying central themes documents 
especially easy cases documents tagged indicate separate news 
misses attributable poor text query pre processing tokenization 
examples 
ideas illustrated concretely considering specific examples retrieval failures 
examined routing topics lsi lsir run poorly relative trec groups average precision measure 
topics relevant documents groups 
topics find relevant documents precision poor 
topics retrieval failures poor precision contribute poor performance 
topic industrial lsi misses 
false alarms top contributes poor precision 
false alarms appear relevant eye distributing proprietary documents directly industrial 
computer security information privacy hacking software involve specific 
counter intelligence government security breaches aimed specific 
missed articles involve insider trading cases lsi performance topic mirrors training documents computer fraud soviet 
topic find innovative companies lsi misses 
topic involves matching specific names 
lsi literal string matching really suffered 
misses involved mentioned article primarily mips stock holder listed chart 
trivial solve particular problem appropriate string matching tools 
topic impact immigration law lsi misses precision poor 
false alarms immigration problems mention immigration act 
lack specificity fairly typical kind lsi failure 
topic impact government regulated grain farming international relations lsi misses 
misses topic generally top user 
false alarms result lack specificity noted previous topic 
irrelevant items near top list tended domestic vs international effects farm regulations farm exports regulation 
able increase likelihood concepts contribute match limiting contribution term similarity 
topic management problems united nations lsi misses precision poor 
topic suffer inconsistent relevance judgements 
lsi false alarms appear quite similar relevant documents training documents failing pay dues inefficiencies budget runs 
addition half relevant documents questionable mind 
just right target 
topic death cancer lsi precision reasonable 
misses come sjm formatted long lists individual articles person 
lsi centroid representation problematic 
easily solved splitting articles multiple topics especially tagged 
top false alarms death cancer specific type cancer mentioned 
research basis preliminary failure analyses exploring precision enhancing methods 
explore additional areas 
separate vs combined scaling separate subcollection trec experiments 
trec trec single scaling small sample cd cd documents 
sampling worked quite believe practically reasons topically coherent collections 
believe result dimensions devoted discriminating objects 
fine grained discriminations computer documents dimensions ziff 
larger analysis fewer dimensions devoted distinguishing computer related topics 
term weights lsi space topically coherent subcollections 
second distributed rapidly changing collections separate analyses may necessary 
time compare sampling results examine issue detail 
centroid query vs separate points interest single vector represent query 
cases vector average terms topic statement cases vector average previously identified relevant documents 
single query vector inappropriate interests facets near lsi space 
developed techniques allow match controllable compromise averaged separate vectors kane 
case routing queries example match new documents previously identified relevant documents separately average 
computational complexity method increased number vectors query splitting cases relevant documents query terms similar 
interactive interfaces lsi evaluations conducted noninteractive system essentially batch mode 
known underlying retrieval matching engine achieve different retrieval success different interfaces 
examine performance real users interactive interfaces 
number interface features help users faster accurate relevance judgements help explicitly reformulate queries 
see dumais schmitt preliminary results query reformulation relevance feedback 
interesting possibility involves returning richer rank ordered list documents users 
example clustering graphical display top documents quite useful 
done preliminary experiments clustered return sets extend trec collections 
general idea provide people useful interactive tools knowledge skills attempting build database representation matching components system 

berry large scale singular value computations 
international journal supercomputer applications 
buckley salton allan effect adding relevance information relevance feedback environment 
proceedings sigir 
buckley salton allan singhal automatic query expansion smart trec 
appear proceedings trec 
caid dumais gallant learned vector space models document retrieval 
appear information processing management 
cooper chen experiments probabilistic retrieval full text documents 
appear proceedings trec 
cullum lanczos algorithms large symmetric eigenvalue computations vol theory chapter real rectangular matrices 
boston 
deerwester dumais landauer furnas harshman indexing latent semantic analysis 
journal society information science 
dumais improving retrieval information external sources 
behavior research methods instruments computers 
dumais lsi meets trec report 
harman ed 
text retrieval conference trec 
nist special publication 
dumais latent semantic indexing lsi trec 
harman ed 
second text retrieval conference trec 
nist special publication 
dumais schmitt iterative searching online database 
proceedings human factors society th annual meeting 
foltz dumais personalized information delivery analysis information filtering methods 
communications acm dec 
furnas deerwester dumais landauer harshman streeter lochbaum information retrieval singular value decomposition model latent semantic structure 
proceedings sigir 
gallant hecht nielson caid qing carleton tipster panel hnc system 
harman ed 
text retrieval conference trec nist special publication 
jing croft association thesaurus information retrieval 
riao conference proceedings 
kane streeter dumais casella relevance density method multi topic queries information retrieval 
proceedings rd symposium interface ed 
lu query expansion reduction impact retrieval effectiveness 
appear proceedings trec 
qiu frei concept query expansion 
proceedings sigir 
salton mcgill modern information retrieval 
mcgraw hill 
strzalkowski 
natural language information retrieval trec report 
appear proceedings trec 
voorhees query expansion relations 
proceedings sigir 
voorhees gupta collection fusion problem 
appear proceedings trec 

appendix latent semantic indexing lsi uses singular value decomposition svd technique closely related eigenvector decomposition factor analysis cullum 
take large term document matrix decompose set typically orthogonal factors original matrix approximated linear combination 
formally rectangular matrix example matrix terms documents decomposed product matrices orthonormal columns diagonal rank called singular value decomposition largest singular values kept corresponding columns matrices rest deleted yielding matrices resulting matrix unique matrix rank closest squares sense idea matrix containing independent linear components captures major associational structure matrix throws noise 
reduced model usually approximate term document association data number dimensions reduced model smaller number unique terms minor differences terminology ignored 
reduced model closeness documents determined pattern term usage documents near regardless precise words describe description depends kind consensus term meanings dampening effects polysemy 
particular means documents share words user query may near consistent major patterns word usage 
term semantic indexing describe method reduced svd representation captures major associative relationships terms documents 
interpret analysis performed svd geometrically 
result svd dimensional vector representing location term document dimensional representation 
location term vectors reflects correlations usage documents 
space cosine dot product vectors corresponds estimated similarity 
term document vectors represented space similarities combination terms documents easily obtained 
retrieval proceeds terms query identify point space documents ranked similarity query 
attempt interpret underlying dimensions factors rotate intuitively meaningful orientation 
analysis require able describe factors verbally merely able represent terms documents queries way escapes unreliability ambiguity redundancy individual terms descriptors 
choosing appropriate number dimensions lsi representation open research question 
ideally want value large fit real structure data small fit sampling error unimportant details 
dimensions method begins approximate standard vector methods loses power represent similarity words 
dimensions discrimination similar words documents 
find performance improves increases decreases dumais 
lsi typically works relatively small compared number unique terms number dimensions shows dimensions fact capturing major portion meaningful structure 
