bioinformatics vol 
pages support vector machine classification validation cancer tissue samples microarray expression data terrence nello cristianini nigel duffy david mich el schummer david haussler department computer science university california santa cruz santa cruz ca usa department engineering mathematics university bristol bristol bs ith uk department molecular biotechnology university washington seattle wa usa received april accepted may motivation dna microarray experiments generating thousands gene expression measurements gather information tissue cell samples regarding gene expression differences useful diagnosing disease 
developed new method analyse kind data support vector machines svms 
analysis consists classification tissue samples exploration data mis labeled questionable tissue results 
results demonstrate method detail samples consisting ovarian cancer tissues normal ovarian tissues normal tissues 
dataset consists expression experiment results tissue 
result computational analysis tissue sample discovered confirmed wrongly labeled 
correction mistake removal outlier perfect classification tissues achieved high confidence 
identify analyse subset genes ovarian dataset expression highly differentiated types tissues 
show robustness svm method previously published datasets types tissues cells analysed 
results comparable previously obtained 
show machine learning methods perform comparably svm datasets 
availability svm software available www 
cs columbia edu svm 
contact booch cse ucsc edu microarray expression experiments allow recording expression levels thousands genes simultaneously 
correspondence addressed 
experiments primarily consist monitoring gene multiple times conditions spellman chu derisi wen roberts alternately evaluating gene single environment different types tissues especially tissues derisi alon golub zhu wang schummer zhang slonim 
type allowed identification functionally related genes due common expression patterns brown eisen wen roberts experiments shown promise classifying tissue types diagnosis identification genes expressions diagnostic indicators golub alon slonim 
order extract information gene expression measurements different methods employed analyse data including svms brown mukherjee clustering methods eisen spellman alon ben dor hastie self organizing maps tamayo golub weighted correlation method golub slonim :10.1.1.41.4971
support vector machines svms supervised machine learning technique shown perform multiple areas biological analysis including evaluating microarray expression data brown detecting remote protein homologies jaakkola recognizing translation initiation sites zien 
aware effort uses svms analyzing expression data mukherjee :10.1.1.41.4971
svms demonstrated ability correctly separate entities appropriate classes identify instances established classification oxford university press svm tissue classification expression data supported data 
expression datasets contain measurements thousands genes proves problematic traditional methods 
svms suited working high dimensional data 
systematic principled method introduced analyses microarray expression data thousands genes tested multiple tissue cell samples 
primary goal proper classification new samples 
training svm samples classified experts testing svm samples seen 
demonstrate svms classify new samples help identification wrongly classified experts 
svms unique classification methods regard show effective 
method demonstrated detail data experiments involving ovarian cancer normal ovarian normal tissues 
able identify tissue sample mislabeled outlier shown results section illustrated 
perfect classification achieved instance performance consistently shown multiple tests considered significant 
experimented method introduced golub focus analysis smaller subset genes appear best diagnostic indicators 
amounts kind dimensionality reduction dataset 
identify particular genes diagnostic classification trying presence cancer hope genes may value investigations disease therapies 
find dimensionality reduction significantly improve classification performance 
reveal genes may interest ovarian cancer 
needs carried identify effective feature selection dimensionality reduction methods kind data 
test generality approach ran experiments leukemia data golub 
patient samples colon tumor data alon tissue samples 
results comparable methods authors papers 
special effort tune method datasets increases confidence approach broad applications analyzing data type 
difficult show diagnostic method significantly better small data sets examined 
conducted full hold cross validation jackknife evaluation classification performance methods tested 
include svm methods variants perceptron algorithm 
single classification technique proven significantly superior experiments performed 
different kernels tried performed nearly equally variations perceptron algorithm shown perform comparably svm tests 
unfortunate typical diagnostic gene expression datasets today involve tissue samples 
datasets available larger numbers samples predict method continue demonstrate performance 
methods years methods developed performing gene expression experiments 
measurements experiments give expression levels genes ests tissue cell samples 
depth discussions techniques see lockhart 
schummer 

datasets experiments consist relatively small number tissue samples expression measurements thousands genes 
previous methods analysis similar datasets start procedure extract relevant features 
learning techniques perform datasets number features large compared number examples 
svms believed exception 
able tests full dataset systematically reduce number features selecting believe relevant 
way show improvement smaller sets indicating contain meaningful genes 
understand method familiarity svms required brief follows 
explain rank features outline svm perform classification error detection 
support vector machines svms cristianini shawe taylor relatively new type learning algorithm originally introduced vapnik workers boser vapnik successively extended number researchers :10.1.1.103.1189
remarkably robust performance respect sparse noisy data making system choice number applications text categorization protein function prediction 
classification separate set binary labeled training data hyper plane maximally distant known maximal margin hyper plane 
cases linear separation possible combination technique kernels automatically realizes non linear mapping feature space 
hyper plane svm feature space corresponds nonlinear decision boundary input space 
th input point realization random vector input point labeled random variable 
mapping input space feature space assume sample labeled data points 
svm learning algorithm finds hyper plane quantity min maximized denotes inner product vector dimensionality held constant real number called margin 
quantity corresponds distance point decision boundary 
multiplied label gives positive value correct classifications negative value incorrect ones 
minimum quantity data positive data linearly separable called margin 
new data point classify label assigned relationship decision boundary corresponding decision function sign 
easy prove cristianini shawe taylor maximal margin hyper plane positive real numbers maximize ij subject decision function equivalently expressed sign 
equation possible see associated training point expresses strength point embedded final decision function 
remarkable property alternative representation subset points associated non zero points called support vectors points lie closest separating hyper plane 
sparseness vector computational learning theoretic consequences 
notice test point quantity negative prediction machine wrong large negative value indicate point regarded algorithm different training data 
matrix ij called kernel matrix particularly important extensions algorithm discussed 
case data linearly separable general functions ij provide non linear decision boundaries 
classical choices polynomial kernels gaussian kernels kernel parameters 
experiments 
presence noise standard maximum margin algorithm described subject fitting sophisticated techniques necessary 
problem arises maximum margin algorithm finds perfectly consistent hypothesis tolerate training error 
necessary trade training accuracy better predictive power 
need tolerating training error led development soft margin classifiers cortes vapnik :10.1.1.15.9362
techniques shawe taylor cristianini replaces kernel matrix training phase follows standard kernel function decision phase 
call diagonal factor 
tuning control training error possible prove risk misclassifying unseen points decreased suitable choice shawe taylor cristianini 
controlling training error wants control trade false positives false negatives possible modify follows diagonal matrix entries locations corresponding positive negative examples 
possible prove technique equivalent controlling size way depends size class introducing svm tissue classification expression data bias larger class smaller turn corresponds asymmetric margin class smaller kept away decision boundary brown 
case imbalanced data sets choosing provides heuristic way automatically adjust relative importance classes respective cardinalities 
experiments performed freely available implementation svm classi obtained www cs columbia edu svm 
implementation described jaakkola 
differs slightly explanation include bias term forcing decision boundaries contain origin feature space 
feature selection feature selection criterion essentially golub 
slonim 

start dataset consisting expression vectors number tissue cell samples number genes measured 
sample labeled cancer vs normal 
gene calculate mean resp 
standard deviation resp 
tissues labeled resp 

want find genes help discriminate classes calculate score gives highest score genes expression levels differ average classes favoring small deviations scores respective classes 
simply take genes highest scores top features 
complete svm method complete svm method described follows choosing kernel starting simple dot product kernel tune diagonal factor achieve best performance hold cross validation tests full dataset 
svm tuning procedure repeated specified number top ranked features 
cases individual hold test features ranked scores default values set software diagonal factor varies convergence threshold set option 
score closely related fisher criterion score th feature bishop 
known samples number top features extracted train svm classify unknown sample 
examples consistently misclassified tests identified 
examples investigated biologist determined original label incorrect correction process repeated 
alternatively example may deemed outlier different rest removed 
svm tests reported simple kernel 
complex kernel required 
possibly complex datasets available providing examples higher order kernels may necessary mukherjee :10.1.1.41.4971
results method tested detail previously unpublished ovarian tissue dataset 
short analysis feature selection included 
demonstrate generality method performed experiments previously published datasets 
dataset contains examples patients human acute leukemia originally analysed golub 
results reported slonim 

dataset obtained waldo wi mit edu mpr cancer class html 
second dataset comprised human tumor normal colon tissues 
alon 
originally analysed data available website www 
princeton edu 
ovarian dataset microarray expression experiments performed dna clones may may correspond human genes tissue samples 
samples ovarian tissue normal ovarian tissue normal non ovarian tissue 
purpose experiments types normal tissue considered single class 
expression values genes normalized distribution samples zero mean unit variance 
hold cross validation experiments performed 
svm trained data tissue samples 
sample training assigned class svm 
single svm experiment consists series hold experiments sample held tested exactly 
initially experiments carried expression scores diagonal factor settings 
genes ranked manner described previously datasets consisting top experimented polynomial radial basis kernels ovarian data data containing mis labeled point performed worse linear kernel correctly labeled data performance similar linear kernel 
table 
error rates ovarian cancer tissue experiments kernel df feature fp fn tp tn dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product dot product setting svm consisting kernel diagonal factor df tissue classified 
column number features clones 
reported number normal tissues misclassified fp tumor tissues misclassified fn tumor tissues classified correctly tp normal tissues classified correctly tn 
features created 
experiments similar diagonal factors performed smaller feature sets 
table displays significant results experiments 
best classification done top features diagonal factor 
smaller datasets achieve slightly better scores compared features believe improvement significant 
analysis misclassified examples reveals normal ovarian tissue sample misclassified instances 
addition margin misclassification calculated relatively large meaning svm strongly believes 
shows classification margins experiments top features diagonal factor 
investigation discovered tissue mistakenly labeled fact 
corrected label experiments run classification results improve 
second tissue called consistently misclassified large margin new tests strongly misclassified original tests shown 
non ovarian normal tissue tissue type svm trained tissues little similarity give spurious classification results 
remove tissue repeat experiments 
perfect classification achieved size margin tissue samples fig 

svm classification margins ovarian tissues 
classifying svm calculates margin distance example decision boundary learned 
graph margin tissue sample calculated shown 
positive value indicates correct classification negative value indicates incorrect classification 
negative point corresponds tissue 
second negative point corresponds tissue 
features diagonal factor 
setting able fewer mistakes place confidence perfect experiment 
ranking features samples attempt sequence top ranked genes determine biologically significant 
yield readable sequence repetitive sequences occur naturally ends messenger rnas correspond actual genes 
represent expressed genes information available homology known assumed tumor gene presence cdna libraries tumor tissues case ests 
cancer related cancer library ests related presence white blood cells tumor 
analysis suggest feature selection method able identify clones cancer related rank highly 
clones obtain high ranking having meaningful biological explanation 
random sequencing clones reveal known tumor genes expected ranked highly 
inability feature selection method significantly improve classification performance conclude additional effort needed develop ways identifying meaningful features types datasets 
svm tissue classification expression data tumor biologist point view accumulation tumor related genes top useful feature 
aml dataset bone marrow peripheral blood samples taken patients acute leukemia aml acute leukemia 
experimental setup original authors data split training set consisting samples aml test set samples aml 
dataset provided contains expression levels human genes produced affymetrix high density oligonucleotide microarrays 
scores dataset represent intensity gene expression re scaled intensities chip equivalent 
methods golub 
normalize scores subtracting mean dividing standard deviation expression values gene 
golub perform hold cross validation tests weighted voting scheme classify training set cluster set self organizing maps soms 
method correctly classifies samples prediction samples cluster som produces cluster aml sample second aml samples 
full hold cross validation tests training set svm method correctly classifies samples diagonal factor setting 
retesting subsets containing top ranked features perfect classification obtained diagonal factor cases 
svm trained examples training set subsets features perform optimally training set classify examples test set producing results ranging classifying samples correctly 
golub predictor trained weighted voting scheme training samples classify correctly samples prediction declining predict 
tests svm correctly classifies predicted method unpredicted samples misclassified svm test 
samples patients misclassified svm tests 
lineage information cell cell provided samples 
samples training test sets svm achieves perfect weighted voting scheme selects genes described subsection feature selection 
gene predicts class sample 
predictions combined weighted score defined threshold exceeded favor class prediction 
classification top ranked features multiple diagonal factor settings hold cross validation tests 
full dataset svm misclassifies single tissue zero diagonal factor 
golub uses soms create clusters containing training set examples including aml samples 
cluster contains aml samples second lineage samples lineage sample third lineage samples lineage samples single aml sample 
additional tests slonim 
weighted voting predictor classify samples predicted correct 
lastly success chemotherapy treatments aml patients available 
slonim report able create predictor mistakes single gene predictors gene generally error rates 
hold cross validation tests svm able classify patients top ranked features diagonal factor performing slightly better chance 
misclassified sample patient consistently misclassified relatively large margin 
colon tumor dataset affymetrix oligonucleotide arrays expression levels tumor normal colon tissues measured human genes 
genes highest minimal intensity tissues selected classification purposes scores publicly available 
score represents gene intensity derived process described alon 

data processed performing classification 
alon clustering method create clusters tissues 
experiments cluster consists tumor normal tissues normal tumor tissues 
svm method full hold crossvalidation classify correctly tissues features diagonal factor 
top genes svm misclassifies samples correspond tumor tissues normal tissues 
tumor tissues alon cluster majority normal tissues cluster containing majority tumor tissues 
alon define muscle index average intensity ests homologous smooth muscle genes hypothesize tumor tissues smaller muscle index 
general proves correct notable exceptions tumor tissues muscle index equal normal tissues index greater equal 
samples especially interesting names indicate originate patient consistently misclassified svm muscle index muscle index contrary proposed hypothesis 
comparison perceptron classification algorithms discussed claim prove superiority svm method classification techniques type dataset 
second family algorithms test generalizations perceptron algorithm rosenblatt 
simple algorithm considers sample individually updates weight vector time mistake 
resulting decision rule linear bias classification sign 
algorithm requires modification perfect linear decision rule 
helmbold warmuth show linear combination decision rules iteration algorithm sufficient able derive performance guarantees 
final decision rule sign results modified perceptron comparable svm scores features dataset table 
freund schapire demonstrate kernels simple inner product applied effectively algorithm achieving performance comparable best svm benchmark test hand written digits 
case svms complex kernel improve performance 
test algorithm known norm perceptron grove averaging procedure 
theoretical results suggest algorithms perform sparse hypotheses available 
norm perceptron perform theory suggest results shown 
method analyse microarray expression data genes tissue cell types svms 
results indicate svms able classify tissue cell types data show methods ones perceptron algorithm able perform similarly 
datasets currently available contain relatively examples allow method demonstrate superiority 
svm performs simple kernel believe datasets containing table 
results perceptron features svm svm dataset features fp fn fp fn ovarian ovarian ii aml train aml treatment colon results averaged data algorithm sensitive order samples 
column dataset second number features considered 
ovarian refers original full dataset incorrectly labeled tissue ovarian ii dataset label corrected tissue removed 
ovarian colon datasets show number normal tissues misclassified fp number tumor tissues misclassified fn 
aml training dataset report number aml samples misclassified fp number patients misclassified fn 
aml treatment dataset shows number unsuccessfully treated patients misclassified fp number successfully treated patients misclassified fn 
columns report corresponding svm score features 
examples available complex kernels may necessary allow svm continue performance 
added feature svm method demonstrate identify mis labeled data 
microarray expression experiments great potential part standard diagnosis tests performed medical community 
shown expression data identification presence disease determination cell lineage 
addition hope predictions success failure particular treatment may possible far results types experiments inconclusive 
svm software written bill grundy assistance comments earlier draft 
particularly grateful tomaso poggio pointing flaw method earlier experiments 
manuel ares suggesting look alon data dick karp putting contact study ovarian cancer data 
grateful globus computer sciences nasa ames research center providing computational resources required perform experiments 
svm tissue classification expression data alon gish mack levine 
broad patterns gene expression revealed clustering analysis tumor normal colon tissues probed oligonucleotide arrays 
proc 
natl 
acad 
sci 
usa 
ben dor friedman nachman schummer yakhini 
tissue classification gene expression profiles 
proceedings th annual international conference computational molecular biology recomb universal academy press tokyo 
bishop 
neural networks pattern recognition 
oxford university press oxford 
boser guyon vapnik 
training algorithm optimal margin classifiers 
proceedings th annual acm workshop computational learning theory acm press pittsburgh pa pp 

brown grundy lin cristianini ares haussler 
knowledge analysis microarray gene expression data support vector machines 
proc 
natl 
acad 
sci 
usa 
chu derisi eisen botstein brown 
transcriptional program yeast 
science 
cortes vapnik 
support vector networks 
machine learning 
cristianini shawe taylor 
support vector machines 
cambridge university press cambridge www support vector net 
derisi iyer brown 
exploring metabolic genetic control gene expression genomic scale 
science 
derisi brown bittner meltzer ray chen su trent 
cdna microarray analyse gene expression patterns human cancer 
nat 
genet 
eisen spellman brown botstein 
cluster analysis display genome wide expression patterns 
proc 
natl 
acad 
sci 
usa 
freund schapire 
large margin classification perceptron algorithm 
proceedings th annual conference computational learning theory acm press new york pp 

golub slonim tamayo mesirov loh downing bloomfield lander 
molecular classification cancer class discovery class prediction gene expression monitoring 
science 
grove littlestone schuurmans 
general convergence results linear discriminant updates 
proceedings th annual conference computational learning theory acm press new york pp 

hastie tibshirani eisen brown ross weinstein alizadeh staudt botstein 
gene shaving new class clustering methods expression arrays 
stanford university technical report 
helmbold warmuth 
weak learning 
comput 
syst 
sci 
jaakkola haussler 
fisher kernel method detect remote protein homologies 
proceedings th international conference intelligent systems molecular biology aaai press menlo park ca 
lockhart dong byrne gallo chee wang kobayashi horton brown 
expression monitoring hybridization high density oligonucleotide arrays 
nature 
mukherjee tamayo mesirov slonim verri poggio 
support vector machine classification microarray data 
technical report cbcl ai memo mit 
jeffrey van de rijn rees eisen ross williams zhu lee lashkari brown botstein 
distinctive gene expression patterns human cells breast 
proc 
natl 
acad 
sci 
usa 
roberts nelson stoughton meyer bennett dai walker hughes friend 
signaling circuitry multiple pathways revealed matrix global gene expression profiles 
science 
rosenblatt 
perceptron probabilistic model information storage organization brain 
psych 
rev 
schummer ng nelson schummer baldwin hood 
comparative hybridization array ovarian discovery genes ovarian 
gene 
shawe taylor cristianini 
results margin distribution 
proceedings th annual conference computational learning theory acm press new york 
slonim tamayo mesirov golub lander 
class prediction discovery gene expression data 
proceedings th annual international conference computational molecular biology recomb universal academy press tokyo japan pp 

spellman sherlock zhang iyer anders eisen brown botstein 
comprehensive identification cell cycle regulated genes yeast saccharomyces cerevisiae microarray hybridization 
mol 
biol 
cell 
tamayo slonim mesirov zhu lander golub 
interpreting patterns gene expression self organizing maps 
proc 
natl 
acad 
sci 
usa 
vapnik 
statistical learning theory 
wiley new york 
wang gan nelson ng schummer hood mulligan 
monitoring gene expression profile changes ovarian cdna microarray 
gene 
wen fuhrman carr smith barker somogyi 
large scale temporal gene expression mapping central nervous system development 
proc 
natl 
acad 
sci 
usa 
zhang zhou kern hamilton 
gene expression pro files normal cancer cells 
science 
zhu cong schenk 
cellular gene expression altered human global monitoring oligonucleotide arrays 
proc 
natl 
acad 
sci 
usa 
zien mika sch olkopf smola lengauer uller 
engineering support vector machine kernels recognize translation initiation sites 
bioinformatics appear 

