static priority scheduling multiprocessors bjorn andersson sanjoy baruah jan jonsson preemptive scheduling systems periodic tasks platform comprised identical multiprocessors considered 
scheduling algorithm proposed static priority scheduling systems algorithm simple extension uniprocessor scheduling algorithm 
proven algorithm successfully schedules periodic task system worst case utilization third capacity multiprocessor platform special case harmonic periodic task systems algorithm proven successfully schedule system worst case utilization half platform capacity 
keywords 
multiprocessor scheduling periodic tasks global scheduling static priorities 
years preemptive periodic task model proven remarkably useful modelling recurring processes occur hard real time computer application systems 
accordingly effort devoted development comprehensive theory dealing scheduling systems comprised independent periodic real time tasks 
particularly uniprocessor context environments hard real time jobs generated periodic tasks comprise hard real time application system execute single shared processor exists wide body results necessary sufficient feasibility tests optimal scheduling algorithms efficient implementations algorithms facilitate application systems designer able model real time application system collection independent preemptive periodic real time tasks 
results extended multiprocessor context environments identical processors available real time jobs may executed 
periodic task model 
periodic model hard real time tasks task characterized parameters execution requirement period interpretation task generates job integer multiple job execution requirement execution units complete deadline equal integer multiple periodic task system consists periodic tasks supported part national science foundation nos 
ccr ccr ccr itr 
execute specified processor architecture 
assume job independent sense interact manner accessing shared data exchanging messages jobs task 
assume model allows job preemption job executing processor may preempted prior completing execution execution may resumed cost penalty 
study scheduling systems periodic tasks 
denote periodic task system periodic task characterized execution requirement period 
task define utilization ratio execution requirement period def define utilization periodic task system sum utilizations tasks def loss generality assume tasks indexed period 
dynamic static priorities run time scheduling process determining execution real time application system job executed instant time 
run time scheduling algorithms typically implemented follows time instant assign priority active job allocate available processors highest priority jobs 
respect certain run time scheduling algorithms possible tasks active jobs times time job higher priority time job higher priority 
run time scheduling algorithms permit switching order priorities tasks known dynamic priority algorithms 
contrast static priority algorithms satisfy property pair tasks active jobs case task jobs priority 
example static priority scheduling algorithm rate monotonic scheduling algorithm assigns task priority inversely proportional period smaller period higher priority ties broken arbitrarily consistent manner equal periods job priority job jobs priority jobs 
scope document compare contrast relative advantages disadvantages static priority versus dynamic priority scheduling 
observe context static priority scheduling run time scheduling problem determining run time jobs execute instant time exactly equivalent problem assigning priorities tasks system priorities assigned run time scheduling consists simply choosing currently active jobs highest priorities 
hard real time task system defined static priority feasible scheduled static priority run time scheduler manner jobs complete deadlines permissible circumstances 
specifications system hard realtime tasks static priority feasibility analysis process determining system static priority feasible 
informally job active ready time remains executed amount time equal execution requirement deadline elapsed 
partitioned versus global scheduling 
study static priority scheduling systems periodic tasks identical multiprocessors 
scheduling systems distinct approaches possible 
partitioned scheduling jobs generated task required execute processor 
global scheduling task migration permitted 
require jobs task execute processor permit different jobs execute different processors 
addition job migration permitted job preempted particular processor may resume execution different processor 
assume penalty associated task job migration 
job level parallelism expressly forbidden permitted processor executing job instant time 
partitioned approach static priority scheduling requires set tasks partitioned available processors ii total order defined tasks partition 
instant run time active job generated task partition chosen execution corresponding processor active job partition corresponding processor left idle 
global approach hand define total order tasks instant run time choose execution highest priority active jobs processors remaining idle fewer active jobs 
proven leung whitehead global approaches static priority scheduling multiprocessors incomparable sense task systems feasible processors partitioned approach priority assignment exists cause jobs tasks meet deadlines global scheduling processors ii task systems feasible processors global approach partitioned distinct subsets individual partition uniprocessor static priority feasible 
result leung whitehead provides strong motivation study partitioned non partitioned approaches static priority multiprocessor scheduling approach strictly better 
research 
partitioned approach static priority multiprocessor scheduling extensively studied see excellent 
global scheduling algorithm scheduling systems periodic tasks 
prove algorithm successfully schedules periodic task system utilization identical processors bound approaches follows algorithm successfully schedules periodic task system cumulative utilization identical processors 
consider proof result interesting right exploit interesting result phillips theorem bounds amount execution performed multiprocessor conserving scheduling algorithm expect result prove useful determining useful properties multiprocessor systems result proof appendix 
special case harmonic periodic task systems task sets periods tasks satisfy relationship integer multiple integer multiple show algorithm offers better performance guarantee 
specifically prove algorithm successfully schedules harmonic periodic task system utilization identical processors bound approaches 
organization 
remainder organized follows 
section briefly describe major results remainder 
section algorithm rm static priority multiprocessor algorithm scheduling arbitrary periodic task systems prove algorithm rm successfully schedules periodic task system utilization identical processors 
section algorithm algorithm rm optimized scheduling harmonic task sets 
section describe series experiments conducted evaluate performance algorithm rm randomly generated task sets 
section briefly review related research topic multiprocessor real time scheduling conclude section brief summary results contained 
proofs postponed appendix 
results interesting important results real time multiprocessor scheduling theory obtained mid 
results results briefly described 
resource augmentation 
previously shown line real time scheduling algorithms tend perform extremely poorly overloaded conditions 
phillips stein wein explored resource augmentation techniques line scheduling real time jobs goal determine line algorithm provided faster processors available algorithm perform better implied bounds derived 
studying line scheduling parameters periodic tasks assumed priori known turns particular result prove useful study static priority multiprocessor scheduling 
result proof may section appendix 
focus scheduling individual jobs periodic tasks 
accordingly define job characterized arrival time execution requirement deadline interpretation job needs execute units interval 
periodic task generates infinite sequence jobs parameters 

remainder symbol denote infinite set jobs generated tasks periodic task system resource augmentation technique improving performance line scheduling algorithms formally proposed 
denote set jobs 
algorithm time instant denote amount done algorithm jobs interval executing processors speed 
conserving scheduling algorithm processor active job awaiting execution 
theorem phillips set jobs time instant conserving algorithm algorithm case 
processor conserving algorithm completes execution algorithm provided processors times fast 
predictable scheduling algorithms 
ha liu studied issue predictability multiprocessor scheduling real time systems perspective 
definition predictability denote scheduling algorithm fj set jobs 
denote time job completes execution scheduled algorithm consider set fj jobs obtained follows 
job arrival time execution requirement deadline job arrival time deadline execution requirement larger 
denote time job completes execution scheduled algorithm scheduling algorithm said predictable set jobs obtained case informally definition recognizes fact specified execution requirement parameters jobs typically upper bounds actual execution requirements run time exact values 
predictable scheduling algorithm may determine upper bound completion times jobs analyzing situation assumption job executes amount equal upper bound execution requirement guaranteed actual completion time jobs determined value 
periodic task system generates set jobs definition may extended straightforward manner algorithms scheduling periodic task systems algorithm scheduling periodic task systems predictable iff periodic task systems case completion time job job execution requirement exactly equal upper bound completion time job job execution requirement ha liu define scheduling algorithm priority driven satisfies condition pair jobs higher priority instant time higher priority notice global static priority algorithm scheduling periodic tasks satisfies condition priority driven 
converse true algorithms scheduling periodic tasks meet definition priority driven global static priority algorithms notice earliest deadline scheduling algorithm schedules instant currently active job deadline smallest priority driven algorithm static priority algorithm 
result ha liu stated follows 
theorem ha liu priority driven scheduling algorithm predictable 
algorithm rm section algorithm rm static priority global scheduling algorithm scheduling periodic task systems derive utilization sufficient feasibility condition algorithm rm particular prove task system satisfying scheduled meet deadlines unit speed processors algorithm rm 
proceed 
section consider restricted category periodic task systems call light systems prove multiprocessor rate monotonic scheduling algorithm henceforth refer multiprocessor rate monotonic algorithm algorithm rm global static priority algorithm assigns tasks priorities inverse proportion periods successfully schedule light system 
section extend results concerning light systems arbitrary systems periodic tasks 
extend algorithm rm define global static priority scheduling algorithm call algorithm rm prove algorithm rm successfully schedules periodic task system utilization identical processors 
light systems definition periodic task system said light system processors satisfies properties property property consider scheduling task systems satisfying property property rate monotonic scheduling algorithm algorithm rm 
theorem periodic task system light processors scheduled meet deadlines processors algorithm rm 
proof suppose ties broken algorithm rm greater priority notice jobs meet deadlines algorithm rm depends jobs generated tasks completely unaffected presence tasks define task set follows def proof strategy follows 
prove algorithm rm schedule manner jobs lowest priority task complete deadlines 
claim algorithm rm successfully schedules follow induction lemma task system feasible processors computing capacity 
proof notice 
task property follows similarly property fact derived consequence inequalities may conclude scheduled meet deadlines processors computing capacity processor sharing schedule henceforth denote opt assigns fraction processor time instant bears witness feasibility proof lemma 
follows existence schedule opt described proof lemma fact algorithm rm conserving rm opt time instant amount done algorithm rm executing unit speed processors amount done opt speed processors 
lemma jobs meet deadlines scheduled algorithm rm 
proof assume jobs met deadlines algorithm rm prove th job meets deadline 
correctness lemma follow induction starting 
th job arrives time instant deadline time instant needs units execution 
inequality fact processor sharing schedule opt schedules task 
units interval rm 

units execution algorithm rm tasks follows fact exactly units generated prior instant remainder executed algorithm rm generated cumulative execution requirement jobs generated tasks arrive prior deadline th job bounded seen discussion inequality 

gets done prior time instant remains executed time instant amount processor capacity left unused interval smaller 
processors available cumulative length intervals leave processor idle minimized different processors tend idle simultaneously parallel lower bound cumulative length intervals leave processor idle 
equals th job meet deadline suffices cumulative interval length large execution requirement simplify lhs inequality property task system property task system inequalities may conclude th job meet deadline 
proof lemma 
correctness theorem follows lemma induction base case meet deadlines directly follows fact processors available system 
proof theorem 
arbitrary systems section saw algorithm rm successfully schedules periodic task system utilization identical processors provided utilization 
relax restriction utilization individual task permit consider section static priority global scheduling task system satisfying condition task systems define static priority assignment scheme algorithm rm follows 
algorithm rm assigns static priorities tasks rule highest priority ties broken arbitrarily rate monotonic priority 
example example priorities assigned algorithm rm consider task system def scheduled platform identical unit speed processors 
utilizations tasks respectively 
equals tasks assigned highest priorities remaining tasks assigned rate monotonic priorities 
possible priority assignments follows highest priority task listed theorem periodic task system utilization scheduled meet deadlines unit speed processors algorithm rm 
proof assume tasks indexed priorities assigned algorithm rm 
observe task assigned highest priority strictly greater tasks assigned highest priority 
denote number tasks assigned highest priority ko utilization greater ko assigned priorities rate monotonically 
def analyze task system consisting tasks having utilization def ko utilization bounded follows ko 

furthermore inequalities conclude periodic task system light processors 
theorem scheduled algorithm rm meet deadlines processors 
consider task system obtained replacing task utilization greater task period utilization equal def ko notice algorithm rm assign identical priorities corresponding tasks notion corresponding defined obvious manner 
notice scheduling algorithm rm devote processors exclusively tasks ko highest priority tasks utilization equal unity executing algorithm rm remaining tasks tasks remaining processors 
seen algorithm rm schedules tasks meet deadlines algorithm rm schedules meet deadlines jobs 
notice execution algorithm rm task system considered instantiation run algorithm rm task system jobs ones generated tasks ko execute full execution requirement 
result ha liu theorem follows algorithm rm predictable scheduling algorithm job task execution algorithm rm task system completes corresponding job execution algorithm rm task system seen deadlines missed execution algorithm rm task system proof theorem 
harmonic task systems section studied static priority global multiprocessor scheduling systems periodic tasks 
harmonic periodic task systems periods tasks related follows integer multiple integer multiple respect static priority global multiprocessor scheduling harmonic periodic task systems variant algorithm rm call algorithm rm prove stronger bound performance algorithm rm 
refine definition light systems harmonic task systems 
specifically call harmonic task system light processors algorithm rm assigns static priorities tasks harmonic periodic task system rule highest priority ties broken arbitrarily rate monotonic priority 
theorem periodic task system utilization scheduled meet deadlines unit speed processors algorithm rm 
proof sketch analog theorem harmonic periodic task system light processors scheduled meet deadlines processors algorithm rm proved manner closely parallels proof theorem 
may verified proof lemma goes unchanged assumed light harmonic periodic task system lemma applicable light harmonic periodic task systems 
proof analog lemma provided section appendix crucial difference arises simplification results inequality 
obtaining inequality replaced notice harmonic tasks case may simply replace harmonic task set guaranteed integer multiple remainder proof merely algebraic manipulation proceeds directly details may appendix 
correctness theorem light harmonic task systems follows directly correctness analog lemma induction 
prove theorem arbitrary harmonic task systems techniques identical section 
consider scheduling processors task system system inflate unity utilizations tasks utilizations ii prove consequence correctness theorem light systems described may conclude remaining tasks successfully scheduled algorithm rm remaining processors meet deadlines iii result ha liu theorem conclude algorithm rm successfully schedule entire task system 
experimental evaluation purpose section show rm fail meet deadlines system utilization slightly higher performs better general task sets 
compare performance different techniques static priority preemptive scheduling multiprocessors partitioning non partitioning non partitioning 
section describes experimental setup terms simulation parameters scheduling algorithms 
section presents results experiments observations 
section compares theoretical utilization bounds scheduling algorithms 
experimental setup experimental setup similar experimental setup completeness setup described 
simulation experiment represents simulation task sets organized different buckets task sets 
bucket contains task sets system utilization greater low greater high 
bucket compute success ratio number successfully scheduled task sets bucket divided number scheduled task sets bucket 
task set bucket generated starting current task set empty adding new task current task set long system utilization lower low system utilization current task set higher low decide current task set inserted bucket 
system utilization current task set lower high number tasks greater number processors task set put bucket new task set generated 
experiment differs simulate buckets tasks bucket contrast simulated buckets tasks bucket 
periods execution time task selected randomly 
period task drawn set discrete periods period having probability selected 
experiments draw period task different period sets 
note type period sets experiments stated 
study synchronous task sets generated tasks arrive time time scheduled time lcm execution time task computed utilization task rounded nearest integer 
utilization task uniform distribution binomial distribution 
determine distribution generate random variable uniform distribution range 
variable equal simulation parameter choose uniform distribution binomial distribution chosen 
case uniform distribution utilization task drawn range 
case binomial distribution utilization task generated way 
perform trials probability success simulation parameter 
count number successes time lcm tn tasks execute tasks execute lcm tn 
divide 
add random number uniform distribution range 
utilization task equal zero greater generate task 
note procedure high value task high utilization 
evaluate partitioning scheme bound mprespan non partitioning scheme wmpfair non partitioning schemes rm adaptivetkc rm 
bound mprespan modification bound mp scheme necessary sufficient schedulability test task processor assignment sufficient test original version 
partitioning non partitioning schemes different strategies assigning task processor concept successfully scheduled needs clearly defined 
bound mp consider task successfully scheduled schedulability test partitioning algorithm guarantee task set uniprocessor schedulable 
schemes consider task successfully scheduled met deadlines lcm 
note wm considered successfully scheduled certain property satisfied 
evaluated scheduling algorithms wm primarily designed periodic scheduling satisfy property chose evaluate scheduling algorithms assumption periodic scheduling 
property stronger condition periodicity wm show worse performance study 
experimental results results experiments different values parameters shown figures section appendix 
plots draw 
observe rm succeeds higher system utilizations suggested utilization bound 
example processors rm breaks system utilization corresponding theoretical bound 
note rm significant performance drop 
breakdown utilization low 
phenomenon effect chosen experimental setup 
choice distributions expected value utilization task approximately uniform distribution binomial distribution resulting large population tasks utilization 
similar behavior observed 
observe rm outperforms rm processors available small tasks low average utilization 
reason rm succeeds schedule task set system utilization rm potentially fail due effect 
larger rm rm offer comparable performance tasks utilization greater guarantee bound 
example tasks utilization greater means rm rm produce priority assignment similar performance 
see rm performs worse wmpfair adaptivetkc systems large number processors 
difference performance typically shows rm suffer drawbacks rm 
rm performs worse bound mprespan long 
higher values fundamental limitations assignment strategy bin packing algorithm reveal causes significant performance drop 
task periods drawn set long periods wmpfair performs significantly better bound mprespan adaptivetkc 
reason periods long relative time unit base wmpfair approximates processor sharing optimal 
task periods drawn set short periods wmpfair offer performance similar mprespan adaptivetkc 
worth noting scheduling algorithms perform processor 
reason evaluated scheduling algorithms wmpfair bound mprespan perform scheduling manner rm 
reason bound mp schedules tasks differently rm special task set transformation 
algorithm task set transformed ratio periods lower 
transformation may case exist task sets schedulable processor 
note processors success ratio rm heavily changing 
reason parameters tasks low utilization probability task utilization drawn uniform distribution higher likelihood large 
task large utilization population low utilization tasks rm fail meet deadlines low system utilization due effect 
comment performance wmpfair 
simulation results show success ratio wmpfair higher 
mentioned effect occurs wmpfair approximates processor sharing optimal periods large comparison time unit base 
scheduling algorithms periods affect success ratio 
notable exception system utilization greater 
case yields higher success ratio way task sets generated 
reason follows 
task sets tasks tasks yields utilization higher rejected 
way achieving utilization bounds generate task sets periods harmonious 
task sets scheduled algorithms wmpfair 
utilization bounds conclude performance evaluation comparing theoretical bounds studies scheduling schemes 
deriving upper guarantee bound system utilization 
consider task set tm cm tm cm scheduled processors positive integer tasks arrive time 
task set system utilization studied approaches partitioning non partitioning non partitioning scheduling deadlines missed task set 
partitioning succeed necessary tasks execute processor processor utilization greater task set 
non partitioning highest priority tasks execute time occupy time units 
time units available lower priority tasks lowest priority task needs time units misses deadline 
letting task set system utilization 
consequently particular scheduling algorithm addressed utilization bound higher 
studied approaches rm tight utilization bound derived bound 
adaptivetkc utilization bound shown greater 
rm utilization bound known greater 
wm known utilization bound hitherto proven due reasoning utilization bound higher 
conclude general static priority scheduling algorithm multiprocessor achieve utilization bound greater 
interesting note utilization bound static multiprocessor scheduling algorithm previously shown higher 
related problem scheduling set periodic tasks identical multiprocessor machines posed liu 
liu derived conditions earliest deadline scheduling algorithm successfully schedule system conditions translate sufficient albeit necessary feasibility test 
baruah obtained necessary sufficient conditions determining feasibility optimal scheduling algorithm successfully scheduling feasible systems 
approach static priority multiprocessor scheduling periodic task systems extensively studied 
research considered problem bin packing algorithms partitioning set periodic tasks set processors partition uniprocessor feasible rate monotonic algorithm efficient algorithm proved partition set periodic tasks twice partitions optimal algorithm equivalently devised efficient algorithm partitioned static priority multiprocessor scheduling uses twice processors optimal algorithm 
oh baker partitioned static priority multiprocessor scheduling algorithm schedules task system utilization processors represents utilization approximately capacity multiprocessor platform 
algorithm rm offers superior bound oh baker bound proves superior algorithm rm 
point results current remain significant despite leung whitehead proven global approaches general incomparable better understand kinds scheduling systems 
studied preemptive scheduling systems periodic tasks platform comprised identical multiprocessors 
proposed algorithm rm new static priority multiprocessor algorithm scheduling periodic task systems 
proved algorithm rm successfully schedules periodic task system utilization identical processors 
special case harmonic periodic task systems obtained better sufficient utilization feasibility test harmonic task set utilization successfully scheduled algorithm rm identical processors 
andersson jonsson fixed priority preemptive multiprocessor scheduling partition partition 
proceedings international conference real time computing systems applications island south korea december ieee computer society press pp 

andersson jonsson insights fixed priority preemptive non partitioned multiprocessor scheduling 
proceedings real time systems symposium progress session orlando fl november 
baruah cohen plaxton proportionate progress notion fairness resource allocation 
algorithmica june 
baruah sharma line scheduling maximize task completions 
proceedings real time systems symposium san juan puerto rico ieee computer society press 
baruah koren mao mishra raghunathan shasha wang competitiveness line real time task scheduling 
real time systems 
proceedings th real time systems symposium san antonio texas december 
baruah koren mishra raghunathan shasha online scheduling presence overload 
proceedings nd annual ieee symposium foundations computer science san juan puerto rico october ieee computer society press pp 

real time task allocation problem 
proceedings th hawaii international conference system science honolulu january 
line algorithm real time tasks allocation 
proceedings real time systems symposium pp 

liu real time scheduling problem 
operations research 
ha validating timing constraints multiprocessor distributed systems 
phd thesis department computer science university illinois urbana champaign 
available technical report 
uiucdcs 
ha liu validating timing constraints multiprocessor distributed real time systems 
tech 
rep uiucdcs department computer science university illinois urbana champaign october 
ha liu validating timing constraints multiprocessor distributed real time systems 
proceedings th ieee international conference distributed computing systems los alamitos june ieee computer society press 
speed powerful 
th annual symposium foundations computer science focs los alamitos oct ieee computer society press pp 

melhem efficient rms admission control algorithm application multiprocessor scheduling 
proceedings international parallel processing symposium april ieee computer society press pp 

leung whitehead complexity fixed priority scheduling periodic realtime tasks 
performance evaluation 
liu layland scheduling algorithms multiprogramming hard real time environment 
journal acm 
liu scheduling algorithms multiprocessors hard real time environment 
jpl space programs summary ii 
oh baker utilization bounds processor rate monotone scheduling static processor assignment 
real time systems international journal time critical computing 
phillips stein wein optimal time critical scheduling resource augmentation 
proceedings ninth annual acm symposium theory computing el paso texas may pp 

moir static priority static scheduling multiprocessors 
proceedings real time systems symposium orlando fl november ieee computer society press 
proof theorem proof restated notation terminology rest 
statement theorem instance jobs time instant conserving algorithm algorithm case 
proof contradiction 
suppose true time instant conserving algorithm executing speed 
processors performed strictly algorithm executing speed processors 
denote job earliest arrival time time instant satisfying 
amount done job time instant strictly amount done time instant exist time 
gives equality 
choice case 
amount done strictly amount done interval 
fact amount done amount done implies complete denote cumulative length time interval executing processors def denote length time interval processor 
observations 
conserving scheduling algorithm job completed instant schedule generated executed time units time schedule generated executed time units schedule generated 
amount done 
mx amount done interval ms case 
mx adding times inequality inequality get 

mx 
mx contradiction 
proof analog lemma harmonic task sets proof essentially reproduction proof lemma section appropriately modified take advantage unique additional properties harmonic task sets 
recall harmonic task set 
particular note case dt assume jobs met deadlines algorithm rm consider th job job arrives time instant deadline time instant needs units execution 
long opt schedules tasks complete deadlines amount done opt time interval utilization task set multiplied time interval 
processors speed tasks complete deadlines lemma 
opt 
applying inequality yields rm 

units execution tasks follows fact exactly units generated prior instant remainder executed algorithm rm generated cumulative execution requirement jobs generated tasks arrive prior deadline th job bounded seen discussion inequality 

gets done prior time instant remains executed time instant amount processor capacity left unused interval smaller 
processors available cumulative length intervals leave processor idle minimized different processors tend idle simultaneously parallel lower bound cumulative length intervals leave processor idle 
equals th job meet deadline suffices cumulative interval length large execution requirement simplify lhs inequality inequalities may conclude th job meet deadline 
graphical depiction experimental results results experiments described section graphed figures 
experiment plotted performance success ratio function system utilization resolution bucket intervals 
system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processors periods selected system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processor periods selected system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processor periods selected system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processors periods selected system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processor periods selected system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio system utilization rm rm adaptivetkc bound mprespan wmpfair system utilization rm rm adaptivetkc bound mprespan wmpfair success ratio function system utilization different scheduling algorithms processor periods selected 
