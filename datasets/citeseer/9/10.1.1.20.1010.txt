workshop virtual intelligence dynamic neural networks stockholm novel concepts neuro accelerator spiking neural networks schoenauer jahnke institute microelectronics technical university berlin 
berlin germany phone fax mail tim ee tu berlin de basic architecture memory optimized accelerator spiking neural networks 
accelerator architecture exploits novel concepts efficient computation spiking neural networks weight caching compressed memory organization 
concepts allow parallelization processing reduce bandwidth requirements accelerator components 
pave way dedicated digital hardware real time computation complex networks pulse coded neurons order neurons 
programmable neuron model accelerator described extensively 
shall encourage discussion suggestions features desirable add current model 
keywords spiking neural networks pulse coded neural networks neurocomputer neuro accelerator 
biology source inspiration artificial neural networks 
spike processing simply spiking neuron models closely related biological neurons take account precise timing spike events 
case conventional rate coding neuron models multilayer perceptrons commonly large networks 
spiking neural networks referred pulse coupled neural networks gained increasing interest experimental evidence stimulus induced synchronized brain activity eck gra 
synchronized firing neuronal assemblies serve brain code feature binding pattern segmentation ground separation mal eck 
human brain technical systems easily solves tasks invariant object recognition spiking neural networks great interest machine vision applications 
employing image processing requires huge networks order spiking neurons 
simulating large networks complex neuron models computational expensive task leads high simulation times high performance workstations 
furthermore solve real world tasks need real time performance complex networks achieved supercomputers dedicated hardware 
university paderborn spiking neural networks spike designed implemented tested har 
speed implementation limited field programmable gate arrays fpga 
faster flexible implementation achieved advantage vlsi technology application specific integrated circuits asics 
approach pursued system neurocomputer spike processing neural networks 
image processing applications spiking neurons wei shown higher demand network complexity order allow sufficient resolution processed images sch concepts second generation system developed memory optimized accelerator spiking neural networks 
comparison architecture memory organization dataflow optimized tackle challenge simulating complex networks 
describing concept spiking neuron models derivation generic programmable neuron workshop virtual intelligence dynamic neural networks stockholm model typical network characteristics outlined 
subsequently major steps simulating networks reviewed 
concepts increase efficiency simulation snn discussed 
new concepts accelerator design introduced 
shown concepts realized architecture 
performance discussed 

spiking neural networks neuron models spiking neuron models biophysical models try account properties real neurons descending level current modelling integrated signal flow parts neuron particular synapses axon dendrites soma 
spiking neurons represent complex leaky integrate fire neurons 
rudimentary behavior spiking neurons input spikes presynaptic neurons weighted summed yielding value called membrane potential 
membrane potential time dependent decays spikes received neuron 
spikes excite membrane potential sufficiently exceeds certain threshold spike emitted 
emission spike neuron unable spike certain period called refractory period 
generic pulse coded neuron model referred spike response model srm described mathematically ger firing time neuron neuron respectively 
ui membrane potential neuron fi fj set firing times neuron neuron respectively 
threshold reached ui neuron emits spike 
set neurons presynaptic kernel model refractory period 
kernel model postsynaptic potential neuron induced spike neuron eq 
yields membrane potential ui neuron contains second addend sum spikes presynaptic neurons spikes presynaptic neurons evaluated kernel function ij models response presynaptic spikes 
membrane potential ui exceeds threshold neuron spikes inhibits refractory period 
modeled negative feed back addend eq 
accounts summing spikes emitted neuron evaluating spikes kernel function typical kernel functions time constants denotes 
srm described eq 
eq 
extended order model synchronization neuronal assemblies introducing linking connections eck 
inputs linking connections modulate feeding inputs correspond second addend eq 

integrated signals linking inputs constant offset term interact multiplicatively integrated signals feeding inputs 
eq 
case ij hs ij wij hs ui ij fi fj tui presynaptic ij ui fij fi extra index fi ffi fij marks values related feeding connections extra index li fli lij marks values related linking connections 
model shall called extended spike response model 
lij lj fi fj ffj li lj flj workshop virtual intelligence dynamic neural networks stockholm graphical model extended srm shown fig 

input linking inputs feeding inputs lp fq lp fq epsp function synapse dendrite lp fq lp linking dendrite fq feeding dendrite dendrites graphical representation extended spike response model 
digital hardware requires model discrete time 
fig 
simple leaky accumulators chosen functions ij refractory period filter function fig 
delay elements output neuron added model axonal delays 
see fig 
order memorize state neuron filter values ut nt nt nt need stored 
values called internal potentials ip values 
nt nt lp input nt nt fq nt lp fq synapse dendrite epsp function rl rlp rf nt nt lp nt linking dendrite nt fq feeding dendrite dendrites time discrete extended spike response model order filters 
extended spike response model described eq 
covers knowledge features inherent spiking neuron models subject active research 
allow different types neurons extended srm configurable called programmable model neuron desirable hardware implementation 
subsection 
network topology characteristics assume sparsely connected networks 
network composed layers layer consists neurons equal properties 
neurons may connected laterally layer layers 
connections usually structured perceptive fields system possible choose arbitrarily 
network activity resembles average number spikes time slice divided total number neurons 
network activity typically low 

computing spiking neural networks basic procedures digital simulation snn computed discrete times period called time slice 
time slice state network computed 
assume snn consists spiking neurons shown fig 

nt soma dynamic threshold function static threshold comparator soma dynamic threshold function static threshold nt comparator axon output nt output nt workshop virtual intelligence dynamic neural networks stockholm major steps need taken 
decay ips internal potentials ut nt nt nt decreased kernel functions ij case simple leaky accumulator correspond multiplication decay factor see fig 


spike propagation spikes propagated outputs neurons source neurons previous time slice inputs connected neurons target neurons 

output output function combines ip values neuron membrane potential nt spike emitted depending comparison threshold 

learning learning parameters adapted learning algorithm 
concepts discussed focus step 
concepts efficient simulation efficiently simulate strategies pursued event list protocol sender oriented connection list fixed point arithmetic neglecting small ip values 
event list implement step spike propagation spikes previous time slice need distributed connections source neurons target neurons 
event list protocol efficient communication scheme 
event list contains addresses source neurons 
due low network activity small fraction total number neurons needs stored list 
sender oriented connection list step connections source neurons corresponding weights need determined 
suitable store connections weight values list 
connection list contains source neuron address target neuron addresses sender oriented target neuron address source neuron addresses receiver oriented fra 
sender oriented connection list appropriate ensures active connections computed 
neglecting small internal potentials network activity low ip values decay time approach zero 
percentage negligible ip values depends network parameters stimuli 
enlarged version simple snn rei average number negligible order 
waste computational resources apply filter function values 
ip value tagged valid tag tag comparison minimum value ip min case ip values valid tag bit processed 
numeric precision floating point arithmetic fast fixed point arithmetic may degradation network performance 
resolution analysis roth rot accuracies bit weights bit internal potentials sufficient vision problems 
programmable model spiking neuron programmable neuron model admits configure spiking neurons various complexity different parameter set 
model shown fig 

represents configurable neuron may programmed correspond neuron model fig 

furthermore programmable neuron allows inputs nt ip filter order reduce computational expense letting spikes modelled filter characteristic split filter 
consists summing nodes sum weighted spikes share filter processing unit combines ip values program code comparator compares resulting value activity threshold delay elements output 
parameter set neuron comprises filter coefficients program code threshold values delay values 
program code specifies ip values combined added subtracted multiplied cascaded 
cascading ip filters higher order filters configured emulate kernel function rise subsequent decay denoted right part eq 

fig 
cascading ip ip depicted broken line specified program code ip events neural networks occur time scale milliseconds modern vlsi circuits operate time scale nanoseconds 
time scale functioning biological neuron vlsi implementation able simulate function neurons 
advantage higher speed vlsi circuits parallelization may limited processing units achieving real time simulations neurons 
values currently calculated stored memory 
reason employing neuron model fig 

simplification valid case spikes extra delay 

source neurons referred neurons emitting spike target neurons receive spike 
workshop virtual intelligence dynamic neural networks stockholm requires memories store ip values parameter set 
small ip values neglected tag memory required 
generic programmable model spiking neuron 
concepts architecture simulation complex spiking neural networks designing snn accelerators real time simulation complex things need considered memory capacity increase store network variables processing speed rise process network variables time frame 
due continuous growth memory capacity past years capacity chip memory minor problem 
bandwidth data transfer memory chip processing chip grown correspondingly 
limited number pins supplied chip package operation frequency 
slightly increased 
bandwidth may limiting factor 
system speed may formulated input clock pe synapse dendrite ip ip ip circuit operation frequency clock pe processing elements working parallel efficiency processing elements pe defined reciprocal value number clock cycle takes processing element process 
clock frequency rises vlsi technology presumed constant certain state technology 
suppose hardware effort chip size pin count board complexity kept constant ways left increase system speed simplifying processing elements higher number pe may chosen increasing hardware effort increasing efficiency processing elements increasing complexity 
concentrate strategy 
task designing accelerator complex conform optimization bandwidth requirements efficiency processing elements 
limitations accelerator architectures subsection concepts efficient simulation spike event list sender oriented connection list neglecting small ip values 
advantage spike event list suggest basic architecture system shown fig 

major system elements neuron unit connection unit spike event list 
neuron unit performs computation neuron network suggested programmable model fig 

continuously updating ips neuron unit supplies addresses neurons emit spike source neurons 
stored spike event list 
time slice connection unit reads addresses relevant source neurons supplies addresses target neurons corresponding weights neuron unit 
basic organization spike 
requires sequential processing steps decay propagation output see subsection 
principle decay ip values spike propagation performed time period 
step requires separate memory access decay potentials organized regular dataflow propagating spikes irregular occurrence spikes predictable 
steps require access memory performed parallel 
suggest new organization system allows processing steps parallel 
fundamental organization shown fig 
quite similar fig 
new concepts prog prog prog soma comparator thresholds activity learning axon delays output workshop virtual intelligence dynamic neural networks stockholm weight caching compressed ip memory 
weight neuron unit connection unit decay propagate output time slice event list list source neuron source neuron processing time basic organization accelerator system employing spike event list denotes address 
typical novel concepts weight caching compressed ip memory weight caching sending weight corresponding target neuron address separately connection unit neuron unit accumulated values ip copy ip memory weight cache connection unit 
time step accumulated weights sent neuron unit performs steps decay potentials propagating accumulated spikes computing output 
case dataflow regular processing fully pipelined 
compressed ip memory tag bit addressing pointed earlier due low network activity decaying characteristics ip values ip values negligible 
illustrated fig 
saving memory location ip value matter relevant compressed ip memory stores non negligible ip values 
optimization memory organization combined tag bit addressing scheme advantages smaller memory size efficient memory access crucial simulation complex networks 
ip memory uncompressed layer ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip layer ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip ip valid internal potential internal potential internal potentials stored ip memory 
ip value holds fixed memory location relevant stored 
neuron unit neuron unit may perform steps decay propagate output fully pipelined processing units parallel 
pipelining possible dataflow regular 
data processed time slice ip ip tags completely available time slice 
case connection unit accumulated weighted spikes ip previous time slice 
neuron unit simply needs add accumulated ip tags neuron unit connection unit decay propagate output time slice event list list ip memory compressed source neuron source neuron layer ip ip ip ip ip ip 
layer ip ip ip ip ip ip 
layer ip ip ip ip ip ip processing time workshop virtual intelligence dynamic neural networks stockholm weights ip decayed ip values 
done consecutively starting ip value layer ip value layer 
doing ip value processed pipelined ip values combined membrane potential program code exceeds dynamic threshold address corresponding neuron source neuron sent spike event list 
illustrated fig 
neuron unit consists neuron chip responsible processing memories store ip values ip tags network parameters 
network parameters contain parameter set programmable neuron see subsection 
layer consists neurons equal properties network parameter memory accessed layer 
hand ip memory ip tag memory need accessed constantly 
achieve high system speed parallel processing desirable 
means ip values ip tag values accessed clock cycle ips need read connection unit 
demand high io bandwidth neuron chip 
values addresses ip values ips contribute requirement high io bandwidth 
example complex network neurons ip values bitwidth bit 
soon required io bandwidth exceeds bandwidth achievable asics bandwidth asics bound limited number pins 
embedded dram technology attractive alternative 
chip memory exhibits virtually unlimited bandwidth 
compressed ip memory concept attractive embedded dram design memory capacity saved 
area major concern extremely expensive technology expensive design design computation far complex networks fabricated 
unfortunately costs embedded dram technology currently prohibitively high small volume designs 
pci bus pci interface source neuron spike event list ip memory connection chip neuron unit ip ip tags internal structure connection unit neuron unit employing weight caching compressed ip memory concept 
compressed organization ip memory exhibits advantages chip memories memory capacity concern 
reading ip values different addresses different memory devices wide word consisting relevant ip values easily accessed memory device simply incrementing address pointer 
compressed ip memory facilitates memory access 
storing ip values causes problem assignment certain ip value certain memory location lost see fig 

information obtained ip value stored location memory 
store address ip value memory solution ip value extra value need accessed memory resources massively wasted 
elegant way extraction address ip tag bits 
tag bits contain information ip value valid valid address valid ip values decode tag bits ip values accessed consecutively 
assuming average validity ip values mean average bits ip value need transferred obtain ip address 
small value considering complex network neurons ip values requires bitwidth bit absolute ip address 
tag bits handled neuron unit anyway prevent computation irrelevant data extra resources required kind address encoding 
neuron unit described subsection exhibits high efficiency pe fully pipelined processing elements due concept weight caching 
furthermore concept compressed ip memory conjunction tag bit addressing scheme reduces io bandwidth requirements neuron chip 
neuron chip ip mem tag mem ip ip mem tag mem 
tag mem tag memory net par memory connection unit weight memory workshop virtual intelligence dynamic neural networks stockholm connection unit illustrated fig 
connection unit receives source neuron addresses supplies ips accumulated weights ip tags 
ip tag bits label corresponding ip values valid ip tag valid ip tag 
fig 
internal structure connection unit depicted 
major components connection unit weight memory copies complete compressed ip memory connection chip 
copies ip memory called weight caches serve accumulation weights time slice 
functional roles 
weight cache receiver 
connection list receives weights corresponding target address 
target address corresponds certain memory location weight cache 
relevant value stored location ip tag weight needs added value 
weight simply written location ip set 
corresponding weights accumulated appropriate location weight cache 
weight cache functions sender 
ip tag reads relevant ip values sends neuron unit 
weight caches switch roles time slice time slice preprocess data received connection list time slice supply data neuron unit 
weight cache performs exactly opposite operation 
advantage concept ip values generated time slice ahead allow parallelization steps decay propagation output 
major benefit io bandwidth requirements neuron chip reduced sending weight target neuron address separately see fig 
accumulated ip value needs transferred 
example neuron receives spikes time slice sending weight corresponding target address separately times sends ip value tag bits 
reduction bandwidth requirements neuron chip achieved employing efficient tag bit addressing scheme obviously advantages extra complexity connection unit mainly weight caches peripheral logic 
fast may weight caches logic function needs implemented simple read accumulate write action 
high connectivity performance weight caches bottle neck system need designed carefully 

performance evaluation concept weight caching compressing ip memory lead speed compared system organization fig 
steps compute snn may performed parallel 
ideally speed factor 
assumes steps require processing time 
reality case step longest processing time determine duration computation time slice 
reasonable assume order magnitude processing time steps 
system organization allows fully pipelined processing neuron function neuron chip 
ideal case processing element throughput ip value performing decay propagation output clock cycle 
assuming architecture employing neuron chip processing elements performance estimation previously mentioned network rei yields results stated tab network complexity neurons ip values 
number neurons number ips ultra sparc mhz pe pentium ii mhz pe alpha mhz pe mhz pe cm mhz mhz pe mhz pe ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms ms avail 
ms avail 
ms ms table performance architecture compared various hardware platforms real time requirement time slice ms 
values marked estimated values measured assumption max 
network activity valid ips 

efficiency tag bit addressing scheme depends course number ip relevant 
small number relevant tag bit scheme inefficient 
matter case bandwidth requirements extremely small anyway 

learning considered 
workshop virtual intelligence dynamic neural networks stockholm 
neuron model system discussed 
typical characteristics spiking neural networks outlined basic concepts design pointed 
novel concepts accelerator architecture spiking neural networks proposed weight caching compressed internal potential memory 
cost additional memory units weight caches concepts weight caching allow parallelization computing spiking neural networks leads speed 
furthermore weight caching admits regular dataflow opposed naturally irregular dataflow due unpredictable spike events previous systems 
regular dataflow facilitates computation fully pipelined processing feasible 
concept compressed internal potential memory simplifies memory access 
attractive concept designs memory expensive chip memory embedded dram required capacity memory storing internal potentials reduced 
chip memory attractive accelerators spiking neural networks computation 
weight caching compressed internal potential memory previously applied concepts event list protocol sender oriented connection list fixed point arithmetic neglecting irrelevant internal potentials constitute backbone proposed memory optimized accelerator spiking neural networks 
estimated performance compared performance variety hardware platforms suggests may perform real time simulation simple neurons fully pipelined processing elements 
currently detailed specification system elaborated 

acknowledgments ulrich ulrich thomas geiger providing simulation results 

eck eckhorn bauer jordan kruse munk ck coherent oscillations mechanism feature linking visual cortex biological cybernetics 
eck eckhorn feature linking stimulus evoked oscillations experimental results cat visual cortex functional implication network model proc 
icnn 
fra frank hartmann artificial neural network accelerator pulse coded model neurons proceedings international conference neural networks icnn perth 
ger gerstner spiking neurons pulsed neural networks bishop eds mit press 
gra gray singer stimulus specific neuronal oscillations orientation columns cat visual cortex proc 
natl 
acad 
sci 
usa 
har hartmann frank schaefer wolff spike accelerator dynamic simulation large pulse coded networks proceedings th international conference microelectronics neural networks evolutionary fuzzy systems dresden pages 
jahnke roth simd dataflow architecture neurocomputer spike processing neural networks pages 
jahnke roth schoenauer digital simulation spiking neural networks pulsed neural networks bishop eds mit press 
wawrzynek silicon auditory processors computer peripherals advances neural information processing systems 
mal malsburg correlation theory brain function internal report mpi 
reprinted models neural networks ii domany 
eds springer pages 
sch eckhorn philips universit marburg internal communication 
wei eckhorn contour segmentation recurrent neural networks pulse coding neurons sommer pauli computer analysis images patterns caip kiel springer verlag 
