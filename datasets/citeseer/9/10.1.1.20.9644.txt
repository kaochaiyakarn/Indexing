appear computer animation simulation eurographics series 
vienna austria springer verlag 
requirements architecture embodied conversational characters cassell bickmore campbell chang yan gesture narrative language group mit media laboratory ames st cambridge massachusetts justine bickmore hannes media mit edu describe computational architectural requirements systems support real time multimodal interaction embodied conversational character 
argue primary design drivers real time multithreaded entrainment processing interactional propositional information approach functional understanding human face toface conversation 
architecture meets requirements initial conversational character developed capable increasingly sophisticated multimodal input output limited application domain 
research computational linguistics multimodal interfaces computer graphics autonomous agents led development increasingly sophisticated autonomous semi autonomous virtual humans years 
autonomous self animating characters sort important production animation interfaces computer games 
increasingly autonomy comes underlying models behavior intelligence simple physical models human motion 
intelligence increasingly refers just ability reason social ability engage human interesting relevant conversation appropriate speech body behaviors 
research concentrates type virtual human social linguistic abilities carry face face conversation call embodied conversational agents 
embodied conversational agents may defined properties humans face face conversation including ability recognize respond verbal non verbal input ability generate verbal non verbal output 
conversational functions turn feedback repair mechanisms 
performance model allows negotiation conversational process contributions new propositions discourse 
current grows experience developing prior systems animated conversation ymir 
animated conversation system automatically produce context appropriate gestures facial movements intonational patterns animated agents deep semantic representations information provide real time multimodal interaction user 
ymir system focused integrating multimodal input human user appear computer animation simulation eurographics series 
vienna austria springer verlag 
including gesture gaze speech intonation capable limited multimodal output real time animated character called gandalf 
currently developing conversational character architecture integrates real time multimodal aspects ymir deep semantic generation multimodal synthesis capability animated conversation 
believe resulting system provide reactive character nuances human face conversation intuitive robust 
believe system provides strong platform continue development embodied conversational agents 
motivation number motivations developing conversational character interfaces including intuitiveness 
conversation intrinsically human skill learned years development practiced daily 
conversational interfaces provide intuitive paradigm interaction user required learn new skills 
redundancy modality switching embodied conversational interfaces support redundancy complementarity input modes 
allows user system increase reliability conveying information modality increase expressiveness modality type expression suited 
social nature interaction 
computers look human people attribute human properties friendliness 
embodied conversational interface take advantage prompt user naturally engage computer human conversation 
interface designed reply conversation interaction may improved 
summary salient features human face toface conversation drive design architecture able control animated character participates effectively kind interaction 
architecture developing meet requirements describe conversational character constructed architecture rea 
human face face conversation embodied conversation relies number different modalities speech prosody hand gestures facial expression head movements 
speaker employs channels parallel combining modalities needed appropriate elaboration listener simultaneously produces multi modal feedback responses similar way 
speaker listener accomplish switching roles sequence overlapping turn behaviors parallel nature communication channels short timescales relevant behaviors provide seamless transition 
behaviors directly contribute content delivery organization conversation termed conversational behaviors surface form appear computer animation simulation eurographics series 
vienna austria springer verlag 
exchange 
typical conversational behaviors include head nods glances side raising eyebrows speaking 
important identify functions conversational behaviors serve 
typical discourse functions include conversation initiation giving turns giving requesting feedback breaking away 
conversational behavior contribute realization different discourse functions discourse function implemented different combinations conversational behaviors 
example head nods indicate agreement simply attention indicate agreement listener may nod say uh huh clarify type roles discourse functions serve contribution conversation divided propositional information interactional information 
propositional information corresponds content conversation includes meaningful speech gestures facial expression head movements intonation complement elaborate speech content 
interactional information consists cues affect conversational process includes range nonverbal behaviors regulatory speech huh 
uh huh 
architectural requirements construction computer character effectively participate face toface conversation described requires control architecture features multi modal input output humans face face conversation send receive information gesture intonation gaze speech architecture support receiving transmitting information 
real time system allow speaker watch feedback turn requests listener send time various modalities 
architecture flexible track different threads communication ways appropriate thread 
different threads different response time requirements feedback interruption occur sub second timescale 
architecture reflect fact allowing different processes concentrate activities different timescales 
understanding synthesis propositional interactional information dealing propositional information requires building model user needs knowledge 
architecture include static domain knowledge base dynamic discourse knowledge base 
presenting propositional information requires planning module plan multi sentence output manage order presentation interdependent facts 
understanding interactional information hand entails building model current state conversation respect conversational process current speaker listener listener understood speaker contribution 
conversational function model explicitly representing conversational functions provides modularity principled way combine different modalities 
functional models influence architecture core modules system operate exclusively functions sentences example modules edges system translate input functions functions outputs 
produces symmetric appear computer animation simulation eurographics series 
vienna austria springer verlag 
architecture functions modalities input output 
related researchers built embodied multimodal interfaces add dialogue discourse knowledge produce natural conversational characters 
example olga embodied humanoid agent allows user employ speech keyboard mouse commands engage conversation microwave :10.1.1.13.3458
olga distributed client server architecture separate modules language processing interaction management direct manipulation interface output animation communicating central server 
olga event driven responds user input unable initiate output 
addition olga support non speech audio computer vision input modalities 
olga uses linear architecture data flows user input agent output passing internal modules 
nagao takeuchi suggest different approach 
conversational agent subsumption architecture rodney brooks 
case agent horizontal decomposition task achieving behavior modules 
modules compete see behavior active particular moment 
global conversational state model conversational interaction arises interplay different behavioral layers 
agent responds speech gaze information coordination input analysis output generation emergent behavior precise control impossible 
result user input agent output decomposed task behaviors conversational function 
lester generate verbal non verbal behavior producing deictic gestures choosing referring expressions function potential ambiguity objects referred proximity objects animated agent 
system understanding achieved objects physical space animated agent utility deictic gestures reducing potential ambiguity 
generation gestures choice referring expressions library voice clips accomplished entirely independent additive processes description interaction modalities 
likewise rickel johnson pedagogical agent move objects virtual world inhabits generate deictic gesture verbal explanation agent provides object 
badler concentrated smooth natural behaviors virtual humans exist virtual environment interact converse virtual characters 
digital actors particular begun address challenges mapping human facial conversational behaviors graphical characters 
demands virtual spaces quite different embodied character respond characters real humans 
issues involved generating appropriate realistic conversational behaviors similar 
current approach derives previous student research group ymir architecture 
main emphasis development multi layer multimodal architecture support fluid face face dialogue appear computer animation simulation eurographics series 
vienna austria springer verlag 
human graphical agent 
agent gandalf recognized displayed interactional information gaze simple gesture produced propositional information form canned speech events 
way able perceive generate turn backchannel behaviors lead natural conversational interaction 
provided example verbal non verbal function paired conversational multimodal interface 
gandalf limited ability recognize generate propositional information providing correct intonation speech emphasis speech output gesture occurring speech 
contrast animated conversation system automatically generated context appropriate gestures facial movements intonational patterns 
case domain conversation artificial agents emphasis production non verbal propositional behaviors emphasized reinforced content speech 
system run real time interaction real user interactional information limited 
approach combines lessons learned gandalf animated conversation projects 
section conversational function architecture developing embodied conversational interfaces 
describe rea conversational humanoid architecture 
conversational humanoid architecture previous experience animated conversation ymir developing architecture handles real time response interactional cues deep semantic understanding generation multimodal inputs outputs high level architecture partitioned input manager responsible collecting inputs modalities action scheduler responsible synchronizing output actions modalities components handle real time interactional functions longer term deliberative responses content understanding synthesis 
full breakdown architecture shown 
modules communicate kqml speech act inter agent communication protocol serves system modular extensible 
modules architecture described 
modules input manager input manager obtains data various input devices converts form usable modules system routes results understanding module 
interactional information forwarded directly reaction module minimize system response time 
architecture developed conjunction conversational characters project fuji xerox palo alto laboratory 
appear computer animation simulation eurographics series 
vienna austria springer verlag 
input devices body gaze gesture motion input manager understanding module knowledge base reaction module response planner discourse model fig 

detailed conversational character input manager typically receive information devices provide speech text user gesture location gaze information modalities 
cases features sent input manager time stamped start times milliseconds 
current implementation input manager bundles input events aggregate semantic representations user utterance accompanying gestures understanding module process 
understanding module understanding module responsible fusing input modalities coherent understanding user doing 
understanding module receives inputs input manager access knowledge application domain static knowledge base current discourse context discourse model help interpret inputs 
example user gestures character speaking interpreted wanting turn function gesture detected user speaking taken speech accompanying gesture 
reaction module reaction module responsible action selection component architecture determines character doing moment time 
reaction module receives asynchronous updates input manager understanding module uses information domain static knowledge base current discourse state determine action perform 
reaction module currently responds interactional cues set states 
system starts state remains user detected time transitions 
user character exchanged greetings similar cues system transitions turn represented states 
conclude state handle user interruptions character allowing continue phrase boundary giving turn back user 
interrupt state entered system detects user turned away 
anticipate adding states explore multi sentential mixed initiative dialog 
response planner module response planner responsible formulating sequences actions need executed execution cycles carry desired communicative task goals 
plans generation module action scheduler output devices animation speech device appear computer animation simulation eurographics series 
vienna austria springer verlag 
generation module generation module responsible realizing discourse functions output reaction module producing set coordinated primitive actions speech gesture generation facial expression sending actions action scheduler performance monitoring execution 
action scheduling module action scheduler motor controller character responsible coordinating output actions lowest level 
takes set atomic commands executes synchronized way 
accomplished event conditions specified output action define action executed 
fulfillment architectural requirements feel architecture described meets requirements embodied conversational character participate face face conversation human 
capable reacting producing inputs outputs multiple modalities mapping specific features modalities conversational functions uniform knowledge representation format kqml system 
run real time providing immediate responses interactional cues decoupling processes content understanding synthesis take seconds response time 
architecture able interactional propositional information fact kqml frames implementation slots kinds input interpretations output specifications 
presence understanding generation modules architecture specifically enable separation channel specific features conversational functions allowing reaction response planning modules deal entirely functional level abstraction 
common kqml representation coupled disciplined functional descriptors allows system extensible respect input output modalities modular respect plugging new modules implement alternative theories discourse 
implementation rea real estate agent instantiation architecture described 
rea computer generated humanoid fully articulated graphical body sense user passively cameras audio input capable speech facial display gestural output 
system currently consists large projection screen rea displayed user stands front 
cameras mounted top projection screen track user head hand positions space 
users wear microphone capturing speech input 
single sgi octane computer runs graphics conversation engine rea computers manage speech recognition generation image processing 
system implemented clips rule expert system programming language 
appear computer animation simulation eurographics series 
vienna austria springer verlag 
sample interaction rea domain expertise real estate acts real estate agent showing users features various models houses appear screen 
excerpt sample interaction lee approaches projection screen 
rea currently turned side gazing 
lee moves range cameras rea turns face says hello name rea hi lee looking place near mit rea replies house briefly looking away pondering 
sounds tell house 
picture house appears onscreen rea nice large garden rea says producing curved gesture indicating fig 

user interacting rea garden surrounds house 
rea continues bedrooms large kitchen lee raises hands space indicating intention take turn rea yields turn lee 
tell bedrooms lee says 
image showing master bedroom appears master bedroom furnished poster bed bathroom 
lee says interrupting rea mid sentence 
bedroom rea replies placing hands close show adjacency arrangement 
house tour continues rea able describe features house responding users verbal non verbal input 
user cues typically associated turn behavior gesturing rea allows interrupted takes turn able 
able initiate conversational repair user says generate combined voice gestural output 
rea speech gesture output generated real time 
descriptions houses shows gestures uses indicate describe houses generated spud natural language generation engine modified generate natural gesture 
input sensors input manager currently receives types input gesture input vision software uses video cameras track flesh color produce position orientation head hands updates second 
audio input simple audio processing routine detects onset pauses cessation speech 
grammar speech recognition speech piped pc running ibm returns text set phrases defined grammar 
data sent input manager time stamped start times milliseconds 
various computers synchronized milliseconds ntp network time protocol clients 
synchronization key associating verbal nonverbal behaviors 
low level gesture audio detection events sent reaction module immediately 
events appear computer animation simulation eurographics series 
vienna austria springer verlag 
stored buffer recognized speech arrives high level multimodal kqml frame created containing mixed speech audio gesture events 
sent understanding module interpretation 
output system multi modal real time requirements call careful design output system 
particular conversational character needs perfect coordination speech nonverbal behavior gesturing 
slightest mismatch look unnatural fact convey different intended 
modularity extensibility requirement enforced defined interfaces various components output system inspired implementation plug style motor skill mechanism 
output system consists main components scheduling component animation component rendering component 
scheduler receives requests activation various behaviors generation module 
requests include interdependencies behaviors requirements behavior finishing starts 
scheduler responsible successfully sequencing pending behaviors 
animator assigns behavior ready executed motor skill responsible animating joints model communicating renderer 
scheduler behavior description preconditions manner execution sent scheduler kqml message 
generation module typically sends scheduler set behaviors properly triggered meant carry single function invitation start conversation 
scheduler instructed notify generation module kqml callback messages certain events occur completion output behavior sequence 
execution behavior scheduler event driven difficult accurately predict output behavior execution timings making impossible plan completely synchronized execution sequences advance 
addition behaviors produce meaningful events executed speech synthesis behavior produce event word produced behavior scheduling animation rendering event callback action scheduler motor skill manager motor skill motor skill motor skill arbitrator body model callback speech fig 

layers output system scheduling animation rendering 
appear computer animation simulation eurographics series 
vienna austria springer verlag 
allow behaviors started stopped events occur 
shows example event driven plan executed action scheduler dependencies individual behaviors 

look away 
look user 

ready right hand 

beat 
peak 

building boston 
high gesture 
peak building 
relax right hand time indicates precondition event indicates precondition plus delay event fig 

example synchronized speech gesture output action scheduler 
specification sent action scheduler contains description individual behavior executed content clause precondition start behavior clause optional symbolic label id preconditions behaviors 
shows kqml input specification plan shown 
action id away immediate content cmd away object user action id offset event away time content cmd object user action id event content speak content action event start content cmd ready action event word content cmd beat action id bldg offset event cond time content speak content building boston action event bldg word content cmd compose trajectory hand bend action event bldg content cmd relax fig 

action scheduler kqml input specification plan shown 
action scheduler works managing set primitive behavior objects represents set animations right arm gestures 
behavior commanded start acquires body degrees freedom dof requires set right arm hand joints 
goes starting phase perform initialization moving arm ready position 
behavior actions carried update phase ends behavior reaches natural stopping point explicitly commanded behavior preempts grabbing appear computer animation simulation eurographics series 
vienna austria springer verlag 
dofs 
returning idle behavior go phase perform operations needed returning arm rest position 
animator scheduler non verbal behavior ready execution passes description animator 
actions involving character body executed directly example verbal behavior sent speech synthesizer 
animator checks motor skill manager see motor skill capable handling request registered 
task animating joints model broken separate motor skills part different skills called different methods animation 
motor skills range straight forward ones executing single head nod elaborate ones employing inverse kinematics pointing objects playing key frame animation 
motor skill activated asks arbitrator body dofs needs modify 
skills ask dof higher priority captures 
depending implementation particular skills losing skill keep trying capture dof 
feature useful instances continuous behavior momentarily interrupted instantaneous character tracking user gaze gets asked glance away higher priority 
glance completed tracking automatically resumes 
arbitrator responsible keeping track dofs allocating skills request 
skills access information environment including virtual objects perceived user position shared world 
motor skills controlling facing accept names objects parameters 
renderer rendering engine abstracted away animator introducing layer essentially maps dof name corresponding model transformation 
implemented interfaces vrml scene graph rendered tgs 
naming character dofs follows anim vrml humanoid specification compatibility 
argued new approach intelligence autonomy needed design virtual humans autonomous animated characters 
approach goes insights reasoning offered classical ai focus believability advocated classical graphical animation 
new approach autonomy comes underlying models social linguistic intelligence allow autonomous animated agents able carry realistic conversations humans speech visual modalities 
argue nature human face face communication imposes strong requirements design embodied conversational characters described architecture satisfies requirements 
demonstrated approach rea system 
increasingly capable making intelligent content oriented propositional contribution conversation rea sensitive regulatory interactional function verbal nonverbal conversational behaviors capable producing regulatory behaviors appear computer animation simulation eurographics series 
vienna austria springer verlag 
improve interaction helping user remain aware state conversation 
rea embodied conversational agent hold interaction 
implementing multimodal embodied conversational characters complex undertaking extensive research agenda conversational competencies add improve 
reliable components system individual modality feature detectors continuing refine extend provide user gaze direction facial expression gestural form 

azarbayejani wren pentland real time tracking human body 
proceedings image com bordeaux france may 

badler parameterized action representation virtual human agents 
proceedings st workshop embodied conversational characters 

mcglashan olga conversational agent gestures proceedings ijcai workshop animated interface agents making intelligent nagoya japan august 
brooks robust layered control system mobile robot 
ieee journal robotics automation 


cassell pelachaud badler steedman beckett douville prevost stone animated conversation rule generation facial display gesture spoken intonation multiple conversational agents 
computer graphics siggraph proceedings 

cassell th risson power nod glance envelope vs emotional feedback animated conversational agents 
journal applied ai press 

lester towns fitzgerald deictic emotive communication animated pedagogical agents 
proceedings workshop embodied conversational characters 


nagao takeuchi social interaction multimodal conversation social agents 
proceedings th national conference artificial intelligence aaai seattle wa august aaai press mit press vol 


reeves nass media equation people treat computers television new media real people places 
cambridge university press 

rickel johnson task oriented dialogs animated agents virtual reality workshop embodied conversational characters 
proceedings workshop embodied conversational characters 


specification standard vrml 
ece uwaterloo ca spec html 
stone modality dialogue planning pragmatics computation 
phd thesis university pennsylvania 

thalmann escher 

face virtual face 
proceeding ieee 

th risson communicative humanoids computational model psychosocial dialogue skills 
phd thesis mit media laboratory 
