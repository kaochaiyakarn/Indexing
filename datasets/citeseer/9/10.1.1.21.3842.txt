learning match cluster entity names william cohen jacob richman com whizbang com whizbang labs school computer science henry st carnegie mellon university pittsburgh pa pittsburgh pa information retrieval large part study methods assessing similarity pairs documents 
document similarity metrics tasks including ad hoc document retrieval text classification yc summarization gc 
problem area similarity metrics central record linkage ka wishes determine database records taken different source databases refer entity 
instance wish determine database records different hospitals containing patient name address insurance information refer person example wish determine bibliography records containing title list authors journal name refer publication 
examples practical cases record fields contain text person names titles 
natural ask document similarity metrics developed ir community useful matching clustering entity names 
substantial amount addressing question 
somewhat surprisingly traditional ir document similarity metrics experimentally useful comparing short documents informal names entities 
tf idf similarity metrics shown competitive superior hand coded similarity metrics string metrics variety domains ranging bibliographic scientific papers names animal species popular movies 
tf idf similarity accurate similarity metric fastest reasonable metric usefully applied combination computationally expensive similarity tests 
propose describe techniques adaptively modifying document similarity metrics 
evaluate techniques entity matching entity clustering tasks particular evaluate learned similarity metrics combination simple tf idf distance schemes 
hope learned distance metrics improve generalpurpose task independent distance metrics tf idf ultimately provide performance comparable engineered domain specific distance metrics entity matching schemes hs gfs 
evaluation solely context entity name matching clustering conjecture similar learning methods useful tasks involving document similarity metrics document retrieval summarization classification clustering 
precisely define problem algorithm experimental results 
discuss related concluding remarks 
adaptive matching clustering methods formally defining problems adaptive matching clustering 
formal preliminaries 
general learning setting assume source training example pairs problem instance solution loss function loss measuring quality proposed solution relative optimal intended solution 
prototypical example binary classification learning taken set binary vector loss different loss 
object learning system take set training examples xm ym learn propose solutions novel problems xj 
ways formalizing goal precisely 
goal prove deep theorems adaptation simply motivate precisely describe particular class adaptive systems adopt simple notion goodness 
imagine repeated game time step learner receives problem instance xi proposes solution yi sees desired solution yi 
step learner suffers penalty loss yi yi 
say system converges steps sequences xn yn cumulative value loss yi yi zero 
adaptive matching 
consider adaptive systems problem instances solutions somewhat complex case supervised learning 
adaptive matching formalize task learning match names domain names second domain example wish learn match researcher name address university name exactly researcher affiliated university 
formalize problem instance pair sets strings 
instance names addresses researchers registered sigir names universities 
solution set pairs ai bj specifically subset indicates pairs matched 
natural loss function loss size symmetric difference 
experiments consider measures recall precision measure relative 
matching problems constrained suggested 
case intended match refer entity example matching names addresses sigir researchers entries phone book 
entity names name refers distinct entity little sense proposed solution contain 
consider constrained adaptive matching problem proposed pairing required toone 
adaptive clustering 
second problem consider adaptive clustering 
case set strings di intended assignment strings clusters encoded function integer 
candidates loss function loss 
obvious constraint loss function depend cluster names permuting values dj shouldn change loss relative intended assignment 
convenient choice define loss number pairs disagree placed cluster 
stated way pairs 
define loss size symmetric difference pairs pairs related measure recall precision measure 
definition loss closely related cost function pairs clustering bh 
natural variation problem number clusters known 
case simply problem instance pair 
call variation adaptive clustering 
relationships matching clustering learning similarities 
formulated problem close connections adaptive clustering adaptive matching classification learning 
instance simple natural reductions problems 
observation constrained adaptive matching reduced clustering 
specifically adaptive clustering algorithm lc converges steps construct constrained adaptive matching algorithm lm converges steps 
desired match function written 
assume numbering elements integer 
construct matching algorithm convert matching instance clustering instance follows union pair pair pair 
intuitively pair cluster named element element mapped cluster cluster unmatched elements numbered 
clearly training lc produce clustering new instance reconstruct pairing noted unconstrained matching reduced clustering procedure absent constraints pairs overlap arbitrary ways clusters pairwise disjoint 
observation 
adaptive clustering reduced adaptive matching 
specifically adaptive clustering algorithm lm converges steps construct constrained adaptive matching algorithm lc converges steps 
idea reduction pair objects iff belong cluster 
detail clustering instance converted matching instance pairs 
examples train lc 
training clustering problem instance converted matching problem instance cluster derived proposed set pairs assume zero loss finding associated cluster trivial instance create cluster connected component set pairs 
note close relationship adaptive matching binary classification learning 
clear introduce idea staged classification learning learner forced step classification predictions set objects single object 
precisely consider adaptive system problem instance vector objects xk solution vector bits yk loss just hamming distance 
easy see adaptive matching reduced minor variation classification learning observation 
adaptive matching reduced staged classification learning 
reduce adaptive matching staged classification learning convert matching instance pair follows vector containing pairs pair corresponding component proposed pair 
observation suggests adaptive matching clustering implemented supervised learning learn pairing function function mapping pair indicating matched placed cluster 
note ordinary supervised learning reduced adaptive matching observation 
supervised learning reduced adaptive matching 
reduce adaptive matching staged classification learning convert learning instance class matching problem contains single pair class 
differences 
simple natural reductions show problems learning constrained adaptive matching adaptive clustering sense equivalent particular perfect zero loss solution problem perfect solution 
zero loss solutions achievable practice 
closer examination shows non zero losses enlarged dramatically decreased dramatically reductions 
instance consider adaptive matching system derived adaptive clustering system observation imagine case intended pairing empty 
suppose clustering algorithm places ai cluster constant function 
associated pairing cluster loss loss cluster pairs token consider adaptive clustering system derived adaptive matching system observation consider problem instance dn intended clustering place item cluster di pairing proposed matching system dn dn 
specify construct cluster pairing remarks notice pairing zero loss correspond correct clustering mapping trivial 
creating cluster connected component pairing graph lead cluster pairs contains pairs loss loss matching system reductions tight respect loss ones associated observations adaptive matching supervised learning 
additional loss suffered constrained adaptive matching system supervised learning system 
remarks 
summarize noted problems adaptive matching clustering superficially similar supervised learning 
similarities strong show solution problem necessarily solution obvious similarities supervised learning strong show supervised learning system necessarily perform adaptive clustering constrained adaptive matching 
remainder experimentally evaluate adaptive matching clustering systems supervised learning classify pairs entity names 
proposed algorithm adaptive matching clustering observations suggest adaptive matching clustering implemented learning appropriate pairing function function predicts matched clustered approach practical issues need addressed 
issue cost evaluating learning pairing function quadratic impractically large 
techniques known blocking finding subset pairs matched 
canopy method proposed mccallum nigam unger 
canopy assumes easy compute distance metric dist thresholds tight loose loose tight summarized follows 
empty set 

set objects computed 

empty pick random 
add pairs dist loose 
remove points dist tight 
output procedure set 
learning train pairs set evaluation assume pair set 
dist cosine distance tokenized version entity name :10.1.1.34.4329
finding sets points steps done quickly ranked retrieval search 
far ignored fact practical learners give prediction give numerical confidence interpretable probability matched denote confidence 
issue addressed pairs accepted learned pairing function need obey necessary constraints constraints associated constrained adaptive matching constraint cluster size clustering 
enforce constraints constrained adaptive matching build graph vertices entity names edges weighted confidence classification learner compute minimal weight cutset graph 
experimented greedy approach exact minimization exploits fact graph bipartite sl 
experiments simple greedy approach 
enforce cluster size constraint build analogous graph vertex set perform greedy agglomerative clustering gac 
implementation gac follows 
initially singleton cluster created hold element 
repeatedly merges closest clusters distance clusters defined minimum distance cluster members clusters remain 
summarize proposed algorithm 
train set clustered matched datasets 
run canopies algorithm dataset generate set 

pair set label positive iff cluster respectively matched 
add labeled pairs training set 
train classifier training set obtain classifier denote confidence classifier pair 
cluster match dataset result training 
run canopies algorithm obtain set 

pair set compute creating graph vertex set edge weights 

perform greedy agglomerative clustering graph respectively find minimal weight cutset return result 
experimental results explored different instantiations adaptive matching clustering algorithm proposed 
different classification learning systems different feature sets representing pairs 
report results maximum entropy learner dlr 
features encode pair shown 
datasets multiple fields bibliographic name address pairs features extracted field 
considered baselines performance 
replaces graphs fixed string edit distance 
specifically compute edit distance uniform costs character insertion deletion 
clustering similar algorithm proposed mccallum nigam unger 
second baseline replaces tf idf distance formula 
true iff strings substring 
true iff strings prefix 
feature true iff edit distance strings true iff th token matches token feature computed possible value analogous 
requires tokens match token computed possible values analogous 
true iff jaccard distance sets tokens 
jaccard distance sets 
computed thresholds 
true contain number 

features learning pairing function datasets evaluation purposes 
summarized table 
clustering dataset cora collection citations cora project 
second dataset collection organization names 
nick providing data 
consider clusterings data clusters clusters difference second clustering different branches organization example virginia institute blacksburg virginia polytechnic institute charlottesville considered distinct 
constrained matching datasets 
restaurant dataset contains restaurants restaurant guide matched second guide 
sheila tejada providing data 
parks dataset contains national park names listing second listing names common 
clustering domains split sizes clusters canopy settings tight loose potential positive negative recall pairs pairs cora matching domains split sizes pairs canopy settings tight loose potential recall positive negative pairs pairs restaurant park names table 
experimental domains 
datasets constrain systems adaptive non adaptive produce true number clusters pairings 
cora wished compare best previous clustering result obtained exploring variety cluster sizes 
tried values report gave best value obtained constraining system create times true number clusters evaluate algorithms variation fold cross validation 
split data partitions trained tested second trained second tested 
report precision recall results partition 
keep partitions separate split data algorithm considers pairs set produced canopy algorithm consider pair containing instance test set instance training set 
implies training set instance loose test set instance 
disadvantage procedure impossible create balanced splits biasing results away adaptive methods 
results experiments shown table 
record dataset number entity names partition number desired clusters pairs thresholds canopy algorithm maximum recall obtainable produced canopy algorithm number positive negative example pairs learner 
tfidf edit distance adaptive 
recall 
recall 
recall cora restaurant parks table 
experimental results 
results cora edit distance 
baseline results edit distance taken hand tuned edit distance report results set 
problem best obtained measure placed bold 
partitions adaptive method obtains results comparable better best baseline approaches 
conjecture relatively poor performance adaptive system due variation partitions training testing 
related formalization adaptive clustering matching inspired model learning order cohen schapire singer css 
consider adaptive systems example set objects ordered intended ordering show problem solved supervised learning binary ordering relation followed greedy method constructing total order set possibly inconsistent binary ordering decisions 
give provable bounds loss system 
finding bounds adaptive clustering learning remains problem 
architecture adaptive matching clustering method modeled system nigam mccallum unger 
system consider matching clustering importantly replace fixed hand coded edit distance metric learned pairing function 
focus general purpose adaptive clustering matching methods distinguishes previous general purpose non adaptive similarity metrics entity names hs general frameworks manually implementing similarity metrics gfs 
core idea learning distance functions entity pairs new substantial literature record linkage problem statistics ka record linkage theory proposed sunter fs 
maximum entropy learning approach advantage sunter require features independent allowing broader range potential similarity features 
com start implemented matching procedure maximum entropy learner 
extend systematic experimental evaluation canopies eliminate potentially quadratic cost matching application pairing function clustering constrained matching 
concluding remarks new scalable adaptive scheme clustering matching 
experimental results method comparable better clustering matching plausible fixed distance metrics 
number enhancements current method possible 
hope examine features instance notable current omission lack feature directly measures tfidf similarity 
features useful bs performance improved adding features word types 
process adding features locations names common words 
hope explore approaches adaptation 
hope investigate robustness method respect size training data number clusters explore semisupervised learning approaches 
dlr dempster laird rubin 
probabilistic models document retrieval relevance information journal royal statistical society pages 

anderberg 


cluster analysis application 
academic press 
bh 
buhmann hofmann 
central pairwise data clustering competitive neural networks 
cowan tesauro alspector editors advances neural information processing systems pages 
morgan kaufmann san francisco ca 
bs borthwick sterling agichtein grishman 

nyu description mene named entity system muc 
proc 
seventh message understanding conference muc fairfax va april may 
cohen 

data integration similarity joins word information representation language acm transactions information systems july pp 
css cohen schapire singer 

learning order things journal ai research volume pages 
dlr dempster laird rubin 
probabilistic models document retrieval relevance information journal royal statistical society pages 

fs sunter 
theory record linkage 
journal american statistical society 
gc goldstein carbonell 
mmr diversity reranking document reranking summarization 
proceedings th workshop language technology multimedia information retrieval pages enschede netherlands 
gfs galhardas florescu shasha simon 

ajax extensible data cleaning tool 
proceedings acm sigmod june 
gdalyahu weinshall 
randomized algorithm pairwise clustering advances neural information processing systems kearns solla cohn eds vol 
mit press usa 
hs hernandez stolfo real world data dirty data cleansing merge purge problem journal data mining knowledge discovery pp 
ka alvey editors 
record linkage techniques 
statistics income division internal revenue service publication 
available www gov lawrence giles bollacker 

autonomous citation matching proceedings third international conference autonomous agents seattle washington may acm press 
monge elkan 
field matching problem algorithm applications 
proceedings second international conference knowledge discovery data mining august mccallum nigam rennie seymore 

automating construction internet portals machine learning 
information retrieval 
mccallum nigam ungar 

efficient clustering high dimensional data sets application matching 
knowledge discovery data mining pages 
salton 

automatic text processing transformation analysis retrieval information computer addison wesley 
sl baier lucchesi 
matching algorithms bipartite graph technical report dcc departamento de ci ncia da computa universidade de campinas 
salton singhal mitra buckley 

automatic text structuring summarization 
information processing management elsevier science 
wf wagner fischer 
string string correction problem acm pages 
yc yang chute 
example mapping method text classification retrieval acm transactions information systems 
