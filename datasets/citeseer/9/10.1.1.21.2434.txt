practical issues automated categorization web sites john pierre technologies townsend street suite san francisco ca com september 
discuss issues re lated automated text classification web sites 
analyze nature web content metadata requirements text features 
approach targeted spidering including metadata extraction opportunistic crawling specific semantic hyperlinks 
describe system automatically classifying web sites industry categories performance results different combinations text features training data 
estimated pages accessible web pages added daily 
describing organizing vast amount content essential realizing full potential information resource 
accomplishing meaningful way require con sistent metadata descriptive data struc tures semantic linking 
categorization important ingredient evident popularity web directories yahoo open directory project 
resources created large teams human editors represent kind classification task widely useful suitable applications 
automated classification needed important reasons 
sheer scale re sources available web changing na ture 
simply feasible keep pace growth change web manual clas expending immense time effort 
second reason classification tive activity 
different classification tasks needed different applications 
single classification scheme suitable applications 
discuss practical issues ap methods automated text categorization web john pierre practical issues automated categorization web sites content 
take size fits approach advocate targeted specific classification tasks relevant solving specific problems 
section discuss nature web content tions extracting text features 
describe specialized system classifying web sites industry categories section results sec tion 
section discuss related 
state suggestions study section 
web sites main challenges classifying web pages wide variation content quality 
text categorization methods rely existence quality texts especially training 
known collections typically studied automated text classification experiments trec reuters comparison web lacks ity 
matters worse existing web page content images plug applications non text media 
usage metadata inconsistent non existent 
section survey landscape web content relation requirements text categorization systems 
analysis web content attempt characterize nature content classified performed rudimentary quantitative analysis 
results obtained analyzing col lection web domains obtained random dump database known domain name reg 
course results reflect bi ases small samples don necessarily generalize web reflective issues hand 
classification method text important know amount qual ity text features typically appear web sites 
table show percentage web sites certain number words type 
analyzed sample domains live web sites counted number words content attribute meta name keywords meta name description tags title tags 
counted free text body tag excluding html tags 
obvious source text body web page 
noticed top level web pages usable body text 
cases include pages contain frame sets images plug ins user agent followed redirects possible 
quarter web pages contained words majority web pages contained words 
john pierre practical issues automated categorization web sites sources text content html tags including titles metatags hyperlinks 
promising sources text features web page metadata 
title tags common amount text relatively small titles containing words 
titles contain names terms home page particularly helpful subject classification 
metatags keywords descriptions major search en play important role ranking display search results 
despite third web sites contain tags 
turns metatags useful exist contain text specifically intended aid identification web site subject areas time metatags contained words smaller percentage containing words contrast number words body text tended contain words 
text features argued purposes au text classification text features 
relatively number possibilities misuse abuse tags improve search engine rankings known practices widespread sample little consequence 

moderate frequency assignment 
low redundancy 
low noise 
related semantic scope classes signed 
relatively unambiguous meaning due wide variety purpose scope cur rent web content items difficult requirements meet classification tasks 
subject classi fication metatags meet requirements bet ter sources text titles body text 
lack widespread usage metatags problem coverage majority web content desired 
long term automated categorization really benefit greater attention paid creation usage rich metadata especially requirements taken consideration 
short term implement strategy obtaining text features existing html natural language cues takes requirements goals classification task consideration 
experimental setup goal project rapidly classify domain names web sites broad industry categories 
section describe main ingredients classifi cation experiments including data architecture evaluation measures 
john pierre practical issues automated categorization web sites classification scheme categorization scheme top level north american industrial classification scheme naics consists broad industry cate gories shown table 
resources previously classified older standard industrial classification sic system 
cases published map pings convert assigned sic categories naics equivalents 
lower level naics subcategories generalized appropriate top level category 
targeted spidering results section obvious selec tion adequate text features important issue certainly taken granted 
balance needs text classifier speed storage limitations large scale crawling effort took approach spidering web sites gathering text targeted classification task hand 
opportunistic spider begins top level web page attempts extract useful text metatags titles exist follows links frame sets exist 
follows links contain key substrings prod services info press news looks content 
substrings chosen ad hoc frequency analysis assumption tend point content useful deducing industry classi fication 
content spider gather actual body text web page 
ef ran spiders parallel working different lists individual domain names 
attempting take advantage current web implicit semantic structure 
advantages moving explicit semantic struc ture hypertext documents opportunistic spidering approach really benefit formal ized description semantic relationships linked web pages 
preliminary tests best classi accuracy obtained contents keywords description metatags source text features 
adding body text decreased classification accuracy 
due lack widespread usage metatags limiting features practical sources text titles body text needed provide adequate coverage web sites 
targeted spidering approach attempts gather higher quality text features metatags resorts lower quality texts needed 
test data initial list domain names targeted spider determine sites live obtained extracted text approach outlined section 
domain names usable john pierre practical issues automated categorization web sites table 
percentage web pages words html tags tag type words words words words title meta description meta keywords body text naics code naics description table 
top level naics categories agriculture forestry fishing hunting mining utilities construction manufacturing wholesale trade retail trade transportation warehousing information finance insurance real estate rental leasing professional scientific technical services management companies enterprises administrative support waste management remediation services educational services health care social assistance arts entertainment recreation accommodation food services services public administration public administration unclassified establishments john pierre practical issues automated categorization web sites text content pre classified indus try category training data took approaches constructing training sets classifiers 
approach combi nation naics category labels including subcat egories securities exchange com mission sec public companies training examples 
second approach set pre classified domain names text domain obtained spider 
approach considered prior knowledge obtained different domain 
interest ing see knowledge different domain gen problem 
furthermore case training examples difficult obtain need automated solution place 
second approach conventional classifi cation example 
case possible fact database domain names pre classified industry categories 
industry classifications provided dunn 
sec annual reports required pub lic companies describe business activities year 
public assigned sic category 
classifier architecture text classifier consisted modules tar spider extracting text features associated web site information retrieval engine comparing queries training examples decision algorithm assigning categories 
spider designed quickly process large database top level web domain names domain com domain net 
described section imple mented opportunistic spider targeted finding high quality text pages described business area products services commercial web site 
ac text features query submitted text classifier 
domain name automatically assigned categories logged central database 
spiders run parallel efficient system resources 
information retrieval engine la tent indexing lsi 
lsi variation vector space model information retrieval uses technique singular value decomposition svd re duce dimensionality vector space 
previ ous shown lsi provided better accu racy fewer training set documents category standard tf idf weighting 
queries compared training set documents cosine similarity ranked list matching documents scores forwarded decision module 
john pierre practical issues automated categorization web sites decision module nearest neighbor algorithm ranking categories assigned top ranking category web site 
type classifier tends perform compared methods robust tolerant noisy data important qualities dealing web content 
evaluation measures system evaluation carried standard precision recall measures 
mea sure combines precision recall equal importance single parameter optimization defined precision recall 
computed global estimates performance ing micro averaging results computed global sums decisions macro averaging results computed category basis av categories 
micro averaged scores tend dominated commonly categories macro averaged scores tend dominated performance rarely categories 
tion relevant problem turned vast majority commercial web sites asso ciated manufacturing category 
results experiment varied sources text features pre classified web domains 
con structed separate test sets text extracted body text metatags keywords descriptions combination 
training set consisted sec documents naics category descriptions 
re sults shown table 
table 
performance vs text features sources text micro micro micro body body metatags metatags metatags source text features resulted accurate classifications 
precision decreases noticeably body text 
interesting including body text metatags results accurate classifications 
usefulness metadata source high quality text features meets criteria listed 
second experiment compared classifiers con structed different training sets described section 
results shown table 
sec naics training set achieved respectable micro averaged scores macro averaged scores low 
reason classifier gener john pierre practical issues automated categorization web sites table 
performance vs training set classifier micro micro micro macro macro macro sec naics web pages categories common business web domains trouble recall categories represented business domain poor precision categories common web domain 
training set constructed web site text formed better 
macro averaged recall lower micro averaged recall 
partially explained example 
categories sale trade retail trade sub tle difference especially comes web page text tends focus products services delivered retail vs wholesale distinction 
training set category common tended assigned place resulting low recall 
rare categories tended low recall 
related automatically constructed large scale web direc deployed commercial services northern light inktomi directory engine web site catalog 
details sys tems generally unavailable propri nature 
interesting directories tend popular manually constructed coun 
system automated discovery classification domain specific web resources described part desire ii project 
classification gorithm weights terms metatags higher titles headings weighted higher plain body text 
describe classification software topic filter harvesting subject specific web dex 
system pharos part alexandria digital library project scalable architecture searching heterogeneous information sources lever ages metadata automated classifica tion 
hyperlink structure web exploited automated classification anchor text context linking documents source text features 
approaches efficient web spider ing investigated especially im portant large scale crawling efforts 
complete system automatically building search able databases domain specific web resources john pierre practical issues automated categorization web sites combination techniques automated classifica tion targeted spidering information extraction described 
automated methods knowledge discovery including classification important establishing se mantic web 
classification objective 
single clas adequate possible appli cations 
specialized approach including pragmatic tar techniques applied specific classification tasks 
described practical system classifying domain names industry categories gives results 
results table concluded metatags best source quality text features compared body text 
limiting selves metatags able classify large majority web sites 
opted tar spider extracted text looked pages described business activities degraded text necessary 
clear text contained structured metadata fields results better automated categorization 
web moves formal semantic structure outlined tim berners lee automated methods ben 
different kinds automated classifica tion tasks accomplished accurately web useful usable 
outline basic approach building targeted automated web categorization solution knowledge gathering important clear understanding domain classified quality content involved 
web heterogenous environment domains patterns commonalities emerge 
ad vantage specialized knowledge improve classi fication results 
targeted spidering classification task different features important 
due lack homogeneity web content existence key features quite inconsistent 
targeted spidering approach tries gather key fea tures possible little effort possible 
type approach benefit greatly web structure encourages metadata semantically typed links 
training best training data comes domain classified gives best chance identifying key features 
cases feasible assemble training data target domain may possible achieve ac results training data gathered different domain 
true web content unstructured uncontrolled immense difficult assemble quality training data 
john pierre practical issues automated categorization web sites controlled collections pre elec documents obtained important domains legal medical applied automated categorization web content 
classification addition accurate possible classification method needs effi cient scalable robust tolerant noisy data 
classification algorithms utilize link struc ture web including formalized semantic linking structures investigated 
better acceptance metadata key fu ture semantic web 
creation quality metadata tedious prime candidate automated methods 
preliminary method outlined serve basis boot strapping sophisticated classifier takes full advantage semantic web 
roger mark butler ron daniel collaboration design sys tem bill collaboration system design software implementation 
special network solutions providing classified domain names 

berners lee 
semantic web road map 
www org designissues semantic html 

yahoo www yahoo com 
www com 
open directory project www dmoz org 
lewis 
text representation intelligent text re trieval classification oriented view 
jacobs edi tor text intelligent systems chapter 
lawrence erlbaum 

north american industrial classification system naics united states 
www census gov www naics html 
pierre butler 
prac tical evaluation ir automated classification systems 
eighth international conference information knowledge management 

deerwester dumais furnas landauer harshman 
indexing latent semantic analysis 
journal american society information science 

van rijsbergen 
information retrieval 
butter london 

lewis 
evaluating text categorization 
proceedings speech natural language workshop morgan kaufmann 

yang liu 
re examination text tion methods 
proceedings nd annual acm sigir conference research development formation retrieval 

northern light www northernlight com 
inktomi directory engine www inktomi com products portal directory 
web site catalog search com html john pierre practical issues automated categorization web sites 
koch 
construction robot generated subject index 
eu project desire ii working 
www lub lu se desire desire wp html 
kock 
automatic classification full text html documents specific subject area 
eu project desire ii working 
www lub lu se desire desire wp html 
agrawal dillon el abbadi 
pharos scalable distributed architecture locating heterogeneous information sources version 
pro ceedings th international conference informa tion knowledge management 

agrawal el abbadi pearlman 
automated classification summarizing selecting heterogeneous information sources 
lib magazine january 

attardi sebastiani 
automatic web page categorization link context analysis 
chris hutchison gaetano eds proceed ings thai european symposium telematics hypermedia artificial intelligence 

cho garcia molina page 
efficient crawling url ordering 
computer networks isdn systems www vol 


rennie mccallum 
reinforcement learn ing spider web efficiently 
proceedings international conference machine learning 

mccallum nigam rennie seymore 
machine learning approach building domain specific search engines 
sixteenth international joint conference artificial intelligence 

jones mccallum nigam riloff 
boot strapping text learning tasks 
ijcai shop text mining foundations techniques ap plications 
