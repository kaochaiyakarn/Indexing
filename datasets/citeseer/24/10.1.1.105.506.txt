journal artificial intelligence research submitted published popular ensemble methods empirical study david opitz opitz cs umt edu department computer science university montana mt usa richard maclin umn edu computer science department university minnesota mn usa ensemble consists set individually trained classifiers neural networks decision trees predictions combined classifying novel instances 
previous research shown ensemble accurate single classifiers ensemble 
bagging breiman boosting freund schapire schapire relatively new popular methods producing ensembles :10.1.1.30.8572:10.1.1.32.9399:10.1.1.153.7626
evaluate methods data sets neural networks decision trees classification algorithm 
results clearly indicate number 
bagging accurate single classifier accurate boosting 
hand boosting create ensembles accurate single classifier especially neural networks 
analysis indicates performance boosting methods dependent characteristics data set examined 
fact results show boosting ensembles may overfit noisy data sets decreasing performance 
consistent previous studies suggests gain ensemble performance comes classifiers combined relatively large gains seen classifiers boosting decision trees 

researchers investigated technique combining predictions multiple classifiers produce single classifier breiman clemen perrone wolpert :10.1.1.30.8572:10.1.1.32.9399
resulting classifier referred ensemble generally accurate individual classifiers making ensemble 
theoretical hansen salamon krogh vedelsby empirical hashem opitz shavlik research demonstrated ensemble individual classifiers ensemble accurate errors different parts input space 
popular methods creating accurate ensembles bagging breiman boosting freund schapire schapire :10.1.1.30.8572:10.1.1.32.9399:10.1.1.153.7626
methods rely resampling techniques obtain different training sets classifiers 
comprehensive evaluation bagging boosting data sets basic classification methods decision trees neural networks 
ai access foundation morgan kaufmann publishers 
rights reserved 
opitz maclin previous demonstrated bagging boosting effective decision trees bauer kohavi drucker cortes breiman freund schapire quinlan little empirical testing neural networks especially new boosting algorithm :10.1.1.30.8572:10.1.1.32.9399
discussions previous researchers reveal authors concentrated decision trees due fast training speed established default parameter settings 
neural networks difficulties testing terms significant processing time required selecting training parameters feel distinct advantages including neural networks study 
previous empirical studies demonstrated individual neural networks produce highly accurate classifiers accurate corresponding decision trees fisher mckusick mooney shavlik towell gove 
second neural networks extensively applied numerous domains arbib 
studying neural networks addition decision trees examine bagging boosting influenced learning algorithm giving insight general characteristics approaches 
bauer kohavi study bagging boosting applied learning methods case decision trees variant naive bayes classifiers study mainly concentrated decision tree results 
neural network decision tree results led number interesting 
bagging ensemble generally produces classifier accurate standard classifier 
feel comfortable bagging decision trees neural networks 
boosting note widely varying results 
data sets boosting produced dramatic reductions error compared bagging data sets increases error single classifier particularly neural networks 
tests examined effects noise support freund schapire conjecture boosting sensitivity noise may partly responsible occasional increase error 
alternate baseline approach investigated creation simple neural network ensemble network full training set differed random initial weight settings 
results indicate ensemble technique surprisingly effective producing results bagging 
research ali pazzani demonstrated similar results randomized decision tree algorithms 
results show ensemble methods generally consistent terms effect accuracy applied neural networks decision trees little inter correlation neural networks decision trees boosting methods 
suggests increases produced boosting dependent particular characteristics data set component classifier 
tests demonstrate bagging resilient noise boosting 
investigated question component classifiers ensemble 
consistent previous research freund schapire quinlan results show reduction error ensemble methods occurs additional classifiers 
boosting decision trees relatively large gains may seen classifiers 
popular ensemble methods organized follows 
section overview classifier ensembles discuss bagging boosting detail 
extensive empirical analysis bagging boosting 
research additional related concluding 

classifier ensembles illustrates basic framework classifier ensemble 
example neural networks basic classification method conceptually classification method decision trees substituted place networks 
network ensemble network network case trained training instances network 
example predicted output networks oi combined produce output ensemble 
researchers alpaydin breiman krogh vedelsby lincoln demonstrated effective combining scheme simply average predictions network :10.1.1.30.8572:10.1.1.32.9399
combining output classifiers useful disagreement 
obviously combining identical classifiers produces gain 
hansen salamon proved average error rate example component classifiers ensemble independent production errors expected error example reduced zero number classifiers combined goes infinity assumptions rarely hold practice 
krogh vedelsby proved ensemble error divided term measuring average generalization error individual classifier term measuring disagreement classifiers 
formally showed ideal ensemble consists highly correct classifiers disagree possible 
opitz shavlik empirically verified ensembles generalize 
result methods creating ensembles center producing classifiers disagree predictions 
generally methods focus altering training process network ensemble output combine network outputs network input network classifier ensemble neural networks 
opitz maclin hope resulting classifiers produce different predictions 
example neural network techniques employed include methods training different topologies different initial weights different parameters training portion training set alpaydin drucker cortes jackel lecun vapnik hansen salamon maclin shavlik 
concentrate popular methods bagging boosting try generate disagreement classifiers altering training set classifier sees 
bagging classifiers bagging breiman bootstrap efron tibshirani ensemble method creates individuals ensemble training classifier random redistribution training set :10.1.1.30.8572:10.1.1.32.9399
classifier training set generated randomly drawing replacement examples size original training set original examples may repeated resulting training set may left 
individual classifier ensemble generated different random sampling training set 
gives sample bagging imaginary set data 
bagging resamples training set replacement instance represented multiple times left 
bagging training set contain examples twice contain example 
result classifier trained training set obtain higher test set error classifier data 
fact bagging component classifiers result higher test set error combined classifiers produce test set error lower single classifier diversity classifiers generally compensates increase error rate individual classifier 
breiman showed bagging effective unstable learning algorithms small changes training set result large changes predictions 
breiman claimed neural networks decision trees examples unstable learning algorithms 
study effectiveness bagging learning methods article 
boosting classifiers boosting freund schapire schapire encompasses family methods :10.1.1.153.7626
focus methods produce series classifiers 
training set member series chosen performance earlier classifier series 
boosting examples incorrectly predicted previous classifiers series chosen examples correctly predicted 
boosting attempts produce new classifiers better able predict examples current ensemble performance poor 
note bagging resampling training set dependent performance earlier classifiers 
examine new powerful forms boosting arcing breiman ada boosting freund schapire :10.1.1.30.8572:10.1.1.32.9399
bagging arcing chooses training set size classifier probabilistically selecting replacement examples original training examples 
bagging probability popular ensemble methods sample single classifier imaginary set data 
original training set training set sample bagging data 
resampled training set training set training set training set training set sample boosting data 
resampled training set training set training set training set training set hypothetical runs bagging boosting 
assume training examples 
assume example outlier hard component learning algorithm classify correctly 
bagging training set independent sample data examples missing occur multiple times 
boosting training sets samples original data set hard example example occurs training sets boosting concentrates correctly predicting 
selecting example equal training set 
probability depends example misclassified previous classifiers 
ada boosting approach selecting set examples probabilities examples simply examples weight error example probability example examples higher probabilities effect error 
approach clear advantage example incorporated part training set 
furthermore friedman 
demonstrated form ada boosting viewed form additive modeling optimizing logistic loss function 
chosen approach subsampling data ensure fair empirical comparison part due restarting reason discussed 
arcing ada boosting initially set probability picking example methods recalculate probabilities trained classifier added ensemble 
ada boosting sum probabilities opitz maclin misclassified instances currently trained classifier ck 
probabilities trial generated multiplying probabilities ck incorrectly classified instances factor renormalizing probabilities sum equals 
ada boosting combines classifiers ck weighted voting ck weight log 
weights allow ada boosting discount predictions classifiers accurate problem 
friedman suggested alternative mechanism fits predictions classifiers additive model maximum likelihood criterion 
revision described breiman reset weights equal restart 
resetting weights disadvantage ada boosting learner cases reaches values ada boosting learner incorporates number classifiers methods tested 
feasible forced approach selecting data set probabilistically weighting examples deterministic method cycle generate duplicate members ensemble 
resetting weights cause learner repeat decision tree learned member ensemble lead reweighting data set second member ensemble 
randomly selecting examples data set example probabilities alleviates problem 
arcing breiman refer simply arcing started simple mechanism evaluating effect boosting methods resulting classifiers combined weighting votes :10.1.1.30.8572:10.1.1.32.9399
arcing uses simple mechanism determining probabilities including examples training set 
ith example training set value mi refers number times example misclassified previous classifiers 
probability pi selecting example part classifier training set defined pi mi nj mj breiman chose value power empirically trying different values breiman :10.1.1.30.8572:10.1.1.32.9399
mechanism weighted voting ada boosting produces accurate ensembles simple implement include method ada boosting empirical evaluation 
shows hypothetical run boosting 
note training set bagging training sets accentuate examples misclassified earlier member ensembles 
example hard example previous classifiers tend misclassify 
second training set example occurs multiple times examples left training set case misclassified learner 
final training set example 
cases results simply large positive value log weight networks 
cases larger approximately results chose weight predictions small positive value negative weight factor produced slightly better results alternate approaches pilot studies 
popular ensemble methods predominant example chosen single example accentuated bagging test set error classifier high 
despite boosting probably obtain lower error rate combines output classifiers focuses correctly predicting previously misclassified examples weights predictions different classifiers accuracy training set 
boosting overfit presence noise empirically show section 
bias plus variance decomposition authors breiman friedman kohavi wolpert kong dietterich proposed theories effectiveness bagging boosting geman bias plus variance decomposition classification error :10.1.1.30.8572:10.1.1.32.9399
decomposition view expected error learning algorithm particular target function training set size having components bias term measuring close average classifier produced learning algorithm target function 
variance term measuring learning algorithm guesses vary respect disagree 
term measuring minimum classification error associated bayes optimal classifier target function term referred intrinsic target noise 
framework suggested breiman bagging boosting reduce error reducing variance term :10.1.1.30.8572:10.1.1.32.9399
freund schapire argue boosting attempts reduce error bias term focuses misclassified examples 
focus may cause learner produce ensemble function differs significantly single learning algorithm 
fact boosting may construct function component learning algorithm changing linear predictions classifier contains non linear predictions 
capability boosting appropriate algorithm combining predictions weak learning algorithms algorithms simple learning bias 
bauer kohavi demonstrated boosting reduce bias certain real world problems 
surprisingly showed bagging reduce bias portion error data sets boosting reduces bias 
bias variance decomposition interesting certain limitations applying real world data sets 
able estimate bias variance target noise particular problem need know actual function learned 
unavailable real world problems 
deal problem kohavi wolpert suggest holding data approach bauer kohavi study 
main problem technique training set size greatly reduced order get estimates bias variance terms 
chosen strictly focus generalization accuracy study part bauer kohavi answered question boosting bagging reduce opitz maclin bias real world problems experiments demonstrate decomposition gives insight ensemble methods small part equation 
different data sets observe cases boosting bagging decrease variance portion error cases boosting bagging reduce bias variance error 
tests indicate boosting generalization error increases domains boosting increases variance portion error difficult determine aspects data sets led results 

results section describes empirical study bagging ada boosting arcing 
methods tested decision trees neural networks 
data sets evaluate performance bagging boosting obtained number data sets university wisconsin machine learning repository uci data set repository murphy aha 
data sets hand selected came real world problems varied characteristics deemed useful previous researchers 
table gives characteristics data sets 
data sets chosen vary number dimensions including type features data set continuous discrete mix number output classes number examples data set 
table shows architecture training parameters neural networks experiments 
methodology results noted averaged standard fold cross validation experiments 
fold cross validation data set partitioned sets set turn test set classifier trains sets 
fold ensemble classifiers created 
cross validation folds performed independently algorithm 
trained neural networks standard backpropagation learning rumelhart hinton williams 
parameter settings neural networks include learning rate momentum term weights initialized randomly 
number hidden units epochs training section 
chose number hidden units number input output units 
choice criteria having hidden unit output hidden unit inputs hidden units minimum 
number epochs number examples number parameters topology network 
specifically epochs small problems involving fewer examples epochs mid sized problems containing examples epochs larger problems 
decision trees tool quinlan pruned trees empirically produce better performance suggested quinlan 
popular ensemble methods features neural network data set cases class cont disc inputs outputs hiddens epochs breast cancer credit credit diabetes glass heart cleveland hepatitis house votes hypo ionosphere iris kr vs kp labor letter promoters ribosome bind satellite segmentation sick sonar soybean splice vehicle table summary data sets 
shown number examples data set number output classes number continuous discrete input features number input output hidden units neural networks tested epochs neural network trained 
data set error rates table shows test set error rates data sets described table neural network methods decision tree methods 
tables show error rates standard deviation values 
test set errors bagging arcing ada boosting include test set error rate single single decision tree classifier 
report results simple baseline neural network ensemble approach creating ensemble networks network varies randomly initializing weights network 
include results certain comparisons demonstrate similarity bagging 
obvious drawn results ensemble method appears reduce error rate data sets cases reduction large 
fact sign test indicates ensemble method significantly better single opitz maclin neural network boosting boosting data set stan simp bag arc ada stan bag arc ada breast cancer credit credit diabetes glass heart cleveland hepatitis house votes hypo ionosphere iris kr vs kp labor letter promoters ribosome bind satellite segmentation sick sonar soybean splice vehicle table test set error rates data sets single neural network classifier ensemble individual network trained original training set differs networks ensemble random initial weights ensemble networks trained randomly resampled training sets bagging ensemble networks trained weighted resampled training sets boosting resampling arcing method ada method single decision tree classifier bagging ensemble decision trees arcing ada boosting ensembles decision trees 
component classifier confidence level ensemble methods significantly better ensemble approach confidence level 
better analyze table results figures plot percentage reduction error ada boosting arcing bagging method function original error rate 
examining figures note gains produced ensemble methods larger standard deviation values 
terms comparisons different methods apparent figures boosting methods ada kr vs kp letter segmentation labor soybean satellite sick sonar vehicle glass ionosphere promoters ribosome bind iris splice credit diabetes hypo hepatitis credit house votes heart cleveland breast cancer popular ensemble methods percent reduction error ada boosting arcing bagging reduction error ada boosting arcing bagging neural network ensembles percentage original error rate reduction error rate reduction error rate just reduction reduction 
shown white portion bar standard deviation results 
standard deviation shown addition error reduction 
letter segmentation promoters kr vs kp satellite labor breast cancer hypo sonar glass ionosphere vehicle sick hepatitis soybean heart cleveland ribosome bind splice credit credit diabetes iris house votes opitz maclin percent reduction error ada boosting arcing bagging reduction error ada boosting arcing bagging decision tree ensembles percentage original error rate 
shown white portion bar standard deviation results 
popular ensemble methods boosting arcing similar results neural networks decision trees 
furthermore ada boosting arcing methods produce largest reductions error 
hand bagging method consistently produces reductions error cases neural networks boosting methods result increase error 
looking ordering data sets figures results sorted percentage reduction ada boosting method note data sets ensemble methods somewhat consistent neural networks decision trees 
domains see increases error difficult reach strong ensemble methods large number domains 
domain boosting methods uniformly poorly house votes domain 
discuss may noise domain examples causes boosting methods significant problems 
ensemble size early hansen salamon ensembles suggested ensembles members adequate sufficiently reduce test set error 
claim may true earlier proposed ensembles boosting literature schapire freund bartlett lee suggested data sets decision trees possible reduce test set error members added ensemble note result applies bagging 
section perform additional experiments investigate appropriate size ensemble 
shows composite error rate data sets neural network decision tree ensembles classifiers 
experiments indicate methods produce similarly shaped curves 
expected reduction error due adding classifiers ensemble comes classifiers variation respect error reduction asymptotes 
bagging boosting applied neural networks reduction error appears occurred fifteen classifiers 
similar reached bagging decision trees consistent breiman 
arcing continue measurably improve test set error classifiers decision trees 
classifiers error reduction methods appears nearly plateau 
results reported ensemble size sufficient manageable size qualitative analysis 
traditionally believed freund schapire small reductions test set error may continue indefinitely boosting grove schuurmans demonstrate ada boosting overfit large ensemble sizes members 
correlation methods suggested appears performance ensemble methods highly correlated 
help identify consistencies table presents correlation coefficients performance ensemble methods 
data set performance measured ensemble error rate divided single classifier error composite error rate opitz maclin number networks ensemble dt ada dt arc dt bag nn ada nn arc nn bag average test set error data sets studies ensembles incorporating decision trees neural networks 
error rate graphed simply average error rates data sets 
alternative averaging error data points weighting data set error rate sample size produces similarly shaped curves 
rate 
high correlation near suggests methods consistent domains greatest impact test set error reduction 
table provides numerous interesting insights 
neural network ensemble methods strongly correlated decision tree ensemble methods strongly correlated correlation neural network ensemble method decision tree ensemble method 
surprisingly ada boosting arcing strongly correlated different component learning algorithms 
suggests boosting effectiveness depends data set component learning algorithm neural network decision tree 
bagging hand correlated component learning algorithms 
results consistent claim boosting powerful ensemble method susceptible noisy data set bagging 
popular ensemble methods neural network decision tree simple bagging arcing ada bagging arcing ada simple nn bagging nn arcing nn ada nn bagging dt arcing dt ada dt table performance correlation coefficients ensemble learning methods 
performance measured ratio ensemble method test set error divided single component classifier test set error 
bagging versus simple network ensembles shows bagging simple network ensemble results table 
results indicate simple ensemble approach produce results accurate bagging correlation results table support statement 
suggests mechanism causes learning method produce randomness formation classifiers form accurate ensembles ali pazzani demonstrated similar results randomized decision trees 
neural networks versus decision trees interesting question effective different methods neural networks decision trees 
figures compare error rates reduction error values ada boosting arcing bagging respectively 
note graph error rate percent reduction error rate baseline method decision trees ada boosting decision trees versus neural networks ada boosting neural networks may partially explain differences percent reduction 
example promoters problem ada boosting larger reduction error decision tree approach may due fact decision trees effective problem ada boosting produces larger percent reduction error decision trees 
results show cases single decision tree lower higher error single neural network data set decision tree ensemble methods lower higher error neural network counterpart 
exceptions rule generally happened data set ensemble methods hepatitis soybean satellite credit heart cleveland 
results suggest performance ensemble methods dependent data set classifier method ensembles cases overcome inductive bias component learning algorithm 
kr vs kp letter labor soybean promoters segmentation satellite splice vehicle house votes glass credit hepatitis ribosome bind heart cleveland iris credit ionosphere diabetes hypo sick breast cancer sonar opitz maclin percent reduction error bagging reduction error bagging simple neural network ensembles percentage original error rate 
shown white portion bar standard deviation results 
simple kr vs kp letter segmentation labor soybean satellite sick sonar vehicle glass ionosphere promoters ribosome bind iris splice credit diabetes hypo hepatitis credit house votes heart cleveland breast cancer popular ensemble methods error neural network decision tree error rates ada boosting ensembles 
white portion shows reduction error ada boosting compared single classifier increases error shown black 
data sets sorted ratio reduction ensemble error error neural networks 
kr vs kp letter labor segmentation soybean satellite vehicle sonar ionosphere sick glass promoters iris splice ribosome bind credit hepatitis hypo diabetes house votes credit heart cleveland breast cancer opitz maclin error neural network decision tree error rates arcing ensembles 
white portion shows reduction error arcing compared single classifier increases error shown black 
data sets sorted ratio reduction ensemble error error neural networks 
kr vs kp letter labor soybean promoters segmentation satellite splice vehicle house votes glass credit hepatitis ribosome bind heart cleveland iris credit ionosphere diabetes hypo sick breast cancer sonar popular ensemble methods error neural network decision tree error rates bagging ensembles 
white portion shows reduction error bagging compared single classifier increases error shown black 
data sets sorted ratio reduction ensemble error error neural networks 
boosting noise opitz maclin freund shapire suggested poor performance boosting results overfitting training set training sets may emphasizing examples noise creating extremely poor classifiers 
argument especially pertinent boosting reasons 
obvious reason method updating probabilities may emphasizing noisy examples 
second reason classifiers combined weighted voting 
previous krogh shown optimizing combining weights lead overfitting unweighted voting scheme generally resilient overfitting 
friedman 
hypothesize boosting methods additive models may see increases error situations bias base classifier appropriate problem learned 
test hypothesis second set results section 
evaluate hypothesis boosting may prone overfitting performed set experiments ensemble neural network methods 
introduced noise different data sets 
level created different noisy data sets performed fold cross validation averaged results 
show reduction error rate ensemble methods compared single neural network classifier 
results demonstrate noise level grows efficacy simple bagging ensembles generally increases arcing ada boosting ensembles gains performance smaller may decrease 
note effect extreme ada boosting supports hypothesis ada boosting affected noise 
suggests boosting poor performance certain data sets may partially explained overfitting noise 
demonstrate effect noise boosting created sets artificial data specifically designed mislead boosting methods 
data set created simple hyperplane concept set features included irrelevant features 
set random points generated labeled side hyperplane fell 
certain percentage points side hyperplane mislabeled part class 
experiments shown generated data sets concept linear features irrelevant features data mislabeled 
trained ensembles neural networks perceptrons data set averaged ensembles predictions 
experiments involve learning situations original bias learner single hyperplane produced perceptron appropriate problem friedman 
suggest additive model may harm performance 
shows resulting error rates ada boosting arcing bagging number networks combined ensemble 
results indicate clearly cases noise bagging error rate increase ensemble size increases error rate boosting methods may increase ensemble size increases 

noise indicates feature training examples input output features chance randomly perturbed feature value feature continuous features set possible values chosen examining training examples 
reduction error rate pts reduction error rate pts diabetes promoters noise rate popular ensemble methods soybean large boosting ada ensemble segmentation noise rate bagging ensemble boosting arcing ensemble simple bagging boosting arcing ada neural network ensemble reduction error compared single neural network 
graphed percentage point reduction error noise segmentation data set single network method error rate bagging method error rate graphed percentage point reduction error rate 
additional tests shown show ada boosting error rate worse restarting employed 
nicely schapire discussion note effectiveness voting method measured examining margins examples 
margin difference number correct incorrect votes example 
simple resampling method bagging resulting classifier focuses increasing margin examples possible 
boosting method classifiers focus increasing margins examples poor current margins 
schapire 
note effective strategy accuracy resulting classifier drop significantly 
problem noise focusing misclassified examples may cause classifier focus boosting margins noisy examples fact misleading classification 
error rate error rate error rate error rate error rate opitz maclin networks ensemble error rates size ensemble ada boosting arcing bagging ensembles different artificial data sets containing sided noise see text description 
arc ada bag arc ada bag arc ada bag arc ada bag arc ada bag 
popular ensemble methods interesting question plan investigate effective single classifier approach allowed time takes ensemble method train multiple classifiers explore concept space 
example neural network approach perform pilot studies training set select appropriate values parameters hidden units learning rate plan compare bagging boosting methods methods introduced 
particular intend examine stacking wolpert method training combining function avoid effect having weight classifiers 
plan compare bagging boosting methods opitz shavlik approach creating ensemble 
approach uses genetic search find classifiers accurate differ predictions 
boosting methods extremely successful domains plan investigate novel approaches retain benefits boosting 
goal create learner essentially push start button run 
try preserve benefits boosting preventing overfitting noisy data sets 
possible approach holdout training set tuning set evaluate performance boosting ensemble determine accuracy longer increasing 
approach pilot studies determine optimal number classifiers ensemble 

additional related mentioned idea ensemble classifiers single best classifier proposed people 
section framework systems theories effective ensemble extensive covering bagging boosting algorithms discussion bias plus variance decomposition 
section referred empirical studies similar methods differ limited decision trees generally fewer data sets 
cover additional related section 
lincoln mani forecasting literature clemen granger indicate simple averaging predictors generates composite model researchers alpaydin asker maclin breiman hashem maclin perrone wolpert zhang mesirov waltz improved generalization voting schemes complex combinations predictor output :10.1.1.30.8572:10.1.1.32.9399
careful case optimizing combining weights easily lead problem overfitting simple averaging avoid krogh 
approaches indirectly try generate highly correct classifiers disagree possible 
methods try create diverse classifiers training classifiers dissimilar learning parameters alpaydin different classifier architectures hashem various initial neural network weight settings maclin opitz maclin shavlik separate partitions training set breiman krogh vedelsby :10.1.1.105.6964:10.1.1.30.8572:10.1.1.32.9399
boosting hand active trying generate highly correct networks opitz maclin examples currently classified incorrectly previous members ensemble 
opitz shavlik example approach directly tries create diverse ensemble 
uses genetic algorithms search explicitly highly diverse set accurate trained networks 
works creating initial population uses genetic operators create new networks continually keeping set networks highly accurate disagreeing possible 
effective incorporating prior knowledge available improve quality ensemble 
alternate approach ensemble framework train individual networks subtask combine predictions gating function depends input 
jacobs adaptive mixtures local experts method identifying myocardial nowlan sejnowski visual model train networks learn specific subtasks 
key idea techniques decomposition problem specific subtasks lead efficient representations training hampshire waibel 
problem broken subtasks resulting solutions need combined 
jacobs 
propose having gating function network learns allocate examples experts 
gating network allocates example experts backpropagated errors resulting weight changes restricted networks gating function 
tresp taniguchi propose method determining gating function problem decomposed experts trained 
gating function input dependent linear weighting function determined combination networks diversity current input likelihood networks seen data near input 
mixtures experts ensemble paradigms similar fact quite distinct statistical point view 
mixtures experts model assumption single expert responsible example 
case expert model region input space job gating function decide model data point originates 
network ensemble approach learns task just subtask mutual exclusivity assumption ensembles appropriate model highly correct point input space 

presents comprehensive empirical evaluation bagging boosting neural networks decision trees 
results demonstrate bagging ensemble nearly outperforms single classifier 
results show boosting ensemble greatly outperform bagging single classifier 
data sets boosting may show zero gain decrease performance single classifier 
tests indicate boosting may suffer overfitting presence noise may explain decreases performance boosting 
simple ensemble approach neural networks differ random initial weight settings performed surprisingly doing bagging 
popular ensemble methods analysis results suggests performance boosting methods ada boosting arcing partly dependent data set examined bagging shows correlation 
strong correlations boosting may partially explained sensitivity noise claim supported additional tests 
show performance enhancement ensemble comes classifiers combined boosting decision trees may continue improve larger ensemble sizes 
general technique decision trees neural networks bagging probably appropriate problems appropriate boosting arcing ada may produce larger gains accuracy 
acknowledgments research partially supported university minnesota aid authors 
dave opitz supported national science foundation iri montana doe petroleum reservoir characterization project supported university montana montana science technology alliance 
extended version published fourteenth national conference artificial intelligence 
ali pazzani 

error reduction learning multiple descriptions 
machine learning 
alpaydin 

multiple networks function learning 
proceedings ieee international conference neural networks vol 
pp 
san francisco 
arbib 
ed 

handbook brain theory neural networks 
mit press 
asker maclin 

ensembles sequence classifiers 
proceedings fifteenth international joint conference artificial intelligence pp 
nagoya japan 
asker maclin 

feature engineering classifier selection case study volcano detection 
proceedings fourteenth international conference machine learning pp 
nashville tn 
bauer kohavi 

empirical comparison voting classification algorithms bagging boosting variants 
machine learning 


improving accuracy artificial neural network multiple differently trained networks 
neural computation 
breiman 

bagging predictors 
machine learning 
breiman 

bias variance arcing classifiers 
tech 
rep uc berkeley berkeley ca 
opitz maclin breiman 

stacked regressions 
machine learning 
clemen 

combining forecasts review annotated bibliography 
journal forecasting 
drucker cortes 

boosting decision trees 
mozer hasselmo 
eds advances neural information processing systems vol pp 
cambridge ma 
mit press 
drucker cortes jackel lecun vapnik 

boosting machine learning algorithms 
proceedings eleventh international conference machine learning pp 
new brunswick nj 
efron tibshirani 

bootstrap 
chapman hall new york 
fisher mckusick 

empirical comparison id back propagation 
proceedings eleventh international joint conference artificial intelligence pp 
detroit mi 
freund schapire 

experiments new boosting algorithm 
proceedings thirteenth international conference machine learning pp 
bari italy 
friedman 

bias variance loss curse dimensionality 
journal data mining knowledge discovery 
friedman hastie tibshirani 

additive logistic regression statistical view boosting 
www stat stanford edu 
geman bienenstock doursat 

neural networks bias variance dilemma 
neural computation 
granger 

combining forecasts years 
journal forecasting 
grove schuurmans 

boosting limit maximizing margin learned ensembles 
proceedings fifteenth national conference artificial intelligence pp 
madison wi 
hampshire waibel 

meta pi network building distributed knowledge representations robust pattern recognition 
tech 
rep cmu cs cmu pittsburgh pa hansen salamon 

neural network ensembles 
ieee transactions pattern analysis machine intelligence 
hashem 

optimal linear combinations neural networks 
neural networks 
popular ensemble methods jacobs jordan nowlan hinton 

adaptive mixtures local experts 
neural computation 
kohavi wolpert 

bias plus variance decomposition zero loss functions 
proceedings thirteenth international conference machine learning pp 
bari italy 
kong dietterich 

error correcting output coding corrects bias variance 
proceedings twelfth international conference machine learning pp 
tahoe city ca 
krogh vedelsby 

neural network ensembles cross validation active learning 
tesauro touretzky leen 
eds advances neural information processing systems vol 
pp 
cambridge ma 
mit press 
lincoln 

synergy clustering multiple back propagation networks 
touretzky 
ed advances neural information processing systems vol 
pp 
san mateo ca 
morgan kaufmann 
maclin 

boosting classifiers 
proceedings fifteenth national conference artificial intelligence pp 
madison wi 
maclin opitz 

empirical evaluation bagging boosting 
proceedings fourteenth national conference artificial intelligence pp 
providence ri 
maclin shavlik 

combining predictions multiple classifiers competitive learning initialize neural networks 
proceedings fourteenth international joint conference artificial intelligence pp 
montreal canada 
mani 

lowering variance decisions artificial neural network portfolios 
neural computation 
mooney shavlik towell gove 

experimental comparison symbolic connectionist learning algorithms 
proceedings eleventh international joint conference artificial intelligence pp 
detroit mi 
murphy aha 

uci repository machine learning databases machine readable data repository 
university california irvine department information computer science 
nowlan sejnowski 

filter selection model generating visual motion signals 
hanson cowan giles 
eds advances neural information processing systems vol 
pp 
san mateo ca 
morgan kaufmann 
opitz shavlik 

actively searching effective neural network ensemble 
connection science 
opitz maclin opitz shavlik 

generating accurate diverse members ensemble 
mozer hasselmo 
eds advances neural information processing systems vol 
pp 
cambridge ma 
mit press 
perrone 

soft competitive splitting rule adaptive tree structured neural networks 
proceedings international joint conference neural networks pp 
baltimore md perrone 

improving regression estimation averaging methods variance reduction extension general convex measure optimization 
ph thesis brown university providence ri 
quinlan 

programs machine learning 
morgan kaufmann san mateo ca 
quinlan 

bagging boosting 
proceedings thirteenth national conference artificial intelligence pp 

portland 
rumelhart hinton williams 

learning internal representations error propagation 
rumelhart mcclelland 
eds parallel distributed processing explorations microstructure cognition 
volume foundations pp 

mit press cambridge ma 
schapire 

strength weak learnability 
machine learning 
schapire freund bartlett lee 

boosting margin new explanation effectiveness voting methods 
proceedings fourteenth international conference machine learning pp 
nashville tn 
krogh 

learning ensembles fitting useful 
mozer hasselmo 
eds advances neural information processing systems vol 
pp 
cambridge ma 
mit press 
tresp taniguchi 

combining estimators non constant weighting functions 
tesauro touretzky leen 
eds advances neural information processing systems vol 
pp 
cambridge ma 
mit press 
wolpert 

stacked generalization 
neural networks 
zhang mesirov waltz 

hybrid system protein secondary structure prediction 
journal molecular biology 
appendix popular ensemble methods tables show complete results set experiments 
single simple bagging arcing boosting data set err sd best err sd err sd err sd err sd breast cancer credit credit diabetes glass heart cleveland hepatitis house votes hypo ionosphere iris kr vs kp labor letter promoters ribosome bind satellite segmentation sick sonar soybean splice vehicle table neural network test set error rates standard deviation values error rates single neural network classifier simple neural network ensemble bagging ensemble arcing ensemble ada boosting ensemble 
shown results column best result produced single network results run training data 
opitz maclin single bagging arcing boosting data set err sd best err sd err sd err sd breast cancer credit credit diabetes glass heart cleveland hepatitis house votes hypo ionosphere iris kr vs kp labor letter promoters ribosome bind satellite segmentation sick sonar soybean splice vehicle table decision tree test set error rates standard deviation values error rates single decision tree classifier bagging ensemble arcing ensemble ada boosting ensemble 
shown results column best result produced single tree results run training data 

