joint induction shape features tree classi ers donald geman amit ken wilder may introduce large family binary features dimensional shapes 
salient ones separating particular shapes determined inductive learning construction classi cation trees 
feature possible geometric arrangement local topographic codes 
arrangements express coarse constraints relative angles distances code locations nearly invariant substantial ne non linear deformations 
partially ordered possible narrow search informative ones node tree 
di erent trees correspond di erent aspects shape 
statistically weakly dependent due randomization aggregated simple way 
adapting algorithm shape family fully automatic training samples provided 
illustration classify handwritten digits nist database error rate 
department mathematics statistics university massachusetts amherst ma email geman math umass edu 
supported part nsf dms onr contract arpa contract mda 
department statistics university chicago chicago il email amit galton uchicago edu 
supported part daal 
department mathematics statistics university amherst ma email wilder math umass edu re visit problem nding features separating dimensional shape classes context invariance inductive learning 
feature set consider virtually nite 
salient ones particular shape family determined training samples construction classi cation trees 
experiment isolated handwritten digits 
line recognition attracted enormous attention including competition national institute standards technology nist solution matches human performance 
approaches today non parametric statistical methods neural networks discriminant analysis nearest neighbor rules di erent metrics classi cation trees 
hybrid multiple classi ers ective 
cases feature vector explicitly address shape 
features shape bear resemblance geometric invariants proposed recognizing rigid shapes dimensional objects 
see review bibliography 
typically involves extracting boundary information computing tangents identifying distinguished points high curvature ections 
invariant geometric relations determined special points see 
authors report better results structural features standardized raw data 
features involve geometric relations points distinguished points 
pixels coded coarse manner image topography immediate neighborhood 
refer codes tags 
common primitive informative shape 
features arrangements tags involving relative angles distances 
strictly invariant ne transformations semi invariant sense precise 
hand making compromises giving discriminating points strict invariance allows de ne large family features natural partial ordering corresponding increasing detail structure 
addition semi invariance extends signi cant non linear deformations 
informative features separating particular shape classes singled recursively partitioning training data standard splitting criterion entropy reduction 
partial ordering computationally feasible 
choice features classi er part training process dedicated modeling 
result method entirely portable example applied recognizing deformed latex symbols classes rigid dimensional objects :10.1.1.102.5478
classi er constructed multiple classi cation trees 
randomization prevents features chosen tree tree guarantees weak dependence 
statistical issues analyzed detail semi invariance general ization bias variance tradeo purpose introduce features outline algorithm experiment handwritten digits :10.1.1.102.5478
training test sets taken nist database 
terms speed accuracy achieve results comparable best reported 
tags rst step algorithm involves assigning pixel image tags characterizing local topography intensity surface neighborhood 
manually characterizing local con gurations interest example trying de ne local operators identify gradients adopt information theoretic approach code micro world sub images tree structured vector quantization 
large sample sub images randomly extracted training data 
corresponding shape classes irrelevant retained 
family training sub images clustered growing decision tree 
node possible questions site black 
question chosen divides sub images node equally possible groups 
tag type node resulting tree root 
tags depth tag tree tags depth tag tree experiments 
depth tags provide detailed descriptions topography 
observe tag corresponding internal node represents union subtree rooted node 
pixel image assigned tags encountered tag levels common con gurations 
sub image containing upper left hand corner proceeds tag tree 
ciency population restricted sub images containing black white site center 
obviously concentrates processing neighborhood boundaries 
grey level context useful consider general tags allowing variations concept local homogeneity local attributes intensity surface 
rst levels tag tree constructed nist data shown 
display common con guration depth nodes 
note con gurations consistent nodes 
show instances depth tags images particular digit instances depth second row depth tags re nements depth tags 
notice instance depth tag instance ancestor depth tag 
xed size neighborhood conveys information certain range resolutions relative shapes consideration 
experience range roughly 
uniform resolution training test sets top instances depth tags 
bottom instances depth tags 
better ultimate performance classi er 
multi resolution approach investigated context grey level images objects 
features tag arrangements shape features involve geometric arrangements tags de ned terms angles vectors connecting locations 
arrangement image 
features binary 
image means set tags prescribed type image locations satisfy indicated relationships 
binary relations locations corresponding compass headings north northeast east points satisfy relation angle vector ofk 
shows digits contain speci geometric arrangement tags 
arrangement involves relative angles xed locations may appear times top row instances geometric arrangement 
bottom row instances geometric arrangement 
image illustrated bottom row 
clear description geometric relations continuum invariant neighborhoods space ne transformations par ticular rotation skew shear opposed algebraic invariants truly invariant continuum 
hand tag arrangements de ned terms coarse tolerances angles invariant substantial nonlin ear deformations robust respect discretization noise forms degradation 
partial ordering arrangements speci arrangement pre extensions involving additional tags relations 
minimal extension arrangement adds additional tag relation existing new relation existing tags 
partial ordering corresponds hierarchy structure 
small arrangements tags produce coarse splits shape space 
arrange ments increase size say number tags plus relations contain information images contain 
important property ordering 
images class share common feature arrangement images minimal extension feature images contain extension image 
property call semi invariance discussed detail :10.1.1.102.5478
metric relations employed example ratios distances pairs tags 
order feature binary employs quantization range ratios quantization range angles described 
example ju vj ju wj ternary relation locations conceivable algebraic functions de ne pure invariants similarly quantized provide additional binary features 
explored possibility 
number features described clearly unlimited 
entire family computed collection training data subsequently conjunction standard classi er 
features may lack discriminating power particular problem hand 
source information accessed ciently 
natural way recursive partitioning 
recursive partitioning shape space tree built follows 
root search simplest arrangements involving tags relation 
recall arrangement splits data node subsets arrangement 
choose arrangement leads greatest reduction mean uncertainty class 
uncertainty measured shannon entropy estimated training data standard procedure pattern recognition machine learning 
denote chosen feature 
data points child node 
split node search arrangements involving tags relation 
data points child node instances pending arrangement 
search minimal extensions see choose leads greatest reduction uncertainty class existence 
example node splitting typical digit tree query involves adding fth 
note extension considered image instances extended satisfy relations de ned 
node tree pending arrangement say largest arrangement path root course data points node note step path involves additional tag relation nodes children 
arrangement chosen split node minimizes mean entropy class minimal extensions continue fashion stopping criterion satis ed number data points falls threshold 
digits taken depth node tree history node accounting existence tags pending arrangement 
depicts data split node tree grown part experiments handwritten digit classi cation 
images representative node 
images left answer query involving existence fth tag relationship fourth tag 
images right answer 
case instance pending arrangement 
multiple randomized trees despite fact minimal extensions pending arrangement entertained node procedure practical due number candidates 
root node arrangements 
number minimal extensions internal nodes large 
solution simple searching admissible arrangements node restrict search small random subset 
set tag arrangements large di erent ones address di er ent aspects shape separate trees provide separate structural descriptions characterizing shapes di erent points view 
visually illustrated image shown instance pending arrangement terminal node di erent trees 
consequently aggregating information provided family trees yield accurate robust classi cation 
ways done impractical due limited amount training data 
chosen simple method aggregation proven successful 
tree may regarded discrete random variable space images terminal node corresponds di erent value terminal node distribution classes estimated training data reaches denote distribution tree test image dropped tree terminal distributions recorded 
average nx number trees 
image classi ed class mode 
alternative ways producing aggregating multiple trees proposed arrangements image terminal nodes di erent trees :10.1.1.32.9399
:10.1.1.72.7289
statistical analysis dependence structure trees :10.1.1.102.5478
various rejection criteria de ned terms example image classi ed value mode exceeds value multiple value second mode 
handwritten digit recognition classi cation rates handwritten digit recognition somewhat di cult assess state art example test sets widely considered di cult 
nist competition best recognition rate zero percent rejection best half systems error rates percent see 
test set nist test data considered quite di cult recognition rates reported instance portions nist training set nist special database usps test set generally higher 
example nearest neighbor system study achieves training points nist training database 
best reported rates obtained research group training testing composites nist training test sets see 
experiments portions nist database consists approximately binary images isolated digits written writers 
images vary widely dimensions ranging rows vary stroke thickness attributes 
training testing 
overlap writers 
random sample test set shown top 
studies mentioned utilize pre processing thinning slant correction size normalization 
utilize post processing example shown additional training data second classi er dedicated mistakes marginal decisions original classi er see 
procedure boosting iterated 
unfortunately requires large training sets ability create arti cial data 
order compare method cited random sample test images pre processing 
experiments pre processing 
speci cally images training set converted pose slant correcting crude form scaling 
slant image taken slope regression line tted set stroke pixels squares slant corrected applying linear transformation row bring regression line vertical orientation 
images fewer rows scaled sampled exactly rows blurring sub sampling regular lattice preserving aspect ratio original 
known virtually loss information resolution character images 
show result slant correcting scaling 
best error rate achieved single tree 
contrast standard recursive partitioning grow prune back approach designed avoid tting 
context multiple trees problem appears importance 
splitting number data points second largest class falls 
trees 
depth terminal nodes number questions random sample incorrectly classi ed digits 
asked tree varies widely average trees 
average number terminal nodes 
pre processed scaled slant corrected test set manner training set 
average classi cation rate tree determined mode terminal distribution 
aggregating trees classi cation rate climbs rejection 
show random sample digits classify incorrectly 
classi cation rate function rejection rate interest 
rejection ratio mode highest class aggregate distribution 
example classi cation rate percent rejection percent rejection 
doubling number trees classi cation rates zero percent rejection respectively error rate vs rejection rate curve shown 
performed second experiment test data pre processed manner training data fact test images classi ed utilizing pixel dimensions digits 
particular size bounding box irrelevant 
test image classi ed set trees resolutions original halved xed 
highest resulting modes determines classi cation 
crude version active testing discrete set poses searched match pose 
classi cation rate 
properties classi ers accuracy important error rate reject rate error rate vs reject rate training time storage requirements recognition time 
nearest neighbor classi ers re quire training considerable memory relatively slow neural networks slow train fast line 
classi er relatively easy train probably comparable speed neural networks lenet easy determine 
classify approximately digits second single processor sun sparcstation special orts optimize code time approximately equally divided extracting tags image sending trees 
reported progress classifying handwritten digits features candidates splitting rules recursive partitioning 
rst step transforming image replacing pixel values bit codes characterize local topography vicinity boundaries 
contrast distinguished point features codes primitive redundant particular points disambiguate shapes 
discriminating power derives spatial relationships codes 
binary feature arrangement 
know decision trees er powerful mechanism feature selection standard method constructing trees practical feature set virtually nite 
remedy utilize natural partial ordering arrangements randomization added bene reducing statistical dependence tree tree 
general algorithm tree construction entire feature set 
particular subset features problem dependent determined inductively training samples 
explicit modeling 
apply training set handwritten digits change images contained shapes hundreds shape classes see :10.1.1.102.5478
main reason property semi invariance signi cant linear nonlinear deformations generic attribute entire feature set 
features separate classes small number samples separate new samples 
speed error rates achieved nist database advanced neural networks special hardware 
advantages simplicity automation portability due built invariance rich world spatial relationships 
currently trying extend method visual recog nition problems involving grey level images structured backgrounds dimensional objects 
acknowledgment 
grateful george nagy sharing insights decision trees ocr problem valuable advice presentation 
wilkinson geist janet hammond hull larsen wilson rst census optical character recogni tion system conference tech 
rep nistir nat 
inst 
standards technol gaithersburg md 
bottou cortes denker drucker guyon jackel lecun muller sackinger simard vapnik comparison classi er methods case study handwritten digit recognition proc 
ieee inter 
conf 
pattern recognition pp 
lecun boser denker henderson howard hubbard jackel handwritten digit recognition back propagation network advances neural information ed vol 
denver morgan kau man 
boser guyon vapnik training algorithm optimal margin classi ers proceedings colt ii philadelphia pa 
hastie buja tibshirani penalized discriminant analysis annals statistics vol 
pp 

massively parallel handwritten character recognition distance transform pattern recognition vol 
pp 

simard lecun denker memory character recognition ing transformation invariant metric ieee inter 
conf 
pattern recog pp 

smith sims voorhees handwritten character classi cation nearest neighbor large databases ieee trans 
pami vol 
pp 

multiple binary decision tree classi ers pattern recognition vol 
pp 

wang suen analysis design decision tree entropy reduction application large character set recognition ieee trans 
pami vol pp 
ho hull srihari decision combination multiple classi er systems ieee trans 
pami vol 
pp 

huang suen combination multiple experts recognition unconstrained handwritten numerals ieee trans 
pami vol 
pp 

reiss recognizing planar objects invariant image features 
lecture notes computer science berlin springer verlag 
mundy zisserman geometric invariance computer vision 
cambridge mit press 
sabourin optical character recognition neural network neural networks vol 
pp 

cho dunn learning shape classes ieee trans 
pami vol 
pp 

amit geman shape quantization recognition randomized trees tech :10.1.1.102.5478
rep department statistics university chicago 
object recognition geometric queries proc 
image com bordeaux france 
wilkinson nist special database 
handwritten segmented characters 
nist gaithersburg md breiman bagging predictors tech :10.1.1.32.9399
rep department statistics university california berkeley 
kwok carter multiple decision trees uncertainty arti cial intelligence shachter levitt kanal lemmer eds north holland amsterdam elsevier science publishers 
oliver hand averaging decision stumps proc 
ecml bergadano de raedt eds berlin springer verlag 
dietterich bakiri solving multiclass learning problems error correcting output codes arti cial intell :10.1.1.72.7289
res vol 
pp 

hull database handwritten text recognition research ieee trans 
pami vol 
pp 

drucker schapire simard boosting performance neural networks int 
pattern recog 
vol 
pp 

breiman friedman olshen stone classi cation regression trees 
belmont ca wadsworth 

