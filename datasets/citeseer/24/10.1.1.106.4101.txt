siam sci 
comput 
society industrial applied mathematics vol 
pp 
fast high quality multilevel scheme partitioning irregular graphs george karypis vipin kumar 
number researchers investigated class graph partitioning algorithms reduce size graph collapsing vertices edges partition smaller graph construct partition original graph bui jones proc 
th siam conference parallel processing scientific computing hendrickson leland multilevel algorithm partitioning graphs tech 
report sand sandia national laboratories albuquerque nm 
early clear multilevel techniques held great promise known consistently produce high quality partitions graphs arising wide range application domains 
investigate effectiveness different choices phases coarsening partition coarsest graph refinement 
particular new coarsening heuristic called heavy edge heuristic size partition coarse graph small factor size final partition obtained multilevel refinement 
faster variation kernighan lin kl algorithm refining uncoarsening 
test scheme large number graphs arising various domains including finite element methods linear programming vlsi transportation 
experiments show scheme produces partitions consistently better produced spectral partitioning schemes substantially smaller time 
scheme compute fill reducing orderings sparse matrices produces orderings substantially smaller fill widely multiple minimum degree algorithm 
key words 
graph partitioning parallel computations fill reducing orderings finite element computations ams subject classifications 
pii 


graph partitioning important problem extensive applications areas including scientific computing vlsi design task scheduling 
problem partition vertices graph roughly equal parts number edges connecting vertices different parts minimized 
example solution sparse system linear equations ax iterative methods parallel computer gives rise graph partitioning problem 
key step iteration methods multiplication sparse matrix dense vector 
partition graph corresponding matrix significantly reduce amount communication parallel sparse matrix vector multiplication 
parallel direct methods solve sparse system equations graph partitioning algorithm compute fill reducing ordering leads high degree concurrency factorization phase 
multiple minimum degree ordering exclusively serial direct meth received editors june accepted publication revised form january published electronically august 
supported army research office contract da daah nsf ccr ibm partnership award army high performance computing research center auspices department army army research laboratory cooperative agreement daah contract daah 
access computing facilities provided minnesota supercomputer institute cray research pittsburgh supercomputing center 
www siam org journals sisc html department computer science engineering university minnesota minneapolis mn karypis cs umn edu kumar cs umn edu 
george karypis vipin kumar ods suitable parallel direct methods provides little concurrency parallel factorization phase 
graph partitioning problem np complete 
algorithms developed find reasonably partition 
spectral partitioning methods known produce partitions wide class problems quite extensively 
methods expensive require computation eigenvector corresponding second smallest eigenvalue fiedler vector 
execution time spectral methods reduced computation fiedler vector done multilevel algorithm 
multilevel spectral bisection msb algorithm usually manages speed spectral partitioning methods order magnitude loss quality edge cut 
msb take large amount time 
particular parallel direct solvers time computing ordering msb orders magnitude higher time taken parallel factorization algorithm ordering time dominate time solve problem 
class graph partitioning techniques uses geometric information graph find partition 
geometric partitioning algorithms tend fast yield partitions worse obtained spectral methods 
prominent schemes algorithm described 
algorithm produces partitions provably bounds exist special classes graphs includes graphs arising finite element applications 
due randomized nature algorithms multiple trials required obtain solutions comparable quality spectral methods 
multiple trials increase time runtime substantially lower time required spectral methods 
geometric graph partitioning algorithms applicable coordinates available vertices graph 
problem areas linear programming vlsi geometry associated graph 
algorithm proposed compute coordinates graph vertices spectral methods 
methods expensive dominate time taken graph partitioning algorithm 
class graph partitioning algorithms reduces size graph coarsen graph collapsing vertices edges partitions smaller graph construct partition original graph 
called multilevel graph partitioning schemes 
researchers investigated multilevel schemes primarily decrease partitioning time cost somewhat worse partition quality 
number multilevel algorithms proposed refine partition uncoarsening phase 
schemes tend give partitions reasonable cost 
bui jones random maximal matching successively coarsen graph vertices partition smallest graph graph level level applying kl algorithm refine partition 
hendrickson leland enhance approach edge vertex weights capture collapsing vertex edges 
particular showed multilevel schemes provide better partitions spectral methods lower cost variety finite element problems 
build hendrickson leland 
experiment various parameters multilevel algorithms effect quality partition ordering 
investigate effectiveness different choices multilevel graph partitioning phases coarsening partition coarsest graph refinement 
particular new coarsening heuristic called heavy edge heuristic size partition coarse graph small factor size final partition obtained multilevel refinement 
new variation kl algorithm refining partition uncoarsening phase faster kl refinement 
test scheme large number graphs arising various domains including finite element methods linear programming vlsi transportation 
experiments show scheme consistently produces partitions better produced spectral partitioning schemes substantially smaller times times faster multilevel spectral bisection 
compared multilevel scheme scheme times faster consistently better terms cut size 
improvement runtime comes faster refinement heuristic improvement quality due heavy edge heuristic coarsening 
graph partitioning scheme compute fill reducing orderings sparse matrices 
surprisingly scheme substantially outperforms multiple minimum degree algorithm commonly method computing fill reducing orderings sparse matrix 
multilevel algorithms quite fast compared spectral methods bottleneck sparse system equations solved parallel 
coarsening phase methods relatively easy parallelize kl heuristic refinement phase difficult parallelize 
coarsening phase refinement phase kl heuristic take roughly amount time runtime multilevel scheme reduced significantly 
new faster methods refinement reduce bottleneck substantially 
fact parallel implementation multilevel partitioning able get speedup processor cray moderate size problems 
remainder organized follows 
section defines graph partitioning problem describes basic ideas multilevel graph partitioning 
sections describe different algorithms coarsening initial partitioning uncoarsening phase respectively 
section presents experimental evaluation various parameters multilevel graph partitioning algorithms compares performance multilevel spectral bisection algorithm 
section compares quality orderings produced multilevel nested dissection produced multiple minimum degree spectral nested dissection 
section provides summary various results 
short version appears 

graph partitioning 
way graph partitioning problem defined follows graph partition subsets vk vi vj vi vi number edges incident vertices belong different subsets minimized 
way graph partitioning problem naturally extended graphs weights associated vertices edges graph 
case goal partition vertices disjoint subsets sum vertex weights msb algorithm chaco graph partitioning package obtain timings msb 
george karypis vipin kumar subset sum edge weights incident vertices belong different subsets minimized 
way partition commonly represented partition vector length vertex integer indicating partition vertex belongs 
partition number edges incident vertices belong different subsets called edge cut partition 
efficient implementation parallel algorithms usually requires solution graph partitioning problem vertices represent computational tasks edges represent data exchanges 
depending amount computation performed task vertices assigned proportional weight 
similarly edges assigned weights reflect amount data need exchanged 
way partitioning computation graph assign tasks processors 
partitioning assigns processor tasks total weight balanced processors 
furthermore algorithm minimizes edge cut subject balanced load requirements communication overhead minimized 
example sparse matrix vector multiplication ax 
matrix vector usually partitioned rows processors receiving rows corresponding elements 
matrix vertex graph ga constructed row matrix corresponds vertex row nonzero entry column edge vertex vertex discussed edges connecting vertices different partitions lead communication retrieving value vector local needed perform dot product 
order minimize communication overhead need obtain way partition ga distribute rows partition 
important application recursive bisection find fill reducing ordering sparse matrix factorization 
algorithms generally referred nested dissection ordering algorithms 
nested dissection recursively splits graph equal halves selecting vertex separator desired number partitions obtained 
way obtaining vertex separator obtain bisection graph compute vertex separator edge separator 
vertices graph numbered level recursion separator vertices numbered vertices partitions 
effectiveness complexity nested dissection scheme depend separator computing algorithm 
general small separators result low fill 
way partition problem frequently solved recursive bisection 
obtain way partition subdivide part way partitions 
log phases graph partitioned parts 
problem performing way partition solved performing sequence way partitions bisections 
scheme necessarily lead optimal partition extensively due simplicity 

multilevel graph bisection 
graph bisected multilevel algorithm 
basic structure multilevel algorithm simple 
graph coarsened vertices bisection smaller graph computed partition projected back original graph finer graph 
step graph uncoarsening partition refined 
finer graph degrees freedom refinements usually decrease edge cut 
process graphically illustrated 
coarsening phase multilevel graph partitioning multilevel graph bisection initial partitioning phase projected partition refined partition fig 

various phases multilevel graph bisection 
coarsening phase size graph successively decreased initial partitioning phase bisection smaller graph computed uncoarsening phase bisection successively refined projected larger graphs 
uncoarsening phase light lines indicate projected partitions dark lines indicate partitions produced refinement 
formally multilevel graph bisection algorithm works follows consider weighted graph weights vertices edges 
multilevel graph bisection algorithm consists phases 
coarsening phase 
graph transformed sequence smaller graphs gm vm 
partitioning phase 
way partition pm graph gm vm em computed partitions vm parts containing half vertices 
uncoarsening phase 
partition pm gm projected back going intermediate partitions pm pm 

coarsening phase 
coarsening phase sequence smaller graphs fewer vertices constructed 
graph coarsening achieved various ways 
possibilities shown 
coarsening schemes set vertices gi combined form single vertex level coarser graph gi 
set vertices gi combined form vertex gi 
refer vertex 
order bisection coarser graph respect original graph uncoarsening phase george karypis vipin kumar fig 

different ways coarsen graph 
weight vertex set equal sum weights vertices order preserve connectivity information coarser graph edges union edges vertices case vertex contains edges vertex weight edge equal sum weights edges 
useful evaluate quality partition coarser graph 
edge cut partition coarser graph equal edge cut partition finer graph 
updating weights coarser graph illustrated 
main approaches proposed obtaining coarser graphs 
approach finding random matching collapsing matched vertices second approach creating groups vertices highly connected 
approach suited graphs arising vlsi applications graphs highly connected components 
graphs arising finite element applications vertices similar connectivity patterns degree vertex fairly close average degree graph 
rest section describe basic ideas coarsening matchings 
graph gi vi ei coarser graph obtained collapsing adjacent vertices 
edge vertices collapsed consisting vertices created 
edge collapsing idea formally defined terms matchings 
matching graph set edges incident vertex 
level coarser graph gi constructed gi finding matching gi collapsing vertices matched 
unmatched vertices simply copied gi 
goal collapsing vertices matchings decrease size graph gi matching contain large number edges 
reason maximal matchings obtain successively coarse graphs 
matching maximal edge graph matching endpoints matched 
note depending matchings computed number edges multilevel graph partitioning belonging maximal matching may different 
maximal matching maximum number edges called maximum matching 
complexity computing maximum matching general higher computing maximal matching preferred 
coarsening graph matchings preserves properties original graph 
maximal planar gi maximal planar 
property show multilevel algorithm produces partitions provably planar graphs 
maximal matchings coarsen graph number vertices gi half number vertices gi require log coarsening phases coarsen graph vertices 
depending connectivity gi size maximal matching may smaller vi 
case ratio number vertices gi gi may smaller 
ratio lower threshold better coarsening phase 
type pathological condition usually arises coarsening levels case gi fairly small aborting coarsening affect performance algorithm 
remaining sections describe ways select maximal matchings coarsening 
random matching rm 
maximal matching generated efficiently randomized algorithm 
experiments randomized algorithm similar described 
random maximal matching algorithm 
vertices visited random order 
vertex matched randomly select unmatched adjacent vertices 
vertex exists include edge matching mark vertices matched 
unmatched adjacent vertex vertex remains unmatched random matching 
complexity algorithm 
heavy edge matching hem 
rm simple efficient method compute maximal matching minimizes number coarsening levels greedy fashion 
goal find partition minimizes edge cut 
consider graph gi vi ei matching mi coarsen gi coarser graph gi vi ei induced mi 
ifa set edges define sum weights edges shown ei ei mi 
total edge weight coarser graph reduced weight matching 
selecting maximal matching mi edges large weight decrease edge weight coarser graph greater amount 
analysis shows coarser graph smaller edge weight smaller edge cut 
finding maximal matching contains edges large weight idea hem 
hem computed randomized algorithm similar computing rm described earlier 
vertices visited random order 
randomly matching vertex adjacent unmatched vertices match vertex weight edge maximum valid incident edges heavier edge 
note algorithm guarantee matching obtained maximum weight possible matchings experiments shown works 
complexity computing hem asymptotically similar computing rm 
george karypis vipin kumar light edge matching lem 
minimizing total edge weight coarser graph try maximize 
achieved finding matching mi smallest weight leading small reduction edge weight gi 
idea lem 
may lem perform useful transformation coarsening 
average degree gi produced lem significantly higher gi 
important certain partitioning heuristics kl produce partitions small amount time graphs high average degree 
compute matching minimal weight need slightly modify algorithm computing maximal weight matching section 
selecting edge matching weight largest select edge weight smallest 
complexity computing minimum weight matching 
heavy clique matching hcm 
clique unweighted graph fully connected subgraph consider set vertices 
subgraph induced defined gu eu eu consists edges belong looking cardinality eu determined close clique 
particular ratio eu goes clique small far clique 
refer ratio edge density 
heavy clique matching scheme computes matching collapsing vertices high edge density 
scheme computes matching edge density maximal 
motivation scheme subgraphs cliques cliques cut bisection 
creating contain subgraphs easier partitioning algorithm find bisection 
note scheme tries approximate graph coarsening schemes finding highly connected components 
previous schemes computing matching compute hcm randomized algorithm 
computation edge density far dealt case vertices edges original graph unit weight 
consider coarse graph gi vi ei 
vertex vi define vw weight vertex 
recall equal sum weight vertices original graph collapsed define ce sum weight collapsed edges edges collapsed form edge ei define ew weight edge 
sum weight edges coarsening collapsed definitions edge density vertices ce ce ew vw vw vw vw randomized algorithm works follows 
vertices visited random order 
unmatched vertex matched unmatched adjacent vertex edge density created combining largest possible involving unmatched adjacent vertices note hcm similar hem scheme 
difference hem matches vertices connected heavy edge irrespective contracted edge weight vertices hcm matches pair vertices multilevel graph partitioning connected heavy edge vertices high contracted edge weight 

partitioning phase 
second phase multilevel algorithm computes high quality bisection small edge cut pm coarse graph gm vm em part contains roughly half vertex weight original graph 
coarsening weights vertices edges coarser graph set reflect weights vertices edges finer graph gm contains sufficient information intelligently enforce balanced partition small edge cut requirements 
partition gm obtained various algorithms spectral bisection geometric bisection coordinates available combinatorial methods 
size coarser graph gm small vm step takes small amount time 
implemented different algorithms partitioning coarse graph 
algorithm uses spectral bisection 
algorithms combinatorial nature try produce bisections small edge cut various heuristics 
algorithms described sections 
choose geometric bisection algorithms coordinate information available test graphs 

spectral bisection sb 
sb algorithm spectral information partition graph 
algorithm computes eigenvector corresponding second largest eigenvalue laplacian matrix ai ew vi vj vi vj em 
eigenvector called fiedler vector 
matrix diagonal di ew vi vj vi vj em 
vertex set vm partitioned parts follows 
ith element vector 
vertices yj vertices 
interested bisections equal size value chosen weighted median values yi 
eigenvector computed lanczos algorithm 
algorithm iterative number iterations required depends desired accuracy 
experiments set accuracy maximum number iterations 

kl algorithm 
kl algorithm iterative nature 
starts initial bipartition graph 
iteration searches subset vertices part graph swapping leads partition smaller edge cut 
subsets exist swap performed partition iteration 
algorithm continues repeating entire process 
find subsets algorithm terminates partition local minimum improvement kl algorithm 
iteration kl algorithm described takes log time 
improvements original kl algorithm coordinates vertices successive coarser graphs constructed midpoint coordinates combined vertices 
george karypis vipin kumar developed 
algorithm fiduccia mattheyses reduces complexity appropriate data structures 
kl algorithm finds locally optimal partitions starts initial partition average degree graph large 
initial partition known kl algorithm repeated different randomly selected initial partitions yields smallest edge cut selected 
requiring multiple runs expensive especially graph large 
partitioning smaller coarse graph performing multiple runs requires little time 
experience shown kl algorithm requires different runs find partition 
implementation kl algorithm algorithm described fiduccia mattheyses fm certain modifications significantly reduce run time 
suppose initial partition vertices 
gain gv vertex defined reduction edge cut vertex moves partition 
gain gv weight edge 
gv positive moving partition edge cut decreases gv gv negative edge cut increases amount 
vertex moved partition gains vertices adjacent may change 
moving vertex need update gains adjacent vertices 
definition gain kl algorithm proceeds repeatedly selecting larger part vertex largest gain moves part 
moving marked considered iteration gains vertices adjacent updated reflect change partition 
original kl algorithm continues moving vertices partitions vertices moved 
implementation kl algorithm terminates edge cut decrease vertex moves 
vertex moves decrease edge cut may increased undone 
setting works quite test cases 
note terminating kl iteration fashion significantly reduces runtime kl iteration 
efficient implementation algorithm depends method compute gains graph type data structure store gains 
implementation kl algorithm described appendix 

graph growing partitioning algorithm ggp 
simple way bisecting graph start vertex grow region breath fashion half vertices included half total vertex weight 
quality ggp sensitive choice vertex start growing graph different starting vertices yield different edge cuts 
partially solve problem randomly select vertices grow different regions 
trial smaller edge cut selected partition 
partition refined input kl fm algorithm slightly different originally developed kernighan lin 
difference step fm algorithm moves single vertex part kl algorithm selects pair vertices part moves 
multilevel graph partitioning algorithm 
gm small step takes small percentage total time 

greedy graph growing partitioning algorithm gggp 
ggp described previous section grows partition strict breadth fashion 
kl algorithm vertex define gain edge cut obtained inserting growing region 
order vertices graph frontier nondecreasing order gain 
vertex largest decrease smallest increase edge cut inserted 
vertex inserted growing partition gains adjacent vertices frontier updated frontier inserted 
note data structures required implement scheme essentially required kl algorithm 
difference precomputing gains vertices vertices touched frontier 
greedy algorithm sensitive choice initial vertex ggp 
implementation randomly select vertices starting point algorithm select partition smaller edge cut 
experiments gggp takes somewhat time ggp partitioning coarse graph requires fewer runs initial cut scheme better ggp 

uncoarsening phase 
uncoarsening phase partition pm coarser graph gm projected back original graph going graphs gm gm 
vertex gi contains distinct subset vertices gi obtaining pi pi done simply assigning set vertices collapsed gi partition pi pi pi 
pi local minimum partition gi projected partition pi may local minimum respect gi 
gi finer degrees freedom improve pi decrease 
may possible improve projected partition gi local refinement heuristics 
reason projecting partition partition refinement algorithm 
basic purpose partition refinement algorithm select subsets vertices part swapped resulting partition smaller edge cut 
specifically parts bisection refinement algorithm selects bisection smaller edge cut 
class algorithms tends produce results kl partition algorithm described section 
recall kl algorithm starts initial partition iteration finds subsets properties 
sections describe different refinement algorithms similar ideas differ time require refinement 
details efficient implementation schemes appendix 

kl refinement 
idea kl refinement projected partition gi gi initial partition kl algorithm described section 
reason projected partition partition kl converge iterations better partition 
test cases kl usually converges iterations 
starting partition small number vertex swaps george karypis vipin kumar decrease edge cut swaps increase size cut vertices negative gains 
recall section implementation single iteration kl algorithm stops soon swaps performed decrease edge cut 
feature reduces runtime kl applied refinement algorithm small number vertices lead edge cut reductions 
experimental results show test cases usually achieved small percentage vertices swapped results significant savings total execution time refinement algorithm 
terminate pass kl algorithm improvement edge cut complexity kl refinement scheme described previous section dominated time required insert vertices appropriate data structures 
significantly reduced number vertices swapped complexity change asymptotic terms 
furthermore experience shows largest decrease edge cut obtained pass 
kl refinement algorithm take advantage running single iteration kl algorithm 
usually reduces total time taken refinement factor section 

boundary kl refinement 
kl kl refinement algorithms insert gains vertices data structures 
terminate algorithms soon longer reduce edge cut computation wasted 
furthermore due nature refinement algorithms nodes swapped kl kl algorithms boundary cut defined vertices edges cut partition 
boundary kl refinement algorithm initially insert data structures gains boundary vertices 
kl refinement algorithm swap vertex update gains adjacent vertices swapped 
adjacent vertices boundary vertex due swap insert data structures positive gain 
notice boundary refinement algorithm quite similar kl algorithm added advantage vertices inserted data structures needed wasted 
kl choice performing single pass boundary kl refinement bkl multiple passes boundary kl refinement bkl refinement algorithm converges 
opposed refinement algorithms cost performing multiple passes boundary algorithms small boundary vertices examined 
reduce execution time boundary refinement maintaining refinement capabilities bkl speed bkl combine schemes hybrid scheme refer bkl 
idea bkl policy bkl long graph small switch bkl graph large 
motivation scheme single vertex swaps coarser graphs lead larger decreases edge cut finer graphs 
bkl coarser graphs better refinement achieved graphs small compared size original graph bkl algorithm require lot time 
experiments number vertices boundary coarse graph number vertices original graph refinement performed multilevel graph partitioning bkl bkl 
choice triggering condition relates size partition boundary proportional cost performing refinement graph original size graph determine inexpensive perform bkl relative size graph 

experimental results graph partitioning 
evaluated performance multilevel graph partitioning algorithm wide range graphs arising different application domains 
characteristics matrices described table 
experiments performed sgi challenge gbytes memory mhz mips processor 
times reported seconds 
nature multilevel algorithm discussed randomized performed experiments fixed seed 
furthermore coarsening process ends coarse graph fewer vertices 
discussed sections alternatives different phases multilevel algorithm 
possible provide exhaustive comparison possible combinations making unduly large 
provide comparisons different alternatives phase making reasonable choice phases 
table various matrices evaluating multilevel graph partitioning sparse matrix ordering algorithm 
graph name 
vertices 
edges description finite element mesh elt finite element mesh finite element mesh add bit adder auto finite element mesh bcsstk stiffness matrix bcsstk stiffness matrix bcsstk stiffness matrix stiffness matrix brack finite element mesh cant stiffness matrix finite element mesh cylinder stiffness matrix linear programming flap stiffness matrix stiffness matrix ken linear programming lhr chemical engineering lhr chemical engineering finite element mesh map highway network map highway network memory circuit pds linear programming finite element mesh rotor finite element mesh sequential circuit shell stiffness matrix cfd navier stokes torso finite element mesh troll stiffness matrix venkat coefficient matrix wave finite element mesh george karypis vipin kumar 
matching schemes 
implemented matching schemes described section results way partition matrices shown table 
schemes rm hem lem hcm 
experiments gggp algorithm initial partition phase bkl refinement policy uncoarsening phase 
matching scheme table shows edge cut time required coarsening phase ctime time required uncoarsening phase utime 
utime sum time spent partitioning coarse graph time spent refinement time spent projecting partition coarse graph level finer graph ptime 
terms size edge cut clear cut winner various matching schemes 
values ec schemes matrices 
schemes rm produces best partition matrices hem matrices lem hcm 
time spent coarsening vary significantly different schemes 
rm hem require amount time coarsening lem hcm require time rm 
surprising rm looks unmatched neighbor vertex adjacency lists randomly permuted 
hand hcm needs find edge maximum edge density lem produces coarser graphs vertices higher degree schemes lem requires time find matching create level coarser graph 
coarsening time required hem slightly higher time required rm 
comparing time spent uncoarsening see hem hcm require amount time lem requires 
cases lem requires times time hem hcm 
explained results shown table 
table shows edge cut way partition refinement performed final edge cut exactly initial partition coarsest graph 
edge cut lem coarser graphs significantly higher hem hcm 
components utime increase lem relative schemes 
higher coarser graph edges increases large number vertices need swapped reduce edge cut ptime increases vertices boundary requires computation described appendix 
time spent uncoarsening rm higher time required hem scheme matrices somewhat similar reasons 
discussion previous paragraphs see utime smaller ctime hem hcm utime comparable ctime rm lem 
furthermore hem hcm problem size increases utime smaller fraction ctime 
discussed particular importance parallel formulation multilevel algorithm considered 
experiments show hem excellent matching scheme results initial partitions requires smallest runtime 
selected hem matching scheme choice consistently behavior 

initial partition algorithms 
described section number algorithms partition coarse graph 
implemented algorithms sb ggp gggp 
multilevel graph partitioning rm hem lem hcm ec ctime utime ec ctime utime ec ctime utime ec ctime utime bcsstk bcsstk brack cant cylinder elt rotor shell troll wave table performance various matching algorithms coarsening phase 
ec size edge cut way partition ctime time spent coarsening utime time spent uncoarsening phase 
george karypis vipin kumar table size edge cut way partition refinement performed various matching schemes 
rm hem lem hcm bcsstk bcsstk brack cant cylinder elt rotor shell troll wave result partitioning algorithms matrices shown table 
partitions produced hem coarsening bkl refinement policy uncoarsening 
quantities reported partitioning algorithm 
edge cut initial partition coarsest graph iec edge cut way partition ec edge cut way partition ec combined time spent partitioning refinement way partition 
number interesting observations table 
edge cut initial partition iec gggp scheme consistently smaller schemes elt exception sb slightly better 
sb takes time ggp gggp partition coarse graph 
schemes fairly small experiments 
difference runtime different initial partition schemes due refinement time associated 
furthermore sb produces partitions significantly worse produced ggp gggp shown iec column table 
happens iterative algorithm compute eigenvector converge allowable number iterations initial partition spectral algorithm far local minimum 
edge cut way way partitions considered sb scheme worse ggp gggp relative difference values ec ec smaller iec 
way partition sb performs better matrix way partition matrices 
comparing gggp ggp see gggp performs better ggp matrices way partition matrices way partition 
average ec sb worse gggp requires time ggp worse gggp requires time 
looking combined time required partitioning refinement see gggp case requires amount time 
initial partition gggp better ggp initial partition leads time spent refinement uncoarsening phase 
particular matrix experiments set maximum number iterations 
multilevel graph partitioning sb ggp gggp iec ec ec iec ec ec iec ec ec bcsstk bcsstk brack cant cylinder elt rotor shell troll wave table performance various algorithms performing initial partition coarse graph 
george karypis vipin kumar performance gggp better close best scheme terms edge cut runtime 
implemented kl partitioning algorithm section 
performance consistently worse gggp terms iec required runtime 
omitted results 
summary results table show gggp consistently finds smaller edge cuts schemes requires slightly smaller runtime 
furthermore advantage choosing spectral bisection partitioning coarse graph 

refinement policies 
described section different ways partition refined uncoarsening phase 
evaluated performance refinement policies terms partition quality execution time 
refinement policies evaluate kl kl bkl bkl combination bkl bkl bkl 
result refinement policies computing way partition graphs corresponding matrices table shown table 
partitions produced hem coarsening gggp algorithm initially partitioning coarser graph 
number interesting drawn table 
matrices refinement policies size edge cut vary significantly different refinement policies best refinement policy particular matrix 
hand time required refinement policies vary significantly 
policies require times time 
kl requires time bkl requires 
comparing kl kl see kl performs better kl matrices 
matrices improvement average time required kl significantly higher kl 
usually kl requires times time kl 
comparing kl kl refinement schemes boundary variants see times required boundary policies significantly required counterparts 
time bkl ranges time kl time bkl ranges time kl 
quite reasonable bkl bkl efficient implementations kl kl respectively take advantage fact projected partition requires little refinement 
surprisingly bkl bkl lead better edge cut kl kl respectively cases 
average bkl performs similarly kl bkl better kl 
bkl better kl matrices bkl better kl matrices 
quality boundary refinement policies counterparts 
difference quality kl bkl algorithm inserts vertices kl data structures different order 
time may vertex largest gain 
different insertion order may lead different ordering vertices largest gain 
consequently kl bkl algorithms may move different subsets vertices part 
comparing bkl bkl see edge cut better bkl nearly matrices improvement relatively small average 
time required bkl higher bkl multilevel graph partitioning kl kl bkl bkl bkl ec ec ec ec ec bcsstk bcsstk brack cant cylinder elt rotor shell troll wave table performance different refinement policies 
matrices partitioned parts 
ec number edges crossing partitions time required perform refinement 
george karypis vipin kumar multilevel vs multilevel spectral bisection msb parts parts parts msb baseline elt add bcsstk bcsstk bcsstk brack cant flap lhr lhr map map rotor shell troll venkat wave fig 

quality multilevel algorithm compared multilevel spectral bisection algorithm 
matrix ratio cut size multilevel algorithm msb algorithm plotted way partitions 
bars baseline indicate multilevel algorithm performs better 
cases times higher 
marginal improvement partition quality comes significant increase refinement time 
comparing bkl bkl see edge cut average bkl runtime significantly smaller bkl somewhat higher bkl 
summary bkl bkl refinement policies require substantially time kl produce smaller edge cuts coupled heavy edge matching scheme 
believe bkl refinement policy strikes balance small edge cut fast execution 

comparison partitioning schemes 
msb shown effective method partitioning unstructured problems variety applications 
msb algorithm graph vertices random matching 
partitions coarse graph spectral bisection obtains fiedler vector coarser graph 
uncoarsening obtains approximate fiedler vector level fine graph interpolating fiedler vector coarser graph computes accurate fiedler vector 
multilevel approach msb algorithm able compute fiedler vector graph time taken original spectral bisection algorithm 
note msb significantly different scheme multilevel scheme uses spectral bisection partition graph coarsest level 
msb algorithm chaco graph partitioning package produce partitions matrices table compared results partitions produced multilevel algorithm uses hem coarsening phase gggp partitioning phase bkl uncoarsening phase 
shows relative performance multilevel algorithm compared msb 
matrix plot ratio edge cut multilevel algorithm edge cut msb algorithm 
ratios indicate multilevel graph partitioning multilevel vs multilevel spectral bisection kernighan lin msb kl parts parts parts msb kl baseline elt add bcsstk bcsstk bcsstk brack cant flap lhr lhr map map rotor shell troll venkat wave fig 

quality multilevel algorithm compared multilevel spectral bisection algorithm kl refinement 
matrix ratio cut size multilevel algorithm msb kl algorithm plotted way partitions 
bars baseline indicate multilevel algorithm performs better 
multilevel algorithm produces better partitions msb 
see problems algorithm produces partitions smaller produced msb 
cases improvement high 
furthermore time required multilevel algorithm significantly smaller required msb 
shows time required different algorithms relative required multilevel algorithm 
see compared msb algorithm usually times faster small problems times faster larger problems 
way improving quality msb algorithm kl algorithm refine partitions msb kl 
shows relative performance multilevel algorithm compared msb kl algorithm 
comparing figures see kl algorithm improve quality msb algorithm 
multilevel algorithm produces better partitions msb kl problems 
kl refinement increases runtime scheme shown making difference runtime msb kl multilevel algorithm greater 
graph partitioning package chaco implements multilevel graph partitioning algorithm modeled algorithm hendrickson leland 
algorithm refer chaco ml uses rm coarsening sb partitioning coarse graph kl refinement coarsening level uncoarsening phase 
shows relative performance multilevel algorithms compared chaco ml 
see multilevel algorithm usually produces partitions smaller edge cuts chaco ml 
problems improvement algorithm 
cases chaco ml better marginally better 
algorithm usually times faster chaco ml 
savings come choice refinement policy bkl usually times faster kl refinement implemented chaco ml 
george karypis vipin kumar multilevel vs chaco multilevel chaco ml parts parts parts chaco ml baseline fig 

quality multilevel algorithm compared multilevel chaco ml algorithm 
matrix ratio cut size multilevel algorithm chaco ml algorithm plotted way partitions 
bars baseline indicate multilevel algorithm performs better 
chaco ml msb msb kl multilevel baseline relative run times way partition elt add bcsstk bcsstk bcsstk brack cant flap lhr lhr map map rotor elt shell add bcsstk troll bcsstk venkat bcsstk wave brack cant flap lhr lhr map map rotor shell troll venkat wave fig 

time required find way partition chaco ml msb msb kl relative time required multilevel algorithm 
note able bkl quality penalty hem coarsening scheme 
addition gggp method partitioning coarser graph requires time spectral bisection chaco ml 
difference cases graph coarsening phase aborts number vertices small 
problems lanczos algorithm converge explains poor performance chaco ml graphs map 
table shows edge cuts way way way partitions different algorithms 
table shows runtime different algorithms finding way partition 
multilevel graph partitioning msb msb kl chaco ml multilevel matrix ec ec ec ec ec ec ec ec ec ec ec ec elt add auto bcsstk bcsstk bcsstk brack cant cylinder flap ken lhr lhr map map pds rotor shell torso troll venkat wave table edge cuts produced msb msb followed kl msb kl multilevel algorithm implemented chaco chaco ml multilevel algorithm 
george karypis vipin kumar table time required find way partition msb msb followed kl msb kl multilevel algorithm implemented chaco chaco ml multilevel algorithm 
times seconds 
matrix msb msb kl chaco ml multilevel elt add auto bcsstk bcsstk bcsstk brack cant cylinder flap ken lhr lhr map map pds rotor shell torso troll venkat wave 
experimental results sparse matrix ordering 
multilevel graph partitioning algorithm find fill reducing ordering symmetric sparse matrix recursive nested dissection 
nested dissection ordering algorithms vertex separator computed edge separator way partition 
vertex separator parts vertex set separated nested dissection ordering ordered second vertices numbered 
ordered recursively applying nested dissection ordering 
multilevel nested dissection mlnd algorithm vertex separator computed edge separator finding minimum vertex cover 
minimum vertex cover produce small vertex separators 
quality fill reducing ordering depends matrix factored serial parallel computer 
serial computer ordering requires smaller number operations factorization 
number operations required usually related number nonzeros cholesky factors 
fewer nonzeros usually lead fewer operations 
multilevel graph partitioning table number operations required factor various matrices ordered multiple minimum degree mmd spectral nested dissection snd multilevel nested dissection mlnd 
matrix mmd snd mlnd elt auto bcsstk bcsstk bcsstk brack cant cylinder flap rotor shell torso troll wave similar fills may different operation counts comparisons section terms number operations 
parallel computer fill reducing ordering minimizing operation count increase degree concurrency exploited factorization 
general nested orderings exhibit concurrency factorization minimum degree orderings 
minimum degree ordering heuristic widely fill reducing algorithm order sparse matrices factorization serial computers 
minimum degree algorithm produce orderings 
multiple minimum degree algorithm widely variant minimum degree due fast runtime 
quality orderings produced mlnd algorithm compared mmd shown table 
multilevel algorithm hem scheme coarsening gggp scheme partitioning coarse graph bkl refinement policy uncoarsening phase 
looking see algorithm produces better orderings test problems 
problems mmd better 
see mlnd consistently better size matrices increases 
particular large finite element meshes auto mlnd requires half amount memory required mmd times fewer operations 
test matrices considered mmd produces orderings require total orderings produced mlnd require 
ensemble matrices factored roughly times faster ordered mlnd 
important advantage mlnd mmd produces orderings exhibit significantly concurrency mmd 
george karypis vipin kumar mlnd snd mmd baseline elt bcsstk bcsstk bcsstk multilevel nested vs multiple minimum degree spectral nested brack cant fig 

quality multilevel nested dissection relative multiple minimum degree spectral nested dissection algorithm 
bars baseline indicate mlnd performs better mmd 
elimination trees produced mmd exhibit little concurrency long unbalanced subtree subcube mappings lead significant load imbalances 
hand orderings nested dissection produce orderings concurrency better balance 
factorization performed parallel better utilization processors cause ratio runtime parallel factorization algorithms ordered mmd mlnd substantially higher ratio respective operation counts 
mmd algorithm usually times faster mlnd ordering matrices table 
efforts parallelize mmd algorithm success 
fact mmd algorithm appears inherently serial nature 
hand mlnd algorithm amenable parallelization 
parallel formulation mlnd algorithm achieves speedup processor cray serial algorithm running single processor graphs 
spectral nested dissection snd ordering matrices parallel factorization 
snd algorithm spectral graph partitioning algorithm described section 
implemented snd algorithm described 
case mlnd minimum vertex cover algorithm compute vertex separator edge separator 
quality orderings produced multilevel nested dissection algorithm compared spectral nested dissection algorithm shown 
see mlnd produces orderings better snd test matrices 
total number operations required factor matrices ordered snd mlnd 
discussed section runtime snd substantially higher mlnd 
snd parallelized better mlnd slower mlnd 
flap rotor shell troll wave multilevel graph partitioning 
characterization different graph partitioning schemes 
due importance problem large number graph partitioning schemes developed 
schemes differ widely edge cut quality produced runtime degree parallelism applicability certain kind graphs 
clear scheme better scenarios 
section categorize properties graph partitioning algorithms commonly finite element applications 
task quite difficult possible precisely model properties graph partitioning algorithms 
furthermore don data edge cut quality runtime common pool benchmark graphs 
presents extensive comparisons multilevel scheme msb msb kl 
limited comparison schemes looking edge cut quality runtime graphs evaluation schemes 
try reasonable assumptions data available 
sake simplicity chosen represent property terms small discrete scale 
absence extensive data done better anyway 
table show different variations spectral partitioning multilevel partitioning described nested dissection kl partition coordinate nested dissection cnd variations inertial partition variants geometric partitioning 
graph partitioning algorithm table shows number characteristics 
column shows number trials performed partitioning algorithm 
example kl different trials performed starting random partition graph 
trial different run partitioning algorithm partition determined best multiple trials 
see table algorithms require single trial multiple trials give partition algorithm deterministic single trial gives results case multilevel graph partitioning 
schemes kl geometric partitioning different trials yield significantly different edge cuts schemes highly sensitive initial partition 
schemes usually require multiple trials order produce quality partitions 
multiple trials show case trials quality saturates trials run time large 
second column shows partitioning algorithm requires coordinates vertices graph 
algorithms cnd inertial coordinate information available 
require set vertices edges connecting 
third column table shows relative quality partitions produced various schemes 
additional circle corresponds roughly improvement edge cut 
edge cut quality cnd serves base shown circle 
schemes circles quality find partitions roughly better cnd 
column shows quality partitions produced multilevel graph partitioning algorithm msb kl 
quality geometric partitioning kl refinement equally trials performed 
quality schemes worse various degrees 
note kl extrapolation results shown geometric partitioning trials default geometric produces partitions comparable msb kl refinement 
george karypis vipin kumar spectral bisection multilevel spectral bisection spectral bisection kl multilevel partitioning nested dissection kernighan lin coordinate nested dissection table characteristics various graph partitioning algorithms 
inertial inertial kl geometric partitioning geometric partitioning kl number trials needs coordinates quality local view global view run time degree parallelism partitioning geometric partitioning quality improves number trials increases 
reason differences quality various schemes understood consider degree quality sum quantities refer local view global view 
graph partitioning algorithm local view graph able localized refinement 
definition graph partitioning algorithms various stages execution variations kl partitioning algorithm possess local view graph partitioning algorithms 
global view refers extent graph partitioning algorithm takes account structure graph 
instance spectral bisection algorithms take account global information graph minimizing edge cut continuous approximation discrete problem 
hand schemes single trial kl utilize graph structural information starts random bisection 
schemes require multiple trials improve amount global graph structure exploit number trials increases 
note sum circles global local view columns equal number circles quality various algorithms 
global view multilevel graph partitioning multilevel graph partitioning highest schemes 
multilevel graph partitioning captures global graph structure different levels 
captures global structure process coarsening second captures global structure initial graph partitioning performing multiple trials 
sixth column table shows relative time required different graph partitioning schemes 
cnd inertial geometric partitioning trial require relatively small amount time 
show runtime schemes square 
additional square corresponds roughly factor increase runtime 
see spectral graph partition schemes require orders magnitude time faster schemes 
quality partitions produced faster schemes relatively poor 
quality geometric partitioning scheme improved increasing number trials kl algorithm significantly increase runtime scheme 
hand multilevel graph partitioning requires moderate amount time produces partitions high quality 
degree different schemes differs significantly depicted number triangles seventh column table 
triangle means scheme largely sequential triangles means scheme exploit moderate amount parallelism triangles means scheme parallelized quite effectively 
schemes require multiple trials inherently parallel different trials done different processors 
contrast single trial kl difficult parallelize appears inherently serial nature 
multilevel schemes rely kl spectral bisection scheme moderately parallel nature 
discussed asymptotic speedup schemes bounded 
speedup obtained schemes graph nearly partitioned processors 
happen graph arises adaptively refined mesh 
schemes rely coordinate information limitation principle appears schemes parallelized quite effectively 
available parallel formulation schemes obtained better speedup obtained multilevel scheme 

direction research 
experiments multilevel schemes shown quite different types coarsening initial partition refinement schemes 
particular coarsening schemes experimented provide global view graph kl algorithm variants refinement uncoarsening phase provide local view 
due combined global local view provided coarsening refinement schemes choice algorithm partition coarse graph relatively small effect quality partition 
particular advantage gained spectral bisection partitioning coarsest graph 
multilevel algorithm find ordering consistently better snd substantially better multiple minimum degree large graphs 
reason multilevel algorithm multiple minimum degree algorithm global view graph critical performance large graphs 
multilevel algorithm uses hem coarsening bkl bkl refinement parallelized effectively 
reason combination requires little time refinement serial part algorithm 
coarsening phase relatively easier parallelize 
george karypis vipin kumar appendix implementation framework 
multilevel algorithm described section consists number different algorithms 
efficient implementation algorithms methods passing information various phases essential fast execution algorithm 
sections briefly describe algorithms data structures implementation algorithm 

graph data structure 
data structure store graph consists arrays 
array called stores information vertices second array called stores adjacency lists vertices 
vertex contains quantities weight size adjacency list index adjacency list weight edges contracted create sum weight edges adjacent quantities different phases multilevel algorithm greatly improve performance multilevel algorithm 
section shows computed incrementally coarsening increase runtime algorithm 

coarsening phase 
coarsening phase consists different stages 
stage matching stage matching computed rm hem lem hcm schemes second stage contraction stage coarser graph created contracting vertices dictated matching 
output matching stage vectors match map vertex match stores vertex matched map stores label coarser graph 
matching stage vertex remains unmatched match note pair matched vertices map map 
initially vector match initialized indicate vertices unmatched 
matching schemes randomized algorithms random permutation vector created guide order vertices visited 
vertices visited random order assigned consecutive labels 
rm matching scheme requires vertex randomly matched unmatched adjacent vertices 
avoid having traverse entire adjacency list find unmatched vertices randomly select initially permute adjacency lists vertices randomly 
doing look unmatched vertex randomization coupled random visitation order ensures randomization 
contraction step match map vectors contract graph 
vertices matched 
label contracted vertex map 
vertices adjacent map map weight edge map map 
multilevel graph partitioning efficiently implement operation matched vertices table keep track vertices seen far 
data structures allow implement graph contraction visiting edge graph contraction takes time proportional number edges 
computing adjacency list vertex coarser graph compute remaining quantities associated vertex 
computed sum 
computed sum ofv plus weight edge connecting vertices 
computed sum ofv minus weight edge connecting 

uncoarsening phase 
uncoarsening phase consists separate stages 
fist stage partition pi graph gi projected back gi projection stage second stage pi refined refinement schemes described section refinement stage 
various partition refinement schemes described section swapping vertices partitions reduction edge cut variations kl algorithm 
described section selections kl algorithm driven gain value vertex 
gain values computed arrays id ed vertex id ed 
value id called internal degree sum edge weights adjacent vertices partition value ed called external degree sum edge weights adjacent vertices different partition 
arrays gain vertex gv ed id 
note edge cut partition ed vertex belongs boundary ed 
implementation partitioning coarse graph gm algorithms described section internal external degrees vertices gm computed 
time quantities computed explicitly 
internal external degrees graphs gi mare computed incrementally projection stage 
done follows 
consider vertex vi vertices vi combined depending values id ed different cases 
ed 
case ed equal sum 
similarly ed equal sum edge weights 
id 
case id id equal weight edge computed difference contracted edge weights value ed ed equal sum edge weights minus id id 
ed id 
case value id ed computed explicitly values id ed computed difference specifically ed ed ed id id id 
vertex partition boundary need explicitly compute internal external degrees 
boundary vertices small percentage total number vertices computing internal external degrees george karypis vipin kumar projection results dramatic speed improvements 
refinement stage internal external degrees kept consistent respect partition 
done updating degrees vertices adjacent just moved partition computation required kl algorithm rolling back speculative computation refinement algorithm 
framework boundary refinement algorithms described section require inserting data structures vertices external degree positive 

data structures kl 
discussed section efficiency kl algorithm depends data structure store gains vertices swapped 
algorithm partition depending level coarse graph doubly linked list gain buckets table gain buckets 
doubly linked list maintained decreasing gain order 
vertices gain inserted gain bucket 
table gain buckets contains entry possible value gain effective range values small 
usually case gi small 
large coarser graphs range values gain get high making implementation expensive uses linked lists 
gain bucket implemented doubly linked list contains vertices particular gain 
auxiliary table stores vertex pointer node gain bucket stores table allows locate gain bucket node vertex constant time 
gains stored doubly linked list gain buckets extracting maximum gain vertex takes constant time inserting vertex takes time linear size doubly linked list 
array gain buckets inserting vertex takes constant time extracting vertex maximum gain may take constant time 
implementation boundary kl algorithm method store boundary vertices important 
possibility store boundary vertices simply determine iteration boundary kl algorithm 
determining vertex boundary simple external degree greater zero 
doing complexity boundary kl algorithm order number vertices boundary small 
implementation hash table store boundary vertices 
vertex boundary stored hash table 
size hash table set twice size boundary level finer graph 
bkl vertices move away boundary removed hash table vertices move boundary inserted hash table 
barnard simon parallel implementation multilevel recursive spectral bisection application adaptive unstructured meshes proc 
th siam conf 
parallel processing scientific computing pp 

barnard simon fast multilevel implementation recursive spectral bisection partitioning unstructured problems proc 
th siam conf 
parallel processing scientific computing pp 

multilevel graph partitioning barnes algorithm partitioning nodes graph siam alg 
discrete methods pp 

bui jones heuristic reducing fill sparse matrix factorization proc 
th siam conf 
parallel processing scientific computing pp 

bui chaudhuri leighton sipser graph bisection algorithms average case behavior combinatorica pp 

chan gilbert 
teng geometric spectral partitioning xerox parc tech 
report 
available ftp xerox com pub gilbert index html 

cheng 
wei improved way partitioning algorithm stable performance ieee trans 
comput 
aided design pp 

hendrickson leland parallel algorithms dynamically partitioning unstructured grids proc 
th siam conf 
parallel processing scientific computing pp 

fiduccia mattheyses linear time heuristic improving network partitions proc 
th ieee design automation conference pp 

steger finding clusters vlsi circuits proc 
ieee international conference computer aided design pp 

george nested dissection regular finite element mesh siam numer 
anal pp 

george 
liu computer solution large sparse positive definite systems prentice hall englewood cliffs nj 
george 
liu evolution minimum degree ordering algorithm siam rev pp 

rothberg parallel implementation multiple minimum degree ordering heuristic tech 
rep old dominion university va 
gilbert miller 
teng geometric mesh partitioning implementation experiments proc 
international parallel processing symposium 
gilbert parallel graph partitioning algorithm message passing multiprocessor internat 
parallel programming pp 

saad heuristic algorithms automatic graph partitioning tech 
rep department computer science university minnesota minneapolis 
gupta karypis kumar highly scalable parallel algorithms sparse matrix factorization ieee trans 
parallel distributed systems pp 

available www url www cs umn edu karypis 
hagen kahng fast spectral methods ratio cut partitioning clustering proc 
ieee international conference computer aided design pp 

hagen kahng new approach effective circuit clustering proc 
ieee international conference computer aided design pp 

hammond mapping unstructured grid problems massively parallel computers ph thesis rensselaer polytechnic institute troy ny 
heath 
ng peyton parallel algorithms sparse linear systems siam rev pp 
parallel algorithms matrix computations gallivan heath ng peyton plemmons sameh voigt eds siam philadelphia pa 
heath raghavan cartesian parallel nested dissection algorithm siam matrix anal 
appl pp 

hendrickson leland improved spectral graph partitioning algorithm mapping parallel computations tech 
rep sand sandia national laboratories albuquerque nm 
hendrickson leland chaco user guide version tech 
rep sand sandia national laboratories albuquerque nm 
hendrickson leland multilevel algorithm partitioning graphs tech 
report sand sandia national laboratories albuquerque nm 
karypis gupta kumar parallel formulation interior point algorithms supercomputing available online www cs umn edu karypis 
karypis kumar analysis multilevel graph partitioning tech 
rep tr department computer science university minnesota available online www cs umn edu karypis short version appears supercomputing 
karypis kumar multilevel graph partition sparse matrix ordering intl 
conf 
parallel processing available online www cs umn edu karypis 
karypis kumar parallel algorithm multilevel graph partitioning sparse matrix ordering parallel distributed computing pp 
available online www cs umn edu karypis short version appears intl 
parallel processing symposium 
george karypis vipin kumar kernighan lin efficient heuristic procedure partitioning graphs bell sys 
tech 
pp 

kumar gupta karypis parallel computing design analysis algorithms benjamin cummings publishing redwood city ca 
leighton rao approximate max flow min cut theorem uniform multicommodity flow problems applications approximation algorithms th annual symposium foundations computer science pp 

lipton tarjan separator theorem planar graphs siam appl 
math pp 


liu modification minimum degree algorithm multiple elimination acm trans 
math 
software pp 

miller 
teng thurston vavasis automatic mesh partitioning sparse matrix computations graph theory issues algorithms george gilbert 
liu eds 
ima workshop volume springer verlag new york 
miller 
teng vavasis unified geometric approach graph separators proc 
st annual symposium foundations computer science pp 

solving finite element equations concurrent computers amer 
soc 
mech 
engrg ed pp 

ciarlet validity front oriented approach partitioning large sparse graphs connectivity constraint tech 
rep computer science department ucla los angeles ca 
paige saunders solution sparse indefinite systems linear equations siam numer 
anal pp 

papadimitriou steiglitz combinatorial optimization prentice hall englewood cliffs nj 
parlett symmetric eigenvalue problem prentice hall englewood cliffs nj 
mansour choudhary fox graph contraction physical optimization methods quality cost tradeoff mapping data parallel computers international conference supercomputing acm new york 
pothen 
fan computing block triangular form sparse matrix acm trans 
math 
software pp 

pothen simon 
liou partitioning sparse matrices eigenvectors graphs siam matrix anal 
appl pp 

pothen simon wang spectral nested dissection tech 
rep computer science department pennsylvania state university university park pa 
pothen simon wang bernard fast implementation spectral nested dissection supercomputing proceedings ieee computer society press washington dc pp 

raghavan line plane separators tech 
rep uiucdcs department computer science university illinois urbana il february 
