taxonomy data grids distributed data sharing management processing rajkumar buyya ramamohanarao grid computing distributed systems laboratory department computer science software engineering university melbourne australia email raj rao cs mu oz au data grids adopted generation platform scientific communities need share access transport process manage large data collections distributed worldwide 
combine high computing technologies high performance networking wide area storage management techniques 
discuss key concepts data grids compare data sharing distribution paradigms content delivery networks peer peer networks distributed databases 
provide comprehensive taxonomies cover various aspects architecture data transportation data replication resource allocation scheduling 
map proposed taxonomy various data grid systems validate taxonomy identify areas exploration 
generation scientific applications domains diverse high energy physics molecular modeling earth sciences involve production large datasets simulations large scale experiments 
analysis datasets dissemination researchers located wide geographic area requires high capacity resources supercomputers high bandwidth networks mass storage systems 
collectively large scale applications come known part science hey trefethen discipline high computing storage networking web technologies facilitate collaborative data intensive scientific research requires new paradigms internet computing address issues multi domain applications operation ordination resource owners blurring system boundaries 
grid computing foster kesselman paradigm proposes aggregating geographically distributed heterogeneous computing storage network resources provide unified secure pervasive access combined capabilities 
aggregations called grids 
data grids chervenak hoschek primarily deal providing services infrastructure distributed data intensive applications need access transfer modify massive datasets stored distributed storage resources 
users derive maximum benefits infrastructure capabilities needed ability search numerous known research inclusion digital libraries humanities community 
available datasets required dataset discover suitable data resources accessing data ability transfer large sized datasets resources short time possible ability users manage multiple copies data ability select suitable computational resources process data ability manage access permissions data 
content delivery networks peer peer file sharing networks distributed databases paradigms similar requirements supporting distributed data intensive infrastructure 
section provide general overview systematic characterization data grids thorough examination differences distributed data intensive mechanisms mentioned 
rapid emergence data grids scientific commercial settings led variety systems offering solutions dealing distributed data intensive applications 
unfortunately led difficulty evaluating solutions confusion pinpointing exact target areas 
taxonomy provided section breaks research data grids specialised areas categorizes turn 
section section surveys representative projects publications classifies taxonomy 
studies investigated surveyed grid research past 

taxonomy various grid resource management systems focuses general resource management architectures scheduling policies 
specifically data grids newman provide extensive survey projects high energy physics qin jiang produce compilation concentrates constituent technologies 
moore identify functional requirements features capabilities components persistent archival system 
contrast papers finkelstein 
spell requirements data grids software engineering perspective elaborate impact architectural choices 
similar characterisation performed 

concentrates issues pertaining data intensive application environments including data grids 
provides detailed complete understanding data grids underlying technologies multiple perspectives including resource allocation data management user requirements 
main objective delineate clearly uniqueness data grids similar paradigms provide basis categorising developments area 
aims provide readers understanding essential concepts rapidly changing research area helps identify important outstanding issues investigation 
overview terms definitions data intensive computing environment consists applications produce manipulate analyse data range hundreds megabytes mb petabytes pb moore 
data organised collections datasets typically stored mass storage systems called repositories tape libraries disk arrays 
datasets accessed users different locations may create local copies replicas datasets reduce latencies involved wide area data transfers improve application performance 
replica may complete partial copy original dataset 
replica management system data replication mechanism allows users create register manage replicas may update replicas original datasets modified 
system may create replicas guided replication strategies take account current demand datasets locality requests storage capacity repositories 
metadata data data information describes datasets consist attributes name time creation size disk time modification 
metadata may contain specific information details process produced data 
replica catalog contains information locations datasets associated replicas metadata associated datasets 
users query catalog metadata attributes conduct operations locating nearest replica particular dataset 
context grid computing hardware software entity supercomputers storage systems applications shared users grid called resource 
rest stated term resource means hardware computers storage systems 
resources nodes network terms interchangeably 
network enabled capabilities resources invoked users applications resources called services 
data grids data grid provides services help users discover transfer manipulate large datasets stored distributed repositories create manage copies datasets 
minimum data grid provides basic functionalities high performance reliable data transfer mechanism scalable replica discovery management mechanism chervenak 
depending application requirements various services need provided 
examples services include consistency management replicas metadata management data filtering reduction mechanism 
operations data grid mediated security layer handles authentication entities ensures conduct authorized operations 
aspect data grid maintain shared collections data distributed administrative domains 
collections maintained independent underlying storage systems able include new sites major effort 
importantly required data information associated data metadata access controls version changes preserved face platform changes 
requirements lead establishment persistent archival storage moore 
shows high level view worldwide data grid consisting computational storage resources different countries connected high speed networks 
thick lines show high bandwidth networks linking major centres thinner lines lower capacity networks connect subsidiary centres 
data generated instrument experiment network sensors stored principal storage site transferred storage sites world request data replication mechanism 
users query local replica catalog locate datasets require 
granted requisite rights permissions data fetched repository local area fetched remote repository 
data may transmitted computational site cluster supercomputer facility processing 
processing results may sent visualisation facility shared repository desktops individual users 
data grid provides platform users access aggregated computational storage networking resources execute data intensive applications remote data 
promotes rich environment users analyse data share results user instruments replica catalog replica catalog compute resource storage resource high level view data grid 
tors maintain state information data seamlessly institutional geographical boundaries 
cited examples data grids ones set analysing huge amounts data generated cms compact muon atlas toroidal lhc alice large ion collider experiment lhc beauty experiments large collider lhc cern production 
data grids involve thousands physicists spread hundreds institutions worldwide replicating analysing terabytes data daily 
resources grid heterogeneous terms operating environments capability availability control local administrative domains 
domains autonomous retain rights users access resources control 
grids concerned issues sharing resources authentication authorization entities resource management scheduling efficient effective available resources 
naturally data grids share general concerns unique set characteristics challenges listed massive datasets data intensive applications characterised presence large datasets size gigabytes gb 
example cms experiment lhc expected produce pb bytes raw data pb event summary data esd annually begins production 
resource management data grids extends minimizing latencies bulk data transfers creating replicas appropriate replication strategies managing storage resources 
shared data collections resource sharing data grids includes sharing distributed data collections 
example participants scientific collaboration want repositories sources data storing outputs analyses 
unified namespace data data grid share logical namespace data element unique logical filename 
logical filename mapped physical filenames various storage resources data grid 
access restrictions users wish ensure confidentiality data restrict distribution close collaborators 
authentication authorization data grids involves coarse fine grained access controls shared data collections 
certain characteristics data grids specific applications created 
example astrophysics high energy physics experiments principal instrument telescope particle accelerator single site data generation 
means data written single site replicated sites read access 
updates source propagated replicas replication mechanism separate consistency management service 
lot challenges grid computing revolve providing access different types resources 
foster kesselman tuecke proposed grid architecture resource sharing different entities concept virtual organizations vos 
vo formed different organisations pool resources collaborate order achieve common goal 
vo defines resources available participants rules accessing resources conditions resources may 
resources just compute storage network resources may software scientific instruments business data 
vo provides protocols mechanisms applications determine suitability accessibility available resources 
practical terms vo may created mechanisms certificate authorities cas trust chains security replica management systems data organisation retrieval centralised scheduling mechanisms resource management 
existence vos impacts design data grid architectures ways 
example vo may stand may composed hierarchy regional national international vos 
case underlying data grid may corresponding hierarchy repositories replica discovery management system structured accordingly 
importantly sharing data collections guided relationships exist vos collections 
subsequent sections look data grids differentiated design choices affect underlying technologies 
layered architecture components data grid organised layered architecture shown 
architecture follows similar definitions foster 
baker 

layer builds services offered lower layer addition interacting operating components level 
resource broker invoking vo tools 
describe layers bottom top grid fabric consists distributed computational resources clusters supercomputers storage resources raid arrays tape archives instruments telescope accelerators connected high bandwidth networks 
resources runs system software operating systems job submission management systems relational database management systems rdbms 
communication consists protocols query resources grid fabric layer conduct data transfers 
protocols built core communication pro applications high energy physics virtual observatory climate modelling portals application tools remote visualization 
remote instrumentation user level services data grid services replica management resource brokering 
virtual organization tools core services replication discovery job submission 
data transfer libraries file transfer protocols ftp gridftp security layer gsi kerberos internet protocol software operating systems batch job systems dist file systems hardware physical layer overlay structures basic grid fabric 
databases clusters instruments networks disks tape archives 
san 
layered architecture 
application communication tcp ip authentication protocols pki public key infrastructure passwords ssl secure sockets layer 
cryptographic protocols allow verification users identities ensure security integrity transferred data 
security mechanisms form part grid security infrastructure gsi foster 
file transfer protocols gridftp grid file transfer protocol provide services efficient transfer data resources data grid 
application specific overlay structures provide efficient search retrieval capabilities distributed data maintaining distributed indexes 
data grid services provides services managing processing data data grid 
core level services replication data discovery job submission provide transparent access distributed data computation 
user level services resource brokering selection resources user requirements replica management provide mechanisms allow efficient resource management hidden commands apis application programming interfaces 
vo tools provide easy way perform functions adding new resources vo querying existing resources managing users access rights 
applications specific services cater users invoking services provided layers suit target domains high energy physics biology climate modelling 
domain provides familiar interface access services visualisation 
portals web interfaces provide single point access available vo services domain specific applications tools 
similar intent provide applications allow users conduct joint operations colleagues 
security layer data grid services provide applications uniform access resources fabric layer abstracting inherent complexity heterogeneity 
formation vos requires interoperability resources components provided different participants 
motivates standard protocols service interfaces information exchange vo entities 
service interfaces separated implementation details described language platform independent format 
realization requirements led grid computing research community forums global grid forum ggf adopt new open grid services architecture ogsa foster emerging web services paradigm 
web services self contained stateless components standard mechanisms representation exchange data 
ogsa builds web service properties vendor platform neutral service definition xml extensible markup language bray standard communication protocols soap simple object access protocol create grid services 
grid services standardized web service interfaces provide grid capabilities secure reliable stateful manner 
grid services may potentially transient service instances support service lifetime management state notification 
ogsa utilizes standard web service mechanisms discovering invoking grid services 
ogsa data services foster deal accessing managing data resources grid environment 
data service implements set basic interfaces describe data provide operations manipulate 
data represented ways different data services implement different set operations data attributes 
view data created data service termed data 
subsequent efforts data access integration services working group wg ggf produced set concrete standards representing data services 
standards provide consumers services advantage isolated inner workings data grids actual transferring managing data done underlying core mechanisms data transport data replication resource management 
taxonomy section focuses core mechanisms define capabilities data grid 
related data intensive research paradigms related distributed data intensive research areas share similar requirements functions characteristics described 
chosen similar properties requirements share data grids 
content delivery network content delivery network cdn davison consists collection non origin servers attempt offload origin servers delivering content behalf krishnamurthy 
cdn client requests satisfied servers distributed internet called edge servers cache content originally stored source origin server 
client request rerouted main server available server closest client host content required 
done providing dns domain name system server resolves client dns request appropriate edge server 
requested object retrieves data origin server edge server 
primary aims cdn load balancing reduce effects sudden requests bandwidth conservation objects media clips reducing round trip time serve content client 
cdns generally employed web content providers commercial providers akamai built dedicated infrastructure serve multiple clients 
cdns haven gained wide acceptance data distribution restricted model follow 
current cdn infrastructures proprietary nature owned completely providers 
peer peer network peer peer networks oram formed ad hoc aggregation resources form decentralised system peer autonomous depends peers resources information forwarding requests 
primary aims network ensure scalability reliability removing centralised authority ensure redundancy share resources ensure anonymity 
entity network join leave anytime algorithms strategies designed keeping mind volatility requirements scalability reliability 
networks designed implemented target areas compute resource sharing seti home anderson compute power market buyya content file sharing napster gnutella kazaa collaborative applications instant messengers project 
milojicic 
detailed taxonomy survey peerto peer systems 
concerned content file sharing networks involve data distribution 
networks mainly focused creating efficient strategies locate particular files group peers provide reliable transfers files face high volatility manage high load caused due demand highly popular files 
currently major content sharing networks provide integrated computation data distribution environment 
distributed databases distributed database ceri ozsu valduriez logically organised collection data stored different sites computer network 
site degree autonomy capable executing local application participates execution global application 
distributed database formed existing single site database splitting different sites top approach existing database management systems accessed uniform interface bottom approach sheth larson 
called multidatabase systems 
varying degrees autonomy possible ranging tightly coupled sites complete site independence 
distributed databases evolved serve needs large organisations need remove need centralised computer centre interconnect existing databases replicate databases increase reliability add new databases new organisational units added 
technology robust 
provides distributed transaction processing distributed query optimisation efficient management resources 
systems employed current form scale data grids envisioned strong requirements acid atomicity consistency isolation durability properties gray reuter ensure state database remains consistent deterministic 
analysis data intensive networks section compares data intensive paradigms described previous sections data grids order bring uniqueness highlight respective similarities differences 
areas mature solutions may applicable problems data grids wholly modification differing properties 
properties summarised table explained purpose considering purpose network generally seen content sharing networks vertically integrated solutions single goal example file sharing 
cdns dedicated caching web content clients able access faster 
integrating existing diverse databases provide uniform consistent interface querying replicating existing databases increasing reliability throughput 
contrast single purpose networks data grids primarily created enabling collaboration sharing distributed resources including data collections support various activities including data transfer computation infrastructure 
goal bring existing disparate resources order obtain benefits aggregation 
aggregation networks formed aggregating individual nodes form distributed system 
aggregation created ad hoc process nodes subscribe network prior arrangements specific process brought particular purpose 
aggregation stable dynamic 
networks definition ad hoc nature nodes entering leaving 
cdn provider creates infrastructure setting dedicated servers caching content 
created existing databases establishing tightly coupled network databases single organisation 
case cdn system entire network managed single entity authority add remove nodes stable configurations 
data grids created institutions forming vos pooling resources achieving common goal 
data grid dynamic configurations possible due removal resources services 
organisation organisation cdn hierarchical data flowing origin edges 
data cached various edge servers exploit locality data requests 
models organisation content sharing network linked searching methods files network 
napster peer connect centralised server search available peer required file 
peers directly communicate 
gnutella avoids centralised directory having peer broadcast request neighbours peer required file obtained 
kazaa fasttrack limit fan gnutella restricting broadcasts superpeers index group peers 
freenet clarke uses content hashing file assigned hash contents nearest neighbour search identify required document 
different models organisation viz 
centralised level hierarchy flat structured unstructured seen examples 
distributed databases provide relational database management interface organised accordingly 
global relations split fragments allocated physical sites 
case replication fragments carried ensure reliability database 
distribution transparency may achieved top databases may case federated databases varying degrees heterogeneity autonomy 
shown taxonomy section different kinds organisation data grid monadic hierarchical federated hybrid combinations 
table comparison various data distribution networks property content cdn data grids purpose sharing file sharing reducing web la integrating ex analysis databases replicating database reliability throughput aggregation ad hoc dynamic specific stable specific stable specific organisation centralised hierarchical centralised fed hierarchical hierarchy bottom flat hybrid data access read read equally read read type frequent writes write rare writes data discov central directory request relational catalogues ery flooded requests document routing schemas latency man replication caching stream replication replication agement caching streaming caching caching stream performance pre staging high speed data consistency weak strong read strong movement optimal selection data source sink weak requirements transaction support currently currently computa currently client transaction pro data production cessing analysis autonomy operational par dedicated operational fed access tional participation heterogeneity system structural management entity security requirements individual single system system system syntactic structural single semantic vo anonymity data integrity authentication authorisation data integrity authentication authorisation data integrity data access type access type distinguishes type data access operations conducted network 
content sharing networks read environments write operations occur entity introduces new data network creates copies existing data 
cdns exclusively read environments users updating data happens origin servers 
data read written frequently 
data grids similar networks read environments data introduced existing data replicated 
key difference depending application requirements data grids may support updating data replicas source modified 
data discovery distinguishing property data discovered network 
approaches searching networks mentioned previously 
current research focuses document routing model algorithms proposed model chord stoica ratnasamy pastry rowstron druschel tapestry zhao 
cdns fetch data requested browser hyper text transfer protocol 
organised relational schema paradigm single site databases data searched retrieved sql structured query language 
data data grids organised catalogues map logical description data actual physical representation 
form catalogues replica catalogue contains possibly mapping logical filename actual physical filenames datasets 
data located querying catalogues resolving physical locations logical datasets 
addition mechanisms metadata searching data supported certain individual products data intensive networks 
data queried attributes description content type 
data grids metadata catalogues offer means querying data 
cases metadata curated properly affect efficiency accuracy data discovery 
look role metadata catalogues detail sections 
latency management performance key element performance distributed networks manner reduce latency data transfers 
techniques commonly regard replicating data close point consumption caching data streaming data pre staging data application starts executing 
replication different caching involves creation maintenance copies data different places network depending access rates criteria involves creating just copy data close point consumption 
replication done source data provider side caching done data consumer side 
replication caching seek increase performance reducing latency aims increase reliability creating multiple backup copies data 
cdns employ caching streaming enhance performance especially delivering media content saroiu 
replication strategies suggested cdn karlsson mahalingam experimentally show caching provides equivalent better performance replication 
absence requirements consistency availability guarantees cdns computationally expensive replication strategies offer improvement simple caching methods 
networks employ replication caching streaming data various degrees 
replication caching distributed database systems optimizing distributed query processing kossmann 
data grids techniques mentioned implemented form 
additionally data grids differentiated requirement transfer massive datasets 
absent data intensive networks considered designing networks 
motivates high speed data transfer mechanisms separation data communication sending control messages happens separately actual data transfer 
addition features parallel striped data transfers required reduce time data movement 
optimization methods reduce amount data transfers accessing data close point consumption employed data grids 
consistency consistency important property determines fresh data grids networks generally provide strong consistency guarantees overhead maintaining locks huge volumes data ad hoc nature network respectively 
exceptions data grids 
discusses consistency service replication data grids 
networks oceanstore kubiatowicz distributed file system provides strong consistency guarantees expensive locking protocols 
cdns data cache may go stale system presents latest version data user requests 
consistency provided cdn strong 
distributed databases mentioned strong requirements satisfying acid properties 
requirements relaxed case unstable conditions mobile networks pitoura bhargava semantics updating stricter distributed databases distribution networks 
updates frequent happen site network 
updates migrated sites network copies data synchronised 
methods updating followed gray lazy updates asynchronously propagated eager copies synchronously updated 
transaction support transaction set operations actions succeed succeed 
transaction support implies existence check pointing rollback mechanisms database data repository returned previous consistent state case failure 
follows discussion previous property transaction support essential distributed databases 
cdns requirements transaction support support read access data users 
networks data grids currently support recovery rollback 
efforts provide transaction support data grids provide fault tolerance distributed transactions transaction management research group ggf 
computational requirements computational requirements data intensive environments originate operations query processing applying transformations data processing data analysis 
cdns exclusively data oriented environments client accessing data remote nodes processing site 
current content sharing networks processing data possible integrate requirements 
com putation involves transaction processing conducted ways requested data transmitted originating site transaction transaction processed site transaction distributed different nodes data 
high volumes transactions cause heavy computational load variety optimisation techniques deal load balancing parallel distributed databases 
data grids heavy computational requirements caused workloads involving analysis datasets 
operations data grids especially involving analysis take long intervals time measured hours days 
contrast situation turnaround time requests short applications oltp line transaction processing measured milliseconds 
high performance computing sites generally constitute existing data grids shared facilities time 
application execution data grids take account time spent queues sites 
autonomy autonomy deals degree independence allowed different nodes network 
different types different levels autonomy provided sheth larson alonso barbara 
access autonomy allows site node decide access user node network 
operational autonomy refers ability node conduct operations overridden external operations network 
participation autonomy implies node ability decide proportion resources network time wants associate network 
data grid nodes kinds autonomy fullest extent 
nodes network fine grained access controls users maximum independence deciding share contribute network 
cdns dedicated networks individual nodes autonomy 
tightly coupled databases retain control individual sites multidatabase systems retain control local operations 
heterogeneity network environments encompass heterogeneous hardware software configurations potentially different protocols 
impacts applications engineered multiple interfaces multiple data formats multiple protocols applicable 
interoperability system refers degree transparency system provides user access information unaware underlying complexity 
heterogeneity split types depending differences various levels network stack 
identified different types heterogeneity case data sources digital libraries 

system heterogeneity arises different hardware platforms operating systems 

syntactic heterogeneity arises presence different protocols encodings system 

structural heterogeneity originates data organised different models schemas 

semantic heterogeneity originates different meanings data especially different metadata schemas categorising data 
seen definitions data intensive networks classification applicable current context 
system heterogeneity feature data intensive networks discussed 
networks cdns simultaneously store data different formats require establishment common protocols individual networks 
cdns homogeneous comes structure data enforce common schema web content schema cdns relational schema 
networks offer structural semantic heterogeneity unify data various sources allow user query available data 
existence different components including legacy speak variety protocols store data proprietary formats little common structure consistent metadata information means data grids contain data syntactically structurally semantically heterogeneous 
data grids truly differ data intensive networks regard level interoperability required 
users data grid expect integrated view data abstracts underlying complexity simple interface 
interface require manipulate data applying transformations conducting analysis viewing results results conduct operations 
means data grid provide interoperability different protocols systems able extract meaningful information data users requirements 
different content sharing networks user queries datasets matching particular criterion downloads 
management entity management entity tasks maintaining aggregation 
generally entity collection stakeholders distribution network 
body usually control individual nodes provides services common data directory locating content authentication service users network 
data grid discussed concept vo 
entities network independent central entity may provide directory service case napster 
cdns owned maintained single organisation 
likewise maintained single organisations constituent databases may independent 
security requirements security requirements differ depending perspective 
data distribution network security may ensured corruption content data integrity safeguarding users privacy anonymity resources verify users identities authentication 
networks freenet concerned preserving anonymity users may breaking local censorship laws 
cdn primarily verify data integrity access manipulating data granted content provider 
users authenticate carrying queries transactions data integrity maintained deterministic operation 
data grids multi user environments shared resources main security concerns authentication users resources granting permissions specific types services user authorisation 
data grids resources spread various administrative entities accepting security credentials user involves trusting authority issued credentials place 
vos adopted community authorization vo provides credentials certifies certain authorities trusted sets access rights user 
issues grids general data grids need verification accessing data need guard malicious operations data transit 
elaborate access controls required grids needed safeguarding confidential data data grids 
seen data grids share characteristics types data intensive network computing technologies differentiated heavy computational requirements wider heterogeneity autonomy presence vos 
current data grid implementations focus scientific applications 
approaches explored integration mentioned technologies data grids take advantage strengths data grid elements organization data transport data replication scheduling data grid elements 
offer areas data discovery storage management data replication 
possible data grids encompass build diverse technologies 
foster iamnitchi discuss convergence grid computing contend able take advantage failure resistance scalability offered gains experience managing diverse powerful resources complex applications multitude users different requirements 

similar view discuss areas aggregation algorithms maintenance research beneficial grids 
practical grid technologies narada brokering fox methods delivering scalable event service 
taxonomy section details taxonomy covers various aspects data grids 
data grids consist elements taxonomy covers depth 
taxonomy split sub taxonomies shown 
sub taxonomy point view data grid organization 
classifies ongoing scientific data grid efforts worldwide 
sub taxonomy deals transport technologies data grids 
covers known file transfer protocols includes means managing data transportation 
scalable robust intelligent replication mechanism crucial smooth operation data grid sub taxonomy takes account concerns grid environments metadata nature data transfer mechanisms 
sub taxonomy categorizes resource allocation scheduling research looks issues locality data 
areas data transport replica management resource management independent fields research merit detailed investigations studied point view specific requirements data grid environments provided previous sections 
data grid organization shows taxonomy various organizational characteristics data grid projects 
characteristics central data grid manifest different ways different systems 
model model manner data sources organised system 
variety models place operation data grid 
dependent source data single distributed size data mode sharing 
common models data grids shown discussed follows data grid organization taxonomy model scope virtual organization data sources management monadic hierarchical federation hybrid interdomain intradomain collaborative regulated economic reputation transient stable autonomic managed data grid organization taxonomy 
monadic general form data grid data gathered central repository answers user queries provides data 
data sources distributed instruments networks available centralised interface web portal verifies users checks authorization 
model shown applied network earthquake engineering simulation project united states 
difference models data grids single point accessing data 
contrast models data wholly partially accessed different points available replication 
central repository may replicated case fault tolerance improving locality data 
model serves better scenarios overhead replication compensated increase efficiency data access case accesses local particular region 
hierarchical model data grids single source data data distributed collaborations worldwide 
example models networked analysis regional centres group cern proposed tiered infrastructure model distribution cms data 
model specifies requirements transfer data cern various groups physicists world 
level compute storage farm cern stores data generated detector 
data distributed sites distributed worldwide called regional centres rcs 
rcs data passed downstream national institutional centres physicists 
tier tier centre satisfy certain bandwidth storage computational requirements shown 
sensors tape institution local data repository instruments central data repository institution local data repository monadic hierarchy institution institution federation institution institution source distributor distributor distributor institution institution institution hybrid possible models organization data grids 
massive amounts data generated experiments motivate need robust data distribution mechanism 
researchers participating institutions may interested subsets entire dataset may identified querying metadata 
advantage model maintenance consistency simpler source data 
federation federation model rajasekar prevalent data grids created institutions wish share data existing databases 
example federated data grid bioinformatics research network united states 
researchers participating institution request data databases federation long proper authentication 
institution retains control local database 
varying degrees integration federated data grid 
example moore 
discuss different types federations possible storage resource broker srb baru various configurations 
differences degree autonomy site constraints cross registration users degree replication data degree synchronization 
hybrid hybrid models combine models emerge data grids mature enter production usage 
come need researchers collaborate share products analysis 
hybrid model hierarchical data grid peer linkages edges shown 
scope scope data grid vary depending restricted single domain intradomain common infrastructure various scientific areas interdomain 
case infrastructure adapted particular needs domain 
example special analysis software may available participants domain specific data grid 
case infrastructure provided generic 
virtual organizations data grids formed vos design vos reflects social organization data grid 
vo collaborative created entities come share resources collaborate single goal 
implicit agreement participants usage resources 
regulated vo may controlled single organization lays rules accessing sharing resources 
vo resource providers enter collaborations consumers due profit motive 
cases service level agreements dictate rights participants 
reputation vo may created inviting entities join collaboration level services known provide 
data sources data sources data grid may transient stable 
scenario transient data source satellite broadcasts data certain times day 
cases applications need aware short life data stream 
see current data grid implementations data sources mass storage systems production databases 
diversification data grids expected handle transient data sources 
management management data grid autonomic managed 
day data grids require plenty human intervention tasks resource monitoring user authorization data replication 
research leading autonomic self organizing self governing systems techniques may find applications data grids 
data transport taxonomy data transport function overlay network security fault tolerance transfer mode file mechanism transfer protocol authentication authorization encryption restart transmission resume transmission cached transfers block stream compressed bulk transfers data transport taxonomy 
passwords cryptographic keys coarse grained fine grained ssl unencrypted data transport mechanism fundamental technologies underlying data grid 
data transport involves just movement bits resources aspects data access security access controls management data transfers 
taxonomy data transport mechanisms data grids shown 
functions data transport grids modelled tier structure similar networking stacks osi model 
bottom transfer protocol specifies common language nodes network initiate control data transfers 
tier takes care simple bit movement hosts network 
transport protocols data grids ftp file transfer protocol postel reynolds gridftp allcock 
second tier optional overlay network takes care routing data 
overlay network provides semantics internet protocol satisfy particular purpose 
networks overlays distributed hash tables provide efficient way locating transferring files andersen 
overlay networks data grids provide services storage network caching data transfers better reliability ability applications manage transfer large datasets 
topmost tier provides application specific functions file file mechanism allows application access remote files locally available 
mechanism presents application transparent interface apis hide complexity unreliability networks 
data transport mechanism perform functions 
security security important requirement accessing transferring files ensure proper authentication users file integrity confidentiality 
transport security divided main categories authentication authorization users encryption data transfer 
authentication passwords symmetric asymmetric public key cryptographic protocols kerberos neuman ts mechanisms respectively 
context data movement authorization users enforced mechanisms access controls data transferred 
coarse grained authorization methods traditional methods unix file permissions restrict number files collections accessible user 
expansion data grids fields medical research strict controls distribution data led requirements fine grained authorization 
requirements include restricting number accesses authorised users delegating read write access rights particular files collections flexible ownership data moore 
fine grained access control methods may employed achieve requirements include time usage limited tickets access control lists acls role access control rbac methods sandhu task authorization controls thomas sandhu 
data encryption may absent transfer mechanism 
prevalent form data encryption ssl secure sockets layer wagner schneier 
fault tolerance fault tolerance important feature required data grid environment especially transfers large data files occur 
fault tolerance subdivided restarting resuming interruption providing caching 
restarting transfer means data transport mechanism provide failure tolerance 
data transit lost slight overhead setting connection 
protocols gridftp allow resuming transfers byte acknowledged 
overlay networks provide caching transfers store forward protocols 
case receiver wait connections restored 
caching reduces performance data transfer amount data cached dependent storage policies intermediate network points 
transfer mode category transfer modes supported mechanism 
block stream compressed modes data transfer available traditional data transmission protocols ftp 
argued transfers large datasets anticipated data grids restricted vanilla ftp underlying internet protocols transmission control protocol tcp initially designed low bandwidth high latency networks 
unable take advantage capabilities high bandwidth optical fibre networks available data grid environments lee 
optimisations suggested improving performance data transfers grid environments reducing latency increasing transfer speed 
listed parallel data transfer ability multiple data streams channel transfer file 
saturates available bandwidth channel completing transfer 
striped data transfer ability multiple data streams simultaneously access different blocks file partitioned multiple storage nodes called striping 
distributes access load nodes improves bandwidth utilisation 
auto resizing buffers ability automatically resize sender receiver tcp window buffer sizes available bandwidth effectively utilised 
container operations ability aggregate multiple files large dataset transferred stored efficiently 
efficiency gains come reducing number connections required transfer data reducing initial latency 
file file storage node replica manager replica catalog update update data transfer protocol file file storage node replica management architecture 
protocol specific optimisations applied transfer mechanism 
group enhancements bulk transfer mode 
mechanism may support mode suitability application gauged features provides transfer modes 
data replication storage data grid geographically distributed collaboration members require access datasets produced collaboration 
replication datasets key requirement ensure scalability collaboration reliability data access preserve bandwidth 
replication bounded size storage available different sites data grid bandwidth sites 
replica management system ensures access required data managing underlying storage 
replica management system shown consists storage nodes linked high performance data transport protocols 
replica manager directs creation management replicas demands users availability storage catalog directory keeps track replicas locations 
catalog queried applications discover number locations available replicas particular dataset 
systems manager catalog merged entity 
client side software generally consists library integrated applications set commands gui utilities built top libraries 
client libraries allow querying catalog discover datasets request replication particular dataset 
important elements replication mechanism architecture system strategy followed replication 
categorization data grid replication properties shown 
architecture replication mechanism subdivided categories shown 
model topology model followed system largely determines way nodes organized method replication 
centralized system master replica updated updates propagated nodes 
decentralized peerto peer mechanism copies need synchronized 
replica architecture taxonomy replication taxonomy replica architecture taxonomy replication strategy taxonomy replication taxonomy 
model topology storage integration transfer protocols metadata update propogation catalog organization centralized decentralized hierarchical flat hybrid tightly coupled intermediate loosely coupled open protocols closed protocols attributes update type synchronous asynchronous tree hash dbms replica architecture taxonomy 
system user defined active passive epidemic demand nodes replica management system organised variety topologies grouped chiefly hierarchy flat hybrid 
hierarchical topologies tree structure updates definite paths 
flat topologies systems progression updates entirely dependent arrangements peers 
structured unstructured 
hybrid topologies achieved situations hierarchy peer connections different levels discussed 

storage integration relation replication storage important determines scalability robustness adaptability applicability replication mechanism 
tightly coupled replication mechanisms exert fine grained control replication process tied storage architecture implemented 
replication system controls filesystem mechanism local disk 
replication conducted level processes triggered read write request file remote location program 
systems try behave distributed file system nfs network file system aim provide transparent access remote files applications 
example mechanism 
coupled replication systems exert control replication mechanism storage resources 
filesystems hosted diverse storage architectures controlled respective systems 
replication initiated managed mechanism interacts storage system low level 
mechanisms level individual applications data transfer handled system 
replication conducted transparent users applications possible direct mechanism control replication process 
example system srb 
loosely coupled replication mechanisms superimposed existing filesystems storage systems 
mechanism exerts control filesystem 
replication initiated managed applications users 
mechanisms interact storage systems standard file transfer protocols high level 
architecture capable complete heterogeneity 
transfer protocols data transport protocols replica management systems differentiating characteristic 
open protocols data movement gridftp allow clients transfer data independent replica management system 
replicated data accessible outside replica management system 
systems follow closed unpublished protocols restrict access replicas client libraries 
tightly coupled replication systems closed terms data transfer 
rls replica location service chervenak gdmp grid data mirroring pilot samar stockinger gridftp primary transport mechanism 
flip side having open protocols user application take care updating replica locations catalog transfer data outside replication management system 
metadata difficult impossible users identify particular datasets hundreds thousands may large distributed collection 
perspective having proper metadata replicated data aids users querying datasets attributes familiar 
metadata types attributes metadata consists file attributes creation date size disk physical location file checksum user defined attributes consist properties depend experiment vo user associated 
example high energy physics experiment metadata describe attributes experiment date mode production simulation experimental event type 
metadata actively updated replica management system updated passively users create new replicas modify existing ones add new file catalog 
replica update propagation data grid data generally updated site updates propagated rest replicas 
synchronous asynchronous modes 
synchronous updating followed databases practiced data grids expensive wide area locking protocols frequent movement massive data required 
asynchronous updating epidemic primary copy changed updates propagated replicas demand gdmp stockinger replica sites subscribe update notifications primary site decide update copies 
catalog organization replica catalog distinguished basis organization 
catalog organized tree case ldap lightweight directory access protocol catalogs globus replica catalog allcock 
data catalogued basis document hashes seen networks 
srb replication strategy taxonomy method granularity objective function static dynamic container dataset file fragment locality replication strategy taxonomy 
popularity update costs economic preservation publication follow approach storing catalog database 
replication strategies determine create replica data 
strategies guided factors demand data network conditions cost transfer 
replication strategies categorized shown 
method classification strategies static dynamic 
dynamic strategies adapt changes demand bandwidth storage availability induce overhead due larger number operations undertake run regular intervals response events example increase demand particular file 
dynamic strategies able recover failures network partitioning 
frequent transfers massive datasets result due strategies lead strain network resources 
may little gain dynamic strategies resource conditions fairly stable data grid long time 
cases static strategies applied replication 
granularity second classification relates level subdivision data strategy works 
replication strategies deal multiple files time granularity datasets 
level granularity individual files strategies deal smaller subdivisions files objects fragments 
objective function third classification deals objective function replication strategy 
possible objectives replication strategy maximise locality move data point computation exploit popularity replicating requested datasets minimize update costs maximize economic objective profits gained particular site hosting particular dataset versus expense leasing dataset site 
preservation driven strategies provide protection data case failures corruption obsolescence underlying storage media software errors 
possible objective function replication strategy ensure effective publication propagating new files interested clients 
scheduling taxonomy application model scope data replication utility function locality resource allocation scheduling process oriented independent tasks bag tasks workflows individual community coupled decoupled makespan load balancing profit quality service temporal spatial data grid scheduling taxonomy 
requirements large datasets presence multiple replicas datasets scattered geographically distributed locations scheduling data intensive jobs different computational jobs 
schedulers take account bandwidth availability latency transfer computational node job going submitted storage resource data required retrieved 
scheduler needs aware replicas close point computation replication coupled scheduling create new copy data 
taxonomy scheduling data intensive applications shown 
categories explained follows application model scheduling strategies classified application model targeted 
application models defined manner application composed distributed scheduling global grids 
range fine grained levels processes coarser levels individual tasks sets tasks workflows 
task considered smallest independent unit computation 
level scheduling requirements 
process oriented applications data manipulated process level 
examples applications mpi message passing interface programs execute global grids foster karonis 
independent tasks having different objectives scheduled individually ensured get required share resources 
bag tasks bot application consists set independent tasks executed successfully subject certain common constraints deadline entire application 
applications arise parameter studies abramson set tasks created running program different inputs 
contrast workflow sequence tasks task dependent results predecessor 
products preceding tasks may large datasets example simple step workflow data intensive simulation task task analysis results simulation 
scheduling individual tasks workflow requires careful analysis dependencies results reduce amount data transfer 
scope scope relates extent application scheduling strategy data grid 
scope individual scheduling strategy concerned meeting objectives user perspective 
multi user environment scheduler independent view resources wants utilise 
scheduler aware fluctuations resource availability caused schedulers submitting jobs common resources strives schedule jobs loaded resources meet objectives 
advent vos efforts moved community scheduling schedulers follow policies set vo level enforced resource level service level agreements allocation quotas foster wasson humphrey 
data replication classification relates job scheduling coupled data replication 
assume job scheduled executed particular compute node 
job scheduling coupled replication data fetched remote storage scheduler creates copy data point computation requests file come neighbourhood compute node satisfied quickly 
job dealing particular data scheduled compute node available 
requirement compute node storage store copies data 
storage management schemes lru fifo manage copies selection compute nodes requirement 
possibility promising computational resources may disregarded due lack storage space 
process creation replica registering catalog adds overheads job execution 
decoupled scheduler job scheduled suitable computational resource suitable replica location identified request data required 
storage requirement transient disk space required duration execution 
comparison decoupled coupled strategies ranganathan foster shown decoupled strategies promise increased performance reduce complexity designing algorithms data grid environments 
utility function job scheduling algorithm tries minimize maximize form utility function 
utility function vary depending requirements users architecture distributed system algorithm targeted 
traditionally scheduling algorithms aimed reducing total time required computing jobs set called makespan 
load balancing algorithms try distribute load machines maximum obtained systems 
scheduling algorithms economic objectives try maximize users economic utility usually expressed profit function takes account economic costs executing jobs data grid 
possible objective meet quality service qos requirements specified user 
qos requirements specified include minimising cost computation meeting deadline meeting stricter security requirements meeting specific resource requirements 
locality exploiting locality data tried tested technique scheduling load balancing parallel programs polychronopoulos kuck mckinley query processing databases stonebraker 
similarly data grid scheduling algorithms categorized exploit spatial temporal locality data requests 
spatial locality locating job way data required job available data hosts located close point computation 
temporal locality exploits fact data required job close compute node subsequent jobs require data scheduled node 
spatial locality termed moving computation data temporal locality called moving data computation 
easily seen schedulers couple data replication job scheduling exploit temporal locality data requests 
mapping taxonomy various data grid systems section classify various data grid research projects taxonomies developed section 
list example systems exhaustive representative classes discussed 
projects category chosen factors broad coverage application areas project support applications scope visibility large scale problem focus ready availability documents project web pages sources 
data grid projects space study analyse various data grid projects developed various application domains world 
projects cover aspects data grid research middleware development advanced networking storage management focus projects involved setting infrastructure 
list projects brief summary provided table 
classified taxonomy provided table data grid projects world 
name domain grid type remarks country region lcg high energy hierarchical model create maintain global physics intradomain data movement vo stable sources ysis infrastructure managed users lhc 
egee high en hierarchical model create seamless global ergy physics interdomain common grid biomedical tive vo stable sources ture support scientific sciences managed research 
bio federated model foster collaboration united ics intradomain biomedical science states tive vo stable sources managed sharing data 
earthquake monadic model enable scientists united pearlman engineering carry experiments states vo transient distributed locations sources managed analyse data uniform interface 
griphyn high energy avery foster physics grid gardner japan virtual szalay gray earth system grid allcock huffman brady belle analysis data grid physics biology protein simulation brain activity analysis hierarchical model intradomain collaborative vo stable sources managed hierarchical model interdomain collaborative vo stable sources managed federated model intradomain collaborative vo stable sources managed astronomy federated model climate modelling high energy physics breast cancer treatment high energy physics intradomain collaborative vo stable sources managed federated model intradomain collaborative vo stable sources managed hierarchical model intradomain collaborative vo stable sources managed federated model intradomain collaborative vo stable sources managed hierarchical model intradomain collaborative vo stable sources managed create integrated infrastructure provides computational storage facilities high energy physics experiments 
provide uniform scalable managed grid infrastructure science applications computational data infrastructure medical biological research 
infrastructure accessing diverse astronomy observation simulation archives integrated mechanisms 
integrating computational data analysis resources create environment generation climate research 
create computational storage infrastructure particle physics uk 
provide medical professionals researchers access distributed databases mammogram images 
create computational storage infrastructure australia physicists involved belle atlas experiments 
scientific domains making data grids follows united states united states japan global united states united kingdom united kingdom australia high energy physics hep computational storage requirements hep experiments covered previous literature newman 
experiments lhc mentioned belle experiment kek japan experiment stanford linear accelerator center slac cdf experiments fermi national laboratory adopting data grid technologies computing infrastructure 
numerous grid projects world setting infrastructure physicists process data hep experiments 
lhc computing grid lcg led cern particle physics data grid ppdg grid physics network griphyn united states uk belle analysis data grid australia 
projects common features tiered model distributing data shared facilities computing storage personnel dedicated managing infrastructure 
entering tested production usage 
astronomy community globe setting virtual accessing data archives gathered telescopes instruments world 
include national virtual observatory australian virtual observatory astrophysical virtual observatory europe uk szalay 
international virtual observatory alliance coordinating efforts world ensuring interoperability 
commonly projects provide uniform access data repositories access software libraries tools may required analyse data 
services provided include access high performance computing facilities visualization desktop tools web browsers 
astronomy grid projects include constructed ligo laser interferometer gravitational wave observatory sdss sloan digital sky survey projects 
bioinformatics increasing importance realistic modeling simulation biological processes coupled need accessing existing databases led data grid solutions adopted bioinformatics researchers worldwide 
projects involve existing databases providing common data formats information exchange 
examples projects project japan online brain activity analysis protein folding simulation project uk breast cancer treatment bioinformatics research network imaging neurological disorders data federated databases 
earth sciences researchers disciplines earthquake engineering climate modeling simulation adopting grids solve computational data requirements 
project link earthquake researchers high performance computing sensor equipment collaborate designing performing experiments 
earth systems grid aims integrate high performance computational data resources study petabytes data resulting climate modelling simulation 
data transport technologies subsection various projects involved data transport grids discussed classified taxonomy provided section 
data transport technologies studied range protocols ftp overlay methods internet backplane protocol file mechanisms 
technology unique properties representative table comparison various data transport technologies 
project function security fault tolerance gass file pki unencrypted ibp overlay coarse grained password unencrypted mechanism coarse grained ftp transfer pro password unencrypted tocol coarse grained transfer pro pki ssl gridftp transfer pro pki ssl kangaroo overlay pki unencrypted mechanism coarse grained legion file pki unencrypted coarse grained transfer mode caching block stream append caching block restart restart resume caching block caching block srb file pki ssl fine grained restart block stream bulk transfer categories placed 
summary technologies categorization provided table 
gass global access secondary storage gass data access mechanism provided globus toolkit reading local data remote machines writing data remote storage moving local disk 
goal gass provide uniform remote interface applications running remote resources keeping functionality demands resources applications limited 
gass conducts operations file cache area secondary storage remote files stored 
remote file requested application reading gass default fetches entire file cache opened reading conventional file access 
retained cache long applications accessing 
writing remote file file created opened cache gass keeps track applications writing count 
count zero file transferred remote machine 
operations remote file conducted locally cache reduces demand bandwidth 
large file cache fetched application requests reading 
similarly file transferred 
gass operations allow access permitted disk areas file cache available api globus commands 
gass integrated globus resource access monitoring gram service czajkowski staging executables staging files retrieving standard output error streams jobs 
gass provides limited ability data transfer remote nodes 
prefetches entire file cache suitable transfer mechanism large data files gigabyte upwards required cache capacity available 
provide features file striping third party transfer tcp tuning provided protocols gridftp 
lightweight functionality suitable applications overhead setting gridftp connection dominates 
ibp internet backplane protocol ibp plank allows applications optimize data transfer storage operations controlling data transfer explicitly storing data intermediate locations 
ibp uses store forward protocol move data network 
ibp nodes temporary buffer data stored fixed amount time 
applications manipulate buffers data moved locations close required 
ibp modelled internet protocol 
data handled units fixed size byte arrays analogous ip datagrams network packets 
just ip datagrams independent data link layer byte arrays independent underlying storage nodes 
means applications move data worrying managing storage individual nodes 
ibp provides global addressing space global ip addressing 
client ibp network ibp node 
ibp thought layer access layer built top storage resources 
ibp provides access heterogeneous storage resources global addressing space terms fixed block sizes making access data independent storage method media 
storage buffers grow size byte arrays thought files live network 
ibp provides client api libraries provide semantics similar unix system calls 
client connects ibp depot server requests storage allocation 
return server provides capabilities reading writing managing allocation 
capabilities cryptographically secure byte strings generated server 
subsequent calls client capabilities perform operations 
capabilities provide notion security client manipulate data 
capabilities exchanged clients text 
higher order aggregation byte arrays possible similar unix inodes 
allow uploading replicating managing files network ibp layer networking layer plank 
capabilities ibp address mechanism keeps track replica generated 
directory service keeps track replica information service return ibp address replica queried 
store metadata ibp provide metadata searching service 
ibp low level storage solution functions just networking layer 
ftp ftp file transfer protocol postel reynolds fundamental protocols data movement internet 
ftp ubiquitous operating system ships ftp client 
ftp separates process data transfer channels control channel sending commands replies client server data channel actual transfer takes place 
ftp commands set data connection specifying parameters data port mode transfer data representation structure 
connection set server initiates data transfer client 
separation control data channels allows third party transfers take place 
client open control channels servers direct start data transfer bypassing client 
data transferred modes stream block compressed 
stream mode data transmitted responsibility sending host notify stream 
block mode data transferred series blocks preceded header bytes 
compressed mode preceding byte denotes number replications byte filler bytes represented single byte 
error recovery restart ftp cover corrupted data takes care data lost due loss network host ftp process 
requires sending host insert markers regular intervals data stream 
transmission restarted marker sent sender previous transfer crashed 
restart available stream transfer mode 
security ftp minimal limited control channel 
username password transmitted clear text facility encrypting data transit protocol 
limits ftp confidential transfers 
numerous extensions ftp proposed offset limitations 
rfcs horowitz lunt propose security features extensions ftp respectively 
implemented popular ftp servers wu ftpd 
ssh file transfer protocol galbraith secure file transfer protocol uses secure shell ssh protocol authentication data channel encryption 
designed transfer protocol remote file system access protocol 
support features required high performance data transfer parallel striped data transfer resuming interrupted transmissions tuning tcp windows 
gridftp gridftp allcock allcock extends default ftp protocol providing features required data grid environment 
aim gridftp provide secure efficient reliable data transfer grid environments 
gridftp extends ftp protocol allowing gsi kerberos authentication 
gridftp provides mechanisms parallel striped data transfers supports partial file transfer ability access part file 
allows changing sizes tcp buffers congestion windows improve transfer performance 
transfer massive data sets prone failures network may exhibit transient behaviour long periods time 
gridftp sends restart markers indicating byte range successfully written receiver seconds control channel 
case failure transmission resumed point indicated restart marker received sender 
gridftp provides features extending basic ftp protocol new commands features new transfer mode 
striped passive command extension ftp command server presents list ports connect just single port 
allows multiple connections download file receiving multiple files parallel 
extended retrieve command supports partial file transfer things 
set buffer buffer extensions allow resizing tcp buffers client server sides 
data channel authentication extension provides encrypting data channels confidential file transfer 
control channel authenticated rfc horowitz lunt mechanisms 
parallel striped data transfers realised new transfer mode called extended block mode mode 
sender notifies receiver number data streams data eod data count codes 
code signifies eod codes received consider transfer closed 
additional protocol required sender side ensure receiver obtains data correctly 
gridftp implements rfc negotiation feature sets client server 
sender requests features supported receiver sets connection parameters accordingly 
gridftp supports restart stream mode transfers provided vanilla ftp protocol 
public implementation gridftp server side protocols provided globus toolkit foster kesselman 
globus gridftp server modified wu ftpd server supports gridftp features striped data transfer automatic tcp buffer size negotiation 
globus toolkit provides libraries apis clients connect gridftp servers 
command line tool globus url copy built libraries functions gridftp client 
examples gridftp clients ncsa gridftp client client ncsa 
evaluation gridftp protocols alongside ftp shown additional features gridftp increases performance data transfer 
particularly usage parallel threads dramatically improves transfer speed loaded unloaded networks 
parallel transfers saturate bandwidth improving link utilisation 
kangaroo kangaroo thain data movement protocol aims improve responsiveness reliability large data transfers grid 
main idea kangaroo conduct data transfer background process failures due server crashes network partitions handled transparently process application having deal 
kangaroo uses memory disk storage buffers data written application moved background process 
transfer data performed concurrently cpu bursts improving utilization 
transfer conducted hops stages intermediate server introduced client remote storage data read written 
data received intermediate stage disk copied stage background process called mover 
means client application writing data remote storage isolated effects network crash slowdown long keep writing disk spool 
possible client write data destination server directly tcp connection kangaroo primitives 
kangaroo services provided interface implements simple file semantics get non blocking read put non blocking write commit block writes delivered stage push block writes delivered final destination 
provides weak consistency envisioned grid applications data flow primarily direction 
seen kangaroo output oriented protocol primarily deals reliability data transfer client server 
design kangaroo similar ibp aims different 
store forward method means transporting data 
ibp allows applications explicitly control data movement network kangaroo aims keep data transfer hidden usage background processes 
ibp uses byte arrays kangaroo uses default tcp ip datagrams data transmission 
legion model legion chapin object oriented grid middleware providing single system image collection distributed resources 
mechanism legion white aims provide transparent access files stored distributed resources apis daemons native legacy applications alike 
resources legion system represented objects 
correspond files conventional file system correspond directories 
separated actual file system 
copied registered context space legion 
context space provides location independent identifiers bound human readable context names 
presents single address space hierarchy users request files worrying location 
representation system independent provides interoperability heterogeneous systems 
access legion file object provided various means 
command line utilities provide familiar interface legion context space 
application developers apis closely mimic file primitives unix system calls 
legacy codes buffering interface provided applications operate local files copied legion objects changes copied back 
method modified nfs daemon translates client request appropriate legion invocations 
security file transfer provided means proxies delegated file access mechanisms ferrari 
data encrypted transit 
caching prefetching implemented increasing performance ensure reliability 
srb storage resource broker srb baru developed san diego supercomputing centre sdsc focuses providing uniform transparent interface heterogenous storage systems include disks tape archives databases 
study srb replication mechanism provided section section focus data transport mechanism srb 
data transport srb provides features parallel data transfers performing bulk data transfer operations geographically distributed sites 
parallel transfer requested client srb server creates number parallel streams depending bandwidth availability speed storage medium 
srb allows streaming data transfer supports bulk operations multiple files sent multiple streams storage resource 
srb transfer multiple files containers stage files tape archival storage disk storage faster access 
srb provides strong security mechanisms supported fine grained access controls data 
access security provided credentials passwords public key private key pair stored 
controlled authorization read access provided table comparison various data replication mechanisms 
project model topology storage integration grid centralised hierarchy tightly coupled rls centralised hierarchy gdmp centralised hierarchy srb decentralised flat intermediate data transport metadata closed system active open userdefined passive open userdefined passive closed userdefined passive update catalog async epidemic async ondemand async ondemand async ondemand tickets issued users control privileges data 
tickets time limited limited 
users control access privileges collection hierarchy 
srb provides support remote procedures 
operations performed data srb having move 
remote procedures include execution sql queries filtering data metadata extraction 
provides additional level access control users specify certain datasets collections accessible remote procedures 
data replication storage subsection data replication mechanisms data grids studied depth classified taxonomy section 
chosen wide usage wide variations design implementation represent 
summary table 
table encapsulates differences various replication mechanisms basis replication strategies follow 
replication strategies simulated explained separate subsection 
grid grid architecture couples storage bandwidth processing provide scalable computing process petabytes pb data 
architecture consists nodes large disk space order terabytes tb coupled computing power 
nodes connected high speed interconnect myrinet fast ethernet 
consists filesystem process scheduler parallel apis 
filesystem parallel filesystem unifies file addressing space nodes 
provides scalable bandwidth integrating process scheduling data distribution 
dbms dbms dbms dbms table comparison replication strategies 
project method granularity objective grid static file fragment locality rls static datasets file popularity publication gdmp stockinger static datasets file popularity fragment tion srb static containers preservation publi datasets file cation dynamic file update costs bell 
dynamic file economic lee weissman dynamic file popularity ranganathan 
dynamic file popularity file large file stored filesystem multiple disks fragments 
fragment arbitrary length stored node 
individual fragments replicated replicas managed metadata 
individual fragments may replicated replicas managed filesystem metadata replica catalog 
metadata updated operation file 
file write file modified saved internally versioned new file created 
targets data intensive applications program executed different data files primary task reading large body data 
data split stored fragments nodes 
executing program process scheduler dispatches node segment data program wants access 
nodes contain data replicas heavy cpu load filesystem creates replica requested fragment node assigns process 
way bandwidth gained exploiting access locality data 
process controlled apis 
possible access file local buffer cache replication 
system tuned high speed data access large scale architecture clusters consisting hundreds nodes 
requires high speed interconnects nodes bandwidth intensive tasks replication cause performance hits 
evident experiments carried clusters wide area testbeds yamamoto 
scheduling process level applications api system call trapping library provided inter operating legacy applications 
targets applications high energy physics data write read 
applications data constantly updated problems managing consistency replicas metadata upcoming version aims fix 
rls giga scale global location engine chervenak architectural framework replica location service rls maintains information physical locations copies data 
main components rls local replica catalog lrc maps logical representation physical locations replica location index rli indexes catalog 
actual data represented logical file name lfn contain information size file creation date metadata help users identify files seek 
logical file mapping actual physical location data file replicas 
physical location identified unique physical file name pfn url uniform resource locator data file storage 
lrc provides pfn corresponding lfn 
lrc supports authenticated queries information data available absence proper credentials 
data file may replicated geographical administrative boundaries information replicas may replica catalogs 
rli creates index replica catalogs set logical file names pointer replica catalog entries 
possible define configurations replica indexes example hierarchical configuration central single indexed configuration partitioned index configuration 
possible configurations listed chervenak 

information rli periodically updated soft state mechanisms similar globus mds monitoring discovery system 
fact structure replica catalog quite similar mds czajkowski 
rls aimed replicating data write read 
data scientific instruments needs distributed world falls category 
data seldom updated strict consistency management required 
soft state management applications 
rls standalone replication service handle file transfer data replication 
provides index replicated data 
gdmp gdmp samar stockinger stockinger replication manager aims provide secure high speed file transfer services replicating large data files object databases 
gdmp provides point point replication capabilities utilizing capabilities data grid tools replica catalogs gridftp 
gdmp publish subscribe model server publishes set new files added replica catalog client request copy making secure connection server 
gdmp uses gsi authentication authorization infrastructure 
clients register server receive notifications new data available requested replication 
failure replication assumed handled client 
example connection fails replicating set files client may reconnect server request re transfer 
file transfer conducted gridftp 
gdmp deals object databases created high energy physics experiments 
single file may contain objects advantageous replication mechanisms deal objects files 
objects requested site copied new file source 
file transferred recipient database remote updated include new objects 
file deleted origin 
case replication static changing grid conditions taken account source site 
left upto client site determine time volume replication 
gdmp originally conceived cms experiment lhc data generated point replicated globally 
consistency replicas big issue updates notifications single direction 
data experiment form files containing objects object represented collision 
gdmp interact object database replicate specific groups objects sites 
srb purpose srb enable creation shared collections management consistent state information latency management load leveling logical resources usage multiple access interfaces baru rajasekar 
srb aims provide unified view data files stored disparate media locations providing capability organise virtual collections independent physical location organization 
provides large number capabilities applicable data grids collection building digital libraries persistent archival applications 
srb installation follows tier architecture bottom tier actual storage resource middleware lies top application programming interface api metadata catalog 
file systems databases managed physical storage resources psrs combined logical storage resources 
data items srb organised hierarchy collections sub collections analogous unix filesystem hierarchy 
collections implemented data items collection located psr 
data items srb collections associated metadata describe system attributes access information size descriptive attributes record properties deemed important users 
metadata stored records attributes collections psrs 
attribute access data items possible searching 
middleware srb master daemon srb agent processes 
clients authenticate srb master starts agent process processes client requests 
srb agent interfaces storage resources execute particular request 
possible create federation srb servers interconnecting masters 
federation server acts client server 
client request handed appropriate server depending location determined service 
srb implements transparency data access transfer managing data collections manage information required describing data independent underlying storage system 
collection takes care updating managing consistency data state information timestamps audit trails 
consistency managed providing synchronisation mechanisms lock stale data access propagates updates environment global consistency achieved 
srb widely data grid technologies various application domains world including uk escience california digital library rajasekar 
replication strategies study replication strategies replica sites arranged different topologies ring tree hybrid 
site node maintains index replicas hosts locations replicas knows 
replication dataset triggered requests site exceed threshold 
replication strategy places replica site minimises total access costs including read write costs datasets 
write cost considers cost updating replicas write replicas 
show simulation best results achieved replication process carried closest users 
bell 
file replication strategy economic model optimises selection sites creating replicas 
replication triggered number requests received dataset 
access mediators receive requests start auctions determine cheapest replicas 
storage broker sb participates auctions offering price sell access replica 
replica local storage element broker starts auction replicate requested file storage determines having dataset economically feasible 
sbs bid lowest price offer file 
lowest bidder wins auction paid amount bid second lowest bidder 
vickrey second price auction vickrey descending bids 
lee weissman architecture dynamic replication service grid 
replicas created basis site evaluating performance improved requesting replica 
popular services replicated entail performance boost lessening load requirements particular replica 
ranganathan 
dynamic replication strategy creates copies trade offs cost benefits creating replica 
strategy designed peer peer environments high degree unreliability considers minimum number replicas required probability node accuracy information possessed site peer peer network 
resource allocation scheduling subsection deals study resource allocation scheduling strategies data grids 
grid scheduling researched topic study limited strategies explicitly deal transfer data processing 
focus features adapting environments varied data sources scheduling jobs order minimise movement data 
table summarises scheduling strategies surveyed section classification 
scheduling strategies data intensive applications distinguished basis couple data movement job submission don mentioned earlier section case temporal locality data requests exploited 
initial focused reuse cached data 
example direction casanova 
introduce heuristics scheduling independent tasks sharing common files grid composed interconnected clusters 
strategy prefer nodes clusters data transferred clusters data 
source data considered client node machine submits jobs grid 
efforts looked extending data replication copies data maintained longer term benefit requests coming job submissions 

simulated project application model table comparison scheduling strategies 
scope data replication utility function locality casanova bag tasks individual coupled makespan temporal grads process level individual decoupled makespan spatial ranganathan independent individual decoupled makespan spatial foster tasks kim weissman independent individual decoupled makespan spatial tasks process level individual coupled makespan temporal pegasus deelman workflows individual decoupled makespan temporal thain 
independent tasks community coupled makespan chameleon independent tasks individual decoupled makespan spatial sphinx workflows community decoupled qos spatial gridbus bro bag tasks individual decoupled qos spatial ker buyya yu buyya job scheduling data replication policies central tier model organization data grids grid architecture 
policies simulated authors establish combination strategy job executed resource contains data job scheduling background replication policies number accesses replicate node maximum estimated performance aggressive replication provides minimum execution time job 
similar intent thain 
describe means creating communities groups cpu resources condor pools clustered storage resource 
storage appliance satisfies data requirements jobs executed processes outside community 
scheduling strategy allows data staged community job executed job migrate community data required staged 
decision user comparing overheads staging application replicating data 
different policies previously mentioned replication process heuristics requires user intervention 
improving temporal locality data replicating community improves performance 
section look coupled strategy proposed phan 
uses genetic algorithms scheduling heuristic 
strategies decouple job submission data movement attempt reduce data transfer time scheduling job close source data accessing data replica site closest site computation 
term close refers site minimum transfer time 
ranganathan foster propose decoupled scheduling architecture data intensive applications consists components external scheduler es decides node jobs submitted local scheduler ls node decides priority jobs arriving node dataset scheduler ds tracks popularity datasets decides datasets replicate delete 
simulation evaluate combinations job scheduling algorithms es replication algorithms ds 
results show worst performance executing job source data absence replication 
sites host data overloaded case 
best performance job scheduling strategy data replication 
similar strategy proposed chameleon park kim site data replicated preferred submitting job data 
strategies studied try reduce makespan minimum completion time mct task defined difference time job submitted computational resource time completed 
makespan includes time taken transfer data point computation allowed scheduling strategy 

grid application development software grads project makespan schedulers operate system process level 
scheduling carried phases execution initial matching application requirements available resources performance model called launch time scheduling initial schedule modified execution take account dynamic changes system availability called rescheduling ordination schedules done meta scheduling 
contracts formed ensure guaranteed execution performance 
mapping search procedure 
forms candidate machine groups cmg consisting available resources pruned yield suitable group application 
mapper maps application data physical location group 
spatial locality primarily exploited 
scheduler tightly integrated application works process level 
algorithms independent application 
suggested extending grads scheduling concept workflow applications cooper 
treatment data remains 
casanova 
extend heuristics reducing makespan min min max min sufferage introduced maheswaran 
consider input output data transfer times 
min min assigns tasks makespan nodes execute fastest max min assigns tasks maximum makespan fastest executing nodes 
sufferage assigns tasks basis suffer assigned particular node 
sufferage value computed difference best mct task particular node second best mct node 
tasks higher sufferage values receive priority 
authors introduce heuristic extended version sufferage takes account file locality scheduling jobs considering mct cluster level 
job scheduled cluster file required job previously transferred node cluster 
kim weissman introduce genetic algorithm ga scheduler reducing makespan data grid applications decomposable independent tasks 
scheduler targets application model large dataset split multiple smaller datasets processed parallel multiple virtual sites virtual site considered collection compute resources data servers 
solution scheduling problem represented chromosome gene represents task allocated site 
sub gene associated value represents fraction dataset assigned site gene associated value denoting capability site fraction datasets assigned time taken transfer fractions execution time 
chromosomes mutated form generation chromosomes 
iteration chromosomes ranked objective function iteration stops predefined condition 
objective algorithm reduce completion time iterations tend favour tasks data processed close point computation exploiting spatial locality datasets 
phan 
apply similar ga strategy case data movement coupled job submission 
chromosome adopt represents job ordering assignments jobs compute nodes assignment data replica locations 
specified number iterations case ga converges near optimal solution gives job order queue job assignments data assignments minimize makespan 
strategies concentrated independent tasks bot model grid applications pegasus deelman concentrates reducing makespan workflow applications 
strategy reduces workflow contains order execution components concrete workflow component turned executable job locations computational resources data specified 
workflow goes process reduction components outputs generated entered replica location service removed workflow substituted physical location products 
emphasis reuse produced data products 
planning process selects source data random temporal spatial locality exploited 
projects aim achieve different scheduling objectives achieving specific qos demanded application 
sphinx scheduling parallel heterogeneous independent middleware project scheduling data intensive applications grid 
scheduling sphinx client server framework scheduling client vo submits meta job directed acyclic graph dag scheduling servers vo qos requirements number cpus required deadline execution 
qos privileges user enjoys may vary groups belongs 
server allocated portion vo resources turn reserves job submitted client allocated qos user sends client estimate completion time 
server reduces dag removing tasks outputs 
client accepts completion time server begins execution reduced dag 
scheduling strategy sphinx considers vo policies dimensional space resource provider resource properties user time forming dimensions 
policies expressed terms quotas tuples formed values dimension optimal resource allocation user request provided linear programming solution minimizes usage user quotas various resources 
data intensive application scheduling gridbus broker buyya carried basis qos factors deadline budget 
execution model parameter sweep bag tasks depends multiple data files replicated multiple data resources 
scheduling algorithm tries minimize economic data grid organization taxonomy model scope virtual organization data sources management monadic hierarchical federation hybrid interdomain intradomain collaborative regulated economic reputation transient stable autonomic managed lcg egee ppdg esg uk escience egee uk escience egee uk escience mapping data grid organization taxonomy data grid projects 
objective incrementally building resource sets consisting compute resource executing job data site file needs accessed job 
scheduler performs replication data case 
scheduling workflows supported gridbus workflow engine yu buyya similar properties respect scheduling data intensive applications 
discussion figures pictorially represent mapping systems analysed section taxonomy 
boxes leaves taxonomy branches contains systems exhibit property leaf 
box containing implies systems studied satisfy property corresponding leaf 
figures seen taxonomy shown complete respect systems studied fully described categories taxonomy 
shows organizational taxonomy annotated data grid projects studied section 
seen current scientific data grids follow hierarchical federated models organization data sources wellestablished 
data sources generally mass storage systems data transferred files datasets repositories 
social point view data grids formed establishing collaborations researchers domain 
cases new participants willing join contribute part particular scientific community collaboration 
mapping various data grid transport mechanisms studied section proposed taxonomy shown 
requirement transfer large datasets led development high speed low latency transfer protocols gridftp rapidly default transfer protocol data grid projects 
ftp certain projects data transport taxonomy function security fault tolerance transfer mode file mechanism overlay network transfer protocol authentication authorization encryption restart transmission resume transmission cached transfers block stream compressed bulk transfers gass legion srb ibp kangaroo ftp gridftp passwords cryptographic keys coarse grained fine grained ssl unencrypted gass ftp srb gridftp ftp gridftp srb ibp ftp gridftp srb srb gass ibp kangaroo legion mapping data transport taxonomy various projects 
data lesser size security constraints srb applicable srb installation ibp kangaroo deployed existing data grids 
due fact research projects products meet requirements data grid environment 
figures show mapping data replication systems covered sections replica architecture strategy taxonomy 
hierarchical model hep experiments motivated development tree structured replication mechanisms designed top terms organization data propagation 
projects followed federation model srb offers flexibility organization model replica sites 
srb hep experiments belle configured hierarchy sites 
currently massive datasets replicated statically project administrators select locations projects intelligent dynamic replication strategies place production data grids 
static replication strategy guided objective increasing locality datasets 
resource allocation scheduling efforts especially involve coupling replication job submission follow similar strategies reduce makespan 
inferred illustrates mapping scheduling efforts taxonomy 
data grid technologies employed production environments evolving meet requirements 
new developments areas replication resource allocation scheduling covered section 
subsection look emerging trends drive evolution data grid technologies 
replica architecture taxonomy model topology storage integration transfer protocols metadata update propogation catalog organization centralized decentralized hierarchical flat hybrid tightly coupled intermediate loosely coupled open protocols closed protocols attributes update type synchronous asynchronous tree hash dbms srb rls gdmp srb gdmp rls srb rls gdmp rls gdmp srb system user defined active passive epidemic demand srb gdmp rls srb gdmp rls srb gdmp rls srb gdmp rls mapping data replication architecture taxonomy various systems 
replication strategy taxonomy method granularity objective function static dynamic container dataset file fragment locality popularity update costs economic preservation publication srb rls gdmp bell lee ranganathan srb srb rls gdmp gdmp rls gdmp lee ranganathan bell srb rls gdmp srb mapping data replication strategy taxonomy various systems 
scheduling taxonomy application model scope data replication utility function locality process oriented independent tasks bag tasks workflows individual community coupled decoupled makespan load balancing profit quality service temporal spatial grads ranganathan kim thain chameleon casanova gridbus broker pegasus sphinx gridbus workflow thain sphinx thain sphinx casanova thain grads ranganathan kim pegasus chameleon sphinx gridbus sphinx gridbus casanova thain pegasus grads ranganathan kim thain chameleon sphinx gridbus mapping resource allocation scheduling taxonomy various systems 
trends trends drive innovation data grids increased collaboration architectures market mechanisms enterprise requirements 
key properties constituent technologies identified taxonomy required realize innovation discussed detail summarized table 
important note exclude characteristics consideration 
increased collaboration data grids built vos current technologies provide capabilities required enabling collaboration participants 
example tree structure replication mechanisms inhibits direct copying data participants reside different branches 
replication systems follow hybrid topologies involve peer peer links different branches enhanced collaboration 
exchange data accompanied enhanced security guarantees 
motivates fine grained access controls system 
communities formed pooling resources participants resource allocation ensure fair shares 
requires community schedulers assign quotas users priorities resource availability 
individual user schedulers submit jobs account assigned quotas negotiate central scheduler quota increase change priorities 
able swap reduce quotas order gain resource share 
users able plan ahead resource requirements advance reservation resources 
service oriented architecture important element web grid services ability services composed services building standard protocols invocation mechanisms 
key difference soa papazoglou georgakopoulos table trends key characteristics 
trend organization transport replication scheduling hybrid models fine grained hybrid topology community tion access active metadata soa autonomic manage overlay net replica publication open protocols ac workflow fault tive metadata models qos tolerance larity replication market interdomain sys fault decentralized profit qos tems economic ance model dynamic reputation economy vos autonomic replication enterprise management regulated economic security active metadata workflow require reputation replica update models qos ments vos preservation strategy traditional client server architecture 
high level transparency requires greater reliability guarantees impact technologies 
service disruptions accounted quickly recovered 
requires clean failure models transparent service migration capabilities realised implementing autonomic system management service grids 
service composition requires selecting right services required qos parameters 
impacts replication resource allocation leads diversification objective functions strategies current static methods 
discussed section major focus realisation grids began ogsa 
realise requirements ogsa web service resource framework foster specification adopted grid standards community 
globus toolkit version foster net humphrey implementations provide basic infrastructure required grid services 
service composition grids currently progress aided ongoing standardisation efforts ggf 
market mechanisms increasing popularity data grids solution large scale computational storage problems lead entry commercial resource providers lead market oriented vos demand supply patterns decide price availability resources 
provides incentive content owners offer data consumption outside specific domains opens interesting new applications 
vos broad interdomain scope consumers able access domain specific services buying competing service providers 
previous discussion seen market mechanisms 
additionally resource allocation replication policies need guided utility functions driven profit time satisfy user defined service quality parameters 
example dynamic system lin takes account cost data movement 
enterprise requirements enterprises production systems place handle business functions distributed data 
amount data retained manipulated growing leaps bounds 
storage devices terabyte capacity challenge organize massive volumes data enable time bound extraction useful information 
data grids provide solution problems need take account stricter reliability security requirements enterprise computing 
support transaction processing required provided consistent computation models enterprises 
challenge extend existing grid mechanisms replication data transfer scheduling new data sources distributed databases businesses 
summary studied characterised categorised aspects data grid systems 
data grids unique features presence applications heavy computing requirements geographically distributed heterogeneous resources different administrative domains large number users sharing resources wanting collaborate 
enumerated characteristics data grids share similarities different distributed data intensive paradigms content delivery networks peer peer networks distributed databases 
focus architecture data grids fundamental requirements data transport mechanism data replication systems resource allocation job scheduling 
developed taxonomies areas classify common approaches provide basis comparison data grid systems technologies 
compare representative systems areas categorize respective taxonomies 
doing gained insight architectures strategies practices currently followed data grids 
characterisation able discover shortcomings identify gaps current architectures systems 
represent directions followed researchers area 
lays comprehensive classification framework serves tool understanding complex area presents efforts mapped 
conclude data grids adopted widely sharing data collaboratively managing executing large scale scientific applications process large datasets distributed world 
research needs undertaken terms scalability interoperability data maintainability data grids truly preferred infrastructure applications 
solving problems creates potential data grids evolve self organized self contained creating generation infrastructure enabling users extract maximum utility volumes available information data 
grateful anonymous reviewers detailed comments helped improving quality 
acknowledge efforts developers grid systems surveyed 
colleagues university melbourne krishna ma goel chee shin yeo comments 
express gratitude reagan moore san diego supercomputing center extensive thought provoking comments suggestions various aspects taxonomy 
heinz stockinger university vienna chris jpl nasa william allcock argonne national lab instructive comments 
partially supported australian research council arc discovery project storage technology sponsorship grid fellowship 
abramson giddy 
high performance parametric modeling nimrod killer application global grid 
proceedings th international parallel distributed processing symposium ipdps cancun mexico 
ieee cs press los alamitos ca usa 

project phase report 
tech 
rep cern 
mar allcock chervenak foster kesselman tuecke 
secure efficient data transport replica management high performance data intensive computing 
proceedings ieee mass storage conference san diego usa 
ieee cs press los alamitos ca usa 
allcock chervenak foster kesselman tuecke 
data management transfer high performance computational grid environments 
parallel computing 
allcock foster chervenak deelman kesselman lee sim shoshani williams 
high performance remote access climate simulation data challenge problem data grid technologies 
proceedings acm ieee conference supercomputing sc denver usa 
acm press new york ny usa 
allcock 
gridftp protocol specification 
global grid forum recommendation 
alonso barbara 
negotiating data access federated database systems 
proceedings th international conference data engineering los angeles ca usa 
ieee cs press los alamitos ca usa 
andersen balakrishnan kaashoek morris 
resilient overlay networks 
proceedings th acm symposium operating systems principles sosp banff alberta canada 
acm press new york ny usa 
anderson cobb 
seti home experiment public resource computing 
commun 
acm 

web services data access integration ws dai 
tech 
rep ggf working group 
june 
informational document 
freitag navarro 
self organizing resource allocation autonomic networks 
proceedings st international workshop autonomic computing systems prague czech republic 
ieee cs press los alamitos ca usa 
avery foster 
griphyn project virtual data grids 
tech 
rep griphyn griphyn collaboration 
baker buyya 
grids grid technologies wide area distributed computing 
softw 
pract 
exper 
dec 
wiley press usa 
baru moore rajasekar wan 
sdsc storage resource broker 
proceedings cascon 
ibm press toronto canada 
beck fagg moore plank wolski 
internet backplane protocol study resource sharing 
proceedings nd ieee acm international symposium cluster computing grid ccgrid berlin germany 
ieee cs press los alamitos ca usa 
bell cameron millar stockinger 
evaluation economy file replication strategy data grid 
proceedings rd ieee acm international symposium cluster computing grid ccgrid tokyo japan 
ieee cs press los alamitos ca usa 
foster kesselman tuecke 
gass data movement access service wide area computing systems 
proceedings th workshop parallel distributed systems atlanta usa 
acm press new york ny usa 
project japan 

www jp 
biomedical informatics research network 

www net 
brady simpson 
wiley press london uk chapter grid enabled federated database annotated mammograms 
bray paoli sperberg mcqueen maler 
extensible markup language xml rd edition 
recommendation 
newman 
grid computing making global infrastructure reality 
wiley press london uk chapter data intensive grids high energy physics 
buyya 
compute power market market oriented grid 
proceedings st international symposium cluster computing grid ccgrid 
ieee cs press los alamitos ca usa 
casanova berman 
heuristics scheduling parameter sweep applications grid environments 
proceedings th heterogeneous computing systems workshop hcw cancun mexico 
ieee cs press los alamitos ca usa 
ceri 
distributed databases principles systems 
mcgraw hill new york usa 
chapin grimshaw 
legion resource management system 
proceedings th workshop job scheduling strategies parallel processing 
ieee cs press los alamitos ca usa 
chervenak deelman foster guy hoschek iamnitchi man ripeanu stockinger stockinger tierney 
framework constructing scalable replica location services 
proceedings ieee acm conference supercomputing sc baltimore usa 
chervenak foster kesselman salisbury tuecke 
data grid architecture distributed management analysis large scientific datasets 
journal network computer applications 
buyya 
peer peer computing evolution disruptive technology 
idea group publishers hershey pa usa chapter peer peer networks content sharing 
clarke sandberg wiley hong 
freenet distributed anonymous information storage retrieval system 
international workshop designing privacy enhancing technologies berkeley ca usa 
springer verlag london uk 
cooper kennedy koelbel marin maz ina mellor crummey berman casanova chien liu xia johnsson liu patel reed deng mendes shi dongarra 
new grid scheduling rescheduling methods grads project 
proceedings nsf generation software workshop international parallel distributed processing symposium santa fe usa 
ieee cs press los alamitos ca usa 
czajkowski foster karonis kesselman martin smith tuecke 
resource management architecture metacomputing systems 
proceedings workshop job scheduling strategies parallel processing ipps spdp orlando florida usa 
springer verlag london uk 
czajkowski kesselman fitzgerald foster 
grid information services distributed resource sharing 
proceedings th ieee international symposium high performance distributed computing hpdc san francisco ca 
ieee cs press los alamitos ca usa 
casanova berman 
decoupled scheduling approach grads environment 
proceedings ieee acm conference supercomputing sc baltimore usa 
ieee cs press los alamitos ca usa 
berman casanova don liu yang foster 
grid resource management state art trends 
kluwer academic publishers cambridge ma usa chapter scheduling grid application development software project 
davison 
web caching primer 
ieee internet computing 
deelman blythe gil kesselman 
grid resource management state art trends 
kluwer academic publishers cambridge ma usa chapter workflow management griphyn 
maggs parikh sitaraman weihl 
globally distributed content delivery 
ieee internet computing 
hoschek martinez segal samar stockinger stockinger 
models replica synchronisation consistency data grid 
proceedings th ieee international symposium high performance distributed computing hpdc san francisco ca 
ieee cs press los alamitos ca usa 
foster 
usage policy cpu sharing virtual organizations 
proceedings th ieee acm international workshop grid computing grid pittsburgh pa usa 
ieee cs press los alamitos ca usa 

performance evaluation gridftp project 
tech 
rep cs dc project 
jan enabling grids science egee 

public eu egee org 
ferrari humphrey chapin grimshaw 
flexible security system metacomputing environments 
proceedings th international conference high performance computing networking 
springer verlag london uk 
finkelstein lewis bowen 
relating requirements architectures study data grids 
journal grid computing 
foster 
globus toolkit version software service oriented systems 
lecture notes computer science 
foster czajkowski ferguson frey graham maguire tuecke 
modeling managing state distributed systems role 
proceedings ieee march 
foster iamnitchi 
death taxes convergence peer peer grid computing 
proceedings nd international workshop peer peer systems iptps berkeley ca usa 
lecture notes computer science vol 

springer verlag london uk 
foster karonis 
grid enabled mpi message passing heterogeneous distributed computing systems 
proceedings ieee acm supercomputing conference sc san jose ca usa 
ieee cs press los alamitos ca usa 
foster kesselman 
globus project status report 
proceedings ipps spdp heterogeneous computing workshop 
ieee cs press los alamitos ca usa 
foster kesselman 
grid blueprint computing infrastructure 
morgan kaufmann publishers san francisco usa 
foster kesselman nick tuecke 
grid services distributed system integration 
computer 
foster kesselman tsudik tuecke 
security architecture computational grids 
proc 
th acm conference computer communications security conference san francisco ca usa 
acm press new york ny usa 
foster kesselman tuecke 
anatomy grid enabling scalable virtual organizations 
international journal high performance computing applications 
foster tuecke unger 
ogsa data services 
global grid forum 
fox 
narada event brokering system overview extensions 
proceedings international conference parallel distributed processing techniques applications pdpta 
csrea press las vegas usa 
galbraith 
ssh file transfer protocol 
internet draft 
valid upto september 
gardner 
grid production grid principles practice 
proceedings th symposium high performance distributed computing hpdc honolulu usa 
ieee cs press los alamitos ca usa 
gray neil shasha 
dangers replication solution 
proceedings acm sigmod international conference management data sigmod montreal quebec canada 
acm press new york ny usa 
gray reuter 
transaction processing concepts techniques 
morgan kaufmann publishers san mateo calif 
rfc feature negotiation mechanism file transfer protocol 
proposed standard 
hey trefethen 
uk science core programme grid 
journal generation computer systems fgcs 
karl wagner 
exploiting spatial temporal locality accesses new hardware monitoring approach dsm systems 
proceedings th international euro par conference parallel processing euro par uk 
lecture notes computer science vol 

springer verlag london uk 
agrawal abbadi 
database replication epidemic update 
tech 
rep university california santa barbara 
jan 
cms requirements grid 
proceedings conference computing high energy physics chep beijing china 
science press 
horowitz lunt 
rfc ftp security extensions 
proposed standard 
hoschek martinez samar stockinger stockinger 
data management international data grid project 
proceedings st ieee acm international workshop grid computing grid bangalore india 
springer verlag london uk 
ford solo 
rfc internet public key infrastructure certificate certificate revocation list profile 
standard 
huffman denis waters 
cdf uk project 
www ac uk metadata subgroups docs cdf cdf internal note 
humphrey wasson morgan 
early evaluation ws notification net 
proceedings th ieee acm international workshop grid computing grid pittsburgh pa usa 
ieee cs press los alamitos ca usa 
avery ranka 
sphinx scheduling middleware data intensive applications grid 
tech 
rep gri griphyn grid physics network 
may avery ranka 
policy scheduling simple quality service grid computing 
proceedings th international parallel distributed processing symposium ipdps 
santa fe nm usa 
ieee cs press los alamitos ca usa 
project 

protocols 
available www org protocol 
karlsson mahalingam 
need replica placement algorithms content delivery networks 
proceedings web content caching distribution conference wcw boulder colorado 
www org 
kim weissman 
ga approach scheduling decomposable data grid applications 
proceedings international conference parallel processing icpp montreal canada 
ieee cs press los alamitos ca usa 
kossmann 
state art distributed query processing 
acm comput 
surv 


heterogeneity digital libraries sides coin 
delos newsletter 
myers wulf 
doing science internet 
ieee computer 
buyya maheswaran 
taxonomy survey grid resource management systems distributed computing 
international journal software practice experience spe 
krishnamurthy wills zhang 
performance content distribution networks 
proceedings st acm sigcomm workshop internet measurement san francisco ca usa 
acm press new york ny usa 
kubiatowicz bindel chen czerwinski eaton geels gum rhea weatherspoon wells zhao 
oceanstore architecture global scale persistent storage 
proceedings th international conference architectural support programming languages operating systems asplos ix cambridge ma usa 
acm press new york ny usa 
szymanski deelman 
simulation dynamic data replication strategies data grids 
proceedings th international symposium parallel distributed processing ipdps nice france 
ieee cs press los alamitos ca usa 
szymanski deelman 
data replication strategies grid environments 
proceedings th international conference algorithms architectures parallel processing ica pp 
ieee cs press los alamitos ca usa 
laser interferometer gravitational wave observatory 

www ligo caltech edu 

large collider project 
proceedings th infn project workshop materials high energy italy 
seltzer huth 

proceedings nd international workshop peer peer systems iptps berkeley ca usa 
lecture notes computer science vol 

springer verlag london uk 
lee 
weissman 
dynamic replica management service grid 
proceedings th ieee international symposium high performance distributed computing hpdc san francisco ca 
ieee cs press los alamitos ca usa 
lee gunter tierney allcock tuecke 
applied techniques high bandwidth data transfers wide area networks 
proceedings international conference computing high energy nuclear physics beijing china 
lhc computing grid 

lcg web cern ch lcg 
lin 
economy data replication broker policies data grids 
tech 
rep university melbourne australia 
jan bsc thesis 

view relational data grid 
proceedings th international symposium parallel distributed processing ipdps nice france 
ieee cs press los alamitos ca usa 
maheswaran ali siegel hensgen freund 
dynamic mapping class independent tasks heterogeneous computing systems 
journal parallel distributed computing 
medvidovic 
unlocking grid 
proceedings th acm sigsoft symposium component software engineering cbse st louis usa 
acm press new york ny usa 
mckinley carr tseng 

improving data locality loop transformations 
acm trans 
program 
lang 
syst 
vol 

acm press new york ny usa 
milojicic lukose pruyne richard rollins xu 
peer peer computing 
tech 
rep hpl hp labs palo alto ca usa 
moore rajasekar wan schroeder 
data grid management systems 
proceedings th nasa goddard st ieee conference mass storage systems technologies college park md usa 
ieee cs press los alamitos ca usa 
moore 
persistent archive basic components 
ggf document series global grid forum 
july 
moore prince 
data intensive computing digital libraries 
commun 
acm 
moore rajasekar wan 
data grids digital libraries persistent archives integrated approach publishing sharing archiving 
proceedings ieee special issue grid computing 
ncsa gridftp client 

dims ncsa uiuc edu set 
neuman ts 
kerberos authentication service computer networks 
ieee communications sept 
oram 
peer peer harnessing power disruptive technologies 
reilly associates sebastopol ca usa 
ozsu valduriez 
principles distributed database systems ed 
prentice hall upper saddle river nj usa 
papazoglou georgakopoulos 
service oriented computing 
commun 
acm 

autonomic grid computing 
proceedings international conference autonomic computing new york usa 
ieee cs press los alamitos ca usa 
tutorial 
park 
kim 

chameleon resource scheduler data grid environment 
proceedings rd ieee acm international symposium cluster computing grid ccgrid tokyo japan 
ieee cs press los alamitos ca usa 
pearlman kesselman gullapalli spencer jr leen foster hubbard 
distributed hybrid earthquake engineering experiments experiences ground shaking grid application 
proceedings th ieee symposium high performance distributed computing hpdc honolulu hi usa 
ieee cs press los alamitos ca usa 
phan ranganathan sion 
evolving perfect schedule job assignments data replication wide area systems genetic algorithm 
proceedings th workshop job scheduling strategies parallel processing cambridge ma 
springer verlag london uk 
pitoura bhargava 
data consistency intermittently connected distributed systems 
ieee transactions knowledge data engineering 
plank beck moore wolski 
internet backplane protocol storage network 
proceedings network storage symposium seattle wa usa 
university tennessee knoxville loci cs utk edu dsi 
plank moore beck 
scalable sharing wide area storage resource 
tech 
rep cs university tennessee department computer science 
jan polychronopoulos kuck 
guided self scheduling practical scheduling scheme parallel supercomputers 
ieee transactions computers 
postel reynolds 
rfc file transfer protocol 
standard 
qin jiang 
data grids supporting data intensive applications wide area networks 
tech 
rep tr university nebraska lincoln 
may rajasekar moore zaslavsky 
grid adventures sdsc storage resource broker web services digital library applications 
proceedings th russian scientific conference digital libraries advanced methods technologies digital collections 
rajasekar wan moore 
data grids collections grid bricks 
proceedings th ieee th nasa goddard conference mass storage systems technologies mss san diego ca usa 
ieee cs press los alamitos ca usa 
rajasekar wan moore schroeder 
data grid federation 
proceedings th international conference parallel distributed processing techniques applications pdpta las vegas usa 
csrea press las vegas usa 
ranganathan foster 
decoupling computation data scheduling distributed data intensive applications 
proceedings th ieee symposium high performance distributed computing hpdc edinburgh scotland 
ieee cs press los alamitos ca usa 
ranganathan iamnitchi foster 
improving data availability dynamic model driven replication large peer peer communities 
proceedings nd ieee acm international symposium cluster computing grid ccgrid berlin germany 
ieee cs press los alamitos ca usa 
ratnasamy francis handley karp schenker 
scalable content addressable network 
proceedings conference applications technologies architectures protocols computer communications sigcomm 
acm press new york ny usa 
rowstron druschel 
pastry scalable decentralized object location routing large scale peer peer systems 
proceedings ifip acm international conference distributed systems platforms middleware heidelberg germany 
springer verlag london uk 
samar stockinger 
grid data management pilot gdmp tool wide area replication 
proceedings iasted international conference applied informatics ai innsbruck austria 
acta press calgary canada 
sandhu coyne feinstein 
role access control models 
computer 
saroiu gummadi dunn gribble levy 
analysis internet content delivery systems 
sigops operating systems review special issue network behaviour 
kant naughton 
cache conscious algorithms relational query processing 
proceedings th international conference large data bases vldb santiago chile 
morgan kaufmann publishers san francisco ca usa 
sheth larson 
federated database systems managing distributed heterogeneous autonomous databases 
acm comput 
surv 

sloan digital sky survey 

www sdss org 
stockinger samar allcock foster tierney 
file object replication data grids 
proceedings th ieee symposium high performance distributed computing hpdc san francisco usa 
ieee cs press los alamitos ca usa 
stoica morris liben nowell karger kaashoek dabek balakrishnan 
chord scalable peer peer lookup protocol internet applications 
ieee acm transactions networking 
stonebraker devine litwin pfeffer sah staelin 
economic paradigm query processing data migration mariposa 
proceedings rd international conference parallel distributed information systems austin tx usa 
ieee cs press los alamitos ca usa 
szalay gray 
world wide telescope 
science 
szalay ed 

proceedings spie conference virtual hi usa 
vol 

spie 
matsuoka morita 
performance analysis scheduling replication algorithms grid architecture high energy physics applications 
proceedings th ieee international symposium high performance distributed computing hpdc seattle usa 
ieee cs press los alamitos ca usa 
morita matsuoka soda 
grid architecture data intensive computing 
proceedings nd ieee acm international symposium cluster computing grid ccgrid berlin germany 
ieee cs press los alamitos ca usa 
ogawa matsuoka aida sato morita williams hicks 
second trans pacific grid testbed experiments sc 
proceedings international symposium applications internet workshops saint workshops tokyo japan 
ieee cs press los alamitos ca usa 
soda morita matsuoka 
grid file system supports high performance distributed parallel data computing 
proceedings computing high energy nuclear physics chep conference switzerland 
thain son livny 
kangaroo approach data movement grid 
proc 
th ieee symposium high performance distributed computing hpdc san francisco ca 
ieee cs press los alamitos ca usa 
thain bent arpaci dusseau arpaci dusseau livny 
gathering creating communities grid proceedings supercomputing denver colorado 
ieee cs press los alamitos ca usa 
thomas sandhu 
task authorization controls family models active enterprise oriented authorization management 
proceedings ifip tc wg th international conference database xi lake tahoe ca usa 
chapman hall london uk 
transaction management research group ggf 

www data grid org tm rg charter html 
buyya 
deadline budget constrained scheduling algorithm science applications data grids 
proceedings th international conference algorithms architectures parallel processing ica pp melbourne australia 
lecture notes computer science vol 

springer verlag london uk 
vickrey 
counter speculation auctions competitive sealed tenders 
journal finance 
mendes reed 
performance contracts predicting monitoring grid application behavior 
proceedings nd international workshop grid computing grid denver 
lecture notes computer science vol 

springer verlag berlin germany 
wagner schneier 
analysis ssl protocol 
proceedings nd usenix workshop electronic commerce 
usenix press berkeley ca usa 
wasson humphrey 
policy enforcement virtual organizations 
proceedings th international workshop grid computing phoenix arizona 
ieee cs press los alamitos ca usa 
white grimshaw nguyen 
grid file access legion model 
proceedings th ieee international symposium high performance distributed computing hpdc pittsburgh usa 
ieee cs press los alamitos ca usa 

data grids high energy physics melbourne perspective 
space science reviews 
yamamoto 
parallel distributed astronomical data analysis grid 
proceedings th ieee acm international workshop grid computing grid pittsburgh usa 
ieee cs press los alamitos ca usa 
yu buyya 
novel architecture realizing grid workflow tuple spaces 
proceedings th ieee acm international workshop grid computing grid pittsburgh pa usa 
ieee cs press los alamitos ca usa 
zhao kubiatowicz joseph 
tapestry infrastructure fault tolerant wide area location 
tech 
rep csd university california berkeley 

