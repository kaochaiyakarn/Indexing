challenges distributed web retrieval ricardo baeza yates carlos castillo vassilis fabrizio yahoo 
research barcelona yahoo 
research la cnr barcelona spain santiago chile pisa italy fpj vassilis yahoo com ricardo baeza cl cnr ocean web data web search engines primary way access content 
data order petabytes current search engines large centralized systems replicated clusters 
web data evolving 
number web sites continues grow rapidly currently indexed pages 
near centralized systems ineffective load suggesting need fully distributed search engines 
engines need achieve goals high quality answers fast response time high query throughput scalability 
survey organize research results outlining main challenges designing distributed web retrieval system 
standard web search engine main parts :10.1.1.27.7690
part conducted line fetches web pages crawler builds index text content indexer 
second part conducted online processes stream queries query processor 
user perspective main requirements short response time large web collection available index 
large number users having access web requirements imply necessity hardware software infrastructure index high volume data handle high query throughput 
currently system comprises cluster computers sufficient capacity hold index associated data 
achieve desired throughput clusters necessary 
get idea system suppose web pages suggests petabytes text index petabytes 
efficiency purposes large portion index fit ram 
computers gigabytes main memory need approximately clus ter hold index 
response time large search engines answer queries fraction second 
suppose cluster answer queries second caching considering system overheads 
suppose answer queries day implies second average 
need replicate system times ignoring fault tolerance aspects peaks query workload 
means need computers 
deploying system may cost dollars considering cost ownership people power bandwidth 
go exercise web conservative need clusters computers computers unreasonable 
main challenge design large scale distributed systems satisfy user expectations queries resources efficiently reducing cost query 
feasible exploit topology network layers caching high concurrency 
designing distributed system difficult depends factors seldom independent 
designing system depends considerations poor design choice affect performance adversely increase costs 
example changes data structures hold index may impact response time 
discuss main issues design distributed web retrieval system including discussions state art 
organized follows 
main goals high level issues web search engine section 
remaining sections divided main system modules crawling section indexing section querying section 
concluding remarks 
main concepts goals ultimate goal search engine answer queries fast large web page collection en table 
main modules distributed web retrieval system key issues module 
partitioning communication dependability external synchronization factors crawling sec 
url assignment re crawling url exchanges indexing sec 
querying sec 
document partitioning term partitioning query routing collection selection load balancing re indexing replication caching vironment constantly changing 
goal implies search engine needs cope web growth change growth number users variable searching patterns user model 
reason system scalable 
scalability ability system process increasing workload add resources system 
ability expand important aspect 
system provide high capacity capacity maximum number users system sustain time response time throughput goals 
system compromise quality answers easy output bad answers quickly 
main goals scalability capacity quality shared modules system detailed 
crawling module downloads collects relevant objects web 
crawler scalable tolerant protocol markup errors overload web servers 
crawler distributed efficient respect network prioritize high quality objects 
indexing module tasks partitioning crawled data actual indexing 
partitioning consists finding allocation schema documents terms partition server 
indexing traditional ir systems consists building index structure 
parallel hardware platforms exploited design implement efficient algorithms indexing documents 
query processing module processes queries scalable fashion preserving properties low response time high throughput availability quality results 
shown table high level issues common modules crucial scalability system partitioning dependability communication external factors 
partial indexing updating merging rank aggregation personalization web growth change network topology bandwidth dns qos web servers web growth change global statistics changing user needs user base growth dns partitioning deals data scalability communication deals processing scalability 
system dependable operation free failures 
dependability property system encompasses reliability availability safety security 
external factors external constraints system 
issues subdivide remaining sections 
distributed crawling implementing web crawler difficult issue basic procedure simple understand crawler receives set starting urls input downloads pages pointed urls extracts new urls pages continues process recursively 
fact software packages wget implement functionality lines code 
operation large scale web crawler may quite straightforward consumes bandwidth processing cycles systems 
fact running crawler connects half servers 
generates fair amount email phone calls :10.1.1.109.4049
web crawlers detrimental effect network deployed account set operational guidelines minimize impact web servers 
important restriction web crawler avoid overloading web servers 
de facto standards operation state crawler open connection time web server wait seconds repeated accesses 
enable scaling millions servers large scale crawling requires distributing load number agents respecting constraints 
distributed crawler web crawler operates simultaneous crawling agents :10.1.1.162.194
crawling agent runs different computer principle agents named parallel crawler literature 
different geographical network locations 
crawling agent processes execution threads running parallel keep typically tcp connections open time 
partitioning parallel crawling system requires policy assigning urls discovered agent agent discovers new url may charge downloading 
crawling agents agree policy computation 
avoid downloading page server simultaneously agent responsible content set web servers distributed crawling systems 
enables exploiting locality links fact links web point pages server unnecessary transfer urls different agent 
effective assignment function balances load agents crawling agent gets approximately load :10.1.1.14.4239
addition dynamic respect agents joining leaving system 
important feature assignment function reduction load servers add agents pool 
feature enables scalable crawling system 
trivial reasonable assignment policy hashing transform server names number corresponds index corresponding crawling agent 
policy consider number documents servers 
resulting partition may balance load properly crawling agents 
dependability issues policy distributing crawler re distribute load crawling agent leaves pool agents voluntarily due failure 
solution rehashing servers re distribute agents increases message complexity communication agents 
authors propose consistent hashing replicates hashing buckets :10.1.1.14.4239
consistent hashing new agents enter crawling system re hashing server names 
assignment function guarantee agent downloads page crawling agent terminates unexpectedly informing 
case necessary re allocate urls faulty agent 
web crawlers require large storage capacity operate failure rates may negligible individual hard disks taken account large storage systems 
web scale data collection disk failures occur frequently crawling system tolerant failures 
communication synchronization crawling agents exchange urls reduce overhead communication agents exchange batches urls time 
additionally crawling agents part input cited urls collection 
example extract information previous crawl :10.1.1.162.194
information enables significant reduction communication complexity due power law distribution degree pages 
way agents need exchange urls frequently 
agent crawls web servers possible reduce communication costs having servers assigned agent topologically close web graph sharing links 
different issue communication crawler web servers 
web crawler continuously polling changes web pages inefficient 
way problem modified header reduce eliminate overhead due polling 
improved web server informs crawler modification dates modification frequencies local pages 
proposals direction largest search engines agreed standard type server crawler cooperation www org 
external factors dns frequently bottleneck operation web crawler submit large number dns queries :10.1.1.13.4762
particularly important crawler control dns servers probes 
common solution cache dns lookup results 
important consideration servers web slow go line intermittently transient failures 
distributed web crawler tolerant transient failures slow links able cover web large extent coverage percentage pages obtained crawling pages available web 
network topology bottleneck 
solve problem carefully distribute web crawlers distinct geographic locations 
optimization problem variables including network costs different locations cost sending data back search engine 
scenario part indexing part parsing distributed creating central collection 
practice web open environment crawler design assume server comply strictly standards protocols web 
different implementations protocol adhere protocol correctly honor accept range headers 
time pages web html code written hand generated software adhere html specification correctly important html parser tolerant sort errors crawled pages 
distributed indexing indexing ir process building index collection documents 
typically inverted index structure storing indexes ir systems :10.1.1.27.7690
vanilla implementation consists couple data structures lexicon posting lists 
stores distinct terms contained documents 
array lists storing term occurrences document collection 
element list posting contains minimal form identifier document containing terms 
current inverted index implementations keep information number occurrences term document position context appears title url bold 
depending index organized may contain information efficiently access index skip lists 
principle represent collection documents binary matrix rows represent documents columns represent terms 
element document contains term 
model building index simply equivalent computing transpose matrix 
corresponding matrix processed build corresponding inverted index 
due large number elements matrix real web collections millions terms billions documents method practical 
indexing considered sort operation set records representing term occurrences 
records represent distinct occurrences term distinct document 
sorting efficiently records balance memory disk usage challenging operation 
shown sort approaches single pass algorithms efficient scenarios indexing large amount data performed limited resources :10.1.1.51.7802
case web search engines data repositories extremely large 
efficiently indexing large scale distributed systems adds level complexity problem sorting challenging 
distributed index distributed data structure servers match queries documents 
data structure potentially increases concurrency scalability system multiple servers able handle operations parallel 
considering matrix distributed index sliced partitioned version matrix 
distributed indexing process building index parallel servers available large scale distributed system cluster pcs 
term partition document partition 
different types partitioning term document matrix 
way servers partition matrix different types distributed indexes 
perform horizontal partitioning matrix 
approach widely known document partitioning means partitioning document collection smaller sub collections building inverted index 
counterpart approach referred term partitioning consists performing vertical partitioning matrix 
practice index complete collection partition lexicon corresponding array posting lists 
disadvantage term partitioning having build initially entire global index 
scale useful actual large scale web search engines 
advantages approach query processing phase 
webber show term partitioning results lower utilization resources 
specifically significantly reduces number disk accesses volume data exchanged 
document partitioning better terms throughput show possible achieve higher values 
major issue throughput fact uneven distribution load servers 
originally illustrates average busy load servers document partitioned system left pipelined term partitioned system right 
dashed line plots corresponds average busy load servers 
case term partitioned system pipeline architecture evident lack balance distribution load servers negative impact system throughput 
overcome issue try smart partitioning techniques take account estimates index access patterns distribute query load evenly 
note load balance issue servers run homogeneous hardware 
case capacity busiest server limits total capacity system 
load evenly balanced servers run heterogeneous hardware load balance problem load server proportional speed hardware 
partitioning partition index decision designing distributed index 
addition scheme partition index enable efficient query routing resolution 
able reduce number machines involved ability balancing load enables increase system ability handle higher query workload 
simple way creating partitions select elements terms documents random 
document partitioning different structured approach kmeans clustering partition collection topics :10.1.1.152.517
document term partitioning widely studied unclear circumstances suitable 
unclear methods evaluate quality partitioning 
date trec evaluation framework served purpose 
large scale search engines evaluation retrieved results difficult 
partitioning potentially enhances performance distributed search engine terms capacity follows 
case document partitioning resources available system evaluate query select subset machines search cluster ideally contains relevant results 
selected subset contain portion relevant document set 
ability retrieving largest possible portion relevant documents challenging problem usually known collection selection query routing 
case term partitioning effective collection selection hard problem solution straightforward consists selecting server holds information particular terms query 
receiving query forward servers responsible maintaining subset terms query 
scale complexity web search engines volume queries submitted day users query logs critical source information optimize precision results efficiency different parts search engines 
features query distribution arrival time query results users click possible examples information extracted query logs 
important question consider exploit transform information enable partitioning document collection routing queries efficiently effectively distributed web search engines 
past years query logs partition document collection query routing focus research projects 
term partitioned ir system major goal partition index number contacted servers minimal load equally spread available servers 
term partitioned system moffat show possible balance load exploiting information frequencies terms occurring queries postings list replication 
briefly problem partitioning vocabulary term partitioned system bin packing problem bin represents partition term represents object put bin 
term weight proportional frequency occurrence query log corresponding length posting list 
shows performance term partitioned system benefits strategy able distribute load server evenly 
experimental results show document partitioned system achieves higher throughput term partitioned system considering performance benefits due distribution load 
similarly build previous bin packing approach designing weighted function terms partitions able model query load server 
original bin packing problem simply aim balancing weights assigned bins 
case objective function depends single weights assigned terms objects occurrence terms queries 
main goal function assign occurring terms queries index partition 
important reduce number servers queried communication overhead server 
approach partitioning ir systems requires building central index clear build scalable system 
document partitioned systems problem assigning documents partitions 
majority proposed approaches load percentage document distributed load percentage pipelined 
distribution average load processor document partitioned pipelined term partitioned ir average systems processor 
busy load tb document distributed processing pipelined processing 
dashed line graph average busy load processors 
literature adopt nodes simple starved queries term node partitioning processing 
considers randomly partitioned query uses servers 
content linkage information 
research di document partitioned system higher average busy load partitioned distributing documents randomly servers sounds promising important guarantee compared load balance 

hand open questions 
document distribution instance collection selection drawback demonstrates document better systems able system document resources partitioning pipelining scheme problem servers execute leaves system operations underutilized 
unnecessarily hand load fact 
designing configuration collection pipelining partitioning querying sub collections able achieve roughly may contain throughput gorithm reduce number servers involved document distribution relevant documents 
far papers dis evaluation query balance resources collection documents model load underlying potential 
open issue 
collection separated summarized system 
load query discussed issues instructive challenges related rated examine context means load shorter 
partition partitioning index 
building index dis shows busy load document distribution query maps distinct collection containing largest tributed fashion interesting challenging prob top pipelining bottom measured queries lines graph number relevant documents possible 
construct lem 
far papers suggest approaches build mapping showing aggregate example logs 
lower index processors distributed meaning fashion 
eighth example possible query shows logs represent total system load approach available create total index resource 
distributed note fashion queries return document answer 
servers pipeline 
alternatively dean document distributed approach consistent performance time intervals representation enables clustering algorithm propose traditional parallel computing paradigm build clusters queries utilization clusters remains documents 
band map reduce show ignoring build trail index large result clustering system step finishing 
partition cluster computers 
area research collection contrast clusters pipelining build bottom col particularly active ex graph stark 
total system utilization lection selection function query document techniques achieve results practice 
varies volatile nodes busy quiet clusters 
results show technique best knowledge testing techniques ex able outperform time 
state art constant model node busy time document acting throttle cori performance currently :10.1.1.31.6094
best known collection important problem verify lection function textual documents 
cori results match expectations 
reason uneven system load lies different ways document partitioned information contained collection technique split advantage collection 
partitioning chief dependability determinants system text crit model evaluation built engine usage information number terms prob processed ical process 
length proper functioning term inverted search engine ably valid 
document queries 
partitioning interesting divides result load evenly depends node processes existence term index structures query logs enable effective par enable query resolution 
example index collection possible iden servers fail possible access index data subset documents queries solve query service failed recall 
show subset comprises parts system may working prop documents 

issue dependability update index 
systems crucial latest results queries content changes important guarantee index data available moment reflects changes timely fashion 
dependability issues partitioning schemes 
term partitioned systems server system fails impossible recover content server replicated 
case possible inefficient way recover rebuild entire index 
possibility partitions partially overlapping server fails able answer queries 
document partitioned systems robust respect servers failures 
suppose server fails 
system able answer queries sub collections possibly losing effectiveness 
dependability issues really studied field distributed systems ir 
accurate analysis real system traces may clarify points 
communication synchronization large search engine hundreds thousands millions queries day 
logging actions query logs effectively challenging volume data extremely high 
moving data server server rarely possibility due bandwidth limitations 
dealing problem important user model engine currently operating may correspond reality 
discover example distribution queries changed system adapt new partition index reflect date distribution queries 
respect index simple straightforward approach halt part index substitute re initiate 
constraint problem correct behavior underlying search engine reduces capacity temporarily 
user model inaccurate issue 
user behavior changes time able update model accordingly 
simple approach schedule updates model fixed time intervals 
question frequently need update 
recall higher update frequency implies higher network traffic lower query processing capacity 
ideally system adapts variations underlying model occur 
indexing process subject distributed merge operations 
practical approach achieving goal primitive map reduce 
primitive requires significant amount bandwidth different sites execute operations independently 
case mechanism merge operations consider communication computational aspects 
practical distributed web search engines indexes usually rebuilt scratch update underlying document collection 
case certain special document collections news articles blogs updates frequent usually kind online index maintenance strategy 
dynamic index structure constrains capacity response time system update operation usually requires locking index mutex possibly system performance 
interesting problem understanding possible safely lock index experiencing loss performance 
problematic case term partitioned distributed ir systems 
terms require frequent updates spread different servers amplifying lockout effect 
external factors distributed ir systems bottlenecks deal 
depending decides partition index may serious degradation due different factors 
document partitioned ir system instance necessary compute values global parameters collection frequency inverse document frequency term 
possible approaches 
compute final global parameter values aggregating local statistics available indexing phase 
possible avoid final aggregation 
point problem computing global statistics moves system broker responsible dispatching queries query processing servers merging results 
compute statistics broker usually resolves queries round protocol 
round broker requests local statistics server second round requests results server piggybacking global statistics second message containing query 
question point smart partitioning strategy local global statistics impact final engine effectiveness 
answering question difficult 
real world search engine fact difficult define correct answer query difficult understand local statistics difference 
possible way measure effect comparing result set computed global statistics result set computed local statistics 
furthermore note collection selection strategy global statistics feasible 
distributed query processing processing queries distributed fashion consists determining resources allocate distributed system processing particular query 
distributed search system pool available resources comprises components having roles coordinator cache query processor 
coordinator receives queries client computers decisions route queries different parts system components evaluate appropriately 
query processors hold index document information retrieve prepare presentation results respectively 
network communication essential part distributed systems parties need communicate progress 
variation latency substantial depending type network physical proximity involving servers processing single query expensive 
mitigate problem cache servers hold results frequent popular queries coordinators cached results reply client 
case communication expensive cache servers reduce query latency load servers making query resolution simple contacting single cache server 
important assumption servers implement components 
assumption particularly important large scale systems systems high request volume large amount data 
designing components way add physical servers increase system capacity fundamental large scale systems system scalable 
fact separating parts system component roles attempt promote scalability single monolithic system scale necessary size web search engine 
servers different physical locations different geographical regions call site group collocated servers 
depicts instance multi site distributed system model comprising components described 
describes role components 
sites located different regions 
site comprises number coordinators caches query processors 
query client directed closest site site 
coordinator site routes query site reasons load balancing collection selection 
site resolves query query processors returns results client 
classify distributed query processing systems attributes number components role system multiple components 
having multiple coordinators brokers distributed document term partitioned system site level brokers route queries different sites 
general term calling brokers 
site region client site region wan site region 
instance distributed query processing system 
role server described 
query processor matches documents received queries coordinator receives queries routes appropriate sites cache stores results previous queries 
role server distributed query processing framework 
tors potential improving user experience improving response time availability 
similar argument multiple cache components potential boosting response time availability reducing server load query processors 
availability caches refers failure cache components failures query processors 
query processor temporarily unavailable cache participants serve cached results period outage 
multiple query processors enable dependable system due geographical resource diversity scalable solution connectivity components connected local area network geographically spread connected wide area network distinction roles components query process ing system multiple roles 
typically components coordinators caches query processors implement server side processes queries clients submit queries 
implements traditional client server model clear distinction clients submit queries servers process queries 
alternatively participants clients servers peer peer systems :10.1.1.20.2814:10.1.1.13.1643
systems peers roles mention interaction federated system independent entities form single system 
example organization spanning different countries independent systems form organization system 
federated systems comprise sites different organizations formal agreement constrains operations site particular behavior 
interaction case federations simpler reasonable assume entity system 
components trust access information necessary component assume components behave best interest system 
open systems may case 
sites different organizations cooperate opposed forming unity may act self interest example changing priorities query resolution affect performance evaluation particular query 
number components important determines amount resources available processing queries 
depending components connected local area network vs wide area network choices allocation components change different choices lead different performance values 
fact minimizing amount resources query general important goal fewer resources query total capacity system increases 
client server systems amount resources available server side determines total capacity system 
total amount resources available processing queries increase number clients 
peer peer systems new participant new client new server 
consequently total amount resources available processing queries increases number clients assuming free riding prevalent 
federated systems independent systems combine form single system consequently necessary consider issues trust parties correct behavior 
open systems partnerships potential open systems called non cooperative literature 
improve quality service system provides clients 
systems parties may allocate resources self interested fashion having negative impact results particular party obtains 
typically architectures appear literature discussing distributed information retrieval peer peer federated systems 
peer peer systems assume large number components geographically spread peer builds version index capable resolving queries 
federated systems client server fashion major constraint prevents system peerto peer 
system unknown participants subscribe participate peer 
participant register join system open system 
discuss specifically challenges implementing systems distributed query processing considering attributes 
section focus behavior system components discussing specific mechanisms implement 
partitioning web grows capacity query processors web search engine grow order match demand high query throughput low latency 
growth size single query processor match growth web large number servers implement processor due example physical administrative constraints size single data center power cooling 
distributed resolution queries different query processors viable approach enables scalable solution imposes new challenges 
challenge routing queries appropriate query processors order utilize efficiently available resources provide precise results 
factors affecting query routing example geographical proximity topic language query 
geographical proximity aims reduce network latencies utilize resources closest user submitting query 
possible implementation feature dns redirection ip address client dns service routes query appropriate coordinator usually closest network distance 
example dns service geographical location determine route queries 
fluctuation submitted queries particular geographic region day possible offload server busy area re routing queries query processors busy areas 
generally query routing depends distribution documents query processors consequently partition index 
way partition index query processors consider topics documents 
example query processor holds index documents particular topic may process queries related topic effectively 
routing queries topic involves identifying topics web pages queries 
matching queries topics problem collection selection 
partitions ranked answer query 
number top ranked partitions process query 
challenge partitioning index changes topic distribution documents queries negative effect performance distributed retrieval system 
shown simulations distributed query processing architectures indicate changes topic distribution queries adversely impact performance resulting resources exploited full extent allocation fewer resources popular topics 
possible solution challenge automatic reconfiguration index partition considering information query logs search engine 
partitioning index language queries suitable approach 
identifying languages document performed automatically comparing gram language models target languages document comparing probabilities frequent words particular language occur document :10.1.1.162.2994
similar techniques enable identification languages queries amount text query additional contextual metadata limited process may introduce errors 
challenge routing queries language presence multilingual web pages 
example web pages describing technical content number english terms primary language different 
addition queries multilingual involving terms different languages 
mentioned discussion previous section partitioning documents terms query processor particular partitioning scheme may introduce workload query processing 
partitioning scheme documents topics languages documents potentially introduces similar workload query processors provisioning sites accordingly viable solution possible forecast workload 
dependability faults render system parts system unavailable 
particularly undesirable mission critical systems query processing component commercial search engines 
particular availability property affects systems impacts main source income companies 
distributed system components leverage plurality resources cope faults different ways 
provide evidence achieving high availability necessarily straightforward repeat graph originally appeared marzullo 
graph summarizes availability figures obtained sites grid system 
sites connected internet measurement period january august 
site comprises number servers say site unavailable possible reach servers site network partition servers failed 
bar graph corresponds average number sites monthly availability corresponding value axis period measurement 
example bar left shows sites participating system average experience outage availability month significant compared total number sites 
illustrates sites unavailable multi site systems 
system different goals design builds idea multiple independent sites forming single system share similarities distributed ir systems 
particular observation site unavailability applies federated ir systems comprising number query processors equivalent sites spread wide area network 
classical way coping faults replication 
distributed information retrieval system different aspects replicate network communication functionality data 
replicate network communication replicate number links making sites multi homed 
redundancy network communication reduces probability partition preventing clients servers communicating client server system 
critical peer peer system large number clients geographically spread design systems significant diversity respect network connectivity 
possible levels replication functionality data single site sites 
single site functionality data replicated single fault render service unavailable 
example cluster single load balancer load balancer crashes cluster stops operating failure 
multiple sites increases likelihood query processor available resolving query 
particularly necessary site failures frequent 
open question context select locations host sites degree replication necessary meet particular availability goal 
average number sites monthly availability 
site unavailability grid system 
observation regarding utilization multiple sites valid roles participants describe 
particular query processors crucial role system fulfill client requests processing capacity data store 
due large amount data indexes documents handle challenging determine replication schemes query processors 
replicating data different query processors increase probability query processor available containing data necessary process particular query 
having query processors storing data full replicas achieves best availability level possible 
impose significant unnecessary overhead reducing total storage capacity 
open question replicate data way system achieves adequate levels availability minimal storage overhead 
high availability important goal online systems 
consistency critical 
particular consider features personalization user state space containing variables indicate preferences potentially query update user state 
cases necessary guarantee state consistent update user state lost 
techniques distributed algorithms state machine replication primary backup implement fault tolerant services :10.1.1.20.4762
main challenge apply techniques large scale systems 
traditional fault tolerant systems assume small number processes 
exception chubby lock service serves thousands clients concurrently tolerates failures chubby servers 
depending requirements application possible relax strong consistency constraint techniques enable stale results implementing weaker consistency constraints 
possible improve fault tolerance caches 
query processor failures system returns cached results 
system design consider caching system alternative complementary replication 
important question design cache system effective coping failures 
course design consider primary goals cache system reducing average response time load servers operating query processors bandwidth utilization 
goals translate higher hit ratio 
interestingly higher hit ratio potentially improves fault tolerance 
different goal reducing average latency availability results respond particular query important coping faults 
example possible architecture caching cache components communicating messages wide area network 
architecture necessarily improve query processing latency message latency cache components high 
wolman argue cooperative web caching necessarily improve request latency mainly wide area communication benefit larger user population 
availability architecture increases number results system respond user queries making system available 
fact important argument favor distributed cooperative caching improve availability large scale distributed information retrieval systems wide area systems network connectivity depends providers routing failures happen frequently :10.1.1.125.8274
communication synchronization distributing tasks information retrieval system enables number desirable features seen previously 
major drawback arises distribution tasks number servers servers communicate 
network communication bottleneck bandwidth scarce resource particularly wide area systems 
furthermore physical distance servers increases significantly latency delivery particular message 
local area networks message latency order hundreds microseconds wide area networks large hundreds milliseconds 
mechanisms implement distributed information retrieval system consider constraints 
simple example suppose model front server queueing system servers model correspond threads serve requests exam queue models system distributions request interarrival service times arbitrary servers serve requests 
maximum number requests second average service time ms 
maximum capacity front server model 
ple web server 
response thread request depends communication thread parts system bandwidth message latency contribute time thread takes answer request 
assuming typical value maximum number clients apache servers shows upper bound capacity system different average service rate point average service time capacity service queue grows infinity 
graph maximum capacity drops sharply average service time thread increases drops average service time goes ms ms 
simple exercise illustrates importance considering impact network communication designing mechanisms 
distributed query processing architectures need consider overheads imposed communication merging information different components system 
term partitioned system pipelining routes partially resolved queries servers 
position information proximity phrase search communication overhead servers increases greatly includes position terms partially resolved query 
case position information needs compressed efficiently possibly encoding differently positions words appear queries 
case document partitioned system query processors send query results coordinator merges detects top ranked results user 
coordinator may bottleneck merging results great number query processors 
case possible hierarchy coordinators mitigate problem 
furthermore response time document partitioned system depends response time slowest component 
constraint necessarily due distribution documents depends disk caching mechanism amount memory number servers 
necessary develop additional models consider characteristics distributed query processing systems 
multiple query processors participate resolution query communication latency significant 
way mitigate problem adopt incremental query processing approach faster query processors provide initial set results 
remote query processors provide additional results higher latency users continuously obtain new results 
incremental query processing implications merging process results relevant results may appear due latencies 
paradigm shift way clients search possible incremental query processing 
example envision applications context infer query return results having users directly searching search engine interface 
query processing involves personalization results additional information user profile necessary search time order adapt search results interests user 
query processing architectures consider information integral part model 
additional challenge related personalization web search engines user profile represents state latest state consistent replicas 
alternatively system implement personalization thin layer client side 
approach attractive deals privacy issues related centrally storing information users behavior 
restricts user terminal 
external factors design search engines includes users clients different ways 
example evaluate precision search engine possible engineer relevance model 
similarly design analysis caching policies require information users user model 
user behavior external factor controlled search engine 
substantial change search behavior users impact precision efficiency search engine 
example topics users search slowly changed past reconfiguration search engine resources necessary maintain performance 
change user behavior affect performance caching policies 
user behavior changes frequently necessary provide mechanisms enable automatic reconfiguration system simple replacement modules 
challenge determine online users change behavior significantly 
concluding remarks summarize main challenges outlined previous sections crawling main open problems efficiently dynamically assign urls download crawling agents considering multiple constraints minimize rate requests web servers locate crawling agents appropriately network exchange urls effectively 
open problems efficiently prioritize crawling frontier dynamic scenario evolving web crawl web efficiently help web servers 
indexing main open problems document partitioning important find effective way partitioning collection query answering phase querying partitions smallest possible subset partitions 
chosen subset able provide high number relevant documents approaches partitioning determine effective way balancing load different index servers 
term partitioning document partitioning query routing possible unbalanced load 
important find strategy distribute data order balance load possible 
querying network bandwidth scarce resource distributed systems network latency significantly increases response time queries 
resolving queries distributed fashion crucial minimize number necessary servers efficiently determine servers contact 
problem query routing 
course query routing depends distribution document collection servers treated separately 
due intrinsic unreliability computer systems crucial able cope faults system example replication 
traditional replication techniques potentially reduce total capacity system increase latency particular operation clear schemes enable high availability preserve properties 
response time high throughput goals devising efficient cache system important 
extensive caching techniques difficulty distributed web retrieval design scheme effective high hit ratio time overcomes network constraints point 
discussed crawling indexing query processing separately important consideration interaction parts 
considering interaction design system complex 
valuable tool analytical model system parameters data volume query throughput characterize particular system terms response time index size hardware network bandwidth maintenance cost 
model enable system designers reason different aspects system architect highly efficient distributed web retrieval systems 
acknowledgment karen murdock valuable comments preliminary versions 
baeza yates ribeiro neto ziviani ziviani 
analyzing imbalance homogeneous index servers web search system 
information processing management 
baeza yates ribeiro neto :10.1.1.27.7690
modern information retrieval 
addison wesley may 
dean lzle 
web search planet google cluster architecture 
ieee micro mar apr 
jensen chowdhury grossman frieder 
hourly analysis large topically categorized web query log 
sigir proceedings th annual international acm sigir conference research development information retrieval pages new york ny usa 
acm press 
bender michel triantafillou weikum zimmer 
content search give web back people 
international workshop peer peer systems iptps february 

bioinformatics research network 
www net november 
boldi santini vigna :10.1.1.14.4239
ubicrawler scalable fully distributed web crawler 
software practice experience 
cho garcia molina shivakumar 
crawler friendly web servers 
proceedings workshop performance architecture web servers paws santa clara california usa 
brin page :10.1.1.109.4049
anatomy large scale hypertextual web search engine 
computer networks isdn systems april 
broder 
web search information retrieval information supply 
page 
marzullo schneider toueg 
optimal primary backup protocols 
proceedings international workshop distributed algorithms pages haifa israel november 
springer verlag 
burrows 
chubby lock service loosely coupled distributed systems 
appear osdi 

performance analysis distributed information retrieval architectures improved network simulation model 
information processing management 
callan :10.1.1.31.6094
distributed information retrieval 
croft editor advances information retrieval 
research center intelligent information retrieval volume kluwer international series information retrieval chapter pages 
kluwer academic publishers boston dordrecht london 
castillo 
cooperation schemes web server web search engine 
proceedings latin american conference world wide web la web pages santiago chile 
ieee cs press 
castillo 
effective web crawling 
phd thesis university chile 
:10.1.1.162.2994
gram text categorization 
proceedings sdair rd annual symposium document analysis information retrieval pages las vegas 
cho garcia molina :10.1.1.162.194
parallel crawlers 
proceedings eleventh international conference world wide web pages honolulu hawaii usa 
acm press 
crespo garcia molina 
semantic overlay networks systems 
technical report stanford university 
dean ghemawat 
simplified data processing large clusters 
proceedings th symposium operating systems design implementation osdi pages san francisco usa december 
macedo alves 
geographical partition distributed web crawling 
gir proceedings workshop geographic information retrieval pages bremen germany 
acm press 
orlando 
boosting performance web search engines caching prefetching query results exploiting historical usage data 
acm trans 
inf 
syst 
grefenstette 
comparing language identification schemes 
proceedings rd international conference statistical analysis textual data 
gupta campbell 
internet search engine freshness web server help 
proceedings symposium internet applications saint pages san diego california usa 
heydon najork 
mercator scalable extensible web crawler 
world wide web conference april 
marzullo 
coterie availability sites 
proceedings international conference distributed computing disc number lncs pages poland september 
springer verlag 
koster 
guidelines robots writers 
www org wc guidelines html 
koster 
robots web threat treat connexions april 
lamport 
paxos simple 
acm sigact news december 
larkey connell callan 
collection selection results merging topically organized patents trec data 
cikm proceedings ninth international conference information knowledge management pages new york ny usa 
acm press 
lempel moran 
predictive caching prefetching query results search engines 
www proceedings th international conference world wide web pages new york ny usa 
acm press 
lester moffat zobel 
fast line index construction geometric partitioning 
cikm proceedings th acm international conference information knowledge management pages new york ny usa 
acm press 
liu croft 
cluster retrieval language models 
sigir proceedings th annual international acm sigir conference research development information retrieval pages new york ny usa 
acm press 
orlando 
mining query logs optimize index partitioning parallel web search engines 
submitted siam data mining conference 
raghavan yang garcia molina 
building distributed full text index web 
acm trans 
inf 
syst 
moffat webber zobel 
load balancing term distributed parallel retrieval 
sigir proceedings th annual international acm sigir conference research development information retrieval pages new york ny usa 
acm press 
paxson :10.1.1.125.8274
routing behavior internet 
acm computer communication review october 

query driven document partitioning collection selection 
proceedings international conference scalable information systems 

search engines web dynamics 
computer networks pages 
ross 
probability models 
harcourt academic press 
saito shapiro 
optimistic replication 
acm computing surveys march 
schneider 
implementing fault tolerant services state machine approach tutorial 
acm computing surveys december 
shkapenyuk suel 
design implementation high performance distributed web crawler 
proceedings th international conference data engineering icde san jose california february 
ieee cs press 
zobel 
capturing collection size distributed non cooperative retrieval 
proceedings annual acm sigir conference seattle wa usa august 
acm press 
zobel 
query logs establish vocabularies distributed information retrieval 
information processing management january 
spink jansen wolfram saracevic 
sex commerce web search changes 
computer 

su 
drafting akamai 
proceedings acm sigcomm conference pages pisa italy september 
tang xu mahalingam 
psearch information retrieval structured overlays 
proceedings acm workshop hot topics networks hotnets pages princeton new jersey usa october 
webber moffat zobel baeza yates 
pipelined architecture distributed text query evaluation 
information retrieval 
published online october 
witten moffat bell :10.1.1.51.7802
managing gigabytes compressing indexing documents images 
morgan kaufmann may 
wolman voelker sharma cardwell karlin levy 
scale performance cooperative web proxy caching 
acm operating systems review december 
zhang marzullo schlichting 
replicating non deterministic services grid environments 
proceedings ieee international symposium high performance distributed computing hpdc haifa israel november 
