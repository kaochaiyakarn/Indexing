indexing latent semantic analysis scott deerwester center information language studies university chicago chicago il susan dumais george furnas thomas landauer bell communications research south st morristown nj richard harshman university western ontario london ontario canada new method automatic indexing retrieval described 
approach take advantage implicit higher order structure association terms documents semantic structure order improve detection relevant documents basis terms queries 
particular technique singular value decomposition large term document matrix decomposed set ca 
factors original matrix approximated linear combination 
documents represented ca 
item vectors factor weights 
queries represented pseudo document vectors formed weighted combinations terms documents supra threshold cosine values re turned 
initial tests find completely automatic method retrieval promising 
describe new approach automatic indexing retrieval 
designed overcome fundamental problem plagues existing retrieval techniques try match words queries words documents 
problem users want retrieve basis con ceptual content individual words provide unreliable evidence conceptual topic meaning docu ment 
usually ways express concept literal terms user query may match relevant document 
addition words multiple meanings terms user query literally match terms documents user 
proposed approach tries overcome cies term matching retrieval treating unreliability correspondence addressed 
received august revised april accepted april 
john wiley sons observed term document association data statistical problem 
assume underlying latent se mantic structure data partially obscured randomness word choice respect retrieval 
statistical techniques estimate latent structure get rid obscuring noise description terms documents latent semantic structure indexing retrieval particular latent semantic indexing lsi analysis tried uses singular value decomposition 
take large matrix term document association data construct semantic space terms documents closely associated placed near 
singular value decomposition allows arrangement space reflect major associative patterns data ignore smaller important influences 
result terms appear document may close document consistent major patterns association data 
position space serves new kind semantic index ing 
retrieval proceeds terms query identify point space documents neigh returned user 
deficiencies current automatic indexing retrieval methods fundamental deficiency current information retrieval methods words searchers information seek indexed 
sides issue call broadly synonymy polysemy 
syn general sense describe fact semantic structure mean correlation structure way individual words appear documents semantic implies fact terms document may taken referents document topic 
journal american society information science 
ccc ways refer object 
users different contexts different needs knowledge linguistic habits describe information different terms 
degree variability descriptive term usage greater commonly suspected 
example people choose main key word single known object time furnas landauer gomez dumais 
comparably poor agreement reported studies consistency tarr borko generation search terms expert inter fidel experienced searchers bates 
prevalence synonyms tends decrease recall performance retrieval systems 
polysemy refer general fact words distinct meaning homography 
different contexts different people term chip takes varying referential significance 
term search query neces mean document containing labeled term interest 
polysemy factor underlying poor precision failure current automatic indexing overcome problems largely traced factors 
factor way index terms identified complete 
terms describe index document typically contain fraction terms users group try look 
partly documents contain terms users apply term selection proce intentionally omit terms document 
attempts deal synonymy problem re intellectual automatic term expansion construction thesaurus 
presumably knowledgeable searchers tools suggest additional search terms 
drawback fully automatic methods added terms may different meaning intended polysemy effect leading rapid degradation precision sparck jones 
worth noting passing experiments small interactive data bases shown monotonic improvements recall rate loss precision terms taken documents large samples actual users words added gomez lochbaum landauer press 
unlimited aliasing method described effective large data bases re table 
sample term document matrix mains determined 
potential issue ambiguity lack precision problem identifying index terms text docu ments grows cumbersome 
motives approach described 
second factor lack adequate automatic method dealing polysemy 
common approach controlled vocabularies human inter act translators 
solution extremely expensive necessarily effective 
approach allow boolean intersection coor terms disambiguate meaning 
suc cess severely hampered users inability think appropriate limiting terms exist fact terms may occur documents may included indexing 
third factor somewhat technical having way current automatic indexing retrieval systems 
systems word type treated independent see example van rijsbergen 
matching terms occur counted heavily matching rarely document 
scoring success straight boolean coordination level searches fails take redundancy account result may distort results unknown degree 
problem exacerbates user difficulty compound term queries effec tively expand limit search 
rationale latent semantic indexing lsi method illustration retrieval problems illustrate problems term formation retrieval systems means fictional matrix terms documents table 
table give fictional query passed database 
column labeled rel relevant user judged document rele vant query documents relevant 
terms occurring query document com puter information indicated asterisk appropriate cell match column indicates document matches query returned user 
documents illustrate common classes problems proposed method access document retrieval information theory database indexing computer rel match dot doc doc query idf computer information look journal american society information science september deals 
document relevant document contains words query 
returned straightforward term lap retrieval scheme 
document nonrelevant docu ment contain terms query returned despite fact query context clear human observer different sense words intended 
note example meaning conditioning terms query index 
intersecting query terms plausible strategy omitting document 
start considering synonymy problem 
way looking problem document contained term look user perspective conversely query contained term access retrieval system flesh analogy consider document title consist small selection com plete discourse written topic 
text extract index terms fal observation infer terms apply topic 
said query sample description intended documents principle contained different terms ones 
job building retrieval system find way predict terms really implied query apply document latent semantics basis fallible sample 
correlation occurrence term way data term document matrix estimate true association terms documents data error 
hand great deal struc ture occurrence patterns words gives strong clue occurrence data part table cor rect portions 
example suppose total collection words access retrieval occurred documents documents contain ing access contained retrieval reason ably guess absence retrieval document containing access erroneous consequently wish retrieve document response query con taining retrieval kind structure inferences limited simple pair wise correlation 
document analysis tell term information fact 
terms query document predict occurrence term mean ing intended information knowledge de searcher 
correlational structure analysis may allow weight polysemous terms ad vantage observations 
research program find effective models overcoming problems 
representation set terms incomplete unreliable evidence relevance document replaced set entities reliable 
take advantage implicit higher order latent structure association terms documents reveal relationships 
choice method uncovering latent semantic structure goal find fit useful model rela tionships terms documents 
want matrix observed occurrences terms applied documents estimate parameters underlying model 
resulting model estimate observed occurrences really 
way example predict term associated document cause variability word association observed 
question sort model choose 
notion semantic similarity documents tween terms central modeling patterns term usage documents 
led restrict con proximity models models try put similar items near space structure 
models include hierarchical partition overlap ping clusterings ultrametric additive trees factor analytic multidimensional distance models see carroll arabie survey 
aiding information retrieval discovering latent prox structure lines precedence literature 
hierarchical classification analyses fre quently term document clustering sparck jones salton jardin van rijsbergen 
latent class analysis baker factor analysis atherton borko borko explored automatic docu ment indexing retrieval 
document clustering example notion dis tance defined documents considered close extent contain terms 
matrix document document distances sub clustering analysis find hierarchical classifi cation documents 
retrieval exploring neighborhoods structure 
similar efforts ana word usage corpus built clusters related terms effect making statistically thesaurus 
believe important weakness clustering approach hierarchies far limited capture rich se mantics document sets 
hierarchical clusterings permit cross classifications example general free parameters essentially parameters objects 
empirically clustering improves com putational efficiency search improves retrieval success unclear jardin van rijsbergen salton mcgill voorhees 
journal american society information science september previously tried factor analytic approaches taken square symmetric matrix similarities pairs documents statistical term overlap human judgments linear algebra construct low dimensional spatial model similar documents placed near 
factor analytic model potential greater richness clustering model dimensional model points nk parame ters 
previous attempts lines shortcomings 
factor analysis computationally expensive previous attempts years ago limited processing con straints borko 
second past considered restricted versions factor analytic model low dimensionality con factor analysis results simple binary clus tering borko 
third attempts relied excessively tedious data gathering tech niques requiring collection thousands similarity judgments humans 
previously reported clustering factor analytic ap proaches struggled certain representa tional awkwardness 
typically original data explicitly relate types entities terms documents conceptions retrieval problem mention types terms describe searchers inter ests relevant documents returned 
represen tations chosen far handle time term clustering document clustering 
attempts put ignored entity back representation arbitrary fact 
exception pro koll terms documents represented space concepts see raghavan wong 
koll approach quite close spirit propose concept space low dimensionality underlying dimensions dimensions hand chosen truly orthogonal underlying axes factor analytic approaches approach differs previous attempts number ways clearer model described detail 
differences examine problems reasonable size document abstracts ooo index terms rich high dimensional representation dimen sions capture term document relations appears necessary success mathematical technique explicitly represents terms documents space retrieve documents query terms directly rotation interpretation underlying axes intermediate docu ment clusters 
koll begins set nonoverlapping spanning documents form axes space 
terms located axis document occur remainder doc uments processed sequentially placed average terms 
approach evaluated small dataset moderately successful 
journal american society information science september considered alternative models criteria adjustable representational richness 
represent underlying semantic structure need model sufficient power 
believe hierarchical clusterings restrictive allow multiple crossed classifications essentially parameters objects 
right kind alternative unknown looked models power varied compensation choosing inappropriate structure 
obvious class dimensional models multidimensional scaling factor analysis representational power controlled choosing number dimensions parameters object 
explicit representation terms documents 
desire represent terms documents simultaneously 
proximity latent structure paradigm retrieval proceeds appropriately placing new object corresponding query semantic structure finding documents close 
simple way achieve appropriate placement terms documents positions structure 
query placed centroid term points 
elegance retrieval mechanisms needed called mode proximity methods carroll arabie start rectangular matrix construct explicit representations row column objects 
method multidimensional unfolding coombs heiser carroll 
terms documents appear points single space similarity related monotonically euclidean distance 
mode factor analysis harshman harshman carroll chang kruskal terms documents represented points space similarity inner product points 
final candidate unfolding trees terms documents appear leaves tree path length distance tree give similarity 
version equivalent simultaneous hierarchical clustering terms objects 
explicit representation terms documents leads straightforward way add fold new terms documents original matrix 
new terms placed centroid documents appear similarly new documents placed centroid constituent terms 
important interesting issues raised considering addition new terms documents space 
addition new objects introduces temporal dependencies representation 
new term document gets placed depends terms documents space 
second general simply folding new terms documents result somewhat different space obtained objects included original analysis 
initial analysis time consuming clearly advantageous able add new objects folding 
done open research issue depend variability database time representativeness original documents terms 
computational large datasets 
existing models require computation goes number terms plus documents 
hoped docu ments sets thousands models efficient fitting techniques needed 
mode satisfied criteria mode factor analysis 
tree unfolding mode considered representationally restrictive nonmetric multidimensional unfolding computationally expensive 
mode factor analysis generalization familiar factor analytic mode singular value decomposition svd 
see forsythe malcolm moler chapter svd applications 
svd represents terms documents vectors space dimensionality dot product cosine points space gives similarity 
addition program available harshman fit model time order 
svd mode factor analysis overview latent semantic structure analysis starts ma trix terms documents 
matrix analyzed singular value decomposition svd derive par ticular latent semantic structure model 
singular value de composition closely related number mathematical statistical techniques wide variety fields including eigenvector decomposition spectral analysis factor analysis 
terminology factor analysis approach precedence information retrieval literature 
traditional mode factor analysis begins matrix associations pairs type ob ject documents borko 
matrix human judgments document document similarity measure term overlap com puted pair documents original term document matrix 
square symmetric matrix de composed process called eigen analysis product matrices special form containing eigenvectors eigenvalues 
special matrices show breakdown original data linearly inde pendent components factors general components small may ignored leading approximate model contains fewer factors 
original documents similarity behavior approximated values smaller number factors 
result represented geometrically spatial configuration dot product cosine tween vectors representing documents corresponds estimated similarity 
mode factor analysis begins square symmetric matrix relating pairs type entity arbitrary rectangular matrix different ties rows columns matrix terms documents 
rectangular matrix decomposed matrices special form time process called singular value decomposition svd 
resulting matrices contain singular vectors singular values mode case special matrices show breakdown original relationships linearly independent components factors 
components small may ig leading approximate model contains fewer dimensions 
reduced model term term document document term document similarities approximated values smaller number dimensions 
result represented cally spatial configuration dot product cosine vectors representing objects corre sponds estimated similarity 
information retrieval purposes svd viewed technique deriving set uncorrelated variables factors term document rep resented vector factor values 
note virtue dimension reduction possible documents somewhat different profiles term usage mapped vector factor values 
just property need accomplish improvement unreliable data proposed earlier 
svd repre sentation replacing individual terms derived factor values help solve fundamental problems described 
various problems approximated original term document matrix orthogonal factors derived dimensions 
roughly speaking factors may thought artificial concepts represent ex common meaning components different words documents 
term document characterized vector weights indicating strength association underlying concepts 
meaning particular term query document expressed factor values equivalently location vector space defined factors 
meaning representation economical sense original index terms replaced best surrogates approximated 
attempt interpret underlying factors rotate meaningful orientation 
aim able describe factors verbally merely able represent terms documents queries way escapes unreliability ambiguity redundancy individual terms descriptors 
possible reconstruct original term docu ment matrix factor weights reasonable perfect accuracy 
important method derived dimensional factor space reconstruct original term space perfectly believe nal term space unreliable 
want derived structure expresses reliable important underlying terms document referents 
journal american society information science september typical uses factor analysis necessarily interested reducing representation low dimensionality say factors interested able visualize space understand 
wish achieve sufficient power minimize degree space distorted 
believe representation tual space large document collection require handful underlying independent concepts number orthogonal factors needed fairly large 
model euclidean space best ful approximation 
reality conceptual relations terms documents certainly involve complex struc tures including example local hierarchies non linear interactions meanings 
complex relations approximately fit dimen sional representation increasing number dimen sions 
effect different parts space different parts language object domain 
reason avoid low extremely high numbers dimensions 
guided appears best 
mean works best customary fields duces greatest amount variance original ma trix give best retrieval effectiveness 
process query representation 
re call term document represented vector dimensional factor space 
query just docu ment initially appears set words 
represent query pseudo document weighted sum component term vectors 
note location document similarly described weighted sum constituent term vectors 
return set potential candidate documents pseudo document formed query compared documents highest cosines nearest vectors re turned 
generally threshold set closeness documents returned closest returned 
concerned issue cosine measure best indication similarity predict human relevance judgments systematically explored alternatives cf 
jones furnas 
table 
sample dataset consisting titles technical memoranda 
terms occurring title italicized 
classes documents human computer interaction graphs ml 
dataset described means term document matrix cell entry indicates frequency term occurs document 
titles cl ml terms technical memo example human machine lab abc computer applications survey user opinion computer response time eps user interface management system system human system engineering testing eps relation user perceived response time error measurement generation random binary unordered trees intersection graph paths trees graph minors iv widths trees quasi ordering graph minors survey cl human interface computer user system response time eps survey trees graph minors documents ml just dimensions 
shows dimensional geometric representation terms documents re svd analysis 
details mathematics underlying analysis sec tion 
numerical results svd example shown appendix verify place ment terms documents 
terms shown filled circles labeled accordingly document titles represented open squares numbers terms contained indicated 
term document described position dimensional factor space concrete example may procedure test set find documents relevant putative advantages clearer 
table gives sample data query human computer interaction simple term set 
case document set consisted titles matching techniques return documents cl bellcore technical memoranda 
words occurring share terms query 
title selected indexing documents relevant italicized 
note classes titles missed method terms human computer interaction labeled common query 
latent semantic structure graph theory labeled ml 
entries method uses derived factor representation process term document matrix simply frequencies query dimensions shown term occurred document 
query represented pseudo document matrix directly keyword re factor space 
query terms human initial input svd analysis 
computer factor space query placed example carefully chose documents terms centroid scaled comparison documents svd produce satisfactory solution point labeled represents query 
journal american society information science september plot terms dots example tree ml survey eps system dimension fig 
dimensional plot terms documents tm set 
terms represented filled circles 
documents shown open squares component terms indicated 
query human computer interaction represented pseudo document point 
axes scaled document document tern term comparisons 
dotted cone represents region points 
cosine query 
documents human computer near query cone graph theory documents ml arc nearby reduced space documents share terms query arc near 
simply look documents near query case documents cl ml nearby cosine indicated dashed lines 
notice documents share index terms query near representation 
relations documents ex pressed factor space depend complex indirect associations terms documents ones come analysis structure set rela tions term document matrix 
strength higher order structure term document matrix represent underlying meaning single term document query 
yields robust eco representation term overlap surface level clustering methods 
technical details singular value decomposition svd model 
section details mathematics underlying par ticular model latent structure singular value tion currently 
casual reader may wish skip section proceed section 
rectangular matrix example matrix terms documents decomposed product matrices orthonormal columns diagonal 
called singular value decomposition matrices left right singular vectors diagonal matrix singular values singular value decomposition svd unique certain row column sign permutation 
convention diagonal elements constructed positive ordered decreasing magnitude 
vd closely related standard eigenvalue eigenvector spectral decomposition square symmetric matrix wy orthonormal diagonal 
relation svd eigen analysis analogy 
fact matrix eigenvectors square symmetric matrix xx matrix eigenvectors cases matrix eigenvalues 
allowable permutations leave diagonal maintain correspondences da 
column may interchanged iff row andj interchanged columns da interchanged 
journal american society information science september presents schematic singular value de composition matrix terms documents 
general matrices full rank 
beauty svd allows simple strategy optimal approximate fit smaller matrices 
singular values ordered size largest may kept re smaller ones set zero 
product result ing matrices matrix approximately equal rank shown new matrix matrix rank closest squares sense zeros introduced representation simplified deleting zero rows columns obtain new diagonal ma trix deleting corresponding columns obtain respectively 
result reduced model rank model best possible squares fit reduced model approximate data 
amount dimension reduction choice critical 
ideally want value large fit real structure data small fit sampling error unimportant details 
proper way choices open issue factor analytic literature 
practice currently operational criterion value yields retrieval performance 
geometric interpretation svd model 
purposes intuition discussion useful interpret terms documents txd singular value decomposition term document matrix orthogonal unit length columns orthogonal unit length columns diagonal matrix singular values number rows number columns rank min svd geometrically 
rows reduced matrices singular vectors taken coordinates points repre senting documents terms dimensional space 
appropriate axes quantities related associated diagonal values dot products points space compare correspond ing objects 
section details comparisons 
computing fundamental comparison quantities svd model 
basically sorts comparisons interest comparing terms similar terms comparing docu ments similar documents comparing term document associated term document 
standard information retrieval approaches amount respectively comparing rows comparing columns examining individual cells original matrix term document data similar comparisons matrix presumed represent reliable patterns underlying data relevant quantities computed just smaller matrices comparing terms 
dot product row vectors reflects extent terms similar occurrence set docu ments 
matrix xx square symmetric matrix containing term term dot products 
diagonal orthonormal 
easy verify note means cell xx ob tained dot product rows mxm fig 

schematic singular value decomposition svd rectangular term document matrix 
original term document matrix decomposed matrices linearly independent components 
journal american society information science september matrix ts 
considers rows ts coordinates terms dot products points give comparison terms 
note relation coordinates ts coor simple diagonal positions points axes stretched shrunk proportion corresponding di element comparing documents 
analysis compar ing documents similar case dot product column vectors matrix tells extent documents similar profile terms 
matrix contains document document dot products 
definitions matrices guarantee cell obtained dot prod uct rows matrix ds 
consider rows ds matrix coordinates documents take dot products space 
note ds space just stretched version space 
comparing term document 
comparison different 
trying dot product rows columns fundamental comparison term document value individual cell 
defined terms matrices repeating cell obtained dot product ith row matrix ts row matrix ds 
note com term term document document involve rows ts ds coordinates comparision requires ts ds coordinates 
possible single configuration points space allow 
similar differing stretching shrinking axes factor 
finding representations pseudo documents 
previous results show possible compute com tht various objects associated rows columns important information retrieval applications compute appropriate comparison quantities objects appear original analysis 
example want able take com pletely novel query find point space look cosine respect terms documents space 
example trying fact find representations documents ap pear original analysis 
new objects documents matrices vectors terms 
reason call pseudo documents 
order compare query pseudo document documents need able start term vector derive representation just row comparison formulas preceding section 
criterion derivation putting real document xi give di model perfect 
constraint little shows ts note appropriate axes amounts placing pseudo document centroid corresponding term points 
just row appropriately scaled usual document factor vector making tween comparisons respectively 
preprocessing normalization 
equations take account preprocessing re weighting rows columns preprocess ing prevent documents different length having differential effect model impose certain preconceptions terms important 
effects certain transforma tions taken account straightforward way go algebra 
tests svd latent semantic indexing lsi method far tried lsi method standard document collections queries relevance ments available med cisi 
harshman program iterative numerical solution multi mode factor analysis prob lems studies reported 
pro grams standard svd available golub luk overton cullum lake 
documents consist full text title ab 
document indexed automatically terms occurring document list common words smart included analyses stem words map variants words root form 
analysis begins term document matrix cell indicates frequency term occurs document 
matrix analyzed singular value decomposition derive latent structure model indexing retrieval 
queries placed re space centroid constituent terms terms list occurring argued terms better far computational constraints limited terms 
terms occur document equally frequently documents little influence svd solution 
rejecting terms usually sufficient satisfy computational constraints 
addi tion wanted consistent smart possible indexing omission smart common words 
greater resources see reason omit terms latent structure analysis 
current limited computational resources terms omitted indexing retrieval purposes folding back concept space described briefly text 
journal american society information science september document 
cosines query vector document vectors straightforward compute see technical details section details documents ordered distance query 
senses current lsi method impoverished provides conservative test utility latent semantic structure indexing information retrieval 
far avoided adding refinements stem ming phrases term weighting boolean combinations generally result performance improve ments order better evaluate utility basic representation technique 
compare results latent structure indexing lsi method straightforward term matching method version smart data reported voorhees standard datasets 
term overlap comparisons provide baseline assess benefits indexing means latent semantic structure raw term matching 
term matching method term document matrix starting point lsi method 
query represented column cosines query column document column calculated 
smart voorhees systems representative state art information retrieval systems differ ences indexing term weighting query processing preclude precise comparisons lsi method systems 
comparisons interest 
smart evaluations documents indexed ing list common words full stemming raw term frequencies options 
queries similarly pro cessed vector sequential search match ing queries documents 
particular invocation smart term matching method initial choice index terms 
voorhees data obtained directly vector retrieval system extended boolean queries see voorhees details 
documents indexed removing words list mapping word variants term weighting terms 
weighted ex tended boolean queries retrieval 
performance evaluated measuring precision sev eral different levels recall 
done separately available query averaged queries 
lsi term matching smart runs full precision recall curves calculated 
voorhees data precision recall pairs available values obtained documents see figures 
values sequential search seq condition best perfor mance generally observed condition retrieval conditions document clusters 
med terms occurring document smart list common words resulted indexing terms 
additional characteristics dataset term lsi voorhees smart number unique terms mean number terms document mean number terms query mean number relevant documents query number unique terms terms document terms query vary somewhat different term processing algorithms different systems 
loo factor svd term document matrix obtained retrieval effectiveness evaluated queries available dataset 
shows precision function recall lsi loo factor solu tion lsi loo term matching term smart smart voorhees data vo set documents queries 
lowest levels recall 
lo preci sion lsi method lies obtained straightforward term matching smart vector method reported voorhees 
average difference precision lsi term matching method vs represents improvement raw term matching 
odds difference large larger chance 
lsi captures structure data ob raw term overlap 
lsi method compares favorably smart odds difference large larger chance voorhees system 
somewhat ing term matching smart methods differ data set 
differences lsi smart word stemming smart lsi smart includes word stems occurring document lsi computational reasons includes terms occurring document lead better performance smart 
difference performance lsi methods especially impressive higher recall levels precision ordinarily quite low repre senting large proportional improvements 
tively poor performance lsi method lowest levels recall traced factors 
precision quite systems low recall leaving little room improvement 
second latent semantic designed primarily handle synonymy problems improving recall successful dealing polysemy precision 
synonymy problem low recall word matches retrieve standard set tried med commonly studied collection medical abstracts 
consists value reported table voorhees article 
suspect error correct value may documents queries 
automatic indexing line measures mean number terms query 
journal american society information science september terms documents txd mri kxk reduced singular value decomposition term document matrix orthogonal unit length columns orthogonal unit length columns diagonal matrix singular values number rows number columns rank min chosen number dimensions reduced model tm rg 

schematic reduced singular value decomposition svd term document matrix 
original term document matrix ap largest singular values corresponding singular vectors 
relevant documents 
largest benefits lsi method observed high recall case 
point reported lsi results loo factor representation loo dimensional space 
raises important issue choosing dimension fig 

precision recall curves term matching loo factor lsi smart systems med dataset 
data term matching lsi smart methods obtained measuring precision levels recall approximately lo increments query separately averaging queries 
voorhees data points taken table article 
recall journal american society information science september ality 
ideally want dimensions capture real structure term document matrix may start modeling noise irrelevant detail data 
choose appropriate number dimensions open research issue 
tests guided operational criterion works best examine performance dif ferent numbers factors select dimensionality maximizes retrieval performance results med dataset shown presents av erage precision function number factors 
seen mean precision doubles number factors increases maximum 
loo factor space results report 
particular dataset performance improve bit solutions factors explored general case factors necessarily means better perfor mance 
small applications seen clearer maxima performance increases point decreases factors 
interpretation decrease extra parameters modeling sampling noise peculiarities sample important underlying relationships pattern term usage documents 
important quite easy svd solutions nested 
explore performance io dimensional solution example cosines calculated coordinates loo factor solution 
note previous attempts factor analytic tech niques information retrieval small numbers factors koll dimensions dimensions borko dimen sions 
show improvement perfor mance range suspect limited utility previous factor analytic approaches may result impoverished representation 
unfortunately med dataset specially constructed way may resulted unrealistically re sults 
determine test collection union returns set thorough keyword searches documents relevant queries set 
may segmented collection 
sets documents par ticular queries probably isolated abnormal extent multidimensional manifold concepts 
circumstance method excellent job defining isolated subdomains separating retrieval 
probably way natural document col structured 
worth noting automatic techniques applied dataset able capitalize abnormal struc tural property 
fact lsi greatly outperforms rest quite significant 
note keyword searches define document test set probably biases results favor methods surface term matching smart documents contain keywords included 
med precision function number factors number factors fig 

plot average precision averaged levels recall function number factors med dataset 
precision doubles number factors increased 
journal american society information science september cisi second test case cisi set information science abstracts 
set consistently difficult automatic retrieval methods 
consists doc uments queries 
automatic indexing ex words smart list common words words occurring document resulted index terms 
additional characteristics dataset term lsi voorhees smart number unique terms mean number terms document mean number terms query mean number relevant documents query loo factor svd solution obtained term document matrix evaluated queries available dataset 
lsi results loo factor solution lsi term matching term smart smart voorhees vo shown 
methods quite poorly dataset precision rising lowest levels recall 
average precision ll lsi term matching 
data set latent structure captured svd analysis useful raw term overlap capturing distinctions relevant irrelevant documents available queries 
voorhees data cover limited range low recall levels values precision similar lsi term matching 
smart hand results reliably better formance lsi absolute levels preci sion 
low 
odds differences large larger chance 
believe superiority smart lsi traced differences term selection tend improve performance 
noted previously smart stemmed words lsi smart included terms lsi included appearing document 
terms appear document excluded lsi queries omission words major determinant performance 
stemming appears source performance differences 
completed new lsi analysis smart index terms 
enabled explore difference smart original lsi due differences term selection see additional latent structure extracted 
analysis began term smart terms document matrix obtained loo factor svd lution 
test queries reevaluated new lsi solution refer lsi smart 
re cisi precision recall curves means queries lsi smart fig 

precision recall curves term matching loo factor lsi smart voorhees systems cisi dataset 
data term match ing lsi smart obtained measuring precision levels recall approximately increments query separately averaging queries 
voorhees data points taken table 
recall journal american society information science september performance indistinguishable smart average precision methods 
suggests initial difference lsi smart due term selection differences 
lsi unable improve term matching initial lsi vs term matching comparison lsi smart vs smart comparison 
stemming capture structure lsi un able capture evidenced superior performance smart relative term matching 
theory latent se mantic analyses extract ties usage stemmed forms 
practice may insufficient data 
problem evaluating cisi dataset low level precision 
intuition database con tains homogeneous distribution documents hard differentiate basis abstracts 
test queries natural lan guage vague poorly stated 
rele vance judgments may sufficiently reliable allow retrieval system perform provide ade comparison methods 
direct evidence reported reliability repeatability relevance judgments conjecture find cases relevance judgments appear obvious error 
addition poorly stated queries invite excessive reliance term overlap judging relevance especially judges familiar term matching possible retrieval strategy 
summary results lsi analyses results modestly encouraging 
show latent semantic indexing method superior simple term matching standard case equal 
databases performance lsi superior obtained system described voorhees performed better smart case equal term selection differences eliminated 
order assess value basic representational method far avoided addi tion refinements consider realistic application discriminative term weighting stem ming phrase finding method handling negation disjunction queries 
far tested method queries formulated re trieval methods method certainly bet ter queries appropriate format 
projects progress add standard enhancements incorporate fully automatic indexing re trieval system 
addition working methods incorporate low frequency highly infor words filtered trial analysis procedures 
improvements lsi offer effective retrieval method previously available 
discussion journal american society information science september factor analytic approaches previ ously suggested tried literature believe serious shortcomings attempt overcomes 
examined problems reasonable size document abstracts index terms rich high dimensional representation appears necessary success 
explicit representation terms documents space retrieving documents relevant user queries straightforward matter 
previous borko colleagues atherton borko borko similar name approach factor space document clustering docu ment retrieval computational simplifications reduced representational power 
borko example factor analysis performed term term correlation matrix calculated word usage abstracts orthogonal factors selected basis interpretability 
documents classi fied categories basis normalized factor loadings term perfor mance comparable automatic system 
noted information classification available dimensional factor space factor load ing significant terms factors value terms defining sample factors appendix 
addition borko addressed problem document classifi cation document retrieval 
example discussion full factor space just document clusters derived document retrieval 
koll concept information re trieval similar spirit latent semantic index ing 
terms documents represented single concept space basis statistical term occurrences 
axes defined set ping terms spanning documents terms placed appropriate axis 
new documents placed mean constituent terms new terms placed location document occurred 
system evaluated small database documents queries cir performance comparable sire boolean natural language queries 
experience med dataset suggests better performance obtained higher dimensional repre sentation 
addition latent semantic approach order dependent koll procedure mathe matically rigorous way uncovering truly orthogonal basis axes factors indexing 
representation documents lsi economical document term need represented order values 
explored degree accuracy needed numbers guess small integer probably suffice 
storage requirements large document collection reduced redundancy characterization documents terms removed representation 
offsetting storage advantage fact way documents retrieved ex comparison query vector stored document vectors 
search algorithms high dimen sional space efficient serial computers may detract desirability method large collections 
additional drawback involves ing 
initial svd analysis time consuming efficient method adding new terms documents 
suggest new documents located centroid terms appropriately scaled new terms placed centroid documents appear appropriately scaled 
updating done having perform new decomposition unknown 
lsi method deals nicely synonymy problem offers partial solution polysemy problem 
helps multiple meanings meaning word conditioned words document appropriate words query author particular relevant document 
failure comes fact term represented just point space 
word entirely different meaning bank represented weighted average differ ent meanings 
real meanings aver age meaning may create serious distortion 
classical term overlap methods meaning term union meanings probably leads outright distortion imprecision 
needed way detect fact particular term distinct meanings place points space 
satisfactory way see choueka lesk 
latent semantic indexing methods dis cussed particular singular value decomposition technique tested capable improving way deal problem multiple terms referring object 
replace individual terms descriptors documents independent artificial concepts specified terms documents combinations thereof 
way relevant documents contain terms query contained terms qualified terms query document properly character ized identified 
method yields retrieval scheme documents ordered continuously similarity query threshold set depending desires resources user service 
point development method regarded potential component retrieval system complete retrieval system 
component serve function served raw term vector ranking comparison methods 
putative advantages noise re duction described data compaction elimination redundancy 
applying method implementation issues arise raw vector methods particular questions term weight ing stemming phrasal entries similarity measure counterparts boolean operators 
unfortunately value retrieval enhancing procedures re evaluated lsi representation changes nature problems procedures intended deal 
example stemming done capture synonyms 
lsi deals problem extent additional value stemming open question 
likewise lsi averages mean ing polysemous words raw term matching main tains mappings result phrases disambiguation techniques may important 
appendix 
svd numerical example technical details section outlined details singular value decomposition svd model 
appendix presents numerical example sample term document matrix described overview sec tion shown table 
example term document matrix table 
recall rectangular matrix example matrix terms documents decomposed product matrices orthonormal columns di 
called singular value decomposition svd computing svd matrix results matrices rounded decimal places 
dimensional left singular vectors terms diagonal matrix singular values dimensional right singular vectors documents journal american society information science september reader verify small rounding errors orthogonal unit length columns th orthogonal unit length columns da approximate keeping sin values corresponding columns matrices 
note coordi position terms documents respectively dimensional representation fig ure 
reduced model multiplying matrices gives estimate things note matrix 
exactly match original term document matrix gets closer closer singular values kept 
want don want fect fit think vice versa 
acknowledgments colleagues involved various aspects project 
laura beck contributed extensively programming data collection analyses 
lynn streeter karen lochbaum bob allen steve hanson programs provided useful feedback 
mike lesk ad vice comments previous drafts article ram john john tukey consultation statistical questions 
journal american society information science september 

machine readable dictionaries 
annual review information science technology 
atherton borko 

test factor analytically derived automated classification methods 
aip rept 
aip drp 
baker 

information retrieval latent class analysis 
journal acm 
bates 

subject access online catalogs design model 
jasis 
borko 

automatic document classification 
journal acm 
carroll arabie 

multidimensional scaling 
porter ed 
annual review psychology 
carroll chang 

analysis individual differences multidimensional scaling way generalization eckart young decomposition 
psychometrika 

choueka 

disambiguation short contexts 
computers humanities 
coombs 

theory data 
new york wiley 
cullum lake 

lanczos algorithm computing singular values vectors large matrices 
siam sci 
stat 
comput 
carroll 

way metric unfolding alternating weighted squares 
psychometrika 
fidel 

individual variability online searching behavior 
ed 
asis proceedings asis th annual meeting vol 

forsythe malcolm moler 

computer methods mathematical computations chapter squares singular value decomposition 
englewood cliffs nj prentice hall 
cl 

objects features metric representation class data 
ph dissertation 
stanford university 


experience au adaptive indexing scheme 
human factors computers systems chl proceedings 
landauer gomez dumais 

vocabulary problem human system communications 
communications acm 
luk overton 

block lanczos method computing singular values corresponding singular vectors matrix 
acm transactions mathematical software 
gomez lochbaum landauer 
press 
right words finding want function indexing vocabulary 
jasis press 
harshman 

foundations procedure models conditions explanatory multi modal factor analysis 
working phonetics 
harshman 

model way factor analysis multi dimensional scaling 
law snyder jr mcdonald 
research methods data analysis 
new york praeger 
harshman 

data preprocessing extended model 
law snyder jr mcdonald eds 
research methods data analysis 
new york praeger 
heiser 

unfolding analysis proximity data 
leiden netherlands psychologie 
jardin van rijsbergen 

hierarchic clustering information retrieval 
information storage retrieval 
jones 

pictures relevance 
jasis 
koll 

approach concept information retrieval 
acm sigir forum 
kruskal 

factor analysis principal components bilinear methods 
kruskal eds 
international statistics new york free press 
lesk 

tell pine cone ice cream cone 
proceedings acm conference 


evaluation subject catalog 
american tation 


classification space multivariate procedure automatic document indexing retrieval 
multivariate behavior re search 
raghavan wong 

critical analysis vector space model information retrieval 
jasis 
salton 

automatic information organization retrieval 
new york mcgraw hill 
salton mcgill 

modern information retrieval 
new york mcgraw hill 
sparck jones 

automatic keyword classification informa tion retrieval 
london 
sparck jones 

statistical interpretation term specificity applications retrieval 
journal documentation 
tarr borko 

factors influencing inter indexer consis tency 
proceedings asis th annual meeting vol 
ii 
van rijsbergen 

theoretical basis occurrence data information retrieval 
journal documentation 
voorhees 

cluster hypothesis revisited 
proceedings sigir 
journal american society information science september 
