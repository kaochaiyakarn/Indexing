ieee transactions knowledge data engineering vol 
may june clustering data streams theory practice sudipto guha adam meyerson nina mishra rajeev motwani member ieee callaghan data stream model attracted attention applicability numerous types data including telephone records web documents 
analysis data ability process data single pass small number passes little memory crucial 
describe streaming algorithm effectively clusters large data streams 
provide empirical evidence algorithm performance synthetic real data streams 
index terms clustering data streams approximation algorithms 
stream ordered sequence points xn accessed order read small number times 
reading sequence called linear scan pass 
stream model motivated emerging applications involving massive data sets example customer click streams telephone records large sets web pages multimedia data financial transactions observational science data better modeled data streams 
data sets far large fit main memory typically stored secondary storage devices 
linear scans cost effective access method random access prohibitively expensive 
data sets router packet statistics meteorological data sensor network data transient need realized disk data processed produced discarded favor summaries possible 
size data sets far exceeds amount space main memory available algorithm possible data stream algorithm remember data scanned past 
scarcity space necessitates design novel kind algorithm stores summary past data leaving memory processing data 
scan large set slow device expensive criteria performance data stream algorithm judged include number linear scans addition usual ones running time memory usage 
case transient streams data streams stored disk scan possible 
guha department computer science university pennsylvania rd st philadelphia pa 
email sudipto cis upenn edu 
meyerson department computer science carnegie mellon university forbes ave pittsburgh pa 
mishra hewlett packard laboratories page mill rd ms palo alto ca 
email hpl hp com 
motwani callaghan department computer science stanford university stanford ca 
email rajeev loc cs stanford edu 
manuscript received sept revised nov accepted dec information obtaining reprints article please send mail tkde computer org ieeecs log number 
ieee published ieee computer society data stream online incremental models similar require decisions data available 
models identical 
online algorithm access data points previous decisions reacting th point amount memory available data stream algorithm bounded function usually sublinear function input size 
furthermore online algorithm data stream algorithm may required take irrevocable action arrival point may allowed take action group points arrives 
models similar particular sublinear space online algorithm data stream algorithm 
definition streaming model inclusive multiple passes characterized form henzinger works munro patterson flajolet martin definition 
interest model started results alon proved upper lower bounds memory requirements pass algorithms computing statistics data streams :10.1.1.102.5483
clustering useful ubiquitous tool data analysis broad strokes problem finding partition data set definition similarity similar items part partition different items different parts 
particular definition clustering focus median objective identifying centers sum distances point nearest center minimized 
study median problem stream context provide streaming algorithm theoretical performance guarantees 
giving algorithm requires small space address issue clustering pass 
give simple algorithm divide conquer achieves constant factor approximation small space 
elements algorithm analysis form basis constant factor algorithm subsequently 
algorithm runs time uses memory single pass data 
randomization show reduce ieee transactions knowledge data engineering vol 
may june running time nk requiring single pass 
provide new clustering algorithm streaming method 
algorithm facility location algorithm defined section produce centers 
show facility location algorithm modified produce exactly clusters solve median problem 
running time resulting algorithm expensive points offer innovative techniques speed algorithm 
give sound way quickly initializing facility location algorithm reasonably set centers 
show assumptions restrict choice potential centers find clustering 
performed extensive series experiments comparing enhanced facility location algorithm commonly means algorithm 
results uncover interesting trade cluster quality running time 
facility location algorithm produces solutions near optimum quality smaller variance multiple runs compared means produced solutions inferior quality higher variance multiple runs 
algorithm took time find better answers 
experiments real data stream technique clustering quality comparable clustering quality running algorithm data 
compared streaming algorithm birch similar trade cluster quality running time 
retain tiny fraction amount information birch retains algorithms took somewhat longer run produced solutions higher quality 
related streaming algorithms rich body fundamental research emerged data stream model computation 
problems solved small space data stream include frequency estimation norm estimation order statistics synopsis structures time indexed data signal reconstructions :10.1.1.130.3576:10.1.1.102.5483:10.1.1.126.5994:10.1.1.24.7941:10.1.1.24.7136
theoretical analysis clustering natural clustering objective functions optimization problems turn np hard 
theoretical design approximation algorithms algorithms guarantee solution objective function value fixed factor value optimal solution 
center median problems studied clustering problems problems solution simply consists members data set desired number clusters input 

notation nk notation hides polylogarithmic terms opposed constants 
example log 
members chosen cluster centers data point assumed assigned cluster center nearest assignment distance distance nearest center 
purpose solution clustering problem exactly centers 
center objective function minimize largest assignment distance median sum assignment distances minimized 
center measure sensitive outliers 
median objective sensitive noise 
facility location problem lagrangian relaxation median problem number centers unrestricted additional cost center included solution 
abundant literature books provable algorithms running time provable clustering heuristics special metric spaces :10.1.1.129.4996:10.1.1.126.7278
median problem relevant context known em means heuristics 
em expectation maximization iteratively refines clustering trying maximize probability current clustering corresponds model 
clusters modeled gaussian spheres enforcing partition heuristic means 
means centers chosen initially iteration center replaced geometric mean cluster corresponding 
median objective function defined real spaces assignment costs distances replaced squares 
charikar gave constant factor single pass center algorithm nk log time space :10.1.1.40.3366
median give constant factor single pass approximation time nk sublinear space constant 
notice single pass data points labeled clusters belong 
algorithms output cluster centers 
involved definitions clustering graph theoretic notions exist cliques cuts conductance 
consider clustering defined projections subspaces 
existing large scale clustering algorithms clustering studied applied literature means exhaustive study related 
means widely heuristic mean cluster defined alternate medoid algorithms developed 
example medoids selects initial centers repeatedly replaces existing center random chosen point doing improves sum squared assignment distances 
clara proposed sampling reduce number exchanges considered choosing new medoid remaining points time consuming clarans draws fresh sample feasible centers calculation improvement :10.1.1.13.4395
see slightly differing 
section see scheme step preserve number medoids eventually guarantee final solution close best possible 
guha clustering data streams theory practice sampling approach 
medoid approaches including pam clara clarans known scalable inappropriate stream analysis 
partitioning methods include bradley subsequent improvement repeatedly takes weighted centers initially chosen randomly weight data fit main memory computes clustering :10.1.1.157.392
new centers obtained weighted number points assigned data memory discarded process repeats remaining data 
key difference approach algorithm places higher significance points data set assumptions 
approaches known outperform popular birch algorithm 
hierarchical clustering sequence nested partitions 
agglomerative algorithm hierarchical clustering starts placing input data point cluster repeatedly merges closest pair clusters number clusters reduces hierarchical agglomerative clustering hac heuristics exist 
celebrated heuristic distance clusters defined closest pair points 
hierarchical technique cure represents cluster multiple points initially scattered cluster shrunk cluster center certain fraction 
depending values cure parameters algorithm fall spectrum hac medoid 
hac cure designed discover clusters arbitrary shape necessarily optimize median objective 
hierarchical algorithms including birch known suffer problem hierarchical merge split operations irrevocable :10.1.1.152.7115
stream clustering algorithm somewhat similar cure 
algorithm constructs hierarchical clustering 
consider dendogram algorithm operates time layers tree maintains front 
algorithm similar cure apply partitioning approach cluster data bottom cure geared robustness clustering arbitrary shapes algorithm designed produce provably clustering 
known approaches dbscan optics sting clique wave cluster designed optimize median objective :10.1.1.131.5152:10.1.1.121.9220:10.1.1.106.7154
stream clustering framework clustering small space data stream algorithms large space requirements goal show clustering carried small space data points concerned number passes 
subsequently develop pass algorithm 
investigate algorithms examine data piecemeal fashion 
particular study performance divide conquer algorithm called small space divides data pieces clusters pieces clusters centers obtained center weighted number points assigned 
show piecemeal approach constant factor approximation algorithm running divide conquer fashion yield slightly worse constant factor approximation 
propose algorithm smaller space similar piecemeal approach reclustering repeatedly weighted centers 
algorithm prove constant number times constant factor approximation obtained expected constant factor worsens successive reclustering 
simple divide conquer separability theorems simplicity start version algorithm 
algorithm small space 
divide disjoint pieces 
find centers assign point 
closest center 
lk centers obtained center weighted number points assigned 

cluster find centers 
interested clustering small spaces set fit main memory 
large may exist address issue 
definition median problem 
instance median integer set points metric median cost simply cost ofa set medians ck ck min ci cost solution sum assignment distances 
define cost smallest possible cost medians required belong set optimization problem find cost discrete case cost euclidean case 
analyzing algorithm small space describe relationship discrete continuous clustering problem 
folklore proof :10.1.1.32.1927
theorem 
instance median cost cost separability theorem sets stage divide conquer algorithm 
theorem carries clustering metrics sum squared distances 

factor familiar case ieee transactions knowledge data engineering vol 
may june theorem 
consider arbitrary partition set points 
cost cost 
proof 
theorem cost cost 
summing result follows 
tu show new instance points median shift weight point weighted lk centers step algorithm small space feasible clustering solution 
assigning point weight median distance cost wd assignment distances multiplied weights objective function 
notice set points new instance smaller may contain optimum medians theorem 
cost cost cost exists solution cost new weighted instance proof 
ci ci medians achieve minimum cost 
medians achieve minimum cost denote closest ci ci denote closest wi number members ci wi weight ci 
ci member distance min ci triangle inequality 
ci wi min ci cost theorem solution cost 
tu show run bicriteria approximation algorithm ak medians output cost times optimum median solution step algorithm small space run approximation algorithm step resulting approximation small space suitably bounded 
note theorems apply ak medians constant theorem 
algorithm small space approximation factor 
proof 
optimal median solution cost theorem implies sum costs optimal solutions instances 
factor case data points medians 
factor case data points medians 
approximation factor points fall medians placed approximate solution cost solution stage bc theorem new instance admit solution cost approximation algorithm guaranteed find solution cost 
sum bounds gives bound cost final medians theorem follows 
tu black box nature algorithm allows devise divide conquer algorithms 
divide conquer strategy generalize small space algorithm recursively calls successively smaller set weighted centers 
algorithm smaller space 
halt 

divide disjoint pieces 
lg find centers 
assign point closest center 
lk centers obtained center weighted number points assigned 

call algorithm smaller space 
claim theorem 
constant algorithm smaller space gives constant factor approximation median problem 
proof 
assume approximation factor jth level aj 
theorem know cost solution level times optimal 
theorem get approximation factor aj satisfy simple recurrence aj aj solution recurrence constant 
tu intermediate medians stored memory number subsets partition limited 
particular lk partition resident 
may exist 
section see way get problem 
implement hierarchical scheme cleverly obtain clustering algorithm streaming model 
clustering data stream model data stream model computation takes place bounded space data accessed linear scans data point seen scan points viewed order 
section modify multilevel algorithm operate data streams 
pass approximation model assuming bounded memory small specifically denotes size stream 
maintain forest assignments 
complete trees nodes tree assigned median denoted root tree 
guha clustering data streams theory practice show solve problem storing intermediate medians 
inspect space requirements running time 
data stream algorithm 
modify multilevel algorithm slightly 
input points algorithm reduce say points 
usual weight intermediate median number points assigned clustering 
assume multiple 
requires space primal dual algorithm 
see mk space algorithm 

repeat till seen original data points 
point intermediate medians 

cluster level medians medians proceed 

general maintain level medians seeing generate level medians weight new median sum weights intermediate medians assigned 

seeing original data points clustering points seen far cluster intermediate medians final medians 
note algorithm identical multilevel algorithm described 
number levels required algorithm log log 
constant approximation 
memory size ignoring factors due maintaining intermediate medians different levels 
argued number levels constant 
linear space clustering approximation quality prove intuitively actual quality clustering obtained instance depend heavily number levels 
perspective profitable algorithm 
local search algorithm provide approximation space linear number points clustered time 
advantage algorithm maintains assignment uses linear space 
complication algorithm achieve bounded approximation need set cost median penalize medians 
algorithm solves facility location problem setting cost median 
done guessing cost powers choosing best solution medians 
step get medians step process reduce number medians reduce allows cluster points time provided running time running time clustering dominated contribution level :10.1.1.129.4996
local search algorithm quadratic total running time argued small approximation quality prove remain small 
theorem follows theorem 
solve median problem data stream time space factor clustering data streams nk time achieve scalability nk algorithm algorithm super linear recall algorithm developed far 
applying alternate implementation multilevel algorithm 
clustering assuming constant points storing medians compress description data points 
local search algorithm 
keep repeating procedure till see descriptors intermediate medians compress 
required output clustering compress intermediate medians levels get penultimate medians cluster exactly primal dual algorithm :10.1.1.129.4996
subquadratic time clustering 
results metric space algorithms subquadratic 
algorithm defined consist passes constant probability success 
high probability results algorithm log passes 
stated algorithm original data points unweighted 
consider algorithm 
draw sample size nk 

find medians points primal dual algorithm :10.1.1.129.4996

assign original points closest median 

collect points largest assignment distance 

find medians points 

point medians 
theorem 
algorithm gives approximation medians constant probability 
algorithm provides constant factor approximation median problem medians constant probability 
repeat experiment log times high probability 
run algorithm substep algorithm 
algorithm requires nk time space 
algorithm local search trade results reduces space requirement nk 
alternate sampling results exist median measure extend weighted case sample sizes depend diameter space 
extension weighted case 
need algorithm weighted input 
necessary ieee transactions knowledge data engineering vol 
may june draw random sample weights points medians respect sample convey information 
simple idea sampling points respect weights help 
step may eliminate points 
suggest scaling round weights nearest power 
group ignore weight lose factor 
nk algorithm summing groups running time nk 
correct way implement compute exponent values weights groups exist running time depend largest weight 
full algorithm sampling scheme develop nk time algorithm requires space 
input points randomized algorithm cluster intermediate median points 
local search algorithm cluster intermediate medians level medians level 
primal dual algorithm cluster final medians medians :10.1.1.129.4996
notice algorithm remains pass log iterations randomized just add running time 
phase contribution running time nk 
level nk points cluster time time total time second phase nk 
contribution rest levels decreases geometrically running time nk 
shown previous sections number levels algorithm logm constant factor approximation small see theorem 
theorem 
median problem constant factor approximation algorithm running time nk log pass data set memory small lower bounds section explore algorithms speeded randomization needed 
note clustering algorithm requires time nk natural question done better 
ll show couldn done better deterministic lower bound median nk 
modulo randomization time bounds pretty match lower bound 
show way get rid randomization yields single pass small memory median algorithm poly log approximation 
deterministic algorithm loss clustering quality 
show constant factor deterministic approximation algorithm requires nk time 
measure running time number times algorithm queries distance function 
consider restricted family sets points exists clustering property distance pair points cluster distance pair points different clusters 
optimum clustering value value distance points nearest centers algorithm doesn discover optimum clustering find constant factor approximation 
note problem equivalent graph partition problem graph complete partite graph find partition vertices independent sets 
equivalence easily realized follows set sng clustered naturally translates set vng edge vi vj iff dist si sj 
observe constant factor clustering computed queries distance function iff graph partition computed queries adjacency matrix kavraki show deterministic algorithm finds graph partition requires nk queries adjacency matrix result establishes deterministic lower bound median 
theorem 
deterministic median algorithm nk queries distance function achieve approximation 
note theorem applies deterministic case 
lower bound applies randomized algorithms proven 
proofs yao minmax principle construct distribution best deterministic algorithm takes nk time 
proven 
theorem 
median algorithm nk queries distance function achieve constant factor approximation 
framework retrospect important aspect previous sections framework emerges sequence algorithms 
choose linear time algorithm performs static data 
repeatedly compose favored algorithm layers subsequent layer inputs weighted cluster centers previous layer outputs clusters 
final layer ensures clusters remain 
essence prove theoretically algorithm performs static chunks data operate stream preserving reasonable performance guarantees 
chose algorithms proven bounds help quantify notion preserving performance guarantees underlying intuition carries linear time clustering algorithm suitable domains 
issue facility location median section consider interesting issue clustering parameter number clusters 
guha clustering data streams theory practice parameter required define suitable optimization objective frequently denote upper bound number possible clusters user wishes consider 
parameter target need held fixed intermediate stages algorithm 
fact flexibility reduce quadratic running time local search algorithm second step algorithm section 
local search algorithm devise settle number centers larger reduce number centers exactly required 
notion ability relax parameter intermediate steps algorithm provide interesting contrast means defined commonly relax number clusters 
fact believe issues stability means algorithms related fact discuss experimental evaluation section 
lsearch algorithm section speed local search relaxing number clusters intermediate steps achieve exactly clusters final step 
medians intermediate steps best solution medians expensive best median solution interested guarantees 
time want save space 
flexibility develop new local search algorithm 
definition facility location problem 
set data points metric space distance function parameter choice fc cluster centers define partition clusters nk ni contains points closer ci center 
goal select value set centers minimize facility clustering fc cost function fc xk ci ni start initial solution refine making local improvements 
section refer cost set medians mean facility location definition 
significant difference means iterative heuristic trying preserve clustering exactly medians representation points extra points twice able provide provable guarantees 
mentioned lagrangian relaxation techniques provide powerful tool combinatorial optimization problems facility location minimization lagrangian relaxation problem 
facility location describing simple algorithm charikar guha referred cg solving facility location problem set points metric space metric relaxed metric facility cost assume feasible solution facility location set currently open facilities assignment point necessarily closest open facility 
define gain cost save expend open facility exist perform possible advantageous facility subject constraints points reassigned second facility closed members reassigned gain easily computed time 
algorithm cg data set facility cost 
obtain initial solution facilities assignment function gives approximation facility location facility cost 
repeat log times randomly order random order calculate gain gain add facility perform allowed closures 
denote cost optimal median solution 
setting gives approximation medians 
course infeasible know suggests try possible minfd jd value left denotes smallest nonzero solution possible lower bound value right indicates feasible solution arbitrary point chosen median serves upper bound arguments carry relaxed metric 
see details 
new algorithm algorithm directly solve median subroutine median algorithm follows set initial range facility cost easy calculate upper bound perform binary search range find value gives desired number facilities value try call algorithm cg get solution 
binary search 
questions spring mind binary search technique second algorithm sufficiently fast accurate 
notice get approximation medians just find optimum value set know try find binary search binary search search parameter calls cg algorithm repeatedly setting checks solution contains exactly medians range values small 
cg algorithm running time log expensive large data streams 
describe new local search algorithm relies correctness algorithm avoids quadratic running time advantage structure local search 
ieee transactions knowledge data engineering vol 
may june finding initial solution iteration step expect total solution cost decrease constant fraction way best achievable cost initial solution constant factor approximation approximation charikar guha provably reduce number iterations log 
algorithm initial solution algorithm data set facility cost 
reorder data points randomly 

create cluster center point 

point distance current point nearest existing cluster center 
probability create new cluster center current point add current point best current cluster 
algorithm runs time proportional times number facilities opens obtains expected approximation optimum 
sampling obtain feasible centers theorem motivate new way looking local search 
stated proven terms actual median problem holds slightly different constants minimization measures ssq sum squares distances median 
assume points ck constitute optimal solution median problem data set ci set points assigned ci ri average distance point ci ci assume jnj constant set log points drawn independently uniformly random theorem 
constant high probability optimum median solution medians constrained cost times cost optimum unconstrained median solution medians arbitrary points 
proof 
log cij mp chernoff bounds 
prf js cij mp cij mp probability point distance ri optimum center ci mp log markov inequality 
prf cj ci rig cluster ci sample contains point xi ri ci cost median times cost optimal median solution triangle inequality assignment distance triple 
tu sense assuming smallest cluster small 
example smallest cluster contains just point jnj clearly point overlooked feasible center 
view small subset points outliers clusters 
assume outliers removed 
evaluating gain point evaluate randomly chosen set log points choose medians finish computation sooner 
complete algorithm full algorithm modification speeds binary search 
observation cost changes little iteration far centers gotten value incorrect 
give facility location subroutine median algorithm call take parameter controls convergence 
parameters data set size metric relaxed metric facility cost initial solution set facilities 
assignment function 
algorithm fl 
current solution 

cost current solution consider feasible centers random order feasible center perform advantageous closures gain description obtain new solution assign point closest center 
cost new solution return step 
give median algorithm data set distance function algorithm lsearch 
zmin 
zmax 
arbitrary point 
zmax zmin 


randomly pick log points feasible medians 

medians zmin zmax current solution 
run fl obtain new solution 
jf exit loop 
zmax zmin zmax zmin 
return solution 

simulate continuous space move cluster center mass cluster 
guha clustering data streams theory practice initial value zmax chosen trivial upper bound sum assignment costs value trying find 
running time lsearch nm nk log number facilities opened 
depends data set usually small leads significant improvement previous algorithms 
empirical evaluations empirical evaluation results experiments comparing performance means lsearch 
conducted experiments sun ultra mhz processors mb ram gb swap space running sunos 
detailed description conference version highlights :10.1.1.142.777
experiments compare ssq measure sum squares distances medians 
algorithms compare measure 
mentioned proof algorithms carry setting weaker theoretical guarantees relaxed triangle inequality setting 
small low dimensional data sets 
generated small data sets containing points dimension ran lsearch means 
consists uniform density radius spheres real vectors percent random noise uniform space 
generated grid data sets spheres centered regular nearly regular intervals shifted center data sets spheres centered positions slightly shifted grid data sets random center data sets 
means lsearch randomized ran algorithm times data set recording mean variance ssq 
small data sets stored minimum ssq achieved data set value upper bound best achievable ssq data set 
figs 
show means lsearch ssq values grid shifted center data sets normalized best known ssq set 
error bars represent normalized standard deviations ssq 
figs 
data set order centers clusters ith grid data set generated centers ith shifted center set shifted center independently shifted small distance position corresponding grid center 
slight asymmetry difference distributions ith grid shifted center data sets results graphs suggest asymmetry accounts greater disparity means lsearch performance shifted center sets 
shifted center random center data sets exhibit 
processes processor went swap 

square distances satisfies relaxed triangle inequality 
particular step follows noting ab fig 

examples means lsearch solutions 
worst means lsearch solutions data set 
best worst means solutions data set 
best worst lsearch solutions data set symmetry grid data sets 
gap means lsearch performance increase increasing data asymmetry 
fig 
shows means lsearch ssq values random center sets normalized best known 
ieee transactions knowledge data engineering vol 
may june fig 

means versus lsearch small synthetic data sets ssq 
grid data sets 
shifted center data sets 
random center data sets 
lsearch performed consistently low variance ssq synthetic data sets 
fig 
shows dimensional random center data set represented histogram horizontal axis gives coordinates data points height bar number points data set fell range covered width bar 
peaks correspond high density regions clusters remaining area corresponds low level uniform noise 
ovals show coordinates highest cost medians means data set recall algorithms run times plus signs give locations highest cost medians lsearch 
fig 
shows best medians represented worst medians diamonds means twodimensional data set 
fig 
shows lowest cost medians rectangles highest cost medians plus signs lsearch data set 
examples illustrate general theme lsearch consistently medians worst run means missed clusters clusters noise assigned median cluster 
larger low dimensional data set 
ran algorithms data set distributed authors birch consists dimensional gaussians grid points 
means ran average standard deviation 
lsearch ran average standard deviation 
average ssq means solutions standard deviation lsearch ssq standard deviation 
small high dimensional data sets 
ran means lsearch dimensional data sets 
points consist uniform density randomly centered dimensional hypercubes edge length percent noise 
data sets answer means average times average cost answer lsearch close best known ssq 
hand means ran times faster 
see :10.1.1.142.777
summary 
standard deviations means costs typically orders magnitude larger lsearch higher relative best known cost low dimensional data set experiments 
increased unpredictability may indicate means sensitive lsearch dimensionality 
terms running time lsearch consistently slower running time low variance 
lsearch appears run approximately times long means 
count amount time takes algorithm find answer lsearch competitive running time excels solution quality 
results characterize differences lsearch means 
algorithms decisions local information lsearch uses global information 
allows trade medians median different location tend get stuck local minima plague means 
clustering streams top versus bottom stream means 
theorem guarantees performance stream bounded constant factor approximation algorithm run steps guha clustering data streams theory practice fig 

birch versus stream synthetic data 
birch versus stream ssq 
birch versus stream cpu time 
stream 
despite fact means guarantees due popularity experimented running means clustering algorithm steps 
experiments compare performance stream lsearch stream means birch 
birch compresses large data set smaller clustering feature tree 
leaf tree captures sufficient statistics second moments subset points 
internal nodes capture sufficient statistics leaves 
algorithm computing tree repeatedly inserts points leaves provided radius set points associated leaf exceed certain threshold 
threshold exceeded new leaf created tree appropriately balanced 
tree fit main memory new threshold create smaller tree 
birch details decision making process 
stream birch common method attack repeated data 
stream bottom substep clustering process birch top partitioning 
put results equal footing gave algorithms amount space retaining information stream 
results compare ssq running time 
synthetic data stream 
generated stream approximately mb size consisting points dimensional euclidean space 
stream generated similarly high dimensional synthetic data sets cluster diameters varied factor number points factor 
divided point set consecutive chunks size mb calculated upper bound ssq previous experiments finding ssq centers generate set 
ran experiments prefixes induced segmentation chunks prefix consisting chunk chunks chunks entire stream 
ran lsearch means times data set cf tree tested 
birch hac deterministic repetition necessary generated cf trees ran hac 
choices depending clustering algorithm method shown fig 

performance algorithm linear error running time expected 
summary ssq achieved stream times better achieved implementation birch clustering algorithm 
possible reason birch cf trees usually point high weight points small weight incorrectly summarizing stream 
stream ran times slower corresponding implementation birch 
birch top partitioning stream uses slower bottom step 
results demonstrate effect accurate decisions stream regarding storing summary statistics 
stream lsearch gave nearly optimal quality 
result unsurprising empirical performance lsearch discussed previous section 
bottom approach stream introduces little extra error process combination finds near optimal solution 
network intrusions 
clustering particular algorithms minimize ssq popular techniques detecting intrusions 
detecting intrusions moment happen essential protecting network attack intrusions particularly fitting application streaming 
offline algorithms simply offer immediacy required successful network protection 
experiments kdd cup intrusion detection data set consists weeks worth raw tcp dump data local area network simulating true air force environment occasional attacks 
features collected connection include duration connection number bytes transmitted source destination vice versa number 
kdd ics uci edu databases kddcup kddcup html 
ieee transactions knowledge data engineering vol 
may june fig 

network intrusion data birch versus stream 
failed login attempts 
continuous attributes total available attributes selected clustering 
outlier point removed 
data set treated stream mbyte sized chunks 
data clustered clusters point represented types possible attacks normal behavior 
attacks included denial service unauthorized access remote machine password guessing unauthorized access root probing port scanning 
top chart fig 
compares ssq birch ls middle chart comparison birch means stream means 
birch performance seventh ninth chunks explained number leaves birch appears third chart 
stream birch amount memory birch fully take advantage 
birch leaves respectively allowed leaves respectively 
believe source problem lies birch global decision increase radius points allowed leaf size exceeds constraints 
data sets birch decision increase radius probably certainly reduces size tree 
global decision fuse points separate clusters cf leaf 
running clustering algorithm fused leaves yield poor clustering quality effects dramatic 
terms cumulative average running time shown fig 
birch faster 
stream ls varies running time due creation weighted data set step 
results point trade cluster quality running time 
applications speed essence clustering web search results birch appears reasonable quick dirty job 
applications intrusion detection target marketing mistakes costly stream algorithm exhibits superior ssq performance 
acknowledgments authors grateful moses charikar umesh dayal aris gionis hsu piotr indyk andy dan bin zhang support 
done guha student stanford university supported ibm research fellowship national science foundation iis 
done meyerson department computer science stanford university palo alto research supported aro daag 
mishra research supported part national science foundation eia 
motwani research supported national science foundation iis 
callaghan research supported part national science foundation graduate fellowship national science foundation iis 
achlioptas mcsherry fast computation low rank approximations proc 
ann 
acm symp 
theory computing pp 

agarwal procopiuc approximation algorithms projective clustering proc 
acm symp 
discrete algorithms pp 

agrawal gehrke gunopulos raghavan automatic subspace clustering high dimensional data data mining applications proc :10.1.1.131.5152
sigmod 
alon matias szegedy space complexity approximating frequency moments proc :10.1.1.102.5483
ann 
acm symp 
theory computing pp 

ankerst breunig kriegel sander optics ordering points identify clustering structure proc 
sigmod 
guha clustering data streams theory practice arora raghavan rao approximation schemes euclidean medians related problems proc 
ann 
acm symp 
theory computing pp 

arya garg pandit local search heuristic median facility location problems proc :10.1.1.126.7278
ann 
acm symp 
theory computing pp 

babcock datar motwani sampling moving window streaming data proc :10.1.1.24.7136
acm symp 
discrete algorithms 
bartal charikar raz approximating min sum clustering metric spaces proc 
ann 
acm symp 
theory computing 
borodin ostrovsky rabani subquadratic approximation algorithms clustering problems high dimensional spaces proc 
ann 
acm symp 
theory computing 
bradley fayyad reina scaling clustering algorithms large databases proc :10.1.1.157.392
acm sigkdd int conf 
knowledge discovery data mining pp 

charikar chaudhuri motwani narasayya estimation error guarantees distinct values proc 
th acm sigmod sigact sigart symp 
principles database systems pods pp 

charikar chekuri feder motwani incremental clustering dynamic information retrieval proc :10.1.1.40.3366
ann 
acm symp 
theory computing pp 

charikar guha improved combinatorial algorithms facility location median problems proc 
acm symp 
foundations computer science pp 

charikar guha tardos shmoys constant factor approximation algorithm median problem proc 
ann 
acm symp 
theory computing 
improved approximation algorithms uncapacitated facility location proc 
conf 
integer programming combinatorial optimization pp 

datar gionis indyk motwani maintaining stream statistics sliding windows proc :10.1.1.24.7941
acm symp 
discrete algorithms 
drineas kannan frieze vinay clustering large graphs matrices proc 
acm symp 
discrete algorithms 
ester kriegel sander xu density algorithm discovering clusters large spatial databases proc :10.1.1.121.9220
acm sigkdd int conf 
knowledge discovery data mining pp 

lewis elkan true scalability clustering algorithms sigkdd explorations 
feder greene optimal algorithms appropriate clustering proc 
ann 
acm symp 
theory computing pp 

feigenbaum kannan strauss viswanathan approximate difference algorithm massive data streams proc 
acm symp 
foundations computer science 
flajolet martin probabilistic counting algorithms data base applications computer system sciences vol 
pp 

frieze kannan vempala fast monte carlo algorithms finding low rank approximations proc :10.1.1.126.5994
acm symp 
foundations computer science 
ganti gehrke ramakrishnan demon mining monitoring evolving data knowledge data eng vol 
pp 

gibbons matias synopsis data structures massive data sets proc :10.1.1.130.3576
acm symp 
discrete algorithms pp 

gilbert guha indyk muthukrishnan strauss fast small space algorithms approximate histogram proc 
ann 
acm symp 
theory computing 
gilbert kotidis muthukrishnan strauss summarize universe dynamic maintenance quantiles proc 
int conf 
large data bases 
gilbert guha indyk muthukrishnan strauss near optimal sparse fourier representations sampling proc 
ann 
acm symp 
theory computing 
greenwald khanna space efficient online computation quantile summaries proc 
sigmod 
guha khuller greedy strikes back improved facility location algorithms proc 
acm symp 
discrete algorithms pp 

guha koudas approximating data stream querying estimation algorithms performance evaluation proc 
int conf 
data eng 
guha koudas shim data streams histograms proc 
ann 
acm symp 
theory computing pp 

guha mishra motwani callaghan clustering data streams proc 
acm symp 
foundations computer science pp 

guha rastogi shim cure efficient clustering algorithm large databases proc 
sigmod pp 

haas naughton stokes sampling estimation number distinct values attribute proc 
int conf 
large data bases pp 

data mining concepts techniques han eds 
morgan kaufman 
henzinger raghavan rajagopalan computing data streams digital equipment technical report tr aug 
hinneburg keim efficient approach clustering large multimedia databases noise proc 
fourth int conf 
knowledge discovery data mining 
hinneburg keim optimal grid clustering breaking curse dimensionality high dimensional clustering proc 
int conf 
large data bases 
hochbaum shmoys best possible heuristic center problem math 
operations research vol 
pp 

indyk sublinear time algorithms metric space problems proc 
ann 
acm symp 
theory computing 
indyk sublinear time approximation scheme clustering metric spaces proc 
acm symp 
foundations computer science pp 

indyk stable distributions pseudorandom generators embeddings data stream computation proc 
acm symp 
foundations computer science 
jain dubes algorithms clustering data 
prentice hall 
jain new greedy approach facility location problem proc 
ann 
acm symp 
theory computing 
jain vazirani primal dual approximation algorithms metric facility location median problems proc :10.1.1.129.4996
acm symp 
foundations computer science 
kannan vempala clusterings bad spectral proc 
acm symp 
foundations computer science pp 

algorithmic approach network location problems part ii media ns siam applied math pp 

kaufman rousseeuw finding groups data 
cluster analysis 
new york wiley 
kavraki latombe motwani raghavan randomized query processing robot path planning computer system sciences vol 
pp 

rao nearly linear time approximation scheme euclidean median problem proc 
seventh european symp 
algorithms pp 

lin vitter approximation algorithms geometric median problems information processing letters vol 
pp 

lin vitter approximations minimum packing constraint violations proc 
ann 
acm symp 
theory computing 
mathematical programming data mining data mining knowledge discovery 
manku rajagopalan lindsay approximate medians quantiles pass limited memory proc 
sigmod 
manku rajagopalan lindsay random sampling techniques space efficient online computation order statistics large datasets proc 
sigmod 
ieee transactions knowledge data engineering vol 
may june statistical method profiling network traffic proc 
workshop intrusion detection network monitoring 
plaxton median problem proc 
acm symp 
foundations computer science 
plaxton optimal time bounds approximate clustering proc 
conf 
uncertainty artificial intelligence 
meyerson online facility location proc 
acm symp 
foundations computer science 
discrete location theory francis eds 
new york john wiley sons 
mishra pitt sublinear time approximate clustering proc 
acm symp 
discrete algorithms 
munro paterson selection sorting limited storage theoretical computer science pp 

offline network intrusion detection looking footprints sas white 
ng han efficient effective clustering methods spatial data mining proc :10.1.1.13.4395
int conf 
large data bases pp 

callaghan mishra meyerson guha motwani streaming data algorithms high quality clustering proc :10.1.1.142.777
int conf 
data eng 
ostrovsky rabani polynomial time approximation schemes geometric clustering proc 
acm symp 
foundations computer science 
procopiuc jones agarwal murali monte carlo algorithm fast projective clustering proc 
sigmod 
chatterjee zhang multi resolution clustering approach large spatial databases proc 
int conf 
large data bases pp 

shmoys tardos approximation algorithms facility location problems proc 
ann 
acm symp 
theory computing pp 

guha indyk koudas dynamic multidimensional histograms proc 
sigmod 
thorup quick median center facility location sparse graphs proc 
int colloquium automata languages programming pp 

vazirani approximation algorithms 
springer verlag 
wang yang muntz sting statistical information grid approach spatial data mining proc :10.1.1.106.7154
int conf 
large data bases 
zhang ramakrishnan livny birch efficient data clustering method large databases proc 
sigmod pp 

sudipto guha received phd degree stanford university working approximation algorithms spent year working senior member technical staff network optimizations analysis research department shannon labs research 
fall assistant professor department computer information sciences university pennsylvania 
adam meyerson received phd degree stanford university working professor serge plotkin algorithms network design 
currently postdoctoral fellow aladdin project carnegie mellon university accepted faculty position ucla fall 
nina mishra received phd degree computer science university illinois urbana champaign 
currently senior research scientist hewlett packard labs acting assistant professor stanford university 
research interests lie algorithms data mining machine learning applications 
currently serves editorial board machine learning journal 
served numerous program committees data mining machine learning conferences 
program international conference machine learning 
rajeev motwani received phd degree computer science university california berkeley 
professor computer science stanford university serves director graduate studies 
dr motwani research areas include databases data mining web search information retrieval robotics computational drug design theoretical computer science 
author textbooks 
serves editorial board siam journal computing journal computer system sciences 
dr motwani recipient godel prize foundation award sloan research fellowship national young investigator award national science foundation bergmann memorial award ibm faculty award 
member ieee 
callaghan received bse degree computer science certificate applied computational mathematics princeton university 
fifth year phd student computer science department stanford university 
advisor professor rajeev motwani 
research field algorithms emphasis clustering data mining problems 
information computing topic please visit digital library computer org publications dlib 
