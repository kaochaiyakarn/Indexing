parallel database systems high performance database processing david dewitt jim gray computer sciences department san francisco systems center university wisconsin digital equipment dayton st market st th floor madison wi 
san francisco ca 
dewitt cs wisc edu gray dec com january parallel database machine architectures evolved exotic hardware software parallel dataflow architecture conventional shared hardware 
new designs provide impressive speedup scaleup processing relational database queries 
reviews techniques systems surveys current commercial research systems 

highly parallel database systems displace traditional mainframe computers largest database transaction processing tasks 
success systems refutes predicting demise database machines bora 
years ago highly parallel database machines advocates 
database machine research focused specialized hardware ccd memories bubble memories head track disks optical disks 
technologies fulfilled promises sense conventional cpus electronic ram moving head magnetic disks dominate scene years come 
time disk throughput predicted double processor speeds predicted increase larger factors 
consequently critics predicted multi processor systems soon limited solution bottleneck 
predictions fairly accurate hardware critics certainly wrong parallel database systems 
decade teradata tandem host startup companies successfully developed marketed highly parallel database machines 
appeared communications acm vol 
june research partially supported defense advanced research projects agency contract national science foundation dcr research digital equipment ibm ncr tandem intel scientific computers 
parallel database systems research curiosity 
explanation widespread adoption relational data model 
relational database systems just appearing marketplace today dominate 
relational queries ideally suited parallel execution consist uniform operations applied uniform streams data 
operator produces new relation operators composed highly parallel dataflow graphs 
streaming output operator input operator operators series giving pipelined parallelism 
partitioning input data multiple processors memories operator split independent operators working part data 
partitioned data execution gives partitioned parallelism 
dataflow approach database system design needs message client server operating system interconnect parallel processes executing relational operators 
turn requires high speed network interconnect parallel processors 
facilities exotic decade ago mainstream computer architecture 
client server paradigm high speed lans basis pc workstation workgroup software 
client server mechanisms excellent basis distributed database technology 
sort scan source data sort scan source data sort scan source data merge sort scan source data sort scan source data pipeline parallelism partitioned data allows partitioned parallelism 
dataflow approach relational operators gives pipelined partitioned parallelism 
relational data operators take relations uniform sets records input produce relations outputs 
allows composed dataflow graphs allow pipeline parallelism left computation operator proceeds parallel partitioned parallelism operators sort scan diagram right replicated data source replicas execute parallel 
mainframe designers difficult build machines powerful meet cpu demands relational databases serving large numbers simultaneous users searching terabyte databases 
multi processors fast inexpensive microprocessors widely available vendors including encore intel ncr ncube sequent tandem teradata thinking machines 
machines provide total power mainframe counterparts lower price 
modular architectures enable systems grow incrementally adding mips memory disks speedup processing job scaleup system process larger job time 
retrospect special purpose database machines failed parallel database systems big success 
successful parallel database systems built conventional processors memories disks 
emerged major consumers highly parallel architectures excellent position exploit massive numbers fast cheap commodity disks processors memories promised current technology forecasts 
consensus parallel distributed database system architecture emerged 
architecture shared hardware design ston processors communicate sending messages interconnection network 
systems tuples relation database partitioned declustered disk storage units attached directly processor 
partitioning allows multiple processors scan large relations parallel needing exotic devices 
architectures pioneered teradata late seventies research projects 
design teradata tandem ncr oracle ncube products currently development 
research community embraced shared dataflow architecture systems bubba gamma 
remainder organized follows 
section describes basic architectural concepts parallel database systems 
followed brief presentation unique features teradata tandem bubba gamma systems section 
section describes areas research 
contained section 
basic techniques parallel database machine implementation 
parallelism goals metrics speedup scaleup ideal parallel system demonstrates key properties linear speedup twice hardware perform task half elapsed time linear scaleup twice hardware perform twice large task elapsed time see figures 
gb gb gb tb speedup batch scaleup term disk shorthand disk nonvolatile storage media 
decade proceeds nonvolatile electronic storage media may replace augment disks 

speedup scaleup 
speedup design performs hour job times faster run times larger system 
scaleup design runs times bigger job done time times bigger system 
formally fixed job run small system run larger system speedup larger system measured speedup small system elapsed time big system elapsed time speedup said linear times large expensive system yields speedup speedup holds problem size constant grows system 
scaleup measures ability grow system problem 
scaleup defined ability times larger system perform times larger job elapsed time original system 
scaleup metric scaleup small system elapsed time small problem big system elapsed time big problem scaleup equation evaluates scaleup said linear distinct kinds scaleup batch transactional 
job consists performing small independent requests submitted clients operating shared database scaleup consists times clients submitting times requests times larger database 
scaleup typically transaction processing systems timesharing systems 
form scaleup transaction processing performance council scale transaction processing benchmarks gray 
consequently called transaction scaleup 
transaction scaleup ideally suited parallel systems transaction typically small independent job run separate processor 
second form scaleup called batch scaleup arises scaleup task single large job 
typical database queries typical scientific simulations 
cases scaleup consists times larger computer solve larger problem 
database systems batch scaleup translates query larger database scientific problems batch scaleup translates calculation times finer grid times longer simulation 
generic barriers linear speedup linear scaleup triple threats startup time needed start parallel operation 
thousands processes started easily dominate actual computation time 
interference slowdown new process imposes accessing shared resources 
execution cost operators increases super linearly 
example cost sorting tuples increases nlog 
billions scaling factor causes nlog increase 
deviation linearity orders magnitude scaleup justifies term near linear scaleup 
skew number parallel steps increases average sized step decreases variance exceed mean 
service time job service time slowest step job 
variance dominates mean increased parallelism improves elapsed time slightly 
speedup speedup curve linearity processors discs speedup bad speedup curve parallelism linearity processors discs bad speedup curve factors startup interference skew processors discs 
bad speedup curves 
standard speedup curves 
left curve ideal 
middle graph shows speedup hardware added 
right curve shows threats parallelism 
initial startup costs may dominate 
number processes increase interference increase 
ultimately job divided finely variance service times skew causes slowdown 
section describes basic techniques widely design parallel database machines overcome barriers 
techniques achieve linear speedup scaleup relational operators 

hardware architecture trend shared machines ideal database machine single infinitely fast processor infinite memory infinite bandwidth infinitely cheap free 
machine need speedup scaleup parallelism 
unfortunately technology delivering machines coming close 
technology promising deliver fast chip processors fast high capacity disks high capacity electronic ram memories 
promises devices inexpensive today standards costing hundreds dollars 
challenge build infinitely fast processor infinitely processors finite speed build infinitely large memory infinite memory bandwidth infinitely storage units finite speed 
sounds trivial mathematically practice new processor added computer designs slows computer just little bit 
slowdown interference maximum speedup processor system effective power single processor system 
build scaleable multi processor systems 
stonebraker suggested simple taxonomy spectrum designs see figures ston single instruction stream multiple data stream simd machines iv derivatives old connection machine ignored date successes database area 
simd machines shared memory processors share direct access common global memory disks 
ibm digital vax sequent symmetry multi processors typify design 
shared disks processor private memory direct access disks 
ibm original digital vaxcluster typify design 
shared memory disk owned processor acts server data 
mass storage architecture distributed processors connecting disks 
teradata tandem ncube machines typify design 
shared architectures minimize interference minimizing resource sharing 
exploit commodity processors memory needing incredibly powerful interconnection network 
suggests architectures move large quantities data interconnection network 
shared design moves questions answers network 
raw memory accesses raw disk accesses performed locally processor filtered reduced data passed client program 
allows scaleable design minimizing traffic interconnection network 
shared characterizes database systems teradata tera gamma dewi dewi tandem tand bubba alex lori ncube 
significantly digital vaxcluster evolved design 
dos unix workgroup systems com digital hp novel microsoft sun adopt shared client server architecture 
actual interconnection networks systems vary enormously 
teradata employs redundant tree structured communication network 
tandem uses level network levels cluster rings connecting clusters 
bubba gamma independent underlying interconnection network requiring network allow nodes communicate 
gamma operates intel hypercube 
prototype implemented ibm processors connected point point network 
workgroup systems currently making transition ethernet higher speed local networks 
main advantage shared multi processors scaled hundreds probably thousands processors interfere 
teradata tandem intel shipped systems processors 
intel implementing node hypercube 
largest shared memory multi processors currently available limited processors 
application simulation pattern matching mathematical search appropriate multiuser intensive dataflow paradigm database systems 
shared architectures achieve near linear speedups complex relational queries online transaction processing workloads dewi tand engl 
results database machine designers see little justification hardware software complexity associated shared memory shared disk designs 
interconnection network 
basic shared design 
processor private memory disks 
processors communicate high speed interconnect network 
teradata tandem ncube newer typify design 
interconnection network global shared memory shared memory multiprocessor interconnection network shared disk multiprocessor 
shared memory shared disk designs 
shared memory multi processor connects processors globally shared memory 
multi processor ibm vax sequent computers typical examples shared memory designs 
shared disk systems give processor private memory processors directly address disks 
digital vaxcluster ibm typify design 
shared memory shared disk systems scale database applications 
interference major problem shared memory multi processors 
interconnection network bandwidth sum processors disks 
difficult build networks scale thousands nodes 
reduce network traffic minimize latency processor large private cache 
measurements shared memory multiprocessors running database workloads show loading flushing caches considerably degrades processor performance 
parallelism increases interference shared resources limits performance 
multi processor systems affinity scheduling mechanism reduce interference giving process affinity particular processor 
form data partitioning represents evolutionary step shared design 
partitioning shared memory system creates skew load balancing problems faced shared machine reaps simpler hardware interconnect benefits 
experience believe high performance shared memory machines economically scale processors running database applications 
ameliorate interference problem shared memory multi processors adopted shared disk architecture 
logical consequence affinity scheduling 
disk interconnection network scale thousands discs processors shared disk design adequate large read databases databases concurrent sharing 
shared disk architecture effective database applications read write shared database 
processor wanting update data obtain current copy data 
updating data concurrently processor declare intention update data 
declaration honored acknowledged processors read shared data disk update 
processor write shared data disk subsequent readers writers aware update 
optimizations protocol exchanging reservation messages exchanging large physical data pages 
creates processor interference delays 
creates heavy traffic shared interconnection network 
shared database applications shared disk approach expensive shared approach exchanging small high level logical questions answers clients servers 
solution interference give data processor affinity processors wanting access data send messages server managing data 
emerged major application transaction processing monitors partition load partitioned servers major application remote procedure calls 
trend partitioned data model shared architecture system reduces interference 
shared disk system interconnection network difficult scale thousands processors disks conclude better adopt shared architecture start 
shortcomings shared disk shared architectures computer architects slow adopt shared approach 
answer simple high performance low cost commodity components available 
traditionally commodity components relatively low performance low quality 
today old software significant barrier parallelism 
old software written uni processors gets speedup scaleup put kind multiprocessor 
rewritten benefit parallel processing multiple disks 
database applications unique exception 
today database programs written relational language sql standardized ansi iso 
possible take standard sql applications written uni processor systems execute parallel database machines 
database systems automatically distribute data multiple processors 
teradata tandem routinely port sql applications system demonstrate near linear speedups 
section explains basic techniques parallel database systems 

parallel dataflow approach sql software terabyte online databases consisting billions records common price online storage decreases 
databases represented manipulated sql relational model 
paragraphs give rudimentary relational model concepts needed understand rest 
relational database consists relations files cobol terminology turn contain tuples records cobol terminology 
tuples relation set attributes fields cobol terminology 
relations created updated queried writing sql statements 
statements syntactic sugar simple set operators chosen relational algebra 
called scan simplest common operator produces row subset relational table 
scan relation predicate attribute list produces relational data stream output 
scan reads tuple applies predicate 
true scan discards attributes inserts resulting tuple scan output stream 
expressed sql scan telephone book relation find phone numbers people named smith written select telephone number output attribute telephone book input relation name smith predicate scan output stream sent relational operator returned application displayed terminal printed report 
lies beauty utility relational model 
uniformity data operators allow arbitrarily composed dataflow graphs 
output scan may sent sort operator reorder tuples attribute sort criteria optionally eliminating duplicates 
sql defines aggregate operators summarize attributes single value example sum min max attribute counting number distinct values attribute 
insert operator adds tuples stream existing relation 
update delete operators alter delete tuples relation matching scan stream 
relational model defines operators combine compare relations 
provides usual set operators union intersection difference exotic ones join division 
discussion focus equi join operator called join 
join operator composes relations attribute produce third relation 
tuple ta join finds tuples tb attribute values equal ta 
matching pair tuples join operator inserts output steam tuple built concatenating pair 
codd classic showed relational data model represent form data operators complete codd 
today sql applications typically combination conventional programs sql statements 
programs interact clients perform data display provide high level direction sql dataflow 
sql data model originally proposed improve programmer productivity offering non procedural database language 
data independence additional benefit programs specify query executed sql programs continue operate logical physical database schema evolves 
parallelism unanticipated benefit relational model 
relational queries really just relational operators applied large collections data offer opportunities parallelism 
queries non procedural language offer considerable latitude executing queries 
relational queries executed dataflow graph 
mentioned graphs pipelined parallelism partitioned parallelism 
operator sends output operators execute parallel giving potential speedup 
benefits pipeline parallelism limited factors relational pipelines rarely long chain length unusual 
relational operators emit output consumed inputs 
aggregate sort operators property 
pipeline operators 
execution cost operator greater example skew 
cases speedup obtained pipelining limited 
partitioned execution offers better opportunities speedup scaleup 
large relational operators partitioning inputs outputs possible divide conquer turn big job independent little ones 
ideal situation speedup scaleup 
partitioned data key partitioned execution 
data partitioning partitioning relation involves distributing tuples disks 
data partitioning origins centralized systems partition files file big disk file access rate supported single disk 
distributed databases data partitioning place relation fragments different network sites ries 
data partitioning allows parallel database systems exploit bandwidth multiple disks reading writing parallel 
approach provides bandwidth superior raid style systems needing specialized hardware sale patt 
simplest partitioning strategy distributes tuples fragments roundrobin fashion 
partitioned version classic entry sequence file 
round robin partitioning excellent applications want access relation sequentially scanning query 
problem round robin partitioning applications frequently want associatively access tuples meaning application wants find tuples having particular attribute value 
sql query looking smith phone book example associative search 
hash partitioning ideally suited applications want sequential associative access data 
tuples placed applying hashing function attribute tuple 
function specifies placement tuple particular disk 
associative access tuples specific attribute value directed single disk avoiding overhead starting queries multiple disks 
hash partitioning mechanisms provided bubba gamma teradata 
range partitioning round robin hashing basic partitioning schemes 
range partitioning maps contiguous attribute ranges relation various disks 
round robin partitioning maps th tuple disk mod hashed partitioning maps tuple disk location hash function 
schemes spreads data collection disks allowing parallel disk access parallel processing 
database systems pay considerable attention clustering related data physical storage 
set tuples routinely accessed database system attempts store physical page 
example smith phone book routinely accessed alphabetical order stored pages order pages clustered disk allow sequential prefetching optimizations 
clustering application specific 
example tuples describing nearby streets clustered geographic databases tuples describing line items invoice clustered invoice tuple inventory control application 
hashing tends randomize data cluster 
range partitioning clusters tuples similar attributes partition 
sequential associative access clustering data 
shows range partitioning lexicographic order clustering algorithm possible 
range partitioning derives name typical sql range queries latitude bubba gamma oracle tandem provide range partitioning problem range partitioning risks data skew data place partition execution skew execution occurs partition 
hashing round robin susceptible skew problems 
range partitioning minimize skew picking non uniformly distributed partitioning criteria 
bubba uses concept considering access frequency heat tuple creating partitions relation goal balance frequency partition accessed temperature actual number tuples disk volume cope 
partitioning simple concept easy implement raises new physical database design issues 
relation partitioning strategy set disk fragments 
increasing degree partitioning usually reduces response time individual query increases throughput system 
sequential scans response time decreases processors disks execute query 
associative scans response time improves fewer tuples stored node size index searched decreases 
point partitioning increases response time query 
point occurs cost starting query node significant fraction actual execution time cope 
parallelism relational operators data partitioning step partitioned execution relational dataflow graphs 
basic idea parallel data streams writing new parallel operators programs 
approach enables unmodified existing sequential routines execute relational operators parallel 
relational operator set input ports input tuples arrive output port operator output stream sent 
parallel dataflow works partitioning merging data streams sequential ports 
approach allows existing sequential relational operators execute parallel 
consider scan relation partitioned disks fragments 
scan implemented scan operators send output common merge operator 
merge operator produces single output data stream application relational operator 
parallel query executor creates scan processes shown directs take inputs different sequential input streams 
directs send outputs common merge node 
scan run independent processor disk 
basic parallelizing operator merge combine parallel data streams single sequential stream 
scan scan scan scan partitioned data parallelism 
simple relational dataflow graph showing relational scan project select decomposed scans partitions input stream relation 
scans send output merge node produces single data stream 
merge operator input ports process executing operator output port merge operator split operator merging inputs partitioning output operator 
relational dataflow graph showing relational operator inputs merged sequential steam port 
operator output decomposed split operator independent streams 
stream may duplicate partitioning operator output stream disjoint streams 
split merge operators web simple sequential dataflow nodes connected form parallel execution plan 
merge operator tends focus data spot 
multi stage parallel operation done parallel single data stream split independent streams 
split operator partition replicate stream tuples produced relational operator 
split operator defines mapping attribute values output tuples set destination processes see 
insert select join scan scan simple sql query associated relational query graph 
query specifies join performed relations comparing attribute tuple relation attribute value tuple relation 
pair tuples satisfy predicate result tuple formed attributes tuples result tuple added result relation associated logical query graph produced query optimizer shows tree operators join insert scanning input relation 
insert example consider split operators shown conjunction sql query shown 
assume processes execute join operator processes execute scan operators scanning partitions relation scan partitions relation relation scan nodes split operator sending tuples port join process port join process port join process 
similarly relation scan nodes split operator outputs merged port port join process 
join process sees sequential input stream tuples port merge left scan nodes sequential stream tuples port merge right scan nodes 
outputs join turn split partitioning criterion relation relation scan split operator relation scan split operator predicate destination process predicate destination process cpu process port cpu process port cpu process port cpu process port cpu process port cpu process port 
sample split operators 
split operator maps tuples set output streams ports processes depending range value predicate input tuple 
split operator left relation scan table right relation scan 
tables partition tuples data streams 
clarify example consider join process processor process ports 
receive relation tuples relation scan operators merged single stream port get tuples relation merged single stream port 
join hash join join nested join tuples arrive proper order 
insert insert insert split join output streams join join join merge join input streams insert node perform join scan scan scan scan scan split scan output streams merge input streams join node simple relational dataflow graph 
shows relational scans project select consuming input relations feeding outputs join operator turn produces data stream processes independent processor independent disk little interference 
dataflow designs natural application shared machine architectures 
split operator just example 
split operators duplicate input stream partition round robin partition hash 
partitioning function arbitrary program 
gamma volcano tandem approach 
advantages including automatic parallelism new operator added system plus support kinds parallelism 
split merge operators flow control buffering built 
prevents operator getting far ahead computation 
split operator output buffers fill stalls relational operator data target requests output 
simplicity examples stated terms operator process 
entirely possible place operators process get coarser grained parallelism 
fundamental idea build self pacing dataflow graph distribute shared machine way minimizes interference 
specialized parallel relational operators algorithms relational operators especially appropriate parallel execution minimize data flow better tolerate data execution skew 
improved algorithms relational operators 
evolution join operator algorithms sketched example improved algorithms 
recall join operator combines relations produce third relation containing tuple pairs matching attribute values 
conventional way computing join sort new relations ordered join attribute 
intermediate relations compared sorted order matching tuples inserted output stream 
algorithm called sort merge join 
optimizations sort merge join possible sort execution cost nlog sort merge join nlog execution cost 
sort merge join works parallel dataflow environment data skew 
case data skew sort partitions may larger 
turn creates execution skew limits speedup scaleup 
skew problems appear centralized sort merge joins 
hash join alternative sort merge join 
linear execution cost nlog execution cost resistant data skew 
superior sort merge join input streams sorted order 
hash join works follows 
relations hash partitioned join attribute 
hash partition relation hashed memory 
corresponding partition table relation scanned tuple compared main memory hash table partition 
match pair tuples sent output stream 
pair hash partitions compared way 
hash join algorithm breaks big join little joins 
hash function data skew bad little variance hash bucket size 
cases hash join linear time join algorithm linear speedup scaleup 
optimizations parallel hash join algorithm discovered decade 
pathological skew cases tuples attribute value bucket may contain tuples 
cases algorithm known speedup scaleup 
hash join example shows new parallel algorithms improve performance relational operators 
fruitful research area bora dewi kits kits schn schn wolf 
parallelism obtained conventional sequential relational algorithms split merge operators expect new algorithms discovered 

state art 
teradata teradata quietly pioneered ideas 
building shared highly parallel sql systems commodity microprocessors disks memories 
teradata systems act sql servers client programs operating conventional computers 
teradata systems may processors thousands disks 
teradata processors functionally divided groups interface processors access module processors amps 
handle communication host query parsing optimization coordination amps query execution 
amps responsible executing queries 
amp typically disks large memory cache 
amps interconnected dual redundant tree shaped interconnect called net tera 
relation hash partitioned subset amps 
tuple inserted relation hash function applied primary key tuple select amp storage 
tuple arrives amp second hash function determines tuple placement fragment relation 
tuples fragment hash key order 
value key attribute possible locate tuple single amp 
amp examines cache tuple fetches single disk read 
hash secondary indices supported 
hashing outputs relational operators intermediate relations 
join operators executed parallel sort merge algorithm 
pipelined parallel execution execution query operator run completion participating nodes operator initiated 
teradata installed systems containing processors hundreds disks 
systems demonstrate near linear speedup scaleup relational queries far exceed speed traditional mainframes ability process large terabyte databases 

tandem nonstop sql tandem nonstop sql system composed processor clusters interconnected fiber optic rings 
systems discussed tandem systems run applications processors operating system database servers 
front back distinction programs machines 
systems configured disk mips mips processor disks 
disks typically 
disk served set processes managing large shared ram cache set locks log records data disk pair 
considerable effort spent optimizing sequential scans prefetching large units filtering manipulating tuples sql predicates disk servers 
minimizes traffic shared interconnection network relations may range partitioned multiple disks 
entry sequenced relative tree organizations supported 
tree secondary indices supported 
nested join sort merge join hash join algorithms provided 
parallelization operators query plan achieved inserting split merge operators operator nodes query tree 
scans aggregates joins updates deletes executed parallel 
addition utilities parallelism load reorganize 
tand 
tandem systems primary designed online transaction processing oltp running simple transactions large shared database 
parallelism inherent running independent transactions parallel main parallelism feature oltp parallel index update 
sql relations typically indices uncommon see indices relation 
indices speed reads slow inserts updates deletes 
doing index maintenance parallel maintenance time multiple indices held constant indices spread processors disks 
tandem systems demonstrate near linear scaleup transaction processing workloads near linear speedup scaleup large relational queries tand engl 

gamma current version gamma runs node intel ipsc hypercube disk attached node 
addition round robin range hash partitioning gamma provides hybrid range partitioning combines best features hash range partitioning strategies 
relation partitioned gamma provides clustered non clustered indices partitioning non partitioning attributes 
indices implemented trees hash tables 
gamma uses split merge operators execute relational algebra operators parallelism pipelining dewi 
sort merge different hash join methods supported dewi 
near linear speedup scaleup relational queries measured architecture schn dewi schn 

super database computer super database computer sdc project university tokyo presents interesting contrast database systems kits 
sdc takes combined hardware software approach performance problem 
basic unit called processing module pm consists processors shared memory 
processors augmented special purpose sorting engine sorts high speed mb disk subsystem kits 
clusters processing modules connected omega network provides non blocking nxn interconnect dynamic routing minimize skewed data distribution hash joins 
sdc designed scale thousands pms considerable attention paid problem data skew 
data partitioned pms hashing 
sdc software includes unique operating system relational database query executor 
sdc shared design software dataflow architecture 
consistent assertion current parallel database machines systems conventional hardware 
special purpose design omega network hardware sorter clearly contradict thesis special purpose hardware investment development resources 
time tell special purpose components offer better price performance peak performance designs built conventional hardware 

bubba bubba prototype implemented node flex multi processor disks bora 
shared memory multi processor bubba designed shared system shared memory message passing 
nodes divided groups interface processors communicating external host processors coordinating query execution intelligent repositories data storage query execution checkpoint logging repositories 
bubba uses partitioning storage mechanism range hash partitioning mechanisms provided dataflow processing mechanisms bubba unique ways 
bubba uses fad sql interface language 
fad extended relational persistent programming language 
fad provides support complex objects type constructors including shared sub objects set oriented data manipulation primitives traditional language constructs 
fad compiler responsible detecting operations executed parallel data objects accessed partitioned 
program execution performed dataflow execution paradigm 
task compiling parallelizing fad program significantly difficult parallelizing relational query 
bubba feature store mechanism persistent database node mapped virtual memory address space process executing node 
contrast traditional approach files pages 
similar mechanisms ibm mapping sql databases virtual memory hp mapping image database operating system virtual address space mach mapped file mechanism 
approach simplified implementation upper levels bubba software 

systems parallel database system prototypes include xprs ston volcano lori persist project development ibm research labs hawthorne almaden 
volcano xprs implemented sharedmemory multi processors xprs unique exploitation availability massive shared memory design 
addition xprs innovative techniques obtaining extremely high performance availability 
oracle database system implemented atop node ncube shared system 
resulting system demonstrate transactions second industry standard tpc benchmark 
far excess oracle performance conventional mainframe systems peak performance price performance 
ncr announced product lines employ shared architectures running system unix intel processors 
interconnection network product line uses enhanced net licensed teradata new multistage interconnection network developed jointly ncr teradata 
software offerings announced 
port teradata software unix environment targeted decision support marketplace 
second parallelization sybase dbms intended primarily transaction processing workloads 

database machines law today shared database machines best peak performance best price performance available 
compared traditional mainframes tandem system scales linearly largest reported mainframes tpc transaction processing benchmark 
price performance benchmarks times cheaper comparable mainframe numbers 
oracle ncube highest reported tpc numbers competitive price performance gray 
benchmarks demonstrate linear scaleup transaction processing benchmarks 
gamma tandem teradata demonstrated linear speedup scaleup complex relational database benchmarks 
scale size largest mainframes 
performance price performance generally superior mainframe systems 
observations defy law 
herb observed economy scale computing 
time expensive computers powerful inexpensive computers 
gave rise super linear speedups 
current pricing mainframes mips mb ram reflects view 
microprocessors selling mips mb ram 
combining hundreds thousands small systems build incredibly powerful database machine money cost modest mainframe 
database problems near linear speedup scaleup shared machines allows outperform current shared memory shared disk mainframes 
law longer applies database transaction processing problems 
economy scale 
best expect linear speedup scaleup performance price performance 
fortunately shared database architectures achieve near linear performance 

directions research problems 
mixing batch oltp queries section concentrated basic techniques processing complex relational queries parallel database system 
concurrently running mix simple complex queries concurrently presents unsolved problems 
problem large relational queries tend acquire locks tend hold relatively long time 
prevents concurrent updates data simple online transactions 
solutions currently offered give ad hoc queries fuzzy picture database locking data browse 
dirty read solution acceptable applications 
systems offer versioning mechanism gives readers consistent old version database allowed create newer versions objects 
better solutions problem may exist 
priority scheduling mixed workload problem 
batch jobs tendency processor flood memory cache large demands subsystem 
underlying operating system quantize limit resources batch jobs insure short response times low variance response times short transactions 
particularly difficult problem priority inversion problem client request high priority server 
server run high priority managing critical resources 
low priority client effectively promoted high priority low priority request serviced server 
ad hoc attempts solving problem considerably needed 

parallel query optimization current database query optimizers consider possible plans optimizing relational query 
cost models relational queries running single processor understood depend cost estimators guess best 
dynamically select plans run time depending example amount physical memory available cardinalities intermediate results 
date query optimizers consider parallel algorithms operator query tree organizations 
needed area 
optimization problem relates highly skewed value distributions 
data skew lead high variance size intermediate relations leading poor query plan cost estimates sub linear speedup 
solutions problem area active research kits wolf hua walt 

application program parallelism parallel database systems offer parallelism database system 
missing tools structure application programs take advantage parallelism inherent parallel systems 
automatic parallelization applications programs written cobol may feasible library packages facilitate explicitly parallel application programs needed 
ideally split merge operators packaged applications benefit 

physical database design database workload possible indexing partitioning combinations 
database design tools needed help database administrator select design options 
tools accept input description queries comprising workload frequency execution statistical information relations database description processors disks 
resulting output suggest partitioning strategy relation plus indices created relation 
steps direction appear 
current algorithms partition relations values single attribute 
example geographic records partitioned longitude latitude 
partitioning longitude allows selections longitude range localized limited number nodes selections latitude sent nodes 
acceptable small configuration acceptable system thousands processors 
additional research needed multidimensional partitioning search algorithms 

line data reorganization utilities loading reorganizing dumping terabyte database megabyte second takes twelve days nights 
clearly parallelism needed utilities complete hours days 
essential data available utilities operating 
sql world typical utilities create indices add drop attributes add constraints physically reorganize data changing clustering 
unexplored difficult problem process database utility commands system remains operational data remains available concurrent reads writes 
fundamental properties algorithms online operate making data unavailable incremental operate parts large database parallel exploit parallel processors recoverable allow operation canceled return old state 

summary applications database systems want cheap fast hardware 
today means commodity processors memories disks 
consequently hardware concept database machine built exotic hardware inappropriate current technology 
hand availability fast microprocessors small inexpensive disks packaged standard inexpensive fast computers ideal platform parallel database systems 
architecture relatively straightforward implement importantly demonstrated speedup scaleup hundreds processors 
furthermore shared architectures simplify software implementation 
software techniques data partitioning dataflow intra operator parallelism employed task converting existing database management system highly parallel relatively straightforward 
certain applications data mining terabyte databases require computational resources available parallel architecture 
successes commercial products prototypes demonstrates viability highly parallel database machines open research issues remain unsolved including techniques mixing ad hoc queries online transaction processing seriously limiting transaction throughput improved optimizers parallel queries tools physical database design line database reorganization algorithms handling relations highly skewed data distributions 
application domains supported relational data model 
appears new class database systems objectoriented data model needed 
systems pose host interesting research problems required examination 
alex alexander process dataflow control distributed data intensive systems proc 
acm sigmod conf chicago il june 
october 
bitton gray disk shadowing proceedings fourteenth international conference large data bases los angeles ca august 
bora boral dewitt database machines idea time passed 
critique database machines proceedings workshop database machines edited 
springer verlag 
bora boral prototyping bubba highly parallel database system ieee knowledge data engineering vol 
march 
codd codd relational model data large shared cacm 
vol 
june 
cope copeland alexander keller data placement bubba proceedings acm sigmod international conference management data chicago may 
dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston ma june 
dewi dewitt gamma high performance dataflow database machine proceedings vldb conference japan august 
dewi dewitt gamma database machine project ieee knowledge data engineering vol 
march 
engl gray kocher shah benchmark nonstop sql release demonstrating near linear speedup scaleup large databases tandem computers technical report tandem part may 
gibbs massively parallel systems rethinking computing business science oracle vol 
december 
ghandeharizadeh dewitt performance analysis alternative declustering strategies proceedings th international conference data engineering feb 
ghandeharizadeh dewitt hybrid range partitioning strategy new declustering strategy multiprocessor database machines proceedings sixteenth international conference large data bases melbourne australia august 
graefe ward dynamic query evaluation plans proceedings sigmod conference portland june 
graefe encapsulation parallelism volcano query processing system proceedings acm sigmod international conference management data may 
gray performance handbook database transaction processing systems gray editor 
morgan kaufmann san mateo 

architecture sdc super database computer proceedings 

hua hua lee handling data skew multiprocessor database computers partition tuning proceedings seventeenth international conference large data bases spain september 
kits kitsuregawa tanaka oka application hash data base machine architecture new generation computing vol 

kits kitsuregawa yang evaluation stage pipeline hardware sorter proceedings rd international conference data engineering feb 
kits kitsuregawa ogawa new parallel hash join method robustness data skew super database computer sdc proceedings sixteenth international conference large data bases melbourne australia august 
lori lorie hallmark stamos young adding intra transaction parallelism existing dbms early experience ieee data engineering newsletter vol 
march 
patt patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm sigmod international conference management data chicago may 
ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report uc berkeley may 
sale salem garcia molina disk striping department computer science princeton university technical report tr princeton dec schn schneider dewitt performance evaluation parallel join algorithms shared multiprocessor environment proceedings sigmod conference portland june 
schn schneider dewitt tradeoffs processing complex join queries hashing multiprocessor database machines proceedings sixteenth international conference large data bases melbourne australia august 
selinger access path selection relational database management system proceedings sigmod conference boston ma may 
ston stonebraker distributed database machine erl technical report ucb erl university california berkeley may 
ston stonebraker case shared database engineering vol 

ston stonebraker katz patterson ousterhout design xprs proceedings fourteenth international conference large data bases los angeles ca august 
tand tandem database group nonstop sql distributed high performance high reliability implementation sql workshop high performance transaction systems asilomar ca september 
tand tandem performance group benchmark non sql debit credit transaction proceedings sigmod conference chicago il june 
tera teradata dbc data base computer concepts facilities teradata document 

tevanian unix interface shared memory memory mapped files mach dept computer science technical report carnegie mellon university july 
performance oltp application symmetry multiprocessor system proceedings th annual international symposium computer architecture seattle wa may 
walt walton dale taxonomy performance model data skew effects parallel joins proceedings seventeenth international conference large data bases spain september 
wolf wolf dias yu effective algorithm parallelizing sort merge joins presence data skew nd international symposium databases parallel distributed systems dublin ireland july 
zeller gray adaptive hash joins multiprogramming environment proceedings vldb conference australia august 

