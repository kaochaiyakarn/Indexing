document clustering nonnegative matrix factorization michael berry department computer science university tennessee knoxville tn paul robert plemmons department computer science wake forest university winston salem nc methodology automatically identifying clustering semantic features topics heterogeneous text collection 
textual data encoded low rank nonnegative matrix factorization algorithm retain natural data nonnegativity eliminating need subtractive basis vector encoding calculations techniques principal component analysis semantic feature abstraction 
existing techniques nonnegative matrix factorization reviewed new hybrid technique nonnegative matrix factorization proposed 
performance evaluations proposed method conducted benchmark text collections standard topic detection studies 
key words conjugate gradient constrained squares nonnegative matrix factorization text mining 
text mining refers detection trends patterns similarities natural language text 
collection text documents need arises research authors plemmons supported part air force office scientific research fa army research office daad 
email addresses berry cs utk edu michael berry plemmons edu paul robert plemmons 
preprint submitted elsevier preprint august classify documents groups clusters similarity content 
relatively small collection may possible manually perform partitioning documents specific categories 
partition large volumes text process extremely time consuming 
automation greatly reduces time needed perform classification 
categories topics classification predefined process classification considered supervised methods satisfactorily automate task supervised classification 
absence information regarding nature data problem classification difficult 
unsupervised classification text data valid assumption text collection completely unstructured 
task organizing documents structure solely patterns learned collection 
structure partitional hierarchical 
hierarchical organization documents tree structure entire collection situated root level 
subsequent levels tree collection partitioned smaller groups eventually document represented separate group bottom level 
text collection partitional structure documents collection partitioned clustered groups nonoverlapping 
proposed nonnegative matrix factorization nmf method text mining introduces technique partitional clustering identifies semantic features document collection groups documents clusters basis shared semantic features 
factorization compute low rank approximation large sparse matrix preservation natural data nonnegativity 
vector space model text data documents encoded dimensional vectors number terms dictionary vector component reflects importance corresponding term respect semantics document 
collection documents represented term document matrix 
vector component positive value weight corresponding term document null zero value resulting term document matrix nonnegative 
inherent data nonnegativity preserved nmf method result constraints placed factorization produce nonnegative lower rank factors interpreted semantic features patterns text collection 
vectors documents original matrix reconstructed combining semantic features documents common features viewed cluster 
shown xu nmf outperforms traditional vector space approaches information retrieval latent semantic indexing document clustering topic detection benchmark collections 
related nonnegative matrix factorization differs rank reduction methods vector space models text mining principal component analysis pca vector quantization vq due constraints produce nonnegative basis vectors possible concept parts representation 
lee seung introduced notion parts representations problems image analysis text mining occupy nonnegative subspaces vector space model 
techniques pca vq generate basis vectors various additive subtractive combinations reconstruct original space 
basis vectors pca vq contain negative entries directly related original vector space derive meaningful interpretations 
case nmf basis vectors contain negative entries allows additive combinations vectors reproduce original 
perception image document collection combination parts represented basis vectors 
text mining vectors represent identify semantic features set words denoting particular concept topic 
document viewed combination basis vectors categorized belonging topic represented principal vector 
nmf organize text collections partitional structures clusters directly derived nonnegative factors 
xu demonstrated nmf outperforms methods singular value decomposition comparable graph partitioning methods widely clustering text documents 
tests conducted different datasets reuters data corpus tdt corpus considered benchmark collections topic detection 
data corpora study observe results nonnegative factorization text mining document clustering 
algorithm derive factorization introduces new parameter control number basis vectors reconstruct document vectors providing mechanism balance tradeoff accuracy computational cost including storage 
reuters kdd ics uci edu databases reuters reuters html 
www lcd upenn edu 
algorithm standard vector space model set documents expressed matrix number terms dictionary number documents column vj encoding document entry vij vector vj significance term respect semantics vj ranges terms dictionary 
nmf problem defined finding low rank approximation terms metric norm factoring product wh reduced dimensional matrices column basis vector contains encoding semantic space concept column contains encoding linear combination basis vectors approximates corresponding column dimensions respectively reduced rank selected number topics 
usually chosen smaller accurately min 
finding appropriate value depends application influenced nature collection 
common approaches nmf obtain approximation computing pair minimize frobenius norm difference wh 
problem cast way nonnegative matrix min 
objective function minimization problem stated wij hij min wh matrices unique 
usually initialized zero randomly generated matrix wij initial estimates improved updated alternating iterations algorithm 
subsections existing nmf techniques discussed new algorithm proposed 
multiplicative method nmf method proposed lee seung multiplicative update rules scheme referred multiplicative method mm 
algorithm contains formal statement method 
mm algorithm initialize nonnegative values 
iterate convergence iterations cj wic wic wh cj ht ic ic steps small positive parameter equal added avoid division zero 
observed mm algorithm remain nonnegative updates 
simultaneous updating generally yield better results updating matrix factor fully 
algorithm columns basis vectors normalized iteration case optimization performed unit hypersphere columns effectively mapped surface hypersphere repeated normalization 
computational complexity mm shown kmn operations rank approximation iteration 
term document matrix factored new data needs added data direct addition minor modification fixed 
case fixed new data integrated iterations initial approximations 
shown lee seung mm update rules objective function monotonically non increasing constant stationary point 
multiplicative method related expectation maximization approaches image restoration classified diagonally scaled gradient descent method 
sparse encoding new nonnegative sparse encoding scheme study neural networks suggested hoyer 
scheme applicable decomposition datasets independent feature subspaces hyv rinen hoyer 
method proposed hoyer important feature enforces statistical sparsity matrix 
sparsity increases basis vectors localized parts representation data enhanced 
mu plemmons put forth regularization approach achieves objective enforcing statistical sparsity point count regularization scheme penalizes number non zero entries sum entries hij ij hybrid method nmf algorithm study hybrid method combines better features methods discussed previous sections 
approach multiplicative method basically version gradient descent optimization scheme iterative step approximate basis vector matrix calculated constrained squares cls model metric 
serves penalize non smoothness non sparsity result penalization basis vectors topics localized reducing number vectors needed represent document 
method approximating similar methods described related squares tikhonov regularization technique commonly image restoration 
hybrid algorithm denoted gd cls gradient descent constrained squares 
gd cls algorithm initialize nonnegative values scale columns unit norm 
iterate convergence iterations wic wic ic ic rescale columns unit norm solve constrained squares problem min vj hj hj subscript denotes th column negative values hj set zero 
parameter regularization value balance reduction metric vj enforcement smoothness sparsity software implementation software packages gtp lapack implementation gd cls algorithm 
general text parser gtp software environment developed university tennessee giles 
functions gtp parse text documents construct sparse matrix data structure term document matrix defines relationship documents parsed terms 
gtp software parse single files entire directories fitted capability process raw text html files 
user integrate external filters software process forms tagged data 
currently versions software available java designed facilitate users ranges expertise 
study version gtp 
lapack various routines individually downloaded lapack website solving different types linear equations 
version nmf software routine lapack derive solutions double precision linear systems form ax symmetric positive definite matrix 
experiments originally written matlab see proposed nmf algorithm gd cls converted study scalability 
performance evaluations conducted different datasets reuters document corpus tdt 
section describes methodology evaluation actual results discussed section 
reuters reuters data corpus contains documents topics document clusters created manually document corpus assigned topics category labels content 
manually created cluster sizes number documents assigned topics range nearly topics 
documents sgml format see meta tags denoting title topic content 
experiment documents associated topic topics cluster sizes smaller discarded 
achieve perl www netlib org lapack results collected sun microsystems workstation mhz ultrasparc iie processor kb cache mb dram gb internal disk 
kdd ics uci edu databases reuters reuters html 
lambda options strcmp options neg neg size rand zeros lambda eye neg fig 

matlab implementation gs cls algorithm script see traverse corpus create index topics associated cluster sizes document considered part cluster single topic 
order observe performance gd cls implementation nmf complexity problem increases number clusters parameter incremented different values chosen 
different document collections subsets generated filter different topic files result creation term document sparse matrices predominant number elements matrices zero boeing hb sparse matrix format access non zero elements 
hb matrices generated nmf clustering algorithm performed matrices values document subsets produce factors hb matrix 
hb matrix topics documents matrix columns basis vectors represent clusters matrix columns represent documents 
column vector components denotes contribution corresponding basis vector column document 
classification clustering documents performed index highest value document 
document maximum value jth entry document assigned cluster documents clustered topics nmf generated clusters compared original clusters mapping function 
mapping performed perl script assigns original cluster labels nmf clusters similarity measure 
example provides explanation mapping process 
relabeling accomplished accuracy classification clustering assessed metric ac defined ac di di set di topic label nmf original classification set number documents collection 
cluster example ac 
gd cls implementation nmf contribution parameter sparsity controlled interest 
results different values calculated 
cluster example 
original topic set document subset gd cls hb matrix generated topic set yields wh assuming value shown table clustering maximum column entry cluster cluster 
values mapping function form matrix table similarity number documents appear 
assigned original cluster label similar 
cluster cluster assigned labels respectively documents reassigned topics new clustering 
comparison original clustering gd cls generated cluster labels shown table 
table matrix cluster example maximum entries represented boldface 
table matrix cluster example 
cluster cluster table comparison original cluster labels gd cls generated labels cluster example 
document original gd cls label label tdt second data corpus tdt obtained language data consortium university pennsylvania contains transcripts total news sources files file containing transcripts documents 
corpus consists documents sgml format see fourteen assigned topic label rest classified 
preclassified documents documents single topic documents documents single topic category label 
sgml markup tags document denote unique document id identification number text content 
document topic relationships described separate file contains line document category label 
line corresponding particular document consists document id topic label name file containing document 
order document collection corpus comparable reuters dataset preprocessing perl scripts applied sgml files 
file containing document topic relationships parsed topic file file containing list topics cluster sizes documents created 
reuters collection documents containing multiple topic labels deemed relevant 
entire document corpus consists documents relevant experiments preprocessing step taken reduce runtime gtp traversing entire collection writing relevant documents single file 
subsequent testing file order avoid traversing thousands irrelevant documents test run 
topic file reduced set documents hand subsets created monitor decline accuracy nmf algorithm complexity values increase 
different values chosen different topic sets document subsets 
application gd cls accuracy metric selection datasets produces results section 
observations results tdt reuters data corpora bring attention trends decline accuracy relation increase complexity www lcd upenn edu 
abc cnn nyt pri 
value results document collections indicate topics document clusters added dataset clustered gd cls accuracy clustering decreases 
reuters collection case dealing topics algorithm performs accuracy case accuracy drops just table 
case tdt drop accuracy reuters table 
tdt accuracy just significant improvement reuters 
disparity attributed differences content collections 
documents reuters collection categorized broad topics earn interest cocoa potato listed tdt topic labels specific asian economic crisis tornado florida lawsuit 
specificity topics tdt guarantees heterogeneity document collection reuters collection 
case reuters potato zinc may constitute distinct clusters interest money fixes 
fact noted xu degree overlapping content topics reuters collection contributes rapid decline accuracy case reuters tdt 
notable trend points sensitivity gd cls algorithm nmf contents document collections differences accuracy different values 
case tdt different values affect performance noticeable amount 
reuters drop accuracy increasing values parameter suggests text collections somewhat homogeneous content sensitive changes parameter sparsity matrix 
primary reason larger value increase sparsity achieve faster computation times 
inspection results table suggests case especially higher complexity problems table 
inferred table increase sparsity results significant increase computational speed holds tdt reuters 
accuracy values affect performance reuters tdt 
compared gain computational time decrease accuracy considered reasonable tradeoff 
aspect gd cls directly observed result tables change performance factorization regards disparate cluster sizes 
creating document subsets value preclassified clusters reuters tdt corpus attention keep cluster sizes reasonable bound 
constraint table results reuters ac accuracy measure defined section cpu time ac sec imposed xu enforced due results obtained experiments similar described table 
imbalance cluster sizes dataset definite effect performance gd cls regardless document corpus 
case original clusters dataset ratio cluster cluster approximately clusters produced gd cls ratio 
implies gd cls performs better datasets balanced cluster sizes dataset clustering performed accuracy 
table results tdt ac accuracy measure defined section cpu time ac sec table cpu time different values reuters tdt study demonstrates gd cls hybrid nmf algorithm effectively classify text collections unsupervised automated manner 
proposed algorithm construct parts representation text data localization parts features table comparison results different cluster sizes corpus dataset cluster original cluster gd cls generated sizes cluster sizes reuters tdt dataset cluster cluster dataset cluster cluster dataset cluster cluster dataset cluster cluster regularized create balance computational cost accuracy 
current stage gd cls algorithm nmf equipped handle updating efficient manner 
document collection clustered nmf adding small number documents collection achieved comparing new documents represented vector basis vectors associating new document basis vector topic similar 
updating technique scalable produce poor results add large number documents associated basis vectors 
nmf general applied image analysis text mining 
field benefit technique bioinformatics 
problems identifying motifs significant features protein sequences partial strings dna natural candidates application nmf 
problems protein sequences viewed analogous text documents basis vectors topics motifs control gene expression 
primary function nmf classification opposed query information retrieval resulting clusters provide retrieval capabilities 
style limited updating discussed earlier user query represented term vector compute similarity measure cosine measurement query basis vectors 
basis vector topic yields highest value deemed relevant documents belonging topic provided user 
authors murray browne technical assistance production manuscript 
berry 
matrices vector spaces information retrieval 
siam review 
berry browne 
understanding search engines mathematical modeling text retrieval 
siam philadelphia pa 
dunham 
data mining introductory advanced topics 
prentice hall upper saddle river nj 
giles berry wo 
gtp general text parser software text mining 
editor software text mining statistical data mining knowledge discovery pages 
crc press boca raton fl 

determining suitable metric non negative matrix factorization 
sixteenth international conference pattern recognition icpr vol 
quebec city qc canada 
hoyer 
non negative sparse coding 
proceedings ieee workshop neural networks signal processing martigny switzerland 
hyv rinen hoyer 
emergence phase shift invariant features decomposition natural images independent feature subspaces 
neural computation 
lee seung 
algorithms non negative matrix factorization 
advances neural information processing systems 

integrating network storage information retrieval applications 
master thesis department computer science university tennessee knoxville tn 
mu plemmons 
iterative ultrasonic signal image deconvolution estimating complex medium response 
ieee transactions frequency control 
ieee 
submitted publication 
berry plemmons 
text mining non negative matrix factorizations 
proceedings fourth siam international conference data mining lake vista fl april 
siam 
prasad plemmons van der 
restoring images space variant blur pupil phase engineering 
optics info 
systems special issue comp 
imaging spie int 
tech 
group newsletter 

clustering method nonnegative matrix factorization text mining 
master thesis department computer science university tennessee knoxville tn 
stuart berry 
comprehensive genome bacterial phylogeny correlated peptide motifs defined high dimensional vector space 
journal bioinformatics computational biology 
xu liu gong 
document clustering non negative matrix factorization 
proceedings sigir july august pages toronto ca 

