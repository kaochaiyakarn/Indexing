generating facial expressions speech reports results program produces high quality animation facial expressions head movements automatically possible conjunction meaning speech synthesis including spoken intonation 
goal research test define theories formal semantics gestures produce convincing animation 
produced high level programming language animation facial expressions 
concerned primarily expressions conveying information correlated intonation voice includes differences timing pitch emphasis related semantic distinctions discourse focus topic comment theme rheme new information 
interested relation affect emotion facial expression 
systems embodied rule governed translation spoken utterance meaning facial expressions 
system embodies rules describe coordinate relations intonation information intonation affect facial expressions affect 
meaning representation includes discourse information contrastive background information context topic theme discourse 
system maps meaning representation accents placement chosen conveyed facial expression speech facial expressions coordinated 
determines sequence functional groups lip shapes conversational signals regulators manipulators 
algorithms impose synchrony create coarticulation effects determine signals eye head movements 
lowest level representation facial action coding system facs generation system portable facial models 
generating facial expressions speech catherine pelachaud norman badler mark steedman department computer information science university pennsylvania philadelphia pa reports results program produces high quality animation facial expressions head movements automatically possible conjunction meaning speech synthesis including spoken intonation 
goal research test define theories formal semantics gestures produce convincing animation 
produced high level programming language animation facial expressions 
concerned primarily expressions conveying information correlated intonation voice includes differences timing pitch emphasis related semantic distinctions discourse focus topic comment theme rheme new information 
interested relation affect emotion facial expression 
systems embodied rule governed translation spoken utterance meaning facial expressions 
system embodies rules describe coordinate relations intonation information intonation affect facial expressions affect 
meaning representation includes discourse information contrastive background information context topic theme discourse 
system maps meaning representation accents placement chosen conveyed facial expression speech facial expressions coordinated 
determines sequence functional groups lip shapes conversational signals regulators manipulators 
algorithms impose synchrony create coarticulation effects determine signals eye head movements 
lowest level representation facial action coding system facs generation system portable facial models 
communication face face interactions expressed number channels including body voice face eyes 
talking people faces rarely 
lips talk raise eyebrows move blink eyes nod turn head ekman 
facial signals help regulate flow conversation way intonation signalling emphasis contrast information related turn control floor interaction 
facial signals express signals may influence participant behavior argyle cook collier 
formal theories discourse semantics signals generally lacking area spoken intonation accounts way spoken intonation conveys discourse information associated speaker messages halliday bolinger pierrehumbert hirschberg steedman 
similarly psychologists claimed find universal facial expressions linked affects attitudes ekman 
animating face specifying action manually tedious task yield entirely appropriate facial expression 
order improve facial animation systems understanding linguistic semantics interaction intonation important priority 
appropriate integration gestural motions head eyes accompany speech essential effective simulation human speaking agents 
reported exploratory originally begun advance having completely satisfactory theory association discourse meanings intonation facial expressions 
concerned development fully formalised theory exploitation animation 
linguistic fragments rules propose incomplete 
arbitrary case empirical motivations observations 
goal research provide easily usable animation primitives intention investigate soundness discourse semantics underpins system effects computationally generated rule investigated controlled simulation 
earlier systems facial animation parke magnenat thalmann thalmann set parameters affect structure model long nose short forehead expressions opening mouth raising eyebrows 
separation conformation parameters expression parameters provides independence facial features production expression 
accurate facial motions obtained simulating muscle actions platt waters 
integrating models layers facial tissue dynamic simulation muscle movements considerable realism creating subtle facial actions may achieved terzopoulos waters 
automatic lip synchronization included animation systems multi layer approach adding speech parameters hill 
correspondence speech unit basic lip shape established 
particular relevance model coarticulation proposed cohen massaro 
uses overlapping dominance functions 
functions specify viseme close lips reach target value 
greater realism expense synthetic control comes techniques extract information live animation williams terzopoulos waters essa pentland 
computed movement information interpreted muscle contractions input animation system 
texture mapping enhance realism features skin tone model williams kurihara arai 
consideration wrinkles aging effects adds rendering facial skin expressions 
approach main goal look coordinated motion conversation 
need understand link spoken intonation information transmitted context facial movement 
facs notation facial action coding system created ekman friesen ekman friesen describe visible facial expressions system anatomical studies 
facial action due muscular activity relaxation contraction 
facs describes temporary changes facial appearance feature affected specifying new location intensity changes 
action unit au corresponds action produced group related muscles 
au describes direct effect muscle plus eventual secondary motion due propagation movement possible appearance wrinkles 
refer reader ekman friesen detailed description au 
highlights approach resolves difficulty manipulating action muscle keyframe level offering user higher level animation lip synchronization automatic computation facial expressions related speech patterns fig 

differentiate facial expressions linked meaning non expressive ones 
elaborated movements pelachaud 
included eye gestures head gestures part animation utterance 
view partitioning facial expression important tool analyzing exploring significance role certain facial actions spoken intonation context facial movements 
facial actions differentiated interpretations highlighting word pause example facial features involved actions eyebrow head eye movements 
separability dimensions facial expressions allows decompose facial expression number independent dimensions action 
facial action determined different facial interpretations 
raised eyebrows signal surprise highlight word utterance 
define determinant specific discourse meaning interpretation relative flow speech 
determinant manifest different facial actions fig 

example highlighting word indicated head nod blink eye flash 
facial action unique determinant shared discussion lately nsf facial workshop pelachaud may suffice fine description mouth region 
different determinants smile pause signal happiness 
determinants separated may facial actions common 
list determinants section 
final animation obtained summing individual sets actions mere fact merge successfully produce unified animation strong evidence decomposition reasonable 
different determinants facial movements intended experimentally manipulable research investigate significance human subjects 
approach allows contribution component determinants selected effects animation observed 
example movements highlighting words activated see type information convey disabled determine facial animation conveys meaning 
reason system allows modular refinement determinant 
computation determinant facial expressions done set rules may easily modified augmented altering part system 
particular rules may added changed determinant affecting 
individuals differ type facial actions speech individual may mainly eyebrow movements may nose eye flashes 
differ number displayed actions place occurrence 
define facial action independent parameters 
parameter type facial action set aus time occurrence action spoken utterance 
user modify parameter action touching variable system 
process allows user independently vary manifestation speaker attitude conveyed individuality computation facial expressions 
important enhancement lip synchronization technique consideration effects examine action muscle affected temporal spatial context 
nature muscle actions face contraction release times taken account 
phenomenon apparent rapid speech mouth shapes created sequences phonemes lost characteristic shapes 
computation facial expressions linked particular utterance intonation affect done independently facial model 
contrary technique stored library expressions computes facial movements model method works au level geometric independence 
facial expressions may applied facial model uses facs drive animation 
facial model presently integrates action muscle group muscles propagates movements skin platt 
programmed facs aus 
organization section background system 
characterize various determinants facial expressions describe head eye movements computation intonational system 
describe system section including input representation assumptions properties 
section describe algorithms implemented determinant particular attention lip synchronization coarticulation problems 
section detail examples various affects intonational meanings influence final animation 
exposition illustrate algorithms examples 
assume moment occurring actions additive 
case smiling speech simply add aus corresponding smile lip shapes 
background background definitions relevant study 
different determinants facial expressions functions facial movements delineate items sequence punctuation marks written text argyle cook 
example raising eyebrows discourse 
consider determinants defined section conversational signals correspond facial actions occurring accented items emphatic segments actions clarify support said 
eyebrow movements appear frequently conversational signals ekman rapid head movements gaze direction may involved 
correspond facial actions occurring pauses actions reduce ambiguity speech grouping separating sequences words discrete unit phrases collier 
specific head motions blink eyebrow actions may highlight pause 
manipulators correspond biological needs face blinking wet eyes 
regulators help interaction speaker listener control flow speech 
breaking looking eye contact listener turning head away listener part elaborated interaction conversation duncan 
decomposed speaker state signal displayed speaking turn speaker turn speaker wants keep floor speaker continuation signal frequently follows speaker turn 
complete facial animation system obtained include determinants 
presently exclude facial functions related directly pattern voice 
consider facial compute automatically actions precise meaning see section 
speaker may replace common verbal expressions specific facial expression may display part facial expression affect mention felt moment ekman 
appearance expressions voluntary depend said 
specification head eye movements facial expression expressed set aus 
head eye movements animation system coded aus defined joint angles decided sake simplicity consistency describe separately 
final position head eyes integrates actions facial determinants 
generality lost 
head movements continuous sequences head movements support verbal stream 
head movements may associated nodding shaking agreement disagreement maintaining flow conversation turn system 
head direction may depend affect sadness marked downward direction table point 
classes head motions distinguished amplitude frequency slow movements sm ordinary movements om rapid movements rm 
postural shifts pos defined linear movements wide amplitude change axis motion table 
speeds affect dependent table 
distinct patterns accompany linguistic features tables 
occurrence pos speech speaking turns duncan grammatical pauses imply involvement speech production regulation turn marking syntactic boundaries inside clauses 
value deg sec pos rm om sm max min head movements classified frequency amplitude 
pos postural shift high frequency wide amplitude rm om sm small amplitude various frequencies 
eye behavior table velocity values class head movements eyes moving 
eye movements defined gaze direction point points fixation percentage eye contact gaze avoidance respect conversant duration eye contact argyle cook 
common variable eye behavior interest 
eyes scan objects interest longer glances 
looking picture person viewers look saccade mainly eyes time mouth remaining regions face scanned just time argyle cook 
eye contact eye contact important non verbal process establish relationship communicate 
depending situation eye contact avoidance variously interpreted argyle cook 

plays important role social encounters process information seek send establish synchronize conversation argyle cook 

linked intonation 
keep control communication process duncan 

follows rules head movements speaking turns 
speak eye contact temporarily broken re established signal turn speak duncan 
eye blinks eye blinks occur quite frequently 
serve accentuate speech wet eye 
normally eye blink utterance 
study consider types blinks periodic blinks keep eyes wet 
average appear sec 
sec sec 
closure time sec 
closed eyes sec 
opening time argyle cook 
period occurrence affect dependent collier table 
voluntary blinks serve emphasize speech accentuate word mark pause ekman 
synchronized word syllable level condon 
blink considered conversational signal occurs accented word occurs pause 
intonation intonational melody utterance viewed conveying partial information kinds 
information syntax semantics utterance hirschberg pierrehumbert pierrehumbert hirschberg 
claim halliday isard pearson prevost steedman appear information includes markers questioning stating speech acts markers discourse information including topic theme comment rheme focus new information background information 
second kind information affecting intonation prosody affect attitude involuntary aspects speaker speech scherer 
third information concerns conversational attitudes speaker stand speaker takes listener irony may directly signaled implied 
conversational attitudes may include conscious manipulation markers calm anger current research considering manipulations 
vocal parameters close relation syntax semantics sentences suprasegmental features suggested steedman 
claims suprasegmental features systematically related discourse information units corresponding topic theme discourse segment comment rheme novel information utterance supplies 
listeners may detect speaker affect prosodic features cahn 
affects differentiated mainly pitch frequency physical property sound pitch subjective loudness perceived intensity sound pitch contour global envelope pitch tempo rate speech pause cahn 
notational system notation intonation contours derived pierrehumbert pierrehumbert 
follow pierrehumbert hirschberg prevost steedman appear assuming different intonational tunes convey various discourse related distinctions focus contrast propositional attitude 
categories defined prevost steedman appear 
intonation contours serve indicate way current utterance relates context established previous ones example may mark continuation topic theme new 
represent informally decomposition utterance prosodic phrases brackets see 
appropriate intonational bracketing determined context utterance produced basis speaker regards topic theme utterance considers requiring contrast opposed background information 
bracketing partially reflected intonation 
consider sentence julia prefers popcorn example related discussed steedman 
context know harry prefers potato chips julia prefer 
bracketing julia prefers popcorn 
accent lh ll tune annotated formally pierrehumbert notation denote high low tones combine various pitch accents boundary tones 
different kinds pitch accent lh ll boundaries phrasal boundary tones 
bracketing sentence placement pauses accents type accents vary context 
consequently facial conversational signals associated utterance differ 
system provides case intonation structure apparently departs traditional surface structure 
speech generation component system information intonation structure ibis system prevost steedman prevost steedman prevost steedman appear exploits novel flexible approach syntax semantics categorial grammar produce apparently appropriate intonation contours spoken responses database queries 
underlying property important property linking intonation facial expression fact extends gesture body movement general lies existence synchrony condon takeuchi magnenat thalmann thalmann 
face body move random concert flow speech 
changes body posture orientation occurs new topic conversation 
similarly facial movement synchronized phoneme level blink word level eyebrow movement condon 
synchrony implies changes occurring speech body movements appear time 
facial synchrony integrated body synchrony scheme extension property 
basic principle regulates computations facial animation system 
justine cassell system related assumptions synchrony extended manual gesture cassell 
description system sections describe system detail 
input assumptions input program file containing utterance decomposed written phonological representation accents marked bracketed elements 
say sidestep entire issue recognition leaving integration speech input 
automatically finding bracketing intonational structure sentence far simple problem silverman 
original reported pelachaud recorded natural speech guide animation 
phase recording sentence timing phoneme pause extracted spectrogram 
query answering program including sentence generation bell labs speech synthesizer automate determination parameters phoneme timing cassell 
file user specifies desired parameters intensity number minimum intensity maximum intensity see appendix 
levels description represented input 
segmental level sentence specified hand generation program list strings corresponding phonetic representation utterance notation compatible notation dec 
pauses acting silence syntactic markers comma period included 
segment pause followed duration expressed seconds 
suprasegmental level word characterized function word article pronoun content word noun verb 
modality utterance declarative interrogative noted boundary marker 
linguistic level accents bracketing utterance defined 
pierrehumbert notation types markers pitch accent phrasal boundary tones 
utterance decomposed intermediate intonational phrases 
consider example introduced section represented intonational phrase jj pitch accent uw ll yy aa pp rr ah ff phrasal tone boundary tone er zz intonational phrase intonational phrase pp pitch accent ao pp kk phrasal tone boundary tone nn intonational phrase phase representation derived entirely rules output generation program synthesizer prevost steedman prevost steedman appear 
organization rules computation facial expressions corresponding determinant conversational signal regulator manipulator entirely rule parameters define action type time occurrence 
adults children systems facial expression ekman 
focus adult model 
rationale allow user modify parameters action touching variable system 
important actions performed person talking may vary 
people show eyebrow movements accentuate word facial actions may chosen nose eye flashes ekman 
user just needs modify rules describe type facial action need alter rules occurrence facial action 
unknown parameter frequency occurrence action ekman 
feature accompanied facial movement accented word accompanied eyebrow movement example 
need access timing occurrence action 
rule involves level 
rules defining lip shapes phoneme level rules related conversational signals word level 
signal computed scanning utterance word word phoneme phoneme 
hand rules expressing affect alter entire utterance 
affect expressed variation parameters modify type placement accents relative words utterance bolinger 
important property allows decomposition aus various facial patterns corresponding affect accents vocal parameters simultaneous additive combination facial actions 
intonational pattern compute corresponding facial actions defined set rules final occurrences types affect dependent 
facial actions conversational signals intensity proportional appearance follows voice pattern 
compute intensity facial expression proportion speech rate 
define constants action minimal maximal 
actual value linear function speech rate constants intensity au minimum au speech rate maximum au speech rate 
noted rules occurrence facial actions may appear arbitrary 
lack information defined rules 
chose intuitively sad person shows hesitation speech uses pauses extrapolate blinks sadness occur frequently pauses 
example facial actions occurring accents define term accent corresponding accent utterances choice follows results movements happen utterance 
new empirical results provide additional data rules refined reflect knowledge 
algorithm read input file contains affect intensity phonemes timing intonational structure fig 

step computation lip shapes involves finding set phoneme clusters depending visual accuracy speech rate applying coarticulation rules 
specified affect corresponds facial expression set aus serves base facial actions combined 
conversational signals computed 
parameters facial expressions type time occurrence computed respect affect 
lists aus added defining affect lip shapes 
computed action follows principle synchrony 
periodic blink added 
stage study consider blinking manipulator determinant 
regulators mainly characterized head eye motions 
final list aus phoneme pause obtained computation corresponding facial expressions performed steve platt program platt 
script files describing animation saved animation played jack badler human animation software system developed university pennsylvania 
visual accuracy defined lighting conditions visibility conditions speaker lip barley 
read input file retrieval rules intonational pattern conversational lip shape manipulator signal regulator coarticulation rules selection parameters selection personal parameters add final sequence au final animation consider display rules determinants algorithm main program 
determinants shown parallel paths input parameters 
example outlining procedure algorithm example clarify process 
consider utterance julia prefers popcorn parameter disgust see section detailed input description 
examples involving affect timings derived hand read speech 
lip shapes automatically computed phoneme 
phonemes grouped clusters depending lip shapes see section 
fig 
depicts lip shapes word popcorn case fast slow speech rate fast speech rate intensity lip shape actions decrease case deformable segments associated lip shapes lose characteristic shape 
algorithm uses value speech rate clustering phonemes depends parameter 
example lips open fast speech rate 
program checks string belongs deformable cluster clusters containing 
strings applies forward backward coarticulation rules 
case considered item receives list aus vowel rules 
phoneme ll word julia receives list aus lower intensity preceding vowel uw 
uw belongs malleable cluster yy 
algorithm applies backward rule ll fig 

step considers environment speech posture surrounding phonemes relaxation contraction times 
result lip shapes computed stages algorithm automatically modified 
modification occurs addition new aus computed previous steps reduction intensity level aus mentioned list 
phoneme yy julia program adds effect phonemes uw ll 
lip shapes ll time relax completely position extended lip shapes effect remains program applied temporal control 
hand position item ao syllable pop altered due surrounding lip closures pp program applied spatial control 
part program lip shapes computed 
program continues goes procedures compute remaining facial movements 
remaining steps program fast speech rate corresponds syllables sec 
slow speech rate corresponds syllables sec 
comparison lip shapes popcorn fast slow speech rate lip shapes julia prefers popcorn slow speech rate affect gives orientation head 
list aus affect computed added list aus item utterance tables 
conversational signals appear example pitch accents various forms ekman 
eyebrow movements coincide actions stressed syllables 
rapid movements actual position head characterize head motion pitch accent 
blinks acting conversational signals start accented syllables synchronized phoneme level 
specification affect disgust facial action intonational phrases juncture pause utterance considered see appendix 
blink mark pause 
blink begins finishes time pause 
utterance statement speaker state signal speaker looks away listener emitted head positioned look speaker reaches sentence 
sentence finishes slow head movement coming rest 
step look periodic blinks needed 
case needed computed blinks occur sufficient rate 
facial expressions item utterance computing platt program platt 
script files output 
animation done jack software badler 
summarizes sequence coordinated expressions 
details determinant far main steps algorithm 
show determinants detail 
lip shape conventional cel animation resolves problem lip synchronization defining set mouth shapes timing speech 
techniques consider small number stereotyped speech postures produce animation including computer graphics 
produce realistic animations technique requires skilled animator considerable investment time manual effort 
systems parke lewis parke magnenat thalmann thalmann hill offer higher level parameterization model 
parameters grouped represent mouth shape phoneme 
user needs phoneme level low level facial parameters 
technique drawbacks due lack biological considerations 
techniques barley offer tool interpret lip facial movements help hearing impaired understand speech 
clustering visible speech facial expression enhances speech perception 
coordination facial movements example julia prefers popcorn cluster slow speech rate fast speech rate context list aus context list aus au au iy ih ix prec 
wh ww au ey exr ah prec 
wh ww au prec 
wh ww au eh ae aa axr prev 
wh ww au prec 
wh ww au prec 
wh ww au au furrow au lip corner au chin raiser au lip au lips part au lip table example rules compute lip shapes techniques phonemes grouped way lip shape corresponds cluster called visemes benoit 
viseme groups may ranked deformable group cluster deformable context dependent cluster barley 
clustering speech rate dependent see table 
person speaking fast moves lips person talking slowly 
decided technique reliability describing visible lip movements 
example rules table 
intonation utterance sequence accented non accented segments 
accented vowel differentiated acoustically remaining part utterance longer duration increased loudness visually jaw dropping motion characteristic accented emphasized segments 
shall draw observations specifying articulatory aus 
coarticulation problem phonemic notation tell deal difficult problem coarticulation 
coarticulation arises temporal overlap articulatory actions realized successive phonemic segments production 
realization consonant may affected anticipation vowel example read rat articulatory acoustically different 
similarly effect vowel may influence succeeding consonant example rat looks sounds different complete 
simple solution problem coarticulation look previous current segments determine mouth positions waters 
cases correct position depend segments current kent 
rules look context phoneme production compute adequate lip positions kent cohen massaro 
completely satisfactory set rules solving coarticulation problem exist 
view lip movements corresponding speech sequence key positions corresponding phonemes belonging non deformable clusters transition positions corresponding phonemes belonging deformable clusters 
problem shape computation transition position 
implemented look ahead model 
model predicts articulatory adjustment starts just key position lasts 
transition position receives shape strongest key position strongest meaning lip shapes belonging deformable clusters 
rules considered forward backward rules 
consider articulatory adjustment sequence consonants followed preceded vowel kent 
forward coarticulation arises sequence consonants belonging low deformable clusters cluster followed vowel showing articulatory adjustment 
respectively backward coarticulation arises sequence consonants belonging low deformable clusters cluster preceded vowel showing articulatory adjustment cited section julia receives lip shape 
name scaling factor au au au au deformation high deformation au lip au lip table scaling factors aus lips show influence vowel consonant sequence 
sequence french example taken structure cited kent influence shown forward rule 
solve particular problems certain visual transitions segments solved rules consider step algorithm 
step coarticulation rules applied clusters defined context dependent 
step considers relaxation contraction time muscle 
look way consecutive actions performed 
speech physical context considered yield physically model 
section give example effects coarticulation rules 
segment belonging highly deformable cluster algorithm fig 
looks backward forward vowel member lower deformable cluster consideration word boundaries 
considered segment take lip shape vowel 
method ensures segment coarticulation rules applies low deformable vowel type shape 
see example section 
computation check current speech posture time contract previous speech posture respectively relax 
time consecutive articulatory configurations smaller contraction time muscle bourne previous speech posture influenced contraction current 
similar manner time consecutive speech postures smaller relaxation time current segment influence segment relaxing 
articulatory adjustments continue pause existing just considered word foreseen pause just word 
influences computed simulating muscular contraction relaxation properties third degree polynomial curves pelachaud 
take account geometric relationship successive actions 
lip closure easily performed slightly position position 
intensity action rescaled depending surrounding context cluster belongs table 
steps obtain list aus speech posture 
constraints adjacent defined constant easily changed relaxation contraction simulation 
lip shapes associated speech posture determined rules easily modified 
preliminary approach solving problem correlating acoustic visual appearance phoneme consider relaxation contraction muscle notion appearance disappearance lip actions 
approach may eventually provide tool phoneticians study coarticulation problems 
conversational signals stressed element accompanied particular movement accumulation rapid movements pronounced mouth position blinks rapid head movements 
brow actions frequently conversational signals ekman 
accentuate word emphasize sequence words 
accented words actions may vary type pitch accent 
user possibility choose type parameter defining facial action 
final manifestation actions affect dependent table 
blink occurrence conversational signals affect dependent table 
algorithm lip shape segment computed apply lip movement rules forward backward rules apply find vowel compute list aus intensity phoneme emphasized accented increase intensity au apply spatial temporal constraint algorithm lip shapes computation coarticulation rules phoneme phoneme accented affect dependent occurrence find action compute onset apex offset movement algorithm eyebrow actions program parses sentence looks possible movement occurrences considering current affect 
facial movement appears stressed word emphasis program computes onset time appearance offset time disappearance actions depending speech rate fig 

speech rate slow movement start syllable word 
knowing location time actions points fig 
program computes apex time maintenance action 
find starting point apex looks closest phoneme duration starting point action equal onset value 
find point apex 
scans sentence backward look phoneme duration action equal offset value 
notice points defining apex vary chosen affect affect different onset offset values 
program computes blinks occurring conversational signals fig 

internal structure eye blink closure time time remains closed time aperture synchronized articulation condon 
find timing program parses utterance looks phonemes closest timing average speed eye blink 
occurring accent fast speech rate blink starts word closes accented phoneme 
slow speech rate starting point syllable closing time remains 
head movements computed depending type accents 
program scans utterance assigns computation onset apex offset add blink accent final occurrence affect dependent blink close accented syllable blink start depend speech rate find parameters algorithm voluntary blinks occurring accents pitch accent phrase tone boundary tone emphasis rm rapid movement om ordinary movement sm slow movement rm rapid movement table head movements accented segments corresponding head movements considered segments table 
boundary point comma underlined slow movement final pause coincides 
occurring hesitation pause type accent varies affect table 
type varies type pause 
question indicated raised eyebrows especially question verbalized period marked 
algorithm action occurs pause starting points apex coincide pause 
values movement onset offset computed conversational signals fig 

blinks occurring pause table start pause time blinks performed blinks synchronized word pause fig 

program computes head movements 
type pause movement type assigned table 
program runs utterance computes corresponding head action pause 
regulators regulators correspond mainly head eye movements 
fig 
gives algorithm 
utterance question head turn listener speaker turn signal raise utterance table 
utterance statement head look away listener speaker state signal look utterance 
speaker turn appears intonational clauses pause compute aus depending affect action occurs affect action pause compute onset apex offset movement algorithm eyebrow actions final occurrence affect dependent blink start pause find parameters algorithm voluntary blinks occurring pauses fluent pause hesitation pause silence rm om om followed sm direction table head movements pauses belonging sentence 
speaker turn speaker turns head listener normally followed speaker continuation turn turns head away listener 
utterance followed utterance speaker turn occurs 
program scans utterance computes potential head movements 
movement specified phonemic items head forced go back starting position om insure head stability 
step computes various timings head movements 
second step find direction motion 
rm associated vertical motion head direction changed cycle previous cycle current vice versa 
cycle corresponds phonemic segment slow speech rate syllable fast speech rate 
types head motion sideways motions 
direction sustained particular motion inverted motion 
phoneme final head position obtained adding occurring stressed element occurs speaker state signal head nod turning away listener 
motions coincide corresponding supra segmental parameters coexist 
program applies adjustment occurring actions fashion spatial constraints lip shapes 
computation specific unique pattern clause 
note case successive utterances having common certain features intonational tunes part topic share type head motion 
second part computation regulators eye motion 
approach decided implement simple simulation eye movements fig 

assume action occurs mutual gaze breaking eye contact head eyes follow behavior 
means interpret eye position head position 
compute constant head values find general direction affect apply head rule head motion specified add om gap compute final head direction apply attenuation rules consider occurrent head actions algorithm head motion speaker state signal speaker turn speaker continuation signal pos word phrase pos pause pos word direction away direction direction away head turned far center position find random point listener face compute eye direction clip eye angles table summary turn system algorithm eye movements eyes follow head motion action occurring eyes scan saccadic motion listener face random way time spent eyes mouth 
eyes forced follow head motion head position passed certain angle 
pupil changes occur experiences 
pupil dilation followed pupil constriction happiness anger remains dilated fear sadness hess 
depending affect eye openness varies 
surprise fear eyes wide open partially closed sadness disgust happiness collier table 
gaze patterns mutual gaze gaze avoidance imply existence listener partner 
scope study 
eye movements linked directly speech example due external event considered 
manipulators currently consider blinks manipulators 
blinks occur periodically 
having computed blinks appearing accents pauses program adds necessary ones fig 

looks phoneme duration blink closest period blink occurrence 
remaining parts blink computed voluntary blinks 
time elapsed consecutive blinks period add blink blink start phoneme timing blink equal blink period find parameters algorithm periodic blinks speech rate fred wan tt ih dd slow forward rule cluster back backward rule 

fast forward rule change cluster backward rule 

speech rate try prod yu ss ax play slow cluster forward rule narrow 
fast cluster forward rule forward rule 


examples table variations speech rate lip shapes examples run basis measurements read speech rule synthesis 
consider utterance fred wanted try produce play sentence recorded various speech rates fast slow different intonational patterns affects 
sections analyze variations affect final animation 
choose affects specification facial expressions parameters system appendix values intended representative affect demonstrate system 
variation speech rate see speech rate parameter affects computation lip shapes 
affect neutral 
intonational pattern fred wanted try produce play 
ll table summarizes lip shapes slow fast speech rate 
results different examples 
speech postures differ intensity actions 
slow speech rate intensity higher mouth time perform movement 
speech postures differ list aus table 
slow speech rate segment ih characteristic shape extension lip corners occurring au au slight opening mouth visible au 
lips extend outer part lips apparent performed au 
fast speech rate fewer different cluster fact gather type moderate opening mouth performed au 
table notice forward rule applied word boundaries kent segment ax word receives list aus segment yu previous word 
variations intonational pattern vary type placement accents utterance intonational boundaries 
affect neutral examples considered 
look determinants facial expressions conversational signals vary intonation 
consider contexts utterance determining different partitions discourse information sentence 
context fred ww aa nn tt ih dd onset apex offset onset apex context try produce silence play fluent pause offset onset apex apex apex offset table variations eyebrow movements depending context context question fred try produce play 
answer fred wanted try produce play 
accent ll context question fred try produce play movie 
answer fred wanted try produce play 
accent ll answer context pronounced slow speech rate fast speech rate context 
context pause appears words play 
context table program outputs eyebrow raise au au accented syllable word wanted 
movement continues decreasing intensity segments 
timing succeeding segments offset 
context speech rate fast eyebrow action occurs word 
movement propagated segment word 
pause words play coincides eyebrow action 
movement 
followed conversational signal accented segment fluent pause movement eyebrows continues word utterance 
notice examples differ number brow movements occurring word play pause occurring words play context time action lasts relative speech rate 
similar considerations apply head eye motions blink occurrence 
variations parameters section examine parameters vary occurrence facial action 
context utterances working identical intonational patterns 
affect fred wanted try produce pause pause play pause anger au au au disgust au au au fear au au au happiness au au au sadness au surprise au au au au inner brow raiser au outer brow raiser au brow table conversational signals occurrences affect question know fred ended trying produce movie 
fred want try produce 
answer fred wanted try produce play 
accent lh ll parameter existing pauses spoken utterance table list aus corresponding type pauses computed table 
program computes constants defining onset offset movement constants specific head motion 
sadness affect low values head motion head moves little slowly 
happiness opposite 
movements appear disappear abruptly affect anger fear smoothly sadness 
final appearance conversational signals affect dependent table 
facial expressions associated vary affect part characteristic expression affect 
features system order able refine rules occurrence facial actions parameter set interactive 
lack empirical information accent intonational components accompanied facial action 
user specify type relative time occurrence facial action apex onset offset values pelachaud 
context affect associated particular facial expression 
may cultural variability cultures forbid direct gaze find gaze aversion cultures acted masked smile 
display rules ekman refer problem show affect 
taken consideration automatic procedures difficult handle little information available 
may affect expression various ways 
amplify de amplify expression ekman may blend expressions may masked facial expressions 
user simulate effects different functions 
amplify de amplify affect intensity facial changes 
blend done summing effects 
masking expression affects timing parameters features remain pelachaud 
seen gaze behavior plays great role communication settings cultural differences amount gaze allowed social encounter harper 
gaze establish power relationships act signal liking argyle cook 
personality context parameters visual pattern 
submissive person frequently breaks eye contact dominant 
dialog situation listener moves synchrony speaker condon 
obtain refinement computation eye movements add regulator group auditor feedback determinant duncan consider various parameters maximum gaze length percentage mutual gaze cassell 
extension system integration emotional ekman 
ones expressed employing parts corresponding affect refer ones replace repeat verbal elements 
time intentional deliberate actions communicate 
general produced consciously driven semantics utterance 

encoding decoding share lot appearances meanings ekman 
discourse driven appearance entered user 
done creating library possible efron gives large list efron ekman proposes set words corresponding 
user build add library pelachaud 
lying timing expression changes 
expression may appear early late fast slow 
having access value onset apex offset action modify order simulate lies 
considering tongue movement lip shapes computed helps unambiguous obscure movements phonemic segments speech postures differentiated tongue motions barley kent pelachaud 
proposed method characterizing facial movements separating phonemic intonational informational determinants 
believe previous computational model taken account factors 
separately computing determinant facial expressions offers better control facial animation 
particularly interested facial actions speech meaning type time occurrence 
important factor lip movement notion coarticulation temporal spatial constraints muscle actions considered 
coordination various facial motions intonation done completely automatically rule 
method allows define various individualized speaker characteristics specifying particular sets type timing parameters facial actions calvert ekman takeuchi 
examples determined measurement real speech reported somewhat narrower range examples generated entirely rule machine generated semantic representations speech synthesizer cassell prevost steedman prevost steedman appear 
model expected help research human communicative faculties automatically synthesized animation 
particular offers linguists cognitive scientists tool analyze manipulate integrate different determinants communication 
program allows user switch determinant function information provides analyzed 
expect mean refine simplified theory discourse information assumed 
providing model coarticulation hope program may eventually help enhance techniques providing hearing impaired persons controllable animation capable demonstrating various effects phoneme speech rate surrounding context 
acknowledgments steve platt facial model useful comments 
improved facial model 
grateful jean griffin francisco mike edwards developed part animation software 
related voice synthesizer speech intonation done scott prevost 
grateful 
members graphics laboratory especially cary phillips zhao helpful comments 
research partially supported nsf iri cise cda ili aro ai center excellence university pennsylvania daal 
appendices example lip shapes run program twice coarticulation rules 
case slow 
results string pref prefers julia prefers popcorn see fig 
coarticulation rules applied name sentence pp name au au intensity name au au intensity name sentence rr name au au intensity name au au intensity name au au intensity name au au intensity name sentence ah name au au intensity name au au intensity name au au intensity name au au intensity name sentence ff name au au intensity name au au intensity coarticulation rules applied name sentence pp name au au intensity name au au intensity name sentence rr name au au intensity name au au intensity name au au intensity name au au intensity name au au intensity name au au intensity name sentence ah name au au intensity name au au intensity name au au intensity name au au intensity name au au intensity name au au intensity name au au intensity name sentence ff name au au intensity name au au intensity case rr receives list aus ah due forward rule 
second case coarticulation rules applied results case aus definition table list aus lip shapes pref julia prefers popcorn curves show smoothing effect coarticulation 
facial expressions affects geometrical constraint rules intensities successive antagonist aus decreased 
intensities re adjusted table comparisons aus 
example intensities au au pp go temporal constraint rules rr ah shows remains lip actions pp duration altogether relaxing time muscle lip shape pp propagated ah pronounced 
au au appear rr ah decreasing intensities 
identically au appears ah due contraction time involved ff 
affect modelling affect meaning confined affects characteristically displayed face voice 
body postures indicate essentially intensity affect collier 
happiness recognized smile corners mouth drawn back raised cheeks creating wrinkles eyes 
disgust characterized nose raised upper lip 
affects anger disgust fear happiness sadness surprise claimed universal facial expressions ekman corresponding prototypes fig 

chosen study 
person may feel affect different strength 
affect felt lightly facial movement corresponding affect visibly displayed just minimum requirement appear little action case high intensity facial expression affect extreme 
intensity affect important parameter reflected system 
extent expressions voluntary control resemble speech acts 
speech acts indirectly 
leave specification parameters animator 
choice rules affects definition affects previous section information stated argyle cook collier ekman established corresponding facial expression affects term set aus eye openness pupil size types movements fig 

sadness active affect shows actions appearing disappearing smoothly face 
hand angry person moves aggressive rapid manner speech facial actions 
amount type movements vary level arousal collier 
example fear varying types action depending intensity affect low high 
fear expressed eyes low intensity intense affect entire face involved 
findings summarized affect tables 
compute intensity facial action affect proportionally intensity affect 
action defined pre established constants minimal maximal 
actual value linear function intensity affect constants intensity au minimum au intensity affect maximum au intensity affect 
possible choose affect belonging basic set considered 
user just needs change set rules defining occurrence facial actions list aus facial expressions chosen affect 
having specified new information program offers procedures compute exact location manner appearance onset offset values facial actions 
example user specify blinks occur type pauses accents actual procedures perform computation 
name list aus eye openness pupil size basic head position active anger au small forward au disgust au backward fear au wide backward low intensity au high int 
happiness au sadness au small downward surprise au wide backward notation active affect corresponding activation level standing number type fast vs slow facial head eye actions shown speaker 
au inner brow raiser au outer brow raiser au brow au upper lid raiser au cheek raiser lid au lid au nose au upper lip raiser au furrow au lip corner au sharp lip au lip corner au lower lip au chin raiser au lip au lip au lip au lips part au jaw drop au lip table occurrence facial actions name conversational signal regulator blink rm blink om st occur 
type pos neutral normal si fl normal fl si raised brow normal anger fl fl disgust si fl fl si nose fear si si brow fear happiness si fl fl smile sadness si fl surprise si fl fl raised brow pauses classified function fl fluent pause occurs boundary points hesitation pause corresponds false start word finding problem si specified silence marked speaker pos rm om sm head movements see explanation table occurrence accented segment occurrence accented segment utterance table occurrence facial actions head movement anger disgust fear happiness sadness surprise pos rm om sm table scaling factors compute head movements affect anger disgust fear happiness sadness surprise shorter change shorter shorter longer change table period occurrence blinks neutral anger disgust fear happiness sadness surprise accent emphasis table occurrence blinks conversational signal affect au neutral au anger au disgust au fear au happiness au sadness au surprise au table aus occurring pauses affect fred wanted try produce play anger silence fluent pause disgust silence fluent pause fear fluent pause fluent pause happiness fluent pause sadness fluent pause fluent pause surprise fluent pause fluent pause examples table occurrence pauses affect sentence fred wanted try produce play recorded indicated authors affects anger disgust fear happiness sadness surprise 
spoken utterance extracted timing including pauses 
table gathers values 
argyle cook argyle cook 

gaze mutual gaze 
cambridge university press 
badler badler phillips webber 

simulating humans computer graphics animation control 
oxford university press 
benoit benoit abry 

nineteen french visemes visual speech synthesis 
proceedings esca workshop speech synthesis 
esca 
bolinger bolinger 

intonation part 
stanford university press 
bourne bourne 

structure function muscle volume iii physiology biochemistry 
academic press second edition edition 


computer graphics synthesis talking faces 
proceedings esca workshop speech synthesis 
esca 
cahn cahn 

generating expression synthesized speech 
master thesis massachusetts institute technology cambridge massachusetts 
calvert calvert 

composition realistic animation sequences multiple human figures 
badler barsky zeltzer editors making move mechanics control animation articulated figures 
morgan kaufmann publishers cassell cassell pelachaud badler steedman becket douville prevost stone 

animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents 
computer annual conferences series pages 


visual perception anticipatory rounding acoustic pauses cross language study 
proceedings international congress phonetic sciences pages aix en provence france 
cohen massaro cohen massaro 

modeling coarticulation synthetic visual speech 
magnenat thalmann thalmann editors computer animation 
springer verlag 
collier collier 

emotional expression 
lawrence erlbaum associates 
condon condon 

speech body motion synchrony speaker hearer 
horton jenkins editors perception language pages 
academic press 
dec 
dtc text speech system owner digital equipment 


body movement speech rhythm relationship cue speech encoding 
editor nonverbal communication 
oxford university press 
duncan duncan 

signals rules speaking turns conversations 
editor nonverbal communication 
oxford university press 
efron efron 

gesture race culture 
hague mouton 
ekman ekman 

movements precise meanings 
journal communication 
ekman ekman 

brows emotional conversational signals 
von editors human ethology claims limits new contributions colloquium pages 
cambridge university press cambridge england new york 
ekman friesen ekman friesen 

facial action coding system 
consulting psychologists press 

digital portfolio tony de 
computer graphics world 
essa pentland essa pentland 

vision system observing extracting facial action parameters 
proceedings computer vision pattern recognition cvpr pages 
steiner rose 

kinematics head movements accompanying speech conversation 
human movement science 
halliday halliday 

intonation grammar british english 
mouton hague 
harper harper 

nonverbal communication state art 
wiley sons new york 
hess hess 

role pupil size communication 
scientific american pages 
hill hill pearce wyvill 

animating speech automated approach speech synthesised rules 
visual computer 
hirschberg pierrehumbert hirschberg pierrehumbert 

intonational structuring discourse 
th annual meeting association computational linguistics pages 
isard pearson isard pearson 

repertoire british english intonation contours synthetic speech 
proceedings speech th fase symposium pages edinburgh 
barley barley 

lipreading 
thomas 
magnenat thalmann thalmann 

smile multilayered facial animation system 
kunii editor modeling computer graphics 
springer verlag 
kent kent 

coarticulation speech production models 
journal phonetics 

president 
acm siggraph film video show issue 
construction kurihara arai kurihara arai 

transformation method modeling animation human face photographs 
magnenat thalmann thalmann editors computer animation pages 
springer verlag 
lewis parke lewis parke 

automated lip synch speech synthesis character animation 
chi gi pages 
magnenat thalmann thalmann magnenat thalmann thalmann 

direction synthetic actors film rendez vous montr ieee computer graphics applications pages 


high level approach animating secondary human movement 
master thesis school computing science simon fraser university 


animation spline figures 
visual computer 
parke parke 

parametrized models facial animation 
ieee computer graphics applications 
pelachaud pelachaud 

communication coarticulation facial animation 
phd thesis computer information science department university pennsylvania philadelphia pennsylvania 
pelachaud pelachaud 

consideration facial audio channels facial animation system 
scan philadelphia 
pelachaud pelachaud badler steedman 

linguistic issues facial animation 
magnenat thalmann thalmann editors computer animation pages 
springer verlag 
pelachaud pelachaud badler 

final report nsf standards facial animation workshop 
technical report nsf university pennsylvania 
pelachaud pelachaud van seah 

modeling animating human tongue speech production 
magnenat thalmann thalmann editors computer animation 
springer verlag 
pelachaud pelachaud 

rule structured facial animation system 
ijcai 
pierrehumbert pierrehumbert 

phonology phonetics english intonation 
phd thesis massachusetts institute technology 
distributed indiana university linguistics club bloomington 
pierrehumbert hirschberg pierrehumbert hirschberg 

meaning intonational contours interpretation discourse 
cohen morgan pollack editors intentions communication pages 
mit press cambridge ma 
platt platt 

structural model human face 
phd thesis computer information science department university pennsylvania philadelphia pennsylvania 
prevost steedman prevost steedman 

information intonation synthesis 
proceedings arpa workshop human language technology princeton 
prevost steedman appear prevost steedman 
appear 
specifying intonation context speech synthesis 
speech communication 
scherer scherer ladd silverman 

vocal cues speaker affect testing models 
journal acoustical society america 


phonology syntax 
mit press cambridge ma 
silverman silverman 

structure processing fundamental frequency contours 
phd thesis university cambridge 
steedman steedman 

structure intonation 
language 
terzopoulos waters terzopoulos waters 

techniques realistic facial modelling animation 
magnenat thalmann thalmann editors computer animation pages 
springer verlag 
takeuchi takeuchi 

generation human motion emotion 
magnenat thalmann thalmann editors computer animation pages 
springer verlag 


facial animation wrinkles 
nd workshop animation eurographics cambridge 
waters waters 

muscle model animating dimensional facial expression 
computer graphics 
williams williams 

performance driven facial animation 
computer graphics 

