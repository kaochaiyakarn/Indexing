automating survey coding multiclass text categorization techniques daniela istituto di linguistica consiglio nazionale delle ricerche pisa italy mail daniela ilc cnr fabrizio sebastiani istituto di dell informazione consiglio nazionale delle ricerche pisa italy mail fabrizio sebastiani cnr survey coding task assigning symbolic code predefined set codes answer response open ended question questionnaire aka survey 
task usually carried order group respondents predefined scheme answers 
survey coding applications especially social sciences ranging simple classification respondents extraction statistics political opinions health lifestyle habits customer satisfaction brand fidelity patient satisfaction 
survey coding difficult task code attributed respondent answer matter subjective judgment requires expertise 
unsurprising task traditionally performed manually trained coders 
attempts automating task detecting similarity answer textual descriptions meanings candidate codes 
take radically new stand formulate problem automated survey coding text categorization problem problem learning means supervised machine learning techniques model association answers codes training set pre coded answers applying resulting model classification new answers 
experiment different learning techniques na bayesian classification multiclass support vector machines test resulting framework corpus social surveys 
results obtained significantly outperform results achieved previous automated survey coding approaches 
survey coding task assigning symbolic code predefined set codes textual expression representing answer response open ended question questionnaire aka survey 
open ended mean question requires allows answer consisting free text open ended questions alternative multiple choice questions require answer selected predefined set deal text written form 
implications coding survey material audio form discussed section 
survey coding usually carried order classify responses respondents category scheme superimposing structure totally unstructured corpus different responses 
survey coding applications especially social sciences classification respondents functional extraction statistics political opinions health lifestyle habits customer satisfaction brand fidelity patient satisfaction 
example asked question carefully chosen sample subjects framework general social survey carried national opinion research center past month think time felt really angry annoyed 
describe couple sentences feel way situation 
professional coders asked classify answers exactly categories consisting code short situation involved situation involved family situation involved government government officials fam situation involved family gvt situation involved government fam gvt situation involved family government situation fit categories answers included example trying teach son stubborn wouldn listen got angry wife went shopping spent dress feel angry coders classified header 
survey coding difficult task code attributed answer matter subjective interpretation requires expertise 
instance different coders especially little trained different opinions answer people authorities treating people right classified gvt authorities respondent refer authorities government include hierarchically superordinate colleagues 
include authorities public institutions government 
difficulty unsurprising task traditionally performed manually professional coders 
survey coding expensive task reason social scientists professionals charge designing administering surveys tend avoid including open ended questions surveys tend rely expensive multiple choice questions definition require coding phase hand strictly limit respondents possible answers 
attempts past automating survey coding task 
exploited simple techniques tradition text retrieval matching detecting www uchicago edu real answers coders versions handwritten notes taken 
consequence answers shorthands syntactic point view ill formed sentences 
similarity answer textual descriptions meanings candidate codes 
take radically new stand formulate problem automated survey coding multiclass text categorization problem problem learning means supervised learning techniques model association answers codes training set manually pre coded answers applying resulting model classification new answers exactly predefined codes 
experiment different supervised learning techniques na bayesian classification multiclass support vector machines test resulting framework corpus social surveys conducted :10.1.1.11.8264
results obtain significantly outperform results achieved previous automated survey coding approaches 
structured follows 
section introduces survey coding reviews related attempting automate task 
section gives brief text categorization methodology main techniques 
section describe survey coding task framed multiclass text categorization problem describe tools outlined section effectively 
section illustrates experiments performed application na bayesian classification support vector machines problem coding corpus social surveys collected 
section concludes commenting results discussing possible avenues research 
survey coding automation general point view survey analysis shares aspects general framework text analysis social sciences quantitative methods requiring measurement frequency qualitative methods requiring measurement applied study text corpora representative sample population order infer properties population 
alexa describes various issues involved computer assisted analysis text social sciences alexa ll review commercial research software packages designed tasks 
deal general problem text analysis social sciences involves phases text import export management exploration plus dictionary classification scheme construction just focus coding task survey analysis process 
survey coding may viewed task identifying common meaningful concepts different responses set questions 
task may come variants depending concepts sought known advance case task really consists checking concept text analysis case novel unforeseen concepts may discovered text analyzed 
concentrate variant common simple reason surveys usually run clear purpose clear set previously identified concepts presence text corpus assessed measured way 
process mapping responses codes slow expensive lot manual effort different professional figures involved 
example take handwritten notes answers returned interview produce text notes stage text analyzed professional coders perform final coding task 
drawback process produce faulty encodings potential sources error may misunderstand answers notes may misunderstand handwritten notes introduce typing errors coders may misinterpret meaning answers codes 
automated approach currently deals phase coding transcript data ignoring errors possibly introduced previous steps better approach code hand data data automatically transcribed directly speech see section discussion 
problem survey coding called inter coder agreement problem fact different coders may classify data different ways simply different opinions meaning answer code 
note problem affect manually performed survey coding may expect different automated methods differ decisions text analysis social sciences important issue software packages address developed 
usually tailored specific task survey analysis solutions provide survey coding task unsatisfactory 
software packages see review concentrate helping coders coding data manually visualizing convenient ways 
packages perform automatic coding relying mainly specialized dictionaries rules 
means text fragments automatically assigned specific category contain words matching dictionary relevant category 
disadvantages approach dictionaries created coding process begins data totally unknown approach extremely static 
second drawback specialized dictionaries need developed category interest requires intervention expert personnel responsible deciding words combination absent answer trigger attribution code answer 
expert personnel re intervene new category added scheme dictionary created new category dictionaries old categories need updated order avoid capturing answers filed newly introduced category 
scientific literature automating survey coding scarce 
dillon reports doing automatic classification surveys grouping questions responses respondents groups similarity start predefined set groups generates groups scratch means uses unsupervised learning clustering supervised learning 
researchers concentrated related issue grading responses open ended questions answered students school essays :10.1.1.42.8449
task deals concerns different addressed survey coding student essays graded quality merit surveys coded topic relatedness 
approach closest spirit probably dictionary approach described 
responses questions general social survey classified means set codes predefined social scientists 
proposes alternative approaches 
words characterize category combined means boolean operators answer classified category boolean description matches 
second method computing similarity weighted vectors words extracted answer textual code choosing code highest similarity score 
similarly dictionary automated approach answer assigned unique code exact match phrases belonging previously defined dictionary associated code assigned best code match partial 
approaches typical drawback dictionary methods need dictionary manually developed actual coding step takes place manually updated result changes structure semantics coding scheme 
approach survey coding advantages respect dictionary approach 
firstly learning approach manual effort directed manual coding small training set answers creation specialized dictionaries 
advantageous easier manually classify set documents build tune dictionary words trigger attribution code simple fact easier characterize concept extensionally select instances intensionally describe concept words describe procedure recognizing instances 
secondly inter indexer inconsistency similar phenomenon known information retrieval human experts decide index document dj index term ci may disagree fact happens relatively high frequency 
approach grounded machine learning theory leverage wealth results techniques developed text categorization discipline bursting activity years see produced systems accuracy rivals exceeds human systems capable generating codes correlate attributed coder codes attributed human coders correlate :10.1.1.119.8039
course approach useful medium large sized surveys learning phase need hand coded set answers train inductive learner 
means survey somewhat limited number surveyed people hand coding training set may coincide hand coding entire set 
surveys examples relatively large sized surveys interviews completed years survey general social survey mentioned section administered year year questions asked unmodified year year 
text categorization turn brief text categorization main tool adopt tackle survey coding task 
text categorization known text classification isthe task approximating unknown target function describes documents ought classified means function called classifier predefined set thematic categories domain documents 
dj ci dj called positive example member dj ci called negative example ci 
categories just symbolic labels additional knowledge procedural declarative nature meaning usually available 
usually case metadata publication date document type publication source available classification accomplished basis knowledge extracted documents 
text categorization subjective task experts human artificial decide classify document dj category ci may disagree fact happens relatively high frequency 
news article george bush attending texas game filed politics sport depending subjective judgment expert 
depending application case exactly ci assigned dj number nj categories may assigned dj case usually dubbed binary case multiclass case depending respectively 
case object interest speaking tc mean multiclass tc roughly distinguish different phases life cycle tc system document indexing classifier learning classifier evaluation 
paragraphs devoted phases respectively detailed treatment see sections respectively :10.1.1.119.8039
document indexing document indexing denotes activity mapping document dj compact representation content directly interpreted classifier building algorithm ii classifier built 
document indexing methods usually employed tc borrowed information retrieval ir text dj typically represented vector term weights dj dictionary set terms known features occur documents wkj quantifies importance tk characterizing semantics dj 
typical values 
strange reasons discuss multiclass tc referred single label tc admittedly confusing 
indexing method characterized definition term ii method compute term weights 
concerning frequent choice identify terms words occurring documents exception words topic neutral words articles prepositions eliminated pre processing phase stems morphological roots obtained applying stemming algorithm 
concerning ii statistical probabilistic techniques compute terms weights common option 
popular class statistical term weighting functions tf idf see intuitions play frequently tk occurs dj important dj term frequency intuition documents tk occurs discriminating smaller contribution characterizing semantics document occurs inverse document frequency intuition 
weights computed tf idf techniques normalized contrast tendency tf idf emphasize long documents 
tc ir dimensionality reduction phase applied reduce size document representations smaller predefined number 
effect reducing overfitting tendency classifier better classify data trained new unseen data problem manageable learning method methods known scale high problem sizes 
dimensionality reduction takes form feature selection term scored means scoring function captures degree positive negative correlation ci highest scoring terms document representation 
classifier learning text classifier categories automatically generated general inductive process learner observing characteristics set documents preclassified characteristics new unseen document order belong generic category ci inorder build classifiers needs labelled corpus documents value dj ci isknown dj ci tc customary partition disjoint sets tr training set va validation set te test set 
training set consists documents learner observes build classifier 
validation set set documents engineer uses fine tune classifier choosing parameter classifier depends value yielded best effectiveness evaluated va test set final evaluation classifier effectiveness 
validation test phase evaluating effectiveness means running classifier set preclassified documents te checking degree correspondence output classifier preassigned labels 
called supervised learning activity learning supervised information membership training documents categories 
methods proposed text categorization literature learning text classifier training data see review including probabilistic methods regression methods decision tree decision rule learners neural networks batch incremental learners linear classifiers example methods support vector machines genetic algorithms hidden markov models classifier committees :10.1.1.119.8039
methods generate binary valued classifiers required form generate real valued functions form csv csv standing categorization status value 
set thresholds needs determined typically experimentation validation set allowing turn real valued final binary decisions 
classifier evaluation training efficiency average time required build classifier corpus classification efficiency average time required classify new document means effectiveness average correctness classification behaviour different measures success learner 
effectiveness usually considered important criterion applications willing trade training time classification time correct decisions 
reliable comes comparing different learners efficiency depends volatile parameters different sw hw platforms 
result measure success approach terms effectiveness 
multiclass tc effectiveness usually equated accuracy defined percentage classification decisions correct 
automated survey coding text categorization section describe experiments survey coding handled text categorization task task automatically generating classifier automatically selects set predefined codes correct code attach answer 
survey coding context set answers question play role domain set possible codes may attributed answer question play role set categories coding answers different questions corresponds different tc tasks 
input learners classifiers built consists answer dj represented vector term weights dj weuse value parameter see section 
note fact answers corpus syntactically ill formed see examples section bag words approach representation approach just considers term occurrence frequency occurrence disregarding deeper syntactic semantic aspects appropriate current syntactic semantic analysis techniques proven worthy performing robust time standard tc usually deal syntactically formed text easy conjecture hardly prove worthy 
run series experiments different classifier learning methods 
learner probabilistic na bayesian learner implemented rainbow package probabilistic text classification methods assume data generated parametric model training set estimate parameters model 
bayes theorem allows estimate model probability category generated document classified classification consists selecting category highest probability 
known variants method multi variate bernoulli method multinomial method 
chose comparative text classification experiments performed better 
second learning method multiclass support vector machine svm learner embodied mcsvm package svms attempt learn hyperplane dimensional space separates positive training examples category ci negative ones maximum possible margin minimal distance hyperplane training example maximum results computational learning theory indicate tends minimize generalization error error resulting classifier unseen examples 
svms initially conceived solving binary classification problems adapted multiclass classification 
crammer singer describe algorithmic implementation multiclass svms notion margin generalized multiclass problems allows train directly multiclass classifier previous multiclass problem decomposed multiple independent binary classification tasks :10.1.1.69.8716
regarding effectiveness text categorization literature shown na bayesian approaches respect learning methods average performers see :10.1.1.11.9519:10.1.1.11.6124:10.1.1.161.6020
contrary support vector machines currently rainbow implemented andrew mccallum downloaded www cs cmu edu mccallum rainbow 
mcsvm implemented crammer yoram singer kindly provided pre release version 
boosting classifier committees top performers tc field 
reason experiment rainbow want show text categorization approach survey coding effective dictionary approach regardless specific learning method adopted average performing learning method text categorization approach survey coding outperform dictionary method 
reason experiment mcsvm want show level effectiveness approach achieve instantiated top performing learning algorithm binary representation input rainbow non binary input mcsvm 
due fact probabilistic models rainbow require binary inputs case svms 
binary representation wkj represents just presence absence term tk answer dj 
non binary representation tfidf function standard ltc variant tr tfidf tk dj tf tk dj log tr tk tr tk denotes number answers training set tr tk occurs times log tk dj tk dj tf tk dj tk dj denotes number times tk occurs answer dj 
weights obtained equation normalized cosine normalization yielding wkj tfidf tk dj tfidf ts dj experiments discussed words punctuation numbers removed letters converted lowercase 
feature selection see section performed 
reason shown extensive experiments effectiveness svms usually worsened feature selection irrespectively feature selection algorithm chosen reduction factor independently confirmed results effectiveness na bayesian methods show systematic patterns improvement 
experiments pointed experiments carried data general social survey 
survey ongoing aims investigating people assess physical mental health balancing security civil liberties external internal security threats intergroup relations cultural pluralism religious deal datasets see table general social survey administered 
datasets angry angry consists set answers question plus associated category codes manually chosen professional coders predefined set category codes task consists choosing exactly code answer 
note published results concerning application tc multiclass svms multiclass svms development tc applications binary 
assumption multiclass svms top performer multiclass tc context top performance multiclass svms delivered multiclass application contexts tc :10.1.1.69.8716
angry angry datasets involve question deals description situation caused anger respondent answer classified different sets codes concerning object anger concerning cause anger 
angry contains subset answers contained angry inthe sense coders classified answers angry set codes 
dataset called breakdown consists answers question source help deal nervous breakdown 
dataset category angry gvt fam fam gvt total self prevented angry critical demanding expect total family friend group agency total table characteristics datasets experiments 
chosen datasets datasets means able obtain direct comparison effectiveness method example dictionary approach survey coding effectiveness supervised learning approach 
note datasets include class 
consideration indicates datasets easy classifier simply take guess picking inappropriate category choices sufficiently inappropriate category applies category typically hard category characterized specific terminology case categories strongly characterized topical sense 
presence category category set tends deteriorate global performance text classifier 
dataset main steps went run experiments 
preprocess data order obtain data format compatible learners repeated rainbow mcsvm systems require different input formats 
partition set answers dataset random disjoint subsets equal size 
run learner generate classifier subsets training set fourth test set 
run classifier classify data test set dataset evaluate results 
order achieve better statistical significance experiments steps repeated times possible choices test set 
results report confirmed everybody experience multiple choice tests 
student likes take test choice preceding answers apply 
dictionary supervised learning vector boolean rainbow mcsvm angry angry average std 
dev 
table comparative accuracy results obtained angry angry datasets boolean vector method na bayesian multiclass svm tc method 
percentile improvements accuracy average accuracy percentile reductions standard deviation reported respect boolean method best dictionary method 
boldface indicates best performance dataset 
result averaging different experiments 
computed accuracy datasets rainbow mcsvm results reported table compared accuracy obtained datasets 
observation supervised learning approach survey coding significantly outperforms dictionary approach improvements respect best performing method reported significant average rainbow mcsvm 
improvement especially noteworthy non obvious datasets instance angry appears hard characterize dataset shown poor performance dictionary methods dataset supervised learning methods improve respect best 
angry dataset looks easier angry fact methods listed table perform better angry angry 
explained fact seen table contains data category angry positive examples average goes angry 
contrary dataset easy tackle simple boolean rules shown accuracy boolean method case rainbow boolean method mcsvm virtually delivers performance boolean method 
supervised learning approach delivers stable performance datasets reductions standard deviation respect best performing method significant rainbow mcsvm 
improvements significant remember obtained method cheaper dictionary method terms expert human resources anticipated section fact improvements order magnitude obtained method na bayesian technique implemented rainbow known average performer text categorization literature bears witness superiority supervised learning approach survey coding 
fact multiclass svms known top performers machine learning literature see outperform rainbow small margin surprising dependent data experimented :10.1.1.69.8716
fact possible explanation vocabulary corpora exhibits low internal stochastic dependence approximating conditions bayesian approaches theoretically optimal 
shown automatic coding responses open ended survey questions may posed multiclass text categorization problem text categorization techniques supervised learning may significantly outperform dictionary techniques dominant approach automated survey coding 
advantage supervised learning approach respect dictionary approach requires text classifiers handcrafted knowledge engineer social scientist working classifiers generated automatically training data substantive savings terms expert human resources 
effectiveness levels text categorization techniques achieved experiments far perfect completely satisfactory 
results obtained research promising think research needed automatic approach survey coding clearly supersede manual approach 
avenues research 
currently working simply run experiments survey data order obtain results statistically reliable 
possible line research experiment satisfactory multiclass tc learners order improve results rainbow mcsvm 
plan combine automated survey coding text categorization speech recognition order allow survey coding task proceed directly audio recording interview believe survey coding may performed better effectiveness better quality input faithful representations answers 
proceeding directly audio recording eliminate sources noise mentioned section noise possibly introduced greater savings term human resources means researchers design survey afford having open ended questions multiple choice ones 
process requires apply text categorization noisy text due current performance speech recognition software think reasons optimism previous research optical character recognition field shows effectiveness levels comparable obtainable case standard text may achieved 
possible similar effectiveness patterns result case noise introduced speech recognition 
wish providing initial impetus research 
text collected general social surveys national opinion research center university chicago supplied authors 
grateful tom smith jennifer providing texts assisting interpretation 
grateful crammer yoram singer andrew mccallum making mcsvm rainbow packages available peter clarifying points experiments henri helping preprocessing issues david lewis suggesting pointers automated survey coding literature 
alexa 
computer assisted text analysis methodology social sciences 
technical report zentrum methoden und mannheim de 
alexa ll 
text analysis software commonalities differences limitations 
results review 
quality quantity 
marko grobelnik mili mladeni 
interaction feature selection methods linear classification models 
proceedings icml workshop text learning sydney au 
jill burstein karen kukich susanne wolff chi lu martin chodorow lisa braden harder mary dee harris 
automated scoring hybrid feature identification technique 
proceedings acl th annual meeting association computational linguistics pages montreal ca 
cyril cleverdon 
optimizing convenient online access bibliographic databases 
information services 
reprinted pp 

crammer yoram singer :10.1.1.69.8716
algorithmic implementation multiclass vector machines 
journal machine learning research 
james davis tom smith 
general social surveys cumulative codebook 
national opinion research center chicago 
martin dillon 
automatic classification harris survey questions experiment organization information 
journal american society information science pages 
susan dumais john platt david heckerman mehran sahami 
inductive learning algorithms representations text categorization 
georges james french luc editors proceedings cikm th acm international conference information knowledge management pages bethesda 
acm press new york 
chih wei hsu chih jen lin 
comparison methods multi class support vector machines 
ieee transactions neural networks 
chih wei hsu chih jen lin 
simple decomposition method support vector machines 
machine learning 
david ittner david lewis david ahn 
text categorization low quality images 
proceedings sdair th annual symposium document analysis information retrieval pages las vegas 
thorsten joachims 
text categorization support vector machines learning relevant features 
claire dellec line rouveirol editors proceedings ecml th european conference machine learning pages chemnitz de 
springer verlag heidelberg de 
published lecture notes computer science series number 
markus junker rainer hoch 
experimental evaluation ocr text representations learning document classifiers 
international journal document analysis recognition 
larkey 
automatic essay grading text categorization techniques 
bruce croft alistair moffat van rijsbergen ross wilkinson justin zobel editors proceedings sigir st acm international conference research development information retrieval pages melbourne au 
acm press new york 
david lewis 
naive bayes independence assumption information retrieval 
claire dellec line rouveirol editors proceedings ecml th european conference machine learning pages chemnitz de 
springer verlag heidelberg de 
published lecture notes computer science series number 
hang li kenji yamanishi 
text classification esc stochastic decision lists 
information processing management 
manuela 
coding textual responses various issues automated coding computer assisted coding 
proceedings th international conference statistical analysis textual data pages st malo fr 
andrew mccallum kamal nigam 
comparison event models naive bayes text classification 
proceedings st aaai workshop learning text categorization pages madison 
gerard salton christopher buckley 
term weighting approaches automatic text retrieval 
information processing management 
reprinted pp 

fabrizio sebastiani :10.1.1.119.8039
machine learning automated text categorization 
acm computing surveys 
karen sparck jones peter willett editors 
readings information retrieval 
morgan kaufmann san mateo 
taira 
feature selection svm text categorization 
proceedings aaai th conference american association artificial intelligence pages orlando 
aaai press menlo park 
peter 
performance evaluation automatic survey classifiers 
honavar editors proceedings th international colloquium grammatical inference pages ames 
springer verlag heidelberg de 
published lecture notes computer science series number 
dave helen hunt 
approaches computerized assessment free text responses 
proceedings rd annual computer assisted assessment conference pages uk 
peter willett editor 
document retrieval systems 
taylor graham london uk 
yiming yang xin liu 
re examination text categorization methods 
marti hearst richard tong editors proceedings sigir nd acm international conference research development information retrieval pages berkeley 
acm press new york 

