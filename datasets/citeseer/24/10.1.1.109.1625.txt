language sensitive text classification roberto basili alessandro maria teresa pazienza university rome tor department computer science systems production roma italy basili pazienza info uniroma traditional belief order scale effective retrieval access methods modern information retrieval consider text content 
modalities techniques fit objectives discussion 
empirical evidence required determine suitable linguistic levels modeling ir subtask information zoning parsing feature selection indexing 
corresponding information 
original classification model sensitive document syntactic information characterized novel inference method described 
extensive experimental evidence derived real test data established academic test sets 
results show significant improvement derived proposed inference model 
role linguistic preprocessing provide positive effects performance 
pos tagging recognition proper nouns received specific experimental attention provided significant effects measured accuracy 

common believe order scale effective retrieval access methods modern information retrieval take content account 
current ir seen combination traditional techniques vector space models advanced access browsing facilities methods able support extraction linguistic information multilinguality 
language processing crucial step information access knowledge management systems stress content retrieval access functionalities 
stressed 
grefenstette vector space models inadequate deal retrieval web commonly available simple short queries 
content play role nature methods account debate 
crucial problems related detect suitable linguistic levels subtask information zoning specific parsing indexing optimize processing level optimal parsing proper nouns terminological expressions part speech assignment suitably combine linguistic processes cooperating target ir tasks specific dependencies 
combine differently derived information 
text classification important task ir scenario 
playing major role retrieval filtering development user driven line services 
users expect relevant information possibly customized operational publishing needs 
design intelligent methods automatic management information knowledge ir seen way knowledge management tightly classification capabilities 
fact authoring information feed user knowledge repository usually content classified texts preliminary classification necessary step 
research described partially funded trevi esprit project ep thematic text classification able retrieve organize textual data existing dynamic framework assuming increasingly relevant role 
classification problem traditionally described follows set possibly evolving user needs expressed hierarchical structures classes topics subtopics labels 
ii variety existing examples classes iii build decision function able automatically classify new texts classes upgrade existing example repository 
classes represents topics areas interest usually organized hierarchical structure representing user needs 
decision function asked map newly incoming documents class es content 
role linguistic content twofold side embodied specific information respect entities facts mentioned documents 
proper nouns companies location persons events involving entities managing succession events indicators topics industry news example type linguistic content 
information widely area involved granular specific recognition 
hand content refers set typical words expressions terminological units occur document documents class 
provide picture topic deals 
second form linguistic content refers clear separation content words open syntactic classes nouns verbs adjectives relevant information functional classes prepositions complex functional expressions far order identification role word corresponding contexts able example distinguish verbal nominal uses lemma 
identification linguistically motivated structures behave non compositionally require completely different treatment probabilistic modeling respect phenomena 
possibly complex proper nouns shell transport trading plc example modeled similarly common nouns granular form linguistic content useful usually provides core information quantitative models developed 
accuracy recognition different components clearly reflected accuracy retrieval process 
empirical evidence relationship necessary study aims add information issue 
original classification model sensitive linguistic content characterized novel inference method see section 
comparative purposes review discuss known tc techniques section 
model departs existing ones aspects uses language sensitive indexing process syntactic processing supports indexing separating functional structures recognized proper nouns candidate term set 
specific inference technique called classification decision extensive experimentation different benchmarking real corpora section 
prototype system called trevi basili platform experiments 
trevi specific technologies deal linguistic content adopted positive contributions suggested experiments 
discussion original aspects proposed method respect trevi performances carried section 
designing text classifier design text classifiers set tasks universally recognized ir community corpus pre processing phase pre processing corpus consisting sub steps corpus validation filtering formatting documents belonging corpus 
extraction relevant words 
step list applied eliminate function words exhibit approximately equal frequencies documents collections 
word stemming common suffixes removed text words suffix deletion system 
words stemming usually called terms 
corpus splitting parts derived source corpus test set performance evaluation training set learning 
term selection attempt remove non informative terms documents improve categorization effectiveness reduce computational complexity 
typical selection criteria information gain document frequency 
features design linguistic information characterize document class selected 
simplest ones single words 
complex features built structured patterns multiple word expressions adding lexical information word senses 
weighting features assume usually different roles documents repre 
different weights associated features producing different representations 
similarity estimation modeled operations spaces features 
carried couples documents complex combination features profiles combination features coming different representative documents 
usually quantitative models metrics adopted 
inference similarity evaluation document representations trigger classification decision 
assignment incoming document suitable classes separate independent decision function similarity scores inference 
different criteria purely heuristics probability driven rules 

profile example driven text classification main approaches construction non parametric classifier proposed experimented literature lewis 
profile classifiers derive description target class terms profile usually vector weighted terms 
vectors extracted training documents previously categorized approach referred category centered classification 
classification evaluation similarity incoming document different profiles class 
early profile classifier vector space model salton buckley define similarity switching information retrieval text classification task 
majors advantages approach computational efficiency easy implementation 
example types classifiers incoming document query training data 
similarity documents evaluated 
categories training documents highest similarity categorized considered promising classification candidates approach referred document centered categorization 

designing profile classifier development profile classifier requires specialization mentioned tasks features design weighting learning synthetic profile representation document defined means set features extracted weights features usually included quantitative representation similar representation class summarizes representation documents positive instances similarity estimation profile classifiers documents defined profiles inference decision function usually depends similarity scores 
widely inference methods literature probability fixed proportional thresholding 
respectively called yang threshold class establishes document belong best ranked classes assigned document testset document assigned classes proportionally size yang 

text classification models classification models proposed literature distinctive aspects briefly summarized 
neighbor example classifier yang making document document similarity estimation selects class document nearest heuristics 
rocchio ittner cohen singer refers systems rocchio formula profile estimation 
ripper cohen singer uses extended notion profile learning contexts positively correlated target classes 
machine learning algorithms allows contexts word affect presence absence contribute classification 
classi system uses neural network approach text categorization ng low 
basic units network perceptrons 
dtree quinlan system known machine learning method decision trees applied training data automatic derivation classification tree 
dtree model allows select relevant words features information gain criterion predict categories occurrence word combinations documents 
charade moulinier ganascia swap apt machine learning algorithms inductively extract disjunctive normal form rules training documents 
sleeping experts experts cohen singer learning algorithms works line 
reduce computation complexity training phase large applications updating incrementally weights gram phrases 
naive bayes tzeras probabilistic classifier uses joint probabilities words categories estimates conditional probabilities categories document 
naive approach refers assumption word independence 
assumption computation naive bayes classifier far efficient exponential complexity pure bayes approach predictors word combinations 
comparative analysis shown 
yang reuters test sets exist systems performs differently 
particular table reports measured performances reuters version reuters corpus 
table breakeven points widely known classifiers policy reuters version neighbor ripper classi dtree swap charade expert rocchio naive bayes 
language sensitive classification model section dedicated definition novel profile model characterized systematic linguistic preprocessing data section statistical inference method called section 
model called weighting driven different experimental evidence performance highly dependent corpora tasks number classes 
sections introduce related definitions specific aspect 
done means breakeven point point recall precision assume value 

language processing text classification trevi model proposed trevi text retrieval enrichment vital information system intelligent text retrieval enrichment 
reuters member consortium main user case released prototype 
trevi components servers cooperating processing extraction classification enrichment delivery news 
basically trevi components contribute task full linguistic preprocessor take normalized versions news produces set grammatical subj obj relations semantic word senses ontology information text 
output derived class profiles assigns topics news 
proper sub system 
trevi basili complex sub system combining tokenization lemmatization independent lexical server part speech tagging brill church robust parsing basili 
details linguistic methods algorithms phase related publications basili basili described 
relevant information outcome parsing process component 
able detect documents set information 
possibly complex tokens lemmas 
simple words complex terminological expressions entire noun phrases bond issue functional expressions order detected treated atomic units phases 
proper nouns pns 
set domain user specific named entities recognized extensive catalogs application special purpose grammars 
typed set proper nouns derived news treated separate process respect lemmas 

syntactic categories lemmas 
units text simple complex terms assigned single part speech pos nouns verbs 
indexes extended pos verbal nominal occurrences lemma independent different 
major grammatical relations subj obj relations words detected significant accuracy see basili evaluation robust parser 
news annotated basic structures significant constituents verbs modifiers 
classification model propose profile classifier features document lemmas associated part speech pos labels point 
nouns verbs adjectives considered candidates features resulting indexes couples lemma 
furthermore proper nouns pns part profile 
information related linguistically different lemmas 
different spaces lemmas pns determined require different treatment 
list trevi pos tagging supplies corresponding linguistically principled filtering ability 
expected process recognition functional units proper nouns pos tag assignment supports selection suitable candidate features terms 
noticed grammatical relation point indexing points influence classification 
contributions component provides trevi basili distributed object oriented system designed developed european consortium trevi esprit project ep 

weighting weighting schemes implemented experimental results shown 
novel introducing new corpus derived parameters referred second common weighting scheme associated rocchio classifier ittner 

weighting order define weighting policy number definitions necessary 
training set feature describe generic document corpus target set classes notations express occurrences features occurrences feature training set occurrences features document document representations defined class profiles document weights accordingly class weights defined inverse word frequency representations similarity function applied model introduces major differences respect traditional weighting strategy example smart salton 
inverse word frequencies basili place role similar penalizes high frequency meaningful terms recovering systematic errors pos tagging 
significant difference respect smart adoption squaring 
fact order balance contribution square preferred 
similar adjustment technique proposed hull 
product biased global frequency term 
rocchio weighting second weighting scheme ittner 
scheme quantities needed number documents training set 
number documents term appears 
accordingly usual document weights class weights max rocchio formula class parameters control relative impact positive negative examples classifier 
experiments described follows standard values cohen singer 
set training documents belonging class documents belonging rocchio weighting system includes document profile normalization inside weights derived similarity function contain normalization respect see equation observe 
inference relative difference scores order select suitable classes document thresholding widely adopted empirical criteria see lewis comparative evaluation 
defined thresholding policy empirical estimation training data differences similarity scores 
scores directly stochastic variable expressing average difference score correct th class remaining classes 
formally document assumes values class mean standard deviation respectively estimated documents training set 
vector assign corresponding property threshold empirically determined optimize recall precision test data 
equation inference method called tree main approaches thresholding probability fixed proportional thresholding 
lewis lewis shown outperforming 
rds method propose produces improvement breakeven point respect policies discussed lewis 
fact seen extension proportional thresholding policy estimated training data 

experimental evaluation order evaluate tc methodology objectives impact linguistic information text classification indirect operational perfor mance evaluation improvement technique real data user driven evaluation known assessed measured data sets influence different weighting schemes different test sets experiments designed implemented 
extensive evaluation collected corpora 
corpora news coming users involved trevi project reuters news collected set documents distributed structured classes 
main topics corpus financial corporate industrial market share general sport elections categories 
refer collection trevi reuters corpus 
hos health line news collection short medicine related abstracts 
hos corpus documents distributed classes 
typical classes clinical oncology vs collection reuters version corpus yang referred reuters 
includes documents classes fixed splitting test learning data vs 
set experiments carried trevi data sets trevi reuters hos order compare weighting schemes inference methods real data sets 
particular weighting schemes smart rocchio tested different inference methods measured simple second test reuters benchmark carried assess contribution original aspects weight ing known collection 
third set experiments aimed evaluate actual contribution linguistic information comparing performances best models observed trevi reuters reuters data sets applied pos information 

description experiments experiment performances trevi experiment run trevi user data performances classifiers obtained adopting different weighting schemes different thresholding policies measured 
adopted features document class representation classifiers couples lemma 
smart refers classical vector space weighting scheme applied profiles table reports results trevi reuters corpus table relates hos data set 
table classifier performances trevi reuters corpus smart smart rds iwf rds rocchio rocchio rds breakeven point table classifier performances hos corpus rocchio rocchio rds iwf iwf rds breakeven point smart model run different classification rules smart adopts probability thresholding smart rds applied relative difference score eq 

experiment assessment reuters corpus measured reuters corpus 
breakeven points reported table 
experiments trevi processing adopted indexing 
line previous results produces significant improvement weighting schemes 
note performance rocchio formula column different respect results obtained literature yang 
suggests linguistic processing difference experiments measurement provides additional positive information 
order better evaluate impact linguistic information test rocchio model run see column rocchio pos pn 
lemmas described pos tags combined new indexes corresponding detected pns loss performance suggests linguistic processing non trivial effect system selectivity 
table classifier performances reuters corpus rocchio rocchio rds iwf iwf rds rocchio pos pn breakeven point experiment evaluating impact part speech information order understand role part speech information measured classification schemes run best performing classifiers pos information 
indexing lemmas applied lemmatization information available weighting 
table shows result experiment previously obtained including pos tag information trevi reuters corpus 
table syntactic information vs classification accuracy trevi reuters iwf iwf pos rec 
prec 
stressed trevi reuters corpus set different indexes refer ambiguous lemmas lemmas pos tag 
table describe recall precision indexing modalities reuters corpus 
reuters corpus obtained different indexes refer lemmas pos tag 

discussion main objective experiments define optimal version model 
experiment indexes different pos tags processing merged cumulated fre pns added new indexes 
table syntactic information vs classification accuracy reuters rocchio rocchio pos rec 
prec 
result establishes effective method classification inference 
produces increment performance respect weighting scheme compared simpler thresholding policies 
shown large heterogeneous corpora 
increment varies table table 
improvements similar indexing policy 
table increment exactly weighting models smart rocchio systematic behavior suggests effect dependent mainly corpus proportional inherent limitations weighting model 
table weaker weighting policy receives best contribution improvement 
natural ways think classification inference flexible respect fixed proportional thresholding biased training set easily adaptable dynamically changing frameworks 
independent document stream set incoming data applies individually documents 
expected improve fact system recall keeping precision compared policies 
influenced average membership scores documents training set biased training data 
fix number classes retained document 
shown robust respect categories different specificity 
better suited deal odd documents similar texts training set texts low values evaluated corpora shown difficult find model optimal corpus pointed yang 
rocchio model performs better characterized profiles smaller numerous classes 
scheme better performing corpus includes generic classes poorly characterized profiles 
reason suitable selection weighting scheme left underspecified pre analysis applied target corpora 
interesting aspect role linguistic processing 
reported results literature see table reuters corpus suggests best performing classifier nn 
rocchio model reported breakeven point 
contrasts evidence see table 
note difference experiments trevi technology adopted indexing 
discussed section linguistic preprocessing differs traditional methods stoplist stemming applied recognition proper nouns pos information available 
evident lemmatization pos tagging supply information similar obtained stemming stoplist adoption fact words pos tagged nouns verbs adjectives indexing 
results table show pos tagging adding proper nouns profiles obtained stemming performances higher yang 
note removal pos tags inclusion proper nouns applied set indexes precalculated trevi processor 
means influence selection candidate feature set lemmas persists experiment 
result small improvements degraded trevi basically due better set indexes stemming stoplist adoption obtain 
improvement performances rocchio model reuters imputed greater accuracy linguistic process clear separation lemmas content words proper nouns 
departure current text processing tools proper noun treatment 
included profiles fact reliably retained topic triggers 
evaluation table suggests correct policy including proper nouns pn column produces loss performances 
emerged pos information added indexes produces small improvements see table 
basically due small number truly ambiguous lemmas effect evident 
evidences quasi optimal version model obtained suitable weighting schemes combining trevi linguistic processor inference mechanism 
produces best performance linear classifiers reuters data set 
accurate classifiers 
best reuters corpus obtained example driven nn classifier llsf yang 
higher training classification complexity design difficult real operational domains 
classifiers complex learning ripper cohen singer knowledge algorithms swap apt show similarly complex design performances comparable lower respect relatively simple nature applicability model successfully adopted trevi real application scenarios reuters hos 
performances retained new domains simpler weighting models vs rocchio 

proposed model shown performances real known reuters data sets 
extensive experimentation suggests main reasons novel technique effective inference systematic linguistic preprocessing texts able better support indexing focusing meaningful syntactic categories real content words supporting lemmatization stemming produce inherent corpus reduction pruning candidate feature set informative units function words proper nouns augment indexes introducing pos information 
indexes derived 
basili inference technique text classification improved performances different classifiers smart rocchio bep 
current extensive experiments known data sets improvement observed corpus respect different weighting policies 
weaker weighting scheme higher improvement produced widely tested collection reuters version weighting schemes compared rocchio best model rocchio inference technique measured best performing linear classifier data set 
suggests model linguistic preprocessing described section rocchio formula call effectively different heterogeneous application domains 
results reported derived development design industrial prototype trevi system 
test carried users reuters operational scenarios confirmed accuracy results 
necessary better establish contribution different original aspects outperforming results 
benchmarking data sets studied comparative purposes 
final assessment role obtained 
second linguistic processing adopted provide better input information indexing schemes result significant improvements bep figures reported literature yang 
systematic language processing adopted trevi supports input material better quality pos tagged words detection complex functional units proper nouns 
selective measurement contribution type linguistic test collections necessary clearly establish role 
represents potential language sensitive approach text classification uses part material currently detected trevi parser 
models able take account linguistic information terminological units descriptions events semantic typing words design 
accordingly extension model short medium term research objective 

colleagues ai research group tor university rome contribution methodological discussion support making available experimental data 
apt damerau weiss 

automated learning decision rules text categorization 
acm transactions information systems 
basili di pazienza 
august 
nlp text classification trevi experience 
proceedings second international conference natural language processing industrial applications universite de new brunswick canada 
basili pazienza 

text classifier linguistic processing 
proceedings ijcai machine learning information filtering www ai cs de events ijcai papers html 
basili pazienza 

efficient parsing information extraction 
proc 
ecai brighton uk 
brill 

simple rule part speech tagger 
proc 
third applied natural language processing povo trento italy 
church 

stochastic parts program noun phrase parser unrestricted text 
proc 
second conference applied natural language processing 
cohen singer 

context sensitive learning methods text categorization 
proceedings th annual international acm sigir conference research development information retrieval sigir pages 
grefenstette 

short queries linguistic expansion techniques word queries providing intermediate structures text 
pazienza editor information extraction multidisciplinary approach emerging information technology 
springer verlag berlin 
ng low 

features selection perceptron learning usability case study text categorization 
proceedings th annual international acm sigir conference research development information retrieval sigir pages 
hull 

improving text retrieval routing problem latent semantic indexing 
proceedings sigir th acm international conference research development information retrieval pages dublin 
moulinier ganascia 

text categorization symbolic approach 
proceedings fifth annual symposium document analysis information retrieval 
ittner lewis ahn 

text categorization low quality images 
proceedings sdair th annual symposium document analysis information retrieval pages las vegas 
lewis 

evaluation phrasal clustered representations text categorization task 
proceedings sigir th acm international conference research development information retrieval pages dk 
lewis callan papka 

training algorithms linear text classifiers 
proceedings sigir th acm international conference research development information retrieval pages rich ch 
quinlan 

induction decision trees 
machine learning pages 
salton 

development automatic text retrieval 
science 
salton buckley 

term weighting approaches automatic text retrieval 
information processing management 
tzeras 

automatic indexing bayesian inference networks 
proceedings th annual international acm sigir conference research development information retrieval pages 
yang 

expert network effective efficient learning human decisions text categorisation retrieval 
proceedings sigir th acm international conference research development information retrieval pages dublin 
yang 
may 
evaluation statistical approaches text categorization 
information retrieval journal 
