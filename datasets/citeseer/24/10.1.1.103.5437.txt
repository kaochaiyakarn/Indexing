efficient algorithm mining association rules large databases ashok savasere edward omiecinski navathe mining rules items large database sales transactions described important database mining problem 
effi cient algorithm mining association rules fundamentally different known gorithms 
compared previous algorithms algorithm reduces head significantly lower cpu overhead cases 
performed extensive experiments compared formance algorithm best existing algorithms 
large databases cpu overhead re duced factor reduced order magnitude 
algorithm especially suitable large size databases 
database mining motivated decision support problems faced business organizations described important area research 
main challenges database mining de fast efficient algorithms handle permission copy fee ot part material granted provided copies ot distributed fog direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment copy ot republish requires fee special permission endowment 
proceedings st vldb conference zurich college computing georgia ute technology atlanta ga mail ashok qcc gatech 
edu large volumes data mining algorithms perform computation entire database databases large 
discovering association rules items data introduced :10.1.1.40.6984
basket data typ ically consists items bought customer date transaction quantity price data may collected example supermarket checkout counters 
association rules identify set items purchased set items 
example association rule may state customers bought items bought association rules may catalog design store layout product place ment target marketing ma ny algorithms discussed lit er discovering association rules 
key features previous algorithms multiple passes database 
disk resident databases requires reading database completely pass resulting large number disk os 
algorithms effort spent performing just considerable large databases 
apart poor response times approach places huge burden subsystem adversely affecting users sys tem 
problem worse client server environment 
describe algorithm called par fundamentally different pre vious algorithms reads database times ge significant association rules 
contrast previous algorithms database scanned multiple times number scans determined ad vance 
surprisingly savings achieved cost increased cpu overhead 
formed extensive experiments compared algo rithm best previous algorithms 
experimental study shows computationally cases algorithm performs better previous algorithm terms cpu overhead 
ot related direct ly applicable database mining reported 
organized follows sec ion give formal description problem 
section describe problem give overview previous algorithms 
section describe algorithm 
performance results de scribed section 
section contains 
problem description section largely description problem :10.1.1.40.6984
formally problem stated follows il ia im set distinct literals called items 
set variable length transactions transaction contains set 
items ii ik 
transaction associated unique identifier called tid 
association rule implication form ii 
called antecedent called consequent rule 
general set items antecedent consequent rule called itemset 
number items itemset called length itemset 
itemsets length referred itemsets 
itemset itemset called extension itemset ed measure sta tistical significance called support 
itemset ik fraction transactions cont equals rule measure strength called confidence defined ratio support support 
problem mining association rules gener ate rules support confidence greater user specified minimum support min imum confidence thresholds respectively 
prob lem decomposed lems itemsets support user specified minimum support generated 
itemset called large itemsets 
said small 

large itemset rules minimum confidence generated fol lows large itemset terminology introduced support support ini mum confidence rule valid rule :10.1.1.40.6984
example tl tz transactions database 
minimum sup port minimum confidence respec tively 
large itemsets ab ad abd 
valid rules second subproblem generating rules large itemsets supports relatively straightforward 
discovering large item sets supports nontrivial problem cardinality set items da large 
exa mple num ber possible distinct itemsets 
problem identify large number itemsets minimum support set transactions 
small values possible setup counters distinct itemset count support itemset scanning dat aba se 
applications 
clearly approach impractical 
reduce combina search space algorithms exploit property subset large itemset large 
conversely extensions small itemset small 
property existing algorithms mining association rules follows initially support itemsets length itemsets tested scanning database 
itemsets small discarded 
set itemsets called candidate item sets gener ated extending large itemsets generated previous pass extensions sup port tested scanning database 
itemsets large extended support 
general kth iteration contains steps 
set candidate itemsets generated extensions large itemsets generated previous iteration 

supports candidate itemsets gener ated pass database 

itemsets minimum sup port discarded remaining itemsets called large itemsets 
process repeated large itemsets 
previous problem generating association rules introduced algorithm called ais pro posed mining association rules :10.1.1.40.6984
algo rithm called setm proposed solve problem relational operations 
new algorithms called apriori aprioritid proposed 
algorithms achieved significant improvements previous algorithms 
rule generation process extended include multiple items con sequent efficient algorithm generating rules 
algorithms vary mainly candi date generated supports itemsets count ed 
didate itemset generated fly pa ss database :10.1.1.40.6984
transaction candidate itemsets generated extending large item sets previous pass ems transac tion new itemsets contained transaction 
candidate generated separate step large itemsets previous pass 
performed joining set large itemsets 
resulting candidate set pruned eliminate itemset subset contained previous large itemsets 
technique produces smaller candidate set technique 
supports candidate itemsets determined follows 
transaction set candi date itemsets contained transaction identified 
counts itemsets incremented 
authors de scribe data structures subset opera tion :10.1.1.40.6984
apriori aprioritid differ data structures generating supports di date itemsets 
apriori candidate itemsets compared transactions determine con tained transaction 
structure rest set candidate itemsets compared subset testing optimized 
bitmaps place transactions testing fast 
aprioritid 
pass encoding la rge itemsets contained transaction place transaction 
pass candidate tested inclusion transaction checking large itemsets generate candidate itemset contained encoding transaction 
apriori subset testing performed transaction pass 
aprioritid transaction contain large itemsets current pass transaction considered subsequent passes 
consequently passes size encoding smaller actual database 
hybrid algorithm proposed uses apriori initial passes switches aprioritid passes 
partition algorithm idea partition algorithm follows 
re call reason database needs scanned multiple number times number possible support tially large done single scan database 
suppose small set potentially large itemsets say item sets 
support tested scan database actual large itemsets discovered 
clearly approach set contains actual large itemsets 
partition algorithm accomplishes scans database 
scan generates set po large itemsets scanning database 
set superset large itemsets may contain false positives 
false negatives re ported 
second scan counters itemsets set act ual support measured scan database 
algorithm executes phases 
phase partition algorithm logically divides database number non overlapping partitions 
partitions considered time large itemsets partition generated 
phase large itemsets merged gen erate set potential large itemsets 
phase ii act ual support itemsets generated large itemsets identified 
partition sizes chosen partition dated main memory partitions read phase 
assume transactions form id ij ik 

items transaction assumed kept sorted lexicographic order 
similar assumption 
straight forward adapt algorithm case transactions kept normalized tid item form 
assume tids monotonically 
justified considering nature application 
assume database resides secondary storage approximate size database blocks pages known advance 
definition partition da refers subset transactions contained database different partitions non overlapping pi pi define local support itemset fraction transactions containing itemset partition 
define ci set local candidate itemsets partition set local large itemsets partition lp set local large partition ck set global candidate itemsets cg set global candidate itemsets set global large itemsets table notation partition database number partitions phase partition gen large itemsets cp merge phase phase ii partition pi candidates cg gen count lg count minsup partition algorithm local didate itemset test ed minimum support partition 
local large itemset itemset local support partition user defined minimum support 
local large may may large cont ext entire database 
define global support global large itemset global candi date itemset context entire database 
goal find global large itemsets 
notation shown table pa 
individual itemsets represented small ters nd sets itemsets represented capital letters 
ambiguity omit parti tion number referring local itemset 
:10.1.1.40.6984
represent le itemset consisting items lc :10.1.1.40.6984
algorithm partition algorithm shown fig ure 
initially database logically partitioned partitions 
phase algorithm takes rz erations 
iteration partition pi consid ered 
function takes par pi input generates local large itemsets lengths li li lj output 
merge minimum support specified ratio procedure gen database partition ly large itemsets lf forall itemsets forall itemsets li :10.1.1.40.6984
lz lz li li lz pruned ic ipi le return procedure gen phase local large itemsets lengths partitions combined generate global candidate itemsets :10.1.1.40.6984
phase ii algorithm sets counters global candidate itemset counts support entire database es global large itemsets 
algorithm reads entire database phase phase ii 
correctness key correctness algorithm potential large itemset appears large itemset partitions 
formal proof ll 
generation local large itemsets procedure takes part ion es large itemset hs tha partition 
procedure shown 
lines show candidate generation process 
prune step performed follows prune itemset forall ic subsets ifs lk return pruned prune step eliminates extensions itemsets large considered counting support 
example candidate generation initially generates itemsets 
pruned le 
technique described case itemset generated count determined immediately 
counts candidate itemsets generated follows 
associated itemset define forall itemsets generate cp forall itemset cf nc :10.1.1.40.6984
idlist count count procedure gen final counts st called 
itemset cont tids transactions contain itemset wit hin partition 
tids kept order 
clearly cardinality itemset divided total number transactions partition gives support tha partition 
initially itemsets generated directly reading partition 
candidate itemset ed joining tidlists wo ic generate candidate ic itemset 
example 
case candidate itemset generated joining 
tidlists itemsets correctness shown ca didate generation process correctly produces poten tial large candidate itemsets 
easy see intersection tidlists gives correct support generation final large itemsets global candidate set generated union local large itemsets partitions 
phase ii algorithm global large itemsets deter mined global candidate set 
phase number partitions iterations 
initially counter set candidate itemsets ini zero 
partition tidlists itemsets generated 
support partition generated intersecting tidlists subsets itemset 
count gives global support itemsets 
procedure counts 
technique subset operation described generate global counts phase ii 
correctness partitions non overlapping cumulative count partitions gives support itemset entire database 
discovering rules large itemsets supports det er mined rules discovered straight forward manner follows large itemset ev ery subset ratio support support computed 
ratio equal user spec ified minimum confidence rule output 
efficient algorithm described pi 
mentioned earlier generating rules large itemsets supports simpler com pared generating large 
attempted improve step 
size global candidate set global candidate set contains itemsets may global support false candidates 
fraction false es global set small possible effort may wasted finding global supports sets 
number false candidates depends factors characteristics data data partitioned number partitions 
se ion study effects partition size data skew size global candidate set 
number partitions increased num ber false candidates increases global candidate size increases 
size bounded times size largest set local large itemsets number partitions 
local large itemsets generated minimum support specified user 
equivalent generating large itemsets minimum support database partition 
sufficiently large partition sizes number local large itemsets ble number large itemsets generated entire database 
additionally data characteristics uniform partitions large number itemsets generated individual partitions may common 
global candidate set may smaller limit 
table show variation size local large itemsets global candidate sets varying number partitions 
database contained transactions 
mini mum support set 
seen table number partitions increases variation sizes local large sets size global candidate set increases 
large overlap local large itemset dataset tl described section number size average size cg partitions largest lp size lp table variation global local set number partitions 
example consider case number parti tions set 
number large itemsets partitions combined 
union itemsets candidate set 
noted hat partition sizes sufficiently large local large itemsets global itemsets close actual large itemsets ends eliminate effects local variations data 
example number partitions table partition contains transactions small large variations 
effect data skew sizes local global candidate sets ma ible dat skew 
gradual change data characteristics average length trans actions lead generation large number local large sets may global support 
example due severe weather conditions may abnormally high sales certain items may bought rest year 
partition comprises data period certain itemsets high support parti tion rejected phase ii due lack global support 
large number spurious local large itemsets lead wasted effort 
problem fewer itemsets common partitions leading larger global candidate set 
effect data skew eliminated large extent randomizing data allocated par 
done choosing data read partition randomly database 
exploit sequential minimum unit data read equal extent size 
size database number extents number parti tions algorithm initially assigns extents randomly partitions 
extent appears partition 
effect sequentially reading data vs ran table effect data skew generating partitions sequentially vs randomly picking blocks highly skewed dataset shown table 
data skew av erage lengths transactions varied 
size database mbytes cont ain ing transactions 
fixed 
set experiments generated partitions reading blocks tially 
second set partitions generated choosing blocks randomly database 
number partitions varied 
table shows sum local large itemset parti tions size global set 
clear randomly reading pages extremely effective eliminating data skew 
data structures implementation se describe da ta structures implement ation algorithm 
generating local large itemsets efficiently generate candidate itemsets join ing large itemsets store itemsets sort ed order 
store itemsets hash ta ble performing pruning efficiently 
computation intersection tidlists maintained sorted order sort merge join algo rithm 
resulting tidlists sorted order 
intersection operation case involves cost traversing lists 
generating global candidate set initially global candidate set empty 
local large itemsets partition added global candidate set 
subsequent partitions local large itemsets added itemset included 
candidate itemsets kept hash table perform ion efficiently 
possible prune global candidate set eliminating itemsets global support known itemsets possibly required global support 
case arises itemset reported large ion 
counts itemset partition known global support known 
second case arises itemset reported large partitions supports par slightly minimum support 
itemsets possibly global support 
example suppose partitions minimum support partition 
itemset large partition support partition global support beca support partitions global sup port 
local large itemset maint cumulative support number partitions reported large merging 
counts perform pruning de scribed ll 
generating final counts data structures final counting phase similar phase initially counter set itemset global candi date set 
tidlists itemsets generated directly reading partition 
local count itemset generated joining tidlists itemsets contained itemset 
exam ple generate count tidlists itemsets joined 
count partitions gives support itemset database 
optimize number joins performed st ep counts longest itemsets gen erated 
intermediate join results set counts corresponding itemsets 
ex ample generating count counts itemsets set 
kept hash table ate efficient lookup 
phase partitions phase obtained reading database blocks sequentially 
additionally size ions may different phase buffer management key objective partition algorithm re duce disk possible 
achieve objective partitions chosen data structures accommodated main mem ory 
number large itemsets generated estimated accurately 
situations may necessary write temporary data disk 
buffer management technique phase sim ilar described 
partition algorithm separate step counting supports 
local candidate itemset gener ated count immediately generated 
iteration need storage large ic itemsets generated previous iteration associated tidlists 
itemsets items needed main memory 
merge phase need space hose global candidate itemset local large item sets length items com mon 
phase ii need space itemsets global set 
ry choose partition sizes accommodated buffer space 
choosing number partitions described partitioning effectively reducing disk choose number partitions 
section describe estimate partition size system parameters compute number partitions database size 
small database may process entire database single partition 
database size grows size tidlists grows may longer able fit main memory tid ist joined 
leads thrashing dation performance 
choose partition size itemsets tidlists generating new large itemsets fit main memory 
noted section iteration need keep main memory large itemsets items common 
assume number itemsets 
heuristics estimate pa size available main memory size average length transactions 
sampling estimate number large itemsets average support compute partition size 
exploring approach part 
performance comparison section describe experiments performance results algorithm 
com pare performance apriori algorithm 
experiments run silicon graphics indy sc workstation clock rate mhz mbytes main memory 
data resided gb scsi disk 
experiments run large itemsets ck apriori gen lk forall transactions ct subset ck forall candidates count li count minsup lo ll answer algorithm apriori synthetic data 
performance comparison ex periments synthetic data sets pi 
apriori aprioritid algorithms im plemented described 
initial experiments showed performance apriori superior aprioritid confirming results reported 
experiments lim ed comparison apriori algorithm 
syn data generation procedure described detail 
section describe apriori gorithm th synthetic data generation procedure sake completeness 
apriori algorithm shown 
procedure apriori gen similar generation step described earlier 
subset oper ation performed bit fields struc ture described 
synthetic data synt het ic data said simulate customer buy ing patt ern retail environment 
length transaction determined poisson distribution mean equal 
transaction repeatedly assigned items set potentially maximal large itemsets length transaction exceed ed length 
length itemset determined accord ing poisson distribution mean equal 
items itemset chosen fraction items common previous itemset deter mined exponentially distributed random variable mean equal correlation level 
remain ing items randomly picked 
itemset exponentially distributed weight determines probability itemset picked 
items itemset picked assigned transaction 
ems itemset dropped long uniformly generated random number tween corruption level corruption level itemset determined normal idi number transactions iti average size average size maximal potentially large itemsets il number maximal pot large itemsets number items table parameters name iti iii idi size mb ook table parameter settings distribution mean variance 
experiments different data sets performance comparison 
table shows names nd er settings dat set 
data sets set il set 
datasets hose experiments 
shows execution times syn datasets decreasing values minimum sup port 
datasets contained transactions largest dataset mb run partition algorithm sett ing number partitions 
comparison ran experiments setting number par 
results indicated partition partition 
im plemented complete buffer disk management include disk times execution times keep comparison uniform 
execution times increase apriori partition algorithms minimum support re duced total number large candi date itemsets increase 
average length transactions increase number large candi date itemsets increase 
datasets partition performed better partition cases expected 
reason partition ests support item sets local support discarded phase ii 
cases minimum sup port high partition performed better ori 
partition performed better apriori cases low minimum support settings 
reason apriori performs better higher mini minimum support minimum support minimum support minimum support minimum support 
execution times minimum sup mum support settings partition head setting data structures 
minimum supports large candi date itemsets cases 
partition benefit setting data structures 
partition performed worse apriori dataset ook minimum sup port 
reason large number itemsets locally large turned small 
behavior repeat case 
attribute characteristics particular dataset 
lowest minimum support setting improvement seconds apriori vs partition 
best improvement seconds apriori vs partition 
improvement factor 
noted improvement exe cution times partition shown mainly due reduction cpu overhead due reduction reason database mbytes small sig affect total execution time 
explanation performance apriori partition candidate itemset generation technique improvement mainly due better technique generating counts 
apriori algorithm counts generated subset operation itemsets didate set compared transactions pass inclusion determine counts 
cost subset operation itemset increases passes length itemsets increase 
illustration amount done subset step consider example 
assume number candidate itemsets transactions database 
assume structure eliminates didate itemsets average comparisons required determine itemset contained transaction 
requires basic integer compare operations 
cost traversing initializing bit field transaction add substantially 
partitioned approach algorithm allows efficient data structures computing counts itemsets 
cost generating support decreases passes lengths tidlists smaller 
illustrate effi ciency counting tidlists consider example 
purpose illustration assume table number comparison operations number partitions 
algorithm operation counting supports involves performing just intersection operations 
assume transaction contains average items distinct items 
average length 
cost basic integer compare operations 
number partitions value larger 
example simple scenario include cost setting data structures 
actual com depend parameters building characteristics data explains partition algorithm performs better apriori 
compared actual number compar performed partition apriori algorithms different support levels 
results shown table 
noted actual execution times include generation data structures generation candidate itemsets case apriori traversing reflect figures shown table compares cost generating supports 
improvement disk partition algorithm motivated need reduce disk aspect clear advantage apriori algorithm 
partition algorithm reads database twice irrespective minimum support number partitions 
apriori reads database multiple number times 
exact number depends minimum support data characteristics determined advance 
measured number read requests data algorithms datasets described table 
page size set kbytes 
re sults shown 
best improvement mini mum support 
improvement factor 
improvement minimum support representing improvement minimum support set high large itemsets generated 
case algorithms read database 
minimum support jo 
zi ool sup minimum ooo 
minimum support minimum support go ooo 

apriori minimum support number database read requests minimum support fa ct 
median pa showed improvement ori bot algorithms read database twice 
support level set high itemsets re quired support 
cases algorithms rea database 
scale experiments studied scale characteristics partition algorithm varying number trans actions loo ooo 
param eter settings 
results shown 
number partitions varied ook transactions transactions partition algorithm 
execu tion times normalized respect size database respect execution times partition algorithm trans actions 
initial jump execution time due increase number partitions 
expected increases size global candidate set increase execution time 
number par increased size global candidate set increase correspondingly local large itemsets common 
execution time relatively linear transactions tr 
partition apriori number 
number transactions scale studied performance algorithm average transaction size average size maximal potentially large itemset scale 
experiment varied transaction length 
size varied 
physical size database kept roughly con stant keeping product number trans action average size constant 
number transactions varied io transaction size transaction size scale dat average transaction length database average transaction length 
minimum support level fixed terms number transactions 
ran ex periments minimum support levels 
results shown 
partition exhibits marginally inferior scale compared apriori minimum support high spends ime initializing data struct ures deriving benefit processing cost 
lower minimum support high processing cost scale superior apriori processing cost increases slower apriori 
described algorithm ef ficient fast discovering associa tion rules large databases 
import ant ion ap proach 
drastically reduces overhead ed previous algorithms 
feat ure may prove useful real life database mining ios data centralized resource shared user groups may support line transactions 
interestingly im provement disk achieved cost cpu overhead 
demonstrated exten sive experiments cpu overhead best existing algorithm low minimum supports cases computationally expensive 
addition algorithm excellent 
scale property 
problem accurately estimating number partitions available memory needs 
currently addressing prob lem 
exploring possibility combining algorithm previous algorithms develop hybrid ch performs best cases 
plan extend ing algorithm shared multiprocessor machine 
acknowledgment wish dr rakesh agrawal ibm research center providing synthetic data running experiments 
author wishes comments suggestions 
agrawal imielinski swami :10.1.1.40.6984
min ing association rules sets items large databases 
proceedings acm sig mod international conference management data pages washington dc may 
agrawal srikant 
fast algorithms mining association rules large dat 
proceedings th international conference large data bases santiago chile au september 
navathe beck 
knowledge mining dat unified ap proach conceptual clustering 
cal report georgia institute technology may 
han cai cercone 
knowledge discovery databases tribute oriented ap proach 
proceedings th international conference large data bases pages vancouver canada august 
siebes 
data mining search knowledge databases 
technical re port cs cwi amsterdam la nds 
swami 
set oriented mining association rules 
proceedings inter national conference data engineering taipei taiwan march 
krishnamurthy imielinski 
pract problems need database research 
acm sig mod record september 
piatetsky shapiro frawley editors 
knowledge discovery databases 
mit press 
savasere omiecinski navathe 
efficient algorithm mining association rules large databases 
technical report git cc georgia 
institute technology atlanta 
ga january 
lo silberschatz stonebraker ullman 
database systems achievements ties 
communications acm october 
ll stonebraker agrawal dayal hold reuter 
database research crossroads vienna update 
proceedings th international conference large data bases pages dublin 
nd au 
tsur 
data 
ieee data engineering bulletin december 

wang 
chirn marr shapiro shasha ii 
zha ng 
pattern discovery scientific data pre results 
proceedings acm sigmod international conference manage ment data pages minneapolis mn may 
