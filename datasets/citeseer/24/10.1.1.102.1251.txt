best effort router architectures differentiated services tomorrow internet vijay kumar lakshman dimitrios bell laboratories lucent technologies transformation internet commercial infrastructure ability provide differentiated services users widely varying requirements rapidly important meeting massive increases bandwidth demand 
deploying routers switches transmission systems increasing capacity internet service providers provide customer specific differentiated services shared network infrastructure 
article describe router architectures support trends rising bandwidth demand rising demand differentiated services 
focus router mechanisms support differentiated services level contemplated proposals currently consideration due concern regarding implementability high speeds 
consider types differentiated services service providers may want offer discuss mechanisms needed routers support 
describe plausible implementations mechanisms scalability performance demonstrated implementation prototype system argue technologically possible considerably raise level differentiated services service providers offer customers necessary restrict differentiated services rudimentary offerings high speed networks 
transformation internet important ubiquitous commercial infrastructure created rapidly rising bandwidth demand significantly changed consumer expectations terms performance security services 
consequently service providers need evolve networks higher higher speeds need plan increasingly sophisticated services address varied requirements different customers 
time internet service providers isps maximize sharing costly backbone infrastructure manner enables control usage network resources accordance service pricing revenue potential 
trends rapidly rising bandwidth demand rising need differentiation resulted intense efforts build fast packet forwarding engines define mechanisms service differentiation 
need build fast forwarding engines addressed variety ways 
discuss various sections article 
focus article gigabit routers capable fast forwarding providing customer specific service differentiation 
consider general flexible model service differentiation restrict specific proposals service differentiation discussed various industry standards bodies 
general model mind discuss detail various router mechanisms necessary provide differentiated services 
particular discuss architectural constraints imposed need provide differentiated services just fast forwarding important components packet filtering buffer management scheduling necessary support differentiated services network element level 
ieee mechanisms discuss implementation considerations drawing experience gained prototype implementation 
theme network element level technologically viable incorporate mechanisms provide customer specific differentiated services high speeds 
consequently point view implementability need restrict service offerings simple schemes encoded type service tos bits 
differentiated services consider multiple sites expect ideally isp providing connectivity sites 
possible scenario expect receive service similar obtained leased line network 
means corporate sites communicating shared interconnecting backbone perceive performance equal leased line minimum prespecified capacity 
traffic sites affected traffic users shared network 
queuing delays congestion occur traffic generated individual load generated 
isolating traffic different customers providing minimum bandwidth guarantees customer specific manner allow customers isp services determine bandwidth require satisfy needs traffic requirements just leased line 
may want additional flexibility able specify manner internal traffic different sources allowed access available bandwidth 
furthermore may desirable define different levels service different types traffic customer dependent manner 
example customers may consider ftp web transfers low priority isp aggregate multiple flows types 
customers may define voice ip database queries high priority isp ensure performance giving traffic types priority guaranteed minimum bandwidth customer available bandwidth 
ieee communications magazine may scenario customers may require extremely reliable predictable performance small set applications 
may indicate requirement network dynamic reservations exact bandwidth specification delay bounds 
indication may explicit signaling resource reservation protocol rsvp done implicitly means 
isp infrastructure capable allowing users choose stringent possibly expensive service require 
considering scenarios generate guidelines regarding user service provider requirements design router mechanisms supporting differentiated services 
customer requirements customers network provide leased line behavior able additional available bandwidth 
customers typically consolidate existing network connections site single connection isp added flexibility dividing bandwidth available particular manner internal users traffic type 
enables effectively support applications telephony lan interconnect audio conferencing video conferencing web hosting internet access time able allocate available bandwidth flexibly internal users 
service provider requirements meeting customer requirements service providers want maximize sharing multiplexing infrastructure maximize revenues 
able take advantage possibility statistical multiplexing 
service providers able identify traffic belonging different customers customer specific differentiation done 
conjunction need provide differentiated services need manage associated revenue customer specific traffic accounting billing 
necessary different service level assurances charged appropriately 
furthermore service providers flexibility distinguish service providers able tailor service offerings competitive manner choose 
imply routers allow controlled resource sharing permits service providers maximize utilization network meeting diverse customer requirements 
current internet architecture prevalent internet service model best effort model known called send model 
model permit users obtain better service matter critical requirements matter may willing pay better service 
clearly increased internet commercial purposes model differentiation satisfactory isps means meet existing market demand 
internet architecture successful point best effort service model adequate 
current internet architecture evolved network providing reliable connectivity despite link failures thousands users 
internet international network millions users 
control mechanisms originally implemented prevent con gestion collapse depend cooperative users 
network infrastructure incorporate means differentiation severely specific portions network 
network bandwidth keeping network lightly loaded order support differentiated services select customers cost effective solution achieved times 
furthermore commercialized network relying cooperation disparate users congestion control desirable 
assumed users cooperatively slow transmission rates significant congestion detected 
assuming cooperative behavior leads problems especially network means isolating traffic different users enforcing cooperation 
problems users ignore expected correct usage tcp transmissions disabling flow control mechanisms purposely due incorrect implementation 
degrades performance complying users 
malicious users easily degrade network performance routing traffic specific paths increase local congestion 
example reported denial service attacks 
increasing number real time applications udp congestion control 
applications optimal adapt congestion tcp friendly manner 
applications may increase transmission rates lossy periods introducing forward error correction 
uncooperative behavior quickly lead poor performance users network sufficient mechanisms isolating penalizing users 
improving best effort may argued best effort may appropriate provisioning 
form differentiation desirable 
focused overload parts network popular web site heavily accessed event accounted traffic engineering happens routers mechanisms treat different customers differently 
events happen just resources available give reasonable service everybody 
providing form differentiation usually requires network keep state information 
requirement translates increased memory requirements processing power 
majority installed routers architectures experience dramatic decrease performance mechanisms added provide sophisticated differentiating features 
safe assume existing architectures implementing sophisticated functionality network impossible speeds required prohibitively expensive 
commonly held belief sophistication systems core network simple possible 
shift incorporating intelligence network 
current discussions differentiated services ietf example assume edge routers core network smart classify packets different users 
requirements sophisticated differentiated services traditional routers limited terms quality service qos differentiation features research advances hardware capabilities provided ieee communications magazine may slow path fast path slow path fast path switch fabric 
queuing model system uses cache architecture packet processing forwarding 
mechanisms overcome limitations 
router perspective tools providing differentiated services operations done high speeds packet classification distinguish packets group different requirements buffer management determines buffer space certain kinds network traffic packets discarded case congestion packet scheduling decides packet servicing order meet bandwidth delay requirements different types traffic high speed implementation possible new developments areas fair queuing scheduling resulted simple efficient algorithms managing complexity scheduling decisions 
algorithms implemented atm switches showing implemented high speeds packets small atm cell 
state information managed aggregation protocol specific information 
context tcp argument flows numerous backbone flow information maintained 
tcp flows continually backlogged router queues 
providing support tens thousands queues done great expense performance requirements higher number tcp flows met advantage statistical multiplexing 
argument route lookup packet classification expensive operations valid new research areas provides fast efficient algorithms 
new schemes examine complete information ip packet header method classification 
combined fast switching fabrics remove processing bottlenecks traditional routers 
processing models forwarding engines output buffers section describe architectural features necessary ip forwarding engines designed provide differentiated services 
showing traditional router architectures offer differentiated services example routing architecture designed specifically new requirements mind 
forwarding engines able identify context packets determine hop ip link layer addresses assign packet appropri output buffers ate buffering output link bandwidth 
forwarding engine prime point control determining manner packets handled router 
requirement real time operation requirement differentiated services maximum delay header processing larger delay packet service class delay experience 
header processing determines service level accorded packet violation service assurances prior header processing allowed 
tolerable delay packets zero allow constant bit rate circuit emulation type flows get architectural constraint queuing header processing 
implies packet header processing done wire speeds traffic dependent 
traditionally routers cache methods forwarding packets 
justification packet arrivals temporally correlated grouped connections flows packet belonging new connection arrives packets belonging connection expected arrive near 
precisely definition connection sequence packets source destination interarrival times reasoning favor cache architectures packets internet usually initiated applications form connections 
expected behavior packet application processed slow path analyzes complete header 
header packet inserted cache hash table action applied packet packets application 
subsequent packets flow arrive corresponding action determined directly cache hash table 
main problems associated architecture current backbone routers number connections active interface extremely high 
studies shown oc interface average connections active concurrently 
connections hardware caches extremely difficult especially consider fact fully associative hardware cache required 
caches size implemented hash tables hash tables scaled sizes 
lookup time hash table average case result worstcase performance hash table poor multiple headers hash location 
number bits packet headers parsed typically bits hash tables limited couple entries 
hash function able randomly distribute bit keys header bits hash index 
knowledge distribution header values packet arrive router design hash function trivial 
due large number connections simultaneously active router fact hash tables generally guarantee hashing arrival patterns performance cache schemes heavily traffic dependent 
large number new connections arrive time slow path ieee communications magazine may system implements complete header processing temporarily overloaded 
result queuing packets processed 
happens intelligent mechanism applied buffering scheduling packets header processing information available destination packets fields relevant differentiation 
possible congestion packet dropping service quality violation occur due processing overload output link congestion 
better see consider model fig 

packets arrive interfaces placed queue processing 
packet classification hop lookup operations performed forwarded outgoing interfaces queued transmission 
architecture interfaces may idle packets destined interfaces waiting input queues 
example packets destined output blocked slow path processing module packets destined outputs 
output remains idle packets buffers available transmission 
obviously system suffer type head line blocking limit router throughput substantially 
note traditional head line problem input buffered switches diminished knowledge destination packet queue 
fundamental problem system fig 
destination context packet known packet processed 
impossible apply intelligent queuing mechanisms input queues form head line blocking eliminated 
commercial internet infrastructure robust provide predictable performance times 
variations throughput forwarding engines traffic patterns undesirable 
addition network vulnerable attacks malicious users 
malicious user group users discovering limitations hash algorithms caching techniques generate traffic patterns force router slow drop large portion packets arriving particular interface 
summarizing claim packet queuing delays acceptable header processing provisioning differentiated services robustness important 
queuing processing principle applies header processing operation enables router determine service level accorded particular packet 
large queues formed waiting packet processing operation violate service levels connections router determines service level accorded connection 
implication design forwarding engines worst case performance forwarding engine determines true maximum packet processing rate average case performance averaging done traffic arrival patterns 
average case performance determine supported packet processing speeds buffering needed processing 
variance execution emphasized head line blocking refer traditional head line blocking switch fabric 
mean output interfaces may idle packets destined interfaces waiting input header processing buffers 
times header processing functions small delay preprocessing buffer cause service assurances violated 
criteria real time packet processing system constraints list prior discussion criteria differentiated services capable fast router meet router fast support gigabit links 
isps envisage building networks link capacities gb 
backbone router able handle packets speeds 
forwarding engines routers able process packet arriving physical interfaces wire speed 
traffic studies shown percent packets smaller typical tcp packet size bytes 
addition nearly half packets bytes length comprising tcp acknowledgments control segments 
forwarding engines buffering absorb variation execution times operate wire speed packets small bytes 
means forwarding engines provably small worst case execution times independent traffic patterns 
processing engines backbone able perform classification packet filtering operations hop lookup operations 
order routers networks manageable packet filtering route lookup operations aggregated rules classless interdomain routing cidr aggregations 
memory accesses expensive dominant factor determining worst case execution time 
operation high speeds processing algorithms amenable hardware implementation 
overview router architectures give brief overview popular router architectures 
show fail meet requirements imposed dual needs high capacity differentiated services 
single processor shared bus generation routers single general purpose cpu intelligent real time operating system 
choice architecture premise protocols constantly changing operation meant routers optimized specific protocol 
establishing maintaining connectivity far important high forwarding capacity 
routers consisted general purpose computer multiple interface cards interconnected shared bus 
packets arriving interfaces forwarded central processing engine determined hop address sent back outgoing interfaces 
routing control protocols implemented forwarding engine 
obviously performance router depends heavily throughput shared bus forwarding speed main processor 
single processor perform multiple real time operations selection operating system critical importance lot emphasis placed sophisticated design operating system 
architecture scale meet increasing throughput requirements interface cards 
ieee communications magazine may interface cards route controller high speed interconnect forwarding engines 
router architecture multiple parallel forwarding engines separated interface cards 
load balancing mechanism attempts equalize processing load forwarding engines 
multiple processors shared bus generation routers packet transmitted twice shared bus interface cards processor processor outgoing interface card 
straightforward improvement introduced second generation routers distribute forwarding computation 
interface cards intelligent addition fast processors caches 
allowed process packets locally time 
packet connection forwarded main forwarding engine 
cache entry added interface card cache allows subsequent packets connection forwarded directly interfaces 
cache entry connection route basis 
argument number connections large number routes needed probably large 
network core highest forwarding speeds required true packets destined parts network localized specific subnets 
packets distributed router network 
architecture clearly traffic dependent throughput shared bus bottleneck 
memory sizes increased cost dropped distributed interface cards enhanced larger memories complete forwarding tables copied interface card 
approach enhanced performance routers 
shared bus architecture general purpose cpus scale higher capacity links traffic pattern independent throughput 
multiple processors space switching third generation routers designed alleviate obvious bottlenecks second generation routers 
congested shared bus replaced crossbar switch providing sufficient bandwidth transmitting packets interface cards allowing throughput increased orders magnitude 
forwarding path interface cards bottleneck anymore new bottleneck packet processing 
third generation router architectures general purpose cpu designs handle large link capacities 
shared parallel processors space switching nice concept parallelizing packet processing able scale processing speeds considerably introduced 
basic observation highly interfaces time 
sharing forwarding engines increase port density router 
shared processor architecture fig 

forwarding engines responsible resolving hop addresses 
results hop address resolution sent back interface cards subsequently forward packets outgoing interfaces 
note packet headers forwarded forwarding engines 
eliminates unnecessary packet payload transfer switch fabric 
packet payloads directly transferred interface cards go forwarding engines controller specifically destined 
possible forwarding engines added system reach necessary forwarding capacities high speed backbones 
assumption architecture single processor able handle peak throughput particular interface processing pool shared multiple interfaces necessary 
time required process packet depends actual load forwarding engine 
load balancing mechanism done connection basis order transmissions trigger tcp fast retransmits degrade performance 
timescale load balancing done timescale connection interarrival times order magnitude different timescale packet arrivals 
connection assigned processor load processor increases hard predict traffic generated connection load balancing decisions packets queued long periods processing cause violation service assurances connection 
claimed number forwarding engines sufficiently large high probability forwarding engine free 
true clear cost effective note copy forwarding databases kept forwarding engine kept consistent 
architectures discussed far promising 
router architecture scale large forwarding speeds providing worst case traffic independent bounds processing times 
optimizing packet processing evident increasing link capacities need differentiated services stretch processor architectures limit 
multiprocessor architecture described previous section attempts address issues forwarding engines perform packet processing packets arriving particular sets links 
section develop economical efficient solution functional partition packet processing processing element optimized specific task operating wire speed traffic independent manner 
step necessary approach identify main functions forwarding process 
example enumeration functions discussed detail subsequent sections buffer forward packets switching fabric 
apply filtering packet classification 
determine hop packet 
forwarding databases created routing protocols determine outgoing interface packet sent specific link layer addresses 
architecture studied processing signaling protocols 
useful load balancing schemes detailed performance analysis 
ieee communications magazine may queue packet appropriate queue classification decisions route table lookup 
schedule packet transmission outgoing links meet qos requirements 
common aspect processing functions inputs packet header data structures created protocols routing protocols 
processing element executes functions access packet data structures 
multiple processors forwarding packets packet completely processed complete data structures date processor 
obviously synchronization problems achieving nontrivial see performance analysis problem context processing signaling protocols 
addition packet requires accesses different databases locality data structures required processors 
processors keep forwarding information data structures memories required large generally slow 
easy way exploit special requirements packet processing increase performance reduce cost 
architecture shown fig 

packets arrive interfaces processing functionally split multiple processors processor handles packet processing functions necessary forwarding 
forwarding functions described processors required 
processor performs type function processor need access data structures associated particular function 
necessary keep information related forwarding processor 
memory required processor smaller faster cheaper 
specializing task processor performs possible get high locality program memory accesses 
additional advantages architecture connection level assignment processing units connections 
previously discussed multiprocessor architecture assignment needed load balancing disadvantages pointed 
architecture flow identification required storing packets output link queues 
importance operating system diminished 
processor single processing element dedicated function 
higher throughput desirable application specific integrated circuits asics replace processing elements easily 
function nature processor enables efficient hardware implementation 
note combination architecture multiple shared processors architecture possible may cost efficient 
minor problem communication interfaces processors add additional constant latency packet forwarding 
see subsequent sections individual functions implemented wire speeds traffic independent manner backbone link rates 
architecture supports twin requirements high speed differentiated services 
variant architecture developed implemented part bell laboratories router project 
router designed interface card process packets processing elements implemented field programmable gate arrays physical interfaces switch interface 
processing architecture parallelism achieved partitioning forwarding functions different processors 
fpgas system speed mhz 
obtaining high throughput differentiated services features low clock speed evidence scalability architecture 
route table lookup filter processor long time route table lookup considered challenging operations performed forwarding process 
problem defined searching database destination prefixes locating longest prefix matches destination address packet 
longest prefix matching introduced consequence requirement increase number networks addressed cidr 
approaches longest prefix matching radix trees modified patricia trees combined hash tables 
lookup algorithms complexity proportional number address bits ipv 
algorithms route lookup complete ns memories resulting forwarding rate packets radix trees changed radix greater time required lower expense wasted memory space 
early implementations routers afford expensive computations 
routers relied connection route caches 
cache architectures result unpredictable performance 
furthermore rapid internet growth clear anymore effective caches network backbones 
research resulted faster solutions 
stratified tree algorithms proposed van emde boas utilized de berg van kreveld snoeyink propose algorithms dimensional point location problem restricted discrete valued ranges log complexity number bits required represent range endpoints 
technique context route table lookups 
main idea create perfect hash table prefixes prefix length 
binary search prefix lengths hash tables searches prefixes particular length find longest prefix match log time 
algorithm fast execution times calculating perfect hashes slow slow updates 
elegant approach proposed 
basic principle create small compressed data structure exploiting sparseness actual entries space possible routing table entries represents ieee communications magazine may scheduler forwarding engine route lookup buffering large lookup tables small amount memory 
results lower number memory accesses fast memory faster lookups 
addition algorithm calculate expensive perfect hash functions updates route table easily done 
approach implementing compression minimizing complexity updates 
packet filtering classification important requirements forwarding engines support differentiated services ability identify context packets apply actions necessary satisfy service requirements 
mechanisms support functions termed packet filtering packet classification 
traditional application packet filters provide firewall security functions 
important application support differentiated services identification classification packets originated specific sites customers provide resources necessary meeting customer specific differentiated services requirements 
large scale packet filtering functionality enables edge routers core routers support differentiated services flexible customer specific restricted service offerings interpretation tos bits 
packet filters parse large portion packet header including information concerning transport protocols forwarding decisions 
parsing set rules defined network management software real time reservation protocols rsvp 
actions packet filters may apply include traditional security functions dropping unauthorized packets redirection packets proxy servers actions related queuing scheduling routing decisions criterion destination address 
desirable attributes packet filtering filter rules apply ranges addresses port numbers protocols restricted exact matches 
allows rules apply aggregates keeps number rules specified manageable 
filter algorithms handle exact matches preprocessing translate ranges filter rules exact values 
unfeasible size ranges grows exponentially length packet field ranges defined 
rules assigned explicit priorities order resolve conflicts rules overlap 
general packet classification problem general packet classification problem viewed point location problem multidimensional space set dimensional objects represent filter rules point dimensional space represents arriving packet problem find object contains point 
classic problem computational geometry numerous results reported literature 
considering general case dimensions problem packet classification best algorithms considering time space log complexity space log time industry forwarding decisions transport protocol information referred layer forwarding 
complexity space 
algorithms complexity bounds useful applications directly useful packet filtering 
illustrate assume router able process rules dimensions sustain packets throughput 
algorithm log execution time space requires memory accesses packet 
impractical current technology 
logn time space algorithm space requirement prohibitively large range gbytes 
furthermore algorithms addresses problem arbitrary overlaps 
results mean packet filtering done high speeds constraints problem applied routers 
sketch ideas prototype implementation 
interested readers referred details implemented algorithm 
simple approach problem multidimensional search packet filtering decomposable search 
idea state original query intersection numbers simpler queries 
challenge instance obtain poly logarithmic solution decompose problem intersection step take time required bound 
pointed log solution packet filtering practical application thousands 
need employ parallelism sort 
require simple elemental operations algorithm amenable hardware implementation 
algorithms best asymptotic bounds interested decomposing queries subquery intersection done fast memory access cost metric thousands memory word lengths feasible current technology 
illustrate algorithm example dimensions 
rules represented dimensional rectangles arbitrarily overlap 
preprocessing step algorithm projects edges rectangles corresponding axis 
worst case projection results maximum intervals dimension 
associate set rules dimension 
rule belongs set corresponding rectangle overlaps interval set corresponds 
assume packet arrives system 
online step locate intervals axes contain point 
second step sets locate highest priority rectangle covers point simple intersection operation 
algorithm implemented dimensions high speed router prototype single fpga device synchronous sram chips supporting rules processing packets worst case 
achievable despite device run low speed mhz 
memory chips caches pcs cost memories low 
device coprocessor general purpose processor handles parts ip forwarding firewall functions 
improved algorithm process filter rules packets mhz clock 
classification dimensions classification problem increasing importance evolving internet architecture 
rsvp similar reservation protocols offer qos guarantees specific flows clear reservation ieee communications magazine may model scaled operation high speed backbones large number flows concurrently active 
alternative approach proposed route aggregated flows specific traffic engineered paths 
directed routing destination address packets source address 
rsvp similar reservation protocols setting aggregation routing rules 
key mechanism needed support scheme high speed core router dimensional classification lookup scheme determines hop associated resource allocations packet function source destination addresses 
dimensional classification useful setting traffic engineered source destination paths multicast forwarding requires lookups source address multicast groups 
dimensional lookup problem restricted case general classification problem rules dimensions source destination address defined terms cidr prefixes 
rules overlaps priority rules resolve conflicts 
ip routers interested solutions scale hundreds thousands entries 
operations interested worst case performance algorithms want avoid queuing header processing order provide qos guarantees 
fast algorithm problem 
shown number possible prefix lengths filter rules number memory accesses possible process packets mhz clock speed 
combining fast filtering dimensions source routing widens range options feasible evolving current best effort internet internet capable providing customized differentiated services 
specifically may need restrict filtering edges simple operations tos bits ip packet header 
resource management previous sections discussed processing power scarce router resources managed meet new differentiated services requirements internet 
important principle queuing processing consequent architectural choices worst case engineering 
critical resource output link bandwidth 
coupled management output link bandwidth buffer allocation 
section focused bandwidth buffer management 
buffer bandwidth allocation jointly addressed 
scheduler dynamic bandwidth allocation merely gives opportunities connections link access 
connection packets waiting transmitted opportunity wasted schedulers retain lost opportunities credits 
adaptive connections especially important provision transmission opportunities scheduling coupled proper buffer allocation ensures connections link access opportunities achieve desired level link sharing 
desired level link sharing set classes packets administrative means dynamic reservations rsvp signaling 
packet filtering mechanisms map arriving packet classes 
schedulers determine sequence packet transmissions link account desired link sharing packets dif ferent classes currently system history service sequence fair queuing scheduler summarized called system potential elaborated 
distinguish types connections impact scheduling 
nonadaptive connections packet arrival rates independent past scheduling decisions 
examples openloop udp traffic video audio streams 
bandwidth requirements connections set provisioning mechanisms established signaling 
provisioning usually done aggregate level requirement amount bandwidth ensured connections certain type sites network 
bandwidth establishment signaling done rsvp allows setting aggregate reservations 
irrespective mechanism resource control mechanisms required node enforce reservations 
adaptive flows adapt transmission rates scheduling decisions past round trip time ago 
example tcp connections constantly probe available bandwidth increasing transmission rates response available network bandwidth 
adaptive flows particular tcp flows loss sensitive adaptation require careful buffer management conjunction scheduling 
need tcp aware buffer management pointed 
discuss tcp aware buffer management detail article 
requirement imposed commercialization internet user specific differentiated service models supported infrastructure serve different user requirements 
state ofthe art candidate scheme bandwidth allocation meet differentiated services requirements hierarchical link sharing hierarchical weighted fair queuing 
discussed 
hierarchical link sharing hierarchical link sharing flexible resource management scheme allows partitioning resources levels aggregation 
initially proposed expanded 
hierarchical link sharing partitions bandwidth hierarchy classes class defined set flows specific properties packets belong protocol packets traveling specific subnets 
levels hierarchy include lowest level packets individual application 
hierarchical link sharing model proposed illustrated fig 

main idea link capacity partitioned different administrative domains domain partitioned application types 
going step bandwidth application type partitioned individual flows type 
different view model link capacity partitioned classes traffic bandwidth traffic class partitioned administrative domains individual flows 
prototype implements hierarchical weighted fair queuing extra advantage schemes hierarchy levels making implementation simpler 
model extended theory shaped rate proportional servers node hierarchy shaped rate proportional ieee communications magazine may mb server 
node hierarchy may share excess bandwidth nodes level may shape traffic particular bandwidth allocation 
implementation node hierarchy allowed shaped virtual clock provides ideal shaping traffic starting potential fair queuing allows fair distribution bandwidth competing classes 
algorithms shaped rate proportional servers exact data structures 
advantage general mechanism best explained example 
assume administrative domain want support types traffic constant bit rate cbr best effort 
second administrative domain want give voice traffic full priority best effort traffic 
third administrative domain different levels best effort service 
assignment schedulers weights shown fig 

assign virtual clock scheduler cbr traffic fair queuing scheduler best effort traffic domain 
mechanism allows best effort traffic get excess bandwidth available classes 
domain assign bandwidth high priority voice traffic 
result best effort traffic serviced voice traffic 
third domain assign different weights different levels best effort service 
advantage scheme data structures algorithms provide variety services different administrative domains applications 
question aggregation flow level 
possible implement flow queuing large number flows derive advantages 
clearly flow isolation benefit flow queuing 
enhanced tcp performance combining flow queuing tcp aware buffer management benefit 
discussed detail 
scalability flow queuing prevailing assumption flow queuing prohibitively expensive routers keep state flows hundreds thousands active flows network backbones 
notion active flow flow active long interarrival time packets source destination cbr mb mb mb mb mb mb mb voice svc link oc mb mb flow queuing selected classes traffic 
application hierarchical link sharing 
node shaped virtual clock svc start potential worst case fair queueing scheduler 

notion useful purpose study mechanisms ensure small number packets forwarded slow path handled cached fast path 
problem basis maintaining flow state scheduling purposes flow queuing schemes overly conservative 
maintaining state active flow necessary provide guarantees fair queuing extreme situations 
mainly types state flow queuing mechanism maintain weights individual flows information service offered flows providing differentiated services cases weights established set flows characteristics individual flows 
example differentiating tcp ftp flows tcp telnet flows 
packet filtering function performs differentiation typically filter rules classify flows class separate class flow 
weight class established flow different queue enable flow queuing mechanism isolate flows guarantee desired differentiation 
discussed state information necessary provide isolation required maintain state active flow 
ideal weighted fair queuing weighted fair queuing schedulers emulate fluid flow system constraints packet system 
ideal fluid flow system packets infinitely divisible backlogged flows simultaneously served rate proportional assigned weights 
scheduler instantaneous service offered individual flow determined weight assigned flow weights assigned flows currently backlogged 
need scheduler keep state flow currently backlogged 
number backlogged flows limited available buffering number flows state maintained limited numbers determined buffer availability 
non ideal weighted fair queuing packet fair queuing schedulers emulate ideal fluid flow system maintain state information fluid flow system information related state packet system 
packet scheduler emulate fluid flow system exactly packets different flows served time 
worst case set flows backlogged fluid system set flows backlogged packet system may completely disjoint 
case maximum state information packet fair queuing system maintain approximately twice fluid flow system 
lower number active flows 
class schedulers defined simple mechanisms extract state fluid flow system actual state packet system 
information ieee communications magazine may schedule packets packet system 
schedulers associate function flow connection called connection potential tracks normalized service offered connection connection active 
system potential keep track normalized service offered flows current system busy period 
flow newly backlogged flow potential calculated maximum previous value value system potential 
types schedulers bound difference connection potential flow system potential 
schedulers addition backlogged flows state maintained small subset flows backlogged immediate past 
furthermore case self clocked fair queuing system potential larger connection potential flow 
state maintained backlogged flows see detailed discussion 
summarizing ideal weighted fair queuing scheduler scheduler worst case number flows equal number packets system 
example assume router supports oc link mb bandwidth 
assume average packet size bytes 
assuming buffer size equivalent ms easy verify maximum number flows backlogged router reasonable number current technology limitations 
tcp aware buffer management tcp controlled traffic constitutes significant component internet traffic natural incorporate mechanisms routers enhance tcp performance 
general criteria act guideline 
long tcp flows transfers larger obtained bandwidth delay product keep link share close desired possible 
short transfers small queuing delays tcp flows telnet flows 
achieve tcp performance presence cross traffic tcp controlled uncontrolled controlled manner unfair tcp sources 
keep link utilization high possible 
tcp observations traffic burstiness tcp creates bursty network traffic 
data transmission tcp ack clocked acks bunch fifo queues create burstiness 
tcp slow start bursty due doubling window sizes round trip time 
losses slowstart phase lead poor throughput buffering equal approximately third bandwidth delay product needed avoid losses slow start phase 
keep throughput high especially long transfers generally accepted rule thumb buffering equal bandwidth delay product 
large buffers packets quasi delay sensitive applications telnet may queue large slowstart burst file transfer experience large queuing delays despite mechanisms red :10.1.1.128.5092
separate telnet sources 
normalized service defined ratio offered service allocated bandwidth 
ease exposition explain case link sharing class equal fair link sharing 
fcfs red fq red fq offered load cbr source link speed 
aggregate throughput tcp sources ms rtt sharing link loss insensitive cbr source 
unfairness known tcp inherently unfair connections long round trip times unfairness bad inverse square roundtrip times :10.1.1.41.7640
implies active tcp aware buffer management routers alleviate unfairness suggested 
synchronization reason buffer management drop tail queuing tcp windows synchronize leading poor oscillatory link utilization 
necessary reduce synchronization appropriate buffer management 
random loss sensitivity tcp assumes loss congestion loss reduces transmission rate drastically tcp throughput vulnerable loss 
fixed loss rate throughput goes inverse square bandwidth delay product 
loss sensitivity increased slow reverse path ack path congested 
sensitivity increase proportional ratio transmission time ack packets reverse path data packets forward path 
random losses caused transient fast faster round trip times fluctuations open loop traffic uncontrolled udp traffic 
buffer management protect tcp sources losses caused tcp unfriendly sources sources react losses reducing transmissions fast tcp 
flow fair queuing sufficient achieving tcp performance goals 
flow fair queuing provides fair opportunities transmit 
flow backlog due small windows instance fair opportunities transmit translate fair link sharing 
proper buffer management needed conjunction fair queuing ensure tcp flows share available bandwidth fair manner controlled unfair manner desired 
link sharing goals tcp achieve high throughput fairness bandwidth sharing competing tcp connections protection conforming connections malicious users reduce known ack compression phenomenon tcp causes network traffic bursty smooth sources provision low latency telnet applications delay sensitive tcp ieee communications magazine may total goodput tcp sources buffer management sufficient 
absence flow queuing control link sharing achieved buffer management packet discard schemes random early detection red drop front 
goals achieved lack flow state hampers degree goals achieved 
goals achieved better combination flow queuing appropriate buffer management 
tcp aware buffer management fair queuing merely dividing available buffer space red queue appealing buffer space wasted drastically 
buffer usage share buffer space different flows 
red shared buffer space breaks natural flow isolation queuing provides see example allows tcp connections affected tcp unfriendly sources 
fair queuing uncontrolled buffer usage flow leads unfairness 
solution give flow nominal reserved buffer space 
nominal allocations set proportion weights ratio bandwidth round trip times known 
flow buffer usage exceed reservation unused buffer space available 
total buffer occupancy exceeds global threshold new packet arrives packet buffer pushed 
candidate queues eligible pushout queues occupancy nominal allocation 
candidate set pick queue excess occupancy longest deviation nominal location 
reason pick longest queue tcp flows short roundtrip times high bandwidth usage longest queues nominal windows grow faster flows longer round trip times 
alleviate unfairness long round trip time connections dropping longest queue 
tcp unfriendly flows long queues 
longest queue drop front 
drop front triggers tcp fast retransmit feature quickly reducing length congestion episodes improving link utilization 
improves fairness fifo queuing reduces chances windows synchronizing 
useful mechanism dropping acks case ack congestion tcp acks cumulative 
fair queuing eliminates chance standard deviation mean fraction integral throughput fcfs red fq red fq link speed equivalent buffer ms 
coefficient variation versus buffer size tcp connections differing round trip times 
retransmitted packets lost 
loss retransmitted packets leads expensive tcp timeouts consequent loss throughput 
buffer management scheme protects tcp sources tcp unfriendly flows 
buffer management need applications reliable multicast rtp applications tcp friendly congestion control 
applications adapt traffic manner preferable having comply tcp congestion control mechanism 
tcp aware buffer management eliminates need applications tcp aware 
useful aspect buffer management allows tcp larger initial windows speeding completion short transfers affecting tcp flows 
protection tcp unfriendly sources protection buffer management scheme gives tcp sources illustrated fig 

shows fraction link bandwidth persistent tcp sources sharing link loss insensitive tcp unfriendly source 
sending rate unfriendly source varied zero twice link bandwidth 
consistent overload produced source buffer management dropping strategy stronger impact bandwidth sharing scheduling policy 
tcp unfriendly source increases rate fcfs fair queuing global random early detection red similar performance degradation 
longest queue drop policies marked denote approximated longest queue implementation fq scheduler able perfectly maintain guaranteed rate flow irrespective flow totally loss insensitive 
shows coefficient variation throughput different tcp flows share common link fair queuing red buffer management scheme proposed previous section 
clearly proposed buffer management scheme better fairness red 

forward engine bell laboratories router prototype 
ieee communications magazine may implementation issues long standing assumption implementation large scale flow queuing hierarchical link sharing possible reasonable cost current technologies 
prototype implementations gigabit routers flow queuing hierarchical link sharing shown possible implement mechanisms necessary scale high speeds 
primary limitation applying intelligent buffer management scheduling mechanisms processing elements performing functions header processing limited throughput functionality increased 
distribution processing functional basis packet basis shown fig 
allows throughput increased considerably increasing functionality 
furthermore state information needed flow queuing prohibitive assumed 
bell laboratories router prototype shown fig 
demonstrated flow queuing hierarchical link sharing implemented scale necessary backbone routers single fpga device running mhz supporting output link capacities mb switch fabric switch fabric design studied area especially context atm networks detailed discussion switch fabric design issues omitted brevity 
key point keep mind transport fabric done service preserving manner 
discussion internet ongoing evolution best effort network network service differentiation important topic interest type differentiated services service providers may want provide 
possibility encode tos bits set canonic differentiated service types incorporate mechanisms network infrastructure 
clear simple evolutionary approach satisfy differentiated services demands 
point view taken article possible incorporate routers current technology mechanisms addition enabling simple differentiated services proposed enables differentiated services sophisticated ability meet specific customer needs 
required mechanisms header processing done wire speed queuing processing packet classification range matching fields large number rules extending route lookups source destination lookups flexible general scheduling buffer management techniques qos capable switch fabric mechanism flow isolation mechanisms routers aggregate customers flexible manner isolate individual customers traffic allocate resources customizable manner 
permits isp customize service offerings suit customer demands offering services customized service virtual leased lines 
restricting router functionality simple differentiated services possibilities due technology constraints necessary 
acknowledgments authors members bell laboratories router team wo responsible building prototype router encompassing ideas discussed article 
particular singh contributions 
claffy internet traffic characterization ph thesis uc san diego 
claffy polyzos braun application sampling methodologies network traffic characterization proc 
acm sig comm sept pp 

jain packet trains measurements new model computer network traffic ieee jsac vol 
pp 

thomson miller wilder wide area traffic patterns characteristics ieee network dec 
mckeown anantharam achieving throughput input queued switch proc 
infocom mar pp 

fuller classless inter domain routing rfc ftp ds internic net rfc rfc txt june 
zhang rsvp new resource reservation protocol ieee network vol 
sept pp 

partridge locality route caches nsf wksp 
internet statistics measurement analysis san diego ca feb 
design gigabit ip router tech 
rep tm bell labs nov 
gigabit ip router high speed networks vol 

lakshman huang parallel architectures processing high speed network signaling protocols ieee acm trans 
networking dec pp 

tree routing table berkeley unix tech 
rep uc berkeley 
routing longest matching prefixes ieee acm trans 
networking vol 
feb pp 

improving gateway performance routing table cache proc 
ieee infocom new orleans li march 
van emde boas preserving order forest logarithmic time proc 
th ieee conf 
foundations comp 
sci pp 

van emde boas design implementation efficient priority queue math 
sys 
theory vol 
pp 

de berg van kreveld snoeyink dimensional point location rectangular subdivisions algorithms vol 
pp 

waldvogel scalable high speed ip routing lookup proc 
acm sigcomm france sept 
small forwarding tables fast routing lookups proc 
acm sigcomm france sept 

longest prefix search compressed trees tech 
rep tm bell labs submission 
clark service allocation profiles internet draft www internic 
net internet drafts draft clark diff svc alloc txt 
nichols blake differentiated services operational model definitions internet draft feb 
ds internic net draft nichols txt 
chazelle search history info 
control vol 
pp 

chazelle friedman point location hyperplanes unidirectional ray shooting comp 
geometry theory apps vol 
pp 

clarkson new applications random sampling computational geometry discrete comp 
geometry vol 
pp 

overmars van der range searching point location fat objects algorithms vol 
pp 

lakshman packet classification algorithms gigabit internet routers tech 
rep lucent technologies bell labs jan appear proc 
acm sigcomm 
li rekhter provider architecture differentiated services traffic engineering paste internet draft www internic 
net internet drafts draft li paste txt 
boyle rsvp extensions cidr aggregated data flows internet draft www internic net internet drafts draft ietf rsvp cidr ext 
txt 
estrin protocol independent multicast sparse mode protocol spec 
rfc june 
ieee communications magazine may partridge deering distance vector multicast routing protocol rfc ftp ds internic net rfc rfc txt june 
golestani self clocked fair queuing scheme broadband applications proc 
ieee infocom apr pp 

varma design analysis frame fair queuing new traffic scheduling algorithm packet switched networks proc 
acm sigmetrics www cse ucsc edu research publications may pp 

recommendations queue management congestion avoidance internet internet draft mar 
design considerations supporting tcp flow queuing proc 
ieee infocom san francisco ca 
efficient active queue management internet routers proc 
interop engineers conf las vegas nv may 
lin morris dynamics random early detection proc 
acm sigcomm sept 
clark shenker zhang supporting real time applications integrated services packet network architecture mechanism proc 
acm sigcomm aug pp 

floyd jacobson link sharing resource management models packet networks ieee acm trans 
networking vol 
aug pp 

bennett zhang hierarchical packet fair queuing algorithms proc 
acm sigcomm palo alto ca aug pp 

varma general methodology designing efficient traffic scheduling shaping algorithms proc 
ieee infocom 
newman flow labelled ip connectionless approach atm proc 
ieee infocom san francisco ca apr pp 

parekh gallager generalized processor sharing approach flow control single node case proc 
infocom vol 
may pp 

demers keshav shenker analysis simulation fair queuing algorithm internetworking res 
experience vol 
pp 

varma rate proportional servers design methodology fair queuing algorithms ieee acm trans 
networking apr 
shenker zhang clark observations dynamics congestion control algorithm comp 
commun 
rev oct pp 

zhang shenker clark observations dynamics congestion control algorithm effects way traffic proc 
acm sigcomm pp 

lakshman madhow performance tcp ip networks high bandwidth delay products random loss ieee acm trans 
networking june 
floyd jacobson random early detection gateways congestion avoidance ieee acm trans :10.1.1.128.5092
networking aug 
floyd jacobson traffic phase effects packet switched gateways internetworking res :10.1.1.41.7640
experience vol 
sept pp 

zhang new architecture packet switching network protocols ph thesis mit comp 
sci cambridge ma 
ott mathis stationary behavior ideal tcp congestion avoidance ftp ftp bellcore com pub ps 
lakshman madhow window error recovery flow control slow acknowledgment channel study tcp ip performance proc 
ieee infocom kobe japan apr 
lakshman ott drop front strategy tcp atm interworking control features proc 
ieee infocom san francisco ca pp 

tobagi fast packet switch architectures broadband integrated services digital networks proc 
ieee vol 
nov pp 

kumar low cost scalable switching solutions broadband networks ieee commun 
mag vol 
dec pp 

design performance implementation stage architecture input output buffers large fast packet switches tech 
rep csl tr csl stanford ca june 
anderson high speed switch scheduling local area networks acm trans 
comp 
sys vol 
nov pp 
digital systems research center tech 
rep 
varma providing bandwidth guarantees input buffered crossbar switch proc 
infocom apr 
biographies vijay kumar vijay bell labs com head high speed networks research bell laboratories lucent technologies 
responsible research development algorithms architectures protocols chips systems high speed data networking 
responsible making generation routing engines products 
obtained bachelor engineering degree electronics communication engineering university india ph degrees electrical computer engineering university iowa iowa city respectively 
bell laboratories conducted led research activities fast packet switching vlsi communication architectures fault tolerant networking vlsi yield enhancement 
resulted atm gigabit routing engine differentiated services 
lakshman lakshman research bell labs com received ph degree computer science university maryland college park 
prior received master degree department physics indian institute technology bangalore india 
bellcore senior research scientist technical project manager information networking research laboratory 
currently high speed networks research department bell laboratories 
research issues related traffic characterization provision quality service video services architectures algorithms gigabit ip routers flow control high speed networks traffic shaping policing switch scheduling parallel architectures fast signaling connection management high speed networks 
current research interests areas high speed networking distributed computing multimedia systems 
acm sigmetrics performance conference outstanding award 
editor ieee acm transactions networking 
dimitrios bell labs com received diploma computer engineering informatics university patras greece 
received ph degrees computer engineering university california santa cruz respectively 
currently member technical staff high speed networks research bell laboratories leading architecture design gigabit router supporting differentiated services 
current research interests include traffic scheduling network performance analysis architectures fast forwarding engines 
ieee communications magazine may 
