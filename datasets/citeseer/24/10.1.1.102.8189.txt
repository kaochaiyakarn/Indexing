evaluation economy file replication strategy data grid william bell david cameron paul millar kurt stockinger university glasgow glasgow qq scotland itc irst sommarive povo trento italy cern european organization nuclear research geneva switzerland optimising grid resources critical users effectively exploit data grid 
data replication considered major technique reducing data access cost grid jobs 
evaluates novel replication strategy economic model optimises selection replicas running jobs dynamic creation replicas grid sites 
model optimisation agents located grid sites auction protocol selecting optimal replica data file prediction function informed decisions local data replication 
evaluate replication strategy data grid simulator developed authors 
experiments show proposed strategy results notable improvement traditional replication strategies grid environment 
grid computing novel emerging paradigm goal providing virtual organisations geographically distributed users software hardware infrastructures allow effective sharing computational storage resources 
international projects currently working realisation data grids analysis huge amounts distributed data computationally intensive applications 
data grid provide virtual organisations set services automate access resources bringing needs single user typically minimisation execution cost jobs agreement demands virtual organisation users members maximisation grid resource exploitation 
data important resource data grid users jobs require access large quantity data 
data stored files spread geographically diverse grid sites 
execution cost job may vary considerably depending computing resource chosen job execution location data files job requires access 
data replication considered important technique reduction job execution cost 
replication involves creation identical copies data files distribution various grid sites 
reduce data access latency increase robustness grid applications 
order grid performance improved essential data access replication services able deal dynamic changes grid environment 
particular dynamic distribution data files file requests jobs strategies able 
determine best replica request job particular file 
trigger replication deletion data files grid sites analysing patterns previous file requests affecting migration files sites show corresponding increased frequency file access requests 
authors proposed approach economic model aims fulfil requirements 
model data files represent goods market traded different optimisation agents grid site file requests running jobs 
idea underlying model achieve global optimisation replica distribution emergent marketplace behaviour 
economic approach currently evaluated data grid simulator called 
developed study complex nature typical data grid evaluate effectiveness replica optimisation algorithms environment 
early results evaluation replication strategy simplified version proposed economic model considered 
extend economy replica optimisation strategy 
introduce novel auction protocol optimal replica selection discuss prediction function file values turn triggers dynamic replication highly requested data files 
order evaluate efficiency algorithm run set benchmarks grid simulator real world data grid testbed high energy physics 
related economic approaches grid computing mainly minimise cost job scheduling 
briefly describe examples refer complete overview 
spawn system provides market mechanism trading cpu times network workstations 
popcorn project provides infrastructure globally distributed computation market mechanisms buying selling cpu time vickrey auction protocol 
popcorn currently central market scale large number concurrent buyers sellers 
nimrod economy driven resource broker scheduling parametric computations typical grid environment 
resource allocation deadline budget constraint scheduling algorithm goal minimising runtime jobs minimising cost usage grid resources 
location data considerations optimal replica selection part scheduling algorithm 
various examples replication caching strategies discussed tested simulated grid environment combination scheduling algorithms studied 
replication algorithms proposed assumption popular files site popular sites 
replication site triggered popularity file overcomes threshold destination site chosen randomly selecting loaded site 
take complementary approach 
replication algorithms grid sites need data locally assumption computational grids areas particular sets data highly requested 
design simulates grid architecture shown studying various file replication approaches particular economy replication strategies section 
simulation constructed assuming grid consists sites may provide computation data storage resources called computing storage elements data intensive jobs 
computing element replica manager replica optimiser storage element resource broker job execution site job execution site computing element replica manager replica optimiser storage element 
simulated datagrid architecture 
jobs submitted grid period time resource broker rb 
rb schedules job computing elements ce goal improve throughput grid 
replica manager rm site manages data flow sites interfaces computing storage resources grid 
replica optimiser ro inside rm responsible selection dynamic creation deletion file replicas 
data grid highly dynamic environment important able cope changes status resources performing allocation grid jobs 
particular avoid making irrevocable decisions job scheduling time file replicas access data particular job 
optimisation performed points time life time job 
optimisation phase occurs rb determines ce job run 
refer phase scheduling optimisation 

second phase optimal dynamic replica selection achieved run time job auction mechanism describe section 
final phase replication triggered third party sites 
dynamic replica optimisation 
detail algorithms phases sections 
scheduling optimisation scheduling algorithm takes account locality files requested jobs ce loads 
calculation file accessing cost implemented ro function 
ce candidate scheduling rb calls list files required job 
function consults replica catalogue find replicas file calculates time access replica ce examining current network status :10.1.1.135.3823
summing times access best replica file returns estimated file access time job scheduled ce 
concerned time complete job time job submitted grid time finished executing ce take account workload ce 
combined cost simply adding file transfer cost obtained number jobs waiting queue ce shown 
cost scheduling algorithm schedules job ce minimum combined cost 
replica selection job running ce requires access files order process data 
multiple copies file available grid ro function called file requested job 
function uses auction mechanism described section return best available replica 
depending popularity file replication may occur deemed economically profitable see section details 
dynamic replica optimisation grid sites monitor log patterns file requests time 
particular file appears popular site decides profit purchasing replication triggered third party sites involved initial request file 
way data migrate areas data requested 
economy optimisation strategy propose economic model data access replication optimisation phases 
model data files purchased ces running jobs storage elements se investment improve expected revenue 
files sold ses ces ses 
ces try minimise file purchase cost ses attempt maximise profits 
ces ses interact intelligent optimisation agents perform reasoning required model 
adoption economic approach main motivations 
reason able replication optimisation decisions distributed manner 
performing complex multidimensional optimisations centralised manner difficult domain attributes resources controlled large 
restricting local optimisation economic interactions problem manageable try improve performance emergent marketplace behaviour 
second reason data grid highly dynamic environment availability resources change warning 
economic model exploit dynamism market informed decisions job execution time 
internals economic model current implementation file costs proportional time needed retrieve depends available network bandwidth grid sites 
way goal minimising file purchase cost results improvement cumulated job execution time 
grid service performs optimisation data access replication replica optimiser ro 
distributed service provided set ro agents grid site see 
ro agent invoked grid job running local ce needs access data file 
ro able select cheapest replica file possibly triggering file replication grid sites predicted improve grid performance 
architecture ro agents includes components access mediator am 
component processes file requests jobs running ce 
requested file starts auction identify cheapest replica file see section details 
am gathers bids file local remote storage brokers sb selects winner auction notify bidders winner 
mediator pm 
responsible establishing maintaining peer peer communications infrastructure grid sites 
propagate auction messages ams sbs 
storage broker sb 
component responsible listening file request messages local mediator 
meet request file stored corresponding se responds immediately mediator 
file stored corresponding se may start nested auction order obtain local replica file able reply parent auction 
grid site exclude ces ses components absent available ro agents site 
depicted 
shows example data grid containing sites 
site contains computing storage elements local ro agents comprise components 
sites include components needed local ro agents simpler 
computing element computing element computing element replica optimiser replica optimiser storage broker storage element site access mediator mediator site mediator storage broker storage element replica optimiser storage broker storage element computing computing element element computing element replica optimiser mediator storage broker storage element site site access mediator mediator storage broker storage element 
components economy grid model 
auction protocol economic model goal auction protocol select cheapest replica file needed job running ce 
type vickrey auction 
vickrey auctions second price sealed bid auctions 
involve single negotiation round bidder submits bid auctioneer 
bidders see bid 
winner auction agent highest bid pays price second highest bid 
advantage type auction dominant strategy bidder bid true valuation 
fact bidding true valuation clearly risky strategy won auction asked pay higher price 
hand bidding true valuation reduce chances winning 
bidding true valuation best strategy agent 
maximises chances winning auction won pay price valuation second best price 
case role auctioneer played am sbs play role bidders 
am start auction selling item file case buying 
sbs bid price willing sell file winning sb paid second lowest bidding price am 
words economic model uses reverse vickrey auction 
auction protocol detailed uml sequence diagram 
replica selection performed replica minimises access cost returned 
may stored locally remotely 
case file accessed ce remote file access 
economic model perform starting reverse vickrey auction 
auction performed starts auction thread waits auction returning winning replica ce 
auction thread issues message required file propagated local mediator local sbs sbs network 
depending topology network maximum distance auction propagation parameter auction message reach set grid sites 
issued request bids auction thread waits potential file sellers bid file see messages 
fixed time auction thread selects auction winner sb submitted lowest bid 
notify message propagated network informing sbs auction result winner notified auction thread waits winning replica ready site replication process winning site completed auction thread notified message physical location winning replica returned ce am 
auction thread receives bids whilst waiting auction winner 
sb bid file related se store replica requested file 
see details 

reverse vickrey auction locate file 
sb receives request bid checks se stores required file 
file calculates bid proportional transfer time sb site site started auction 
replies bid message 
local pm gathers bid messages local sbs forwards pm site started auction 
pm forward messages corresponding ro agent 
file stored locally sb start nested auction 
purpose auction create corresponding se replica requested file 
nested auction started sb decides having local replica file economically beneficial possibly including case se space store file 
details decision process described section 
nested auction successfully terminated sb calculates bid file takes part parent auction 
worth emphasising separate bidding parent auction replication activity 
result sb wins auction check corresponding replication finished 
replication completed current auction added set pending auctions 
replication finished parent auctioneer notified winning replica ready access 
important difference level parent nested auctions 
goal locate cheapest replica required job executed ce 
best replica located site ce remote site 
aims replicate file local se increase sb expected income 
words mechanism underlying auction protocol performs long term optimisation allowing automatic replication data hot spots 
nested auctions allow replication third party sites sites file initially needed 
third party replication appears provide mechanism distributing required files neighbourhood nearby ses 
reduces bottleneck caused considering close ses located site ce replication 
prediction function file value model nested auctions may trigger dynamic replica optimisation see section time vary set files stored se 
decision nested auction started depends local replication file economically beneficial sb 
ideally sb keep files local se maximise sb expected revenue local replication new file increases sb expected income nested auction conducted 
model prediction function estimating revenue data files 
function currently approximates revenue af file number times requested time window assumes file access history represented random walk space files 
random walk identifier requested file obtained current identifier addition step value binomial distribution 
function uses history file requests access patterns experienced sb time window past returns predicted number times file requested time window 
refer detailed discussion prediction function economic model 
experimentation configuration goal simulation authors developed study various replica optimisation algorithms generic grid jobs 
simulate set high energy physics analysis jobs cdf experiment case described 
case file size gb total size file set gb 
grid topology see comprises sites europe usa world wide data production cms experiment 
simplify simulation assumed contending network traffic 
goal simulation fold 
want verify replication algorithm real world case 
second simulation results serve bases understanding large scale scientific analysis general particular assisting cms experiment resource planning data challenge 
data challenge tb data analysed distributed manner sites 
ucsd ufl caltech wisconsin bristol usa ic ral uk france lyon cms testbed site router switzerland cern russia italy moscow torino catania pisa bologna firenze roma padova bari 
grid topology cms world wide data production challenge spring 
consider current cms testbed total storage capacity ses tb 
ses cern capacity gb remaining testbed sites depicted storage capacity gb 
assume initially file physical instance referred master copy 
simulation considered initial file distributions master copies stored cern master copies stored cern replicas randomly distributed testbed sites ses full 
access patterns order job requests files determined job access pattern 
consider access patterns sequential files requested predetermined order gaussian random walk successive files selected gaussian distribution centred previous file 
simulation results indication effective algorithm performs estimated time taken complete jobs simulation run 
important note metrics replica optimisation fault tolerance security issues 
wish evaluate optimisation strategy respect job throughput 
simulation run jobs various types executed 
jobs submitted second intervals job type determined fixed probability distribution job types 
estimated time taken complete job calculated time waiting queue ce plus execution time ce 
duration auction replica location critical performance economic model 
auction takes long time taken find best replica significant respect file transfer time 
little time allowed receive possible bids 
achieved best results ms timeout reducing nested auctions 
values allowed sb time conduct nested auction return bid parent auction 
compare economic model simple replication optimisation algorithm lru 
algorithm files replicated site job executing 
se full file accessed number times previous time interval deleted 
call replica replacement decision 
economic model se site job executing space files replicated 
space left se replica replacement takes place considered economically beneficial sb see section valuable file deleted space 
results comparing algorithms access pattern initial replica population policy shown figures 
bar shows total job time averaged simulation runs 
shows results replicas start simulation ses filled replicas 
results show economic model provides substantially better throughput jobs sequential access pattern typical high energy physics applications 
mainly due inability lru algorithm optimise replicas job requests files stored local se 
circumstances algorithm replicates deletes files required point 
replicate deleted file required job 
economic model prediction function learns files needed delete 
result files read remotely reduce network usage removing repeated replication jobs run faster 

total job times replicas start simulation 

total job times ses initially filled replicas 
economic model designed sequential access patterns gaussian walk access pattern results files requested job execution time smaller economic model shows improvement sequential access patterns 
lru algorithm shows significant improvement gaussian walk access pattern jobs 
gaussian walk access pattern allows files set accessed whilst accessed 
set files job potentially access fit local se set files selected gaussian random walk probably 
problem encountered lru algorithm sequential access jobs arise 
conclude economic model shows significant performance improvements sequential access patterns 
gaussian walk access patterns lru performs better experiments show economic model robust jobs accessing files various patterns 
novel optimisation technique economic model discussed data grid optimise replica selection dynamic access pattern driven replication 
detailed reverse vickrey auction protocol optimisation agents dynamically selecting best replica requested file 
considers data locality network latencies 
discussed prediction function agents making replication decisions uses historical data file access patters 
evaluate efficiency algorithm ran grid simulator configured represent realworld data grid testbed high energy physics job throughput benchmark 
studied impact different file access patterns performance economic model compared results traditional replication algorithm 
results clearly show access patterns economic model replication algorithm shows markedly improved performance compared traditional algorithm 
due ability prioritise files file access history replicate accordingly 
part plan extend simulation framework evaluate results typical access patterns large scale analysis efforts 
plan embed economic model virtual currency file take consideration storage costs neglected far 
authors casey stockinger valuable discussions preparation 
partially funded european commission program ist eu datagrid project project 
bell cameron millar stockinger 
design replica optimisation framework 
technical report datagrid ted cern geneva switzerland december 
bell cameron millar stockinger 
simulation dynamic grid replication strategies 
int 
journal high performance computing applications 
appear 
buyya abramson 
deadline budget constrained cost time optimization algorithm scheduling task farming applications global grids 
int 
conf 
parallel distributed processing techniques applications las vegas nv usa june 
buyya stockinger giddy abramson 
economic models management resources peer peer grid computing 
spie int 
symposium convergence information technologies communications denver usa august 
stockinger 
preliminary evaluation revenue prediction functions economically effective file replication 
technical report datagrid ted cern geneva switzerland july 
serafini stockinger 
economy optimisation file access replication data grid 
workshop agent cluster grid computing int 
symposium cluster computing grid ccgrid berlin germany may 
ieee cs press 
chervenak deelman foster hoschek iamnitchi kesselman ripeanu stockinger stockinger tierney :10.1.1.135.3823
framework constructing scalable replica location services 
proc 
int 
ieee acm supercomputing conference sc baltimore usa november 
chervenak foster kesselman salisbury tuecke 
data grid architecture distributed management analysis large scientific datasets 
journal network computer applications 
hamscher 
economic scheduling grid computing 
job scheduling strategies parallel processing edinburgh scotland july 
springer 
lncs 
gray neil shasha 
dangers replication solution 
acm sigmod int 
conference management data montreal quebec canada june 
hoschek jean martinez samar stockinger stockinger 
data management international data grid project 
ieee acm int 
workshop grid computing grid bangalore india december 
huffman cdf uk project 
cdf internal note 

tony editors 
spring daq tdr production 
cms internal note 
geneva switzerland 
nisan london regev 
globally distributed computation internet popcorn project 
proc 
int 
conference distributed computing systems icdcs amsterdam netherlands may 
ieee cs press 
foster 
identifying dynamic replication strategies high performance data grid 
proc 
int 
grid computing workshop denver colorado usa november 
foster 
decoupling computation data scheduling distributed data intensive applications 
int 
symposium high performance distributed computing edinburgh scotland july 
vickrey 
counterspeculation auctions competitive sealed tenders 
journal finance march 
waldspurger hogg huberman kephart stornetta 
spawn distributed computational economy 
ieee transactions software engineering 
