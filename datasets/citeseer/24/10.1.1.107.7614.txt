web pocket 
sergey brin rajeev motwani lawrence page terry winograd amount information available online grown enormously past decade 
fortunately computing power disk capacity network bandwidth increased dramatically 
currently possible university research project store process entire world wide web 
limit text humans generate plausible decades able store process human generated text web shirt pocket 
web rich interesting data source 
describe stanford webbase local repository significant portion web 
furthermore describe number experiments leverage size diversity webbase 
largely automated process extracting sizable relation books title author pairs hundreds data sources spread world wide web technique call dual iterative pattern relation extraction 
second developed global ranking web pages called pagerank link structure web properties useful search navigation 
third pagerank develop novel search engine called google heavy anchor text 
experiments rely significantly size diversity webbase 
web diverse data source combining highly structured html fully general natural language contained html embedded images 
top data reasonably defined link structure directed graph web pages labels links text anchors 
applications data describe 
extraction structured data unstructured pieces spread web copyright ieee 
personal material permitted 
permission reprint republish material advertising promotional purposes creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
bulletin ieee computer society technical committee data engineering partially supported community management staff massive digital data systems program nsf iri ibm hitachi supported nsf young investigator award ccr matching funds ibm mitsubishi schlumberger foundation shell foundation xerox 
supported stanford integrated digital library project see 
supported stanford integrated digital library project 
project supported nsf cooperative agreement iri 
funding cooperative agreement provided darpa nasa interval research industrial partners stanford digital libraries project 
process sufficiently accurate provide comprehensive source information 
technique initial results automatically extracting relations web section 
enhanced information retrieval 
area explored number researchers search engine companies 
plenty room improvement information retrieval web novel techniques sections 
take advantage central idea web provides metadata link structure anchor text partially redundant content 
substantial portion web web 
take full advantage data require human intelligence 
simple techniques focus small subset potentially useful data succeed due scale web 
technique capture percent available information useful 
size crucial techniques amount publicly available information grow rapidly important maintain large web repository stanford webbase 
stanford webbase size world wide web elastic number 
automatically generated infinite web spaces large amount duplication web changes day 
estimate put size web pages november bb 
web search engines world wide web worm mcb index web pages web accessible documents 
march largest search engines claim index web documents sul 
foreseeable year comprehensive index web contain documents 
stanford webbase designed store significant subset text content web research purposes 
currently holds roughly web pages soon expand approximately double size 
repository roughly gb html stored compressed gb 
additionally keep inverted index text includes word position font information occupying additional gb 
various metadata including url link structure occupy gb traditional standards repository contains huge amount information 
acquisition indexing fully automated repository collected processed maintained university research project 
disk space network bandwidth computing power continue improve fall price eventually school child able store comparable collection portable computer 
extraction relations world wide web provides vast resource information 
time extremely distributed 
particular type information restaurant lists may scattered thousands independent information sources different formats 
chunks information extracted world wide web integrated structured form form unprecedented source data combined international directory people largest diverse databases products broadest bibliography academic works 
considerable integrating multiple information sources specially coded wrappers filters tsi mos 
time consuming create maintain usually tens thousands sources 
section address problem extracting relation thousands sources may hold pieces relation world wide web 
goal discover information sources extract relevant information entirely automatically minimal human intervention 
dual iterative pattern relation expansion dipre test problem extract relation books author title pairs web 
intuitively solution works follows 
small seed set author title pairs tests set just pairs 
find occurrences books web occurrence book appearance title author close proximity web page 
occurrences recognize patterns citations books 
search web patterns find new books 
take books find occurrences generate patterns 
new patterns find books forth 
eventually obtain large list books patterns finding 
call technique dipre dual iterative pattern relation expansion 
process applying dipre important precise generate garbage complete effect adding false patterns proliferation false entries 
far vague concepts occurrence pattern 
formalized number ways 
chose simple approach demonstrate general technique occurrence author title pair represented tuple author title order url prefix middle suffix 
order boolean value determines author appears title title appears author 
url url document occurred 
prefix consists characters tests preceding author title title 
middle text author title suffix consists characters title author 
pattern tuple order prefix middle suffix 
boolean attributes strings 
order true author title pair matches pattern document collection www url matches contains text matches regular expression prefix author title middle suffix 
order false author title reversed 
relation extracting set patterns extracting set oc 
dipre works follows 
sample initialize small seed relation trying find 
tests just list author title pairs 

find occurrences tuples web 

generate patterns set occurrences 

find occurrences patterns web 
tuples 
add newly author title pairs 
large terminate 
go step 
important operations tuples just trivial project 
find occurrences books patterns respectively web repository 
fairly similar operations challenging compute efficiently tens isaac asimov robots dawn david brin rising james chaos making new science charles great expectations william shakespeare comedy errors initial sample books 
url pattern text pattern www sff net locus li title author dns city net com awards html title author dolphin upenn edu texts sf award htm author title patterns iteration 
thousands books hundreds patterns 
purposes experiment equivalent grep webbase 
experiment limited just portions webbase operation time consuming 
third operation 
key avoid generating overly general patterns 
avoid patterns requiring patterns generated provide sufficiently long prefixes suffixes 
refer bri details process 
experiment started experiment just books see 
produced occurrences generated patterns see 
interestingly books produced patterns science fiction books 
run patterns matching url produced unique author title pairs 
science fiction exceptions 
search roughly web pages occurrences books 
number disappointment large blowup happened iteration 
taken couple days run entire repository attempt generate 
occurrences produced patterns url prefixes complete urls 
pass roughly urls produced unique author title pairs 
unfortunately bogus books 
particular legitimate titles author 
removed list 
manual intervention process 
experiments interesting see leaving produce unacceptable amount junk 
final iteration chose subset repository contained word books subset consisted roughly documents 
scanning remaining books produced occurrences 
turn generated patterns 
scanning set documents produced unique books little bogus data 
quality results surprisingly 
random sample proposed books revealed roughly legitimate books 
remainder articles media 
roughly amazon incidentally part webbase accessible robots major sites legitimate books copyrights publishers 
print published electronically missing online book stores apparent reason 
union hundreds small sources book citations web useful presence huge catalogs available online 
details experiment see bri 
pagerank link structure web estimates vary current graph web roughly nodes pages edges links 
page number forward links outedges backlinks see 
know backlinks particular page downloaded know forward links time 
backlinks web pages vary greatly terms number backlinks 
example netscape home page backlinks current database pages just backlinks 
generally highly linked pages important pages links 
simple citation counting things including speculating winners nobel prize san 
pagerank provides sophisticated method doing citation counting :10.1.1.31.1768
reason pagerank interesting cases simple citation counting correspond common sense notion importance 
example web page link yahoo home page may just link important 
page ranked higher pages links obscure places 
pagerank attempt see approximation importance obtained just link structure 
propagation ranking links discussion give intuitive description pagerank page high rank sum ranks backlinks high 
covers case page backlinks page highly ranked backlinks 
definition pagerank web page 
set pages points set pages point number links factor normalization total rank web pages constant 
defining simple ranking slightly simplified version pagerank simplified pagerank calculation steady state solution pagerank calculation equation formalizes intuition previous section 
note rank page divided forward links evenly contribute ranks pages point 
note number pages forward links weight lost system 
equation recursive may computed starting set ranks iterating computation converges 
demonstrates propagation rank pair pages 
shows consistent steady state solution set pages 
stated way square matrix rows columns corresponding web pages 
edge 
treat vector web pages eigenvector eigenvalue fact want dominant eigenvector may computed repeatedly applying nondegenerate initial rank vector 
small problem simplified ranking function 
consider web pages point page suppose web page points 
situation shown 
iteration loop accumulate rank distribute rank outedges 
loop forms sort trap call rank sink 
overcome problem rank sinks introduce rank source loop acts rank sink definition vector web pages corresponds source rank 
pagerank set web pages assignment web pages satisfies maximized denotes sum components 
vector web pages corresponds source rank 
note rewrite vector consisting ones 
eigenvector positive increased balance equation 
technique corresponds decay factor 
matrix notation random surfer model definition pagerank intuitive basis random walks graphs 
simplified version corresponds standing probability distribution random walk graph web 
intuitively thought modeling behavior random surfer 
random surfer simply keeps clicking successive links random 
real web surfer gets small loop web pages surfer continue loop forever 
surfer jump page 
additional factor viewed way modeling behavior surfer periodically gets bored jumps random page chosen distribution personalization malicious manipulation spam far left user defined parameter 
tests uniform web pages value skewed particular user say weigh bookmarks homepage higher 
preliminary experiments set particular stanford professor home page 
result higher ranking things relating loosely professor 
type personalized nearly impossible mislead ranking algorithm 
way inflate importance page convincing pages give part importance 
create web pages trying mislead system pages total importance sum links 
link outside web pages pages ranking link distribute 
type resistance important commercial space great deal economic incentive move pages top popular search results 
computing pagerank computation pagerank fairly straightforward ignore issues scale 
vector web pages example 
pagerank may computed follows note factor increases rate convergence maintains alternative normalization multiply appropriate factor 
may small impact influence note large number nodes outgoing edges complete version web 
presence nodes unknown outedges completely satisfactory solution distribute weight 
nodes outgoing edges cause factor larger 
solution remove nodes outgoing edges computation pagerank add back weights stabilized 
results slight boost nodes due change normalization preferable alternatives 
google search engine major application pagerank searching 
implemented search engines pagerank 
simple title search engine 
second full text search engine called google bpa bp 
google utilizes number factors rank search results including standard ir measures proximity anchor text text links pointing web pages pagerank 
encourage readers try google google stanford edu allows searching full text web pages 
pagerank benefits pagerank greatest underspecified queries 
example conventional search engine query stanford university may return number web pages mention stanford publication lists 
pagerank university home page listed 
general query university completely hopeless conventional search engines best returning home pages random universities worst returning random pages random universities 
pagerank top results home pages major universities uiuc stanford michigan forth 
anchor text consider query stanford university 
happens nearly links stanford home page overwhelming majority text link reads stanford university 
links match query exactly point web page stanford example pretty indication search engine page may result return query 
cases just anchors pointing page match query anchors useful 
anchors better descriptions web pages pages 
frequently state precisely significant web page 
second written people author web page resistant malicious tampering move page top search results commercial gain 
fact google distinguishes site site domain anchors improve resistance malicious tampering 
anchors allow search engine return web page crawling 
webbase contains roughly web pages google return roughly url search results including images email addresses 
proximity important component google heavy reliance word proximity 
query words occur close document document weighted heavily appear far apart 
proximity searching considerably computationally expensive 
practice unoptimized system answer vast majority queries matter seconds 
experiments webbase experiments mention briefly 
range duplicate detection data mining search 
web useful testbed experimenting systems may applied broadly 
scam project stanford detect duplicated nearly duplicated documents 
webbase turns test set purpose large corpus large amount duplication variations texts duplicated 
results duplicate analysis sgm show roughly documents webbase exact duplicates approximate duplicates 
application web test data set market basket mining 
consider web pages baskets words appear items 
data set particularly challenging traditional algorithms 
distinct words tens thousands occur significant frequency 
number words occur extremely strong correlations 
project dynamic data mining considers market basket algorithm possible exhaustively explore possible rules 
research direction searching call background surfing search 
contributions google far underspecified queries word queries 
consider case zero word queries 
goal build system listens conversation going produce relevant web pages 
feel system substantial impact way people aware things know look 
current early prototype scans email retrieves relevant web pages 
goal difficult task include combine high quality continuous speech recognition large vocabulary high quality search feasible display results 
summarization issue wish explore summarization collection documents 
currently developing process 
suppose wish summarize contents pages returned query web search engine 
fetch pages urls form response query local repository identify family important keywords proximity search terms traditional ir techniques frequency identify phrases containing keywords output set phrases occur frequently documents notion approximate phrase equality 
thesis set phrases read summary web documents 
critical component approach identification interesting phrases collections documents 
important avoid generating phrases merely common language constructs sporadic terms 
restrict grammatical english phrases generate general kinds phrases including dates email addresses phone numbers names expectation supported preliminary experimental results resulting sets phrases provide sense contents topic document collection 
developed approach quickly identifying interesting phrases 
instance define word phrase pair words strong affinity appear particular order far explained language constructs pure chance 
technique scans text linear time produces ranked list phrases prior knowledge content document relationship document collection 
performing experiments phrase detection noticed technique applied collection documents returned search engine query detected phrases descriptive quality pages returned search engine 
way summarization visualize clusters documents 
clusters may formed responses query may just clustering part web 
particular suppose hierarchical clustering collection web pages 
provide user summary document sub collection associated point hierarchy differences set characterizing phrases adjacent points hierarchy 
summarization enable user visualize clustered documents navigating browsing hierarchy 
repository web pages webbase excellent research tool enabling experiments impossible perform efficiently 
course crucial development better search engines 
important lesson learned experiments size matter 
extraction experiment failed webbase third current size 
furthermore hardware cost large webbase quite reasonable trends disk capacity computing power applications involving local web repository practical near 
analyzing web important look just text 
extraction experiment heavy formatting url pagerank takes advantage link structure 
google anchor text font information 
information web plain text applications achieve great gains leveraging 
scott hassan alan critical development google 
talented contributions authors owe gratitude 
recognize generous support equipment donors ibm intel sun 
bb krishna bharat andrei broder 
technique measuring relative size overlap public web search engines 
proceedings seventh international world wide web conference 
bpa sergey brin larry page 
google search engine 
google stanford edu 
sergey brin lawrence page 
dynamic data mining exploring large rule spaces sampling 
www db stanford edu sergey ddm ps 
bp sergey brin lawrence page 
anatomy large scale hypertextual web search engine 
proceedings seventh international world wide web conference 
bri sergey brin 
extracting patterns relations world wide web 
proceedings webdb workshop edbt 
www db stanford edu sergey extract ps 
mcb oliver mcbryan 
wwww tools taming web 
editor proceedings international world wide web conference page cern geneva may 
mos workshop management semistructured data 
www research att com suciu workshop papers html may 
lawrence page sergey brin rajeev motwani terry winograd :10.1.1.31.1768
pagerank citation ranking bringing order web 
google stanford edu google papers html 
san 
speculation biomedical community abounds candidates nobel 
scientist oct 
sgm narayanan shivakumar hector garcia molina 
finding near replicas documents web 
proceedings webdb workshop edbt 
sul danny sullivan 
search engine watch 
www searchenginewatch com 
tsi tsimmis home page 
www db stanford edu tsimmis tsimmis html 

