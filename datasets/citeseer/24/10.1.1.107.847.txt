computing iceberg queries ciently min fang narayanan shivakumar hector garcia molina rajeev motwani je rey ullman department computer science stanford ca 
hector rajeev cs stanford edu number applications compute aggregate functions count sum attribute set attributes nd aggregate values speci ed threshold 
call queries iceberg queries number threshold results small tip iceberg relative large amount input data iceberg 
iceberg queries common applications including data warehousing information retrieval market basket analysis data mining clustering copy detection 
propose cient algorithms evaluate iceberg queries little memory signi cantly fewer passes data compared current techniques sorting hashing 
experimental case study gigabytes web data illustrate savings obtained algorithms 
develop cient execution strategies important class queries call iceberg queries 
iceberg query performs aggregate function attribute set attributes eliminates aggregate values speci ed threshold 
prototypical iceberg query consider follows relation target target rest threshold select target target count rest group target target having count rest apply iceberg query relation table result tuple ha 
call iceberg queries relation number unique target values typically huge iceberg answer number frequently occurring targets small tip iceberg 
data mining queries fundamentally iceberg queries 
instance market analysts execute market basket queries large data warehouses store customer sales transactions 
queries identify user buying patterns nding item pairs triples bought customers 
target sets item pairs minimum number transactions required support item pair 
queries operate large datasets phone number fax target target rest joe fred sally sally bob tom table example relation solving iceberg queries ciently important problem 
fact park claim time execute query dominates cost producing interesting association rules 
concentrate executing iceberg queries ciently compact memory data structures 
discuss examples iceberg queries section 
simplest way answer iceberg query maintain array counters main memory counter unique target set answer query single pass data 
indicated possible applications relation usually times larger available memory irrelevant attributes projected early possible 
approach answer iceberg query sort disk pass aggregating selecting targets threshold 
available memory small relative size sorting take passes data disk 
instance merge sorting produce jrj sorted runs number tuples memory 
need log jrj merge passes produce nal sorted run 
passes need read write entire relation values target attribute 
encounter similar problems popular techniques early aggregation hashing aggregation 
materialized 
cases may large explicitly materialized disk 
instance market basket application input data set transaction records 
record describes collection items bought customer corresponds multiple records 
example say interested pairs items frequently bought store say customer bought items fa cg 
contain tuples representing association pairs items 
general average number items customer buys customer record generates tuples wecan see initial data customer transactions small materializing may feasible due quadratic increase size initial input 
situation may get worse analyst wants nd popular item triples quadruples 
large useful execute iceberg query virtual relation explicitly materializing traditional techniques cases input data stores runs hundreds gigabytes 
sorting hashing require 
primary contributions fold 
identify iceberg queries fundamental data mining queries discuss applications appear directly sub queries complex queries 
iceberg queries today processed techniques scale large data sets crucial develop better techniques 

propose variety algorithms iceberg query processing 
algorithms building blocks known techniques multiple hash functions combine extend improve performance reduce memory requirements 
techniques avoid sorting hashing compact memory structures allow identify threshold targets 
cases materialized show perform iceberg computation materializing iceberg algorithms may produce errors target values threshold reported answer targets reported threshold 
algorithms cient may errors tolerable application 
extend techniques ciently post process results correct errors 

evaluate algorithms case study approach di erent applications real data queries 
results show new algorithms ciently handle larger iceberg problems current techniques 
case study serves illustrate tradeo involved choosing strategy depending available system resources size disk main memory 
rest structured follows 
section discuss examples iceberg queries illustrate di erent kinds iceberg queries 
section simple algorithms execute iceberg queries 
section propose hybrid algorithms combine advantages simple algorithms di erent ways 
section propose orthogonal techniques optimize hybrid strategies 
section evaluate techniques case studies gigabytes data size scenarios materialized require gigabytes storage 
section propose extensions algorithms conclude section directions research 
iceberg queries important 
illustrate examples executing iceberg queries ciently important traditional techniques sorting hashing lead high query times inordinately large disk requirements 
example query consider tpc benchmark style relation lineitem attributes partkey key parts sold price price corresponding item number units sold transaction region area part sold 
query computes keys popular items regions item revenues region exceed dollars 
create view select partkey region sum price lineitem group partkey region having sum price easy see apply current techniques sorting sort lineitem relation perform aggregation response time query large 
case items lineitem popular small revenues 
course minimum criteria selecting item revenue dollars sorting approach may best items satisfy query 
see traditional techniques sorting hashing kill solutions output sensitive perform amount ofwork irrespective small query output course threshold execute query faster rst perform aggregation apply thresholding 
example query web searching engines altavista cluster web documents syntactic similarity documents goal clustering develop better web crawlers identifying documents replicated near replicas documents manuals faqs 
engines break web document set signatures hashed byte integers sequences words sentences 
maintain relation tuples hdi cii document di contains signature ci 
identify document pair copy share signatures common query 
create view select doc doc count chunk 
chunk 
chunk doc doc group 
doc 
doc having count chunk currently dec prototype uses sorting execute self join follows 
rst sort signatures signature sk tuples hdi ski frequency freq heavy light rank graphical view terminology 
document di contains sk contiguous 
pair form hdi ski ski explicitly materialize relation form hdi indicating di dj share signature common 
sort tuples document pair contiguous 
sequentially scan count number document pairs occur times document pairs signatures common 
process explicitly materializes termed discussions sorts thresholds 
shall see case studies materialized relation large storage requirements 
fact small input size megabytes relation grew gigabytes nal answer query megabyte worth document pairs 
iceberg queries arise information retrieval ir problems 
instance ir systems compute words set frequently occuring words corpus optimize query processing building inverted indices iceberg query 
ir systems compute sets frequent occurring words help users construct queries 
instance pairs stock market stock price chicken stock may occur collection documents 
user enters word stock query system may suggest market price chicken useful words add query distinguish way stock 
computing occurring words involves iceberg query target sets pairs words 
study application detail experimental case study 
illustrative examples see iceberg queries occur commonly practice need executed carefully query times temporary storage requirements output sensitive 
techniques thresholding simplicity algorithms sections context materialized relation pairs 
assume executing simple iceberg query groups single target opposed set targets 
discuss algorithms easily extended multiple target sets 
start establishing terminology 
ordered list targets th frequent target th highest rank 
jv freq frequency inr 
area pr freq total number tuples frequent targets 
special case area equal jrj 
shows typical frequency curve freq 
leftmost value horizontal axis representing rank frequent target value 
prototypical iceberg query section selects target values frequencies higher threshold de ne rt answer query set fv rt call values heavy targets de ne remaining light values 
algorithms describe answer prototypical iceberg query easily adapted iceberg queries 
general algorithms compute set potentially heavy targets contains members possible 
cases non empty algorithm reports false positives light values reported heavy 
non empty algorithm generates false negatives heavy targets missed 
algorithm form errors 
errors eliminated post processing 
eliminating false positives computed scan explicitly count frequency targets targets occur times output nal answer 
call procedure count 
post processing cient targets held main memory say bytes target counting 
large ciency counting deteriorates 
fact jf post processing take time running original iceberg query 

eliminating false negatives general post processing regain false negatives ine cient may fact bad original problem 
regain false negatives ciently high skew cases tuples target values small set 
particular suppose obtained partial set heavy targets tuples target values 
scan eliminating tuples values 
iceberg query run remaining small set tuples sorting counting obtain heavy values missed simple algorithms compute basic blocks rule instance high skew 
rule applies small fraction targets account tuples targets account 
subsequent sophisticated algorithms 
algorithm uses simple data structures lists counters bitmaps cient counting 
ease presentation assume number elements structure smaller jv structures main memory 
section evaluate memory requirements carefully 
sampling algorithm scaled sampling sampling procedures widely adopted practice estimate sizes query results perform online aggregation 
see discussion sampling techniques ciently obtain unbiased samples 
consider simple sampling algorithm iceberg queries 
basic idea follows take random sample size count distinct target sample scaled exceeds speci ed threshold target part candidate set sampling algorithm simple implement cient run 
algorithm false positives false negatives removing errors ciently non trivial discussed 
show remove errors hybrid algorithms section 
coarse counting elements coarse count coarse counting probabilistic counting technique query size estimation computing number distinct targets relation mining association rules applications 
simplest form coarse counting uses array ofm counters hash function maps target values log bits log bits algorithm works follows initialize entries zero 
perform linear scan tuple target increment counter 
completing hashing scan compute bitmap array bitmap scanning array setting bitmap heavy compute bitmap smaller maintains information required phase 
bitmap computed reclaim memory allocated compute performing candidate selection scan scan target bitmap add remove false positives executing count 
note false negatives coarse counting approach 
candidate selection scan simple coarse counting algorithm may compute large may times large memory light targets may hashed heavy buckets 
bucket may heavy heavy elements light elements combined counts speci ed threshold 
hybrid techniques di erent approaches combine sampling counting approaches earlier 
approach rst samples data identify candidates heavy targets uses coarse counting principles remove false negatives false positives 
approach manage reduce number targets fall heavy buckets leads fewer light targets false positives 
refer approaches hybrid class algorithms 
defer count algorithm compute small sample size data sampling techniques discussed section 
select frequent targets sample add 
targets heavy know sure 
execute hashing scan coarse count increment counters targets perform candidate selection scan adding targets remove false positives executing count 
see example approach 
consider case heavy targets targets light targets 
case identi ed sampling phase potentially heavy maintained explicitly memory denote counted buckets 
intuition defer count algorithm follows 
sampling identifying heaviest targets nding heavy targets 
select place targets avery high probability heavy 
targets identi ed advance hashing scan avoid pushing threshold account ofv 
leads fewer heavy buckets fewer false positives 
disadvantage defer count splits valuable main memory sample set buckets counting 
small maintain explicit target 
instance defer count count heavy item pairs eld target set data mining need bytes store item pair 
gets progressively worse start counting heavy item triples heavy item quadruples 
problem implementing defer count hard choose values useful variety data sets 
problem defer count target incur overhead checking target exists hashing scan 
multi level algorithm propose algorithm explicitly maintain list potentially heavy targets main memory defer count 
multi level uses sampling phase identify potentially heavy buckets follows 
perform sampling scan data target chosen sampling scan increment hash function sampling targets consider buckets 
mark th bucket potentially heavy 
bucket allocate defer count multi level multi stage alternate hybrid techniques combine sampling coarse counting 
auxiliary buckets main memory 
refer buckets primary buckets maintain distinction 
reset counters array zero 
perform hashing scan data 
target data increment bucket corresponding marked potentially heavy 
bucket marked apply second hash function increment corresponding auxiliary bucket 
show example procedure 
sampling phase buckets marked dotted identi ed potentially heavy allocated auxiliary buckets 
subsequent scan targets fa qg fall heavy buckets corresponding auxiliary buckets 
note explicitly store targets auxiliary buckets indicated gure continue maintain counters 
idea multi level algorithm similar concept extensible indices commonly databases indices grow populated buckets adding auxiliary buckets dynamically 
di erence case extensible indices entire key indexed stored 
buckets populated dynamically add auxiliary buckets ciently 
recall ord store targets explicitly main memory maintain counters 
reason perform pre scan pre allocate auxiliary buckets potentially heavy buckets 
notice multi level store sample set explicitly defer count 
useful especially size targets large 
problem multi level splits amount main memory primary auxiliary buckets 
deciding split memory structures simple problem empirically determine splits datasets 
cost rehashing auxiliary buckets expensive second hash function employed 
practice avoid hash function fewer bits rst hashing residual bits hash target auxiliary buckets 
discuss important detail implementing scheme 
maintain pointers auxiliary buckets 
cases maintaining bytes pointer may expensive especially number potentially heavy buckets high 
cases allocate auxiliary buckets potentially heavy buckets contiguously main memory starting base address th potentially heavy bucket store set auxiliary buckets 
compute auxiliary buckets potentially heavy bucket locations 
multi stage algorithm propose new technique uses available memory ciently multi level algorithm 
multi stage pre scan sampling phase multi level identi es potentially heavy buckets 
multi stage allocate auxiliary buckets potentially heavy bucket 
allocates common pool auxiliary buckets 
performs hashing scan data follows 
target data increments bucket corresponding marked potentially heavy 
bucket marked apply second hash function increment 
example procedure 
mark common arrays dotted lines 
note targets fa qg remapped auxiliary buckets second hash function uniformly distributes targets common pool auxiliary buckets 
easy see example chance heavy targets fall bucket 
cases targets longer due gure case fall bucket 
analysed multi level intuition full version 
main intuition sharing common pool auxiliary buckets potentially heavy buckets heavy targets fall bucket heavy targets illustrated example 
multi level characteristic heavy targets local auxiliary structures 
expect multi stage fewer false positives multi level amount memory 
multi stage shares disadvantage multi level determining split memory primary buckets auxiliary buckets determined empirically 
optimizing hybrid algorithms hybrid algorithms may su er false positives light values fall buckets heavy targets light values 
sampling strategies outlined section alleviate rst problem certain extent 
heavy targets identi ed sampling lead light values falling heavy buckets 
hybrid avoid second problem 
propose improve hybrid techniques section multiple sets primary auxiliary buckets reduce number false positives signi cantly 
analyze idea di erent contexts subsections number passes required data 
clarity describe techniques section context simple defer count algorithm techniques applicable multi level multi stage algorithms 
furthermore techniques continue perform sampling scan identify potentially heavy targets store count targets hashing scans count explicitly candidate selection phase 
candidate selection phase continue execute count remove 
steps common techniques repeat steps discussion 
single scan defer count multiple hash functions illustrate hash functions map target values log bits log bits memory allocated rst divided parts counting bitmap arrays 
bitmap bitmap 
execute pre scan sampling phase defer count identify potentially heavy candidates store pass input data tuple value increment 
set bitmap ifa 
similarly bitmap deallocate 
candidate selection phase pass data tuple value add bitmap bitmap set 
easily generalize procedure di erent hash functions hk 
mentioned earlier assume bitmaps main memory 
discuss model memory usage section 
choosing right value interesting problem amount main memory 
choose larger value wehave hash tables hash table smaller 
helps reducing number false positives increases number false positives 
natural trade point choosing discuss appendix choose value 
multiple scan defer count multiple hash functions multiscan multiple hash functions hashing scan su er increased number false positives due smaller hash tables idea multiple hashing scans follows 
sampling pre scan execute hashing scan hash function 
store corresponding bitmap array disk 
perform hashing scan di erent hash function 
store corresponding bitmap array disk 
performing hashing scans hashing scan hashing scan bitmap bitmap multiscan multiscan shared comparing multiscan versus multiscan shared 
leave bitmap memory retrieve bitmap arrays disk 
execute candidate selection scan add value hi improving multiscan shared bitmaps multiscan shared multiscan performed hashing scan independent previous scans bitmap information previous scans available 
multiscan shared assume th hashing scan bitmaps previous hashing scans retained memory 
optimization works follows st hashing scan target increment hi hj example illustrates multiscan shared reduces number multiscan 
consider case target frequency pairs ha hb hc hd target occurs tuples occurs tuples 

map targets buckets set targets pairs fag fb dg fcg feg similarly maps targets buckets fe dg fa bg fg fcg 
show counts array corresponding bitmap rst hashing scan execute multiscan 
similarly compute bitmap second hashing scan 
candidate selection scan multiscan 
choose fb dg part targets fall heavy buckets hash functions 
consider execution multiscan shared 
rst hashing scan remains 
second scan computes di erent bitmap second hashing scan uses information bitmap incrementing illustrate consider counted algorithm second hashing scan 
multiscan incremented occurrences multiscan shared incremented occurences know light bitmap 
increment second hashing scan longer part candidate set 
fact candidate selection scan target chosen multiscan shared fcg opposed fb dg chosen multiscan 
variant shared multiscan shared propose variant multiscan shared uses memory bitmaps 
variant maintain bitmap hashing scans performing st hashing scan maintaining prior bitmaps 
conjecture latest bitmaps hashing scans fewer fewer bits set 
bitmaps signi cant pruning power terms pruning away light values cost lower memory usage 
multiscan shared denote algorithm 
extending hybrid algorithms section brie describe variations schemes earlier 

collapsing candidate selection scan nal counting scan multiscan algorithm extensions proposed sections performs hashing scans candidate selection scan nally counting scan false positives eliminated 
cases size expected small collapse scans follows 
executing candidate selection scan add memory counter element scan add target appeared heavy buckets hash functions check target increment counter add counter initialized 
dispense nal counting scan count times target appears targets count exceed threshold nal answer 

parallelizing hashing scans multiscan parallelize hashing scans multiscan multiple processes 
case time hashing scans drops time sequential scans time single scan 
course optimization multiscan shared multiscan shared bitmaps previous iterations 

sum queries mentioned section extend techniques iceberg queries containing having sum attrib 
illustrate consider query section 
perform query performing hashing scan lineitem relation 
pass compute partkey region increment corresponding counter price 
hashing scan compress array bitmap de nition bucket heavy greater equal threshold value 
perform subsequent hashing scans necessary nally produce total revenues exceed speci ed threshold 
case studies relatively large number techniques parameterized di erent ways data sample values retain potentially heavy memory allocations di cult draw concrete looking particular application scenarios 
chose distinct application scenarios designed experiments answer questions scheme perform vary amount memory allocated 
report performance terms number false positives jf produced total time scheme takes produce aswell remove false positives count 
scheme perform vary threshold 
report jf total time 
perform di erent data distributions 
input data zip distribution called distribution opposed skewed distributions schemes ected sampling 
results discuss allocate memory experiments 
experimented variety split available memory sample set size case defer count algorithms primary auxiliary buckets 
approach best data 

allocate algorithms defer count choose small sampling scan allocate memory set 
discuss value application 

allocate auxiliary buckets allocate percent remaining memory rst step auxiliary buckets 
algorithm executes may discover amount allocated memory insu cient auxiliary buckets 
happens greedily select buckets highest counter values assign possible auxiliary area 
remaining potentially heavy buckets assigned limited auxiliary area treated primary bucket hashing scan 

allocate primary buckets bitmaps allocate balance memory primary buckets bitmaps 
case need memory primary buckets bitmaps value chosen analysis appendix 
experiments values splitting memory 
candidate selection scan reclaim memory allocated primary buckets allocate store experiments nal input count main memory stream tuples disk execute count disk sorting algorithm 
implementation enhanced early aggregation integrates counting sorting merging processes cient execution 
discussed earlier merely way execute count 
reader interpret results section absolute predictions illustrations performance trends 
experiments sun ultra ii running sunos mbs ram local disk space 
case market basket query market basket query nd commonly occuring word pairs 
web documents crawled stored stanford webcrawler 
average length document words 
data computed relation document identi er docid word identi er 
relation mbs byte integers 
note removed entries corresponding pre de ned words relation 
recall iceberg query executed pairs words occur document 
materialized disk require store addition may require temporary storage performing aggregation 
impractical discuss technique section 
avoid explicitly materializing technique general execute iceberg queries materialized 
typically tuples refer document contiguous 
produced reading parsing documents time 
entries contiguous sort relation 
property simply scan produce hwi wji wi wj pair occurs document 
explicitly storing tuples stream tuples directly algorithm execute iceberg query 
instance defer count execute iceberg query assume increment wi wj soon tuple hwi wji produced 
notice apply similar optimization sorting hybrid hashing schemes tuples materialized explicitly sorting need stored hash table hybrid hashing 
discuss representative schemes speci values illustrate trade involved 
study performance schemes greater detail full version 
speci cally results multiscan multiscan shared corresponding multi bucket optimization defer count 
evaluate multi stage 
sample practice data 
number candidate pairs multi stage multiscan multiscan shared memory allocated mbs jf memory varies 
total running time multi stage multiscan multiscan shared memory allocated mbs total time memory varies 
show jf number candidate pairs varies amount memory allocated increases 
see jf drops memory allocated expected 
see multiscan multiscan shared perform best terms choosing smallest jf amount memory small doing multiple passes data available memory array helps prune number false positives signi cantly 
performs poorly initially amount main memory small di erence drops larger memory 
memory mbs see performs better counterpart 
see total time answer iceberg query amount memory varies 
see multiscan multiscan shared perform steadily di erent memory sizes produce false positives 
hand multi stage performs badly memory limited mbs performs best 
number false positives relatively small counting done main memory multi stage scans data time uses cpu time computing fewer hash functions multi bucket algorithms 
study jf number candidates varies threshold varied 
see multiscan multiscan shared tend smallest jf see performing multiple passes data multiple hashing functions helps prune away false positives 
see corresponding total time answer iceberg query 
see multi stage performs best interval relatively small performs fewer scan data needs compute fewer hash functions multiscan multiscan shared summary see multi stage works best application little data 
number candidate pairs rank multi stage multiscan multiscan shared threshold jf threshold varies mb 
frequency frequency rank curves di erent 
case computing total running time multi stage multiscan multiscan shared threshold total time threshold varies mb 
result size percentage threshold result sizes di erent thresholds 
consider sensitive schemes skews data distribution ir example 
discussed section ir systems compute set words ciency 
general ir systems compute chunks syntactic units text occur frequently 
identifying popular chunks improve phrase searching indexing 
instance chunks netscape mozilla occur frequently web documents may indexed certain implementations ir systems reduce storage requirements 
set experiments documents obtained stanford crawler 
de ned chunks sliding windows words 
chunking th chunk document sequence words 
corpus documents compute relation contains sji document dh contains sj byte hashed version th chunk 
experiments computed di erent tables 
note relation relation compute words ir systems 
rst graphs illustrate nature data speci algorithm 
show log log plot frequency rank curves di erent 
expected smaller construct chunk fewer number distinct target values larger data skew 
instance number distinct chunks heaviest target occurs times 
heaviest target occurs times 
size relations gigabytes note remove pre computed words relations market basket query 
show log log plot percentage unique terms heavy di erent thresholds 
see gure expected targets tip iceberg drops signi cantly increases 
graphs study number hashing scans number hash buckets ect false positive errors 
due lack space results context multiscan shared number previous bitmaps cached memory 
vertical axis gures percentage false positives fp fp number false positives 
expected percentage false positives drops dramatically increasing instance percentage drops 
interesting note number false positives drops data skewed especially number hashing scans increases 
attribute factors fewer heavy targets data skewed fewer light targets fall buckets heavy due heavy targets hashing scans performed fewer light targets fall heavy buckets hashing scans 
summary experiments quantify impact skew provide guidelines selecting number hashing scans needed multiscan shared tip iceberg changes size 
analogous behavior observed schemes 
case query total time execute query discussed section multiscan multiscan shared techniques amount memory changes 
executed query relation case 
data query sampling scan 
see multiscan shared performs best amount memory small progressively inferior multiscan multiscan shared memory increases 
multiscan shared multiscan shared multiscan shared small values memory 
behavior multiscan fp performance multiscan shared ofn 
fp performance multiscan shared 
shared compared multiscan shared due competing factors multiscan shared uses fewer bitmaps multiscan shared allocating memory primary buckets 
amount memory multiscan shared prunes light targets multiscan shared discussed earlier 
small values memory multiscan shared performs better multiscan shared rst factor dominates 
larger values memory extra space allocated additional bitmaps multiscan shared leaves memory primary buckets 
second factor dominates 
see multiscan perform small memory bitmaps prune away light targets discussed earlier 
see choosing may useful small sized memory leaving su cient main memory primary buckets 
size materialized 
assume disks execute sequential scans rate mb sec take seconds read write notice multiscan shared done executing written read 
course sorted execute iceberg query easy see sorting execution require disk space materialize sort take longer schemes 
summary case studies experiments report due lack space propose informal rules thumb combine schemes hybrid algorithms 
hybrid algorithms multi level rarely performs experiments defer count multi stage tend di erent circumstances 
expect data distribution skewed zip distributions targets heavy constitute relation defer count small set 
expect data skewed multi stage time seconds multiscan multiscan shared multiscan shared multiscan shared size memory mb performance algorithms query 
incur overhead looking values expect data distribution sampling scan 

algorithms general recommend multiscan shared 
relatively large values memory recommend multiple hash functions choose apply multiple hash functions hashing scan discuss full version 
related flajolet martin whang proposed simple form coarse counting estimating number distinct elements multiset 
park proposed coarse counting context mining association rules 
approaches single hash function coarse counting tend false positives 
extend techniques hybrid algorithms perform comprehensive study techniques case study approach 
studied cient execution techniques iceberg queries important class queries widespread application data warehousing data mining information retrieval copy detection 
proposed algorithms compute result tip iceberg ciently conventional schemes 
evaluated algorithms case study approach real applications observed savings signi cant 
algorithms suite provided better suited scenarios depending data skew available memory factors 
provided empirical rules thumb selecting scheme allocating memory data structures 
agrawal srikant 
fast algorithms mining association rules large databases 
proceedings international conference onvery large databases vldb pages september 
bitton dewitt 
duplicate record elimination large data les 
acm transactions database systems tods 
brin motwani silverstein 
market baskets generalizing association rules correlations 
proceedings acm sigmod conference pages may 
brin motwani ullman tsur 
dynamic itemset counting implication rules basket data 
proceedings acm sigmod conference pages may 
brin page 
google search engine web crawler 
broder 
resemblance containment documents 
technical report digital systems research center tech 
report 
broder glassman manasse 
syntactic clustering web 
sixth international world wide web conference april 
fang motwani ullman 
improvements hash algorithms mining association rules 
technical report stanford dbgroup technical report october 
fang shivakumar garcia molina motwani ullman 
computing iceberg queries ciently 
technical report stanford dbgroup technical report february 
flajolet martin 
probabilistic counting algorithms database applications 
journal computer system sciences 
graham knuth patashnik 
concrete mathematics 
addison wesley publishing reading ma 
haas naughton seshadri swami 
selectivity cost estimation joins random sampling 
journal computer system sciences june 
hellerstein haas wang 
online aggregation 
proceedings acm sigmod international conference management data sigmod arizona june 
jordan 
calculus finite di erences 
chelsea nd edition 
olken 
random sampling databases 
ph dissertation uc berkeley april 
park chen yu 
ective hash algorithm mining association rules 
proceedings acm sigmod conference pages may 
salton buckley 
term weighting approaches automatic text retrieval 
information processing management 
shivakumar garcia molina 
scam copy detection mechanism digital documents 
proceedings nd international conference practice digital libraries dl austin texas june 
shivakumar garcia molina 
building scalable accurate copy detection mechanism 
proceedings st acm conference digital libraries dl bethesda maryland march 
shivakumar garcia molina 
computing replicas near replicas documents web 
appear workshop webdb valencia spain march 
tpc committee 
transaction processing council tpc 
www tpc org 
ullman 
principles database knowledge base systems volume 
computer science press 
whang vander zanden taylor 
linear time probabilistic counting algorithm db applications 
acm transactions database systems 
zipf 
human behavior principle ort 
addison wesley press cambridge massachusetts 
analyzing zip distribution suppose hashing items item ij weight wj 
items itemsets weights counts 
available memory size partitioned equally hash tables hk hash table total cells available 
goal determine optimal choice point view pruning away items weight support 
recall item pruned away hash table certi es weight hash table particular cell property total weight items hashed items hashed cell certi ed pruned away 
problem choose hash functions prune away maximum number items 
pruning expect worst case function various parameters 
case analysis fairly di cult theoretical problem ignore 
assume item weights follow pleasant distribution perform analysis basis 
assumption assume items weights wj chosen independently probability distribution pr wj particular reason assuming weights integer valued bounded analysis generalizes quite easily continuous unbounded distributions 
assumption hash functions 
assumption assume hashing performed independent completely random hash function 
second part assumption unrealistic hash table associated hash function assigns items cells hash table independently uniformly random 
consider modifying analysis universal universal hash functions practice 
de nition denote event item ij gets pruned hash table hi cell containing ij hi total weight ej denote event item ij gets pruned hash tables ej de nition pr note independent assumptions 
follows pr ej basically need estimate function note expected number items pruned away np rst note probability exactly items mapped cell hi ij exactly items cell probability total weight cell denoted 
obtain nx remains obtain expression clearly depends distribution weights 
assume item weights follow simplest form zip distribution viz constant chosen ensure clear ln general zip distribution allows higher powers denominator complicate expressions obtain adding insight 
stick simple form zipf law 
deriving closed form expression proves fairly tricky simple case 
recall probability generating function random variable de ned gx pr follows simple zipf distribution gx zx ln expression derived page 
note assuming weights drawn range preceding derivation reasonable approximation generating function extending summation 
really interested probability sum independent random variables simple zipf distribution sum random variable distributed sum random variables simple zipf distribution 
obtain probability generating function tth power gx 
gy gx ln ln 
zk 
expression derived page notation denotes stirling number rst kind 
probability easily seen sum rst coe cients gy 
obtain sx 



sx 


expression derived pages 
bound probability element ij gets pruned follows pr ej nx nx 

expression plugging estimate stirling number obtain desired probability 
goal merely determine optimum choice maximizes pruning probability 
unfortunately known closed form formula stirling approximation possible plot curve see maximum value lies 
complete analysis simplifying assumption 
assume cell jth element gets mapped unique cell hash tables exactly expected number elements kn gives fairly approximation summation preceding expression dominated term kn wenow asymptotic approximation stirling number rst kind valid small held constant ass goes nity 
inequality due jordan states 

ln euler constant 
proceeding assumption kn asymptotic estimate obtain pr ej 

ln kn ln possible estimate ect varying degree pruning obtained multiple hash tables 
values parameters possible determine optimal choice 
