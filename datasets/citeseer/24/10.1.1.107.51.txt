robust system accurate real time summaries internet traffic ken keys caida san diego supercomputer center university california san diego caida org performance extreme workloads isolation resource consumption concurrent jobs perennial design goals computer systems ranging multitasking servers network routers 
specialized system computes multiple summaries ip traffic real time achieves robustness isolation tasks novel way automatically adapting parameters summarization algorithms 
traditional systems anomalous network behavior denial service attacks worms overwhelm memory cpu making system produce meaningless results exactly measurement needed 
contrast measurement system reacts gracefully degrading accuracy affected summaries 
types summaries compute widely network administrators monitoring workloads networks ports sending traffic ip addresses sending receiving traffic opening connections evaluate compare existing algorithmic solutions computing summaries new solutions propose flow sample hold bloom filter tuple set counting 
compared previous solutions new solutions offer better memory versus accuracy tradeoffs predictable resource consumption 
evaluate actual implementation complete system combines best algorithms 
categories subject descriptors computer communication networks network operations network monitoring general terms measurement experimentation performance algorithms permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigmetrics june banff alberta canada 
copyright acm 
david moore caida san diego supercomputer center university california san diego caida org keywords cristian estan computer sciences department university wisconsin madison estan cs wisc edu passive monitoring measurement sampling traffic estimation adaptive response 
order run networks efficiently network administrators need understanding networks misused 
important tool network administrator toolbox ability monitor traffic mix especially important links 
increases traffic volumes possible increases line speeds main driving forces evolution traffic measurement 
capturing traces packets packet headers feasible low speeds higher speeds aggregation necessary reduce amount traffic measurement data 
routers report traffic measurement data netflow format aggregates packets belonging flow flow record 
kind aggregation router traffic measurement fragile assumptions aggregation hold traffic mixes 
small flows predominate netflow aggregation help 
anecdotal evidence abounds routers netflow crashing denial service attack randomly faked source addresses run memory 
netflow uses packet sampling router reduce processing memory usage size output aggressive sampling needed keep resource consumption control extreme traffic mixes compromises accuracy measurement results 
presents robust traffic measurement system handles unfriendly traffic mixes gracefully degrading accuracy results 
furthermore measurement results produces concise traffic summaries accuracy high possible resources available 
structure follows 
section describe goals traffic measurement system 
section discuss related including prior algorithms incorporated system 
section describe algorithms computing summaries including new algorithms bloom filter tuple set section flow sample hold section 
section describe system including adaptation methods achieve robustness respect memory cpu usage 
section measure performance different configurations system real traces 
evaluate perform response adverse network traffic 
conclude section 
measurement system goals set build system produces compact timely traffic summaries 
section describes summaries interested 
section identify potential bottlenecks tangible goals set system graceful degradation accuracy summaries faced unfriendly traffic mixes isolation resource consumption algorithms generating summaries 
traffic summaries traffic summaries want system produce divided categories global traffic counters hog reports list heavy hitters packets bytes flows 
types summaries implemented current systems widely network administrators 
computing accurate timely hog reports high speed links challenging 
summaries reflect traffic monitored link fixed duration measurement intervals 
global counters measure counts entities interval packets sent bytes sent active flows active source ip addresses active destination ip addresses active protocol source port pairs active protocol destination port pairs 
numbers measured simple counters need complicated flow counting algorithms 
refer sources destinations send receive packets bytes packet hogs byte hogs 
sources destinations flows flow hogs 
measurement system produces types hog reports keyed specific packet header fields source ip destination ip source port protocol destination port protocol 
system produces byte packet flow hog reports key 
system produces total hog reports 
example report lists source ip packet hogs packets sources sent 
particular reports allow answering common questions asked network operators 
example port reports provide information application usage 
hosts engaged malicious activity visible source ip flow hog reports port scanning spam relaying generates outbound flows 
total volume malicious traffic low hosts typically visible packet hog byte hog reports 
network administrators may interested summaries ones 
example want aggregate traffic longest matching prefix number ip address 
want measure degree source ip addresses number destination addresses connect degree destination addresses flow counts 
methods readily applied measurements 
furthermore software architecture changes relatively easy implement 
robustness isolation underlying architecture system general purpose computer oc gbps dag capture card shown 
expect techniques prove useful different architectures potential bottlenecks example devices built network processor 
identify potential bottlenecks memory cpu processing power bus bandwidth output network speed 
simplest bottleneck system avoid output bandwidth 
exporting compact summaries described minimize amount data sent network 
optical splitter router router oc card potential bottlenecks pci pci disk cpu cpu memory nic pci network cpu bus memory output underlying architecture system current high pc motherboard 
potential bottlenecks measurement exist cpu processing bus bandwidth memory size output network speed 
specialized hardware deployment router blade potential bottlenecks exist 
address potential memory bottleneck counting algorithms accurate sampling techniques 
implementation techniques reduce cpu usage cpu overwhelmed large number packets system bus 
resort protect problem performing kind sampling sampled netflow packet selection directly card 
card currently support simulations evaluate adaptive sampling provide robustness respect cpu usage 
system overcome potential bottlenecks allow results approximate 
want achieve accurate results possible existing resources 
faced atypical traffic strains system resources system continue providing summaries possibly lower accuracy 
example distributed denial service ddos attack fake source addresses exhaust available memory consuming entries source ip table 
system react refusing create new entries table poor response big hogs appear decision completely omitted table 
small errors counters similar entries hog reports acceptable ways degrading accuracy omitting source traffic significantly included hog report 
sharing memory cpu resources components computing various summaries result cheaper efficient systems compared alternative complete isolation components 
want traffic mix strains components starve resources 
example acceptable response ddos attack system decreases accuracy source ip report destination ip report affected attack implemented isolation affected 

related netflow widely deployed general purpose measurement feature cisco routers 
volume data produced netflow problem 
handle volume traffic diversity high speed backbone links netflow resorts packet sampling 
sampling rate configuration parameter set manually seldom adjusted 
setting low causes inaccurate measurement results high result measure ment module memory processing power especially faced increased unusual traffic lead dropping data poor accuracy 
adaptive netflow proposed adaptively tune sampling rate memory consumption 
advantage flow records traffic summaries computed measurement device wide variety analyses reach remote collection station 
know advance aggregations want produce traffic summaries error 
gigascope project exemplifies approach maintains accuracy achieve processing raw data locally flexibility general sql query language guarantee robustness unfavorable traffic mixes 
algorithmic problems need solve compute accurate traffic summaries identifying measuring streaming fashion addresses ports heavy traffic counting number flows 
existing solutions address problems subset measurements provides picture 
identifying heavy hitters addressed database networking contexts 
counting number distinct items addressed database community :10.1.1.12.7100
related problem finding flow hogs counting flows easily solved hash tables explicitly store flow identifiers memory cost excessive 
problem algorithmically equivalent problem finding addressed venkataraman independently proposed techniques equivalent flow sample hold bloom filter tuple set counting 
efficient bitmap algorithms flow counting proposed 
system directly uses improving 
bloom filters useful data structure testing set membership section count flows 
kumar variation bloom filter related different problem counting packets flow 

algorithms traffic reports global counters part reports pose significant issues bytes packets simple counters counting distinct addresses ports flows multiresolution bitmaps 
low constant cpu memory usage understood accuracy rest focus hog reports 
simple way producing hog report key keep hash table counter key traffic just report top entries measurement interval 
approach problems flows counted simple counters tables get large 
section discusses algorithms counting flows section identifying entries worth keeping tables 
flow counting counting flows table entry harder counting bytes packets 
distinguish packets belonging old new flows increment flow counter flow new 
true global flow counter flow counters individual table entries 
discussing existing algorithms counting flows propose new ones bloom filter tuple set counting list triggered bitmaps 
background obvious method counting flows bytes packets source address destination address source port destination port maintain global tuple table keyed flow id update packet 
measurement interval aggregate entries target tables appropriate keys 
algorithm coralreef crl flow 
gives exact counts tuple table uses large amount memory processing cost concentrated interval 
extreme conditions worm attempting spread ddos attack tuple table overflows exactly interested results 
estimate number active flows explicitly storing flow identifiers 
start empty bitmap set bit bitmap corresponding hash value flow id packet interval estimate number active flows number bits set 
algorithm called linear counting direct bitmap provides accurate estimates memory requirements scale linearly maximum number active flows 
size bitmap depends required accuracy estimate 
similar algorithms multiresolution bitmaps probabilistic counting complex mappings flow ids bits memory requirements scale logarithmically maximum number active flows 
kilobytes algorithms give estimates average errors hundreds millions flows 
bloom filter tuple set tuple table algorithm spread expensive interval aggregation maintaining target tables interval incrementing flow counter corresponding entry add new tuple table entry 
reduce memory usage tuple table 
note tuple table decide packet belongs new flow 
think tuple table test flow id packet set flow ids seen 
willing accept estimate flow count entry replace tuple set compact fixed size structure designed testing set membership bloom filter 
bloom filter implemented bitmap bits initially empty independent uniform hash functions range 

insert flow id set compute hash functions flow id set bits corresponding hash value 
test flow id new test bits corresponding hash flow id bits set assume flow id new bits flow id definitely new increment counters target tables 
seen flows far probability false positive mistakenly concluding seen flow kn kn bloom filter falsely indicates seen particular flow id identify new source address destination address source port destination port seen 
check keys insertion corresponding tables additional checks newness additional cost greatly reducing effect false positives bloom filter 
difficult predict theoretically helps practice large fraction entries table flows bloom false positives fraction counted 
example consider worm attacking large number destinations 
destinations attack flow flow bloom filter false positives counted keeping attacker flow count relatively accurate 
similar logic holds ddos attacks large number spoofed source addresses 
described bloom filter tuple set algorithm gives lower bounds flow counts bloom filter test table insertion tests incorrectly identify existing flow new flow 
measurement contexts useful know estimate lower bound 
list triggered bitmaps global tuple table bloom filter simple flow counter entry target tables add multiresolution bitmap smaller bloom filter entry 
typical traffic mixes ip sources destinations flows entry flow counters need memory multiresolution bitmaps configured hundreds millions flows 
triggered bitmap algorithm saves memory starting small direct bitmap new entry allocating multiresolution bitmap number bits set direct bitmap exceeds trigger value 
avoid bias multiresolution bitmap updated packets hash bits set direct bitmap 
direct bitmap accurate small multiresolution bitmap loses accuracy covers sample cover 
propose alternative triggered bitmap avoids loss accuracy multiresolution bitmap comparable amounts memory list triggered bitmaps 
replace direct bitmap small list flow identifiers 
value small typically list efficiently implemented array 
save space store flow ids bit hashes flow ids 
packet append hash value flow id list list 
list full try append new value allocate multiresolution bitmap insert new hash value old hash values list 
true number flows equal maximum list size multiresolution bitmap allocated estimate exactly number hash values list source error collisions hash function negligible values 
multiresolution bitmap algorithm refinement multiresolution estimate say list triggered estimate multiresolution bitmap allocated hash values 
identifying important entries lightly loaded oc favorable traffic mix measurement system megabytes memory efficient algorithms counting flows afford keep entry source destination ip 
adverse traffic mixes massive dos attacks source addresses faked random worms aggressively probing random destinations keeping small entry unique ip address consume memory generously endowed workstation 
want keep state hogs afford keep state entries 
need algorithms identify hogs 
packet sample hold sample hold algorithm identify accurately measure packet hogs keeping state entries 
packets sampled random sampled packet entry created target table exist packets corresponding entry counted 
refer algorithm packet sample hold psh distinguish algorithm intro duce 
sampling probability tuning knob trade memory accuracy high probability gives accurate results lower reduces memory usage allows packets go entry created 
analysis psh shows identifies packet hogs high probability 
naive thinking suggests psh identify flow hogs source flows packets traffic example shows psh achieve goal 
consider minute interval traffic saturated oc containing flows packets bytes say pairs distinct hosts doing peer peer sharing mb files 
add port scanner sends single byte scan packet destinations 
course want detect port scanner largest flow hog 
measurement system assume packet different source ip source ip table space entries psh sample packet risking filling table 
sampling rate probability catching port scanner approximately 
low probability source ip getting entry table depends number packets sends number flows 
general traffic mixes dominated sources high packet flows hard psh detect early sources low packet flows 
traffic mix example typical failure mode unacceptable want system robust face anomalous traffic 
flow sample hold accurately identify flow hogs regardless packets introduce flow sample hold fsh 
similar psh sampling function favors entries flows 
hash flow identifier packet hash value control variable range hash values create entry target table 
fsh bit hash function flow sampling probability note packets flow hash value number packets flow affect probability triggering creation entry source ip 
furthermore number flows source increases probability getting entry decreases exponentially 
big flow hogs get entries early flow counter entries count corresponding flows active point 
formally quantify probability source sending certain number flows detection 
number flows source flow sampling probability 
probability particular source entry bound expected number source flows creating entry source equal absolute error entry flow count estimate accurately count flows entry created 
missed pf exactly flows pf 

example previous section say fsh sampling probability 
probability port scanner gets entry 
time sources peer peer traffic flow probability getting entry 
peer peer traffic add entries source ip table 
fsh better job psh finding flow hogs reducing number noise entries low flow counts 
fsh replace psh 
guaranteed catch packet hogs byte hogs 
answer 
extending example imagine host sending mb file single tcp connection 
far largest sender probability fsh sample single flow ignore important source 
obvious answer system aims detect packet hogs flow hogs psh fsh populate tables entries 
question arises naturally need byte sample hold bsh algorithm detect byte hogs 
reason need psh fsh ratio number packets flows thousands 
ratio number bytes packets exceed current traffic mixes packets range size bytes 
byte sampling give accurate results psh samples packets equal probability difference small ratio packet sizes bounded small constant number entries keep tables larger number entries report 
implementation system trivially bsh available optional user decide extra accuracy catching byte hogs worth extra cpu overhead 
simplicity efficiency rest rely psh identify byte hogs 

system description section describe actual measurement system implemented 
describe section component computes hog report adapt traffic mix avoid exhausting memory cpu 
section describe integrate components form full system show components better resources sharing 
section describe ensure despite sharing components starve resources 
robustness adaptation discuss component computes hog report robust respect memory cpu usage faced adverse traffic 
simplicity focus packet hog report source addresses easily generalized hog reports point differences matter 
basic idea keep table entry source count packets send 
psh limits number entries created need choose sampling rate high run memory low results needlessly inaccurate 
solution adaptively decrease psh sampling rate quickly memory filling 
start measurement interval sampling probability creating entry distinct source ip traffic stream 
allocates entries quickly decrease probability value estimate keep table size memory budget interval 
appendix describes exactly choose new probability 
bloom filter tuple set algorithm count flows table entry size table entry fixed adaptive sample hold control number entries sufficient control memory 
triggered list triggered bitmap entries grow number flows triggers allocation large multiresolution bitmap sample hold effective controlling memory usage 
decreasing psh sampling probability reduce cpu usage somewhat table lookup packet may 
issue software implementation implementation router spe hardware 
oc speeds cpu average ns process byte packet 
packet buffers absorb bursts packets long streams back back short packets come example massive ddos attack 
control cpu usage adaptively pre sampling packets capture card reach cpu 
see technical report details adapt packet pre sampling probability 
compensate pre sampling updating counters 
example pre sampling probability sampled packet counted packets 
randomness pre sampling reduces counter accuracy packet hogs relative error small 
pre sampling reduces number table entries sources packets packets dropped suggesting psh control memory usage 
analysis shows psh gives accurate results pre sampling sampling probability memory usage 
byte counters compensate pre sampling way packets increment counters size packet divided pre sampling probability 
situation difficult flow counters 
shown flow estimator random sampling packets belonging source ip traffic mix estimate far actual count 
additional information tcp syn flags pre sampled packet headers lead consistently accurate estimates 
methods apply tcp rely hosts correctly setting flags 
problem fundamentally hard pre sampling probability keeps changing respond changes traffic mix adopt simple solution flow counters compensate pre sampling 
result underestimating number flows pre sampling rate low mix contains short flows know flow estimates lower bound actual flow counts 
inaccuracies introduced pre sampling system relies sample hold control memory usage lowers pre sampling rate necessary control cpu usage 
note existing systems equivalent fixed rate packet pre sampling time effect problems described worse 
structure system integrate modules compute various summaries sharing saves memory cpu cycles allowing maintain higher sampling rates achieve better accuracy 
note reports key types byte hogs packet hogs flow hogs 
keeping separate tables key type single table entry having counters 
entries larger keys appear reports having share single table entry results net reduction memory 
clear win merged tables perform table lookups packet twelve significantly reducing cpu usage 
shows combined table operates 
choose bloom filter tuple set algorithm counting flows 
reason experiments section show configurations accuracy equal better bitmap algorithms 
reason better control memory usage need control number entries tables 
sharing single bloom filter tables major reduction memory cpu usage 
furthermore bloom filter pre sample randomly packet entry 
captured packet headers selected queue compute new queue occupancy psh select probability fsh hash compute new adjust pre sampling rate selected need adjust 
selected need adjust 
create entry increment packet byte counters update bloom filter new bits set 
increment flow counter entry tables keyed various fields combine algorithms selecting entries psh fsh bloom filter tuple set algorithm counting flows 
dynamically adapting psh fsh sampling rates ensures system tries allocate entries memory hold 
larger flow counters accurate larger shared bloom filter fewer errors due collisions 
summaries produced system include various global counters total distinct source ips flows 
total flow count estimated treating tuple set bloom filter large direct bitmap generalized multiple hash functions additional memory needed 
global counters implemented multiresolution bitmaps 
efficient implementation hash function family useful property computed piecewise 
calculating hash value global flow counter save cpu time reusing hash values calculated source ip destination ip counters keys subsets flow key 
estimates accurate hash functions bloom filter bitmaps produce uniformly distributed values input 
hash functions satisfy requirement 
additionally want hash function unpredictable external observer impossible maliciously craft traffic subvert system causing hash collisions bloom filter bitmaps hash tables described crosby wallach 
achieve randomly generating functions 
isolation isolating resource consumption various components system ensures strain component hurt accuracy 
memory dynamically allocated tables compute hog reports 
isolating memory consumption easy divide number entries allocate 
dos attack faked source ip addresses strain source ip table cause decrease psh fsh sampling probabilities leading reduced accuracy hog reports tables unaffected reports lose accuracy 
current system divides memory equally tables overridden configuration 
simple improvement strategy implemented tables share memory port tables interval redistribute surplus 
algorithms psh fsh adding table entries 
protect dividing memory budget table equally algorithms adjusting sampling probabilities psh fsh independently see 
algorithms sample packet causes creation new entry get charged half entry 
packet processing modules producing various summaries severely intertwined performing packet pre sampling separately control cpu usage module impractical 
fortunately unnecessary reasons 
firstly average packet cpu usage modules constant share total cpu usage module take disproportionate share cpu 
modules need reduce cpu usage time packet headers process 
secondly packet pre sampling effectively protect cpu bus implemented capture card 
measurement results section experiments evaluate various system configurations validate design 
experimental setup describe experiments test specific system components 
compare algorithms identifying important entries psh fsh see advantages predicted theoretical analysis 
second compare flow counting algorithms triggered bitmap bitmap bloom filter tuple set 
third investigate behavior adaptation methods test provide robustness isolation 
test fully configured system variety data sets seeds show behaves consistently 
experimental setup metrics experimental datasets 
metrics evaluate system memory usage memory entire process minute interval cpu run time user system cpu time usage top selection error measures far system correctly selecting top entries packets bytes flows table 
exact definition detailed results metric technical report version 
rms relative error measures average error byte packet flow estimates table giving weight values greater average error rms rel 
err 
nx ni ni normalized absolute error measures absolute error byte packet flow estimates table capture card experiments support random packet sampling simulate pre sampling 
ni dataset start time utc duration packets pkts sec bytes bits sec flows flows sec robustness testing backbone wed aug min 

backbone ddos wed aug min 


validation averages min 
samples oc wed aug hour 
oc wed aug hour 

campus fri may hour 
table datasets study 
backbone test dataset consists minutes oc trace 
backbone ddos dataset adds simulated ddos packets spread minutes 
metric value percent pkts rms rel pkts norm abs flows rms rel flows norm abs entries dst ip psh rate table entries metric value percent pkts rms rel pkts norm abs flows rms rel flows norm abs entries fsh rate trading memory accuracy sample hold rates 
counting done backbone ddos tuple set algorithm 
giving weight important larger entries normalizing sum entries norm 
abs 
err 
pn pn ni ni ni metrics measure entire groups counter estimates applied top counter estimates 
recall see section table types src ip dst ip src dst counters packets bytes flows 
evaluate sets estimates error metrics giving values 
evaluate relative error global counters 
including memory cpu measure values system configuration 
brevity comparing different system configurations focus subset values significantly different configurations 
tables values system configurations discussed available technical report version 
tested system multiple data sets simplicity chosen representative sets results oc hour trace aug direction traffic oc link located fiber network mfn san jose 
oc hour trace direction oc link mfn san jose 
campus hour trace inbound outbound traffic large university campus may 
dst ip backbone minute trace direction traffic oc ip backbone link average rate approximately mbps minutes oc 
ddos artificially generated byte packets spread minutes mbps fixed dst ip dst random src ip src simulating random source distributed denial service attack single victim 
ddos data mixed datasets 
table presents summarized characteristics traces 
comparing sample hold variants compare algorithms identifying important entries psh fsh run separately 
sampling rates algorithms trade memory accuracy repeat experiments number sampling rates 
separate errors introduced entries allocated late due flow counting algorithms exact flow counting algorithms hash tables 
illustrates tradeoff algorithm ip tables backbone ddos dataset 
metrics byte counters omitted brevity similar packet counters expected 
accuracy flow summaries generally better packet summaries fsh worse psh 
expected fsh worse psh cancel weaknesses 
normalized absolute errors dst ip graphs smaller corresponding rms relative errors system counted flows single ddos victim accurately flow count dwarfs destination hosts 
table entries metric value percent src ip flows rms rel flows norm abs memory mrb bloom bloom bloom bloom memory mb metric value percent dst ip flows rms rel flows norm abs memory mrb bloom bloom bloom bloom comparison flow counting algorithms multi resolution bitmap mrb triggered bitmap list triggered bitmap bloom filter tuple set bloom fixed psh rate fixed fsh rate 
memory mrb graph mb 
data backbone ddos 
counting algorithms configurations compare various flow counting algorithms fixed sampling rates psh fsh appear reasonable visual inspection 
chosen counting algorithm switch adaptive sampling rates 
compare different flow counting algorithms 
packet byte counter estimates plain integers accuracy determined entirely sampling rates flows values counted counting algorithms analyze accuracy memory usage flow reports 
configure bitmap algorithms multiresolution bitmaps give error 
expect triggered list triggered bitmap algorithms memory mrb algorithm psh fsh cause omission small entries trigger creation mrb memory saving dramatic sampling 
trigger value list triggered bitmap algorithm effect accuracy large entries try reasonable values see uses memory 
list triggered bitmap bit hash functions bits trigger overhead 
gives procedure choosing triggered bitmap direct bitmap size trigger value start matching memory usage list triggered bitmap just described setting try higher values save memory avoiding allocation increase error 
try bloom filter tuple set algorithm bit array sizes ranging bloom filters fixed amount memory mb mb variable affecting memory configuration number table entries 
consider results shown algorithms multi resolution bitmap mrb triggered bitmap list triggered bitmap 
expected memory usage mrb impractically large attack situations bitmap algorithms lower memory usage 
perform roughly time error increases significantly conditions 
hand accuracy consistent susceptible parameter choice bad choice affect memory slightly 
reasons plus fact slightly faster preferable 
bloom filter tuple set algorithm bloom filter small densely filled attack gives flow count true rank memory mb true bloom flow estimates src ip table rank zoomed show detail bloom runs 
bloom curve nearly monotonic starting true rank significantly non monotonic sections curve result incorrect rankings 
rate results 
reasonably sized bloom filter say bits gives quite accurate results extreme conditions significantly memory bitmap algorithms 
bloom filter tuple set appears accurate graphs reasonable choices different traffic mixes variations system different tables slightly better 
bloom filter tuple set algorithm additional advantages 
table entries smaller bit counter bitmap algorithms bit trigger bit mrb memory usage grows slowly increased traffic 
table entries fixed size allocate large multiresolution bitmaps triggered bloom memory usage closely related number table entries easier control 
bloom algorithm significantly lower memory usage half approaches bits able stand better algorithms conditions extreme simulated ddos attack 
additionally plot errors rank nearly monotonic bloom filter tuple set meaning better correctly ranking results 
bloom significantly metric value percent pkts rms rel pkts norm abs flows rms rel flows norm abs entries backbone traffic ddos src ip table entries limit table entries metric value percent pkts rms rel pkts norm abs flows rms rel flows norm abs entries backbone traffic ddos dst ip table entries limit effect total table entries limit adaptive algorithm accuracy results total number entries allocated 
counting done bit bloom filter adaptive sample hold rates 
sampling rate backbone traffic adaptive sampling rate time fsh src proto port psh src proto port fsh src ip psh src ip fsh dst ip psh dst ip time seconds sampling rate backbone traffic ddos adaptive sampling rate time fsh dst ip psh dst ip fsh src proto port psh src proto port fsh src ip psh src ip time seconds adaptive sampling rate course measurement interval table entry limit bit bloom filter 
normal traffic causes little reduction sampling rates system reacts quickly accurately tables filling due ddos attack 
note axes different scales 
faster algorithms bit array ran seconds compared seconds fastest bitmap configuration 
reasons chose bloom filter tuple set counting algorithm system 
adaptivity system achieves robustness resource isolation respect memory usage adjusting sampling rates psh fsh algorithms see appendix details responsible creating table entries instance allocating new memory 
keep cpu usage control adapt pre sampling rate see technical report details 
section see different memory limits affect accuracy results ddos scenario 
fix memory limit measure smoothly sampling rates adapt achieve isolation ddos traffic adverse tables 
look pre sampling adaptation works extreme attack scenarios 
see error kept low simulated ddos attack wide range memory limits 
higher limits actual number entries somewhat lower limit partially equal division entries table samplers quite optimal partially memory usage prediction perfect 
plan re allocate entry limits table interval entries previous interval 
limit number actual entries normal backbone traffic shown nearly constant able get entries needed reducing sampling rates 
low limits metrics obvious exception src ip flows ddos test ddos creates extremely large number src ip entries 
limits higher hardest hit metric error metrics 
shows system dynamically adapted sample hold rates time meet memory constraint 
backbone dataset number entries allocated table samplers slightly wanted system reduce sampling rates little 
hand ddos traffic quickly created entries src proto port src ip tables system reacted second tables reached capacity reducing sampling rate 
just correction seconds samplers settled rate able sustain remainder interval 
dst ip dst proto ports samplers maintained high sampling rate situations ddos little effect apparent difference dst ip curves due change scale axis 
table entries metric value percent dataset comparison dst ip oc oc campus dataset pkts rms rel pkts norm abs flows rms rel flows norm abs entries system behaves consistently different datasets 
comparatively large spikes intervals oc due unusual network event deviation system 
counting done bit bloom filter adaptive sample hold rates table entry limit 
fix entries limit runs system error rates keeps memory usage tables mb ram current stl implementation 
combined bit bloom filter miscellaneous overhead keeps total memory usage stack heap mb 
handle higher traffic rates system resort packet pre sampling 
new packet sampling system avoid detailed measurement effects deferred technical report version 
validation measured system different random seeds different datasets verify behavior consistent 
tested different seeds random number generator create hash functions ddos attack 
stressed counter src ip flows maintained rms relative error seeds seeds 
dst ip table consistent 
results proto port tables similar ip tables 
details experiment available technical report version 
show results running system different minute samples different real traffic traces 
system demonstrates remarkable consistency error metrics oc dataset contains approximately twice traffic backbone dataset 
comparatively large quite acceptable rms relative errors flows fourth fifth intervals oc deviation system fact due unusual traffic event intervals oc flows intervals 

system produces real time summaries internet traffic 
main novelty system achieves robustness anomalous malicious traffic mixes isolation resource consumption modules com table entries puting different traffic summaries adapting parameters algorithms 
types summaries produced system widely network administrators monitoring workloads networks ports sending traffic gives information applications ip addresses sending receiving traffic gives information heavy users ip addresses flows reveals victims denial service attacks computers performing aggressive network scans evaluate algorithmic solutions problem identifying accurately measuring sources destinations flows 
propose novel solutions flow sample hold bloom filter tuple set counting specific advantages prior solutions 
particular flow sample hold improves accuracy traffic mixes packet sample hold inaccurate 
compared best flow counting algorithm bloom filter tuple set faster uses approximately half memory generally accurate 
summaries produced measurement system concise accurate measurement results current systems 
anomalous network behavior denial service attacks worms push resource consumption limits hardware handled system graceful degradation accuracy summaries 
system able maintain error rate summaries trace data lightly loaded oc gbps combined simulated denial service attack th memory traditional system 
mhz processor system handle oc speeds pre sampling packet headers 
traffic larger malicious pre sampling protects cpu drastically affecting accuracy summaries reporting byte counts packet counts 
evaluation system shows feasible build robust systems computing accurate internet traffic summaries real time 
particular combining appropriate identification flow counting algorithms adaptive control system able compute multiple useful traffic summaries affordable memory cpu budgets oc speeds 

ipmon packet trace analysis 
ipmon com php 
working group www ietf org html charters charter html 
bar yossef jayram kumar sivakumar trevisan 
counting distinct elements data stream 
proc 
th international workshop randomization approximation techniques computer science 
bloom 
space time trade offs hash coding allowable errors 
commun 
acm volume pages july 
carter wegman 
universal classes hash functions 
journal computer system sciences volume apr 
chaudhuri motwani narasayya 
random sampling histogram construction 
pages june 
cormode muthukrishnan 
hot tracking frequent items dynamically 
proceedings pods june 
cranor johnson shkapenyuk 
gigascope stream database network applications 
sigmod june 
crosby wallach 
denial service algorithmic complexity attacks 
usenix security 
usenix aug 
duffield lund thorup 
charging sampled network usage 
sigcomm internet measurement workshop nov 
duffield lund thorup 
estimating flow distributions sampled flow statistics 
sigcomm pages aug 
durand flajolet 
loglog counting large cardinalities 
esa sept 
estan keys moore varghese 
building better netflow 
sigcomm aug 
estan varghese 
new directions traffic measurement accounting 
sigcomm aug 
estan varghese fisk 
bitmap algorithms counting active flows high speed links 
internet measurement conference oct 
fang shivakumar garcia molina motwani ullman 
computing iceberg queries efficiently 
international conference large data bases pages aug 
feldmann greenberg lund reingold rexford true 
deriving traffic demands operational ip networks methodology experience 
sigcomm pages aug 
flajolet martin 
probabilistic counting algorithms data base applications 
journal computer system sciences oct 
gibbons matias 
new sampling summary statistics improving approximate query answers 
pages june 
intel 
chipset www intel com design 
intel 
chipset www intel com design 
keys moore estan 
robust system accurate real time summaries internet traffic technical report www caida org outreach papers tr 
keys moore koga claffy 
architecture coralreef internet traffic monitoring software suite 
pam passive active measurement workshop apr 
kumar xu wang li 
space code bloom filter efficient flow traffic measurement 
proc 
ieee infocom mar 
moore keys koga claffy 
coralreef software suite tool system network administrators 
usenix lisa san diego ca dec 
usenix 
cisco netflow www cisco com warp public tech netflow 
sampled netflow 
www cisco com cc td doc product software ios limit htm 
gc le chipset www com products html 
venkataraman song gibbons blum 
new streaming algorithms fast detection 
ndss feb 
waikato applied network dynamics group 
dag project dag cs waikato ac nz 

whang vander zanden taylor 
linear time probabilistic counting algorithm database applications 
acm transactions database systems 
appendix adapting psh sampling rate control memory usage adjusts sampling rate measurement interval actual memory usage 
approach vulnerable memory overflowing individual measurement intervals traffic mix changes suddenly 
memory overflows new entries created remainder measurement interval important sources traffic go unnoticed 
aim build robust adaptation mechanism achieves results intervals traffic gets suddenly worse achieve goal adjusting sampling rate measurement intervals 
describe algorithm adapting sampling rate measurement interval assuming single table say keyed source ip address single algorithm say psh creating entries 
discuss generalize multiple parallel sample hold algorithms multiple tables 
assuming system memory handle packet normal traffic exceeding memory limit interval sampling rate set 
means packet create new entry src ip table packet src ip exist table 
goal sure traffic mix changes stay available memory decreasing sampling rate 
furthermore want achieve goal minimal loss accuracy 
want reduce sampling rate necessary ensure exceed available memory 
way approaching problem divide measurement interval multiple smaller subintervals observed behavior earlier subintervals adjust sampling rates 
robust solution sudden spike malicious traffic available memory current subinterval ends 
defend problem making subintervals small vulnerable subintervals put aside big chunks table safety buffer 
additionally small subintervals sensitive random short bursts traffic cause adapt sampling rate 
address adaptation sampling rates dividing available memory smaller budgets 
number allocated entries reaches current budget look rate entries allocated decide need adjust sampling rate decrease sampling rate expect memory run measurement interval growth rate table rate adjustment 
traffic mix suddenly changes psh starts allocating entries quickly table exhaust budget quickly algorithm promptly reduce sam uses second measurement intervals minute intervals problem having incomplete data couple measurement intervals grave 
predict fill time slowdown slowdown endif slowdown endfor return estimating time takes fill memory times took fill halves budget 
pling rate 
choosing sizes budgets need balance competing considerations small algorithm small random spikes traffic large algorithm react slowly 
furthermore near interval want react promptly memory left unfriendly traffic consume faster 
algorithm solves problem budgets quarter remaining available memory budget quarter available memory quarter remaining memory total memory 
avoid small budgets measurement interval perform adaptation memory run slightly measurement interval 
adapt sampling rate pretend time memory longer memory left actual memory interval 
size budget smaller quarter remaining memory amount memory expect fill extension measurement interval 
full adaptation algorithm technical report version 
adaptation algorithm needs prediction rate table entries going fill current sampling rate 
prediction implemented predict fill time function 
prediction need exact adaptation efficient prediction close actual behavior predicting memory run lot sooner prompt adaptation algorithm decrease sampling rate unnecessarily reducing accuracy results predicting memory run consume memory prematurely forcing algorithm drastically reduce sampling rate 
increase sampling rate measurement interval want especially careful severely underestimate time take memory fill 
simplest way predicting memory run assume rate entries allocated current budget period continue 
shows number entries created sampling typical measurement interval 
clearly shows linear prediction far experimented fixed fractions half eighth quarter offer best balance responsiveness stability 
linear prediction assumes rate entries created rate created current budget underestimates time takes fill memory 
accounting fact takes progressively longer fill memory advance time gives better prediction 
reality rate entries created slows time progresses fewer fewer new source ip addresses traffic mix 
higher sampling rates memory usage curve closer straight line 
need simple predictor works cases 
predictor achieves measuring rate slowdown memory usage measure time takes second halves budget store times 
difference slowdown 
predict time takes algorithm consume eighth memory slowdown longer time previous eighth 
third eighth take slowdown fourth take slowdown total time remaining slowdown 
plots new prediction closer reality 
note prediction algorithm enforces slowdown nonnegative speedup 
second half budget quickly half due attack example slowdown zero base prediction linearly rate second half budget 
remember actual measurement system tables algorithms psh fsh operating table 
extend algorithm straightforward manner situation 
available entries divided equally tables overridden user configuration furthermore entries table divided equally algorithms 
algorithms sample packet causes creation new entry get credit half entry 
rate adaptation samplers tables proceeds independently achieving isolation measurement tasks 
