usenix association proceedings th symposium operating systems design implementation boston massachusetts usa december advanced computing systems association usenix association rights reserved information usenix association phone fax email office usenix org www www usenix org rights individual papers remain author author employer 
permission granted noncommercial reproduction educational research purposes 
copyright notice included reproduced 
usenix acknowledges trademarks 
pastiche making backup cheap easy cox christopher murray brian noble department electrical engineering computer science university michigan ann arbor mi umich edu mobility eecs umich edu backup cumbersome expensive 
individual users back data backup significant cost large organizations 
presents pastiche simple inexpensive backup system 
pastiche exploits excess disk capacity perform peer peer backup administrative costs 
node minimizes storage overhead selecting peers share significant amount data 
easy common installations find suitable peers peers high overlap identified hundreds bytes 
pastiche provides mechanisms confidentiality integrity detection failed malicious peers 
pastiche prototype suffers overhead modified andrew benchmark restore performance comparable cross machine copy 
backup cumbersome expensive 
personal machines backed rarely 
internet backup services exist costly 
example connected offers individual users backup gb covers applications operating system month 
machines organization backed centrally significant cost 
example computer support arm michigan college engineering provides backup service gb single machine month 
cost inconvenience backup unavoidable prohibitive 
small scale solutions require significant administrative efforts 
large scale solutions require aggregation substantial demand justify capital costs large centralized repository 
increasing recognition disks better serve needs near line archival storage 
purchasing cost disk subsystems caught tape disks provide better access restore time 
time conventional wisdom data expands fill storage space proving untrue 
douceur examination nearly machines finds file systems full average 
furthermore amount newly written data client day small fraction total file system 
systems take advantage low write traffic presence excess storage capacity including elephant 
pastiche uses excess disk capacity efficient effective administration free backup 
pastiche nodes form cooperative untrusted collection machines provide mutual backup services 
individual machines may come go pastiche node replicate archival data peer 
replicas placed nearby ease network overhead minimize restore time replica guard catastrophe 
effort part user modest additional disk space backups provided automatically 
pastiche primarily aimed user machines back repositories care 
pastiche afford keep duplicate copies data replica 
luckily data machine unique generated install time 
furthermore machines common data shared widely 
default installation office professional requires mb nearly ubiquitous different installations largely 
randomly grouping disparate file systems coalescing duplicate files produces significant savings 
pastiche identifies systems overlap increase savings 
pastiche builds developments accomplish goals 
pastry peer peer network provides scalable self administered routing node location 
content indexing provides flexible discovery redundant data similar files 
convergent encryption allows hosts encrypted representation common data sharing keys 
building blocks pastiche faces number challenges 
nodes discover backup buddies substantial overlap centralized directory 
nodes reuse disk state backup 
nodes restore files entire machine requiring administrative intervention 
nodes detect buddies 
pastiche computes small file system content potential backup buddies inspect approximate overlap 
pastiche able limit size advantage fact arbitrary small pieces larger logical entities unique stand 
allows machines common installations find suitable buddies little effort 
machines uncommon installations may need pastry overlay new routing metric coverage rate 
sharing supported sub file granularity pastiche provides new file system 
stores data host backup state units sharing compromising performance common case workloads 
archive state described skeleton tree metadata 
root tree recovered pastry overlay name machine restored 
entire file systems restored easily single file 
address problem storing data untrusted nodes pastiche uses probabilistic mechanism detect missing backup state periodically querying buddies stored data 
pastiche able keep overhead queries small bounding chance loss 
examination file system data shows abstracts bytes effectively discriminate candidate buddies 
simulations show pastiche nodes common installations easily find overlap 
file system induces overhead modified andrew benchmark despite unoptimized layout 
analytical results show pastiche node detect corrupted backup state high probability checking chunks 
enabling technologies pastiche depends enabling technologies 
pastry scalable self organizing peer peer routing object location infrastructure 
second content indexing technique finds common data different files 
third convergent encryption allows sharing compromising privacy 
remainder section describes focusing features essential pastiche 
peer peer routing pastiche centralized authority manage backup sites 
authority single point control limiting scalability increasing expense 
pastiche relies pastry scalable self organizing routing object location infrastructure peer peer applications 
pastry node named nodeid set nodeid expected uniformly distributed nodeid space 
pastry nodes way measuring proximity 
typically metric captures notion network costs 
node maintains sets state leaf set neighborhood set routing table 
leaf set consists nodes closest numerically smaller nodeids closest larger ones 
neighborhood set nodes contains closest proximity metric 
pastry group deprecated neighborhood set 
show section neighborhood set critical buddy discovery nodes uncommon installations 
routing table supports prefix routing 
row hexadecimal digit nodeid space 
row contains list nodes nodeids differ current node digit entry possible digit value 
second row holds list nodes digit current node second digit differs 
route arbitrary destination packet forwarded node matching prefix digit longer current node 
node known packet forwarded node identical prefix numerically closer destination nodeid space 
process continues destination node appears leaf set delivered directly 
expected number routing steps log number nodes 
positions routing table satisfied node 
choice pastry records closest node proximity metric 
result nodes routing table sharing shorter prefix tend nearby nodes 
particular node far 
pastry self organizing nodes come go 
maintain pastry locality properties new node join nearby proximity metric 
pastry provides seed discovery protocol finds node arbitrary starting point 
pastiche uses separate pastry overlay networks uses buddy discovery 
node identified backup set traffic routed directly ip 
pastiche adds mechanisms pastry 
technique called lighthouse sweep guarantees distinct pastry nodes queried buddy discovery 
second distance metric file system contents find buddies machines rare installations 
content indexing minimize storage overhead pastiche find redundant data versions files files system files distinct machines 
rsync tivoli employ schemes finding common subsets versions presumably file 
techniques easily capture general sharing 
challenge find sharing structure seemingly unrelated files knowing underlying structure 
content indexing accomplishes identifying boundary regions called anchors rabin fingerprints 
fingerprint computed overlapping byte substring file 
low order bits fingerprint match predetermined value offset marked anchor 
anchors divide files chunks 
anchors purely content driven editing operations change chunks touch change offsets 
lbfs pastiche names chunk sha hash contents 
probability different chunks hash value lower probability hardware errors 
customary assume chunks hash value fact chunk pastiche adopts custom 
pastiche chunks form basis disk file structures easily share data local host remote client 
sharing confidentiality chosen backup buddy pastiche node data backup 
pastiche guarantee confidentiality integrity participants data 
clients free choose cryptographic keys chunks identical content represented differently precluding sharing 
farsite file system solves problem convergent encryption 
convergent encryption file encrypted key derived file contents 
farsite encrypts file key key known client key stored file 
file shared clients gains new encrypted keys client shares single encrypted file 
pastiche applies convergent encryption disk chunks 
pastiche node backs new chunk stored backup buddy buddy discover contents shipment 
buddy chunk knows node stores data 
pastiche allows small information leak exchange increased storage efficiency 
design pastiche data stored disk chunks 
chunk boundaries determined content indexing encrypted convergent encryption 
chunks carry owner lists name set nodes interest chunk 
chunks may stored machine disk machine backup client 
data chunks immutable chunk persists node holds 
pastiche ensures rightful owners capable removing possibly deleting chunk 
newly written file closed scheduled chunking 
chunk hashed result called chunk handle hc 
handle generate symmetric encryption key kc chunk 
handle hashed determine public ic chunk 
chunk stored disk encrypted kc named ic 
process illustrated 
writing chunk disk pastiche checks see exists 
local host added owner list necessary local count incremented 
chunk encrypted message authentication code appended chunk written disk count local owner 
chunking writing disk deferred avoid needless overhead files short lifetimes cost slightly weaker persistence guarantees 
list describes node current file system called signature 
data chunks immutable 
file overwritten set constituent chunks may change 
chunks longer part file local owner count decremented count drops zero local owner removed 
owner list empty chunk storage reclaimed 
file deletion handled similarly 
meta data file contains list handles chunks comprising file plus usual contents ownership permissions creation modification times handles list derive decryption key constituent chunk 
meta data chunks encrypted protect handle values cryptographic keys 
differs slightly farsite convergent encryption 
cleartext chunk sha keygen sha encrypted chunk depicts chunks stored named 
cleartext chunk hashed producing handle 
handle key generation hashed produce 
chunk stored encrypted key named 
naming storing chunks farsite stores keys data encrypting derived key key private writing host 
pastiche stores handles keys meta data blocks 
data meta data chunked mutable 
pastiche chunk meta data typically small shared 
meta data mutable avoid cascading writes 
write file changes constituent 
meta data immutable pastiche create new meta data chunk new name update 
new name added enclosing directory change file system root 
hc kc ic file meta data computed creation time re 
meta data object corresponding file system root treated specially hc generated host specific 
section explains plus machine name required restore machine scratch 
chunk part node backup state includes nodeid owner list 
remote hosts supply public key backup storage requests 
requests remove signed corresponding secret key requests rejected 
prevents third party deletions prevent buddy dropping chunks accord 
storing files directly chunks simplifies number pastiche tasks imposes modest performance costs 
simplifies implementation chunk sharing convergent encryption backup restore 
pastiche keep persistent index consistent disk files 
index consulted backup restore complicates garbage collection chunks retired snapshot 
furthermore convergent encryption requires chunk encrypted separately complicating contiguous layout 
alternative detect sharing file level corresponding increase storage costs backup 
abstracts finding redundancy long lived data machine written overwritten 
observations file type volume ownership suggest amount data written small 
words signature node change time 
data shipped backup site initial backup freshly installed machine expensive 
ideal backup buddy newly installed pastiche node holds superset new machine data machines complete coverage preferred 
simple way find nodes ship full signature new node candidate buddies report degree overlap 
unfortunately signatures large bytes chunk 
expected chunk size function anchors selected 
implementation size kb signatures expected cost mb gb stored data 
cost paid acceptable 
node buddy set change time buddies unreliable degrees overlap change 
send full signature pastiche nodes send small random subset signatures called 
motivated observation data disk belongs files part larger logical entity 
example linux hacker kernel source tree largely source tree working version 
machine holding small number random chunks common source tree hold 
preliminary experiments show tens bytes distinguish matches bad ones 
size similar reported border individual web objects 
overlays finding set buddies node buddies substantial overlap reduce storage overhead 
addition buddies nearby reduce global network load improve restore performance 
buddy located provide geographic diversity 
rule thumb pastiche node maintains buddies 
pastiche uses pastry overlays facilitate buddy discovery 
standard pastry overlay organized network proximity 
organized file system overlap 
pastiche node joins pastry overlay organized network distance 
nodeid hash machine fully qualified domain name 
joined new node picks random nodeid routes 
attr block size type ctime time stamp handle handle depicts meta data chunk stored disk 
chunk stored log file states entry log represents state file update 
entries comprised attribute block time stamp list constituent chunk handles 
meta data chunk layout discovery request 
discovery request contains new node 
node encountered route computes coverage fraction chunks stored locally returns 
initial probe generate sufficient candidate set probe process repeated 
subsequent probes generated varying digit original nodeid 
pastry uses prefix routing probe generate sets candidates disjoint examined 
call rotating probe lighthouse sweep 
nodes common installations find sufficient candidate set easily 
nodes rare installations difficulty 
nodes find adequate set lighthouse sweep join second overlay called coverage rate overlay 
overlay uses file system overlap network hops distance metric 
new node chooses backup buddies pastry neighbor set set nodes encountered join best coverage available 
coverage rate distance metric interesting implications pastry 
network distance coverage rate obey triangle inequality 
network distance coverage rate symmetric holds files converse probably true 
means individual node build routing state correct perspective 
likewise seeding algorithm supplied new node compute coverage correct point view 
possible malicious node report coverage 
reports avoid selected buddy 
reports attract unsuspecting clients discard backup time time time time time time depicts small skeleton 
chunk stored log entry log chunks 
top chunk begins empty adds 
bottom chunk adds data chunk appends removes chunk 
chunk skeleton state 
unfortunately possible matter computes coverage rates 
honest node random list match 
likewise malicious node cache report abstracts sent commonly appearing hoping false match 
backup protocol pastiche node full control back 
discrete backup event viewed single snapshot 
nodes subscribe calendar cycle landmark scheme schedule 
machine responsible archival plan keeps meta data skeleton retained snapshot 
file part local machine current file system part archived snapshots corresponding meta data entry stored local machine 
skeleton retained snapshots stored collection persistent file logs shown figures 
skeleton representing machine current file system state plus retained snapshots stored machine backup buddies 
state necessary establish new snapshot consists things chunks added backup store list chunks removed meta data objects skeleton change result 
call add set delete set meta data list 
snapshot process begins shipping host public key 
key associated new chunks validate requests delete replace 
snapshot node forwards elements add set 
chunks stored buddy buddy fetches chunks node 
node sends delete list 
snapshot host adds delete list belong snapshot client wishes retain 
delete list signed signature checked ensure matches public key associated chunks scheduled deletion 
note deletion effected immediately 
deferred snapshot process 
snapshot node sends updated metadata chunks 
may overwrite old meta data chunks signed 
state transferred host requests commit checkpoint 
responding buddy ensure new chunks changed meta data objects deleted stored persistently 
complete buddy respond apply new snapshot performing appropriate deletions 
performance snapshots crucial asynchronous 
exception marking copy write done synchronously 
afs volume clone operation inexpensive 
load induced buddy backup protocol regulated resource containers progress mechanisms 
load quantified section 
snapshot process restartable 
expensive phase shipping new data chunks progress presence failures new chunks stored arrive 
new snapshot applied faithful buddy complete copy metadata skeleton plus data chunks skeleton names 
restoration pastiche node retains archive skeleton performing partial restores straightforward 
node identifies chunks correspond restore request obtains nearest buddy 
recovering entire machine requires way bootstrap skeleton 
pastiche node keeps copy root meta data object member network distance leaf set 
machine recover disaster rejoins distance overlay nodeid computed host name 
obtains root node leaves decrypts key generated host 
root block contains set buddies effect replicated node recover state 
detecting failure buddy expected retain backup snapshots required 
faced sudden disk space crisis buddy free reclaim space 
buddy may fail connected intermittently leaving ability serve restore requests doubt 
malicious buddy may claim store chunks doing 
pastiche employs probabilistic mechanism detect situations 
new snapshot pastiche node asks buddies random subset chunks node archive 
requesting modest number chunks clients bound probability compromised backup state goes undetected 
savvy users traditional backup schemes employ technique confirmation correctness 
buddy produce data claims hold client removes buddy list initiates search replacement 
buddy responded significant period time client likewise removes 
unfortunately request provides instantaneous assurance malicious node drop chunks requested 
increasing frequency requests provide increased assurance increasing size single request 
technique assumes malicious party occupy substantial fraction nodeid space produce collusion single host backup buddies 
defending sybil attacks practice requires centralized agency certify identities 
certification essential pastiche nodes increase chances selected buddies falsely reporting coverage rates 
pastiche leverages spot check mechanism detect snapshots belonging machines 
buddy knows corresponding host fully trust 
buddy expects probed periodically 
buddy hear corresponding host exceptionally long period assume host re installed 
decision conservatively lest long lived failure mistaken voluntary removal 
lack trust places limits pastiche applicability intended primarily user systems backup currently difficult 
back repositories centrally managed adding backup services comparatively simple 
pastiche extended services choosing backup buddies administered trusted machine provided service expected workload shows temporal locality 
locality performance poor 
preventing greed greedy host aggressively consume space storage hosts retiring 
challenging problem faced pastiche 
pastiche needs distributed quota enforcement mechanism node occupy space contributes 
considered solutions problem completely satisfactory 
solution places nodes equivalence classes resources consume 
node monitors storage costs imposed backup clients compares costs usage 
space intensive ejected search suitable partner 
unfortunately mechanism circumvented sybil attack 
second approach force node solve cryptographic puzzles proportion amount storage occupies 
forging identities defense spreading snapshots usual number buddies 
dislike solution reasons 
adds needless expense backup pastiche goals 
second trades storage storage space 
third nodes equivalent processing power difficult provision solution properly 
third approach account space form electronic currency 
sufficient offline protocol amount double spending tolerable long detected eventually 
currency accounting requires backup goods atomic exchange currency backup state atomic transaction 
adding complicates pastiche substantially 
alternative design settling pastiche current approach considered alternative appears natural fit peer peer substrate 
having small list backup buddies holding complete backup alternative stores chunk pastry nodes nodeids numerically closest chunk identifier 
call alternative finegrained approach 
fine grained approach advantages pastiche 
ensures backup copies chunk exist network 
second pastry takes care detecting failed unresponsive hosts individual nodes need keep track 
fine grained approach disadvantages 
loss network proximity replicas increasing network load backup latency restoration 
restoration costs avoided caching pastry route taken backup chunks increases global disk overhead 
second disadvantage difficulty dealing malicious nodes 
harder client probe malicious nodes set nodes containing client state order number chunks 
pastiche trades disk space reduce network costs give clients tools ensure backups safely stored 
implementation pastiche prototype consists main components file system backup daemon 
written implemented primarily user space simplicity 
user space component 
small kernel portion implements vnode interface integrating linux 
pastiche uses xfs device open source afs implementation kernel portion 
data stored individual chunks underlying file system 
performance reasons pastiche maintains cache contiguous decrypted copies files called container files 
prototype support machine backup implemented booting kernel 
xfs device sees container files acts mediator device container files 
application requests file container retrieves meta data chunk file uses form contiguous container file 
returns inode container file device subsequent operations applied container 
container file cache managed lru replacement maximum size 
notified close 
corresponding file dirty scheduled chunking 
chunking deferred seconds avoid needless overhead short lived files 
implemented convergent encryption openssl beta cryptographic library 
chunk encrypted bit key aes stream cipher 
container files restore parity logical disk proximity storing chunks individually eliminates 
storing chunks individually induces storage overhead 
storing chunk separately pastiche files yield internal fragmentation stored contiguously 
recall content indexing generates chunks exam lower bits rabin fingerprint bits match target value offset marked chunk boundary 
average expect lose half disk block chunk 
set giving expected chunk size kb expected fragmentation overhead 
meta data chunks stored log updates file 
time file re chunked list constituent chunks appended log 
deletion represented terminal log entry 
appends logs removes chunk 
backup daemon called written uses rpc remote procedure call package communication 
acts backup server client 
server manages remote requests storage restoration client supervises selection buddies snapshots 
additionally cleans meta data logs reaps deleted chunks 
communicates file locking disk chunks 
simple efficient need hold locks guarantee consistent snapshot 
root meta data chunk read reachable chunks guaranteed remain reachable deleted 
meta data chunks may tainted additional log entries 
entries detected timestamps backup restore rendering inclusion snapshot harmless 
provide utilities allow users manage file system take system snapshot immediately chunk files queue immediately restores file subtree previous state 
utility communicates unix domain sockets 
evaluation evaluating prototype set answer questions performance file system 
operations perform perform badly 
long backups restores take 
large fingerprints 
lighthouse sweep able find buddies 
coverage rate overlay yield suitable backup buddies 
costs detect malicious nodes reasonable 
experiments run machines mhz pentium iii xeon processor mb memory rpm scsi ultra wide disk ms seek time ms rotational latency mb peak throughput 
ab phase ext fs mkdir cp cat total presents results modified andrew benchmark 
times reported seconds standard deviations parentheses 
andrew benchmark task ext fs wide create wide mkdir deep mkdir bulk xfer presents results file creation throughput benchmarks 
times reported seconds standard deviations parentheses 
performance micro benchmarks overhead induced 
answer compare performance underlying native file system ext fs 
measure overhead modified andrew benchmark 
benchmark identical original form uses source tree 
source tree mb size compiled tree occupies mb 
ran trials results shown 
step bound experience slight overhead 
due part cost computing rabin fingerprints copied tree extra cost creating deleting files 
copied data scheduled chunked written seconds step chunking begins 
total overhead reasonable copy phase expensive takes longer 
believe overhead due excess meta data management limits peak throughput 
confirm hypothesis performed micro benchmarks isolate operations involved copying source tree writing data creating files 
examine performance creating files directories ran different experiments wide create wide mkdir deep mkdir 
wide create new files created directory 
wide mkdir new directories created directory task time cp backup rm restore nfs cp presents results backup restore experiment 
times reported seconds standard deviations parentheses 
backup restore deep mkdir new directories recursively inside 
ran trials results 
wide create wide mkdir ran slower ext fs respectively deep mkdir ran slower 
poor performance due meta data chunk container file maintenance 
creates file update create files new meta data chunk new container file parent meta data chunk 
deep mkdir experiment shows number entries parent directory significant 
way directory entries laid meta data chunks container files 
cases directory entries stored linear array 
current implementation rewrites entire list container file chunk new entry added 
deep mkdir entry list creating file faster 
interesting note wide mkdir somewhat faster wide create 
reason related kernel xfs device handles file directory creation 
regular file created xfs device extra upcall close newly created file call directory created 
verify throughput responsible phase modified andrew benchmark ran xfer experiment 
experiment new file created mb data written file closed 
ran trials results 
fs performed meaning throughput statistically identical 
backing recovering file system determine performance backup restore utilities applied file system consisting openssl beta source tree 
mb tree files directories stored pastiche chunks 
trials consisted phases copying source tree file system sending backup buddy removing local source tree restoring source tree backup buddy 
pastiche backup restore performs comparably time copy source tree nfs 
results 
noted demand resources buddy experiences carrying backup restore bursty 
trials maximum mb memory averaged disk transfers sec maximum transfers sec averaged idle cpu minimum 
finding buddies turn attention buddy discovery process 
questions answer 
large discriminate buddy candidates bad ones 
second effective lighthouse sweep discovering buddies 
third effective coverage rate overlay discovering buddies 
answer question took signatures seventeen machines michigan 
machines run windows linux solaris various flavors bsd 
took signatures freshly installed machines 
ran windows office professional installation service packs applied 
machine held roughly chunks second linux machine running debian unstable release configured conventional workstation development document processing tools 
machine held approximately chunks 
chose machine worst case 
comparison machines debian runs unstable distribution 
distribution changes quickly machine updated infrequently 
computed actual coverage machines full signatures 
estimate impact smaller abstracts coverage estimates took uniform random samples signature rates samples rate 
results windows machine plotted 
axis gives sampling rate axis shows coverage rate 
sample shows exact coverage estimate smaller sample 
group bars represents coverage estimate seventeen hosts 
group hosts sorted actual coverage rate experiment smaller expected chunk size kb pastiche larger chunks may require slightly larger sampling rates 
coverage estimate coverage estimate soar garcia signature sampling rate windows office speak sheep saturn signature sampling rate debian developer varying size highest lowest 
top matches identified legend 
win machine running office relevant service packs security updates applied 
estimates surprisingly independent sample size lowest rate produces abstracts 
soar estimate changes appreciably 
coverage rate comparable garcia choosing favor soar consequence 
shows results linux machine top matches identified legend 
match rates lower machines distributions substantial matches 
windows host coverage estimates change materially sizes go 
interestingly windows machine coverage rate debian machine 
release debian installed vmware virtual machine vmware disk image stored regular file windows 
ordinarily files expected buddies installation popularity expected number buddies form implicit chunk boundaries content indexing 
viewed windows host file boundaries disappear 
despite content indexing able find substantial overlap 
small abstracts effective delivered host provide coverage 
conducted simulation determine effectively lighthouse sweeps find useful buddies 
simulation uses pastry simulation visualization tool 
simulation populated graph pastiche nodes drawn distribution types 
nodes type types comprise nodes types comprise type comprises types eleven represent population 
simulated different pastry networks conditions 
network randomly selected nodes type performed lighthouse sweep node counting number hosts identical type sweep 
results shown 
bar gives average number matches sweep category popularity error bars show standard deviation 
expected common nodes representation higher find adequate number buddies distance overlay 
lower popularity need join coverage rate overlay 
built pastry simulator determine effectiveness network 
experiments involved nodes 
node assigned species genera orders 
nodes order share content nodes genus nodes species 
nodes species serve backup buddies 
results simulations 
axis give size neighborhood set percent nodes neighborhood set size coverage rate simulation results axis shows percent nodes number buddies 
ran series trials varying size neighborhood set 
neighborhood set size able find buddy routing table able find 
results show nodes able find buddies coverage rate overlay 
shows important role neighborhood set plays locating buddies 
increasing neighborhood set increases percent nodes find buddy percent nodes find increases 
determining query size backup buddies drop chunks error maliciously 
chunk dropped replicas backup state said corrupted 
node certain state corrupted requesting chunks clearly expensive 
pastiche nodes query just chunks assured probability corrupted state detected exists 
assume replicas collude agree specific chunk drop 
replicas drops chunks rate pastiche node set probability drops causing corruption going undetected equal zero chance corruption zero problem solved trivially 
hand query chunk guaranteed detect corruption 
intermediate values require queries chunks 
analysis proceeds parts 
compute pc probability corruption 
second compute pu probability dropped chunks go undetected 
conditionally independent query size mb backup size gb growth query size product expresses event probability wish bound replica drops chunk probability chance chunk dropped replicas chance exists chunks chance exist replica chance exist replicas chance corruption pc 
suppose node asks buddy single chunk 
chance buddy supply node asks chunks simultaneously chance buddy respond successfully chance dropped chunks go undetected pu 
want bound product minimize probability undiscovered corruption solving get 
log 
take discrete values feasible compute maximum possible values resulting queries grow slowly respect backup size shown 
shows total backup size axis computed query size axis assuming average chunk size kb replicas 
query sizes computed buddies values high degrees assurance query costs modest 
related backup critical surprisingly small amount literature topic 
focuses centralized backup large installations chervenak provides survey number different backup systems 
current commercial systems veritas ibm tivoli connected remote backup service focus large centrally managed repositories 
projects suggested peer topeer routing object storage systems substrate backup including chord freenet pastry 
file systems built past cfs provide protection machine failure 
protect human error provide ability retrieve prior versions files replaced 
oceanstore provide benefits decision versions retire rests utility clients 
pstore cooperative backup system built top chord stores individual objects number nodes storing entire set objects number nodes 
exploit inter host sharing address problem hosts falsely claiming store data 
presents cooperative backup scheme requests random blocks partners assumes partners drop archived state 
number systems exploit duplicate data files machines minimize costs archival storage 
single instance store detects coalesces duplicate files venti divides files blocks hashes find duplicate data 
approaches take advantage small edits move data file content indexing 
sophisticated techniques detecting changes exist run pairs files assumed overlap 
broder provides mathematical foundation detecting similarity inclusion sketches similar pastiche abstracts 
sketches bytes able find similarities single documents web 
pastiche extends result find similarities entire disks 
exploit redundancy turn erasure codes stripe data replicas 
codes allow low overhead replication tolerant failure replicas employed myriad oceanstore 
main shortcoming compared simpler scheme require participation node restore 
afs plan expose snapshot primitive variety purposes including backup 
typically snapshots stage data archival media disk 
leverages snapshot mechanism provide finegrained remote disk mirroring low overhead 
backup tedious expensive 
embarrassingly authors workstations backed 
user data stored distributed file system backed regularly 
pastiche enables automatic backup administrative costs requiring excess disk capacity set cooperating peers 
pastiche matches nodes significant data common excess capacity modest 
peers selected peer peer overlay networks organized network distance degree data held common 
self organizing nature overlays combined mechanisms detect failed malicious peers obviates need administrative intervention 
evaluation pastiche prototype demonstrates service penalize file system performance unduly 
simulations confirm effectiveness node discovery analysis shows detecting malicious hosts requires modest resources 
pastiche promises lower barriers backup data protected just judged worthy expense burden current schemes 
authors wish mark assistance analysis section 
jason flinn jim gray anonymous reviewers provided helpful comments 
supported part intel novell national science foundation ccr defense advanced projects agency darpa air force materiel command usaf agreement number 
government authorized reproduce distribute reprints governmental purposes notwithstanding copyright annotation thereon 
views contained authors interpreted necessarily representing official policies endorsements expressed implied intel novell national science foundation defense advanced research projects agency darpa air force research laboratory government 
ajtai burns fagin long stockmeyer 
compactly encoding unstructured inputs differential compression 
journal association computing machinery appear 
banga druschel mogul 
resource containers new facility resource management server systems 
proceedings rd symposium operating systems design implementation pages new orleans la february 
barr 
pstore secure peer peer backup system 
unpublished report mit laboratory computer science december 
blaze ioannidis keromytis 
offline trusted hardware 
proceedings fifth annual conference financial cryptography islands bwi february 
bolosky goebel douceur 
single instance storage windows 
proceedings th usenix windows systems symposium pages seattle wa august 
bolosky douceur ely theimer 
feasibility serverless distributed file system deployed existing set desktop pcs 
proceedings international conference measurement modeling computer systems pages santa clara ca june 
broder glassman manasse zweig 
syntactic clustering web 
proceedings th international world wide web conference pages santa clara ca april 
broder 
resemblance containment documents 
proceedings 
compression complexity sequences pages italy june 
published 
castro druschel ganesh rowstron wallach 
security structured peer peer overlay networks 
proceedings th symposium operating systems design implementation boston ma december 
castro druschel hu rowstron 
exploiting network proximity peer peer overlay networks 
submitted publication 
chang ji leung maccormick perl zhang 
myriad cost effective disaster tolerance 
proceedings usenix conference file storage technologies pages monterey ca january 
chaum 
blind signatures untraceable payments 
advances cryptology proceedings crypto pages august 
chervenak 
protecting file systems survey backup techniques 
proceedings joint nasa ieee mass storage conference march 
clarke miller hong sandberg wiley 
protecting fee expression online freenet 
ieee internet computing 
connected 
re missing preventing data loss pc management 
white ma 
dabek kaashoek karger morris stoica 
wide area cooperative storage cfs 
proceedings th acm symposium operating systems principles pages banff canada october 

aes proposal rijndael 
advanced encryption standard submission nd version march 
douceur 
sybil attack 
st international workshop peer peer systems cambridge ma march 
douceur bolosky 
large scale study file system contents 
proceedings international conference measurement modeling computer systems pages atlanta ga may 
douceur bolosky 
progress regulation low importance processes 
proceedings th acm symposium operating systems principles pages kiawah island resort sc december 
lillibridge burrows zwaenepoel 
cooperative backup system 
usenix conference file storage technologies monterey ca january 
progress report 
hitz lau 
file system design nfs file server appliance 
proceedings usenix winter technical conference pages san francisco ca january 
howard kazar menees nichols satyanarayanan sidebotham west 
scale performance distributed file system 
acm transactions computer systems february 
juels 
client puzzles cryptographic countermeasure connection depletion attacks 
proceedings network distributed system security symposium pages san diego ca february 
kaashoek engler ganger hunt mazieres grimm jannotti mackenzie 
application performance flexibility exokernel systems 
proceedings th acm symposium operating systems principles pages saint malo france october 
kleiman 
vnodes architecture multiple file system types sun unix 
usenix association summer conference proceedings pages atlanta ga june 
manber 
finding similar files large file system 
proceedings usenix winter conference pages san francisco ca january 

burt backup recovery tool 
proceedings lisa pages seattle wa november 
microsoft 

www research microsoft com pastry download htm 
muthitacharoen chen mazi res 
network file system 
proceedings th acm symposium operating systems principles pages banff october 
national institute standards technology 
computer data authentication 
fips publication may 
national institute standards technology 
secure hash standard 
fips publication april 
network appliance 
release 
computer news page march 
patterson manley hitz kleiman 
file system asynchronous mirroring disaster recovery 
proceedings usenix conference file storage technologies pages monterey ca january 
peterson 
error correcting codes 
mit press 
preston 
gigabit ethernet backup terabytes 
proceedings lisa pages boston ma december 
quinlan 
cache worm file system 
software practice experience december 
quinlan dorward 
venti new approach archival storage 
proceedings usenix conference file storage technologies pages monterey ca january 
rabin 
fingerprinting random polynomials 
technical report tr center research computing technology harvard university 
rhea wells eaton geels zhao weatherspoon kubiatowicz 
maintenance free global data storage 
ieee internet computing september 
rowstron druschel 
pastry scalable distributed object location routing large scale peerto peer systems 
ifip acm international conference distributed systems platforms pages heidelberg germany november 
rowstron druschel 
storage management caching past large scale persistent peer peer storage utility 
proceedings th acm symposium operating systems principles pages banff canada october 
feeley hutchinson veitch 
deciding forget elephant file system 
proceedings th acm symposium operating systems principles pages kiawah island resort sc december 
satyanarayanan 
rpc user guide manual 
school computer science carnegie mellon university october 
satyanarayanan 
empirical study wide area distributed file system 
acm transactions computer systems may 
stoica morris karger kaashoek balakrishnan 
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm conference pages san diego ca august 
strunk goodson soules ganger 
self securing storage protecting data compromised systems 
proceedings th symposium operating systems design implementation pages san diego ca october 
tridgell 
efficient algorithms sorting synchronization 
phd thesis national university 
tygar gupta shmueli widom 
atomicity versus anonymity distributed transactions electronic commerce 
proceedings th annual international conference large data bases pages new york ny august 
vogels 
file system usage windows nt 
proceedings th acm symposium operating systems principles pages kiawah island resort sc december 
danielsson 
free afs client 
proceedings usenix freenix track new orleans la june 
