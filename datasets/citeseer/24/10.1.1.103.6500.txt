myths realities performance impact garbage collection stephen blackburn department computer science australian national university canberra act australia steve blackburn cs anu edu au explores quantifies garbage collection behavior heap collectors generational counterparts copying semi space mark sweep counting canonical algorithms essentially collection algorithms derived 
efficient implementations mmtk java memory management toolkit ibm jikes rvm share common mechanisms provide clean experimental platform 
instrumentation separates collector program behavior performance counters measure timing memory behavior architectures 
experimental design reveals key algorithmic features match program characteristics explain direct indirect costs garbage collection function heap size spec jvm benchmarks 
example find contiguous allocation copying collectors attains significant locality benefits free list allocators 
reduced collection costs generational algorithms locality benefit contiguous allocation motivates copying nursery newly allocated objects 
benefits dominate overheads generational collectors compared non generational collection myth garbage collection garbage collection performance sensitive mature space collection algorithm benchmarks 
locality pointer mutation characteristics program occasionally prefer copying mark sweep 
study unique breadth garbage collection algorithms depth analysis 
categories subject descriptors programming languages processors memory management garbage collection general terms design performance algorithms keywords java mark sweep semi space counting generational supported arc dp nsf itr ccr nsf ccr nsf eia darpa ibm 
opinions findings expressed authors necessarily reflect sponsors 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigmetrics performance june new york ny usa 
copyright acm 
perry cheng ibm watson research center box yorktown heights ny usa ibm com kathryn mckinley department computer sciences university texas austin austin tx usa mckinley cs utexas edu 
programmers increasingly choosing object oriented languages java automatic memory management garbage collection software engineering benefits 
researchers studied garbage collection long time detailed performance studies exist 
previous study compares effects garbage collection algorithms instruction throughput locality light modern processor technology trends explain garbage collection algorithms programs combine yield performance 
studies detail canonical garbage collection algorithms semi space mark sweep counting generational counterparts 
collectors encompass key mechanisms policies essentially garbage collectors composed 
findings application algorithms 
conduct study java memory management toolkit mmtk ibm jikes rvm 
collectors efficient share common mechanisms policies provide clean meaningful experimental platform 
results wide range heap sizes spec jvm benchmarks reveal inherent space time trade offs collector algorithms 
fair comparisons experiment fixes heap size triggers collection program exhausts available memory 
architectures athlon pentium powerpc find trends 
experiment divides total program performance mutator application code collection phases 
mutator phase includes memory management activity allocation sequence generational collectors write barrier 
hardware performance counters measure tlb misses collector mutator phases 
experiments reveal direct cost garbage collection indirect effects mutator performance locality 
set experiments confirm widely held unexamined hypothesis locality benefits contiguous allocation improves locality mutator 
heap collectors small heaps space efficient free list mark sweep collector performs best collection frequency dominates locality benefit contiguous allocation 
heap size increases mutator locality advantage contiguous allocation copying collection outweighs space efficiency mark sweep 
contiguous allocation provides fewer misses levels cache hierarchy tlb 
results counter myth collection frequency order effect determines total program performance 
experiments reveal locality benefits young objects motivates contiguous allocation generational collectors 
generational collectors divide newly allocated nursery objects mature objects survive collections collect nursery independently frequently mature space 
rate death young objects high 
order collect nursery independently generational collectors write barrier records pointer nursery mature objects 
nursery collection collector assumes referents pointers live avoid scanning entire mature generation 
implement write barrier compiler generates sequence code pointer store runtime records pointers mature space nursery 
write barrier induces direct mutator overhead programs heap versus generational collection 
experiments show generational collectors provide better performance heap collectors virtually circumstances 
significantly reduce collection time contiguous nursery allocation positive impact locality 
carefully measure impact write barrier mutator find mutator cost usually low high cost outweighed improvements collection time 
comparing generational collectors performance differences typically small 
factors contribute result 
allocation order provides spatial locality young objects program briefly uses discards 
second majority reads mature objects caching usually achieves temporal locality objects regardless mature space policy 
object demographics preference 
instance generational collection copying mature space works best mature space dispersed frequent 
mark sweep mature space performs best significantly small heaps space efficiency reduces collector invocations 
section compares study previous collector performance analysis studies consider variety collectors apples apples setting include similar depth analysis vary architecture 
overview collectors number key implementation details experimental setting 
results section studies base algorithms separating allocation collection costs possible compares heap algorithms generational counterparts examines cost generational write barrier 
examine impact nursery size performance myth nursery size tied cache size 
examine mature space behaviors fixed size nursery hold mature space load constant 
perform experiment benchmarks architectures select representative results brevity clarity 

related knowledge studies quantitatively compare uniprocessor garbage collection algorithms studies evaluate various copying generational collectors 
results copying collectors similar theirs compare free list mark sweep counting collectors explore memory system consequences 
attanasio evaluate parallel collectors specjbb focusing effect parallelism throughput heap size running processors 
concluded mark sweep generational mark sweep fixed size nursery mb mb equal best collectors 
data shows generational superior heap collectors especially variable size nursery 
studies explore heap size effects performance show garbage collectors sensitive heap size particular tight heaps 
diwan hicks measure detailed specific mechanism costs architecture influences consider variety collection algorithms 
researchers evaluated range memory allocators programs include copying collectors programs may store pointers arbitrarily 
java performance analysis disabled garbage collection introduces unnecessary memory fragmentation hold constant 
kim hsu measure similar details simulation ibm jdk java jit heap mark sweep algorithm occasional compaction 
stands thorough evaluation variety different garbage collection algorithms compare affect performance execution measurements performance counters 
comprehensiveness approach reveals new insights space efficient collection algorithms distinct locality patterns young old objects suggests mechanisms matching algorithms object demographics reveals performance trade offs strategy 
evaluate reuse modularity portability performance mmtk separate publication 
explore generational collectors measure explain performance differences collectors 
demonstrate mmtk combines modularity reuse high performance rely finding 
example collectors share functionality root processing copying tracing allocation collection mechanisms exact implementation mmtk 
addition allocation collector mechanisms perform hand tuned monolithic counterparts written java experiments offer true policy comparisons efficient setting 

background section presents garbage collection terminology algorithms features compares explores 
presents algorithms enumerates key implementation details 
thorough treatment algorithms see jones lins blackburn additional implementation details 
mmtk policy pairs allocation mechanism collection mechanism 
heap collectors single policy 
generational collectors divide heap age cohorts policies 
generational incremental algorithms counting write barrier remembers pointers 
pointer store compiler inserts write barrier code 
execution time code conditionally records pointers depending collector policy 
literature execution time consists mutator program periodic garbage collection 
memory management activities object allocation write barrier mix mutator 
collection run concurrently mutation uses separate collection phase 
mmtk implements standard allocation collection mechanisms 
contiguous allocator appends new objects contiguous space incrementing bump pointer size new object 
free list allocator organizes memory size segregated free lists 
free list unique size class composed blocks contiguous memory 
allocates object free cell smallest size class accommodates object 
tracing collector identifies live objects computing transitive closure roots stacks registers class variables statics remembered pointers 
reclaims space copying live data space freeing untraced objects 
counting collector counts number incoming object reclaims objects 
collectors modern collectors build mechanisms 
examines heap collectors generational counterpart 
generational collectors copying nursery newly allocated objects 
semispace semi space algorithm uses equal sized copy spaces 
contiguously allocates reserves space copying worst case objects survive 
full traces copies live objects space swaps 
collection time proportional number survivors 
throughput performance suffers reserves half space copying repeatedly copies objects survive long time responsiveness suffers collects entire heap time 
implementation details copying tracing implements transitive closure follows 
enqueues locations root repeatedly takes locations queue 
referent object copies object leaves forwarding address old object enqueues copied object gray object queue adjusts point copied object 
previously copied referent object adjusts forwarding address 
locations queue empty collector scans object gray object queue 
scanning places locations pointer fields objects locations queue 
gray object queue empty processes locations queue 
terminates queues empty 
experiments depth order experiments show performs better standard breadth order 
mmtk supports orderings 
semispace write barrier 
marksweep mark sweep uses free list allocator tracing collector 
heap full triggers collection 
collection traces marks live objects bit maps lazily finds free slots allocation 
tracing proportional number live objects reclamation incremental proportional allocation 
tracing marksweep exactly semispace copying object marks bit live object bit map 
marksweep heap collector maximum pause time poor performance suffers repeatedly tracing objects survive collections 
implementation details free list uses segregated fits range size classes similar lea allocator 
mmtk uses size classes attain worst case internal fragmentation objects bytes 
size classes bytes apart bytes apart bytes apart bytes apart bytes apart bytes apart 
small word aligned objects get exact fit practice vast majority objects 
objects kb larger get block see section 
marksweep write barrier 
collector keeps blocks size class circular list ordered allocation time 
allocates free element block 
finding right fit slower allocation 
free list stores bit vector block block 
block sizes vary bytes bytes organization may source conflict misses leave investigation 
refcount deferred counting collector uses freelist allocator 
mutation write barrier ignores stores roots logs mutated objects 
periodically updates counts root referents generates count increments decrements logged objects 
deletes objects zero count recursively applies decrements 
uses trial deletion detect cycles 
collection time proportional number dead objects mutator load significantly higher collectors logs mutated heap object 
implementation details refcount uses object logging coalescing 
refcount records objects time program modifies buffers decrements referent objects 
collection time generates increments root modified object referents coalescing intermediate updates introduces temporary increments deferred objects roots deletes objects zero count 
count goes zero puts object back free list setting bit decrements referents 
collection includes decrement temporary increments previous collection 
gencopy classic copying generational collector allocates young nursery space 
write barrier records pointers mature nursery objects 
collects nursery full promotes survivors mature semi space 
mature space exhausted collects entire heap 
program follows weak generational hypothesis young objects die quickly old objects survive higher rate young gencopy attains better performance semispace 
gencopy improves semispace case repeatedly collects nursery yields lot free space compacts survivors improve mutator locality incurs collection cost mature objects infrequently 
better average pause times semispace nursery typically smaller entire heap 
genms hybrid generational collector uses copying nursery marksweep policy mature generation 
allocates bump pointer nursery fills triggers nursery collection 
write barrier nursery collection nursery allocation policies mechanisms identical gen copy 
test exhausted heap accommodate space copying entire nursery full survivors marksweep space 
genms better marksweep programs follow weak generational hypothesis 
comparison gen copy genms memory efficiently gencopy reserves half heap copying space 
mark sweep genms fragment free space objects distributed size classes 
infrequent collections contribute spreading consecutively allocated promoted objects memory 
sources fragmentation reduce locality 
mark compact collectors reduce fragmentation need additional passes live dead objects 
genrc hybrid generational collector uses copying nursery refcount mature generation 
ignores mutations nursery objects marking logged logs addresses mutated mature objects 
nursery fills promotes nursery survivors counting space 
part promotion nursery objects generates counts referents 
nursery collection genrc computes counts deletes dead objects refcount 
genrc ignores frequent mutations nursery objects performs better refcount 
collection time proportional nursery size number dead objects refcount space 
small nursery collection triggers pause times low 
refcount genrc subject free list fragmentation issues marksweep genms 
genrc collects mature space collection maintain smaller memory footprint 
implementation details section adds implementation details shared mechanisms including nursery size policies inlining write barriers allocation counting header large object space boot image 
nursery size policies default generational collectors implement variable nursery initial size half heap half reserved copying 
nursery collection reduces nursery size survivors 
available space nursery small kb default triggers mature space collection 
mmtk provides bounded nursery takes command line parameter initial nursery size collects nursery full nursery bound mature space accommodate nursery survivors 
shrinks variable nursery policy lower bound 
fixed nursery reduces size nursery triggers heap collection sooner bounded nursery size 
bounded nursery triggers collections variable nursery uses space efficiently variable nursery large pause time suffers 
write barrier allocation inlining generational collectors mmtk inlines write barrier fast path filters stores nursery objects record pointer updates ignores pointer stores 
slow path appropriate entries remembered set 
write barrier refcount unconditional fully inlined forces slow path object remembering mechanism line minimize code bloat compiler overhead 
semispace marksweep write barrier 
mmtk inlines fast path allocation sequence 
copying generational allocators inlined sequence consists incrementing bump pointer testing limit pointer 
test fails failure rate typically allocation sequence calls line routine acquire block memory may trigger collection 
marksweep refcount free list allocators inline allocation sequence consists establishing size class allocation non array types compiler statically evaluates size removing free cell appropriate free list cell available 
available free cell allocation path calls line move block blocks size class acquire new block 
header large objects boot image mmtk word byte header object contains pointer tib type information block located immortal space see hash bits lock bits gc bits 
word header marksweep collectors possible implemented 
bacon word header yields average improvement execution 
refcount mature space genrc additional word bytes object headers accommodate count 
mmtk allocates objects kb larger separately large object space los integral number pages 
genera tional collectors allocate large objects directly space 
los uses treadmill algorithm 
records pointer object list 
heap collections collectors refcount genrc trace live large objects placing list 
reclaim objects left original list 
refcount genrc count large objects collection 
mmtk priori reserve space los allocates demand 
boot image contains various objects precompiled classes necessary booting jikes rvm including compiler classloader garbage collector essential elements virtual machine part java java design 
mmtk puts objects immortal space collectors collect 
refcount genrc trace boot image objects perform heap collection 
refcount genrc assume pointers boot image live avoid priori assigning counts boot time 

methodology section describes jikes rvm experimental platform key benchmark characteristics 
ibm jikes rvm mmtk jikes rvm version cvs patches support performance counters pseudo adaptive compilation 
jikes rvm high performance vm written java aggressive optimizing compiler 
configurations possible including key libraries optimizing compiler turn assertion checking fast build time configuration 
adaptive compiler uses sampling select methods optimize leading high performance lack determinism 
statistical techniques show including adaptive compiler short running programs skews results measure virtual machine 
addition adaptive compiler variations result changes allocation behavior running time run runs different heap sizes 
example sampling triggers compilation different methods compilation different write barriers collector part runtime system program induces different mutator behavior collector load 
goal focus application garbage collection interactions pseudo adaptive approach deterministically mimics adaptive compilation 
profile benchmark times select best collecting log methods adaptive compiler chooses optimize 
log deterministic compilation advice performance runs 
performance runs run iterations benchmark 
iteration compiler optimizes methods advice file demand base compiles 
second iteration perform heap garbage collection flush heap compiler objects 
measure second iteration uses optimized code hot methods heap includes application objects 
perform experiment times report fastest time 
methodology avoids variations due adaptive compilation 
experimental platform perform experiments architectures athlon pentium power pc 
athlon results performs best relatively simpler memory hierarchy easier analyze 
pre release cvs timestamp utc 
huang narendran jointly implemented pseudo adaptive compilation mechanism 
source field target object alloc alloc gc nur read focus read focus mb min srv nur mat imm nur mat nur mat imm nur mat jess jack raytrace mtrt javac compress pseudojbb db mpegaudio ghz amd athlon xp 
byte cache line size 
data instruction caches kb way set associative 
unified exclusive kb way set associative cache entry victim buffer caches 
holds replacement victims contain copies data cached 
data cache evicts line goes victim buffer turn evicts lru line victim buffer 
athlon gb dual channel mhz ddr ram configured mb motherboard mhz front side bus 
machine marketed amd comparable ghz pentium 
ghz pentium uses 
byte cache line size kb way set associative data cache ops instruction trace cache kb unified way set associative chip cache 
machine gb dual channel mhz ddr ram configured mb intel motherboard mhz front side bus 
apple power mac ibm powerpc 
byte cache line size kb direct mapped instruction cache kb way set associative data cache kb unified way set associative chip cache 
machine mb mhz ddr ram apple motherboard mhz front side bus 
platforms run configuration debian linux kernel 
run experiments standalone mode non essential daemons services including network interface shut 
instrument mmtk jikes rvm amd intel performance counters measure cycles retired instructions cache misses cache misses tlb misses mutator collector collector algorithm heap size features vary 
hardware limitations performance counter requires separate execution 
version intel hardware performance counters linux associated kernel patch libraries 
time writing unavailable powerpc 
benchmarks table shows key characteristics benchmarks 
spec jvm benchmarks pseudojbb variant spec jbb executes fixed number transactions perform comparisons fixed garbage collection load 
alloc column table indicates total number megabytes allocated 
prior reports adaptive compiler activity shows allocation higher ratios live data allocation 
show adaptive compiler program behaviors methodology exposes variations due program vm 
alloc min column quantifies garbage collection load ratio total allocation minimum heap size genms executes 
heap size minimum gc semispace shows percentage time table benchmark characteristics semispace spends performing gc 
nur srv quantifies generational behavior mb fixed size nursery percentage allocated data collector copies nursery 
remaining columns indicate access patterns object accesses 
instrument pointer read count dereferenced field columns referent object columns 
table includes percentage reads nursery nur mature mat immortal imm spaces 
focus presents accesses nursery mature space divided number bytes allocated nursery mature space respectively 
example jess nursery time dereferenced object nursery 
focus accesses mature space times greater accesses nursery 
higher number reflects higher temporal locality 
jess promotes data mature space jess field reads objects survive nursery 
group programs table 
jess jack raytrace mtrt exhibit low nursery survival high ratios total allocation minimum live size 
javac pseudojbb db higher nursery survival relatively high heap turnover 
programs high nursery survival exercise collection compress mpegaudio 
compress allocates large objects requires little garbage collection 
mpegaudio allocates mb generational collectors collect 
groups programs better tests memory management influences policies focus 
results section presents representative benchmarks discuss detail 
benchmarks follow trends noted 
complete results included technical report 

results section examines collector performance influence mutator total performance athlon 
explain occasionally small changes heap sizes cause variations collection time 
compare heap generational collectors validating uniform performance benefits weak generational hypothesis 
tease apart influences allocation collection mechanisms 
contiguous allocation yields better mutator locality free list allocation space efficient free list reduces total collector load 
programs cache measurements reveal spatial locality objects allocated close time key nursery objects important mature objects 
fixed nursery isolates influence mature space collection policy showing mutator performance usually agnostic mature space policies notable exceptions need copying achieve locality 
mature space benefits frequent collection genms total time improves 
varying nursery size reveals frequent gc small nursery degrade collector perfor mance nursery sizes cache size perform best 
show trends hold athlon ppc architectures 
subsequent figures plot total time garbage collection gc time mutator time cache statistics different benchmarks function heap size 
right axis expresses time seconds left normalizes fastest time 
heap size shown multiple smallest heap size particular application executes genms bottom axis mega bytes mb top 
collector sensitivity heap size shows general trend point increases heap size tend decrease frequency garbage collection total time see 
heap size independent trial 
experiments variation runs heap size 
small changes heap size produce chaotic behavior differences total gc time heap sizes minimum genms javac 
reason small change heap size triggers collections different points changes objects collector promotes 
instance consider program builds large relatively short lived pointer data structure 
small heap generational collection point happens just prior program builds data structure slightly larger heap happens middle 
second case collector promotes data structure dies shortly detect death heap collection 
increased heap occupancy triggers nursery collection sooner 
exact timing collection cascading positive negative effects explains variations nearby heap sizes 
evaluating generational behavior section compares heap collectors generational counterparts explores generational write barrier cost 
shows jess db javac generational collectors perform better heap variants 
result holds benchmarks low gc load programs compress benefit small heaps 
generational collectors reduce gc time jess order magnitude javac nursery objects survive gencopy improves gc time semispace factor genms improves marksweep 
generational collectors reduce gc time reducing cost collection examining nursery 
counting number collections shows reductions come dramatically fewer collections 
collection costs heap size dependent impact gc time total time greatest small modestly sized heaps 
examining mutator performance reveals heap size systematically influence mutator time 
application unchanged heap size larger heap sizes tend spread objects result counter intuitive 
overhead jess jack raytrace mtrt javac compress pseudojbb db mpegaudio geometric mean table write barrier mutator overhead mb nursery mutator time strongly correlated gc algorithm semispace usually performs best 
semispace benefits write barrier faster allocation marksweep 
generational collectors benefit contiguous allocation 
gencopy semispace perform javac db mutator performance gencopy slower semispace jess 
show difference due write barrier 
write barrier friend foe 
examine cost write barrier new collector heap organization write barrier promotion policies gencopy traces collect heap collection 
collects heap mature space full 
traces entire heap establishes liveness nursery objects reachability write barrier required correctness 
garbage collection overhead collector substantial recommend yields experimental platform include exclude write barrier holding factors constant heap organization promotion policy 
table shows overhead standard mmtk generational write barrier mutator performance mb nursery moderate heap minimum athlon platform 
show percentage slowdown mutator write barrier relative mutator performance barrier 
overhead low average ppc 
jess suffers substantial mutator slowdown 
table indicates high mortality rate concentration accesses objects survive cause heavy write barrier traffic jess 
previous section shows massive reduction collection costs mutator overhead setting 
benchmarks show low overheads 
example mpegaudio collects objects large space write barrier test adds remembered sets 
multi issue architecture completely hides cost unused issue slots 
write barrier potential expensive overhead usually low advantages seen collection time far outweigh cost 
combination mutator performance outstanding gc performance clear total time results 
javac low infant mortality db low gc load generational collectors perform better heap collectors 
jess advantage generational collectors dramatic 
data supports weak generational hypothesis indicates true generational collectors offer benefits 
allocation free list versus contiguous essential allocator choice free list contiguous turn dictates choice collection algorithm 
free list allocation expensive contiguous allocation permits incremental freeing obviates need copy reserve 
contiguous allocations provide spatial locality objects allocated close time free list allocation may spread objects 
reveal allocation time trade offs examine impact mutator 
refcount marksweep free list allocator analysis focuses marksweep genms simpler refcount genrc 
mutator costs heap collectors contiguous free list allocators directly impact mutator performance consequence mutator allocation cost collection policies impose 
impact mutator locality effects 
normalized time normalized gc time normalized mutator time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess total time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess gc time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size time sec gc time sec mutator time sec normalized time normalized gc time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db total time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db gc time time sec gc time sec normalized time normalized gc time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size javac total time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size javac gc time jess mutator time db mutator time javac mutator time total mutator gc performance collectors measure upper bound time program spends contiguous allocation pushing allocation sequence 
cost typically ranges total time 
micro benchmark establish relative costs mechanisms 
benchmark allocates objects size tight loop 
contiguous allocation faster free list allocation allocating mb mb respectively 
reported slower times older architecture 
allocation time small difference mechanisms reduces total time excludes allocation sequence major source variation 
examines mutator time memory hierarchy performance jess db pseudojbb representative behaviors plotting mutator time misses misses tlb misses function heap size log scale 
consider semispace marksweep 
semispace mutator performance improvements range marksweep compress mpegaudio free list allocation 
limit analysis indicates direct effect allocator typically difference 
application code identical second order effects dominate 
jess db pseudojbb show strong consistent correlation cache memory mu normalized mutator time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size mutator time sec normalized mutator time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size performance semispace improves mark sweep 
contiguous allocation semispace offers locality sources allocation order copying compaction 
freelist allocation marksweep degrades program locality 
mutator benefit semispace marksweep relatively insensitive heap size suggesting benefit allocation locality mature object compaction 
exception tlb performance jess copying collectors show sharp reduction tlb misses smaller heap sizes presumably due collection induced locality 
misses appear dominate reduction tlb misses translate reduction mutator time 
mutator costs generational collectors perform experiment examine closely semispace locality due allocation order copying compaction mature objects 
hold load mature space constant fixed size nursery variant generational collectors 
young objects allocation order 
young objects collected frequency mature space collection policies differ 
shows geometric mean mutator performance benchmarks 
nursery size fixed gencopy genms similar mutator performance 
locality mature space objects dominant effect mutator performance 
sec time sec gc time sec mutator time sec mutator time sec log mutator misses millions log mutator misses millions log mutator tlb misses millions log semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator time semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator tlb mutator time sec log mutator misses millions log mutator misses millions log mutator tlb misses millions log semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db mutator time semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db mutator semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db mutator semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size db mutator tlb mutator time sec log mutator misses millions log mutator misses millions log mutator tlb misses millions log semispace marksweep gencopy genms genrc heap size relative minimum heap size pseudojbb mutator time semispace marksweep gencopy genms genrc heap size relative minimum heap size pseudojbb mutator semispace marksweep gencopy genms genrc heap size relative minimum heap size pseudojbb mutator semispace marksweep gencopy genms genrc heap size relative minimum heap size pseudojbb mutator tlb mutator time tlb misses collectors collectors log scale 
tion discusses detail variable size nursery attains space advantage combined genms reduces number nursery collections direct benefit 
indirect benefit slightly improved locality nursery objects stay allocation order nursery longer 
suggests mature object compaction free list little programs 
reveals exceptions rule db pseudojbb 
striking counterpoint db generational collectors little impact mutator time 
copying nursery genms provides advantage marksweep 
gencopy slightly degrades mutator locality compared pace due write barrier see table 
section shows db dominated mature space accesses nursery locality immaterial db 
pseudojbb copying nursery benefits genms compared marksweep gencopy performs significantly better 
suggests pseudojbb mature space access patterns locality sensitive 
access pattern statistics section confirm result 
mature space accessed heavily pseudojbb accesses relatively unfocused 
heap generational results indicate free list allocation significantly degrades locality contiguous allocation achieves locality young objects allocation mutator time sec log semispace marksweep gencopy fixed mb genms fixed mb heap size relative minimum heap size mutator time heap fixed size nursery collectors geometric mean benchmarks order 
furthermore copying nursery locality penalty mature space free list db pseudojbb mature space reads play large role 
collection 
choice allocation mechanism governs choice collection mechanisms 
examine time space overheads collection algorithms influence mutator locality 
consider frequently collect 
show results consistent architectures discuss choose garbage collection 
garbage collection costs contiguous allocation dictates copying collection requires copy reserve 
semispace gencopy genms collector performance graphs reflect copying space overhead leads collections pure marksweep semispace typically collects times marksweep heap size 
example gc time semispace typically worse marksweep 
measured tracing rates semispace marksweep micro benchmark close mb sec mb sec means frequency collection source overhead 
addition genms variable nursery reduces number nursery collections gencopy space efficient 
order effect fewer collections reduced collection time 
second order effect fewer cache line displacements collector invocations 
stability mutator cache performance function heap size face dramatic differences numbers collections hypothesis 
trading collection cost mutator locality total performance course function mutator collector performance 
contiguous allocation offers significant mutator advantage copy reserve requirement results substantial overhead 
small heap sizes collection time typically total performance overwhelms mutator locality differences marksweep outperforms semispace 
large heaps mutator time dominates semispace outperforms marksweep 
illustrates crossovers total performance marksweep semispace javac jess 
sections establish locality advantage contiguous allocation greatest young objects 
results indicate copying nursery combined space efficient marksweep mature space offers combination locality benefits reduced collection costs 
mature space locality dominates db gencopy perform best 
tracing counting 
free list collector trace live objects roots count 
continuously tracking number marksweep mutator semispace mutator min ratio min ratio gcs time gcs time jess jack raytrace mtrt javac compress pseudojbb db mpegaudio geometric mean table impact large heap size mutator time object expensive aggressive optimizations mmtk implementation uses 
result evident refcount performs dramatically worse marksweep jess javac 
refcount performs compress application atypical 
discussed sections compelling evidence generational policy copying nursery free list mature space 
distinctly different demographics young old objects motivate hybrid generational counting policy 
shows genrc performs similar generational collectors javac unusually large amount cyclic data structures 
performance genrc sensitive frequency cycle detection tune experiments 
genrc holds potential locality space advantage genms promptly reclaims dead mature space objects tightly pack free list 
genrc performs counting nursery collection genms infrequently performs heap collections 
promise borne may reflection immaturity genrc implementation fundamentals algorithm 

examine limits collecting examine collect nursery 
heap collected memory monotonically consumed spatial locality older objects gradually degrade neighboring objects die 
assuming approximately uniform death rate time fragmentation exponential function age older objects fragmented allocated objects suffering fragmentation 
examine effect table compares mutator time benchmark contiguous free list allocation modest heap minimum heap large avoid triggering collection 
benchmarks mb adequate 
jess follows hypothesis collecting degrades performance 
jess high heap turn accesses mature space suffer fragmentation degrades mutator performance heap collected 
benchmarks mutator performance heap modest heap 
result little surprising light inevitable degradation locality older objects 
section showed spatial locality mature objects dominant factor benchmarks 
db achieves better performance collection attains locality contiguous allocation low gc load 
blackburn memory constrained machine collecting caused severe degradations db due paging 
table mutator locality results indicate programs slight majority accesses mature objects mutator time sec log mutator misses millions log gc misses millions log gencopy genms nursery size kb log mutator time gencopy genms nursery size kb log mutator misses gencopy genms nursery size kb log gc time sec log mutator misses millions log gc misses millions log gencopy genms nursery size kb log gc time gencopy genms nursery size kb log mutator misses gencopy genms nursery size kb log time sec log mutator tlb misses millions log gencopy genms nursery size kb log total time gencopy genms nursery size kb log tlb mutator misses nursery size kb log gc misses gc misses tlb gc misses performance effect nursery size kb mb log scale temporal locality accesses large number young objects poor temporal locality typically briefly discarded 
compression mature space objects important source locality programs 
expect server applications large memory usage foot prints follow jess results 
sizing nursery performance advantages generational collection examine influence nursery size 
shows performance genms gencopy wide range bounded nursery sizes kb mb running large heap mb 
note axis nursery size heap size figures 
shows small improvement larger mutator performance due fewer tlb misses 
difference gc time dominates smaller demand frequent collection substantially higher load 
measured fixed overhead collection invocation collection scanned kb roots 
fixed costs significant nursery small kb 
garbage collection cost tapers mb mb fixed collection costs insignificant 
results myth nursery size matched cache size kb architectures 
gc tlb misses millions log gencopy genms architecture influences compares geometric mean benchmarks collectors athlon ppc 
axis heap size axis time 
fastest clock speed followed athlon ppc 
intel believe ordering means perform best 
athlon performs better 
generational collectors ppc close 
athlon advantage comes substantially fewer cache misses compare figures 
due athlon exclusive cache architecture substantially larger higher associativity simply effective cache advantage dominates clock speed 
collectors follow trends discussed architectures 
generational collectors perform best architectures due reductions collection time locality contiguous nursery allocation 
difference pronounced ppc athlon suggests reductions influence collection time faster processors 
space advantage marksweep semispace locality advantage semispace marksweep show different crossover points architecture 
faster clock speed closer cross point moves minimum heap size cross semispace improves marksweep athlon ppc 
trend normalized time mutator misses millions log heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator time sec normalized time heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size athlon total time architectures mutator misses millions log semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator time sec normalized time mutator tlb misses millions log heap size mb semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size ppc semispace marksweep refcount gencopy genms genrc heap size relative minimum heap size jess mutator tlb mutator tlb misses jess log scale 
compare figures 
suggests processors locality advantages contiguous allocation pronounced 
garbage collection idea 
software engineering benefits garbage collection explicit memory management widely accepted performance trade languages designed garbage collection unexplored 
section shows clear mutator performance advantage contiguous free list allocation architectural comparison shows architectural trends advantage pronounced 
traditional explicit memory management malloc free tightly coupled free list allocator fact mmtk free list allocator implementation lea allocator default allocator standard libraries 
standard explicit memory management unable exploit locality advantages contiguous allocation 
possible garbage collection presents performance advantage explicit memory management current architectures 
striking example seen figures total time genms matches mutator time marksweep 
unfortunately scope 
alternative reclaiming memory 

study examines implications key policy choices memory management collection time space mutator locality mutator performance total performance 
key observations emerge 
programs follow generational hypothesis contiguous allocation copying nursery offers locality benefits indicate weak generational collectors collectors choice 
corollary accesses go mature objects performance relies temporal locality nursery allocation order provides spa tial locality young objects die quickly 
show cost generational write barrier usually low 
secondly choice mature space collector dictated space efficiency prefer marksweep include rate death mature objects access mutation rate mature space 
rates high copying mature space attain better mutator locality overcomes higher collection time penalty 
results guide users right collector program offer insights memory management designers collectors tune long running applications 

alpern implementing jalape java 
acm conference object oriented programming systems languages applications pages denver nov 
alpern jalape virtual machine 
ibm systems journal february 
appel 
simple generational garbage collection fast allocation 
software practice experience 
arnold fink grove hind sweeney 
adaptive optimization jalape jvm 
acm conference object oriented programming systems languages applications pages minneapolis mn october 
attanasio bacon cocchi smith 
comparative evaluation parallel garbage collectors 
languages compilers parallel computing lecture notes computer science 
springer verlag 
bacon fink grove 
space time efficient implementations java object model 
proceedings european conference object oriented programming ecoop pages 
acm press june 
bacon rajan 
concurrent cycle collection time sec counted systems 
knudsen editor proc 
th ecoop volume lecture notes computer science pages 
springer verlag 
baker 
treadmill real time garbage collection motion sickness 
acm sigplan notices 
berger mckinley blumofe wilson 
hoard scalable memory allocator multithreaded applications 
acm conference architectural support programming languages operating systems cambridge ma nov 
berger zorn mckinley 
composing high performance memory allocators 
acm sigplan conference programming languages design implementation pages salt lake city ut june 
berger zorn mckinley 
reconsidering custom memory allocation 
acm conference object oriented programming systems languages applications pages seattle wa nov 
blackburn cheng mckinley 
oil water 
high performance garbage collection java 
icse scotland uk may 
blackburn jones mckinley moss 
beltway getting garbage collection 
proc 
sigplan conference pldi pages berlin germany june 
blackburn mckinley 

putting write barriers place 
acm international symposium memory management pages berlin germany june 
blackburn mckinley 
counting fast garbage collection long wait 
acm conference object oriented programming systems languages applications pages anaheim ca oct 

boehm 
space efficient conservative garbage collection 
acm sigplan conference programming languages design implementation pages 
li pham 
controlling garbage collection heap growth reduce execution time java applications 
acm conference object oriented programming systems languages applications pages tampa fl 
cheney 
non recursive list compacting algorithm 
communications acm nov 
cohen nicolau 
comparison compacting algorithms garbage collection 
acm transactions programming languages systems oct 
detlefs zorn 
memory allocation costs large programs 
software practice experience june 
deutsch bobrow 
efficient incremental automatic garbage collector 
communications acm september 
lzle 
study allocation behavior specjvm java benchmarks 
proceedings european conference object oriented programming pages june 
dijkstra lamport martin scholten 
fly garbage collection exercise cooperation 
communications acm september 
diwan tarditi moss 
memory subsystem performance programs copying garbage collection 
conference record acm symposium principles programming languages pages portland jan 
georges 
java programs interact virtual machines microarchitectural level 
acm conference object oriented programming systems languages applications pages anaheim ca oct 
fitzgerald tarditi 
case profile directed selection garbage collectors 
acm international symposium memory management pages minneapolis mn oct 
hicks moore nettles 
measured cost copying garbage collection mechanisms 
acm international conference functional programming pages 
hosking hudson 
remembered sets play cards oct 
position oopsla workshop memory management garbage collection 
jones lins 
garbage collection algorithms automatic dynamic memory management 
wiley july 
jouppi 
improving direct mapped cache performance addition small fully associative cache prefetch buffers 
proceedings th international symposium computer architecture pages seattle wa june 
kim hsu 
memory system behavior java programs methodology analysis 
acm sigmetrics conference measurement modeling computer systems pages santa clara ca june 
lea 
memory allocator 
gee cs edu dl html malloc html 
levanoni petrank 
fly counting garbage collector java 
acm conference object oriented programming systems languages applications pages tampa fl oct 
lieberman hewitt 
real time garbage collector lifetimes objects 
communications acm 
pettersson 
linux intel performance counters 
user uu se linux 
shuf gupta singh 
characterizing memory behavior java workloads structured view opportunities optimizations 
acm sigmetrics conference measurement modeling computer systems pages cambridge ma june 
standard performance evaluation 
specjvm documentation release edition march 
standard performance evaluation 
specjbb java business benchmark documentation release edition 
hertz blackburn mckinley moss 
older garbage collection practice evaluation java virtual machine 
memory system performance pages june 
tarditi diwan 
measuring cost storage management 
lisp symbolic computation dec 
ungar 
generation scavenging non disruptive high performance storage reclamation algorithm 
acm sigsoft sigplan software engineering symposium practical software development environments pages april 
zorn 
measured cost conservative garbage collection 
software practice experience 
