ieee acm transactions networking vol 
december protocol design scalable reliable group rekeying brian zhang student member ieee simon lam fellow ieee dong young lee richard yang member ieee design specification protocol scalable reliable group rekeying performance evaluation results 
protocol key trees secure groups periodic batch rekeying 
rekey interval key server sends rekey message users consisting encrypted new keys encryptions short carried sequence packets 
scheme identifying keys encryptions users key assignment algorithm ensures encryptions needed user packet 
protocol provides reliable delivery new keys users eventually 
attempts deliver new keys users high probability rekey interval 
rekey message protocol runs steps multicast step followed unicast step 
proactive forward error correction fec multicast reduce delivery latency 
experiments show small fec block size reduce encoding time server increasing server bandwidth overhead 
early transition unicast multicast rounds reduces worst case delivery latency user bandwidth requirement 
key server adaptively adjusts proactivity factor past feedback information experiments show number nacks multicast round effectively controlled target number 
protocol design strive minimize processing bandwidth requirements key server users 
index terms adaptive fec group key management proactive fec reliable multicast secure multicast 
emerging internet applications pay view distribution digital media restricted teleconferences multiparty games virtual private networks benefit secure group communications model 
model members group share symmetric key called group key known group users key server 
group key encrypting data traffic group members restricting access resources intended group members 
group key distributed group key management system changes group key time time called group rekeying 
manuscript received september revised august approved ieee acm transactions networking editor paul 
supported part nsf ani nsa university research program mda 
early version appeared proceedings spie conference scalability traffic control ip networks denver august 
zhang lam 
lee department computer sciences university texas austin tx usa mail cs utexas edu lam cs utexas edu cs utexas edu 
yang department computer science yale university new haven ct usa mail cs yale edu 
digital object identifier ieee desirable group key changes new user joined new user able decrypt past group communications existing user departed departed user able access group communications 
group key management system functional components registration key management rekey transport 
components implemented key server 
improve registration scalability preferable trusted registrars offload user registration key server 
user wants join group user registration component mutually authenticate protocol ssl 
authenticated accepted group new user receives symmetric key called user individual key shares key server 
authenticated users send join leave requests key management component validates requests checking encrypted individual keys 
key management component generates rekey messages sent rekey transport component delivery users group 
build scalable group key management system important improve efficiency key management rekey transport components 
consider key management component primary focus prior :10.1.1.16.7732
follow key tree approach uses hierarchy keys facilitate group rekeying reducing processing time complexity leave request group size key tree degree 
rekeying join leave request incur large server processing overhead 
propose reduce processing overhead periodic rekeying key server processes join leave requests rekey interval batch sends just rekey message rekey interval users :10.1.1.16.7732
batch rekeying reduces number computationally expensive signing operations 
reduces substantially bandwidth requirements key server users 
consider rekey transport component 
reliable delivery rekey messages attention prior 
prototype system keystone designed implemented basic protocol uses proactive forward error correction fec improve reliability multicast rekey transport 
investigated performance issues rekey transport observed reliable multicast protocols proposed studied years zhang protocol design scalable reliable group rekeying rekey transport differs conventional reliable multicast problems number ways :10.1.1.16.7732:10.1.1.121.1027
particular rekey transport requirements 
reliability requirement 
required user receive encrypted new keys matter large group size 
requirement arises key server uses keys rekey interval encrypt new keys rekey interval 
user receive entire rekey message needs small subset new keys 
soft real time requirement 
required delivery new keys users finished high probability start rekey interval 
requirement arises user needs buffer encrypted data keys arrival encrypting keys limit buffer size 
scalability requirement 
processing bandwidth requirements key server user increase function group size low rate single server able support large group 
objective detail rekey transport protocol performance 
particular contributions 
new marking algorithm batch rekeying 
second key identification scheme key assignment algorithm block id estimation algorithm evaluated 
third show fairly small fec block size reduce encoding time server increasing server bandwidth overhead 
adaptive algorithm adjust proactivity factor see table definition proposed evaluated 
algorithm effective controlling number nacks reducing delivery latency 
adaptive algorithm refinements 
server protocol rekey message consists phases generating sequence packets containing encrypted keys called enc packets generating packets containing fec redundant information called parity packets multicast enc parity packets transition multicast unicast 
achieve reliability protocol runs steps multicast step followed unicast step 
multicast step typically lasts just rounds users receive new keys user needs specific packet guaranteed key assignment algorithm proactive fec 
subsequently user recover new keys multicast step keys sent user unicast 
user needs small number new keys users remaining unicast step protocol achieves reliability small bandwidth overhead 
meet soft real time requirement proactive fec multicast step reduce delivery latency 
increase system reliability group size consider multiple servers topic scope 
table notation furthermore early transition multicast unicast reduces worst case delivery latency server need wait maximum round trip time rtt users sending unicast step 
scalable design ideas 
reduce key server processing requirement partition rekey message blocks reduce size block reduce key server fec encoding time 
reduce user processing requirement key assignment algorithm assigns encrypted new keys user needs packet 
user high probability receive specific packet 
result vast majority users need recover specific packets fec decoding 
reduce key server bandwidth requirement protocol uses multicast send new keys users initially 
reduce user bandwidth requirement unicast user recover new keys multicast step 
way small number users high loss environments cause protocol perform multicast users 
balance organized follows 
section ii briefly review ideas key tree periodic batch rekeying 
section iii server user protocols 
section iv show construct rekey message 
key identification scheme key assignment algorithm 
block partitioning block id estimation evaluated section section vi discuss adaptively adjust proactivity factor achieve low delivery latency small bandwidth overhead 
section vii discuss unicast 
section viii 
ii 
background review section ideas key tree periodic batch rekeying new marking algorithm :10.1.1.16.7732
algorithm update key tree generate workload rekey transport 
key tree key tree rooted tree group key root 
key tree contains types nodes nodes containing users individual keys nodes containing group key auxiliary keys 
user individual key contained node keys contained nodes path ieee acm transactions networking vol 
december fig 

example key tree 
node root 
consider group users 
example key tree shown fig 

group user keys path root key individual key key group key shared users auxiliary key shared suppose leaves group 
key server need change keys knows change change distribute new keys remaining users group oriented rekeying strategy key server constructs rekey message traversing key tree bottom denotes key encrypted key referred encryption 
receiving rekey message user extracts encryptions needs 
example needs words user need receive encryptions rekey message 
periodic batch rekeying rekeying join leave request expensive 
periodic batch rekeying key server collects join leave requests rekey interval 
rekey interval key server runs marking algorithm update key tree construct rekey subtree 
marking algorithm appendix different previous papers :10.1.1.16.7732
new algorithm facilitates key identification see section iv 
marking algorithm key server modifies key tree satisfy leave join requests 
nodes departed users removed replaced nodes newly joined users 
key server split nodes rightmost node highest level root level lowest accommodate extra joins see fig 

modifying key tree key server changes key node node path changed node removed newly joined node root 
key server constructs rekey subtree 
rekey subtree consists nodes keys updated key tree direct children updated nodes edges connecting updated nodes direct children 
rekey subtree key server generate encryptions 
particular edge rekey subtree key server uses key child node encrypt key parent node 
fig 

basic protocol key server 
iii 
protocol overview section give overview rekey transport protocol 
informal specification key server protocol shown fig 

notation defined table key server constructs rekey message follows 
rekey interval marking algorithm generated encryptions key server runs key assignment algorithm assign encryptions enc packets 
key assignment algorithm guarantees user needs enc packet 
key server uses reed solomon erasure rse coder generate fec redundant information called parity packets 
particular key server partitions enc packets multiple blocks 
block contains enc packets 
call block size 
key server generates parity packets block 
define ratio proactivity factor denoted key server multicasts enc parity packets users 
user recover required encryptions cases 
user receives specific enc packet contains encryptions user 
user receives packets block contains specific enc packet user recover original enc packets 
user receives usr packet subsequent unicast phase 
usr packet contains encryptions needed user 
multicasting enc parity packets users server waits duration round typically larger maximum rtt users collects nacks users 
nacks key server adaptively adjusts proactivity factor control number nacks rekey message 
nack specifies number parity packets user needs order packets recover block 
particular key server collects largest number parity packets needed denoted block round key server generates new parity packets block multicasts new parity packets users 
process repeats conditions switching unicast satisfied see section vii 
typically unicast start multicast rounds 
unicast key server sends usr packets users recovered required encryptions 
enc packet protocol message generated application layer refer packet conform terminology literature 
zhang protocol design scalable reliable group rekeying fig 

basic protocol user 
informal specification user protocol shown fig 

protocol nack feedback mechanism vast majority users receive recover required encryptions single round 
particular round user checks received specific enc packet recover block 
user report number parity packets needed recover block key server 
property reed solomon encoding equal minus number packets received block containing specific enc packet 
summary protocol uses types packets enc packets contain encryptions set users parity packets contain fec redundant information produced rse coder usr packets contain encryptions specific user nack packets feedback user key server 
type packet reports number parity packets needed specific blocks 
note protocols figs 
outline behaviors key server users 
detailed specifications protocols appendix iv 
construction enc packets running marking algorithm generate encryptions rekey message key server runs key assignment algorithm assign encryptions enc packets 
increase probability user receive required encryptions round key assignment algorithm guarantees encryptions user assigned single enc packet 
user identify specific enc packet extract encryptions enc packet key server assigns unique id key user encryption id information included enc packets 
discuss assign id key user encryption define format enc packet 
evaluate key assignment algorithm 
key identification uniquely identify key key server assigns integer id node key tree 
particular key server expands key tree full balanced adding null nodes refer nodes 
result expansion key tree contains types nodes nodes containing individual keys nodes containing group key auxiliary keys nodes 
key server traverses expanded key tree top order sequentially assigns integer node id id starts increments 
example root node id leftmost child id 
fig 
fig 

illustration key identification 
left illustrates ids nodes expanded key tree tree degree 
key identification strategy observe ids node parent node simple relationship node id parent node id key tree degree 
fig 
right illustrates relationship 
uniquely identify encryption assign id encrypting key id encryption key node encrypt key 
parent node id easily derived id encryption 
id user definition id corresponding node contains individual key 
id encryption id user simple relationship node parent node user easily determine encryption encrypted key path user node tree root 
users join leave marking algorithm may modify structure key tree ids nodes changed 
user determine date id node straightforward approach server inform user new id sending packet user 
approach obviously scalable 
lemma theorem show knowing maximum id current nodes user derive new id independently 
lemma key server uses marking algorithm appendix tree update updated key tree id node id node 
theorem user denote user id key server runs marking algorithm denote id key server finishes marking algorithm 
denote maximum node id key server finishes marking algorithm 
define function integer key tree degree 
exists integer equal proof shown appendix theorem know user derive current id knowing old id maximum id current nodes 
format enc packets results previous subsection define format enc packet 
shown fig 
enc packet fields contains id information encryptions 
number parentheses fig 
suggested field length number bits 
id information enc packet allows user identify packet extract required encryptions update ieee acm transactions networking vol 
december fig 

format enc packet 
fig 

illustration uka algorithm 
user id changed 
particular fields uniquely identify packet 
flag bit field specifies packet duplicate field explained section field maximum id current nodes 
discussed previous subsection user derive current id field old id field specifies enc packet contains encryptions users new ids range 
field enc packet contains list encryption id pairs 
encryption payload enc packet may padded zero fixed length fec encoding requires fixed length packets 
observe padding zero cause ambiguity encryption id zero 
user oriented key assignment algorithm format enc packet discuss details key assignment algorithm refer user oriented key assignment algorithm uka 
uka guarantees encryptions user assigned single enc packet 
fig 
illustrates particular run uka algorithm enc packets generated 
uka puts user ids list increasing order 
longest prefix list extracted encryptions needed users prefix fill enc packet 
repeatedly uka generates sequence enc packets intervals overlap 
particular algorithm guarantees previous enc packet packet 
property useful block id estimation performed user see section 
performance uka uka assigns encryptions user single enc packet significantly increases probability user receive encryptions single round 
consequently number nacks sent key server reduced 
benefit achieved expense sending duplicate encryptions 
rekey subtree users may share en fig 

average number enc packets function 
fig 

average number enc packets function 
users encryptions assigned different enc packets shared encryptions duplicated enc packets expect uka increase bandwidth overhead key server 
evaluate performance uka subsection simulations 
simulations assume rekey interval key tree full balanced nodes 
rekey interval join leave requests processed 
assume leave requests uniformly distributed nodes 
set key tree degree length enc packet bytes 
experiments average value computed simulation runs 
investigate size rekey message function shown fig 

fixed observe average number enc packets increases linearly fixed observe increases number enc packets increases leaves imply keys changed decreases keys pruned rekey subtree 
investigate size rekey message function shown fig 

observe average number enc packets rekey message increases linearly combinations values 
uka algorithm encryptions duplicated enc packets 
define duplication overhead ratio duplicated encryptions total number encryptions rekey subtree 
fig 
shows average duplication overhead function consider case fixed observe duplication overhead decreases zhang protocol design scalable reliable group rekeying fig 

average duplication overhead function 
fig 

average duplication overhead function increase consider case fixed observe duplication overhead increases decreases increase plot fig 
average duplication overhead function observe average duplication overhead increases approximately linearly rekey subtree full balanced duplication overhead directly related tree height observe duplication overhead generally number encryptions carried enc packet packet size bytes 
rekey subtree sparse graph duplication overhead fluctuates graph block partitioning running uka assignment algorithm generate enc packets rekey message key server generates parity packets enc packets rse coder 
grouping enc packets single rse block may reduce server bandwidth overhead large block size significantly increase encoding decoding time :10.1.1.35.7747
example rse coder rizzo encoding time parity packet approximately linear function block size :10.1.1.35.7747
evaluation shows large group number enc packets generated rekey interval large 
example group users key server generate enc packets packet size bytes 
large number enc packets rekey interval necessary partition enc packets multiple blocks order reduce key server encoding time 
consider enc packets rekey message sequenced order generation uka algorithm 
packet sequence partitioned blocks packets packets forming block packets forming second block 
block formed assigned sequentially integer valued block id packet block assigned sequence number form block key server may need duplicate enc packets packets fill block 
key server may choose enc packets blocks duplicate duplicates fill block 
flag bit enc packet specify packet duplicate shown fig 

duplicate enc packet contents fields original packet flag bit fields 
anew pair assigned duplicate enc packet reed solomon encoding needs uniquely identify packet duplicate 
block id estimation issue arises partitioning enc packets blocks user loses specific enc packet user needs determine block enc packet belongs 
user try recover block fec decoding 
algorithm appendix users estimate id block containing specific enc packet 
algorithm probability user determine precise value block id worst case loss rate observed user assumption independent packet loss 
happens user estimate possible range block id request parity packets block range sends nack 
packets sent interleaving pattern forming blocks rekey message key server generates parity packets multicasts enc parity packets users 
remaining issue determine order key server sends packets 
protocol key server sends packets different blocks interleaving pattern 
interleaving packets different blocks packets block separated larger time interval experience burst loss link 
interleaving evaluation shows bandwidth overhead key server reduced 
choosing block size block partitioning carried block size determine block size need evaluate impact block size terms performance metrics 
performance metric key server multicast bandwidth overhead defined ratio number enc packets rekey message ieee acm transactions networking vol 
december total number packets key server multicasts enable recovery specific enc packets users 
second performance metric fec encoding time time key server spends generate parity packets rekey message 
block size direct impact user fec decoding time impact small protocol vast majority users receive specific enc packets perform decoding 
simulations evaluate impact block size 
support large group size developed simulator model proposed 
model key server connects backbone network source link user connects backbone network receiver link 
backbone network assumed loss free 
source link fixed loss rate fraction users high loss rate low loss rate loss rate state continuous time markov chain simulate burst loss follows 
average duration burst loss ms average duration loss free time consecutive loss bursts ms default values simulations follows key server sending rate packets rekey interval length enc packet bytes 
simulation topology parameter values experiments described sections stated 
impact block size key server bandwidth overhead shown fig 

set 
observe key server average bandwidth overhead sensitive block size consider impact block size key server fec encoding time 
rizzo rse coder encoding time parity packets rekey message approximately product total number parity packets encoding time parity packet :10.1.1.35.7747
encoding time parity packet approximately linear function relative encoding time assuming time units generate parity packet block size shown fig 

summary small block size chosen enable fast fec encoding server incurring large server bandwidth overhead 
experiments sections choose default value specified 
vi 
adaptive fec multicast previous section discussed partition enc packets rekey message blocks generate note unicast recovery involved evaluate server bandwidth overhead 
key server multicast users receive recover specific enc packets 
network topology loss model simplistic compared internet 
needed simulating large group size 
simulation results gt itm smaller group size refer interested reader 
result case adaptive similar 
see details :10.1.1.106.4394
fig 

average server bandwidth overhead function block size 
fig 

relative fec encoding time function block size 
parity packets block 
discussion assumes proactivity factor section investigate determine proactive fec widely improve reliability reduce delivery latency :10.1.1.16.7732
proactivity factor large key server may incur high bandwidth overhead 
hand proactivity factor small users may depend retransmissions achieve reliability benefit reduced delivery latency diminishes 
furthermore depend proactive fec avoid feedback implosion proactivity factor small users may experience packet losses key server overwhelmed nacks 
appropriate proactivity factor depend network status particular factors network topology loss rates network links number users session number sessions proactive fec 
factors unknown key server may changing session life time 
objective investigation study adaptively adjust proactivity factor observing impact number nacks users 
adaptive adjustment aim achieve low delivery latency small bandwidth overhead 
impact proactivity factor designing algorithm adjust desirable evaluate impact number nacks delivery latency users bandwidth overhead key server 
zhang protocol design scalable reliable group rekeying fig 

average number nacks round function 
table ii percentage users average need number rounds receive encryptions evaluate impact number nacks 
fig 
plots average number nacks round function note axis log scale 
observe average number nacks decreases exponentially increase 
similar observation 
evaluate impact delivery latency 
table ii shows percentage users average need number rounds receive encryptions 
observe average users receive encryptions single round percentage value increased percentage value increased 
evaluate impact average server bandwidth overhead shown fig 

close key server sends small amount proactive parity packets round needs send reactive parity packets subsequent rounds allow users recover packets 
result small increase little impact average server bandwidth overhead 
large bandwidth overhead round dominates bandwidth overhead bandwidth overhead increases linearly summary observe increase effects 
significantly reduce average number nacks multicast round 
reduce worst case delivery latency 
increase key server bandwidth overhead larger needed 
fig 

average server bandwidth overhead function 
fig 

algorithm adaptively adjust proactivity factor 
adjustment proactivity factor fig 
algorithm adaptively adjust basic idea algorithm adjust nack information received current rekey message target number nacks expected returned rekey message 
key server runs algorithm multicast round 
input algorithm list item number parity packets requested user 
user requests packets range blocks key server records number parity packets requested block contains user specific enc packet 
algorithm works follows 
rekey message round key server compares number nacks received equal number nacks targets denoted results cases 
comparison case key server receives nacks target 
case server selects th largest item denoted increases additional proactive parity packets generated block rekey message 
illustrate suppose users sent nacks current rekey message user requests parity packets 
illustration purposes assume target number nacks algorithm rekey message key server send additional parity packets users higher probability recover enc packets single round 
current rekey message users receive parity packets recovered enc packets single round 
ieee acm transactions networking vol 
december fig 

traces proactivity factor initial initial ap 
fig 

traces number nacks initial ai 
second case key server receives nacks target 
receiving nacks better terms reducing delivery latency small number nacks received may mean current proactivity factor high may cause high bandwidth overhead 
algorithm reduces parity packet probability equal performance evaluation simulations evaluate algorithm 
investigate protocol effectively control number nacks evaluate extra bandwidth overhead may incur 
experiments choose default value specified 
controlling number nacks evaluating algorithm control number nacks investigate stability algorithm 
fig 
shows adaptively adjusted key server sends sequence rekey messages 
initial shown fig 
observe takes rekey messages settle stable values 
initial shown fig 
observe keeps decreasing reaches stable values 
comparing figures note stable values figures match 
figs 
plot traces number nacks multicast round 
fig 
initial value number nacks received stabilizes quickly stable values generally times fig 
shows case initial observe stable values figures match 
evaluate algorithm control number nacks various values shown fig 

traces number nacks initial ap 
fig 

traces number nacks various values initial ai 
fig 

traces number nacks various values initial ap 
figs 
initial initial number nacks received key server fluctuates target number specified 
observe fluctuations significant larger values choosing need consider potential impact large fluctuations large 
overhead adaptive fec previous section know algorithm effectively control number nacks reduce delivery latency 
compared approach send proactive parity packets round generates reactive parity packets subsequent rounds zhang protocol design scalable reliable group rekeying fig 

average server bandwidth overhead adaptive fec case various loss conditions 
adaptive fec scheme may incur extra bandwidth overhead key server 
investigate issue subsection 
evaluate extra server bandwidth overhead caused adaptive fec various loss conditions 
fig 
compares average server bandwidth overhead adaptive fec case parity packets generated reactively call case 
observe adaptive scheme causes little extra server bandwidth overhead homogeneous low loss environment 
scheme save little bandwidth 
case key server takes rounds users recover encryptions reactive scheme adaptive scheme 
possible total number parity packets generated rounds case larger adaptive scheme 
case extra bandwidth overhead generated adaptive evaluate average server bandwidth overheads schemes various group sizes 
fig 
observe extra bandwidth overhead incurred adaptive increases extra bandwidth overhead incurred measure average server bandwidth overhead adaptive fec set initial key server send rekey messages 
compute average server bandwidth overhead rekey messages 
fig 

average server bandwidth overhead adaptive fec ai case group size varies 
vii 
speedup unicast rekey transport soft real time requirement desirable users receive new keys start rekey interval 
meet requirement proposed previous section adaptively adjust multicast phase reduce number users send nacks 
reduce delivery latency key server switch unicast multicast rounds 
unicast reduce delivery latency compared multicast duration multicast round typically larger maximum rtt users 
issue early unicast possible high bandwidth overhead key server 
protocol unicast cause large bandwidth overhead key server reasons 
size usr packet sent unicast smaller size enc parity packet 
protocol usr packet contains encryptions specific user packet size bytes see appendix format usr packet height key tree 
hand size enc parity packet typically kilobyte long 
second protocol guarantees users need unicast small 
fact evaluations show initial roughly fewer ieee acm transactions networking vol 
december users need recovery multicast rounds system stable 
conditions switching unicast follows 
protocol switches unicast multicast rounds 
suggest multicast rounds large rekey interval multicast round small rekey interval 
large interval time switch unicast earlier total length usr packets parity packets needed multicast round 
unicast step improve reliability reduce delivery latency key server sends multiple copies usr packet user needs recovery 
number copies send depends loss rate user easily estimated key server see details :10.1.1.106.4394
viii 
objective detail rekey transport protocol performance 
server protocol rekey message consists phases generating sequence enc packets containing encrypted keys generating parity packets multicast enc parity packets transition multicast unicast 
phase running marking algorithm generate encryptions rekey message key server constructs enc packets 
major problem phase allow user identify required encryptions key tree modified 
solve problem assign unique integer id key user encryption 
second key assignment algorithm guarantees user needs enc packet 
including small amount id information enc packets user easily identify specific enc packet extract encryptions needs 
second phase key server uses rse coder generate parity packets enc packets 
major problem phase determine block size fec encoding 
large block size significantly increase fec encoding decoding time 
performance results show small block size chosen provide fast fec encoding increasing bandwidth overhead 
algorithm user estimate block id received specific enc packet 
third phase key server multicasts enc parity packets users 
proactive fec multicast effectively reduce delivery latency users large proactivity factor may increase server bandwidth overhead 
major problem phase achieve low delivery latency small bandwidth overhead 
protocol key server adaptively adjusts proactivity factor past feedback 
experiments show number nacks effectively controlled target number achieving low delivery latency extra bandwidth overhead incurred small 
fourth phase key server switches unicast reduce worst case delivery latency 
problems phase determine switch unicast unicast cause large server bandwidth overhead unicast provide small delivery latency 
key server fig 

key server protocol rekey message 
switch unicast multicast rounds 
reduce delivery latency key server estimates user loss rate sends multiple copies user usr packet unicast 
summary contributions 
new marking algorithm batch rekeying 
algorithm facilitates key identification 
second key identification scheme key assignment algorithm block id estimation algorithm evaluated 
third show fairly small fec block size reduce encoding time server increasing server bandwidth overhead 
adaptive algorithm adjust proactivity factor proposed evaluated 
algorithm effective controlling number nacks reducing delivery latency 
adaptive algorithm refinements 
appendix protocol specification protocol key server shown fig 
protocol user shown fig 

protocols consider rekey message 
figs 
define formats enc parity usr nack packets respectively 
number parentheses suggested field length number bits 
usr packet encryption ids optional arrange encryptions increasing order id appendix marking algorithm periodic batch rekeying key server collects join leave requests rekey interval 
interval server runs marking algorithm update key tree construct rekey subtree 
marking zhang protocol design scalable reliable group rekeying fig 

user protocol rekey message 
fig 

format parity packet 
fig 

format usr packet 
fig 

format nack packet 
algorithm different previous papers :10.1.1.16.7732
marking algorithm consists steps 
step algorithm modifies key tree satisfy leave join requests 
operations step specified fig 

node id information algorithm section iv 
second step marking algorithm constructs rekey subtree 
operations specified fig 

input second step algorithm copy updated key tree 
algorithm label nodes prune tree 
call remaining subtree rekey subtree 
edge rekey subtree corresponds encryption 
key server traverses rekey subtree uses key assignment algorithm assign encryptions packets 
fig 

marking algorithm step updating key tree 
fig 

marking algorithm step constructing rekey subtree 
appendix proofs lemma theorem proof lemma initially key tree empty 
collecting join requests key server construct key tree satisfies property stated lemma rekey interval 
property holds key server processes join leave requests rekey interval property holds joined nodes replace departed nodes marking algorithm 
note algorithm change ids remaining nodes 
newly joined nodes replace departed nodes nodes ids larger maximum id current nodes 
replacements property hold 
marking algorithm splits node id property holds splitting 
ieee acm transactions networking vol 
december proof theorem exists integer marking algorithm know node needs change id splits 
splitting happens splitting node leftmost descendant 
exists integer lemma node 
maximum id current nodes maximum id current nodes equal suppose exists leftmost descendant denoted satisfies condition get contradiction assumption node node 
furthermore node descendant node 
ancestor parent node assumption wehave contradicts lemma node 
proof appendix estimating block id partition enc packets multiple blocks user loses specific enc packet user able know directly block enc packet belongs 
address issue appendix 
user estimate block id enc packet belongs id information contained received enc packets 
suppose user enc packet th packet block denote pair 
user receives enc packet computes new user id denoted refines estimation block id example received packet duplicate larger packet larger equal block id received packet received packet generated earlier user specific enc packet 
way user receive enc packet receive enc packet determine precise value lost 
fig 
illustrates block id estimation 
detailed algorithm estimate block id shown fig 

user determine precise value required block id high probability 
probability failure low shown lemma 
worst case probability lemma assume packets experience independent loss 
packet loss rate observed user 
probability user determine precise value id fig 

illustration block id estimation 
fig 

estimating required block id block specific enc packet belongs sequence number specific enc packet block size 
proof illustrated fig 
enc packets set lost packets set lost user determine precise value required block id probability failure case user determine precise value block id estimate possible range required block id feedback user requests parity packets block estimated block id range 
key server receives nack considers block user specific enc packet belongs see key server protocol fig 

algorithm shown fig 
user sets initial values lower bound low upper bound high respectively 
statement lines guarantees eventually high infinity user receives enc packet 
reasoning follows 
user receives enc packet pkt field packet specifies maximum id current nodes 
maximum id current users larger worst case enc packet contains encryptions user enc packets subfield larger maximum block id larger zhang protocol design scalable reliable group rekeying acknowledgment authors kim liu anonymous reviewers constructive comments 
sherman 
key management large dynamic groups way function trees amortized initialization 
internet draft 
online 
available www org drafts htm 
bolot towsley adaptive fec error control internet telephony proc 
ieee infocom mar pp 

byers luby mitzenmacher digital fountain approach reliable distribution bulk data proc 
acm sig comm vancouver canada sept pp 

chang engel kandlur saha key management secure internet multicast boolean function minimization techniques proc 
ieee infocom vol 
mar pp 

floyd jacobson liu mccanne zhang reliable multicast framework light weight sessions application level framing ieee acm trans :10.1.1.121.1027
networking vol 
pp 
dec 
handley floyd vicisano luby reliable multicast design space bulk data transfer network working group rfc aug 
harder 
logical key hierarchy protocol 
internet draft 
online 
available org related htm reliable multicast transport rmt charter internet research task force irtf 
online 
available www ietf org html charters rmt charter html secure multicast research group internet research task force irtf 
online 
available www org kurose towsley comparison server receiver local recovery approaches scalable reliable multicast proc 
ieee infocom san francisco ca mar pp 

scoped hybrid automatic repeat request forward error correction proc 
acm sigcomm sept pp 

levine garcia luna aceves comparison known classes reliable multicast protocols proc 
ieee int 
conf 
network protocols columbus oh oct pp 

li yang gouda lam batch rekeying secure group communications proc 
th int 
world wide web conf hong kong may pp 

mckinley mani experimental study adaptive forward error correction wireless collaborative computing proc 
ieee symp 
applications internet san diego ca jan pp 

biersack towsley parity loss recovery reliable multicast transmission proc 
acm sigcomm sept pp 

jung biersack carle bad reliable multicast local recovery proc 
ieee infocom san francisco ca mar pp 

paul kristol multicast transport protocols high speed networks proc 
ieee int 
conf 
network protocols boston ma oct pp 

rizzo effective erasure codes reliable computer communication protocols comput :10.1.1.35.7747
commun 
rev vol 
pp 
apr 
rubenstein kurose towsley real time reliable multicast proactive forward error correction proc 
nossdav cambridge july pp 

setia jajodia harder kronos scalable group re keying approach secure multicast proc 
ieee symp 
security privacy pp 
may 
towsley kurose pingali comparison sender initiated reliable multicast receiver initiated reliable multicast protocols ieee select 
areas commun vol 
pp 
mar 
wallner harder key management multicast issues architectures network working group rfc june 
wong gouda lam secure group communications key graphs proc 
acm sigcomm sept pp 

wong lam keystone group key management system proc 
int 
conf 
telecommunications acapulco mexico may 
yang li zhang lam reliable group rekeying performance analysis proc :10.1.1.16.7732
acm sigcomm san diego ca aug pp 

yoon bestavros matta adaptive reliable multicast proc :10.1.1.16.7732
ieee int 
conf 
communications vol 
new orleans la june pp 

zhang lam 
lee group rekeying limited unicast recovery dept comput 
sci univ texas austin tech 
rep tr july 
revised feb 
zhang lam 
lee group rekeying limited unicast recovery proc 
ieee int 
conf 
communications vol 
anchorage ak may pp 

zhang lam :10.1.1.106.4394
lee yang protocol design scalable reliable group rekeying dept comput 
sci univ texas austin tech 
rep tr june 
revised nov 
zhang lam 
lee yang protocol design scalable reliable group rekeying proc 
spie conf 
scalability traffic control ip networks vol 
denver aug pp 

brian zhang received degree computer science technology tsinghua university beijing china 
currently working ph degree computer science university texas austin 
research interests areas network security multicast peer peer systems 
simon lam sm received degree distinction washington state university ph degrees engineering university california los angeles ucla respectively 
postgraduate research engineer arpa network measurement center ucla worked satellite radio packet switching networks 
research staff member ibm watson research center yorktown heights ny 
faculty university texas austin professor chair computer sciences served department chair 
current research interests network protocol design analysis distributed multimedia internet security services 
dr lam served editorial boards ieee acm transactions networking ieee transactions software engineering ieee transactions communications proceedings ieee performance evaluation 
editor chief ieee acm transactions networking 
currently serves editorial board computer networks 
organized program chair acm sigcomm symposium held university texas austin 
founding steering committee member ieee international conference network protocols 
received leonard abraham prize best published ieee transactions communications william bennett prize best published ieee acm transactions networking ieee communications society 
fellow acm elected 
ieee acm transactions networking vol 
december dong young lee received degrees computer science seoul national university seoul korea respectively 
currently working ph degree computer science university texas austin 
research interests include peer peer networks streaming media 
richard yang received degree computer science technology tsinghua university beijing china ph degrees computer science university texas austin respectively 
department computer science yale university new haven ct assistant professor 
current research interests heterogeneous networks mobile ad hoc networks network security 
