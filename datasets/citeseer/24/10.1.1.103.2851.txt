multiprocessor hash join algorithms david dewitt robert gerber computer sciences department university wisconsin research partially supported department energy contract de ac er national science foundation mcs 
extends earlier research hash join algorithms multiprocessor architecture 
implementations number centralized join algorithms described measured 
evaluation algorithms served verify earlier analytical results 
addition demonstrate bit vector filtering provides dramatic improvement performance algorithms including sort merge join algorithm 
multiprocessor configurations centralized grace hybrid hash join algorithms 
algorithms shown provide linear increases throughput corresponding increases processor disk resources 

publication classic join algorithm eswaran blas topic virtually abandoned research area 
everybody knew nested loops algorithm provided accept able performance small relations large relations suitable index existed sort merge algorithm choice ad hoc queries 
year papers dewi brat took look join algo rithms centralized relational database systems 
particular papers compared performance traditional join algorithms variety algorithms hashing 
papers reached conclu sion sort merge commonly accepted algorithm ad hoc joins fact nearly fast join algorithms hashing 
retrospect interesting observe simple algo rithm virtually ignored simply system astr support hashing access method 
motivation research described twofold 
dewi brat analytical evaluations wanted implement measure algorithms proposed papers common framework order verify performance hash join algorithms 
second wanted see results single processor extended multiple processors 
hash join algorithms described dewi particular hybrid algorithm effective main memory minimize disk traffic 
multiprocessor joins require data moved pro cessors multiprocessor hash join algorithms minimize amount data moved process executing join algorithm 
hash multiprocessor join algorithms multiprocessors new 
suggested adopted grace database machine project kits evaluated vald 
papers important contributions understanding multiprocessor hash join algorithms number questions remain 
hard factor influence tree architecture parallel readout disks results obtained 
kits hand concentrates speed sort engine performance grace hash join algorithm 
algo rithm vald exploits hashing partitioning process resorts pure nested loops algorithm aided bit vector filtering join phase 
goal research examine ad hoc mean join suitable index exists 
ingres ston uses hashing ad hoc queries limited address space pdp ingres implemented impossible exploit large amounts memory effectively 
consequently algorithm received recognition deserves 
multiprocessor hash join algorithms multiprocessor environment enabled identify cpu communica tions bandwidth design parameters 
section review join algorithms analytical results dewi 
step developing multiprocessor version hash join algorithms implemented join algorithms described dewi top wisconsin storage system wiss 
results section verify analytical results dewi 
results feel relational database systems provide hash join algorithm order effectively exploit main memory increasingly inexpensive 
algorithms described section gather real numbers simu lation multiprocessor join algorithms 
section describe multiprocessor hash join algorithms 
results simulation study algorithms 
results extremely exciting indicate algorithms provide close linear speedup performance corresponding increases resources 
section plans new database machine multiprocessor join algorithms described 

overview hash partitioned join operations dewi performance hashed join algorithms termed simple grace kits hybrid compared traditional sort merge algorithm 
discussion hash partitioned join algorithms source relations named assumed smaller pages hash join algorithms partitioning disjoint subsets called buckets kits 
partitions important characteristic tuples join attribute value share bucket 
term bucket confused overflow buckets hash table 
partitioned buckets merely disjoint subsets original relations 
tuples assigned buckets value hash function applied tuple join attribute value 
assuming potential range hash values partitioned subsets tuple hashed join attribute value falls range values associated put bucket similarly tuple hashes partition put bucket hash function partitioning ranges relations tuples bucket joined tuples case tuples bucket join attribute values equal tuples potential power partitioning lies fact join large relations reduced separate joins smaller relation buckets 
hash join algorithms distinct phases 
phase relations partitioned buckets 
centralized environment partitioning done allocating page frame buffer tuples assigned particular buckets 
page buffer filled flushed file disk represents particular bucket 
relation scanned partitioned turn 
partitioning phase relations represented equal numbers bucket files written disk 
partitioning phase create suitable number buckets bucket relation small fit main memory 
size buckets ignored single page relation needs resident memory time join phase 
second phase hash join algorithms effects actual search tuples relations matching join values 
traditional join methods phase realize final join result 
relation partitioned buckets fit memory appropriate hash algorithm process search matching join tuples 
second phase referred join phase 
step join phase bucket build hash table main memory 
bucket read tuple probe hash table matches 

problems hash join algorithms partitioning phase ensure size buckets created relation exceed size main memory 
guaranteeing chosen partitioning hash values result buckets relation fit memory necessarily trivial 
problem buckets growing unacceptably large termed bucket overflow 
choice appropriate hash function tend randomize distribution tuples buck ets minimize occurrence bucket overflow 
chosen hash function fails distribute tuples uniformly bucket overflow occurs number remedies available 
relations parti tioned hash function 
solution expensive 
better alternative apply partitioning process recursively oversized buckets dewi brat 
net effect solution split oversized bucket smaller buckets 
relation partitioned relation method requires particular bucket overflowed 
range values governing partitioning relation adjusted reflect final partitioning bucket overflow han 
method fail case combined sizes tuples having identical join values exceeds size available memory 
case hash variation nested loops join algorithm applied 
performance algorithm analyzed section 
solutions handle bucket overflow applied overflow hash table 

simple hash join simple hash join processes bucket time doing minimal amount partitioning 
fact partitioning join phases executed simultaneously 
files associated relations files input input contain tuples waiting processed current phase algo rithm 
files output output contain tuples passed current phase algo rithm 
start algorithm input input set equal relations output output initially empty 
partitioning basis consisting number range hash values chosen start 
stages algorithm buckets relation buckets sequentially build hash tables main memory 
hash table built start stage 
stage begins scan input 
tuple considered belongs targeted memory bucket tuple added hash table 
tuple written output 
output contains remaining buckets current interest 
input scanned sequentially 
tuple input hashes bucket probe hash table built bucket match tuples joined output 

tuple belong bucket written output 
stage simple hash join output output file input input file stage 
algorithm progresses output output file progressively smaller buckets interest consumed 
algorithm finishes output output empty processing stage 

grace hash join grace hash join algorithm kits characterized complete separation parti joining phases 
partitioning relations completed prior start join phase 
ordinarily partitioning phase creates buckets relation necessary insure hash table bucket fit memory 
single page frame needed output buffer bucket possible memory pages remain unused requisite number bucket buffers allocated 
grace algorithm extra pages increase number buckets generated partitioning phase 
partitioning phase smaller buckets logically integrated larger buckets optimal size building memory hash tables 
strategy termed bucket tuning kits 
bucket tuning useful method avoiding bucket overflow 

hybrid hash join hybrid hash join described dewi 
partitioning finished stage algorithm fashion similar grace algorithm 
grace algorithm uses additional available memory partitioning phase partition relations large number buckets hybrid uses additional memory joining process 
hybrid creates minimum number buckets bucket reasonably expected fit memory 
allocating page frame output buffer bucket hybrid algorithm utilizes remaining pages frames build hash table 
partition ing range adjusted create equal sized buckets written disk independently sized bucket build hash table 
partitioning range relation tuples hash bucket immediately probe hash table matches 
partitioning phase com hybrid hash join completed processing part join phase 
tuples immediately processed written retrieved disk partitioning join phases 
savings significant amount memory increases 

sort merge join algorithm standard sort merge blas algorithm begins producing sorted runs tuples average twice long number tuples fit priority queue memory knut 
requires pass relation 
second phase runs merged way merge large possible 
number runs produced phase phases needed 
final phase sorted source relations sequentially scanned matching tuples joined output 

comparison join algorithms displays relative performance join algorithms analysis parameter set dewi 
vertical axis execution time seconds 
horizontal axis ratio respectively sizes main memory relation pages equals factor account fact hash table occupy pages main memory 
algorithms assumed resident mass storage algo rithm begins execution 
results clearly indicate advantage hash join algorithm traditional sort merge algorithm 
retrospect results surprising sorting creates total ord ering records files hashing simply groups related records bucket 

evaluation centralized hash partitioned join algorithms verify analysis dewi gather information cpu utilizations dur ing partitioning joining phases hashing algorithms implemented simple grace hybrid algorithms vax running berkeley unix 
addition hash partitioned join algorithms popular join algorithms studied 
algorithms sort merge algorithm hash nested loops algorithm provide context comparing performance hash partitioned join algo rithms 
algorithms implemented wisconsin storage system wiss chou 

overview wiss wiss project begun approximately years ago recognized need flexible data storage system serve basis constructing experimental database management systems 
originally conceived replacement unix file system wiss run top raw disk unix wiss ported run crystal multicomputer dewi 
services provided wiss include structured sequential files byte stream files unix indices stretch data items sort utility scan mechanism 
sequential file sequence records 
records may vary length page length may inserted deleted arbitrary locations sequential file 
optionally sequential file may associated indices 
index maps key values records sequential file contain matching value 
indexing mechanism construct unix style byte stream files pages index correspond inode components unix file 
stretch item sequence bytes similar file unix 
insertion deletion arbitrary locations supported 
associated stretch item record unique identifier rid 
including rid stretch item record con struct records arbitrary length 
demonstrated chou wiss performance comparable commercially available database systems 

summary algorithms evaluated centralized versions grace simple hybrid hash partitioned join algorithms implemented manner described section 
modified version nested loops algorithm termed hashed loops implemented brat 
hashed loops algorithms named uses hashing means effecting internal join tuples main memory 
similar algorithm university version ingres ston 
phase hashed loops algorithm hash table constructed pages staged memory 
tuples probes hash table 
constructing hash table avoids exhaustively scanning tuples memory tuple done simpler form nested loops algorithm 
algorithm sort merge join employed sort utilities provided wiss 
algorithms allocated identical amounts main memory buffering pages relation 
similarly algorithms accessed relations disk page time blocking disk operations completed 

presentation performance results join algorithms compared queries data wisconsin benchmark database 
execution time join algorithm shown function amount avail able memory relative size smaller relation 
relative amount memory defined number pages main memory divided size pages smaller relation 
elapsed times join algorithms include time required write final result relation disk 
tests run single user mode 
test machine megabytes memory paging occurred 
bucket overflow occur tests hash partitioned algorithms 
results joining tuple relations join algorithms 
join produces result tuples 
join attribute randomly ordered byte integer 
tuple relations participates result relation produced join query 
perfor mance results calculated analytical models presents measured performance actual implementations algorithms 
find similarity figures reassuring encouraging 
performance grace hash join algorithm constant range available memory 
results total separation partitioning join phases grace algorithm 
performance viewpoint grace algorithm uses memory optimally joining phase 
excess memory partitioning phase means creating large number buckets bucket tuning process 
contrast performance simple hash join algorithm significantly affected amount available memory performs smaller relation twice size available memory 
formance hybrid algorithm reflects fact combines best performance features grace simple hash join algorithms 
hybrid completes partitioning single pass source rela tions performance grace algorithm 
hybrid algorithm increasingly outperforms grace amount relative memory increases additional memory joining tuples bucket source relation 
immediate joining eliminates cost writing reading tuples disk partitioning joining phases 
performance hash partitioned algorithms remains unchanged smaller relation fits memory 
point occurs relative memory value available memory exactly equals size smaller relation 
results fact hash join algorithms available memory join phase structure hash table 
realized partitioning predictive process requires additional memory accommodate fluctuations size hash tables con structed buckets 
performance sort merge join algorithm constant wide range available memory 
source relation fits memory sorting process completely reads writes relation twice sorted runs produced second time sorted runs merged 
sort merge join algorithm reads source relations third time effect final joining tuples 
optimiza tion possible 
sufficient memory sorted runs relations merged joined simple hash join algorithm performance equal hybrid algorithm relative memory values excess approximately 
difference performance hybrid simple algorithms relative memory values artifact implementation 
ously 
case performance sort merge algorithm expected similar grace algo rithm algorithm access page source relation times reads write 
surprisingly hashed loops algorithm quite performance wide range avail able memory 
due existence hash table cost probing matches tuples relation relatively inexpensive operation 
algorithm performs especially size smaller relation twice size available memory 
exactly situation expect case bucket overflow hash nested loops algorithm attractive remedy handling bucket overflow 
performance join algorithms join tuple relation tuple relation shown 
result relation contains tuples 
hybrid algorithm continues dominate join algorithms wide range relative memory values 
stepwise performance transitions sort merge nested loops algorithms obvious environment query 
reflects performance join algorithms query 
differ ence algorithms bit vector filtering techniques babb brat vald 
notable performance improvements demonstrated result eliminating earlier stage processing tuples produce result tuples 
bit vector filtering technique hash partitioning sort merge algorithms similar 
prior initial scan relation bit vector initialized set ting bits 
tuple join attribute hashed hashed value set bit bit vector 
relation scanned appropriate bit bit vector checked 
bit set tuple safely discarded 
applying bit vector relation relation approximates semijoin relation relation net impact process depends semijoin selectivity factor relation defined ratio tuples resulting semijoin relative cardinality example query semijoin relation semijoin selectivity factor 
net effect approximately tuples relation eliminated early stage processing hash partitioned sort merge algorithms 
significant savings accrue fact non participating tuples stored disk partitioning joining phases hash partitioning algorithms 
disk accesses saved page tuples eliminated bit bit vector filtering technique hash partitioned sort merge algorithms directly extendible case hashed loops names relations discussion reversed 
vector filtering relation hashed loops algorithm complete scan relation query bit vector filtering approximate semijoin relation semijoin selec tivity factor semijoin 
instance hashed loops algorithm doesn derive benefit applying bit vector filtering 
collisions occur process accessing bit vectors may result non qualified phantom tuples propagated final joining process 
phantom tuples eliminated final joining process 
number phantom tuples reduced increasing size bit vector split ting vector number smaller vectors babb 
separate hash function associated smaller bit vectors 
costs associated bit vector filtering modest 
test single bit vector length bytes 
hash partitioning algorithms compute hashed value tuple join attribute additional cost bit vector filtering algorithms amount space required bit vector 

multiprocessor hash join algorithms multiprocessor versions hybrid grace algorithms attractive number reasons 
ability algorithms cluster related tuples buckets provides natural opportunity exploit ing parallelism 
addition number buckets produced partitioning phase activated join ing phase algorithm adjusted produce level parallelism desired joining phase 
second buckets multiprocessor versions algorithms minimize communications head 
furthermore just centralized form hybrid algorithm effective main memory order minimize disk traffic expect multiprocessor version hybrid hash join algorithm able memory minimize disk communications traffic 
appears control algorithms decentralized straightforward manner 

horizontal partitioning relations relations assumed horizontally partitioned ries disk drives system 
view point raw bandwidth approach aggregate bandwidth disk striping strategies garc kim brow equal number disk drives 
difference approach data read processed directly transmitted interconnection network processor 
obvious strategies distributing tuples disks drives system 
approach apply randomizing function tuple key attribute tuple select disk stor ing tuple 
processor maintains independent index tuples stored disk 
advantage approach additions file number tuples disk remain relatively balanced 
second approach cluster tuples key value distribute disk drives 
case disks associated processors viewed nodes primary clustered index 
control ling processor acts effect root page index 
intend investigate traditional tree ing algorithms provide acceptable performance environment 
approach similar simpler clustering approach employed mdbs 
mdbs backend processor examine query clustering mechanism implemented backends controlling processor 
real advantage second approach comes processing queries 
distribution stra 
tuples distributed randomly case exact match queries attribute distribute tuples processors execute query 
second distribution strategy controlling processor maintains root page index direct query appropriate processors 
certainly overhead performing function certainly cost sending query processors 
furthermore fairly large database root pages indices fit controlling processor main memory 
distribution strategies provide approximately response time single user benchmarks expect system throughput significantly higher second distribution strategy multiuser environment 
suitable index available processors available perform query 

description multiprocessor hybrid grace algorithms algorithms described section assume relations database horizontally partitioned multiple disk drives manner described 
disk drive processor associated 
note converse necessarily true 
purposes performance evaluation assumed processors interconnected mbit second token ring 
demonstrate interconnection topology provides adequate performance processors 

multiprocessor version grace hash join algorithm appear number alternative strategies parallelizing grace hash join algorithm 
approach selected evaluated assumes different set processors joining parti phases algorithms 
furthermore partitioning processors assumed disk drives associated joining processors assumed diskless 
reason find strategy attractive diskless nodes cheaper nodes disks interested exploring processors effectively utilized 
algorithm proceeds follows 
node disk partitions smaller relation buckets written network nodes disks 
nodes perform join phase algorithm 
joining node contain single hash table built tuples single bucket smaller source relation 
hash tables completely built larger relation partitioned buckets sent joining nodes 
corresponding buckets source relations guaranteed sent joining node 
tuples larger relation probe join node hash tables matches 
size smaller relation exceeds aggregate memory capacity joining nodes multiple phases necessary unused buckets temporarily saved disks attached partitioning nodes 
multiprocessor grace algorithm allocate varying numbers joining nodes 
grace algorithms named ratio partitioning nodes joining nodes 
grace design allocates partitioning node joining node 
partitioning node joining nodes grace design 
grace design allocates partitioning nodes joining node 
design combinations proved optimal execution single join queries may case varied combinations processors may prove optimal complex queries 

multiprocessor version hybrid hash join algorithm multiprocessor grace algorithm employs combination processors disks multiprocessor hybrid algorithm requires processor disk drive 
multiprocessor hybrid hash join algorithm performs partitioning joining phases nodes 
processor partitions source relations fashion similar grace algorithms 
node allocates excess memory partitioning phase hash table bucket tuples 
source relations partitioned local hybrid processor tuples written net appropriate join node 
tuples belonging bucket associated partitioning processor immediately build probe local hash table 
tuples processed locally hybrid hash join algorithm generates relatively lighter network load grace algorithm 
level resources hybrid multiprocessor algorithm disks fewer processors grace multiprocessor algorithm 

discussion simulation model evaluate performance distributed hybrid grace hash join algorithms simulation model proposed multiprocessor architecture constructed 
hardware components represented model intended examples current commercially available components 
capabilities various components varied test effects various combinations resources 
distributed hash partitioned algorithms implemented different kinds network environments processors current simulation loosely coupled token ring network 

hardware model allows simulate mip processors 
disk drives modeled eagle drive assumed support transfer rate mbytes second 
combined positioning latency times modeled normal distribution mean value milliseconds standard ation milliseconds 
processor network interface assumed single output buffer kbytes 
similar input buffer assumed 
effective dma bandwidth buffers filled flushed main memory processor assumed mbits second mbits second 
mbits second number derived measurements vax interface prot attached 
mbits second estimate dma rate device attached internal bus vax 
token ring assumed bandwidth mbits second mbits second 
mbits second value representative currently available local network interfaces token ring 
mbits second interface mbits second dma rate representative ci interface digital equipment 
multiprocessor version hybrid algorithm requires processor disk drive grace algorithm employs processors disks method computing cost par ticular configuration processors disk needed 
approach adopted assume mip pro cessor cost disk drive controller 
relative cost mip processors computed law gros relates cost processor performance speed processor performance technology constant processor cost technology constant cost exponent assigned respectively values 
cost particu lar configuration calculated computing aggregate cost processors disks 
far incorporated memory communications costs cost model 
exam ple cost effective memory lower speed communication device 
cost model calculating cost particular configuration processors disks straight forward 
reverse transformation obvious 
assume example processors mip processors 
hybrid join configuration cost consist processors disks 
grace configuration partitioning processors join processor cost consist parti processors disks joining processors 
grace configuration exactly cost 
example configuration partitioning nodes disks joining nodes cost configuration cost 
likewise grace configuration cost closest partitioning processors disks join processors 
facilitate interpretation results summarized table resource costs alternative hardware configurations assuming mip processors algorithms hybrid grace 
configurations evaluated mip processors 
cost configuration changes cases table determine hardware configuration associated data point 

software operation simulated processor controlled simple operating system kernel provides preemptive scheduler 
processes associated priorities resolve contention system resources 
price performance relationship ibm system series correlates value cost exponent 
note case grace algorithm different performance processors parti joining nodes 
resource hybrid grace grace grace cost pp jp pp jp pp jp number processors number disks pp number partitioning processors jp number joining processors table resource costs hash join configurations mip processors minimize overhead disk transfers done track kbytes time garc 
addition double buffer associated open file process processing track track read 
max imum packet size supported network assumed bytes 
proposed multiprocessor join algorithms require large blocks data transferred communications device 
model built modified sliding window protocol insures reliable delivery large blocks data enhancing effective throughput network transfers 
help control contention receivers higher level connection communications protocol incorporated simulation model 
far ignored issue memory size bucket overflow 
preliminary results assume smaller relations joined fits aggregate memory proces sors joining 
assumption true number cases want base design machine assumption 
assume example processors partitioning 
rams megabyte memory boards common 
rams available typical memory board hold megabytes data 
just memory boards aggregate megabytes available holding buckets 
assumes smaller relation produced applying selection operation megabytes hold temporary relations 
addressed issue bucket overflow size bucket larger memory joining processor bucket assigned occur case size smaller relation total available memory 

preliminary results evaluate performance different algorithms tuple relations joined 
result relation contained tuples 
mip processors network bandwidth dma rate held constant varying resources available multiprocessor hybrid join algorithm configurations multiprocessor grace algorithm 
throughput measured terms queries minute performance metric 
conducted wide range tests included results obtained network bandwidth mbits second dma rate mbits second 
summary results obtained configurations contained section 
cost displaying saving result relation configuration ignored results displayed 
performance obtained multiprocessor hybrid join algorithm configurations mul grace algorithm displayed figures mip processors respectively 
think results exciting represent breakthrough designing architecturally simple high speed database machine 
type processor linear speedups obtained increasing level resources 
mip processors grace configuration provides higher throughput rate wide range available resources 
principal reason mip processors average cpu utilization hybrid design grace design uses larger number processors resource cost level cpu bound 
example total resource cost equal grace design parti nodes join nodes disks 
comparison resource cost hybrid design processors disks 
average disk utilization approximately hybrid design grace design 
hybrid advantage having source relations partitioned larger number disks resource cost level significant factor 
presents throughput results case processors assumed mip proces sors 
test hybrid processors longer cpu bound hybrid algorithm outperforms grace design combinations 
balanced nature processing requirements query favor hybrid grace designs allocate balanced processor resources 
grace designs perform lower processor utilizations resulting mismatch processor resources 
presents throughput results mip processors 
increased processor performance favors hybrid design processes bucket relation local processor 
grace designs able utilize increased processor performance magnitude network data transfers impediment increased performance 

look resource utilizations mip processors performance multiprocessor hash join algorithms necessarily depend algo rithms utilize hardware resources 
hybrid algorithm intrinsic advantage sending relatively smaller number tuples communications network 
hand hybrid algorithm imposes greater load processors 
presents resource utilization levels multiprocessor hybrid algorithm mip pro cessors 
high cpu utilization levels reflect fact processor hybrid algorithm partitioning joining phases algorithm 
initial increase cpu utilization caused transi tion algorithm single processor processors 
single processor hybrid design utilize network processor hybrid design expend substantial amount pro cessing effort transferring buckets tuples processors 
additional processors added hybrid algorithm cpu utilization processors begins decline 
decline corresponds increased level contention network 
level contention network increases processors frequently query grace designs transfer larger amount data network hy design 
blocked waiting transfer blocks data network 
increased levels network contention result increase total utilization network 
relatively low disk utilizations result fact data read disk track time 
disk blocking factor disk frequently idle previously read tuples partitioned 
presents resource utilizations grace multiprocessor algorithm design mip processors 
relative cpu utilizations partitioning nodes joining nodes reflect fact parti phase normally computationally expensive phase hash join algorithm 
cpu tions partitioning nodes joining nodes decrease levels network contention increase 
cpu utilizations grace processors relatively lower cpu utilizations hybrid algorithm 
due fact resource level grace algorithm uses greater number pro cessors hybrid algorithm 
conversely fact grace algorithm uses fewer disks hybrid algorithm resource level leads relatively higher disk utilizations seen grace algorithm 

tests similar results obtained varied network bandwidth dma rate 
network bandwidth mbits second dma rate mbits second slowest configuration tested linear speedups obtained approximately resource cost 
point network tended completely utilized throughput remained constant 
far chosen type processors partitioning joining nodes alternative grace designs 
join queries varied distributions join attribute values may provide possibility altering balance performance processing joining nodes 
plan investigating alternative 
disk blocking factors reduced low kbytes significantly altering perfor mance algorithms 
actual point varied mip rate processors 

research hash join algorithms dewi extended multiprocessor architec ture 
step algorithms described dewi implemented wiss chou running vax running berkeley unix 
addition providing cpu utilization figures simulation multiprocessor algorithms centralized experiments provided interesting results 
measured performance algorithms similar predicted analytically dewi 
second bit vector filtering babb shown provide dramatic reduction execution time algorithms including sort merge join algorithm 
fact query tested bit vector filtering algorithms virtually execution time 
extended centralized grace hybrid hash join algorithms common multiprocessor configuration 
centralized algorithms chosen provide natural point separating joining partitioning phases algorithm 
multiprocessor hybrid algorithm uses multiprocessor configuration consisting entirely nodes having associated disk drive 
nodes partition ing join phases algorithm 
configurations multiprocessor grace algorithm evaluated grace grace grace 
design diskless joining processor allocated partition ing processor 
design allocates partitioning nodes diskless joining node 
design partitioning node diskless joining nodes 
results simulation experiments algorithms encouraging algorithms provide linear increases throughput corresponding increases processor disk resources 
interesting extensions research currently exploring 
term adjustable join parallelism 
adjusting partitioning algorithms number buckets produced adjusted 
turn effects parallelism joining phase 
example partitioning phase produces just buckets processors joining phase 
number cases technique useful load balancing heavy loads constrained requirement bucket reasonably expected fit memory joining processor 
equivalently multiple buckets assigned join processor 
bucket active time level parallelism controlled 
low priority queries joins small relations parallelism doesn sense relations joined small 
second promising area bit filtering multiprocessor hash join algorithms 
number ways bit filtering babb kits exploited multiprocessor hashing algorithms 
example joining node build bit vector simultaneously construction hash table 
completed bit vectors distributed partitioning processors 
partitioning processors maintain bit vec tors bucket basis 
alternately partitioning nodes merge bucket bit vectors single bit vector 
bit vector applied partitioning relation strategy plus number bit vector filtering strategies look promising 
intend algorithms part gamma project 
gamma new database machine project begun 
gamma provide test vehicle validating multiprocessor hash join results 
gamma built crystal multicomputer dewi wiss chou basis 
crystal multicomputer project funded part national science foundation coordinate experimental research program 
crystal network bare vax processors currently eventually serving nodes connected mbit second token ring associates prot 
ring currently upgraded mbit second ring 
node machines attached disks 
file database services provided crystal users wiss 
crystal software provides simple operating system nose multiple lightweight processes shared memory reliable connections nose processes node machines unix processes host machines vax running unix 
wiss runs top nose 
crystal nose wiss operational production 

astr astrahan system relational approach database management acm transactions data systems volume june pp 

babb babb implementing relational database means specialized hardware acm transactions database systems volume 
bitton dewitt benchmarking database systems systematic approach proceedings large database conference october 
blas eswaran storage access relational data bases ibm systems journal 
brat hashing methods relational algebra operations proceedings large database conference august 
brow browne dale leung parallel multi stage architecture self managing disk cache database management applications proceedings th international workshop database machines march 
chou chou dewitt katz klug design implementation wisconsin storage system wiss appear software practice experience computer sciences department university wisconsin technical report november 
dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston ma june 
dewi dewitt finkel solomon crystal multicomputer design implementation experience submitted publication ieee transactions software engineering computer sciences department technical report university wisconsin september 
garc garcia molina kenneth salem disk striping appear proceedings sigmod conference dept electrical engineering computer science technical report december 
goodman investigation multiprocessor structures algorithms database management university california berkeley technical report ucb erl may 
gros high speed arithmetic digital computer research tool journal optical society america volume april 
implementation database systems mdbs advanced database machine architecture edited david hsiao prentice hall 
kim kim parallel operation magnetic disk storage devices proceedings th international workshop database machines march 
kits kitsuregawa tanaka oka application hash data base machine architecture new generation computing volume 
kits kitsuregawa tanaka oka relational algebra machine grace rims symposia software science engineering lecture notes computer science springer verlag 
kits kitsuregawa tanaka oka architecture performance relational algebra machine grace university tokyo technical report 
knut knuth art computer programming sorting searching volume iii 
prot associates operation maintenance manual model waltham mass 
ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report uc berkeley may 
siewiorek bell newell computer structures principles examples mcgraw hill 
ston stonebraker michael eugene wong peter kreps design implementation ingres acm transactions database systems volume september 
vald valduriez join semi join algorithms multiprocessor database machine acm transactions database systems volume march 
