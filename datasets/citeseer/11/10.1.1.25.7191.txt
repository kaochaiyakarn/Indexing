ieee journal solid state circuits vol 
september energy dissipation general purpose microprocessors investigate possible ways improve energy efficiency general purpose microprocessor 
show energy processor depends performance chose energy delay product compare different processors 
improve energy delay product explore methods reducing energy consumption lead performance loss wasted energy explore methods reduce delay exploiting instruction level parallelism 
careful design reduced energy dissipation 
pipelining give approximately improvement product 
superscalar issue improve energy delay product overhead required offsets gains performance 
improvements hard come large fraction energy dissipated clock network chip memories 
efficiency processors depend technology algorithm chosen programmer micro architecture 
interest lowering power processor grown dramatically past years 
interest power dissipation fueled partly high power levels greater today state art processors growing market portable computation devices 
result attention power increasing diverse space processors user choose simple machines modest performance power consumption watt processors sophisticated architectural features power dissipation tens watts 
processors power performance strongly correlated 
low power invariably means lower performance 
correlation different published results signal processing applications power reduced orders magnitude maintaining performance 
show reason slow progress processors fundamental barring radical new architecture energy delay product processor roughly set energy delay product underlying technology 
section describes power delay underlying cmos technology processors related shows easy trade increased delay reduced energy 
energy needed complete program manuscript received june revised march 
research supported advanced research projects agency contract fbi 
authors computer systems laboratory stanford university stanford ca usa 
publisher item identifier 
ricardo gonzalez mark horowitz ieee jules instruction inverse spec metric compare designs 
needs consider energy delay simultaneously reason energy delay product jules spec inverse spec rest 
section iii looks lower bound energy energy delay product processor investigating number ideal machines including machine simple risc machine superscalar machine 
machines energy data storage accounted includes essential latches cache accesses register file accesses 
control computation free machines form lower bound achieved real machine 
section iv looks real processors designed simple risc machine superscalar processor called torch 
starting unoptimized design conventional optimizations save machine power 
optimizations show real machines factor ideal machine previous section 
power distributed number small units reducing overhead fairly difficult 
ii 
energy delay product performance single important feature microprocessor 
today designers concerned power dissipation cases low power key design goals 
led increasing diversity processors available 
comparing processors wide spectrum difficult need suitable metric energy efficiency 
table shows possible metrics processors available today 
power metric compare processors proportional clock frequency 
simply reducing clock speed reduce power dissipated processors 
power decreases processor really better possible metric energy measured jules instruction inverse spec better power metric problems 
proportional reduce energy instruction reducing supply voltage decreasing capacitance smaller transistors 
changes increase delay circuits expect lowest energy processor low performance shown table ieee journal solid state circuits vol 
september usually want minimum power performance level performance power need consider quantities simultaneously 
simplest way product energy delay jules spec inverse spec 
wide distribution performance power processors shown table terms energy delay product processor remarkably close 
improve energy delay product processor increase performance reduce energy dissipation adversely affecting quantity 
common low power design techniques reduce energy delay product simply allow designer tradeoff performance energy 
reducing supply voltage example reduce energy performance order magnitude small changes energy delay product 
effective way reduce energy delay product shrink technology 
scaling factor ideal scaling conditions energy delay product scales technologies scale ideally threshold voltage scale 
performance processor limited external memory system 
expect energy delay product scale table show energy delay product scaled row labeled spec spread high performance low power processors narrower 
energy efficiency processor highly dependent efficiency underlying technology 
technology scales energy delay product processors continue improve 
improvement approximately constant processors ignore technology scaling remainder 
technology scaling factored processors shown table factor performance energy vary order magnitude 
understand processors similar section investigates intrinsic factors set energy energy delay product processor 
simplified model indicates table current microprocessors architectural changes superscalar issue modest effect processor energy delay product 
iii 
lower bound energy energy delay papers dramatic reductions power dissipation processors investigate lower bound energy energy delay product determine reductions accomplished represent large fraction potential improvements 
section investigate bounds looking idealized machines processor simple pipelined risc processor superscalar processor 
processors fundamentally perform operations 
fetch instructions cache information determine operands fetch register file operate data generate address fetch data cache store result 
operations sequenced global clock signal 
high performance processors sophisticated architectural features improve instruction fetch data cache bandwidth exploit instruction level parallelism 
perform basic operations instruction 
real processor course overhead 
example functional units run parallel correct result considerable logic needed control pipeline stalls exceptions 
overhead depends implementation sense essential functionality processor neglect 
operations outlined require reading writing chip memories instruction data caches register file 
steps requires computation 
aggressively assume energy cost performing computation zero assume communication costs datapath zero 
consider energy needed read write memories required energy clock storage elements program semantics require executed instruction 
second instruction depend executed simultaneously 
call instruction level parallelism 
gonzalez horowitz energy dissipation general purpose microprocessors fig 

pipeline diagram 
pipeline latches 
furthermore machines dissipate energy absolutely necessary 
processors perform operations speculatively hope result useful 
ideal machines perfect knowledge need speculative operations 
unwanted transitions glitches 
trace simulation estimate energy delay idealized machines 
detailed description simulation methodology please refer appendix 
machine models simple machine basic compute element similar dlx 
processor consists simple state machine fetches instruction fetches operands performs operation stores result 
processor pipelined model execution time assuming control transfer instructions cti take cycles alu operations take cycles cache operations take cycles 
machine pipelined assume energy dissipated clocking 
energy required read write caches register file taken consideration 
implementation lowest average energy instruction take advantage available parallelism relatively poor performance high energy delay product 
improve performance created pipelined processor similar previous pipelining exploit instruction level parallelism ilp 
instruction executed concurrently 
change energy delay product machine compared ideal due entirely pipelining 
traditional mips dlx stage pipeline shown fig 

possible build pipelined machine kind storage element addition energy required read write memories take account energy required clock latches pipeline pc chain 
ideal superscalar processor similar pipelined machine execute maximum instructions cycle 
concerned energy dissipated control logic instruction level parallelism significant sets amount parallelism exploited 
aggressive static scheduler torch gives comparable performance dynamic scheduled machine 
integer programs parallelism fill issue slots regularly assume machine supports conditional execution instructions directed compiler 
machine idealization torch machine described section 
difference energy delay product machine previous due ability execute instructions parallel 
comparison energy energy delay product fig 
shows total energy required complete benchmark 
numbers section normalized corresponding value superscalar processor 
expect machine lowest energy dissipation superscalar machine highest 
execution time shown fig 
reversed 
superscalar processor highest performance machine lowest performance 
explicitly shown time spent stalled due memory system 
fig 
shows energy delay product 
pipelining provides big boost performance little energy cost gives improvement energy delay product 
superscalar issue hand gives small improvement energy delay product 
performance gain small energy cost higher 
simple model processor wider parallel issue limited utility 
basic problem amount instruction level parallelism integer benchmarks limited effective parallelism small 
increasing peak issue rate increases energy operation ideal machine energy memory fetches clocks increase 
furthermore speedup superscalar processor limited amdahl law 
performance processor increases stall time larger fraction total execution time corresponding decrease energy delay product smaller 
show section overhead superscalar machine worse simple machine overwhelms modest gain energy delay product gotten parallelism 
iv 
current implementations see real machines compare ideal machines described previous section section looks processors designed simple risc machine superscalar processor call torch 
idealized machines earlier focused essential operations ignored sources overhead 
real processors include sources overhead 
simulation method described appendix 
shown simple optimizations yield significant gain energy dissipation 
careful design possible reduce reports amount ilp available typical integer programs 
studies realistic machines ilp severely limited cases smaller 
aggressive machines average number instructions issued cycles 
ieee journal solid state circuits vol 
september fig 

normalized energy ideal machines 
fig 

normalized execution time ideal machines 
energy waste considerably change critical path 
briefly discuss optimizations designs improvements observed 
compare results optimized real machines ideal machines previous section 
machine models simple risc processor similar original mips described kane includes chip caches 
processor stage pipeline shown fig 

processor similar ideal pipelined machine accounts energy required complete instruction includes overhead associated architecture tlb coprocessor 
difference energy delay product processor pipelined ideal machine represents limit possible improvements efficiency focus logic required execute instruction 
torch statically scheduled way superscalar processor uses stage pipeline shown fig 

torch supports conditional execution instruction directed compiler 
processor includes shadow state buffer results conditional instructions committed 
improve code density special nop bit indicate instruction fig 

normalized energy delay product ideal machines 
held cycle executed 
important programs parallelism keep datapaths busy improves instruction cache performance reduces number cache accesses needed complete program 
instructions encoded word packed main memory special format improves instruction fetch efficiency 
instructions unpacked written level instruction cache 
torch example smaller overhead compared aggressive dynamically scheduled processor 
due larger overhead processor higher energy instruction equivalent performance higher energy delay product 
energy optimizations additional energy associated particular architectural feature divided overhead waste 
consider overhead part energy eliminated careful design 
example adding additional functional units increase average wire length increasing overhead architecture 
sources energy simply designed away 
example pipelined design clock gating eliminate unwanted transition clock interlock cycles 
implementation reduce waste possible 
designer carefully weigh gains power dissipation versus cost complexity cycle time cost 
particular optimization causes large increase cycle time slightly energy running higher frequency may better 
techniques reduce waste implementations 
clock gating eliminate transitions happened 
implementation qualify latches datapath instruction produce result 
torch densely coded nop improve code density reduce number instruction cache accesses 
introduce extra instructions pipeline cause spurious transitions 
clock gating eliminate spurious transitions 
qualify latches main execution datapath 
latches tend gonzalez horowitz energy dissipation general purpose microprocessors fig 

reduction energy simple optimizations 
enabled infrequently 
example latches address translation datapath need enabled load store instruction instruction cache latches control sections qualified introduce clock skew 
control sections automatically synthesized fine control implementation clock gating 
power dissipated control sections small fraction total power clock power fraction 
qualify control signals prevent spurious transitions datapath buses 
instruction dynamically preventing datapath latches opening sufficient 
control signals datapath change cause spurious transitions datapath buses cause significant energy consumption 
clock gating saved approximately third clock power close total power 
latches datapath blocks enable signal 
reduce energy need enabling signal restrictive qualify latches control sections 
case improvements require larger effort provide smaller returns 
selective activation large reduce power dissipation 
obviously important step eliminate accesses caches register file machine stalled 
important eliminate accesses instruction cache instruction dynamically 
case instruction read previous cycle need reread cache 
doing saved approximately total power 
speculative operations commonly improve performance microprocessors 
example source operands read register file instruction decoded 
reduces critical path consumes extra energy operands may needed 
simple way eliminate waste pre decode instruction fetched second level cache store extra bits instruction cache 
bit indicate particular operand fetched register file 
energy required perform cache access strong function number bits accessed cost small 
fig 

normalized energy ideal superscalar simple risc torch processors 
designers dec chip similar idea 
second level cache kb way set associative 
reduce power dissipation cache tags accessed 
known bank data resident bank accessed 
reduces number accesses reducing power dissipation 
level cache refill penalty increases cycle 
idea reducing speculative operations taken far 
torch microprocessors computing pc usually critical paths 
machine determine branch taken perform addition compute branch target increment current pc 
remove adder critical path perform additions parallel outcome branch determined multiplexer select results 
energy save eliminating extra addition negligible cycle time penalty large 
designers carefully consider trade eliminating speculative operations 
fig 
shows energy saved simple optimizations section 
torch refers fully optimized processor 
torch disabled selective activation instruction cache speculatively read register file 
torch removed qualification clocks 
normalized energy torch 
simple optimizations save total power 
gains harder come show energy dissipated variety units accounts significant fraction total energy 
comparison ideal machines fig 
shows energy ideal superscalar machine simple risc machine torch 
figures sections normalized corresponding value torch 
expected torch requires energy execute program closely followed risc processor 
difference energy ideal machine torch represents potential improvements 
ieee journal solid state circuits vol 
september fig 

normalized execution time ideal super scalar simple risc torch processors 
fig 

normalized energy delay product ideal super scalar simple risc torch processors 
aggressive simulations expect gains smaller 
fig 
shows total execution time machines 
torch ideal superscalar machine identical execution models execution time 
superscalar processors speedup compared single issue machine 
ideal memory system speedup highlights importance external memory system low power applications 
fig 
shows energy delay product machines 
expected previous figures torch simple risc processor nearly efficiency 
super scalar issue provides small gain performance 
unfortunately increases energy cost instructions 
net result significant improvement energy delay product 
ideal super scalar processor roughly twice efficient real machine 
want understand torch approach ideal processor look extra energy dissipated 
energy breakdown chose divide energy dissipation categories 
energy dissipated reading writing fig 

energy breakdown ideal superscalar simple risc torch processors 
memories caches register file 
second category energy dissipated clock network 
third energy dissipated global interconnect nodes 
final category comprises previous categories 
fig 
shows energy breakdown machines simulated 
figures normalized total energy dissipation torch 
energy dissipated chip memories ideal machines implementations 
means successful reducing number unnecessary cache accesses 
clock power real machines slightly higher large amount state consider ideal machines 
storage element dissipates little energy sum total represents significant fraction 
global interconnect computation represent total energy 
important point graph improvements energy delay product hard come energy dissipated small units 
reduce energy significantly reduce energy small units 
shown performance energy processor related 
wide spectrum performance energy processors quite similar products 
shown main reasons 
processors perform similar functions 
important operations accessing chip memories clocking account large fraction total energy dissipation 
doubling energy dissipated combinational logic slightly change energy dissipation 
second pipelining provides large boost performance low cost energy 
architectural features significantly change energy delay product 
processors today pipelined expect similar energy delay product 
possible reduce energy requirements careful design provide time improvement 
shown easy implement gonzalez horowitz energy dissipation general purpose microprocessors optimizations energy reduced approximately 
improvements require sophisticated optimizations remaining energy dissipated small units account significant fraction total energy dissipation 
appendix simulation methodology sources energy dissipation cmos circuits static energy results resistive paths power supply ground dynamic energy results switching capacitive loads voltage levels 
static energy dissipation exists chip powered usually represents small fraction total energy dissipated chip idle large periods time 
ignoring static energy dissipation estimate energy dissipation number times th node toggles capacitive load node 
compute energy dissipation need accurately estimate capacitance toggle count node 
estimating energy dissipation blocks easier energy blocks dissipated pre charge discharge differential structures 
signals differential pair guaranteed discharge access energy dissipated independent actual data values read written 
approximate energy dissipated simply counting number read accesses number write accesses multiplying energy dissipated access 
estimate energy dissipation idealized machines simple trace method 
machines energy dissipated memories storage elements necessary compute toggle count capacitive load clock 
trace instructions executed compute number accesses memory total energy dissipated 
find clock energy determining capacitance single latch multiplying minimum number latches maintain processor state 
estimate energy dissipation simple risc machine torch accurately determine toggle count capacitance nodes 
developed complete verilog model torch includes main datapath instruction data caches coprocessor tlb external interface include floating point unit 
model stall take exceptions take external interrupts 
model run mips mode case behaves simple risc machine 
model estimate toggle counts capacitance node 
determine toggle count run simulated program verilog model 
written routines verilog programming language interface pli gather information 
pli routines traverse network determine total capacitance node 
gate diffusion capacitance annotated library cells 
written programs allow estimate wire capacitance standard cell datapath blocks 
estimate length global wires generating floorplan chip extracting layout 
performance energy dissipation processor depend test run decided compress jpeg spec benchmark suite 
representative traditional integer programs normally run processor 
second program representative multimedia type applications 
results applications similar terms performance energy show results compress 
compile benchmarks torch optimizing compiler mips compiler depending target machine 
horowitz techniques reduce power fast wide memories symp 
low power electr ieee oct pp 

mhz microprocessor ieee int 
solid state circuits conf feb pp 

watt compatible microprocessor symp 
low power electr ieee solid state circuits council oct vol 
pp 

mhz quad issue cmos risc microprocessor ieee int 
solid state circuits conf feb pp 

microprocessor multimedia support ieee int 
solid state circuits conf feb pp 

chandrakasan brodersen brodersen low power cmos digital design ieee solid state circuits vol 
pp 
apr 
chen burr plummer cmos technology scaling low voltage low power applications symp 
low power electr oct pp 

processor dynamic execution ieee int 
solid state circuits conf feb pp 

gordon 
meng low power subband video decoder architecture int 
conf 
acoustics speech signal processing apr pp 

hennessy patterson computer architecture quantitative approach st ed 
san mateo ca morgan kaufmann 
horowitz gonzalez low power digital design symp 
low power electr oct pp 

integrated device technology orion product overview mar 
jouppi wall available instruction level parallelism superscalar machines int 
conf 
architec 
sup 
programming language operating systems apr pp 

kane mips risc architecture 
englewood cliffs nj prentice hall 
pham specint specfp superscalar risc microprocessor ieee int 
solid state circuits conf feb pp 

smith support speculative execution high performance processors ph thesis stanford university stanford ca nov 
smith johnson horowitz limits multiple instruction issue int 
symp 
computer architecture boston ma apr pp 

wall limits instruction level parallelism int 
conf 
architec 
sup 
programming language operating systems santa clara ca apr pp 

yeung design specint risc processor ieee int 
solid state circuits conf feb pp 

ieee journal solid state circuits vol 
september ricardo gonzalez received electrical engineering stanford university stanford ca respectively 
currently working ph field stanford university 
research interests area processor architecture low power circuits 
mark horowitz received electrical engineering mit cambridge ma ph field stanford university stanford ca 
september working computer systems laboratory stanford currently associate professor electrical engineering 
research area digital system design 
led number processor design projects stanford including mips processors include chip instruction cache torch statistically scheduled superscalar processor 
worked number chip design areas including high speed memory design high bandwidth interfaces fast floating point 
took leave stanford help start rambus designing high bandwidth memory interface technology 
current research includes multiprocessor design low power circuits memory design processor architecture 
dr horowitz recipient presidential young investigator award ibm faculty development award best award international solid state circuits conference 
