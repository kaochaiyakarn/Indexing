information theoretic measures anomaly detection wenke lee dong xiang computer science department north carolina state university raleigh nc wenke csc ncsu edu unity ncsu edu anomaly detection essential component protection mechanisms novel attacks 
propose information theoretic measures entropy conditional entropy relative conditional entropy information gain information cost anomaly detection 
measures describe characteristics audit data set suggest appropriate anomaly detection model built explain performance model 
case studies unix system call data bsm data network tcpdump data illustrate utilities measures 
intrusion detection systems idss important component defense depth layered network security mechanisms 
ids collects system network activity data bsm tcpdump data analyzes information determine attack occurring 
main techniques intrusion detection id misuse detection anomaly detection 
misuse detection sub systems example idiot stat signatures known attacks patterns attack behavior effects identify matched activity attack instance 
misuse detection effective new attacks don known signatures 
anomaly detection sub systems example anomaly detector ides established normal profiles expected behavior identify unacceptable deviation possibly result attack 
anomaly detection effective new attacks 
new legitimate behavior falsely identified attack resulting false alarm 
practice reports attacks sent security staff investigation appropriate actions 
darpa conducted evaluation assess state art id research 
results showed best research systems detection rates percentages attack incidents correctly identified 
missed intrusions new attacks lead unauthorized user root access military network evaluation 
results darpa evaluation troubling 
improved capabilities added modules detecting attacks missed previous evaluation research idss detection rates new attacks new evaluation missed 
evaluations showed cutting edge id technology effective new attacks improvement slow little keep innovation sophisticated attackers 
research systems darpa evaluations leading commercial products employ mainly misuse detection techniques 
main reason deploying anomaly detection sub systems tend generate false alarms compromise effectiveness intrusion detection 
adversaries develop launch new types attacks attempt defeat deployed intrusion prevention detection systems anomaly detection key defense novel attacks develop significantly better anomaly detection techniques 
computing environments behavior subject user program network element observed available audit data logs 
basic premise anomaly detection intrinsic characteristic regularity audit data consistent normal behavior distinct abnormal behavior 
process building anomaly detection model involve studying characteristic data selecting model best utilizes characteristic 
due lack theoretical understandings useful tools characterizing audit data anomaly detection models built solely expert knowledge intuition imprecise incomplete complexities today network environments 
result effectiveness models limited 
seriously lot research anomaly detection intrusion detection general focusing specific ad hoc method specific environment 
research results contribute fundamental understanding field lend broader problem domain 
research aims provide theoretical foundations useful tools facilitate ids development process improve effectiveness id technologies 
propose information theoretic measures entropy conditional entropy relative conditional entropy information gain information cost anomaly detection 
measures describe characteristics audit data set suggest appropriate anomaly detection model built explain performance model 
case studies sendmail system call data sendmail bsm data network tcpdump data illustrate utilities measures 
rest organized follows 
section describes information theoretic measures 
section presents case studies measures build anomaly detection models 
section discusses limitations possible extensions current approach 
section compares research related efforts 
section outlines 
information theoretic measures section discuss information theoretic measures concepts covered texts information theory 
explain measures characterize regularity embedded audit data influence performance anomaly detection models 
outline procedure measures build anomaly detection models 
entropy entropy shannon wiener index important concept information theory communication theory 
measures uncertainty impurity collection data items 
definition dataset data item belongs class cx entropy relative jc wise classification defined cx log probability typical interpretation entropy specifies number bits required encode transmit classification data item 
entropy value smaller class distribution data pure 
example data items belong class entropy bit needs transmitted receiver knows outcome 
entropy value larger class distribution data impure 
example data items evenly distributed jc classes bits required encode classification 
anomaly detection entropy measure regularity audit data 
unique record audit dataset represents class 
smaller entropy fewer number different records higher redundancies say regular audit dataset 
high regularity data contains redundancies help predicting events fact events repeated redundant current dataset suggests appear 
anomaly detection model constructed dataset smaller entropy simpler better detection performance 
example audit data contains single event class user command dataset commands mail entropy single rule identify event ftp anomaly 
audit data contains event types entropy greater complex model needed 
conditional entropy definition conditional entropy entropy probability distribution xjy xjy cx log xjy joint probability xjy conditional probability temporal nature user program network activities need measure temporal sequential characteristic audit data 
definition collection sequences denoted gamma audit event collection subsequences conditional entropy xjy tells uncertainty remains rest audit events sequence seen events note subsequence 
anomaly detection conditional entropy measure regularity sequential dependencies 
case entropy smaller conditional entropy better 
example audit trail sequence events type conditional entropy event sequences deterministic 
conversely large conditional entropy indicates sequences deterministic harder model 
relative conditional entropy definition relative entropy probability distributions defined cx pjq cx log anomaly detection build model training dataset apply model test dataset 
datasets similar regularity anomaly detection model attain high performance 
relative entropy measures distance regularities datasets 
obvious smaller relative entropy better 
example relative entropy indicating datasets regularity 
conditional entropy measure regularity sequential dependencies relative conditional entropy measure distance audit datasets 
definition relative conditional entropy probability distributions xjy xjy defined cx pjq cx log xjy xjy anomaly detection smaller relative conditional entropy better 
information gain classification intrusion detection cast classification problem wish classify audit event belonging normal class abnormal class case anomaly detection particular class intrusion case misuse detection 
assuming classifiers anomaly detection models discuss regularity audit data influences performance anomaly detection models 
training dataset records defined set features record belongs class goal constructing classifier selectively applying sequence feature value tests dataset partitioned pure subsets target class sequence feature value tests conditions classifier determine class new record class known 
process records final subset considered belonging majority class subset record classification outcome 
obvious purer final subsets accurate classifier 
constructing classifier classification algorithm needs search features high information gain reduction entropy dataset partitioned feature values 
definition information gain attribute feature dataset gain gamma values jx jxj values set possible values subset value features low information gain classifier poor performance original dataset partitioned subsets large entropy impure 
anomaly detection intrusion detection general higher information gain features better 
regularity sequential dependencies directly anomaly detection model direct connection conditional entropy information gain 
example suppose classifier uses audit events classify predict normally nth event 
case events features nth event class 
features classifier simplicity discussion collapse single feature gain second term formula essentially conditional entropy length sequence length subsequence prefix 
model sequence smaller conditional entropy higher information gain better detection performance model 
model complex subject network need information pertaining current event sequential temporal information previous events 
conditional entropy feature construction process suggest features added feature set contains information current previous events 
example suppose timestamped audit dataset record defined timestamp feature duration current connection number bytes sent class label 
suppose service connection class want model service normally behaves 
strong regularity low conditional entropy sequence services combination service features add features express regularity 
way add features act place holders services previous connections fall time window connection record includes names previous services gamma gamma alternatively reduce total number features complexities model statistical feature past seconds percentage services current percentage different approximate regularity information 
showed temporal statistical features usually high information gain better model built features added audit data 
information cost intuitively information better detection performance 
cost gain 
intrusion detection define information cost average time processing audit record checking detection model 
include information increase data processing time increase model complexities 
needs trade detection performance cost 
example measure accuracy cost may determine optimal amount information model 
application anomaly detection information theoretic measures define anomaly detection general approach ffl measure regularity audit data perform appropriate data transformation 
iterate step necessary dataset modeling high regularity 
ffl determine model built achieve best performance optimal performance cost trade regularity measure 
ffl relative entropy measure determine model suitable new dataset 
section case studies illustrate approach details 
case studies section describe experiments university new mexico unm sendmail system call data mit lincoln lab darpa evaluation sendmail bsm data mit lincoln lab tcpdump data show information theoretic measures defined earlier build anomaly detection models 
case studies order simpler complex terms audit data 
unm system call data demonstrate conditional entropy determine appropriate length sequencing system calls construct anomaly detection models 
lincoln lab bsm data show conditional entropy determine including additional information obname improve detection performance 
lincoln lab tcpdump data show entropy partition network data regular subsets conditional entropy determine time window size temporal statistical features computed included anomaly detection models 
unm sendmail system call data ground breaking study forrest discovered short sequences consecutive system calls program normal executions consistent :10.1.1.47.6145
importantly sequences different sequences abnormal exploited executions executions programs 
concise database containing normal sequences self definition normal behavior program basis detect anomalies 
number follow studies example attempted alternative models variable length patterns classification rules neural nets hidden markov model original simplistic model database look fixed length sequences :10.1.1.40.1452:10.1.1.46.2976
alternative sophisticated models significant performance improvement original model 
believed sendmail system call data highly regular simple model suffice 
seen attempt study measure regularity exploit model building process 
noticeably original study forrest suggest means determine appropriate sequence length ad hoc trial error approach 
follow studies simply sequence length forrest case study attempt suggest model 
studied measure data regularity determine sequence length model built explain performance anomaly detection model works 
obtained set sendmail system call traces unm 
details data gathering process experiments data results :10.1.1.47.6145
trace contains entire sequence consecutive system calls run time process es 
sliding window size process system call trace set length sequences 
set dataset sequence data point 
compute conditional entropy measure regulatory dataset 
represent set length sequences set prefix subsequences length conditional entropy xjy measures regularity system calls determines nth system call 
details unique jxj number occurrences length subsequence gamma gamma gamma xjy jxj jxj log jxj jy shows conditional entropy normal trace window size varies increment 
trace plus queue models different kind configuration normal sendmail runs model traces separately :10.1.1.47.6145:10.1.1.47.6145
put traces form total dataset compute model 
mean simply average results individual traces 
see conditional entropy drops sequence length increases intuitively information included deterministic regular dataset 
see conditional entropy drops small values sequence length reaches forrest length original study 
small conditional entropy values suggest sendmail system call data nth window size conditional entropy training data bounce int bounce int queue int plus int sendmail int total mean conditional entropy training data window size misclassification rate training data bounce int bounce int queue int plus int sendmail int total mean misclassification rate training data sequence length entropy misclassification rate total total mean mean conditional entropy vs misclassification rate window size misclassification rate intrusion testing data bounce int bounce int queue int plus int sendmail int total sm int syslog local int fwd loops int fwd loops int fwd loops int fwd loops int fwd loops int misclassification rate testing data window size relative conditional entropy training testing bounce int bounce int queue int plus int sendmail int total mean relative conditional entropy btw 
training testing normal data sequence length system call accuracy cost estimated accuracy cost estimated cost total cost total estimated cost mean cost mean real estimated accuracy cost trade system call highly deterministic system calls 
discussion section build classifier system calls features nth system call class 
expect anomaly detection model detection performance 
normal trace training data testing data 
applied ripper typical classification rule induction program training data compute classifier tested testing data intrusion traces 
verify direct connection conditional entropy detection performance see section built classifiers 
shows misclassification rate training data 
shows comparison misclassification rate training data conditional entropy values scaled range 
misclassification situation classifier predicts item class actual class misclassification rate computed percentage misclassification dataset measures detection performance 
see trend misclassification rate coincides trend conditional entropy 
expected discussion section 
phenomenon conditional entropy plot considered estimated trend misclassification rate select sequence length detection model 
example detection performance care know length better better 
shows misclassification rate testing data 
see misclassification rates intrusion traces higher fact sequence length different ranges 
suggests range misclassification rate indicator trace normal abnormal intrusion 
practice ids reports anomaly misclassification rate trace high system call misclassified 
shows relative conditional entropy training testing normal data 
see relative entropy larger training testing normal datasets differs see discussion section misclassification rate testing normal data gets higher 
phenomenon suggests relative conditional entropy simply relative entropy training testing sets understand detection performance satisfactory discover testing set different regularity suitable model 
figures see longer sequence length better detection performance 
discussed section need consider information cost 
define information cost average time required processing audit record checking detection model 
results time measurement experiments verified pencil analysis cost linear function sequence length 
normally estimate cost building running model know data algorithm model 
suppose wish select sequence length build model optimal accuracy cost unit 
study ratio estimated accuracy minus conditional entropy cost sequence length 
shows ratios real estimated accuracy cost 
plots estimated accuracy cost versus sequence length match trend real accuracy cost select best sequence length want optimize accuracy unit cost 
mit lincoln lab sendmail bsm data unm sendmail data contains system call names 
interesting question building anomaly detection sendmail programs detection performance gain including additional information arguments object names studied regularity data find answer expensive trial error process building testing models 
bsm data developed distributed mit lincoln lab darpa evaluation experiments 
processed week bsm data extracted audit records sendmail sessions 
audit record corresponds system call sendmail 
addition system call name audit record contains additional information real length sequence conditional entropy conditional entropy outbound email length sequence misclassification rate bound email length sequence misclassification rate misclassification rate bound email length sequence relative conditional entropy length sequence accuracy cost mean accuracy cost trade sequence length system call estimated accuracy cost mean estimated accuracy cost trade effective user group ids obname name object accessed system call arguments sendmail bsm trace session 

represent system call name obname argument respectively 
experiments unm data know sendmail conditional entropy directly influences detection performance 
find including additional information help improve detection performance just need test results smaller conditional entropy 
tested alternative methods including obname denoted trace obname simply appended system call name second denoted trace obname treated equally important system call name sequence 
changed value obname system indicating object system directory user indicating object user directory 
transformation necessary full obname temporary file system user directory data irregular 
experiments sendmail traces computing conditional entropy training classifiers remaining testing 
directions sendmail runs bound bound data directions separate experiments 
exploit sendmail data compare detection models normal testing data 
figures legends denote system call data refer datasets system call combined obname mode denote data sets system call followed obname mode 
appendix refers training datasets refers testing datasets 
see conditional entropy decreases sequence length increases case experiments unm data 
addition datasets system call slightly larger conditional entropy added obname datasets slightly smaller conditional entropy datasets 
figures show detection models computed datasets added obname slightly lower misclassification rate better detection performance detection models datasets slightly outperform models datasets 
confirms direct connection conditional entropy detection performance 
comparing figures see bound mails testing data clearly higher misclassification rates training data bound mails phenomenon 
shows relative conditional entropy training testing datasets 
see bound mails smaller relative conditional entropy bound mails 
confirms relative conditional entropy indicative detection performance test data sets 
computed information cost experiments unm data 
estimated accuracy cost plots match trend real accuracy cost plots select best sequence length particular model best model 
plots suggest including additional obname shown improve detection performance trade accuracy cost considered better system call 
mit lincoln lab network data major challenge anomaly detection determine granularity subject 
example modeling user behavior need decide build separate profiles weekdays weekends weekdays finer time segments mornings necessary :10.1.1.33.1238
likewise network build models host service combinations 
proper guidelines tools remains ad hoc process 
studied measure regularity network data guide data partitioning equivalent subject refinement help feature construction model building 
tcpdump data developed distributed mit lincoln lab darpa evaluation experiments 
data contains simulated military network date entropy entropy host entropy service monday tuesday wednesday thursday table entropy network connection data consists hundreds hosts 
processed days tcpdump data modified version bro programmable ids robust packet filtering re assembly engine :10.1.1.116.8880
record describes connection features timestamp duration source port source host service destination port destination host source bytes number bytes source destination destination bytes flag summarizing hand shake behavior 
connection data day separate set experiments 
separated intrusions create pure normal datasets 
computed entropy irregularity normal dataset 
data point simply connection record timestamp removed 
order achieve high detection performance low false alarm rate dataset needs regular possible entropy small possible see discussion section 
entropy large try partition data set regular subsets 
table shows entropy original unpartitioned datasets subsets 
entropy partitioning average entropy values subsets 
see entropy values original datasets large 
implies build model dataset contains hosts services data may irregular model 
tried features select results subsets smallest entropy values 
destination host partitioning data host subsets 
see entropy significantly decreased means subset regular 
partition data service subsets entropy continues decrease dramatically 
note data partitioning process equivalent classification process see section reduction entropy information gain guiding principle 
previous showed introducing host service temporal statistical features count connections host current past seconds connection data significantly improve detection performance network models :10.1.1.33.1238:10.1.1.33.1238
develop means determine proper time window seconds computing features 
case study explored conditional entropy determine time window 
created sequences service destination host flag combination connection data follows sliding time window seconds step connection scan connection records fall past seconds regard current connection put services destination hosts flags short sequence 
set sequences compute conditional entropy sequence length subsequence prefix length uncertainty determine service host flag past services 
sequences different lengths due fact traffic volume time window constant computed entropy subset length sequences weighted sum entropy values entropy entire set 
different time windows increment seconds create sequences compute conditional entropy 
figures see general conditional entropy decrease window size grows 
intuitively information included smaller uncertainty 
see conditional entropy flag sequences low indicating normal dataset connections time window similar behavior regard network protocols normal flags error flags connection failures due network congestion 
length sequence destination monday tuesday wednesday thursday conditional entropy destination length sequence service monday tuesday wednesday thursday conditional entropy service length sequence flag monday tuesday wednesday thursday conditional entropy flag length sequence service destination flag monday tuesday wednesday thursday conditional entropy service destination flag window size misclassification rate test attack trace attack host partition attack host service attack test host partition test host service test misclassification rate normal data intrusion data previous time window constructed set temporal statistical features approximately capture host service sequential dependencies connections past seconds percentage destination host current percentage different hosts percentage normal flags percentage error flags added features connection records applied ripper build classifiers anomaly detection models :10.1.1.33.1238:10.1.1.33.1238
goals study data partitioning scheme entropy feature construction process conditional entropy affect performance detection models 
normal data training remaining normal data intrusion data testing 
factors determine dataset experiments derived original dataset partitioning host host service temporal statistical features particular time window compute add features 
datasets partitioning destination host connection class label host datasets service service datasets flag 
shows misclassification rates anomaly detection models constructed datasets 
window size means temporal statistical features added 
misclassification rates host models likewise service models time window averaged 
simply presentation plotted day averages 
see intrusion datasets higher misclassification rates ranges clearly separated corresponding normal datasets 
normal data models partitioned datasets better performance models datasets added temporal statistical features better performance 
note compared results experiments sendmail data relationship conditional entropy misclassification rate clear features added approximate sequential dependencies 
experimenting place holder method see section construct features directly represent sequential dependencies discussion section discuss advantages limitations 
illustrated case studies information theoretic measures characterize regularity audit data guide model building evaluation process 
experiments exhaustively computed models example different sequence lengths purpose showing relationship regularity detection performance 
understand relationship practice simply compute regularity dataset determine build model 
computing regularity general efficient computing model 
approach superior current adhoc expensive trial error practice guideline building model explaining performance 
false alarm rate important performance measure intrusion detection general anomaly detection particular 
believe probabilistic nature anomaly detection alarms post processed sporadic false alarms due inherent uncertainty data assume regular data filtered 
example sendmail data misclassification rate trace individual misclassification detecting anomalies 
likewise network connection data misclassification rate time segment anomaly detection 
believe anomalies single connection buffer overflow attack program destination telnet connection best detected models lower level data system call data note reviewers results case study preliminary 
continuing experiments report new results final version 
target program 
regardless alarms post processed model needs high accuracy normal data low misclassification rate 
say regularity audit data indirectly influences false alarm rate 
attempted explain reason certain regularity exists particular dataset 
motivation approach independent assumptions underlying computing environments aim develop general theories tools anomaly detection 
practice approach expert domain knowledge validate computed regularity 
shown relationship regularity detection performance model classifier 
probabilistic algorithms clustering bayesian modeling hidden markov model anomaly detection 
similar information theoretic measures algorithms 
fundamentally select best algorithm build model regularity data 
questions 
conjecture answers algorithms including classification information theoretic measures probability theories 
experiments regularity measure sequential dependencies conditional entropy fixed sequence length time window models 
shown variablelength pattern matching model sendmail data difficult built effective 
likewise variable time window network traffic load may improve detection performance 
naively conditional entropy plot estimate performance various sequence lengths time windows build multiple models different sequence lengths select appropriate models run time relative conditional entropy sequences run time training 
better approach build adaptive model dynamically adjust different length run time information 
extend approach facilitate construction models 
related anomaly detection important research area intrusion detection 
earlier systems normal profile user program usually statistical measures system features cpu usage number shell commands studies learning approaches applied build anomaly detection models system call data privileged programs 
lane proposed learning algorithm analyzing user shell command history detect anomalies 
algorithm attempts address concept drift problem normal user behavior changes 
emerald uses statistical anomaly detection modules monitor network resolver correlate alarms misuse anomaly detectors enterprise 
systems degree success developed particular kind environment 
fundamental question build evaluate anomaly detection model general adequately addressed 
result approaches developed studies may applicable environments 
researchers begun develop principles theories intrusion detection 
axelsson pointed established field detection estimation theory bears similarities ids domain 
example subject anomaly detection model corresponds signal source detection estimation theory auditing mechanism corresponds signal transmission audit data corresponds observation space cases task derive detection rules 
results detection estimation applicable wide range problems may ids domain 
key findings axelsson building detection model anomaly intrusion data needed ensure detection performance 
previous showed labeled training dataset normal intrusion connections build highly effective classifier intrusion detection :10.1.1.33.1238
practice difficult obtain intrusion data 
focus build anomaly detection models normal data available training 
key finding axelsson detection model optimized utility function necessary statistical accuracy definition cost 
independently began address build cost sensitive ids ids provides best valued protection 
related maxion relationship data regularity detection performance anomaly detection model studied 
study focused sequence data regularity defined conditional entropy 
key result experiments synthetic data anomaly detection model tested data range datasets varying regularity values detection performance varies 
suggests current practice deploying particular anomaly detection system different environments flawed reconsidered 
study confirmed finding showed expected detection performance attained relative conditional entropy training testing datasets small 
study extensive real system network audit data case studies importantly defined information theoretic measures showed build anomaly detection models 
proposed information theoretic measures anomaly detection 
entropy measure regularity audit dataset unordered records 
conditional entropy measure regularity sequential dependencies audit dataset ordered records 
relative conditional entropy measure similarity regularity measures datasets 
information gain feature describes power classifying data items 
information cost measures computation cost processing audit data anomaly detection 
discussed measures guide model building process explain performance model 
case studies sendmail system call data showed conditional entropy determine appropriate sequence length accuracy trade accuracy cost problem posed solved community 
showed relative conditional entropy low detection performance testing dataset comparable training dataset 
case study network data showed entropy direct partitioning dataset refining subject build better models 
showed evidence conditional entropy guide construction temporal statistical features 
preliminary especially case studies encouraged results far 
intended show despite need expert domain knowledge building ids theoretical understandings tools necessary possible 
may argue results obvious surprising feel important develop formal framework just stating obvious field intrusion detection progress rapidly rigorously 
remained explored 
conducting comprehensive experiments evaluations study extend information theoretic measures accommodate algorithms classification building anomaly detection models 
study determine best algorithm regularity data 
study build model variable sequence length time window 
anderson valdes 
generation intrusion detection expert system nides summary 
technical report sri csl computer science laboratory sri international menlo park california may 
axelsson 
preliminary attempt apply detection estimation theory intrusion detection 
technical report department computer engineering chalmers university technology goteborg sweden 
cohen 
fast effective rule induction 
machine learning th international conference lake ca 
morgan kaufmann 
cover thomas 
elements information theory 
wiley 
debar dacier wespi 
fixed vs variable length patterns detecting suspicious process 
proceedings esorics lncs 
forrest hofmeyr somayaji longstaff :10.1.1.47.6145
sense self unix processes 
proceedings ieee symposium security privacy pages los alamitos ca 
ieee computer society press 
ghosh 
study neural networks anomaly misuse detection 
proceedings th usenix security symposium august 
ilgun kemmerer porras 
state transition analysis rule intrusion detection approach 
ieee transactions software engineering march 
jacobson leres mccanne 
tcpdump 
available anonymous ftp ftp ee lbl gov june 
kumar spafford 
software architecture support misuse intrusion detection 
proceedings th national information security conference pages 
los alamos national laboratory 
wisdom sense guidebook 
los alamos national laboratory 
lane brodley 
temporal sequence learning data reduction anomaly detection 
proceedings th acm conference computer communication security 
lee 
data mining framework constructing features models intrusion detection systems 
phd thesis columbia university june 
lee stolfo 
data mining approaches intrusion detection 
proceedings th usenix security symposium san antonio tx january 
lee stolfo chan 
learning patterns unix process execution traces intrusion detection 
aaai workshop ai approaches fraud detection risk management pages 
aaai press july 
lee stolfo mok :10.1.1.33.1238
data mining framework building intrusion detection models 
proceedings ieee symposium security privacy may 
wenke lee wei fan matt miller sal stolfo erez zadok 
cost sensitive modeling intrusion detection response 
st acm workshop intrusion detection systems 
lippmann fried graf haines kendall weber webster 
evaluating intrusion detection systems darpa line intrusion detection evaluation 
proceedings darpa information survivability conference exposition january 
lunt 
detecting intruders computer systems 
proceedings conference auditing computer technology 
lunt jagannathan neumann javitz valdes garvey 
real time intrusion detection expert system ides final technical report 
technical report computer science laboratory sri international menlo park california february 
maxion tan 
benchmarking anomaly detection systems 
proceedings st international conference dependable systems networks 
mitchell 
machine learning 
mcgraw hill 
paxson :10.1.1.116.8880
bro system detecting network intruders real time 
proceedings th usenix security symposium san antonio tx 
porras neumann 
emerald event monitoring enabling responses anomalous live disturbances 
national information systems security conference baltimore md october 
shannon weaver 
mathematical theory communication 
university illinois press 

haystack intrusion detection system 
proceedings ieee fourth aerospace computer security applications conference 
sunsoft 
basic security module guide 
sunsoft mountain view ca 
forrest pearlmutter 
detecting intrusions system calls alternative data models 
proceedings ieee symposium security privacy may 

