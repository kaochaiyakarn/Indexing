parallel computational geometry approach randomization john reif sandeep sen july describe general methods designing efficient parallel algorithms problems computational geometry 
main focus pram provide strong evidence techniques yield equally efficient algorithms concrete computing models butterfly networks 
algorithms exploit random sampling randomized techniques result general strategies solving wide class fundamental problems computational geometry convex hulls voronoi diagrams triangulation point location arrangements 
description emphasizes algorithmic techniques detailed treatment individual problems 
appear chapter handbook computational geometry edited 
sack urrutia 
department computer science duke university durham department computer science engineering indian institute technology new delhi india 
quest faster methods computation coupled development vlsi technology tremendous growth research parallel computation 
objective reduce time complexity sequential algorithm processors working problem simultaneously 
seq denote best known sequential time bound problem size clearly parallel time complexity better seq number processors 
improve best sequential algorithm parallel algorithm executing parallel steps sequentially 
chapter stated parameter represent input size problem consideration 
major drawback area parallel computation lack consensus regarding ideal model parallel computation 
parallel machines mpp connection machine paragon maspar available commercially vastly different architectures play crucial role algorithm design 
ram model serves reasonable abstraction uniprocessor computers available today 
substantial amount research focused developing algorithms tailor specific architecture mesh butterfly hypercube interconnection networks 
algorithms specialized extent efficient implemented different architecture designed 
notwithstanding contributions algorithms clear need generality parallel algorithm research theoretical perspective need decrease dependence algorithms architecture 
objectives mind major amount research theory parallel algorithms developed parallel random access machine pram model 
model natural extension ram model ubiquitous 
pram model model identical processors execute instructions synchronously global clock parallel different data values 
processor identified unique integral label called processor id processors access common shared memory 
time step processor capable accessing memory shared local location executing logical arithmetic operation log bit words 
number processors usual ram model 
variations basic model depending resolution schemes memory access conflicts 
restrictive model exclusive read erew processors allowed read write simultaneously memory location 
concurrent read exclusive write model processors write memory location number processors allowed read memory location 
note constraints guaranteed algorithm designer 
strongest model concurrent read concurrent write model crcw number processors allowed read write simultaneously memory location 
reading destructive operation concurrent write models specify result memory location processor attempts write location 
arbitrary crcw model assume processors succeed writing value assumption regarding processor succeeds 
clearly processors try writing value simpler case processors trying write different values 
responsibility ensure correctness algorithm depend value gets written 
practitioner pram model may appear far reality especially problems regarding unbounded fan crew crcw models near impossibility synchronization large number processors time inconsistent physics real machine 
issues constitutes right parallel model subject continuing debate research community 
wish confuse reader offering views 
claim methods described general efficiently mapped reasonable parallel computation model 
imply algorithms perform parallel environment performance measured respect particular machine 
example known algorithm running dimensional mesh theoretically achieve performance butterfly machine number processors 
exact asymptotic time bound sense context fixed machine model 
illustrate point give implementations algorithms butterfly interconnection network achieve optimal performance architecture 
evidence generality number techniques exploited successfully efficient algorithm design bsp bulk synchronous parallel model initially proposed valiant rectify shortcomings pram model 
bsp model coarse grain parallel computing model considered closer reality explicit accounting inter processor communications 
algorithm design bsp model active area research interested reader referred papers goodrich relevant material chapter 
initial trends indicate successful algorithm design techniques pram carry bsp model nicely 
parts chapter shall crew model performance analyzed respect model significant loss generality observations previous paragraph 
addition shall assume single memory location hold real number infinite precision processor perform arithmetic operation involving real numbers single step 
consistent model sequential computational geometry called real ram 
model register memory location store real number arithmetic operations computed arbitrary precision 
shall randomization assume processors access log random bits constant time 
performance measures parallel algorithms parallelism intrinsic property problem problems admit greater degree parallelism 
degree parallelism imply speed sequential counter part obtained processors 
class nc refers problems obtain polylogarithmic running time algorithm polynomial number processors 
class rnc includes problems obtain algorithm previous property allowing randomization 
clearly huge numbers processors high degree polynomial problem may wasteful amount resources 
useful metric context processor time pt product 
ideally seq represent number processors time solving problem size shall pt subscript 
problems nc pt seq 
commonly agreed definition efficient algorithms pt seq log number parallel operations polylog factor best known sequential algorithm 
parallel algorithm called optimal pt seq 
chapter goal derive optimal algorithms simply nc algorithms 
typical sequential complexity problems tackled theta log cases able obtain log time optimal algorithm 
processors appear large situations implies problems linear speed linear number processors number processors known result justifies observation lemma slow lemma exists algorithm processors running time runs time processors proof follows observation processors emulate dp processors algorithm 
implies speed obtained decrease reducing number processors may fact increase get linear speed processors get linear speed processors 
studying relationship speed number processors determine profitable employ processors problem certain size 
randomized algorithms technique randomizing algorithm improve efficiency introduced independently rabin solovay strassen 
idea solve myriad computational problems successfully 
today randomization powerful tool design sequential parallel algorithms 
informally randomized algorithm bases decisions outcomes coin flips 
think algorithm possible sequence outcomes coin flips different algorithm different sequence outcomes coin flips 
randomized algorithm viewed family algorithms 
objective designing randomized algorithms ensure number bad algorithms relatively small fraction total number algorithms 
input show ffl ffl close fraction algorithms family bad probability independent input distribution 
types randomized algorithms literature algorithms produce correct output may run indefinite period running time random variable 
called las vegas algorithms run specified amount time output correct specified probability 
called monte carlo algorithms 
primality testing algorithm rabin second type 
error randomized algorithm sided sided 
consider randomized algorithm recognizing language 
output algorithm 
algorithms saying correct saying may produced wrong answer 
algorithms said sided error 
algorithms non zero error probability possible outputs said sided error 
performance measures randomized algorithms algorithms describe chapter las vegas produce correct results running time stochastic process 
predicted performance revolves able analyze random variable models running time performance measures 
ideal determine actual probability distribution random variable usually complex 
try bound various characteristics actual probability generating function expectation variance higher moments 
possible bound tails distribution function type probability random variable exceeds certain value note context worst case algorithm analysis mainly concerned upper tail 
just big function serves represent complexity bounds deterministic algorithms serves represent complexity bounds randomized algorithms 
notation say randomized algorithm resource time space bound exists constant amount resource algorithm input size probability gamma ff ff 
shall refer bounds high probability bounds 
known polynomial bounds 
possible bound tails higher probability gamma omega gamma called exponential bounds 
elementary tools analyzing randomized algorithms previous discussion bound probability algorithm terminate certain time 
discussion running time applies parameters 
may think failure probability failure algorithm terminate certain time 
randomization respect random numbers chosen algorithm failure probability expressed probability random numbers assuming certain sets values 
view events appropriate sample space failure probability expressed combinations set operations certain events 
events independent probabilistic sense analysis simpler probability conjunction independent events product probabilities events 
limited independence independence 
cases rely trivial upper bounds pr pr event sample space 
significance high probability bounds union polynomial number events succeed high probability succeeds high probability 
follows definition high probability bounds 
frequently tools probabilistic inequalities 
yield bounds tails probability distribution functions 
probability generating function gx nonnegative discrete random variable defined pr gx possible determine expectation variance higher moments 
celebrated chernoff bound bounds tail random variable gx 
generalized chernoff bounds pr gammax delta gx minimizing respect obtain fairly sharp bounds 
getting hold gx usually quite difficult inequality quite useful expectation known 
markov inequality pr delta chernoff bounds binomial random variables frequently design randomized algorithms parameters interest running time space random variables binomial distribution 
example assume run time algorithm binomial mean say run time algorithm high probability 
answer sufficiently large 
intuitively large area tail ends binomial distribution negligible 
chernoff bounds provide fairly tight estimates computing area tail ends binomial 
turns mean binomial random variable omega gamma probability greater gammaff ff constants omega gamma depend ff 
easier bound random variable corresponding running time known distribution analyze exact distribution 
definition say random variable upper bounds random variable equivalently lower bounds probability probability 
bernoulli trial experiment possible outcomes success failure 
probability success binomial variable parameters number successes independent bernoulli trials probability success trial distribution function easily seen pr gamma gammak angluin valiant gave sharp bounds approximating tail ends binomial distribution 
particular results summarized lemma chernoff bounds binomial parameters np integer pr np pr gamma ffl pnc exp gammaffl np pr ffl exp gammaffl np ffl 
general form inequalities known chernoff hoeffding bounds success probabilities bernoulli variables may different 
need chapter 
problems considered computational geometry stands today concerned design analysis geometric algorithms 
quite vast scope including problems data bases mathematical programming 
chosen fundamental problems usually serve computational geometry 
serve building blocks solving complex problems 
rely reductions algorithms versatile 
informal definition parallel reduction problem time parallel reducible problem instance solved algorithm problem subroutine parallel time processors 
sub routine invoked constant number times running time included 
words time algorithm problem implies time algorithm problem omega gamma time lower bound problem implies similar lower bound convex hulls convex polygons important objects computational geometry large number cases give rise efficient algorithms nice property convexity 
convex hull set points euclidean dimensional space smallest polygon containing points 
input set tuples output consists ordered set points convex hulls 
dimensions ordering simply clockwise counter clockwise ordering vertices convex hulls 
dimensions cyclic ordering edges convex hull vertex 
restrict dimensional case 
known sequentially takes omega gamma log operations construct convex hull dimensions exist algorithms matching upper bound 
voronoi diagrams general definition voronoi diagram edelsbrunner follows finite set subsets mapping positive real numbers call distance function set fp gamma voronoi cell cell complex defined voronoi cells subsets called voronoi diagram chapter confine case set points distance function metric 
subsets considered singleton points voronoi diagram versatile tool obtaining efficient solutions important proximity problems fundamental mathematical object right 
large number problems solved linear log time information contained voronoi diagram 
partial list includes closest pair set points plane determine pair points euclidean distance smaller pair points 
nearest neighbor points plane determine point closest 
largest empty circle set points find largest circle contains point interior center lies inside convex hull points 
euclidean minimal spanning tree set points find minimal spanning tree edge weights proportional euclidean distance points 
technique brown construction voronoi diagram plane reducible convex hull dimensions 
chapter describe algorithm computing convex hull 
triangulation visibility simple polygon self intersecting edges vertices triangulation involves adding gamma edges face triangle 
equivalent problem determining visibility vertex polygon determine edges edges vertex intersect vertical line drawn vertex 
optimal time triangulation algorithm subject research settled chazelle 
related problem trapezoidal decomposition non intersecting line segments necessarily forming simple polygon determine visible edges point vertical direction 
problem lower bound omega gamma log dimensional dominance problem reduced known lower bound omega gamma log 
called vertical visibility problem context sequential algorithms problem triangulation problem linear time reducible 
triangulation log log reducible trapezoidal decomposition yap 
note optimal reduction simple polygons triangulated faster trapezoidal decomposition arbitrary non intersecting segments 
point location planar sub division allowed preprocess query point determine quickly typically log sequential time subdivision point belongs 
sub division holes preprocessing time dominated time triangulate sub division 
elegant solutions kirkpatrick decomposed sub divisions hierarchy planar maps decreasing sizes 
determining intersections polyhedra dimensions 
arrangements arrangement hyper planes dimensions contains information connected regions space partitioned incidence relation regions dimensions 
arrangements fundamental combinatorial structures useful solving numerous problems including detecting degeneracy motion planning 
basic parallel routines section review parallel algorithms problems sorting selection basic parallel procedures frequently design geometric algorithms 
particular focus randomized algorithms simpler faster deterministic counterparts 
material section skipped loss continuity remaining chapter 
fact recommend reader familiarity parallel algorithms go directly section refer back results section necessary 
sections attempted develop algorithms scratch 
detailed treatment material section provide extensive bibliographic chapter 
omitted description complicated algorithms sub logarithmic time algorithms understanding important development subsequent geometric algorithms 
detailed description methods outside scope discussion 
parallel prefix computations elements semi group phi semi group operation required compute partial sums form partial sums computed time sequentially straight forward approach optimal pt product 
log time algorithm difficult derive binary tree cole vishkin obtained result lemma crcw arbitrary pram model prefix sum elements computed optimally log log log time 
list ranking related problem prefix computation computing prefix sums input linked list array 
linked list elements linear chain element degree degree identically elements 
special case determining element list distance head tail list 
position element list known algorithm prefix sum applied linked list prefix sums 
log time algorithm due wyllie known processors optimal 
result obtained independently anderson miller han cole vishkin 
lemma list ranking problem solved erew model optimally log time 
parallel sorting selection sequential algorithms sorting selection play important roles design parallel algorithms 
various basic parallel routines compaction processor allocation accomplished directly sorting 
see direct faster ways implementing 
sorting forms preprocessing step ordered searching searching performed domains ordered set points 
context deterministic pram algorithms parallel mergesort algorithm due cole elegant small constants 
drawback amenable network models 
known log time optimal sorting algorithms aks network reischuk 
reischuk algorithm randomization describe detail 
lemma erew pram model keys totally ordered set sorted log time processors 
algorithms refer sorting mentioned sorting algorithms changing running time constant factor 
development quicksort natural exposition algorithms subsequent sections 
parallel quicksort reischuk parallel adaptation quicksort algorithm nc keys chosen randomly key chosen probability keys called splitters sorted pairwise comparisons ranks computed easily 
done log time easily pairwise comparisons simultaneously constant time processor comparison 
splitters partition input keys nc intervals natural fashion 
key determine appropriate interval simple binary search processor key simultaneous reads 
algorithm called recursively parallel interval 
ignored task putting elements partition contiguous locations applying recursion properly shall discuss problem 
denotes size gamma th bucket claim lemma probability larger log gamma proof shall show key sample probability log away rank sampled key right gamma follows fact key chosen probability event happen probability gamma log large bounded probability happen element gamma consequently distance rank sampled elements log probability gamma lemma extended easily case number sampled keys general proof lemma extends easily bound interval sizes log lemma proved case 
discussion shall bound intervals size ffl ffl gammaffl gammaffl extra log factor subsumed exponent 
depth root size sub problem bounded ffl may helpful view algorithm tree node represents subproblem children represent recursive calls node 
example root represents procedure sort bn ffl children procedure calls size gammaffl log leaves tree represent problems size pre determined threshold say log fixed integer stage problem size small direct sorting procedure sort sort log log time adding factor log 
objective show leaf level procedures completed log time high probability 
suffices show particular leaf level procedure completed log time 
leaf node defines fixed path root leaf problem sizes successive nodes path decreasing 
denote node depth root problem size time taken claim proposition pr delta ffl cff log log ff integers constant 
proof previous claim comment previous paragraph pr ffl appropriately chosen constant ffl 
verify log time prefix sum repeat sampling ffl log time iteration sampling algorithm immediately conclude pr log log ffl log arrive required inequality 
resampling scheme guaranteed ffl log prove claim true strictly ffl log ffl log 
substituting value previous inequality obtain pr ffl log ffl log inequality implies pr bac ffl log bac ffl log bac lemma follows 
shall prove useful result theorem process tree property procedure depth root takes time pr log ffl gamma ffl cff log leaf level procedures completed log time 
proof setting ffl log nff gamma constant obtain pr ffl log gamma ffl cff log gammat total time worst case chain nested calls ffl probability exceeds log nc sum probability events log nc shall compute probability gammat gammat log log tuples 
pr log nc gammat log log log gamma log large values rewrite expression pr log gammaff gammac log gamma required bound pr gamma cff log gammac ff assuming larger 
selection focus primarily extremal selection choosing smallest largest element set jn general selection choosing th ranked element important problem right geometric algorithms 
known extremal selection takes omega gamma log rounds processors reasonable parallel computing model parallel computation 
show fairly simple constant time randomized algorithm exists selecting smallest element 
idea lemma focus interval contains smallest element 
choose set splitters randomly smallest element randomly chosen elements candidate elements minimum elements smaller denote set lemma size interval exceed log bounds ignore time processor allocation entire algorithm works time needed compute minimum elements processors equivalently computing minimum elements processors 
done easily time follows 
input keys 
group processors groups group processors 
group parallel computes maximum elements constant time 
done checking element larger element input processor pair special marker cell element accomplished time 
processor comparing writes concurrently marker cell finds marker cell written corresponds maximum key 
subsequently choose maximum maxima application previous strategy processors keys phase 
determining compress elements contiguous locations round previous algorithm 
fact approximately compressing empty cells suffices purpose 
discuss section 
load balancing processor allocation large number problems observed processor complexity reduced careful scheduling processors 
example consider problem computing sum elements 
naive algorithm start processors processors add numbers pairwise fashion 
letting pattern repeat log stages computation similar binary tree 
processor time product log exceeds sequential complexity factor log 
rectified simple modification start log processors compute sum log elements sequentially proceed previous algorithm 
adds factor log pt product asymptotically optimal 
result due brent observation formal statement lemma brent synchronous parallel algorithm needing time total elementary operations executed processors time br pc proof denote number operations executed ith step algorithm simultaneously computed time dr pe processors 
total running time dr pe br pc br pc observation useful may sight doesn take account time required allocate processors tasks step letting processor simulate fixed set processors previous algorithm may obtain efficient algorithm 
notice slow lemma stated earlier special case lemma 
example summation elements view processor simulate operations carried log processors naive algorithm 
task scheduling possible execution profile determined advance 
execution profile mean task carried processor time step 
cases scenario unpredictable 
determine total number operations simulating fixed set processors processor may distributing load evenly processors 
brent theorem assumes distribute tasks evenly processors achieve optimal running time 
shall consider special case parallel algorithm property algorithm log stages total number operations 
processors algorithm executes log time stage processors active know advance processor active particular stage 
processor ceases active stage participate subsequent stages algorithm 
claim claim algorithm run log time log processors crcw pram model 
scheme relies sub logarithmic time algorithm prefix sum 
log log stages log processors required 
slow lemma know log log log compute prefix sum optimal time 
stage algorithm log log new processor simulate log active processors 
distribute load uniformly stage associate tag processor going active tag 
find th active processor prefix sum 
new processor processor id simulate block log processors active th stage 
additional time needed re distribution processors log log levels scheme log log log log claim holds long problem size decreases constant factor necessarily proof follows lines 
important component recursive parallel algorithms actual divide step 
figuring recursive subproblems collate elements subproblem restore initial condition recursive calls 
division uniform predictable dividing input array median mergesort step trivial 
hand elements subproblem scattered unpredictably brought contiguous locations proceed recursion 
geometric algorithms develop deal scenario shall examine detail 
recall parallel quicksort important step 
natural way think problem associate integral labels certain range element subproblem elements subproblem unique integral labels 
problem size unusual labels exceed shall restrict case labels range 
special case constant number labels counting techniques previous section 
definition elements range place array size elements having label placed subarray size 
subarrays corresponding distinct labels overlap 
clearly accomplished sorting integer labels integer sorting 
definition allows flexibility exploited sub logarithmic algorithms 
describe method labels range log somewhat smaller 
assume know elements label array shall return problem discuss approximate counting 
done allocating subarray required size label placing elements appropriate subarray 
done parallel prefix sums compute boundaries non overlapping subarrays size requirements 
suppose elements having label overestimate elements label 
subarray corresponding label addresses 
element having label placed location 
call placement problem 
processors try place elements label location call collision 
restriction certain element having label placed difficult avoid collision 
ji delta chances collision 
formally elements placed random location probability collision case collision attempt place element 
expected number tries element gamma observation refined claim state proof 
lemma placement lemma log processors placement problem elements solved time arbitrary crcw model 
estimation approximate counting address problem estimating number elements having label explicitly counting labels specifically label want determine number upper bound number elements having label additionally 
describe method reduce problem explicit counting elements log sample element probability call set denote number elements having label 
obtained explicitly counting smaller 
dk max jd logn constant determined analysis 
dk log dk log suppose dk log easy see jd binomial variable parameters 
chernoff bounds see lemma equation imply ff exists pr jd ff choose cff gamma probability gamma gammaff chernoff bounds equation imply ff exists hff probability gamma gammaff dk jd log log log jd dn dk delta dn log may summarize observation manner useful 
lemma estimation lemma log examining fraction input elements labels compute high likelihood number elements label immediate utility lemma increasing processor efficiency parallel algorithms 
problem estimating number elements particular label reduced denote dg 
exact counting small fraction elements reducing number processors 
exact counting smaller number elements done efficient algorithms 
particular fast parallel sorting algorithms suboptimal 
refer reader bibliography chapter algorithms 
state result lemma elements labels range done log time log crcw processors 
randomized symmetry breaking application point location number parallel algorithms typical scenario processor choice local information apparently distinguish choices 
global perspective local choices properly coordinated quite disastrous 
consider problem identifying large independent set linked list elements 
recall independent set set nodes edge links 
large independent set imply set larger ffl delta constant ffl 
called fractional independent set fis 
know maximum sized independent set size choosing elements odd ranks ranks 
linked list ranked distances element known easy processor determine element odd rank 
locally difficult simultaneously element include 
inclusion exclusion implies neighbor excluded included 
sequentially simple procedure concurrent decision making symmetric situations causes complications parallel context 
consider method 
choose tag equal probability element denote sets elements tags respectively 
note expected size 
choose element fis linked list 

neighbors tags 
condition limits fis subset second condition ensures neighboring elements list chosen 
expected size fis pr fis pr fi fn ae fact element assigned tag probability 
procedure takes time processors erew pram basis simple optimal list ranking algorithm 
geometric algorithm planar point location crucial technique referred literature random mate 
point location triangulated planar maps planar straight line graph pslg embedding planar graph plane straight line edges 
pslg query point point location problem identify subdivision plane induced pslg contains query point 
addition assume pslg triangulated 
section shall describe efficient parallel algorithms triangulation assumption serious bottleneck 
pslg vertices optimal query time log space achieved elegant methods 
performance achieved binary search organized data structure constructed pslg preprocessing 
describe randomized method preprocessing done log time high probability processors triangulated pslg 
kirkpatrick proposed triangulation refinement technique builds hierarchy triangulated pslg initial graph 
review method help reader understand parallel version 
starting triangulated pslg faces including exterior face triangles algorithm removes independent set vertices remaining graph 
addition keeps track set eliminated triangles non empty intersection new triangles re triangulated graph 
procedure repeated successively left constant number triangles 
problem size reduced log 
search proceeds hierarchical manner top level problem solved constant time log time log size graph 
subsequently level relocate point respect triangles intersect triangle current level refining regions location level 
lowest level point located respect regions original pslg search terminates 
search data structure directed acyclic graph 
nodes represents triangular region connected directed arcs triangular regions intersects previous level 
node algorithm determines children point lies 
notice node parent graph underlying search structure necessarily tree 
efficiency approach depends number levels triangulated pslg number intersections triangle triangles lower level 
guaranteeing constant fraction vertices triangles planar graph eliminated successive level logarithmic level search achieved 
doing careful triangle intersects maximum constant number triangles level node bounded constant degree constant time spent search level 
criteria satisfied identifying independent set vertices having degree fixed constant 
number edges planar triangulated graph vertices edges respectively jv euler formula assuming exterior face triangle 
adds total vertex degree jv giving lower bound number vertices degree number vertices degree jv triangulated graph typical value 
constant fraction vertices eliminated stage identifying maximal independent set vertices height search tree log jv 
preprocessing time dominated identification independent set degree costs linear size pslg level resulting total time 
initial pslg triangulated cost triangulation dominates preprocessing time 
discussion randomized method identify large independent set constant time level processors high probability 
result search structure constructed log time 
associate processor vertex edge pslg 
euler formula need jv processors pslg 
independent set consisting vertices degrees equal identified generalizing random mate technique described previous section 
algorithm fis input pslg form doubly connected edge list 
output large independent set vertices degree 
identify set vertices degree done constant time processor vertex 
jv ignoring small constant vertices previous discussion 
phases randomly assign tag male female equal probability selected vertex step 
males constitute candidates independent set 
edge males pronounce vertices dead marking corresponding cells 
easily done processor edge concurrent write capability 
note easy get rid concurrent read feature vertex degree step carried constant number steps exactly step 
males dead form independent set 
output set males dead 
set independent set vertices having degree male female tags 
obvious algorithm gives independent set possibly smaller maximal independent set null set worst case chain males 
shall show average technique produce independent set proportional constant fraction total number nodes vertices degree high probability 
lemma jv denote number vertices degree equal shown earlier 
exist constants pr jx exp proof assuming equal probabilities vertex assigned male female tag probability vertex independent set greater equal neighbors 
consider independent set vertices distance shortest distance vertex set edges 
graph bounded degree selection vertex prevent selection dmax gamma gamma gamma vertices 
cardinality set max delta constant 
event vertex independent set independent vertex 
distribution cardinality independent set produced algorithm random mate bounded binomial distribution expectation ji jp np chernoff bounds see lemma equation ffl pr jx gamma ffl exp gammaffl gamma ffl ffl obtain required result 
shown high probability size independent set greater constant fraction key finding logarithmic depth search structure 
complete algorithm 
procedure point location tree number vertices stage log fixed constant halt locate query point log triangular faces log time single processor 
choose independent set vertices degrees method described 
time step 
triangulate remaining pslg removal independent set 
note removal vertex degree necessitates triangulating simple polygon vertices 
done constant time processor polygon 
addition adjacency list vertices incident edges removed inserted updated 
done time processor vertex 
determine new triangles created step old triangles intersects 
done constant time processor new triangles concurrent read 
increment go step 
theorem algorithm point location tree runs log time processors space crew pram model 
furthermore input pslg triangulated reduce processor bound log increasing asymptotic running time algorithm 
proof steps level recursion algorithm done constant time processors 
lemma exist constants probability reducing problem constant fraction high 
denote problem size number vertices remaining graph stage show log stages problem size log high likelihood 
lemma pr gamma gamma gamma gamma log constant probability fails hold level log gamma ffi ffi 
abort algorithm number vertices greater log stage re run entire procedure 
argument space similar sequential case 
input pslg triangulated number operations performed linear follows sequential algorithm 
slow technique processor bounds reduced log affecting asymptotic run time 
routines designers parallel algorithms investigating parallel algorithms achieved running time log 
mainly due lower bound omega gamma log loglog running time parity crcw model polynomial number processors 
exceptions extremal selection done constant time processors 
weaker models erew crew models log lower bound computing simple function bits polynomial number processors 
logarithmic time appeared natural barrier interesting problems including sorting prefix sums 
note sort elements array size parity computed constant time 
sorting considered fundamental problem idea time parallel algorithms considered fairly impractical sorting related problems 
attempts study parallelism stronger models parallel comparison tree pct operations counted comparisons 
example counting processor allocation accounted 
results better crcw pram pct model considered unrealistic designing algorithms primarily tool proving lower bounds 
situation crcw models changed dramatically slightly modified notion sorting called padded sorting defined mackenzie stout 
roughly speaking problem padded sorting involves ordering input size output array size close lower bound selection applicable 
crucial factor performance padded sorting algorithm size output array specifically ratio called padding factor 
surprising result state formally showed possible match bounds pct padding factors significantly 
tradeoff running time state slightly simplified version useful purpose theorem elements ordered universe sorted kn crcw processors log log time padding factor log log consecutive input keys empty cell output array 
speed implied theorem known optimal pct model 
nice consequence theorem ordered searching 
output algorithm directly applicable search predecessor key value 
simply probe elements normal binary search empty cell probed extra probe adjoining cell 
consequence theorem adjacent cells empty 
alternatively may simply fill empty cells contents preceding cell usual binary search 
holds true gamma ary search 
summary lemma output padded sorting algorithm performing ary search element ordered array log log steps 
algorithms develop sections depend critically sorting searching able results derive time algorithms spirit padded sorting 
note sorting accomplish basic parallel routines compaction 
efficient direct algorithms available tasks 
definition approximate compaction elements active problem approximate compaction find placement active elements array size 
definition interval allocation interval allocation problem non negative integers compute nonnegative integers starting addresses intervals size block size starting overlap block size starting 
ng 
interval allocation problem looked general method processor allocation 
integers represent processor requirement task interval allocation simply divide array equally processors ensuring load balancing 
constant hidden output array captures slow ideal load balancing 
result stated details algorithms 
lemma constant ffl problems interval allocation approximate compaction size solved crcw pram time log processors log space probability gamma gamman ffl alternatively done steps log processors 
random sampling polling computational geometry divide conquer certainly commonly technique designing parallel algorithms 
idea analogous sequential algorithm design original problem sub divided smaller subproblems solutions subproblems combined obtain solution original problem 
smaller subproblems solved recursively sub problem size smaller predetermined threshold 
stage direct usually brute force method solve 
analyzing procedure usually suffices write recurrence equation time complexity max predetermined threshold size ith subproblem complexity direct algorithm cost dividing problem recombining solutions 
number problems size largest subproblem size crucial determining running time algorithm 
equations processor space bounds written similarly processor complexity maximum number processors step algorithm 
trade number processors running time necessary write recurrence variables problem size number processors 
generalization procedure allow expected bounds possible write recurrence equation expected bound respect specific resource 
equation time bound associate distribution size largest subproblem solution expected running time algorithm 
exact distribution hard ascertain cases expectation known 
special forms solve probabilistic recurrence relations satisfactorily see karp 
cases general solutions hard obtain 
example parallel quicksort described previous section analysis proof theorem depended heavily tail estimates problem sizes 
context computational geometry sorting looked dimensional problem 
basic tools develop section enable extend techniques higher dimensional problems 
sense exercise viewed readers cautioned simplified expanding basic paradigm algorithms 
section techniques discussed general particular problem 
shall interesting applications section specific problems algorithms formally 
random sampling divide conquer mechanism partitioning problem random subset input 
recall quicksort input partitioned splitters randomly chosen elements input 
higher dimensional problems obvious splitters partition input absence linear ordering 
example concreteness consider problem constructing trapezoidal map set line segments 
segments partition plane regions may complicated shapes 
passing vertical lines point intersection regions get partitioned trapezoids triangles degenerate trapezoids 
vertical lines allowed cross line segments 
see illustration 
denote trapezoidal map set set trapezoids 
choosing random subset line segments ae clear partition natural ordering segments points line 
dimensional problem natural solution consider dimensional partitions induced example consider 
trapezoid consider restricted 
union contains relevant information 
recursively compute construct 
denote line segments intersecting trapezoid recursively compute 
earlier discussion bound crucial running time algorithm 
addition quantity important segment intersect implying quantity exceed represents blow problem size recursive call affect efficiency recursive algorithm 
case quicksort worry element belong exactly interval 
example consider problem computing intersection set half spaces dimensions 
adopt previous approach choose random sample half spaces construct intersection convenience assume non empty contains origin interior 
previous case regions analogous trapezoids 
thought difficult come sub divisions analogous trapezoids 
example pyramids formed joining origin vertex intersection 
technical reasons clear regions shall call ranges defined constant number input objects equivalently having constant size 
pyramid defined fairly large base corresponding face large 
subdividing bases parallel translates fixed plane restrict pyramid bases trapezoids triangles constant size 
intersection constructed recursively pyramids 
context denotes set half spaces defining half planes intersect pyramid 
previous examples reader intuition random sampling gives rise natural class divide conquer algorithms computational geometry 
difficult come suitable definition range context problem 
prove interesting results algorithms bound quantities 
crucial bound depth recursion determines parallel running time determine efficiency approach 
shall prove useful bounds quantities fairly general situations 
denote range setting range subset euclidean space defined appropriately context problem require range defined constant number input objects say bounds possible number ranges polynomial 
case trapezoidal maps reader verify 
denote jl referred conflict size 
note interested ranges range 
result gives bound random sample lemma jn random sample obtained choosing element independently probability max fl bounded log 
lemma uses sampling slightly different manner discussed previously 
seen easily jrj high probability bound hold random sample size exactly 
subsequent discussions distinguish sampling schemes 
proof avoid complicated notations required general situations prove special case trapezoidal maps 
extensions problems intersection half spaces problems considered chapter fairly straightforward 
reader refer clarkson mulmuley general proofs 
trapezoid partitioned disjoint classes segments intersect possibly boundary lie completely 
bound sets denoted log 
union vertical line points intersection points input segments jlj bound 
fixed line look ordered intersections line intervals induced sampled segments maximum size interval bound 
bounded log arguments identical lemma remarks 
bounding define trapezoid bad ffn log segments chosen probability bad gamma gamma delta ffn log ff number potential trapezoids segments 
trapezoid bad high probability ff 
implies bounded log event bad special case previous event 
argument hold 
number problems arguments complicated 
intersection half spaces similar argument applied segments joining origin vertex arrangement planes bounding input half spaces 
case bound number planes sampled plane starting origin 
bound improved direction probability max fl log log replaced log 
see details 
result bounds expected value 
lemma jn random sample obtained choosing element independently probability delta jh jh expected number ranges 
proof prove specifically trapezoidal maps extension problems dealt straightforward 
note segments complications segments lie exactly trapezoid jl jh omega gamma subsumed right hand side 
focus remaining proof denote segments stated 
union vertical lines points intersection points input segments 
fixed line look ordered intersections line 
associate random variable intersection represents number segments sampled segment upward direction 
corresponding random variable downward direction 
cardinality index set bounded polynomial care numbered 
segment sampled independently probability geometric distribution expected value inequality takes care case aren intersections holds number random variable law conditional expectation pr jh delta delta jh delta denotes expected size 
expected number trapezoids jh depends number sampled segments number intersections segments don know appear sample equation expected cardinality set 
claim follows trapezoid union 
independent linearity expectation delta jx claim written union proof point intersection point associate trapezoid containing trapezoid right lies boundary 
distinct shall show union claim follows 
arguments valid arbitrary point plane necessarily point 
arbitrary sampled segment downward upward directions respectively 
upper lower bounding segments vertical projections respectively 
set segments intersecting intersects vertical boundaries haven discovered 
segments intersecting union likewise segments intersecting union see illustration 
segments intersecting right vertical boundary bounded union point segment defines right boundary argument left boundary identical 
gives bound boundary 
improved walking boundary looking boundaries separately 
claim distinguished identical purpose geometric orientations 
proof hypothetical ordering way samples selected example coin tossing discover relevant trapezoid 
dependent order individual segments selected bounds dependent 
result lemma extended case interested higher moments 
unfortunately previous proof technique unable deal segments 
arguments apply situations elements intersecting range intersects boundary 
proof assumes 
true constructing intersection half spaces arrangement lines 
general proof reader consult bibliographic :10.1.1.125.6778
lemma jn random sample obtained choosing element independently probability delta jh trapezoidal map set line segments segments intersecting jh expected number ranges fixed positive integer independent 
proof proof lemma follows delta jh geometric distribution 
shown geometric random variable success probability th ordered moment gamma constant hidden fixed required bound follows 
bound useful situations algorithm performance expressed cf 
section 
converting expected bounds high probability discussed section probabilistic recurrence relation arising recursive randomized algorithm hard solve knowledge tail distributions 
parallel algorithm running time maximum resulting recursive calls sequential algorithm sum 
easier bound linearity expectations 
nice properties known maximum expected values appear depend tail estimates 
informal discussion motivation results obtained subsection claim way get problem bounding maximum expected values 
naive random sampling gives high probability bound maximum size subproblem lemma expected bound sum subproblems lemma 
restate results manner 
lemma suitable constants total max conditions hold probability sample input elements selected independently probability 
maximum size subproblem max log ii sum subproblems total delta jh 
proof lemma markov inequality choose total probability ii fails sum subproblems expected value 
choose max failure probability lemma sufficiently large 
probability ii satisfied 
additional conditions bounding higher moments hold probability argument 
sample satisfies required set conditions called sample 
consequence previous claim repeat sampling log times probability conditions satisfied samples gammat choose independently log sets samples high likelihood 
assume verification procedure verifies sample operations input elements 
determine sample run log times total log operations 
depending algorithm inefficient 
resampling efficient run fraction input samples 
example estimate size subproblem looking fraction input 
recall method lemma estimation lemma gives constant factor estimates estimate sum subproblem sizes 
describe method observation main difference bound estimate sides 
exposition describe special case trapezoidal maps problems arguments apply minimal modifications replacing trapezoids appropriate ranges 
choose delta log input segments randomly input segments fixed integer constant actual value determined required success probability algorithm 
number segments intersecting trapezoid corresponding sample log fixed integer greater determined success probability algorithm 
number segments intersecting log randomly chosen input segments sample 
clearly binomial random variable parameters delta log number trials probability success 
assuming greater delta log constant apply chernoff bounds tightly bound estimates constant multiplicative factor 
log input segments total number operations log random subsets bounded log delta log 
see section problems hand quantity 
note log easy case ffl delta log sample size ffl ffl 
formally invoking chernoff bounds ff ff function exists independent prob ffc log ff prob ffc delta log ff ff 
inequalities bounded log ff log ff 
appropriate choice constants condition holds high likelihood defined section simultaneously 
procedure simultaneously samples choose sample jo simple test procedure polling input samples rm log 
output sample jo notation actual number intersections denoted upper lower bounds obtained respectively 
denote total re jh 
clearly accept sample clearly bad sample bad choose best accept sample jo jo minimum 
jo lie interval guarantees jo delta constant 
recall earlier discussion samples satisfy conditions high likelihood 
summarize lemma polling lemma procedure polling obtain sample high probability naive random sample known probability 
verification procedure runs operations elements procedure uses polylog logn operations 
definition sample sum segments output polling algorithm larger factor strictly speaking needs modify definition accommodate extra factor clear succeeded objective choosing sample sum subproblems delta jh high probability 
procedure general situation need samples bound higher moments expectations known lemma 
randomized divide conquer tools techniques developed previous sections design general scheme parallel divide conquer 
random sampling achieve fairly partitioning problem analysis done various properties random sampling proved earlier 
illustrate general methodology problem computing trapezoidal map line segments intersect points 
parallel model crew mentioned 
trapezoidal map construction problem defined previous section segments non intersecting possibly points 
point want determine segment lying immediately 
problem called vertical visibility map particularly interesting close connection triangulation 
algorithm describe construct visibility map set line segments 
high level description follows algorithm vertical visibility 
select sample size ffl ffl constant determined analysis 
sample imply conditions lemma hold 
technique polling step efficiently 

construct brute force approach 

segment determine trapezoids intersects procedure describe shortly 
procedure verification algorithm polling step 

trapezoid apply clean phase called filtering discard segments 
show phase crucial bounding processor complexity 

predefined threshold call algorithm recursively solve problem directly assume suitable algorithm exists usually brute force method suffices 
look individual steps details 
procedures steps quite related 
ffl brute force method works 
endpoint draw vertical line order segments intersecting line sorting direction intersections suffices done log time processors point 
information determine segment lying immediate point 
compute easily segment points visible 
fact order vertical projections points sorting 
constructing individual trapezoids done walking vertices trapezoid successor information previous computation 
entire computation done log time ffl delta ffl processors 
partitioning problem determine segments intersecting trapezoid locus approach 
approach involves considering query higher dimensional point partitioning underlying space regions providing answer 
query problem reduced point location problem sufficient preprocessing time space 
problem hand involves preprocessing trapezoidal subdivisions induced sample manner points segment able list regions intersects log time dk log ne processors number regions intersects 
shall show preprocessing segments done log time processors fixed constant 
sample size suffice 
input segments non intersecting extend regions exists clear path intersect sample segment 
clear exist clear path regions 
objective partition plane regions equivalent classes fixed pair regions points segment lies regions segment intersects pre determined 
boundaries clear paths straight lines joining vertices trapezoidal subdivisions equivalent regions intersections half spaces defined boundaries 
need fast preprocessing procedure shall settle finer partition space pair partitioned region may intersect exactly set trapezoids 
size trapezoidal regions vertices 
produce boundary conditions straight lines joining pair vertices 
may intersect sampled segments boundaries clear paths doesn affect procedure partition fine see illustration 
lines intersect clear path regions segment points regions redundant partitioning affect asymptotic complexity algorithm 
vertices giving rise regions partition 
implies possible pairs regions points segment lie precompute pair trapezoids corresponding segment intersects processors log time 
point location problem preprocessing scheme proposed dobkin lipton 
result straightforward consequence 
lemma set line segments plane possible preprocess log time time processors point location query point done log time 
space needed 
proof merely mimic sequential algorithm 
computing possible pairs intersections time processors project intersection axis interval compute total ordering lines log time processors intervals 
space required 
point search locate interval binary search interval binary search lines totally ordered 
dimensions hyper planes preprocessed gamma processors log steps allows point searching log steps 
idea take intersections pair hyper planes project gamma dimension 
region gamma dimensional arrangement original hyper planes totally ordered additional binary search suffices inductively locating query point gamma dimensions gamma log steps 
processor space complexity grow claimed get squared level 
case corresponding linear constraints regions induced preprocessing trapezoidal regions interval finer partitioning regions induced lines 
finer regions require delta delta processors precompute possible intersections 
takes care possible placements endpoints segment 
region trapezoid choose sample point trapezoid precomputing part 
table corresponding pair regions containing trapezoids corresponding segment intersects 
input segment point location points perform search ordered pair regions 
clearly procedure requires constant number binary searches takes log time 
store number intersecting trapezoids entry allocate required number processors corresponding segment list intersecting trapezoids prefix sum 
segments belonging trapezoid packed contiguous locations application see section labels identify trapezoids 
clean processor bound recall sample implies total sub problem size constant factor delta jh 
case non intersecting segments jrj total subproblem size kn constant recursion depth total subproblem size bounded algorithm recursion depth log log total subproblem size omega gamma 
quantity related number processors wish bound 
achieved clean phase call filtering partitioning segments trapezoidal regions group segments categories segments part segments point region segments span region horizontally notice number segments type trapezoid completely ordered respect coordinate 
points type straight forward binary search suffices find nearest segments vertical direction 
consequently preprocess segments leave recursive calls 
total size subproblems level recursive call 
processor allocation achieved simply allocating processors region equal number points lying 
ensures algorithm require processors step 
analysis algorithm recursive shown step done log steps subproblem size processors 
total processor requirement exceeds reader verify time complexity depth satisfies preconditions theorem 
follows theorem algorithm vertical visibility executes log steps crew processors 
general strategy algorithm developed visibility maps previous section number problems modifications required context problem 
gives bird eye view approach 

sampling method polling choose sample satisfying certain properties holds constant probability naive sample 

partitioning computing subproblems sample 
step conjunction previous step verifying sample 
common partitioning method doing point location parameterized space 

filtering keep total problem size stage algorithm processor bounds pruning individual subproblems recursively solving 
step problem dependent depends geometric properties problem 

solve sub problems recursively size exceeds certain threshold 
illustrate approach context problem construction convex hull points dimensions 
convex hull shall solve dual problem intersection half spaces dimensions 
dual transformation maps point non vertical hyper plane vice versa 
point hyper plane vice versa hyper plane containing origin mapped point transform extended sets points hyper planes natural way 
convex polytope non empty interior assume origin contained infinite set hyper planes avoid convex region dual defined closure pos pos denotes half space containing origin 
observation verified lemma point belongs hyper plane avoids avoids int intersects int respectively 
words set points vertices convex hull dual transform facets intersection half spaces 
property exploited algorithm convex hulls intersection half spaces know interior point 
derive algorithm constructing intersection half spaces 
dual transform applications partitioning step 
remainder section shall assume half spaces described inequalities form 
shall terms half space bounding plane interchangeably clear context 
output list vertices polyhedron intersection half spaces 
vertices defined tuples intersecting planes defining vertex 
assume planes general position vertex intersection exactly planes 
assumption convenience analysis real bottleneck algorithm 
standard perturbation techniques simulates non degeneracy condition 
example changing coefficients sufficiently small real value chosen randomly satisfies property non degeneracy probability approaching 
textbook discusses symbolic perturbation techniques deterministic expensive 
edges polytope pairs vertices common planes tuples 
face defined tuples common plane 
tuple written ways permutation planes sorting possible representation vertices enable obtain faces edges necessary adjacency structure polytope planar graph 
observation useful constructing intersection random subset halfspaces split problem evenly 
lemma intersection set half spaces computed log time processors crew pram model 
proof assuming non degeneracy planes intersect common point candidate vertices output convex polytope intersection 
vertex test vertex convex polyhedron checking satisfies equations defining half spaces 
done trivially log time processors candidate point 
vertices survive 
determine faces convex polyhedron identifying planes contain vertices intersection 
necessary adjacency structure constructed application sorting 
algorithm derived general strategy context convex hull problem 
algorithm hull input set half spaces contain point output output convex polyhedron intersection half spaces 
choose random subset ae half spaces jrj ffl ffl ffl shall determine course analysis 
find intersection half spaces lemma 
take fixed plane cut face polyhedron parallel translates plane passing vertices example section 
face trapezoid 
partition trapezoid diagonal face triangular 
face consisting vertices consider pyramid formed apex base 
cr denote set pyramids 
note jc jrj 
remaining gamma half spaces find intersection planes bounding halfspaces pyramids 
note plane may intersect pyramid 
intersection half spaces union intersection half spaces intersecting pyramid pyramids 
cr fh restricted 
number planes intersecting pyramid pre determined threshold apply steps recursively pyramid set half spaces bounded planes solve problem directly 
recall section example problem ranges pyramids 
size bounds lemma hold respect number planes intersecting pyramid 
context lemma jh skeleton intersection half spaces planar graph jrj faces 
implies sum sub problem sizes sample 
polling conjunction steps achieve 
finding intersections quickly focus procedure find intersection planes pyramids shall locus approach solve problem 
case preprocess convex polytope sampled half spaces way plane able report list pyramids intersects log time processors number intersections 
shall show preprocessing convex polytope size done log parallel time processors fixed constant 
choose sample size processors 
problem precise value emerge analysis 
convex polytope dimensions size internal point apex pyramids polynomial number combinatorially distinct possibilities way plane intersect pyramids 
seen simple argument 
plane intersects polyhedron perturb plane changing pyramids intersects long remains fixed set bounding vertices 
illustrates situation dimensional case 
consider equivalence relation lines equivalent iff intersect sets pyramids equivalence classes correspond cells arrangement fd vertex convex gon internal point dual transform query line pyramids intersects defined partition belongs 
observation extended hold dimension case 
consider partitions space induced intersections constraining halfspaces equivalent classes respect pyramids intersect 
notice partitioning may minimal suffices purpose 
remains done precompute regions pyramids corresponding planes intersect query plane equivalence class list intersecting planes table look 
recall method lemma generalization entire preprocessing point location planes dimensions done space processors log time 
cells space precompute pyramids corresponding plane intersects processors choosing representative point cell testing pyramids 
note subdivisions finer minimal equivalence classes subdivisions set intersecting pyramids 
store number intersecting pyramids subdivisions listing number pyramids query plane intersects processor allocation easily log time prefix computation 
choosing jrj complete entire preprocessing required time processor bounds 
entire procedure takes log time 
filtering consider pyramid subscripts necessary 
denote set half spaces intersecting 
step goal identify half spaces contribute vertices 
discussion refer half spaces planes bounding half spaces 
planes intersecting categorize planes completely occluded plane part output planes occluded plane plane completely occludes planes contribute edge point points lie pyramids planes contribute vertex 
eliminate planes type variant maxima algorithm 
maxima problem defined set points dimensional space determine points point coordinates simultaneously exceed corresponding coordinates case point said dominate triangular base edges join apex sort intersections planes edge increasing distances apex 
repeat edges 
call edges denote intersection plane ranks sorted list 
observation plane occluded completely plane iff dominated ranks intersection edges plane gives effective strategy eliminating planes type identifying complement set maximal elements ranks intersection edges order relation 
log time linear number processors algorithm 
elimination step change asymptotic bounds algorithm 
may eliminate planes going recursive call improving performance practice 
identify planes type construct intersection convex polytope faces 
intersections faces convex polygonal chain 
referred contours discussion 
contours computed log time processors optimal convex hull algorithms 
note convex contours faces part output plane appears contour part final output denote set planes define contours complement nc 
consequently plane type 
unfortunately planes part output part contour 
consider plane chops portion polytope 
plane may contribute vertex convex polytope contributes edge hull 
case edge intersects exactly faces vertices labeled intersecting planes contributes output edge 
planes identified quickly sorting labels intersecting planes 
say plane nc contour generates ray originates closest point contour contained bounding planes defined point identified doing binary search vertices contour 
contour contain vertex choose ray plane defines contour 
observation ray generated nc contour intersect contribute vertex say plane nc pinned iff intersected rays generated contours 
convexity follows observation plane nc pinned 
previous observation follows need call algorithm recursively nc pinned 
number processors allocated basis potential number vertices 
calculated follows 
shall term flattening imply vertices contour projected edges intersection planes lie coplanar 
notice may planes 
just choose arbitrarily projected vertices defines base face 
wish ensure going recursive call sum subproblems output size 
define output size convex polytope jv number vertices convex polytope 
surface convex polytope connected planar map euler equation show jv jf gamma set faces polytope 
jf jv gamma 
calculation done property vertex degree follows assumption planes general position 
number processors 
distribute processors subproblems depending output size 
pyramid contain free edge output bound claim output size bounded gamma number planes contour contributing vertex number planes type 
proof denote number edges intersect contour contribute vertex vertices contour edges 
number edges lie including points 
number vertices degree consider planar map polyhedron formed planes base face flattening contour 
refer explanations terms base face flattening previous paragraphs 
number edges contour equals number vertices contour 
applying euler formula jv gamma number faces show part contour 
type bounded claim proved 
notice contains free edges formula applied separately partitions induced free edges 
participant planes partitions disjoint giving claim output size bounded gamma number free edges 
processor allocation strategy simply allocate number processors subproblem pyramid 
total number vertices pyramids bound maximum output size allocation strategy allocating processors proportional maximum output size pyramid 
note actual output size may shall fewer processors required maximum size achieved 
way look processor allocation strategy processors allocated edge output hull allocate processors pyramids contains potentially contain vertices associated edge 
free edges allocated processors 
sufficient number processors 
analysis hull algorithm previous subsections showed step algorithm done log steps subproblem size processors 
total processor requirement exceed processor allocation strategy 
theorem follows theorem convex hull points dimensions constructed log time crew processors 
constructing arrangements set lines arrangement contains information way plane partitioned connected regions lines 
known dimensions partitioned connected regions hyper planes connected region dimension points cells 
textbook edelsbrunner see bibliography excellent source discussion combinatorial properties arrangements 
construction imply representation incidence relation faces face dimension called face contained intersection gamma hyper planes 
considered planar graph vertices intersection points lines edges portions line consecutive intersections faces dimensional partitions plane 
constructing arrangement equivalent constructing representation graph 
easily done sorting intersections lines takes delta log steps 
sequential algorithms construct graph steps general dimensions 
outline parallel algorithm matches sequential bound 
technique extends naturally higher dimension description case 
simplicity assume lines common intersection 
differ slightly previous generic algorithm choose larger sample size number recursive levels constant 
consequently away filtering phase 
note lines arrangement constructed trivially log time sorting processors 
face arrangement convex range triangle obtained triangulating convex face joining bottommost vertex face vertices 
known bv triangulation 
deal unbounded faces assume intersections contained symbolic triangle appropriate size 
previous conventions denotes lines intersecting triangle cardinality 
algorithm follows algorithm arrangement 
choose sample log lines 
imply sample satisfies properties lemma addition 

find lines gamma intersecting range triangles corresponding 

log construct arrangement optimal sequential algorithm 

triangle log choose sample size delta log log random sample respect 
denote set triangles bv triangulation 

max fl ff log triangles obtained step construct arrangement lines gamma intersecting optimal sequential algorithm 

remaining construct arrangement lines intersecting directly sorting 
random sample size jh size lemma nr lemma 
polling select sample 
lemma log actual partitioning step carried sorting intersections log lines 
done log time log processors 
generally sample size done log time nr processors 
point know set lines gamma intersects face 
denote faces 
determine bv triangulation brute force method checking respect triangle face 
total done bounded gammar oe jf jf denotes size face gammar delta equality follows zone theorem bounds number vertices visible line jrj 
lemma partitioning lines faces induced subset lines done log time nr crew processors 
step done log steps processor triangle log triangles euler formula 
step partitioning done log steps delta processors lemma 
total number processors required delta delta delta log log log log log log log step follows equation 
property sample log log log slowing log log log time number processors reduced log log log log step takes log steps total bounded equations follow property sample respect respectively 
done log time log processors load balancing 
lemma applied constant ff pr max fl ff log resampling polling probability exceeds lemma 
step bound follows 
log probability sample respect log max fl ff log sample chosen 
probability sampling done log equation 
step done independently probability repeated log delta log triangles gamman log chernoff bounds equation 
equation log 
assigning log processors construct arrangement directly sorting log log steps 
total number processors required log step 
theorem arrangement lines plane constructed log steps log crew processors 

dispense polling algorithm processors steps step resampling respect entire input parallel 

practically algorithm extends optimally fixed dimension carefully choosing representation arrangements higher dimensions 
algorithms previous section described parallel algorithms trapezoidal maps convex hulls run log time high probability processors crew model 
time optimal crew model computing bits take omega gamma time 
concurrent writes log log steps kn processors theorem 
suggests may able speed previous algorithms faster parallel routines described section 
basic idea follows 
assume kn crcw processors integer sample roughly nk input elements partition problem 
earlier discussion maximum subproblem size nk ignoring logarithmic factor adjusted choosing slightly larger sample high likelihood 
constant processors solve problem constant time 
example vertical visibility problem determine processors point closest segments 
shall show step general algorithm partitioning polling filtering log log steps 
consider recurrence relation solution crux analysis algorithms 
represent parallel running time input size processors 
nk nk nk nk log log constants larger 
recurrence arises property algorithms nk maximum subproblem size nk processor advantage easily verified induction solution recurrence appropriate stopping criterion log log 
technically deterministic solution recurrence directly purposes bounds probabilistic 
technique extension solution described proof theorem 
view algorithm tree root represents problem size internal node subproblem 
children node represents sub problems obtained partitioning node random sampling leaves represent problems solved directly resorting recursive calls 
denote time taken node depth root lemma suppose pr log log gammaffl log constants ff positive integer 
leaf nodes tree representing algorithm terminate steps prob ff log log gammaf ff constant 
proof lines theorem omitted details 
describe modifications required generic algorithm obtain faster running time look individual problems 
speeding range generic divide conquer approach described section partitioning step speeded padded sorting faster way searching lemma 
locus approach lemma obtain generalization 
lemma hyper planes dimensions data structure point location constructed delta log log time delta gamma processors 
data structure point location delta log log steps processors point 
basic procedure resampling polling inherently parallel samples tested concurrently 
fact dispense polling omega gamma processors test entire input sample 
similarly filtering redundant log constant observation algorithms recursive depth log log constant factor blow implies bound 
critical issue processor allocation 
recall common scenario algorithms 
suppose number subproblems input elements subproblems tagged index sorted indices array size previous theorem sum sizes subproblems 
processor indexed associated element cell numbered dp se cases kn processors number processors allocated subproblem size delta 
processor advantage defined ratio number processors subproblem size initially purposes little difference property number recursive levels algorithm bounded log log 
processor advantage depth recursion worse log log omega gamma 
discussions shall implicitly property processor allocation 
trapezoidal decomposition triangulation modify algorithm vertical visibility substituting routines partitioning processor allocation 
filtering step recall basically involves discarding segments span entire trapezoid 
basically compaction done dlog gamma log ke time lemma log log 
follows theorem trapezoidal decomposition non intersecting segments constructed log log steps kn crcw pram processors 
convex hulls voronoi diagrams identical approach works algorithm hull 
filtering step essentially locating half spaces pinned pyramid 
find closest point contour half space ary search sorted vertices contour 
clearly done log log steps 
compaction discard redundant half spaces pyramid 
mentioned previously maxima routine dispensed affecting asymptotic bounds 
theorem convex hull points dimensions constructed log log steps kn crcw pram processors 
note output algorithm produces list vertices array slightly larger size 
compute adjacency information edges require application integer sorting 
avoid ceiling floor functions clear context sorting done list tuples planes intersecting point permutations corresponding tuple 
adjacent tuple planes common define edge 
consequence lifting transformation obtain similar bound voronoi diagram 
output list voronoi vertices adjacency information 
lower bounds gauge efficiency algorithms described previous section prove matching lower bounds related model computation 
material subsection read independently rest chapter 
model computation parallel analogue bounded degree decision tree model bdd tree 
node tree processors compares value fixed degree polynomial 
accordingly processor gets sign gammag depending result comparison respectively 
subsequently algorithm branches sign vector considering signs processors 
algorithm terminates reach leaf node containing final answer 
polynomials restricted form gamma parallel comparison tree pct model 
cost branching includes processor allocation read write conflicts arithmetic instruction set pram model 
strictly speaking incomparable pram model 
notably known geometric algorithms pram model exploit extra power lower bounds bdd tree regarded binding pram model 
note comparison tree model meaningful computing model problems geometry convex hulls inherently involve polynomials degree greater 
prove worst case bound lines ben subsequently extend average case 
number leaves related number connected components solution space dimension solution space input size 
arity tree number distinct outcomes computations performed processors 
additional complication bdd tree model leaf node may associated connected components solution set know jw number connected components need lower bound number leaves 
tackles bounding number connected components associated leaf results milnor thom 
result shows conditions worst case sequential lower bound omega gamma jw 
parallel bdd algorithm uses processors signs polynomials computed simultaneously 
test yields sign branch sign vector obtained tests 
shall result number connected components induced fixed degree polynomial inequalities due pollack roy bound number feasible sign vectors lemma number connected components nonempty realizations sign conditions polynomials variables degree bounded bm gives bound arity parallel bdd tree model number connected components associated leaf node depth number polynomials defining space leaf node depth hp number connected components associated node context number processors polynomial signs computed stage bound kn dimension solution space approximately size input 
example dimensions point input consists real numbers corresponding coordinates considered point euclidean dimensional space 
gives theorem theorem ae set jw connected components 
parallel bdd tree algorithm decides membership kn processors time complexity omega jw log 
proof length longest path tree lemma hn delta jw constant subsumes degree polynomials 
expression left hand side represents maximum number leaves second expression maximum number connected components associated leaf depth simple manipulations hn log arrive required result 
theorem immediately yields corollary omega log worst case bound number problems jw holds slightly modified version previously convex hull identification problem objective determine set points points belong convex hull 
note version constant time reducible standard version crcw pram model processors 
corollary algorithm parallel algebraic decision tree model constructs convex hull points kn processors requires omega gamma log rounds 
clearly similar bound holds sorting real numbers strengthens lower bound pct model 
corollary parallel algebraic decision tree algorithm requires omega gamma log steps sort numbers kn processors 
extend result average case require technical lemma generalizes property balanced trees balanced tree leaves achieves minimum average height trees leaves 
extend property balanced trees case leaf node depth weight associated integer significantly arity tree 
arity tree maximum number children node 
total weight tree sum weights leaf nodes 
previous property viewed case leaves unit weight 
lemma tree attains minimum average height trees total weight weight function defined balanced tree 
proof proof approach 
start balanced tree height weight avoid unnecessary complications assume required form justify doesn affect arguments 
shall show unbalanced tree weight larger average height 
unbalanced tree weight leaf nodes depth greater depth node distance root 
leaf node depth corresponding subtree gammai leaf nodes depth arity tree 
match weight weight loss compensated leaves depth greater way view leaves depths corresponding sub tree missing weights leaves depths greater precisely leaf depth weight gammai delta gamma group leaf leaves depth attain weight 
notice groupings leaves depth groups overlapping node depth greater may compensating fractionally group 
remainder proof shall show average height group exceeds imply lemma 
leaves height 
compensating height fractional 
weight compensation delta delta delta gammai delta gamma want show delta rearranging delta gamma gamma suffices show maxfc gamma maximum clearly gammai deltah gammai gamma clearly average height group exceeds consider gamma 
gammai delta gamma gamma gamma gammai inequality written gammai delta gamma gamma gamma minimizing gamma maximizing gamma gamma respectively gammai delta delta gamma gamma gamma delta gammai gamma delta sufficiently large arity ek gamma context parallel algebraic decision trees arity ek bound number leaves bdd tree omega gamma jw average height 
yields bound similar previous theorem 
theorem ae set jw connected components 
parallel bdd tree algorithm deciding membership kn processors average time complexity omega jw log 
consequently randomized algorithm worst case time complexity 
jw dimensional convex hull problem average running time omega log time 
sorting dominance problem bounds hold 
simple reduction dominance trapezoidal decomposition obtain similar bound problem 
geometry fixed connection machines motivation overview previous sections described fairly general methods parallelizing algorithms pram environment 
process number basic problems recognized sophisticated techniques developed viewed tool kit tackling increasingly complex problems 
general consensus pram models appropriate algorithm designer algorithms implemented fixed connection networks practical significance 
known general purpose emulation schemes algorithms implemented run butterfly hypercube network log multiplicative factor degradation time complexity 
crucial question pram algorithms extended fixed connection networks logarithmic penalty running time 
top approach algorithm design complicated algorithms built top complex procedures 
answer question depend far hierarchy go running problems mapped optimally network 
depend nature algorithm 
basic problem hierarchy sorting 
example reischuk log time processors randomized pram sorting algorithm successfully extended networks reif valiant run log time additional new sampling techniques problem size control 
contrast cole deterministic log time parallel mergesort algorithm prohibitively difficult implement logarithmic slowdown networks liberal pointers 
consequently number algorithms approach pram models difficult adapted network models 
eventual goal develop efficient algorithms interconnection networks reader view general context mapping certain kinds pram algorithms fixed connection networks difficulties associated 
section term fixed connection network networks log diameter node networks 
exists large body literature geometric algorithms grid networks diameter bottleneck achieving kind time complexity aiming 
underlying problems doing binary search optimally model allow concurrent reads 
common scenario tree leaves represent intervals keys determine interval key lies 
depth tree trivial sequentially nd time 
case pram models allow concurrent reads problem quite simple 
processors simultaneously search keys parallel time resulting optimal speed 
main difficulty associated problem stems possibility keys may unevenly distributed intervals 
recall partitioning step generic algorithm point location arrangements parameterized space 
additional problem allocating sub problems sub networks recursive calls 
pram models network topology imposes severe constraints processor allocation number processors match sub problem sizes inter connected certain manner 
ideas similar splitter directed routing route keys appropriate sub networks 
may confronted situations dynamically allocate resources sub problems varying sizes 
cases possible near optimal solutions problems applications wide class algorithms 
basic procedures serve crucial link pram algorithms inter connection networks 
remaining section briefly sketch method implementing generic divide andconquer strategy context trapezoidal maps non intersecting line segments 
omitted details outside scope main focus 
details network implementation reader encouraged consult bibliographic 
model computation section butterfly inter connection model processors operate synchronous fashion bounded buffer size 
assumptions consistent existing machines bbn butterfly connection machine 
step processor allowed perform real arithmetic operation consistent standard models sequential geometric algorithms 
processor access generator returns unit time truly random number log bits 
primary reasons choosing butterfly network nice recursive nature 
butterfly network size referred bf levels nodes nodes 
node address see 
significance network numerous copies bb bb shall crucial fact 
fact jw jw gamma subgraph bf spanned nodes ww jw jw jw isomorphic bf may emulate larger butterfly preserving fashion 
simple result 
fact bb emulate bb slowdown positive integer 
similar brent slowdown lemma construct mapping processors bb bb respecting interconnection topology 
case straightforward 
assume map processors addresses xw jwj 
verify processors bf neighbors neighbors smaller network 
processor smaller network twice amount require twice amount local memory 
processors rank extra emulating processors rank 
scheme extended directly yield claimed bound 
fixed implies constant factor slow 
algorithms scheme value 
overview sorting routing fixed connection networks algorithms sorting routing extensively various stages brief review routines help understanding algorithms built 
problem packet routing involves routing message processor pi pi permutation function 
long rich history routing algorithms fixed connection networks see summarized lines intersect different set sectors 
dual plane duals lie different faces case separated dual vertex 
butterfly network size 
solid lines illustrates sub network isomorphic bf lemma exists algorithm permutation routing node butterfly network executes log steps uses constant size queues achieve running time 
general result proved maggs layered networks 
layered network nodes assigned layer numbers edges connects layer node layer node butterfly example network 
denote maximum distance traveled packet largest number packets traverse single edge called congestion network 
parameters fixed selection paths packets routed 
exists scheme scheduling movements packets high probability routing completed logn steps size network packets routed 
result fact log path selection strategies especially butterfly network remains bound value get bound routing time 
packets routed random location bounded log high probability 
optimal log time sorting algorithm called butterfly network due reif valiant 
pram sorting algorithm due required additional techniques constraints imposed network connectivity 
slightly simplified version 

select ffl ffl size random subset set keys 

sort simple method doing pairwise comparisons ranking 

keys set binary tree leaves tree correspond intervals defined pair consecutive splitter keys 
sampling techniques ensure intervals partition remaining keys roughly equal sized subsets 
eliminates need dynamic load balancing special case sorting 
keys assumed random locations initially 
subset sub network appropriate size set aside keys belong subset routed part network 
done procedure called splitter directed routing referred sdr 
useful operation describe details 

steps applied recursively size subproblems log original analysis showed log buffer size may required results routing enables constant amount storage buffer 
splitter directed routing set cn keys totally ordered relation 
set nodes network 
suppose set splitters sigma size sigmaj gamma 
index splitter oe sigma distinct binary string length oe denote ordering defined follows oe oe 
require oe oe oe assume copy splitter oe available node 
set nodes rank jwj addresses prefixed reif valiant 
empty string 
initially assume keys located nodes having stage 
splitter directed routing tree executed temporarily overlapping stages gamma 
set keys eventually routed defined recursively 
splitter oe partitions gamma oe disjoint subsets fx jx oe fx jx oe subsequently routed respectively 
case assume recursive call sub networks varying sizes corresponding different subroutine calls relabeled isolated networks 
defined accordingly 
time analysis procedure carried delay sequence argument shown takes log time bf need generalization result theorem process tree modified manner 
sub routines node proceeding independently subroutines fixed constant depth subtree required finish proceeding level subtrees 
reduced previous case contract subtree fixed depth see single node tree 
appropriate adjustment constants prove result lines theorem 
single node contract contracting subtrees fixed depth get tree satisfying preconditions lemma corollary leaf level procedures modified tree terminate log steps 
binary search concurrent reads frequently encountered problems case sequential parallel algorithms doing binary search tree structure 
particular binary tree depth log leaves represent certain intervals keys processor key locate interval key belongs log parallel time key simultaneously 
problem trivial model allowing concurrent reads 
problem complicated concurrent reads permitted model case interconnection networks 
simple algorithm uses concurrent reads inherent fashion situations distribution keys known problem appears formidable see paul 
note certain cases intervals keys chosen total ordering problem reduces merging done efficiently 
concerned cases intervals may induce ordering different ordering keys see 
points different relative orderings expect segments shall look special case number leaves ffl ffl search tree roughly balanced depth log 
basic strategy 
try get reasonably accurate estimate number keys associated leaf nodes 
allocate appropriate number sub networks estimate 
route keys destination sub networks scheme similar splitter directed routing sdr 
solve problem recursively sub network 
omitting details summarize follows 
theorem binary search tree leaves binary search keys log time butterfly network processors 
applications computational geometry searching arrangements focus attention problem 
arrangement fl lines fl want find points region belongs 
particular log time butterfly network 
problem useful locus partitioning 
result binary searches butterfly network obtain result 
omitted details loadbalancing processor allocation scope discussion 
theorem points plane arrangement lines points face containing point determined log time node butterfly network 
trapezoidal maps trapezoidal decomposition sample line segments build convex map 
build brute force approach 
segment point order line segments coordinates 
segment order projection points visible bottom top 
information construct trapezoids simulating pointer jumping fixed number times 
lemma trapezoidal map ffl segments segments constructed log time ffl processor butterfly network 
remaining segments part sample partitioned subproblems defined trapezoidal map 
partitioning step trapezoidal decomposition reduced problem searching arrangements linear constraints dimensions see section 
faces arrangement preprocessed point location table look determine answer 
case set trapezoids segment intersects 
various length done little care 
number trapezoids determined just number appropriate number processors delegated responsibility determining actual trapezoids 
allocation done help prefix computation 
subsequently processor table look 
table look done emulating single step crew pram log steps 
filtering step need keep track parts segments completely span trapezoid 
segments trapezoid processed binary search points lying trapezoid quickly determine closest visible upper lower segments 
done log time algorithm section 
segments partially completely lie trapezoid needed recursive calls 
stage keep track point closest upper lower segments trapezoidal edge 
information decompose simple polygon sided monotone polygons see 
accomplished application sorting prefix computation goodrich 
yap technique calls trapezoidal decomposition sided monotone polygons enables determine triangulation edges 
procedure follows 
step construct horizontal trapezoidal decomposition sided monotone polygon vertex determine edges polygon horizontal line line contained polygon 
assume distinguished edge polygon monotone horizontal 
step denote left visible edge right visible edge ae denote vertices respectively lower altitude 
step set edges fv form triangulation polygon 
trapezoidal decomposition enables solve problem determining visibility set non intersecting line segments projected orthogonally 
sort points line segments projected direction choose point say mid point interval 
points determine trapezoidal edge trapezoidal decomposition algorithm described 
state main result section 
theorem exist algorithms problems trapezoidal decomposition triangulation simple polygons visibility execute time log processor butterfly network input size problem 
similar methods implement algorithm dimensional convex hulls lines hull algorithm described section 
fact filtering step simpler 
theorem convex hull points plane constructed log node butterfly network bounded buffer size 
bibliographic notes random sampling introduced parallel computational geometry reif sen time seminal papers clarkson haussler welzl 
papers clarkson haussler welzl exploited ffl net property partitioning problem random subset 
subsequent papers clarkson clarkson shor refined techniques considerably developed general elegant techniques designing geometric algorithms randomized divide conquer randomized incremental construction :10.1.1.125.6778:10.1.1.125.6778:10.1.1.125.6778
mulmuley extended randomized incremental construction dynamic settings obtained impressive results random updates 
textbook mulmuley comprehensive source dealing general techniques 
number general properties random sampling proved clarkson shor exploited algorithms :10.1.1.125.6778
simplified improved existing algorithms 
discussion section properties random sampling follows methods reif sen 
proofs lemmas somewhat simpler direct compared general 
technique polling reif sen critical parallel algorithms useful situations 
earliest known results parallel computational geometry traced thesis anita chow described polylog algorithms number basic problems 
aggarwal developed earliest techniques unified approach solving problems convex hulls voronoi diagrams triangulation 
atallah cole goodrich improved efficiency problems extending techniques cole parallel mergesort called pipelined cascaded merging 
goodrich thesis comprehensive source basic parallel techniques solving geometric problems 
majority research area directed obtaining log time algorithms mentioned problems optimal speed 
reif sen designed algorithms randomization successful achieving goals problems matching deterministic algorithms known 
algorithm trapezoidal decomposition section simpler version 
clarkson cole tarjan describe optimal speedup algorithms general version problem input union polygonal chains possibly self intersecting 
case simple polygon goodrich designed optimal deterministic log time algorithm chazelle optimal sequential algorithm triangulation efficient construction planar separators 
optimal algorithm dimensional convex hulls appears version uses simpler filtering scheme amato 
algorithm dimensional arrangements hagerup optimal speed algorithms constructing arrangements hyperplanes dimensions 
ramaswamy rajasekaran describe optimal speed algorithms constructing voronoi diagrams line segments 
algorithms section appear sen 
algorithms play important role fast log log log time output size output sensitive algorithms gupta sen 
efficient output sensitive algorithms convex hulls described goodrich 
details butterfly implementation reif sen 
detailed treatment basic parallel routines section reader referred textbook ja ja rajasekaran sen 
planar point location algorithm discovered independently kirkpatrick reif sen version follows 
omega gamma log log lower bound selection due beame hastad discouraged researchers investigating algorithms 
breakthrough obtained mckenzie stout subsequently hagerup raman obtained tight bounds padded sorting 
log result approximate compaction discovered simultaneously goodrich matias vishkin hagerup 
algorithms referred lemma bast hagerup 
issue bounding number random bits dealt reif sen show polylogarithmic number random bits suffice algorithms described chapter 
bounding number random bits important ramifications derandomization 
improved results obtained efficient derandomization randomized parallel algorithms goodrich amato 
impressive results obtain deterministic optimal dimensional convex hull algorithm 
important problem discussed chapter fixed dimensional linear programming 
randomization successfully obtaining elegant efficient algorithms problem 
alon describe expected time algorithm problem processors asymptotically best possible 
aggarwal chazelle guibas yap 
parallel computational geometry 
proc 
th annual symposium foundations computer science pages 
appears full version algorithmica vol 
pp 

alon azar 
average complexity deterministic randomized parallel comparison sorting algorithms 
siam journal computing 
alon parallel linear programming fixed dimensions surely constant time journal acm pp 

atallah goodrich 
efficient parallel solutions geometric problems 
journal parallel distributed computing 
atallah goodrich 
parallel algorithm functions convex polygons 
algorithmica 
atallah cole goodrich 
cascading divide conquer technique designing parallel algorithms 
siam journal computing 
amato goodrich ramos 
parallel algorithms higher dimensional convex hulls 
proc 
th annual focs pages 
akl 
optimal algorithms computing convex hulls sorting 
computing 
ajtai 
sorting parallel steps 
combinatorica 
anderson miller 
deterministic parallel list ranking 
manuscript 
amato preparata 
parallel convex hull problem revisited 
internat 
jl 
comput 
geom 
appl 
azar vishkin 
tight comparison bounds complexity parallel sorting 
siam journal computing 
bast hagerup 
fast parallel space allocation estimation integer sorting 
technical report mpi june 
beame hastad 
optimal bounds decision problems crcw prams 
proc 
nineteenth acm stoc 
ben 
lower bounds algebraic computation trees 
proc 
fifteenth stoc 
boppana 
average case parallel complexity sorting 
information processing letters 
brent 
parallel evaluation general arithmetic expressions 
journal acm 
brown 
voronoi diagram convex hulls 

process lett 
chazelle 
triangulating simple polygon linear time 
discrete computational geometry pp 

chazelle dobkin 
intersection convex objects dimensions 
jl 
acm 
chow 
parallel algorithms geometric problems 
phd thesis 
comp sc univ urbana il 
cole 
parallel merge sort 
siam journal computing 
cole 
optimal efficient selection algorithm 
inform 
proc 
lett 
cole vishkin 
approximate exact parallel scheduling applications list tree graph problems 
proc 
th ieee symp 
foundations computer science pages 
clarkson 
randomized algorithm closest point queries 
siam journal computing august pp 

clarkson 
new applications random sampling computational geometry 
discrete computational geometry pp 

clarkson :10.1.1.125.6778
applications random sampling computational geometry ii 
proc th annual acm symp computational geometry 
clarkson 
las vegas algorithms linear integer programming dimension small 
proc 
th ieee symposium foundations computer science pp 

clarkson cole tarjan 
randomized parallel algorithms trapezoidal diagrams 
int journal computational geometry applications pp 

clarkson shor :10.1.1.125.6778
applications random sampling computational geometry ii 
discrete comp 
geom 
deng 
optimal parallel algorithm linear programming plane 
inform 
proc 
lett 
kirkpatrick 
parallel construction subdivision hierarchies 
jl 
comput 
syst 
sc 
dobkin lipton 
multidimensional searching problems 
siam journal computing 
bast dietzfelbinger hagerup 
perfect parallel dictionary 
proc 
th intl 
symp math foundations computer science lncs 
edelsbrunner algorithms combinatorial geometry 
springer verlag new york 
edelsbrunner guibas stolfi 
optimal point location monotone subdivision 
siam journal computing pp 

goodrich 
place techniques parallel convex hull algorithm 
proc 
rd acm sympos 
parallel algo 
architect goodrich 
efficient parallel techniques computational geometry 
phd thesis purdue university 
goodrich 
approximate algorithms design parallel algorithms may ignore processor allocation 
proc 
nd annual focs 
goodrich planar separators parallel polygon triangulation 
appear journal computer system sciences 
preliminary version appeared proc 
th acm stoc pp 

goodrich 
geometric partitioning easier parallel 
proc 
th acm symp 
computational geometry 
goodrich 
communication efficient parallel sorting 
proc 
th acm symp 
theory computing 
goodrich 
randomized fully scalable bsp techniques multi searching convex hull construction 
proc 
th symp 
discrete algorithms 
graham 
efficient algorithm determining convex hull finite planar set 
information proc 
lett 
gupta sen optimal output sensitive algorithms constructing planar hulls parallel 
appear computational geometry theory applications 
gupta sen faster output sensitive parallel convex hulls optimal algorithms small outputs 
proc 
th acm symp 
computational geometry 
proc 
acm symposium computational geometry 
han 
designing fast efficient parallel algorithms 
phd thesis duke university 
hagerup 
log star revolution 
proc 
th annual stacs lncs 
hagerup jung welzl 
efficient parallel computation arrangements hyperplanes dimensions 
proc 
acm symp parallel algorithms architectures pages 
hagerup raman 
waste tight bounds loose parallel sorting 
proc 
rd annual focs pages 
haussler welzl 
ffl nets simplex range queries 
discrete computational geometry pp 

joseph ja ja parallel algorithms 
addison wesley 
karp 
probabilistic recurrence relations proc 
rd acm stoc pp 

karlin upfal 
parallel hashing efficient implementation shared memory 
proc 
th acm stoc pages 
kapoor 
lower bounds maximal convex layer problems 
algorithmica pages 
kalai 
subexponential randomized simplex algorithm proc 
th acm symposium theory computing 
kirkpatrick 
optimal search planar subdivisions 
siam journal computing pp 

kirkpatrick seidel 
ultimate planar convex hull algorithm 
siam journal computing feb 
maggs leighton rao 
universal packet routing algorithms 
proc 
th ieee focs pages 
matousek sharir welzl 
subexponential bound linear programming proc 
th acm symposium computational geometry 
matias vishkin converting high probability nearly constant time applications parallel hashing 
proc rd acm symp 
theory computing 
mackenzie stout 
ultra fast expected time parallel algorithms 
proc 
nd soda 
manber tompa 
effect number hamiltonian paths complexity vertex colouring problem 
siam journal computing 
mulmuley 
fast planar partition algorithm proc 
th ieee foundations computer science pp 

mulmuley 
randomized multidimensional search trees dynamic sampling 
proc 
th 
computational geometry pp 

mulmuley randomized multidimensional search trees lazy balancing dynamic shuffling 
proc 
nd ieee foundations computer science pp 

mulmuley computational geometry randomized algorithms 
prentice hall 
paul vishkin parallel dictionaries trees 
proc 
tenth icalp vol 
pp 

preparata hong 
convex hulls finite sets points dimensions 
comm 
acm 
preparata 
optimal real time algorithm planar convex hulls 
comm 
acm 
preparata shamos 
computational geometry 
springer verlag new york 
rajasekaran sen random sampling techniques parallel algorithm design 
reif editor 
morgan kaufman publishers 
ramaswami rajasekaran optimal parallel randomized algorithms voronoi diagram line segments plane related problems proc 
th acm symp 
computational geometry pp 


emulate shared memory 
proc 
th ieee focs pages 
reif sen optimal randomized parallel algorithms computational geometry 
algorithmica 
preliminary version appeared proc 
th int ce parallel processing aug reif sen optimal parallel randomized algorithms dimensional convex hulls related problems 
siam journal computing 
reif sen randomized algorithms binary search load balancing networks geometric applications siam journal computing pages 
reif valiant 
logarithmic time sort linear size networks 
journal acm 
reischuk 
fast probabilistic parallel sorting algorithm 
proc 
nd ieee focs pages 
roy pollack 
number cells defined set polynomials 
comptes rendus 
tarjan 
planar point persistent search trees 
communications acm pp 

sen random sampling techniques efficient parallel algorithms computational geometry 
phd thesis duke university 
sen lower bounds algebraic decision trees complexity convex hulls related problems appear theoretical computer science 
preliminary version appeared proc 
th fst tcs madras india 
shamos 
computational geometry 
phd thesis yale univ new haven 
steele yao 
lower bounds algebraic decision trees 
journal algorithms 
valiant 
scheme fast parallel communication 
siam journal computing 
valiant bridging model parallel computation 
communications acm 
wyllie 
complexity parallel computation 
phd thesis cornell university 
yao 
lower bound finding convex hulls 
journal 
yap 
parallel triangulation polygon calls trapezoidal map 
algorithmica 
decomposition sided monotone polygons 
dotted lines indicate triangulation edges 
distinguished edge 

