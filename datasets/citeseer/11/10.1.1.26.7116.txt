appear parallel architectures languages europe parle july adaptive update cache coherence protocol reduction rate traffic kan nilsson department computer engineering lund university box lund sweden 
directory write invalidate cache coherence protocols potential improve performance large scale multiprocessors coherence misses limit processor utilization 
called competitive update protocols hybrid protocols write invalidate considered means reduce coherence rate shown better coherence policy wide range applications 
unfortunately protocols may cause high traffic applications extensive migratory objects 
traffic offset performance gain reduced rate network bandwidth sufficient 
propose study extend competitive update protocol previously published adaptive mechanism dynamically detect migratory objects reduce coherence traffic cause 
detailed architectural simulations scientific engineering applications show adaptive protocol outperform write invalidate protocol reducing rate bandwidth need respectively 
private caches conjunction directory cache coherence protocol unified approach reduce memory system latencies large scale multiprocessors 
cache coherence protocols proposed literature write invalidate write update protocols 
pure write update protocols appropriate may incur severe performance degradation compared write invalidate protocols result heavy network traffic 
previous study shown competitive update protocol hybrid write invalidate write update protocols outperforms write invalidate protocols relaxed memory consistency models wide range applications lower rate 
idea competitive update protocol simple 
invalidating copy block write processor copy updated 
local processor access copy invalidated number global updates determined competitive threshold 
result copies regularly accessed updated 
competitive update protocols better performance suboptimal coherence maintenance migratory objects 
reason migratory objects accessed read modify write manner processor turn processor reads shared block updates copies block processor reads updates block 
block migrate caches 
competitive update protocol risk updates sent caches processors access block invalidated due competitive threshold 
cause unnecessary traffic may increase read penalty time processors stall due cache misses networks insufficient bandwidths 
write invalidate better policy migratory blocks 
reduce traffic competitive update protocols maintain low rate propose extend previously published mechanism dynamically detects memory blocks exhibiting migratory sharing 
blocks handled read exclusive requests avoid unnecessary network traffic blocks handled competitive update policy 
detailed architectural simulation study parallel applications splash benchmark suite find competitive update protocols extended simple migratory detection mechanism reduce read rate compared write invalidate protocol 
experimental results show bandwidth requirements applications reduced compared write invalidate protocol applications exhibiting migratory sharing 
read rate traffic reductions help reducing read penalty compared write invalidate protocol 
rest organized follows 
background section defining migratory sharing previously proposed cache coherence policies act respect migratory sharing 
serves motivation adaptive protocol propose section 
move experimental evaluation sections starting experimental methodology detailed architectural assumptions benchmark programs section experimental results section 
conclude study section 
cache coherence protocols migratory sharing section architectural framework 
discuss migratory sharing write invalidate protocol optimized type access pattern 
briefly describe competitive update protocol works performance limitations respect migratory objects 
architectural framework architectural framework cache coherent non uniform memory access cc numa architecture directory cache coherence protocol 
architecture consists number processor nodes interconnected mesh network 
processor node consists processor private caches local portion shared memory network interface control connected local bus 
global cache coherence supported directory full map protocol memory block associates presence flag vector indicating nodes copy block 
refer node page containing block allocated home local node request originated remote node involved coherence action 
cc numa multiprocessor processor stall times due completion memory accesses limit performance system stem mainly reasons read stall time arises cache misses write stall time arises propagating new values remote copies processor writes 
previous studies shown possible hide write latency remove write stall time relaxed memory consistency model release consistency rc sufficient amount buffering local node 
shown possible write invalidate protocols protocols 
order achieve high performance assume study release consistency model 
migratory sharing write invalidate protocols gupta weber classify data objects access pattern exhibit 
migratory data objects manipulated processors single processor time 
parallel programs objects unusual data structures accessed critical sections high level language statements asi exhibit migratory sharing 
way formally defining migratory sharing sequence read actions alternating processors data object 
global stream migratory object described regular expression 
ri ri wi ri wi rj rj wj rj wj 
represent read access write access respectively processor denotes zero occurrences preceding string denotes logical operation 
write invalidate protocols rely invalidation remote copies maintain coherence cached copies shared memory block 
write invalidate protocol regular expression results coherence actions block cache results read request block loaded cache shared state 
write request block copy memory invalidated cache receives exclusive dirty copy block 
subsequent processor reads block cache encountered read request forwarded cache exclusive copy 
cache sends copy cache block shared 
processor modifies block modification results single invalidation message sent cache optimization merge read request invalidation request single read exclusive request 
previous papers studied migratory optimization 
papers migratory blocks dynamically detected hardware handled read exclusive requests separate read invalidation requests 
optimization reduces network traffic single invalidations migratory blocks removed 
coherence rate unaffected 
write invalidate protocol extended migratory detection mechanism reduce number global write requests appli cations exhibiting migratory sharing 
result network traffic reduced studied applications migratory sharing 
competitive update protocols migratory sharing competitive update protocols coherence maintained update messages invalidation messages 
write request update messages sent caches sharing memory block 
contrast write update protocols competitive threshold locally invalidate copies accessed local processor number updates copy updated times invalidated update messages ceases 
counter cache line indicates number external updates local access block 
network traffic reduced compared write update protocol copies regularly accessed updated 
details competitive update protocols implemented detailed performance evaluation 
give brief description protocol main results 
local access block resides cache counter associated block preset cache occurs block fetched memory loaded cache counter preset cache receives update message processor cache controller checks counter associated block 
counter zero block invalidated acknowledgment returned home indicating cache copy anymore updates cache ceases 
counter decremented cache copy updated acknowledgment sent home indicating cache block valid 
performance evaluation shows competitive update protocols reduce read penalty compared write invalidate protocols mainly result highly reduced number coherence misses lower 
higher number global writes competitive update protocols shown offset reduced read penalty release consistency assuming mesh network stanford dash multiprocessor 
unfortunately competitive update protocols migratory blocks cached copies updated local access invalidated 
results unnecessary network traffic 
networks insufficient bandwidth contention may offset benefits competitive update protocol 
address problem propose study extend competitive update protocol previously published migratory detection mechanism 
expect extended protocol reduce traffic caused blocks exhibiting migratory sharing maintaining low coherence rate competitive update protocol blocks exhibit migratory sharing 
proposed adaptive protocol section identify hardware mechanisms protocol extensions incorporate migratory detection mechanism competitive update protocol starting high level view previously published detection mechanism 
high level view migratory detection mechanism order identify migratory blocks migratory detection mechanism conceptually detects sequence wi rj wj classifies memory block migratory wj occurs 
distinguish migratory blocks ordinary blocks blocks exhibit migratory sharing 
study cache coherence ordinary blocks maintained write invalidate protocol 
blocks classified ordinary default home detect block starts migratory 
letting home keep track processor modified block block classified migratory home receives global write processor requirements fulfilled condition migratory detection write invalidate protocols processor issues write request processor issued write request block 
number block copies exactly 
hardware requirement writer pointer lw size log bits caches system associated memory block keep track identity processor modified block bit denoting memory block migratory 
full map protocols number copies derived content presence flag vector 
detection mechanism described directly applicable competitive update protocol competitive update protocol sufficient know number block copies copy block may exist cache local processor accessed modification processor 
reformulate condition section serve basis detection mechanism adjusted fit competitive update protocol 
competitive update protocol migratory detection mechanism sequence section migratory detection mechanism classifies sequence migratory processor issues write request wj 
point may exist arbitrary number copies 
base detection algorithm reformulate requirement condition condition migratory detection competitive update protocols processor issues write request processor issued write request block 
processors ones may read block write processor requirement competitive update protocols write invalidate protocols 
associate writer pointer lw memory block case 
lw pointer updated global write request 
requirement algorithm detects processor processor ones read block write processor letting home ask caches copy processors read block detected write processor checking counter associated block cache locally decides processor read block write processor 
counter preset local processor writes block additional state needed determine update came processor 
home keeps track migratory ordinary memory blocks new stable state memory blocks new transient state 
processor writes block processor updated read block deemed potentially migratory block 
see left fig 
message sent home ordinary global write 
home checks lw 
lw write treated ordinary write 
memory block home agrees block potentially migratory sends messages caches sharing block 
cache responds ways agrees block migratory mok processor read block update global update originated ii disagrees processor read written block update processor 
home classifies block migratory iff acknowledgments mok 
exclusive ownership local 
contrast cache responds block classified ordinary sent local 
grd mok data migratory fig 

coherence actions detection migratory blocks left coherence actions read misses migratory blocks right 
read requests migratory blocks handled right part fig 

local issues grd ordinary blocks 
home knows block migratory requests remote send exclusive copy back home invalidate copy 
remote responds home forwards exclusive copy local migratory message 
protocol new cache state called migrating needed detect block migratory 
migratory blocks home sees requests write requests home sees sequence result home detect processor modified block subsequent read requests 
solve problem migratory block loaded cache state migrating read local processor modifies block state changes exclusive global actions 
remote receives home decides block migratory 
block state exclusive remains migratory sent home 
contrast block state migrating processor modi fied arrives block longer migratory 
remote sends home keeps shared copy block 
home block ordinary data sent local 
block loaded cache shared 
summary extra hardware needed detect migratory blocks support competitive update protocol pointer associated memory block extra bit associated cache block 
competitive update protocol extended memory states local cache state 
enhanced adaptive protocol applications false sharing processors problem arise adaptive protocol described section 
consider sequence block block alternatively accessed processor 
ri wi rj ri wj ri rj wi 
sequence detected migratory time processor issues wj subsequent read access processor results read exclusive copy block leads cache processor rj avoided write invalidate protocol 
increased number misses occur 
observed anomaly migratory detection mechanism applications experimentally study ocean 
approach mitigate problem resort competitive update mode exactly processors share block 
writer pointer referred associated memory block addition previous lw pointer 
lw pointer updated new value old value lw moved pointer 
order classify block migratory processor currently modifies block say ones modified block lw 
experimental methodology section simulation framework studied effectiveness adaptive protocol section 
simulation models built top test bench program driven simulator programming environment 
simulator consists parts functional simulator multiple sparc processors architectural simulator 
functional simulator issues memory architectural simulator delays processors timing model 
interleaving memory obtained target systems model 
model processing nodes connected mesh network 
organization processor node shown fig 

level cache hierarchy simulate consists level cache flc second level cache slc associated write buffers entries 
flc kbyte write chip cache slc infinite copy back cache 
caches line size bytes full inclusion supported 
slc flc blocking invalidation pin block invalidated outside processor 
coherence actions associated system level cache coherence protocol handled slc memory controller 
acquire release requests supported queue lock mechanism similar implemented dash multiprocessor 
page size kbyte pages allocated memory modules round robin fashion 
level cache second level cache flc slc standard microprocessor level write buffer second level write buffer memory module fig 

organization processor node 
timing model consider sparc processors clocked mhz ns 
slc assumed implemented static ram access time ns 
slc write buffer connected network interface control local memory module bit wide split transaction bus clocked mhz 
takes ns arbitrate bus ns transfer request block 
furthermore memory assumed implemented dynamic ram access time ns including buffering 
simulate system containing nodes interconnected wormhole routed synchronous mesh flit size bits 
especially look adaptive protocol manages reduce network contention assume conservative mesh implementation clocked mhz 
correctly model contention parts system 
assumptions takes satisfy processor read request flc slc local memory respectively 
read serviced home remote takes respectively assuming contention free system 
simulations requests normally take longer time result contention 
order understand relative performance adaptive protocol scientific engineering applications 
taken splash suite mp water cholesky pthor 
fifth application ocean provided steven woo stanford university 
programs written anl macros express parallelism compiled version optimization level 
mp run particles time steps 
cholesky bcsstk matrix 
water run molecules time steps 
pthor risc circuit run time steps 
ocean grid tolerance factor set previous studies shown mp cholesky water high degree migratory objects pthor ocean producer consumer objects 
local bus network interface control experimental results section evaluate performance enhanced adaptive protocol described section henceforth referred ad 
previous study showed competitive update protocol reduces read penalty execution time compared write invalidate protocol wide range applications assuming mhz mesh 
mhz mesh study competitive update protocol may suffer higher network traffic 
fig 
normalized execution times write invalidate wi competitive update cu enhanced adaptive ad protocols applications study 
bars associated application correspond wi cu ad respectively 
vertical bar divided sections correspond bottom top busy time processor utilization processor stall time due read misses processor stall time perform acquire requests processor stall time due full level write buffer 
note write stall time release consistency 
measurements assumed competitive threshold 
normalized execution time comparing wi cu observe fig 
mp cholesky longer read stall times cu wi mainly result network contention 
table bandwidth requirements application calculated network traffic divided execution time normalized bandwidth requirement wi application 
observe wi requires bandwidth cu applications 
large number unnecessary updates migratory objects results dramatic difference bandwidth needed mp cholesky 
mp see cu requires bandwidth wi cholesky cu requires bandwidth wi 
fig 
observe pthor acquire stall time significantly higher cu wi 
effect arises pthor exhibits contention critical sections time lock released processor waiting get lock 
higher rate global write actions cu delays issuance release secondary effect delays processors waiting lock 
adaptive protocol propose reduce problems show 
wi cu ad wi cu ad wi cu ad wi cu ad wi cu ad mp cholesky water pthor ocean fig 

normalized execution times wi cu ad 
buffer stall acquire stall read stall busy time table read rates normalized bandwidth requirements applications 
application read rates percentage cold coherence normalized bandwidth requirements wi wi cu ad cu ad mp cholesky water pthor ocean observe comparing execution times ad wi ad manages outperform wi applications pthor 
execution times decreased ad 
mp cholesky main reason read penalty reduced respectively lower contention network 
furthermore read penalty reduced pthor ad compared wi 
acquire stall time ad longer wi contention locks 
highest read penalty reduction achieved ocean ad cuts read penalty compared wi 
ocean ad reduces acquire stall time compared wi 
ocean counters barriers exhibit migratory sharing 
fewer global write actions ad result shorter release issuance time 
result acquire stall time reduced processor waits lock 
remarkably water exhibits substantial migratory sharing virtually difference performance wi ad 
reason bandwidth requirement water low means read penalty affected network contention wi 
table show read rates decomposed cold coherence components application 
read rates number processor reads flc slc divided number processor reads 
expected mp rates ad wi 
rates cholesky water lower respectively ad wi data objects migratory 
objects migratory 
objects resort lower coherence rate encountered 
applications marginal migratory sharing pthor ocean read rates reduced ad respectively compared wi 
ad preserved low read rates cu applications little migratory sharing 
traffic reduction ad see table bandwidth requirements ad significantly reduced compared wi compared cu mp cholesky water 
applications bandwidth requirements reduced compared wi 
comparing ad cu find bandwidth requirements reduced 
expected bandwidth requirements ad cu applications little migratory sharing pthor ocean 
evaluated benefits ad compared basic adaptive protocol described section henceforth referred ad uses single lw pointer memory block 
application ad ad differ performance ocean non negligible degree false sharing 
simulation results show ad higher read penalty read misses ad 
result execution time longer ad ad 
thorough analysis 
summarize ad appears better default policy wi cu handles migratory blocks read exclusive strategy provided migratory detection mechanism helps reducing traffic 
competitive update protocols ad handles producer consumer sharing ocean pthor competitive update mode helps reducing coherence rate blocks 
concluding remarks improve performance competitive update protocols proposed extend previously published migratory detection mechanism dynamically detects migratory blocks handles read exclusive requests 
result global write actions migratory blocks eliminated 
addition migratory detection mechanism extended detect exactly processors modify memory block alternately result false sharing 
detecting sharing behavior adaptive protocol resorts competitive update mode reduces coherence rate accordingly 
shown migratory detection mechanism adds marginal complexity competitive update protocol 
program driven simulations detailed multiprocessor architectural model shown competitive update protocols possible reduce read rates bandwidth requirements respectively compared write invalidate protocol detecting migratory data objects 
architecture assumed study cc numa mesh network detection mechanism applicable bus systems low traffic rate important cc numa architectures mesh networks 
study simulated system processors 
scale system larger number processors expect latencies longer important keep network bandwidth requirements low level 
believe benefits adaptive protocol increases system size especially applications exhibit migratory sharing 
study cache invalidation patterns gupta weber shows migratory sharing independent system size range processors study 
study shows adding simple mechanism detection migratory sharing network traffic competitive update protocols significantly reduced result adaptive competitive update protocols shown outperform write invalidate protocols networks low bandwidths 
acknowledgment lars nsson implementing basic adaptive protocol simulator part master thesis 
supported swedish national board industrial technical development contract number 

dahlgren nilsson test bench flexible effective approach simulation multiprocessors proceedings th annual simulation symposium pp 
march 
cox fowler adaptive cache coherency detecting migratory shared data proceedings th international symposium computer architecture pp 
may 
gharachorloo gupta hennessy performance evaluation memory consistency models shared memory multiprocessors proceedings asplos iv pp 
april 
gupta 
weber cache invalidation patterns shared memory multiprocessors ieee transaction computers pp 
july 
lenoski laudon gharachorloo 
weber gupta hennessy horowitz lam stanford dash multiprocessor ieee computer march 
nilsson dubois implementation evaluation update cache protocols relaxed memory consistency models technical report dept computer engineering lund university sweden july 
nilsson evaluation adaptive update cache protocols technical report dept computer engineering lund university sweden march 

singh 
weber gupta 
splash stanford parallel applications shared memory computer architecture news march 
survey cache coherence schemes multiprocessors ieee computer june 
dahlgren lockup free multiprocessor cache design proceeding international conference parallel processing vol 
pp 
august 
sandberg adaptive cache coherence protocol optimized migratory sharing proceedings th international symposium computer architecture pp 
may 
