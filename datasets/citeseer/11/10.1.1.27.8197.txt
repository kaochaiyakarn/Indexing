audio vision audio visual synchrony locate sounds john hershey cogsci ucsd edu department cognitive science university california san diego la jolla ca javier movellan movellan cogsci ucsd edu department cognitive science university california san diego la jolla ca advances neural information processing systems solla leen 
uller eds mit press psychophysical physiological evidence shows sound localization acoustic signals strongly uenced synchrony visual signals 
ect known sound coming side tv set feels coming mouth actors 
ect suggests important information sound location encoded synchrony audio video signals 
spite evidence audiovisual synchrony rarely source information computer vision tasks 
explore audio visual synchrony locate sound sources 
developed system searches regions visual landscape correlate highly acoustic signals tags contain acoustic source 
discuss experience implementing system results speaker localization task discuss potential applications approach 
method locating sound sources sampling regions image correlate time auditory signal 
approach inspired psychophysical physiological evidence suggesting audio visual contingencies play important role localization sound sources sounds emanate visual stimuli synchronized sound 
ect particularly noticeable perceived source sound known false case dummy television screen 
phenomenon known psychophysical community ect de ned sounds apparent visual source 
ect robust wide variety conditions strongly dependent degree synchrony auditory visual signals driver de gelder 
ect fact speech speci rst thought 
example ect disrupted upside lip signal correspondence addressed 
de gelder just strong lip signals replaced light synchronized amplitude peaks audio signal 
crucial aspect correlation visual auditory intensity time 
light synchronized ect disappears 
ect strong produce enduring localization bias known ect 
time experience spatially set auditory visual stimuli causes persistent shift subsequent auditory localization 
exposure audio visual stimuli set degrees azimuth minutes sucient shift auditory localization amount 
corresponding shift neural processing detected macaque monkeys early primary auditory cortex 
barn owls misalignment visual auditory stimuli development causes realignment auditory visual maps optic zheng knudsen feldman knudsen 
strength psychophysical physiological evidence suggests audiovisual contingency may important source information currently underutilized computer vision tasks 
visual auditory sensor systems carry information events world information combined correctly order useful interaction modalities 
audiovisual contingency exploited help determine signals di erent modalities share common origin 
bene ts fold signals help localize paired help interpret 
ect developed system localize speakers input camera single microphone 
approach searching regions image synchronized acoustic signal 
measuring synchrony concept audio visual synchrony formalized psychophysical literature working de nition interpret synchrony degree mutual information audio spatially localized video signals 
ultimately causal relationship interested causes inferred ects synchrony 
vector describing acoustic signal time components cepstral coecients pitch measurements outputs lter bank 
vector describing visual signal time pixel 
components represent gabor energy coecients rgb color values consider set audio visual vectors 
sampled times 
spatial coordinates 
set vectors goal provide number describes temporal contingency audio video time approach take consider vector independent sample joint multivariate gaussian process de ne audio visual synchrony time estimate mutual information audio visual components process 
nn nm represents means covariance matrices 
jointly gaussian nn 
mutual information shown follows log log log log jj special case log pearson correlation coecient 
triple estimate mutual information considering element independent sample random vector 
amounts computing estimates joint covariance matrix 
example estimate covariance th audio component th video component follows sa simple covariance estimates computed recursively constant time respect number timepoints 
independent treatment pixels lend parallel implementation 
measure performance secondary system produces single estimate auditory location database labeled solitary audiovisual sources 
unfortunately ways producing estimates dif cult separate performance measure underlying system 
model centroid computation mutual information estimates enhancements aid tracking reduce background noise 
implementation issues real time system prototyped linux operating system ported nt lter 
platform provides input real time audio video capture hardware static movie les 
video output rendered live compressed saved movie le 
implementation challenging turns dicult scores audio video intensity frames talking 
scores audio video intensity frames talking 
normalized audio visual intensity sequences frames sequence numbers spoken 
top trace contour acoustic energy speakers bottom trace contour intensity values single pixel near mouth process precisely time synchronized audio video serial machine real time 
multiple threads required read peripheral audio visual devices 
time audio visual streams reach av lter module quite separate asynchronous 
separately threaded auditory visual packet streams synchronized bu ered nally matched aligned time stamps nally processed 
interesting successful audiovisual systems employ parallel architecture avoid problem 
results obtain performance baseline rst tried simplest possible approach single audio visual feature location intensity pixel time average acoustic energy interval 

msec sampling period ntsc video signal 
illustrates time course signals non synchronous synchronous pair acoustic energy pixel intensity 
notice particular pair sound pixel values come speaker relationship signals changes time 
regions positive negative covariance strung succession 
clearly relationship entire sequence far linear 
shorter time periods linear relationship looks better approximation 
window size samples coincides approximately time scale 
averaging small windows capture larger scale lost method applied larger window 
course trade time scale sensitivity spurious transients response time system 
applied mutual information measure pixels movie spirit perceptual maps brain 
result changing topographic map audiovisual mutual information 
illustrates snapshots frame left talking 
frame right talking 
estimated mutual information pixel intensity audio intensity bright areas indicate greater mutual information overlaid stills video person mid utterance 
di erent parts face synchronous possibly di erent sign sound take part producing 
interesting synchrony shared parts eyes directly contribute sound contribute communication 
estimate position speaker computed centroid point weighted estimated mutual information pixel audio signal 
time step mutual information estimated past frames order reduce intrusion spurious correlations competing targets target employ gaussian uence function 
goodall uence function reduces weight mutual information locations far current centroid computing centroid 
allow speedy source mutual information set threshold mutual information 
measurements threshold treated zero 
threshold reduces ects unwanted background noise camera microphone jitter 
log log represents estimate coordinate position speaker time thresholding function uence function depends position pixel sampled prior estimate 
estimate correlation intensity pixel acoustic past video frames 
log corresponding estimate mutual information factor cancels quotient adjusting threshold function accordingly 
tried approach movie people turns saying random digits 
shows estimates actual positions speaker function time 
estimates clearly provide information localize speaker especially combination approaches detection 
frame number estimated actual position speaker frame frames 
sources took turns uttering series digits turns 
actual positions alternation times measured hand video recording exploratory system localizing sound sources video signal tagging regions image correlated time auditory signal 
approach motivated wealth evidence psychophysical physiological literature showing sound localization strongly uenced synchrony visual signal 
measure local synchrony modeling audio visual signal non stationary gaussian process 
developed general software tool accepts inputs major video audio le formats direct input video camera 
tested tool speaker localization task encouraging results 
approach practical applications localizing sound sources situations acoustic stereo cues unreliable 
example approach help localize actor talking video scene put closed captioned text near audio source 
approach guide camera teleconferencing applications 
results reported encouraging needs done practical applications developed 
example need investigate sophisticated methods processing audio video signals 
point average energy represent video changes fundamental frequency ect average energy captured model 
similarly local video decompositions spatio temporal gabor ltering approaches designed enhance lip regions may helpful 
changing symmetry observed audio video signals addressed rectifying squaring normalized signals derivatives 
relaxing gaussian constraints measure audio visual contingency may help improve performance 
shown exploratory point approach promising emphasizes idea machine perception multimodal process backed psychophysical evidence combined approaches may help improve robustness tasks localization separation sound sources 
de gelder 

exploring relation interference 
proceedings international conference spoken language processing volume pages 
driver 

enhancement selective listening illusory speech sounds due lip reading 
nature 
feldman knudsen 

anatomical basis visual calibration space map barn owl 
journal neuroscience 
goodall 

estimators location outline theory 
wiley series probability mathematical statistics 
applied probability statistics 


adaptation auditory visual semi realistic situations 
perception psychophysics 


rapidly induced auditory plasticity ect 
proceedings national academy sciences usa 


sensory maps move 
science 
zheng knudsen 

functional selection adaptive auditory space map mediated inhibition 
