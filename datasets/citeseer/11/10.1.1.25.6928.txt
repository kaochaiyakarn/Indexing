borrowed virtual time bvt scheduling supporting latency sensitive threads general purpose scheduler systems need run larger diverse set applications real time interactive batch uniprocessor multiprocessor platforms 
schedulers address latency requirements specialized complex real time paradigms limiting applicability general purpose systems 
borrowed virtual time bvt scheduling showing provides low latency realtime interactive applications weighted sharing cpu applications system policy thread failure real time level low overhead implementation multiprocessors uniprocessors 
minimal demands application developers reservation admission control module hard real time applications 
modern processor speeds memory capacities systems run wide diversity application tasks need order meet user customer expectations 
example software engineer reasonably watch listen training video pc editing re compiling software receive voice ip call midst activity software performing packet reception decompression timed playback sampling compression transmission 
embedded systems ip router multiple command permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sosp kiawah island sc acm 
kenneth duda david cheriton computer science department stanford university cheriton cs stanford edu line interpreters network management tasks run concurrently real time tasks performing routing protocols packet forwarding signaling protocols 
general purpose operating system processor schedulers just provide fair sharing cpu competing tasks limited support different latency sensitivity competing threads guarantees 
example scheduler may allow frame display video player delayed concurrent compilation process disk completes shortly frame time degrading video playback real benefit compilation 
similar delay degrade voice quality 
hard real time tasks excessive delay cause outright failure 
contrast specialized real time operating system schedulers handle latency sensitivity allowing requiring application threads specify processing needs detail 
particular deadline scheduler thread required specify advance deadline needs complete processing cycles requires complete processing earliest starttime prepared initiate processing 
complex scheduling model imposes extra overhead application developer scheduler scheduler unsuitable unpredictable real time threads general purpose single multi user timesharing systems 
conventional wisdom holds costs special mechanisms necessary meet real time response requirements 
believe 
borrowed virtual time bvt general purpose scheduling algorithm allows single operating system kernel support diverse range applications outlined candidate universal processor scheduler 
show bvt scheduling allows simple low overhead implementation requires little change applications provides comparable superior response behavior specialized real time schedulers 
bvt scheduling bvt scheduling thread execution time monitored terms virtual time dispatching runnable thread earliest effective virtual time evt 
thread allowed warp back virtual time appear earlier gain dispatch preference 
effectively borrows virtual time cpu allocation disrupt long term cpu sharing 
name borrowed virtual time scheduling 
algorithm described detail rest section 
bvt thread includes state variables effective virtual time evt actual virtual time avt virtual time warp set warp enabled 
thread unblocks currently executing thread blocks scheduler runs thread minimum runnable threads 
evt thread computed determined described 
scheduler accounts running time units minimum charging unit mcu typically frequency clock interrupts 
thread runs time charged running time 
thread runs microseconds amount rounded multiple time units 
approximately context switch cost rounding average charges current process context switch 
scheduler configured context switch allowance real time current thread allowed advance runnable thread equal claim cpu 
typically larger multiple preventing compute bound threads avt thrashing switching timer interrupt 
example system scheduler milliseconds microseconds 
similar quantum conventional timesharing 
weighted fair sharing runnable thread receives share processor proportion weight scheduling window number see section 
achieve avt currently running thread incremented running time divided 
implementation scheduler stores thread advance variable set proportional 
scheduler increments context switch thread run microseconds 
avt update scheduler switches current thread runnable thread factor context switch decision 
gcc 
weighted fair sharing cpu 
axis real time axis virtual time running thread appears diagonal line waiting runnable thread appears flat line 
gcc twice weight receives cpu receives 
scheduler gives runnable threads equal amounts virtual time gcc consumes virtual time slowly greater weight 
sharing cpu illustrated vertical axis indicates virtual time horizontal axis indicates physical time 
context switches occur running thread passes waiting thread context switch allowance 
scheduling window thread receives fair share 
general error fair share actual allocation greater context switch allowance plus threads runnable 
lines graph intersect precise sharing achieved 
thread runnable sleeping scheduler virtual time svt scheduler variable indicating minimum runnable thread adjustment prevents thread claiming excessive share cpu sleeping long time happen adjustment illustrated 
adjustment thread gets share cpu wakeup runnable dispatched point avt cases 
scheduler consider avt threads blocked involuntary sleep page fault part minimum computation avoid problem runnable batch svt captures notion current virtual time scheduler threads similar role global virtual time gvt optimistic parallel simulation 
thread runnable effectively blocked event hold back svt gvt 
gcc 
adjusting avt thread long sleep 
gcc sleeps executes 
gcc wakes brought fairly shares cpu 
adjusting avt gcc starve indicated lower thin line starting real time virtual time 
thread effectively losing portion share page fault immediately dispatched 
fits logical model thread logically waiting event just delayed implementation artifact virtual memory system 
equivalent doing avt adjustment thread sleep voluntary waiting user input 
scheduling behavior similar weighted fair queueing start time fair queueing 
low latency dispatch thread created non zero warp give dispatch preference 
larger warp values provide lower latency dispatch smaller values 
flag set directly system call causing thread run warped normally may enabled signal invocation passing sa bvt warp flag sigaction causing thread signal handler run warped 
illustrates mpeg player warp value achieve low latency dispatch competition gcc sharing processor 
mpeg player wakes generate frame immediately preempts applications evt warp programs svt definition 
mpeg player long term usage constrained weighted fair sharing bvt similar advanced actual cpu usage 
warp mpeg player delayed frame time interactive batch application threads avt time slicing threads completion similar behavior illustrated 
warping reduces gcc mpeg 
low latency dispatch warp showing effective virtual time axis mpeg player wakes time time uses goes back sleep 
runs warped back virtual units giving earliest evt 
thread wakes avt shown advanced causing short vertical segments evt 
jitter milliseconds microseconds depending time context switch 
thread warp time limit unwarp time requirement real time units microseconds 
thread allowed run warped time attempts run warped longer scheduler dispatches new lowest evt thread similarly thread attempts warp having previously warped scheduler runs time passed 
time measured thread explicitly blocks 
relating back earlier setting thread run warped warp variable true true limits satisfied 
non zero thread automatically running warped time remains explicitly sets state warped 
thread time limit long run warped 
warp parameters set limit short term cpu consumption high priority high warp thread strictly thread weight limit latency add threads illustrated 
contrast strict priority scheduler allow high ideally hardware provides accurate interval timer cycle counter detects case thread running longer warp time limit allowing limit accurate microseconds 
gcc mpeg 
infinite loop low latency thread mpeg player wakes time goes infinite loop 
time exceeded causing time reverts allowing threads run preserving weighted fair sharing 
priority thread infinite loop starve lower priority threads 
parameter prevents periodic task excessive cpu short term waking frequently 
example periodic device task requires low latency dispatch milliseconds consumes millisecond cpu time large get immediate dispatch unblocks warp time limit milliseconds unwarp time say milliseconds 
device fails signals thread milliseconds scheduler prevents thread warping excessive cpu cycles application scheduling window 
warp limit parameters failed device thread large warp run milliseconds preempted exceeding cpu share 
default value suitable threads warp values cpu share low significantly interfere threads 
parameters need complicate system configuration time critical real time threads 
bvt scheduler implementation includes logging facility debug scheduling behavior programs including detecting threads running warp time limit unwarp time requirement 
alternatively system generate signal delete thread hits limits 
interrupt service routines interrupt routine handled signal handler bvt thread providing weight warp warp limits 
case running time interrupt routine accounted cycles thread signal handler 
interrupt thread attempts excessive share cpu blocked running svt advanced sufficiently just threads signal handlers 
avoids problem interrupt routines blocking processing mogul identified problem network protocol processing 
multiprocessor scheduling bvt shared memory multiprocessor processor runs earliest evt thread runnable threads adds migration penalty thread ran processor 
thread ran evt dispatch locally computation favors migrating latency sensitive thread available processor achieve lower latency higher warp value 
value set small machines fast response critical larger throughput primary purpose multiple cpus 
multi level scheduling bvt multi level hierarchical scheduling structure similar hierarchical allow set threads treated aggregate respect lowerlevel scheduler 
instance level scheduler configured run set real time threads closed system known set threads requirements admission control 
level allocates fixed cpu share second level weight second level scheduler runs set timesharing threads open system 
threads simply degrade performance demands exceed second level cpu share appropriate timesharing 
group real time threads aggregated similarly set threads handling network protocol processing 
level scheduler run threshold mode case second level thread effectively runs second level scheduler warp value warp specified threshold 
mode intended second level scheduler running timesharing best effort threads warp values threshold just give thread response preference relative second level threads 
warp values threshold threads mpeg player benefit low latency response relative threads level 
setting larger threshold value effectively conserves limited warp time second level scheduler higher priority threads 
direct mode second level scheduler runs threads warp value thread executing 
mode second level scheduler grouping set real time threads allocate cpu share aggregate closed system refers admission control module knows threads ensures processing demands met contrast open system threads degrade new threads load openly added control 
individual threads 
example system may allocate percent cpu capacity network protocol processing spread threads 
second level scheduler executes warp value warp time limit network processing thread executing dispatch latency affected running network processing aggregate assuming aggregate cpu share adequate 
third level bvt scheduler provide virtual scheduling simulation framework avt corresponds simulation time advanced simulation events weights 
warp mechanism allow simulation process compute ahead actual virtual time ahead gvt process appropriate optimistic parallel simulation limited warp value 
explored bvt levels date 
describes complete system interface provided user bvt scheduling administrative controls setting weights warp parameters 
setting parameters details multi level scheduling described section 
bvt implementation implemented bvt scheduling linux follows 
milliseconds timer interrupt period 
thread corresponds linux process 
thread descriptor holds thread mcu advance integer weight 
context switch finding thread lowest evt scheduler identifies thread run assuming threads wake computes number context switch take place context switch allowance account stores value context switch countdown thread descriptor 
timer interrupt active thread counter incremented 
reaches countdown timer interrupt handler invokes scheduler 
scheduler invoked due timer expiration wakeup running thread blocking running thread reaching context switch countdown advances avt running thread times mcu counter sets thread mcu counter updates scheduler virtual time 
picks best thread second best thread described 
thread wakes dispatch immediately evt running thread 
coarse grained switching cpu bound threads occurs context switch allowance 
standard linux thread descriptor augmented integers representing timer interrupt advance warp warp time limit unwarp time limit actual virtual time scheduler id thread runs 
implement runtime limits include record warped runtime thread left flag waiting warp timestamp allowed run warped 
new thread inherits quantities parent thread 
initial thread mcu advance warp remaining fields 
implemented hierarchy schedulers scheduler reserved effort scheduler best effort 
scheduler structure holds scheduler scheduler virtual time context switch allowance warp threshold 
best effort scheduler acts thread reserved effort scheduler contains thread fields described 
level runs bvt scheduling algorithm differs parameters admission policy 
root add threads level child scheduler provides conventional open system allowing threads added dynamically restriction 
additional storage bvt implementation adds linux kernel bytes global variables mainly bytes scheduler times schedulers bytes thread plus debugging log 
avoid integer overflow problems system virtual time exceeds system subtracts virtual time quantities system 
expected parameter values happens days 
runnable threads kept unsorted linked list cost selecting thread dispatch grows linearly number runnable threads 
implemented system call set scheduler parameters user program provide shell interface system call modest amount kernel instrumentation monitoring code help gather experimental results 
significant change scheduler main loop lines code update thread descriptor thread just ran lines select thread run 
lines implement system call manage bvt scheduling user space specify warp runtime limits set scheduler parameters move threads schedulers 
new lines routine add thread run queue check see new thread earlier effective virtual time current invoke scheduler 
new lines signal delivery warp behalf threads set bvt warp flag thread signal sa flags field 
total kernel support bvt scheduling comes lines including comments whitespace total kernel size approximately lines 
total modifications linux system including instrumentation code header files user level shell interface bvt scheduling totals lines code took engineer weeks write debug 
simplicity bvt scheduling lines code significant advantage approaches favoring relatively small embedded systems 
experiments linux bvt implementation evaluated measuring behavior applications real test mpeg play play mpeg video decoder playing back mpeg video files frame second warp 
modified record frame got displayed time reading system clock receiving shared memory operation complete event define time millisecond ideal time previous frame int run millisecond bursts warp percent cpu modeling heavy interactive process 
grep unmodified linux grep find 
cont run continuously warp modeling process 
rt runs milliseconds warp sleeps milliseconds corresponding warp time limit unwarp time requirement modeling periodic hard real time task 
experiments run pentium iii mhz system mb ram running linux modified include implementation bvt enabled disabled runtime switch 
kernel modified generate memory log context switches warping events measure overhead bvt scheduling implementation 
timestamps pentium cycle counter accurate microsecond provided machine independent layer 
noted numbers obtained logs 
experiments set server warp mpeg play equally 
experiments context switch allowance set milliseconds resulting context switch rate cpu bound jobs comparable system linux solaris 
allowance affects time slicing threads thread immediately dispatched wakeup evt equal current thread 
measurements indicate scheduler overhead runs level scheduling overhead includes costs log generation overhead measurement making slight overestimate context switch indirect costs reduced cache tlb performance scheduling algorithms incur costs 
scheduler overhead indicates cost significant bvt considered 
experiments indicate thread gets percent weighted fair share cpu measurements section stricter notion time ms bvt look better linux appear worse reflecting visually noticeable 
measure bvt linux frames frame rate late table 
video player frame performance competing large scale text search 
frame milliseconds frame time 
thread runnable significant period time 
argued section occur suitable scheduling window time 
rest section focuses dispatch latency response time 
mpeg player grep measurement captures variant scenario described software engineer watching training video running mpeg play linux pc running way parallel grep large number files product source tree 
table characterizes mpeg performance configurations bvt scheduling play server warped programs warped standard linux scheduling default parameter settings programs 
subjectively bvt video basically glitch free standard linux video painful watch 
assessment supported measurements 
line table indicates linux produces roughly frames produced bvt time interval leading roughly half frame rate 
mpeg play implementation video playback simply slowed amount held strictly real time drop half frames multiple frames time 
frames delivered frames late linux late ms net effect unacceptably poor quality video playback standard linux 
bvt little percent frames late due conflicts video performance fine 
large way grep receives roughly cpu linux reasonable price pay high quality video back 
performed experiments running mpeg play concurrently strictly compute bound test program 
standard linux scheduler correctly gives compute bound processes lower priority differences significant 
strictly compute bound applications realistic compared real text search extensive disk 
standard linux scheduler surprisingly running mpeg play various batch applications suggesting sophisticated scheduler compelling really latency critical workloads hard real time 
measure bvt linux frames late late max 
int 
latency table 
performance video player int late time test late milliseconds frame time 
measure bvt frames late max 
int 
latency mean int 
latency table 
performance video players int mpeg player interactive task table shows results running mpeg player instance int 
bvt produces frames time linux delays frames outside test run time seconds delivers milliseconds 
maximum interactive latency bvt larger expect giving preference mpeg milliseconds unnoticeable increase interactive applications 
table shows results running mpeg players instance int just bvt 
test suggests bvt able handle multiple simultaneous latency sensitive tasks 
running mpeg players increase maximum interactive response milliseconds test quite small mean milliseconds remains similar test 
hard real time thread performance table shows performance test programs rt int cont running bvt 
expected rt dispatch latency comparable linux context switch time cpu share cpu consumption period 
int longer response time acceptable interactive threads far superior batch response time 
table shows performance test programs rt having failed infinite loop 
int cont continue receive similar share cpu comparable response time measure rt int cont cpu share disp 
latency ms ms ms table 
real time thread interactive batch measure rt int cont cpu share disp 
latency ms ms ms table 
real time thread failure interactive batch failure 
example int command line interpreter allow user restart thread recover 
contrast strict priority scheduler rt higher priority thread completely starve making impossible user regain control system 
dispatch latency int ms worst arise ms checking warp time limits granularity detect exceeding ms boundaries 
experiments show bvt scheduling provides low latency response real time interactive tasks competing batch processes general purpose operating system dealing infinite loop failures high priority tasks 
linux substantially worse quite successful heuristic identifying latency sensitive processes 
expect generalpurpose schedulers perform worse linux 
deadlines compare effectiveness bvt scheduling achieve low latency specialized real time scheduler implemented deadline scheduler dbs ran number experiments comparing bvt 
dbs thread requests reservation form requesting units cpu times 
scheduler accepts request feasible satisfy previous requests accepted point 
runs accepted reservations earliest deadline distributing leftover cycles round robin threads reservations 
test programs configurations test program simulates real time task scheduling deadline reservations dbs 
requests reservations runs 
request denied counts deadline missed run reservation 
reaches deadline time received desired quanta counts deadline missed run reservation 
behavior favors making deadline compared just running stage 
picks reservation parameters follows 
picks time deadlines uniformly distributed calculates requested amount cpu actual need uniformly distributed deadlines deadlines dbs exact bvt diff fixed prio bvt round robin low medium high hopeless 
percentage deadlines different schedulers relative different levels contention indicated axis assuming accurate cpu need predictions 
levels contention correspond low medium high hopeless 
prediction error calculated specified 
calculated test parameter specifying thread runs 
thread willing run point deadlines easy schedule approaches moves closer resulting constraint harder satisfy 
approximate error prediction cpu need introduces error modes best guess corresponding positive negative mixed respectively 
average magnitude test parameter range 
models application reserves extra cpu ensure deadlines risk having requests denied causing requests denied unnecessarily 
test workload configured consisting instances instance cont run bvt dbs comparison scheduler fps weighted round robin scheduler wrr bvt warp threads various values 
running dbs cont receives quanta 
running fps instances priority highest priority 
running bvt quantum advances set dividing cpu instance exceeds fair share 
instances warp respectively modeling threads different latency requirements 
deadlines prediction error shows deadlines various test configurations completely low contention dbs upper dbs middle dbs lower bvt err err err err 
deadlines relative prediction error low contention deadlines feasible 
cally accurate cpu predictions 
dbs column represents optimal performance fcfs handling reservation requests predictions exact dbs runs task task deadline 
waste resources deny requests satisfy favor ones occur inaccurate estimates 
measurements show bvt dbs behavior fixed priority absence failure 
wrr expect 
bvt diff different warp values performs better bvt instances warp values 
reality different tasks different latency requirements different warp values sense practice 
dbs threads attempt schedule time run risk refused 
conflict just fine bvt warp value 
deadlines prediction error figures show effect prediction error dbs 
graphs degree error vertical bar runs bar dbs upper positive error prediction higher actual need second bar dbs middle positive negative error third bar dbs lower negative error 
horizontal line graph fraction deadlines bvt level contention 
bvt sensitive magnitude sign error bvt rely thread prediction cpu needs 
horizontal line vertical bars bvt making larger fraction deadlines dbs 
considering graphs bvt performs dbs high contention cpu predictions error competitive dbs medium contention error 
performs just medium contention dbs upper dbs middle dbs lower bvt err err err err 
deadlines relative prediction error medium contention deadlines feasible 
high contention dbs upper dbs middle dbs lower bvt err err err err 
deadlines relative prediction error high contention deadlines feasible 
dbs low contention prediction error reaches 
error prediction degrades dbs significantly especially high load scheduling matters 
experiments suggest application developers program cpu predictions bvt better dbs advantages bvt dbs simplicity efficiency greater generality 
predicting cpu needs difficult uncertainties workload cache behavior tlb behavior interrupts 
example cpu cycles decompress frame vary order magnitude mpeg player section 
predictions exact deadlines dbs bvt 
basic result apply deadline scheduling approaches smart 
systems differ dbs primarily algorithm deciding accept reservation request adding requirements mere feasibility improve fairness 
expect differences affect result 
utility deadline scheduling utility deadlines basis operating system scheduler limited 
tasks network input processes specific deadlines accomplish processing deadline notion apply tasks latency sensitive 
tasks predict processing requirements advance risk having deadline requests refused intermediate point execution system 
example network input process predict needs process packet packet arrives predict cycles required process arrive 
request deadline processing right packet arrives refused leaving thread time slice low priority threads 
hand threads suitable deadlines predictable processing requirements request reservations advance typically periodic tasks requirements easily expressible bvt parameters handled simpler general scheduler bvt 
jitter control difficult deadline schedulers 
thread allows short time requested starttime deadline risks request refused scheduler latitude satisfy causing run time sliced unpredictable delay jitter 
thread allows long time risks significant jitter periodic execution scheduler free dispatch time start time long sufficiently deadline 
conversely warp time limit unwarp time requirement regarded efficient way specify deadline requirements periodic tasks 
parameters useful cases 
deadlines introduce extra complexity scheduler writing task code specifies deadlines handles refusal 
claimed benefit deadline scheduling ensures threads deadlines open system overload opposed threads degraded missing deadlines 
practice system needs ensure particular threads deadlines just random subset 
system needs partition threads critical non critical limit threads allowed reservations critical set sized deadline requests fact satisfied 
consequently system necessarily closed deadlines open best efforts threads 
partitioning feasible multilevel bvt place critical threads level scheduler non critical threads open portion second level scheduler 
structure claimed benefit deadlines relevant avoiding priority inflation priority scheduling designers pick increasing priority levels attempt ensure meet response requirements 
closed realtime system set threads requirements known warp parameters algorithmically set 
warp parameters best effort threads controlled system described section 
deadline scheduling appears limited utility applications identify ability bvt support real time scheduling ability address lower cost complexity wider range system requirements configurations described section 
configuring bvt scheduling configuring bvt meet application response cpu sharing requirements requires careful selection parameters levels especially hard real time systems 
section describes configure bvt scheduling systems 
key dimensions configure thread cpu share warp limits response time 
cpu share portion cpu allocated thread extended period time absolutely relative threads 
standpoint cpu share types threads reserved effort re thread specified percentage cpu cycles reserved 
best efforts thread shares cpu cycles left re threads claiming share relative demands threads 
systems bvt may entirely re entirely combination described 
warp limits thread specify limits cpu dispatch preference thread limiting amount temporarily warp scheduling weighted fair sharing 
response time thread real time signaling event occurs thread dispatched handled event 
key bvt parameters thread weight warp warp time limit unwarp time requirement set achieve desired behavior application described subsections 
hard real time systems hard real time system reserves cpu share response time threads guaranteed respond events specific real time limits 
cpu share static set re threads system designer admission control module selects mcu advances obtain desired sharing determine scheduling window time interval desired sharing guaranteed occur 
illustrate calculation consider threads receive cpu respectively assume threads warp 
system designer calculates mcu advance threads reciprocals weights scaling small integers 
example weights reciprocals normalizing multiplying yields mcu advances 
system designer calculates virtual window smallest amount virtual time property system starts state threads virtual times threads remain runnable point system reach state threads virtual times calculate designer computes common multiple mcu advances times 
example suppose 
virtual window start threads virtual time point reach virtual time 
system designer calculates physical window amount real time takes threads consume units virtual time 
example takes threads respectively consume virtual time units physical window 
system designer knows real time window threads remain runnable thread receive exactly weighted share 
extend analysis threads warp 
high priority warping threads warp time limits typically set limit cpu share scheduling window 
limits may restrict thread running far 
example example hard real time threads allocated percent cpu limited warp time limits amount scheduling window 
case cpu share specified threads need accurate long corresponds share provided warp limits 
handle threads calculations weights cpu share deducted total available weights remaining threads determined 
example allow percent required threads reduce cpu share thread original example perform calculation shares threads adding 
warping threads unwarp time limit mcu advance accurately specify cpu share changing choice necessary get accuracy 
example real time threads unwarp time limit percent share cpu advance set 
worst case threads unblock warp run cpu shares number scheduling windows warp allows advance 
example run cpu shares current scheduling window 
case allow worst case share cpu computing available threads scheduling window 
example allow example relative threads actual cpu share allocated percent 
alternatively increase application notion scheduling window minimum window considering far lower multiple cpu share 
example application scheduling window times minimal thread times cpu share scheduling windows twice share worst case 
approach attractive applications generally need fine grain guarantee sharing 
instance millisecond thread allocated percent cpu receive share milliseconds warping thread sleeping warped aggressively run possible re system requires admission control module checks attempt create new re thread system able accommodate new thread 
example new thread requiring percent cpu percent unallocated refused cause removal reduction shares existing threads depending system policy 
acceptable system needs weights threads new threads created terminate 
situation arise system design time system configuration time system execution systems supporting dynamic configuration 
admission control module explicitly part bvt different systems different modules policies depending requirements bvt scheduler 
example statically configured re behavior reflects fact thread warping borrowing allocation pay back gaining long term advantage 
system admission control performed module checks allocation configuration system initialization time normal system execution 
system dynamic set threads may need module execution 
warp limits setting values accurately possible minimizes negative impact thread failure dispatch latency response time threads 
values selected measuring time thread longest processing adding safety margin plus determining minimum reasonable time needs run warped 
focus high priority periodic threads reasonable predicting processing requirements behavior 
parameters unpredictable non periodic threads 
accurately setting parameters particularly important high priority periodic threads 
lower priority threads need set parameters critical 
example network input thread may unwarp time requirement relying cpu share limit impact system overload allowing multiple cpu share scheduling window worst case discussed earlier 
may attractive set non zero unwarp time limit thread input packet buffer large packet inter arrival times unpredictable 
non zero unwarp time requirement thread delayed dispatch handle incoming packets traffic level high causing batch process packets time waking individual packet 
result efficient packet handling cycles threads cost slightly delaying input packet handling 
warp value thread may fixed creation general putting limit dimension warping admission control mechanism limit warp values allow threads achieve response requirements developed 
response time approach response time pick warp values mimic behavior conventional priority scheduler assuming application system threads assigned priorities latency sensitivity 
thread latency sensitive thread classified higher priority meaning gets higher priority dispatch run threads competing cpu 
earlier formulation bvt provided separate warp limit thread allowing thread warp value limit 
simplified scheme observing threads practice warped 
thread allowed multiple levels warp deal instance priority inversion issues 
re threads priority mapped warp value thread algorithm 
set current warp value consider lowest priority level 

set warp value threads priority current warp value 

go priority level increment current warp value maximum value threads priority amount thread avt increases running full time period 

threads go step terminate 
low priority interactive threads may operate warp time limit limit may fairly long execution times occasionally losing warp 
cases assume value purposes calculation view threads level timeslice run longer 
consider dispatch latency response time re thread assignment assuming thread cpu share limit specified weight warp limits 
assumption reasonable re thread limits failed parameters set incorrectly 
thread fails concerned containment damage response time 
highest priority latency sensitive thread dispatched immediately signaled executed warp value ensures runs warp time limit preempted second latency sensitive thread blocks 
thread requires microseconds processing time respond event response time context switch time including interrupt disable time latency 
microseconds section 
response time assumes threads priority dispatched time 
threads response time increased worst case sum response times threads typical case thread response time significantly equal priority thread executed sequentially occur conventional priority scheduler 
context switch allowance ensures second competing thread logical priority level run executed real time 
lower priority threads worst case dispatch latency response time plus worst case times higher equal priority threads conventional priority scheduler absence failures 
higher priority thread fails going infinite threads explicitly schedule nonconflicting times conflict application level schedules 
loop response time processing standpoint lower priority threads response time calculation presumably preempted behaved threads demonstrated section 
assuming unwarp time requirements higher priority threads dispatched application scheduling window worst case sum higher equal priority threads 
case requires threads unblock time fail infinite loops presumably extremely improbable 
warping thread zero unwarp time requirement assume fails infinite loop exceeds causing get run lowest priority threads restarted 
lower priority threads may run zero indicating warp time limit 
assume warp small running times thread evt comparable svt begins timeslice lower priority threads 
thread response time requirement necessarily comparable effectively relying control excessive cpu priority level threads 
case interactive applications 
equivalence scheme absence failure conventional priority scheduler allows bvt directly systems applications designed priorities little modification sense bvt regarded mapping notion priority virtual time share latency requirements effectively evaluated scheduler single simple consideration thread evt 
complex model managing warp values possible necessary applications considered date 
scheme provides basis admission control module hard real time system 
example flight control system life critical flight control system re scheduler critical flight control threads guaranteed shares cpu response times strict limits maximum short term warp limit parameters long term weight 
tasks determined characterized fixed system design time allowing parameters set accurately system performance guarantees verified 
sense scheduler focus particular thread failure sandboxing techniques memory protection catch forms failure harm system solve halting problem 
application level checks catch higher level forms failure performing wrong action right time 
handle failures watchdog thread run periodically detect restart failed threads 
sophisticated failure detection handling option 
best efforts systems entirely system threads allocated fixed range weights corresponding different allocation preferences 
example interactive tasks may weight batch threads may weight giving half cycles interactive threads fully loaded case 
number threads system increases share cycles thread receives decreases accordingly relative weights threads preserved 
warp limits warp limits set reserved effort systems non zero limits primarily higher priority threads mpeg player 
warp limits conjunction scheduler logging facility determine application threads fact executing execution parameters developer expecting 
response time re warp assignment scheme system response time analysis assumes share cpu available thread adequate meet processing requirements 
response time degrades proportional thread cpu share scheduler experiences overload 
provide simple api conventional applications system provide single priority parameter specify thread creation time thread signal handler 
system maps priority value fixed set values weight warp warp time limit unwarp time requirement system administrator selected values 
example user priority latency sensitive user threads mpeg display thread providing weight versus normal threads warp time limit milliseconds warp computable relative priority interactive threads 
threads warp small warp interactive threads 
normally execute presumption executing warped normally warp computed assuming described earlier 
threads lowest priority ones non zero warp warp interactive thread evt svt executing time case start timeslice interactive threads executing 
example large scale web server large scale web server google search engine receives large number competing search requests 
requests simple handled small number quanta frequent complex queries take times long process average 
bvt system designer guarantee fair share long queries providing response time short queries cases 
fixed number threads say assigned handling requests 
thread repeatedly dequeues request request queue processes repeats sleeping requests request queue 
new request arrives sleeping thread longest added request queue threads busy 
thread assigned weight warp sufficient handle typical simple request say 
illustrate dynamics arise setup consider scenario system begins idle receives complex query 
thread dequeues query begins working 
svt advances thread evt 
simple query arrives thread wakes process avt advanced svt part wakeup 
units warp thread may run quanta row thread waits 
short queries complete half time compared unix style round robin 
third complex request arrives thread runs quanta time slices thread 
subsequent short requests complete third time compared round robin 
behavior continues system overwhelmed short queries sustained time period 
simple query running borrowing time complex query avt thread handling simple query advancing svt 
svt advances past point threads evt including complex query thread passed point 
threads consumed warp short queries complex queries get chance run matter offered load complex query receives weighted fair share cpu long run 
combined real time best efforts systems system supporting mixture re threads configured level bvt scheduler level handling re threads second level handling threads dividing cpu cycles available threads weights 
second level scheduler scheduler uses threshold mode threads run warped relative level warp specified threshold 
level re scheduler corresponds re system cpu share assigned threads scheduler re techniques applied level techniques applied second 
scheduler warp value set effectively give higher priority re threads desired 
impact response time re threads giving scheduler priority limited scheduler warp time limit unwarp time requirement threads 
example scheduler warp value greater re thread handles disk subsystem 
mpeg player frame update example dispatched lower latency providing scheduler thread cpu share significantly increasing file system response time dominated physical disk latencies 
scheduler thread exceeds share warp limits behavior threads degrade accordingly appropriate best efforts scheduling 
configuration user sees high quality video play normal non overloaded conditions disk actions occasionally delayed favor displaying new video frame delay occurring rotational latency longer seek latency 
re scheduler handle non latency sensitive threads simply need reserved cpu share 
instance periodic review housekeeping task executed re scheduler warp weight equivalent percent cpu ensuring review performed matter want demand threads 
level bvt scheduler approach supports re threads bvt scheduling algorithm level clean interface separation levels 
allows system configuration specify aggregate cpu share reserved threads 
minimizes need modify weight warp values threads re levels 
supporting re threads single scheduler incurs overhead revising weights warp values threads time new thread created deleted 
single scheduler allow full control aggregate cpu share available threads 
example router software modern router includes performance critical real time component deals packet forwarding plus real time routing protocol tasks timesharing command line interpreter cli tasks managing router 
packet forwarding bvt scheduled re threads including interrupt service routines signal handlers providing low latency dispatch guaranteed share cpu 
routing protocol tasks run re level lower priority 
thread implementing signal processing processing soft modem execute re scheduler 
guaranteed low latency dispatch limited specified long term share cpu plus limited number cycles units time 
second level scheduler runs cli threads vary number depending users administrators accessing router 
bvt guarantee specified cpu share routing protocol tasks cli threads critically important ensure packet forwarding overload disable tasks 
instance network administrator able cli correct misconfiguration router causing excessive level packet forwarding 
bvt insures packet forwarding receives low latency service long system overloaded routing protocol processing assured receiving cpu accordance weight long term 
bvt scheduling router various specialized ad hoc throttling mechanisms keeps router implementation behavior simpler error prone 
example multi user timesharing conventional timesharing system linux uses various heuristics scheduler guess programs latency sensitive interactive requiring explicit setting parameter warp 
example linux uses parameter decremented process runs full quantum process dispatched unblocks heuristic indications interactive latency sensitive program 
incremented process blocks quantum 
heuristic learning mechanism readily adapted bvt 
warp value selected warp real time applications 
linux mechanism modified update warp value depending interactive process behaves 
consequently process behaves batch ends warp acts interactive retains full warp value 
interactive task unblocks typically evt causing run immediately delayed real time application mpeg player just latency requirements dictate 
interactive thread warp relatively small meant enable rapid completion small amount enable thread cpu extended time period 
warping provides behavior proven systems unix scheduler modest preference thread order improve response time interactive tasks 
provided part general scheduling mechanism accommodates real time tasks 
prevent undue interference users process inherit weight warp parameters parent process 
user process effectively nice processes reducing warp parameters weight spirit unix nice command increase 
related various scheduling algorithms number different bases selecting thread dispatch 
previous systems virtual time basis bvt measuring controlling longterm sharing cpu behaves similarly 
provide application control low latency dispatch introduce extra mechanisms deadlines 
start time fair queueing describes hierarchy schedulers similar multi level scheduling bvt 
contrast virtual time bvt priority schedulers base dispatch decisions priority value associated thread running ready thread highest priority represented lowest numeric value 
schedulers problem high priority thread going infinite loop permanently lower priority threads 
example posix realtime scheduling user may assign fixed high priority latency sensitive threads assuring low latency dispatch highest priority thread 
show mechanism significantly skew long term cpu allocation point total starvation single highest priority thread 
priority scheduling extended providing time slicing threads equal priority having system modify priority timesharing threads cpu consumption commonly done unix implementations 
requires separate accounting cpu usage mechanism modify priority part thread execution 
deadline scheduling spring smart threads declare cpu needs system 
periodic thread may express sequence similar reservations single period length need period 
system accepts request case thread guaranteed dispatched need system rejects request case thread receives preferential dispatch 
bvt reservation capability modularly separated scheduler provided higher level system function reservation admission control module described section 
instance appears system resource planner perform function top bvt 
separate facility allows unit cpu resource accounting planning separate abstractions threads processes done mercer processor capacity reserves 
smart scheduler adds deadline scheduling real time threads basic virtual time mechanism notifying applications determines deadlines 
smart adds bias virtual times non real time threads preferentially dispatching real time threads provide application control bias 
believe bvt scheduling performs comparably smart video player application incurring complexity deadlines 
furthermore smart deadline systems risk system predicts deadline met fact due threads full reservation risk converse case sudden network interrupt overload example 
bvt scheduling multi level implementation provides universal scheduler configurable support applications hard real time tasks interactive applications batch jobs ensuring weighted fair sharing competing threads protecting low latency threads excessive processing cycles 
level bvt scheduler allows hard real time threads run strictly admission controlled regime called soft real time interactive batch thread run second level scheduler gracefully degrades increasing load 
linux implementation demonstrates scheduler simple implement provides performance incurring low time space overhead context general purpose operating system kernel 
bvt primary innovation extends virtual scheduling ability thread warp back virtual time effective virtual time scheduling earlier causing dispatched earlier 
warping mechanism associated warp limits results show bvt provides real time performance comparable specialized deadline schedulers supporting general purpose task scheduling 
standard technique giving unblocking interactive threads slight priority boost realized bvt corresponding warp value unifying proven heuristic general scheduler framework 
virtual time base bvt provides single simple measure handles cpu share latency requirements superior priority deadlines basis 
particular warping effectively encodes priority virtual time paradigm simple algorithm described disrupting fair sharing mechanism 
context switch allowance migration penalty factor costs operations virtual time measure prevent thrashing threads processor processors 
bvt supports unpredictable threads response time commitment cpu share extra mechanism scheduler 
supports best efforts scheduling reserved effort threads allowing best effort threads request low latency dispatch 
requests honored limit availability cpu resources time execution accepted denied worst case estimates cpu demands occurs scheduling 
advantage analogous best efforts datagram networks bandwidth shared efficiently circuit switched approaches freeing applications requirement fitting communication mechanisms small fixed size pipes 
contrasting merits bvt measurements show deadline scheduling significant vulnerability inaccurate prediction processing requirements causing approach bvt predictions little percent 
prediction problem significant insurmountable practical situations processing requirements strictly periodic task mpeg playback vary order magnitude 
interrupt service routines effectively steal cycles making number cycles available time period uncertain 
point difficult trade sizing scheduling window deadline reservation minimize jitter 
issues implementation complexity approaches support virtual time scheduling extended bvt superior solution hard real time 
bvt demonstrates key principle operating system design better provide single simple measure virtual time provides specified behavior relative tasks applications map requirements measure require applications specify requirements detail 
single measure approach applications system policy modules contain policies mapping measure operating system performs complex fixed mapping effectively incorporates fixed policies difficult applications achieve desired results 
simple measure approach fitting principle separating policy mechanism allows systems determine mapping design configuration time forcing take place run time attendant overhead 
see bvt important step achieving fully general efficient stable operating system kernel simultaneously execute wide range applications different requirements behaviors failure modes 
hope going see tested deployed spectrum support results date 
initially supported cisco systems project high speed switch router software 
shepherd jack stankovic anonymous reviewers plus andy valencia dan li help improving content presentation 
brin 
personal communication 
www google com 
demers keshav shenker 
analysis simulation fair queueing algorithm 
proceedings acm sigcomm pages september 
duda cheriton 
time bvt scheduling 
stanford edu pub bvt html 

proportional share resource allocation algorithm real time time shared systems 
proceedings th ieee real time systems symposium pages december 
goyal guo vin 
hierarchical cpu scheduler multimedia operating systems 
proceedings usenix symposium operating system design implementation pages october 
jones barrera forin leach rosu rosu 
overview real time architecture 
microsoft research technical report msr tr july 
microsoft redmond wa 
jones rosu rosu 
cpu reservations time constraints efficient predictable scheduling independent activities 
proceedings th acm symposium operating system principles pages october 
mercer savage tokuda 
processor capacity reserves multimedia operating systems 
proceedings ieee international conference multimedia computing systems pages may 
mogul ramakrishnan 
eliminating receive livelock interrupt driven kernel 
acm trans 
computer systems august 
wall 
svr unix scheduler unacceptable multimedia applications 
proceedings ieee international conference multimedia computing systems pages november 
lam 
design implementation evaluation smart scheduler multimedia applications 
proceedings sixteenth acm symposium operating systems principles pages october 
rowe patel smith 
performance software mpeg video decoder 
proc 
acm multimedia pages august 
stankovic ramamritham 
spring kernel new paradigm real time systems 
ieee software 
waldspurger weihl 
lottery scheduling flexible proportional share resource 
proceedings symposium operating system design implementation pages november 
