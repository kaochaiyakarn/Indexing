proceedings supercomputing dimensions meaning hinrich schutze center study language information ventura hall stanford ca representation documents queries vectors high dimensional space established information retrieval 
proposes represent semantics words contexts text vectors 
dimensions space words initial vectors determined words occurring close entity represented implies space dimensions words 
vector representations dense cumbersome directly 
dimensionality reduction means singular value decomposition employed 
analyzes structure vector representations applies word sense disambiguation thesaurus induction 
new representational scheme introduced tries provide basis determining closeness meaning 
approach motivated vector representations information retrieval 
ir systems smart sire documents queries represented vectors term space 
assumption documents similar extent contain words 
obvious extension methodology representation contexts assign context set words occur close proximity say window words 
content expressed different words simple scheme contexts similarity measure close meaning 
problem absence presence word little information treat words unanalyzed symbols indices term vectors 
lexical representations comparing contexts enriched 
approach adopted represent words term vectors reflect pattern usage large text corpus 
shows done 
terms cash sport dimensions space similarity measured 
columns matrix represent words bank interest finals 
entry matrix cooccurrence count 
instance cash bank encodes fact words cash bank cooccur times hypothetical corpus 
cooccurrence defined respect windows size basis sentence boundaries 
cosine angle vectors measure get correlations words cos bank interest cos interest finals cos bank finals 
numbers interpreted geometrically shown 
terms axes words vectors components various dimensions determined cooccurrence counts collocation matrix 
similarity vectors straightforward graphical equivalent proximity multidimensional space corresponding collocation matrix 
bank finals close close vector interest 
position compute representation context reliable bagof words method criticized normalized average centroid vectors words context seen approximation semantic content 
words context frequently describe current context vectors pull centroid bank interest finals cash sport collocation matrix 
cash sport bank finals interest context ffi context oe vector model context 
direction topic content 
possible defeat scheme describing content exclusively words normally express unrelated thoughts 
situations expected rare 
look word sense disambiguation see representation context put 
consider example word interest percent tag uses interest sense charge borrowed money concern tag feeling accompanies causes special attention 
percent sense occur contexts score high cash dimension concern sense occur contexts score high sport dimension 
disambiguate occurrence interest position text computing context vector position determining close cash sport dimensions space 
context vectors depicted 
vector context closer cash probably occurrence percent sense interest vector context closer sport occurrence concern sense 
space dimensions cash sport impoverished representation 
better results words considered 
supercomputing crucial 
collocation matrices usually zeros large windows corpus size words 
result pair words 
practise means cells filled 
example typical matrix zeros 
systematic framework needs efficient representations vectors components take space time processing 
dimensionality reduction means singular value decomposition performed 
algorithms mike berry mainly lanczos algorithm las 
shown section vector representations key properties distributed representations characteristic parallel distributed processing 
referred sublexical representations analogy terms subsymbolic subconceptual connectionism 
word sense disambiguation word sense disambiguation important areas language processing 
instance different senses word different translations foreign languages rendered differently text speech system 
main problem sublexical representations disambiguation find directions space correspond best various senses ambiguous word 
imagine ways identifying directions instance finding dozen typical uses computing centroid 
reliable automatic method taken cluster training set contexts assign senses clusters assign new occurrences sense closest cluster 
clustering programs autoclass buckshot 
autoclass bayesian classification program theory finite mixtures 
determines number clusters automatically imposing penalty new cluster fact clusters necessarily better account data 
due computational complexity high quality classification buckshot efficient linear algorithm large data sets shown table 
buckshot clusters items applying quadratic high quality clustering algorithm random sample size kn constant extending classification linear time rest data set 
word training set test set contexts sense correct months contexts months contexts clustering classes rare senses major sense sum sum capital interest motion plant ruling space suit tank train vessel table disambiguation experiments 
word sense pos definition capital stock goods seat government interest nv feeling special attention charge borrowed money motion movement proposal action plant factory nv living ruling nv authoritative decision exert control influence space area volume outer space suit action process court set tank combat vehicle receptacle liquids train line railroad cars teach vessel ship plane blood vessel hollow concave utensil table definition senses table 
table summarizes disambiguation experiments conducted far 
column contains word disambiguated 
cases inflected forms excluded ambiguous 
decision sense spaces mean outer space words training test set taken new york times news service 
training sets consisted months period may october 
test set november vessel trained june october tested may november 
columns show ambiguous word occurred test training set 
column clustering autoclass buckshot 
column gives number classes autoclass number classes requested buckshot 
usually classifications classes tried 
successful trial reported table 
infrequent senses ambiguous words excluded 
percentage column rare senses indicates occurrences accounted 
includes repetitions identical contexts tank plant interest suit vessel words repeated contexts count 
column major sense shows dominant major sense word instance frequent uses tank vehicle uses receptacle uses 
contexts test set disambiguated sense closest cluster 
instance word nearest neighbors absolutely absurd whatsoever totally exactly understood truly matter dip copper drops slide trimmed slightly squeeze flat mix witty stylized tale dog porch crawling downstairs sofa crawled makeup glossy skin gel hue mediating reconciliation negotiate cease peace talks immediate nations oas keeping hoping bring rest drawings picasso dali monet paintings artwork pathogens bacteria organisms bacterial parasites humans microbial parasitic amino senses grasp psyche truly clumsy naive innate awkward realm instinct table randomly selected words nearest neighbors sublexical space 
context tank test text closest cluster training set assigned sense tag vehicle context disambiguated belonging sense 
columns table contain absolute number occurrences sense percentage correct disambiguation 
table glosses major senses words 
column pos shows part speech word 
senses realized verbs nouns 
general verbs harder disambiguate nouns results plant interest ruling train show success range possible 
senses occurred new york times excluded tank top think tank tank metaphorical senses plant cup garfield physical plant school plant legal share sense interest adjectival sports senses capital capital punishment washington capitals verbal sense suit proper card game sense follow suit rule ruling orderly succession drive train train 
senses occur fixed expressions easy filter preprocessing 
important note senses assigned classes basis training set 
case autoclass classes errors members training corpus assigned 
case buckshot majority members training corpus determined sense assignment 
possible cluster occurrences test set finely cluster homogeneous 
extreme case classification classes items test set guaranteed correct 
classes assigned training set high number classes unproblematic 
word space applied word sense disambiguation information sublexical space reduced binary opposition particular context instance sense sense 
information sublexical representations words viewed constituting thesaurus interpreting proximity space measure semantic relatedness 
table shows randomly selected words nearest neighbors 
set words contained proper names chun trademarks neighbors listed order proximity head word 
sample turns representative general nearest neighbors words space intuitive ones shown makeup significant number words keeping characterized spatial neighborhood 
characterization better clearly set typical topics word question delineated topics 
makeup mediating pathogens topic areas clear boundaries 
nearest neighbors terms appropriate describing topic area 
stands people liberation front absolutely senses clearly delineated topics 
nearest neighbor sets contain counterintuitive words 
mainly financial contexts new york times market april keeping topic 
reason nearest neighbors random 
shows limitations way word space computed 
key article infrequent word occurs report exhibition designer new york new supercomputing supercomputer supercomputers cray computing thinking processors computer computer microcomputer risc workstations ibm hillis software mainframe pcs desktop laptop microprocessors technology peripherals compatible vax micro intel convex sparc unix jobs nec mips fujitsu ps xerox pc technologies cisc apple packard cmos os sx laptops interface hitachi algorithms hewlett toshiba networked metaphor ast chip server microsystems optical microchip gallium technologically silicon processing digital compaq software interface silicon lotus circuitry technological transistors interfaces sparcstation hp midrange microsoft mp lsi robotics rom chips microprocessor lc motorola macintosh amdahl devices rl applications logic cupertino advanced adobe micron ncr presentation harnessing canon sunnyvale megabytes application graphical vlsi internet encryption bipolar icl computation font dos spreadsheets tandem printers disk modem systems facsimile hackers networking microchip configured circuits mips zenith user lasers bytes strategies diskette etch disk hardware clones machine macs data users vector bis scanner handheld xt amd semantic field supercomputing sublexical space 
york museum lands architects june 
contains architectural terms probably reason porch downstairs ended close 
article representative general usage word dominated computation vector 
problem disappear larger corpus 
word space classical thesaurus roget differ roget concentrates synonyms near synonyms nearest neighbors sublexical space include collocates terms frequently word question 
illustrate roget gives words dilemma nut crack knot problem 
prominent neighbors word space solve recurring panacea 
words important problem expressing content similar problem synonyms 
table evaluating proximity meaning proximity space correlate doesn show fine structure space particular location 
word supercomputing chosen closer examination small region space 
shows principal components matrix correlation coefficients nearest neighbors supercomputing center vectors similar neighborhood 
principal component captures similarity interesting variation data 
word plotted position determined projections second third major axis variation computed principal component analysis 
words position shown 
words moved points legible 
seen representations highly corpus dependent 
instance collocation matrix proceedings part semantic field supercomputing new york times topic supercomputing clearly distinct general computer science manufacturing computing machinery 
applications asset liability representations corpus dependent 
consider example information retrieval 
new york times document collection financial queries 
context fine distinctions different branches computer industry don necessary 
hand sublexical space collection articles devoted research development computer science richer structure location supercomputing articles microcomputers retrieved query supercomputing 
little manual labor involved inducing space representation finely tuned document collection question promising basis applications information processing 
analyzing sublexical space disambiguation results table improved 
parameters fixed arbitrarily may gotten suboptimal settings 
section investigates size window weighting dimensions space selection different sets dimensions 
window size table window sizes characters computing context vector 
sense limit window number characters number words long words better short words tend high frequency function words 
window size influence disambiguation performance 
answer question cluster context sets computed varying window sizes 
variability results clustering best window size may yield mediocre disambiguation results accident 
average clusterings taken time consuming 
deterministic expensive method needed 
canonical discriminant analysis cda linear discrimination method 
finds best weighting linear combination dimensions space ratio sum group distances sum group distances maximized 
task slightly different classification 
say dimensions sufficient clustering needed tease words apart linear scale cda 
conversely giving large weights dimensions low values original space result nice separation clustering procedure may able take advantage situation distance measure cosine concentrates dimensions high values 
results interpreted caution 
linear discrimination supervised learning method items training set labelled 
labelling thousands instances ambiguous word feasible simple trick employed 
discriminating ambiguous word sense tags corpus unknown artificially ambiguous words created author baby politicians train tennis 
pairs selected contexts pair word training set test set jun oct nov pair author baby pair train tennis pair politicians table frequency words cda 
words pair comparable frequency corpus distinct semantically different senses ambiguous words suit capital words nouns meaning verbs depends arguments general context 
percent occurrences train verbs see 
table lists frequencies cda words training test set 
shows generalization test set depends number dimensions window size 
solid line characters dense dotted line characters sparse dotted line characters 
point graph computed follows window size linear discrimination analysis performed data points training set dimensions value indicated horizontal axis 
computed weighting project points dimension 
optimal cutting point determined 
projection cutting point applied test set 
graph shows contexts test set discriminated correctly percent 
apparently characters ideal window size discriminating author baby results train tennis similar characters optimal size time characters produced generalizations close quality dimensions 
politicians graphs window sizes identical dimensions 
suggests characters window size computing context vector 
suggests dimensions improve disambiguation results 
unfortunately dimensions extracted computing singular value decomposition tested curve keeps rising flattens fast dimension 
discrimination author baby different window sizes dimension sets 
optimal dimension weights discriminating author baby train tennis 
nation graph politicians clear rising tendency improvement perfomance dimensions 
dimension weights second question dimensions important distinctions relevant 
preliminary answer 
shows optimal weights computed cda algorithm dimensions 
dimensions marked horizontal axis figures 
height rectangle shows relative weight corresponding dimension 
weightings stable new dimensions added incoming dimension dampening weights changing gestalt weight graph 
different weightings necessary different word pairs 
instance dimension second marked dimension left weight zero author baby high positive weight train tennis 
dimensions second third marked dimensions right weights signs author baby weights different signs train tennis 
high positive values strongly favor sense discriminating author baby cancel train tennis 
optimal weights politicians display pattern 
evidence indicates different dimensions important different semantic distinctions potentially useful 
distributed representation experiments conducted find groups dimensions important 
general singular value decomposition yields space leading dimension important second dimension second important doesn case disambiguation results table show 
data set contexts suit table classified dimensions 
error rate test set 
classification dimensions computed yielding error rate 
dimensions classified 
error rate 
suggests vector representations highly redundant dimensions error rate data set data set table sublexical representations distributed 
singular value decomposition computed different svd applications dimensions equally meaningful disambiguation task 
hypothesis confirmed classification second data set table contexts suit 
dimensions error rate 
deleting dimensions odd dimensions increases error rate information find classification moderate quality 
instructive repeat linear discrimination experiments sets final dimensions opposed sets initial dimensions 
evidence leading dimensions may relevant information immediately ones 
disambiguation basis dimensions attains optimal performance adding dimensions leads minor improvements 
final dimensions necessary correctness dimensions needed level performance 
curve final dimensions initially steeper counterpart 
research necessary find dimensions better 
discussion approach semantic representation proposed bears similarity latent semantic indexing lsi information retrieval singular value decomposition 
important difference lsi main purpose space reduction improve quality representations achieving better performance 
initial term document matrix noisy contains small counts inherently unreliable 
svd smoothing technique removes noise 
term term matrices described dense contain high counts due size corpus 
mentioned matrices typically contain zeros elements greater 
smoothing necessary deal small counts 
detection term dependencies motivation svd lsi 
documents may low similarity score original term space different terms express concept 
instance document may coast document uses shoreline 
truncated vectors computed singular value decomposition similar original term vectors coast shoreline occur documents 
loosely speaking singular value decomposition assign component 
result recall precision improve truncated vectors svd full term vectors 
application svd different original vectors coast shoreline collocation matrix similar coast shoreline words 
order test prediction noise detection term dependencies play important role application disambiguation experiment repeated unreduced vectors 
columns words collocation matrix cooccur interest normalized counts application square root 
context vectors interest june july computed summing vectors words word window occurrence interest set context vectors clustered classes buckshot applied context vectors occurrences interest november 
sense prediction correct concern contexts percent contexts 
result identical truncated vectors described concern percent 
indicates contrast lsi application svd influence performance case sublexical representations 
hand compact representation loss information possible singular value decomposition important lsi document vectors information retrieval sparse efficiently stored processed unreduced form 
compactness property principal component analysis crucial 
words represented component vectors memory required application program instance word sense disambiguation prohibitively slow 
sublexical representation depends high performance computing application aims efficient real world 
technical motivation dimensionality reduction different sublexical representation close lsi far interpretation dimensions reduced space concerned 
long tradition social sciences principal component analyses understand variation large data sets 
instance survey elderly home variables subjected principal component analysis 
eleven principal components interpreted corresponding elderly people living vs share approach taken follows lsi interest interpreting dimensions gaining additional insights structure data rotating space order position axes intuitive way 
directions space treated equally 
important information measure similarity obtained words contexts computing correlation coefficient 
disambiguation results achieved compare favorably reported approaches 
instance methods perform slightly better average table 
rely thesauri bilingual corpora 
technical domains foreign languages thesauri bilingual corpora available 
word sense disambiguation basis sublexical representation needs raw text input virtually limitation application 
representations derived means dimensionality reduction differ statistical approaches small number parameters order estimated 
trigram models estimate millions billions parameters 
largest corpus sufficient estimate large number parameters reliably 
contrast couple principal components easily justified corpus words resulting robust estimates statistical parameters 
approach word sense disambiguation proposed different knowledge intensive methods 
classical ai word sense disambiguation knowledge representation logical infer ence 
challenge encode items knowledge may relevant tasks disambiguation integrate system respond appropriately 
goal achieved systems cyc far coming close 
application principal component analyses seen tool integrating large number constraints word imposing constraint sense neighborhood 
basic idea take notion semantic similarity seriously 
order dimensions meaning vector representations words reflect closeness meaning faithfully global optimization cooccurrence constraints necessary operation complex supercomputer perform 
semantic similarity underlies processes linguistics instance metonymy replacement name thing closely related psychology instance priming presentation concept subject reaction times short semantically related terms long unrelated ones 
host papers mutual information instance witness importance computational linguistics lexicography 
semantic similarity important intricate set lexical relations needed ambitious natural language processing linguistics relations hyponymy 
relations read sublexical space easily semantic relatedness space basis representation semantic theories dealing 
representations processes tend go hand hand way knowledge represented largely fixes appropriate processes vice versa 
novel approach semantic representation approach possible availability supercomputers linguistic research may lead theories semantics look different today 
indebted ken church patrick hanks john maxwell john tukey comments martin kay jan pedersen discussions help 
grateful mike berry nasa autoclass sdsc computing time xerox parc corpora corpus tools 
salton mcgill modern information retrieval 
new york mcgrawhill 
rumelhart mcclelland pdp research group parallel distributed processing 
cambridge ma mit press 
cheeseman kelly self stutz taylor freeman autoclass bayesian classification system proceedings fifth international conference machine learning 
cutting karger pedersen tukey scatter gather cluster approach browsing large document collections proceedings sigir 
methods statistical data analysis multivariate observations 
new york john wiley sons 
deerwester dumais furnas landauer harshman indexing latent semantic analysis journal american society information science vol 
pp 

jolliffe principal component analysis 
new york springer verlag 
yarowsky word sense disambiguation statistical models roget categories trained large corpora proceedings coling 
gale church yarowsky bilingual materials develop word sense disambiguation methods proceedings fourth international conference theoretical methodological issues machine translation 
brown della pietra della pietra mercer word sense disambiguation statistical methods proceedings acl 
lenat guha building large knowledge systems 
reading ma addison wesley 
church hanks word association norms mutual information lexicography proceedings acl 
