automatic language model adaptation spoken document retrieval dric john garofolo jonathan fiscus william fisher national institute standards technology bureau drive gaithersburg md usa cedric john garofolo jonathan fiscus william fisher nist gov describes experiments implemented nist adapting language models time improve recognition broadcast news recorded months 
experiments designed specifically improve utility automatically generated transcripts retrieval applications 
evaluate potential approach time adaptive automatic speech recognition run implemented support trec spoken document retrieval sdr track hours broadcast news sampled months 
accuracy retrieval systems time adaptive system transcripts evaluated transcripts produced virtually recognition system fixed language model 
details process employed identify implement time adaptive language model discusses results experiment terms effect word error rate vocabulary rate retrieval accuracy mean average precision 

spoken document retrieval sdr technology enables user search audio collection typed queries 
sdr involves combination human language technologies automatic speech recognition asr information retrieval ir 
asr technology create searchable timestamped textual representation audio indexed searched conventional text retrieval algorithms 
time stamps provide pointers source audio playback 
nist eighth text retrieval conference trec spoken document retrieval track provides environment evaluation technologies garofolo :10.1.1.31.3395
sdr track uses audio recordings radio television news broadcasts spoken document collection 
asr algorithms processor speeds greatly increased years asr component sdr system require great deal processing time ir indexing component 
processing times significant realistically large collections 
example state art xrt asr systems davenport odell wegmann sankar processing time hour collection require processor hours 
time significant multiple processor approach 
real working implementation sdr system speech recognition portion task performed online speech data collected available retrospectively audio recorded 
means recognizer data optimize models audio re transcribed better models 
sense best possible recognition algorithm recognition run 
contrast derived textual form entire collection completely re indexed daily basis 
current hub style pallett speech recognizers static pre trained recognition algorithm models 
recognizer collection spans months broadcast news system unable recognize new words appear news words important retrieval engine recognition models actual spoken language gradually diverge time eventually yielding significant increases word error rate 
hypothesized continuously update language model recognizer parallel text corpus contained approximately language characteristics spoken corpus recognized 
working broadcast news domain sdr believed contemporaneous newswire text corpus adaptation 
broadcast news domain provides testbed hypothesis news events change new words appear gradually time 
new words appear immediately collateral newswire texts 
newswire data perform periodic update recognizer dictionary contains list words speech recognizer understands pronunciations 
updating lower discrepancy recognizer model spoken language 
online recognition scenario means today previous days news hypothesize tomorrow lexicon 
trec sdr corpus contained broadcast news sampled month period garofolo provided perfect testbed experimentation adaptive language modeling techniques 
report similar cache language modeling 
clarkson kuhn 

trec sdr track past years nist organized sdr track provided evaluation infrastructure task providing test specifications scoring software speech text corpora test topics 
past years nist created baseline set recognizer transcripts contributed research recognizer 
baseline transcripts provided valuable control condition permitted sites access speech recognizers participate evaluations garofolo 

test corpora trec sdr collection broadcast news audio portion tdt news corpus originally collected linguistic data consortium ldc support darpa topic detection tracking evaluations fiscus 
corpus contains recordings transcriptions associated data radio television news sources broadcast daily january june 
total tdt contains broadcasts shows hours digitally sampled audio 
sdr track february june subset tdt corpus month january excluded conflict hub recognizers trained overlapping material january 
resulting sdr test collection contained broadcasts hours audio 
previous sdr corpora collection contain detailed human generated transcriptions especially created asr training testing 
contained transcriptions television sources paid transcriptions radio sources 
transcripts form retrieval purposes 
order important words retrieval appear query real production system virtually word documents appear query expect date queries 
test specifications document regarding sdr track available www nist gov speech sdr sdr htm 
information regarding upcoming sdr track available www nist gov speech sdr sdr htm 
accurately benchmark participants asr transcripts ldc transcribed hour randomly selected subset corpus provide hub training quality transcripts 
tdt corpus provided newswire texts runs parallel recorded broadcast news 
text data available sdr participants adaptive language modeling purposes 
table provides breakdown corpus source 
source number sentences number tokens number types associated press new york times total table sdr newswire collection distribution 
baseline recognizer transcript set trec nist wanted provide baseline recognizer transcript set compare retrieval performance sites permitted retrieval sites speech recognition technology participate evaluation 
realizing cmu sphinx recognizer far slow recognize trec collection time allotted nist set find faster baseline recognizer 
fortune hub evaluation included evaluation fast speech recognizers systems operated times real time single processor 
new evaluation caused asr sites improve speed efficiency recognizers 
gte bbn offered nist linux instantiation fast byblos rough ready bbn rnr recognizer operated xrt baseline sdr tdt davenport kubala 
experimenting adaptation nist decided create control recognizer traditional hub style fixed language model 

recognizer description baseline recognizer transcripts created nist bbn rnr system trained data acoustic model training marketplace broadcast news training sets released linguistic data consortium hub speech recognition evaluations language model training set ldc published text sources totaling words dictionary original bbn dictionary carefully chosen words pronunciations performing runs benchmarked bbn rnr times real time state theart hardware time pentium ii mhz mb ram running linux 
results previous hub evaluation test sets table similar obtained bbn kubala 
test wer rt eval eval eval eval table bbn rnr performance past hub test sets 
performance took approximately weeks run recognizer entire sdr corpus processor pc cluster 
open source pbs scheduler distribute processing data hub darpa nist sponsored evaluation asr technology pallett 
portable batch system available pbs com processors 
provided logging error checking 
results hour scoring subset trec sdr track table 
snt words corr sub del ins err sent 
err nist table nist scoring results vocabulary oov rates computed word frequency list files extracted human generated closed captioning 
closed accurate transcript usual hub transcripts provided ldc 
errors asr closed spelling mismatch taken account reading oov rates 
permitted compute oov rates larger corpus hour subset 
illustrate discrepancy closed quality hub training quality consider oov rates computed original bbn dictionary hour subset hub training quality transcripts closed captioning quality transcripts differences due part lack quality assurance closed captioning closed transcripts normalized asr 
instance written dollars 
oov numbers article seen pessimistic 
recognizer dictionary vocabulary oov rate recognizer regard entire sdr corpus 

implementing rolling language model trec retrieval accuracy highly correlated content word recognition accuracy simple recognition word error rate garofolo 
broadcast news domain hypothesized reduction oov rate increase retrieval accuracy new words news content bearing words supposed important retrieval 
year set create second experimental baseline recognizer adaptive language model give lower oov rate comparable recognizer fixed language model 
identified possible parameters vary implementing continuous language model adaptation lexicon size balancing word addition deletion pronunciation model generation language model dictionary update period language model retraining method 
lexicon balancing keep experiment tractable produce second recognizer run time sdr track employed technique augmented words original bbn language model 
original bbn dictionary contained words 
left margin words added reaching word limit recommended bbn 
process word selection attempts predict words language 
option add words encountered 
approaches inevitably fail lexicons grow large language model perplexity grows control 
need judiciously choose words fairly high probability occurring 
approach limiting number word additions look number occurrences new word training data newswire texts set threshold additions deletions 
approach word added encountered minimum count times day 
likewise new word removed lexicon encountered lookback days 
select parameters created tool simulates language model update procedure computes oov rate different parameter values 
ran set experiments months newswire corpus january february lm training data computed oov rate months closed texts 
lookback period days increments 
count occurrences increments 
lookback days count minimized oov rate collection 

pronunciation model generation generate necessary pronunciations new words added dictionary statistical text phone ttp engine created william fisher fisher segmental phonemic accuracy trained tested english pronunciation dictionary 
pronunciations original words bbn dictionary left 
language model dictionary update period choosing adaptation frequency balance utility date language model computational cost producing 
process completely updating language model took approximately hours linux workstation 
chose initially day update period capture weekly news program cycle maintain reasonable computational cost 
wanted store adapted language models study ended generating weekly language models spanning february st june th 
language model retraining newswire data retrain language models adapt dictionary lexicon 
data added history count maintained bbn language model tools 
known language model training generally requires large quantities text order properly sample model language 
parallel news corpus probably adequate finding new words may inadequate fully train language model new words 
word word probabilities questionable 
best possible data 

system configuration system implement language model adaptation shown 
begins newswire text corpus set new words added lexicon derived selection tool 
ttp tool create pronunciation models new words added dictionary 
entries original dictionary kept updated original lexicon selected words selection tool updated lexicon newswire text corpus system diagram updated dictionary storage requirements mb model daily models prohibitively large 
ttp lm tools original pronunciations original lm language model dictionary contains original words pronunciations plus new words automatically generated pronunciations 
newswire texts revised dictionary create updated language model 
table summarizes resulting oov rate relative closed captioning data different conditions fixed language model adaptive language minimum oov case new words added discarded 
oov rates shown month period second month period 
month result informative full day lookback days 
fixed lm nist rolling lm nist best case oov jan feb oov feb table average oov rate partial corpus shows plot daily oov rate conditions 
graph shows divergence days models updated 
days models diverge lookback window grows maximum possible days 
oov difference oov days appears stable 
somewhat counter intuitive expect continued divergence adaptive fixed models 
language stable short sample period oov rate appears constant fixed model 
case longer sample core words language change 

adaptive recognition experiment results parameters set lookback period days minimum count update period days created language models complete sdr corpus 
recognizer oov rate relative closed captioning data entire test corpus 
ran recognizer corpus scored results hour subset table 
snt words corr sub del ins err sent 
err nist nist table nist asr scoring results days fixed model nist rolling lm nist best case oov rate comparison models january february results show absolute decrease word error rate adaptive system fixed system representing relative decrease word error rate 
seemingly small nist statistical significance software indicates difference significant 
surprisingly insertion deletion rates similar recognizers 
substitution rate recognizer lower recognizer 
indicates words correctly recognized adapted lexicon language model 
stories performance recognizers visually depicted shows histogram number stories word error rate 
graph recognizer shifted left flatter recognizer indicating majority stories benefited gain 
table summarizes oov rate baseline recognizer runs entire tdt corpus sdr test set tdt subset 
results show oov rate entire months sdr corpus bit subset estimations indicating months corpus contain greater percentage oov words 
explained lack voice america broadcasts months 
presumably broadcasts geared non native speakers language simpler sources broadcast primarily american audiences 
interesting point adaptive language model provided relative reduction oov sdr corpus 
fixed lm nist rolling lm nist relative reduction oov jan june oov feb june table average oov rate baseline runs complete sdr corpus shows daily graph relative reduction oov recognizers 
graph shows day spike oov probably related weekly broadcast news cycle effect 
larger periodicity explained seasonal variations news 
wer nist nist wer histogram comparison relative decrease oov relative gain oov 
effect adaptive recognition retrieval hypothesis adaptive recognizer fewer oov words produce better retrieval results 
trec sdr participants ran retrieval engine recognition transcripts cambridge university johnson limsi gauvain sheffield university 
table summarizes results sdr retrieval test test sites baseline recognizers garofolo :10.1.1.31.3395
retrieval metric mean average precision map standard metric trec ad hoc tests voorhees 
site baseline baseline relative gain cu htk limsi sheffield table ir results baseline runs results indicate small consistent gain retrieval accuracy recognizer 
small gain indicative previous results demonstrate retrieval performance minimally effected recognition performance 
mainly due redundancy content words collection garofolo 

alternative adaptation experiments frequency algorithm words news may appear limited number times day appear consistent frequency 
minimum count algorithm recognizer pick words 
hypothesize algorithm improved add frequency component 
implement add word language model appeared count days past window days 
performed similar oov experiment varying frequency optimal lookback period days count determined earlier 
varied frequency window official result published trec cu htk retrieval engine nist baseline recognizer transcript 
result due bug procedure actual number johnson 
days february st june th days day increments frequency count increments 
frequency window days frequency count gave lowest oov rates 
oov shows daily oov rate new original algorithms 
reduction insignificant month frequency window covers full days small measurable reduction relative second month 

trec sdr track large audio collection collateral newswire corpus provided nearly ideal testbed exploration automatic language model adaptation 
significantly improve oov rate word error rate bbn byblos rough ready recognizer sdr test corpus implementing time count adaptation algorithm parallel newswire texts augment recognizer language model 
improved recognition translated small improvement retrieval performance retrieval engines 
begun explore additional approaches improve recognizer oov performance including making word frequency information selecting words added recognizer language model 

nist trec sdr track sponsored part defense advanced research projects agency 
francis kubala liu bbn gte generous donation byblos rough ready recognizer language modeling tools developing sdr baseline asr transcripts support helping install configure software 
days rolling lm nist frequency algorithm oov rate comparison algorithm new frequency algorithm 
renals robinson ellis 

thisl sdr system trec 
proceedings eighth text retrieval conference 

graff liberman 

tdt text speech corpus 
proceedings darpa broadcast news workshop 
clarkson robinson 

language model adaptation mixtures exponentially decaying cache 
proceedings icassp 
davenport nguyen schwartz makhoul 

bbn byblos real time system 
proceedings darpa broadcast news workshop 

fiscus doddington garofolo martin 

nist topic detection tracking evaluation tdt 
proceedings darpa broadcast news workshop 
fisher 

statistical text phone function ngrams rules 
proceedings ieee international conference acoustics speech signal processing 

garofolo voorhees 

trec spoken document retrieval track success story 
appear proceedings riao 
garofolo voorhees stanford lund 

trec spoken document retrieval track overview results 
proceedings darpa broadcast news workshop 

gauvain de lamel adda 

limsi sdr system trec 
proceedings eighth text retrieval conference 

johnson sparck jones woodland 

spoken document retrieval trec cambridge university 
proceedings eighth text retrieval conference 

kubala liu srivastava makhoul 

integrated technologies indexing spoken language communications acm volume page 
kuhn de mori 

cached natural language model speech reproduction 
ieee transactions pattern analysis machine intelligence 

kuhn de mori 

corrections cached natural language model speech reproduction 
ieee transactions pattern analysis machine intelligence 

odell woodland hain 

entropic xrt broadcast news transcription system 
proceedings darpa broadcast news workshop 
pallet fiscus garofolo martin przybocki 

broadcast news benchmark test results 
proceedings darpa broadcast news workshop 
sankar gadde weng 

sri broadcast news system faster better smaller speech recognition 
proceedings eighth text retrieval conference 

voorhees harman 

overview eighth text retrieval conference trec 
proceedings eighth text retrieval conference 

wegmann zhan carp newman gillick 

dragon systems broadcast news transcription system 
proceedings darpa broadcast news workshop 

