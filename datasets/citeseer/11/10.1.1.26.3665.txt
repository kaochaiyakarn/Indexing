information extraction hmm structures learned stochastic optimization dayne freitag andrew mccallum just research henry street pittsburgh pa com research demonstrated strong performance hidden markov models applied information extraction task populating database slots corresponding phrases text documents 
remaining problem selection state transition structure model 
demonstrates extraction accuracy strongly depends selection structure presents algorithm automatically finding structures stochastic optimization 
algorithm begins simple model performs hill climbing space possible structures splitting states gauging performance validation set 
experimental results show technique finds hmm models perform fixed model superior average performance tasks 
internet available tremendous amount text generated human consumption unfortunately information easily manipulated analyzed computers 
information extraction process filling fields database automatically extracting fragments human readable text 
examples include extracting location meeting email message name corporate takeover target 
research demonstrated effectiveness hidden markov models hmms information extraction 
hmms applied successfully sub domains information extraction named entity extraction task bikel task recovering sequence set entities occurring close proximity dense extraction seymore sparse extraction task object extract relevant phrases documents containing irrelevant text leek freitag mccallum 
cases accuracy hmms applied tasks state art significantly better alternative learning approaches 
address sparse extraction task 
assume document corpus corresponding relational record template slot empty filled fragment text document 
copyright american association artificial intelligence www aaai org 
rights reserved 
example electronic seminar announcement contain title talk name speaker starting time typed relevant fragments called fields 
field train separate hmm 
performing extraction particular file model account tokens document 
special states called target states trained emit tokens part phrases extracted 
states background states designated emit non target tokens 
varying number connection states design models account wide range text patterns including patterns language neighborhood target phrases structure phrases 
significant problem applying hmms information extraction selection state transition structure 
certain structures better capture observed phenomena prefix target suffix sequences certain targets 
example know want extract names set aside single target state names names connect states way matches intuitions 
unfortunately approach building structures hand scale large corpora difficult follow practice 
furthermore human intuitions correspond structures best hmm potential 
shows selection state transition structure effects tremendously accuracy hmm extractor presents stochastic optimization approach learning task specific structures automatically 
method begins minimal number states explores various state splitting operations selects operation gives best performance labeled validation set recursively explores splitting operations 
final model chosen cross validation generated 
idea automatic structure selection hmms new stolcke omohundro carrasco oncina lockwood blanchet applied problem dense extraction seymore 
typically uses goodness statistical fit data structure selection process step optimizes performance task hand 
shows greater improvements due structure learning 
improvement possible context sparse extraction question research 
experimental results different data sets 
learned structures give higher accuracy previously attained hand built models outperform srv rapier state art information extraction systems employ ilp methods freitag califf :10.1.1.32.8501
hmms information extraction tasks involving discrete sequences performance information extraction tasks relies powerful modeling context current observations 
finite state machines hidden markov models offer balance simplicity expressiveness context 
hidden markov models ahmm finite state automaton stochastic state transitions symbol emissions rabiner :10.1.1.131.2084
automaton models probabilistic generative processes sequence symbols produced starting state transitioning new state emitting symbol selected state transitioning emitting symbol designated final state reached 
associated set states fs 
probability distribution symbols emission vocabulary fw 
wk probability state emit vocabulary item written 
similarly associated state distribution outgoing transitions 
probability moving state state written js 
prior state distribution 
training data consists sequences observed emissions written fo 
om information extraction hmms model parameters performed determining sequence states generated entire document extracting symbols associated certain designated target states 
determining sequence efficiently performed dynamic programming viterbi algorithm rabiner :10.1.1.131.2084
models characteristics hmm extracts just type field seminar speaker 
multiple fields extracted document seminar speaker seminar location separate hmm constructed field 
model entire document require pre processing segment document sentences pieces 
entire text training document train transition emission probabilities 
contain kinds states target states nontarget states 
target states intended produce tokens want extract 
fully connected 
restricted transition structure captures context helps improve extraction accuracy 
addition traditional hmm parameters training data labels indicating target states observations 
binary value indicating state target states 
training instance labeled indicate observations target observations task represented sequence binary labels observation sequence written fl 
parameter estimation state transition structure determined remaining parameters model transition emission probabilities 
estimated labeled training data sequences words target words identified 
hmm structures labels determine unique path states 
unique path exist em form baum welch iteratively estimate parameters fill missing path 
step estimate expected path exactly rabiner obey target label constraints :10.1.1.131.2084
example iteration step forward procedure sjs js backward procedure modified analogously 
transition probabilities low degree multinomials estimate maximum likelihood ratios counts traditional 
emission probabilities hand high degree multinomials require smoothing prior training data extremely sparse relative number parameters 
smoothing simply uniform distribution results build shrinkage hmms information extraction freitag mccallum 
machine learning tasks tension constructing complex models states constructing simple models states 
complex model able represent intricate structure task results poor high variance parameter estimation training data highly fragmented 
simple model results robust parameter estimates performs poorly sufficiently expressive model data bias 
shrinkage general term includes hierarchical bayes empirical bayes family statistical techniques balance competing concerns 
hmms shrinkage shrink parameter estimates states complex model estimates related data rich states simpler models 
combination estimates provably optimal appropriate conditions 
employ form shrinkage combines estimates weighted average example hmm structures 
circle nodes represent non target states hexagon nodes represent target states 
learns weights expectation maximization 
smoothed shrinkage emission probability word emitted state term represents uniform distribution parent state shrinkage data rich state simpler model 
implementation target states share parent non target state share parent 
space limitations prevent full description shrinkage implementation see freitag mccallum freitag mccallum details 
learning state transition structure stochastic optimization class structures consider information extraction reflects intuition successful extraction requires learner model typical contents field context side 
distinguish types states target states required model content target phrases 
prefix prefix set states connected string 
prefix state transitions state string state string target states 
models designed way state sequence returned viterbi passes target state pass prefix 
suffix suffix similar structure prefix 
state sequence pass suffix leaving set target states 
background background states model text modeled kinds states 
background state outgoing transitions beginnings prefixes incoming transitions ends suffixes 
shows hmm structures meet criteria 
bottom model single background state prefix suffix length fully interconnected target states 
model performs quite range information extraction tasks 
top model simplest consider serves starting point method search structure space 
simple model perform hill climbing space possible structures step applying set operations current model selecting resulting structures model 
experiments reported define operations lengthen prefix single state added prefix 
penultimate state transitions new state new state transitions target states penultimate state previously transitioned 
split prefix duplicate prefix 
transitions duplicated states new prefix connectivity rest network old prefix 
lengthen suffix dual prefix lengthening operation 
split suffix identical prefix splitting operation applied suffix 
lengthen target string similar operation target states contrast prefix suffix states self transitions 
single target state simple model target string length 
split target string identical prefix splitting operation applied target string 
add background state add new background state model connectivity respect non background states background states new state outgoing transitions prefix states incoming transitions suffix states 
note operations may applied ways resulting distinct structures depending model 
result applying operation set topologically distinct models generate 
experiments efficiency structures shrinkage configuration described previous section 
note shrinkage configuration determined optimization ways states created splitting operation share local shrinkage distribution distributions created part previous splits 
resulting hierarchical configuration reflect sequence operations led construction 
include additional set shrinkage modification operators independently stochastic optimization 
table presents method selecting structure 
consists loops set structures generated step look ahead hill climbing performance hold set models set re scored fold cross validation see section description metric 
procedure ops simple model fewer states candidates fm jm op op candidates score average runs trained scored candidates highest score score average fold cross validation return highest score table optimization procedure select hmm structure 
training set 
step loop selects model single candidate scores best average training testing runs 
average runs way seeding model different way time baum welch settles different local optima depending initial parameter settings 
model returned series generated structures scores best separate runs fold cross validation training set 
experimental results tested approach information extraction tasks defined document collections sa collection seminar announcements posted electronically large university 
fields include speaker name speaker seminar location location room number seminar 
acq collection reuters articles detailing acquisitions 
fields include acquired name purchased purchase estimated price sale 
jobs collection usenet job announcements 
fields include name seeking hire title job title 
cfp collection internet call announcements ascii format 
fields include conf name conference deadline full submission deadline 
cfp collection corpora previously published research 
experiments adopt basic procedure document collection partitioned times training set testing set 
train learner training set measure performance testing set 
case approach described training set select model structure set parameters 
exception jobs partitions training testing sets roughly equal size 
jobs partitions exactly califf califf contain training testing 
results experiments ran represent average performance training testing splits 
rapier scores reported califf califf represent average performance training testing splits 
extraction problems consider single correct filler may occur times document slight variations slot answer template 
test document learner identify target fragment decline perform extraction 
order extraction counted correct precise boundaries target fragment identified 
learner issues multiple predictions document take highest confidence 
metrics characterize performance learner precision number correct extractions divided number documents learner issued prediction recall number correct extractions divided number documents containing target fragments 
report harmonic mean precision recall 
compare structure learning approaches rule learning approaches previously reported literature srv freitag rapier califf static hmm models :10.1.1.32.8501
srv rapier relational rule learners shown perform variety tasks 
srv induces rules top general rule specializing 
rapier induces rules bottom successively generalizing cover target phrases 
rows labeled simple hmm complex hmm show performance static models shown 
note simple hmm model structure selection begins 
table shows performance hmm learned structure tasks competing approaches lists difference score grown hmm respective approach 
clear results balance hmms preferred rule learners mentioned 
achieve superior performance tasks substantial margins 
simple hmm occasionally performs symbolic methods 
course order hmm realize potential structure selection required vs simple hmm row table indicates 
average performance difference simple model constitutes improvement 
designed static model row complex hmm table achieve performance average performance lags dynamically selected model 
note complex model selected considerable manual interaction sa domain particularly speaker task 
sense optimized task comes surprise tasks structure learning yields worse results static model 
shows parts structures hmms designed extract seminar locations speakers respectively 
transitions labeled probability assigned baum welch transitions probability shown 
node location graph speaker location acquired title conf deadline average grown hmm vs srv vs rapier vs simple hmm vs complex hmm table difference performance hmm learned structure methods 
numbers indicate better grown hmm alternative method 
room hall wing room baker adamson baker mellon carnegie hall conference wing institute room wean weh doherty hall hall place pm seminar reminder theater artist additionally speakers porter hall room hall room dr professor robert michael stevens christel speaker speak appointment received part learned structures designed extract locations top speakers bottom 
displays top probable tokens emitted state order top bottom nodes speaker graph show top tokens odds ratio metric 
token stands carriage return token stands unknown token experiments token occurring fewer times training set 
models best respective splits 
location model states state splitting speaker model steps 
suggests order extract seminar locations single relatively short prefix context needed 
fact model retains single prefix points unambiguity length invariance kinds language leading location 
phrases place pm encoded prefix 
phrase indication locations preceded times 
target states partitioned parallel paths 
top path accounting half location phrases captures common location phrases consisting tokens phrases weh wean hall 
wean doherty buildings cmu campus common meeting places talks announced sa corpus 
middle path length appears dedicated modeling longer location phrases particularly popular meeting place appears variety formats adamson wing baker hall baker hall adamson wing adamson wing baker hall 
bottom path appears garbage path dedicated modeling locations easily modeled paths 
high probability unknown token states supports interpretation 
target state speaker model appears dedicated emitting names target state emits middle initials names 
prefixes suggests seminar speakers occur contexts 
top prefix dedicated accounting initial formal presentation phrases speaker common followed speaker full name including 
bottom prefix body announcement formal contexts 
accounts phrases reminder seminar 
interestingly significant fraction contexts prefix skip second target state apparently name omitted 
related hmms applied various versions information extraction problem years 
approach described freitag mccallum freitag mccallum addresses problem training hmm extraction task involves manually constructed models 
seymore 
seymore describe experiments structure learning hmms model fields simultaneously address problems ordering fields sought location single field large body background text 
bikel 
bikel applies hmms named entity recognition problem problem identifying text fragments signify particular types entities people organizations regard role document 
describe manually designed hmms state type entity gram statistics hmm structure exploit context 
hmms leek leek carefully designed state transition structure emission distributions model syntactic constraints particular extraction problem 
problem learning hmm structure tasks information extraction seen fair amount 
stolcke omohundro stolcke omohundro propose state merging approach begins large maximally specific topology iteratively merges pairs states 
merging criterion performance particular task bayesian combination prior expectations regarding suitable topologies goodness fit data 
seymore 
seymore apply approach extraction problem 
closely related state merging algorithms investigated years field grammatical inference particularly involving stochastic regular grammars carrasco oncina 
state splitting appears better suited state merging sparse extraction problem 
state merging presupposes problems resemble formal language modeling 
problem dense extraction closer character formal language identification sparse extraction 
alternatives state merging splitting exist 

describe method begins fully connected structure iteratively deletes transitions 
lockwood blanchet lockwood blanchet propose method applies incremental patches circuit free model speech processing 
previous shown hidden markov models state art method information extraction 
shown task specific state transition structure models tremendously important performance pushed state art showing discriminative stochastic optimization automatically discover structures 
hope initial investigations lead improved methods 
daniel bikel scott miller richard schwartz ralph weischedel 
nymble high performance learning name finder 
proceedings anlp pages 
mary elaine califf 
relational learning techniques natural language information extraction 
phd thesis university texas austin august 
rafael carrasco jose oncina 
learning stochastic regular grammars means state merging method 
rafael carrasco jose oncina editors grammatical inference applications second international colloquium 
springer verlag september 
dayne freitag andrew mccallum 
information extraction hmms shrinkage 
papers aaai workshop machine learning information pages july 
aaai technical report ws 
dayne freitag 
information extraction html application general machine learning approach 
proceedings fifteenth national conference artificial intelligence aaai 
timothy leek 
information extraction hidden markov models 
master thesis uc san diego 
philip lockwood marc blanchet 
algorithm dynamic inference hidden markov models 
ieee international conference acoustics speech signal processing icassp 
rabiner 
tutorial hidden markov models selected applications speech recognition 
proceedings ieee february 
seymore andrew mccallum ronald rosenfeld 
learning hidden markov model structure information extraction 
papers aaai workshop machine learning information pages july 
aaai technical report ws 
andreas stolcke stephen omohundro 
best model merging hidden markov induction 
technical report tr international computer science institute berkeley california january 
raymond jr el boston thomas rudy 
hidden markov model topology estimation characterize dynamic structure repetitive lifting data 
proceedings th annual international conference ieee engineering medicine biology society 
