online clustering collaborative filtering wee sun lee department computer science national university singapore singapore august study online clustering methods collaborative filtering 
method assume user equally belong clusters users user rating item generated randomly distribution depends item cluster user belongs 
second method assume user equally belong clusters users item equally belong clusters items 
rating user item pair generated randomly distribution depends cluster user belongs cluster item belongs 
derive performance bounds bayesian sequential probability assignment methods elucidate trade offs involved methods 
bayesian sequential probability assignment appear computationally tractable model classes 
propose heuristic approximations bayesian sequential probability assignment model classes performed experiments movie rating data set 
proposed algorithms fast perform results experiments agree insights derived theoretical considerations 
keywords collaborative filtering recommender systems clustering online learning growth world wide web resulted enormous increase amount information available consumers information 
result information filtering tools increasingly useful helping users manage large amount information 
users filtering tools tell item interesting decide spend time effort consuming 
user interests vary widely personalized information filtering system able perform better system caters masses 
various ways perform personalized information filtering 
machine learning algorithm learn mapping features item number indicating utility item user previous ratings user items 
example words article serve features predict article interesting user 
alternative method ratings similar users order predict rating items user rated 
commonly called collaborative filtering 
basic premise people similar taste tend similar types items rating similar predictor personalized rating item 
study collaborative filtering methods 
method assume user equally belong clusters users user rating item generated randomly distribution depends item cluster user belongs 
second method assume user equally belong clusters users item equally belong clusters items 
rating user item pair generated randomly distribution depends cluster user belongs cluster item belongs 
study performance methods online learning framework 
online learning learning algorithm asked sequence predictions 
time algorithm allowed access labels items time making prediction suffers loss due difference prediction actual label encountered time framework reasonable studying effectiveness algorithm situations user allowed query predicted rating item may best framework studying effectiveness algorithms intended retrieving set highly rated items 
simplicity log loss theoretical considerations deriving heuristic algorithms 
set log loss considered code length needed compressing rating know user item identities 
similar analyses possible loss functions squared loss absolute loss slightly different form explore 
method rating generated randomly distribution depends item cluster user belongs 
case user cluster distribution unknown 
second method rating generated distribution depends group item belongs group user belongs 
item cluster user cluster distribution unknown 
simplify theoretical considerations consider case distribution belongs finite set distributions 
example set may set gaussian distributions discretized suitable way 
system method items clusters users cluster item pair assigned distributions giving total possible assignments 
users assigning users clusters 
view having experts advising prediction expert advises possible assignments distributions ways assign users clusters 
sum log losses suffer bayesian sequential probability assignment algorithm shown log log sum log losses suffered followed advice expert performed best hindsight 
roughly speaking pay average log user system log item system 
second method system users items clusters users clusters items allows mn possible assignments distributions ways assign user class item class 
view having mn experts advising different assignment person item clusters 
case sum log losses suffered bayesian sequential probability assignment algorithm log log mn log sum log losses suffered followed advice expert performed best hindsight 
roughly speaking pay average log user system log item system extra overhead mn log bounds independent number ratings seen holds possible sequence ratings 
draw insights performance bounds 
collaborative filtering roughly categorize losses online clustering algorithm categories 
classification losses arise knowing cluster user item belongs 
approximately log user models log item second model 
parameter losses arise knowing parameters distributions approximately proportional number distributions models log model mn log second model 
approximation losses losses suffered best expert system able represent ratings actual distributions ratings randomly distributed exactly 
performance bayesian sequential probability assignment relative model class performed best sequence case true model model class 
approximation losses sense case 
methods method smaller approximation loss possible represent model second method model method grouping items setting parameters associated items groups 
collaborative filtering system may situations number users increase quickly number items increase quickly number users items increase quickly 
number users increase quickly number items relatively stable model perform better classification losses models approximately log user approximation losses model smaller 
number items increase quickly parameter loss model log item opposed classification loss log item second model 
may mean second model perform better model smaller approximation losses 
interesting consideration performance system entire system received ratings 
parameter losses dominate losses case 
log model mn log second model 
usually expect second model perform better model initial stages system set 
unfortunately bayesian sequential probability assignment appears computationally intractable models 
propose simple heuristic approximations bayesian sequential probability assignment performed experiments movie rating data set eachmovie 
results experiments roughly agreement theoretical performance bounds bayesian sequential probability assignment indicating insights derived may applicable heuristic algorithms 
compared performance algorithms correlation algorithm algorithm commonly collaborative filtering 
find algorithms significantly accurate user ratings 
agreement theoretical bounds indicate classification loss small log new user algorithms 
heuristic approximation second method significantly accurate rating newly introduced movies received votes compared algorithm method correlation algorithm 
agreement theoretical bound log item second method opposed log item method 
algorithm model smaller error algorithm second model correlation algorithm probably smaller approximation losses 
performed experiments case system received ratings 
case algorithm second method performed better algorithm method expected 
method smaller approximation losses performs better ratings received second method performs better newly introduced items system received ratings 
give simple heuristic algorithm tries combine benefits methods 
main idea heuristic second method doing initial ratings item order benefit low classification losses method doing ratings item order benefit lower approximation losses 
implemented simple weighting scheme 
experimental results shows algorithm effective achieving aim performing algorithm performs 
second method closely related collaborative filtering model proposed ungar foster 
unger foster concentrated parameter estimation address performance online learning model 
theoretical model related second model deterministic randomly generated ratings done nakamura abe 
give polynomial time algorithm nearly optimal problem system allowed choose sequence ratings consider 
system allowed choose sequence give polynomial time near optimal algorithm case clusters users clusters items 
nakamura abe motivated earlier works goldman rivest schapire goldman warmuth models similar model deterministic ratings limit number clusters 
nakamura abe generalized goldman warmuth performed experiments simulated real data 
running time algorithms grow number users system 
running time heuristic algorithms depend number users items system 
algorithms theoretical guarantees algorithms 
empirical comparison algorithms collaborative filtering breeze heckerman kadie different algorithms compared data sets :10.1.1.21.4665
correlation algorithm introduced resnick 
issue communications acm recommender systems provides overview uses issues collaborative filtering 
bayesian sequential probability assignment denote user rated time denote item rated time xy rating person item sequence ratings received system time assume possible models model class corresponding different experts 
bayesian sequential probability assignment sequential method calculating je sequential updating done rewriting expression jz jz chain rule noting time need able calculate posterior distribution jz 
set experts posterior distribution jz je jz case posterior probability experts calculated sequentially jz je je je jz jz je je jz small sequential updating method feasible 
obtain performance bound note je je logs sides see log loss log log je log performed best take prior distribution uniform see loss bayesian sequential probability assignment log loss best expert hindsight 
row clustering method assume user belongs group users 
rating user group item independently generated source probability distribution ij assume ij distributions known set distributions 
assume users system items system 
distributions ij system ways assigning distribution distributions 
furthermore user assign groups giving ways assign user groups 
imagine having group experts advocates way assigning distributions way assigning users 
different ways giving rise set experts 
analysis previous section shows bayesian sequential probability assignment sum losses log log sum losses best expert hindsight 
losses attribute log result knowing groups users belong 
rest losses bound log attributed knowing parameters distributions 
ratings generated models class losses approximating actual process models 
row column clustering second method assume user belongs group users item belongs groups items 
rating user group item group independently generated source probability distribution ij assume ij distributions known set distributions 
mn distributions ij system mn ways assigning distribution mn distributions 
user assign groups items assigned groups giving ways assign user items groups 
mn different ways assigning distributions users items giving rise set mn experts 
bayesian sequential probability assignment sum losses log log mn log sum losses best performing expert 
losses log attributed knowing group user log attributed knowing group item mn log attributed knowing distributions 
approximation losses class models larger approximation losses row clustering class models subset row clustering model class 
analysis provided upper bounds losses algorithms 
experiments show upper bounds appear capture actual behaviour practical algorithms similar bayesian sequential probability assignment 
heuristic online approximations performing bayesian sequential probability assignment equation impractical large numbers experts models classes 
able find computationally efficient shortcuts performing computations 
insights gained analysis design practical fast algorithms collaborative filtering hope approximations retain useful properties bayesian sequential probability assignment 
row clustering approximation expectation maximization em algorithm 
assume distributions gaussian distributions variances restrict discrete sets parameters 
row clustering model distributions known posterior distribution assigning user cluster calculated efficiently sequential manner 
time posterior distribution assigning user cluster known maximum likelihood estimate parameters distributions calculated efficiently 
em algorithm iterative algorithm calculating maximum likelihood estimate parameters distributions 
describe em algorithm 
dimensional vector containing unknown parameters system 
example system types users items ij gaussian distributions dimensional vector containing unknown means variances gaussian distributions 
probability distribution vector parameters define distribution 
observation vector likelihood function function 
aim maximum likelihood method find value maximizes 
pose maximum likelihood problem problem incomplete data 
introduce sequence unobservable data dimensional matrix zero indicator variables component ik zero arose arise ij ik equals complete data sequence 
complete data likelihood function 
th iteration em algorithm defined steps step 
calculate jz expectation taken respect step 
choose value parameters maximize 
likelihood parameters shown non decreasing respect iterations em algorithm 
em algorithm case rewrite gaussian distribution zjd ij ij ij log ij complete data likelihood function written mn ik zx ij ij log ij conditional expectation log likelihood written mn jz ef ik jz xk ij ij log ij step want find expected value ik denoted ik iteration current parameter values 
just posterior probability assigned group user equally belong groups probability calculated ik xk jd iy xk jd normalizing constant 
step differentiate respect ij ij set resulting equations order find ij yk ik xk yk ik ij yk ik xk ij yk ik possible algorithm collaborative filtering run em algorithm available data try obtain maximum likelihood estimate parameters distributions 
posterior distribution assignments users groups parameters order prediction 
algorithm essentially approximate posterior distributions parameters produced em performing updates sequentially 
iteration algorithm shown 
user assigned vector numbers components initialized parameter update performed rating received 
running time algorithm update constant respect number users number items system 
inputs user item rating user weights iy iy algorithm row update probability int iy iy iy probability probability jd iy int jd iy probability update online approximation em algorithm row clustering 
prediction performed algorithm shown 
log loss need predict approximate posterior distribution 
experiments measure performance absolute loss 
loss expected value posterior distribution reasonable method doing prediction 
calculations approximating posterior distribution prediction expected value shown 
online algorithm nice property 
disregarding parameters ways assigning users groups 
assignments viewed model time varying parameters varies updates shown 
consequently algorithm viewed bayesian sequential probability assignment respect set time varying models 
sum log losses algorithm log sum log losses best time varying model class 
model class performs respect data algorithm perform 
row column clustering efficient calculations bayesian sequential probability assignment possible distributions known row clustering 
unfortunately possible row column clustering 
means efficient calculation step em algorithm possible 
online approximation ignores dependencies calculating posterior distributions order obtain computational efficient implementation 
inputs user item user weights algorithm posterior row distribution null prediction int distribution distribution zjd iy prediction prediction zjd iy algorithm calculating posterior probability predicting expected value user item row clustering 
assume distributions known fixed 
convenient way think model matrix entries ij interested finding posterior distribution ij jx jd ij variable representing actual type row person variable representing actual type column item jc jz calculate ij jz jjz jjz 
problem reduced problem calculating jc jz 
try find jc jz 
jc jc jc jc jr jc assume happen 
true restrict user item pair appear 
unfortunately jr jc appear easy calculate 
approximate follows 
set jr jc update done 
approximate jr jr jjz jd rx jjz jz jz jc jz approximate jc jr jd icy update 
intuition approximations system knowledge class users items belong small additional effect probability class user item concerned data 
assume independence items user certainly true data received 
longer strictly true received data assume approximately true computational convenience 
update parameters manner done row clustering algorithm 
implement algorithms need store vector numbers item vector numbers user components initialized components initialized algorithm shown 
inputs user item rating item weights user weights ij ij algorithm row column update probability sumx int int ij ij ij probability probability jd ij sumx sumx jd ij jd ij int sumx probability int probability update online approximation em algorithm row column clustering 
shows calculate approximate posterior distribution conditional expectation prediction time disregarding item clusters parameters ways assigning users groups 
assignments viewed model time varying parameters varies algorithm 
viewed bayesian sequential probability assignment respect set time varying models 
sum log losses algorithm log sum log losses best time varying model class 
similarly disregard row clusters parameters ways assigning items groups 
result sum log losses algorithm log sum log losses best time varying model class column assignments 
interesting consequence difference sum log losses best assignment users rows max log log sum log losses best assignment items inputs user item item weights user weights algorithm posterior row column distribution null prediction int int distribution distribution zjd ij prediction prediction zjd ij algorithm calculating posteriori probability predicting expected value user item row column clustering 
columns algorithm 
combined method theoretical analysis indicates row column clustering method perform better row clustering method new item initially introduced system classification loss log normally smaller parameter loss log corroborated experimental results 
row clustering method eventually outperform row column clustering method smaller approximation losses 
section give simple heuristic algorithm designed combine strengths algorithms 
row column clustering method item initially introduced row clustering method performance better 
algorithm analysis 
assume system models expect perform significantly better initial part sequence expect perform significantly better part sequence 
perform bayesian sequential probability assignment prior probabilities 
result get je je small expect term dominate sum performance close model 
large expect second term eventually dominate 
large expect overhead contributed small small compared losses 
resulting update algorithm shown 
associated item additional weights 
weights updated bayesian sequential probability assignment probabilities provided row column clustering method row clustering method respectively 
shows approximate posterior distribution expected value calculated 
experiments section describe experimental results performing online updating algorithm correlation algorithm movie rating data set 
eachmovie data set obtained dec systems research center running movie recommendation service months 
data set contains users entered total numeric ratings different movies 
rating comes set lowest score highest 
research compaq com src eachmovie inputs user item rating combining weights item weights user weights ij iy ij iy algorithm combined update sumx int iy iy iy jd iy int ij ij ij jd ij sumx sumx jd ij jd ij probability int sumx jd iy probability int probability probability update online approximation em algorithm combined algorithm 
inputs user item combining weights item weights user weights algorithm posterior combined distribution null distribution null prediction prediction int distribution distribution zjd iy prediction prediction zjd iy int distribution distribution zjd ij prediction prediction zjd ij distribution distribution distribution prediction prediction prediction algorithm calculating posteriori probability predicting expected value user item combined algorithm 
nth rating number user ratings number users ratings 
shows number users ratings 
interesting note number ratings decline approximately exponentially data set 
experiments algorithms done way 
data set ratings sorted time ratings obtained 
prediction item sorted list rating shown algorithm 
rating measure absolute prediction error jz actual rating predicted rating 
rating update state algorithms process repeated item 
experiments row clustering algorithm row column clustering algorithm combined algorithm correlation algorithm described 
expected value posteriori distribution prediction algorithms 
algorithms requires random initial conditions 
mean values gaussian distributions initialized random values range variances set row clustering row column clustering algorithms row column clustering part combined algorithm 
row clustering part combined algorithm random initialization 
mean values distributions set variances variables initialized variables initialized variables initialized 
set combined algorithm 
ratings average ratings movies predicted rating predict rating received movie 
furthermore ratings parameters updated statistics updating parameters measured stored 
parameters updated system received ratings 
parameters updated rating received described figures 
done give algorithms reasonably starting points 
results shown averaged random initial conditions 
correlation algorithm introduced resnick known predictive performance 
aj rating user item average rating user prediction aj calculated aj kj jw value zero kj exist set calculations equation including averages performed respect values ratings exist user user algorithm predicts user rating 
ratings average movie rating predictor conditions identical algorithms 
update weights equation computational complexity xy 
order experiment feasible entire eachmovie data set limit users predictors users system replacing value equation computational complexity correlation algorithm improved 
term rewritten rewritten similarly 
users predictors new ratings sums updated constant time giving constant time updates users system 
users predictors new ratings regularly computational complexity update 
practice expect improvement significant 
compare performance algorithms 
table shows average absolute prediction error averaged ratings data set 
table see increasing number rows row clustering decreases performance 
probably parameter losses significant improvements approximation losses number rows increased 
performance increasing rows columns row column clustering improvement slowed 
experiment larger numbers rows columns high computational demands 
similarly performance increasing predictor correlation algorithm improvement slowed 
consider larger numbers predictors high computational demands 
better methods selecting predictors users explore 
predictor avg abs error predictor avg abs error average movie rating row rows row col rows cols row rows row col rows cols row rows row col rows cols row rows row col rows cols corr predictors combined rows cols corr predictors combined rows cols corr predictors combined rows cols corr predictors combined rows cols table average absolute prediction error averaged ratings predictions done online manner 
row clustering appears perform better row column clustering correlation algorithm 
combined algorithm appears perform better row clustering 
give complete picture point view practical usage collaborative filtering system 
particular large number users votes see reflected higher average error correlation algorithm perform users ratings 
plotted average errors users nth rating movies nth received rating see system perform new users ratings new item received ratings 
compares performance row clustering algorithm best number clusters clusters table performance best row column clustering algorithm rows columns performance best correlation algorithm predictors performance best combined algorithm rows columns 
nth error plotted averaged users ratings 
points plots averaged ratings 
plots show performances row clustering row column clustering algorithms significantly better performance correlation algorithm user ratings 
row clustering performs better row column clustering correlation algorithm 
combined algorithm able match performance row clustering algorithm 
compares performance row column clustering algorithm performance algorithms shown average errors plotted nth rating received movie averaged movies received ratings 
expected theoretical results row column clustering performs significantly better row clustering movies received ratings 
row column clustering algorithm performs significantly better correlation algorithm situation 
combined algorithm able match performance row column clustering algorithm reasonably closely 
looked performance systems system received large number ratings 
table shows performance systems ratings received 
situation row clustering algorithm correlation algorithm larger average prediction errors average movie ratings predictors 
row clustering algorithm mainly due large parameter losses comes having parameters learn 
predictor avg abs error predictor avg abs error average movie rating row rows row col rows cols row rows row col rows cols row rows row col rows cols row rows row col rows cols corr predictors combined rows cols corr predictors combined rows cols 
corr predictors combined rows cols corr predictors combined rows cols table average absolute prediction error averaged ratings predictions done online manner ratings received 
nth rating row clustering versus row column clustering row column row avg nth rating row clustering versus correlation algorithm corr row avg nth rating row clustering versus combined combined row avg plots show average absolute prediction error nth vote users row clustering rows compared row column clustering rows columns top correlation algorithm predictors center combined algorithm rows columns bottom 
performance average movie rating predictor included 
nth rating row column clustering versus row row row column avg nth rating row column clustering versus correlation algorithm corr row column avg nth rating row column clustering versus combined combined row column avg plots show average absolute prediction error nth vote received movie row column clustering rows columns compared row clustering rows top correlation algorithm predictors center combined algorithm rows columns bottom 
performance average movie rating predictor included 
shows plots average errors nth user ratings 
points plots averaged ratings 
average movie rating predictor considered non personalized predictor prediction regardless asking prediction 
plots show row clustering personalized predictor non personalized prediction outperformed personalized prediction system received large number ratings 
row column clustering combined algorithm able give better performance non personalized predictor 
correlation algorithm able give advantage non personalized predictor user reasonable number ratings 
average absolute error nth rating row clustering versus average movie ratings row avg nth rating row column clustering versus average movie ratings row column avg average absolute error nth rating correlation algorithm versus average movie ratings corr avg nth rating combined versus average movie ratings combined avg plots show average absolute prediction error nth vote users average movie rating predictor compared row clustering rows top left row column clustering rows columns top right correlation algorithm predictors bottom left combined algorithm rows columns bottom right 
studied bayesian sequential probability assignment performing online clustering collaborative filtering 
designed heuristic algorithms approximate bayesian sequential probability assignment performed experiments movie rating data set 
combining algorithms studied able design algorithm performs new users ratings new items received ratings newly deployed systems received large number ratings 
source code source code producing results obtained hal comp nus edu sg recommender papers online online html 
research supported national university singapore academic research fund rp 
eachmovie data set provided digital equipment 
john breese david heckerman carl kadie :10.1.1.21.4665
empirical analysis predictive algorithms collaborative filtering 
proceedings th annu 
conference uncertainty artificial intelligence pages 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society 
goldman warmuth 
learning binary relations weighted majority voting 
proc 
th annu 
workshop comput 
learning theory pages 
acm press new york ny 
goldman rivest schapire 
learning binary relations total orders 
siam comput october 
haussler kivinen warmuth 
sequential prediction individual sequences general loss functions 
ieee trans 
information theory 
nakamura naoki abe 
line learning binary ary relations multi dimensional clusters 
proc 
th annu 
conference comput 
learning theory pages 
acm press new york ny 
nakamura naoki abe 
collaborative filtering weighted majority prediction algorithms 
proceedings fifteenth international conference machine learning 
resnick iacovou suchak bergstrom riedl 
grouplens open architecture collaborative filtering netnews 
proceedings acm conference computer supported cooperative 
paul resnick hal varian 
recommender systems 
communications acm march 
lyle ungar dean foster 
clustering methods collaborative filtering 
workshop recommendation systems fifteenth national conference artificial intelligence 

