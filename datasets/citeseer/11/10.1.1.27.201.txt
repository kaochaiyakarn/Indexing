vision mobile robot localization mapping scale invariant features stephen se david lowe jim little department computer science university british columbia vancouver canada fse lowe cs ubc ca key component mobile robot system ability localize accurately build map environment simultaneously 
vision mobile robot localization mapping algorithm described uses scale invariant image features landmarks unmodi ed dynamic environments 
landmarks localized robot ego motion estimated matching account feature viewpoint variation 
stereo vision system experiments show features robustly matched views landmarks tracked robot pose estimated map built 
mobile robot localization mapping process simultaneously tracking position mobile robot relative environment building map environment central research topic past years 
accurate localization prerequisite building map having accurate map essential localization 
simultaneous localization map building critical underlying factor successful mobile robot navigation large environment irrespective higher level goals applications 
achieve di erent types sensor modalities sonar laser range vision 
early successful approaches utilize arti cial landmarks bar code re ectors ultrasonic beacons visual patterns function properly beacon free environments 
vision approaches stable natural landmarks unmodi ed environments highly desirable wide range applications 
harris vision system uses visual motion image corner features reconstruction 
kalman lters tracking features determines camera motion positions features 
accurate short medium term long term drifts occur 
ego motion perceived structure self consistently error 
incremental algorithm runs near real time 
stereo vision algorithm mobile robot mapping navigation proposed occupancy grid map built stereo data 
robot localize map odometry error corrected map may drift time 
proposed combining occupancy map sparse landmarks robot localization corners planar objects stable landmarks 
landmarks matching frame kept matching subsequent frames 
markov localization employed various teams success 
example deutsches museum bonn tour guide robot rhino utilizes metric version approach laser sensors 
needs supplied manually derived map learn maps scratch 
thrun proposed probabilistic approach map building expectation maximization em algorithm 
step estimates robot locations various points currently best available map step estimates maximum likelihood map locations computed step 
searches map simultaneously considering locations past sonar scans 
traversing cyclic environment algorithm revises estimates backward time 
batch algorithm run real time 
rhino latest museum tour guide robot minerva learns map uses camera mosaics ceiling localization addition laser scan occupancy map 
uses em algorithm learn occupancy map novelty lter localization 
monte carlo localization method proposed condensation algorithm 
vision bayesian ltering method uses sampling density representation 
kalman lter approaches represent multi modal probability distributions 
visual map ceiling obtained mosaicing localizes robot scalar brightness measurement 
sim dudek proposed learning natural visual features pose estimation 
landmark matching achieved principal components analysis tracked landmark set image thumbnails detected learning phase grid position pose space 
global registration correlation techniques proposed method reconstruct consistent global maps laser range data reliably 
thrun proposed novel realtime algorithm combining strengths em algorithms incremental algorithms 
approach computes full posterior robot poses determine pose just laser scan incremental mapping 
closing cycles backwards correction computed di erence incremental guess full posterior guess 
existing mobile robot localization mapping algorithms laser sonar sensors vision processor intensive stable visual features dicult extract 
propose vision algorithm tracking sift features 
robot equipped stereo system estimated position landmarks obtained map built robot localized simultaneously 
map represented sift landmark database incrementally updated time adaptive dynamic environments 
section explains sift features stereo matching process 
ego motion estimation matching features frames described section sift database landmark tracking section 
experimental results shown section lab environment mapped sift landmarks 
section describes enhancements sift database 
conclude discuss section 
sift stereo sift scale invariant feature transform developed lowe image feature generation sift features scale orientation indicated size orientation squares 
top image 
left image 
right image 
object recognition applications 
features invariant image translation scaling rotation partially invariant illumination changes ane projection 
characteristics suitable landmarks robust mobile robots moving environment landmarks observed time di erent angles distances di erent illumination 
frame extract sift features images stereo match images 
matched sift features stable serve landmarks environment 
generating sift features key locations selected maxima minima di erence gaussian function applied scale space 
computed building image pyramid resampling level 
furthermore sift locates key points regions scales high variation making locations particularly stable characterizing image 
demonstrated stability sift keys image transformations 
shows sift features top left right images 
resolution levels scales 
subpixel image location scale orientation associated sift feature 
size square surrounding feature images proportional scale feature orientation squares corresponds orientation sift features 
image number sift features top left right stereo matching right camera serves camera left camera cm right top camera cm directly 
addition epipolar constraint disparity constraint employ sift scale orientation constraints matching right left images 
subpixel horizontal disparity obtained match 
resulting matches matched top image similarly extra constraint agreement horizontal vertical disparities 
feature match satisfying criteria ambiguous discarded resulting matches consistent reliable 
positions matches knowing camera intrinsic parameters compute world coordinates relative robot feature nal set 
subsequently serve landmarks map building tracking 
disparity taken average horizontal disparity vertical disparity 
orientation scale matched sift feature taken average orientation scale corresponding sift feature left right top images 
results matches right left images shown 
matching top image nal number matches 
result shown matched sift feature marked length horizontal line indicates horizontal disparity vertical line indicates vertical disparity feature 
figures show sift stereo results slightly di erent views robot small motion 
number nal matches relaxing constraints necessarily increase number nal matches stereo matching results slightly di erent views 
horizontal line indicates horizontal disparity vertical line indicates vertical disparity 
line lengths proportional corresponding disparities 
closer objects larger disparities 
cause sift features multiple potential matches discarded 
ego motion estimation obtain stereo matched sift feature measured image coordinates camera scale orientation disparity associated feature coordinates relative camera 
build map need know robot moved frames order put landmarks coherently 
robot odometry data give rough estimate prone error drifting slipping nd matches second view odometry allows predict region search match eciently 
sift features matched matches squares procedure compute accurate camera ego motion better localization 
help adjust coordinates sift landmarks map building 
predicting feature characteristics coordinates sift landmark odometry data compute expected relative position expected image coordinates disparity new view 
expected scale computed accordingly inversely related distance 
search appropriate sift feature match region currently pixels frame disparity constraint sift scale orientation constraints 
matching results images shown rough camera movement odometry movement initial position forward cm rotate clockwise frames matched figures match 
matches matches shows match results visually shift image coordinates feature marked 
white dot indicates current position white cross indicates new position line shows matched sift feature moves frame analogous sparse optic ow 
figures forward motion cm figures clockwise rotation seen matches consistent 
squares minimization matches obtained ego motion determined nding camera movement bring projected sift landmark best alignment matching observed feature 
minimize errors projected image coordinates observed image coordinates employ squares minimization compute camera ego motion 
robot move forward rotate full degrees freedom general motion 
newton method computes correction term subtracted initial estimate error measurements expected projection sift landmarks image position observed matching feature 
jacobian matrix estimated numerically gaussian elimination pivoting employed solve linear system 
feature matching quality implies high percentage inliers outliers simply eliminated discarding sift feature matches consecutive frames cm forward movement 
clockwise rotation 
features signi cant residual errors currently pixels 
minimization repeated remainder matches obtain new correction term 
results pass sift feature matches squares procedure odometry initial estimate ego motion 
frame movement smooth oor odometry quite accurate judge accuracy solution 
results obtained squares estimate corresponds translations directions yaw pitch roll respectively fig odometry mean squares estimate cm cm cm cm pixels cm cm cm pixels landmark tracking matching sift features frames maintain database containing sift landmarks observed match features subsequent views 
sift feature stereo matched localized coordinates 
entry database current position sift landmark relative camera scale orientation count indicate consecutive frames landmark missed 
subsequent frames maintain database add new entries track features prune entries appropriate cater dynamic environments occlusions 
track maintenance frames obtain rough estimate camera ego motion robot odometry predict feature characteristics database landmark frame 
types landmarks consider type landmark expected view frame 
matched count remains unchanged 
type ii 
landmark expected view matches frame 
count incremented 
type iii 
landmark view match position scale orientation disparity criteria described 
count reset 
type iv 
new landmark corresponding sift feature new view match existing landmarks database 
type iii landmarks matched squares minimization obtain better estimate camera ego motion 
landmarks database currently updated averaging 
update replaced data fusion methods kalman lter section 
insucient type iii matches due occlusion instance odometry ego motion current frame 
track initiation initially database empty 
sift features rst frame arrive start new track features initializing count 
subsequent frames new track initiated type iv landmarks 
track termination count landmark database reaches prede ned limit experiments observed predicted position consecutive frames landmark track terminated pruned database 
removes features belonging objects moved dynamic environment 
field view firstly compute expected coordinates current coordinates odometry 
database landmark eld view frame check camera tan jx tan jy camera lens eld view wide 
coordinate frame initial camera coordinate frame landmarks relative xed frame 
type type ii landmarks need transformed camera egomotion estimate frame 
matching sift landmarks referenced initial frame features observed current frame helps avoid error accumulation 
experimental results sift feature detection stereo matching egomotion estimation tracking algorithms implemented robot system 
sift database kept track features frames 
robot camera location change ground reduce estimation forcing height change parameter 
depending distribution features scene ambiguity yaw rotation sideways movement known problem 
set limit correction terms allowed squares minimization odometry frame movement quite 
safeguard frames erroneous matches may lead excessive correction terms mess subsequent estimation 
ego motion estimation determines movement camera placed centre robot need adjust odometry information get camera motion 
experiment carried robot moving 
manually drive robot go chair lab loop come back 
frame keeps track sift landmarks database adds new ones updates existing ones matched 
shows frames image sequence frames total captured robot moving 
white markers indicate frames image sequence sift features marked 
st frame 
th frame 
th frame 
th frame 
bird eye view sift landmarks including ceiling features database frames 
cross indicates initial robot position dashed line indicates robot path 
sift features 
total sift landmarks positions relative initial robot position gathered sift database 
shows bird eye view features 
consistent clusters observed corresponding chairs shelves posters computers scene 
robot traversed forward metres come back trajectory shown 
maximum robot translation rotation speeds set cm sec sec respectively suciently matches consecutive frames 
accuracy ego motion estimation depends sift landmarks distribution number matches experiment suciently matches frame ranging depending particular part lab viewing direction 
robot comes back original position judged visually sift estimate cm cm cm sift database basic approach described various enhancements dealing sift database help tracking robust map building stable 
database entry order assess reliability certain sift feature database need information regarding times feature matched matched far 
new database entry count number times missed consecutively decide feature pruned tracking 
count number times missed far count number times seen far 
feature appear times considered valid feature 
eliminate false alarms noise highly noise cause feature match right left top images times total camera views 
experiment move robot lab environment chair middle 
order demonstrate visually sift database map dimensional visualization package 
shows views sift map di erent angles 
see centre region clear false alarms noise features discarded 
visual judgement indicates sift landmarks correspond actual objects lab 
permanent landmarks scene volatile features blocks camera view stable features observed earlier matched number consecutive frames discarded 
sift database map viewed di erent angles 
feature appeared consistently camera views 
top 
left 
right 
environment clear build sift database mark permanent landmarks valid having appeared frames percentage occurrence certain threshold 
set reliable landmarks wiped missed consecutive frames 
important subsequent localization view unblocked 
viewpoint variation sift features invariant image orientation scale image projections landmarks vary large changes viewpoints di erent parts object observed part object occluded 
example front object seen rst robot moves views object back image feature general completely di erent 
original feature may observable viewpoint observable appear di erent count increase gradually pruned 
allow sift landmark sift characteristics sift characteristic scale orientation associated view vector keeping track viewpoint feature observed 
subsequently new view direction di ers original view direction threshold currently set count incremented match 
way avoid corrupting feature information gathered earlier current partial view world 
feature matches direction larger threshold add new view vector associated sift characteristic existing landmark 
database landmark multiple sift characteristics scale orientation view direction time landmark observed various directions richer sift information gathered 
matching procedure follows compute view vector database landmark current robot position nd existing view direction associated database landmark closest minimal angle vectors check update existing feature matching succeeds increment count feature matching fails add new entry sift characteristics existing landmark feature matching succeeds positions landmarks updated accordingly matched 
error modeling various errors noise quantization associated images features 
introduce inaccuracy landmarks position squares estimation robot position 
stochastic mapping single lter maintain estimates landmark positions robot position covariances high computational complexity 
employed kalman filter database sift landmark covariance matrix position assuming independence landmarks 
match current frame covariance matrix current frame combined covariance matrix database far position updated accordingly 
ellipsoidal uncertainty covariance associated landmark position 
ellipses shrink landmarks matched frames indicating localized better 
hand ellipses expand landmarks missed indicating higher positional uncertainty 
proposed vision algorithm sift features 
scale orientation invariant sift features natural visual landmarks tracking long periods time di erent views 
tracked landmarks concurrent robot pose estimation map building promising results shown 
algorithm currently runs hz images mobile robot pentium iii mhz processor 
majority processing time spent sift feature extraction mmx optimization investigated 
map re robot starts position robot starts position initial frame 
preliminary kidnapped robot problem initializing localization positive 
allow robot re map arbitrary robot position matching rich sift database 
currently looking recognizing return previously mapped area detecting occurrences drift correct 
supported institute robotics intelligent system iris iii canadian network centres excellence 
bar shalom fortmann 
tracking data association 
academic press boston 
borenstein everett feng 
navigating mobile robots systems techniques 
peters wellesley ma 
burgard cremers fox lakemeyer schulz steiner thrun 
interactive museum tour guide robot 
proceedings fifteenth national conference arti cial intelligence aaai madison wisconsin july 
davison murray 
mobile robot localisation active vision 
proceedings fifth european conference computer vision eccv volume ii pages freiburg germany june 
dellaert burgard fox thrun 
condensation algorithm robust vision mobile robot localization 
proceedings ieee conference computer vision pattern recognition cvpr fort collins june 
fox burgard thrun cremers 
position estimation mobile robots dynamic environments 
proceedings fifteenth national conference arti cial intelligence aaai madison wisconsin july 
gutmann konolige 
incremental mapping large cyclic environments 
proceedings ieee international symposium computational intelligence robotics automation california november 
harris 
geometry visual motion 
blake yuille editors active vision pages 
mit press 
isard blake 
condensation conditional density propagation visual tracking 
international journal computer vision 
little lu murray 
selecting stable image features robot localization stereo 
proceedings ieee rsj international conference intelligent robotic systems iros victoria canada october 
lowe 
fitting parameterized dimensional models images 
ieee trans 
pattern analysis mach 
intell 
pami may 
lowe 
object recognition local features 
proceedings seventh international conference computer vision iccv pages kerkyra greece september 
murray jennings 
stereo vision mapping navigation mobile robots 
proceedings ieee international conference robotics automation icra pages new mexico april 
murray little 
real time stereo vision mobile robot navigation 
proceedings ieee workshop perception mobile agents santa barbara ca june 
nourbakhsh powers birch eld 
oce navigating robot 
ai magazine 
sim dudek 
learning evaluating visual features pose estimation 
proceedings seventh international conference computer vision iccv kerkyra greece september 
simmons koenig 
probabilistic robot navigation partially observable environments 
proceedings fourteenth international joint conference arti cial intelligence ijcai pages san mateo ca 
morgan kaufmann 
thrun burgard cremers dellaert fox rosenberg roy schulte schulz 
minerva museum tour guide robot 
proceedings ieee international conference robotics automation icra detroit michigan may 
thrun burgard fox 
probabilistic approach concurrent mapping localization mobile robots 
machine learning autonomous robots joint issue 
thrun burgard fox 
real time algorithm mobile robot mapping applications multi robot mapping 
ieee international conference robotics automation icra san francisco ca april 
