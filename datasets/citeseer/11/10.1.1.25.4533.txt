augmenting microprocessor reconfigurable hardware john reid hauser 
north carolina state university 
north carolina state university 
university california berkeley dissertation submitted partial satisfaction requirements degree doctor philosophy computer science graduate division university california berkeley committee charge professor john wawrzynek chair professor randy katz professor john strain fall dissertation john reid hauser approved chair date university california berkeley fall date date augmenting microprocessor reconfigurable hardware copyright john reid hauser augmenting microprocessor reconfigurable hardware john reid hauser doctor philosophy computer science university california berkeley professor john wawrzynek chair vlsi technology continues improve configurable hardware devices progressively replacing specialized digital integrated circuits 
field programmable gate arrays fpgas class devices characterized ability reconfigured desired 
lately fpgas advanced stage host large computational circuits giving rise study reconfigurable computing potential alternative traditional microprocessors 
previous recon computers ad hoc designs fully compatible existing general purpose computing paradigms 
thesis examines problem combining reconfigurable hardware con processor single chip device serve core general purpose computer 
impact memory cache stalls multitasking context switches vir tual memory page faults design reconfigurable hardware considered 
pos sible architecture device defined detail implementation vlsi studied 
basic development tools full fledged simulator benchmarks tested proposed architecture performance compared favorably existing sun ultrasparc 
additional experiences architecture related followed suggestions research 
professor john wawrzynek dissertation committee chair departed mother wanted see get degree 
contents list figures list tables ix background motivation potential reconfigurable computing 
computing devices 
utilizing growing hardware resources 
limitations superscalar vliw processors 
reconfigurable computing new model 
hybrid machine 
fpgas 
previous fpga systems applications 
focus research 
related 
concept prototypes 
reconfigurable functional units processor 
streaming reconfigurable hardware 
novel reconfigurable hardware computation 
design issues integrating reconfigurable hardware computer 
level integration 
programming paradigm 
configuration encoding loading 
caching configurations 
array clocking 
external interface access memory 
multitasking 
servicing page misses 
designing reconfigurable hardware computation 
dominance wires 
ii bit serial bit parallel bit pipelined arithmetic 
array granularity 
multiplication elements 
review 
proposed garp design garp architecture 
array organization 
array logic blocks 
array wires 
array timing 
support computational primitives 
processor control array execution 
configurations 
array access memory 
memory queues 
contrast designs 
implementation study 
functional organization 
pass transistors switching 
array wires 
configuration cache management 
logic block layout 
configuration storage distribution 
logic block functions 
speed power area 
benchmarks statistics hypothetical garp 
software tools 
configurator 
linking configuration program 
simulator 
hand coded benchmarks 
data encryption standard des 
md sha hashes 
image dithering 
image median filter 
sorting 
library functions strlen strcpy 
benchmark review 
configuration statistics 
functional density 
logic block inputs 
logic block functions 
iii granularity 
wire connections 
memory accesses 
garp retrospective noteworthy features 
processor handling start shut particulars support extended functions logic blocks 
limited configuration turnaround 
array access memory 
array clocking context switches 
corrected mistakes 
weaknesses 
wire network 
memory bottleneck 
programming experience 
summary contributions 
application niche 
architectural alternatives 
programming challenge 
outlook 
bibliography garp architecture 
reconfigurable array 
internal wire network 
logic block configurations 
logic block functions 
internal timing 
integration array main processor 
processor control array 
array control blocks 
array memory queues 
garp application notes single bit operations 
shifts 
carry chain 
adding subtracting terms 
multiplication 
iv list figures data flow graph simple expression 
simplified diagram aggressive superscalar vliw processor 
application specific pipeline computing graph 
model reconfigurable device analogous traditional processor 
practical hybrid machine combining traditional processor reconfigurable device 
reconfigurable structure appears commercial fpga 
canonical logic block function 
simplified view xilinx series logic block 
reconfigurable array attached functional unit coprocessor style register transfer interface 
configuration cache multiple cache planes 
bus array loading configurations moving data memory main processor register file 
bit serial bit pipelined bit parallel addition 
possible schemes inserting dedicated carry chain logic block 
skew conversion bit parallel serial pipelined form back 
comparison followed multiplexor implementing expression 
mixture parallel pipelined serial techniques 
various structures 
organization garp 
garp array organization 
typical natural layouts multi bit functions 
simplified logic block schematic 
simple table lookup function logic block 
logic block triple add function 
carry chain row 
logic block select function 
wire channels input output logic block 
pattern vertical wires wires single column rows 
horizontal wires wires wires rows 
main parts needed implement complete garp array 
broadcasting control signals row control block 
routing signal pass transistors 
physical implementation wire matching garp architecture logical definition 
input multiplexors output drivers underneath vertical wire channel logic block 
single input multiplexor implemented binary tree pass transistors 
common style tri state driver transistors series 
common tri state driver circuit final transistors series 
tri state driver circuit non minimal transistors final transistors series making higher control voltage select line 
layout underneath vertical wires driver circuit 
breaking longer wires pieces logic blocks long joined configurable buffers 
array core quilt patches logic blocks 
proposed layout organization logic block 
outline single logic block tile 
allocation metal layers individual logic block 
relative space assumed various logic block parts detailed layout main density sensitive components 
contacts memory buses boundary adjacent logic block tiles 
bit line configuration storage 
gates transmission gates 
complete contents logic block datapath 
floorplan ultrasparc die hypothetical garp die constructed technology 
garp programming environment 
iteration inner loop des 
iteration inner loop md hash 
floyd steinberg error diffusion 
execution times speedups image dithering 
algorithm finding median values arranged grid 
execution times speedups image median filter 
execution times speedups sorting 
execution times speedups strlen function 
execution times speedups strcpy function 
vi time bring strlen strcpy configuration dram compared time execute function strings various lengths 
connection vector plots benchmark configurations 
typical processing image configuration reconfigurable hardware capable handling middle scan line edges corrected main processor 
basic organization garp 
structure reconfigurable array 
internal wiring array independent memory buses 
simplified logic block schematic 
vertical wires wires arrays various sizes 
twisting vertical wires obtain recursive structure 
horizontal wires rows 
logic blocks reachable wire driven center 
options driving wires row 
logic block configuration encoding 
configuration encoding logic block inputs 
configuration encoding logic block registers outputs 
input completely separate path routing copying 
internal register logic block input 
delaying logic block input path 
delaying output path 
reading values memory buses internal registers configured logic block inputs 
complete logic block diagram 
function mode encodings 
table mode mode 
crossbar functions encoding 
interpretation lookup table table mode 
split table mode mode mx 
interpretation lookup table split table mode 
select mode mode mx 
shift invert functions encoding 
partial select mode mode mx 
carry chain mode mode 
interpretation lookup table carry chain mode 
operation carry chain 
result functions modes carry chain 
triple add mode mode 
interpretation lookup table triple add mode 
set logic blocks read written various processor instructions 
control block configuration encoding 
control block signals 
vii reduction functions 
valid connection control block 
configuration encoding control block processor interface mode 
configuration encoding control block memory interface mode 
steps memory access initiated array 
memory interface configuration fields associated initiate step demand memory access 
memory interface configuration fields associated transfer step memory access 
timing memory write executed array 
timing memory read executed array 
format queue control record 
memory interface configuration fields associated initiate step memory queue access 
timing write array memory queue 
timing read array memory queue 
fewest power terms sum odd integer 
layout garp array multiplier unsigned bit variables calculating bit product 
viii list tables sampling fpga chips available xilinx 
applications utilizing shelf fpgas 
approximate formulas area latency turnaround different arithmetic styles 
reduction formulas table certain assumptions 
relative total area supposing retiming register takes area rest logic block 
granularity area bit op simple model 
summation tree form number bit operators tree height approximate relative latency numbers terms ranging 
examples primitive operations implemented garp reconfigurable array 
array features employed various operations 
basic processor instructions controlling reconfigurable array 
comparison garp research designs 
synopsis hand coded benchmarks 
number calls strlen strcpy needed cover initial configuration loading time achieve parity ultrasparc 
representative set benchmark test cases sorted approximately speedup factors limiting improvements 
names sizes configurations benchmarks 
utilization major logic blocks parts 
utilization logic block inputs tabulated separately 
logic block utilization array column 
distribution input sources active inputs 
subdivision horizontal wire inputs table 
distribution logic block function modes 
distribution permutation box functions 
percentage logic blocks operations bit width ranging 
percentage operations bit width ranging 
ix distribution wire hops logical connection logic blocks 
inherent memory access patterns benchmark configurations memory access resources 
peak memory bandwidth requirements benchmark configuration 
results compiling wavelet image compression program ultrasparc garp callahan 
added instructions 
list added instructions encoding order 
configuration carry chain comparison 
configuration carry chain comparison 
configuration carry chain addition 
acknowledgments advisor john wawrzynek generous support encouragement years 
confidence project completed 
berkeley computer science faculty graciously extending time bring dissertation 
cohort garp project tim callahan quiet friendship listening various monologues regular poor software 
garp compiler tim helped project success increased impact community 
equal notably chang bowman dancing william tsu joe distracting discussions religion politics language culture history travel photography stock market intellectual property law times computer architecture software 
left join faculty mit helped sharpen thinking computer architecture sub jects 
dave johnson folks icsi cal hiking outdoor society chaos people played ultimate friend dave helping keep life perspective 
jim beck enjoyable commentary 
graduate assistants kathryn crabtree peggy lau deserve helping graduate students negotiate rules accompanying phase progress degree 
graduate funded part darpa adaptive computing systems program dabt onr nsf cda donations xilinx hewlett packard 
recognize continued support family years 
xi chapter history years digital electronics technology improved exponentially time doubling performance roughly months device sizes costs shrunk correspondingly 
line growth number transistors available constructing commodity microprocessor currently doubles years 
persistent evolution computer components computer archi tecture constantly reexamined reinvented 
designs excellent decade ago may hopelessly simplistic today techniques prohibitively expensive today norm 
intuition current state art may judge bring 
decade order superscalar processors developed stan dard desktop microprocessors 
widely believed fast reach ing limits paradigm 
superscalar issue width grows overhead increases quadratically time opportunities exploiting instruction level parallelism grow 
approach day single chip holds transistors literally pack vintage intel die doubtful superscalar designs available potential 
alternative considered technology field programmable gate arrays fpgas 
obvious application best served custom circuitry targeted specifically fact application specific integrated circuits asics response special needs 
afford turn custom chip application wants run feasible state art asics expensive day 
technology improved market grown versatile shelf parts programmed emulate arbitrary digital circuits place asics 
fpgas class devices distinguished ability reprogrammed reconfigured number times 
versatility fpgas comes price 
years ago algorithms implemented single fpga chip fairly small 
example largest fpgas programmed circuits logic gates 
fast bit adder requires couple gates capabilities devices somewhat bounded 
fpgas reached size imple ment reasonable application single fpga part 
led new concept computing processor include fpga devices theory support specialized application specific circuit program stage program execution 
unlimited reconfigurability fpga continuous sequence custom circuits employed optimized task moment 
fpgas scale better superscalar techniques designs potential better continuing advances device electronics long term 
idea reconfigurable computing subject research decade projects investigated potential connecting commercial fpgas existing microprocessor standard external bus pci bus 
reconfigurable computing really computing paradigm main parts brought closer 
studies considered integrating processor fpga single device tailored cooperate closely remain important questions device built programmed fit existing general purpose computing frame 
questions addressed bigger issue reconfigurable computing really model answered 
thesis attempts progress question reconfigurable computing viable option general purpose computers 
succeeding chapters contain look fundamentals computing machines followed summary past reconfigurable computing articulation purpose research project 
exploration numerous issues arising integration reconfigurable hard ware processor 
presentation plausible architecture reconfigurable enhanced processor examination feasibility implementing efficiently vlsi 
summary development simulation tools created proposed archi tecture quantitative results handful benchmarks design evaluated 
lastly brief retrospective weaknesses proposed architecture lessons learned design 
thesis closes opinions direction research reconfigurable computing 
chapter background motivation chapter reviews fundamentals computation considers reconfigurable computing important 
lays focus research ends summarizing related 
potential reconfigurable computing computing devices computation represented combination data flow control flow graphs nodes graphs primitive operations integer addition comparison 
example data flow graph short expres sion 
primary function computer evaluate graphs mechanically accomplish goal 
course real computer processors operate graphs directly programs encoded collection machine instructions executed specific sequence 
just artifact design machine intended originally simplify processor task programmer 
modern processors fact re expose instruction level parallelism dynamically decoding short sequences machine instructions correspond ing data control flow forms executing 
regardless program physically encoded data flow control flow graphs represent true computation performed 
evaluate computational primitives graphs addition multiplication data flow graph simple expression 
processors include functional units capable performing certain class functions 
simple processor may single purpose functional unit known alu arithmetic logic unit execute operation time 
sophisticated processors superscalar vliw attempt utilize multiple functional units different kinds simultaneously execute programs faster 
concept functional units computer needs evaluate operations data flow graph 
practice computer support physical movement data functional units memory 
computers multiple functional units clearly move data trivial sound 
simple processor single alu small amount data stored close alu time 
practical general purpose computer memory hierarchy fastest smallest memory usually registers closest functional units increasingly slower memory correspondingly farther away 
moving data different levels memory explicitly implicitly computer operation 
shows simple diagram superscalar vliw processor functional units 
clock cycle attempt execute primitive operations possible available functional units 
forwarding crossbar carries output units back functional unit inputs set operations executed clock cycle minimum delay 
multi ported forwarding crossbar fu fu multi ported register file fu fu fu core aggressive superscalar vliw processor 
boxes labeled fu functional units 
small rectangles registers preceding functional units may registers shown 
application specific pipeline computing graph 
register file forms highest level memory hierarchy store values multiple cycles 
ideal functional unit clock cycle processor achieve programs data control dependencies inherent practical algorithms 
flexibility functional units forwarding crossbar register file standard processor programmable capable executing arbitrary application decent performance applications thought processor built 
antithesis programmable processor asic application specific circuit 
asic functional units dedicated individual program operations wired match precisely calculation performed 
fig ure shows example application specific pipeline layed perform calculation data flow graph 
advantages asic programmable processor threefold considerably overhead needed control mapping functional units op erations routing data values 
programmable processor overhead manifest time die area 
smaller specialized functional units overhead circuitry functional units fit die area 
operation functional unit known planned advance functional unit idleness minimized 
programmable processor certain kinds functional units specific application 
obviously definitions programmable device asic vice versa 
shall see reconfigurable devices fpgas share characteristics processors asics 
hand fpgas implement asic style circuits infinitely reprogrammable general purpose 
leads question reconfigurable hardware capture advantages asics general purpose computing environment 
utilizing growing hardware resources past fpgas modest compete relatively efficient super scalar processors relationship may changing 
electronic devices continue grow smaller faster day 
benefits faster transistors wires obvious smaller means get cost 
market forces provide strong incentive find way added resources improve new processor generation 
real processor done functional units obvious place focus 
additional transistors employed functional units ways individual functional units faster reengineering speed expense die area 
example bit time iterative multiplier replaced larger faster array multiplier 
physical limits approach 
processor array multipliers opportunities improving multiplication dramatic 
new functional units added functions previously required sequence operations 
exactly happened example floating point functional units originally added processors happening today small simd operations mmx vis 
expanding different kinds functional units likelihood increased unused application 
copies existing kinds functional units added 
easiest route contemplate hardest productive 
aside increased hardware complexity having functional units juggle new degrees parallelism software new units sit perpetually idle 
despite difficulties increased parallelism viable path opportunities options 
modern superscalar vliw processors committed way instruction issue considered 
software contains roughly classes parallelism exploited thread parallelism independent threads execution executing separate sequence instructions 
example subroutine contains separate loops dependencies case loops executed simultaneously 
inter iteration parallelism exists iterations single loop mutually independent executed parallel 
known data parallelism vector parallelism kind parallelism vector processors profit 
classic matrix multiply fast fourier transform inter iteration parallelism grows sizes operand arrays 
instruction level parallelism ilp exists operations single thread control single loop iteration 
short expression example instance way ilp subtractions allowing operations executed time 
limitations superscalar vliw processors desktop processors adopted superscalar techniques exploit ilp 
definition superscalar processor accepts sequential instruction stream discovers parallelism instructions dynamically automatically 
basic model followed forwarding crossbar multi ported register file 
extra large register file automatic register renaming commonly overcome false dependencies registers 
popularity superscalar machines efficient ex parallelism 
way issue effort usually expended testing instruction dependencies controlling instruction issue executing operations 
sue overhead grows quadratically number functional units 
pressure grow quadratically forwarding crossbar register file register file size bits number ports increased 
way superscalar processor require tremendous overhead just keep units busy 
vliw long instruction word processors eliminate instruction issue overhead programmer compiler task scheduling instruc tion execution take maximum advantage ilp 
superscalar processor fly find ilp avoid false dependencies register renaming done advance program run 
wide vliw processors known resist quadratic growth register file crossbar typically segmenting crossbar fully connected register accessible functional unit 
limitations vliw processor difficult schedule efficient 
circuitry needed issue new instructions functional units reroute crossbar clock cycle remains potential source inefficiency vliw processors 
furthermore superscalar vliw designs take advantage thread parallelism 
greatest sources parallelism programs inter iteration thread parallelism opposed simple ilp eventually exposed serious shortcoming 
retiming queues configurable network fu fu fu fu fu model reconfigurable device analogous traditional processor 
important aspect visible fact reconfigurable device generally take cycle cycle instruction stream reconfigured execution 
reconfigurable computing new model reconfigurable computing alternative superscalar vliw para 
illustrates reconfigurable device lines previous processor diagram 
main distinction reconfigurable device standard processor instruction stream purest form reconfigurable device cycle cycle instruction stream 
device configured loading complete specification function part device 
configured intention device run configuration decent interval reconfigured 
configuration mimics asic circuit specialized par ticular task hand 
changing configurations take clock cycles cycles 
accordance simpler programming mechanism dynamic forwarding crossbar replaced flexible configurable network mak ing static connections functional units short queues retiming registers associated functional unit take place traditional processor shared multi ported register file 
familiar rule asserts execution time consumed program code generally inner loops 
reconfigurable devices excel cases computation represented configuration repeated times time required load configuration amortized long execution time overlapped execution 
application important loop bodies configured fit reconfigurable machine time need overhead fully dynamic instruction fetch issue master processor slave reconfigurable device practical hybrid machine combining traditional processor reconfigurable device 
mechanism allowing machine efficient 
reducing hardware just essentials needed support computation reconfigurable design scales better larger sizes complex superscalar vliw styles 
naive expansion configurable network cause grow quadratically number functional units needs grow support connectivity required real applications 
furthermore superscalar vliw machine reconfigurable hardware easily exploit simple ilp inter iteration thread parallelism making reconfigurable computing poised large numbers functional units 
hybrid machine corollary rule program code accounts execution time 
practice reconfigurable devices get bogged large parts programs executed repetition justify time takes load configuration 
practical compromise couple reconfigurable device traditional style processor order exploit strengths 
organization reconfigurable hardware execute innermost loops kernels application modest traditional processor handles mass code kernels 
hybrid architecture sense reconfigurable part traditional processor reasons traditional processor executes control code logically ties various kernels reconfigurable device perform execution traditional processor default condition allowing new machine fit easily existing computing practice 
master processor instruction set compatible existing proces sor architecture leverage existing development tools operating systems 
configurable network logic blocks reconfigurable structure appears commercial fpga 
fpgas input table lookup canonical logic block function 
single bit inputs taken configurable network index entry table possible outputs 
box labeled bit register output optionally latched sent back configurable network logic blocks 
common reconfigurable devices today fpgas indepen dently packaged parts marketed prototyping platforms reconfigurable alter natives asics 
commercial fpga basic structure reshaped dimensions look functional units earlier diagram broken larger number logic blocks individually small 
canonical logic block considered lookup table takes bits input generates bit output shown 
filling table right bits input logic function realized 
various studies suggested inputs size lookup tables trading utility powerful blocks utilization fraction power ends idle 
logic blocks actual fpgas tend complex single lookup table similar diagram xilinx series logic block input lookup tables extra input table total eleven bits input bits output 
dedicated carry chain circuitry top easy gang line logic blocks form relatively fast multi bit adder 
diagram fact ignores additional details way xilinx bit lookup tables bits random access memory options available carry logic input table lookup carry logic input table lookup input table lookup simplified view xilinx series logic block 
block eleven input bits output bits plus special carry chain hardware basic arithmetic operations 
number input bytes chip lookup tables data ram xc xc xc xc xv xc xv xcv xcv xcv xcv xcv xcv xcv table sampling fpga chips available xilinx 
devices additional capabilities just lookup tables data memory listed 
controlling clocking single bit registers 
complex xilinx logic block quite small compared usual functional units computer 
large numbers small logic blocks add considerable compute power 
table lists current offering fpgas xilinx currently popular vendor xilinx com 
new xcv example hardware implement bit adders 
depending device configured equates hundreds bit variable dozens fully pipelined bit multipliers 
die sizes largest parts generally boundary manufactured course true smaller parts expected bring greater densities 
previous fpga systems applications past decade projects reported fpgas obtain speedups traditional computers particular applications 
literature includes quite examples collection shelf fpgas connected achieve performances hundreds thousands times faster workstation type computer working problem 
early splash example fpga machine calculate genome dna edit distances times faster contemporary sparc perform median filter grey scale image times faster sparc 
numbers interest reconfigurable computing general purpose reconfigurable architecture years reach 
pointed splash board contains fpga parts sparc built microprocessor single chip 
fairer comparison normalize performance number compute chips special board sparc processors compute faster single sparc 
speedups divided number active fpgas chip speedup factors genome edit distance just grey scale median filter 
numbers obviously interesting put fpga speedups better perspective 
examples fpga applications listed table 
general best speedups tend range times chip reconfigurable compared speedup application machine chip year military target splash board mhz recognition xilinx hp finding golomb board mhz rulers xilinx ultrasparc bit multiply divide square root xilinx xl ultrasparc frequency domain xilinx xl mhz adi sonar beamforming computing xilinx mhz partitions mips rendering zier pci card desktop pc curves xilinx genome matching vme card sparc generalized profiles xilinx infrared military pci card mhz target recognition xilinx pentium notes estimated experience perle board xilinx 
fpga operated curves times longer overhead rendered pixel 
table applications utilizing shelf fpgas 
fpga chips performing computation counted speedup numbers 
exceptional applications doing better 
arguments earlier sections right numbers improve technology advances 
memory support chips counted comparisons partly subject interest partly rare information provided possible 
assumed memory system bottleneck examples 
current research indebted early projects done dec paris research lab supercomputing research center maryland 
board third generation dec programmable active memories pam project contained xilinx chips connected host dec workstation tur bus 
similarly supercomputing research center splash board xilinx plugged sparcstation 
splash boards attached single sparcstation apparently 
half experimental boards accelerate collection applications including genome dna pattern matching determin ing stereo vision paired images human fingerprint minutia matching solving dimensional heat equations hough transforms gaussian laplacian mid generation images 
perle board assisted particle detection cern large collider 
new reconfigurable machines solve large problems hundreds times faster workstations time 
needed dozens fpga chips 
full size board dozen large processing chips competitive replacement single chip microprocessor 
fpga parts available back small allow interesting problems fit just chip 
situation improved time various companies marketed plug boards shelf fpgas 
boards typically plug computer expansion slot pci bus generic accelerator cards specially pro applications 
visible current vendors include limited www 
com alpha data parallel systems www uk annapolis micro systems com virtual computer vcc com 
boards useful people regularly complained shortcomings slow reconfiguration times fpgas overhead shipping data back forth connecting bus 
generally slow configuration time commercial fpgas reflection intended market 
xilinx xcv instance largest parts takes ms load complete configuration 
older slower xc fourth logic blocks needs ms load configuration 
fpga flexible alternative asic configured system booted case configuration times dozen milliseconds inconsequential 
acting computational accelerator mhz processor hand configuration overhead means kernel fpga works execute clock cycles chance achieving speedup factor 
reconfigurable hardware configuration overhead far greater applicability 
overhead moving data back forth singh example xilinx fpga virtual computer board perform fir filter image times faster pci bus transmit original filtered images board 
memory bottlenecks problem matter computation performed safe bet main processor computer bandwidth dram devices side pci bus 
reconfigurable hardware going execute program kernels faster main processor deserves equal better bandwidth memory processor 
focus research recap truths stated reconfigurable devices may small highly kernels applica tions standard processors superior remaining code irregular rarely repeated 
reconfigurable computing economically viable small fraction market number parts involved squeezed chip preferably 
existing microprocessors implemented single chip pressure market fewer parts 
reconfigurable hardware meet full potential reconfiguration time minimized reconfigurable hardware access computer memory available main processor 
better integrate reconfigurable device computer various researchers called combining traditional microprocessor fpga device die form new kind processor :10.1.1.21.7928
took fpga chip interesting reached stage powerful reconfigurable device fit partial die 
superscalar vliw designs fail capitalize increasing transistor counts chip hybrid machine provides way employ greater vlsi densities just larger caches 
remains uncertain just effective machine practice general purpose platform 
say hard predict processor fpga share die commercial product 
year www 
com chameleon systems www com altera www altera com announced begun shipping parts 
products intended embedded market ad hoc coupling fpga processor memory tolerated 
challenging question hybrid architecture successful general purpose market desktop pcs dominated intel processors 
definition general purpose computer prepared run software written arbitrary third party sources purposes unknown time computer created 
special features general purpose environments include preemptive multitasking multiple processes threads execution active time running process may suspended time give process chance run 
virtual memory memory accesses translated virtual physical ad dresses time allocated virtual memory may reside physical ram slower device hard disk 
mem ory access may necessitate suspension running process requested memory page retrieved hard disk 
interprocess protection better isolate faults ensure security users processes prevented performing actions interfere 
binary compatibility user level executable code run family architecture implementations 
binary compatibility protects customers investments software upgrade better machines 
advantage reconfigurable hardware general purpose proces sor measured idea machine look 
just know parts die performance surely affected way pieces interconnected 
better access memory part point moving reconfigurable hardware die place 
issues listed addressed 
making fpga amenable preemptive multitasking instance performance implications embedded market face 
dissertation project attempted shed light value augment ing traditional general purpose processor reconfigurable hardware defining prospective architecture assessing performance sampling applications 
number design issues chapter relating formance reconfigurable part adaption general purpose environment 
effort verify proposed architecture reasonably implemented vlsi 
running programs simulator new architecture compared ordinary superscalar processor see speedups achieved typical applications 
evaluate new processor design benchmark rigorously existing processors broad sampling workloads 
commonly accepted framework integrating reconfigurable hardware processor project little bit necessary design reasonable architecture evaluate performance 
considering current processor design benefited decades refinement hundreds researchers ambitious expect project generate absolutely definitive efficacy reconfigurable computing 
goal find trends narrow focus research 
related researchers discussing reconfigurable hardware traditional processor years number prototypes partial experiments tried varying degrees success 
concept prototypes probably earliest prototypes virginia polytechnic institute prism ma chines 
prism consisted board xilinx plugged host system motorola 
prism reconfigurable hardware essentially multi fpga board discussed section focus prism making board fully transparent extension host processor 
name prism acronym processor reconfiguration instruction set metamorphosis 
compiler created minimal assistance programmer automatically picked candidate subroutines compiled reconfigurable hardware processor 
compiled programs ran partly host processor partly attached fpga board 
second prototype prism ii brought host processor fpgas closer attaching amd am directly xilinx irregular network 
machines sizes fpgas time limited example kernels small functions hamming distance bit reversal finding bit bit word 
just small kernels speedups host processor ranged factors fpga chip 
encouraging small kernels said representative real applications 
similar project conducted cole polytechnique rale switzerland 
spyder machine extended custom processor xilinx acting reconfigurable execution units 
spyder programmer sible dividing program main processor reconfigurable units programming special subset 
brigham young university prototyping hybrid machine taken step dynamic instruction set computer disc 
orig inal disc disc ii entire combined processor main processor reconfigurable component constructed fpga parts 
disc national semiconductor clay primitive main processor squeezed part clay majority chip supplying prototype reconfigurable component 
second clay fpga served control loading configura tions 
disc ii main processor moved separate third clay powerful 
lacking special compiler disc kernels separated hand programmed usual fpga tools 
disc ad vance primarily handling configuration loading 
reconfigurable component treated small cache cache resulting automatic stall needed configuration loaded 
reconfigurable functional units processor early prototypes researchers looked possibility integrating reconfigurable hardware closely just functional unit pipeline processor 
projects include prisc design harvard university chimaera northwestern university concise philips research laboratories :10.1.1.47.1042
designs reconfigurable hardware separate data state functional units processor data inputs obtained register file results stored back 
internal registers reconfigurable functional units support combinatorial circuits loops circuit 
systems compiler extended find common sequences instructions implement reconfigurable units 
disc systems load configurations cache manner 
program requests configuration wants ready execution stalls automatically requested configuration loaded 
unfortunately speedups demonstrated systems impressive rarely factor 
fundamentally technique limited ability exploit parallelism explored section 
streaming reconfigurable hardware different tack research dedicated reconfigurable hardware pri streaming applications 
streams data sequential order stream processing generally done basis 
examples streaming applications include audio video filtering compression decompression encryption decryption 
streaming hardware problems decomposed vector op erations unit stride vectors contiguous memory vectors treated streams 
stream oriented architecture university washington rapid 
rapid reconfigurable unit composed primarily bit functional units registers connected configurable network original image 
part reconfigurable unit stream specific input output reconfigurable unit required form streams memory 
streams supported 
data connection specified main processor reconfigurable unit memory 
stream oriented architecture 
original different organization fully fleshed 
single input stream single output stream supported restrictions stream length alignment design compelling 
streaming applications decomposed assembly line sequence smaller operations act streams 
characteristic opens door way virtualizing reconfigurable hardware streaming application run range reconfigurable units varying sizes execution speed proportional amount reconfigurable hardware available 
keeping assembly line analogy easy understand assembly line workers ought able turn product team simply take twice long generate quantity output 
interesting lines carnegie mellon university piperench reconfigurable unit :10.1.1.21.5165
compiler piperench breaks streaming application long sequence component stream operations configuration represented program 
comes time run program particular piperench implementation large contain entire sequence individual pieces reconfigurable hardware regularly recycled different parts long sequence automatically 
design piperench hardware permit problems adequately represented terms streams way 
novel reconfigurable hardware computation design commercial fpgas generally acknowledged historic bias random control logic called glue logic core arithmetic operations addition multiplication computation 
reconfigurable hardware adopted general purpose processor appropriate consider alternative designs 
projects mentioned invented new reconfigurable hardware processors 
studies focused exclusively reconfigurable array specifying exactly connected memory main processor 
direction taken re optimize fpga logic blocks bit serial arithmetic 
approach represented nec experimental sea processors sop reconfigurable array developed tokyo institute technol ogy 
common notion replace lookup table logic blocks fpga larger alus capable bit bit larger operations 
chess array described marshall bit logic blocks bit functions favored piperench matrix array designed mas institute technology :10.1.1.21.5165
reconfigurable hardware rapid divided parallel tracts bit functional units data separate control tract fpga style lookup tables 
ideas structures proposed list 
example haynes cheung describe novel array bit blocks combined directly form multiply accumulate operators 
noted rapid chess matrix break reconfigurable tradition allowing functional units receive instructions data configurable network 
certainly consensus best structure reconfigurable accelerator shared theme existing fpga hardware may best choice doing type computation associated application software 
chapter design issues general purpose computers distinctive features limitations including support multitasking virtual memory structured programming 
multitasking im plies ability perform context switches 
virtual memory requires memory ad dresses translated memory accesses cause page faults serviced transparently system 
structured programming assumes functional implemen tation hidden clients functions extent separate compilation function client 
aspects considered designing reconfigurable hardware augmenting general purpose processor 
chapter covers gamut issues starting high level processor reconfigurable integration moving low level details reconfigurable unit 
integrating reconfigurable hardware computer bringing reconfigurable hardware closer processor interact tightly 
main advantage proximity reconfigurable array processor memory system eliminating need copy data back forth laboriously external bus 
closer connection memory improved coordination processor permit reconfigurable array employed larger number smaller tasks 
achieve greatest cooperation options specifics coupling need explored 
processor registers functional units reconfigurable array processor registers functional units move reconfigurable array reconfigurable array functional unit main processor pipeline existing register file 
separating reconfigurable unit processor pipeline coprocessor style register transfer interface 
internal array state permits execution proceed array independently main pipeline 
level integration freedom integrate reconfigurable hardware processor designers gone way added reconfigurable array functional unit processor pipeline 
noted section examples literature include prisc chimaera concise :10.1.1.47.1042
design array inputs naturally taken processor registers results written back register file just pipeline functional units 
adding processor instructions form rd ra rb reconfigurable array provide unique tailor operations program 
seemingly straightforward ap proach pitfalls 
face question array hold internal data state stateless functional units dependent main register file storing data 
array contains internal data registers able execute independently extended length time useful combinatorial calculation done words read register file generate couple words write back 
consequence seen speedups reported previous examples 
prisc achieves speedups averaging specint benchmarks lone exception eqntott benchmark saw speedup factor :10.1.1.47.1042:10.1.1.47.1042
chimaera speedups factor exceptions short bit simd techniques 
concise speedups des encryption stream cipher respectively 
contrast experience prism ii agarwal argued reconfigurable unit able execute cycles maximize advantage 
parallelism achieved reconfigurable unit data state strictly number read write ports register file preventing array realizing tremendous speedups traditional processor 
situation improved addition ports register file better direct solution allow array contain internal state analogous separate traditional register file 
state presumably spread array array keep large number operations running simultaneously extended period time way impressive speedups obtained 
complication necessary suspend array execution midway context switch occurs array computing 
trouble essentially unavoidable addressed section 
computation array take indefinite time instructions form rd ra rb cause problem processor pipeline 
assume moment results instructions interlocked instruction takes input register written reconfigurable array instruction instruction stall array execution completed 
absence interlock stall subsequent processor instructions continue execute parallel reconfigurable array usual manner processor pipeline 
difficulties arise context switch occurs array instruction progress precise interrupts impractical mechanism backing processor state reorder buffer necessary restore state point instruction began 
addition backing array effects instructions completed array executing undone 
wanted take risk discarding potentially thousands cycles forward progress state need saved prohibitive 
saved state necessarily cover memory accesses time 
ordinarily context switch software save registers simple sequence register store instructions 
register value pending ongoing array computation store register interlock blocking context switch indefinitely 
information registers pending array instruction saved part context switch state restored context resumed register interlocks properly process resumed 
designers admit partly recognition difficulties reconfigurable units prisc concise limited clock cycles execution 
throttling power reconfigurable hardware answer 
concerns moot interlock result reconfigurable array instructions 
option causes problems solves 
automatic interlock instructions statically scheduled compiler human programmer 
static instruction scheduling hundreds thousands clock cycles array execute surely tricky get right 
worse fact static scheduling possible exact instructions proces sor execute cycle strictly determinable architecture definition means improved implementations 
architecture specifies integer multiplication takes clock cycles number reduced rescheduling software new implementation instruction execution get sync execution function reconfigurable array 
possible full interlocking find way context switches functional unit takes indefinite time complete 
easier simply discard rd ra rb style instruction causes trouble place 
long executing functional unit need processor pipeline separated coprocessor distinct instructions transfer data main register file 
previous instruction form split multiple ones move argument data coprocessor start coprocessor execution move result back 
overhead executing extra instructions transfer data small reconfigurable hardware executes cycles time 
avoid static scheduling instruction copy data back coprocessor interlocked completion computation 
interlock problematic explicitly tied completion array computation earlier case connection implicit register 
section covers required context switches coprocessor model 
programming paradigm reap greatest speedups reconfigurable functional unit execute clock cycles stretch amount static program code implemented reconfigurable array time usually small 
code program best candidates implementing array inner loops small static code size potentially large dynamic instruction counts 
loops transferred array account majority program execution time speedup achieved entire program 
simplest programming model assumes program execution reaches inner loop appropriate configuration loaded array input data copied array array execution started 
loop done results copied instruction execution resumed main processor loop 
interesting loops repeatedly access memory pointers arrays means provided getting memory data loop execution discussed section 
experiment jantsch real programs contain inner loops potential candidates acceleration 
candidates execute long risking time load configuration exceed time saved reconfigurable hardware 
hide time takes load configurations proposed re configurable unit able preload configuration needed current 
obstacle doing general purpose computer way structured programming decomposes programs independent subroutines implementations supposed hidden may fact separately compiled 
reworking paradigm known configuration needs loaded subroutine needs called may late overlap load computation 
section explains may excess bandwidth memory preloading configuration array executing 
preloading techniques combat configuration load ing overheads configurations encoded densely bandwidth mem ory loading configurations widened configurations cached array reuse 
configuration encoding loading part reason takes xilinx xcv ms load full configuration section configuration size kb bits input lookup table 
existing fpgas relatively decoded representation configurations 
take simple case logic block inputs connected choice nearby wires network selected input 
wires choose typical fpga encode choice bits indicating connection 
compact encoding log bits choose wire connect logic block input 
seen section encoded form case costly array hardware 
dense encoding outright compression employed obvious redundancy logic blocks configuration 
bit wide arith operation instance contiguous logic blocks configured exactly 
redundancy compressed simple run length encoding example 
configuration compression studied hauck students 
compression reduce bandwidth needed read configuration memory maintaining compressed form array adds hardware cost benefit 
certainly array sufficient storage space fully uncompressed configuration legitimate configurations need redundancy logic due way fpga networks connection wire logic block input 
general potential connections selected 
block configured differently 
adding support run length encoding array require extra wires multiplexors distribute configuration bits simply stored redundantly needed 
avoid cost compressed configuration decompressed read array 
bottleneck loading configurations memory system wires array run length compression may little value 
configuration sizes running kilobytes minimum sense load configurations level cache probably smaller typical configuration 
configuration loading bypass data instruction caches 
synchronous dram second level cache bypassed bandwidth latency critical factor loading kilobytes time 
memory systems set support bypassing cache 
configurations kept kilobytes reason concerned polluting cache probably half megabyte 
typical mhz general purpose computer easily sustain gb band width cache 
comparison commercial fpgas load configurations little bit wide shift chain optimistically mhz load mb newer fpgas wider configuration paths xilinx xcv stance loads configuration bits time 
really prevents custom reconfigurable unit having configuration interface equal width cache data bus order match available memory bandwidth 
cache buses commonly bits wide 
fpgas exist invalid parasitic configurations destroy device 
configurable network logic blocks wires physically connected tri state driver output valid configuration select just driver wire time 
tri state driver controlled configuration bit easy multiple drivers selected accidentally wire causing fpga burn 
parasitic configurations tolerated general purpose computer application load configuration random bits 
fpgas xilinx encoded configurations way guarantees possible configuration parasitic 
sounds attractive hardware cost 
replaced simple network bus wires safer expensive multiplexors resulting increase fpga size 
alternative solution verify configuration validity loaded 
processor simply refuse load configuration fails pass test 
approach require die space multiplexor solution smaller amount checking hardware repeatedly time multiplexed piece configuration streamed reconfigurable array 
technique promoted section addition loading configurations fpgas allow array con figuration modified editing operations 
xilinx example individual logic block configurations updated need load complete configuration entire fpga 
problem configuration editing dangerous parasitic configurations possible 
way revalidate edited configuration streaming past checking hardware editing considered incompatible technique validating configurations loading 
time array configuration needs written back memory context switch 
current configuration edited copy memory originally loaded intact write skipped configuration simply reloaded original process resumes 
array configurations needed written memory context switches avoid write little faster 
ensure configurations need written architecture needs forgo support configuration editing require configurations modified memory loaded array 
clear valuable configuration editing practice 
assuming configurations inner loops program circumstances editing appropriate configurations independent loops share common structure second loaded merely editing 
inner loop nested inside loop inner configuration called 
configuration benefit small edits value variable changes outer loop 
second compelling 
weighed hardware expense ensuring parasitic configurations time expense writing configurations memory context switches support configuration editing 
caching configurations save loading time multiple configurations regularly reused array include cache loaded configurations 
cache especially valuable expected programming model configuration loaded just needed 
program requests load configuration cache load able activate cached configuration clock cycles 
caches configuration cache dynamically managed hard ware part simplify programming cache size vary imple mentation programs having explicitly adjusted correspond 
dynamically managed cache efficient multitasking processes working set configurations fills half cache size 
cache statically managed program difficult share 
reasonable place store cache distribute array logic blocks 
assuming reconfigurable array roughly square size area perimeter grows configuration cache kept outside perimeter available bandwidth array block proportional decreasing array grows 
fpgas wires periphery load configuration way clock cycles 
simply internal bandwidth fpga move bits far quickly 
configuration cache distributed reconfigurable array divided equal planes number planes number full configurations cache hold 
useful configurations need entire array achieve better cache utilization possible keep multiple full size configurations plane 
pointless store configuration particular location cache plane configuration executed location array problem quickly moving configuration large distance array 
consequently array able load execute small configurations configurations cached cache plane additional cache planes configuration cache multiple cache planes 
plane store full size configuration multiple smaller configurations 
various different positions greater number configurations kept cache 
exact positions smaller configurations loaded array depend array design 
perfect array configuration arbitrarily shifted position 
reality wire network logic blocks look respect logic block 
fpgas example divide logic blocks groups richer interconnect available group groups 
array configuration shifted multiples blocks best logic block interconnections thoroughly rerouted 
cache managed automatically hardware position small configuration gets placed array ought invisible program loads 
logic block configuration appear logic block program regardless configuration placed 
hardware translate logical block addresses physical block addresses just translates logical physical memory addresses virtual memory 
save little die area cached configurations stored dynamic memory 
certainly cache access time order clock cycles acceptable configurations really execute substantially longer average 
assuming cache planes dynamic memory circuitry need complex 
course dynamic memory cache require regular refreshing configuration running 
parasitic configurations possibility important remember dynamic storage cells susceptible 
redundancy necessary guard catastrophes 
probability errors small sufficient abort current process event error detected goal solely protect hardware disaster 
array clocking commercial fpgas allow configuration different clock frequency multiple clocks different frequencies 
development task tools human designer ensure signal path exceeds maximum allowed delay 
clock frequency simply set highest value works particular configuration 
practice relationships different fpga components delay times varies fpga implementation making hard predict advance speeds versions fpga family execute configuration 
problem upward compatibility software general purpose computer configurations originally created version processor known clock speed newer version processor having new part 
allowing reconfigurable unit flexible clock speed necessitate complex synchronizers reconfigurable array rest system introducing additional latency risk 
specify component delays precise times change processor generation delays defined terms sequences fit fixed array clock cycle determined implementation 
rules set architecture implementations responsible ensuring configurations follow rules run properly 
example architecture specify signal propagate certain distance logic blocks array clock cycle 
implementation responsible setting array clock speed slow guarantee rule 
array clock need identical processor clock actual implementation surely simple ratio 
disadvantage fixed clock potential loss efficiency due forced time 
path registers specific configuration happens short propagate full clock period configuration run faster faster clock 
hand type loss suffered main processor 
processor pipeline assign integer number clock cycles execution functional unit functional unit actual delay cycles 
program performs bitwise logical operations example accumulate large proportion unproductive time fact logical operation require full clock period allocated 
efficiency usually worth sacrificing simplify architecture permit range implementations varying performance cost 
aside simplifying architecture fixed clock enables implementa tion techniques impractical 
circuits example known fixed clock period array hardware implement carry chain faster carry propagation circuits 
techniques compensate inefficiency caused clock 
superscalar processor executes instructions variable unspecified rate architecture reconfigurable array include precise conception time measured array clock cycles 
perform certain computation configuration execute specific number clock cycles perform exact computation desired 
interesting number clock cycles needed known advance particular number iterations loop data dependent 
handle cases array needs way signal computation complete array execution halted 
processor waiting interlocked array completion indicate processing continue main processor pipeline 
freezing array inactive accomplished hardware gating array clock forcing array registers hold values indefinitely 
disabling array inactive may necessary times stall array execution cycles active 
configuration cache uses dynamic storage example cache refreshes may require regular suspension array execution 
section discusses stalling array hide latency memory accesses array 
cases array execution delayed due irregular hidden events 
add complexity configuration handle occurences array stalled transparently hardware briefly gating clock necessary number cycles 
array clock cycles way logical execution increments necessarily connected real time 
external interface access memory main reason bringing reconfigurable unit closer processor bring closer processor data especially means memory system data stored 
reconfigurable array main pipeline sense existing processor load store instructions transfer data memory main register file values forwarded reconfigurable unit functional unit 
section argued putting array pipeline depending main register file storage limit speedups obtainable array 
array attached coprocessor interface continue main processor perform memory accesses copying array access 
practical sequence memory accesses easily predictable 
cases necessary communicate information array main processor access resulting steps memory load copy address information array main register file load memory register copy loaded value array 
scheme memory bandwidth available array half main processor double latency 
reconfigurable unit going compute faster main proces sor need bandwidth memory 
connection memory needed loading configurations quickly 
assuming array contains paths copying contents array registers back forth main processor essentially remains allow paths diverted bus configurations loaded memory 
main complication supplying address necessary control signals memory hierarchy 
inside array physical wires needed distinct purposes 
interconnecting logic blocks 
bringing configurations memory 
transfering data main processor 
transfering data memory system 
master processor memory system array memory interface bus array loading configurations moving data memory main processor register file 
array design contain distinct wires purposes 
commercial fpgas typically support cases separate sets physical wires 
interconnect logic blocks configured loading configuration memory probably sense rely legitimate claim keeping cases distinct 
hand comes communicating processor memory networks job moving values registers array 
array includes configuration cache argued earlier configurations full size need loadable multiple different locations array order better cache 
configuration bus run entire array configurations loaded quickly array location 
bus naturally connected full bandwidth memory system 
logical bus support memory accesses array array executing 
sharing connection memory arrangement preclude possibility preloading configuration current running 
memory bandwidth limited resource executing configuration saturate available bandwidth left preloading anyway sharing bus memory really bottleneck 
convenient give main processor random access register state array values transfered processor register file bus array active 
told proposed bus main external connection array direct random access logic block 
configurable wire network logic blocks remain separate entity 
configuration requests load value memory expect cycles latency value returned 
point forcing array sit idle time configuration continue executing need know array clock cycle memory value returned 
preferably memory latency known time configuration created extra control circuitry included synchronizing configuration calculations variable memory latency 
truth memory latency vary implementation fact vary depending requested value memory caches 
memory loads complete order systems 
complications avoided simple compromise configuration specify exact latency expects memory loads array interface memory responsible ensuring expectations met 
memory load requires time configuration indicates example cache array clock automatically stalled memory system catch 
conversely memory returns data quickly expected memory interface hold intervening cycles 
technique array initiate new memory access array clock cycle results returned predictable pipelined fashion respect array execution 
multitasking support multitasking possible freeze swap execution reconfigurable unit context switch 
step context switch processor interrupt trap 
proceed normal special case time interrupt occurs processor interlocked awaiting completion execution reconfigurable array 
assuming array outside main processor pipeline proposed section interlocking instruction attempt read result array 
case interlock simply ignored interrupt taken point instruction stream just interlocking instruction 
process resumes instruction read array re executed interlock 
interrupt trap taken operating system context switch software suspend save current array state restore resume process swapped 
new instruction needed permit processor force halt array execution employ essentially mechanism array uses halt done 
configurations edited array section need write current configuration 
memory address current configuration originally loaded address copy presumably memory saved reason hardware keep record memory address current configuration loaded 
array access memory directly operate pipeline memory loads proposed previous section halting array leaves progress loads suspended limbo 
memory operations continue completion perspective memory system values loaded memory accepted array saved restored 
require additional support architecture involving numerous special registers accessible ordinary user mode programs 
lastly main processor random access array data registers array data state saved restored ordinary processor instructions 
complete sequence swapping array execution memory 
force halt array execution 

save state memory loads pipeline special architectural support provided step 

array register read register value main register file store memory 

save memory address current configuration 
restoring previously saved context reverse process 
interesting twist concerns signal propagation array register state restored 
explicitly propagation path registers arbitrarily long configuration legitimate long configuration holds values source registers constant full time takes signals propagate destination registers 
context swapped array halted moment just long propagating signal ready latched destination register 
case context swapped back array execution ready proceed signal propagation chance path destination register 
operating system ensure occurs array execution resumed 
try ascertain exact time needed configuration easier simply put time limit propagation registers valid configuration 
reasonable limit short array clock cycles certainly burden wait context switch 
short time easily overlapped context switch activities restoring main register file 
complete sequence swapping array execution back 
load configuration memory possibly configuration cache 

restore array registers reading memory copying array 

restore state outstanding memory loads special architectural support provided step 

allow signals time propagate array 
architecture programming conventions place limit long required 

resume array execution 
servicing page misses case troublesome context switches page misses 
typical risc instructions array initiated memory access causes page array execution backed access relevant memory page brought disk operating system 
failed memory accesses completed participation hardware 
assume failed access store causing trap initiates context switch 
array execution moved backward array store resumes operating system complete store missing page brought disk 
operating system needs failed address data written accessible additional special registers existing interface array memory 
array memory interface simply remember information automatically access process resumed multiple processes running number page misses process serviced time 
page occurs load access operating system complete load data loaded inserted pipeline outstanding loads array memory interface 
suggested previous section state visible operating system context switches hardware needed support completion failed loads 
distinction needs memory request fails virtual memory page fails invalid address 
support deep pipelining operations stream data important able load data advance operating 
processing completed input stream additional speculative loads past input stream performed invalid addresses 
prevent programs terminated speculative loads invalid addresses possible simply ignore invalid virtual address exceptions return arbi data 
ignoring exceptions debugging difficult cause correct program fail 
contrast speculative loads virtual addresses valid currently resident definitely cause trap operating system service page fault 
designing reconfigurable hardware computation fpga design adapted reconfigurable unit 
commercial fpgas generally intended processor functional units may best suited purpose 
section considers reconfigurable hardware better tailored accelerating software loops 
dominance wires issue major bearing array design extent fpgas normally dominated configurable networks terms circuit area delay 
rose asserted area routing usually larger active area 
representing total area 
significance network increases fpgas grow 
years rose delay circuit implemented fpga due routing delays logic block delays fpga area devoted programmable routing 
situation favors inclusion special case circuitry reduce number logic blocks needed common tasks provide faster short cut connections logic block expense making logic blocks somewhat larger slower 
prototypical special case circuitry carry chain support commercial fpgas 
obvious special paths bypass slow general network secondary effects beneficial direct connections neighbors logic blocks require fewer physical connec tions network allows general network efficient 
fewer network taps mean loading wires example 
general network fewer signals carry allowing smaller efficient 
fewer wires needed network taps smaller faster fewer wires choose 
benefits compound special logic block circuitry reduces number blocks needed perform common operation fewer logic blocks paths circuit inputs outputs fewer network traversals needed reducing total function delay 
fitting configured circuits smaller area reconfigurable hardware network traversal blocks may distance travel may individually faster 
conversely denser packing configurations functionality config die area 
better comes logic block complexity 
special purpose circuitry get presumably functionality rarely needed eats space acts drag performance 
special features added logic block chosen judiciously 
reconfigurable hardware intended computation standard arithmetic operations place start 
bit serial bit parallel bit pipelined arithmetic basic arithmetic operations performed various ways corresponding different engineering tradeoffs 
major distinction different techniques way numeric values represented delivered operator 
restrict usual binary representation primary categories bit serial bit parallel bit pipelined 
style lead different optimization structures reconfigurable array worth attempting assess relative advantages 
lines discussion see 
bit serial corresponds way addition taught grade school significant digits added pair digits added carry previous place digit positions processed turn 
implemented hardware bit serial adder little bit adder carry looped back 
operands fed adder single wire bit binary digit clock cycle starting significant bit 
sum generated rate 
bit operands obviously takes clock cycles form complete sum 
hand adder output input adder second addition need wait full cycles complete soon significant sum bit addition computed 
overlapping operations way back back additions completed clock cycles cycle single addition 
overlap effect extends number additions applies subtractions comparisons hardware multiplications 
reason bit serial arithmetic obtain minimal area implementation functions carry chain bit serial addition 
bit pipelined addition 
bit parallel addition 
boxes labeled calculate propagate generate signals carry chain 
digital fir filters require addition subtraction multiplication 
maximum overlap bit serial arithmetic output bit final result clock cycles 
bit pipelined adder similar concept bit serial adder making lone bit adder add bit turn individual bit adders arranged assembly line form full bit adder 
addition operation occurs bit position handled dedicated bit adder 
soon rightmost bit adder summed significant bits free start addition 
consequently additions progress time giving rate bit addition clock cycle 
aside factor increase hardware throughput bit pipelined arithmetic shares characteristics bit serial arithmetic 
standard processors perform full bit addition single processor clock cycle 
intermediate carry registers removed clock times slower result ripple adder complete single longer clock cycle 
adder called bit parallel bits input output value latched single clock edge 
ripple adders best modern bit parallel adders employ sophisticated technique illustrated 
critical part bit parallel adder carry propagation factored separate highly optimized entity 
bit position carry known immediately operand bits position carry carry position right 
bit position calculates propagate generate signals determine carry follows propagate generate carry carry job carry chain unit propagate carry values quickly possible positions propagate 
bit addition done faster ripple adder albeit considerably hardware 
bit parallel adder operates total latency addition potential throughput terms additions unit time bit pipelined adder 
bit adders bit serial bit pipelined addition simple easily implemented lookup tables typical fpgas 
main issue number logic blocks needed bit adder 
logic block exactly lookup table output wire network take logic blocks bit adder calculate bit sum determine carry bit position 
squeezing single logic block requires block able output independent bit values 
obvious way providing block drivers general wire network 
addition occurs reasons explained section usually efficient build dedicated carry connection neighboring blocks row column array 
shows possible forms carry connection take 
commercial fpgas include support bit parallel adders necessarily better ripple adders 
typically hardware calculating propagating carry logic block specified fpga architecture physical fpga implement alternate ways 
note xilinx carry chain example 
leaves open possibility sophisticated carry chain unit employed existing fpga chips 
done existence bit parallel carry units fpgas outside realm possibility 
carry input table lookup input table lookup carry carry carry logic input table lookup simple extension basic input lookup table logic block implement dedicated carry connection neighboring blocks 
configured bit adder table calculates sum bit carry 
form lookup table input tables multiplexed fourth logic block input 
support bit adders xilinx series logic blocks 
main lookup table determines sum bit dedicated circuitry generates carry appropriate addition subtraction 
arrangement allows faster ripple adder construction left 
seen bit adders fit xilinx logic block 
skew conversion bit parallel serial pipelined form back 
skew conversion required initial inputs final outputs computation 
carry select select select select select comparison followed multiplexor implementing expression skew conversions needed result totalling roughly bit registers bit width select appropriate assistance forms bit serial bit pipelined bit parallel common statistic logic blocks perform average bit addition clock cycle 
clock speed bit serial bit pipelined signifi cantly faster bit parallel causing bit parallel lag metric 
bit pipelined optimal circumstances due effects interaction rest system ordinarily done bit parallel form necessitating skew conversions function inputs outputs 
memory access example bits address delivered simultaneously data read written way 
true values transfered main processor 
circuit lot interaction require constant skewing inputs outputs throughput advantage bit pipelined bit parallel 
feedback high order bits low order bits introduces delay equal clock cycles bit width 
shows effect simple expression case entire comparison complete bit selection proceed 
similar thing occurs shift operations depending shift distance 
skew conversion numerous bit registers needed 
shows data values bits wide bits registers needed 
data bits wide total bits registers needed equivalent bit registers 
operations part feedback loop latency entire loop considerably reduced making bit parallel techniques faster 
tables attempt analyze differences detail 
table presents rough formulas area latency throughput styles simple addition comparison multiplexor example 
bit latency time subsequent operation start result previous operation turnaround refers time hardware operating set values coming pipeline 
clock frequency differences accounted formulas 
area cost skew conversion tabulated bit serial bit parallel styles 
table simplifies formulas conditions assumptions operation bit width 
data values may smaller size application manipulates pointers addresses need operate bit bit quantities 
wire network consumes thirds area reconfigurable array 
traversing network nearby logic blocks takes time performing simple lookup table operation 
traversing network distance logic blocks takes times long nearby blocks 
area needed block implement decent bit parallel carry propagation unit double rest lookup table logic block 
carry unit bit bit parallel addition takes times long execute simple table lookup 
assumptions table easier judge relative merits form 
differences bit pipelined bit parallel arithmetic worth noting bit serial area bit latency turnaround addition comparison mux skew conversion bit pipelined area bit latency turnaround addition comparison mux nw nl nr nw nl skew conversion bit parallel area bit latency turnaround addition nw nl nr comparison mux nw nl data size bits area wire network corresponding single logic block area simple logic block function configurable bit adder multiplexor area logic block including carry chain supporting bit parallel addition area externally accessible clocked register time traverse network close logic blocks time traverse network logic blocks bits apart time perform table lookup logic block function time perform bit parallel addition table approximate formulas area latency turnaround different arithmetic styles 
operands assumed available time 
bit serial area bit latency turnaround addition comparison mux skew conversion bit pipelined area bit latency turnaround addition comparison mux skew conversion bit parallel area bit latency turnaround addition comparison mux table table additional assumptions 
number retiming registers logic block bit serial addition comparison mux skew conversion bit pipelined addition comparison mux skew conversion bit parallel addition comparison mux table relative total area assumptions previous table supposing configurable retiming register takes area rest logic block 
integral number logic blocks case size logic blocks varying depending number retiming registers contain 
bit parallel addition latency throughput slower turnaround bit pipelined difference masked time takes traverse wire network logic blocks 
bit parallel forms suffer variability latency common operations 
bit pipelined addition twice fast bit parallel bit pipelined comparison order magnitude slower bit parallel coun 
stated large number register bits needed bit parallel skew conversion situations high order bits effect outcome low order bits 
get better handle area costs scheme table gives relative total areas operations assumption adding bit retiming register logic block adds die area array 
logic block area number logic blocks needed operation vary number retiming registers included logic block 
retiming registers added logic block area increases number logic blocks needed may decrease 
furthermore registers logic block risk registers go unused increases 
complex relationship plays differently different operations shown table 
bit pipelined arithmetic optimal number registers seen highly sensitive proportion additions multiplexors skew conversions application choice varied committed physical hardware 
bit parallel approach appears robust despite efficient addition 
accumulated assumptions numerous second third order effects accounted wrong put stock exact figures tables 
hope simply sense numbers steer design decisions productive direction 
issue reflected tables instance greater power cost distributing faster clock array 
bit pipelined bit serial techniques require faster clock chance beating bit parallel clock distribution power factor tip balance bit parallel forms 
mixture parallel pipelined serial techniques 
bit parallel adders bits wide arranged pipeline bit adder applied serially add values multiples bits size bits bits 
preceding analysis compared pure bit serial bit pipelined bit parallel techniques allowing 
fact prevents tech niques concert 
illustrates instance adder employing styles bit parallel adders linked stage pipeline bit adder applied serially multiple bits 
choices preceding tables merely extremes best balance occur 
array provide hardware bit parallel adders example fall back pipelined serial styles composing larger sizes 
finding optimum balance require refined cost model better understanding applications possible priori 
commercial fpgas current trend clearly better bit parallel support 
array granularity array granularity core design issue 
granularity reconfigurable device default data unit size similar concept natural word width proces sor 
array granularity determined primarily number bits wire network requires routed group logic block 
commercial fpgas route individual bits independently granularity bit 
contrast research designs matrix operate units bits 
best choice depends mix sizes data control values applications 
note compared fine grained wire network network granularity roughly number config bits data bit routed 
array granularity studied fpgas general lewis piperench particular goldstein :10.1.1.21.5165
larger grain routing generally associated larger grain data operations 
arrays single bit granularity fpgas logic blocks typically support generic set bit wide functions inputs outputs implemented lookup tables 
larger granularity hand logic blocks limited usual arithmetic operations addition multiplication general table lookups 
granularity characteristic tends entire array wire network logic blocks 
granularity confused support bit parallel operations dis cussed previous section 
array bit granularity include hardware constructing fast bit parallel adders 
carry chain structures simply stretch multiple logic blocks commercial fpgas 
contrast array bit granularity construct adder smaller bits minimum data operand size 
main tradeoffs large fine grain bit parallel operations wide data widths fine grained array suffer wasted redundancy configuration representation 
implement wide bit parallel operator linear array logic blocks usually configured identically nearly identically bit data width flexibility fine grained array 
large grained array able configure wide operator standard arithmetic operations fewer configuration bits 
denser configurations require time load array area store array loaded 
hand control logic bit serial operations large granularity suffers internal fragmentation allocation resources array 
operands operations single bits array bit granularity wastes factor wires computation hardware bit granularity array 
terms area stronger effect wasting configuration bits previous point wires computation functions consume hardware area configuration storage 
applications roughly divided data control sections datapath comprising bit wider operations control involving single bit random logic 
rule construct simple model relative proportion area configuration storage logic block granularity ratio control bit ops total bit ops table granularity area bit op simple model 
die area affected parameters array granularity ratio control bit ops total bit ops proportion area configuration storage consume equivalent array granularity 
ak area logic block granularity array define area logic block corresponding array granularity 
assume granularity granularity arrays number configuration bits logic block estimate ak ca 
granularity area application bit op ak ak ak 
supposing constant independent formula estimate relative die area consumed different settings parameters 
particular formula evaluated different granularities find granularity area bit op 
table summarizes results exercise range granularity restricted powers 
table shows example ratio control bit ops data bit ops optimal granularity surely depending proportion area consumed configuration bits 
analysis far assumed reconfigurable array homogenous single granularity 
known control accounted application bit ops rest wider multi bit data operations smarter build array single bit granularity control rest coarser granularity datapath 
type split advocated lewis wittig chow noted earlier adopted rapid reconfigurable array 
multiplication elements usual arithmetic operations multiplication right addition subtraction importance 
applications multiplication occurs frequently addition 
unfortunately far costly implement addition general bit bit multiplication essentially equivalent summing bit terms 
impact array design consider multiplication 
simplest solution just build multipliers existing reconfigurable hardware giving hardware additional capabilities task 
core multiplier ability sum terms 
dedicated hardware multipliers typically tree carry sum adders known adders input terms output numbers having sum inputs 
carry save adders small fast replicated eventually reduce number input terms 
terms added conventional adder obtain final product 
shows carry save adder tree summing terms constructed reconfigurable array 
structure apparent terms 
stage set logic blocks calculates carry result xor sum result 
number blocks cut half shown single logic block perform logic operations drive outputs network 
potential cost allowing dual outputs limited sure impact network delays negatively section 
assumption dedicated fast carry chains supported reconfigurable hardware set terms summed simple binary tree adders 
naturally adder slower carry save adders structures height full adder tree carry save tree number terms mitigate slowness full adders 
free standing hardware multiplier implemented way reason laying fast carry chains 
reconfigurable carry xor carry xor carry xor carry xor carry xor carry xor various structures 
carry save tree carry xor operations done separate logic blocks 
carry save tree logic blocks drive outputs configurable network 
tree adders making special carry chain circuitry reconfigurable array 
tree input adders 
implement input adders logic blocks need perform internal carry save addition advance hardwired carry chain 
box shown collection logic blocks sufficient perform operation operand bits 
number approx 
operators tree height relative latency number terms table summation tree form number bit operators tree height approximate relative latency numbers terms ranging 
section latency bit parallel addition taken twice basic lookup table operation wire traversal taken account 
correspondingly times simple table lookup 
input addition assumed latency hardware carry chains presumably anyway 
employing wider adders summation tree height reduced illustrated 
input adder easily invented giving logic blocks ability perform carry save addition internally advance full addition 
significantly extension reconfigurable hardware drastic increasing number outputs logic blocks configurable network 
table shows reasonable assumptions recall section latency summation forms surprisingly 
hand drastic difference number logic blocks consumed appears favor overwhelmingly structure input adders 
form turns quite fast table suggests decreasing disproportionate size multipliers positive impact explained back section 
review main chapter summarized follows achieve best performance reconfigurable unit needs contain data state designed execute clock cycles time 
reconfigurable unit integrated directly pipeline main processor attached chip coprocessor 
simplify interlocking processor instructions initiating operation reconfigurable unit separate attempt retrieve results 
system avoid relying configuration preloading hide loading times separate compilation defeats may unused bandwidth memory reconfigurable unit executing 
path memory wide possible configurations encoded densely practical system cache configurations reuse 
allowing configurations edited loaded reconfigurable array context switches omit having copy current configuration back memory save 
prohibition editing solves problem careless edits creating parasitic configurations having driver single wire 
turn permits integrity configuration verified just loaded external memory minimal checking hardware 
configuration cache supported distributed array minimize time needed load configuration cache 
configuration cache management ought done hardware processor caches 
maximize cache utilization possible place small configurations multiple alternative locations array execute correctly locations 
location configuration placed invisible software 
clock array fixed implementation clock cycle corresponding logical execution step reconfigurable hardware 
architecture specify computational distance traversed clock cycle allowing configurations created run unchanged range implementations 
array execution stalled cache array clock automatically delayed affecting sequence logical steps executed configuration 
ensure reconfigurable unit sufficient memory bandwidth execution connection memory dependent main processor 
memory accesses performed wires bring con array memory 
loads memory reconfigurable hardware sit idle cycles load 
support multitasking context switch able freeze swap current configuration restore time 
memory reads pipeline time context switch saved restored visible data state 
limit placed maximum signal propagation distance configuration configurations safely resumed having swapped 
page misses occur due memory accesses reconfigurable unit completed operating system reconfigurable hardware backed retry access 
pipelining easier configurations loads invalid addresses ignored returning arbitrary data 
standard reconfigurable hardware dominated mainly configurable network logic blocks logic blocks 
reconfigurable unit efficient general logic blocks expanded additional functionality succeeds reducing number blocks needed configurations 
bit serial bit pipelined arithmetic efficient bit parallel basic additions subtractions multiplications mixes operations bit parallel superior 
bit parallel style variance require profusion registers needed skew converting bit serial bit pipelined arithmetic 
support bit parallel arithmetic reconfigurable array include fast carry chains hardware 
reconfigurable hardware constant granularity granularity bits efficient terms chip area 
reconfigurable array contains carry chain hardware multipliers configured fairly efficiently simple trees basic adders 
extending logic blocks include dedicated carry sum adder carry chain input adders created denser multiplier structures built 
reconfigurable functional unit processor presumably want take account concerns 
chapter proposed garp design architecture proposed called garp attempts address issues previous chapter 
garp designed fit ordinary processing environment includes structured programs software libraries context switches virtual memory multiple users 
garp architecture brief comparison related designs study suitability garp reconfigurable hardware implementation vlsi 
garp architecture garp extends mips ii compatible processor reconfigurable hardware de signed specifically accelerating kernels application software 
view garp provided 
garp reconfigurable array just called array short 
garp main processor complete control loading execution configurations reconfigurable array 
instructions added mips ii instruction set purpose including ones allow processor move data array processor registers 
garp reconfigurable array read write main processor registers array contain data registers 
garp external storage accessible reconfigurable array giving array access standard memory hierarchy main processor 
provides immediate memory consistency array processor 
furthermore garp instruction cache main processor mips ii external cache dram data cache reconfigurable array external bus internal data bus crossbar array memory buses organization garp 
boxes labeled memory queues supporting streams memory discussed section 
defined support strict binary compatibility implementations recon hardware 
overview array architecture integration processor memory sections 
complete details garp architecture appendix array organization garp reconfigurable hardware dimensional array entities called blocks 
block row known control block 
rest blocks array logic blocks correspond roughly logic blocks commercial fpga 
garp architecture fixes number columns blocks 
number rows implementation specific expected 
architecture defined number rows grow upward compatible fashion 
granularity array set bits 
logic blocks operate values bit units wires arranged pairs transmit bit quantities 
operations bit values generally require logic blocks 
multi bit functions naturally laid array rows 
logic blocks row space row operation bits plus logic blocks left right overflow checking control block row logic blocks row extra logic logic blocks bits blocks msb aligned processor data word lsb memory buses extra logic blocks garp array organization 
addition memory buses configurable network interconnects array blocks 
bit adder bit comparator bit logical operation bitwise bit word alignment memory bus typical natural layouts multi bit functions 
rounding control functions wider data sizes needed 
relatively fine granularity preferred garp array small granularity roughly emulate larger granularity desired reverse true 
fine granularity safer choice research design 
reconfigurable hardware bit granularity provides contrast capabilities bit proces sor 
granularity bit hand seen unnecessarily extreme analysis section 
doubling bits size configurations time required load configurations space taken die store nearly cut half cost loss flexibility 
proposed section memory buses run vertically rows moving information array 
array idle processor memory buses load configurations transfer data processor registers array registers 
array executing master memory buses uses access memory 
memory transfers restricted central portion memory bus corresponding middle logic blocks row 
loading configurations saving restoring array data entire width memory buses 
configurable network provides interconnection array blocks 
wires various lengths run orthogonally vertically horizontally 
vertical wires communicate blocks column horizontal wires connect blocks adjacent rows 
fpga designs connections wire logic block 
logic block includes resources potentially making wire wire connection independent obligations 
individual configuration covers number complete rows array may total number physical rows array 
distributed array cache configurations programs quickly switch configurations cost reloading memory time 
traditional memory caches size management configuration cache transparent programs 
data registers array latched synchronously array clock frequency fixed implementation 
relationship array clock main processor clock required intended clocks 
clock counter governs array execution 
clock counter nonzero shifts carry logical arithmetic function shifts carry simplified logic block schematic 
compare figures available functions seen subsequent figures 
decremented array clock cycle 
clock counter zero updates state array stalled effectively stopping array 
copies array main processor may modify array state 
main processor sets array clock counter nonzero array execute specific number array clock steps 
array zero clock counter computation completed counter reaches zero exceptional condition example 
large value array clock counter acts infinity returned zero explicitly array processor 
cases number clock steps needed complete computation entirely data dependent processor set counter infinity array zero done 
control blocks row serve array outside world 
things control blocks interrupt main processor zero clock counter initiate data memory accesses array 
array logic blocks logic block array implement function bit inputs 
operations data wider bits accomplished adjoining logic blocks row 
construction multi bit adders major functions aided hardware invoked different logic block modes 
crossbar crossbar dual input table lookup crossbar crossbar simple table lookup function logic block 
provides basic diagram logic block 
bit inputs taken adjacent wires derive outputs 
output calculated direct copy input 
output value optionally buffered register bit outputs driven wires logic blocks 
logic block registers read written memory buses 
input needed logic block function case path copy value wire 
primary modes logic block function table mode implements input bitwise logical function table lookups fig ure 
single bit lookup table independently applied high low bits generate high low bits result function deter mined bit lookup table 
effect perform arbitrary logical function bitwise bit inputs 
advice section triple add mode performs input addition 
values reduced carry save adder values summed dedicated carry chain 
support fast bit wide additions row includes fast carry chain box spread logic blocks row depicted 
full sized addition inputs performed array clock cycle 
triple add mode flexible permit shift shift shift shift carry carry optional shift invert carry dual input table lookup optional shift invert carry save addition propagate generate sum result function optional shift invert carry chain dual input table lookup logic block triple add function 
generate generate propagate propagate generate generate propagate propagate carry chain carry chain row 
shift shift shift shift carry carry shift shift shift optional shift invert hout optional shift invert select optional shift invert shift shift shift logic block select function 
mode needs inputs extra hout input comes directly logic block column row 
negation inputs arbitrary sum difference inputs calculated 
supported modes special select mode implements way multiplexor 
mode needs extra fifth input takes directly logic block column row 
function modes include permutation boxes shift inputs 
table mode perform arbitrary permutation bits input shift invert boxes modes shift input left bit row optionally complement logically 
permutation boxes essential opportunity low high bits bit values cross paths 
interestingly lewis adopted similar feature bit granularity array 
theme function modes listed cousin variation split table mode similar table mode uses separate input lookup tables determine high low bits result 
input ignored 
wire channels logic block wire channels input output logic block 
logic blocks read horizontal wires read output horizontal wires 
exactly vertical channel associated column logic blocks 
carry chain mode dispenses carry save addition triple add mode 
inputs participate table lookups determine propagate generate controls carry chain 
partial select mode variant select mode useful selecting partial products multiplications 
array wires vertical horizontal wires exist array moving data logic blocks 
array bit granularity array wires grouped pairs carry bit quantities 
pair wires driven single logic block read simultaneously logic blocks spanned wires 
wire network passive value jump wire passing logic block 
shows wire channels input output logic block 
illustrates pattern vertical wires wires single column rows 
configuring vertical wires concert multi bit values easily moved array rows 
wire pair driven logic blocks spans read logic blocks spanned 
vertical wires associated single column blocks horizontal wires exist rows accessible logic blocks rows pattern vertical wires wires single column rows 
line drawn represents pair wires bits 
horizontal wires wires wires rows 
line represents pair wires bits 
wires seen 
full set pairs spanning blocks wires pairs wires spanning entire width array wires 
horizontal wires read blocks wires driven row 
horizontal wires communicate columns single row logic block row different column row immediately 
horizontal vertical wires different patterns opti mized different purposes 
shorter horizontal wires tailored multi bit shifts row vertical wires oriented connecting functional units laid horizontally 
long horizontal wires typically broadcast control signals logic blocks implementing single multi bit operation 
driver wire fixed configuration changed loading new configuration 
discussed section configurations checked hardware loaded ensure wire driver 
configurations failing test loaded 
array timing delays garp array defined terms sequences fit array clock cycle 
sequences permitted short wire simple function short wire simple function long wire function carry chain short wire function 
sequence assumed require multiple clock cycles 
short wires include shorter horizontal wires plus vertical wires certain length 
simple function direct table lookup traversal independent path logic block 
cycle computed value may latched logic block register affecting timing 
time simple set rules easy determine number clock cycles computation need 
implementor perspective rules delineate required implementation order run valid configurations correctly facilitating development family implementations executing bit identical configurations 
support computational primitives garp array designed expressly computation table lists areas speeds various computational primitives configured array 
area counted array rows speed latency turnaround time array clock cycles 
note multiplies divides small constants especially dense configured hard wired shifts adds horizontal wires rows triple add mode 
operations table data bits size convenient data size full row 
operations easily reduced smaller sizes course full width array rows 
design garp array permits simpler operations done need extra logic blocks left right data width 
means example bit comparison fit neatly logic blocks row bit positions logic block array having bit granularity recall 
fact significant bit words read written memory exactly middle columns array section 
bits contain bit characters operation rows cycles cycles bit sum bit comparison signed unsigned bit fixed shift bits logical arithmetic bit fixed shift distance logical arithmetic bit variable shift left right logical arithmetic multiply bits bit constant bits multiply bits bit constant bits multiply bits bit constant bits multiply unsigned bits bits bits multiply unsigned bits bits bits integer divide unsigned bits bit constant integer divide signed bits bit constant arbitrary table lookup function bit index bits arbitrary table lookup function bit index bits arbitrary table lookup function bit index bits bit input multiplexor conditional operator table examples primitive operations implemented garp reconfigurable array 
latency time inputs supplied result ready turnaround measures soon implementation accept set inputs pipelined operation 
plus sign rows column indicates implementation depends row immediately drive wires operands operation 
row immediately implementation needs additional row purpose may take additional cycle marked latency column 
horizontal split partial triple carry wires table select select add chain operation type mode mode mode mode mode additions subtractions equality comparisons ordered comparisons fixed shifts variable shifts constant multiplications general multiplications constant divisions unsigned table lookup functions multiplexors table array features employed various operations 
grid point indicates operation type significant listed mode wire class 
parallel bit operations done directly set columns individual characters having shifted apart slightly room extra logic blocks 
table tells different logic block functions different types horizontal wires various operations 
garp function modes total ordinary table mode implements bitwise logical operations listed 
part control logic tends table mode split table mode exclusively 
processor control array execution main processor number instructions controlling array 
important listed table 
include instructions loading configurations copying data array processor registers manipulating array clock counter saving restoring array state context switches 
loading configuration initializes data registers array zero default 
mentioned earlier array clock counter controls array execution 
counter nonzero array executing zero array halted 
avoid restricting main processor implementation garp architecture specify main processor instructions execute array clock cycle 
keep processor array synchronized new processor instructions table wait clock counter reach zero performing function 
simplest example main processor needs read result computation performed array 
setting array clock counter proper value processor execute instruction time 
long array done wait clock counter zero attempting copy result processor 
instructions copy middle logic blocks row recall additional instructions listed give processor access data logic blocks edges array 
instructions exist primarily support context switches 
configurations block garp array requires configuration bits bytes specify sources inputs function block wires driven outputs 
instruction interlock description reg load switch configuration address reg zero array registers 
reg array row reg count copy reg value array row reg set array clock counter count 
reg array row reg count copy array row reg value reg set array clock counter count 
reg increase array clock counter value reg 
reg copy array clock counter reg array zeroing clock counter 
reg invalidate cache copy configuration address reg 
reg array control reg copy value array control reg reg 
reg save internal array state memory address reg 
reg restore previously saved internal state memory address reg 
table basic processor instructions controlling reconfigurable array 
interlock column indicates instruction stalls waiting array clock counter run zero 
instructions interrupted stalled 
instructions intended context switches 
configuration bits needed array wires configuration rows requires exactly bytes 
assuming bit path external memory loading full row configuration takes sequential memory accesses 
typical processor external bus need complete load 
useful configurations require entire resources array partial array configurations allowed 
smallest configuration row configuration fill exactly number contiguous rows 
configuration loaded uses entire array rows unused automatically inactive 
cache configurations may distributed array similar ordinary instruction cache 
size cache implementation dependent 
reasonable garp deep cache logic block sufficient hold row configurations sixteen row configurations combination size 
maximize cache utilization discussed section partial configurations necessarily loaded physical row array 
hardware translates row numbers programs see configurations starting logical row 
exactly partial configurations placed array dependent pattern vertical wires 
vertical wires garp follow repeated recursive pattern partial configurations loaded various offsets 
garp configurations active time matter array rows left unused small configuration 
analogous thread control program counter main processor 
independently written configurations active simultaneously way guarantee interfere wires 
program special need making configuration active time easily load larger configuration containing smaller ones 
configurations loaded memory 
edited array written back memory 
configuration loaded array copy memory modified main processor explicitly purged configuration cache instruction table 
array access memory maximize bandwidth memory section memory accesses ini array direct processor intervention 
memory accesses proceed phases phase memory access request second data transfer 
stores phases occur array cycle 
loads memory request necessarily precedes data transfer 
restrictions phases pipelined new memory access initiated cycle 
array memory accesses controlled control blocks edge array 
parallel memory buses address bus runs vertically rows 
control signals requesting memory accesses generated array logic blocks forwarded control blocks memory system 
memory address read address bus registers row just initiated accesses 
data transferred memory bus selected row different row supplied address 
contiguous bit words read written request memory buses 
array sees memory hierarchy main processor 
misses chip data cache cause array execution stalled data fetched external memory 
reduce cache misses array perform prefetching accesses merely load chip data cache 
page faults due array memory accesses possible cause faulting process suspended page fault serviced 
commercial fpgas blocks memory reconfigurable hardware permit logic block lookup tables transformed small memories 
contrast amount data state garp intentionally kept bits logic block help limit time needed context switches 
existing chip data cache provides ample temporary storage limited bandwidth memory buses certainly bottleneck 
exploiting maximum parallelism program entails executing memory loads speculatively earlier appear original code known sure executed 
speculative load occurred invalid virtual address 
garp hardware supports speculative loads case simply ignoring invalid virtual address exceptions returning arbitrary data suggested section 
loads valid virtual addresses cause page fault usual memory page resident serviced manner described section 
memory queues addition mechanism demand accesses just described array available memory queues performing read write mul tiple data streams 
streams supported operate direction 
streams read written cycle memory buses con currently 
memory queues programmed main processor configuration executed 
array perspective queue accesses resemble memory accesses array provide address 
read response usually faster data waiting queue 
array perform arbitrary memory accesses anyway behavior queues implemented part configuration array 
providing dedicated hardware common task array resources freed actual kernel computation 
similar memory stream hardware considered standard processors mckee 
contrast designs table compares features garp research de signs 
designs considered rapid piperench recon coprocessors operate main processor registers execute arbitrary numbers clock cycles independently master processor 
garp rapid piperench define hardware 
garp limited exclusively stream processing 
table data flow feedback refers reconfigurable hardware ability encode computations feedback cycles 
piperench virtualization reconfigurable hardware section limits ability support feedback feedback fit stripe piperench unit virtualization 
transparent stalling sync 
means reconfigurable hardware stall automatically transparently needed stay synchronized external components memory system 
authors fail mention fpga unit maintains synchronization presumably garp rapid piperench feature granularity data flow feedback allowed limited configuration preloading fast configuration cache preemptable multitasking transparent stalling sync 
arbitrary memory accesses 
streams memory 
virtual hardware streams data dependent loop exits table comparison garp research designs 
putting onus configuration 
alluded section puts severe restrictions sizes alignments memory streams order easily implement novel scheme memory interlocking 
streams power size aligned corresponding power address generally impeding utility reconfigurable unit 
input output stream unable execute simple vector addition mix audio signals 
designs support arbitrary streams apparently direction garp supplemented limit additional demand memory accesses 
piperench operate streams non unit stride perform arbitrary memory accesses demand garp 
data dependent loop exits number loop iterations lengths streams known advance depend data read 
point systems evenly split 
experience prism ii agarwal data dependent exits valuable garp supports ability array zero array clock counter 
systems table garp array superficial similarities earlier dynamic instruction set computer disc disc ii 
division array rows simplify array management technique reported disc 
garp resembles disc way multi bit operations naturally oriented rows global buses run orthogonally rows bringing values array 
disc said configuration cache plane deep 
just garp disc hold multiple configurations full size plane 
configuration needed cache fault occurs serviced software disc host processor garp services misses hardware 
apparently supported systems table garp entirely unique preemptable 
xilinx mentioned section capable albeit complications 
setting aside question progress memory accesses necessary support consisted mainly ability suspend fpga clock read write data state outside chip 
reported system external accelerator time shared rest system 
implementation study garp architecture implemented tested physically necessary question effectively realized standard vlsi 
main interest assign estimates chip area speed power consumption garp architecture faithfully measured contemporary processor chapter 
matter concrete specific vlsi process technology assumed transistor gate length layers metal operating layout conforming standard scalable cmos design rules tight metal 
state art process technology best available project began corresponding approximately early tel pentium pro mips original alpha 
chapter results study extrapolated slightly better process ultrasparc 
implementation garp restricted realistic die area power budget account intended shrink 
functional organization garp architecture connects reconfigurable array traditional mips processor simple coprocessor interface relatively points contact processor array 
features needed connection processor register read write ports necessary support movement individual bit words registers array garp instructions 
traditional mips coprocessor interfaces supported equivalent move coprocessor move coprocessor instructions feature new 
array access primary data cache 
assuming cache dual ported real complication need arbitrate processor array attempt access cache time 
simple policy suffice giving preference processor conflict 
note reverse array preference steady stream array memory accesses ultimately prevent processor exercising control array 
configuration loading bypass primary data cache cache swamped new configuration loaded array 
processors mips loads instructions separate instruction cache bypassing data cache routing configuration loads data cache way pose significant burden 
array needs option prefetch main memory data cache perform memory access cache allocation access cache 
options strictly necessary defined garp architecture performance reasons 
commercially successful processors give software control caching memory accesses 
garp new processor instructions interlock stall processor execution array clock counter nonzero 
instruction stalled clock counter indefinitely stall interruptible 
stall condition need remembered context switch long stalled instruction gets context resumed 
features requires truly novel mechanisms expected add cost processor 
leaves questions feasibility implementing garp focused squarely array 
config cache tags control section memory interface array core main parts needed implement complete garp array 
scale approximate 
illustrates hardware array divided main parts core array logic blocks largest part control section incorporating control blocks left edge array memory interface presumably adjacent edges array tags managing configuration cache distributed array core 
control section naturally nexus control signals entering exiting array core place coordinate control control blocks 
cache tags keep track configurations cache responsible choosing configuration evict space needed 
complex part outside array core memory interface things includes memory queues alignment network control cir tracking multiple memory accesses progress 
memory interface directly responsible memory buses run array 
addition mem ory accesses initiated array memory interface involved data transfers initiated processor loading configurations memory 
memory interface responsible checking validity configuration loaded 
configuration driver wire rejected 
configurations edited cache configuration active directly cache need checked 
local horizontal wires wires row require checking design exactly driver configuration 
global horizontal wires wires checked tested full row configuration brought 
case vertical wires information needed spread control section logic blocks broadcasting control signals row control block 
multiple configuration rows block row 
assuming configurations read memory contiguous order full row time status vertical wire maintained memory interface updated row configuration read 
status required great amounting single bit wire indicate driver wire seen 
vertical wires span entire height array shorter vertical wire entirely validated status bit reclaimed checking wire 
regular pattern wire breaks seen explained architecture manual appendix straightforward construct state machine handle breaks 
network wires memory buses dynamically simply checked driver conflicts load time 
array memory accesses initiated control blocks array guard multiple rows driving memory bus time control section check run time cases abort array execution offending configuration 
main processor notified ordinary processor interrupt 
control signals affecting array core apply rows logic blocks units individual logic blocks columns blocks 
sense broadcast control signals row row control block row suggested 
examples control signals row include enable row currently active wires manipulate configuration cache select active configuration cache signals loading logic block registers memory buses driving set register values buses 
far control features concerned garp logic blocks completely passive merely responding direct manipulation control blocks 
little clocking fact needed array core architecturally visible logic block registers latched clock cycle array executing 
routing signal pass transistors 
maximum voltage traverse pass transistor threshold voltage drop voltage transistor gate transmitted signal lower voltage swing control signals transistor gates 
subsequent figures indicate higher voltage gates signal passing transistor 
best efficiency signal regularly regenerated inverting buffers operating entirely lower data voltage 
pass transistors switching reconfigurable device concerned simply routing data configuration controlled switches logic blocks 
switches support large number possible signal paths give reconfigurable device flexibility slow signal propagation performing obvious computation 
vlsi simplest type switch single pass transistor voltage gate controls path source drain open closed 
case gate controlled directly configuration bit resulting highly compact implementation 
unfortunately single type transistor pass zero volt signal cleanly pass signal full source voltage reduced voltage specifically transistor threshold voltage drop source voltage 
means signal downstream side pass transistor reduced voltage swing ranging zero volts full source voltage 
reduced voltage weaker slower driving subsequent transistor gates higher source voltage 
switches combined sequence weakness reduced swing signal output speed signal traverses simple pass transistors smaller area switches compared alternatives 
advantage pass transistors dies series due combined impedance rc delay 
best results signal restored buffer preferably inverter pass transistors shown 
input buffer reduced swing harm making output reduced swing buffer efficient operated entirely lower voltage reduced swing signal 
leads eventually dual voltage design high full voltage generally associated configuration reduced voltage active data signals 
dual voltage design viable lower operating voltages ex pected depends transistor threshold voltages effectively scaled operating voltages question researched 
technique technology assumed considering com fpgas built way fair adopt method hypothetical garp implementation 
circuit diagrams voltages appear full swing signals usually distinguished higher voltage signals low swing default 
array wires reconfigurable devices wire network connecting logic blocks large part garp array 
garp architecture stipulates network wires broadcasting logic block adjacent wire sense signal wire 
vertical wires global horizontal wires driven logic blocks adjacent wire 
single wire defined logically illustrated adjacent logic block able drive sense wire 
actual physical implementation wire mimic logical view 
shorter wires spanning logic blocks simple circuit wire common node fairly efficient area speed 
complications longer wires discussed shortly 
shows single wire wire channels blocks contain wires course 
single logic block view vertical wire channel 
garp logic block inputs connect wire channel 
input associated multiplexor choose wires input 
just vertical wires vertical wire channel 
similar story applies horizontal wires logic block 
reduce combined loading multiple logic blocks wires block buffer wires small inverters passing signals input physical implementation wire matching garp architecture logical definition 
active configuration input mux input mux input mux input mux decoder input multiplexors output drivers underneath vertical wire channel logic block 
minimize loading network wires inputs multiplexed locally buffered copy wires 
data values bits size shown single lines 
configuration bits wires local buffers single input multiplexor implemented binary tree pass transistors 
data values multiplexed really bits wide 
multiplexors 
best speed smallest area input multiplexors constructed binary tree pass transistors shown 
ways build multiplexors pass transistor tree fastest 
buffers needed tree refresh signal tree reduced branches buffers small proportion total area 
output side logic block may drive bit wire pairs channel output value 
accomplish battery tri state drivers connected wires channel small decoder select destination encoded configuration 
assuming little settling time tolerated configuration changes output decoder need fast consequently quite small 
seen area taken decoder tri state drivers sizable overcome loading resistance wires 
fundamental reality contended wire connected tri state drivers multiple logic blocks drives wire 
active driver overcome capacitance kin 
hand drivers stronger making larger multiplies loading entire wire making drivers jobs harder 
advantage tri state drivers context typical tri state driver designed respond quickly changes data input enable control signal 
logic block output drivers enable signal changes configuration changes enable response time sacrificed improve parameters 
figures show common styles tri state drivers troublesome application 
circuits components affect select response time drawn smaller elements indicate built transistors minimal size 
trouble driver puts transistors series pull pull sides forcing transistors doubly large achieve power unnecessarily compounding wire capacitance problem 
better single transistor final pull pull needs transistors trivial size 
third alternative better choice 
select wire common style tri state driver transistors series 
pairing pull pull transistors means transistors twice large simple inverter achieve speed 
select wire common tri state driver circuit final transistors series 
final transistors need large non minimal transistors signal inverted twice 
circuit depends higher voltage select configuration line pass tran achieve fewest number transistors wire 
garp drives pairs bits tandem small inverter shared pair drivers seen 
circuit layed neatly underneath vertical wire channel illustrated dedicating nearly half area just crucial pull pull transistors 
lines drivers logic block tied circuit fastest excellent compromise speed area purpose 
garp longest wires run length array rows long simple circuit effectively 
combined capacitance output drivers wire driver reasonable size overcome 
solution install configurable buffers shorter segments illustrated 
segment blocks long longest wires contain buffers 
buffers need fairly ultimately save power sharpening rise fall times signals wire 
global horizontal wires wires dimension blocks long buffers 
insertion inter wire buffers select wire select tri state driver circuit transistors final transistors series making higher control voltage select line 
compare figures 
driver doubled transmitting bits parallel 
wire wire layout underneath vertical wires driver circuit 
small select inverter top 
half area consumed final pull pull transistors 
logic blocks breaking longer wires pieces logic blocks long joined configurable buffers 
logic blocks buffers global horizontal wires buffers long vertical wires array core quilt patches logic blocks 
patches reside buffers longer wires 
array core layout quilt logic block patches space patches allocated buffers 
direction inter wire buffer set match current configura tion actual encoding configurations defined architecture knows buffers 
fortunately array memory interface col lect information wire drivers guard multiple drivers wire easily information set inter wire buffers 
configuration loaded memory array memory interface expands configuration include wire buffer settings time checks driver violations 
interpolated configuration bits loaded physical array managed 
existence operation inter wire buffers completely transparent garp software 
configuration cache management garp design supports configuration cache distributed core array 
need proved supposed small number cache planes start range 
garp implementation cache planes assumed understanding number doubled difficulty needed 
mentioned section physical wire pattern array limits locations arbitrary configuration blindly loaded executed 
pattern vertical wires adopted garp power recursion permits configuration example rows offset multiple 
configurations rows rounded power located multiple boundary 
mean non power configuration consumes extra rows 
row configuration placed starting row boundary rows th free hold smaller configuration fit row configuration th row 
power hierarchy suggests version buddy system technique allocating storage described numerous sources including knuth 
reduce associated allocating array space smallest unit allocation rows 
maximum number row configurations cache plane store possible fit row configurations single cache plane 
expected useful configurations small rows row little need carry buddy system hierarchy way individual rows 
limiting minimum allocation rows cuts maximum number loaded configurations size cache management hardware factor 
logic block layout estimate vlsi area needed implement garp promising logic block organization floor planned layout completed critical com ponents thought greatest influence logic block size 
lookup tables considered logical heart logic block hardware form lookups represents small portion logic block total area 
see consider lookup tables garp logic block configuration inputs reduce input data bits output bits 
configuration bits input bits generating output bits 
input multiplexors contrast require configuration bits reduce adjacent wires bits inputs logic block datapath 
differences numbers illustrate clearly input multiplexors dwarf lookup table hardware size 
output side bits worth drivers needed vertical wires fairly large seen 
logic block find place store bits active configuration planes configuration cache grand total bits 
prevent parts input multiplexors output drivers configuration storage ultra dense visible impact size entire array core 
shows individual logic block organized 
logic block framed horizontal wires memory buses side shown left side 
underneath network wires twelve input multiplexors leading principal bit inputs output drivers vertical wires horizontal wires block 
inner logic block datapath sits side handing bit outputs back output drivers box containing data registers connection memory buses external reading writing 
sides configuration input input config storage input input horizontal wires vertical wires input input input input output input input input input horizontal wires logic block datapath config storage registers memory bus contacts address memory buses proposed layout organization logic block exactly scale 
grey paths carry configuration control bits configuration storage rest logic block 
output input input config storage input input horizontal wires vertical wires input input input input output input input input input horizontal wires logic block datapath output config storage registers memory bus contacts address memory buses outline single logic block tile 
illustration tile dimensional space 
storage configuration cache conveys active configuration web parts represented grey figures 
exactly scale intended approximate 
config storage small dynamic memory assumed cache 
storage distribution configuration bits covered section 
logic blocks identical neighbors sides logic block layout tile dimensions 
gives outline tile shows pattern repeats 
note logic blocks horizontal wire channel share channel little sharing contact neighbors side side vertical wire channel confined single column logic blocks 
addition network wires memory buses logic blocks reached power ground clock signal control signals row control block carry chain shifts connect neighboring logic blocks row 
shows designed weaved layers metal 
extra connections brought row third metal layer horizontal wire channels 
network wires bob second third metal layers 
unfortunately gives network wires metal layer transitions traverse logic block 
wires faster extra resistance helped 
hand fact memory buses burdened little faster vertical wires plus 
said earlier key parts logic block design layed principally input multiplexors vertical output drivers table lookups dynamic storage active registers configuration storage blocks 
brought image logic block tile shows space reserved remaining parts 
correlation image previous diagrams clear 
third metal layer removed prevent obscuring 
thing note table lookups input multiplexors output drivers expected 
rest large unfilled area logic block datapath reserved implementing extra functionality garp input input config storage input input vertical wires input input input input output input input input input horizontal wires logic block datapath output config storage registers memory bus contacts horizontal wires power ground control signals clock carry chain address memory buses allocation metal layers individual logic block 
shown allocated diagram metal layer available locally metal polysilicon layers 
relative space assumed various logic block parts detailed layout main density sensitive components 
logic blocks carry chain 
empty space configuration storage boxes controlling reading writing cache raw storage cells mapped 
lastly reason horizontal output drivers space vertical ones fewer options selecting horizontal wire drive 
wire pairs driven logic block wire pairs choose 
details workings horizontal wires architecture manual appendix layout area corresponding logic block vertically horizontally half drawn transistor gate length 
process equates mm mm little mm logic block counting additional components memory interface 
configuration storage distribution configurations loaded memory buses full bandwidth avail able 
connections memory bus inside box labeled registers memory bus contacts lead direction data registers configuration storage 
illustrates path memory bus contacts configuration storage 
configuration storage boxes adjacent logic blocks sit back back memory bus channel load part configuration block left part block right 
memory bus channel bits wide bits memory buses bits loaded time channel 
configuration contexts store configuration cache divided pieces bit bytes contexts 
complete configuration logic block bits byte wide pieces complete cache logic block 
instruction cache configuration cache blocks unidirectional configuration bits enter side memory bus exit logic block 
garp implementation uses standard transistor dynamic cell cache bit 
shows design single bit line cache optimized primarily size quick access configuration priority 
output side active configuration register drives configuration bit logic block 
horizontal wires logic block left config storage registers memory bus contacts horizontal wires address memory buses config storage logic block right contacts memory buses boundary adjacent logic block tiles 
memory bus enter read write return exit precharge hold logic block bit line configuration storage 
dynamic storage cells need speed sophisticated sense amp circuitry overkill 
cache control lines intended governed minimalist passive state machine manipulated control block row 
simplify matters cache read written set scripts 
configurations read outside memory instance configuration byte time stored sequence memory buses 
configuration retrieved cache bits read simultaneously 
case logic blocks row participate concert 
mechanism needs exist manipulating single logic block cache isolation 
demon dynamic storage course retention 
cache refreshed periodically 
cache refresh involves sequence 
suspend array execution disabling register latching wire output drivers 
write active configuration back cache overlapped step 
cached contexts precharge bit lines read active configuration register write back cache 
precharge bit lines recall suspended configuration active config register 
wait configuration control lines settle logic block 
resume array 
operations occur parallel configuration bits logic blocks array 
pointed refresh procedure depends ability suspend execution garp array arbitrary number clock cycles feat possible ordinary fpgas 
cache hardware built requirement register separate active configuration register needed adding area configuration cache 
problem refreshing cache prevent loss decay 
assuming execution time set aside refreshes full refresh easily done compared milliseconds standard dram 
fact stored cache bits active configuration register bit gives configuration cache far refresh bandwidth typical dram 
refresh protect dynamic storage charge leakage susceptible rare stray particles 
way detect events redundancy 
flipped bits certainly rare occurrence mass market dram regularly sold today redundancy protection hardly notice difference 
remember configurations loaded garp array checked ensure wire driver bits change configuration results disastrous 
redundancy configuration bits choose output wires drive 
logic block need verify consistency redundant coding abort array execution interrupting processor error detected 
goal merely protect hardware allow computation complete happened 
alternative store bits matter static ram dram 
require area methods tried smaller adopted 
seen figures logic block layout especially logic block active configuration distributed block dense rings logic block datapath vertical wire contacts 
bus tracks optimized strictly density speed configuration bits distributed tracks polysilicon second metal layer contacts side metal layer needed 
instances polysilicon leads straight gates transistors controlled configuration bit 
configuration distributed logic block polysilicon wires assumed configuration latched active configuration registers need couple clock cycles fully dissipate 
decoding garp configuration necessary logic block 
input multiplexors output drivers covered amount decoding required minimal easily done logic block component needed 
usual logic circuitry decoding configuration optimized area expense speed 
presents example alternative circuits gate created transmission gate place common full complementary version 
smallest possible transistors circuits accomplish necessary decoding fairly 
ab ab full complementary gate 
gate transmission gate 
smaller version complement inputs available 
logic block functions tentative layout leaves space internal logic block func tions previously summarized section documented detail appendix technically speaking different functions supported design functions overlap implementations 
combined circuit ev fit reserved datapath portion logic block 
boxes fairly simple operations multiplexors fact 
purpose pieces understood details appendix 
top permutation boxes alluded section 
left way multiplexor implementing select function partial select variant mul 
remainder largest pieces input table lookups carry chain 
help gauge area needed datapath table lookups layed included 
sixteen configuration bits provide tables directly closely bound lookup hardware 
table lookups essentially multiplexors implemented binary trees pass transistors just input multiplexors 
lookup tables main complex part datapath carry chain expected need area little table lookups 
aside sixteen table bits eleven configuration bits control operation datapath garp logic block 
bits needed permutation ab shift shift shift shift carry carry optional shift invert hout optional shift invert select carry carry save addition optional shift invert sum result function crossbar dual input table lookup carry chain crossbar crossbar dual input table lookup table selector crossbar shift shift shift carry shift carry complete contents logic block datapath 
boxes table lookups carry chain complex 
boxes brought top logic block datapath inputs layout 
routing decoding remaining control bits presents real difficulty 
speed power area addition layout experiment circuit model critical path logic block created simulated arrive estimate maximum clock speed array 
usual circuit model determine transistor sizes layout 
path modeled register logic block network wire logic block farthest distance allowed input multiplexor slowest function path register destination logic block 
considering delay fpgas wire network model careful include parasitic capacitances network wires addition transistors attached node path 
separate critical paths considered corresponding different sequences guaranteed fit clock cycle section 
carry chain critical path 
carry chain modeled reliance placed speed carry chains devices created similar process technologies 
interestingly hauck detailed spice simulation bit carry chain reconfigurable hardware implemented process delay chain ns 
carry chain invert carry propagation needed basic arithmetic operations slow carry chain noticeably 
garp allow carry inverted carry chain expected take ns cover logic blocks 
assumptions simulation critical path circuit model indicated ns clock cycle mhz clock fast process 
simulations rough estimate power consumption extrapolated array 
done multiplying worst case power con sumed circuit component number components entire array 
intention get highly accurate estimate entirely unrealistic implementation techniques 
resulting estimate power consumed array counting clock distribution comes additional power course needed garp main processor parts reconfigurable array expected half die area perform heaviest computing 
considering underestimate right array compared typical high performance desktop processor pulling power range higher 
section gave area single logic block process mm mm 
assuming dimension long wire buffers fig ure equivalent logic blocks rows vertical dimension array memory interface total size array logic blocks comes mm mm approximately mm chapter benchmarks statistics chapter evaluates garp architecture benchmarking stan dard sun ultrasparc variety applications 
hypothetical garp implementation defined combines garp processor memory system identical ultrasparc software tools introduced permit programs written simulated hypothetical garp 
suite benchmarks performance system 
chapter ends collection statistics array configurations benchmarks case information may useful designs 
hypothetical garp attempt evaluate garp architecture hypothetical garp compared sun ultrasparc 
ultrasparc way superscalar bit processor running mhz kb chip instruction data caches 
addition floating point unit processor supports sun vis graphics instructions small simd operations 
ultrasparc implemented process layers metal die size mm hypothetical garp constructed removing sparc super scalar integer floating point processing units ultrasparc die replacing mips processor extended garp reconfigurable array 
shows die actual ultrasparc proposed garp derived 
surgery essentially puts garp top ultrasparc memory system 
new main cache prefetch grouping integer unit floatingpoint graphics unit cache dmmu reconfigurable array cache dmmu floorplan ultrasparc die 
hypothetical garp die constructed technology 
processor single issue bit mips ii smaller powerful ultrasparc processing unit 
previous chapter put size garp array process mm mm clock speed approximately mhz 
adjusting ultrasparc process believed garp array scale mm mm run mhz 
additional fourth layer metal ultrasparc process provides obvious room error extrapolated array size 
factor favor fact layout ultrasparc process bound common denominator scalable cmos design rules allowing improvements provide room error 
space allocated reconfigurable array corresponds scaled size 
removing floating point unit course means software needs floating point disadvantage garp 
situation bad reconfigurable array configured help floating point operations fpgas sources 
floating point arithmetic fast reconfigurable hardware particularly double precision small garp array considered 
real intention processor eliminate floating point unit keep part main processor reconfigurable array 
cache integer unit standard preprocessor standard compiler modified mips assembler standard linker executable garp simulator ga configurator config garp programming environment 
new modified tools highlighted 
software tools software tools created possible write programs hypothetical garp simulate clock cycle accuracy 
software path summarized 
tools substantially new configurator garp simulator 
garp assembler merely modified mips assembler 
array configuration coded ga file simple textual language 
source fed program called configurator generate representation configuration collection bits 
simplicity configurator creates text file initializer integer array program 
need assembly language programming invoke garp instruc tions interface reconfigurable array 
compiler gnu compiler gcc accomplished inline asm statements 
configurator configurator accepts human readable description configuration con binary representation accepted reconfigurable array 
input lan guage configurator akin assembly language high level language typical fpga netlist 
data operations placed explicitly rows columns programmer 
configuration defined collection rows row containing logic blocks specific columns 
basic syntax row optional row name column number logic block settings 
feel permissible logic block settings probably easiest impart ex ample 
specifies complete configuration adding bit values columns middle columns array row row send registers vertical wires 
function vout send registers horizontal wires 
dreg hout row row dreg add registers values row latch result registers 
dreg add carry sum sum result configuration values registers row registers row added sum stored registers row 
column significant rightmost columns 
row names period distinguish syntactically 
field second row specifies input logic blocks come row labeled case row 
obtain connection vertical wires programmer merely names source needed logic block input 
responsibility configurator choose specific vertical wires making connections 
inputs row example taken vertical wires row 
different syntax hand indicates inputs read row horizontal wires rows 
logic block drive output vertical wires horizontal wires 
example output configurator text 
eleven lines elided 
ccf ccd suitable initializing array bit integers linking configuration program garp reconfigurable array time consuming parts program usefully employed 
remainder program written compiled ordinary compiler executed main processor reconfigurable array 
configuration linked ordinary program 
continuing example configurator output file called add config code uint config add include add config suffices initialize array config add desired configuration bits 
configuration accessible program loaded activated array 
configuration invoked new garp specific instructions unknown compiler assembly language programming required 
garp assembly code loads executes example refer back table add la config add load pointer config add array 
load configuration 
copy operands array step array clock cycles 
copy result back array 
ra return subroutine 
names ra refer ordinary mips registers la mips load address instruction 
symbols denote registers array row row 
mips subroutine calling convention passes subroutine arguments registers subroutine return value passed back register 
assembly language stub program add integers reconfigurable array executing ordinary subroutine call add 
add subroutine loads proper configuration array switches array configuration cache 
copies arguments array registers steps array cycles perform addition reads sum back returns 
course example involves overhead 
practice array substantial just easily done main processor 
simulator hardware implementation garp exist garp programs executed simulator 
simulator loads executes standard mips executables 
operating system calls forwarded environment simulator running 
outside operating system calls simulator best count true clock cycles 
main processor assumed simple single issue mips 
interlocks stall instructions observed stall cycles counted 
memory caches mod cache stalls added 
simulation configuration cache memory queues mimic real protocols essentially register transfer level 
simulator cycle cycle identical actual im plementation cycle counts realistic 
far practical full behavior ultrasparc memory system duplicated perspectives main garp processor reconfigurable array 
ultrasparc usual separate level instruction data caches kb kb unified second level cache 
details ultrasparc memory system gleaned 
hand coded benchmarks benchmark applications coded hand garp formance compared applications ultrasparc 
table lists benchmarks summarizes speed difference garp ultrasparc selected input sizes 
applications chosen intended cover range behavior just large speedups easily predicted 
set des md sha cryptography related applications des standard encryption algorithm md sha hash functions digital signatures 
benchmarks common operations images typical sorting problem cou ple string functions standard library 
benchmark applications covered detail subsequent sections 
cryptography applications chosen precisely cryptography claimed sort application gives fine grained reconfigurable hardware chance excel instruction fed processors 
cryptography benchmarks mode des inherent feedback loops latency critical 
mentioned feedback frequent characteristic cryptographic algorithms limit parallelism available 
contrast des encryption mode example application tremendous data parallelism 
image operations fall category opportunities showcase reconfigurable array ability sustain op erations simultaneously 
sorting traditional challenge problem 
theory highly parallel need shuffle data unpredictable patterns puts great stress memory system 
cleverly input mhz mhz benchmark size sparc garp ratio des encrypt cbc mode mb ms ms des encrypt mode mb ms ms md hash mb ms ms sha hash mb ms ms floyd steinberg dither color image kb ms ms median filter grey scale image kb ms ms sort key value pairs kb ms ms strlen kb strcpy kb strlen bytes strcpy bytes table synopsis hand coded benchmarks 
times garp obtained program simulation 
strlen strcpy garp execution times include cost loading configurations cache external dram 
complicating processor number uncorrelated memory accesses slow memory reduced 
standard string functions examples workhorse routines see wide range data sizes strings characters long kilobyte 
production garp system reconfigurable hardware accelerate standard library functions fully transparently calling programs 
small data sizes overheads swamp potential speedups 
benchmarks small data generally assumed cache reasonable conjecture 
primary data cache kb reasonable suppose strings kb cache 
likewise strlen strcpy functions assumed processor level instruction cache functions called 
token garp configurations functions assumed configuration cache functions called garp 
assumptions applied benchmarks 
aside strlen strcpy quoted garp execution times include cost loading configurations entirely external dram 
process choosing parts benchmarks implement garp reconfigurable hardware job designing configurations done hand examples 
case attempt productive main processor garp array operating 
speedup numbers free multiprocessing effects 
data encryption standard des important encryption algorithms years data encryption standard des 
des application reconfigurable hardware normal processors trouble implementing efficiently 
implementa tions des fpgas reported tse board duncan 
des encrypts bits data time bit key 
group bits run obfuscation loop sixteen times loop des spends time 
bits divided bit quantities steps repeated see 
extract bit subsequences ri xor bits encryption key 

apply resulting bit values index box table bit values 
box unique approximates random function 

perform permutation bits box results 
permutation 

xor permuted result older ri form new ri 
sixteen iterations encrypted bit output taken 
software implementations des invariably implement boxes table look ups requiring read memory box evaluation 
told table lookup memory reads needed bits encrypted 
hand software implementations avoid final bit permutation pre permuting box table entries 
table entries full bits size box outputs need ored combined ri 
software sufficiently large reconfigurable hardware implement algorithm directly 
box table lookups bit permutations done quickly parallel external memory 
configuration garp array needs cycles inner loop iteration 
key bits box table box table box table box table bits bits bits bits bits bits bits bits bits bits box table box bit permutation box table box table box table iteration inner loop des 
symbols indicate xor operations 
key bits iteration des loop uses different bits key xor step 
addition main loop key bits constantly muted 
design permutation sequence bit group run obfuscation loop software implementations precompute key permutations line subsequently read array bit group encrypted 
garp configuration easy dedicate part array permuting key fly 
common modes des employed electronic code book cbc cipher block chaining 
mode encrypts bits message separately cbc mode uses results encrypting previous bit groups help encrypt bits 
chaining property cbc mode encryption secure introduces strict data dependency bit encryption 
mode encryption bit piece message done parallel 
simulation indicates garp times faster ultrasparc cbc mode bit piece encrypted separately sequence 
mode des configuration pipeline little modification encryptions simultaneously making total speedup times faster ultrasparc 
md sha hashes important type cryptographic operation way hash function 
ordinary hash function maps arbitrarily long string bits small fixed size hash value 
distinguishes way hash function difficulty finding different source strings function maps hash result 
way hash functions generating digital signatures documents 
major way hash functions tried garp md sha 
md done napa arnold 
md treats source string sequence bit blocks updating hash value block processed turn 
bit hash accumulated bit variables named updating hash single block requires steps form depicted 
individual step incorporates bits current bit block bit pieces read sequentially block 
bit constant data bits bit rotation bitwise logical function iteration inner loop md hash 
different bit constant different rotation distance applied iteration 
bitwise logical function changes iterations 
sixteen bit words entire block source word gets exactly times 
steps requires unique bit constant rotation operation changes step step 
sixteen steps bitwise logical function changes 
different logical functions employed 
implement md garp configurations created corresponding logical functions 
configuration physically contains steps take advantage fact rotation distances repeat steps group sixteen steps 
rotations hard wired proper distances 
outputs fourth step looped back inputs iterations configuration equal sixteen algorithm steps 
iterations configuration loaded cache sixteen steps bitwise logical function 
bit source pieces read sequentially room keep array demand memory accesses load correct word proper time 
part constants supplied sequentially memory read memory queues 
latency steps configurations clock cycles averaging cycles algorithm step 
repeatedly changing configurations resetting memory queue steps consumes additional clock cycles 
simulation shows large blocks garp times fast ultrasparc md hash 
sha hash function similar style md differing details 
sha generates bit hash value algorithm steps source block 
md different configurations cycle garp corresponding differ ent bitwise logical functions 
sha garp times faster ultrasparc large inputs 
image dithering image processing applications implemented garp dithering full color image fixed palette fewer colors 
input image stores bytes pixel total levels red green blue pixel 
target palette case called web palette web browsers netscape navigator 
palette contains colors orthogonal arrangement levels red green blue 
dithering algorithm employed floyd steinberg error diffusion essentially standard algorithm task 
dithering image proceeds top bottom scan line order 
dither ing pixel involves steps 
find color target palette closest pixel color 

find color error introduced quite correct color distribute error neighboring pixels adjusting neighbors colors 
shows pixel color error distributed diffused neighbors floyd steinberg algorithm 
finding closest target color matter reducing source image levels red green blue levels target palette 
accomplished floyd steinberg error diffusion 
image dithered top bottom scan order 
replacing pixel original color closest available color results color error error gets pushed uncommitted neighboring pixels adjusting original colors pixels 
process repeats pixel right 
execution time ms ultrasparc garp image size pixels garp speedup image size pixels execution times speedups image dithering 
smallest image sizes tested pixels 
dividing color component rounding 
calculating error requires multiplying result back subtracting 
distributing error involves scales additions neighboring pixels seen 
save errors diffused single pixel multiple neighbors added added destination pixel 
application garp times faster ultrasparc large images 
graphs garp speedups ultrasparc range image sizes 
garp advantage comes ability manipulate bit quantities 
garp ultrasparc division done multiplying approximation 
multiplies implemented terms shifts adds garp fairly efficiently 
image median filter image operation implemented median filter correct outlying spots noise image 
variants median filter done abbott splash board box custom fpga board 
benchmark images grey scale color median filters done color images 
median filter replaces pixel original image median pixels neighborhood pixel 
median set values value middle set sorted increasing order 
median pixels center usually neighboring pixel nearly value 
single pixel extreme white black value inconsistent neighbors chosen final image filter eliminates spots 
important point easiest think median operation terms sorting sorting pixel values find median strictly necessary 
knowing median information knowing full sort values median value obtained doing full sort 
algorithm finding median exactly values 
algorithm primitive operations sorting values finding median values 
values algorithm finding median values arranged grid 
individually sort columns greatest value 
find medians diagonals wrapping shown 
median medians median original 
sorted short sequence compare exchanges exchange exchange exchange finding median easier assuming notation exchange median explains element sorting operations followed element median operations suffice extract median original values 
reasonable implementation median filter processes image scan line order finding median pixel works finding median neighbor right 
observe step sorting pixels columns done previous pixel left 
rightmost column new 
pays save sort columns pixel 
reduces output pixel just element sorting operation followed element median operations 
garp implementation median filter algorithm turns times faster ultrasparc large images 
speedup numbers different sizes images graphed 
compare exchange operations typical processor especially bulk median filter 
garp configuration contrast pipeline fed memory queues reading scan lines simultaneously pixel cycle 
pipeline output pixels written rate cycle time production wraps edge image 
execution time ms ultrasparc garp image size pixels garp speedup image size pixels execution times speedups image median filter benchmark 
smallest image sizes tested pixels 
sorting sorting garp benchmarks 
benchmark orders sequence key value pairs bit keys 
corresponding bit values interpreted correctly permuted keys 
best implementation sorting garp varies depending number elements sort 
elements radix sorting algorithm involving buffers 
pass radix sort reads elements buffer writes pass works opposite direction radix digit 
radix size bits passes needed fully sort bit keys 
single radix sort pass implemented garp configurations 
reads entire source buffer counts number elements digit value 
digit position pass 
known exactly elements digit value second configuration reads elements second time writes output buffer proper places 
passes radix sort algorithm sort number elements strictly linear time 
configuration reads elements clock cycle second processes element cycle total cycles element pass counting inevitable memory stalls 
passes comes clock cycles element entire radix sort 
radix sort buffers fit second level cache execution time ms ultrasparc garp number elements garp speedup number elements execution times speedups sorting 
tests run key value elements 
elements scale graphs garp speedup ultrasparc 
cache misses add tremendously total time 
radix sort mandatory passes reading elements twice serious liability 
avoid cost garp implementation uses radix sort elements kb size time 
input set divided groups group sorted radix sort algorithm 
sorted groups merged mergesort style passes 
merge takes separate sorted streams input outputs single sorted stream times long 
radix sort passes merge passes expected overflow kb second level cache forcing reads writes ultimately go external dram 
elements sorted way single expensive merge pass elements merge passes elements 
merge pass performed array configuration reads irregularly streams writes sequentially merged stream 
output element written merged stream element input stream read output element chosen 
full latency writing output elements clock cycles including time service cache misses 
cache misses occur frequently read 
cache line larger element cache brings element cache occur subsequent elements cache line 
output stream garp memory queue hardware buffer merged stream fewer larger memory stores 
radix sort mergesort techniques generally complex ul better simple quicksort 
attempts sophisticated invariably lose time executing additional instructions saved clever algorithm 
previous benchmarks shows difference execution times garp ultrasparc different numbers elements 
bump speedup graph due cache limitations 
unbounded cache speedups continue rise factor sorts elements 
elements effects cache misses felt execution times larger sizes dominated dram access latencies 
library functions strlen strcpy benchmarks strlen strcpy functions standard library 
strlen function fairly easy implement 
garp configuration function pipeline accepts sixteen new characters clock cycle accumulates count string length 
configuration search null character bundle sixteen cut short count soon 
pipeline doing cycles long plus cycles memory latency feed pipeline 
strcpy function little complex strcpy write string time byte terminating null character 
middle part string strcpy configuration cycle pipeline reads writes sixteen characters alternating clock cycles 
string additional parts configuration write remainder string characters time character time necessary 
figures usual graphs execution times speedups 
note garp performance small length strings substantially better ultrasparc 
strings length garp faster ultrasparc strlen strcpy 
increases factors respectively longer strings 
execution time ultrasparc garp string length bytes string length bytes execution times speedups strlen function 
strings length characters tested 
execution time ultrasparc garp string length bytes garp speedup string length bytes execution times speedups strcpy function 
string lengths tested strlen 
garp speedup load config 
string length garp clock cycles strlen load config 
string length garp clock cycles strcpy time bring strlen strcpy configuration dram compared time execute function strings various lengths 
garp hardware supports reads writes sixteen bytes time requiring memory address aligned special boundary 
byte access aligned byte boundary garp breaks access parts introducing extra stall cycle necessary 
garp execution times assume particular string alignments include extra cycles 
source destination strings happen aligned sixteen byte boundaries garp speedups long strings exceed factor strlen factor strcpy 
noted earlier functions functions data func tion code assumed resident level caches string functions called 
applies instruction data caches ration cache reconfigurable array 
case strlen strcpy configuration cached time load configuration external dram cache negate advantage reconfigurable array depending part times function called configuration brought cache 
graphically compares time required load configuration versus time execute function strings various lengths 
graphs show ration loading time negligible surprising thing worse 
efforts minimize configuration encoding size maximize bandwidth memory garp keep configuration cache penalty manageable size 
instructive relevant question config number calls break strlen strcpy string length table number calls strlen strcpy needed cover initial configuration loading time achieve parity ultrasparc 
loading undermines garp speed compared ultrasparc 
table looks question point view number function calls garp fully pays cost loading configuration 
table suggests typical average string length characters calls cover cost loading configuration memory break relative ultrasparc 
benchmark review sampling benchmark test cases brought table sorted approximately speedup 
table identifies immediate obstacle achieving greater speedup cases 
top entries size garp array currently limiting factor meaning larger array possible push speedup numbers higher 
long string lengths strlen strcpy functions limited garp memory bandwidth 
doubling available memory bandwidth approximately double speedup achieved functions 
clear earlier need arbitrarily permute contents memory primarily limits sorting benchmark 
remaining cases constrained latencies loop carried dependencies greater significance function overhead operating small amounts data 
line table divides benchmark cases groups ones line examples applications abundant data parallelism easily exploited ones line having property 
tentative draw results advantage custom circuits better implement non applications real lies applications accessible parallelism 
fact majority fpga applications quoted genome benchmark speedup limiting factor image median filter array size image dither array size des encrypt mode mb array size strlen kb memory bandwidth strcpy kb memory bandwidth des encrypt cbc mode mb latency sort elements irregular memory accesses sort elements irregular memory accesses sha hash mb latency md hash mb latency strlen bytes overhead strcpy bytes overhead table representative set benchmark test cases sorted approximately speedup factors limiting improvements 
matching image filtering military target recognition graphics rendering neural networks excessively data parallel 
time try applications presumably garp 
contrast non parallel applications limited speedups low single digits reaching high 
configuration statistics section presents numerous statistics garp array configurations benchmarks 
table names configurations covered gives sizes array rows numbers logic blocks 
md configurations section nearly identical analyzed 
likewise sha hash 
configuration des mode exactly cbc mode similarity cbc mode configuration considered 
benchmarks configuration apiece exception sorting benchmark explained previously uses radix sort pass mergesort pass 
configuration number number benchmark name array rows logic blocks des encrypt cbc mode des cbc md hash md sha hash sha image dither dither image median filter med filter sort radix counting digits radix copying elements merge strlen strlen strcpy strcpy table names sizes configurations benchmarks 
functional density configuration table gives fraction logic blocks configured purpose percentage major logic block subsections 
may helpful refer back figures structure garp logic block 
categories table inputs functions subdivided tables 
logic block physical inputs contributes inputs utilization percentage table depending input effect outputs logic block 
block configured way value input impact logic block results input considered unused 
input considered active output latched register driven output wire 
active inputs necessarily come logic blocks wire network registers constants logic block 
table breaks utilization logic block inputs separately 
categories shift inverts permutation boxes described section visible 
physical crossbar boxes shift invert boxes 
garp permit shift invert boxes time logic block average categories 
operative depends logic block function mode 
permutation box considered active input connected active des cbc md sha dither med filter radix radix merge strlen strcpy part part inputs inputs functions paths registers functions paths registers table utilization major logic blocks parts 
des cbc md sha dither med filter radix radix merge strlen strcpy input input input input input input input input table utilization logic block inputs tabulated separately 
des cbc md sha dither med filter radix radix merge strlen strcpy logic block column logic block column table logic block utilization array column 
columns middle logic blocks array aligned memory bus 
input passes permutation box part selected function mode logic block 
active permutation boxes necessarily perturb input may pass value counted 
matters opportunity perturb input value 
functions column logic block generally counted function output 
logic block configured simple table lookup merely passes inputs unchanged ignoring inputs considered useful function counted 
paths entry counts cases output driven output wire 
instances path connection wire garp wire network way connect wires 
lastly registers category reports utilization registers may participate circuit bypassed 
table divides logic block utilization part category ta ble columns blocks reconfigurable array 
center section array columns aligned middle bits memory bus usually core datapath configured array 
extra logic blocks left right typically control signals configurations layed hand participate computation 
table clearly shows side logic blocks employed consistently middle sixteen columns 
safe say ex contributes numbers reaching middle columns 
experience having side blocks impossible pack main datapath tightly surely resulting decrease functional density array 
logic block inputs inputs actively tables break sources inputs type 
previous section defined counts active input 
obvious option reading nearby network wire inputs taken directly registers logic block configured constant 
note third inputs come des cbc md sha dither med filter radix radix merge strlen strcpy zero constant nonzero constant zero constant nonzero constant internal register vertical wire horizontal wire internal register vertical wire horizontal wire table distribution input sources active inputs 
rows add 
des cbc md sha dither med filter radix radix merge strlen strcpy row wire row wire row wire row wire row wire row wire row wire row wire table subdivision horizontal wire inputs previous table 
sources wire 
inputs read horizontal wire table distinguishes wire local global wire row row 
different types horizontal wires explained section interesting note thirds signals read horizontal wire come row third row 
logic block functions logic blocks useful function table breaks percentage function mode recall section table 
partial select mode chosen benchmarks performs multiply variable values 
benchmark requiring multiplication image dithering explains configuration triple add mode 
surprisingly cryptography applications table lookup functions benchmarks 
table shows permutation boxes configured different applications 
section specified permutation boxes considered active included table 
reverse crossbar function comes free hardware options straight high bit duplicated low bit duplicated 
obvious combined shift invert operation 
shift invert variants important multiplications various constants despite fact combined shift invert case needed multiplies done image dithering benchmark 
granularity table gives results experiment find apparent bit widths operations encoded configurations 
configurations searched cally sequences similarly configured logic blocks considered multi bit operations layed row 
table expresses results terms percentages logic blocks perceived multi bit operations size ranging bits wide 
widths possible garp array granularity bits 
des cbc md sha dither med filter radix radix merge strlen strcpy input table input table dual input table select partial select dual input table select partial select carry chain carry chain table distribution logic block function modes 
logic blocks useful function counted rows add 
triple add triple add des cbc md sha dither med filter radix radix merge strlen strcpy straight high low reverse straight invert shift shift invert straight high low reverse straight invert shift shift invert table distribution permutation box functions 
active crossbar shift invert boxes counted specified section 
des cbc md sha dither med filter radix radix merge strlen strcpy bit width bit width table percentage logic blocks operations bit width ranging 
row adds logic blocks 
bit width percentage table percentage operations bit width ranging 
interpreted table 
image dithering configuration peak bits multiplications done bits wide 
peaks generally nearly bits 
note widths greater bits des cbc merge 
oddly cryptography configurations unimodal des preferring bit bit operations way hash functions extreme preferring bit operations 
table bit deceiving blush recommend granularity bits having highest average 
table reports percentages logic blocks size percentages operations size 
find requires dividing number logic blocks width normalizing total number multi bit operations 
exercise done table dramatically puts operations bits minority percentage operations 
reason bit operations consume large fraction logic blocks logic blocks individually 
course results table biased fact configura tions hand coded specifically reconfigurable hardware granularity bits 
grouping operations multi bit runs priority possible say distribution 
wire connections logical connections garp logic blocks ideally single wire order happen blocks column vertical wire neighboring rows horizontal wire 
logic block connections need hop get source destination hop defined traversal single straight piece wire 
garp additional hop requires entering exiting logic block logic block path 
table gives percentage distribution number hops logical connec tions blocks configurations 
logic block considered facilitate hop des cbc md sha dither med filter radix radix merge strlen strcpy hop hops hops hops hop hops hops hops hop wire hop wire hop wire hop wire hop wire hop wire table distribution wire hops logical connection logic blocks 
columns right break hop case wire class 
des cbc 
md 
connection vector plots benchmark configurations 
destination logic block middle plot numbers give count connections sources relative position set positions usually 
source positions strips marked lines connection single hop vertical horizontal wire 
sha 
dither 
med filter 
part 
radix 
radix 
part 
merge 
strlen 
strcpy 
part 
passes value unaffected wire 
registers ignored values may may delayed registers 
sharing wires signal fans logic block source multiple destinations accounted numbers 
table shows great majority logical connections meet ideal single wire hop connections hops 
worth single hop cases fairly evenly distributed different classes horizontal wires 
provides connection vector plots benchmark configura tions 
plots give indication physical lengths connections logic blocks 
provide visual verification claim connections satisfied single hop 
memory accesses inherent memory access patterns various benchmarks indicated table 
nearly benchmarks operate streams 
couple circular buffers contiguous blocks memory read written stream fashion cyclically 
md configurations section read constants essentially circular buffer image dithering configuration needs circular buffer hold errors diffused scan line section 
md forced perform truly nonsequential accesses 
explained earlier md algorithm reads sixteen bit words nonsequential pattern updates hash value 
imagine loading sixteen words head sequential stream garp array accessing internally order needed room array md 
consequently reads counted inherently non sequential accesses 
table tallies actual garp resources configuration uses access memory specifically number hardware memory queues allocated configuration independent demand memory accesses 
despite fact benchmark data organized streams majority configurations demand memory accesses 
common reason need read write streams maximum possible garp memory queues 
radix configuration part radix sort pass operates seventeen streams total circular memory demand streams streams buffers memory queues accesses configuration accesses des cbc md sha dither med filter radix radix merge strlen strcpy table inherent memory access patterns benchmark configurations memory access resources 
bytes array clock cycles memory demand memory demand queue memory queue memory configuration reads reads writes writes des cbc md sha dither med filter radix radix merge strlen strcpy table peak memory bandwidth requirements benchmark configuration 
entries des cbc example mean array clock cycles configuration reads writes bytes simultaneously cycle 
cache misses stalls may delay array clock 
input stream sixteen output streams 
input stream easily delegated memory queue hardware sixteen output streams written irregularly making writes indistinguishable arbitrary demand writes 
reverse true mergesort configuration reads irregularly input streams writes output single memory queue 
memory queues strlen strcpy simply avoid extra overhead cost 
similarly remaining third memory queue employed image dithering configuration avoid having reset queue scan line 
rate different configurations attempt access memory recorded table 
memory buses total bits maximum memory bandwidth available bytes cycle 
radix sort string functions notable saturating memory buses array clock cycle 
numbers table represent attempted rates bandwidth sustained memory system 
radix configuration attempts byte write array cycle write misses cache resulting slower actual rate 
noted earlier sorting configurations particularly susceptible cache misses 
chapter garp retrospective chapter collects lessons learned observations garp benefit hindsight 
positive aspects considered followed weaknesses deserve better attention 
review changes garp design correct earlier flaws 
noteworthy features positive side garp features deserving special emphasis may reflected thesis 
processor handling start shut particulars feature turned valuable expected main pro cessor ability reconfigurable array access data registers 
course obvious application debugging easy program single step array report happening 
unexpected extent feature normal execution help applications run faster 
assume reconfigurable array execute critical program loops 
loops require certain amount start shut activity ignored overhead means dedicating scarce array resources circuits sit idle time 
overhead circuitry takes space loops fit array crowded configuration optimized processing middle scan line overhead handling ends 
main processor achieve desired behavior ends stepping configuration manipulating array data state 
typical processing image configuration reconfigurable hardware capable handling middle scan line edges corrected main processor 
executed back main processor 
worse fit start shut circuitry inserts multiplexors main part loop increasing length critical path slowing execution speed 
usually better build configuration start shut overhead rely main processor handle 
loading new configuration array processor single step array execution cycles adjust array pipeline state step ensure loop properly started 
simplest cases done initialize registers loop execution started times loop stepped adjusted clock cycles prime pipeline 
reverse process occur loop execution extract results 
way processor smooth special cases 
example image processing application progresses image scan line order illustrated 
edges image require special handling amount special case circuitry usually needed array process entire image top bottom 
smallest images great majority time clearly spent middle image circuitry edge cases useless 
configuration usually efficient extra circuitry leaving main processor take care edges 
garp easiest way main processor perform calculation edges entirely done processor simply tweak configuration calculation single stepping array near edges manipulating array register contents 
trick dithering benchmark section possible processor arbitrary access array registers 
support extended functions logic blocks traditional fpgas garp logic blocks designed basic arith operations mind 
garp supports standard table lookups table lookup modes popular 
table previous chapter table lookup modes seen account logic block func tions remaining configured higher level functions 
single frequent function mode carry chain mode supports additions subtractions comparisons values third control input 
image dithering application thirds logic blocks configured triple add mode reflecting multiplications divisions performed benchmark 
cryptography applications extent strcpy major table lookup modes 
course insignificant fraction table modes play role control circuitry benchmark 
point fine grained array garp arithmetic operations dominate rule justifying extra support garp design 
limited configuration turnaround garp architecture includes configuration cache expressly denies configuration loaded cache clock cycles 
anticipated switching cached configuration take clock cycles possible cycles 
architecture enforce delay loading cache license delay valuable minimizing area garp array 
recalling implementation survey section particularly logic block layout page design predicated freedom ignore configuration delays 
freedom tight tracks distributing configuration bits logic block polysilicon totally unacceptable small pieces circuitry involved decoding configuration including notably slow narrow decoder vertical output drivers visible 
parts configuration storage input multiplexors redesigned 
told conservative suppose increase array area 
benefit able change configurations quickly justify cost 
array access memory section case giving reconfigurable array direct access memory intervention main processor 
data section confirmed benchmark kernels depend having maximal bandwidth memory radix sort string functions specifically 
applications run nearly fast memory accesses routed main processor 
image dithering benchmark saturating array memory buses accesses memory sustained garp main processor 
somewhat processor exclusively responsible memory accesses 
emphasized memory bandwidth reason reported garp speedups 
chosen benchmarks ultrasparc implemen tation primarily limited bandwidth memory 
reconfigurable array performs computation order magnitude faster ultrasparc dithering strlen example natural memory bandwidth needs increase 
decision give garp array wide direct access memory consistent expectation deliver speedups 
array clocking context switches final important aspect garp separation notion logical array clock cycles real time 
reconfigurable hardware interacts processor memory system standard caches prepared deal unpredictable delays due cache misses 
automatically suspending array register updates hardware reconfigurable array stalled cache misses serviced completely transparently executing configuration 
frees configurations concentrate computation synchronization issues 
array clock cycles garp logical units array execution just instructions units execution standard processors 
context switches far extreme example decoupling array clock cycles real time 
preemptive context switch able freeze array execution stage preserve array state corresponding process swapped back 
array clock cycles garp provide clean boundaries array execution suspended resumed 
corrected mistakes design garp went variations early flaws realized late game late changes architecture 
corrections worth mentioning control blocks provide reconfigurable array ability perform memory accesses array execution originally placed right edge array left 
carry chains array operate right left right side array closest significant bits multi bit values 
putting control blocks side intended leave room left overflow handling 
obvious decisions outcome comparisons comparison results carry chain available left side 
continue transmit signals way side array control blocks moved left side shorten distance 
time main processor access data registers extra logic blocks sides array middle logic blocks copied processor way middle blocks source destination memory access section 
inconvenient bordering impossible processor perform certain start shut duties discussed earlier 
meant context switches needed additional special handling save restore bits 
instruction set eventually extended give main processor access full array 
currently garp array short horizontal wires wires span eleven blocks send value distance blocks away corresponding shift bits section section appendix 
previously wires little shorter support shift bits 
easy see reason choosing distance bits common data size 
clear experience need wires just little longer provide margin flexibility laying bit operations array 
changes come publications garp addition logic block functions covered section original archi tecture included variable shifts 
mode bits horizontal wires logic block treated bit value shifted right values usual logic block inputs 
significant bits shifted value returned function result 
concert row mode created row variable shifter 
variable shift mode strikes 
start rarely needed fact benchmarks 
second hardware mode overlap logic block functions cheap include 
worse immediately suitable common shift operations 
style right shifts example required extra logic blocks delay correctly 
reasons mode ultimately discarded 
minor adjustment definition select mode time variable shifts implemented garp rows witnessed back table 
section discusses basic arithmetic operations usually done just natural number logic blocks garp example bit comparison done exactly logic blocks bits block 
feature easier configure garp array small simd segmented operations adjacent bit comparisons pair bit words 
originally certain inequality comparisons segmented way 
fix shortcoming operation carry chain triple add modes modified 
general ensuring arithmetic operations requires care definition logic block functionality connected carry chain 
weaknesses corrections garp architecture far perfect 
flaws basic design challenge programming device bear scrutiny 
wire network garp array intended expandable larger sizes technology im proves increasing number rows 
previous configurations able run modification number rows merely smaller fraction new array 
configurations filling new larger array run older just software requiring intel mmx extensions run older feature 
unfortunately garp architecture insistence having wires stretch full height array difficult proposition practice 
section scheme hiding buffers longest wires proposed works row garp ideal 
originally hoped similar schemes longer wires larger arrays largely naive 
rows possible implement longest garp wires tricks involving multiple physical wires point recognized signals simply sent arbitrary distances single clock cycle 
wire networks larger reconfigurable arrays need able take clock cycles transmit value presumably registers embedded network support pipelining 
designed garp wire network really adequate arrays larger row garp assumed thesis 
problem garp network shortage resources connecting horizontal vertical wires 
logic block connection path independent normal logic block function 
case instance occupied connections generally minority 
connection horizontal vertical wire direction called turn 
turn logic block sufficient datapaths created configuration tendency datapaths orthogonal connections turns 
values needed inputs addition example operands usually brought straight vertical wires horizontal shifting needed columns 
control circuitry irregular datapaths turn logic block 
arranging routing control circuitry bench mark configurations kind puzzle requiring logic blocks connections placed vertical horizontal relationships conserve available turn resources 
automatic place route tools hard pressed duplicate effort commercial fpgas constrained 
need better wire network garp apparent 
memory bottleneck garp reconfigurable array accesses memory memory buses stretch array rows 
arrays rows access memory problematic reasons larger array implies need bandwidth memory avoid having memory bandwidth bottleneck contrast 
entails multiplying memory buses potentially memory queues 
currently garp architecture permits memory bus matched memory queue crossbar bridging groups 
continue attractive arrangement uncertain 
bigger concern arose garp wire network 
memory buses span entire array array larger impossible transmit value memory bus clock cycle 
memory buses pipelined proposed network wires cease buses intuitive difficult 
solution dilemma provided suggest discussion section concerning array interface memory may need revisited 
programming experience basic garp development tools section create benchmark configurations 
tools get job done provide especially attractive programming environment writing software high level language 
describing configuration primitive level garp configuration assembler configurator little laborious coding normal assembly language considered labor resort 
simplest garp configurations took day create debug took days 
better garp tools constructed task easier question may 
better tools creating configurations hand high list priorities project 
investigate compiling high level language hybrid machine callahan created compiler garp 
automatically chooses kernels program implement reconfigurable array creates kernels integrates rest pro gram compiled garp main mips processor 
callahan compiler translates chosen kernels configuration descriptions fed previous low level tools way compilers invoke assembler final compilation stage linking 
compiler development complete programs tested far 
program wavelet image compression table summa performance program compiled garp ultrasparc comparison purposes chapter 
table shows able eke speedup garp relative ultrasparc 
expectation garp compiler match performance possible hand coded configurations 
compiler distinct advan tage able consider program loops reasonably done hand space minutes days 
full extent performance achievable compiler remains seen 
results turn far better expected difficulty programming garp continue weakness system 
loop number percentage mhz mhz number executions total time sparc garp ratio ms ms total loops ms ms code ms ms total ms ms table results compiling wavelet image compression program ultrasparc garp callahan 
garp compiler extracts loops implementation reconfigurable array 
execution times loop combine invocations loop 
time percentages respect ultrasparc taken default system 
chapter summary contributions main contributions thesis investigation basic issues integrating reconfigurable unit tra ditional general purpose processor 
recommended reconfigurable unit attached chip coprocessor outside immediate processor pipeline geared executing program loops independent path memory 
implications cache stalls context switching virtual memory page faults design addressed 
evaluation certain reconfigurable hardware parameters granularity preferred arithmetic style bit serial bit pipelined bit parallel impact reconfigurable unit efficiency 
bit pipelined arithmetic faster operations additions multiplications bit parallel forms robust handling wider range operations require fewer register bits data pipelining 
support building multipliers reconfigurable hardware considered assuming fast carry chains embedded reconfigurable hardware additional hardware support input adders allows denser multipliers major sacrifice delay chip area 
detailed specification garp prototype combined processor reconfigurable architecture responding previous issues 
garp design fully adapt reconfigurable computational unit conventions standard general purpose systems 
reconfigurable hardware garp fixes clock re configurable array supports notion logical array clock steps separate real time 
fairly novel control blocks edge reconfigurable array give array control memory accesses 
study potential vlsi implementation garp including ideas configuration cache effect logic block layout 
proposal verify integrity configuration loading external memory believed innovation 
study demonstrates feasibility implementing garp estimates area clock speed 
test fitness garp design benchmarking assortment example applications 
execution times garp measured comparable ultrasparc showing impressive garp advantage certain problems 
applications garp determined faster ultrasparc factors respectively 
benchmark results brief analysis garp effectiveness different types applications 
statistics extracted benchmark configurations may help design garp reconfigurable units 
things statistics show arithmetic functions frequently table lookup functions straight connections single wire account quarters communi cations logic blocks 
retrospective garp highlights weaknesses corrections architecture time 
application niche speedup factors benchmarks high teens times faster des encryption times image dithering exceeding median filter benchmark clear garp reconfigurable unit boon certain applications 
experience benchmarks summarized table page suggests applications successful ample parallelism simple ilp instruction level parallelism 
applications limited ilp run times faster garp ultrasparc 
reconfigurable hardware touted best bit manipulation func tions cryptography compression offered examples 
question fine grained reconfigurable hardware faster bit level operations normal processors garp experienced order magnitude speedups functions arithmetic oriented applications image dithering 
encryption algorithms nature designed maximize dependency original plaintext encrypted form ideally changing bit original causes change half bits encrypted encoding 
called avalanche effect cryptographers maximizing dependencies operations side effect minimizing algorithm parallelism 
encryption method modified parallel expense secure difference cbc modes des encryption algorithm section 
similar property applies compression compression algorithm parallel sacrificing compression quality 
absence parallelism reconfigurable hardware gain speedup improving latency operations 
pure bit manipulation functions lead factor improvement speed shown example des cbc mode 
real algorithms purely bit manipulation 
way hash functions md sha instance include bit additions garp array faster ultrasparc 
consequently hash functions achieve speedup factor garp 
greatest reconfigurable computing come applications bit manipulation tremendous parallelism 
leading example genome dna pattern matching machines built fpgas compared fa cray supercomputers 
fine granularity fpgas allows pack large number small operators needed genome matching exploiting large quantity parallelism inherent problem 
parallelism reconfigurable machines successful 
section program parallelism divided categories ilp inter iteration data parallelism thread parallelism 
reconfigurable hardware freely able exploit forms thread parallelism factor benchmarks selected 
reasons garp array large loop memory access conflicts mul tiple threads difficult arbitrate array finding examples hand tedious 
larger reconfigurable unit topic research examine automatic compilation successful finding simultaneous threads execution move reconfigurable array 
significant technique tested garp run time spe loop invariants 
loop invariant value constant duration loop 
run time specialization generally entails creating template configuration parts changed values known execution 
configuration loaded reconfigurable unit template copied edited mem ory main processor appropriate constants 
run time specialization useful pattern matching problems demonstrated genome pattern matching perle text keyword search fpga board 
technique garp left open exercise 
architectural alternatives rushing adopt reconfigurable unit important recognize may better ways chip area accelerate applications 
research tried measure garp performance proposals relying commercial superscalar processor common baseline comparison 
warranted direct comparisons reconfigurable units alternatives left research 
vector units promising idea studied iram project univer sity california berkeley 
long relegated realm supercomputers vector processors emerging option new quantities transistors accelerate software 
vector units achieve speedups capitalizing exclusively data parallelism 
reconfigurable units get best speedups sources vector processors clear rival reconfigurable computing 
commercial processors begun incorporating vector capabilities form small simd instruc tions vis mmx intel 
potential advantage reconfigurable hardware vector units ability exploit thread parallelism 
reconfigurable hardware better independent loop iterations share significant common subexpressions vector processors find costly share information iterations 
true example image median filter benchmark chapter 
exactly types software better system deferred study 
way building faster compute engine may simply shift bottleneck memory system 
noted garp reconfigurable array grow larger reworking memory interface 
berkeley iram project attentive interface vector unit memory tailoring vector unit expressly take advantage properties memory system 
contrast reconfigurable computing community coherent model memory 
reconfigurable systems adopted ad hoc memory banks requiring explicit partitioning data separate banks 
attempts automate partitioning experience shown hard problem compilers solve 
general purpose platform better model needed compatible high level languages compilers 
programming challenge challenge programming reconfigurable devices serious obstacle 
cre ating configurations hand difficult programming assembly language due limitations development tools actual hardware 
provide better programming environment experimental compilers list developed nonstandard variants high level language usually version compilers accept pure standard input 
garp compiler created callahan section standard compilers described jantsch peterson 
luk adapt vectorizing compiler techniques reconfigurable hardware probably worth mentioning 
large gap accomplished hand demonstrated far automatic compilation 
clear ers need improved part solution involve making reconfigurable hardware amenable compilation 
date vector processors leverage decades experience vec compilers 
advantage enjoyed vector systems ability scale hardware need software recompiled 
vector operation length executed functional unit steps functional units simultaneously step number functional units 
long vector lengths applications long doubling number functional units vector processor cuts execution time approximately half change software 
recall valuable scaling property exactly obtained vir streaming reconfigurable hardware described section exhibited piperench 
fact piperench targets data parallelism vector processors immediately obvious extent differences re ally matter 
thorough contrasting approaches research topic 
normally garp increasing size reconfigurable unit lead performance increase existing program new configuration generated utilize expanded hardware 
assuming best program compiled high level language compiler original source code recompiled minimum 
maintain top performance processor implementation require collection compiled executables unattractive proposition software suppliers 
old software upgraded newer processors irregularly causing reconfigurable unit perpetual underutilized 
piperench style virtualization solution problem kind just time compilation frequently java programs example 
possible substantial remains done compilers reconfigurable hardware just time compilation seriously contemplated 
outlook told results thesis indicate considerable promise integration reconfigurable device microprocessors 
reconfigurable unit truly familiar object mainstream processors reconfigurable hardware need specifically designed task just clone current fpga chips 
believed garp architecture represents advance direction 
serious shortcomings remain may hinder acceptance device creative remedies 
hoped research continue address issues ultimately clarify reconfigurable computing best model title belongs style computing technology 
bibliography lynn abbott peter athanas luna chen robert elliot 
finding lines building pyramids splash 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
agarwal mike sumit ghosh 
asynchronous approach effi cient execution programs adaptive architectures utilizing fpgas 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
jeffrey arnold 
mapping md hash algorithm napa architecture 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
peter athanas harvey silverman 
processor reconfiguration instruction set metamorphosis 
computer march 
jonathan babb martin rinard walter lee matthew frank rajeev barua saman amarasinghe 
parallelizing applications silicon 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
patrice bertin herv touati 
pam programming environments practice experience 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
jonathan rose 
fpga routing architecture segmentation buffering optimize speed density 
proceedings acm sigda interna tional symposium field programmable gate arrays pages february 
brian box 
field programmable gate array reconfigurable preprocessor 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
duncan buell jeffrey arnold walter 
splash fpgas custom computing machine 
ieee computer society press 
srihari jeffrey seth copen goldstein herman schmit don ald thomas 
managing pipeline reconfigurable fpgas 
proceedings acm sigda international symposium field programmable gate arrays pages february 
timothy callahan john hauser john wawrzynek 
garp architecture compiler 
computer april 
timothy callahan john wawrzynek 
instruction level parallelism computing 
reiner hartenstein andres editors proceedings th international workshop field programmable logic applications vol ume lecture notes computer science pages august 
timothy callahan john wawrzynek 
adapting software pipelining recon computing 
proceedings international conference compilers architecture synthesis embedded systems pages november 
don david lewis 
datapath oriented architecture fpgas 
proceedings acm sigda international symposium field programmable gate arrays pages february 
darren paul franklin stefan berg carl ebeling 
specifying compiling applications rapid 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
andr dehon 
dpga coupled microprocessors commodity ics early st century 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 

architecture design ge fccm ruler derivation 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
carl ebeling darren paul franklin 
rapid reconfigurable pipeline datapath 
reiner hartenstein editors proceedings th international workshop field programmable logic compilers pages august 
carl ebeling darren paul franklin jason stefan berg 
mapping applications rapid configurable architecture 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
greg gent scott smith regina 
fpga custom coprocessor automatic image segmentation applications 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
maya gokhale janice stone 
automatic allocation arrays memo ries fpga processors multiple memory banks 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
seth copen goldstein herman schmit mihai budiu srihari matt moe reed taylor 
piperench reconfigurable architecture compiler 
computer april 
seth copen goldstein herman schmit matthew moe mihai budiu srihari reed taylor ronald laufer 
piperench coprocessor streaming mul acceleration 
proceedings th annual international symposium computer architecture pages may 
paul graham brent nelson 
frequency domain sonar processing fpgas dsps 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
bernard gunther george milne narasimhan 
assessing document rele vance run time reconfigurable machines 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing ma chines pages april 

ultrasparc sparc performance 
microprocessor report october 

ultrasparc rolls target clock speed 
microprocessor report may 
scott hauck 
configuration prefetch single context reconfigurable coprocessors 
proceedings acm sigda international symposium field programmable gate arrays pages february 
scott hauck thomas fry matthew jeffrey kao 
chimaera reconfigurable functional unit 
kenneth pocek jeffrey arnold editors pro ceedings ieee symposium fpgas custom computing machines pages april 
scott hauck matthew thomas fry 
high performance carry chains fpgas 
proceedings acm sigda international symposium field programmable gate arrays pages february 
scott hauck li eric schwabe 
configuration compression xilinx xc fpga 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
scott hauck william wilson 
compression techniques fpga configurations 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing ma chines pages april 

reconfigurable hardware shared resource parallel threads 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
gunter wolfgang 
reconfigurable hardware shared resource multipurpose computers 
reiner hartenstein andres editors proceedings th international workshop field programmable logic ap plications volume lecture notes computer science pages august 
simon haynes peter cheung 
reconfigurable multiplier array video image processing tasks suitable embedding fpga structure 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
walter iii scott mcmillan greg kevin fred keith underwood 
re evaluation practicality floating point operations fpgas 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
christian eduardo sanchez 
compiler fpga custom execution units synthesis 
peter athanas kenneth pocek editors proceedings ieee symposium fpgas custom computing machines pages april 
jeffrey jacob paul chow 
memory interfacing instruction specification reconfigurable processors 
proceedings acm sigda international symposium field programmable gate arrays pages february 
axel jantsch johnny berg ahmed 
case study hardware software partitioning 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
jack jean liang brian karen 
accelerating ir au target recognition application fpgas 
kenneth pocek jef frey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
bernardo jan 
concise compiler driven instruction set accelerator 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
tom ann duncan 
des key breaking encryption decryption xc 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
donald knuth 
fundamental algorithms volume art computer pro gramming 
addison wesley publishing second edition 

reduction latency resource usage bit level pipelined data paths fpgas 
proceedings acm sigda international symposium field programmable gate arrays pages february 
david patterson thomas anderson neal cardwell richard jason benjamin kimberly keeton randi thomas noah katherine yelick 
scalable processors transistor era iram 
computer september 
ronald laufer reed taylor herman schmit 
pci piperench sword api system stream reconfigurable computing 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
dominique 
computing partitions pseudo random bit generator operators fpga systolic array 
reiner hartenstein andres editors proceedings th international shop field programmable logic applications volume lecture notes computer science pages august 
eric david 
run time reconfiguration fpga scanning genomic databases 
peter athanas kenneth pocek editors proceedings ieee symposium fpgas custom computing machines pages april 
li chu 
implementation single precision floating point square root fpgas 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
li scott hauck 
don care discovery fpga configuration compression 
proceedings acm sigda international symposium field programmable gate arrays pages february 
todd cook william johnson 
implementation ieee single precision floating point addition multiplication fpgas 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
wayne luk teddy wu ian page 
hardware software codesign multidimensional programs 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
donald singh 
accelerating dtp reconfigurable computing engines 
reiner hartenstein andres editors proceedings th international workshop field programmable logic applications volume lecture notes computer science pages august 
alan marshall tony stansfield igor jean vuillemin brad hutchings 
reconfigurable arithmetic array multimedia applications 
proceedings acm sigda international symposium field programmable gate arrays pages february 
sally mckee robert kenneth wright william wulf james alan 
smarter memory improving bandwidth streamed 
computer july 
ethan andr dehon 
matrix reconfigurable computing architecture configurable instruction distribution deployable resources 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
takashi olukotun 
quantitative analysis reconfigurable processors multimedia applications 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing ma chines pages april 
matthew moe herman schmit seth copen goldstein 
characterization pa pipeline reconfigurable fpga 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
eduardo sanchez 
fpga hardware implementation generalized profile search online arithmetic 
proceedings acm sigda international symposium field programmable gate arrays pages ary 
ohta hiroaki 
new fpga architecture bit serial pipeline datapath 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
park 
configuration cloning exploiting regularity dynamic dsp architectures 
proceedings acm sigda international symposium field programmable gate arrays pages february 
james peterson brendan connor peter athanas 
scheduling partitioning ansi programs multi fpga ccm architectures 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
rahul michael smith :10.1.1.47.1042
high performance microarchitecture hardware programmable functional units 
proceedings th annual interna tional symposium microarchitecture pages november 
michael brad hutchings 
automated target recognition splash 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
jonathan rose robert francis david lewis paul chow 
architecture field programmable gate arrays effect logic block functionality area efficiency 
ieee journal solid state circuits october 
jonathan rose abbas el gamal alberto sangiovanni vincentelli 
architecture field programmable gate arrays 
proceedings ieee july 
bruce schneier 
applied cryptography protocols algorithms source code john wiley sons second edition 
shirazi walters peter athanas 
quantitative analysis floating point arithmetic fpga custom computing machines 
peter athanas ken pocek editors proceedings ieee symposium fpgas custom computing machines pages april 
singh robert 
accelerating adobe photoshop reconfigurable logic 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
alexandre milo 
variable long precision arithmetic unit design reconfigurable coprocessor architectures 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
steve bob conn architecture issues solutions high capacity fpga 
proceedings acm sigda international symposium field programmable gate arrays pages february 
tse chen 
implementation data encryption standard pro gate array 
proceedings rd international workshop field programmable logic applications pages september 
robert 
digital 
mit press cambridge massachusetts 
jean vuillemin patrice bertin didier mark shand herv touati philippe 
programmable active memories reconfigurable systems come age 
ieee transactions vlsi systems march 
walters peter athanas 
scaleable fir filter bit floating point com plex arithmetic configurable computing machine 
kenneth pocek jef frey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
agarwal lee smith lam athanas silverman ghosh 
prism ii compiler architecture 
duncan buell kenneth pocek editors proceedings ieee workshop fpgas custom computing machines pages april 
markus wayne luk 
pipeline vectorization reconfigurable systems 
kenneth pocek jeffrey arnold editors proceedings seventh annual ieee symposium field programmable custom computing machines pages april 
michael brad hutchings 
dynamic instruction set computer 
peter athanas kenneth pocek editors proceedings ieee symposium fpgas custom computing machines pages april 
michael brad hutchings 
sequencing run time reconfigured hard ware software 
proceedings acm sigda international symposium field programmable gate arrays pages february 
ralph wittig paul chow 
fpga processor reconfigurable logic 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
xilinx 
programmable logic data book 
yamauchi 
sop reconfigurable mas parallel system control data flow compiling method 
kenneth pocek jeffrey arnold editors proceedings ieee symposium fpgas custom computing machines pages april 
zhi alex ye shenoy banerjee 
compiler processor reconfigurable functional unit 
proceedings acm sigda international symposium field programmable gate arrays pages february 
appendix garp architecture garp processor architecture combines industry standard mips processor new reconfigurable computing device accelerate certain compu tations 
shows organization architecture highest level 
core garp ordinary processor supporting mips ii instruction set 
added device called reconfigurable array dimensional array small comput ing elements interconnected network wires 
garp reconfigurable array somewhat resembles field programmable gate arrays fpgas available xilinx altera manufacturers 
computing element reconfigurable array perform simple logical arithmetic operation operands bits size 
larger computations achieved aggregating small elements larger computational circuits 
function array element connections elements determined configuration array loaded direction main processor 
array con figuration changed desired allowing array applied different pieces computation time 
reconfigurable array controlled exclusively program executing main processor 
program execute entirely main processor referencing reconfigurable array certain computations completed faster array main processor 
expected certain loops subroutines programs switch execution temporarily array obtain speed advantage 
instruction cache main processor mips ii external cache dram data cache reconfigurable array external bus internal data bus basic organization garp 
crossbar array memory buses document defines garp architecture detailing garp extensions mips ii architecture 
documentation mips ii architecture 
reconfigurable array described section section covers integration array main processor memory system 
reconfigurable array core reconfigurable array dimensional matrix small processing elements called blocks 
block row known control block rest blocks logic blocks 
number columns blocks fixed 
number rows implementation specific expected 
basic quantum data array bits 
wires organized pairs transmit bit quantities logic blocks operate values bit units 
operations bit quantities generally require logic blocks 
shows array access standard memory hierarchy main processor 
memory buses run vertically rows moving information array 
array execution memory buses moving data memory main processor 
memory accesses control block row logic blocks row extra logic logic blocks bits blocks msb aligned processor data word lsb memory buses extra logic blocks structure reconfigurable array 
addition memory buses array blocks connected internal wire network shown 
internal wiring array independent memory buses 
arrow represents multiple physical wire paths 
transfers limited central portion memory bus corresponding middle logic blocks row 
loading configurations saving restoring array state entire bandwidth memory buses 
memory buses available moving data array blocks internal wire network provides connections blocks 
wires various lengths run orthogonally vertically horizontally 
summarizes available wire paths 
vertical wires communicate blocks column hori wires connect block row row 
connections wire logic block 
logic block includes resources potentially making wire wire connection indepen dent obligations 
addition performing small computation logic block hold bits data registers 
data registers latched synchronously array clock frequency fixed implementation 
relationship array clock main processor clock required intended clocks 
main processor array clock governs progress computation array 
logic block implement function bit inputs 
operations data wider bits achieved adjoining logic blocks row 
construction multi bit adders major functions row aided hardware invoked special logic block modes 
particular fast carry chain runs right left row facilitate large adders comparators execute single array clock cycle 
logic blocks row leftmost block row control block space row operation bits plus logic blocks left right overflow checking rounding control functions extended data widths needed 
shows main data paths logic block 
bit inputs taken adjacent wires derive outputs 
output calculated direct copy input 
output value optionally buffered register bit outputs driven pairs wires leading logic blocks 
logic block registers read written memory buses 
subsections cover core array architecture detail shifts carry memory bus memory bus clocked register logical arithmetic function clocked register dreg vout hout shifts carry simplified logic block schematic 
inter block wire network data paths logic blocks available logic block functions illustrated box 
discussion control blocks memory buses deferred integration array main processor covered section 
internal wire network internal wires run vertically horizontally array moving data tween logic blocks 
wires network grouped pairs carry bit quantities 
pair wires driven single logic block read simultaneously logic blocks spanned pair 
wire network passive value jump wire passing logic block 
internal wires divided groups vertical wires called wires global horizontal wires wires local horizontal wires wires 
wires running horizontally logic block rows global wires local wires 
wires span entire block width array wires nominally span exactly blocks 
wires run vertically come range lengths 
pattern horizontal wires vertical wires vertical horizontal dimensions array symmetric 
asymmetry due preference aligning multi bit operations rows columns 
categories wires described turn 
vertical wires wires column array blocks set vertical wires wires making connections blocks column 
number rows array strictly fixed amount vertical wiring available depends number rows configuration 
illustrates patterns vertical wires configurations rows 
wire spans specific set blocks configured drive wire 
logic blocks spanned wire read wire simultaneously 
configuring vertical wires columns concert multi bit values easily moved array rows 
pair wires nominal length shown tops vertical wires rows 
vertical wires rows 
vertical wires rows 
vertical wires wires arrays various sizes 
boxes represent single column array 
line drawn represents pair wires bits 
wire pair connect blocks spans vertically 
numbers top give nominal lengths different wires 
vertical wires rows 
vertical wires rows 
vertical wires rows 
twisting vertical wires obtain recursive structure 
compare 
note pattern vertical wires row array repeated upper lower rows row array row pattern turn repeated upper lower halves row array 

wires nominally infinite length global vertical wires nominal lengths wires powers 
actual length wire shorter nominal length wire extend topmost row bottommost row 
row array includes wires nominal length wire longer blocks reality 
obviously applies global wires labelled having infinite length 
doubling number rows merits increase number wire tracks seen 
array rows wires nominal length global wire pair wires infinite length 
array rows adds wires nominal length global wire pair 
successive doubling adds new wire tracks global wire pair 
array rows wires nominal lengths global wire pairs 
logic block vertical wire block connect assigned unique index identifies wire logic block 
configuration uses indices specify vertical wires block connects 
assignment indices wires peculiar twisting wires illustrated 
twisting gives vertical wires recursive structure property exploited improve efficacy configuration cache introduced section numbers assigned wires close wire logic block 
closest wire assigned index number closest number 
note twisting wire number change logic block 
assignment indices different logic block 
driver wire 
configurations checked loaded ensure requirement met 
configurations failing test loaded 
global horizontal wires wires vertical wires associated single column array blocks wires exist rows accessible logic blocks rows wires 
horizontal wire read wire driven logic block row wire 
horizontal wire communicate columns horizontal wires rows 
line represents pair wires bits 
full set pairs length wires bit buses span entire width array wires 
wire pair read blocks spans horizontally logic blocks wires 
single row logic block row different column row immediately 
bias favors computations proceed downward row 
wires ones nominally infinite length 
wire driven logic block row wire 
wires configuration driver wire loaded 
shows wires spanning control blocks leftmost column array control blocks examine drive wires section 
local horizontal wires wires remaining wires wires nominal length 
wires wire driven logic block wire read block wire 
shows logic blocks reachable wire wire driven logic block centered wire 
wire categories wires unique limited options choosing logic block drives wire 
row single choice determines unique driver wires immediately row 
illustrates options available row 
default wire row driven center 
alternatively logic blocks reachable wire driven center 
driven center 
driven left shift right 
driven right shift left 
options driving wires row 
wire row driven near left wire wire row driven near right wire 
options driving wires entire row determined control block row 
choice driver wires row concert wire automatically exactly driver 
possible configuration specify driver wire 
logic block configurations principle data paths logic block depicted 
logic block selects bit inputs wires hand performs logical arithmetic function inputs generate output value value optionally buffered internal register driven adjacent wire pairs leading logic blocks 
time original input optionally buffered driven wire pairs 
logic block drive output values simultaneously exactly wire pairs plus wire pairs plus wire pairs 
possible lookup table mode logic block configuration encoding 
bits configuration state needed active block 
mx lookup table mode fields determine logic block function section 
binary binary internal register internal register wire pair wire pair leftmost wire pair rightmost wire pair wire pair wire pair leftmost wire pair rightmost wire pair wire pair wire pair configuration encoding logic block inputs 
inputs identical encodings 
mx suppress latching register output directly latch register cycle output register suppress latching register output directly latch register cycle output register hout hout vout vout output wires output wire pair output wire pair output wires output vout wire pair output vout wire pair configuration encoding logic block registers outputs 
single logic block drive wire pair wire pair wire pair 
logic block drive wire pairs hand drive wire pairs block 
stated previous section logic block drives wire pair pattern row selected control block row 
direction output selected result 
logic block bits internal configuration state determine active configuration block 
configurable elements logic block include sources inputs function performed inputs operation registers destinations outputs 
figures detail encodings logic block configuration state 
shows logic block registers read written memory buses 
path control logic block represented logic block configuration 
transfers memory bus main processor control block array row section 
note logic block function require inputs path completely independent path example route buffer value wires 
available logic block functions ignore input leaving free purpose 
addition selecting internal wires inputs set constant 
supported constant values binary 
binary values provided synthesized cases 
outputs internal registers connected back logic block inputs illustrated register 
notable application feature path buffer input function output extra cycle 
shows input delayed connecting register output function inputs 
conversely path tied register output delay result cycle 
register operate modes 
register buffer automatically latches new value clock cycle 
alternatively register bypassed output case latches written memory bus 
clocked register logical arithmetic function clocked register dreg input completely separate path routing copying 
logical arithmetic function clocked register inputs taken internal registers 
input side bypassed register effectively decoupled logic block 
note implies instance registers examples figures bypassed output cease act buffers 
perspective memory buses bypassed register hold value written updated memory bus 
connecting output register logic block input value latched memory bus immediately logic block function 
demonstrates internal registers holding memory bus inputs way 
register selected buffer written memory bus case memory bus value internal value clock cycle 
value written memory bus subsequently overwritten clock cycle 
gives detailed view logic block internal paths 
clocked register logical arithmetic function dreg clocked register delaying logic block input path 
memory bus register logical arithmetic function clocked register clocked register dreg delaying output path 
register dreg logical arithmetic function values read memory buses latched internal register immediately function inputs logic block 
memory bus memory bus adjacent wire pair vout clocked register logical arithmetic function clocked register dreg adjacent wire pair adjacent wire pair hout wire pair selected control block adjacent wire pair wire pair complete logic block diagram 
adjacent wire pair mode mx table mode split table mode select mode suppresses shifts partial select mode result carry chain mode suppresses carry result triple add mode suppresses shifts carries function mode encodings 
modes bit bit determines shifts carries suppressed 
logic block functions section details computational functions logic block perform 
main inputs function values bits size 
primary output bits 
addition primary ones miscellaneous inputs outputs associated specific logic block functions 
extra connections block nearest leftmost rightmost neighbors support multi bit functions built multiple logic blocks row 
details extra inputs outputs function mode reviewed 
logic block function determined fields active configuration mx lookup table mode fields 
mode mx fields select possible function modes 
mode defined 
modes lookup table 
modes fields choose form initial perturbation corresponding inputs 
table mode table mode basic mode performing simple logical functions shown 
input passes crossbar function table lookup implements arbitrary bitwise logical operation inputs give result 
table mode selected configuration mode field binary 
operation illustrated 
name implies crossbar allows output bits selected independently input bits 
possibilities pass incoming bits unperturbed crossbar crossbar dual input table lookup crossbar crossbar table mode mode 
mx field selects crossbar function bit crossbar functions encoding 
bit bit bit bit interpretation lookup table table mode 
lookup table function takes input bits returns single output bit 
listed underneath table entry pattern input bits corresponding table output 
bits calculated independently function 
duplicate incoming bit duplicate incoming bit swap bits 
configuration field mx field defines crossbar function mode 
bit lookup table specifies arbitrary input logical function shown 
function independently applied high low bits inputs generate high low bits result 
split table mode split table mode just table mode fixed binary 
simple effect allowing bits calculated crossbar crossbar dual input table lookup crossbar split table mode mode mx 
interpretation lookup table split table mode 
forcing causes bits calculated separate input functions 
compare 
separate input functions shown 
usual path logic block affected section input logic block function simply ignored function box 
split table mode chosen mode mx 
select mode select mode implements multiplexor inputs illustrated 
place inputs optionally shifted complemented inverted form perturbed values resulting select inputs follows hout row shift shift shift optional shift invert hout optional shift invert select optional shift invert shift shift shift select mode mode mx 
mode bit set mode mx function shifts assumed 
shift shift zero shift invert functions 
symbol represents logical complement 
function mode suppresses shifts bit 
bit taken bit logic block right regardless mode logic block right 
inputs value hout logic block column row 
value driven wires logic block immediately 
value exception row configuration 
improper binary select mode topmost row configuration 
functions shift invert blocks shown 
bit input optionally shifted left bit resulting bit value shifted optionally complemented 
shift performed bit shift taken high bit input logic block immediate right regardless mode logic block right 
improper depend bit shifted rightmost logic block row 
shifts shift invert blocks forced configuration 
option useful rightmost logic block multi block functions rightmost logic block row 
shifts individual shift invert blocks independently suppressed 
select mode chosen mode mx 
case mode suppresses shifts second mode 
select mode performs table lookups 
configuration lookup table field set constant partial select mode partial select mode ordinary select mode different set values choose shifted inverted mode enabled mode mx 
setting mode suppresses perturbation shifts mode 
ordinary select mode partial select mode restriction value topmost row configuration 
shift shift shift optional shift invert optional shift invert optional shift invert select shift shift shift partial select mode mode mx 
mode bit set mode mx function shifts assumed 
carry chain mode carry chain mode performs logical arithmetic function involving fast carry chain row 
mode 
inputs input ignored 
path exists employed separately see section table mode inputs passed crossbar functions applied table lookups 
results table lookup control carry chain values logically combined carry chain output obtain final result table lookups deliver total bits control carry chain propagate generate signal associated low bit result pair signals associated high bit result 
shows control bits affect carry chain 
propagate bit carry position propagated higher bit position corresponding generate value carry bit position 
propagate generate value ignored carry function may result function recall 
shows carry chain repeats operation carry crossbar crossbar crossbar dual input table lookup propagate generate result function dual input table lookup carry chain carry carry chain mode mode 
mx field selects result function 
mode bit set mode function carry assumed 
bit propagate bit bit bit bit generate bit bit bit interpretation lookup table carry chain mode 
carry propagate generate propagate generate carry zero operation carry chain 
low order carry forced logic block mode 
bit position 
mx carry result functions modes carry chain 
operation lookup tables documented 
input tables propagate table generate table 
table looked twice low bit position high bit position 
carry chain outputs bit value comprising carry bit po sition 
fed result function original propagate generate signals renamed respectively 
result function implements bitwise logical functions chosen mx field configuration 
logic block carry chain mode mode mode 
case forces carry low bit 
second case accepts carry logic block right 
improper depend carry logic block immediate right carry chain mode 
applies particular rightmost logic block row logic block immediate right 
triple add mode complex mode triple add mode perform sum difference inputs 
inputs passed shift invert function carry save addition performed perturbed inputs 
outputs carry save addition index lookup tables obtain carry chain propagate generate signals 
point forward triple add mode identical simpler carry chain mode 
shift shift shift shift carry carry optional shift invert carry dual input table lookup optional shift invert carry save addition propagate generate sum result function optional shift invert carry chain dual input table lookup shift shift shift shift carry carry triple add mode mode 
mx field selects result function 
mode bit set mode function shifts carries assumed 
bit propagate carry bit sum bit bit generate carry bit sum bit interpretation lookup table triple add mode 
table represented bits bits sufficient 
redundancy tables required consistent 
carry save addition performs usual function called sum output calculated bitwise carry output calculated shifted left bit position manner shift invert functions 
shift invert functions shift carry ultimately carry forced configuration mode field 
triple add mode selected mode 
case forces shifts carry second case accepts logic block right 
mx field specifies result function 
carry chain mode improper depend carry shift carry logic block immediate right triple add mode 
likewise improper depend shifts carries rightmost logic block row 
internal timing delays array defined terms sequences fit array clock cycle 
sequences permitted short wire simple function short wire simple function long wire function carry chain short wire function 
sequence assumed require multiple clock cycles 
short wire local horizontal wire wire vertical wire length 
simple function table mode function traversal independent path logic block 
cycle values latched logic block registers affecting rules 
combinatoric circuits necessary latch intermediate results registers clock cycle latches desired achieve pipelining 
maximum allowed path delay registers array clock cycles 
integration array main processor loading execution array configurations control main processor 
instructions added mips ii instruction set purpose including ones allow processor move data array processor registers 
configurations data transferred array memory buses run entire array 
array execution array initiate reads writes memory memory buses intervention main processor 
memory accesses coordinated control blocks array row 
array memory accesses go memory hierarchy main processor including level data cache 
array available relatively large fast memory store automatically kept consistent memory accesses processor 
addition demand random accesses memory array memory queues provide enhanced support sequential memory accesses 
processor control array main processor instruction set extended new instructions controlling array 
full list added instructions documented table section 
array clock counter array execution governed countdown counter called array clock counter 
clock counter nonzero decremented array clock cycle 
array clock counter zero latching array registers disabled effectively stopping array 
configuration loaded array clock counter zero 
loading configuration main processor set array clock counter nonzero start array executing number clock cycles 
counter set instruction 
various processor instructions able set counter addition functions 
defined relationship array clock rate main processor executes instruction 
ensure proper synchronization processor instructions interact array stall clock counter reaches zero performing function 
clock counter provides mechanism array calculations interlocked subsequent dependent processor instructions 
number clock cycles needed calculation may known advance array ability halt function complete forcibly zeroing clock counter 
array configured discussed functions control blocks section 
possible processor halt array time zeroing clock counter 
instruction performs function covered connection context switches section 
array clock counter bit register significant bits count 
significant bit sticky bit set remains set entire counter forcibly zeroed array processor 
array halted entire bit counter zero significant bit acts infinity bit 
latency array calculation entirely data dependent processor set significant bit clock counter start array operating indefinitely 
array zero clock computation completes 
processor ready receive array results array done instruction attempting retrieve data array interlock usual counter zeroed array 
loading configurations loading array configurations control instructions executed main processor 
loading configuration configuration active configuration controls behavior array 
configuration active array time 
loading new configuration replaces previous 
logically configuration loaded time practice expect implementation incorporate array configuration cache loaded configurations process loading configuration necessarily involve transferring external memory time 
processor clock cycles needed load configuration configuration cache 
configuration cache expected close full aggregate bandwidth memory buses load external memory 
smallest configuration row configuration fill exactly number contiguous rows 
configuration loaded uses entire array rows unused automatically inactive 
topmost row configuration row number default subsequent rows labelled increasing integers 
active configuration changed array clock counter zero array halted 
instructions load configurations stall waiting clock counter zero performing function 
simplest instruction loading configurations takes single register operand giving address configuration stored memory 
bytes bits address interpreted count number rows configuration 
row count bytes block control blocks logic blocks configuration starting bytes row row 
configuration row contains bytes control block followed logic block leftmost column rightmost logic block column 
addition loading configuration array making active initializes registers logic blocks zero 
time configuration active copy memory changed may need reloaded time 
reloads caused context switches multitasking system example 
furthermore inactive configuration modified memory explicitly reloaded changes may take effect earlier unmodified version configuration cache 
attempt load modified configuration previous version definitely cleared cache 
instruction performs function 
may executed configuration running 
instruction allow state remain logic block registers configuration 
complex pair instructions supports configura tion overlays purpose 
instruction reserves group rows subsequent configurations overlayed 
displaces currently active configuration zeros registers array configura tion loaded instruction 
instruction loads configuration previously allocated group rows 
overlayed configuration may extend rows allocated need fill allocation may loaded starting row allocated row 
register state allocated space preserved overlay 
overlay smaller allocated space rows overlaying configuration active 
inactive rows maintain data state subsequently active 
instruction takes operand pointer bit word memory value number contiguous rows allocate 
logically indirection pointer unnecessary register operand just easily specified number rows directly pointer intended identifier internally cache 
execution precedes repeat sequence overlays pointer operand order maximize cache 
completeness active configuration 
array activity disabled time configuration loaded 
transfering data array processor collection instructions copying data pro cessor register file registers array logic blocks 
single logic block register bits data transfers gang contiguous logic blocks row bits data copied time 
individual transfer copies combined registers combined registers logic blocks 
transfer operation array row number specified array source target registers 
parameters row number selection encoded constants instructions instructions obtain additional register operand 
row logic blocks individual transfer operation touches corresponding full bit word 
set logic blocks read written fixed particular instruction 
instructions copy middle logic blocks columns inclusive 
variant instructions allow access logic blocks extreme left right ends row 
rightmost logic block associated significant bits transferred leftmost logic block associated significant bits 
move garp array instruction transfers bit word processor 


set logic blocks read written various processor instructions 
move garp array instructions copy bit word processor register contiguous set logic block registers array row 
move garp array instructions transfer word opposite direction 
logic block registers bits logic blocks correspond bit data word 
leftmost block row control block containing visible data registers 
register registers middle logic blocks fixed row 
row number choice registers encoded constants instruction 
move garp array instruction transfers opposite direction array processor register 
instructions similar array row number register choice instruction second register operand supplies parameters 
access logic blocks leftmost rightmost columns row pro vided variants 
instructions access columns identical 
row variants read write bits columns 
column left contains control blocks visible data registers 
instructions unusual transfer bits 
significant bits source processor register ignored direction zeros significant bits destination processor register 
processor copy array array clock counter zero 
clock counter nonzero data transfer instruction stall clock counter zero 
instructions set clock counter small constant performing transfer 
memory queue control processor instructions load store state array memory queues 
details instructions deferred section array memory queues covered 
saving restoring array state information active configuration stored read registers pointer argument current array allocation 
bit word address gives number rows allocated 
array allocation separate pointer argument 
pointer configuration memory argument 
row offset argument 
active configuration loaded value zero 
instruction retrieve values processor register 
context switch occurs array active possible suspend array save state computation resumed time 
step suspending array execute instruction step copies clock counter processor register zeros counter 
current allocation configuration obtained array control registers logic block registers read instructions described 
state array memory queues saved instruction 
remaining internal state array including status pending memory reads written memory special instruction 
resuming array computation requires array allocation restored executing previously saved value 
active configuration reloaded executing values saved 
logic block registers restored simple instructions reloads state array memory queues 
logic block registers restored read back internal state saved 
final step resuming array restore array clock counter value originally returned 
reading back array internal state ensures com propagations array time complete tion logic block register values 
load array configuration rt rt loads configuration memory active 
register rt gives starting address configuration memory 
array clock counter nonzero instruction waits clock counter fall zero 
array reads progress cancelled existing array allocation released 
sufficient space allocated array hold specified configuration configuration loaded active 
registers newly allocated space zeroed 
instruction equivalent sequence instruction followed 
copy configuration memory change flush configuration instruction executed address 
reset array resets array releasing existing array allocation 
array clock counter nonzero instruction waits clock counter fall zero 
array reads progress cancelled existing array allocation released 
flush array configuration cache rt rt flushes configuration cache configuration array allocation address rt 
table added instructions part 
allocate array space rt rt allocates space array configuration loading configuration 
register rt gives address word memory specifying number rows allocate 
array clock counter nonzero instruction waits clock counter fall zero 
array reads progress cancelled existing array allocation released 
new allocation put effect array rows inactive 
registers newly allocated space zeroed 
memory word pointed register rt change flush configuration instruction executed address 
load array configuration overlay rt rd count rt rd rt rd clock count loads configuration memory previously allocated array space preserving array data state 
register rt gives starting address configuration memory register rd gives allocated row load overlaying configuration 
array clock counter nonzero instruction waits clock counter fall zero 
specified configuration loaded active array clock counter set bit unsigned integer constant encoded instruction 
configuration loaded extend outside current allocated array space 
existing array allocation remains effect rows overlaying configuration active 
contents registers allocated array space unaffected operation 
copy configuration memory change flush configuration instruction executed address 
table part 
copy word array rt reg count rt reg rt row number clock count copies value register rt middle logic blocks fixed array row 
array row number encoded unsigned integer constant instruction 
instruction bit concatenation sixteen bit registers columns destination copy 
concatenation sixteen registers columns destination 
column receives significant bits value copied column receives significant bits 
array clock counter nonzero instruction waits clock counter fall zero 
copy performed clock counter set bit unsigned integer constant encoded instruction 
reg argument assembler accepts syntax zn dn array row number expressed decimal integer numeral 
example denotes registers array row 
count argument integer constant 
count defaults zero 
copy word array rt reg count rt reg rt row number clock count instruction identical direction copy reversed 
table part 
copy word array variable row rt rd rt rd copies value register rt middle logic blocks array row specified register rd instruction similar row number field value register rd follows row number significant bit rd bit destination copy concatenation sixteen registers columns specified row significant bit rd destination concatenation sixteen registers columns 
column receives significant bits value copied column receives significant bits 
array clock counter nonzero instruction waits clock counter fall zero copy performed 
copy word array variable row rt rd rt rd instruction identical direction copy reversed 
table part 
copy word array variable row low columns rt rd rt rd instruction identical destination copy columns specified row 
column receives significant bits value copied column receives significant bits 
copy word array variable row low columns rt rd rt rd instruction identical direction copy reversed 
copy word array variable row high columns rt rd rt rd instruction identical destination copy columns specified row 
significant bits source register rt copied 
significant bits rt ignored 
column receives significant bits value copied column receives significant bits 
copy word array variable row high columns rt rd rt rd instruction identical direction copy reversed 
significant bits destination register rt zeroed 
table part 
load array queue control rt rd rt rd loads control registers queue specified register rd bytes address register rt 
value register rd integer range inclusive indicating array memory queues 
details memory queues queue control registers section 
array clock counter nonzero instruction waits clock counter fall zero load performed 
store array queue control rt rd rt rd stores control registers queue specified register rd bytes starting address register rt 
value register rd integer range inclusive indicating array memory queues 
array clock counter nonzero instruction waits clock counter fall zero store performed 
increase array clock counter rd rd adds value register rd array clock counter 
addition performed modulo carry significant bit occurs unsigned overflow significant bit clock counter set 
table part 
array rt rt zeros clock counter halting array execution 
register rt gets value counter zeroed 
assembler allows destination operand omitted case rt set mips pseudo register zero register 
copy word array control register rt zd rt zd copies array control register zd processor register rt 
bit zd field integers version register format implementation revision number bytes writes memory 
constant implementation revision 
pointer argument current array allocation 
pointer configuration memory argument 
row offset argument zero active configuration loaded 
assembler accepts zd notation 
table part 
save internal array state rt rt saves internal state array memory address register rt 
internal state includes particular status pending reads memory 
amount memory needed store saved state discovered reading control register instruction 
array clock counter nonzero instruction waits clock counter fall zero store performed 
restore internal array state rt rt loads internal state array memory address register rt 
instruction stalls long ensure signals array time settle assuming maximum path delay array clock cycles 
array clock counter nonzero instruction waits clock counter fall zero load performed 
table part 
rt rt rt rt rt rt rt rt rt zd rd rd rd rd rd rd rd table list added instructions encoding order 
rt rt rt rt rt rt rt rt rt table continued 
rd rd rd row number row number clock count clock count clock count array control blocks control blocks left row help interface array hand processor memory 
functions control block perform include zero clock counter halting array execution interrupt processor initiate memory access arbitrary address initiate read write array memory queue load store data memory access logic block registers 
active configuration determines functions control block perform 
shows general encoding configuration control block 
logic block control block configuration bits bit inputs taken adjacent wires 
inputs control subset functions listed mode control block configured 
regardless mode bits input reduced control signals illustrated figures 
individual bit input reduced single bit discarding bits logically ing bits 
resulting signal gate corresponding signals construct control signals 
control signals generated directly inputs acts enable signals 
inputs fixed binary constant logic block 
control block input come local horizontal wire wire control block 
control blocks outputs vertical wires associated column control blocks 
aside fewer options encoding control block inputs identical logic blocks 
timing purposes inputs constant come directly logic block register connecting wire control block illustrated 
mode specific fields binary binary leftmost wire pair rightmost wire pair leftmost wire pair rightmost wire pair wires driven right shift left wires driven center wires driven left shift right mode function processor interface memory interface control block configuration encoding 
mode adjacent wire pair adjacent wire pair adjacent wire pair reduce reduce reduce reduce mode specific control signals control block signals 
wire control block logic block register adjacent wire pair clock cycle reduction functions 
signal latched upstream register signal observed control block control block input come directly local horizontal wire logic block register row row 
enable zero clock counter interrupt processor configuration encoding control block processor interface mode 
logic block register supplies input control block way known upstream register control input 
processor interface blocks processor interface mode control block perform simple actions con nected main processor 
format processor interface configuration 
input allows array zero clock counter input possible array interrupt processor 
inputs array clock counter zeroed current array clock cycle halting array execution 
main processor forced take interrupt 
note array execution directly affected processor interrupts 
memory interface blocks memory accesses initiated reconfigurable array direct processor intervention 
memory access proceeds steps initiate step starts access providing memory address transfer step transfers data fig ure 
address read registers selected row special address bus runs parallel memory buses mentioned 
contiguous words read written memory access word size selectable bits 
word transferred separate memory bus 
memory writes initiate transfer steps occur clock cycle 
reads initiate step necessarily precedes transfer step 
demand access memory initiated array clock cycle multiple memory accesses may different stages progress time 
type delay sizea enable initiate memory access load store registers bus direction transfer load store bus configuration encoding control block memory interface mode 
details various fields covered figures 
initiate step address read address bus 
registers transfer step words transferred memory buses 
registers registers registers registers steps memory access initiated array 
array sees memory hierarchy main processor including data caches 
misses level data cache may cause array execution stalled data fetched external memory 
reduce cache misses array perform prefetching accesses merely load data cache 
array memory accesses may generate page fault traps discussed 
memory interface mode control block ability initiate memory access participate transfer data 
shows format memory interface configuration 
initiate transfer phases controlled independently configuration fields associated initiate step separately concerned transfer step 
highlights parts memory interface configuration control initiation memory accesses 
actual memory access controlled type delay sizea enable initiate memory access read write prefetch type demand access read prefetch cache allocate demand access read write cache allocate demand access read write cache allocate delay cycle cycles sizea bits bits bits aligned address ignore bottom bits possibly address demand access word demand access words demand access words memory interface configuration fields associated initiate step demand memory access 
signal direction access read versus write determined demand access memory initiated 
time access read write prefetch depending configuration 
control block initiates demand memory access contents registers logic blocks columns row sent address bus provide bit address memory system 
configuration fields control various memory access 
sizea fields choose word size number words access respectively 
largest possible access contiguous bit words smallest single bit word word size number words power ranges 
access read write prefetch 
type field configuration determines non read memory access write prefetch cache cause data brought cache 
prefetches performed solely purpose bringing data cache sense cache allocation misses case 
normal reads writes may configured cache allocation misses 
access word size larger byte address may aligned natural word size boundary 
configuration chooses possibilities significant bits address ignored memory access performed specified address 
number bits ignored dependent word size bit word size bits bits word size bits 
delay field configuration determines perceived delay read accesses 
field ignored writes prefetches 
timing details memory accesses covered section 
number control blocks configured memory interfaces control block initiate memory access array clock cycle 
transfer step performs actual movement data simultaneously initiate step case writes data read memory 
shows memory interface configuration fields associated transfer step 
input control block decides clock cycle transfer row occurs cycle 
signal indicates direction transfer initiate step 
fields configuration determine enable load store registers bus load store bits bits bits load store registers load store registers bus bus bus bus bus bus memory interface configuration fields associated transfer step memory access 
clock cycle control signals upstream registers initiate write memory address registers row store registers memory buses data registers rows timing memory write executed array 
write occurs active cycle control signals applied see text 
clock cycle initiate signal upstream register initiate read memory address registers row cycles delay load signals upstream registers load registers memory buses causes data latched registers rows timing memory read executed array 
memory bus data written loaded registers written loaded number bits write load 
bits transferred registers columns row written read selected bus 
bits transferred columns affected registers columns involved 
likewise bits transferred columns participate operation 
word words transferred memory bus dedicated transfer 
word memory address copied bus 
access involves word subsequent words copied buses order 
example memory access words involves buses bus word address memory bus contiguous word memory 
initiation memory read words specific number array clock cycles elapsed discussed buses contain values read memory 
time control blocks rows values latched signal transfer step 
writes initiate transfer steps signaled simultaneously 
exactly word driven buses 
shows timing write 
conceptually write occurs clock cycle control signals applied 
clock counter zeroed clock cycle write signaled write occur clock counter subsequently nonzero value continuing execution configuration 
current configuration resumed write occur despite having initiated 
shows timing read 
reads delay field memory interface configuration specifies number array clock cycles data delayed 
great actual latency read operation execution array stalled waiting read return 
implementation stall array sufficiently give data returned specified number array clock cycles 
array memory queues able request memory accesses directly array available memory queues increase performance sequential accesses 
array reads writes queue directly memory supply address information access 
memory queue programmed main processor information advance instruction 
shows format bytes control information loaded memory memory queue controller instruction 
corresponding instruction writes back information memory format facilitate context switches 
demand memory accesses memory queue programmed transfer words request 
demand access words matched buses arbitrarily word necessarily transferred bus bytes loaded queue controller assign bus word 
configuration control block allows initiate queue access variation demand memory accesses seen 
access initiated 
additional information encoded configuration queue number access 
direction transfer read write determined queue decided input control block demand accesses 
address bus queue accesses 
transfer step queue access identical demand access keeping mind association buses words fixed set queue controller 
ultimately queue access affect demand memory access address maintained queue controller recall 
access memory queue stored address incremented contiguous byte read written 
instruction writes queue control record updated address properly restore state queue time executed 
figures show timing queue write queue read respec tively 
timing queue write indistinguishable demand memory write queue read appears demand read delay fixed clock cycle 
demand memory write queue write committed array clock size address bus queue disabled queue enabled read write cache allocate cache allocate bus bus size bits bits bits word access words access words access word bus word bus word bus word bus format queue control record 
bus type enable initiate queue access type queue access queue queue queue memory interface configuration fields associated initiate step memory queue access 
compare 
clock cycle control signals upstream registers initiate write memory queue store registers memory buses data registers rows timing write array memory queue 
write occurs active cycle control signals applied see text 
clock cycle initiate signal upstream register initiate read memory queue load signals upstream registers load registers memory buses causes data latched registers rows timing read array memory queue 
equivalent demand memory read fixed delay clock cycle 
cycle initiation write control block 
clock counter zero cycle queue write initiated array execution resumed write occur 
queues accessed array clock cycle simultaneously initiation new demand memory access cycle 
possible achieve independent memory accesses clock cycle array 
memory bus transfer word cycle total maximum bit words accessed cycle 
appendix garp application notes garp features 
appendix contains notes program common operations single bit operations garp array bit granularity values passed logic blocks bit pairs operated logic block functions bit values 
simple true false boolean values conveniently encoded array binary 
table mode logic block function operates bit positions identically arbitrary input boolean functions programmed output emerging form 
crossbar permutation boxes permit inputs selected individual source bits duplicating high low bit input bit positions input passed lookup table 
shifts unsigned shifts constant distance easily accomplished horizontal wires rows 
upper row drives value shifted wires lower row reads shifted bits 
values blocks transmitted bit pairs suffices unsigned shifts distance number bits 
shifted value immediately available operand lower row 
value shifted odd number bits lower row usually responsible performing final shift bit 
shift invert permutation boxes partly designed job accessible logic blocks second row certain modes select modes triple add mode 
modes table modes carry chain mode crossbar boxes pick correct bits logic block functions encoded independently high low bit positions 
signed left shifts indistinguishable unsigned left shifts 
signed right shift hand replicate original sign bit number bit positions 
done shift invert permutation boxes source sign bit duplicated high low bits boolean values previous section 
signed right shifts depend crossbar boxes get correct places 
cases value shifted different distances input row 
example addition operation take value row shifted left bits input shifted left bits input compute value 
technique multiplication covered section 
variable shifts done garp array series multiplexors choosing constant shifts 
complete variable left shift bit value optionally shift bits row shift bits second row shift bits third row 
stages corresponds bits shift amount implemented single row logic block select mode horizontal wires 
select control input inverted shift invert box value binary corresponds accepting value row shift 
carry chain garp array carry chains function expressible terms carry chains propagate generate control signals 
simple example test integers equal 
carry chain progresses right left carry chain value defined mean integers equal significant bits position 
pair corresponding bits result propagate generate table configuration carry chain comparison value result result propagate generate table configuration carry chain comparison carry position forced indicate values unequal 
corresponding bits carry duplicate carry integers equal point depends entirely equal previous bit position 
corresponding bits original carry significant bit position propagate side unchanged 
table shows propagate generate tables programmed get desired effect logic blocks carry chain mode 
final result exactly carry significant bit position false true small modification configuration illustrated table changes comparison case corresponding bits carry forced true false depending greater bit value 
corresponding bits point depends true bits right position 
final result comparison exactly carry significant bit position 
propagate generate settings calculating addition table 
result output represented propagate appears garp documentation result function 
subtraction implemented variant addition making rule result propagate generate table configuration carry chain addition value result propagate bitwise logical complement integer simple fact derive notation denotes bitwise logical complement subtraction accomplished complementing input adding lastly complementing result 
complement input effected configuration propagate generate lookup tables result complemented simply choosing result function adding subtracting terms triple add logic block mode supports direct addition terms reducing inputs carry save adder feeding results carry chain summing 
terms negated tricks similar just shown subtraction 
simplest case negated terms 
clearly scheme get 
triple add mode complement input achieved programming shift invert permutation box complement invert input 
theorem case just term negated subtle requires theorem proof theorem gives way compute feed carry save adder resulting sum carry terms sum adding sum carry usual program rest logic block calculate sum carry exactly manner done previous section obtain result multiplication practice multiplications constants fortunate multiplying constant usually efficient general multiplication variables 
variable factor small bits constant factor large problem turned lookup table variable factor supplying index table 
multiplying constant best done tree input adders discussed section 
calculate example suffices sum value driven horizontal wires row row immediately perform necessary shifts adds appropriate configurations triple add mode selecting proper bits horizontal wires 
multiplications larger constants just require adders rows row duplicates variable factor horizontal wires logic block paths row obtain necessary shifted partial products add 
breaks odd integers fewest power terms sum integer 
integers observe odd integer number terms integer form instance noted 
pattern visible easy determine smallest multiplier constant requires terms number array rows number smallest multiplier array rows summed fit stated way known multiplication constant fewest power terms sum odd integer 
pattern constructed centered exact powers observe 
example done array rows 
shows possible multiply terms values larger multiplied just terms 
multiplication instance requires row 
factor constant multiplication takes little 
fig ure shows physical organization garp array multiplier unsigned bit variables generating bit product 
example multiplies multi bits clock cycle iterations clock cycles complete entire bit multiplication 
additional cycles latency pushes total time multiplication clock cycles 
multiplier shifter shifts multiplier bits cycle 
partial product selectors determines product bits multiplier result trivial logic block logic block partial product selector partial product selector sum partials accumulated sum partials latch route multiplier shifter layout garp array multiplier unsigned bit variables calculating bit product 

separate set logic blocks calculates partial product selectors 
value change pair factors 
partial product selector primarily multiplexor inputs configured partial select mode provided purpose 
rest pieces merely add partial products 
variable multipliers constructed principles 

