predicting parallel applications performance non dedicated cluster platforms dipartimento di informatica universit di torino corso torino italy email di address problem performance prediction parallel programs executed clusters heterogeneous workstations resource contention 
develop methodology construction performance models analysis allows estimation execution time programs 
timed petri nets represent behavior parallel programs contention model queueing theory quantify effects resource contention execution time application processes 
methodology demonstrated construction model example program validate predictions measured execution times obtained executing program different clusters workstations 
clusters workstations increasingly costeffective parallel computing platforms effective exploitation requires consideration research problems addressed context parallel computing 
problems development performance evaluation methods fundamental importance design development applications able take advantage platforms require availability accurate predictions performance 
instance information essential assist scheduler find effective process allocations 
performance evaluation techniques proposed classical parallel programs clusters execution platform consider effects typical features computing systems heterogeneity resource contention may dramatically affect performance applications executed 
parallel systems computation communication resources cluster typically het partially supported eu ct match project italian murst 
appear proc 
th acm international conference supercomputing july melbourne australia time required execute computation complete communication depends machine activities take place 
machine may shared users utilize resources execute stream background jobs reducing amount computing power available parallel programs 
similar considerations apply communication network presence background traffic reduces bandwidth available parallel programs 
net effect contention increase execution times parallel programs executed cluster 
order obtain accurate performance predictions necessary quantify effects heterogeneity importantly resource contention behavior parallel programs 
quantification general difficult random nature phenomena generating contention 
matter fact amount cpu time required background job cpu demand time elapsed consecutive job arrivals interarrival time fixed quantities vary randomly probability distributions 
similar considerations apply background traffic communication network 
randomness introduced scheduling algorithms manage simultaneous requests resource usage 
methodology construction performance models accurately predict average execution time parallel programs executed cluster platforms characterized presence heterogeneity resource contention 
methodology behavior parallel program modeled means timed petri net model representing various processes interactions 
effects cpu contention quantified means parameter expansion factor expresses slow experienced parallel processes contention 
multiclass queueing model estimate expansion factor various workstations cluster models family particularly suited characterize random contention phenomena 
mix empirical analysis analytic modeling represent network contention effects 
development performance models class programs systems addressed authors 
berman focus development cpu contention model expansion factor assume number background jobs competing parallel process workstation change entire execution process 
general case random fluctuations number jobs expected consequence model may unable deliver accurate predictions 
yan propose prediction methodology cpu contention model combined network contention model 
cpu contention model allows fluctuations number background jobs assumptions interarrival times cpu demand background jobs geometrically distributed background jobs preemptive priority parallel processes parallel tasks guaranteed receive time quantum consecutive user requests 
assumptions required permit analysis model seldom satisfied real cases distributions typical background jobs larger variance scheduling algorithms workstation operating systems guarantee process receive cpu specified time 
schopf berman randomness introduced resource contention modeled representing computation communication times random variables normally distributed 
assumption probability distribution activities may satisfied practice 
contrast proposals restrictive assumptions behavior operating systems running workstations probability distributions background load traffic 
possible analytical solution queueing model estimate expansion factor computed means technique theory usable system background load satisfy certain conditions practice able yield reasonably accurate predictions general situations conditions hold experimentally observed 
organized follows 
section describes assumptions section methodology 
section illustrates application methodology performance analysis parallel scientific application matrix multiplication 
predictions obtained model application validated execution times measured various experiments artificially loaded machines cluster background job stream violating conditions required application 
section concludes outlines research directions 
environment focus coarse grain message passing parallel applications 
assume applications cpu bound activity negligible amount computation perform 
assume programmed non blocking send blocking receive paradigm extension methodology blocking send blocking receive paradigm trivial computational environment cluster possibly heterogeneous workstations wm connected local area network 
workstation cpu schedules processes locally independently form priority round robin policy various versions unix operating system executes process parallel program consideration may shared users submitting jobs independently 
assume instant parallel program execution cluster main memory workstation large accommodate working set parallel process executes 
assume communication network carries traffic generated workstations cluster parallel program jobs executed users traffic limited burstiness 
performance prediction methodology performance prediction methodology construction timed petri net tpn model parallel application 
timed petri nets represent extension basic petri net formalism possible specify timing information associating firing delay transition different possible variants class firing delays constant quantities contrast extensions delays random variables 
assume reader familiar timed untimed petri nets detailed description formalisms 
tpn model parallel application executed particular workstation cluster carried schematically indicated fig 
boxes denote methodology steps ovals represent outcomes 
untimed petri net model representing duration basic activities processes allocation untimed pn model construction computing system performance characterization timed petri net model construction tpn model untimed pn program source code contention indicators perfomance prediction methodology ior processes parallel application interactions constructed starting program source code 
untimed model subsequently transformed timed associating transitions durations various communications computations represent 
durations depend characteristics computing system processors network particular processes workstations allocation amount resource contention may obtained result system characterization step 
system characterization involves distinct activities determination performance delivered various resources absence contention performed means various available techniques determination characteristics background job stream traffic may carried means standard workload characterization methodologies :10.1.1.53.6631
tpn model fully specified analyzed order estimate execution time application particular allocation chosen 
fig 
various steps depicted different colors indicate system characterization step performed forall model construction performed time new program considered new allocation requires redefinition parameters model 
modeling application behavior automatic construction petri net models parallel programs widely studied literature 
usually petri net model message passing parallel program constructed separately modeling process merging submodels single order represent communications processes 
model process obtained merging submodels segments portions computation included consecutive communication statements order occur process code 
th segment process modeled subnet fig 
transition represents computation carried segment place models input message buffer weight arc connecting places corresponds number messages segment receive computation start 
segment require message instance delimited send operations place arc 
place snd snd pn model segment 
marked token control passed segment place marked control passed transition fires 
subnet gamma snd gamma pw represents communication involving message sent segment process pw messages sent subnets loops body contains segments modeled depicted fig 
provided number iterations know priori loops type 
process computation reaches loop place belonging subnet corresponding segment loop body marked tokens single case fig 

time iteration completed segment loop executed token added place place contains tokens transition models completion loop may fire 
duration transition set firing corresponds logical action computation 
role place enforce execution single iteration time 
representation loops iteration count unknown priori loops loops internal segment represented explicitly 
pn model loop involving segments 
type possible complex discussed focus programs containing deterministic loops surveyed represent majority parallel scientific applications 
initial marking places marked token places empty 
modeling computation times model execution time various segments associate transition representing segment delay equal amount cpu time requires 
delay depends amount computation segment perform cpu speed workstation executed presence processes competing processor cpu demand 
assuming process allocated workstation wk delay transition computed td wk theta rk td wk execution time segment machine wk dedicated mode rk rk expansion factor workstation quantifies effects cpu contention due presence background load wk dedicated execution times td td wm segment workstations cluster obtained computing td wk particular workstation wk eq 
calculate td wx machine wx td wx ae ae delta td wk ae ae denotes power weight workstation quantity relating cpu speed fastest workstation system 
smaller weights correspond slower machines fastest machine wf ae 
segment portion sequential code standard approaches sequential programs compute td wk 
compute power weights workstations proceed discussed execute serial benchmark dedicated mode machine calculate ae ae tf tf denote execution time benchmark wf respectively 
course order obtain accurate estimations ae benchmark computational nature similar program consideration 
discussion issue scope see details 
discuss compute expansion factors various workstations cluster 
anticipated section expansion factor workstation estimated means multiclass queueing model consisting server represents cpu queue holding jobs waiting service scheduling discipline processor sharing 
background load represented open job class characterized suitable probability distributions job interarrival times cpu demand 
want quantify effects background load segment parallel application represent generic segment particular 
segment modeled closed job class containing job system 
expansion factor estimated solving model waiting time closed class job corresponds sum time spent execution time spent waiting receive service 
conditions applications satisfied technique yields expression waiting time see wc dc gamma delta dc cpu demand closed class job denote respectively mean arrival rate number jobs arrive time unit mean cpu demand open class jobs 
wc corresponds execution time generic segment presence contention dc execution time dedicated mode gamma delta 
formula interpreted follows 
quantity uo delta called background load utilization corresponds mean cpu utilization open class jobs fraction cpu time dedicated execution consequently gamma uo corresponds fraction cpu power dedicated execution closed class job practice sees cpu dedicated slower 
final consideration note formula holds uo background load saturate cpu workstation 
situation uo corresponds background load utilization case waiting time predicted eq unbounded cpu power required complete jobs fast avoid job queue grow unboundedly 
methodology deal workstations computing power entirely background jobs machines background load utilization raises relatively long period times provided long run average background utilization uo 
hand workstation background load utilization little practical running parallel applications 
order assess accuracy predictions delivered eq situations assumptions violated performed experiments processor sharing idealization round robin control processor circulates infinitely rapidly jobs 
effect jobs served simultaneously jobs service receives th full processor power 
background load utilization confused load average parameter unix measure average lenght ready run job queue 
measured execution times set sequential programs executed various workstations background load artificially generated characterized probability distributions different negative exponential required 
distributions erlang hyperexponential gamma pareto representative wide class realistic workloads 
preliminary results obtained experiments indicate eq underestimates execution times relative error predicted measured execution times increases increasing values uo acceptable values uo error increases increasing values coefficient variation distribution cpu demand sensitivity increments interarrival times distribution small 
worth point cpu demand distribution high accuracy predictions satisfactory cluster analysis split background jobs classes characterized different value having smaller coefficient variation 
case eq wc dc gamma delta respectively number background load classes arrival rate class average cpu demand 
modeling communication times communication times represented associating suitable delays transitions corresponding message transmissions 
known model compute delay communication transition snd snd ts size message bytes ts startup cost bandwidth network measured bytes sec 
determine ts suitable benchmark programs described 
cope random fluctuations values ts caused presence background traffic eq sample mean estimated running benchmarks times suitable confidence interval constructed 
approach reasonably accurate network operates conditions discussed section extended straightforward way case multiple heterogeneous network connect workstations cluster different values ts various different networks 
case shared medium networks ethernet eq modified order take account contention generated simultaneous network processes parallel program 
commonly adopted solution take effect account divide bandwidth number simultaneously transmitting processes case transition snd corresponds delay computed snd ts delta marking transition fires corresponds number communications place simultaneously snd 
computed denote respectively number segments process number send operations performed th segment number tokens contained place marking execution time prediction estimation average execution time parallel program calculated computing time required reach final marking tpn model representing marking transitions enabled corresponds termination program 
time required reach final marking computed means algorithm oe transition enabled sched time add time oe remove time sched time gamma enabled sched time time add time sched time time instant firing transition scheduled list enabled transitions ordered scheduling time 
number iterations algorithm denotes number times transition enabled 
transitions included loops transitions belonging loops including modeling communications performed segments loop number loop iterations 
example matrix multiplication program illustrate validate performance prediction method consider parallel version matrix multiplication algorithm show construct corresponding timed petri net model 
verify predicted results various types background load measurements obtained running pvm implementation algorithm cluster workstations 
matrix multiplication mm algorithm matrix multiplication algorithm consider computes product theta theta matrices utilizing set processes arranged logical ring 
process responsible computation elements included th gamma th row allocated elements included th gamma th rows 
algorithm pseudo code reported fig 
works follows 
initially process asynchronously sends por size send size size size size receive size size size size pseudo code matrix multiplication program 
tion process ring multiplies portions held locally 
enters loop waits portion predecessor ring forwards successor performs local multiplication piece just received 
cycle ends process receives portions timed petri net model mm program construction tpn model mm program starts breaking segments graphically highlighted fig 

program spmd type processes structure corresponding tpn models identical 
model process depicted fig 
existence processes assumed 
transitions representing segments transition representing communications snd snd 
segments included send receive statement perform communication operation consequently input output subnets see sec 

communications process performed segments destined segment process transitions snd snd output place note place belong model process included explanation purposes 
complete model mm program obtained replicas tpn fig 
connecting communication relations transitions snd snd connected place 
fig 
show tpn model processes mm program 
performance prediction measurement order validate prediction methodology performed experiments measured execution time mm program executed workstation cluster artificially loaded background job streams characterized distributions violating assumptions required application 
performed set experiments different workstation clusters snd snd tpn model process mm program 
tpn model processes mm program 
order test methodology different conditions 
experiments matrix size fixed theta 
aim set experiments determine impact value uo parameters interarrival cpu demand distributions background jobs accuracy model predictions 
sun sun sparcstation sun sparcstation denoted respectively running sunos connected mbit sec 
ethernet carrying traffic generated workstations 
order avoid mixing effects different background loads artificially loaded machine workstations dedicated mode 
power weights workstations ae ae ae ae average values confidence level accuracy ts respectively sec 
kbytes sec respectively 
execution times various segments dedicated machines computed means eq listed table fig 
time communication computed means eq sec size message bytes 
experiment experiments set execution times segments 
set fixed distributions background load increased uo varying parameters distributions 
results various experiments reported fig 
axis axis indicated value uo average confidence level accuracy measured execution time 
respectively 
measurements system clock granularity millisecond 
group bars corresponds experi 
background load utilization elapsed time sec 
predicted experiments set comparison measured predicted times 
min 
error max 
error avg 
error experiments set relative error predictions 
ments value uo different distributions interarrival time cpu demand 
particular bars labeled correspond experiments negative exponential distributions interarrival times cpu demand background jobs 
bars labeled correspond experiments negative exponential distribution interarrival times hyperexponential distribution parameters set way cpu demand 
bars labeled correspond experiments negative exponential distribution interarrival times background jobs hyperexponential distribution cpu demand 
bars labeled predicted represent execution times predicted model 
observed graph table fig 
predictions delivered model reasonably accurate cases average errors ranging 
second set experiments aimed analyzing impact operating system scheduling policy accuracy models 
case cluster identical workstations equipped intel pentium ii mhz processors running linux operating system connected mbit ethernet lan average values ts respectively sec 
kbytes sec 
configuration significantly differs previous set experiments scheduling algorithm operating system performance processors network 
seen execution times various segments dedicated machine listed table fig 
time taken various communications sec case cost communications comparable segments order magnitude higher segments 
set experiments allows validate predictions models different operating systems programs having relatively fine granularities 
second experiments set execution times segments 
set experiments machine artificially loaded ones dedicated mode 
execution time mm program measured various experiments set reported fig 
maximum minimum average error predictions measurements reported table fig 

respect set experiments case values background load utilizations coefficient variations changed distributions interarrival times cpu demand 
particular kept negative exponential distributions experiments coefficient variation gamma distributions experiments coefficient variation 
background load utilization elapsed time sec 
predicted second experiments set comparison measured predicted execution times 
min 
error max 
error avg 
error second experiments set relative error predictions 
seen fig 
results obtained second set experiments show accuracy similar previous experiments confirming models able deliver accurate predictions independently particular operating system workstations 
note case machines identical report execution times single machine 
relative error insensitive particular distribution magnitude appreciably change gamma hyperexponential distributions 
methodology construction analysis performance models parallel programs executed non dedicated clusters workstations 
previous research methodology restrict class programs computing platforms background load represented restrictive assumptions operating systems workstations cluster 
moment writing performed experiments different distributions erlang exponential hyperexponential gamma pareto representative load distributions observed real systems 
generality come free accuracy predictions shown preliminary experiments reasonable cases practical interest decreases high values uo greater cpu demand background jobs 
experiments conducted far indicate error predictions relatively insensitive particular distribution excluded distributions behave differently result higher error models inappropriate 
extensive experimentation required determine class distributions methodology able deliver accurate predictions 
final worth pointing methodology limited computational cost predictions reported section required milliseconds cpu time intel pentium machine provide fly predictions resource systems process allocation may modified run time react changes resource status apples 
interesting issues remain open investigation 
randomness introduced system background load traffic cause execution time parallel programs vary execution execution range variability increases increasing values coefficient variation 
knowledge range provide valuable information programmers optimization tools plan investigate methodology extended provide estimations parameter 
possible extension include effects due contention memory resources moment taken account order able analyze memory bound applications 
shows lan traffic self similar consequence traffic burstiness appears different time scales 
cases simple technique model communication costs inadequate necessary develop suitable extensions 
adve analyzing behavior performance parallel programs 
phd thesis university madison december 
anderberg cluster analysis applications 
academic press 
queueing models analysis contention effects cluster platforms 
tech 
rep dipartimento di informatica universita di torino 
balbo understanding parallel programs behaviour petri net models 
journal parallel distributed computing july 
barrera smith analysis benchmark characteristics benchmark performance prediction :10.1.1.53.6631
acm transactions computer systems november 
berman wolski schopf shao application level scheduling distributed heterogeneous networks 
proc 
supercomputing ieee cs press 
workload characterization survey 
proc 
ieee august 
dynamic load balancing distributed spmd computations explicit message passing 
proc 
heterogeneous computing workshop ieee computer society press 
iyer predictability process resource usage measurement study unix 
ieee trans 
soft 
eng 
dec 
dongarra message passing performance various computers 
tech 
rep ornl tm oak ridge national laboratory february 
ferscha petri net approach performance oriented parallel program design 
journal parallel distributed computing july 
berman modeling contention effects clustered environments 
tech 
rep cs university california san diego december 
foster designing building parallel programs 
addison wesley 
harchol balter downey exploiting process lifetime distributions dynamic load balancing 
proc 
sigmetrics acm press 
kim lilja exploiting multiple heterogeneous networks reduce communication costs parallel programs 
proc 
heterogeneous computing workshop ieee cs press 
krueger livny comparison preemptive non preemptive load distributing 
th intern 
conf 
distributed computing systems june pp 

lazowska zahorjan graham sevcik quantitative system performance computer system analysis queueing network models 
prentice hall 
leland taqqu willinger wilson self similar nature ethernet traffic extended version 
ieee acm transactions networking 
leutenegger sun distributed computing feasibility non dedicated homogeneous distributed system 
proc 
supercomputing ieee computer society press 
murata petri nets properties analysis applications 
proceedings ieee april 
probability load balancing success homogeneous network 
ieee trans 
soft 
eng 

sarkar determining average program execution times variance 
proc 
sigplan conference programming language design implementation acm press 
schmidt sunderam empirical analysis overheads cluster environments 
concurrency practice experience february 
schopf berman performance prediction production environments 
proc 
merged symposium ipps spdp orlando florida usa april ieee cs press 
cheng petri net framework automated static analysis ada tasking 
journal systems software october 
clement performance prediction pvm programs 
proc 
international parallel processing ieee cs press 
sunderam geist dongarra manchek pvm concurrent computing system evolution experiences trends 
parallel computing april 
yan zhang song effective practical performance prediction model parallel computing non dedicated heterogeneous 
journal parallel distributed computing 
zhang yan modeling characterizing parallel computing performance heterogeneous networks workstations 
proc 
th ieee symposium parallel distributed processing 

