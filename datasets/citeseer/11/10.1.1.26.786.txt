appear seventh international symposium high performance computer architecture hpca january programmable processor profiling craig zilles sohi computer sciences department university wisconsin madison west dayton street madison wi usa zilles sohi cs wisc edu aggressive program optimization requires accurate profile information accuracy requires samples collected 
explore novel profiling architecture reduces overhead collecting sample including programmable processor analyzes stream profile samples generated microprocessor 
stream samples processor detect correlations instructions memory dependence profiling different dynamic instances instruction value profiling 
profiler programmable nature allows broad range data extracted post processed formatted provides flexibility tailor profiling application program test 
processor specialized profiling execute profiling applications efficiently general purpose processor 
processor significantly impact cost performance main processor implemented small number transistors chip periphery 
demonstrate proposed design detailed evaluation load value profiling 
implementation quickly accurately estimates value invariance loads time overhead roughly proportional size instruction working set program 
algorithm demonstrates number general techniques profiling including estimating completeness profile means focus profiling particular instructions management profiling resources 
understanding dynamic program behavior key maximizing performance 
means identify bottlenecks inefficiencies difficult effectively optimize program execution 
program profiling important mechanism observing dynamic program behavior 
program profiling systems proposed consensus desired attributes system :10.1.1.52.139:10.1.1.34.8429
attributes grouped main categories usability widespread adoption profiling necessitates effort required user minimized technique widely applicable 
specifically special compilation requirements avoided 
low overhead overhead space time minimized enable profiling long running applications realistic data sets 
run time optimization systems especially sensitive overhead 
accuracy precision behaviors correctly attributed individual instructions possible profiling system keep result perturbation minimum 
expressiveness ideal profiling system able measure behavior 
ideal profiling system developed scheme strengths limitations 
profiling architecture feel compares favorably existing schemes cost additional hardware 
system profiling architecture profiles instructions performed transparently hardware special application preparation required 
stores profiled instructions retire dynamic information sample buffer 
proposed implementation multiple flight instructions profiled simultaneously 
sample buffer accessed directly main processor architecture includes programmable profiling processor serves intermediary 
processor distill profiling information compact form passing main processor 
way high quality profiling information gathered quickly maintaining low overhead 
processor controlled downloading programs main processor 
processor programmable nature coupled richness profile information collected enables broad range program behaviors observed single piece hardware 
programmability allows profiling software specialized program observation 
processor exclusively profiling tailor design efficiency 
implementing common profiling operations discussed section primitives hardware high performance profiling processor implemented small area power budgets 
processor decoupled main processor sample buffer located significantly impact design core 
hardware design discussed section 
brief discussion profiles collected processor section evaluate profiling architecture case study load value profiling 
demonstrate algorithm general collects accurate profiles faster lower overhead simple sampling value profiler 
algorithm section demonstrates number techniques applicability profiling value profiling 
techniques enable algorithm implicitly identify frequent instructions profile instructions confident characterized mask profile set frequent instructions 
way profiler successively profiles instructions largest potential impact algorithm stops incurring overhead profile complete 
observations profiling motivation looking forward see trends feel place larger demands rate profiling information need collected 
section discuss trends explain sampling able meet demands increasing overhead 
changing face profiling program profiling systems proposed date concentrated topics identifying control flow profiles instructions associated performance degrading events :10.1.1.42.629
techniques employed including value code specialization speculative multithreading pre execution software managed caches require exploit additional types profile information 
order collect larger set profile information rate profile information gathered increased 
techniques program optimization evolving rapidly developed require new types profile information collected 
programmable profile engine profile information collected existing hardware having wait hardware design cycle include necessary special purpose hardware 
addition trend run time optimization program execution optimized profile information gathered :10.1.1.141.2606:10.1.1.34.8429
run time optimization requires profile collection quick maximize portion program execution optimized low overhead impact run time 
profiling systems leverage sophisticated analysis post process profiles run time optimization environment post processing may cost effective 
reducing overhead collecting samples profiling systems sampling maintain low overheads 
sampling meta technique applied techniques including instrumentation interpretation reduce overhead decreasing rate information collected 
sampling exploits fact profile information hint need complete necessarily correct 
sampling effective statistically collect information common events ones provide potential performance improvement 
furthermore highly biased behaviors ones provide potential estimated confidence level fewer samples highly biased behaviors 
overhead interrupt sampling proportional data collection rate higher profiling rates equate larger overheads shown 
order reduce overhead collecting sample constant proportionality proposed profiling system delegates profiling computation dedicated profiling processor 
processor summarizes information contained samples passing main processor 
specializing processor task profiling provide profiling computation cheaply general purpose host processor 
section discuss design profiling processor 
hardware proposed profiling architecture requires hardware support included current implementations 
light fact peak processor performance growing rapidly real program performance feel dedicating hardware resources features close gap including profiling support justifiable micro normalized error overhead cycles normalized error time cycles time cycles increased sampling rate increased sampling rate overhead cycles 
relationship accuracy overhead sampling rate traditional interrupt driven sampling data shown load value profiling gcc samples loads faster sampling rate enables profile converge faster higher sampling rate translates correspondingly higher overhead leading profile quality function overhead independent sampling rate processors 
important aspect design profiling processor minimizing impact main processor performance cost 
specifically processor moderate number transistors 
keep additional circuits far core processor 
design able tolerate communication latencies core 
avoid loading critical circuit paths order minimally impact processor frequency 
significantly increase power consumption 
feel design section constraints 
estimate baseline design implemented approximately half transistors estimated transistors memory arrays believe core simpler strongarm required transistors 
substantially smaller modern microprocessor amd athlon cache transistors processors expected larger 
transistors processor located core periphery 
additional hardware core required collect export profile information processor 
hardware similar required proposal additional storage required multiple flight instructions profiled 
types information collected instruction including instruction pc register values memory address micro architectural events associated instruction instruction caused branch misprediction instruction 
generality profiler design dependent information core available instruction 
exporting information processor requires additional datapaths studies done bit datapath sufficient signals latency tolerant interconnect pipelined cycles 
section describe major features profiling architecture 
start describing requirements processor section 
sub sections covers portion design instruction filtering sample buffer section processor datapath section processor control section interactions main processor section 
high level block diagram profiling architecture shown 
characteristics profiling applications analyzing profiling algorithms identified common operations 
order efficiently execute profiling applications operations provided hardware primitives 
list common operations brief description hardware implements implicit loop structure routine executed sampled instruction 
processor provides special branch target fetches instruction sample jumps routine processing type instruction described section 
opcode filtering certain classes instructions considered branch instructions considered control flow profiling 
decode stage main processor configurable hardware filter filter instructions opcode described section 
field extraction processing instructions usually requires extracting fields instruction branch target pc register identifiers 
processor includes hardware instruction decoder field extractor provides bit fields need shift mask instruction bits software described section 
lookups matching current sample paired previous related samples 
processor associative array provides match operations software described section 

information wires largely subset required core diva style checker architecture 
processor design employs checker impact wires amortized features 
host cpu fetch decode instruction filter tag instructions execute order collect profile information tagged instructions tagged retired instructions pc kb microcode array counter manipulation counters summarize repeated events management profiling resources 
processor data memory provides read modify write operations alus support saturating arithmetic described section 
data dependent control flow profiling applications control intensive branches hard predict outcomes differ sample sample 
profiling processor capable executing branch cycle parallel operations short pipeline minimizes stalls due branch misprediction discussed section 
specializing processor design needs profiling applications provide computation profiling inexpensively 
instruction filtering sample buffer profiling processor resources profile retired instruction profiling instruction required useful profiling information main processor needs collect profile information rate processor consumes 
configurable hardware filter accessed decode time allows instructions tagged profiling controllable way 
pro actively filtering tagging instructions randomly focus subset instructions increases locality sample stream enabling better utilization processor memory resources 
filter considers instruction characteristics opcode class program counter pc 
opcode filtering provided profiling applications monitor subset instructions loads branches 
pc filters provide ability consider fraction program time exclude particular instructions consideration 
filters shown uses described section section respectively 
filters conjunction determine instruction profiled 
filters able support decode width processor 
small opcode filter pc filter easily replicated 
replicating larger pc filter costly constructed exploit fact blocks instructions consecutive pc way instruction caches built fetch multiple instructions 
host access bus value registers const registers index registers base addr 
regs profiling processor sample buffer kb associative array words kb data array words kb decoder extractor current inst 

block diagram profiling processor hardware showing major arrays size estimates baseline design 
pc pc hash mask match compare hash table kb index 
pc filters hashed version pc masked variable width mask compared programmable value match way program sub divided regions profiled independently number ones mask register hashed version pc indexes table bits set independently enabling individual instructions ignored profiling 
cases multiple hash functions provided reduce conflict problems 
actual collection profile information highly dependent underlying micro architecture 
simulation micro architecture process similar 
sample buffer serves decouple retiring tagged instructions main processor processing processor 
sample buffer helps tolerate burstiness retirement letting processor go idle 
conserve space sample buffer conserve bandwidth main processor processor profiling hardware programmed collect fields current profiling application 
experiments kb sample buffer bit datapath processor processor sufficient 
profiling processor datapath processors profiling processor memories register files arithmetic logic units alus 
structures tailored support profiling applications minimum resources 
memory arrays included microcode array processor program storage associative array efficient matching data array general purpose data storage 
memories main processor caches backed main memory 
design avoids size complexity associated cache tags logic coherency logic enables efficient static code scheduling operations known fixed latency 
profiling information need complete correct data dropped algorithms simplified fit constrained resources 
communication main memory discussed section performed main processor host access bus shown 
associative array implemented content addressable memory cam provides inexpensive hash table functionality lookups matching 
entry associative array valid bit set entry written cleared invalidate operation 
data memory special support read modify write operations incrementing counters 
memories single ported having twice data memory associative memory compromise cost functionality 
order minimize number ports structure reduce register specifier size register file partitioned separate special purpose register files value index constant base address branch target 
size number port configuration register files shown table 
value registers wide hold data retired host instructions register values addresses pcs 
narrower index registers hold offsets memory arrays counters monitoring profiler status 
facilitate implementing circular buffers saturating counters different sizes width index registers configurable program load time 
types registers constant base address branch target read processor configured program loaded 
constants stored constant register file requiring immediates instructions 
base address registers subdivide processor memory sub arrays 
aligned power size sub arrays supported allow addresses generated arithmetic 
branch target registers discussed section 
main alu processor limited functionality compared traditional processor 
multiplication division seldom profiling supported limited shifts available 
alu provide mechanism generating pseudo random numbers linear feedback shift register resource management decisions helps avoid pathological behaviors caused repetition program 
addition main alu provided specifically manipulating index register values 
information distorted counters roll alus support saturating arithmetic 
alus provide control conditions comparisons results saturated branch predicates 
control processor described section profiling processor control processor executes short routine instruction sample buffer order instructions retired 
instruction comes head sample buffer copied structure size ports transistor count pc filter bit mask kb sample buffer kb microcode array associative array kb data array kb value registers index registers constant registers base address registers jump target registers decoder field extractor total transistor count table 
estimated sizes number ports major structures baseline processor design 
decoder field extractor dfe 
dfe provides access information associated current retired instruction including efficient field extraction supplies starting pc processing instruction 
typically instructions different opcode classes profiled single profiling application treated differently 
avoid performance degrading multi way branch software dfe contains table associates opcode class starting processor pc 
significant amount parallelism profiling applications needs exploited cost effective manner 
processor executes single instruction cycle instruction encodes multiple operations 
processor instruction set microcode instruction simple encoding processor control signals 
allows large fraction resources cycle reduces instruction decode time 
short decode time necessary maintain high clock rate short order pipeline 
stage fetch decode execute pipeline minimize microcode branch misprediction penalty 
profiling applications extremely control intensive microcode instruction includes branch slot 
percent branch slots 
predict direction branches instruction bit branch predictor 
branches profiling applications short small set short forward backward immediate offsets included instruction set 
rare cases insufficient architecture includes branch target registers enable jumps location 
addition special branch targets included done interrupt 
routine branches target done finished processing host instruction increments head pointer sample buffer jumps routine associated new head instruction type 
processor branches interrupt target execution halted main processor interrupted 
interactions main processor providing processor direct path memory powerful fear impact circuit speed main processor memory access path 
read write main memory profiling processor leverages existing memory system hardware main processor 
loads stores special address ranges main processor read write processor state 
way main processor copy programs initial state processor copy profile data processor main memory 
baseline processor counting sample buffer kb state 
completely transfer state requires bit memory operations full transfer seldom required 
special operations provided invalidate associative array clear data array desired initial states profiling applications 
arrays dominate processor state number stores necessary program processor drastically reduced 
program loaded processor continues collecting type information interrupt processor typically re initialized stores 
reading profile state processor necessary read data changed necessary read microcode array uncommon read associative data arrays kb 
processor programmed performs profiling autonomously desires external communication 
filled arrays useful profiling information requires guidance profiling application interrupts main processor 
overhead observed profiling roughly product number interrupts number samples recorded interrupt average time required record sample 
minimize total overhead attempt minimize maximizing quality information extracted function number samples recorded 
component number interrupts minimized design profiling algorithm strives interrupt slots high information content complements enhances information collected discussed section 
second component samples interrupt slightly reduced having processor post process information collected remove samples low information content 
overhead sample third component reduced hand assembling interrupt handler minimize instruction count maximize instruction level parallelism organizing data structures minimize number cache misses described 
addition processing multiple samples interrupt modulo scheduling overlap cache misses associated hash table lookup 
techniques written interrupt handlers require little cycles process sample depending complexity handler 
example applications addition case study follows briefly discuss applications implemented profiling processor 
profiles new potentially implemented low overhead manner specialized hardware 
edge profiling 
pass profiler built profiles direct branches counting times branch taken taken profiles indirect branches identify targets count frequencies 
addition observing pair branch samples close proximity potentially identify correlations branch outcomes 
call stack monitoring 
call return instructions profiled maintain current call stack enabling events branch mispredictions correlated calling contexts 
memory dependence profiling 
storing pcs memory addresses stores comparing memory addresses loads dependences stores loads identified 
cache conflict profiling 
storing memory addresses cache missing loads identify block brought cache multiple times short duration indicating conflict 
address compute set identify instructions accessing set 
case study value profiling predictability invariance data values actively studied 
mechanisms exploit program behavior value prediction dynamic specialization identification candidate invariant values strict requirement enhancement 
requiring programmer identify values tedious error prone value profiling proposed automatically characterize value invariance frequency value seen identify common values :10.1.1.40.2933
early implementations value profiling instrumentation simulation feasible large programs calder reports average slowdown factor 
sampling implementation value profiling demonstrated slow sampling instructions implementation interprets program collect values cost collecting sample high hundreds thousands cycles sample 
profiling processor emulate simple sampling algorithm achieve comparable results lower overheads 
values captured hardware interpretation required multiple samples buffered allowing cost interrupt amortized samples 
simulation results show equivalent sampling frequency achieved percent overhead 
low overhead behaviors profiled simultaneously significantly impacting performance 
demonstrate benefit features hardware profiler examine performing value profiling support dynamic optimization challenging profiling scenario 
context additional requirement profile collected high rate maximize portion execution optimized 
greatly increasing sampling rate limits overhead strict performance lost profiling reduces benefit achieved dynamic optimization 
challenging scenario motivated profiling processor approach 
algorithm improves existing algorithms respects providing mechanisms policies targeting profile particular instructions summarizing multiple related samples processor fewer updates memory profile result tables required 
sub section describe algorithm 
experimental methodology described section 
quantitative results profiling accuracy overhead comparing simple sampling approach provided section 
algorithm high level algorithm performs steps 
find frequently executed unmasked instructions 
collect summarize profile information instructions 
interrupt processor 
copy information data structure memory 
instruction sufficiently characterized mask 
repeat instructions masked number nice things structure 
profiles instructions order importance frequently executed frequently executed 
section discuss replacement policy statistically retains frequently executed instructions prior knowledge 
second predicting sufficiently profiled instruction discussed section profiling instruction focus profiling resources remaining instructions 
way profile infrequently executed instructions may difficult traditional sampling scheme 
unmasked instructions profile declared complete processor profile behaviors 

exact proposal samples instructions interrupt interrupt frequency instructions 
section follows important components algorithm including maximizing benefit limited processor resources section thrash detection section invariances estimated section 
additional detail appendix slots limited set resources monitor program algorithm designed maximize utilization resources 
order simultaneously track maximum number static load instructions minimize storage allocated static load tracking value load time 
load monitored profiling processor allocated portion processor storage resources call slot 
manner storage allocated configured software part processor programmability 
slot shown consists storage pc active value byte counters hit byte counter total 
performed experiments bit alpha architecture upper half word little information content bits usually sufficient discriminate pcs select bits values low bits stored 
previous value profiling techniques slot keeps active value time value associated static instruction data structure main memory 
accurately estimate invariance active value keeping track number times see matching value hits dividing total number values seen hits misses 
simply select top invariant values active values 
identifying top value done priori select random sample active value statistically select top value 
similar observation bala regards path profiles 
assured get right value need periodically re select active value invariance low 
informational replacement instruction currently allocated slot encountered decide replace current slots 
cost replacing slot loss information gleaned associated instruction 
amount information stored slot considered making replacement decision 
number samples observed total counter incremented time sample observed estimate information content slot 
way infrequently executed instructions replaced frequently executed instructions 
total bits pc value hit bits bits bits associative array data array 
static load profiling processor maintains data structure slot contains instruction pc active value statistics instruction past behavior 
pc stored associative array fast matching 
thrash detection filtering algorithm described far sufficient working set unfiltered loads fits slot array 
working set unfiltered loads frequencies roughly equal larger slot array algorithm constantly replacing entries chance observe multiple samples 
happens processor throwing away information rate collecting 
thrashing quickly easily detected monitoring number times performed slot replacements 
thrashing occurring number replacements large fraction samples observed 
avoid thrashing divide conquer technique pc filter partition program 
subset profiled turn partitioning artificially increases locality sample stream 
confidence estimation samples collected estimate invariance instruction necessary accuracy collecting additional samples instruction provide benefit 
difficulty approach determining samples collected 
truly random process set samples desired accuracy statistical methods compute confidence set samples represents process desired accuracy program behaviors random processes 
calder investigated scheme called convergent profiling compares set samples instruction profile determine profile converged 
converging collecting samples discontinued 
rest algorithm streamlined comparison expensive unnecessary 
confidence decisions information 
statistical confidence increases measured bias sample 
easy confident highly invariant highly variant instructions 
storing data memory interrupt handler test invariance high threshold low mask instruction second larger pc filter 
instruction profiled multiple times attempt characterize dominant values allow instruction sampled times masking 
phase behavior necessary periodically re sample ensure important behaviors observed 
time re sampling improved including explicit phase detector 
special case phase behavior referred values 
benchmarks gap vpr loads load single value long interval thousands instances change repeatedly loading different value 
may sample phases equally profiler trouble determining fraction execution associated value 
easily diagnose behavior occurring multiple profiled values counts zero bad counts important knowing exact contributions 
performing diagnosis difficult traditional sampling profiler 
invariance estimation algorithm estimate value invariance need reconstruct data collect data collect 
static instruction post processed isolation main processor 
value accumulated hit counts compute invariance hits hits misses regions selected active value profiler 
clustering stream values loaded instruction computed invariance estimates value invariance program 
get accurate estimate consider counts recorded values active total number samples observed 
methodology order evaluate capabilities proposed profiling architecture built cycle accurate simulator processor 
profiling algorithm described section implemented processor microcode executed simulated processor 
processor model included timing simulator derived alpha version simplescalar simulates main processor 
addition benchmark program main processor executes profiling system code including interrupt handler responsible configuring processor storing processor results memory 
timing simulation required determine instruction samples dropped sample buffer full estimate profiling overhead 
simulated main processor way superscalar dynamically scheduled processor roughly modelled alpha 
processor kb caches shared mb cache cycle access cycle main memory access 
simulated processor configurations observe processor sensitivity sizes associative data memories memories substantial portion processor cost 
baseline configuration kb associative memory kb data memory 
addition simulated processors half kb kb twice kb kb memory resources 
simulate processor executing frequency main processor explore sensitivity section 
benchmarks spec integer benchmark suite 
modified inputs attempt maintain data set size reducing execution duration modified inputs ran instructions 
instruction region selected dominant execution phase program simulation 
typically profiler characterizes program shorter interval 
set experiments concern identifying load values account dynamic instances particular load invariances 
general loads benefit value optimizations difficult accurately characterize complete profile 
single static instruction multiple values exceed requirements attempt estimate invariance values 
results run collect complete profile compare estimated profile 
shows estimated invariance values versus true invariance gcc program largest instruction working set 
point scatter plot represents single static instruction value pair shape point roughly indicates frequency value values loaded times triangles squares values loaded times 
ideal results points dashed line pair dotted lines aid visualization represent percent estimate 
points axis values sampled largely due infrequently executed instructions 
general estimates accurate estimates percent 
fact results better appear points near diagonal obscure points location 
general accurately predict values high invariances outliers tend infrequently executed values 
quantitative results 
obtain quantitative estimate quality profiles compute root mean square error weighted value frequency estimations 
compare algorithm hardware implementation simple sampling approach described section increased sampling rate loads enable faster profile collection 
compares profile quality generated algorithms demonstrating lot variation accuracy 
accuracy simple sampling approach largely inversely proportional size instruction working set gcc perl largest number loads simulated region 
processor implementation better accuracies benchmarks 
gap worse algorithm inaccurately characterized values mentioned section 
bzip parser lower accuracy algorithm satisfied accuracy discontinued profiling benchmarks overhead substantially lower processor algorithm 
crafty special case accuracy suffers algorithms bit flags tracking state chess board values aliased store bottom bits value 
currently working extension algorithm detect condition second pass invariant instructions capture bit values 
overhead 
overhead profiling discussed section comes transferring state processor associated cache pollution 
difficult compare overhead algorithms simple sampling approach fixed overhead unit time processor algorithm cease execution satisfied profile collected estimated invariance true invariance gcc instances instances instances 
scatter plot shows accuracy invariance estimates value basis 
data shown benchmark gcc baseline array size slots 
sheer number points chose plot points estimated actual invariance percent causes empty box lower left 
overhead largely function size program instruction working set 
percentage slowdowns meaningful way represent overhead processor algorithm provide means compare algorithms 
measured overheads shown include initialization processing required set filter bits final estimation algorithm described section 
final estimation overhead linear number static loads profiled 
mechanisms overheads cases overhead processor algorithm lower 
largely due processor interrupting program fewer times making fewer updates memory data structure 
overhead update higher processor algorithm typically multiple counters updated decision mask number updates lower overhead lower 
convergence rate 
potentially important dynamic optimization scenario rate profiles converge 
shows relationships accuracy overhead time processor algorithm simple sampler gcc 
seen processor profile converges quickly 
interrupts frequently quickly characterize frequent instructions 
leads higher overhead initially shifts profiling frequent instructions interrupt frequency drops leading decrease overhead 
seen processor better accuracy lower error overhead true benchmarks 
weighted rms error percent overhead percent bzip crafty eon gap gcc gzip mcf parser perl twolf vortex vpr processor simple bzip crafty eon gap gcc gzip mcf parser perl twolf vortex vpr processor simple 
results benchmarks weighted root mean square error invariance estimation overhead 
cases smaller numbers better 
gcc perl largest benchmarks represent real workloads best demonstrate capabilities processor algorithm 
see substantial increase accuracy times respectively significant reduction overhead respectively 
sensitivity analysis 
explore sensitivity profiler processor design ran experiments configurations twice storage resources half 
major differentiation configurations rate profiles captured linearly related array size shown gcc 
accuracies overheads hand dramatically affected shown 
general accuracies better resources relationship sub linear 
cases smaller arrays provide better profiles 
due second order effects including interrupts performed interaction filtering rate samples processed 
interestingly smaller arrays tend slightly lower overhead increase interrupt frequency corresponding decrease samples interrupt 
frequency processor executes appear substantial impact results 
comparing results processors clocked main processor frequency able achieve comparable profile accuracies eventually achieve accuracies roughly equivalent overheads 
rate profiles collected somewhat affected cases largest benchmarks gcc perl appears largely due poor decisions profile software perform interrupts 
expect tuning algorithm mitigate penalty 
normalized error normalized error overhead cycles time cycles processor simple time cycles overhead cycles 
relationship accuracy overhead time processor simple algorithms 
processor algorithm converges faster overhead early having better accuracy amount overhead 
data shown gcc 
normalized error normalized error weighted rms error percent overhead percent overhead cycles base base base time cycles time cycles overhead cycles 
rate profile collected sensitive storage resources processor overhead collecting profile accuracy 
data shown gcc 
bzip crafty eon gap gcc gzip mcf parser perl twolf vortex vpr bzip crafty eon gap gcc gzip mcf parser perl twolf vortex vpr base base base base base base 
profiling accuracy overhead moderate sensitivity amount storage resources available processor 
related proposed profiling architecture builds previous instruction sampling 
schemes instruction selected profiling fetch time instruction proceeds pipeline stage captures information 
addition micro architectural events system assumes architectural state associated instruction register values captured proposed 
approaches interrupt processor sample scheme buffer multiple samples condense profile data reduced form 
addition include filter constrains instructions selected sampling 
previous proposed mechanisms coalesce profile information multiple samples specific types profiling typically control flow profiling 
conte proposed profile buffer tracks retired branch outcomes incrementing counters branch address 
propose slightly complicated structure hot spot detector uses retired branch outcomes identify program hot spots captures branch biases 
extend hot spot detector enable autonomous re layout frequently executed program regions 
schemes merging algorithm implemented hard wired logic proposed profiling approach trades efficiency flexibility programmable processor perform reduction 
chou described instruction path processor cop programmable processor observes retirement stream 
describe array processors trace construction optimization trace caches estimate cop roughly size kb fast sram 
profiling processor exclusively performs profiling hardware tailored provide high profiling rates resources order magnitude smaller 
addition richer set information provided retirement stream profiling processor collect broader range profiles 
concurrently heil smith proposed relational profiling architecture rpa 
architecture shares common profiling processor approach designed exploit characteristics underlying designed virtual machine model 
example instructions include extra bit field set control instructions profiled serving purpose pc filter bit array 
post processing samples dedicated processor rpa sends messages service threads execute small general purpose peripheral processors 
addition demonstrate datapath communicating profile information core feasible propose concept assured sampling instance set instructions monitored enabling rpa ensure correctness presence speculative optimizations 
programmable processors previously proposed manage sub tasks processor behalf 
proposed programmable processor magic implement cache coherence demonstrated coherence performance monitoring 
reinhardt proposed software managed cache uses processor implement replacement policy 
propose new profiling architecture profiling processor performs local post processing profiling data 
post processing sample data passing main processor reducing overhead collecting data sample 
post processing performed efficiently processor implements common profiling operations hardware primitives 
processor modestly impact design main processor estimate implemented half transistors majority far away main processor core 
processor programmable capable collecting wide range profile data 
demonstration implemented load value profiling 
application demanding large state space values detect patterns 
profiling algorithm monitors results terminates profiling instruction confident estimate invariance 
way algorithm successively profiles instructions frequent frequent terminates satisfied profile 
believe structure profiling algorithm techniques implement applicable types profiling 
authors amir roth milo martin ras bodik anonymous reviewers comments earlier drafts 
supported part national science foundation mip ccr eia donations intel sun microsystems university wisconsin graduate school 
craig zilles supported intel foundation graduate fellowship wisconsin distinguished graduate fellowships academic years respectively 
intel 
visual tuning environment 
support intel com support 
anderson continuous profiling cycles gone 
proc 
th symposium operating system principles oct 
auslander philipose chambers eggers bershad 
fast effective dynamic compilation 
proc 
sigplan conference programming language design implementation pages may 
austin 
diva reliable substrate deep microarchitecture design 
proc 
nd international symposium microarchitecture pages nov 
wolfe 
initial results variable analysis 
proc 
th international workshop languages compilers parallel computing august 
bala duesterwald banerjia 
transparent dynamic optimization 
technical report hpl hewlett packard labs june 
ball larus 
efficient path profiling 
proc 
th international symposium microarchitecture pages dec 
burger austin 
simplescalar tool set version 
technical report cs tr university wisconsin madison jun 
burrows efficient flexible value sampling 
proc 
th conference architectural support programming languages operating systems nov 
calder feller eustace 
value profiling 
proc 
th international symposium microarchitecture pages dec 
calder feller eustace 
value profiling optimization 
journal instruction level parallelism march 
calder tullsen 
selective value prediction 
proc 
th international symposium computer architecture pages jun 
chou schmit shen 
piperench implementation instruction path coprocessor 
proc 
rd international symposium microarchitecture dec 
dean hicks waldspurger weihl 
apparatus sampling instruction operand result values processor pipeline 
patent july 
consel noel 
general approach run time specialization application proc 
conference principles programming languages pages jan 
conte menezes hirsch 
accurate practical profile driven compilation profile buffer 
proc 
th international symposium microarchitecture pages dec 
conte patel cox 
branch handling hardware support profile driven optimization 
proc 
th international symposium microarchitecture pages nov 
dean hicks waldspurger weihl 
hardware support instruction level profiling order processors 
proc 
th international symposium microarchitecture pages dec 
engler hsieh kaashoek 
language high level efficient machine independent dynamic code generation 
proc 
conference principles programming languages pages jan 
gabbay mendelson 
program profiling support value prediction 
proc 
th international symposium microarchitecture pages dec 

shift register sequences 
park press revised edition 
reinhardt 
fully associative software managed cache design 
proc 
th international symposium computer architecture june 
heil smith 
relational profiling enabling thread level parallelism virtual machines 
proc 
rd international symposium microarchitecture dec 
hollingsworth miller 
dynamic program instrumentation scalable performance tools 
proc 
scalable high performance computing conference may 
horowitz martonosi mowry smith 
informing memory operations providing memory performance feedback modern processors 
proc 
rd international symposium computer architecture pages may 
kessler 
alpha microprocessor 
ieee micro mar apr 

technology crusoe processors 
technical report transmeta jan 
stanford flash multiprocessor 
proc 
st international symposium computer architecture pages apr 
lipasti wilkerson shen 
value locality load value prediction 
proc 
th international conference architectural support programming languages operating systems pages oct 
martonosi clark 
shrimp hardware performance monitor design applications 
proc 
sigmetrics symposium parallel distributed tools may 
martonosi heinrich 
integrating performance monitoring communication parallel computers 
proc 
sigmetrics conference measurement modeling computer systems may 
trick george gyllenhaal 
hwu 
hardware driven profiling scheme identifying program hot spots support runtime optimization 
proc 
th international symposium computer architecture pages jun 
trick nystrom barnes 
hwu 
hardware mechanism dynamic extraction re layout program hot spots 
proc 
th international symposium computer architecture june 
mhz cmos risc microprocessor 
ieee journal solid state circuits nov 
gupta soffa 
value prediction vliw machines 
proc 
th international symposium computer architecture pages jun 
srivastava eustace 
atom system building customized program analysis tools 
proc 
sigplan conference programming language design implementation 

sampling methods applied research text cases 
john wiley sons 
tullsen seng 
storage value prediction prior register values 
proc 
th international symposium computer architecture pages jun 
white 
instruction sampling instrumentation 
patent sept 
zagha larson turner 
performance analysis mips performance counters 
proc 
conference supercomputing nov 
zhang wang chen smith 
system support automatic profiling optimization 
proc 
th symposium operating system principles oct 
appendix value profiling algorithm details section covers details important achieving results value profiling algorithm aren required casual reader 
flow chart referred text value profiling algorithm shown 
value re sampling implementation measured invariance drops percent tested state re select active value state set hit counters respectively 
addition updating hit counters sample increments total counter enables track samples dropped active value re selected 
counter saturation slot learned useful damaged additional updates turn clearing valid bit associative array matches occur 
important case saturation hit counters state 
occurs updates added slot order preserve ratio hits misses 
decide select new active value previous active value accrued non trivial number samples current implementation turn slot retain information state 
lastly uncommon case total counter saturates turn slot maintain accurate count number samples observed 
static instruction slot turned new instances instruction compete remaining slots instructions slot 
informational replacement expensive consider slots replacement consider denoted 
current scheme index array slots tracks slot replacement 
slot occurs total counter compared pseudo random number inclusive 
random number greater slot replaced new instruction value stored new active value hit counters reset state 
replacement fails current sample ignored state 
way relatively infrequently executed instructions array frequent ones masked 
entry replaced index slot replacement incremented giving new slot time take hold re considered replacement 
interrupt strategy eventually slots un replaceable total count exceeds 
long current working set instructions represented slots continue collecting data 
start ignoring samples instructions allocated slots time copy profiler state main memory clean slate 
identify perform interrupt algorithm includes saturating failed done turn done done counter incremented time replacement fails decremented time succeeds 
counter initialized zero hits threshold interrupts processor 
cases mechanism implicitly detects program phase changes new instruction working set represented slot array 
thrash detection filtering algorithm counts number replacements interrupts processor exceeds threshold 
replacements infrequent thrashing low threshold times number slots allows thrashing detected quickly minimum number false positives 
thrashing detected attempt estimate extent decide finely program partitioned 
algorithm looks number samples processed indicator fast thrashing detected decide current partition sub divided ways 
interrupt caused thrash detection copy captured samples memory generally low information content 
estimation algorithm algorithm assumes captured samples representative full program estimates invariances estimating number captured samples belong value 
value gets samples sources hits counter portion counters values fraction remaining samples measured total counter 
value gets associated hit samples 
samples value divided values proportionally number hit counts values 
value gets share counts measured total counter un accounted 
counts divided equally values value percent counts derived regions active value invariance percent 
estimated counts divided total number samples recorded compute value invariance 
new instruction pc value failed interrupt pc match slot 
total value equal active value 
increment hits hits 
failed slots 
done pc pc hits misses active value value total total rand 
failed failed dropped dropped slots 
misses hits 
hits 
turn increment misses active value value misses 
hits misses total 

flowchart processor value profiling algorithm instruction processed processor pc value slot matching pc exists slot replacement failed dropped counters maintained determine interrupt main processor rand generates random number final states done interrupt darker border 
