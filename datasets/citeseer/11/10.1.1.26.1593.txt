vision navigation environmental representations omni directional camera jos member ieee winters jos santos victor member ieee proposes method visual navigation mobile robot indoor environments single omni directional catadioptric camera 
geometry catadioptric sensor method obtain bird eye orthographic view ground plane 
representation significantly simplifies solution navigation problems eliminating perspective effects 
nature navigation taken account designing required navigation skills environmental representations 
propose main navigation modalities topological navigation visual path 
topological navigation traveling long distances require knowledge exact position robot qualitative position topological map 
navigation process combines appearance methods visual servoing environmental features 
visual path required local precise navigation door traversal docking 
robot controlled follow pre specified path accurately tracking visual landmarks bird eye views ground plane 
clearly separating nature navigation tasks simple powerful navigation system obtained 
keywords omni directional vision navigation visual servoing topological maps address problem indoor navigation mobile robot visual information provided omnidirectional panoramic camera 
research vision navigation centered problem building full partial representations environment drive autonomous robot argue shifting emphasis actual navigation problem process building maps explains existing systems require large computational resources lack robustness required real world applications contrast examples efficiency drawn biology insects instance solve large complex navigation problems real time spite having limited sensory computational resources 
striking observation diversity ocular geometries animals eyes point laterally suitable navigation purposes majority insects benefit wide field view eyes space variant resolution extent performance animals explained specially adapted similarly explore advantages having large fields view omni directional camera horizontal field view studies animal navigation suggest species utilize parsimonious combination perceptual action manuscript received october revised june 
recommended publication associate editor hager editor evaluation reviewers comments 
partially funded project praxis eu tmr network smart ii 
part ieee workshop omnidirectional vision hilton head island sc june 
santos victor instituto de sistemas rob tica instituto superior cnico lisboa portugal isr ist utl pt isr ist utl pt 
winters department computer science university dublin trinity college dublin ireland email winters cs tcd 
representational strategies lead efficient solutions compared today robots 
robustness efficient usage computational sensory resources achieved visual information closed loop accomplish specific navigation tasks behaviors approach deal global tasks coordinate systems going distant goal lacks adequate representations environment challenging problem extending local behaviors having build complex representations environment 
point worth discussing nature navigation requirements covering long distances compared short paths animals instance alternate landmark navigation approximate route integration methods example walk city avenue sufficient know position accuracy block entering hall door require precise movements 
path distance accuracy tradeoff long distance short distance high accuracy mission segments plays important role finding efficient solutions robot navigation problem denote navigation modes topological navigation versus visual path 
show omni directional images navigation modes provide suitable environmental representations topological navigation visual path integrated natural way 
omni directional vision omni directional cameras provide view robot environment single image applied autonomous navigation video conferencing surveillance omni directional images usually obtained catadioptric panoramic cameras combine conventional cameras lenses convex mirrors mirror shapes conic spherical parabolic hyperbolic 
visual landmarks easier find omni directional images remain field view longer conventional camera imaging geometry various properties exploited navigation recognition tasks example vertical lines environment viewed radial image lines main omni directional images loss resolution comparison standard images 
describe image formation model omnidirectional camera spherical mirror sensor single projection center severe limitation approach show unwarp omni directional images obtain orthographic bird eye views ground plane perspective effects removed 
topological maps navigation topological navigation approach travel long distances environment demanding accurate control robot position path environment represented topological map described graph 
nodes correspond recognizable landmarks actions may elicited entering door turning left 
links associated regions environmental structure control robot 
col gio rios campo grande universit ria campo roma fig 

topological map landmarks lisbon portugal 
approach landmarks directly represented omni directional images links represented sequences images correspond trajectories robot follow servoing environmental features allowing corridor behavior 
map collection inter connected images example representing landmarks lisbon portugal go particular locale think precise metric terms example get city center square may go forward reach statue turn right direction carry reach square navigation problem decomposed succession sub goals identified recognizable landmarks 
required navigation skills ability follow roads turns recognize reached landmark 
omni directional images implicit topological representation environment rely appearance methods provide qualitative measurement robot global position progression assessed comparing current view images acquired apriori images topological map encoded manifold low dimensional eigenspace obtained principal components analysis 
localization achieved matching images frequency domain horswill actual views landmarks closely related described combined appearance methods visual servoing image geometry matching scheme method servoing different detailed 
visual servoing applied control locally pose robot relative image features navigate nodes 
control robot heading position servoing corridor guidelines extracted bird eye views ground plane combination appearance methods visual servoing global level means fig 

left omni directional camera 
right camera mounted mobile robot 
maintain causality constraint traversing longer distances sampling environment frequently previous approaches 
visual path topological maps navigating distant environmental sites qualitative topological properties environment different approach necessary precise guidance localization required docking precise navigation problems propose approach visual path complement topological navigation 
visual path allows robot follow pre specified path location relying visual tracking features landmarks track visual features bird eye views image geometry topological navigation self localize robot design closed loop controller drive robot accurately desired trajectory pre specified image coordinates relative visual landmark 
combination omni directional images topological visual path navigation strategies illustrated complete experiments described 
believe complementary nature approaches omni directional imaging geometries result powerful solution build efficient robust navigation systems 
ii 
omni directional vision sensor omni directional camera provides rich description environment robot composed ccd camera pointed upwards platform aligned platform axis rotation see 
omni directional images contain ground wall regions spherical mirror distorts image projection general straight lines projected curves image horizon line projected image circle corridor appears image band narrower width points away robot lines belong vertical planes project straight lines 
catadioptric panoramic camera spherical mirror geometry image formation obtained relating coordinates point coordinates projection mirror surface pm image projection shows relevant parameters geometric model image formation 
spherical mirror radius denoted cm distance camera projection center reflection point pm observed camera angle mirror normal pm angle relative vertical spherical mirror zm pm rm projection center image plane fig 

camera spherical mirror projection geometry 
symmetry axis simplifies geometry 
axis incident reflection angles denoted elevation angle formed vertical axis ray point indicates radial distance optical axis vertical coordinate denoted rm zm mirror surface fulfill equations rm zm tan arctan rm zm equations reduced vertical plane containing vertical axis system rotationally symmetric axis equation expressed function vertical viewing angle coordinates point parameters involved equation fixed physical setup coordinates observed point 
projection point xyz denote coordinates point want find image projection uv ofp determine pm mirror surface project point image plane coordinates expressed cylindrical coordinates arctan vertical viewing angle expressed zm arctan rm rm zm denote coordinates pm mirror surface replace equations solve resulting non linear system equations determine rm zm 
notice knowing rm zm determines value 
project point pm rm zm image plane perspective projection account camera intrinsic parameters get fu fv tan cos tan sin fu fv denote focal length expressed vertical horizontal pixels position principal point image coordinate system 
fig 

top omni directional image left corresponding bird eye view right 
bottom panoramic image 
derived operator projects point image projection operator depends intrinsic extrinsic parameters catadioptric panoramic camera estimated set image projections known coordinates bird eye views images acquired omni directional camera naturally distorted instance corridor appears image band variable width knowing image formation model correct distortions obtain panoramic images bird eye views 
panoramic image scan line contains projections visible points constant angle elevation consists mapping concentric circles lines 
example horizon line transformed scan line 
bird eye views obtained radial correction image center bird eye view scaled orthographic projection ground plane significantly simplifies navigation system example corridors appear image bands constant width image bird eye views illustrated 
iii 
navigating topological maps topological map describe robot global environment map qualitative position robot traveling long distances mission specified go third office left hand side second corridor 
robot able travel corridor recognize ends corridor turns identify count door frames behaviors implemented appearance system visual servoing strategy 
appearance system provides qualitative estimates robot position corridor recognizes distinctive places corners door entrances achieved comparing current omni directional images previously acquired views corridor landmarks 
control robot trajectory corridor detect corridor guidelines generate adequate control signals keep robot desired trajectory processing performed bird eye views ground plane computed real time 
topological maps scale easily connecting graphs multiple resolutions map different regions environment hicks demonstrated obtain ground plane images directly custom shaped mirror 
fig 

eigenimages obtained omni directional vision system 
robot needs specialized behavior navigate links vision control process procedure recognize locations nodes actions may undertaken 
image eigenspaces topological maps topological map consists large set images acquired pre determined positions landmarks connected links graph robot perceives world omni directional images images natural way represent landmarks 
operation image best matches current view indicates robot qualitative position topological map images seen large dimensional space point indicates possible position robot 
general number images required represent environment large needs find method compress information build reduced order manifold approximate images principal component analysis pca described 
input space composed images ik pca determine set eigenimages ej form low dimensional subspace approximates original set images eigenimages eigenvectors covariance matrix formed input images computed efficiently eigenvalue proportional relevance associated 
shows eigenimages computed omni directional images represent corridor shown descending order accordance eigenvalues 
experiments keep eigenimages highest eigenvalues principal components 
images ik coded vector coefficients representing projection principal components ej reduced order eigenspace 
illustrates reduced order manifold eigenimages efficiently approximate original input images 
image ik associated qualitative robot position half way corridor 
find robot position topological map determine image best matches current view distance dk current view images computed directly projections fig 

input left retrieved right omni directional images similar 
lower dimensional eigenspace dk diagonal matrix containing ordered express relative importance various directions eigenspace notice dk computed dimensional coefficient vectors case opposed image size vectors position robot associated image ik having lowest distance dk 
omni directional images easier deal relatively dynamic environment people partially occlude robot view person close robot occlusion sufficiently large cause robot misinterpret topological position pca closest image correctly determined alternative approach taken number small image windows pixels deal occlusions tolerance illumination variations improved normalizing brightness distribution 
additional benefit building topological map omni directional images eigenspace forward return trajectories simply rotating real time acquired omni directional images similarly image power spectrum build eigenspace represent acquired images 
power spectra panoramic images invariant image rotation direction robot motion offers alternative way travel topological map recognize various locations irrespective robot orientation 
corridor behaviour navigate topological graph define suitable vision behavior corridor links map different environments simple knowledge scene geometry define behaviors 
exploit fact corridors parallel guidelines control robot heading direction aiming keep robot centered corridor 
visual feedback provided omni directional camera bird eye views floor simplifies servoing task images scaled orthographic projection ground plane perspective effects 
shows top view corridor guidelines robot trajectory follow center corridor 
images measure robot heading respect corridor guidelines distance central trajectory simple kinematic planner control robot position orientation corridor angular velocity single degree freedom consider look ahead distance defines instant goal point fig 

person close robot seen omni directional image 
retrieved image input image corresponding estimated position topological space 
occlusion affect topological position estimation 
fig 

left bird eye view corridor 
right measurements control law robot heading distance corridor center angle point ahead corridor central path 
error controlling robot orientation 
robot aim combining robot heading position errors obtain desired robot orientation arctan value quantifies influence displacement set image width corresponded meter value input dynamic controller controls robot angular velocity 
tracking corridor guidelines benefits bird eye orthographic views ground plane projective planar transformations homographies predict position points lines image 
describe euclidean image transformations computed reliably differential odometric data 
improvements eliminate need odometric readings 
extract corridor lines find edges predicted bounding boxes robust line fitting procedure ransac deal occlusions 
prediction accurate vastly improves probability extracting corridor guidelines erroneous data door frames shows sequence bird eye view images acquired tracking 
notice bird eye views ground plane simplifies extraction corridor guidelines corridor constant width computation robot position orientation errors respect corridor central path 
iv 
visual path topological navigation travel distant places relying accurate localization path 
local precise navigation tasks rely visual path door traversal docking navigating cluttered environments cases robot follow trajectory accurately 
feature tracking self localization bird eye views track environmental features estimate robot position orientation drive robot pre specified trajectory 
features corner points defined intersection tracked edge segments compare favorably terms accuracy stability corner detection filters 
long edge segments easier track corner points directly instance continually track edge segments intersection occluded image situation corner detector fail 
edge segments represented sampled points tracked searching image perpendicularly edge segments search criterion evaluation image gradient distance original edge position edge segments obtained robust fitting procedure new corner points determined intersection 
track edges lying ground plane vertical edge segments corner points defined intersection ground edge segments vertical ground line segments notice vertical lines project radial vertical lines bird eye view panoramic images 
robot position orientation estimated relative pre defined coordinate system process tracking simplified utilizing bird eye orthographic views ground plane preserving angular measurements uniformly scaling distances 
illustrates tracking self localization traversing door corridor room tracked features shown black circles defined vertical ground plane segments tracked bird eye view images 
currently user initializes relevant features track 
detect loss tracking operation process continuously self evaluated robot gradient intensities obtained specified areas landmark edges gradients decrease significantly compared expected recovery mechanism launched 
image num fig 

top feature tracking instants black circles bottom estimated scene model self localization results 
robot control robot state consists pose vector describing position pixels orientation navigation system modify robot linear angular velocities denoted robot dynamic model wheeled mobile robot degrees freedom linear angular velocities 
extended kalman filter estimate temporal evolution robot pose velocities assume constant driven white noise 
path follow defined set points expressed coordinate system units robot state vector time instant motion planning module de termine point trajectory ref determine position orientation errors correct robot motion ref argmin ref ref image num fig 

bird eye views tracking corridor guidelines 
avoid multiple solutions regularization term selects path point ref closest previous time instant ref signed distance path error orientation error defined ref ref nx ny ref nx ny normal path chosen point geometry kinematic motion planner shown 
image num ref ref ref fig 

kinematic motion planner points define control error visual path system 
dynamic controller generate robot angular velocity proposed path shown stable sin cos constants tuned designates path length local path curvature 
forward velocity equal maximum vmax safety reasons impose maximum value angular velocity wmax value achieved saturate reduce vmax wmax order avoid overshooting narrow turns 
experimental results experiments described undertaken instituto de sistemas rob tica isr lisbon portugal consists typical indoor environment corridors offices laboratories 
trc labmate robotics equipped omni directional vision system built house system contains ccd camera pointed upwards looking spherical mirror grayscale images captured full resolution pixels sub sampled images pca visual servoing visual path processing carried board mobile platform pentium ii mhz pc 
results obtained illustrate potential approach variety different tests show separate results topological navigation visual path integrated results combine global local navigation methodologies 
navigating topological map topological map built omni directional images acquired cm corridors corresponding distances bird eye views acquired local pose control positions ordered direction motion maintaining causality constraint 
show appearance methods provide qualitative estimates robot position acquired set prior images ran robot corridor acquire different set run time images shows distance dk see equation prior run time images run time global minimum prior images fig 

plot images acquired run time versus acquired priori plot represents traversal single corridor 
global minimum estimate robot topological position 
error surface presents global minimum corresponding correct estimate robot topological position degrades piecewise smooth manner spurious local minima due distant areas corridor may look similar robot current position local minima easily avoided restricting search space images close previous estimated position images captured sequentially direction motion 
cases obtain correct estimate robot position presence occlusions misclassification occurs results vicinity correct answer due smoothness error function 
shows results obtained driving robot corridor behaviors described section iii distance traveled approximately meters odometry display path graphically 
results show successfully drive robot corridor switch different behavior appropriate example behavior turn order proceed corridor 
visual path experiments visual path specified trajectory image coordinates relative single landmark composed rectangles mobile robot uses input omni directional camera move closed loop control described section iv 
figures show estimates self localization noise primarily due small size chosen landmark poor image resolution kalman filter effectively reduce noise mainly smooth paths shows errors trajectory dotted resulting visual self localization solid line small 
shows mobile robot final position completion desired navigation task 
processing time approximately sec image image processing remaining fig 

paths traveled robot isr 
xy pixel vs image num start orientation deg vs image num fig 

visual path trajectory specified image coordinates 
positions dotted line filtering solid line 
orientation dotted line filtering solid line 
dash dotted line shows landmark defines origin 
dotted line specified trajectory solid line shows filtered position estimates 
image mobile robot path 
displaying debugging information image acquisition serial communication mobile robot 
integrated experiments concluding experiment integrates global local navigation tasks combining topological navigation visual path approaches 
mission starts computer vision lab visual path navigate inside lab traverse lab door drive robot corridor corridor control transferred topological navigation module drives robot way corridor 
position new behavior launched consisting robot executing turn topological navigation mode drives robot back lab entry point backward trajectory image eigenspaces forward motion see section iii robot approximately located lab entrance control passed visual path module immediately locates appropriate visual landmarks see section iv drives robot door follows pre specified path final goal position inside lab reached shows image sequence robot experiment 
fig 

sequence images experiment combining visual path door traversal topological navigation corridor 
shows robot trajectory experiment estimate odometry returning laboratory uncertainty odometry approximately 
door traversal possible visual control 
mm mm fig 

experiment combining visual path door traversal topological navigation long distance goals 
trajectory estimate odometry top true trajectory bottom 
integrated experiment shows topological maps navigating distant environmental points visual path accurate path traversal resulting system robustly solve various navigation problems parsimonious available computational resources 
vi 
method visual navigation mobile robot indoor environments omni directional camera sole sensor 
key observation different navigation methods environmental representations different problems distinct requirements terms processing accuracy goals distinguish missions involve traveling long distances exact trajectory unimportant corridor opposed cases robot accurately follow pre specified trajectory door traversal types missions distinct paradigms topological navigation visual path 
topological navigation relies graphs describe topology environment qualitative position robot graph determined efficiently comparing robot current view previously learned images low dimensional subspace representation input image set 
node landmark different navigation behavior launched entering door turning left 
robot needs move cluttered environments follow exact path resorts visual path case tracked features closed loop visual controller ensure robot moves desired trajectory 
omni directional images navigation modes build necessary environmental representations 
example bird eye views ground floor substantially simplify navigation problems removing perspective effects 
combining topological navigation visual path powerful approach leads system exhibits improved robustness scalability simplicity 
zhang faugeras building world model mobile robot line segment representation integration proc 
int 
conf 
pattern recognition pp 

wehner wehner insect navigation maps ariadne thread ethology ecology evolution vol 
pp 

collett wehner visual landmarks route desert ant comp 
physiology vol 
pp 

schatz collett path integration guide route learning ants nature vol 
pp 
june 
santos victor sandini divergent stereo autonomous navigation bees robots int 
computer vision vol 
pp 

santos victor sandini docking computer vision image understanding vol 
pp 

yachida map navigation mobile robot sensor ieee trans 
robotics automation vol 
pp 

navigation system sensor proc 
int 
conf 
intelligent robotics systems pp 

lin hancock judd robust landmark system vehicle location low bandwidth vision robotics autonomous systems vol 
pp 

kato tsuji ishiguro representing environment target guided navigation proc 
int 
conf 
pattern recognition pp 

peri nayar generation perspective panoramic video proc 
darpa image understanding workshop pp 

nayar catadioptric proc 
ieee conf 
computer vision pattern recognition pp 

baker nayar theory catadioptric image formation proc 
int 
conf 
computer vision pp 

epipolar geometry panoramic cameras proc 
european conf 
computer vision pp 

wei yachida building local floor map ultrasonic omni directional vision sensor proc 
ieee int 
conf 
robotics automation pp 

kuipers modeling spatial knowledge cognitive science vol 
pp 

ko visually guided navigation proc 
int 
symp 
intelligent robotic systems pp 

winters santos victor omni proc 
int 
symp 
intelligent robotic systems pp 

hong tan weiss riseman image homing ieee int 
conf 
robotics automation pp 

jones andersen crowley appearance processes proc 
ieee rsj int 
conf 
intelligent robots systems pp 

memory omnidirectional images proc 
int 
conf 
pattern recognition pp 

turk pentland face recognition eigenfaces proc 
ieee conf 
computer vision pattern recognition pp 

matsumoto inaba inoue route representation proc 
ieee int 
conf 
robotics automation pp 

ishiguro tsuji image memory environment proc 
ieee rsj int 
conf 
intelligent robots systems pp 

horswill polly vision artifical agent proc 
nat 
conf 
artifical intelligence pp 

santos victor topological maps proc 
int 
conf 
computer vision systems pp 

de wit samson chap nonlinear control design mobile robots nonlinear control mobile robots yuan zheng ed 
world scientific series robotics intelligent systems 
santos victor visual path catadioptric panoramic camera int 
symp 
intelligent robotic systems pp 

srinivasan reflective surfaces panoramic imaging applied optics vol 
pp 

hicks bajcsy reflective surfaces ieee workshop perception mobile agents cvpr pp 

murase nayar recognition objects appearance int 
computer vision vol 
pp 

murakami kumar efficient calculation primary images set images ieee trans 
pattern analysis machine intelligence vol 
pp 

colin de re crowley local appearance space recognition navigation landmarks int 
symp 
intelligent robotic systems pp 

fischler bolles random sample consensus paradigm model fitting applications image analysis automated cartography communications acm vol 
pp 

