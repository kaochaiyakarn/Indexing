parameter adjustment bayes networks 
generalized noisy gate iez 
inform atica autom atica 
senda del rey 
madrid 
spain es 
spiegelhalter lauritzen studied sequential learning bayesian networks proposed models representation conditional probabilities 
forth model shown assumes parameter distribution product gaussian functions updates messages evidence propagation 
generalize noisy gate multivalued variables develop algorithm compute probability time proportional number parents networks loops apply learning model gate 
knowledge acquisition bottlenecks expert systems building 
bayesian networks bns having theoretical grounds supporting framework uncertain reasoning offer important advantage model construction 
field task consists building network observed cases gives optimal prediction ones 
fortunately field normative theory learning provided bayesian analysis look probable bn observed cases 
chosen variables step determine qualitative relations drawing causal links 
quantitative information obtained form conditional probabilities 
optimal situation happens available database containing large number cases values variables specified 
efficient algorithms eliciting structure proceedings th conference uncertainty ai washington dc july pp 

morgan kaufmann san mateo ca 
parameters network developed 
process performed database called batch learning allows automated discovery dependency relationships 
batch learning 
unfortunately cases contained database incomplete mathematical framework complex definitive theory learning established 
incomplete database knowledge engineer resort subjective assessments probability obtained human experts memory literature published field 
second situation model needs refinement desirable endow system capability adaptation executes 
process called sequential learning important sequential learning bns performed spiegelhalter lauritzen 
introduce assumptions mainly global local independence parameters see section order problem tractable 
problem difficult data incomplete variables determined 
final problem representation conditional probability tables propose different models discretization parameters dirichlet distributions gaussian distributions log odds relative probability state 
second approach applied 
problem addressed update sequentially parameters probability distribution 
main difference assume normal distribution parameters log odds 
study general case gate 
important reasons usually nodes bn observable 
means databases variable instantiated take criticism remembering value stored unobservable unobserved variable obtained directly inferred values variables 
unfortunately construction general bns incomplete databases complex normative algorithm exists :10.1.1.52.1068
assume initial causal network elicited human experts 
gaussian distributions allows integrate easily subjective assessments probability experimental results produces sigma patients 
parameter adjustment takes place network performs diagnosis new cases 
model learning naturally deal incomplete uncertain data 
general number parameters required family exponential number parents time evidence propagation 
gate hand number parameters proportional number causes 
difference considerable real world applications medicine dozen known causes disease 
building bn database resulting model gate accurate cases instantiation parent nodes 
human expert easier answer question probability cause lots questions entailing complex 
useful model sequential learning gate 
gate valuable knowledge acquisition evidence propagation 
applied probability tables save important amount storage space processing time 
algorithms usually employed probabilistic inference take advantage possibility 
section generalizes noisy multivalued variables develops efficient formulas propagating evidence 
allow local conditioning algorithm exploit gate networks 
parameter adjustment assumptions introduce section hypotheses constitute basis model 
case instantiation variables corresponding observed evidence assumption cases independence cases independent parameters theta theta assumption reasonable probability new case depends parameters model conditional priori probabilities cases far going find 
assumption key sequential updating probabilities ff theta delta gamma ff gamma normalization factor independent theta 
assumption parameter independence parameters priori pairwise independent 
includes local independence family formed node parents global independence different families 
clear holds arbitrary election parameters 
show case pedigree analysis example global independence clearly violated 
assumptions introduced 
specific feature model follows assumption gaussian distributions initial distribution parameter gaussian distribution je gamma oe oe min gamma eq 
implies theta outside interval theta assumptions allow apply simplifications derived 
statistical properties start multivariate normal distribution uncorrelated variables 
represented product gaussian distributions theta oe oe exp gamma gamma oe study new distribution theta ae theta normalization constant 
shall assume loss generality positive 
distribution non negative 
conditions guarantee theta outside interval theta approximately approximation moments new distribution delta oe gamma oe gamma delta delta oe observe normalization constant irrelevant 
advantage computations parameter adjustment unnecessary normalize messages 
covariance cov gamma delta delta properties condition non negativity allow conclude delta oe expected oe 
observe standard deviation reduced 
property ensure convergence applying study parameter adjustment 
algorithms purpose section apply statistical model order update parameters eq 

set parameters partitioned subsets relative arbitrary variable see fig 
theta includes parameters relative family un ym gamma gamma gamma gamma psi gamma gamma gamma psi delta delta delta delta delta delta theta theta gamma xj theta gamma messages family parameters determine xju represents possible configurations states parents theta theta gamma represent parameters determining probabilities families parents respectively 
way theta ux represents parameters link ux 
new case considering consists evidence observed 
node going update parameters information 
conditional probability theta xj theta gamma xj theta theta xj theta gamma xju theta theta definitions taken 
formulas general applied case complete conditional probability tables gates 
study general case represented giving parameter instantiation family xju theta 
probabilities values sum 
represented independent parameters xju theta gamma parameters eq 
turns theta theta gamma xj theta gamma gamma theta gamma theta axioms section theta theta gamma theta theta represents product univariate gaussian distributions 
expressions combined integration get theta je gamma theta xj theta gamma theta gamma theta gamma theta theta theta define xju gamma xju comparison eq 
study section applying equivalence gamma eventually find delta oe gamma new distribution parameter changed mean value delta variance oe oe gamma delta gaussian distributions general correlations arise case complete observed evidence sufficient determine exactly values variables 
order tractable model shall assume new distribution approximated product gaussian univariate distributions xju theta delta oe gamma delta gamma ju theta case treated way having sequential framework learning 
comments ffl approximation eq 
valid delta small compared min gamma 
resulting distribution differ gaussian function correlations eq 
negligible standard deviations wide observed values priori improbable 
approximations justified oe small say original model relatively accurate 
ffl messages obtained locally considering messages received node parameters family 
consequence global independence assumption 
allows distributed learning capability see fig 

ffl eq 
xju equivalent eq 
xju theta 
difference average values taken original distribution 
true eq 

evidence propagation model formally equivalent traditional case mean values exactly determined probabilities 
words need worry distributions take average value parameter neglect moment standard deviation 
ffl eq 
delta oe 
naturally parameter updated exactly determined 
ffl observe delta 
expected parameters family updated evidence arrives effects 
case oe delta values eq 
standard deviation parameter reduced time evidence observed corresponding configuration state 
ffl node parents priori probability dealt ordinary conditional probability adding dummy node representing fictitious binary variable value true 
ffl equations derived section including eq 
change multiplied constant 
necessary normalized defining xj theta theta xje theta theta defined xj theta theta theta theta formalism applied evidence propagated local conditioning algorithm learning method applied general networks singly connected ones 
generalized noisy gate definition algorithms noisy gate introduced 
model parent node conceived mere factor age patient instance modulating probability certain configuration parents sex weight smoking 
node represents physical world entity example disease may absent parents represent phenomena general anomalies presence produce words link gate represents intuitive notion causation produces statistical definition 
main advantage gate number parameters proportional number causes exponential general case 
consequence gate simplifies knowledge acquisition saves storage space allows evidence propagation time proportional number parents 
generalization multivalued variables introduced henrion order simplify knowledge eqs 
slightly modified 
chosen original definition just simplicity 
eq 
oe eq 
oe eq 
delta eq 
learning node acquisition 
model save storage space clustering method chosen evidence propagation conditional probability table family worked advance wasting computational advantage gate 
reason formalizing model develop algorithm computing probability time proportional number causes deal multiply connected networks 
definition graded variable variable absent degrees intensity said graded variable 
possible values assigned non negative integers means absence succeeding numbers indicate higher intensity 
observe concept graded independent number outcomes multivalued variables represent different degrees presence conversely definition includes binary variables intervening noisy type absent differ non graded binary variables sex 
concept relevant gate sense graded variables 
parameters certain family gate conditional probabilities causes absent case cause causes xju abbreviated xju obviously gamma gx causes absent absent ae consequence gu delta parameters required link 
introduce definition qu xje ux probability evidence link case causes absent 
xje ux xju ux deduced qu gamma gu gx far section introduced definitions assumption 
going key axiom gate allow calculate probability causes 
leaky probability assigned certain anonymous cause 
way treatment trivially extensible leaky gate 
definition generalized noisy gate bayes network graded variable parents un graded variables say interact generalized noisy gate xju un xju interpretation follows degree reached maximum degrees produced causes acting independently synergy 
eq 
reflects fact cause raised degree higher model interaction termed max gate 
way graded gate called min gate 
definition xje straightforward get ae gamma gamma eq 
qu allows compute 
summarize get qu combining messages arrive time proportional number causes claimed 
case family formed part loop local conditioning applied messages normalized formulas remain valid minor modifications 
link lies loop path conditioning apply qu messages allows important additional save computation gate 
similar treatment gate studied gate appears 
additional advantage gates enable generate explanations evidence hand increased reduced probability 
parameter adjustment gate going develop formalism parameter adjustment gate similar section general case 
starting point eq 

expression xj theta theta similar eq 
just including conditioning parameters theta 
way expression xj theta theta similar eq 
global independence parameters leads xj theta theta qu xj theta theta ux theta parameters associated link ux 
eq 
get qu xj theta theta ux gamma gu uj theta ux gx expressions substituted eq 

assumptions independence allow integrate parameters outside link ux defining gamma gv gx ru gamma qv gx qv arrive theta cases ru gamma gu gx theta ru gamma gamma gx gu gamma ru theta comparing expression eq 
substituting eq 
conclude delta gamma oe gamma ru ru gamma gx gu gamma ru case binary variables gx just parameter link ux 
notation result simplified delta oe gamma gamma gamma gamma gamma repeating considerations general case observe equation means evidential support presence delta positive delta negative expected result parameter represents probability produces model parameter adjustment bayesian networks 
starting point bn conditional probability mean value standard deviation 
main virtue approach updating parameters performed locally distributed node messages evidence propagation 
statistical model cumbersome consequence notation ideas involved leads simple algorithms 
tried show agreement results expected common sense 
mathematical definition generalized noisy gate multivalued variables shown compute probability time proportional number parents 
conjunction local conditioning method networks loops representing important advantage inference algorithms conditional probability tables 
learning model applied gate 
main shortcomings model reside strong assumptions independence approximation valid standard deviations wide observed evidence differs significantly expected values 
directed prof jos mira thesis advisor supported plan nacional de de personal spanish ministry education science 
benefited comments marek druzdzel anonymous referees 
buntine :10.1.1.52.1068
theory refinement bayesian networks 
proceedings th conference uncertainty artificial intelligence pages los angeles ca 
morgan kaufmann publishers san mateo ca 
iez 
local conditioning bayesian networks 
technical report cognitive systems laboratory university california los angeles 
submitted artificial intelligence 
iez mira 
distributed reasoning bayesian expert systems 
editor advances fault diagnosis problem solving 
crc press boca raton fl 
appear 
dubois wellman ambrosio smets editors 
proceedings th conference uncertainty artificial intelligence stanford university 
morgan kaufmann publishers san mateo ca 
henrion 
practical issues constructing belief networks 
kanal levitt lemmer editors uncertainty artificial intelligence pages 
elsevier science publishers north holland 
henrion druzdzel 
qualitative propagation scenario schemes explaining probabilistic reasoning 
bonissone henrion kanal lemmer editors uncertainty artificial intelligence pages 
elsevier science publishers north holland 
jensen olesen andersen 
algebra bayesian belief universes knowledge systems 
networks 
lauritzen spiegelhalter 
local computations probabilities graphical structures application expert systems 
journal royal statistical society series 
olesen lauritzen jensen 
system creating adaptive causal probabilistic networks 
proceedings th conference uncertainty artificial intelligence pages stanford university 
morgan kaufmann publishers san mateo ca 
pearl 
fusion propagation structuring belief networks 
artificial intelligence 
pearl 
probabilistic reasoning expert systems 
morgan kaufmann san mateo ca 
revised second printing 
pearl verma 
statistical semantics causation 
statistics computing 
peot shachter 
fusion propagation multiple observations belief networks 
artificial intelligence 
spiegelhalter bull 
assessment criticism improvement imprecise subjective probabilities 
henrion shachter kanal lemmer editors uncertainty artificial intelligence pages 
elsevier science publishers north holland 
spiegelhalter lauritzen 
sequential updating conditional probabilities directed graphical structures 
networks 
