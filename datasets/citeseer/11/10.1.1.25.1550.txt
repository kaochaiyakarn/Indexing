draft november appear proceedings th th dimacs implementation challenges goldwasser johnson mcgeoch eds american mathematical society 
theoretician guide experimental analysis algorithms david johnson labs research www research att com november presents informal discussion issues arise attempts analyze algorithms experimentally 
lessons learned author course decade experimentation survey writing lively discussions 
written perspective theoretical computer scientist intended researchers fields want study algorithms experimentally 
goals provide useful guide new best performed written second challenge current researchers think improved scientific point view 
purpose mind author hopes recommendations considered controversial 
common days distinguish different approaches analyzing algorithms worst case analysis average case analysis experimental analysis 
ordering approaches theoretical computer scientists choose experimental analysis treated afterthought 
experimental analysis algorithms invisible theoretical computer science literature experimental dominates algorithmic research areas computer science related fields operations research 
past emphasis theoreticians rigorous theoretical modes analysis course expected 
strong justifications 
day difficult draw useful extrapolations experimental studies 
lack scientific rigor early experimental led knuth researchers emphasize worst average case analysis general provide especially respect asymptotic behavior 
benefits mathematical approach added understanding old algorithms invention new algorithms data structures ones served faster machines larger memories allowed attack larger problem instances 
interest experimental theoretical computer science community 
theorists suddenly discovered love programming necessarily growing recognition theoretical results tell full story real world algorithmic performance 
encouragement experimentation come actively experimenting funding agencies view experimentation providing pathway theory practice 
result relatively new forums include experimental theoretical highlight hybrids 
include acm journal experimental algorithmics acm siam symposium discrete algorithms soda european symposium algorithms esa workshop algorithm engineering workshop algorithm engineering experimentation 
addition traditional forums experimental operations research mathematical programming artificial intelligence scientific computing communities 
value added involving theoretical computer scientists experimentation 
real possibility experience real world computing may turn theoretical research agenda suggesting new questions study establishing connections applications 
am interested influences go direction 
background theoretical analysis algorithms help doing experimentation 
hope strongly supported researchers bentley goldberg ben cgr theoretician concern asymptotics generality understanding help drive scientific approach experimentation 
scientific bias stressing providing general advice 
unfortunately researchers discovered field experimental analysis fraught pitfalls 
ways implementation algorithm easy part 
hard part successfully implementation produce meaningful valuable 
research results 
purposes argument basic reasons worthwhile implement algorithm giving rise different type papers hybrids type 
ffl code particular application 
typically gives rise application purpose describe impact algorithm context 
includes called experimental mathematics application generation proof mathematical conjectures primarily interested output algorithm efficiency 
ffl provide evidence superiority algorithmic ideas 
gives rise call horse race results published standard benchmark instances illustrate desirability algorithm comparison previous competitors 
ffl better understand strengths weaknesses operation interesting algorithmic ideas practice 
motivation call experimental analysis 
ffl generate conjectures average case behavior algorithms specific instance distributions direct probabilistic analysis hard 
leads call experimental average case 
say applicable types follows concentrate mainly third type sense general type experience author reader referee editor scholar survey writer 
roles opportunity read widely experimental literature special emphasis papers traveling salesman problem tsp surveyed jm 
unfortunately seen papers seriously defective ones set examples 
fairly papers typically receive referee reports suggesting significant revisions involving substantial additional experiments 
note shall attempt draw experience articulating set general principles applicable experimental papers explaining satisfy 
presentation organized terms basic overlapping principles believe govern writing experimental papers 
perform experiments 

tie literature 

instance testbeds support general 

efficient effective experimental designs 

reasonably efficient implementations 

ensure reproducibility 

ensure comparability 

report full story 

draw justified look explanations 

data informative ways 
remainder discuss principles turn explaining mean elaborating implications 
way highlight pitfalls practices lead experimenters substantial wastes time personal pet literally favorite common experimental practices particularly misguided 
practices may obviously bad worth mentioning seen worth explicit discussion 
practices list pet common labeling misguided may come surprise argue violate principles 
cases highlight suggestions avoiding pitfall pet peeve cite papers suggested practices exploited explained 
specific citations bad behavior part omitted spare guilty included 
view issues evolved years 
may impossible write avoids pet 
appendix collect pitfalls pet suggestions separate lists ease 
concentrates study algorithms problems standard format instances outputs finite objects key metrics resource usage typically time memory case approximation algorithms quality output solution 
key computational problems fit model short section mention challenge reader think ideas adapted extended domains issues arise 
conclude final collection warnings unable fit conveniently main body text 
said principles enunciated may somewhat controversial elaborate 
common agreement experimental analysis algorithms certain aspects subject debate relevance running time comparisons 
points view see papers bgk cs hoo mcg mm ru 
particular constructed earlier short draft joh template adding material developed process giving talks expanding draft 
points view expressed refined augmented years stimulating discussions researchers including richard anderson david applegate jon bentley andrew goldberg cathy lyle mcgeoch kurt mehlhorn bernard moret panos pardalos mauricio resende gerhard woeginger 
section 
discussions principles main section discuss illustrate principles outlined 
principles interlinked discussion unavoidable refer tried avoid repetition possible points worth repeating 
principle 
perform experiments principle applies scientific papers results new interest reasonably sized collection readers 
standards interest stringent experimental algorithms papers 
instance harder justify experimental problems direct applications justify theoretical problems 
theoretical researchers choose problems amenability analysis hope representative lessons learned proof techniques developed may widely applicable 
contrast problems amenable experimental analysis sort lessons learned experimental analysis typically highly problem instance specific 
problems applications real world instances experimenter left invent justify test data vacuum 
referees may question testing code algorithms practice 
second dimension algorithms studied 
key question algorithm useful alternative practice 
theoretical analysis especially worst case analysis relied answer justify studying wide variety algorithms point question practicality answered assuming plausible argument favor practicality place 
answer definitive value writing papers algorithm limited necessarily eliminated 
consider example case dominated algorithm slower studied competitor case approximation algorithms produces better solutions 
pitfall 
dealing dominated algorithms 
suppose spend time implementing testing algorithm turns dominated 
may lost 
experimental literature devoted dominated algorithms 
cases fact algorithm dominated known time written known author referees 
pet peeve 
authors referees don homework 
particularly annoying authors cite relevant clearly haven read parts relevant experiments 
know discover algorithm dominated 
algorithm newly invented written pretty luck 
people interested fact previously unknown algorithm bad 
known algorithm assuming adequately studied possible situations ffl algorithm widespread algorithms dominate complicated soon enter widespread 
detailed study algorithm performance gives sophisticated approaches interest 
ffl algorithm question embodies general approach applicable problem domains provides mechanism studying performance data structures algorithmic constructs studying best adapt underlying approach current domain may general consequences 
argument example viewed possible justification papers published dominated metaheuristic algorithms tsp see jm 
ffl algorithm known expected behave poorly verified previous options apply 
case luck negative result worth including general talked algorithms 
ffl algorithm sufficient independent interest promising theoretical results widespread publicity fact dominated unexpected 
worth note better part comprehensive study 
situation fact algorithm dominated 
note domination easy establish conclusively running times depend strongly implementations machine operating system interactions 
cases simply getting factor algorithm running time may claim competitiveness 
facing difficult task proving negative experimentally demonstrate great differences performance convince readers missed important instance class supposedly dominated algorithm outperforms competitors 
convince readers simply mis implemented algorithm 
example early papers simulated annealing claimed dominated approaches domains question 
implementations described papers parameter settings severely limited computation time subsequent experiments showed allowing annealing process take long time enabled perform domains compared long running algorithms 
original papers show simulated annealing dominated just particular bad implementations 
precisely defined algorithm simulated annealing convincing readers efficient correct implementation may easier added burden requiring extra measurements identify unavoidable bottlenecks algorithm operation 
third dimension generality relevance credibility results obtained derivable 
necessity limited finite number tests interesting results yield broader insights terms asymptotics presumptions robustness point shall elaborate discussing principle 
way experimental higher goals horse race settle simple tested algorithm produces stated results set benchmark instances 
algorithm outperforms algorithm interesting believable supported measurements operation counts subroutine profiling show detail happens 
talk little strategies getting results experiments pitfalls way 
pitfall 
devoting computation wrong questions 
computational cycles cheap days tempting worry wasted computation time 
computation time includes time spent setting running evaluating experiments just user time reported operating system 
want production process efficient algorithms pays systematic 
examples potential wastes time include ffl excessive study results just instances 
natural temptation parameterized algorithm needs tuning 
typically computing time better spent testing variety instances systematic way 
ffl running full experimental suites finish figuring implementation efficient 
ll doubt rerun experiments new code anyway runs probably take time 
ffl running full experimental suites decided data collect instrumented code report data 
ll probably rerun experiments 
suggestion 
think compute 
issues need resolved major data generation project include 
algorithmic phenomena want study questions want experiments address 
care answers current state literature area 
implemented algorithm correctly incorporating features variants want study providing production output data ll need 
adequate set test instances runs yield convincing answers questions asked 
current computer speeds memory capacity instances small yield meaningful distinctions large yield feasible running times 
course thinking presupposes done little computation 
order resolve issues mentioned perform exploratory experiments 
suggestion 
exploratory experimentation find questions 
exploratory experimentation mean testing formal data collection process computational study 
includes experiments performed debugging optimizing code pilot studies various sorts 
addition trying confirm algorithm competitive previous approaches examining performance varies instance type size profiling code determine computational bottlenecks sorts tradeoffs involved various program design data structure choices 
special interest unexpected anomalies performance reproducible may merit study 
assuming study simply reveal bugs code may suggest surprising insights way algorithm performs 
research tend take iterative approach 
spend half proposed experimentation time generating lots data looking patterns anomalies 

finalize algorithm implementation decide interesting questions design perform comprehensive experiments investigate 

analyze resulting data 
fails answer questions raises new ones go back step 
tends lead results dangers pitfall 
getting endless loop experimentation 
experimental papers improved extensive experimentation point draw line leave remaining questions infamous research section 
prepared resist temptation keep going requests referees additional non essential experiments 
gets finished provide news 
point having discussed dangers working wrong questions described techniques finding right questions say bit questions sorts answers problems algorithms studied pass test 
list means exhaustive cover range possibilities 
typical address questions 
list simplicity follow common practice algorithm shorthand implementation algorithm 
descriptions algorithms technical papers texts omit technical details implementer fill affect performance 
experiments typically give direct information implementations 
extensive study may able deduce implementation independent properties algorithm specific implementation details need included description algorithm promote best performance 
question 
implementation details parameter settings heuristics data structure choices affect running time algorithm 

running time algorithm scale instance size depend instance structure 

algorithmic operation counts best help explain running time 

practice computational bottlenecks algorithm depend instance size structure 
differ predictions worst case analysis 

running time running time growth rate affected machine architecture detailed profiling help explain 

running similar instances fixed machine predictable running times operation counts 
wide variability affect usability algorithm 

algorithm running time compare top competitors comparisons affected instance size structure machine architecture differences explained terms operation counts 

answers questions running time replaced memory usage usage computational resource assuming algorithm usage isn easily predictable theory 

answers questions deals approximation algorithms running time replaced solution quality 
standards comparison measure solution quality covered discussion principle 

substantially new class instances identified cause significant changes algorithmic behavior previously studied algorithms 
conclude discussion mentioning temptation lead astray 
pitfall 
start randomly generated instances evaluate behavior algorithms algorithms investigate properties instances 
example kind behavior flurry activity random instances sat 
early experimenters looking hard instances test discovered randomly generates clauses variables obtains transition instances fewer clauses highly satisfiable instances clauses probably unsatisfiable instances just clauses tend difficult known algorithms solve 
observation useful algorithm evaluators gave nice unrealistic class challenging test examples 
suggested interesting mathematical questions precise nature phase transition asymptotic properties 
unfortunately effect hijacking experimental research satisfiability algorithms examining just class instances variants clear experiments tell performance structured instances tend occur real world applications 
second benign example experimental jmr pm devoted estimating expected optima random euclidean instances tsp 
tsp random geometric instances provide performance practice 
tight bounds expected optima may give useful metric evaluating quality solutions produced approximation algorithms instances large instance specific bounds easy obtain 
course performing experiments order deduce properties random instances justified straight mathematical grounds may intrinsic interest performance heuristic 
experimental mathematics experimental analysis algorithms sense represents diversion task concerned 
principle 
tie literature key component establishing placing proper context respect literature problem studied 
undertaking experimental project best discover thoroughly study prior literature exists 
go saying surprisingly papers failed lack point 
knowing done save performing uninteresting experiments suggest interesting questions 
behavior needs explaining 
algorithms open improvement 
types test instances adequately studied 
problem literature obligations opportunities 
assuming earlier studied instances large considered interesting today provide comparisons results earlier 
case experimenter job may difficult theoretician 
potential difficulty direct comparisons may problematic 
earlier may dealt algorithm similar test instances may dealt precisely test instances implementation algorithm provide running times machine operating system combination today 
ideally goal provide comparisons previously studied algorithm obtain code implementation algorithm previous experiments report results code machine verifying results consistent reported code previously 
possible best option develop comparable implementation previous algorithm run machine comparisons previously reported results comparable effectiveness 
added benefit helping confirm algorithmic claims earlier 
unfortunate event implementations appear comparable effectiveness example appears run quadratic time linear time point noted explanations provided possible implementation linear time see principle 
desirable option occasionally resort attempting provide comparisons hard implement incompletely specified algorithm literature simply compare results machine test instances reported previous 
cases previous experiments performed unfamiliar architecture may impossible 
typically provide significantly accurate bounds relative machine speeds answer question running times possibly competitive implementation clearly faster 
rough comparisons better 
readers need see fits literature fit best approximate 
principle 
instance testbeds support general basically types test instances available experimenters particular instances real world applications pseudo applications randomly generated instances 
typically standard repositories tsplib rei come private sources proprietary author 
provided instance generators seed list instance parameters size details instance structure produce random instance consistent parameters 
note random instances need random graphs random distance matrices preferably structured ways reflect aspects real world instances 
key property random instance generators able generate instances arbitrarily large size 
allows get partial handle types asymptotic questions typically addressed theoretical analysis machine dependent effects cache limitations typically precise asymptotics impossible 
determine biggest instance reasonably run machine idea larger runnable instances generation machine greater speed memory 
key questions practice 
gives random instances advantage experimental studies substantially dissipated evidence random instance class says happen real world instances 
pet peeve 
concentration unstructured random instances 
may unstructured random instances tell little real world performance may actively mislead difficulty problem 
example papers optimization algorithms asymmetric tsp concentrate asymmetric distance matrices entries chosen independently randomly small ranges ng number cities 
instances particularly easy increases optimal tour length equal easily computed assignment problem lower bound 
authors ability codes find optimal solutions instances sort thousands cities codes great difficulty structured instances tsplib containing cities 
get trouble concentrating solely real world instances especially outdated ones pet peeve 
millisecond testbed 
computer speeds grown rate problem areas modern running times old testbeds shrunk 
seen maximum running time reported algorithms tested instances studied second 
despite fact papers devote effort determining algorithm fastest 
maintain applications algorithm takes second running time probably irrelevant algorithm takes seconds machine doesn provide significant advantage takes times faster 
exception real time computing applications usually relevant applications question need solve thousands instances quickly usually relevant 
argue factor difference larger instances case test larger instances confirm advantage persists instance size grows 
pet peeve 
solved testbed 
related philosophical objection 
evaluating approximation algorithms need standard measure solutions desirable standard course optimal solution value 
natural temptation restrict testing instances optimal value known 
major reasons resorting approximation algorithms handle cases hard find optimal values restricting tests instances optima known essentially ignores domain algorithms intended 
argue approximation algorithm faster optimization algorithm examining trade running time solution quality 
papers restrict attention instances optima known simply take optimum values literature seriously address question relative running times 
typically nontrivial instances optimum solutions known relatively small 
previous pet peeve restricting instances doesn allow address questions algorithm performance scales instance size 
alternative occasionally tried construct large artificial instances way optimum solution value known advance 
unfortunately restricting tests solely instances yield results narrow artificial nature instances 
evaluate instance quality instances unknown optima discuss detail get principle 
returning general discussion real world test beds note test bed contains reasonable range instance sizes papers study instances testbed hard task drawing general algorithms operate design experiments isolate instance properties test affect performance 
set real world instances broad varied may able draw robustness various performance measures instance types 
hybrid approach clearly recommended 
idea study structured random instance classes combined results real world instances enable reader evaluate predictive quality random results 
especially useful parameterized random instance generators washington network generator anderson available dimacs ftp dimacs rutgers edu pub netflow generators allow investigate effect structure size performance 
principle 
efficient effective experimental designs earlier warned danger spending computation time wrong questions identified right questions ones want answer computational savings 
particular exist important techniques help reduce amount computation need perform allow get broader accurate answers 
mention just specific ones 
suggestion 
variance reduction techniques 
dealing randomized algorithms randomly generated instances variability runs algorithms instances may obscure results hard draw 
may perform large numbers runs test large numbers instances obtain reliable estimates average performance 
variance reduction techniques help reduce numbers 
broad ranging survey techniques see mcg 
mention useful reducing effects instance variability 
suppose attempting compare average performance approximation algorithms class randomly generated instances 
independently estimate average performance algorithm instance class comparing estimates set randomly generated instances tests 
algorithm sees instances variability instances factored comparison 
may tight confidence intervals average solution qualities algorithms distinguish statistically estimate average difference solution values may statistically significant allow claim better 
variant technique studying algorithms tsp evaluate solution quality tour length terms excess held karp bound instance 
popular model cities correspond points uniformly distributed unit square distances euclidean obtain estimates expected value bound number cities jmr compare algorithmic results estimates 
gets precise performance metric fewer samples focuses difference algorithm tour length held karp bound instance 
suggestion 
bootstrapping evaluate multiple run heuristics 
randomized approximation algorithms practice may want exploit variability results performing multiple runs best solution 
naive way estimate expected behavior algorithm perform runs algorithm take best run algorithm number times compute average best requires mk total runs runs better spent technique known bootstrapping sort mk results order solution value 
relatively simply matter compute expected best value random sample results chosen independently replacement estimate better data simply average 
data set estimate expected best results values note going take approach special attention paid obtaining correct estimations running time especially best algorithms need read instance perform preprocessing steps amortizing operations runs 
may performed steps just km runs sure measure time separately order account properly final running time figures 
minor addition total involved 
leads final suggestion experimental design 
suggestion 
self documenting programs 
suggestion designed reduce experimenter time needed computation 
generate large quantities data deal problem organizing accessing data 
note accesses may take place years example response referee report desire follow study 
dangerous rely simply personal memory 
saving data files directories descriptive names help constructing readme files providing directory road maps information 
data accurately interpreted fact useless data 
desirable output files contain linked information want know experiment generated 
includes performance metrics running time solution quality name version algorithm machine run date help case machine gets upgraded name instance applied settings adjustable parameters subsidiary measurements operation times counts intermediate solution values think may interest 
minimize possibility misinterpretation rely syntax output file tell data item include name item algorithm version item 
detailed discussions issues see ben mcg 
principle 
reasonably efficient implementations surprisingly somewhat controversial principle 
glance obvious want efficient implementations especially field algorithm design efficiency main goals efficiency come cost programming effort situations researchers argued allowed settle 
example problem domains traveling salesman problem example best algorithms gain speed sophisticated data structures speed tricks 
places fairly high barrier entry researchers new algorithmic ideas want promote order get competitive codes incorporate new ideas may implement complicated speed mechanisms 
researchers attempted argue permissible forgo speed ups get meaningful results 
pet peeve 
claiming inadequate programming time ability excuse 
cases researchers simply assert implementations competitive previous algorithms time skill speed mechanisms 
slightly sophisticated variant involves comparing results speed free implementation algorithm implementation competitor speed mechanisms disabled 
implicit claim running time comparisons speed free case translate directly situation codes included speed mechanisms 
highly suspect argument 
hard quantify speed obtained implementing additional mechanisms implement test 
second guarantee speed mechanism equally effective different algorithmic approaches 
third slower implementations perform tests handle large instances crucial comparative data missed 
second reason argue saving programming time expense additional computation time guilty arises case primarily studying metric quality solutions produced approximation algorithm speed mechanisms affect running time solutions 
machine sufficiently fast enable inefficient implementation generate data need acceptable referees start asking data larger instances 
general advantages efficiency 
efficient implementations easier support claims practicality competitiveness 

results implementations significantly slower want practice may yield distorted pictures 

faster implementations allow perform experiments larger instances finish study quickly 
note principle imply need go efficiency issues fine tune code save running time 
mean implement theoretical refinements yield small improvements worstcase running time especially indication tweaking major practical impact 
current principle refers reasonable efficiency 
specific experimental goal evaluate impact running time theoretical refinements speed tricks advised avoid pitfall 
pitfall 
code tuning 
certainly efficient data structures called real world implementers theta sorting algorithms typically avoided 
situation advance thinking experimental exploration save effort 
understanding computational bottlenecks algorithm lie profiling early implementations determine code optimizations sophisticated data structures major effect concentrate programming effort 
ideally efficiency code test constant factor practice code expect people real world 
principle 
ensure reproducibility scientific studies key part experimental reproducibility results 
reproducibility mean context experimental analysis algorithms 
strictest sense means ran code instances machine compiler operating system system load combination get running time operation counts solution quality averages case randomized algorithm 
informative correspond meant reproducibility classical scientific studies 
reproducing study scientist basic methods typically different apparatus similar distinct materials possibly different measuring techniques 
said reproduced original results data obtains consistent original experiments supports 
way helps confirm results original experiment drawn independent precise details experiment 
broader notion reproducibility consider important 
implications experiments report 
experiments need extensive give confidence true artifacts experimental setup machines compilers random number generators particular instances test reporting results describe algorithms test instances computing environment results detail reader principle perform similar experiments lead basic 
typically necessary provide precise instances tested unique properties difficult reproduce 
results original experiment reproducible broader sense able obtain similar results similar distinct instances 
token original claimed hold algorithm particular implementation broader notion reproducibility require test independent implementation algorithm described original author code available 
enhance confidence avoids significant danger 
pet peeve 
supplied code doesn match description 
code author supplies precisely implement algorithm described corresponding 
differences range incorrect input specifications serious issues missing added steps 
typically honest mistake due poor record keeping author part frustrating 
course original refer performance specific code algorithm implements reproducibility require author provide access code 
happen instance evaluation software packages papers provide complete description details algorithms involved 
similarly dealing horse race main algorithm implementation beats algorithm implementation testbed instances reproducibility requires author provide access testbed 
cases product testing science main focus 
complicating issue reproducibility fact key algorithmic measurement interested inherently broad sense advocating 
running time 
broadly reproducible results machine dependent fixes implementation instance running times dependent machine compiler operating system system load factors 
best hope conclude running times different combinations machines operating system sense consistent measurements relative speeds combinations 
say inexact science making comparison discussion principle ensure comparability 
principle reproducibility violated literature today 
simple failures report key information appropriate provide access code instances obvious pet peeve 
standards comparison 
suppose experimentally evaluating approximation algorithms followed advice restricted attention instances optimal solution value known 
confronted question measure relative goodness solution 
list answers question encountered associated reproducibility drawbacks fatal see mcg 
ffl simply report solution value 
certainly reproducible narrow sense broader sense perform experiments similar instances determine getting similar results 
provides direct insight quality algorithm 
ffl report percentage excess best solution currently known 
narrowly reproducible explicitly state current best instance available researchers 
unfortunately authors omit actions 
provide instance value approach yield reproducible results broader sense 
furthermore current represent moving target usually tell current testbed equally 
may left clear picture algorithm true quality 
ffl randomly generated instances report percentage excess estimate expected optimal 
approach leads reproducible results explicitly states estimate completely specifies method computing 
leads meaningful results estimate fact consistently close expected optimal ii values true optima distribution relatively low variance 
applications approach seen requirements satisfied 
ffl report percentage excess defined lower bound 
example approach discussion principle described held karp tsp lower bound hk hk jmr variance reduction 
assuming lower bound usually close optimal solution case held karp bound useful approach 
reproducible lower bound feasibly computed reliably approximated 
started held karp lower bound standard comparison tsp joh probably completely meet criteria compute estimates quality guarantee 
subsequent validation experiments showed estimates reliably close true value dealing randomly generated instances 
bound calculated exactly instances large cities publicly available concorde code abcc 
unfortunately problems computable bounds 
ffl report percentage excess improvement heuristic 
appears ultimate fallback option 
reproducible long heuristic completely specified 
unfortunately difficult specify heuristic complicated authors settled simply naming heuristic simply saying opt lin kernighan favorite example gross underspecification simulated annealing 
algorithms variants having wide range behaviors name provide detail distinguish 
apply approach successfully best simple algorithm standard specified precisely words preferably deterministic 
complicated benchmark algorithm desired viable option provide source code implementation source code available web 
pet peeve 
running time stopping criterion 
types approximation algorithm example multiple start local search truncated branch bound provide better better solutions longer lets run 
practical situation limited computation time available may want simply run code hour take best solution far 
note run code hour defined algorithm yield reproducible results 
machine different processor operating system just efficient implementation algorithm machine get solutions having distinctly different level quality 
defining algorithm way acceptable scientific 
temptation stopping criterion especially strong comparing variety different algorithms 
authors hopes providing fair comparison performed experiments algorithm allowed amount running time say minutes 
comparisons reproducible 
test machine times faster algorithms presumably better relative rankings may change substantially 
wants reproducible fair comparisons 
solution design codes readily measurable combinatorial count number neighborhoods searched number branching steps stopping criterion 
defined algorithm running time quality solution measured function combinatorial count reproducible 
data average values metrics function count derive table reports results specific running time includes combinatorial counts associated running time algorithm 
subsequent researchers principle reproduce table counts observe differences caused machines implementations affected various running times may may remain roughly equal 
pet peeve 
optimal solution value stopping criterion 
complaint optimization algorithms optimal solution proved optimal 
practice encountered papers metaheuristic literature algorithms concerned mechanism verifying optimality simply look solution stopping criterion reached 
papers question algorithms instance optimal solution value known halted early solution optimal value 
algorithms typically back stopping criterion instances unknown optima runs fail find known optima 
temptation truncate searches way guess natural know optimal solution value heuristic waste time reached goal 
drawback approach practice typically run approximation algorithm instances optimal solution known 
practice know optimal solution value reached stopping criteria 
tests instances known optima need reflect performance practice benefit early stopping felt reproducible sense dramatically different running times reported similar instances depending knew optimal value 
pet peeve 
hand tuned algorithm parameters 
heuristics parameters need set algorithm run 
instance multiple start local optimization algorithm specify number starts 
elaborate metaheuristics simulated annealing tabu search genetic algorithms come ensembles adjustable parameters 
algorithm defined fix parameters define way depends measurable aspects instance handled 
case fixed parameters problem reproducibility long reports settings chosen informative useful insight provided performance affected changes settings 
case papers different settings different instances explaining settings derived words experimentation settings instance class instances 
drawbacks approach 
means algorithm ill specified parameter setting process explained detail 
involved human experimentation judgment may involved sort codified procedure 
second reported running times typically include time spent determining parameters leads serious underestimate computing time needed apply algorithm new instance class instances 
rule apply different parameter settings different instances adjustment process defined algorithmic adjustment algorithm described time adjustment included reported running times 
pet peeve 
run study 
study covers wide range instances large number runs case randomized algorithms drawn may wrong reason 
amount data needed course vary detail 
algorithm may settle trying indicate general trends performance quantifying may require fewer test instances fewer runs test instance subsequent wishes characterize specific aspects performance accurately 
remembered instances distribution widely varying properties especially instances small size randomized algorithms yield widely varying results instance 
dangerous infer single run single instance 
pet peeve 
best result evaluation criterion 
randomized algorithms avoid dangers run study performing multiple runs instance 
lead 
providing tables results randomized approximation algorithms papers include column best result average result 
objections twofold 
best solution sample tail distribution reproducible average 
second tables running times reported usually single run algorithm entire ensemble runs yielded reported best 
time obtaining answer obscured 
case number runs performed clearly stated way determine running time 
number runs stated note simple process multiplying running time number runs may overestimate time needed certain actions reading instance setting data structures may need done multiple runs performed 
think practice users may want perform runs take best appropriate experimental approach evaluate algorithm perform runs take best directly reporting running time solutions iterative approach 
saw discussion principle efficient techniques performing evaluations bootstrapping 
principle 
ensure comparability principle essentially reverse side principle tying literature 
earlier principle referred past literature 
refers 
write papers extent possible relevant data code instances publicly available long term manner researchers included accurately compare results new algorithms instances results 
part simply recommendations ensuring reproducibility additional steps necessary 
trying compare results literature encountered difficulties due omissions various sorts past papers 
pet peeve 
uncalibrated machine 
papers mention machine experiments run omit key factors processor speed evident machine model name operating system language compiler 
information difficult estimate relative difference speeds earlier system difficulty gets worse time passes machines get outdated forgotten 
talking machines generations apart knows quoted processor speeds machines mhz versus mhz raw speed processor notoriously unreliable predictor performance 
processors currently market differences machine architecture render comparisons solely quoted processor speed highly suspect 
suggestion 
benchmark codes calibrate machine speeds 
benchmark distributed portable source code preferably involves data structures algorithmic operations somewhat similar algorithms studied 
compile run benchmark code machine compiler implementations studying reporting running times specified set publicly available test instances varying size 
researchers calibrate machines way benchmark data reported original attempt normalize old results current machines 
world scientific computing floating point computation fortran dominant computational paradigms approach widely practiced 
benchmark codes linpack suite described don report lists various combinations machine operating system compiler number millions floating point operations second performed benchmark computations 
benchmark codes certain drawbacks purposes 
written fortran dominated highly structured loops floating point operations may adequately reflect codes study combinatorial nature written 
furthermore linpack benchmarks limited just computations derived numbers may adequately quantify memory hierarchy effects 
world combinatorial algorithms may worthwhile new relevant benchmark codes 
approach taken dimacs implementation challenges 
example see web site tsp challenge www research att com 
benchmark algorithm nontrivial tsp heuristic instances cover large range sizes cities 
benchmark results machines plot relative speeds machines function instance size interpolation normalize time algorithm specific instance machine 
limits accuracy approach course preliminary data dimacs tsp challenge suggests hope normalized results closer factor gotten system studies 
better factors introduce discrepancies large 
pet peeve 
lost testbed 
mentioned earlier talking variance reduction gained comparing algorithms run instances 
important reproducibility really wants verify study typically independent precise answers various instances 
sake researchers best perform runs instances subsequent researchers access 
days standard solution sure instances generators available web 
course crucial testbed includes samples distribution studied enables average variability encountered individual instances 
individual instances researcher may insight instance particularly easy hard atypical ways having access instance 
admittedly requirement open possibilities abuse 
researchers interested winning horse races tempted optimize codes precisely instances studied beat instance specific code tuning 
testbed sufficiently large varied 
alternative resolving pet simply source code algorithm available 
better way ensuring comparability 
worthwhile provide machine calibrations testbed instances enable researchers verify code provide correspond results reported 
course obstacles making code available 
depending policies employer may may possible release code public 
allowed may want release finished performing experiments corrected spelling errors put comments programming style recommends 
willing source code available obstacle may encountered 
pitfall 
lost code data 
lose code lose best approach obtaining comparability algorithms designed 
lose data summaries reported papers lose chance going back answering detailed questions raised readers papers 
allow happen 
mention ways bitter personal experience 
ffl modifying code saving copy original version 
ffl responses systems administrators clean ffl failure keep back copies 
ffl poorly organized directories containing multiple variants code data clearly identifying crucial ones 
fortunately common effort recover 
recover completely lost data re running experiments tempted discard original data complete especially takes large quantities disk space 
re running experiments yield exactly running times especially longer machine may able justify precise figures reported 
randomized approximation algorithms may able exactly reproduce solution quality results saved seeds random number generator 
course results truly reproducible regenerated results support original data 
just scientists required preserve lab notebooks policy keep original data going publish results 
principle 
report full story typically overkill raw data overly selective may fail reach accurate adequately support 
may impair reproducibility comparability 
report averages say instances runs case randomized algorithms averages 
precise values averages important provide information distribution results 
simply standard deviations data appears roughly normally distributed need pictorial histograms boxplots distribution idiosyncratic 
scaling normalizing measurements carefully explained raw averages regenerated desired 
particular pictorial summaries data best way support typically presentation data pictures typically lack precision 
tables data values averages may relegated appendix included 
course go 
pet peeve 
false precision 
common statistical abuses presentation averages far digits accuracy justified data subsequent temptation draw differences basically just noise 
case running times reporting individual measurements misleading imprecision timing mechanisms operating systems unpredictable effect users system effects may reported running times 
admittedly lead including extra precision simply data layout reasons 
example consider table includes average running times large range instance sizes 
case may need go units gamma get digits accuracy smallest instances column entries digits right decimal point temptation keep entries large instances may bigger solution violating pet peeve simply replace insignificant digits add comment text explain doing 
second major part telling full story concerns anomalous results 
hide omitting failing point 
reasons intellectual honesty course include results anomalous inconsistent wish draw results instances code wish champion 
report strange reproducible phenomena encounters experiments 
ideally provide explanations anomalies reader know existence 
currently anomalies may eventually prove key major insights algorithms implementations test data 
pet peeve 
anomalies 
worst anomaly don notice 
unfortunately papers contain leaving reader wonder true anomaly simply typographical error evidence implementation bug 
anomalies important 
look 
pet peeve 
ex post facto stopping criterion 
similar earlier pet peeve optimal solution value stopping criterion concerns telling full story reproducibility 
search heuristics find local optimum continue looking solutions means examining solutions worse ones seen 
typically runs heuristic fixed number steps returns best solution encountered 
similarly performing multiple runs randomized algorithms typically fixes number runs advance completion takes best result 
unfortunately studying algorithms authors don report total running time merely time best solution encountered 
effect investigating algorithm knows advance best solution value see stops soon solution value encountered 
real world 
statistic reported presumably reproducible obscures full story underestimating total time algorithm take 
better approach taken authors report addition full running times number steps iterations taken best solution 
information may help determining general rules set parameter governing total number steps iterations performed 
special case general controversial complaint pet peeve 
failure report running times 
main subject running times report 
noted running time important component reader may legitimately want know information committing time detailed study results 
common reasons stated reporting running times 
stated reason give counter argument running time interest 

main subject study component running time say local optimization phase 
readers may legitimately want know important contribution component studied need information running time 

main subject study combinatorial count related algorithm operation 
readers may legitimately expect establish meaningfulness count question presumably means studying correlations running time 
example seen studies different pruning strategies exhaustive search algorithm measure number subproblems explored 
misleading fact better pruning scheme uses far time processing node leads larger running time 

concerns approximation algorithms main concern simply measuring quality solutions produce 
key reason approximation algorithms trade quality solution reduced running time readers may legitimately want know tradeoff works algorithms question 

goal estimate average case solution quality studied approximation algorithm running time previously studied 
pretty excuse 
argument applies cases reader interested reproducing results may want know computation involved doing 
goes really doing simply algorithms tool experimental mathematics estimating asymptotic constants determining properties distributions 
note may stated reasons reporting running time real reason typically takes bit effort record running times current code sufficiently slow reporting running times may cast doubts significance results reported 
need minor bit extra excuse principle failure efficient implementations 
principle 
draw justified look explanations purpose doing experiments algorithms presumably learn performance experimental state support 
worth emphasizing conference submissions seen beginners apparently realize 
pet peeve 
data interpretation 
simply perform tests tabulate results leave reader job finding implications data 
aren implications find express done wrong experiments shouldn writing failed test 
minimum able summarize patterns data 
ideally able pose general conjectures data supports subsequent research experimental theoretical may try confirm deny 
note data inconclusive set study order answer interesting questions recommended able derive answer sort 
need convincing case data support answers state 
pet peeve 
support 
surprising papers state supported data glaring exceptions don comment trends don notice failure 
example second failing consider read claimed algorithms equally better half time failed notice better smaller instances testbed better increasing margins instance size increased 
particularly common example poorly supported 
pet peeve 
myopic approaches 
theorists interested asymptotics asymptotic running times asymptotic worst case ratios natural community try address questions experimentally 
learns field behavior small relatively large instances predict behavior large instances 
studies try extrapolate asymptotic running time studying times instances size led astray 
early bin packing experiments joh experiment item lists misleading 
concluded item sizes uniformly distributed best fit average worse optimal 
subsequent experiments lists items implied best fit fact asymptotically optimal proved sho 
similarly tsp heuristics relative quality tours heuristics city instances far different relative quality city instances direction 
interested asymptotics study large instances possible 
addition interested running time pays study detail possible 
suggestion 
profiling understand running times 
algorithm running time typically components growth rate 
theta component high constant proportionality may dominate theta component small eventually determine algorithm behavior 
profiling code provide number calls various subroutines time spent help spot higher exponent components running time significant contribution time 
note helping get better estimate true asymptotic running time profiling provides explanation running time comes 
explanations key part experimental analysis 
real world key performance characteristics algorithm resource requirements running time memory usage approximation algorithms quality solutions generates 
natural concentrate measurements quantities performing experimental analysis 
goal understanding soon turn question explaining observed measurements occur 
plausible explanations add credibility experimental results 
explanations believable backed compelling evidence 
worst case theta algorithm appears theta log practice part worst case analysis proved overly pessimistic 
seemingly complicated algorithm take time practice supposedly simple efficient 
questions answered profiling instrumenting code perform additional measurements 
measurements sort occasion led explanation implementation defective definitely know publishing results 
principle 
data informative ways best way support easiest way derive display data way highlight trends exhibits distinctions forth 
display techniques depending types points wants 
illustrating unfortunately require longer 
readers best advised take critical look examples experimental papers listed papers try adapt techniques find informative 
additional ideas consult general literature data display see cle cle 
approach principles organize discussion warnings potential mistakes suggestions avoid 
pet peeve 
tables pictures 
tables usually inefficient way telling story 
readers talk attendees hate presentations punch line large multi table fine print 
graphical way summarize data reveal message preferred table 
pet peeve 
pictures tables 
hand pictures tell story quickly usually poor way presenting details results 
don want get ruler estimate value solution algorithm compare results algorithm 
contain pictures tables feel free stick tables appendix readers just want see big picture don deal 
pet peeve 
pictures yielding little insight 
pictures add understanding data pictures equally useful 
care taken figuring display display care get figures tell little 
suppose example wish construct meaningful display running time growth 
choose example papers poor job 
suppose tested algorithms tsp instances ranging size cities going factors roughly table gives average running time data obtained doubt stated precision justified larger instances smallest ones 
algorithm algorithm algorithm algorithm algorithm simply staring table going give insight fact algorithms roughly ordered speed ranking holding instance size 
picture tell 
illustrates different ways display data seen experimental papers argue gives useful additional insight 
running time versus instance size time log scale time log log scale time time nlogn time displaying running time function instance size 
display upper left hand corner simply charts running time versus number cities 
note large majority data points concentrated leftmost tenth coordinates hard distinguish 
picture conclude able conclude labeled curves large instances algorithms lot slower gap increasing 
lost insight relative rankings consistent instance sizes 
display upper right hand corner uses logarithmic scale coordinate data points evenly spread direction running times instances fewer cities small comparison larger instances get insight previous display 
display bottom left uses logarithmic scales axes consistent ranking algorithms different instance sizes visible 
theory determine running time growth rates measuring slopes curves 
visually slopes look essentially impossible estimate values resorting ruler scratch 
final display bottom right hand corner exploits suggestion 
suggestion 
display normalized running times 
having determined theoretical understanding algorithms detailed analysis data fastest algorithms running times grow roughly log divide running times quantity chart resulting normalized times logarithmic axis 
resulting picture reveals running time rankings consistent algorithms slower close theta log running times asymptotically worse 
get clearer idea relative speeds added horizontal grid lines appropriate intervals 
thing lose clear picture actual running times tables 
get illustration pet 
pet peeve 
inadequately confusingly labeled pictures 
clearly data real curves labeled algorithms correspond 
common practice different symbols data points curve symbols sufficiently distinct distinguish magnifying glass 
totally data points close coincide happen situations 
pet peeve 
pictures information 
pictures job best clear uncluttered 
bottom right display previous discussion covered algorithms lost impact making difficult distinguish keep track trend lines different algorithms 
general algorithms try cover single harder points clearly 
addition extent include algorithms widely different run times may forced compress data obscure distinctions order fit 
better solution multiple figures devoted subset algorithms performance range 
provide view links results overlapping sets 
pet peeve 
confusing pictorial metaphors 
ak ar az ca ct de fl ga algorithm algorithm instance seconds spurious trend lines 
creativity dangerous thing 
explain short short additional short paragraph text may able get message readers 
pet peeve 
spurious trend line 
common practice illustrated 
performed experiments collection instances 
samples instance distribution simply members standard testbed 
instance name sorting names alphabetical arbitrary order plot running times metrics instances algorithm connect data points lines 
reasons done understandable 
plotting software packages automatically 
concerned data points algorithms confused links clarify ones go algorithm 
linking data points way normally certain implications 
suggests underlying trends behavior move left right 
suggests conjecture interpolate results curves shown 
inferences typically warranted situation seriously means suggest algorithmic performance influenced alphabetic ranking instance name 
pet peeve 
poorly structured tables 
going relegate table appendix especially haven figured point graphically important order rows columns highlight important information 
example fairly common usually idea simply sort columns rows instance algorithm name 
danger previous discussion suggest false trends obscure true ones 
ordering instances size lot sense ordering name readily spot trends time solution quality correlate size 
ordering algorithms solution quality running time relationships visible 
single table reports values metrics thought best order columns rows metrics 
pet peeve 
making readers arithmetic 
common problem tables refers called missing column 
example suppose evaluating approximation algorithm instances lower bounds optimal solution values known 
case simply table solution values algorithms leaving readers task performing division tell close solutions corresponding lower bounds information reader typically want know 
derived statistic table 
pet peeve 
undefined metric 
typically occurs tables thing show axis labels figures cryptic ambiguous label column axis remains unexplained text 
common example running time column clear times reported include instance reading preprocessing times algorithms substantial refers time single run total time runs performed 
example column marked number iterations clearly stated constitutes iteration 
column marked time indication measured seconds microseconds 
really isn difficult spell things clearly excuse doing 
pet peeve 
comparing apples oranges 
prime example problem table presents running times various algorithms set instances algorithm entries taken earlier experiments performed different slower machine 
text contain caveat different machines involved reader skimming seriously misled relative running times algorithms 
readers want accurate comparison left task normalizing running times making illustration problem making reader arithmetic 
pet peeve 
detailed statistics unimportant questions 
get full picture algorithm performance perform tests instances 
precise determination results instance random distribution instances may important picture 
doing runs get narrow confidence limits data point usually mis allocation resources may prevent examining data points 
example misguided statistics detailed tests determine confidence say algorithm better algorithm particular instance class instances 
class narrow results narrow interest example applying approach set small instances ignoring fact relative performances may change drastically instance size increases 
class broad tests may obscure interesting fact identity better algorithm may depend type instance 
really needs sophisticated statistical tests distinguish performance algorithms appropriate practical purposes performance respect metric decision algorithm grounds 
statistics useful support general particularly interesting specific ones 
particular necessary role play experimental average case papers instance jmr pm 
pet peeve 
comparing approximation algorithms find optima 
situation interested details distribution results case randomized approximation algorithms 
mentioned opportunity run algorithm multiple times exploit variability distribution solutions 
aspect distributions definitely interest certain situations probability algorithm find optimal solution instance 
example observation instances tsp cities lin kernighan algorithm randomized choice starting solution typically finds optimal solution high probability 
frequency optimal solutions primary metric comparing algorithms serious limitations 
restricts attention test instances optimal solutions known see pet peeve 
second ignores question near optimal algorithm gets find optimum 
metric fail distinctions algorithms instances get reasonably large expected probability finding optimal solution goes zero competitors 
pet peeve 
data 
doing experimental study getting additional data valuable 
writing studies fully analyzed data presenting data overwhelm readers obscure main points 
raw data replaced averages summary statistics appropriate 
instance classes yield basically results choose representative data pointing text classes behave similarly 
algorithms dominated interesting reasons dropped tables charts 
data omitted may included appendices better relegated web archive interested readers access 
growing popularity online journals distinction appendix web archive course disappear 
section 
extensions points ponder attempted give advice best analyze algorithms experimentally report results 
discussion hope reader come away ideas practices agree points stimulated think deeply issues involved 
discussions preceding sections primarily addressed interested studying sequential algorithms classic problem single input asked produce single output quality measured single valued objective function 
computational tasks fit paradigm issues raised suggestions apply broadly 
leave exercise reader determine ones apply need modified situations ffl parallel distributed algorithms classic problems 
ffl algorithms problems multi valued imprecise objective functions 
ffl algorithms program testing checking correcting 
ffl dynamic reactive algorithms required respond sequence requests conceptually infinite time horizon 
operating principle basically lists conclude additional list addressing extent rely various common resources constant vigilance 
trust 

trust random number generator 

trust code correct 

trust previous author known literature 

trust memory put data generated 

trust computer remain unchanged 

trust backup media web sites remain readable indefinitely 

trust called expert experimental analysis 
abcc applegate bixby cook 
solution traveling salesman problems 
mathematica journal der deutschen icm iii 
additional information source code concorde package available www rice edu concorde html 
ben bentley 
tools experiments algorithms 
rashid editor cmu computer science th anniversary pages 
acm press new york 
ben bentley 
fast algorithms geometric traveling salesman problems 
orsa journal computing 
bgk barr golden kelly resende stewart 
designing reporting computational experiments heuristic methods 
journal heuristics 
bentley johnson leighton mcgeoch 
experimental study bin packing 
proceedings st annual allerton conference communication control computing pages urbana 
university illinois 
cgr cherkassky goldberg 
shortest paths algorithms theory experimental evaluation 
proceedings fifth acm siam symposium discrete algorithms pages 
acm siam new york philadelphia january 
cle cleveland 
elements graphing data 
wadsworth ca 
cle cleveland 
visualizing data 
hobart press summit nj 
cs 
statistical analysis computational tests algorithms heuristics 
informs computing 
don dongarra 
performance various computers standard linear equations software 
technical report 
cs computer science department university knoxville tn august 
currently date version available www netlib org benchmark performance ps 
fredman johnson mcgeoch 
data structures traveling salesmen 
algorithms 
preliminary version proceedings fourth acm siam symposium discrete algorithms pages siam philadelphia 
hk held karp 
traveling salesman problem minimum spanning trees 
operations research 
hk held karp 
traveling salesman problem minimum spanning trees part ii 
math 
prog 
hoo hooker 
needed empirical science algorithms 
operations research march april 
johnson bentley mcgeoch rothberg 
near optimal solutions large traveling salesman problems 
monograph preparation 
jm johnson mcgeoch 
traveling salesman problem case study local optimization 
aarts lenstra editors local search combinatorial optimization pages 
john wiley sons 
preliminary draft available www research att com 
jmr johnson mcgeoch rothberg 
asymptotic experimental analysis held karp traveling salesman bound 
proceedings seventh annual acm siam symposium discrete algorithms pages atlanta january 
joh johnson 
near optimal bin packing algorithms 
phd thesis project mac tr mit cambridge ma june 
joh johnson 
local optimization traveling salesman problem 
proc 
th colloq 
automata languages programming pages 
lecture notes computer science springer verlag berlin 
joh johnson 
theoretician guide experimental analysis algorithms 
page postscript draft available www research att com papers exper ps 
mcg mcgeoch 
analyzing algorithms simulation variance reduction techniques simulation speedups 
acm computing surveys june 
mcg mcgeoch 
experimental method algorithm simulation 
informs journal computing winter 
mcg mcgeoch 
experimental analysis algorithms 
pardalos editors handbook global optimization volume approaches 
kluwer academic 
appear 
mm mcgeoch moret 
experimental algorithms 
sigact news december 
available www cs amherst edu ccm howto ps 
pm martin 
finite size dimensional dependence euclidean traveling salesman problem 
phys 
rev lett 
rei reinelt 
tsplib traveling salesman problem library 
orsa journal computing 
website www uni heidelberg de software tsplib 
ru 
experimental evaluation heuristic optimization algorithms tutorial 
heuristics 
sho shor 
average case analysis line algorithms bin packing 
combinatorica 
tufte 
visual display quantitative information 
graphics press 
appendix appendix collects separate lists suggestions pitfalls pet highlighted course discussions section 
pitfalls 
dealing dominated algorithms 

devoting computation wrong questions 

getting endless loop experimentation 

start randomly generated instances evaluate behavior algorithms 
algorithms investigate properties randomly generated instances 

code tuning 

lost code data 
suggestions 
think compute 

exploratory experimentation find questions 

variance reduction techniques 

bootstrapping evaluate multiple run heuristics 

self documenting programs 

benchmark algorithms calibrate machine speeds 

profiling understand running times 

display normalized running times 
pet 
authors referees don homework 
concentration unstructured random instances 

millisecond testbed 

solved testbed 

claiming inadequate programming time ability excuse 

supplied code doesn match description 

standards comparison 

running time stopping criterion 

optimal solution value stopping criterion 

hand tuned algorithm parameters 

run study 

best result evaluation criterion 

uncalibrated machine 

lost testbed 

false precision 

anomalies 

ex post facto stopping criterion 

failure report running times 

data interpretation 

support 

myopic approaches 

tables pictures 

pictures tables 

pictures yielding little insight 

inadequately confusingly labeled pictures 

pictures information 

confusing pictorial metaphors 

spurious trend line 

poorly structured tables 

making readers arithmetic 

undefined metric 

comparing apples oranges 

detailed statistics unimportant questions 

comparing approximation algorithms find optima 

data 

