increasing application performance virtual environments run time inference adaptation ashish gupta peter dinda ais ashish cs northwestern edu department computer science northwestern university virtual machine distributed computing greatly simplifies widespread computing resources lowering level abstraction benefiting resource providers users 
middleware closely emulates existing process buying configuring physical machines 
vnet component simple efficient layer virtual network tool virtual machines vms appear physically connected home network user simultaneously supporting arbitrary topologies routing 
vttif component continually infers communication behavior application running collection vms 
combination overlays vnet inference frameworks vttif great potential increase performance user developer involvement existing unmodified applications adapting virtual environments underlying computing infrastructure best suit applications 
show continually inferred application topology traffic dynamically control mechanisms adaptation vm migration overlay topology forwarding significantly increase performance classes applications bulk synchronous parallel applications transactional web ecommerce applications 
virtual machines greatly simplify grid distributed computing lowering level abstraction traditional units jobs processes rpc calls raw machine 
abstraction re effort sponsored national science foundation ani aci ani eia eia gifts vmware dell 
opinions findings recommendations expressed material authors necessarily reflect views national science foundation nsf vmware dell 
source management easier perspective resource providers results lower complexity greater flexibility resource users 
virtual machine image includes versions correct operating system libraries middleware applications deployment new software far simpler 
detailed case grid computing virtual machines previous developing middleware system virtual machine grid computing 
shown incorporate virtual machines emerging grid standards environment 
state art resource virtualization available 
grid computing intrinsically multiple sites different network management security philosophies spread wide area 
running virtual machine remote site equivalent visiting site connecting new machine 
nature network presence active ethernet port traffic blocked routable ip address forwarding packets firewalls machine gets gets presence depends completely policy site 
connections machines possible paths network free 
impact variation exacerbated number sites increased permit virtual machines migrate site site 
deal network management problem developed vnet simple layer virtual network tool 
vnet virtual machines network presence remote site 
vnet provides mechanism project virtual network cards network moves network management problem network 
virtual network layer network machine migrated site site changing presence keeps ip address routes version vnet publicly available 
part reports dramatically extended second version 
application running distributed comput inference information adaptation algorithms adaptation mechanisms improved performance 
application inference adaptation algorithms adaptation mechanisms overlay topology vm migration increase application performance 
ing environment adapt dynamically changing available computational networking resources achieve stable high performance 
despite efforts adaptation mechanisms control common today applications 
reason tend application specific require considerable user developer effort 
claim adaptation low level application independent adaptation mechanisms possible virtual machines interconnected virtual network highly effective 
furthermore mechanisms controlled automatically developer user help 
provides evidence claim 
custom adaptation user resource provider exceedingly complex application requirements computational network resources vary time 
vnet ideal position 
measure traffic load application topology virtual machines 
monitor underlying network topology 
adapt application measured step network measured step 
adapt network application advantage resource reservation mechanisms 
focuses steps illustrated 
abundant suggests step accomplished virtual network active passive techniques begun developing approach 
just step services done behalf existing unmodified applications operating systems running virtual machines 
previous laid argument formalized adaptation problem second workshop gave preliminary results automatic adaptation mechanism 
demonstrate control adaptation mechanisms provided system response inferred communication behavior application running collection virtual machines provide extensive evaluation 
adaptation mechanisms virtual machine migration allows migrate vm physical host 
exists demonstrates fast migration vms running commodity applications operating systems possible 
migration times seconds reported 
migration times decrease rate adaptation support relevance increases 
note process migration remote execution long history facilities modify relink application particular os 
case vm migration 
overlay topology modification vnet allows modify overlay topology user vms 
key difference overlay application layer multicast community vnet provides global control topology adaptation algorithms currently necessarily assume 
overlay forwarding vnet allows modify messages routed overlay 
forwarding tables globally controlled topology routing completely separated multicast systems 
system virtual machine grid computing user closely emulates existing process buying configuring intel computer collection computers web site 
rudimentary admission control vms described additionally provides ability system adapt user state resource requirements ability support mode operation vms processes compete resources 
effect competition cheaper cost admission 
details available 
user lan proxy vnet vm foreign host lan vnet host vnet tcp connections ip network vm host vnet foreign host lan foreign host lan vm foreign host lan vm 
vnet startup topology 
host vnet host vnet vnet part system creates maintains networking illusion user virtual machines vms user local area network 
specific mechanisms packet filters packet sockets vmware host networking interface 
physical machine instantiate virtual machines host runs single vnet daemon 
machine user network runs vnet daemon 
machine referred proxy 
vmware virtual machine monitor vmm vnet operate vmm provides externally visible representation virtual network interface 
example vnet modification successfully user mode linux vserver extension linux 
shows typical startup configuration vnet hosts may support multiple vms 
vnet daemons connected tcp connection vnet link vnet daemon running proxy 
refer resilient star backbone centered proxy 
resilient mean possible connections reestablish failure 
running vm host machines possible way communicate 
communication mechanism exploited provide vnet connectivity remote vm 
example ssh connection host vnet traffic tunneled ssh connection 
vnet daemons running hosts proxy open virtual interfaces promiscuous mode berkeley packet filters 
packet captured interface received link matched forwarding table determine send possible choices sending outgoing links writing local interfaces built ethernet packet captured promiscuous packet filter host ethernet packet matched forwarding table vnet match packet forwarded link rule case match forwarding link link successfully matched packet inspected vttif determine local traffic matrix vnet multiple tcp connections overlay links necessarily vnet proxy second link case optionally hosts link case vm link second link proxy eth vnet host network ip network vnet ethernet packet injected directly ethernet packet tunneled host vm tcp ssl connection interface local traffic matrix inferred vttif vnet periodically sent vnet proxy form global traffic matrix ethz 
vnet link 
vm eth ethernet packet matched forwarding table vnet case match forwarding link destination interface ethernet packet injected interface packet sockets available unix windows 
illustrates operation vnet link 
successfully matched packet passed vttif 
proxy physical interface provides network presence vms user lan configuration responsibility user site administrator 
star topology simply initial configuration 
additional links forwarding rules added removed time 
case migration vm seamlessly maintains layer layer network presence mac ip addresses change external network presence vm remains lan proxy 
shows vnet configuration dynamically adapted reflect topology change 
vnet client query vnet daemon available network interfaces links forwarding rules 
add remove overlay links forwarding rules 
primitives generally execute ms including client time 
initial startup vnet calculates upper bound time taken configure change topology 
number determine sampling smoothing intervals vttif describe 
building primitives developed language describing vm host mapping topology forwarding rules 
vnet overlay usually managed scripts generate parse descriptions language 
start collection vnet daemons establish initial topology 
fetch display current topology vm mappings 
fetch display route packet take ethernet addresses 

fast updates 
low pass filter aggregation smoothed traffic matrix 
threshold change detection topology change output 
overview dynamic topology inference mechanism vttif 
compute differences current topology forwarding rules mappings specified topology forwarding rules mappings 
reconfigure topology forwarding rules vm mappings match specified topology forwarding rules mappings 
fetch display current application topology vttif 
vttif virtual topology traffic inference framework integrates vnet automatically infer dynamic topology traffic load applications running inside vms system 
earlier demonstrated possible successfully infer behavior bsp application observing low level traffic sent received vm running 
show smooth vttif reactions adaptation decisions output lead oscillation 
vttif works examining ethernet packet vnet daemon receives local vm 
vnet daemons collectively aggregate information producing global traffic matrix vms system 
application topology recovered matrix applying normalization pruning techniques 
monitoring done vm depend application operating system manner 
vttif automatically reacts interesting changes traffic patterns reports driving adaptation process 
illustrates vttif 
vttif accurately recover common topologies synthetic application benchmarks pvm nas benchmarks 
example shows topology inferred vttif nas benchmark integer 
nas benchmark running vm hosts inferred vttif 
sort running vms 
thickness link reflects intensity communication 
vttif adds little overhead vnet 
latency indistinguishable throughput affected 
performance vttif runs continuously updating view topology traffic load matrix collection ethernet addresses supported vnet 
face dynamic changes natural questions arise fast vttif react topology change 
topology changing faster vttif react oscillate provide damped view different topologies 
vttif depends certain configuration parameters affect decision topology changed 
sensitive vttif choice configuration parameters inference algorithm 
reaction time vttif depends rate updates individual vnet daemons 
fast update rate imposes network overhead allows finer time granularity topology changes detected 
current implementation fastest updates arrive rate hz 
proxy vttif aggregates updates global traffic matrix 
provide stable view dynamic changes applies low pass filter updates aggregating updates sliding window basing decisions aggregated view 
vttif reacts update declaring topology changed depends smoothing interval 
vttif damped 
detection threshold 
smoothing interval sliding window duration updates aggregated 
parameter depends adaptation time vnet measured startup determines long change persist vttif notices 
detection threshold determines change aggregated global traffic matrix large declare change topology 
vttif determines topology changed take time settle showing topology changes 
best case settle time measured second par adaptation mechanisms 
update rate smoothing interval detection threshold maximum rate topology change vttif keep 
rate designed vttif reacting settling topology union topologies unfolding network 
shows reaction rate vttif function topology change rate shows damped 
separate topologies switching rapidly 
topology change rate exceeds vttif configured rate reported change rate settles declines 
knee curve depends choice smoothing interval update rate best case second 
limit rate interval set knee nyquist criterion 
vttif largely insensitive choice detection threshold shown 
parameter determine extent similar topologies distinguished 
note appropriate settings vttif parameters determined adaptation mechanisms application 

vttif largely insensitive detection threshold 
adaptation uses vttif determine communication behavior application running collection vms leverage plethora existing network monitoring taxonomy determine behavior underlying resources 
vnet component provides mechanisms needed adapt application network 
needed measure application performance algorithms control adaptation mechanisms response application network behaviors 
measure throughput application 
adaptation control algorithms implemented component 
formalization adaptation control problem please see previous 
full control problem informally stated english network traffic load matrix application computational intensity vm topology network load links routers hosts mapping vms hosts overlay topology connecting hosts forwarding rules topology maximizes application throughput uses greedy heuristic algorithms quickly answer question application information available vm migration topology forwarding rule changes adaptation mechanisms 
user lan proxy vnet dynamically created ring topology fast path links hosting vms matching communication topology application running vms ring case vttif resilient star backbone merged matrix inferred vttif vm foreign host lan host vnet ip network vm foreign host lan host vnet foreign host lan vm vm host vnet foreign host lan host vnet 
application progresses vnet adapts overlay topology match application communication inferred vttif leading significant improvement application performance participation user 
topology adaptation uses greedy heuristic algorithm adapt vnet overlay topology communication behavior application 
vttif infers application communication topology giving traffic intensity matrix represented adjacency list entry describes communication vms 
topology adaptation algorithm follows 
generate new list represents traffic intensity vnet daemons implied vttif list current mapping vms hosts 

order list decreasing traffic intensity 

establish links order links established 
cost constraint supplied user system administrator 
cost constraint specified percentage total intensity reflected inferred traffic matrix absolute limit bandwidth 
illustrates topology adaptation 
application configured neighbor exchange ring application topology vms starts executing vnet star topology dotted lines centered proxy 
vttif infers topology response tells vnet precise details algorithm website cs northwestern edu rev pdf 
add links dark lines form overlay ring vnet daemons matching application topology 
refer added links fast path topology lead faster communication application components 
important note links may different types tcp udp soap depending security policies sites 
links may costly example support reservations 
desired links possible 
resilient star topology maintained times 
fast path topology associated forwarding rules modified needed improve performance 
migration uses greedy heuristic algorithm map virtual machines physical hosts 
uses application communication behavior captured vt expressed adjacency list input 
addition throughput estimates pair vnet daemons arranged decreasing order 
algorithm follows 
generate new list represents traffic intensity vnet daemons implied vttif list current mapping vms hosts 

order vm adjacency list decreasing traffic intensity 

order vnet daemon adjacency list decreasing throughput 

pass vm adjacency list locate non overlapping pair communicating vms map greedily pair vnet daemons vnet daemon adjacency list currently vms mapped 
pass pair vms list vm mapped 

second pass vm adjacency list locating order vms mapped physical host 
stragglers 

vms vm adjacency list order map vm vnet daemon throughput estimate vm mapped counterpart maximum 

compute differences current mapping new mapping issue migration instructions achieve new mapping 
forwarding rules determines overlay topology compute forwarding rules pairs shortest paths algorithm edge weight corresponding total load edge paths determined 
spreads traffic improve network performance 
combining algorithms combine algorithms run migration algorithm map vms vnet daemons 
determine overlay topology mapping 
compute forwarding rules 
experiments bsp evaluation bulk synchronous parallel applications examines inference time reaction time benefits adaptation topology adaptation migration 
find overheads low benefits adaptation considerable 
especially remarkable system completely automated requiring help application os developer 
patterns patterns synthetic workload generator captures computation communication behavior bsp programs 
particular vary number nodes compute communicate ratio application select communication operations reduction neighbor exchange application topologies including bus ring dimensional mesh dimensional torus dimensional hypercube binary tree 
patterns emulates bsp program alternating dummy compute phases communication phases chosen topology operation compute communicate ratio 
topology adaptation earlier demonstrated topology adaptation increase performance patterns evaluation limited 
summarize expand results 
studied combinations parameters number vms 
application topology communication patterns neighbor exchange bus ring mesh 
environments vms single ibm cluster vms equally divided adjacent ibm clusters connected firewalls mbit ethernet link vms equally divided ibm cluster slower cluster connected firewalls campus network vms spread wide area hosted performance diverse machines cmu northwestern chicago dot network reaction time vnet daemons single cluster separated proxy user man different fast path topologies default forwarding rules configured seconds 
configuration emphasizes configuration costs 
creating initial star takes seconds 
recall section vttif inference time depends smoothing interval chosen parameters best measured time second 
vttif configured second smoothing interval 
benefits add inferred links topology adaptation algorithm gain terms throughput measured iterations second patterns 
repeated experiment configurations 
show representative results 
gives example single cluster configuration running vm communication 
resilient star application throughput iterations second increases iterations second highest priority fast path link added 
increase continues add links improving throughput factor 
illustrates worst performance measured bus topology machines spread clusters separated man decrease performance 
shows performance vms wan scenario hosts spread wan single cluster northwestern cluster northwestern third man network chicago cmu 
proxy user located separate network northwestern 
see significant performance improvement fast path links added 
nodes dual ghz gb ram running red hat linux vmware gsx server connected mbit switch 
nodes dual ghz gb ram running red hat vmware gsx server connected mbit switch 
www org 
topology vms cluster 

bus topology vms spread clusters man migration topology adaptation show time results migration topology adaptation section separately 
studied scenarios adapting compute communicate ratio patterns 
topology vms spread wan 
run vms spread wan northwestern slower northwestern cluster cmu 
compute communicate ratio patterns varied 
adapting external load imbalance patterns run vms northwestern 
high level external load introduced nodes cluster 
compute communicate ratio patterns varied 
cases patterns executed communication pattern 
reaction time time needed vnet change topology described earlier 
additional cost vm migration 
mentioned considerable vm migration 
reported times low seconds migrate full blown personal windows vm 
supports plug migration schemes implemented copy ssh synchronization rsync migration transferring redo logs versioning file system rsync 
migration time typically seconds 

effect application throughput adapting compute communicate ratio 
benefits application low compute communicate ratio expect migrating vms closely coupled environment improve performance 
expect benefit topology adaptation application high ratio 
illustrates scenario adapting compute communicate ratio application 
low compute communicate ratio see application benefits migration local cluster formation fast path links 
wan environment adding overlay links doesn help underlying network slow 
adding overlay links local environment dramatic effect underlying network faster 
move high compute communicate ratios migration local environment results significant performance improvements 
hosts initially diverse performance characteristics 
heterogeneity leads increasing throughput differences application compute intensive 
bsp applications run speed slowest node benefit migrating similar performing nodes increases compute communicate ratio grows 
shows results adapting external load imbalance 
see low compute communicate ratios migration help 
vms bound benefit relieved external cpu load 
migrating lightly loaded host adding fast path links dramatically increases throughput 
migration vm cpu cycles needed drive network faster 
compute communicate ratio increases see effect migration quickly effect 
effect application throughput adapting external load imbalance 
adding overlay links expect 
migrating vm lightly loaded machine greatly improves performance application 
scaling tested topology adaptation scenarios section traffic vms maximum possible single clusters 
cost vm migration meet adaptation goal grows number vms number links overlay topology grow square number vms system scale vnet scales migration scales 
number forwarding rules host grow square number vms worst topology linear topology 
topology number forwarding rules host grows linearly number vms 
initial star topology total number links forwarding rules system grows linearly number vms 
vms create initial star topology seconds time spent loading forwarding rules vnet daemons 
adding full topology takes seconds involves loading forwarding rules 
inference time remains roughly smaller scenarios described previously 
surprisingly benefit adapting topology application grows number vms grows 
discussion common belief lowering level abstraction increases performance increasing complexity 
particular case rule may apply 
abstraction spare rbe spare spare image server web application server spare database server 
configuration tpc experiment 
user identical existing model group machines increase performance sees 
addition belief lowering level abstraction adaptation straightforward accomplish 
clearly possible inference tool vttif adaptation mechanisms vnet adaptation algorithms greatly increase performance existing unmodified bsp applications running vm environment 
adaptation needs sensitive nature application different multiple adaptation mechanisms may needed increase performance 
inference capabilities tools vttif play critical role guiding adaptation maximum benefit derived application 
vttif tells application resource demands tell performance bottleneck important step 
determining application performance goal key problem 
throughput 
generally objective function programmer learned user 
multi tier web sites help non parallel applications 
web sites serve dynamic content built multi tier model including client web server front application server cache database 
early stages applying domain promising results indicate considerable performance gains possible 
tpc industry benchmark sites 
tpc wisconsin group implementation particularly distribution created jan kiefer 
topology topology migration migration 
web throughput image server facing external load different adaptation approaches 
models online bookstore 
separable components site hosted separate vms 
shows configuration tpc spread vms hosted cluster 
remote browser emulators simulate users interacting web site 
talk web server apache runs application server tomcat 
web server fetches images nfs mounted image server alternatively forwarding image requests directly apache server running image server 
application server uses backend database mysql generates content 
run browsing interaction job mix accesses place pressure front web servers image server 
primary tpc metric rating 
shows sustained achieved different adaptation approaches 
adapting considerable external load applied host image server running 
migrates vm host cluster performance improves 
reconfiguring topology improves performance considerable traffic outbound image server 
adaptation mechanisms simultaneously increases performance factor compared original configuration 
demonstrated power adaptation level collection virtual machines connected virtual network 
specifically run time infer communication topology bsp application web site executing set vms 
information dramatically increase application throughput heuristic algorithms place vms appropriate nodes partially completely match application topology overlay topology 
previous adaptive systems load balancing modifications application os needed techniques place requirements generate ethernet packets 
beguelin lowekamp man stephan dome parallel programming heterogeneous multi user environment 
tech 
rep cmu cs carnegie mellon university school computer science april 
banerjee lee bhattacharjee srinivasan resilient multicast overlays 
proceedings acm sigmetrics conference measurement modeling computer systems june 
resilient peerto peer multicast cost 
proceedings th annual multimedia computing networking conference january 
blythe deelman gil kesselman agarwal mehta role planning grid computing 
proceedings international conference automated planning scheduling 
cornell dinda wayback user level versioning file system linux 
proceedings usenix freenix track july 
cybenko dynamic load balancing distributed shared memory multiprocessors 
journal parallel distributed computing october 
dike user mode port linux kernel 
proceedings usenix annual linux showcase conference atlanta ga october 
douglis ousterhout process migration sprite operating system 
proceedings th international conference distributed computing systems icdcs september 
figueiredo dinda fortes eds 
special issue resource virtualization 
ieee computer 
ieee may 
figueiredo dinda fortes case grid computing virtual machines 
proceedings rd international conference distributed computing systems icdcs may 
foster kesselman tuecke anatomy grid enabling scalable virtual organizations 
international journal supercomputer applications 
grimshaw wulf legion team 
legion vision worldwide virtual computer 
communications acm 
grimshaw strayer narayan 
dynamic object oriented parallel processing 
ieee parallel distributed technology systems applications may 
gupta dinda topology traffic load parallel programs running virtual machine environment 
proceedings th workshop job scheduling policies parallel program processing june 
gupta dinda lowekamp free network measurement adaptive virtualized distributed computing 
submission 
harchol balter downey exploiting process lifetime distributions dynamic load balancing 
proceedings acm sigmetrics may pp 

harold cain ravi lipasti architectural evaluation java tpc 
proceedings seventh international symposium high performance computer architecture january 
hua chu rao zhang case endsystem multicast 
proceedings acm sigmetrics conference measurement modeling computer systems pp 

keahey foster sandbox playground dynamic virtual environments grid 
proceedings th international workshop grid computing november 
karamcheti optimal deployment planning component distributed applications 
proceedings thirteenth ieee international symposium high performance distributed computing hpdc june pp 

satyanarayanan bressoud ke efficient state transfer internet suspend resume 
tech 
rep irp tr intel research laboratory may 
lange dinda automatic dynamic run time optical network reservations 
proceedings th ieee international symposium high performance distributed computing hpdc july 
volume 
lin dinda mixing batch interactive virtual machines periodic real time scheduling 
submission 
version available technical report nwu cs department computer science northwestern university 
linux vserver project 
www linux vserver org 
lopez hallaron support interactive heavyweight services 
proceedings th ieee symposium high performance distributed computing hpdc 
lowekamp beguelin eco efficient collective operations communication heterogeneous networks 
proceedings th international parallel processing symposium pp 

lowekamp hallaron gross direct queries discovering network resource properties distributed environment 
proceedings th ieee international symposium high performance distributed computing hpdc august pp 

lowekamp tierney hughes jones hierarchy network performance characteristics grid applications services 
tech 
rep recommendation global grid forum may 
mccanne jacobson bsd packet filter new architecture user level packet capture 
usenix pp 

milojicic douglis wheeler zhou process migration 
acm computing surveys september 
noble satyanarayanan narayanan flinn walker agile application aware adaptation mobility 
proceedings th acm symposium operating systems principles 
osman su design implementation zap system migrating computing environments 
proceedings th symposium operating systems design implementation december 
rosenberg weinberger huitema simple traversal user datagram protocol udp network address translators nats 
tech 
rep rfc internet engineering task force march 
chandra pfaff chow lam rosenblum optimizing migration virtual computers 
proceedings th symposium operating systems design implementation december 
savage sting tcp network measurement tool 
proceedings usenix symposium internet technologies systems 
seshan stemm katz spand shared passive network performance discovery 
proceedings usenix symposium internet technologies system usits 
lange dinda system virtual machine marketplaces 
tech 
rep nwu cs department computer science northwestern university july 
steenkiste automatic generation parallel programs dynamic load balancing 
proceedings third international symposium high performance distributed computing august pp 

steensgaard jul object native code process mobility heterogeneous computers 
proceedings th acm symposium operating systems principles december acm 
gupta dinda dynamic topology adaptation virtual networks virtual machines 
proceedings seventh workshop compilers run time support scalable systems lcr october 
dinda virtual networks virtual machine grid computing 
proceedings rd usenix virtual machine research technology symposium vm may 
chung hollingsworth active harmony automated performance tuning 
proceedings acm ieee conference supercomputing pp 

thain livny bypass tool building split execution systems 
proceedings ninth ieee symposium high performance distributed computing hpdc pittsburgh pa august 
tridgell efficient algorithms sorting synchronization 
phd thesis australian national university 
vmware 
www vmware com 
white sunderam performance nas parallel benchmarks pvm networks 
journal parallel distributed computing 
reeves strategies dynamic load balancing highly parallel computers 
ieee transactions parallel distributed systems september 
wolski spring hayes network weather service distributed resource performance forecasting system 
journal generation computing systems october 
miller livny process hijacking 
proceedings th ieee symposium high performance distributed computing redondo beach ca august 
lowekamp passive traces application traffic network monitoring system 
thirteenth ieee international symposium high performance distributed computing hpdc june 
zinky bakken schantz architectural support quality service corba objects 
theory practice object systems april 
