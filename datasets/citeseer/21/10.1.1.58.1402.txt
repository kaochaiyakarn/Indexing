natural terrain classification ladar data nicolas daniel huber martial hebert carnegie mellon university forbes avenue pittsburgh pa usa email ri cmu edu difficulty interpreting laser data meaningful way safe navigation terrain daunting challenge 
focus segmentation ladar data local point statistics classes clutter capture grass tree canopy linear capture thin objects wires tree branches surface capture solid objects ground terrain surface rocks tree trunks 
details method proposed modifications implement board autonomous ground vehicle 
results field tests rover results produced different stationary laser sensors 
autonomous robot navigation terrain remains considerable challenge difficulty capturing representing variability environment 
trivial task possible build models smooth terrains bare ground 
difficult cope areas described piecewise smooth surface grass bushes tree canopy 
exhibit porous surfaces random medium propagation interior naturally described texture smooth surfaces 
method segment point clouds acquired laser radar classes surface ground bare terrain surface solid object large tree trunk linear structures wires thin branches scatter tree canopy grass 
similar points grouped consensus region corresponding large pieces surfaces 
method rely specific sensor geometry scanning pattern 
particular internal representation updated time new data point acquired sensor irrespective order acquisition 
statistical classification techniques learn method parameters training data sets manually label reducing amount hand tuning 
results produced line data coming different laser radar sensors variety environments 
results onboard processing general dynamics robotic systems experimental unmanned vehicle xuv additional results stationary laser radars 
importance obstacle detection environment modeling issue detecting segmenting vegetation explored past 
spectral data received lot attention compared geometric information 
approaches pioneered mumford considered single point statistics range image natural environments 
characterize texture need local statistics range derivative ranges frequency components 
robotics matthies results single point statistics computed data single point laser range finder differentiate vegetation solid surface rocks 
geometric approach problem 
large literature exists recovery ground terrain surface airborne laser sensor see review comparison methods 
includes filtering vegetation interpolation terrain surface 
robotics measured permeability scene detect vegetation 
similar approach wellington addition methods recover load bearing surface 
approach problem data segmentation implementation produce run board xuv results different stationary sensors results field test xuv 
ii 
approach approach points statistics compute saliency features capture spatial distribution points local neighborhood 
saliencies distribution captured gaussian mixture model gmm automatically expectation maximization em algorithm 
model produced line classify line new data bayesian classifier 
local point statistic saliency features inspired tensor voting approach 
distribution surface orientation distribution points directly 
distribution captured decomposition principal components covariance matrix points computed local neighborhood support region 
size neighborhood considered defines scale features 
symmetric covariance matrix set points xi xi yi zi xi defined equation 
xi xi matrix decomposed principal components ordered decreasing eigenvalues 
eigenvectors corresponding respectively eigenvalues 
case scattered points dominant direction 
case linear structure principal direction lie plane 
case solid surface principal direction aligned surface normal linear combination eigenvalues see equation represent saliencies named point ness curve ness surface ness 
saliencies point ness curve ness surface ness practice feasible hand tune thresholds directly saliencies perform classification values may vary considerably depending type terrain type sensor configuration sensor vehicle 
standard way doing learn classifier maximizes probability correct classification training data set 
object sections 
learning learn parametric model saliencies distribution fitting gaussians mixture model gmm expectation maximization em algorithm hand labeled training data set 
see practical details em algorithm 
resulting density probability model class sum ng gaussians weight mean covariance matrices ng order capture variability terrain ensure data flat surfaces rough bare surfaces short grass terrains thin branches power line wires dense sparse tree canopy tall grass 
set arbitrarily cm diameter limit linear surface structure tree trunk branches 
tedious labeling process performed studio max allows select points individually 
enforce balanced labeled data set different classes 
order capture influence clutter compute saliencies selected points support region includes points 
saliencies branches capture influence leaves example 
evaluated experimentally optimal number gaussians necessary capture distribution fitting training data set 
fitted gaussians class model compared classification rate model different test data set 
achieve best results gaussians class 
confirmed correct convergence em algorithm 
labeling model fitting performed line sensor 
section discuss classification method 
classification call gmm kth class 
saliency features new point want classify line 
conditional probability new point pertain th class number saliency features 
class chosen argmax normalized confidence classification defined max mk max mk min section describes implementation details 
iii 
rover implementation method directly onboard mobile robot 
reasons 
detail modification achieve fast processing information board xuv 
issues mentioned earlier task method running board xuv robot navigating natural environment 
similar platform demo iii xuv program 
robot equipped mobility laser 
rugged laser radar provides pixels range images hz laser mounted turret controlled navigation system build terrain model local obstacle avoidance 
context face challenges high acquisition rate laser producing points second 
turret robot motion area scene perceived times different viewpoints different distances 
advantage term coverage environment implies incorporating new data continuously existing data structure recomputing classification perceived scene areas 
robot stationary time need accumulate huge amount data scene viewpoint 
method requires data support region point interest time consuming range search procedure 
new point added saliency features classification need recomputed 
need new point falling neighborhood existing point 
rest section solution implemented deal problems 
practical implementation directly points produced laser stored dense data representation 
approach expensive board processing number individual points consider update classification size data structure maintain robot motion 
data collected experiments estimated percentage voxels occupied dense data representation varies voxel size varies cm edge length 
result decide implement sparse voxel data representation 
call basic element cm size prototype point 
prototype point maintains set intermediate results computed raw data falling inside bounds necessary evaluate saliency feature incrementally 
data discarded achieve significant reduction data size kept memory 
store complete set prototype points structure call prototype volume 
allows access prototype point efficiently hashing function range searches 
flowchart current system implementation 
shows asynchronous processes update intermediate saliency features done continuously classification data done request regular intervals 
update consists incorporating new point creating new prototype point updating existing 
classification prototype point consists recovering intermediate results saliency feature support region range search merging pieces information compute actual saliency features doing classification described section ii 
update new data point ladar hashing function address nearest point prototype point exists create new prototype point update prototype point state classification prototype point hashing function active neighboring prototype point compute sum state neighboring prototype points compute saliency features classify class models classification label confidence fig 

flowchart current system implementation intermediate saliency features computed incrementally rate points second 
classification performed rate prototype points second cm radius support region 
approach allows incorporate data real time comes ladar 
implemented partial update strategy 
method calls re computation saliency features time new prototype point created time prototype point updated prototype points include new modified prototype points need updated 
showed size prototype point step skipped acceptable loss classification performances compared gain processing time 
worst case scenario classification error rate increases percent processing time reduced factor 
interface architecture robot nist rcs communicate processes performed neutral message language nml 
laser radar data stored updated continuously nml buffer robot boards running vxworks 
code runs linux laptop communication robot nml buffers ethernet cable 
laser data saved native file format 
test method modified software packages developed read ladar data file create nml buffer robot live data process laser data display raw data results 
step allows move directly robot additional effort 
iv 
results section results data collected stationary sensors sick mobile sensor mounted unmanned ground vehicle 
stationary sensor order demonstrate sensor independence approach results produced sensors 
cmu laser results produced data collected sick lms attached custom scanning mount similar sensor 
laser seen picture 
laser collects points scan 
angular separation laser degree degrees field view 
angular beams separation laser sweeps degree degrees 
shows examples classification scene isolated wires scene wires adjacent tree canopy scene bare trees 
results visually accurate denote border effect edge ground surface points misclassified linear 
problem reduced selecting carefully training data set introduce artifacts scene 
looking methods address issue 
observed misclassification ground points linear scanning pattern sensor 
consecutive scan lines project far dimension ground plane 
spacing red blue green colors display information concerning surface linear scatter classification results features 
points enlarged assure proper rendering print version isolated wires scene wires adjacent clutter scene bare tree scene isolated wires segmentation wires adjacent clutter segmentation bare tree segmentation fig 

examples classification sick laser 
points red blue green represent surface curve scatter structures 
sub color saturated 
sub level saturation color represents classification confidence 
scene segmentation largest connected components fig 

complementary example classification sick laser 
sub points red blue green represent surface curve scatter structures 
sub component unique color laser points scan line remains close 
method deal artifact currently looking geometric method deal 
laser results produced data lara imaging sensor 
maximum range mm accuracy fov produces range intensity measurements scan 
positioned laser trail densely terrain flat ground covered thick vegetation trail crossed densely area 
shows picture scene 
shows data elevation color coded blue red low high elevation 
shows close view segmentation results scene area 
classes surface scatter linear separated ground surface class points surface class points geometric method 
xuv field test results may tested software board xuv army research lab field test site fort gap 
vehicle drove cumulative distance natural environment robot classifying data 
performed real time update continuously classification seconds meters traversed 
test intended evaluate communication mechanism robot scrolling mechanism maintain consistent environment representation robot move long distances 
shows xuv vehicle traverse 
note turret laser locate front vehicle 
shows path vehicle scene color elevation segmented scene fig 

example classification results laser laser 
sub points red blue green represent non ground surface ground surface scatter structures blue line positions classification performed red points 
shows classification processing time function number prototype points 
processing performed ibm thinkpad mb ram ghz pentium iii cpu 
processing done laser graphic interface debugging purposes 
relative trajectory robot ladar acquisition positions relative xuv traverse duration processing time vs nbr proto point nbr proto point xuv path board processing time fig 

experiment shortly conducted additional set tests facility 
objective test stand version code graphic interface process log results 
shows classification result 
scene composed areas rough terrain covered tall grass unevenly distributed bordered tall trees half left parking lot trees 
saliency features update intermediate classication results performed robot moved final classification result stored 
classification consistent scene observed 
target detection clutter order assess performance algorithm detecting hidden targets vegetation synthetic data perform controlled experiments 
draw random points produce plate non null thickness point cloud 
experiment varied number point elements reduce number point plate increase number point clutter 
able achieve percent global error rate 
shows scene classification result 
confusion matrix table shows number prototype points correctly incorrectly classified compared ground truth 
raw data classified data fig 

synthetic data simulating planar target hidden vegetation table confusion matrix plane clutter surface point line surface point line top view side view fig 

xuv results test 
red blue prototype points classified surface 
summary method perform data segmentation terrain classification environment 
method uses local point distribution statistics produce saliency features capture surface ness point ness local area 
statistical classification techniques capture variability scenes sensor characteristics scanning pattern range resolution noise level 
fit gaussian mixture models training data set parametric model perform bayesian classification 
implemented tested approach autonomous mobile robot xuv 
classification results static sick laser addition results obtained xuv 
examples show versatility limitations current method implementation 
focus improving processing time reducing classification error rate dealing border effects isolated range measurements 
pay attention formal numerical assessment method problem target hidden vegetation 
plan implement opportunistic data processing ladar data classifying data obstacle detection robot plans drive 
acknowledgments prepared collaborative participation robotics consortium sponsored army research laboratory collaborative technology alliance program cooperative agreement daad 
general dynamics robotics system specifically bradley stuart help laser autonomous vehicle 
hebert terrain classification techniques ladar data autonomous navigation collaborative technology alliances conference may 
huang lee mumford statistics range images ieee conference computer vision pattern recognition pp 

macedo manduchi matthies ladar discrimination grass obstacle autonomous navigation international symposium experimental robotics 
castano matthies foliage rotating ladar ieee international conference robotics automation 
comparison filters commission iii working group tech 
rep 
murphy autonomous mobility demo iii experimental unmanned vehicles proceedings conference 
wellington stentz learning prediction load bearing surface autonomous rough terrain navigation vegetation international conference field service robotics 
duda hart stork pattern classification nd ed 
wiley interscience 
medioni lee tang computational framework segmentation grouping 
elsevier 
bilmes gentle tutorial em algorithm application parameter estimation gaussian mixture hidden markov models university berkeley tech 
rep icsi tr 
albus rcs sensory processing world modeling demo iii experimental unmanned ground vehicles ieee symposium intelligent control 
rcs version model architecture unmanned vehicle system national institute standards technology tech 
rep nistir 
langer imaging ladar surveying cad modeling real world en international journal robotics research vol 

hebert experimental results aerial ladar data mobile robot navigation international conference field service robotics 
