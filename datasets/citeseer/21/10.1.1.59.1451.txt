aris dept computer science brown university providence ri usa aris cs brown edu sampling search engine results consider problem efficiently sampling web search engine query results 
turn small random sample full set results leads efficient approximate algorithms applications determining set categories taxonomy spanned search results finding range metadata values associated result set order enable multi faceted search estimating size result set data mining associations query terms 
analyze efficient algorithm obtaining uniform random samples applicable search engine posting lists document time evaluation 
knowledge popular web search engines google inktomi altavista belong class 
furthermore algorithm modified follow modern object oriented approach posting lists viewed streams equipped method method boolean complex queries built method primitive terms 
case show construct basic method samples term posting lists probability show construct methods boolean operators wand primitive methods 
test efficiency quality approach synthetic real world data 
categories subject descriptors information storage retrieval information search retrieval general terms algorithms keywords search engines sampling weighted wand performed author ibm watson research center 
copyright held international world wide web conference committee iw 
distribution papers limited classroom personal 
www may chiba japan 
acm 
andrei broder ibm watson research center skyline drive hawthorne ny usa ibm com david carmel ibm haifa research lab haifa israel carmel il ibm com 
web search continues explosive growth pew internet american life project web search users united states queries month june 
time web corpus grows february google com claims pages indexed 
search algorithmic efficiency important processor speeds increasing hardware getting expensive day size corpus number searches growing faster pace 
hand web search users tend short queries words long result large result sets 
search engines accurate respect navigational queries see definitions informational queries situation quite responses meet user needs especially ambiguous queries 
example consider user interested finding famous opera enters query google search box 
turns popular responses refer tv series name top google results documents refer program 
google numbers refer experiments conducted february 
situation stimulated search engines offer various post search tools help users deal large sets somewhat imprecise results 
tools include query suggestions refinements yahoo com com result clustering naming clusters com vivisimo com mapping results predetermined taxonomy odp open directory project google yahoo look smart 
tools full part analysis result set 
instance previous example search engine may categories tv series opera query extensions ideally order extract frequent categories results set documents matching query examined web size corpora course prohibitive thousands millions documents may match 
common technique restrict attention top hundreds ranked documents extract categories 
faster search engines combination static rank factors pagerank query dependent factors 
sorting index decreasing order static rank branch bound approach top say results produced faster entire set results 
problem approach highly ranked documents necessarily representative entire set documents may biased popular categories 
example top documents google refer series query matches pages google google report query opera matches completely different picture 
corporate search engines especially commerce sites implement technique called multi faceted multidimensional search 
approach allows refinement full text queries meta data specifications associated matching items price range weight order nonempty refinements possible 
refinement browsing results satisfy certain metadata conditions similar narrowing results particular category 
example consider user visits online music store com performs query say string james 
engine com provides number hits numerous possible refinements various facets instance genre blues children country price format cassette cd maxi single compact disc 
refinements offered depend initial query nonempty categories offered sparse subcategories merged subcategory 
similar approaches 
multi faceted search contexts instance yee show benefits approach applied project berkeley searching images metadata refinement 
categories displayed multi faceted search depend result set query extracted quickly problem corpus large 
current multi faceted search engines limited corpora represented memory 
sampling search results applications described require significant processing time order apply large corpora propose sample set documents match user query 
asymptotically term independence assumptions average running time sampling approach proportional sample size grows logarithmically size full matching set 
hand sampling allows extract information unbiased respect search engine ranking produce better coverage topics metadata values full result set 
main technical difficulty sampling follows fact results query explicitly available results generated expensive process potentially involving numerous disk accesses query term 
straightforward implementation pay price find store pointers documents matching original query build uniform sample results 
mentioned algorithm obtain sample generating examining small fraction result set sample produced uniform set matching pages size desired sample size equal probability selected output sample 
best knowledge idea sampling query results search engines new sampling applied different contexts means give fast approximate answers particular problem 
areas randomized approximation algorithms provide numerous examples 
area data streams input size large sampling input operating common technique see 
databases allow user specify sampling rate select operation performing query full set data operates sample result db standard augmented order support option 
applications mentioned result categorization multi faceted search random sample query results potential uses 
theorem show execution algorithm obtain unbiased estimator total number documents matching user original query theorem show estimator achieve prespecified degree accuracy confidence 
users estimates help decide try refine query 
case web search engines generally provide estimates number results matching query 
instance google yahoo provide estimates top search results page 
estimates notoriously unreliable especially disjunctions 
example february google reports results containing term george pages containing term washington estimate documents satisfying query george washington done advanced search 
contrast experiments see section result uniform sample yielded estimates target cases 
application random sampling identify terms properties associated query terms 
instance ask person mentioned web osama bin laden approach envisage sample results query osama bin laden fetch sample pages run entity detection text analyzer recognize people names extract names 
advantage approach compared top results query osama bin laden top results biased particular context 
similar application suggested authors demonstrate finding hand new terms relevant irrelevant query useful building corpus independent performance measures information retrieval systems 
main idea providing set relevant set irrelevant terms query evaluate performance information retrieval system checking documents retrieved contained specified relevant irrelevant terms 
discovering sets terms daunting task requires time skill ir specialist sample search results query help specialist identify relevant irrelevant terms 
lack bias probably useful 
application suggested proposes web knowledge source domain independent question answering paraphrasing natural language questions way produce list hits containing answer question 
case results better random sample matches ranked set matches ranking different idea best results 
list potential applications search results sampling proposed probably far complete 
hope stimulate search engines implement random sampling feature turn lead uses conceive 
alternative implementations simple way producing pseudo random samples keep index random order 
matches query viewed random sample sample needed take matches sample 
fact approach ibm system large scale web data mining 
standard web search engine disadvantages architecture 
index random order decreasing static rank order ranking regular searches topk expensive branch bound optimization 
random order index stored separately search index doubles storage cost 
issue web fountain top searches small fraction load 

maintaining true random order documents added deleted nontrivial 
solution random static score associated document keep index sorted random score allows having old index delta index deal additions 

creating multiple truly independent random samples query nontrivial 
regular web search engines sampling better alternative 
retrieval model notations model traditional document time model ir systems 
document database assigned unique document identifier 
mentioned dids assigned way increasing dids corresponds decreasing static scores 
relevant rest discussion 
possible term associated posting list 
list contains entry document collection contains index term 
entry consists document information required system scoring model number occurrences term document offsets occurrences posting lists ordered increasing order document identifiers 
posting lists stored secondary storage media assume access stream reader operations 
particular pointer term posting list supports standard operations 

loc returns current location pointer 

advances pointer entry term posting list 

moves pointer document greater equal purposes need special operator 
jump moves pointer th entry posting list document greater equal 
equivalent followed operations 
simulating jump way cost moves see 
operations loc easily implemented linked list data structure search engines augment linked lists tree data structures order perform operation efficiently 
example binary tree leaves posting locations corresponding posting consecutive disk records inner node contains location subtree rooted jump operation traditionally supported easily implemented tree data structures needed simply augment inner nodes count postings contained rooted subtree 
modern object oriented approach search engines posting lists evaluation posting lists viewed streams equipped method method boolean complex queries built method primitive terms 
instance aor min 
show construct basic method samples term posting lists probability show construct methods boolean operators wand primitive methods 
posting lists stored secondary storage jump operation may result disk accesses 
additional search engine data structures ensure disk access operation 
goal minimize number disk accesses want minimize number stream reader move operations 
rest assume moves unit cost calculation negligible cost 
assumption course approximation correlated observed wall clock times 
accurate model distinguish block moves block moves 
easy list notations remainder 
total number documents number documents containing term ti ni 
query consideration number terms contained query number documents satisfy query 
sample size require size expect general cases assume assumption clear context 
general sampling technique propose applicable search engine architectures 
describe section 
section specialize particular architecture wand operator introduced specialization allows achieve better performance 
implemented performed various experiments results section 
section summarize conclude results 

general scheme sampling motivating examples order build intuition sampling problem examples query conjunction terms query disjunction terms 
provide details sampling mechanism generalize broader class queries 
example consider term appears documents term appears documents assume number documents containing terms 
assume want sample results 
sampling document satisfies query probability equal creates random sample desired expected size 
notation resp 
mean term set postings associated meaning clear context 
initial problem arises fact may know documents contain term contain term know priori number documents contain terms know proper sampling probability 
ways circumvent issue discuss subsection 
assume know correct sampling probability question sample efficiently 
naive approach identify document contains terms document independently add sample probability means checking postings rarest terms need examine postings posting list 
consider approach sample posting list rarest term probability create virtual term ap posting list contains sampled postings posting list ap contains roughly documents 
return documents satisfying query ap andb 
easy verify result uniform sample documents containing aand show create posting list ap online time proportional ap method allows examine postings clear gain postings examined naive approach 
look example turns somewhat complicated 
consider term appears documents assume documents containing aor want sample documents case 
naive approach check document aor insert sample probabil ity means traversing posting lists operations 
apply technique create term ap time proportional ap 
document may satisfy query contain create virtual term cp manner return documents ap cp 
total number postings examined ap cp factor improvement 
need careful document contains term inserted ap probability similarly contains term inserted cp probability document contains terms probability contained ap cp document containing contained ap cp rejected sample probability 
ensure document aor included sample probability exactly sampling search results general query generalize examples previous section show apply procedure sampling query results search engine inverted indices document time retrieval strategy 
class includes google altavista ibm trevi 
consider query simple prior examples complicated boolean expression including terms exclusively terms 
contain advanced operators phrases proximity operators 
query contains number simple terms say 
operators applied term associated posting list 
exact details depend specific implementation search engine traverses lists evaluates documents lists heuristics optimization techniques applied reduce number documents examined example query engine ideally traverse infrequent term 
recall total number documents satisfying query need sample size means document satisfying query sampled probability assume moment know know sampling probability subsection show handle 
way sample results simple concept 
term ti terms ti create pruned posting list document entries contains document posting list ti probability independently 
naive way create pruned list traverse original posting list insert document pruned list probability efficient equivalent way skip random number documents distributed geometric distribution parameter create geometrically distributed random variable parameter constant time formula log log real random variable uniformly distributed interval see 
random skip simulated executing jump operation document considered 
recall discussion section data structure postings allows efficiently skipping documents posting lists skip unit cost 
insert document pruned list skip random number documents continuing posting list completely traversed 
note pruned lists precomputed query created fly documents examined 
perform query considering documents contain term pruned lists 
equivalent replacing original query 
query 
construction document appears posting list probability considered 
documents originally appear posting list 
consider document appears posting lists terms pruned 
document increased chances appear pruned list probability exactly document satisfies query count number posting lists subject pruning originally appears 
insert document sample probability probability document accepted exactly remarks technique want stress generality allows incorporated large class search engines 
second method clean simple require additional nontrivial data structures pruned lists precomputed improve response time stored disk common search terms fixed pruning probabilities pruned lists exist conceptual level 
iterator traverses pruned list actual implementation may traverse original posting list skip necessary documents 
implementation describe detail section demonstrates approach 
addition require support jump operation described section significantly different operation 
programming point view needed modifications transparent 
furthermore modern object oriented approach search engines view posting lists streams method build method boolean complex queries basic method primitive terms 
geometric jumps method provides method samples term posting lists probability providing primitive method approach described provides method arbitrary queries advance minimum posting pruned posting lists primitive method evaluate query match perform rejection method described 
want mention general mechanism appropriately modified efficient particular implementations 
example example previous section saw need create pruned list terms 
section show apply technique wand operator ibm trevi search engine search engine gain similar benefits 
estimating sampling probability previous discussion assumed know total number documents matching query compute sampling probability reality know adjust probability execution algorithm 
problem sequential sampling sample exactly elements arrive sequentially unknown considered past 
vitter propose efficient algorithms address problem technique called reservoir sampling 
main idea th item arrives insert sample reservoir probability replacing random element sample 
technique ensures moment reservoir contains random sample elements seen far 
vitter subsequent researchers proposed efficient algorithms simulate procedure checking element skip number see example 
techniques applied directly problem list matching documents represents union intersection lists 
simply skip number documents know skipped documents matched query decide acceptance probability chosen document 
apply technique related method context stream processing maintain buffer size equal initially set sampling probability equal upper bound correct sampling probability 
words accept document satisfies query probability 
buffer full number documents accepted equals indicates probably large set new sampling probability constant 
accepted document retained sample probability deleted sample probability 
expected sample size chernoff bound shows high probability actual size close large 
subsequent documents satisfy query inserted sample probability independently documents decreased buffer full 
eventually algorithm goes posting lists ends final sampling probability equal value final number documents sample high probability 
assuming holds easily sample replacement set extract sample exactly documents 
observe number times sampling probability decreased bounded log log log log time probability decreased expected number samples removed buffer total number samples considered bound log log log 
tempting assert algorithm chooses independently document probability unfortunately case independent sampling probability probability sample larger algorithm produces sample larger holds conditional size sample uniform 
furthermore final size final sampling probability compute size set sampled 
captured theorems 
theorem 
assume sampling algorithm actual size sample produced sample set uniform sets documents satisfy query 
proof 
coupling simulation argument give main intuition 
assume documents satisfy query associated real random variable xi chosen independently uniformly random interval 
build new algorithm proceeds exactly buffer full reduced keep buffer documents xi new document inserted buffer iff xj new sampling probability 
sp xi 
largest value set 
sp xi final sample sp 
clearly set sp uniform sets size sp 
hand original algorithm new algorithm obvious correspondence conditional size final sample uniform 
notice algorithm know initially number documents satisfy query value usually hard estimate 
mentioned additional feature algorithm estimate number documents matching query 
theorem summarizes result 
theorem 
assume algorithm size sample final sampling probability ratio unbiased estimator number documents matching query proof 
view algorithm performing types steps buffer full algorithm reduces sampling probability resamples buffer buffer full algorithm considers candidate document inserts probability assume steps kt documents sample sampling probability pt considered mt candidate documents 
algorithm stops steps kf pf mf prove step ratio kt pt mt define sequence random variables xt follows 
xt kt pt mt show sequence xt martingale xt 
xt xt implies kf pf mf completes proof 
brevity gloss technical details complete proof included longer version 
notice kt sampling probability change pt pt consider new document inserted probability pt 
indicator random variable event time document accepted get xt 
xt kt kt mt 
xt pt kt pt mt pt kt pt xt 
mt hand kt document sample resampled probability pt pt considering new document mt mt 
xt 
xt kt binomial kt pt pt mt 
xt kt pt pt pt mt xt 
conclude sequence xt martingale implies optional sampling theorem xf 
having correct expectation estimator close correct value high probability 
general approximation scheme quantity defined procedure positive computes estimate relative error probability pr 
theorem shows sampling procedure buffer size quadratic logarithmic fact approximation scheme 
theorem 
constant positive algorithm buffer size log approximation scheme algorithm size sample final sampling probability pr 
proof 
proof similar theorem omit lack space 

efficient sampling wand operator described general sampling mechanism applied diverse settings seen specialize particular operator achieve improved performance 
section describe operator wand introduced generalizes efficient implementation sampling results wand 
wand operator briefly describe wand operator introduced means optimize speed search queries 
wand stands weak weighted 
takes arguments list boolean variables 
xk list associated positive weights 
wk threshold 
definition wand 
xk wk true iff xi indicator variable xi xi true xi 
observe wand implement 
xk wand 
xk 
xk wand 
xk 
purposes shall assume goal simply sample set documents satisfies equation xi indicating presence query term ti document note situation considered complicated term ti associated upper bound maximal contribution document score document subject preliminary filtering wand ub ub 
xk xi indicates presence query term ti document wand evaluates true document undergoes full evaluation document matches wand necessarily match query 
deal approach doing full evaluation document normally insert buffer 
document won coin toss 
document inserted buffer passes full evaluation 
insures reduced needed 
refinements considered varying threshold algorithm meant increase efficiency finding top results scope 
sampling wand results example saw previously sample rarest term minimize total number operations 
contrast example sample posting lists terms 
wand operator varies sampling algorithm handle efficiently extremes 
set query terms 
divide subsets set contains terms sampled set contains rest terms example set contains frequent term example set contains terms 
issue select set discuss optimal way discussing running time algorithm 
time assume choose set arbitrarily wi 
document satisfies equation contain term easy check examples expressed wand obey inequality respective choices description section create pruned lists terms terms document posting list term included pruned list term probability independently documents terms 
course algorithm know initially starts accepting documents probability reduces time process described subsection 
algorithm guarantees document contains term probability selected 
selected satisfies wand normalize probability exactly rejection method described subsection 
document contain term total weight strictly smaller satisfy wand 
give high level description sampling algorithm 
details appear contains visual example 
term set associated producer iterator traversing pruned list selecting documents evaluation query 
furthermore order perform evaluation term query associated checker traverses original posting list 
iteration algorithm advance producers point document smallest document selected probability 
checkers determine terms contained document sum weights exceeds threshold document candidate selected sample 
general approach pruned list may exist conceptual level producers may traverse original posting lists jump random number geometrically distributed documents 
document held variable global selected consideration checkers determine global satisfies query 
checkers point documents smaller global terms far know point contained document global 
algorithm maintains upper bound equal sum weights terms checkers point document greater global 
long upper bound exceeds threshold global satisfy query 
function 
initializations 


global 

foreach term 
checker 
foreach term 
producer 

repeat 
advance global smallest checker global wi 
global min producers 
global min producers 
producer global 

terms producer global 
producer points global 
pick 
producer global 
producer points global 
global min producers 
global 
return finished documents 
global points exists pruned list accumulated weight 

terms checker global 
contains terms contribute upper bound 
global 
document global considered 
pick 
probably best pick 
checker 
global 
checker global wi advance term checker document global 
assume doc 
doc global term contained global 
continue advancing rest checkers global total sum weights terms checkers positions global threshold case document satisfy query sum weights terms contained global exceeds threshold case document candidate selected sample 
case step count exact number terms contained document 
terms offers chance document inserted corresponding pruned list counting terms contained document apply rejection method described subsection accept document correct probability probability 
notice algorithmic description leaves details unspecified 
instance checker advanced usually choice 
goal select checker advance farthest possible simple heuristic select checker infrequent term 
problem appears gen sampling wand 

success mass global 

global 
consider candidate 
count exactly posting lists contain global order perform probability normalization correctly 

foreach checker 
checker 
terms checker global 
probability 
line 
mass global advance preceding terms 

pick checker global 
probably best pick 
checker global 
repeat 
function producer 
geometric 
producer jump 
function 
return 
function 
add sample 
size buffer 

size sample 
take smaller sample 

foreach sample 
keep probability 
eral context query constraints satisfaction posting list iterators advanced heuristics try guess best move results seen far see 
particular case point execution algorithm flexibility advance checker producer example line advance producer checker 
principle select better advance producer checker experience far expected benefit choice implementation uses heuristic 
running time estimation choice set bound running time algorithm assuming know correct value sampling probability consider query terms recall ni total number documents containing ith term wi weight th term wand operator 
order obtain upper bound number pointer advances note advance checker advance past producer execution algorithm document consideration global originally selected term term term term term term producer checker global example posting lists 
bullet indicates term exists corresponding document 
black bullet indicates document sampled exists pruned list 
producer 
total number checker advances bounded total number producer advances expected ni 
running time expected ni 
sampling probability known advance worst case sampling help 
instance standard search wand spends large amount time getting matches starts producing matches fast sampling wand spend equal amount time decrease 
course entirely possible 
average case need assume results uniformly distributed respect numbers 
assume probability model ir assume document contains query terms independently certain probabilities 
case conditional document containing term ti fixed probability satisfies query 
similarly fixed probabilities 
satisfies query contains exactly 
terms consider time document selected producer say term ti 
assume time sampling probability view probability satisfies query passes rejection procedure jp hand view equation know total number samples inserted buffer bounded log number occur term ti selected producer bounded log total number moves producers checkers tk log log fixed query 
order minimize running time algorithm want select sum minimized 
course known advance estimated query progresses 
approach ni rough estimate ni 
equation suggests choice try minimize ni 
simple way achieve selection vein sort terms increasing order frequencies decreasing order weights case ties min tx wj 


notice greedy approach includes examples special cases 
optimal choice set minimize ni obtained solving integer program min ni wi equivalently max ni wi interpreted knapsack problem 
values ni integral solve exactly polynomial time dynamic programming small number terms solve efficiently brute force 
flexibility assigning weights usually want terms low frequency large weight case greedy approach suffice obtain optimal solution 
analysis minimizing upper bound actual running time usually smaller depend actual joint distribution query terms generally changes algorithm iterates posting lists 
practice achieve better performance observing performance producer dynamically changing set algorithm progresses 
want insert terms produce large jumps correlated successful samples sampling probability go quickly 

experiments implemented sampling mechanism wand operator performed series experiments test efficiency approach accuracy results 
search engine developed ibm 
data consisted set web pages consisting total words total distinct words 
document classified content categories 
taxonomy categories classification documents categories performed ibm eureka classifier described 
total categories document belonged zero categories 
eureka taxonomy contains additionally number broader super categories form hierarchical structure 
structure experimental evaluation argue section provide meaningful results category suggestion problem 
order estimate gain run time efficiency count number times pointer advanced jump terms posting lists 
argued previously total running time depends heavily number advances posting lists usually stored secondary storage accessing main bottleneck query response time 
experimented ambiguous queries depicted table chosen produce results different categories 
query created different samples sizes 
experiments resampling probability equals buffer size 
table compare number pointer advances different sample sizes 
notice total number matching documents small order thousands motivation techniques query schumacher joel michael olympic airline games turkey customs long island tea california terminator taxi driver dylan musician poet football indian america asia table queries inserted sampling algorithm 
query matches 
table number pointer advances queries 
second column contains total number pages matching query 
rest columns contain number pointer advances performed sampling samples pages 
applying queries result sizes millions show significant gain small sample sizes 
order establish point performed additional queries artificially created documents built random sequences numbers result sets larger 
results table 
tables clear sampling justified sampling size orders magnitude smaller actual result size case total time reduced factor depending ratio query type 
hand comparable overhead sampling due pointer term increase total time 
estimating frequent categories search results evaluated accuracy results small sample produced represented fre query matches sampling table comparison pointer advances queries performed artificially created documents samples sizes 
query table number top frequent categories appear samples 
query table number top frequent categories appear frequent sample categories 
quent categories matched documents 
consider queries table 
query results induces set categories eureka taxonomy 
order determine sampling succeeds discovering frequent categories measured frequent categories sample size results table 
additional desirable property frequent categories result set frequent sample identify 
check top frequent categories query appear top frequent categories sample depict results table 
facts worth noticing respect results sampling revealed tables 
notice cases small sample sizes succeed sampling documents frequent categories table larger sample size needed order ensure frequent categories manage popular sample depicted table 
sample size successful examples somewhat misleading examples total number documents small sampling extracts original categories 
final important explains poor performance cases table compared table 
focus concreteness corresponding query indian america asia 
total number matching documents sample size fails completely identify frequent categories sample size fails spot frequent categories table notice table match ry count est 
err est 
err est 
err table evaluation estimates sizes query results 
table shows actual value sampling size estimate percentage error 
manage sample documents related frequent categories 
due eureka categorization categories tag documents fine resulting documents matching specific categories 
query matching documents related categories tried extract top 
categories contains number documents frequent contains documents th frequent contains accumulated mass top categories sum number documents contained top categories total mass 
sampled documents chance document contained top categories negligible probability contained top th category 
solution categorization artifact straightforward obtaining samples aggregate categories coarser super categories taxonomy categories lions monkeys aggregated mammals animals 
final result sample smaller number categories large mass case small sample size efficiently discover popular super categories user 
emphasis lies mainly method sampling pursued line research 
estimating size result set evaluate quality estimator size result set 
table shows estimates relative errors 
mention commercial web search engines fail provide accurate estimation number results 
contrast notice smallest sampling size error exceeds usually negligible sample size greater 

summary propose performing sampling results queries order extract fast summary information ensemble results 
information means providing feedback user order refine query 
develop general scheme performing sampling efficiently show increase performance particular implementations 
test efficiency quality methods synthetic real world data 
issues worth investigation 
general wand sampling choices improve running time optimal selection set selection checkers producers advance 
approach inspired adaptive mechanism keeps track effect past choices query running 
second interesting understand classes queries sampled efficient method general procedure section 
particular simple common boolean combinations expressible single wand probably sampled efficiently general procedure general wand mechanism 
third model average running time sampling wand allows rigorous analysis requires fewer independence assumptions remains challenge 

steve gates useful discussions suggestions providing experimental set hardware eureka taxonomy web crawled data allowed perform experiments 
indebted andrew tomkins observations regarding early draft benefitted comments received andreas neumann ronny lempel qi jason zien anonymous referees 

aggarwal gates yu 
partial supervision text categorization 
ieee trans 
knowl 
data eng 
amitay carmel lempel 
scaling ir system evaluation term relevance sets 
proceedings th annual international conference research development information retrieval pages 
acm press 
babcock datar motwani 
sampling moving window streaming data 
proceedings thirteenth annual acm siam symposium discrete algorithms pages 
society industrial applied mathematics 
beyer lyle rajagopalan shekita 
pivot join runtime operator text search 
manuscript 
brin page 
anatomy large scale hypertextual web search engine 
www computer networks isdn systems april 
broder 
taxonomy web search 
sigir forum 
broder carmel zien 
efficient query evaluation level retrieval process 
proceedings twelfth international conference information knowledge management pages 
acm press 
burrows 
sequential searching database index word location pairs 
united states patent 
carmel amitay maarek 
trec experiments index pruning 
proceedings tenth text retrieval conference trec 
national institute standards technology nist 
devroye 
non uniform random variate generation 
springer verlag 

popularity importance search engines august 
pew internet american life project www org pdfs pip data memo pdf 
shekita zien rajagopalan neumann 
high performance index build algorithms intranet search engines 
vldb proceedings thirtieth international conference large data bases pages 
morgan kaufmann 
gibbons 
estimating simple functions union data streams 
spaa proceedings thirteenth annual acm symposium parallel algorithms architectures pages 
acm press 
gruhl gibson meyer tomkins zien 
build architecture large scale text analytics 
ibm systems journal 
haas naughton swami 
relative cost sampling join selectivity estimation 
proceedings thirteenth acm sigact sigmod sigart symposium principles database systems pages 
acm press 

li 
reservoir sampling algorithms time complexity log 
acm trans 
math 
softw 
muthukrishnan 
data streams algorithms applications 
rutgers edu stream ps 
radev qi zheng blair zhang fan prager 
mining web answers natural language questions 
proceedings tenth international conference information knowledge management pages 
acm press 
silverstein marais henzinger 
analysis large web search engine query log 
sigir forum 
turtle flood 
query evaluation strategies optimizations 
information processing management 
vitter 
random sampling reservoir 
acm trans 
math 
softw 

yee swearingen li hearst 
faceted metadata image search browsing 
proceedings conference human factors computing systems pages 
acm press 
