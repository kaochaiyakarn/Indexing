experiments quanti ed facial asymmetry human identi cation liu mitra cmu ri tr robotics institute carnegie mellon university pittsburgh pa carnegie mellon university research supported part onr research part nsf research iis 
human facial asymmetry long critical factor evaluations attractiveness facial expressions psychology anthropology 
rarely human identi cation tasks 
investigate ect quanti ed statistical facial asymmetry biometric expression variations 
ndings show asymmetry measure automatically selected facial regions captures individual di erences relatively stable facial expression variations 
importantly synergy combining asymmetry faces conventional fisherface method data publicly available face databases cohn kanade feret quantitatively evaluated 
improvements classi cation accuracy shown statistically signi cant 
di erent experiments setup fisherfaces subjects cohn kanade database train anger disgust test joy train joy anger test disgust train disgust joy test anger train neutral faces test peak expressions train peak expressions test neutral faces 
addition facial asymmetry information automatic image feature subset selection procedure classi cation error rates reduced reduced zero 
human facial asymmetry long critical factor evaluation facial attractiveness expressions psychology anthropology albeit studies carried qualitatively human observers judges locally features measured individually length ears 
asymmetrical faces considered attractive reported facial attractiveness men inversely related recognition accuracy 
face recognition humans small statistically signi cant decrease recognition performance observed facial asymmetry removed images suggests facial asymmetry may play role human identi cation humans 
report serves sequel initial facial asymmetry new biometric reported 
record detail experimental results carried cohn kanade au coded facial expression database :10.1.1.41.8048
section provides de nitions various facial asymmetry gives description data set 
image data sets face dataset report cohn kanade au coded facial expression database :10.1.1.41.8048
dataset consists video sequences subjects di erent races gender displaying requested facial expressions 
subject videotaped bilaterally balanced ambient lighting single high intensity lamp dual high intensity lamps re ective 
subjects selected complete video data expressions anger disgust joy 
expression sequence begins neutral expression ends target expression 
video sequences range length frames 
frame grey scale image pixels 
maintain equal sampling di erent subjects frames emotion sequence chosen 
frames initial neutral middle nal peak expression images 
total sample size 
quanti cation facial asymmetry self contained repeat de nitions quanti ed facial asymmetry de ned 
asymmetry structural descriptor object captured single local measure left right face 
bilateral re ection symmetry de ned respect re ection line plane 
human faces possess natural line plane necessarily geometrically straight line plane 
face image normalization goal normalization establish common coordinate system di erent faces meaningfully easily compared 
facial asymmetry measures readily comparable combinable eigenface fisherfaces follow face normalization process similar :10.1.1.12.7580
identify anatomical feature points face inner eye 
de ne face midline line going mid point neutral joy disgust anger normalized faces cohn kanade au coded facial expression database :10.1.1.41.8048
column represents subject total subjects displayed neutral peak joy peak disgust peak anger expressions video sequences respectively 
borrowed face image normalized points left right inner ane transformation follows rotation rotate horizontal line segment skewing skew face image horizontally located perpendicular line going midpoint scaling scale length scale distance length common coordinate faces formed transforming face midline xed vertical line centered face image 
facial feature points marked manually rst frame tracked lucas kanade algorithm 
related study tracked feature points highly correlated manually marked nal positions 
image cropped squared image face midline centered vertically 
normalized faces inner pixel locations 
upper left corner coordinates figures 
facial asymmetry measurements face midline determined point normalized face image unique corresponding point side face image number columns image 
establish coordinate system normalized face image axis perpendicular face midline axis coinciding face midline 
normalized face density image vertically re ected image respective edge images formed applying edge extraction algorithm de ne facial asymmetry measurements density di erence face edge orientation similarity face cos angle edge orientations images pixel point displays normalized faces respective face face 
face face capture facial asymmetry di erent perspectives 
face represents left right relative intensity variation face ected zero crossings intensity eld 
higher value face asymmetrical face 
higher value face symmetrical face 
construction face bilaterally symmetric left right halves face opposite 
half face face contains needed information 
denote half faces face face 
table de ne projections face face call 
dimension called feature 
feature space dimension reduction face face size total dimension 

dimensions necessarily independent equally useful human identi cation 
nd combination local facial asymmetry measures discriminative human identities reduce computation cost experimented approaches feature dimensionality reduction 
speci set computed cohn kanade database concrete example feature space reduction 
dimensions database speci ed right column table 
normed face face face normalized face face face 
principle component analysis pca pca performed matrix produce dataset de ned table 
total number pixels feature dimension face face sample number 
commonly accepted criterion face recognition stated keep top principle components pcs account variance data 
cut rate top principal components face principal components face retained 
feature dimensions reduced respectively 
feature averaging computed mean values axes obtain table way reduce feature space dimensions respectively 
provide economical way examine facial asymmetry row row column column 
representation facial asymmetry expression video expressed spatiotemporal surface visualization comparison 
figures show sheets expressions subjects respectively shows example row projections face varies expression video clips joy anger disgust 
observed despite expression changes subject variation pronounced variation expression 
discriminative feature subset selection common theme research available image features selectively di erent image discrimination tasks especially ective redundancy presents di erent feature dimensions expressions subject expressed form expressions subject expressed form expressions subject expressed form table di erent de ned 
right column indicates dimensions 
pcs means principal components 
notation de nitions size axis axis face intensity di erence image face edge similarity image description dimensions samples features top pcs accounting variance face column mean face axis row mean face axis top pcs accounting variance face column mean face axis row mean face axis 
current study full range table certain criteria seek discriminative feature subspace 
feature values sf data set total classes de ne augmented variance ratio avr follows av ar sf ar sf min sf mean sf mean mean feature values class avr ratio variance feature subjects variance feature subjects added penalty features close inter subject mean values 
individual features higher variance ratios discriminative 
experimental methods fisherface baseline classi er expression video sequence image dataset primary testbed multiple samples frames video subjects expressions joy anger disgust respective neutral peak frames :10.1.1.41.8048
fisherface known method face recognition 
fisherface linear discriminant analysis lda applied pca components normalized face images 
set relatively independent features dataset consisting classes objective lda obtain dimensional linear combination maximizes ratio ba wa variance groups common covariance matrix features single group 
word lda creates linear combination feature dimensions yields largest mean di erences desired classes 
designed types experiments table systematically investigate facial asymmetry measures de ned contribute expression invariant human identi cation 
listed table table types experiments train image expressions test image expressions anger disgust joy disgust joy anger joy anger disgust peak expressions neutral neutral peak expressions di erent feature sets de ned table pca components normalized face images experiments carried steps step fisherface apply fisherface step subsets possible combinations compute avr value feature dimension training data order features non increasing order carry forward feature subset selection ordered feature list obtain feature subspace apply linear discriminant analysis lda test data selected feature subspace 
step ff af de ne symbol denote process possible feature vector concatenation pca components compute avr values feature dimension rank features non decreasing order avr values followed apply forward feature subset selection concatenated feature vector training data perform lda classi cation selected reduced feature subspace test data 
classi cation procedure included feature subset selection step applying lda 
reason additional step eliminate irrelevant redundant feature dimensions original feature space establishing feature subspace relatively independent feature dimensions 
experimental results goal experiments test incremental validity relative fisherface 
test robust variation type intensity facial expression cohn kanade database 
experiments dx sx table table showing misclassi cation rates feature sets separately 
dx sx dx sx sx dx dx sx dx sx table table showing misclassi cation rates pairs feature sets 
dx sx dx sx dx sx dx sx sx dx sx sx dx dx dx sx sx dx dx sx table table showing misclassi cation rates possible sets feature sets 
dx sx dx dx sx sx dx sx dx dx sx dx dx sx sx sx dx sx dx sx table table showing misclassi cation rates possible sets feature sets 
dx sx dx sx dx sx dx sx dx sx table table showing misclassi cation rates possible sets feature sets 
dx sx table table showing misclassi cation rates combining sets feature sets 
experiments combining fisherface ff ff ff ff ff dx ff sx ff sx table table showing misclassi cation rates combinations fisher faces feature sets 
ff ff ff ff ff ff ff dx ff sx ff sx ff dx ff dx sx ff dx ff sx ff sx ff dx table table showing misclassi cation rates possible combinations fisher faces pairs feature sets 
ff ff ff dx ff sx ff dx sx ff dx sx ff ff ff dx ff dx ff sx ff sx ff dx ff dx ff sx ff sx ff dx sx ff dx sx ff dx ff sx table table showing misclassi cation rates possible sets feature sets 
ff ff dx sx ff dx ff sx ff dx ff sx ff sx ff dx ff dx sx ff dx sx ff sx ff dx ff dx sx ff dx sx ff dx sx table table showing misclassi cation rates possible combinations fisher faces sets feature sets 
ff dx ff sx ff dx sx ff dx sx ff dx sx ff dx sx table table showing misclassi cation rates possible combinations fisher faces sets feature sets 
ff dx sx table table showing misclassi cation rates combining feature sets subsets fisher faces 
statistical signi cance tests tables tables statistically signi cant test results 
combination performed signi cantly better fisher faces subsets testing anger disgust frames components 
fisherfaces vs combination signi cant improvement testing subsets ff components 
test set joy anger disgust neutral peak value signi cant 
table statistical signi cance results versus fisherface 
test set joy anger disgust neutral peak value signi cant 
table statistical signi cance results fisherfaces combinations 
feature dimensions selected feature sets individual dimensions selected total number ff dx sx total table testing joy frames training anger disgust 
feature sets individual dimensions selected total number ff dx sx total table testing anger frames training joy disgust 
implies number fisher face components combining asymmetry faces 

feature sets individual dimensions selected total number ff dx sx total table testing disgust frames training joy anger 
implies number fisher face components combining asymmetry faces 

feature sets individual dimensions selected total number ff dx sx total table testing neutral frames training peak ones 
feature sets individual dimensions selected total number ff dx sx total table testing peak frames training neutral ones 
summary table show outcome experimental steps section fisherface ff af di erent setups table 
dimension reduced feature space fisherface larger follow choice report results fisherface principal components retained 
table results fisherface versus ff af 
numbers parenthesis indicate feature dimensions selected feature subset selection testing training fisherface error error ff af error joy anger disgust anger joy disgust disgust joy anger neutral peak peak neutral comparison fisherface lower error rates experiments table 
experiments errs fisherface ff af testing joy 
paired tests show signi cance level results ff af statistically better fisherface table 
shows change error rates addition feature sets 
observe trend increasing di erent types error rates fisherface ff af decreasing 
steepest slopes appear fisherface axis face added axis 
testing joy sees error rate declines additional introduced 
nding implies redundant terms contribution human identi cation 
table values tests 
ones indicate statistical signi cance level 
test set fisherface versus fisherface versus ff af joy anger disgust neutral peak fisherface ff add add add dy add dy sy add dy sy dx add afs error rates fisherface ff af error rates fisherface ff af increasing number test anger test disgust test joy test neutral test peak error rates fisherface ff af added ff af 
plot represents error rate testing unseen expressions listed table 
discussion classi cation error relation number retained principal components experimental results table suggest quanti ed facial asymmetry information discriminative power human identi cation 
explicitly included existing face identi cation methods obvious improvements classi cation rates observed 
computed observed principal components normalized face images fisherface error rate decreases table 
pertinent question raised possible small principal components normalized face images contain information facial asymmetry discarded early eigenface fisherface classi ers 
table error rates fisherface di erent number principal components indicated parenthesis test joy anger disgust neutral peak train anger disgust joy disgust joy anger peak neutral ff ff ff ff pursued question case testing joy largest remaining error experiment 
shows results subjects frames number principal components eigen features increased dimensions 
principal components increased dimensions ff af method doing better fisherface 
suggests explicitly computing including facial asymmetry measurements human identi cation bene cial 
peak expression faces versus neutral faces easier identify observed table di erent experimental setups table neutral face test peak face relatively easier cases training expressions testing third expression 
tests human identi cation expression variation fall neutral peak categories 
observation suggests studies di erent expressions intensity levels may important necessary 
error rates reported tables see training expressions testing unseen expression usually higher error rates fisherface methods 
training anger disgust testing joy dicult worth study 
joy faces harder identify 
small consistent decrements face recognition joy relative anger disgust 
possible explanation di erence emotional valence emotion expressions 
theory ff af method shows superior performance compared fisherface method extending pca components fisherface method dimensions 
data suggest positive emotions joy left hemisphere negative emotions anger disgust right 
di erence explain increased asymmetry side face uence face recognition asymmetry metrics 
critical factor may location range motion muscles involved 
anger disgust expressions involve muscle actions near midline face movements relatively small eye narrowing lip compression joy expressions involve muscles side face muscles major involved relatively large ords greater range motion 
larger motion side face joy expressions increase asymmetry relative smaller facial motion midline 
interpretation consistent nding asymmetry images greatest side face decreased moves midline 
limitations limitation study reliance expressions produced demand deliberate elicited emotion eliciting stimuli 
deliberate facial expressions relative spontaneous ones believed asymmetric means variance due expressions increased relative variance due individual di erences faces 
study may provide conservative estimate extent asymmetry metrics contribute face recognition 
limitation sizes datasets experiments 
larger datasets preferable current ndings appear reliable 
con rmed statistical tests possible consistent independent databases 
study larger databases worthwhile 
previous psychology suggests facial asymmetry contributes human identi cation 
similar bene ts may obtained automated face recognition 
facial asymmetry provide signi cant information especially combined conventional face recognition algorithms 
studied facial asymmetry human identi cation 
proposed quantitative measures facial asymmetry demonstrated face face measures projections easy fast compute table automatically selected facial asymmetry regions capture individual di erences show robustness variations facial expression table important nding classi cation accuracy improved combining fisherface eigenface 
results suggest facial asymmetry may provide complementary discriminative information human identi cation methods missing automatic human identi cation 
current includes studying issue distill intrinsic facial asymmetry images cluttered extrinsic facial asymmetries examining faces veri cation hypothesis aiding recognition asymmetry facial expression identi cation gender relevance analysis pose estimation designing ective discriminative feature subspace reduction schemes optimal face classi cation 
authors professor andrew moore drs 
geo gordon tom minka cmu phillips darpa productive discussions 
cmu students weaver statistics dan computer science marc physics yan computer science statistics worked dr liu subsets data reported course projects fall spring 
zhang generated 
research supported part onr nsf iis nimh mh 
belhumeur kriegman 
eigenfaces vs recognition class speci linear projection 
pami july 
bishop 
neural networks pattern recognition 
clarendon press 
isbn 
casella berger 
statistical inference 
duxbury press belmont california 
duda hart stork 
pattern classi cation 
john wiley sons new york 
gross shi cohn 
quo face recognition 
third workshop empirical evaluation methods computer vision pages kauai hawaii december 
hager ekman 
asymmetry facial actions inconsistent models specialization 
psychophysiology 
kanade cohn tian :10.1.1.41.8048
comprehensive database facial expression analysis 
th ieee international conference automatic face gesture recognition grenoble march 
publically available www ri cmu edu projects project html 
lien kanade cohn li 
detection tracking classi cation subtle changes facial expression 
journal robotics autonomous systems 
liu dellaert 
classi cation similarity metric image retrieval 
proceedings computer vision pattern recognition conference cvpr pages santa barbara june 
ieee computer society press 
liu dellaert moore schneider kanade 
classi cation driven pathological neuroimage retrieval statistical asymmetry measures 
international conference medical imaging computing assisted intervention miccai 
springer october 
liu lazar kanade 
classi cation driven feature space semantic neuroimage retrieval 
international symposium information retrieval exploration large medical image collections october 
liu mitra 
human identi cation versus expression classi cation bagging facial asymmetry 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa 
liu mitra 
quanti ed study facial asymmetry gender di erence 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa 
liu schmidt cohn mitra 
facial asymmetry quanti cation expression invariant human identi cation 
computer vision image understanding journal special issue face recognition appear 
liu schmidt cohn weaver 
facial asymmetry quanti cation expression invariant human identi cation 
international conference automatic face gesture recognition may 
liu weaver schmidt cohn 
facial asymmetry new biometric 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa 
liu zhao zhang farkas kanade 
learning discriminant features biological images 
ieee international symposium biomedical imaging macro nano 
submitted february 
martinez 
semantic access frontal face images expression invariant problem 
proceedings ieee workshop content access images video libraries 
martinez 
recognizing imprecisely localized partially occluded expression variant faces single sample class 
ieee transactions pattern analysis machine intelligence 
martinez kak 
pca versus lda 
ieee transactions pattern analysis machine intelligence 
toole 
perception face gender role stimulus structure recognition classi cation 
memory cognition 
richardson bowers bauer leonard 
digitizing moving face dynamic displays emotion 
neuropsychologia 
gur 
emotions expressed intensely left side face 
science 
schmidt cohn 
temporal patterning smile onsets discriminates posed spontaneous smiles 
international society research emotion july spain 
swets weng 
discriminant eigenfeatures image retrieval 
ieee transactions pattern analysis machine intelligence august 

facial attractiveness 
trans 
cognitive sciences december 
bilateral symmetry human faces recognition novel views 
vision research 
turk pentland 
eigenfaces recognition 
neuroscience 
cohn 
automated tracking facial features facial disorders 
plastic reconstructive surgery 

