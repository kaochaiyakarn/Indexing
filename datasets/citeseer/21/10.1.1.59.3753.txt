person identification automatic integration speech lip face experts fox dept electronic electrical engineering university college dublin dublin ireland tel fox ee ucd jeffery cohn robotics institute carnegie mellon university forbes ave pittsburgh pa tel cs cmu edu presents multi expert person identification system integration separate systems employing audio features static face images lip motion features respectively 
audio person identification carried text dependent hidden markov model methodology 
modeling lip motion carried gaussian probability density functions 
static image identification carried faceit system 
experiments conducted subjects xm vts audio visual database 
late integration automatic weights employed combine experts 
integration strategy adapts automatically audio noise conditions 
integration experts improved person identification accuracies clean noisy audio conditions compared audio case 
audio faceit lip motion tri expert identification maximum accuracies achieved respectively 
maximum bi expert integration visual experts achieved identification accuracy comparable best audio accuracy 
categories subject descriptors computing methodologies pattern recognition design methodology classifier design evaluation 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
november berkeley california usa 
copyright acm 
ralph gross robotics institute carnegie mellon university forbes ave pittsburgh pa tel cs cmu edu richard reilly dept electronic electrical engineering university college dublin dublin ireland tel richard reilly ucd philip de dept electronic electrical engineering university college dublin dublin ireland tel philip ee ucd general terms algorithms reliability experimentation security 
keywords person identification multi expert audio face lips late integration automatic weighting 

biometrics field technology devoted verification identification individuals biological traits 
verification binary classification problem involves validation claimed identity identification multi class problem involves identifying user set subjects 
person identification inherently difficult task particularly number registered subjects large 
person identification systems analysis audio signals achieve high performance signal noise ratio snr audio signal high 
performance degrades quickly decreasing snr values 
expected integration audio expert context term expert refers particular audio visual person identification system visual expert improve audio scores clean audio conditions increase robustness presence audio noise 
audio expert fused visual expert improve robustness speech recognition audio noise 
multi expert person identification experiments showed integration visual experts incorporating visual features eyes nose mouth audio expert significantly improved scores 
person identification robust audio noise audio lip motion experts integrated 
previous studies shown faceit person identification system places lot emphasis eye region 
faceit experiments carried different face occlusions shown performance faceit degrades significantly high level eye occlusion 
lip motion system described uses lip features extracted sequence lip region interest roi images 
expected integration visual person identification systems emphasizing eyes emphasizing lips lead synergistic improvement 
systems person identification single expert speech facial features 
investigated relative performance approaches person identification speech lip motion facial features benefits improvements possible combining multi expert classifier conditions varying time delays training testing sets number training sessions audio noise 
results integration experts experiments integration faceit lip motion experts faceit audio experts lip motion audio experts experts 

xm vts av database xm vts audio visual av database employed experiments described :10.1.1.35.468
database consists video data recorded subjects sessions spaced monthly 
recording session third sentence joe took fathers green shoe bench research 
start sentences clipped 
due errors sentences possible subjects experiments 
lip motion features extracted mouth roi 
roi identified manually th frame roi intermediate frames determined interpolation 
identify roi manually midpoint labial corners identified pixel block centered midpoint extracted roi 
faceit system processes entire visual frame taken video sequence 

face recognition faceit current face recognition algorithms categorized classes image template geometry feature 
template methods compute correlation face model templates estimate face identity 
statistical tools support vector machines svm linear discriminant analysis lda principal component analysis pca kernel methods neural networks construct suitable set face templates 
templates viewed features capture global features face images 
facial occlusion difficult handle approaches 
geometry feature methods analyze explicit local facial features geometric relationships 
cootes active shape model extending approach yuille 
wiskott developed elastic bunch graph matching algorithm face recognition 
developed pca local feature analysis basis commercial face recognition system faceit 
addresses major problems pca 
application pca set images yields global representation image features robust variability due localized changes input 
furthermore pca representation non topographic nearby values feature representation necessarily correspond nearby values input 
overcomes problems localized image features form multi scale filters 
feature images encoded pca obtain compact description 
faceit top performing systems number independent evaluations 
shown robust variations lighting facial expression lower face occlusion 
faceit handle pose variations degrees frontal 
performance drops significantly larger pose changes occlusion eyes dark 

audio person identification audio signal pre emphasized increase acoustic power higher frequencies filter 
pre emphasized signal divided frames hamming window length ms overlap ms give audio frame rate fa hz 
mel frequency cepstral coefficients mfcc dimension extracted frame 
energy frame calculated th static feature 
seventeen order differences delta features calculated adjacent frames appended static audio features give audio feature vector dimension 
number mfcc employed determined empirically give best performance 
cepstral mean normalization performed audio feature vector order compensate long term spectral effects audio channel 
text dependent person id expert 
text dependent modeling subject says utterance training testing 
employed opposed text independent modeling suited database study 
text dependence outperform text independence 
subject si modeled single audio sentence subject dependent hmm 
background hmm 
sessions training session testing 
background hmm trained sessions subjects 
background model captures audio speech variation entire database 
training utterances subject insufficient training data train subject dependent hmm initialized prototype model 
background model initialize training subject dependent models 
sentence observation tested subjects si subject gave maximum score chosen identified subject 
score observation subject si si calculated normalized dividing number frames sentence observation 

identification lip motion transform features represent visual information discrete cosine transform dct high energy compaction 
color pixel blocks converted gray scale values 
gray scale roi histogram equalized mean pixel value subtracted 
image pre processing carried account varying lighting conditions sessions subjects 
dct applied gray scale pixel blocks 
coefficients taken zigzag pattern form visual frame observation feature vector 
features modeling feature corresponds mean roi due mean removal zero valued feature vector frame 
gaussian model consisting single probability density function model lip motion subject 
entire visual sentence modeled gaussian model 
mean feature vector diagonal covariance matrix calculated training data 
log likelihood probability calculated frame test sentence scores summed entire sentence 
summation score normalized dividing number frames test sentence 
done subject models model giving highest score chosen identified subject 

late integration various experts audio faceit lip motion integrated late integration li 
advantages li include ability account expert reliabilities small feature vector dimensions expert ease adding experts system 
li expert scores weighted account reliability mode 
scores may integrated addition multiplication shown equations respectively bi expert li 
li methods investigated results achieved similar 
results additive integration 
prior li expert scores normalized fall range 
si xv si 
si xv 



fusion parameter varies audio snr 
shows expert weights depend fusion parameter higher values place emphasis audio expert lower values place emphasis visual expert 
decision entirely audio expert decision entirely visual expert 
automatic integration mapping audio reliability measure fusion parameter employed 
reliability measure employed sum difference top highest scores difference second third highest scores person test 
audio snr decreases reliability measure decreases audio scores discriminatory 
determine mapping values provided optimum fusion opt exhaustive search tests snr value 
mean reliability measure mean tests snr value 
sigmoidal function os exp employed provide mapping opt mean parameters os os determined empirically give best performance 
automatic integration calculated scores test determined 
integration approach similar 

variation expert fusion parameter 
experiments experiments probe images testing obtained final fourth session 
faceit galleries training formed sessions table 
trials constructed test performance faceit varied time difference gallery probe set varied months multiple sessions form gallery 
testing lip motion feature person identification system carried trials table 
table 
outline visual trials performed trial gallery train probe test os audio models tested trial table 
additive white gaussian noise applied clean audio signal noise ratios snr ranging db db steps db 
audio models trained clean speech tested speech containing noise 
evaluation faceit system selected subjects xm vts database proceeded follows 
trials single gallery image chosen random image sequence subject compared randomly chosen probe image subject 
faceit produces matching score gallery probe image pair 
probe image gallery image highest score selected recognition result 
trials faceit randomly chosen gallery images respectively internally combined faceit determine matching score 
cases original unprocessed images 
separate experiment verified faceit face finding module able reliably locate face image 
integration experiments carried experts 
integrating faceit lip motion visual experts integrated test fusion led synergistic improvement 
fusion carried equation fusion parameter equal weighting experts 
integrating faceit audio noise free audio conditions audio person identification system achieve high accuracies 
presence audio noise performance degrade significantly 
scores faceit trial integrated audio scores various audio snr order investigate audio accuracies improved low snr expert weighting determined automatically described section 
integrating lip motion audio tests described section carried lip motion trial scores place faceit scores 
integrating experts experts integrated 
visual weight divided equally visual experts shown equation 
si xa xv 
xa si xv xv 
results left right hmm twelve state mixture topology audio classification experiments 
audio models trained baum welch algorithm tested viterbi algorithm implemented hmm toolkit htk 
audio features calculated htk 
background models trained sessions 
gave training examples background model 
hmm topology exhaustive search give best result 
audio results versus snr table 
table 
audio audio faceit audio lip motion tri expert scores trial snr audio audio audio experts faceit lip motion results faceit lip motion trials table 
results percentage accuracy number correctly identified subjects possible subjects 
table 
faceit lip motion faceit integrated lip motion scores trials faceit lip motion faceit trial lip motion mean integrating faceit lip motion results late integration faceit lip motion experts table 
integrated scores equal weights 
integrating faceit audio results late integrating faceit trial audio expert thirteen audio noise levels automatic weights table 
results shown 
sigmoidal fit opt reliability measure shown 
sigmoidal fit audio faceit trial data sigmoidal fit reliability measure 
sigmoidal fit audio faceit trial 
audio faceit trial audio visual av noise level db 
integration faceit trial audio versus snr 
integrating lip motion audio results late integrating lip motion trial audio expert thirteen audio noise levels automatic weights table 
results shown 
sigmoidal fit opt reliability measure shown 
sigmoidal fit audio lip motion trial data sigmoidal fit reliability measure 
sigmoidal fit audio lip motion trial 
audio lip motion trial audio audio visual visual av av noise level db 
integration lip motion trial audio versus snr 
integrating experts results tri expert late integration trial thirteen audio noise levels automatic weights table 
sigmoidal fit opt reliability measure shown 
sigmoidal fit tri expert integration data sigmoidal fit reliability measure 
sigmoidal fit tri expert integration 
tri expert integration audio audio lip lip motion motion faceit faceit experts noise level db 
integration experts versus snr 

discussion person recognition rates audio expert table high high snr highest recognition rate attained snr db 
snr decreased recognition rate decreased 
large change recognition rate snr db snr db 
snr db lower recognition rate equal recognition rate random guessing 
steep roll recognition performance respect snr due mismatched audio testing conditions training noise free audio testing audio lower snr 
expected roll steep matched testing employed training testing audio snr 
table shows lip motion expert performs training sessions trial giving recognition rate 
rate obtained manual roi determination may positively biased results 
automatic roi detection system need order test bias 
lip motion scores trials respectively show large variance 
may indicate gaussian models poorly trained test session trial provided person discrimination 
trial time difference training testing may reason performed better trials 
trial best faceit trials 
score variance lip motion trials 
faceit recognition rate trials decreased time difference increased training testing data 
decrease recognition rate may apparent practical system time difference training phase identification phase exceeds months 
addition gallery sessions improved faceit scores sessions trial giving score 
adding additional gallery images session trial improved recognition accuracy falls far short accuracy achieved trial 
conclude increase performance due availability gallery images time 
integrating faceit lip motion combining visual experts resulted comparable performance audio expert 
shown table best result combining image experts resulted recognition rate lower best recognition rate audio expert 
suggests visual experts comparable importance audio expert person identification 
worth noting xm vts visual data extremely high quality little variation illumination pose emotion recording sessions 
practical system may produce high quality visual data person recognition system greater reliance audio expert 
trials combining visual experts employing equal weightings resulted improvement recognition rate visual expert 
integrating faceit audio integration faceit audio shown table resulted perfect recognition rate snr greater db 
recognition rate decrease rapidly respect snr audio expert see table 
integrated system performed better noise levels sensitive audio noise 
integrating lip motion audio integration lip motion expert audio expert shown table successful integration section 
improvement audio scores achieved noise levels 
recognition rate decreased rapidly respect snr equivalent rates section 
integrating experts perfect recognition rate achieved experts integrated snr audio signal exceeded db 
tri expert integration outperformed bi expert uni expert recognition rates noise levels db 
tri modal scores db db decline rise level achieved purely integrating visual experts 
poor performance db db due sigmoidal fit shown trained reliability parameters opt opt values determined globally person tests see section may large variance 
sigmoidal fit take variance opt account 
different curve fit different reliability parameter exhibiting lower variance may improve tri expert scores 
aim investigate effect image degradations identification performance 
automatic determination integration weights important note automatic weight sigmoidal mapping functions trained tested data may resulted slightly optimistically biased performance results 
ideally sigmoidal mapping functions trained tested different data sets 
noted reliability measure employed may behave differently snr different noise types 
interesting carry experiments different noise types additive white gaussian noise employ reliability measures dispersion score variance entropy voicing index 
automatic weights employed take reliability visual experts account 
major issue experiments carried study visual data constant high quality 
presence varying visual degradations expert weights depend visual expert reliability measure 

integration visual experts resulted higher identification performance performance obtained visual expert 
results show visual experts provide complementary information emphasizing different visual cues 
visual experiments performance system presence eye occlusion provide insight 
results showed system integrating audio visual expert accurate noise free audio robust audio noise compared performance audio system 
automatically determined experts weights leads synergistic integration 
integration method efficient computationally expensive carry 
tri expert results show integration available experts leads best recognition rates 
advantage multi expert system subjects difficult identify expert may easily identified expert 

research described supported informatics research initiative enterprise ireland part office naval research contract 
belhumeur hespanha kriegman eigenfaces vs fisherfaces recognition class specific linear projection ieee transactions pattern analysis machine intelligence vol 
pp 

fox reilly audio visual speaker identification dynamic audio visual features proc 
th international conference audio video biometric person authentication june 
blackburn bone philips facial recognition vendor test evaluation report 
brunelli person identification multiple cues ieee transactions pattern analysis machine intelligence vol 
pp 
oct 
chen audiovisual speech processing ieee signal processing magazine vol 
pp 
jan 
davis comparison parametric representations monosyllabic word recognition continuously spoken sentences ieee transactions acoustics speech signal processing vol 
pp 

gross shi cohn quo face recognition third workshop empirical evaluation methods computer vision 
heckmann kristian noise adaptive stream audio visual speech recognition eurasip journal applied signal processing special issue joint audio visual speech processing vol 
pp 
nov 
www com road mn 
lanitis taylor cootes automatic interpretation coding face images flexible models ieee transactions pattern analysis machine intelligence vol 
pp 

lawrence giles tsoi back 
face recognition convolutional neural network approach ieee transactions neural networks vol 
pp 

li gong support vector regression classification multi view face detection recognition ieee international conference automatic face gesture recognition 
audio visual speech processing 
phd thesis queensland university technology brisbane australia apr 
luettin evaluation protocol xm database lausanne protocol idiap communication idiap martigny switzerland oct 
luettin speaker verification experiments xm vts database idiap communication idiap martigny switzerland aug 
matas kittler luettin xm extended vts database proceedings second international conference audio video biometric person authentication washington pp :10.1.1.35.468
mar 
netravali haskell digital pictures plenum press pp 

atick local feature analysis general statistical theory object representation network computation neural systems vol 
pp 

phillips blackburn bone face recognition vendor test evaluation report 
rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee vol 
pp 
feb 
reynolds rose robust text independent speaker identification gaussian mixture speaker models ieee transactions speech audio processing vol 
jan 
ripley pattern recognition neural networks 
cambridge cambridge university press 
sirovich kirby low dimensional procedure characterization human faces journal optical society america pp 

reilly visual feature analysis automatic dsp research group ucd dublin ireland 
turk pentland eigenfaces recognition journal cognitive neuroscience vol 
pp 

vapnik nature statistical learning theory springer verlag 
wiskott krueger von der malsburg face recognition elastic bunch graph matching ieee transactions pattern analysis machine intelligence vol 
pp 

young moore odell valtchev woodland htk book htk version microsoft cambridge university engineering department nov 
yuille deformable templates face recognition journal cognitive neuroscience vol 
pp 

