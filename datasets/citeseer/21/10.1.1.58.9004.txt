final version www com link asp id la class imbalances versus class overlapping analysis learning system behavior gustavo maria laboratory computational intelligence department computer science statistics sce institute mathematics computer science icmc university paulo campus carlos box carlos sp brazil phone 
fax 
icmc usp br 
works point class imbalance obstacle applying machine learning algorithms real world domains 
cases learning algorithms perform imbalanced domains 
fair directly correlate class imbalance loss performance learning algorithms 
develop systematic study aiming question class imbalances truly blame loss performance learning systems class imbalances problem 
experiments suggest problem directly caused class imbalances related degree overlapping classes 
draft draft machine learning methods advanced point applied real world problems data mining knowledge discovery 
applied problems new issues previously considered machine learning researchers coming light 
issues class imbalance problem differences class prior probabilities 
real world machine learning applications reported class imbalance hinder performance standard classifiers 
relationship class imbalance learning algorithms clear understanding affects lacking 
spite decrease performance standard classifiers imbalanced domains mean imbalance sole responsible decrease performance 
quite possible class imbalances yield certain conditions hamper classifiers induction 
research motivated experiments performed imbalanced datasets instance sick dataset provided results auc high degree imbalance examples belong minority class 
addition research works agree standpoint 
springer verlag berlin heidelberg final version www com link asp id la develop systematic study aiming question class imbalances hindrance classifier induction deficiencies explained ways 
develop study series artificial datasets 
idea artificial datasets able fully control variables want analyze 
able control variables results may masked difficult understand interpret risk producing misleading 
experiments suggest problem solely caused class imbalances related degree data overlapping classes 
organized follow section introduces hypothesis regarding class imbalances class overlapping 
section presents notes related evaluating classifiers performance imbalanced domains 
section discusses results 
section presents concluding remarks 
role class imbalance learning years works published machine learning literature aiming overcome class imbalance problem 
international workshops sponsored aaai held twentieth international conference machine learning 
exist agreement machine learning community statement imbalance classes major obstacle inducing classifiers imbalanced domains 
conversely believe class imbalances problem 
order illustrate conjecture consider decision problem shown 
problem related building bayes classifier simple single attribute problem classified classes positive negative 
assumed perfect knowledge regarding conditional probabilities priors 
conditional probabilities classes gaussian functions standard deviation class negative class having mean standard deviation standard deviations draft draft apart positive class mean 
vertical lines represent optimal bayes splits 
clear influence changing priors positive class indicated dashed lines stronger 
indicates class probabilities main responsible hinder classification performance degree overlapping classes 
dealing class imbalances help classifiers performance improvement 
evaluating classifiers imbalanced domains straightforward way evaluate classifiers performance confusion matrix analysis 
table illustrates confusion matrix class problem having class values positive negative 
springer verlag berlin heidelberg final version www com link asp id la high overlaid instances low overlaid instances fig 

simple decision problem positive prediction negative prediction positive class true positive false negative negative class false positive true negative table 
confusion matrix class problem 
matrix possible extract number widely metrics measuring learning systems performance classification error rate defined err equivalently accuracy defined acc err 
prior classes probabilities highly different measures produce misleading 
error rate accuracy particularly suspect performance measures studying effect class distribution learning strongly biased favor majority class 
instance straightforward create classifier having accuracy error rate domain majority class proportion correspond instances simply forecasting new example belonging majority class 
fact accuracy error rate metrics consider different classification errors equally important 
highly imbalanced problems generally highly non uniform error costs favor minority class class primary interest 
instance sick patience diagnosed healthy fatal error healthy patience diagnosed sick considered serious error mistake corrected exams 
point considered studying effect class distribution learning systems class distribution may change 
consider confusion matrix shown table 
note class distribution proportion positive negative instances relationship second lines 
performance metric uses values columns inherently sensitive class skews 
metrics accuracy error rate values lines confusion matrix 
class distribution springer verlag berlin heidelberg draft draft final version www com link asp id la changes measures change fundamental classifier performance 
things considered interesting performance metric errors hits occurred class 
table possible derive performance metrics directly measure classification performance positive negative classes independently false negative rate percentage positive cases misclassified belonging negative class false positive rate percentage negative cases misclassified belonging positive class true negative rate percentage negative cases correctly classified belonging negative class true positive rate percentage positive cases correctly classified belonging positive class performance measures advantage independent class costs prior probabilities 
aim classifier minimize false positive negative rates similarly maximize true negative positive rates 
unfortunately real world applications tradeoff similarly 
roc graphs analyze relationship classifier 
roc graph characterizes performance binary classification model possible trade offs classifier sensitivity false alarm 
roc graphs consistent problem distribution positive negative instances highly skewed 
roc analysis allows performance multiple classification functions visualized compared simultaneously 
standard classifier corresponds single point roc space 
point represents classifying instances negative point represents classifying instances positive 
upper left point represents perfect classifier 
point roc diagram draft draft dominates left 
point dominates point outperforms possible class distributions misclassification costs 
classifiers na bayes classifier neural networks yield score represents degree instance member class 
ranking produce classifiers varying threshold instance pertaining class 
threshold value produces different point roc space 
points linked tracing straight lines consecutive points produce roc curve decision trees class distributions leaf score proposed roc acronym receiver operating characteristic term signal detection characterize tradeoff hit rate false alarm rate noisy channel 
conceptually may imagine varying threshold tracing curve roc space springer verlag berlin heidelberg final version www com link asp id la ordering leaves positive class accuracy producing trees re labelling leaves time forecasting negative class forecasting positive class positive accuracy order 
area roc curve auc represents expected performance single scalar 
auc known statistical meaning equivalent test ranks equivalent statistical measures evaluating classification ranking models 
auc main method assessing experiments 
results experiments shown section 
experiments purpose study understand class imbalances influence degradation performance learning algorithms run experiments series artificial datasets characteristics able control allowing fully interpret results 
case real datasets stated 
artificial datasets employed experiments major controlled parameters 
distance centroids clusters second grade imbalance 
distance centroids control level difficulty correctly classifying classes 
grade imbalance analyze imbalance factor degrading performance 
main idea experiments analyze class imbalance degrade performance learning systems 
order perform analysis created datasets 
datasets composed clusters representing majority class representing minority class 
presents pictorial representation possible instances datasets dimensional space 
draft draft fig 

pictorial representation instances artificial datasets employed experiments 
aim answer question analyzing performance obtained datasets 
main questions springer verlag berlin heidelberg final version www com link asp id la class imbalance problem learning systems stated research works 
words learning system low performance highly imbalanced dataset classes far apart 
distance class clusters factor contributes poor performance learning systems imbalanced dataset 
supposing distance clusters matters learning imbalanced datasets class imbalance influence learning performance distance cluster 
section provides deep description approach generate artificial datasets experiments 
experiments setup evaluate hypothesis generated artificial domains 
artificial domain described attributes attribute value generated random gaussian distribution standard deviation 
jointly domain classes positive negative 
domain mean gaussian function classes 
domains stepwise add standard deviation mean positive class standard deviations 
domain generated datasets 
dataset instances having different proportions instances belonging class considering instances positive class remainder negative class 
class complexity quite simple generate datasets classes class grouped cluster situation faced machine learning algorithms classification problems follow called separate conquer strategy recursively divides solves smaller problems order induce concept 
furthermore gaussian distribution approximation statistical distributions 
draft draft run experiments chose algorithm inducing decision trees 
chosen quickly community standard algorithm evaluating learning algorithms imbalanced domains 
experiments evaluated fold cross validation 
discussed section area roc curve auc quality measure 
implemented method proposed obtain roc curves corresponding aucs standard classifiers induced 
results results obtained applying artificially generated datasets summarized table shows mean auc value respective standard deviation parenthesis classifiers induced springer verlag berlin heidelberg final version www com link asp id la datasets having different class priors different distances positive negative class centroids 
omitted values auc datasets having distance class centroids greater equal standard deviations results quite similar datasets having distance standard deviations 
furthermore datasets difference auc statistically insignificant confidence level proportion instances class 
results dataset having class centroids standard deviations apart included order illustrate small variation previous column 
positive distance class centroids instances table 
auc obtained classifiers induced varying class priors class overlapping expected positive negative classes centroids constant auc value independently class imbalance 
auc value means examples classified belonging majority class 
consider column centroids class standard deviation appart 
column analyzed solely may infer degree class imbalance main factor influences learn draft draft ing process 
auc upward trend increasing nearly proportion instances positive class proportion positive negative instances 
class centroids distance goes standard deviations see influence class priors weaker 
instance value auc classifiers induced dataset having instances positive class centroid class standard deviations apart centroid negative class worst classifiers induced changing class distribution centroids values auc closer values proportion difference centroids standard deviation 
classifiers induced datasets having standard deviations apart problem quite trivial auc values nearly regardless class distribution 
springer verlag berlin heidelberg final version www com link asp id la better visualization trends results shown graphically 
graphs show behavior algorithm assessed auc metric class imbalance class overlapping 
plots percentage positive instances datasets versus auc classifiers induced different centroids positive class standard deviations negative class 
curves centroids positive class standard deviations apart omitted better visualization curves quite similar curve centroid standard deviations apart negative class 
consider curves positive class class centroids standard deviations apart 
classifiers performances auc higher proportion positive class barely 
particularly curve positive class centroid standard deviations negative class centroid represents perfect classifier independently class distribution 
auc draft draft proportion positive instances fig 

variation proportion positive instances versus auc plots variation centroids distances versus auc classifiers induced different class imbalances 
curves represent proportion positive instances omitted visualization purposes quite similar curve represents equal proportion instances class 
graph see main degradation classifiers performances occurs mainly difference centre positive negative class standard deviation 
case degradation significantly higher highly imbalanced springer verlag berlin heidelberg final version www com link asp id la datasets decreases distance centre positive negative class increases 
differences performance classifiers statistically insignificant difference centers goes standard deviations independently instances belongs positive class 
auc distance centroids sds fig 

variation centre positive class versus auc draft draft analyzing results possible see class overlapping important role concept induction stronger class imbalance 
trends validate hypothesis section 
class imbalance reported obstacle induction classifiers machine learning algorithms 
domains machine learning algorithms able achieve meaningful results presence highly imbalanced datasets 
develop systematic study set artificially generated datasets aiming show degree class overlapping strong correlation class imbalance 
correlation best knowledge previously analyzed machine learning literature 
understanding correlation useful analysis development tools treat imbalanced data re design learning algorithms practical applications 
springer verlag berlin heidelberg final version www com link asp id la order study question depth approaches taken 
instance interesting vary standard deviations gaussian functions generate artificial datasets 
worthwhile consider generation datasets distribution instances minority class separated small clusters 
approach lead study class imbalance problem small disjunct problem proposed 
point explore analyze roc curves obtained classifiers 
approach produce useful insights order develop analyze methods dealing class imbalance 
experiments conducted real world datasets order verify hypothesis apply 
research partially supported brazilian research councils capes 

chawla japkowicz editors 
icml workshop learning imbalanced data sets ii 
proceedings available www site 
ca nat workshop workshop html 

drummond holt 
representing expected cost alternative roc representation 
proceedings sixth acm sigkdd international conference knowledge discovery data mining pages 

ferri flach 
learning decision trees area roc curve 
hoffman editor nineteenth international conference machine learning icml pages 
morgan kaufmann publishers 

hand 
construction assessment classification rules 
john wiley sons 

japkowicz editor 
aaai workshop learning imbalanced data sets menlo park ca 
aaai press 
report ws 

japkowicz 
class imbalances focusing right issue 
proc 
icml workshop learning imbalanced data sets ii 
draft draft 
japkowicz stephen 
class imbalance problem systematic study 
intelligent data analysis 


improving identification difficult small classes balancing class distributions 
technical report university tampere finland 

merz murphy 
uci repository machine learning datasets 
www ics uci edu mlearn mlrepository html 

provost fawcett 
analysis visualization classifier performance comparison imprecise class cost distributions 
knowledge discovery data mining pages 

quinlan 
programs machine learning 
morgan kaufmann san mateo ca 

weiss provost 
effect class distribution classifier learning empirical study 
technical report ml tr rutgers university department computer science 
springer verlag berlin heidelberg 
