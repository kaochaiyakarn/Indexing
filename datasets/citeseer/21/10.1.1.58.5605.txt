preliminary design papyrus system high performance distributed data mining clusters meta clusters super clusters robert grossman national center data mining magnify university illinois chicago south drive south morgan street suite chicago il chicago il grossman uic edu magnify com stuart bailey ashok andrei national center data mining university illinois chicago south morgan street chicago il august draft grossman bailey preliminary design papyrus system high performance distributed data mining clusters advances distributed parallel knowledge discovery kargupta chan editors aaai press mit press menlo park california pages 
data mining problem cluster computing provides competitive alternative specialized high performance computers mining large data sets 
clusters provide natural infrastructure mining large distributed data sets 
distributed clusters connected commodity networks form call meta clusters high performance networks form call super clusters 
describe design system called papyrus designed mining data distributed clusters meta clusters super clusters 
describe experimental results preliminary implementation 
problems clusters workstations connected specialized switching fabrics high performance networks provide competitive alternative specialized high performance computers including mpp computers 
clusters workstations proved effective variety data mining applications 
data mining process involves compute intensive data intensive steps 
clusters serve fundamental roles data clusters provide storage data management services data sets mined 
compute clusters provide compute services required data cleaning data preparation data mining tasks 
natural distributed clusters infrastructure distributed data mining 
interest article focus special important case globally distributed high performance clusters workstations connected networks supporting different levels service 
network quality service qos measured dimensions rate concerning amount data application requires delay jitter guarantees concerning timeliness delivery loss guarantees concerning quality delivery 
network qos provides type guarantee dimensions contrast today commodity internet uses best effort model 
today network high performance links may offer links faster commodity links 
example nfs vbns network supports oc links mb practice provides performance faster commodity internet 
provides model emerging premium services differentiated services allow applications example request services bandwidth guarantees 
call clusters clusters clusters connected commodity services clusters clusters clusters connected premium services super clusters 
testbed experimental studies described consisted workstation clusters chicago philadelphia college park davis toronto forming super cluster connected clusters london canberra form meta cluster 
specifically clusters chicago toronto connected mbs network clusters chicago davis philadelphia connected mbs network remaining clusters connected commodity internet 
expect meta clusters super clusters grow common emergence generation internet 
example large distributed operations employing virtual private network may operational data cities connected high performance network employing pre services marketing related data may accessible commodity network 
amount data grows replacing servers data compute clusters provides cost effective means supplying appropriate data management processing capabilities required data mining 
concretely data mining may viewed extracting learning set distributed data warehouses applying data mining algorithm produce predictive model rule set 
different strategies possible depending data distribution resources available accuracy required move results today commodity networks move results local data mining computations central site 
mm move models commodity networks move predictive models site site 
md move data generation broadband networks create possibility moving large amounts data 
majority distributed data mining focused strategies mm 
introduce papyrus distributed data mining system supporting strategies mixtures strategies 
describe experimental studies strategies md mm 
interested distributed data mining problems characteristics data available data clusters fundamental task correlate data different data clusters different strategies available depending clusters form super cluster meta cluster appropriate compute services provided compute clusters 
section provides background material describes related 
key concepts underlying system reviewed section 
design system described section 
implementation described section 
experimental studies described section 
section contains 
background related section part 
systems developed distributed data mining 
mature jam system developed stolfo kensington system developed guo bodhi developed kargupta 
systems differ ways data strategy 
distributed data mining choose move data move intermediate results move predictive models move final results data mining algorithm 
distributed data mining systems employ local learning build models site move models central location 
systems employ centralized learning move data central location model building 
systems employ hybrid learning strategies combine local centralized learning 
jam kensington bodhi employ local learning 
task strategy 
distributed data mining systems choose coordinate data mining algorithm sites apply data mining algorithms independently site 
independent learning data mining algorithms applied site independently 
coordinated learning sites coordinate tasks data mining algorithm sites 
model strategy 
different methods employed combining predictive models built different sites 
simplest common method voting combine outputs various methods majority vote 
meta learning combines models building separate metamodel inputs outputs various models output desired outcome 
knowledge probing considers learning black box viewpoint creates model examining input outputs various models desired output 
multiple models called ensembles committees models quite centralized data mining 
variety methods studied combining models ensemble including bayesian model averaging model selection stacking partition learning statistical methods mixture experts 
jam employs metalearning kensington employs knowledge probing 
papyrus designed support different data task model strategies 
example contrast jam kensington papyrus move models node node move data node node strategy desired 
contrast bodhi papyrus built data warehousing layer move data commodity high performance networks 
papyrus specialized system designed clusters meta clusters super clusters jam kensington bodhi designed mining data distributed internet 
systems java 
jam employs java applets move machine learning algorithms distributed data 
kensington uses java jdbc mine distributed data 
papyrus uses java aglets 
distributed data mining system developed parthasarathy designed clusters smp workstations papyrus designed exploit clusters workstations 
system papyrus designed data clusters compute clusters 
papyrus explicitly supports clusters clusters clusters connected different types networks 
distributed clusters workstations example known computational grids 
computational grid hardware software infrastructure provides dependable consistent mbps mbps high performance network mbps mbps philadelphia chicago college park mbps mbps mbps mbps clusters chicago philadelphia connected high performance network form super cluster 
super cluster connected cluster college park form meta cluster 
clusters types data clusters providing data compute cluster providing cycles 
papyrus applications transparent access data compute clusters meta cluster 
pervasive inexpensive access high computational capabilities grid applications divided classes distributed supercomputing applications requiring lots cpu memory high throughput computing applications idle resources tackle large problems demand computing applications integrate remote resources local computation data intensive computing applications requiring analysis large data sets collaborative computing applications enhance human human interactions 
data mining cuts classes data mining applications cpu intensive classes data mining algorithms genetic algorithms require searching space hypotheses exploit high throughput techniques class data mining applied data remote instrumentation class interactive exploration large data sets common class 
projects underway developing computing infrastructure grid applications including globus legion 
contrast systems broadly concerned providing general grid services distributed applications papyrus focused just services required distributed data mining grids built clusters clusters clusters 
philosophy papyrus general grid cluster services possible 
grid services globus legion mature expect versions papyrus part 
similar grid services globus papyrus provides shared wide area persistent data space transparent remote execution data mining processes wide area parallel processing data mining processes scheduling data mining processes 
course globus provides general grid applications papyrus provides specialized vertically integrated versions services framework suitable distributed data mining 
papyrus globus take hour glass layered approach system design protocols services neck hour glass connect adjacent layers system 
legion advocates object component view grid services 
objects defined interfaces communicate data control paths respond events broadcast objects 
papyrus exploits data paths clusters 
clusters communicate agents data access specialized servers designed high performance distributed data mining general object services databases 
berkeley project provides infrastructure high performance distributed computing workstation clusters including scheduling middleware high performance messaging system scalable parallel file system 
papyrus uses high performance light weight object manager parallel file system designing scheduler specifically targeted data intensive computations wide area networks different levels services general purpose scheduler distributed applications 
key concepts section describe key concepts underlying papyrus exposition 
data ensembles 
restrict attention data mining problems mechanism partitioning data set mechanism combining partitioned data single data set 
case speak data partition data ensemble 
example building fraud model credit card accounts data may partitioned customer separate models built different sets customers 
example model credit card accounts may built data sets set credit card transactions set summarizing account level data payments received 
example illustrates called horizontal partitioning domain partitioned second example illustrates called vertical partitioning range partitioned 
data mining 
data mining viewed quite broadly semi automated extraction knowledge data 
take narrower point view regarding data mining process extracting learning set data warehouse applying data mining algorithm produce predictive model rule set 
continuing model applied data obtain numerical result view vector 
model ensembles 
restrict attention collections ensembles predictive models may combined produce single model 
basic example provided predictive models built partitioned data combined voting 
example consider cluster model data set summarized specifying centroids clusters 
model may partitioned creating collections centroids containing centroids cluster models may combined simply concatenating centroids 
fundamental trade 
large data files may orders magnitude larger file describing model model file may orders magnitude larger result vector 
distributed data mining system different strategies possible depending data files model files result vectors moved node node 
general accurate result obtained moving data single node 
usually expensive 
measure expense cost function includes computation communication costs 
extreme process data locally obtaining local results combine local results obtain final result 
general approach expensive accurate 
summarize distributed data mining fundamental trade accuracy desired predictive model cost willing bear computation 
configurations 
assume different sites connected network 
configuration specifying data 
graph nodes describing network 
nodes say th network root result computed 

vector di describing initial distribution data 

cost cij measured dollars gigabyte move data th th node expensive path 

cost ci measured dollars gigabyte process data th node predictive model 

constant describing amount compression data node processed compute predictive model 
strategies fix configuration defined 
node employ different strategies md move data 
ship raw data network node processing 
mm move models 
process data locally produce predictive model ship predictive model node processing 
move results 
process data locally result obtained ship result node processing 
general progress md mm strategies loss accuracy decrease cost computation 
complete strategy moves data models results node node root produces final result 
problems sufficient accuracy required data moved central root 
problems sufficient speed desired computation done locally 
recall takes approximately hours move terabyte data oc network 
terabytes data distributed meta cluster clusters super clusters correct strategy mean difference waiting minutes hours 
simplify discussion consider mixed strategies involving md mm general case handled similarly 
see 
strategy matrix numbers xij xij amount data di moved th node th node processing strategy 
move amount data th node dj 
cost function strategy easily computed ij cjk xij 
sum nodes sources data nodes targets data 
critical observation cases cost function convex 
cases possible error occurs data moved single node largest possible error max occurs data evenly distributed nodes 
note vector dn defines relevant data distribution dj xij 
form error function strategy max dj amount data network usual euclidean norm vector scaling coefficient 
suppose error tolerance threshold tol 
find optimal strategy solving optimization problem minx tol 
easy find examples intermediate strategies cost effective naive ones leaving data place moving data single fixed node 
sense design distributed systems flexibility moving data moving predictive models moving results local computations 
key ideas papyrus system 
papyrus far know distributed data mining system designed level flexibility 
architectural design recall interested distributed data mining systems data accessed data clusters analyzed compute clusters data compute clusters combined commodity networks form meta clusters high performance networks form super clusters 
simplicity view single node cluster size 
papyrus clusters interact ways 
metadata moved clusters agents 
cluster single node designated cluster access point cap 
agents move queries predictive models result vectors metadata caps different clusters 

data moved clusters distributed data warehouse 
practice moderate amounts data practical clusters connected high performance network 
viewpoint described data mining viewed process applying data mining algorithms learning sets extracted data warehouses produce predictive models natural design papyrus layered system consisting main layers data warehouse layer 
lowest layer consists data warehouse designed local distributed clusters workstations 
training sets extracted data warehouse 
practice small amounts data moved clusters general larger amounts data moved clusters connected high performance networks 
data mining layer 
role data mining layer apply data mining algorithms training sets extracted data warehouse produce predictive models rule sets results 
precisely assume input data mining layer data set learning set output model ensemble models 
model mean predictive rules rule sets 
predictive modeling layer 
layer manages predictive models ensembles predictive models 
contributed development xml mark language called predictive model markup language pmml predictive models rule sets 
pmml supports predictive models ensembles predictive models meta data required describe effectively 
description current draft pmml 
predictive modeling layer handles models pmml 
concretely data mining layer extracts learning sets data warehouse produces models rules pmml managed predictive modeling layer 
agent layer 
agent layer moves queries predictive models metadata results local computations cluster access points 
developed xml markup language call data discovery markup language describe queries metadata associated distributed data mining computation 
agents move metadata pmml models cluster access points 
separately control expressed files data moved directly distributed data clusters 
described query papyrus processed different strategies mm md 
selecting query 
papyrus application dispatches agents gather files various registered caps 

files returned agents analyzed application user chooses specifies query 
move results 
query carried agents appropriate caps query executed produce results 

agents return results commodity network papyrus application processed produce final result 
move models mm 
query carried agents appropriate caps query executed produce predictive models 

agents return predictive models pmml commodity network papyrus application processed produce final result 
move data md 
query request move data carried agents various caps 
process query data moved data warehousing layer high performance network root cluster query processed 

agents return results root cluster papyrus application processed produce final result 
preliminary implementation developed versions papyrus general design ideas sketched 
papyrus version developed tested demonstrated supercomputing conference san jose california november 
papyrus version developed tested demonstrated supercomputing conference orlando november 
currently developing version papyrus 
data management layer version papyrus high performance light weight persistent object manager developed called 
papyrus version version developed provided support wide area clusters 
particular able stripe data wide area data clusters 
data management layer papyrus version different design explicit support data mining primitives specialized protocols moving data high performance networks explicit support multiple network protocols 
main interest system design high performance distributed data mining system related high performance data mining algorithms se chose standard algorithms data mining layer 
chose popular implementation decision trees main tool data mining layer 
modified data clusters emit pmml 
papyrus version sgml basis pmml 
papyrus version xml papyrus version 
general design papyrus calls layer manage predictive models pmml called 
versions papyrus separate layer implemented necessary code papyrus applications 
example applications combined pmml models single meta model simple voting strategy 
built agent layer called bast move queries predictive models results meta data various data clusters 
bast version agent tcl move sgml data describing queries associated data metadata managed bast 
bast version uses aglets move xml data metadata language designed purpose called data discovery markup language 
simplicity strategy moving data metadata 
data distributed super cluster move data mine locally resident 

data distributed meta cluster built predictive models locally data cluster super cluster merged results voting scheme 
experimental results section describe series experiments papyrus version 
performed experiments november supercomputing conference orlando 
experiments conducted explore issues arose experiments 
describe experiments influenced design papyrus currently development 
goal experiments gain information suitability papyrus system architecture design especially layer name version version agent bast agent tcl moving pmml aglets moving pmml predictive model unimplemented unimplemented data mining producing producing pmml pmml data warehouse osiris supporting local clusters ing local wide area clusters table summary implementation version papyrus 
modified produce sgml pmml version 
design data warehouse agent layers 
emphasize goal test distributed data mining algorithms se improve understanding critical factors effecting distributed data mining system operating networks different levels services 
experiment supercomputing analyzed high energy physics data node super cluster distributed chicago philadelphia college park davis orlando toronto 
second experiment analyzed health care outcome data node meta cluster chicago philadelphia college park orlando london canberra 
experiment super cluster access approximately gigabytes high energy physics data organized approximately events representing putative particle collisions 
adopted standard physics analysis code run super cluster created application benchmark called event 
goal event maximize number events analyzed second 
example event benchmark subset approximately events spanning approximately gigabytes distributed nodes took seconds depending node 
data clusters connected high speed backbone network server vbns consists mb sec fully switched asynchronous transfer mode atm internal backbone mb sec mb sec edge atm links site 
toronto cluster connected vbns mb sec link 
limit data analysis essentially speed data managed moved network responsibility papyrus data warehouse layer 
roughly speaking network interface papyrus system move data approximately mb sec process providing upper bound node approximately mb sec upper bound site approximately mb sec 
version papyrus custom code connected various nodes appropriate number sockets 
approach performance event benchmark disappointing despite presence high performance links 
follow experiment described table examined issue carefully varying number sockets connecting nodes 
basis experiments decision develop library moving data nodes multiplexes sockets maximize amount data transfered second 
library papyrus version 
second follow experiment described table event data arranged ways event attribute 
event benchmark data moved horizontal layout event events analyzed vertical layout attribute 
difference larger depending query 
course queries see speed exactly opposite layout 
reason investigating supporting vertical horizontal layouts papyrus version 
second series experiments supercomputing meta cluster analyzed approximately health care outcome records comprising gigabyte data distributed continents 
case analysis essentially limited congestion commodity internet especially pronounced international links 
agent communication utilized papyrus cluster layer worked effectively meta cluster queries tested 
experiments combined trees built local site single classifier papyrus cluster layer bast 
papyrus application combined trees majority vote standard technique working ensembles classifiers 
interest understanding papyrus globally distributed meta clusters wide variations latency bandwidths various sites 
concluded approach effectively 
queries able complete due network congestion considering putting explicit support papyrus version gracefully handling nodes respond timely fashion 
third follow experiment empirically examined trade offs moving models mm built distributed data vs moving data md building centralized model health care outcome data 
experiment super cluster particular application benchmark called 
see tables 
particular benchmark essentially accuracy obtained building local trees merging mm 
moving models approximately faster moving data 
notice moving data md takes essentially length time local geographically distributed 
course queries data sets loss suffered employing mm strategy acceptable 
observations lead cost approach selecting strategies described section 
plan implement papyrus version number sockets tt seconds mb sec socket sockets sockets sockets sockets sockets sockets table table shows result socket multiplexing move data nodes 
practical limit mb ds link appears mb tt transfer time mbytes application apparent transfer rate horizontal store store size gb total data moved gb comp 
servers processes events second mb seconds seconds vertical store store size gb total data moved gb comp 
servers processes events second mb seconds seconds table data may placed disk record horizontally attribute vertically 
optimal choice depends query 
table analyzes performance osiris data server choices particular benchmark query high energy physics data called event 
events processed second amount data moved second total time seconds complete query 
data transfer vs model transfer locations strategy data transfer model transfer lan wan lan wan lan wan records dt dt total total total total table query time different strategies local lan wide area wan clusters connected high performance links 
columns indicates time seconds health care application benchmark 
total refers time required execution time time required move data dt model mt indicated 
dt data transfer mt model transfer records number models table prediction error percent number records number models varies application benchmark 
workstation clusters high performance networks grow common clusters meta clusters clusters linked commodity networks clusters linked high performance networks prove popular infrastructure mining large distributed data sets 
papyrus uses simple layered architecture flexible employ strategies move data move predictive models move numerical results computations distributed clusters workstations linked high performance commodity connections 
described section papyrus architecture implementation demonstrated practicality mining distributed gigabyte size data sets high performance ds oc networks 
queries hundreds thousands seconds important develop systems intelligent flexible move smallest amount data consistent achieving results acceptable accuracy 
goals papyrus version experiments performed date versions papyrus currently developing version 
effectively high performance links version papyrus required papyrus applications explicitly multiple sockets deal known latency problems tcp acks 
library provided papyrus papyrus applications transparently high performance links 

version papyrus supports strategies data moved models moved numerical results moved support mixed strategies choice varies node node 
papyrus version remedy supporting optimal strategies described section 
version papyrus supports clusters workstations linked high performance networks commodity networks effectively support mixed networks nodes may connections different quality service 
papyrus version remedy supporting servers effectively schedule requests incorporating different qualities service 
anderson culler patterson case networks workstations ieee micro volume pages 
chan stolfo comparative evaluation voting meta learning partitioned data proceedings twelfth international conference machine learning morgan kaufmann san francisco california pages 
chan kargupta editors proceedings workshop distributed data mining fourth international conference knowledge discovery data mining new york city aaai press 
dietterich machine learning research current directions ai magazine volume pages 
fayyad piatetsky shapiro smyth data mining knowledge discovery overview advances knowledge discovery data mining edited fayyad piatetsky shapiro smyth uthurusamy aaai press mit press pp 

foster kesselman globus metacomputing infrastructure toolkit international journal supercomputing applications volume pages 
foster kesselman editors grid blueprint new computing infrastructure morgan kaufmann san francisco 
gannon grimshaw object approaches grid blueprint new computing infrastructure foster kesselman editors morgan kaufmann san francisco pages 
gray rus kotz transportable information agents technical report pcs tr department computer science dartmouth college 
grimshaw wulf legion vision worldwide virtual computer communications acm volume pages 
grossman poor data mining tree optimization proceedings second international conference knowledge discovery data mining aaai press menlo park california page 
grossman bailey hanley data mining light weight object management clustered computing environments proceedings seventh international workshop persistent object stores morgan kauffmann san mateo california pages 
grossman supporting data mining process generation data mining systems enterprise system journal 
grossman bailey qin management mining multiple predictive models predictive modeling markup language pmml information system technology volume pages 
grossman papyrus system data mining clusters meta clusters super clusters preparation 
guerin schulzrinne network quality service grid blueprint new computing infrastructure foster kesselman editors morgan kaufmann san francisco pages 
guo forbes meta parallel data mining proceedings seventh parallel computing workshop pages 
kargupta stafford scalable distributed data mining agent architecture heckerman mannila pregibon uthurusamy editors proceedings third international conference knowledge discovery data mining aaai press menlo park california pages 
johnson park hershberger scalable data mining vertically partitioned feature space collective mining gene expression genetic algorithms kdd workshop distributed data mining appear 
lange oshima programming deploying java tm mobile agents aglets tm addison wesley reading massachusetts 
moore baru rajasekar wan data intensive computing grid blueprint new computing infrastructure foster kesselman editors morgan kaufmann san francisco pages 
world wide web consortium www org 
predictive model mark language version data mining group www org 
quinlan programs machine learning morgan kauffmann san mateo california 
raftery madigan 
bayesian model averaging linear regression models journal american statistical association volume pages 
stolfo prodromidis chan jam java agents meta learning distributed databases proceedings third international conference knowledge discovery data mining aaai press menlo park california 
parthasarathy architecture distributed data mining appear 
teitelbaum qos requirements internet submitted publication 
grossman optimal strategies distributed data mining data model partitions submitted publication 
wolpert stacked generalization neural networks volume pages 
xu jordan em learning generalised finite mixture model combining multiple classifiers proceedings world congress neural networks hillsdale new jersey erlbaum 

