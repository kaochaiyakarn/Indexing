zhai department computer science university illinois urbana champaign cross collection mixture model comparative text mining define study novel text mining problem refer comparative text mining ctm 
set comparable text collections task comparative text mining discover latent common themes collections summarize similarity differences collections common theme 
general problem subsumes interesting applications including business intelligence opinion summarization 
propose generative probabilistic mixture model comparative text mining 
model simultaneously performs cross collection clustering clustering applied arbitrary set comparable text collections 
model estimated efficiently expectation maximization em algorithm 
evaluate model different text data sets news article data set laptop review data set compare baseline clustering method mixture model 
experiment results show model quite effective discovering latent common themes collections performs significantly better baseline mixture model 
categories subject descriptors information search retrieval text mining general terms algorithms keywords comparative text mining mixture models clustering 
text mining concerned extracting knowledge patterns text 
research text mining existing research focused single collection text 
goals extract basic semantic units named entities extract relations information units extract topic themes 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
kdd august seattle washington usa 
copyright acm 
department electrical computer engineering university illinois urbana champaign bei yu graduate school library information science university illinois urbana champaign study novel problem text mining referred comparative text mining ctm 
set comparable text collections task comparative text mining discover latent common themes collections summarize similarity differences collections common theme 
specifically task involves discovering different common themes collections discovered theme characterize common collections unique collection 
need comparative text mining exists different applications including business intelligence summarizing reviews similar products comparing different opinions common topic general 
study ctm problem propose generative probabilistic mixture model ctm 
model simultaneously performs cross collection clustering clustering applied arbitrary set comparable text collections 
mixture model component multinomial distribution models characterizing different theme 
common themes collection specific themes explicitly modeled 
proposed model estimated efficiently expectation maximization em algorithm 
evaluate model different text data sets news article data set laptop review data set compare baseline clustering method mixture model 
experiment results show model quite effective discovering latent common themes collections performs significantly better baseline mixture model 
rest organized follows 
section briefly introduce problem ctm 
baseline simple mixture model new cross collection mixture model section section 
discuss experiment results section 
comparative text mining motivating example popularity commerce online customer evaluations widely provided online stores third party websites 
pioneers amazon com epinions com accumulated large amounts customer input including reviews comments recommendations advice example number reviews epinions com 
product hundreds reviews impossible readers go 
desirable summarize collection reviews certain type products order provide readers salient feedbacks peers 
review summarization important task identify different semantic aspects product reviewers mentioned group opinions aspects show similarities differences opinions 
example suppose reviews different brands laptops dell ibm apple want summarize reviews 
useful summary tabular representation opinions shown table row represents aspect subtopic different columns correspond different opinions 
table tabular summary subtopics dell ibm apple battery life long short short memory bad speed slow fast fast course difficult impossible produce table completely automatically 
achieve ambitious goal identifying semantic aspects identifying common specific characteristics product unsupervised way 
concrete example comparative text mining 
general problem example possible applications comparative text mining 
general task comparative text mining involves discovering common themes collections discovered theme characterize common collections unique collection 
hard precisely define theme corresponds roughly topic subtopic 
granularity themes application specific 
ctm fundamental task exploratory text analysis 
addition opinion comparison summarization applications business intelligence comparing different companies customer relationship management comparing different groups customers semantic integration text comparing component text collections 
ctm challenging ways completely unsupervised learning task training data available 
reason ctm useful different purposes minimum assumptions collections principle compare arbitrary partition text 
need identify themes different collections challenging identifying topic themes single collection 
task involves discrimination component discovered theme want identify unique information specific collection 
discrimination task difficult training data 
way ctm goes regular collection text mining requiring alignment multiple collections common themes 
training data available general rely unsupervised learning methods clustering perform ctm 
study probabilistic mixture models perform ctm 
describe simple mixture model clustering represents straightforward application existing text mining method sophisticated mixture model specifically designed ctm 

clustering simple mixture model simple mixture model naive solution ctm treat multiple collections single collection perform clustering 
hope clusters represent common themes collections represent themes specific collection see 
simple multinomial mixture model clustering arbitrary collection documents assume latent common themes collections characterized multinomial word distribution called unigram language model 
document regarded sample mixture model theme models components 
fit mixture model union text collections obtained component multinomial models analyze common themes differences collections 
formally cm comparable collections documents 
theme unigram language models background model collections 
document regarded sample mixture model word generation 
pd bp jp word document specific mixing weight th aspect theme 
mixing weight background model log likelihood collections log ci log bp jp set words vocabulary count word document set theme model parameters 
purpose background model force clustering done discriminative words leading informative discriminative component models 
control effect model estimated estimator 
example expectation maximization em algorithm compute maximum likelihood estimate updating formulas zd zd bp bp zd zd zd zd mixture model closely related probabilistic latent semantic indexing model plsi proposed treats ctm single collection text mining problem :10.1.1.1.4458
simple model inadequate ctm reasons completely ignored structure collections 
result may clusters represent collections 
easy way identify theme cluster represents common information collections represents specific information particular collection 
sophisticated coordinated mixture model specifically designed ctm addresses deficiencies 

clustering cross collection mixture model cross collection mixture model model main idea improving simple mixture model comparative text mining explicitly distinguish common theme clusters characterize common information collections special theme clusters characterize collection specific information 
consider latent common themes potentially different set collection specific themes collection illustrated 
component models directly correspond information interested discovering 
sampling distribution word document collection ci collection specific 
specifically involves background model common theme models collection specific theme models capture unique information themes collection ci 
pd ci cp bp weight background model weight common theme model opposed collection specific theme model 
intuitively generate word decide background model larger decide need decide theme controlled probability theme generating words decide theme need decide common theme model collection specific theme model controlled probability common model 
weighting parameters intentionally set user interpretation follows 
reflects knowledge noisy collections 
believe text verbose set larger value 
experiments value works 
indicates emphasis commonality opposed speciality comparative text mining 
larger allow learn richer common theme model smaller learn weaker common theme model stronger special models 
optimal value depends specific applications 
generative model log likelihood set collections log ci log bp cp parameter estimation estimate background model available text text collections 
set manually leaves parameters estimate common theme models special theme models collection ci theme mixing weights document 
zd zd zd cp bp bp cp cp zd zd zd zd zd zd ci zd ci zd ci zd zd zd zd ci zd ci zd ci em updating formulas cross collection mixture model simple mixture model em algorithm compute maximum likelihood estimate 
updating formulas shown 
em iteration involves scanning text algorithm quite scalable 
model model estimated models collections common theme models collections 
models word distribution unigram language model 
high probability words characterize theme cluster extracted 
words directly summary indirectly hidden markov model extract relevant sentences form summary corresponding theme 
extracted word distributions ways classify text documents link related passages text collections user navigate information space comparative analysis 
input bias ctm setting manually 
specifically allows input knowledge noise words data know text data verbose set high value data concise content bearing keywords need set smaller value 
similarly allows input trade extracting common theme models setting higher value vs extracting collection specific models setting smaller value 
biases learned maximum likelihood estimator 
maximizing data likelihood means achieve ultimate goal want regularize model meaningful way impose certain preferences maximizing data likelihood 
flexibility control provided possible user control focus results comparative text mining 

experiments result analysis evaluated simple mixture model cross collection mixture model domains war news laptop reviews 
war news war news data consists news excerpts comparable events iraq war afghanistan war occurred years 
iraq war news excerpts combination articles cnn bbc web sites year span 
afghanistan war data consists news articles downloaded cnn bbc web sites year starting nov 
goal compare wars find common specific characteristics 
results simple mixture model cross collection mixture model shown table top words theme model listed probabilities 
set set cases number clusters fixed 
variations parameters discussed 
see interesting themes results cluster cluster appear american british inquiry presence weapons iraq respectively cluster suggests presence british soldier town southern iraq iraq war 
see obvious theme common iraq war afghanistan war 
expected pools documents exploiting collection structure 
contrast results explicitly suggest common themes corresponding collection specific themes 
example cluster clearly suggests wars loss lives 
furthermore top words corresponding iraq theme include names key defense people involved iraq war name british defense secretary sanchez name general iraq 
comparison top words corresponding afghanistan theme includes name defense secretary important role afghan war 
cluster cluster meaningful themes 
common theme captured cluster monday briefings official spokesman political administration wars corresponding special themes indicate difference topics discussed briefings weapon inquiry iraq war bin laden afghanistan war 
common theme cluster role table war news results model top vs model bottom cluster cluster cluster cluster cluster common british weapons inquiry countries theme soldiers kay intelligence contracts words united dossier god air commission hutton inspectors group claim russian mosque senate wmd international nation southern survey mps russia fired committee reconstruction cluster cluster cluster cluster cluster common killed monday united theme nation month official nations words dead deaths action general re defense died border key drive spokesman political blair iraq god iraq troops intelligence theme weapons weapons words sanchez inquiry inspectors nato commission council live independent declaration afghan story bin northern theme afghan full laden alliance words meeting saturday hotel steinberg kabul euro front taliban highway dropped chat aid played united nations un 
corresponding special themes suggest difference wars 
iraq theme indicates role un sending weapon inspectors iraq afghanistan theme refers northern alliance received aid un came power afghanistan defeat taliban 
laptop customer reviews data set constructed test models comparing opinions customers different laptops 
manually downloaded review sets epinions com filtering misplaced ones apple ll mac notebook reviews dell pc notebook reviews ibm thinkpad pc notebook reviews 
results data set generally similar war news 
due limit space show results table obtained setting fixing number clusters 
see interesting common themes top words common themes provide summary themes sound speakers cluster battery hours cluster microsoft office cluster 
special themes suggesting differences laptops harder interpret 
may great deal variation product specific opinions data data extremely sparse learning coherent collection specific theme themes 
parameter tuning vary results generally different 
specifically set small value non informative words tend show common themes 
reasonable value generally higher case model automatically eliminates non informative words theme clusters allowing discriminative clustering 
experiments intentionally retained words model clearly able filter non informative words cases show top words common themes news data 
eliminated higher may having insufficient information learn common theme reliably 
affects vocabulary allocation common collection specific themes 
news data experiments change value collection specific terms dominate common theme models 
laptop data experiments lose content keywords common themes corresponding collection specific themes 
intentionally left user tune incorporate application specific bias model 

related related coupled clustering method appears studies considering clustering problem multiple collections 
extend information bottleneck approach discover common clusters different collections 
comparative text mining goes analyzing similarities collection specific differences 
completely different approach probabilistic mixture models 
related cross training learning classifiers multiple document sets 
differs perform unsupervised learning 
aspect models studied related closer baseline model designed comparing multiple collections 
studies document clustering 
difference lies consider collection similar baseline model 
related document summarization especially multiple document summarization 
results ctm special form summary multiple text collections 
important difference summary intends retain explicit information text maintain fidelity ctm aims extracting non obvious implicit patterns 

define study novel text mining problem referred comparative text mining 
con table laptop review results model cluster cluster cluster cluster cluster cluster cluster cluster sound port ram battery cd office speakers jack mb hours modem drive microsoft playback ports memory chip life internet rw little feel mb improved dvd basic pros mb volume configuration combo cons warm tech free drives market keep latch high vga rom mhz size support processor floppy word rests options fans palm pentium ran shipping blah angle record eraser nd hook portion smart supposedly crucial toshiba requiring tracking tug usb reader sdram second spoke magazine macos macos airport quartz personal netscape interlaced burn word strong instance shield apache mac import result icon underneath airport book reads spreadsheet choppy cooling installation ll quicktime schools excel technology rj exchange thinkpad list outdated ibm connector factor surprisingly dsl disc turn covers connectors tells months buttons lightest device cap recommend number discovering latent common themes set comparable collections text summarizing similarities differences collections theme 
propose generative cross collection mixture model performing comparative text mining 
model simultaneously performs cross collection clustering clustering applied arbitrary set comparable text collections 
define model em algorithm estimate model efficiently 
evaluate model different text data sets news article data set laptop review data set compare baseline clustering method simple mixture model 
experiment results show cross collection mixture model quite effective discovering latent common themes collections performs significantly better baseline simple mixture model 
proposed model obvious applications opinion summarization business intelligence 
obvious applications general area text mining semantic integration text 
example model compare course web pages major computer science department web sites discover core computer science topics 
compare literature collections different communities support concept switching 
reported just initial step promising new direction 
interesting research directions 
may interesting explore improve model estimation 
interesting direction explore maximum posterior map estimator allow incorporate prior knowledge principled way 
example user may certain thematic aspects mind 
map estimation easily add bias component models 
second generalize model model semi structured data perform general comparative data mining 
way achieve goal introduce additional random variables component model model structured data 
interesting explore exploit learned theme models provide additional help user wants perform comparative analysis 
example learned common theme models construct hidden markov model hmm identify parts text collections common themes connect automatically generated hyperlinks 
allow user easily navigate common themes 

baker mccallum 
distributional clustering words text classification 
proceedings acm sigir 
blei ng jordan 
latent dirichlet allocation 
journal machine learning research 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statist 
soc 

epinions com 
www epinions com 
feldman dagan 
knowledge discovery textual databases 
proceedings international conference knowledge discovery data mining 
hearst 
text data mining 
proceedings acl 
hofmann :10.1.1.1.4458
probabilistic latent semantic indexing 
proceedings acm sigir pages 
marx dagan buhmann shamir 
coupled clustering method detecting structural correspondence 
journal machine learning research 
mckeown klavans hatzivassiloglou barzilay multidocument summarization reformulation progress prospects 
proceedings aaai 
sarawagi chakrabarti 
cross training learning probabilistic mappings topics 
proceedings acm sigkdd 
schatz 
concept navigation distributed communities 
computer 
zha 
generic summarization keyphrase extraction mutual reinforcement principle sentence clustering 
proceedings acm sigir 
