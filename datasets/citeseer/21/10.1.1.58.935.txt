user attention model video summarization yu fei ma lie lu hong jiang zhang li automatic generation video summarization key techniques video management browsing 
generic framework video summarization modeling viewer attention 
fully semantic understanding video content framework takes advantage computational attention models eliminates needs complex heuristic rules video summarization 
set methods audio visual attention model features proposed 
experimental evaluations indicate computational attention approach effective alternative video semantic analysis video summarization 
keywords video summarization attention model skimming video content analysis 
key technologies required efficient management video data automatic video content summarization 
concise informative video summary enable user quickly overview contents video decide video program worth watching 
generate perfect summarization video requires understanding video semantic content 
automatic understanding semantic content general videos far intelligence today computing systems despite significant advances computer vision image processing pattern recognition machine learning algorithms 
video summarization offers concise representation original video clips showing representative synopsis video sequence 
generally speaking fundamental types video summarization static video dynamic video skimming 
static known static storyboard collection salient images key frames extracted original video sequence 
dynamic skimming consists collection associated audio video sub clips permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
acm multimedia december juan les pins france 
copyright acm 
microsoft research asia beijing sigma center road beijing china microsoft com selected video sequence shortened length 
known approach extracting multiple key frames shot frame content changes computed features color histogram motion activity 
zhuang proposed unsupervised clustering scheme adaptively extract key frames shots 
methods require pre defined threshold key frame number control density keyframes shot 
shot independent approaches proposed 
instance proposed clustering approach key frame extraction entire video 
sophisticated methods include integration motion spatial activity analysis face detection technologies progressive multi resolution keyframe extraction techniques object approach 
static video summary effective preserve time evolving dynamic nature video content 
audio track lost important content channel video 
skimmed sequence hand able provide users impressive preview entire video 
literatures addressed dynamic video skimming indispensable tool video browsing 
straightforward approaches compress original video speeding playback 
factor approach limited playback speed order keep speech comprehensible 
informedia system generates short synopsis video integrating audio video textual information 
combining language understanding techniques visual feature analysis system gives reasonable results 
satisfactory results may achievable text driven approach speech signals noisy case life video recording 
approach generating semantically meaningful summaries abstraction scheme 
sophisticated techniques proposed 
example trajectories objects 
linear dynamical system theory applied 
singular value decomposition adopted summarize video content 
despite numerous efforts generating static dynamic video summary results far satisfactory 
direct sampling low level feature approaches inconsistent human perception 
semantic oriented methods general far meeting human expectations precise textual information may available summarization 
systems totally neglect audio track able generate impressive results 
algorithms involving large number summarization rules intensive computation normally impractical real applications 
aiming removing limitation current algorithms avoiding fully semantic understanding developed generic video summarization framework modeling viewer attention 
main contributions twofold new scheme model viewer attention viewing video set algorithms apply modeling video summarization 
attention neurobiological conception 
implies concentration mental powers object close careful observing listening ability power concentrate mentally 
computational attention allows break problem understanding live video sequence series computationally demanding localized visual audio linguistic analytical problems 
computational attention methodologies studied powerful tool active vision systems 
itti reviewed works computational models focal visual attention bottom saliency imagebased visual attention system 
combining multiple image features single topographical saliency map attended locations detected order decreasing saliency dynamical neural network :10.1.1.53.2366
selective attention method visual pattern recognition 
promising results obtained applying method handwritten digit recognition face recognition 
proposed attention system control gaze shifts active vision system integrating dynamic features motion induced attention 
previous proposed computational motion attention model generate video skimming 
extend build generic user attention model integrating set attention models extracted video sequence 
static attention model reasonable extension video characters 
video attention model video summarization generated user attention curve resulted attention modeling 
frame assigned attention value easy determine frame segment frames attract viewer attention 
way number needed key frames shot determined number wave crest attention curve 
dynamic skims extracted wave attention curve need sophisticated rules 
rest organized follows section introduces framework user attention model 
section section discuss attention modeling methods visual audio features respectively 
new video summarization approach including static dynamic summarization user attention model described section 
performance summarization approaches evaluated user study experiment 
section describes experiment method reports experimental results 
section presents concluding remarks discussions 

user attention model video compound image sequence audio track textural information 
image sequence presents motion object motion camera motion color texture shapes text regions 
audio channels consist speech music various special sounds 
textual information represented linguistic form obtained sources closed automatic speech recognition asr superimposed text 
human attention attracted information elements complete user attention model integrated set visual audio linguistic attentions 
video sequence analyzing modeling visual audio linguistic fusion scheme attention curve 
framework user attention model presents proposed framework user attention model 
obtain model video sequence analyzed extract kinds content features 
set attention modeling methods employed generate attention models information channels 
extractable video audio linguistic features integrated user attention framework computational attention model available 
extendable framework 
fusion scheme key issue framework 
linear combination user interaction machine learning method adopted 
fusion process attention models integrated generate user attention curve video sequence 
currently adopt linear combination implement fusion scheme due effectiveness simplicity 
scheme attention model normalized 
denote attention model computed wv wa wl weights linear combination normalized visual audio linguistic attention models respectively defined follows scm cm sas wi wj wk weights visual audio linguistic attention models respectively normalized attention model components attention model 
normalized camera attention visual cm attention model 
scm works switch 
scm open scm closed 
higher scm value powerful similar camera attention normalized audio saliency attention audio attention 
mcm mas normalized 
definition attention models weights control user preference corresponding channel 
adjusted automatically interactively 
user attention model extensible framework computational visual audio linguistic attention model integrated framework 
discuss modeling methods salient audio visual features demonstrate effectiveness proposed user attention model applications video summarization 
details modeling methods summarization scheme sections 
linguistic attention modeling method discussed 

visual attention modeling section discuss detail model visual attentions 
image sequence visual features including motion color texture shape text region features classified classes dynamic static features 
recognizable objects face attract human attention 
camera operations induce reviewer attention 
visual attention models proposed model visual effects due motion static face camera attention 
motion attention model motion attention model built motion vector field 
frame video sequence extract motion field current frame calculate set motion characteristics 
implementation video sequences stored mpeg format extracted mpeg data directly 
treat retina eyes motion vectors perceptual response optic nerves 
assume intensity spatial coherence temporal coherence 
motion vectors go transformed kinds maps 
normalized outputs fused saliency map linear combination 
way attended regions detected saliency map image image processing methods 
basic assumption location macro block mb intensity induces motion energy activity called motion intensity computed normalized magnitude motion vector dx dy dx dy denote components motion vector maximum magnitude 
spatial coherence induces spatial phase consistency motion vectors 
regions consistent motion vectors high probability moving object 
contrast regions inconsistent motion vectors located boundary objects background 
measure spatial coherency similar method 
compute phase histogram spatial window size pixels location macro block 
measure phase distribution entropy follows log cs sh sh sh spatial phase histogram probability distribution function number histogram bins 
similar spatial coherence define temporal coherency output temporal coherence sliding window size frames time axis th th log ct th temporal phase histogram probability distribution function number histogram bins 
way obtain motion information channels cs ct compose motion perception system 
gives example outputs 
outputs cs ct characterize dynamic spatio temporal attributes motion particular way define motion attention cs ct outputs cs ct channels integrated motion saliency map shown motion attention areas identified precisely 

motion attention detection 
map cs map ct map saliency map original image motion attention areas marked blue box 
order detect salient motion regions employ image processing procedures histogram balance median filtering binarization region growing region selection 
results motion attention detection may calculate motion attention model accumulating brightness detected motion attention regions saliency map follows motion mb brightness macro block saliency map set detected areas motion attention denotes set macro blocks attention area number macro blocks normalization purpose 
motion value frame video forms continuous motion attention curve time axis 
shows example curve 
static attention model motion attention model reveal attentions video due inherent characters video limitations 
instance static background region may attract human attention motion 
need static attention model deficiency 
itti defined saliency visual attention model static scene analysis 
adopt similar approach 
changes order meet requirements attention model framework inherent characteristic videos 
modification mainly focuses generate time serial attention curve individual saliency maps 
similar saliency map generated frame channel saliency maps computation color contrasts intensity contrasts orientation contrasts 
final saliency map built applying iterative method proposed 
stead locating human focus attention orderly detect regions attractive human attention saliency map 
shown size position brightness attended regions gray saliency map decide degree human attention attracted 
blue boxes marked original image binarized saliency map 
binarization threshold estimated adaptive manner 
result define static attention model number attended regions position size brightness saliency map follows static bi pos frame bi denotes brightness pixels saliency regions denotes number saliency regions frame area frame pos normalized gaussian template center located center frame 
human usually pay attentions region near center frame normalized gaussian template assign weight position saliency regions 
shows example static attention curve video segment 

static attention detection face attention model face salient characters human beings 
appearance dominant faces video frames certainly attracts viewers attention 
face attention model important part user attention model able enhance power user attention model significantly 
employing real time face detection module obtain face information frame including number faces poses sizes positions 
gives example face detection result video frame 
current system total face poses plane rotation detected frontal profile 
size position face usually reflect importance face 
model face attention face ak frame pos denotes size th face frame frame denotes area frame weight position defined index position 
face attention model may calculate face attention value frame generate face attention curve 
shows example face attention curve video clip closed faces higher values 

face detection position weights camera attention model know camera motion utilized emphasize neglect certain objects segment video guide viewers attentions 
camera motions useful formulating user attention model 
generally speaking axis go axes lens perpendicular image plane camera motion classified types panning tilting resulted camera rotations axis respectively referred panning rolling resulted camera rotations axis tracking resulted camera displacement axis respectively referred tracking resulted camera displacement axis zooming resulted lens focus adjustment 
affine motion estimation easily determine camera motion type speed accurately 
challenge map parameters effect attracting viewer attention 
derive camera attention model general camera rules 
attention factors caused camera motion quantified range shown 
visual attention definition camera motion model multiplied sum visual attention models 
value higher means emphasis value smaller means neglect 
value equal camera intend attract human attention 
want consider camera motion visual attention model closed setting switch coefficient cm 
model camera attention assumptions 
zooming emphasize 
faster zooming speed important content focused usually zoom forward emphasize details backward emphasize overview scene 
consider zooming 
video producer wants neglect horizontal panning applied 
faster speed important content contrary video producer wants emphasize vertical panning bring viewers unstable feeling 
panning direction seldom usually caused mistakes 
camera motions obvious intention 
assign value leave attention determination visual attention models 
camera motion changes frequently consider random unstable motions 
case modeled 
assumptions model camera motions shown 
zooming process intended emphasize part zooming sequence frames zooming usually important 
assume importance increases temporally camera zooms 
shown attention degree assigned zooming started attention degree part zooming direct ratio speed zooming camera zooming attention degree zooming continue certain period time tk return shown 
attention degree panning determined aspects speed vp direction attention modeled product inverse speed quantization function direction shown 
quadrant example map motion direction subsection function 
assigned direction assigned direction assigned direction 
section monotonously decreasing second section monotonously increasing 
similar zooming camera panning attention degree continue certain period time tk attention degree inverse ratio speed panning vp shown 
vz tk tk 
camera attention modeling zooming zooming followed panning direction mapping function panning panning followed types camera motion zooming followed panning panning followed zooming followed zooming 
shows model camera motions constant value 
addition zooming followed panning modeled independently shown 
types motion followed zooming start attention degree zooming determined motions 
give examples zooming followed panning respectively 
shows example camera motion attention curve 

audio attention modeling audio attentions important parts user attention model framework 
speech music semantically meaningful human beings 
hand loud sudden sound effects grab human attention 
section define audio attention models audio saliency attention speech attention music attention 
audio saliency attention model characters represent audio saliency attention model 
fundamental loudness 
sound speech music special sound whistle explosion people attracted louder sudden sound subjective intention 
loudness represented energy model audio saliency attention audio energy 
general people may pay attention audio segment cases occurs 
audio segment absolute loud sound measured average energy audio segment 
loudness audio segment suddenly increased deceased 
measure sharp increases decreases energy peak 
audio saliency model defined components audio saliency normalized average energy normalized energy peak audio segment 
calculated follows respectively 
avr peak avr peak avr peak denote average energy energy peak audio segment respectively 
maximum average energy energy peak entire audio segment corps 
sliding window compute audio saliency audio segment 
similar camera attention audio saliency attention plays role audio attention model 
shows example curve 
speech music attention models special sound effects laugh whistle explosion human pay attention speech music speech music important cues scene video 
general music emphasize atmosphere scenes video 
highlight scene accompanied music background 
hand textual semantic information conveyed speech 
example speech attractive audience tv news 
obviously audience usually pays attention salient speech music segments retrieving video clips speech music 
saliency speech music measured ratio speech music sounds audio segment 
previous audio classification music speech ratio calculated steps 
audio stream segmented sub segments 
set features computed sub segment 
features include mel frequency cepstral coefficients mfccs short time energy ste zero crossing rates sub band powers distribution brightness bandwidth spectrum flux sf linear spectrum pair lsp divergence distance band periodicity bp pitched ratio ratio number pitched frames total number frames sub clip 
support vector machine classify audio sub segment speech music silence 
results classification speech ratio music ratio sub segment computed follows 
speech music speech music total total denote speech attention music attention model respectively 
speech number speech sub segments music number music sub segments 
total number sub segments audio segment denoted total 
numbers accumulated segment show examples speech music attention curve respectively 

video summarization scheme video summarization scheme developed proposed user attention model 
shows flowchart proposed scheme including static dynamic summarization 
scheme component attention models computed user attention curve generated linear combination fusion scheme 
example segment attention curve shown 
curve key frames video skims extracted 
user attention modeling user attention curve generation derivative curve calculation zero crossing points searching keyframe selection static summarization skims generation dynamic summarization 
video summarization flowchart shot boundary skim ratio sentence boundary simple rules user attention curve composed time series attention values associated frame video sequence 
smoothing normalizing number identified curve 
definition user attention model video segments attract viewer attentions 
reasonable assume key frames skims extracted 
order determine precise position peak crest derivative curve computed shown 
zero crossing points positive negative derivative curve locations wave crest peaks 
pin height equal peak attention value represent key frame 
way key frames video sequence identified shot boundary detection 
attention value key frame importance measure key frame 
measure multi scale static abstraction generated conveniently ranking importance key frames 
shot extraction key frames shot boundaries representative frames shot 
maximum attention value key frames shot importance indicator 
case crest shot middle frame chosen key frame important value shot assigned zero 
key frame required shot key frame maximum attention selected 
hand total number key frames allowed number shots video shots lower importance values neglected 
approaches create dynamic video skims user attention curve 
developed straightforward shot approach skim generation require complex heuristic rules 
skim ratio skim segments selected key frame skim ratio shot 
process skim segment selection illustrated 
skimmed length length shot sentence keyframe skim keyframe sentence skim 
video summarization scheme order sound skimmed video smoother speech audio track interrupted sentence 
sentence boundary indispensable information video skimming 
difficult fully retrieve sentence useful criteria 
fundamental important usually pause silence duration sentences 
due background sound noise audio clip sentences may silence 
adaptive background sound level detection needed purpose estimating threshold pause detection 
implementation segment speech sentences steps adaptive background sound level detection set threshold 
pause non pause frame identification energy information 
result smoothing minimum pause length minimum speech length respectively 
sentence boundary detection determined longer pause duration 
attention curves shot boundary sentence boundary key frames simple rules create video skims shown 
segment shorter minimum length min 
usually min set frames segment shorter frames short convey content creates annoying effects 
skim ratio length skim segment determined length shot number key frames shot 
skim length shot distributed key frame shot evenly 
average length skim segment smaller lmin key frame minimum attention value removed 
skim length re distributed rest key frames 
process carried iteratively average length higher minimum length lmin 
skim segment shot boundary trimmed boundary 
skim segment boundaries adjusted speech sentence boundaries avoid splitting speech sentence aligning sentence boundary skim evading sentence boundary skim 

attention model curves summarization examples 
skimming curve 
sentence boundary 
zero crossing curve 
derivative curve 
user attention curve 
motion attention curve 
static attention curve 
face attention curve 
camera attention curve 
audio saliency attention curve 
speech attention curve 
music attention curve 

evaluations issues key frame extraction video summary intensively addressed standard method evaluate algorithm performance 
assessment quality video summary strong subjective task 
difficult programmatic simulated comparison obtain accurate evaluations methods consistent human perception 
evaluate proposed video summarization approach carried user study experiment 
gives examples key frames segment user attention model curves generated skim selection curve ratio 
top shows shots keyframes 
key frames marked asterisk selected generate video skims 
bottom gives corresponding segment attention model curves derivative curve zero crossing curve shot boundary sentence boundary skimming curve 
vertical lines shot boundaries 
shots example segment extracted mpg news video program test dataset 
segments positive pulses skim selection curve denote selected skims 
similarly segments positive pulses denote speech sentences 
addition worth noticing key frames detected shot frames displayed illustrate process zooming 
zooming segment identified camera motion detection algorithm emphasized camera attention model curve 
result segment selected part video skims 
implementation weights linear combination assigned switches assigned currently 
quantitatively evaluate quality video summarization invited volunteered subjects including males females gave subjective scores video summaries generated proposed approach 
experiment composed parts single key frame evaluation multiple key frame evaluation video skimming evaluation 
order keep subjects innocent video content look video skims required evaluate dynamic summary 
table 
test videos 
video genre shot time animals mpg documentary ii mpg iii basketball mpg sport game iv mpg tv news mpg home video total chosen test data various types videos different lengths proposed attention model aimed generic detecting important content general videos 
totally video sequences selected test dataset 
include animals mpg educational documentary mpg audio track video basketball mpg sports video mpg half hour news program mpg segment home video 
total length test videos close minutes 
details test videos listed table 
fundamental structure video shot automatically detected employing algorithm proposed 
total number shots segmented test videos 
static summarization evaluation number key frame selected presenting shot tailored applications 
evaluate static abstraction aspects single key frame multiple key frames 
main concern single key frame representation informative key frame representative icon shot 
single key frame multiple key frames provide user information showing process evolving events 
assessment criteria different single key frame 
users usually concerns extracted key frames redundant insufficient 
experiments subjects required give assessment neutral bad single key frame representation give assessment multiple key frames representation 
evaluation subjects briefly reviewed shots double clicking icons 
asked give assessment single multiple key frames respectively 
single key frame shot icon shot 
shot icons displayed planar view 
subject clicks icon multiple key frames displayed view 
way subjects judgments representations shot shot conveniently 
table 
evaluation static video abstraction single neutral bad avg 
ii iii iv avg 
order obtain quantitative assessment quantify subjects assessment single key frame score corresponding neutral bad respectively 
average score single key frame calculated number shots counted category 
statistical results listed table 
average score single keyframe extraction evaluation 
table 
evaluation static video abstraction multiple 
ii iii iv avg 
evaluation multiple key frames quantified measure user satisfaction defined ratio number shots assessment total number shots 
details listed table 
average user satisfaction score close 
reasons promising results computational attention models consistent human perception 
user attention curve embeds audio information provide important hints key frame selection speech special sound effects 
dynamic summarization evaluation generally speaking users expect skimmed video short informative possible 
difficult achieve objectives time 
video program skim ratio controlled automatically setting threshold user attention curve reasonable user choose skim ratio experiments 
experiments skimmed video considered 
criteria set performance evaluation 
skimmed video informative important video skimming 
set criterion informativeness 
skimmed video enjoyable original important criterion 
call 
assesses smoothness image sequence influence speech music 
consequently part experiment subjects required assign scores skimmed videos criteria informativeness respectively 
users may think original video enjoyable informative give subjects right assign scores original video 
normalize scores skimmed videos scores assigned original ones 
order obtain precise scores subjects know content test videos look skimmed video 
part experiment performed key frame evaluation 
subjects looked skimmed video sequences high low skim ratio turn controlled evaluation program 
look skimming original videos fast forward backward functions 
subjects allowed give scores test sequence finishes viewing sequence 
finishing viewing original video chance modify scores assigned skimmed sequences understand video content details time 
scores subjects assigned average normalized informativeness scores calculated reflect user satisfactory degree skimmed videos 
experimental results list table 
scores non highlighted rows average real scores subjects 
highlighted rows show average scores normalized subjects scores original video 
average results bottom table calculated normalized scores 
table see average informativeness scores skim ratio respectively ones respectively 
numbers indicate proposed skimming scheme effective high skim ratio 
video skimmed skim ratio viewers satisfactory degree drops score informativeness score respectively 
table 
evaluation dynamic video skimming informativeness ii iii iv avg 
drop score usually higher informativeness score skim ratio 
difference limited 
possibly due fact difficult subjects discriminate uninformative viewer obtain information expect tends feel skimmed enjoyable 
hand original audio track result quite different 
indicated scores video mpg absolute informativeness score original lowest test videos normalized scores skims video highest 
case important informativeness information sequence 

automatic video summarization powerful tool video browsing accessing 
new approach video summarization including key frame extraction video skimming fully semantic content understanding requirements complex heuristic rules 
approach constructs video summaries modeling viewers attentions attracted motion object audio language viewing video program 
generic extendable user attention model designed set modeling methods audio visual features proposed support framework 
user study results show static dynamic video summarizations able meet users requirements video browsing 
average satisfaction scores single key frame multiple key frames extracted proposed approach respectively 
satisfaction scores dynamic summarization ratio ratio 
promising result verifies effectiveness proposed summarization scheme indicates computational attention model efficient method extracting important content video fully semantic analysis 
generic extendable framework proposed video attention model applications works 
hand fusion scheme requires studies proved kind fusion scheme effective currently 
addition evaluation method summarization needs improvement 
independent measure investigated evaluate smoothness dynamic summarization heavily affected informativeness score 

express appreciation lan feng yu tsinghua university 
internship implemented components 
express appreciation prof chong wah ngo city university hong kong gave valuable advices visit lab 

zhang integrated system content video retrieval browsing pattern recognition vol pp 
wolf key frame selection motion analysis proc 
icassp vol pp 
zhuang adaptive key frame extraction unsupervised clustering proc 
icip 
time constrained key frame selection technique proc 
pp 

key frame selection represent video proc 
icme 
neri automatic key frame selection wavelet approach proc 
spie vol 
pp 
july 
kim hwang integrated scheme objectbased video abstraction proc 
acm multimedia 
los angeles ca 
gupta grudin time compression system concerns usage benefits proc 
acm ich 
smith kanade video skimming characterization combination image language understanding techniques proc 
computer vision pattern recognition 
ahmed dynamic video summarization visualization proc 
acm multimedia october 
summarizing video datasets spatiotemporal domain proc 
th inter 
workshop database expert systems applications 
em algorithm video summarization generative model approach proc 
iccv 
gong liu video summarization singular value decomposition proc 
cvpr june 
itti koch computational modeling visual attention nature reviews neuroscience vol 
pp 
mar 
itti koch niebur model saliency visual attention rapid scene analysis ieee trans 
pattern analysis machine intelligence 
itti koch comparison feature combination strategies saliency visual attention systems proc 
spie human vision electronic imaging iv hvei san jose ca vol 
pp 
jan 
alpaydin selective attention method visual pattern recognition application handwritten digit recognition face recognition ieee trans 
pattern analysis machine intelligence vol mar 
integration static dynamic scene features guiding visual attention wahl 
eds 
springer pp 

ma zhang model motion attention video skimming proc 
icip 
ma zhang new perceived motion shot content representation proc 
icip 
li statistical learning multi view face detection proc 
eccv 
lu jiang zhang robust audio classification segmentation method proc 
th acm international conference multimedia pp 
lu stan li zhang content audio segmentation support vector machines 
proc 
icme pp tokyo japan 
zhang kankanhalli smoliar automatic partitioning full motion video multimedia systems pp 
