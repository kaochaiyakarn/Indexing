algorithms partially observable markov decision processes zhang thesis submitted hong kong university science technology partial fulfillment requirements degree doctor philosophy computer science august hong kong copyright fl zhang authorization declare am sole author thesis 
authorize hong kong university science technology lend thesis institutions individuals purpose scholarly research 
authorize hong kong university science technology reproduce thesis photocopying means total part request institutions individuals purpose scholarly research 
zhang ii algorithms partially observable markov decision processes zhang certify examined ph thesis complete satisfactory respects revisions required thesis examination committee 
dr nevin zhang thesis supervisor prof roland chin head department department computer science august iii express sincere gratitude supervisor nevin zhang academic progress 
past years source encouragement research 
taught lot research importantly person 
influence continue benefiting long time 
members thesis defense committee judy goldsmith golin yeung zheng spending time reading thesis providing valuable feedbacks improvements 
go fangzhen lin james kwok part thesis proposal defense 
thesis defense comments committee members incorporated final version 
due time limit am able summarize main results complexity solving pomdps suggested judy 
benefited discussions members ai stat group 
meetings give chances look different research flavors postgraduate students researchers 
james kwok yeung nevin zhang organizing meetings liu stephen lee sam choi chan martin law discussions 
visit eric hansen month exciting pleasurable experience 
supporting trip sharing ideas policy iteration topics 
mississippi conversations feng compact representation pomdp models 
extend yan family chinese university hong kong 
broad experience research life helped perspectives 
friendship friends colleagues past years colorful enjoyable 
ding jin gu dong hua hung li li chong wah ngo ge yong sun sun feng tian wu jun wu sam xia wei xiong li yan yong iv zhang zhao 
ai lab lively place outside working hours 
am fortunate supportive family 
parents advanced education possible 
youngest member big family am encompassed love parents brothers sisters 
am able proper words express wife son 
patience sacrifices 
feel indebted 
come world months total time spent just days 
table contents title page authorization page ii signature page iii iv table contents vi list figures xi list tables xii xiv chapter planning applications thesis outline chapter pomdp theory algorithms pomdp model model definition belief states policies value functions belief space mdp value iteration properties value functions policy tree piecewise linear convex property parsimonious representations difficulties solving pomdp standard algorithms value iteration vi policy iteration theoretical results overview pomdp algorithms decomposing value functions value iteration superset algorithms value iteration subset algorithms current research status chapter modified value iteration motivation uniformly improvable value function modified value iteration algorithm backing witness points input vectors retaining uniform algorithm stopping point value iteration convergence modified value iteration computing bellman residual empirical studies effectiveness point improvements variations point dp update related point standard dp updates point procedure value function approximation previous related modified value iteration chapter value iteration subspace motivation explicit value iteration subspace belief subspace mdp explicit dp updates subspace stopping criterion decision making technical issues subspace representation value functions subspace vii implicit value iteration subspace implicit dp updates subspace implicit dp updates subspace ii value iteration subspace complexity analysis implementations empirical studies maze problem deterministic observations maze problem nondeterministic observations related reachability analysis online updates state space decomposition chapter informative pomdps pomdps informativeness reducing complexity dp updates belief subspace value functions subspaces value iteration subspace dp updates subspace versus oe subspace empirical studies reducing number iterations backup operator point value iteration subspace empirical studies related model applicability special pomdps solutions value updates subspace chapter near discernible pomdps pomdps histories subspace value functions viii space progressive value iteration algorithmic structure value iteration subspace subspace expansion stopping criterion optimality empirical results generalization near discernible pomdps approximate spvi empirical studies related model applicability anytime planning algorithms anytime dynamic programming chapter contributions extensions appendix proofs proof lemma proof theorem proof theorem proof theorem proof lemma appendix sets parsimonious representation appendix computing bellman residuals bellman residual space bellman residual subspace appendix incremental pruning space versus subspace standard incremental pruning incremental pruning subspace algorithmic structure incremental pruning simplex ix appendix experiments informative pomdps elevator problem regular grid appendix experiment discernible pomdps appendix computational environment list figures interactions agent world interactions pomdp agent world step policy tree value function state pomdp parsimonious representation value function running example pass algorithm illustration basic idea modified value iteration dp update space subspace maze problem comparative studies vi ssvi maze problem comparative studies vi ssvi noisy maze problem belief space belief simplexes belief subspace comparative studies vi ssvi infovi maze comparative studies vi infovi performance spvi near discernible pomdps performance spvi pomdps bellman residual sets vectors performance vi ssvi infovi elevator grid world performance ssvi infovi regular grid csd office environment performance approximate spvi office navigation problem xi list tables linear program determine vector usefulness value iteration pomdps policy iteration pomdps relations value functions testbed times value iteration pomdps modified value iteration pomdps time costs computing optimality detailed statistics vi modified vi quality policies vi modified vi number standard dp updates time cost modified vi takes projected points number standard dp updates time vi took non lp point update number standard updates time pi took compute optimality linear program determine vector usefulness simplex parsimonious representation set simplex parsimonious representation set subspace linear program determine vector usefulness set oe simplex space progressive value iteration value iteration subspace subspace expansion spvi detailed statistics maze spvi detailed statistics maze spvi detailed statistics modified maze approximate spvi detailed statistics modified maze spvi monahan pruning algorithm pruning algorithm bellman residual belief space bellman residual subspace xii operators incremental pruning incremental pruning dp update algorithm value iteration subspace operators dp update simplex incremental pruning dp update simplex statistics csd environment approximate spvi xiii algorithms partially observable markov decision processes zhang department computer science hong kong university science technology partially observable markov decision process pomdp general sequential decision making model effects actions nondeterministic partial information world states available 
finding near optimal solutions pomdps computationally difficult 
value iteration standard algorithm solving pomdps 
conducts sequence dynamic programming dp updates improve value functions 
value iteration inefficient reasons 
dp update expensive due need accounting belief states continuous belief space 
second value iteration needs conduct large number dp updates convergence 
thesis investigates ways accelerate value iteration 
centers idea conducting dp updates value iteration belief subspace subset belief space 
belief subspace reduce number dp updates value iteration converge 
design computationally cheap procedure considering belief subspace consists finite number belief states 
additional step improving value functions 
due additional improvements procedure value iteration conducts fewer dp updates xiv efficient 
second belief subspace reduce complexity dp updates 
establish framework carry value iteration belief subspace determined pomdp model 
belief subspace smaller belief space model dependent 
true pomdp value iteration belief subspace expected efficient 
framework study pomdp classes special problem characteristics propose different value iteration algorithms 
informative pomdp assumes agent idea world states 
subspace determined model smaller belief space 
value iteration belief subspace efficient pomdp class 
near discernible pomdp assumes agent get idea states executes particular actions 
pomdp belief subspace determined model size belief space 
propose anytime value iteration algorithm focuses computations small belief subspace gradually expand 
general class near discernible pomdps assumes agent get idea states high likelihood executes particular actions 
pomdps adapt anytime algorithm conduct value iteration growing belief subspace 
xv chapter important long term objective artificial intelligence ai build intelligent agent capable autonomously achieving goals complex environments 
ai planning effort elegant objective 
addresses problem agent act respond feedbacks environment 
thesis studies computational aspects popular planning model 
planning planning framework agent world environment separate interacting components 
world described set states 
time point agent change world state executing action 
feedback world provides agent information changes 
process repeats time point 
description initial state set actions set goal states planning problem find course action enables agent achieve goals 
world agent actions feedback interactions agent world relationship agent world illustrated 
time point agent executes action change world state collects feedback 
assumptions effects actions forms feedback characterize planning problem 
history planning research assumptions evolved simple complex 
briefly examine planning models including model interest thesis assumptions 
classic strips planning framework effects actions assumed deterministic 
assumption means state uniquely determined current state action executed 
assumption initial state known states possible plan execution trivially computed initial state actions executed 
need collect feedback environments 
classic planning framework extended accommodate uncertainty effects actions need tradeoff competing objectives handle complex realistic tasks 
extensions decision theoretic approach attracted attention :10.1.1.107.9127
approach probability theory represent uncertainties utility theory represent competing objectives 
extension allows ai planning benefit theoretical foundations related operations research optimal control theory decision sciences 
heart decision theoretical planning model called markov decision process mdp 
mdp model extends classic planning framework aspects 
allows effects actions nondeterministic 
specifically current world state agent executes action state unique 
possible states probabilities 
second feedback world provides exact information states world 
third due actions longer appropriate agent take goal attainment objective 
sequence actions may lead different sequence states 
mdps objective related utility function 
frequently measurement function rewards payoffs agent decision horizon 
measurement adapted consistent objective goal attainment giving larger payoffs goal states 
sense objective utility function regarded extension goal attainment 
planning problem modeled mdps solution problem policy specifies action response feedback state environment 
mdp feedback assumed take simplistic form states environment 
words agent informed perfect information states 
sense mdp said completely observable 
assumption reasonable environmental state problem explicit freely available 
partially observable markov decision process pomdp generalization mdps 
assumes effects actions nondeterministic mdp assume feedback provides perfect information state world 
assumes feedback may provide incomplete imperfect information states environment 
due pomdp said partially observable 
see extension important take look interactions agent modeled pomdp environment 
hand world states changed executing actions 
procedure viewed control effects actions 
hand feedback provided agent world states change 
procedure viewed information gathering effects actions different actions change world different states turn allows agent receive different feedback 
pomdp provides unified framework handle sources uncertainties control effects actions information gathering effects actions 
pomdp provides way tradeoff choosing actions change world states actions collect information agent 
tradeoff highlighted examples subsection review applications pomdp model 
applications characteristics nondeterministic effects actions partial observability environment distinguish pomdps planning models 
pomdp takes account uncertainties applications reality 
application area great interest mobile robot navigation 
application states locations environment 
actions categorized goal achieving moving desired location ones information gathering figuring current location ones 
reliable 
instance move forward action occasionally leads overshoot reality 
means states change nondeterministically 
complication comes sensors 
reliably detect real states 
give agent vague idea surroundings landmarks junctions feedbacks reveal true states 
pomdp model provides way tradeoff choosing move action information gathering action time point 
working robots pomdp model form control navigation 
reported exper iments show pomdps elicit robust reliable solutions kind problems models 
interesting application pomdps medical therapy planning 
case states refer patient health status feedbacks refer symptoms 
actions different treatment choices 
problem separate relevant processes diagnosis disease treatment 
diagnosis process helps choose appropriate treatment 
hand case treatment pursued knowing underlying patient state certainty 
complexity stems uncertainty associated symptoms patient different treatment choices 
pomdp model provides way tradeoff choosing investigative actions diagnosis actions 
reported experiments show pomdps provide clinically reasonable justifiable solutions case study management patients heart disease 
pomdp origin operations research community 
area cited example pomdp application machine maintenance problem 
briefly introduce ignore various variations extensions see 
machine internal components 
components malfunction 
different configurations internal components constitute state space 
actions manufacture inspect replace 
machine manufactures product components wear probabilistically 
machine components replaced 
inspect machine status replace components means product manufactured duration 
manufactured products partially reflects machine status 
pomdp model provides way tradeoff choosing manufacture action inspect replace action 
reported pomdp elicit elegant solutions problem circumstances 
applications pomdps 
include decoding noisy signals network communications channel problem coping possibility answers questionnaire design attacking vast uncertainty dispatching elevators control attention machine vision systems searching moving target :10.1.1.17.5519
thesis pomdps potential application areas actual applications severely limited high computational complexity 
overcome difficulties researchers ai community extensive effort computational aspects past years 
led development new exact algorithms efficiently compute optimal solutions various approximation approaches solve larger complex problems complexity theory characterize difficulty problem machine learning approaches cope uncertainty 
despite efforts unfortunately efficient algorithm able compute near optimal solutions pomdps small state space 
thesis developing new algorithms 
briefly explain computational difficulties introduce thesis 
mdp state world completely observable 
policy mapping set states feedback set actions 
sets assumed finite number possible mappings finite 
optimal policy conducting search finite set mappings 
pomdp hand current feedback provide sufficient information world states 
information previous steps need taken consideration 
information summarized probability distribution set states 
literature probability distribution referred belief state 
belief space defined set possible belief states 
continuous space world finite number states 
pomdp policy mapping belief space set actions 
definition similar policy mdp context 
continuum belief space poses big challenge computational perspective number mappings uncountably 
find optimal policy pomdp conduct search space 
fundamental difference solving pomdps drastically difficult solving mdps 
closely related concept policy concept value function mapping belief states real numbers 
policy associated value function better policy better value function 
hand construct policy value function better value function better policy constructed 
leads strategy solve pomdp conduct search value function space 
value iteration exactly improves value functions iterative fashion 
iteration referred dynamic programming update dp update 
dp update computes new value function entire belief space current 
value iteration stops current value function sufficiently close optimal 
iteration needs consider uncountably belief states dp updates expensive 
value iteration needs conduct steps dp updates find near optimal value function 
factors value iteration inefficient 
thesis propose approaches accelerate value iteration reducing complexity dp updates value iteration reducing number iterations value iteration converge 
concept unify belief subspace subset belief space 
value functions policies mappings belief space subset belief space considered set mappings belief subspace subset set mappings entire belief space 
value iteration conducts search value function space means smaller set belief states suggests lower computational complexity 
exploit concept belief subspace ways 
purpose reducing complexity dp updates approach restrict belief subspace 
put way dp updates need consider subset belief space value iteration dp updates need consider entire belief space 
second purpose reducing number dp updates propose additional improvements value functions addition standard steps 
additional improvements consider special type belief subspace consists finite number belief states 
outline remaining chapters thesis organized follows 
chapter describe pomdp model explain difficulty solving model briefly survey existing 
chapter accelerate value iteration reducing number dp updates converge 
design computationally cheap procedure 
procedure considers finite set belief states 
dp updates 
due additional improvements value functions procedure number iterations cut value iteration efficient 
chapter show accelerate value iteration restricting belief subspace 
framework established issues value value iteration subspace addressed 
develop condition determine subspace determined model smaller belief space 
subspace smaller show value iteration able take advantage excluding belief states considered 
idea conducting value iteration subspace motivates studies special pomdps 
special pomdps specific problem characteristics 
characteristics related particular regularities subspaces determined models 
chapter apply framework pomdp class observation restricts world small set states 
pomdp class subspace determined model smaller belief space 
addition computational advantage time value iteration take advantage representational savings space 
chapter study pomdp classes 
class actions leading world small set states 
pomdp subspace determined model size belief space 
propose anytime algorithm 
algorithm computations concentrated belief states visited agent 
time permits subspace expanded 
value iteration conducted expanded subspace 
second pomdp class actions leading world small set states high likelihood 
class subspace interest size belief space 
adapt anytime algorithms general pomdp class 
chapter conclude thesis summary contributions extensions 
chapter pomdp theory algorithms chapter introduces pomdp model explains computational difficulties solving pomdp 
briefly surveys existing introduces motivations thesis 
pomdp model section presents model definition shows pomdp interest transformed completely observable mdp 
transformation existing approaches solve mdp original pomdp 
model definition interested pomdp consisting components ffl finite set world states ffl finite set actions ffl finite set observations ffl transition model 
state set agent performs action world jumps state probability js 
transition probabilities specified transition model 
ffl observation model 
current state previous time point agent executed action agent observes set probability zjs 
observation probabilities specified observation model 
ffl reward model agent state current action performed receives units reward 
immediate rewards specified reward model interaction agent modeled pomdp environment follows 
initially world state 
information state agent executes action 
action effects 
agent receives immediate reward specified reward model 
second action changes world state new probabilistically 
dependent new state action executed agent receives observation probabilistically 
process repeats 
process demonstrated 
note pomdp agent planner informed observations providing incomplete information world states 
world action observation agent interactions pomdp agent world agent executes action state time point receives immediate reward objective maximize expected sum rewards period time 
finite horizon framework agent needs maximize sum steps gamma infinite horizon framework interested maximizing agent long term expected sum rewards 
assumes rewards received earlier value agent received 
case agent acts maximize discounted objective function discount factor 
reward function upper bounded constant discount factor ensures sum finite 
thesis focus infinite horizon discounted pomdps 
belief states policies value functions classical planning agent able know identities world states 
pomdp agent obtain incomplete information world states observations 
needs choose action time point refer historical information includes initial state observations collected actions performed far 
infinite horizon framework keeping history agent exhaust memory 
fortunately proven useful information underlying history purpose decision making summarized belief state 
sense belief state said sufficient statistic agent action selection 
belief state probability distribution states usually denoted belief state 
sum beliefs states 
agent current belief state action performed observation received belief state updated follows 
zjs zjs formula notation zjs joint probability world jumping state agent observing previous state executed action equals js 
possible belief states form belief space 
frequently denoted formally fb 
pomdp policy prescribes action belief state 
words policy mapping belief space action space belief state action prescribed policy stationary independent time 
put way time point stationary policy prescribes action belief state 
policy agent starts belief state discounted expected reward receives gamma belief state action time step quantity denoted 
viewed function said value function mapping belief space real line 
belief state expected discounted rewards agent starts belief state behaves policy policies compared value functions 
policies say dominates intuitively starting belief state agent behaves dominating policy receives larger rewards 
policy optimal dominates policies 
optimal policy denoted optimal value function value function optimal policy 
denoted maximum expected discounted sum rewards agent receive starts belief state value function ffl optimal ffl 
value function policy ffl optimal policy said ffl optimal 
solving pomdp means finding optimal ffl optimal value function policy pomdp 
belief space mdp concept belief state pomdp model transformed belief space mdp state space action space remains 
transition model reward model defined follows 
ffl transition model belief state action specifies transition probability follows 
jb ae 
ffl reward model belief state action specifies immediate reward follows 
due reformulation task solving pomdp accomplished solving reformulated mdp 
proved exists stationary optimal policy infinite discounted mdp 
known mdps solved stochastic dynamic programming 
value iteration value iteration standard approach solving infinite horizon discounted pomdps 
consists basic steps compute near optimal value function dynamic programming dp update termination test 
discuss dp update termination test 
dp update step computing value function current 
current value function operator return value function tv operator defined tv max fr operator inductively defined gamma integer greater 
proved operator contraction mapping sense gamma jj gamma gamma jj jj jj denotes norm 
quantity gamma gamma jj referred bellman residual 
maximal difference value functions gamma max jt gamma gamma fixed point theorem converges optimal value function goes infinity initial chosen said step optimal value function 
alternatively notation denote step optimal value function basic step value iteration termination test 
due contraction property operator value iteration continues bellman residual value functions gamma smaller 
step dp update residual value functions computed test stopping condition 
met value iteration terminates 
theorem characterizes stopping condition 
tells terminate value iteration construct policy 
theorem policy arg max fr max jv gamma gamma max jv gamma gamma value function policy defined said greedy 
theorem means greedy policy near optimal value iteration terminates residual value functions sufficient small 
unfortunately dp updates carried uncountably belief states 
enumerate equation form 
conduct dp steps implicitly need discuss properties value functions 
properties value functions section studies properties value functions 
due value functions finite representation 
possible conduct value iter ation implicitly 
fundamental concept understand finite representation value functions policy tree 
policy tree step policy tree prescribes action current time point action possible information scenario gamma gamma time points 
shows step policy tree 
prescribes action step specifies action observation steps 
fact step policy tree prescribes way agent behaves current gamma time points 
step policy tree subtree rooted node called rooted gamma step policy tree denoted ffi gamma mapping set set possible gamma step policy trees 
step policy tree components action current time point rooted gamma step policy tree ffi gamma gamma time points 
reason step tree written ffi gamma 
altering actions action nodes obtains different step policy trees 
set possible step policy trees denoted step policy tree simply action set actions 
state step policy tree ffi gamma recursively define pn ffi gamma zjs second term understood 
expected discounted total rewards agent receives current time gamma time points world currently state agent behaves policy tree pn said vector associated policy trees dimension number states 
notations ff fi refer vectors 
collection vectors associated step policy trees denoted fv pn jp denote vector defined fi ffi set set ffi ffi ja ffi ffi gamma gamma piecewise linear convex property reveal relations value function set vectors give couple definitions 
vector ff induces value function ff ff regarding vector component induced function linear combination components convenience simply say ff linear collection vectors induces belief space function max ff ff case collection said representation convenience set denote value function induces 
induced value function piecewise linear convex sense ff equals ff region fi fi vg belief space linear region 
theorem means step value function value function induced set 
theorem belief state 
intuition theorem follows 
hand quantity reward agent receives starts behaves optimally 
hand policy tree pn reward agent gets starts behaves policy trees optimal max pn pn pn 
consequently set representation fact implies step optimal value function 
see illustrative example 
pomdp states 
axis denotes belief space line segment extreme belief states 
example value function represented set vectors fff ff ff ff ff parsimonious representations size denoted jv increases exponentially matter fact total number step policy trees jp jaj jzj gamma jz gamma 
potentially number vectors associated policy trees 
value function state pomdp keep vectors pose big challenge agent limited memory space 
fortunately vectors pruned affecting induced value function 
set vectors value function 
set parsimoniously represents represents proper subsets 
set parsimoniously represents value function refer parsimonious representation proved value function unique parsimonious representation terms size 
define parsimonious representation representation contains minimum number vectors 
connecting relations know parsimonious representation representation parsimonious representation attractive imposes space requirement represents value function 
gives parsimonious representation value function 
set consists vectors fff ff ff ff ff pruned 
set vectors represents value function 
great interest compute parsimonious representation set parsimonious representation value function representing value function purpose vector ff set define ff fb delta ff delta ff ff gamma ff fb delta ff delta ff ff gamma words ff set belief points inner products ff strictly greater vectors 
set called ff witness region fact ff region 
notion ff set belief points inner products ff greater equal vectors set called ff closed witness region 
vector useful witness region nonempty 
useless 
useless vector removed set changing induced value function 
useless vectors removed representing set parsimonious 
practice solves linear program order determine usefulness vector set 
specifically vector fi set solves linear program table determine fi 
table line sets constraints defining regions fi dominates vectors line sets constraints defining belief state 
optimal value objective function positive returns solution point case fi useful witness points 
returns null fi useless vector 
lp fi 
variables state 
maximize 
constraints 
fi ff deltab ff 
states table linear program determine vector usefulness set contains large number vectors expensive identify parsimonious representation needs solve number linear programs 
thesis subroutine prune compute parsimonious representation set see appendix discussions implementations 
difficulties solving pomdp proven value function represented finite set vectors due finiteness representing sets refer step computing parsimonious representation tv implicit dp update simply dp update 
number vectors representing step value function grows exponentially impossible maintain vector due limited computational resource 
hopefully vector useful 
vectors removed affecting value function comes price solving number linear programs size representing set 
conse quently worst case dp update needs solve great number linear programs 
standard algorithms value iteration policy iteration standard algorithms solving pomdps 
value iteration algorithms conduct search value function space policy iteration algorithms conduct search policy space 
value iteration value iteration starts value function iteratively improves value functions 
difference consecutive value functions falls predetermined threshold algorithm terminates outputs latest value function 
value functions represented sets vectors 
vi ffl 
ffl gamma 

dp update 

max jv gamma gamma 
return gamma table value iteration pomdps table outlines value iteration algorithm 
table line initializes value function computes predetermined precision loop improves value function tests termination condition 
line dp update computes new set vectors previous set 
line tests termination condition 
bellman residual max jv gamma gamma small vi terminates see appendix implementation 
value iteration terminates outputs set vectors agent keeps memory decision making 
time point derives greedy policy 
theorem ensures ffl optimal policy 
policy iteration policy iteration initial policy 
iterative step current policy updated new 
new policy roughly previous algorithm terminates outputs policy algorithm enters loop 
pi ffl 


policy update 

big difference gamma 
return gamma table policy iteration pomdps table gives policy iteration 
line initializes policy 
line new policy obtained policy update step 
line tests condition algorithm terminate 
depth discussions policy iteration 
theoretical results known finding optimal policy simplified finite horizon pomdp pspace complete 
broader problem class np result suggests pomdp problems harder npcomplete problems 
clearly infinite horizon pomdps easier solve finite horizon pomdps 
due result complexity theory researchers turn attention approximate optimal solution 
finding approximate solutions hopefully easier finding optimal solution 
case pomdp algorithms far 
ffl optimality 
unfortunately complexity results show pomdp solutions 
result optimal stationary policy pomdps finite state space ffl approximated np 
addition problem finding optimal near optimal pomdp solutions problems plan existence evaluation incurred researchers interest 
plan existence problem cast pomdp determine exists policy expected reward greater constant 
complexity np hard 
plan evaluation problem asks pomdp policy threshold expected total discount reward greater 
complexity solving problem np complete 
overview pomdp algorithms pomdp algorithms divided classes value iteration algorithms policy iteration algorithms 
class depending dp update carried exactly approximately pomdp algorithm exact approximate 
lot algorithms approximating value iteration approximating policy iteration :10.1.1.51.5703:10.1.1.126.4744
addition value iteration policy iteration studies algorithms machine learning ml theory :10.1.1.117.6173
briefly survey exact value iteration algorithms closely related thesis 
introducing algorithms need study properties value functions 
decomposing value functions process obtaining divided steps follows 
max notations interpreted follows 
value function denotes portion reward 
discounted previous value belief state weighted probability observing refer portions function 
belief state maximum discounted expected reward steps starts performs action step summation immediate fraction possible fractions action referred function va function 
equation means maximum actions 
nice property step value functions functions functions 
property means represented sets vectors 
talk parsimonious representations 
operators assists revealing relations parsimonious representations value functions matrix transformation cross sum union 
define operators show constructing matrix transformation operator takes pair set input returns new set 
pair determines jsj theta jsj matrix entry joint probability zjs 
vector ff define vector fi follows state fi ff zjs vector fi said transformed vector ff 
notation denote transformed set ff zjs ff vg sets vectors cross sum phi new set fff fi vg 
words vector phi sum vector vector union sets defined obvious way 
notations value functions equations replaced representing sets respectively set equations 
fr phi phi proven represents value function represents value function set represents value function table visualizes discussed value functions relations 
table assume actions observations 
obvious reasons call sets sets va sets sets respectively 
delta delta delta fr phi phi phi delta delta delta phi fr phi phi phi delta delta delta phi phi phi phi delta delta delta phi fr phi phi phi delta delta delta phi table relations value functions value iteration superset algorithms dp update computes parsimonious representation value function current value function possible methods constructing set method starts superset prunes useless vectors superset 
set algorithms called superset algorithms 
incremental pruning superset algorithm 
constructs supersets sets 
union sets superset parsimonious representation prunes union obtains parsimonious representation specifically dp update incremental pruning consists steps 
constructs set prunes useless vectors right away 
conducts prunings cross sum operations fr phi prune prune prune phi phi delta delta delta phi zm 
sets constructed step takes union sets prunes useless vectors 
yields parsimonious representation prune 
equation denote computations involved incremental pruning update prune ffr phi prune prune prune phi phi delta delta delta phi zm incremental pruning gets name incrementally constructs set pruning operator second step 
removes useless vectors set constructed expects save subsequent computations 
empirical studies shown incremental pruning efficient various exact algorithms dp update 
pseudo code incremental pruning dp update appendix 
phase algorithm works similarly incremental pruning 
differ different ways construct supersets sets vectors representing value functions 
value iteration subset algorithms superset algorithms construct superset prune obtain parsimonious set 
contrast subset algorithms take direction 
algorithms starts empty set 
step useful vector identified added intermediate set parsimonious representation algorithms base called backup operator 
answers question set specific belief state construct vector set tv witness points 
backup operator constructs vector steps follows 
action observation find vector maximum inner product belief state case observed executing action belief state vectors break ties lexicographically 
denote vector fi 
action define vector fi fi js fi 
find vector fi maximum inner product vectors break ties lexicographically 
denote vector backup 
shown backup member parsimonious set vectors obtained performing dp update witness point vector backup 
backup operator subset algorithm works follows 
dp update initializes set tv empty 
step identifies belief state uses backup operator build vector 
vector added tv 
procedure repeats set tv constructed 
example algorithms include pass algorithm relax region linear support witness algorithm :10.1.1.107.9127
algorithms differ approaches systematically search finite set belief states 
shows running example pass algorithm 
pomdp 
belief space extreme belief states 
shows value function computed dp update 
algorithm starts belief state say back vector ff algorithm systematically discovers corner points region 
corner points considered 
back vector ff algorithm finds corner points region abcd 
corner points added list considered 
process repeats set constructed fff ff ff true region running example pass algorithm current research status finding optimal value function optimal policy pomdp difficult infeasible 
optimal value function continuous possibly represented finite set vectors 
known value function finite representation 
literature little research answer question pomdp model determine optimal value function finite representation 
known optimal value function ffl approximable finite set vectors positive ffl 
due property near optimality researchers turn attention ffl optimality 
value function finite representation terms size representing set solving pomdp exactly computationally intractable 
worst case dp update step tv size set tv minimal representation large jaj delta jvj jzj number exponential size consequently dp update tv needs solve big jaj delta jvj jzj linear programs 
exact value iteration algorithms share worst case complexity 
empirical studies exact algorithms compared dimensions 
frequently metric time cost 
problem empirical studies show algorithm faster compute solution quality precision better possible better problem better problem 
fairness comparison testbed established algorithms compared problems testbed 
problems better conclude empirically efficient metric compare algorithms memory requirement 
metric frequently time cost algorithms compute sets representing value functions share space complexity 
basis time cost extensive experiments conducted compare various exact value iteration algorithms 
accepted incremental pruning efficient witness algorithm witness efficient test problems :10.1.1.107.9127
generally accepted result true test problem 
instance linear support algorithm efficient problems small state space 
solving pomdp exactly challenging existing algorithms inefficient 
result toy problems solved practice 
table summarizes problem parameters testbed cpu seconds incremental pruning compute optimality 
see appendix experi see web site www cs brown edu research ai pomdp index html 
mental setups computational environment 
problem jsj jzj jaj set size iterations cpu seconds cheese painting tiger shuttle network aircraft id unknown hours table testbed times give remarks results table 
value iteration terminates iterations 
know single dp update step expensive 
iterations factor making value iteration efficient 
leads research problem possible way reduce number dp updates 
second problems easier solve 
instance problem aircraft id problem parameters size performance difference big 
leads research problem determine problem difficult solve 
thesis works questions 
proposes ways accelerate value iteration 
part propose algorithm reducing number dp updates 
second part study possible conduct dp updates efficiently 
studies provide insights second question directly answer 
chapter modified value iteration chapter proposes algorithm accelerate value iteration reducing number dp updates convergence 
approach design computationally cheap procedure standard dp updates 
design procedure conduct dp updates finite set belief states 
motivation illustrate idea algorithm rewrite value iteration algorithm table table 
table alternate sets represent value functions 
line computes predetermined threshold value iteration terminate 
line conducts dp update compute set current set value iteration needs continue line assigns set set input iteration 
line computes bellman residual line tests stopping condition 
vi ffl 
ffl gamma 

dp update 
max ju gamma 


return table value iteration pomdps strategy reducing number iterations improve value functions additional steps 
additional steps interleaved standard dp updates 
value function improved dp update fed additional steps improvements 
types steps improving value functions expects value functions built reach ffl optimality fewer standard dp updates 
specific propose modify value iteration way shown table 
note change line 
assigning directly pass subroutine point vi assign output subroutine subroutine point vi regarded additional step improving value function 
called point value iteration 
works way value iteration performs multiple point dp updates standard dp updates 
simply mention point dp update computationally cheap procedure 
vi ffl 
ffl gamma 

dp update 
max ju gamma 
point vi 

return point vi 


point 
false 
return table modified value iteration pomdps illustrates basic idea modified value iteration contrast value iteration 
initial value function properly selected sequence value functions produced value iteration converges monotonically optimal value function 
convergence usually takes long time partially standard dp updates indicated fat upward arrows computationally expensive 
modified value iteration interleaves standard dp updates point dp updates indicated thin upward arrows 
pointbased dp update improve value function standard dp update 
complexity lower 
consequence modified value iteration hopefully converge time 
value iteration point update standard update modified value iteration illustration basic idea modified value iteration modified value iteration algorithm raises issues 
procedure point designed 
second stopping criterion point value iteration 
third guarantee stopping criterion eventually satisfied 
fourth guarantee convergence modified value iteration algorithm 
address issues introduce concept uniformly improvable value function 
uniformly improvable value function suppose value functions 
say dominates write belief state value function said uniformly improvable tv set vectors dominates set vectors value function induced dominates induced set vectors uniformly improvable value function induces lemma operator isotone sense value functions implies tv tu lemma obvious known mdp community 
enables explain intuition term uniformly improvable 
suppose uniformly improvable value function suppose value iteration starts sequence value functions generated monotonically increasing converges optimal value function implies tv tv close belief states lemma address issues listed previous section 
lemma consider value functions uniformly improvable uniformly improvable 
proof tv tu lemma 
condition consequently uniformly improvable 
corollary value function uniformly improvable tv modified value iteration algorithm point dp update approximation standard dp update 
designing point dp update try strike balance quality approximation computational complexity 
need guarantee modified value iteration algorithm converges 
backing witness points input vectors set vectors going perform point dp update 
assume know witness point vector vector generated standard dp update associated witness point product 
denote witness point vector ff ff 
point dp update backs points obtains new set vectors see subsection backup operator 
specific begins subroutine 

fi 
ff backup fi 
ff 
ff fi 
fffg 
return subroutine line sure resulting set contains duplicates line takes note fact fi witness point ff tv 
retaining uniform address convergence issues assume input point dp update uniformly improvable require output uniformly improvable 
explain assumption facilitated requirement guarantees convergence modified value iteration algorithm 
discuss requirement fulfilled 
point dp update constructs new vectors backing belief points new vectors members tv 
output point dp update trivially dominated tv 
output dominates uniformly improvable lemma 
question guarantee output dominates consider set resulted 
dominate exist belief state 
consequently exist vector fi fi deltab 
gives subroutine testing dominates case adding vectors 
subroutine called belief points solving linear programs 

fi 

fi 
null 
ff backup 
ff 
fffg 
null subroutine examines vectors 
fi calls subroutine try find belief point fi deltab 
point backs resulting new vector ff line 
property backup operator witness point ff tv line 
vector equals ff 
consequently vector simply added checking duplicates line 
process repeats fi returns null belief points fi deltab 
terminates fi deltab vector fi belief point dominates subroutine fi checks exists vector ff pointwise dominates fi ff fi states ff exists returns null right away 
solves linear program lp fi table see subsection 
returns solution point optimal value objective function positive returns null 
algorithm complete description point dp update 
backs witness points input vectors 
solves linear programs identify belief points backs output dominates input uniformly improvable 
point 


return terms computational complexity point dp update performs exactly jvj backups step jt vj backups second step 
solves linear programs second step 
number linear programs solved upper bounded jt vj jvj usually smaller bound 
numbers constraints linear programs upper bounded jt vj 
stopping point value iteration consider loop point vi table 
starting initial set vectors generates sequence sets 
initial set uniformly improvable value functions represented sets monotonically increasing upper bounded optimal value function 
converge value function necessarily optimal value function 
question loop 
straightforward method compute distance max ju gammav consecutive sets distance falls threshold 
compute distance needs solve delta ju delta jvj linear programs time consuming 
metric expensive compute 
specific loop max ff ju ff gamma ff words calculate maximum difference witness points vectors loop quantity larger threshold bellman residual terminating value iteration number 
experiments set 
convergence modified value iteration sets vectors respectively generated vi table vi table line iteration suppose initial set uniformly improvable 
lemma corollary prove induction uniformly improvable induced value functions increase dominates dominated optimal value function 
known converges optimal value function 
converge optimal value function 
question sure initial set uniformly improvable 
lemma answers question 
lemma min gamma ff vector components singleton set fff uniformly improvable 
proof see appendix 
computing bellman residual modified value iteration algorithm input standard dp update uniformly improvable 
output dominates input 
fact simplify computation bellman residual 
matter fact bellman residual max ju gammav reduces max gammav 
compute quantity goes vectors 
vector vector solves linear program 
quantity simply maximum optimal values objective functions linear programs 
uniformly repeat process time roles exchanged 
empirical studies empirical studies conducted demonstrate effectiveness pointbased improvements reducing number iterations value iteration converge 
addition studied variations point procedure proposed chapter 
effectiveness point improvements effectiveness point dp update determined comparing standard value iteration algorithm vi modified value iteration algorithm vi 
implementation standard value iteration experiments borrowed hansen 
modified value iteration implemented top hansen code 
table shows amounts time vi vi took compute optimal policies test problems 
see vi consistently efficient vi especially larger problems 
times faster vi problems respectively 
aircraft id problem vi able compute optimal policy hours vi able produce optimal policy hours 
cheese paint tiger shuttle network aircraft vi vi table time costs computing optimality various statistics table highlight computational properties vi explain superior performance 
numbers standard dp updates carried vi vi shown rows 
see vi performed standard updates test problems vi performed 
indicates point update effective cutting number standard updates required reach convergence 
consequence vi spent time vi standard updates row 
problem cheese paint tiger shuttle network vi time time vi time quality ratio complexity ratio table detailed statistics vi modified vi row shows numbers point updates carried vi 
see numbers larger numbers standard updates performed vi 
expected 
see recall point update approximation standard update 
set vectors uniformly improvable 
denote sets vectors resulted performing point update belief state tv 
means point update improves necessarily standard update 
consequently point update increases total number iterations number standard updates plus number point updates 
intuitively better point update approximation standard update difference total number iterations vi vi need take 
ratio numbers problem certain extent measurement quality point update problem 
shall refer quality ratio point update 
row shows quality ratios test problems 
see quality point update fairly stable problems 
row shows test problem ratio average time standard update performed vi point update performed vi 
ratios measure certain extent complexity point update relative standard update referred complexity ratios point update 
differences times problems 
summary statistics suggest quality point update relative standard update fairly stable complexity lower 
fact point update drastically reduce number standard updates explains superior performance vi 
close section note vi finds policies quality close predetermined criterion vi usually finds better ones table 
vi checks policy quality standard update vi point updates 
problem cheese paint tiger shuttle network vi vi table quality policies vi modified vi variations point dp update studied possible variations point update 
ideas drawn existing literature 
variations able significantly enhance effectiveness algorithm accelerating value iteration 
brief discussion worthwhile 
discussion provides insights algorithm shows compares related discussed detail section 
quality policy estimated bellman residual 
variations divide categories aimed improving quality point update aimed reducing complexity 
shall discuss 
improving quality point dp update natural way improve quality point update back additional belief points 
explored randomly generated points additional product points projected points :10.1.1.126.4744
additional product points refer points generated various stages standard update excluding witness points 
projected points points reachable step points rise useful vectors 
table shows test problem number standard updates amount time vi took projected points 
see projected points reduce number standard updates cheese shuttle 
increased time complexity test problems network 
kinds points combinations significantly improve vi 
contrary significantly degraded performance vi 
cheese paint tiger shuttle network aircraft table number standard dp updates time cost modified vi takes projected points close examination experimental data reveals plausible explanation 
point update stands reduce number standard updates just time consuming 
possibility reducing number standard updates low reduced effect roughly shift time consuming standard updates earlier 
consequently achieve substantial gains 
hand additional points increases overheads 
reducing complexity point dp update solving linear programs expensive operation point update 
obvious way speed avoid linear programs 
point update solves linear programs backs belief points guarantee uniform 
linear programs skipped way guarantee uniform 
easy solution problem 
suppose set vectors try update uniformly improvable 
set obtained backing witness points done solving linear programs 
set uniformly improvable 
union guaranteed uniformly improvable 
reprogram point update return union hope reduce complexity 
resulting variation called non lp point dp update 
way reduce complexity simplify backup operator idea modified policy iteration 
backing set vectors belief point operator considers possible actions picks optimal greedy policy 
speed simply action belief point previous standard update 
resulting operator called mpi backup operator mpi stands modified policy iteration 
output previous standard update actions 
usually different result point updates standard update 
table shows test problem number standard updates amount time vi took non lp point update standard backup operator 
comparing statistics point update tables see number standard updates increased test problems amount time increased problems 
plausible reasons 
clear non lp point update improve set vectors point update 
consequently effective reducing number standard updates 
second solve linear programs non lp point update produces extraneous vectors 
means need deal large number vectors iterations efficient point update 
cheese paint tiger shuttle network aircraft table number standard dp updates time vi took non lp point update extraneous vectors pruned 
matter fact prune vectors pointwise dominated extraneous experiments 
inexpensive 
pruning extraneous vectors requires solution linear programs expensive 
discussed done efficient way 
results table 
explored combination non lp point update mpi backup operator 
results table 
reason mpi backup operator compromises quality point update 
quality non lp point update improved gauss seidel asynchronous update 
suppose updating set idea vector created backup add copy vector set right away 
hope increase components vectors 
tested idea preparing costs exceed benefits 
reason asynchronous update introduces extraneous vectors synchronous update 
point procedure conceptually simple clean 
compared complex variations effective accelerating value iteration 
related chapter levels point dp update bottom point value iteration middle modified value iteration top 
section discuss relevant levels 
point standard dp updates mentioned subsection point update closely related exact algorithms standard update pass linear support relaxed region 
backup finite number belief points 
difference exact algorithms generate points systematically expensive point update generate points heuristically 
exact algorithms standard dp update 
reduction algorithms incremental pruning generate set vectors parsimonious prune extraneous vectors solving linear programs 
point dp update generates extraneous vectors 
generate duplicate vectors 
duplicates pruned solving linear programs 
witness algorithm stages :10.1.1.107.9127
stage considers actions 
action constructs set vectors finite number systematically generated belief points operator similar backup operator 
second stage vectors different actions pooled extraneous vectors pruned 
proposals carry standard update approximately dropping vectors marginally useful 
idea line empirically evaluated 
recall achieve ffl optimality stopping threshold bellman residual ffl gamma 
idea drop marginally useful vectors various stages standard update keeping error bellman residual falls 
easy see ffl optimality guaranteed way 
tried start large error tolerance hope prune vectors gradually decrease tolerance level 
reasonable improvements observed especially need quality policy high 
approximate updates expensive point updates 
context modified value iteration algorithm suitable alternatives standard updates point update 
point procedure value function approximation point value iteration starts set vectors generates sequence vector sets repeatedly applying point update 
set approximate optimal value function 
various methods approximating optimal value function developed previously 
compare point value iteration dimensions map set vectors interleaved standard updates guarantee convergence interleaved standard updates 
lovejoy proposes approximate optimal value function pomdp optimal value function underlying markov decision process mdp 
function state space 
approximated vector 
littman extend idea approximate jaj vectors corresponds function underlying mdp 
extension introduced dietterich 
idea base approximation underlying mdp called odd pomdp identical original pomdp state fully observable time steps 
suggests approximating value functions fixed suboptimal policies constructed heuristically 
methods start set vectors map set vectors 
easily adapted 
put predetermined limit number hauskrecht conducted extensive survey previous value function approximation methods empirically compared terms criteria complexity quality 
interesting include point value iteration empirical comparison 
done presently focus point value iteration speed value iteration value function approximation method 
output vectors 
consequently convergence guaranteed interleaved standard updates 
fast informed bound function curve fitting softmax curve fitting map set vectors 
differ drastically point value iteration ways deriving set vectors current 
regardless size current set fast informed bound function curve fitting produces jaj vectors action 
softmax curve fitting number vectors determined priori necessarily related number actions 
methods interleaved standard dp updates 
point value iteration may converge :10.1.1.126.4744
cases converge algorithms resulting interleaving standard updates necessarily converge due priori limits number vectors 
grid interpolation extrapolation methods approximate value functions discretizing belief space fixed variable grid maintaining values grid points :10.1.1.51.5703
values non grid points estimated interpolation extrapolation needed 
methods interleaved standard dp updates sets vectors 
grid methods sets vectors 
lovejoy method lower bound optimal value function instance falls category 
method identical point value iteration way derives set vectors current 
point update backs grid points regular grid 
convergence method guaranteed 
algorithm resulting interleaving standard updates may converge 
incremental linear function method roughly corresponds variation point value iteration uses non lp point update subsection augmented gauss seidel asynchronous update :10.1.1.126.4744
method access witness point 
starts purpose backup extreme points belief space supplements projected points 
choice points appears poor leads large number vectors consequently backup process usually stopped convergence :10.1.1.126.4744
previous related modified value iteration basic idea modified value iteration algorithm vi add consecutive standard updates operations inexpensive 
hope operations significantly improve quality vector set reduce number standard updates 
previous algorithms fashion 
differences lie operations inserted standard updates 
reward revision algorithm constructs iteration second pomdp current set vectors 
runs value iteration second pomdp predetermined number steps 
output modify current set vectors resulting set vectors fed standard update 
reward revision expected speed value iteration 
value function represented current set vectors 
second pomdp constructed way shares optimal value function original pomdp optimal 
expect pomdps similar optimal value functions close optimal 
consequently running value iteration second pomdp improve current value function 
inexpensive second pomdp fully observable 
reward revision conceptually complex vi efficient 
reward revision average reduce number standard updates computational time 
tables see differences vi vi larger 
iterative discretization procedure idp similar vi 
main differences 
vi uses point update idp uses non lp point update 
point update vi backs witness points belief points linear programs non lp point update idp backs extreme points witness regions products cheng linear support relaxed region algorithms 
cheng conducted extensive experiments determine effectiveness idp accelerating value iteration 
idp cut number standard updates amount time 
significant reductions tables 
hansen policy iteration pi algorithm maintains policy form finite state controller 
node controller represents vector 
iteration standard update performed set vectors represented current policy 
resulting set vectors improve current policy improved policy evaluated solving system linear equations 
gives rise third set vectors fed standard update 
hansen writings policy improvement includes dp update substep 
dp update considered part policy improvement 
compared performance hansen pi algorithm vi 
table shows test problem number standard updates amount time algorithm took 
comparing statistics vi table see pi performed standard updates vi 
indicates policy improvement evaluation effective point value iteration cutting number standard updates 
terms time pi efficient vi problems significantly efficient problems 
cheese paint tiger shuttle network aircraft table number standard updates time pi took compute optimality possible combine vi pi 
specific probably insert policy improvement evaluation step point updates point value iteration 
accelerate point value iteration vi 
possibility benefits investigated 
value iteration popular algorithm finding ffl optimal policies pomdps 
typically performs large number dp updates convergence dp updates notoriously expensive 
chapter developed technique called point dp update reducing number standard dp updates 
technique conceptually simple clean 
easily incorporated existing pomdp value iteration algorithms 
empirical studies shown point dp update drastically cut number standard dp updates significantly speeding value iteration 
pointbased dp update compares favorably complex variations explored 
compares favorably policy iteration 
chapter value iteration subspace modified value iteration accelerates value iteration reducing number standard dp updates 
chapter study speed value iteration reducing complexity dp updates 
purpose approach restrict value iteration subset belief space 
motivation subset belief space referred belief subspace simply subspace text 
value iteration restricted subspace means dp updates consider belief states subspace 
conducting dp update restricted subspace results advantages 
belief states subspace considered 
yields computational advantage time 
second fewer vectors needed represent value function subspace 
yields representational advantage space 
gives idea dp update subspace versus belief space state pomdp 
belief space segment ab 
shows value function computed standard dp update 
represented vectors fff delta delta delta ff second shows value function computed dp update restricted subspace 
subspace consists segments ac db 
dp update restricted subspace saves time need consider belief states segment cd 
represent value function subspace need keep vectors fff ff ff ff smaller number size set representing value function entire space 
dp update space subspace belief subspace defined arbitrarily value iteration dp updates restricted takes risk quality loss value functions generated 
chapter study specific type belief space 
value iteration restricted value functions generated generated standard value iteration terms subspace 
ease presentation subspace refer particular subspace discussed 
term value iteration subspace mean value iteration restricted particular subspace dp updates subspace similarly 
subsequent sections define subspace establish principles conducting value iteration 
discuss represent subspace prune set vectors 
show implicitly conduct value iteration subspace 
explicit value iteration subspace section establishes principles conducting value iteration subspace 
specifically study define specific subspace conduct dp updates stopping criterion agent decision making value iteration subspace terminates 
section value functions involved explicit form represented sets vectors 
belief subspace mdp value iteration dp update computes value function belief space 
similarly value iteration subspace dp update computes value function subspace 
formulate value iteration subspace needs subspace value function subspace 
start defining subspace 
pomdp model agent acquires knowledge environmental states receiving observations executing actions 
observations reveal exact state information actions executed observations received reasoning states 
formalize idea 
suppose current belief state agent executes action receives observation belief state denoted 
vary belief state space obtain set jb bg 
abusing notation denote set 
words matter belief state agent starts receives performing belief state 
set takes account subspaces possible combinations actions observations 
consists belief states agent encounter 
words agent get set regardless initial belief state 
abusing notation denote set 
closed set sense agent starts belief state set action lead belief state outside set 
thesis say set belief state closed mean sense 
lemma set closed 
obviously pair true subspace set subspace 
corollary means subspace closed sense 
corollary set closed set 
due property subspace able define mdp follows 
mdp referred belief subspace mdp subspace mdp 
ffl state space ffl action space transition model reward model remain subsection 
explicit dp updates subspace subspace mdp value function defined domain 
denote value function step dp update subspace formulated follows 
value function subspace compute value function accomplished dp equation subspace mdp 
max fr theorem means dp updates subspace generate series value functions belief subspace standard dp updates start value functions subspace 
theorem maps belief state value 
proof see appendix 
stopping criterion decision making value iteration subspace starts initial value function 
continues quantity max jv gamma gamma maximum difference value functions subspace smaller 
derive stopping criterion value iteration subspace terminate 
lemma application theorem subspace mdp 
lemma policy arg max fr max jv gamma gamma max jv gamma gamma value function optimal value function subspace mdp 
value iteration terminates outputs value function gamma value function entire space defined step lookahead operation follows max fr gamma value function defined said gamma greedy 
equation means value function subspace induce value function entire space 
value function subspace quality greedy value function 
value function subspace define policy belief state policy said gamma greedy 
interest ask question guarantee near optimality value functions policies entire belief space value iteration subspace terminates 
theorem shows predetermined threshold impacts quality value function gamma gamma greedy value function 
theorem threshold ffl gamma jzj value iteration subspace outputs value function gamma gamma greedy value function ffl optimal 
proof see appendix 
theorem important reasons 
value iteration subspace outputs value function subspace ffl optimal value function entire space induced step lookahead operation 
second implies greedy policy ffl optimal condition met 
see consists possible belief states agent encounters initial belief state 
assumption initial belief state 
may may belong set 
theorem means agent select near optimal action initial belief state subspace 
fact agent select near optimal action belief state entire belief space 
note guarantee ffl optimality threshold set ffl gamma jzj value iteration subspace smaller belief space 
convenience referred strict stopping criterion 
set ffl gamma standard value iteration condition referred loose stopping criterion 
technical issues principle developed value iteration procedure dp updates conducted subspace entire space 
potential benefit subspace smaller belief space excluding belief states considered reduce complexity dp updates 
order potential advantage need develop procedure implicit dp updates subspace 
procedure implemented questions addressed preparatory issues 
subspace 
far notation 
second set vectors represents value function subspace parsimonious set computed subspace 
subsections address questions respectively 
subspace representation subspace representation addresses problem represent subspace 
introduce concept simplex 
belief simplex simply simplex specified list extreme belief states 
simplex psi extreme belief states consists belief states form 
belief state simplex represented linear combination belief states set fb delta delta delta said basis simplex psi 
convenience notation psi denote basis simplex psi 
addition simplex basis fb delta delta delta denoted psi delta delta delta 
main result subspace simplex 
intuition follows 
assume number states pomdp unit vector equals zero 
obvious note set fb delta delta delta forms basis belief state 
intuition set forms basis subspace 
words belief state represented linear combination belief states theorem pair subspace simplex 
proof see appendix 
presentation hides technical complications 
belief state basis action executed impossible agent observe case belief state exist 
number belief states basis smaller number states pomdp model 
accordingly basis formally represented set jp 
convenience denote basis due theorem subspace union simplexes 
convenience subspace refer subset simplex refer subset 
value functions subspace value function entire space represented sets vectors 
similarly value functions simplex subspace possesses property 
representable finite sets vectors 
consequently talk parsimonious representations 
subsection answer questions 
set representing value function simplex compute parsimoniously representation simplex 
second set compute parsimonious representation subspace 
explain importance questions continue discussing value function 
represented vectors 
second set vectors represents value function segment simplex say segment ac 
value function restricted ac vectors ff ff removable 
value function restricted subspace union ac bd vectors removable 
questions discussed address remove useless vectors 
value function simplex answer question key determine vector set useful useless 
question settled compute parsimonious representation set vectors simplex amounts determining vector set keeping useful vectors 
set space vector fi set determine fi needs solve linear program table 
technique directly applied subspace case 
reason existence witness point space necessarily means existence simplex 
setups linear program changed determine vector usefulness 
show 
notation denote set vectors representing value function simplex 
consider vector fi set 
useful belief state simplex fi delta ff delta sufficiently small positive number ff vector set 
belief state exists simplex representable belief states basis 
replace fi delta ff delta condition determining fi usefulness equivalent exists series nonnegative numbers vector ff fi delta ff delta rewriting inequality fi delta ff delta determine fi usefulness procedure table 
optimality linear program reached checks objective positive means exists belief state simplex belief state fi dominates vectors 
belief state witness point fi 
represented solutions values variables lp 
case belief state returned 
cases null returned fi useless vector 
fi 
variables 
maximize 
constraints 
fi delta ff delta ff 
table linear program determine vector usefulness simplex compute parsimonious representation set simplex linear program solved vector 
set need solve jv linear programs 
table subroutine computes parsimonious representation set vectors representing value function simplex 
input arguments set vectors basis simplex set initialized set set empty line 
useful vectors added set sequel 
vector set line procedure called determine 
returns belief state vector added set line 
eventually set parsimonious representation subspace 


fi 
fi 
null 
ffig 
return table parsimonious representation set simplex value function subspace turn second question set compute parsimoniously representing set 
regard twodimensional array sets indexed actions observations 
pair action observation set simplex 
array said parsimonious parsimonious 
compute parsimonious representation procedure compute parsimonious set pair table presents pseudo codes procedure 
computes parsimonious representation input value function temporary variable store copy input store outputs 
layered loop line line computes parsimonious representation set simplex 
line parsimonious returned 





return table parsimonious representation set subspace implicit value iteration subspace section study implicitly conduct value iteration subspace 
key problem implicitly conduct dp updates subspace 
compare complexity dp update belief space versus subspace 
examine issues initial value function setup decision making implicit dp updates subspace problem cast set representing value function subspace compute set dp update tv vector introduced step policy tree 
step policy tree defined pair action mapping set observations set step trees 
vectors induced policy trees constitute set tv vectors representing set defined similarly 
specifically vector defined pair action mapping set observations set precise action mapping ffi vector denoted fi ffi defined follows 
fi ffi js zjs ffi ffi mapped vector observation enumerate possible combinations actions mappings define various vectors 
vectors form set ffi ffi ja ffi ffi set denoted lemma reveals relation set value function lemma set represents value function subspace 
theorem shows set defines value function subspace 
theorem set induces value function subspace 
interesting compares number vectors generated sets size large jaj delta jv jzj see definition set 
size large jaj delta jv jzj clear jv smaller jv dp update subspace generates fewer vectors 
implicit dp updates subspace ii approach computing simplified 
discuss simplification introduce notation dimensional array sets indexed actions observations pair set representing simplex step note differs single set vectors 
say array parsimonious array parsimonious simplex 
convenience refer set exact term 
previous subsection shown construct set terms subspace 
subsection formulate dp update terms individual simplexes 
specifically implicit dp update formulated follows array compute array discussed vector fi ffi defined action mapping ffi 
fact belief state implies ffi restricted vector set new formulation dp updates set available exploited 
altering actions mappings obtains set ffi ffi ja ffi ffi differs mappings 
lemma reveals relation set value function lemma action observation set defined represents value function simplex 
set contains pi jv vectors 
smaller number jaj delta jv jzj size set see number rewritten pi jv due lemma able construct set keeps copy set 
compute parsimonious representation procedure table 
step individual sets contain different number vectors 
interesting property set shows equivalent set sense 
illustrated theorem 
theorem set 
due theorem notation denote value 
theorem dp update computing equivalent computing sense compute value function subspace 
dp update computing considers fewer vectors 
take advantage rest chapter mention dp update value iteration subspace mean conducted approach subsection 
value iteration subspace value iteration subspace starts value function array sets fv sets initialized contain zero vector 
value iteration subspace continues bellman residual max jv gamma gamma smaller 
terminates gamma greedy value function policy belief space defined 
strict stopping criterion theorem met ensured gamma greedy value function gamma greedy policy near optimal 
complexity analysis dp update tv improves values space dp update computing improves values subspace 
initial set subset subset vector inductively set subset analysis suggests advantages conducting value iteration subspace subspace smaller entire space 
fewer vectors needed represent value function subspace 
representational advantage space 
second fewer vectors means lesser degree computational complexity computing vectors needs solve linear programs 
computational advantage time 
advantages strongly depend size subspace 
simplex dp update subspace jaj theta jzj times slower standard dp update 
worst case complexity dp update subspace compared standard dp update 
key problem measure largeness set 
union simplexes helps show simplex related set turns transformation matrix az determine simplex 
matrix dimension jsj theta jsj entry joint probability zjs 
lemma characterizes condition contains number belief states lemma exists bijection simplex space matrix az invertible 
proof see appendix 
lemma conclude matrix az degenerate simplex proper subset true combinations actions observations pomdp model proper subset belief space 
fortunately pomdp condition determined priori starts compute solution 
theorem subspace proper subset belief space matrix az degenerate 
subspace proper subset belief space dp update subspace expected efficient standard dp update 
unfortunately safe due complication 
dp update subspace lead computational overhead intersections simplexes empty 
directly compute dp update 
compute simplex 
belief states intersection simplexes takes account multiple times 
degree overlaps simplexes small expect computational overhead 
summary subspace smaller intersections simplexes negligible value iteration subspace expected efficient standard value iteration 
implementations established principles conducting value iteration subspace 
conduct value iteration subspace techniques existing algorithms dp updates 
section show implement dp update subspace incremental pruning 
entire algorithm value iteration subspace implemented appendix 
consider computing illustrate computing set simplex 
similarly case entire belief space algorithm constructs sets 
union sets representation prunes union obtains parsimonious representation simplex 
specifically dp update incremental pruning consists steps 
constructs set prunes useless vectors right away specifically az 
conducts prunings cross sum operations fr phi phi phi delta delta delta phi zm 
sets constructed step takes union sets prunes useless vectors yields parsimonious representation 
equation denote computations involved incremental pruning update 
amounts replacing third step equation definition second step 
comparing steps subsection note differences 
step set transformed set standard incremental pruning transformed set jv smaller jv means efficiency 
efficiency propagates second step transformed sets operands cross sum operators 
second pruning needed prune sets simplex 
empirical studies section compare performances value iteration belief space versus subspace 
convenience refer standard value iteration vi value iteration subspace ssvi 
discussed subsection complexity analysis know ssvi efficient vi 
grid world problems problem ssvi efficient problem ssvi efficient 
maze problem deterministic observations presents layout robot navigation environment 
locations states goal location 
agent execute actions move actions directions declare goal action 
transition model follows 
move actions nondeterministic achieve intended effect probability lead overshooting probability 
declare goal action change agent position 
introduce observation model note thick lines stand walls thin lines open 
time point robot reads sensors determine current locations 
sensor informs robot wall direction east south west north 
observation string letters 
example location observation means means wall 
examining locations observations find possible strings 
reward model defined follows agent declares goal location receives reward unit location receives penalty combinations actions locations receives reward penalty 
agent required maximize long term discounted sum rewards 
experiments quality requirement ffl set 
incremental pruning compute set vectors representing value functions belief space subspace 
compare vi ssvi iteration maze problem dimensions size set representing value function time cost conduct dp update 
collect results table 
chart depicts time cost dp update logscale vi ssvi exact stopping criterion 
compute optimal value function vi terminates seconds iterations ssvi strict stopping criterion terminates seconds iterations 
note ssvi needs iterations takes time 
performance difference big 
iterations means value function generated ssvi closer optimality 
number iterations vi space ssvi subspace number iterations vi space ssvi subspace comparative studies vi ssvi maze problem surprising result take look matrix az action observation know matrix impacts size simplex 
dimension matrix theta 
convenience refer entry ij product probabilities transition probability js observation probability zjs 
assume observation possible locations 
regardless action executed entries column az non zero 
matrix highly sparse non invertible simplex smaller analysis holds similarly combinations actions observations 
means ssvi accounts small portion belief space 
explains ssvi efficient vi 
addition expect size sets representing value functions subspace smaller sets representing value functions space 
confirmed second chart 
depicts sizes set representing value function generated ssvi vi iteration 
counting size collect sum sizes representing sets simplexes 
note iteration vi generates vectors ssvi 
sizes curves increase sharply iterations stabilize 
size vi reaches peak iteration maximum size ssvi iteration 
size vi times ssvi 
magnitude consistent performance difference 
sizes stabilize sizes sets generated vi ssvi 
compare performance ssvi loose stopping criterion 
curve ssvi strict stopping criterion fewer iterations 
explained shape curves 
time costs sizes ssvi vi increase sharply stabilize 
algorithm ssvi exact stopping criterion conducts iterations ssvi loose stopping criterion 
fact stabilization reached dp updates take time 
maze problem nondeterministic observations revised version maze problem 
designed show value iteration subspace efficient standard value iteration circumstances 
layout navigation problem remains 
actions set enlarged include new stay 
starting location agent performs action change location 
addition agent executes stay receives null observation probability string letters surrounding locations probability 
revised problem complications observation model 
location agent receives string 
due hardware limitations probability wrongly reports string 
case happens location 
declare actions executed agent receives null observation 
move actions leads null observation 
precise observation model move actions summarized table 
locations null reward model changed reflect new design considerations 
assume agent needs pay information states 
purpose agent executes stay really yields cost 
contrast move actions cause cost 
depending locations executes declare receives rewards costs location state receives cost gamma state receives reward receives reward 
stay action attractive yields cost luck leads useful observation states small likelihood 
maze problem compare time costs sizes representing sets vi ssvi 
results collected 
note vi ssvi able run iterations reasonable time limit hours 
compare performance data collected iterations 
chart presents time costs iterations 
run iterations ssvi takes seconds vi takes seconds 
ssvi slower vi problem 
magnitude performance difference big 
number iterations ssvi subspace vi space number iterations ssvi subspace vi space comparative studies vi ssvi noisy maze problem explain consider matrix az determined action stay observation null 
transition matrix identity state lead null observation probability stay executed 
matrix az invertible simplex size belief space ssvi needs account additional simplexes combinations actions observations ssvi efficient vi 
explains performance difference time ssvi vi 
analysis suggests ssvi generate vectors vi iteration size defined sum individual sets 
confirmed demonstrated second chart 
curve ssvi upper side vi 
th iteration ssvi generates vectors vi generates vectors 
related primary idea value iteration belief subspace restrict value iteration subset belief space 
initial belief state possible belief states agent encounter fall subset 
approach constructing subspace application reachability analysis :10.1.1.48.6957
addition reachability analysis approaches conducting value updates subset state space 
approaches include real time dynamic programming rtdp state space decomposition techniques see model minimization technique :10.1.1.117.6173
reachability analysis reachability analysis general technique applicable large state space problems 
problems problem large state space current state number reachable states fly fraction total number states 
reachability analysis exploits fact 
concentrates computational effort subsets entire space 
mention applications context mdps pomdps 
reachability analysis mdp environment 
envelope algorithm value iteration conducted subset state space :10.1.1.48.6957
subset called envelope 
reachable states states envelope added envelope value iteration envelope converges value changes states envelope 
reachability analysis mdps states represented binary variables 
experiments reported show number reachable states smaller problem large space 
computational gains shown great circumstances 
papers propose apply reachability analysis partial observable domains 
assume existence fixed initial belief state 
belief state belief states agent encountered structured decision tree tree 
initial belief state known decision horizon finite number reachable belief states finite 
value updates need conducted set belief states 
due finiteness set procedure value updates computationally cheaper standard dp updates need consider entire belief space 
value updates approaches conducted finite decision horizon proved values near optimal initial belief state purpose bounding optimal near optimal values 
approach differs search approaches assume fixed initial belief state 
relaxing assumption show subsequent belief states form simplex action observation pair 
considering pairs show union simplexes closed set 
say complete set sense belief state exists belief state pair 
hand pair exists belief state 
addition value iteration subspace computes exact values belief states subspace 
furthermore near optimal values entire belief space computed step lookahead operation 
property ensures near optimal action selected initial belief state fact belief state matter belong defined subspace 
online updates rtdp value updates carried belief states agent encounters explores belief space 
mdp environment proved values subset state space converges markov process resulted policy ergodic :10.1.1.117.6173
means mdp nonzero probability visiting matter actions executed 
partially observable domains hard prove optimality convergence literatures reinforcement learning considerable effort direction 
contrast online property algorithms reinforcement learning algorithm chapter line 
computations focus static subset belief space online algorithms computations focus subset belief state encountered agent explores environment 
state space decomposition state space decomposition approach widely alleviate dimension curse problem case large state space mdp 
typical idea solve mdp mdps smaller size solutions approximate original mdp 
idea borrows theoretical foundations operations research combinatorial optimization 
methods cited differ dimensions strategies split state space ways combine solutions smaller mdps form solution original mdp 
state space decomposed set smaller subsets states 
decomposition subset mdp defined solved 
local solutions individual smaller mdps utilized construct global solution original mdp 
proposal solve mdps region subset state space 
macro action local policy acts certain regions 
mdp defined states boundaries certain regions 
mdp defined way significantly smaller state space 
solution sake approximating original mdp 
flexible decomposition algorithm works similarly 
common rationale value iteration subspace algorithms relying state space decomposition smaller space implies tractable computational challenge 
value iteration subspace original pomdp exists need construct mdps pomdps 
algorithms state space decomposition new mdps need defined needs solve global solution constructed original pomdp 
inherently algorithms exploiting state space decomposition hierarchical fashion 
attempts machine learning field fashion find solutions mdps pomdps see 
conducting dp updates subspace approach accelerate value iteration 
yields advantages time cost space 
chapter study carry value iteration subspace 
establish theoretical principles develop pragmatic algorithms 
addition describe condition priori determine value iteration subspace bring advantages pomdp 
chapter informative pomdps chapter studies class pomdps observation restrict world small set states 
pomdps belief subspace known smaller belief space 
value iteration accelerated conducting dp updates efficiently 
accelerated reducing number iterations 
pomdps informativeness discuss characteristics navigation problem 
experiments reported previous chapter show value iteration significantly accelerated conducting subspace see subsection 
chapter show additional regularities underlying problem exploited speed value iteration 
agent perform move actions plus declare goal action 
assumption time point robot receives string letters 
total observations 
agent receive string world different locations 
example states string observed 
enumerate possible observations set states agent receive observations table 
observations states observations states hand agent receives string knows world state 
observation restricts world small range world states 
fact observation restrict world states world 
reason say pomdp informative 
general agent perceives world observations 
starting state agent executes action receives observation world states categorized classes observation model states agent reach states 
formally set possible states zjs 
denote az pair said informative size js az smaller jsj 
intuitively pair informative executing receiving agent knows true world states restricted small set 
observation said informative informative action giving rise intuitively observation informative gives agent idea world states regardless action executed previous time point 
pomdp said informative observations informative 
words observation agent receives provides idea world states 
observation received time point pomdp agent albeit imperfect idea world 
informative pomdps observation restricts world small set states agent receives observation knows world state outside small set 
words states outside set agent zero beliefs 
consequently observation restrict belief states belief subspace 
union subspaces determined observations consists possible belief states agent encounter 
value iteration carried union 
previous chapter expect value iteration accelerated union smaller belief space 
addition value iteration accelerated integrating point improvements reduce number iterations convergence 
reducing complexity dp updates section shows reduce complexity dp updates informative pomdps 
approach restrict belief subspace take additional advantage underlying pomdps 
belief subspace previous chapter know action observation subspace simplex 
context informative pomdps belief states simplex nice property explored 
belief state update equation state set az belief state equals 
nonzero beliefs distribute reachable states 
reveal relation belief states set az define subspace oe oe saz az proven belief state set 
subset oe pair 
trivial see belief simplex 
convenience refer oe simplex oe simplex respectively 
union oe simplexes denoted oe 
distinction refer sets oe subspace oe subspace 
lemma true subset oe 
lemma pomdp model oe 
interest compare simplex oe simplex pair simplexes specified list extreme belief states oe simplex intuitive geometric meaning 
easy see corner point oe unit vector probability mass state 
extreme belief states oe simplex corner points belief space 
contrast extreme belief states simplex interior points 
example shown illustrate relation oe simplex oe subspace belief space 
pomdp states observations 
belief region tetrahedron abcd extreme belief states 
simplicity letters refer states 
notation means set states agent observe assume sets independent actions 
specifically fa cg fa dg fa dg fb dg 
pomdp oe simplexes facets abc abd acd bcd 
form surface tetrahedron oe subspace 
belief simplexes belief space belief space belief simplexes belief subspace value functions subspaces value function represented set jsj dimensional vectors 
restricted simplex oe value function oe simplex 
preserves piecewise linear convex property represented set vectors 
denote set oe informative pomdps restriction yields advantage representation 
specifically pair beliefs states outside set az zero vector oe js az components 
typically value function belief space represented great number vectors 
represents value function simplex oe yield tremendous savings vectors smaller dimensions 
collection fv oe set oe associated underlying states set az defining value function oe oe subspace oe exhibits little difficulty 
underlying set az contains different states different pairs 
sense defines value function computing inner product vector belief state possibly dimension vector differs belief state 
simplicity notation oe dimensional array sets vectors similarly needs determine value belief state identifies simplex containing belief state computes value corresponding set vectors 
set oe representing value function oe computing parsimonious set exploit low dimensional property set 
vector fi set oe useful belief state oe fi delta ff delta ff oe gamma ffig small positive number 
particular procedure table set determine vector usefulness 
input arguments vector fi set oe vectors set az states 
exists belief state simplex oe fi dominates vectors procedure returns 
witness point fi fi useful vector 
procedure returns null fi useless 
fi oe az 
variables 
maximize 
constraints 
fi delta ff delta ff 
saz table linear program determine vector usefulness set oe simplex differs lp table aspects 
vectors set oe js az dimensional 
number variables js az table number jsj 
second need set basis extreme belief states subspace oe 
vector basis unit 
transformation procedure table unnecessary 
lead computational advantages lp 
set oe vectors oe simplex compute parsimonious representation needs solve jv oe linear programs 
taken vector set 
procedure oe az return parsimonious representation set oe value iteration subspace due lemma fact oe subspace superset subspace oe subspace closed set 
formulate belief subspace mdp state space oe subspace 
consequently able conduct value iteration oe subspace 
convenience notations value functions oe oe sets oe oe implicit dp update computes array oe array oe compute set oe construct set oe possible pair 
procedure constructing set subsection notation replaced oe 
proved oe induces value function simplex oe 
collectively oe induces value function oe value iteration subspace oe starts value function oe array sets oe sets initialized contain js az dimension 
value iteration continues residual smaller value functions oe 
residual falls threshold max max oe jv oe gamma oe ffl gamma jzj value iteration terminates 
similar result theorem ensures oe gamma greedy value functions policies ffl optimal 
practice bellman residual determined solving linear programs 
informative pomdp low dimensional property value functions implies fewer variables computing bellman residual sets 
addition dp update subspace generates fewer vectors means fewer linear programs need solved 
incremental pruning conduct dp updates implementation similar appendix exceptions 
oe simplex associated underlying set states simplex basis simplex 
implementations value iteration oe subspace underlying set states replaces basis simplex pseudo codes 
second prune procedure replace procedure occurs 
dp updates subspace versus oe subspace subsection gives comparison value iteration subspace oe subspace 
principles established previous chapter foundations algorithms 
general subspaces smaller belief space algorithms enjoy advantages time space 
informative pomdps subspace clearly smaller belief space 
addition informative pomdps low dimension property exploited accelerate value iteration 
interesting note dp updates oe subspace account larger subspace subspace 
definition oe simplex depends observation model simplex depends transition model 
different actions say observation seldom case 
actions effects transition model observation model 
true observation actions identical 
hand case oe oe obser vation happens true pomdps observation model depends states 
words probability zjs independent written zjs 
property exploited accelerate value iteration 
observation define simplex oe 
account jzj oe simplexes 
value iteration subspace need account jaj delta jzj simplexes 
empirical studies report experiments maze problem 
convenience vi ssvi refer value iteration algorithms discussed previous chapter infovi value iteration oe subspace 
compare performances vi ssvi infovi 
ssvi infovi report results strict stopping criterion 
assume observations received deterministically 
set algorithms able converge reasonable time limit hours 
compare number vectors representing value functions time costs dp updates 
results collected 
chart collects timing results axis logscale 
see infovi significant faster ssvi ssvi significant faster vi 
compute optimality vi takes seconds ssvi takes seconds infovi seconds 
shows informative characteristics exploited accelerate value iteration significantly 
gather statistics numbers vectors vi collect numbers vectors representing value function entire belief space 
ssvi collect sum numbers vectors representing individual value functions simplexes 
sum jaj delta jzj numbers 
infovi additional number iterations vi space ssvi subspace infovi subspace number iterations vi space ssvi subspace infovi subspace comparative studies vi ssvi infovi maze problem regularities oe subspace independent actions exploited 
report number vectors collect jv oe delta number vectors infovi computes 
second chart depicts numbers vectors generated algorithms iteration 
see infovi produces significant fewer vectors ssvi ssvi produces significant fewer vectors vi 
example iterations near algorithms convergence vi generates vectors representing value functions belief space ssvi produces vectors representing value functions infovi produces vectors representing value functions oe 
difference numbers ssvi infovi explained way collect statistics 
difference plus fact linear programs solved algorithm infovi lower dimensions explains performance difference time cost 
interest compare sizes oe ssvi infovi iteration 
subset oe expects oe contains vectors iterations near convergence ssvi generates vectors representing value function simplex 
case oe simplex results 
means oe contains belief states problem cause sharp increasing number vectors representing value functions simplexes 
reducing number iterations accelerate value iteration informative pomdps section integrates point improving procedure reduce number iterations subspace 
backup operator value iteration subspace dp update computes oe oe computes set oe pair 
conceivable easy oe usually consists infinite number belief states 
consequently necessary design point procedure improve oe fed dp update subspace oe 
generate heuristically finite set belief states simplex back set obtain set vectors 
key problem array oe belief state oe compute vector set oe define backup operator context 
backup vector built steps follows 

action observation find vector oe maximum inner product 
vectors break ties lexicographically 
denote fi 
action construct vector fi set fi fl saz zjs fi zjs equals js zjs 

find vector fi maximum inner product vectors break ties lexicographically 
denote fi 
lemma shows fi vector oe lemma vector fi constructed set oe comparing standard backup operator subsection note differences 
set oe standard backup operator set 
second pair dimension vector oe js differences mean backup vector efficiently constructed context belief subspace 
point value iteration subspace backup operator show integrate point improvements value iteration oe subspace 
integral algorithm interleaves steps standard dp update subspace oe point update 
point update computes set say oe set say oe point update needs compute set oe simplex oe 
set oe constructed making set oe pair 
witness points associated vectors set oe backup 
second additional belief states heuristically generated back vectors point procedure 
new vectors added set oe value function induced set oe dominates set oe case point update improving oe terminates simplex oe 
gain improvements point value iteration developed multiple steps point procedures 
preliminary steps sets representing value functions individual simplexes fed dp update subspace 
due additional improvements expect number dp updates oe subspace reduced value iteration converges 
empirical studies subsection reports experiments revised version maze problem 
experiments reported appendix pomdps states 
problem main purpose compare time costs value iteration oe subspace integration point improvements 
convenience refer infovi respectively 
maze problem nondeterministic observations layout problem remains previous section 
observation model modified noisy observations allowed 
certain locations agent receives ideal string probability may receive string probability 
noisy string differs ideal letter 
particular locations observations observation probabilities tabulated follows 
assume observations independent actions executed 
locations chart shows time costs number iterations ssvi infovi 
note visualize data clearly curve shifted iterations axis 
significant differences performance algorithms 
compute optimality infovi runs iterations takes seconds 
point procedure integrated conducts steps standard dp updates subspace takes seconds 
note infovi accelerated drastically reducing number iterations convergence 
point procedure effective cut number iterations value iteration subspace 
interesting compare ssvi infovi original vi algorithms 
problem characteristics exploited vi run iterations takes seconds 
conceivable vi solve problem reasonable time limit 
time costs ssvi infovi demonstrated 
ssvi terminate reasonable time limit 
data iterations take seconds 
number iterations infovi takes seconds 
shows infovi faster ssvi problem 
number iterations ssvi subspace infovi subspace infovi pb subspace number iterations ssvi subspace infovi subspace infovi pb subspace comparative studies vi infovi numbers vectors generated ssvi infovi depicted second chart 
curve shifted iterations horizontal direction 
infovi collect number vectors computed iteration collect number vectors generated dp updates oe subspace 
note iterations ssvi vectors infovi oe subspace larger subspace 
due fact 
observation model independent actions infovi needs compute vectors jzj oe simplexes ssvi considers jaj delta jzj simplexes 
elevator problem see appendix 
regular grid see appendix 
related informative pomdps value iteration subset belief space related previous perspectives applicability model special pomdp classes approaches solve pomdps value iteration carried belief subspace 
model applicability assumption observation restricts world small set states validated problem instances literature 
cover problems need start issue state space representation 
problems implemented experiments explicitly enumerate states 
known flat space representation efficient called compact representation terms space requirement 
compact representation state space state described set variables fluents propositional logic 
variable take values domain 
suppose state described binary variables 
number states increases exponentially number variables 
state space pomdp represented compactly 
literature pomdp instances compact state space representation informative pomdps 
example slotted aloha protocol problem 
state system consists number backlogged messages channel status 
channel status observable possible assignments form observation space 
hand system access number backlogged messages 
maximum number backlogged messages set possible values channel status number states delta particular assignment channel status restrict system states delta similar problem characteristic exists non stationary environment model proposed reinforcement learning 
problems algorithm chapter accelerate finding near optimal solutions 
special pomdps solutions solving pomdp generally computationally intractable advisable study pomdps special characteristics 
hope characteristics may exploited find near optimal solutions efficiently 
special pomdps examined literature 
memory resetting pomdps assume exists actions informing agent unique state 
actions performed agent knows world definite state 
initial belief state known optimal policy execute actions periodically number belief states agent visit finite set 
accordingly dp updates set cheaper 
citation studies pomdp class memory resetting actions 
class assumption remains agent visits finite number belief states 
regional observable pomdps assume time point agent restricted handful states 
similar assumption informative pomdps 
motivation proposing model solution approximate pomdp 
relation regional observable pomdps complementary competitive 
value iteration subspace especially suitable algorithm pomdps 
suggested experiments drastically speed procedure finding solutions regional observable pomdps 
second note incremental pruning efficient find solution regional observable pomdp original pomdp 
provides insights case 
value updates subspace observed defining value function belief subspace exhibits lower complexity entire belief space 
works pomdps compact state space representation 
states depicted set variables classified observable variables hidden variables 
noted belief states reached certain combinations observable variables hidden variables 
previous chapter systematically studied value iteration subspace 
formally describe belief subspace combination actions observations show complete set belief states 
second formally develop value iteration algorithm 
third discuss stopping criterion 
know guarantee near optimality output value function value iteration subspace terminates 
chapter apply principles special pomdp class 
knowledge studying medical problem proposing pomdp solutions problem cited uses approximate algorithms solve pomdp 
chapter studied informative pomdps observation informative sense provides information states 
value iteration subspace previous chapter directly applied pomdps class 
exploit improvements low dimension property lets linear programs fewer variables point improvements reduce number iterations 
chapter near discernible pomdps chapter studies classes pomdps 
pomdp class pairs actions observations restricting world small set states 
pomdps belief subspace belief space 
alleviate complexity value iteration propose anytime value iteration algorithm 
value iteration continues subspace considered dynamically grows larger 
second pomdp class pairs actions observations restricting world states high likelihood 
adapt anytime algorithm general class 
pomdps informative pomdp assumes observation restricts world small set states 
words pair action observation informative 
practice pomdps exhibit different problem characteristic pairs actions observations informative pairs non informative 
consider maze world problem 
agent execute actions move actions declare goal action 
assume time point observation string letters freely available agent 
consider different setting 
new action look added agent control set 
action dedicated gathering information environments 
action performed agent receives string 
due existence action move actions dedicated changing environmental states 
move actions executed null string received provides information world states 
example pairs move actions null observations noninformative pairs look action strings informative 
convenience observation led action informative say action informative information rich 
non informative informative poor 
maze problem goal achieving move actions information poor information gathering look action 
pomdps characteristic said near discernible agent knows world possible states executes informative action 
discernible pomdp means uncertainty world states vanishes informative action observation realized observation reveals identities world states 
near discernible pomdps generalization discernible pomdps informative actions executed agent get rough exact idea states uncertainty vanishes sense 
value iteration subspace yield advantage pomdps 
fact move actions non informative implies subspace determined move null size belief space 
proposal solve relies interesting intuition follows 
suppose agent starts initial belief state 
achieve goal agent execute move actions 
agent executes actions uncertainties states increase actions non informative 
hand get higher long range rewards agent need declare goal 
doing non goal state lead penalty agent ascertain agent execute look action 
consequently intuitively agent execute information rich action sequence information poor actions 
suggests consider possible histories related agent navigation 
pair sequence pairs actions observations determines subspace 
union subspaces associated histories subspace 
value iteration conducted subspace 
know steps executing goal achieving actions agent execute information gathering action 
words needs find tradeoff goal achieving actions information gathering actions 
due try see approach 
histories taken account subspace grows 
histories subspace value functions history sequence ordered pairs actions observations 
usually denote history number pairs actions observations referred length history 
note pair action observation history length 
suppose agent starts belief state denote history length delta delta delta 
time point agent observes executing action belief state updated time point 
belief state time denoted 
varies initial belief state set consists possible belief states agent time point jb bg convenience denote set 
length say degenerates previous notational convention 
know history length subspace simplex 
similar argument holds subspace 
lemma history subspace simplex 
intuition theorem 
suppose belief states delta delta delta unit vectors form basis belief space history realized denote resulting belief state 
set ji delta delta delta forms basis simplex 
denote basis question related history value function represented set vectors compute parsimonious representation simplex 
turns similar procedure table 
context history occurrences basis replaced set histories usually denoted define subspace union simplexes induced histories set 
subspace denoted 
defined 
space progressive value iteration section proposes space progressive value iteration spvi algorithm near discernible pomdps 
conducts value iteration dynamically growing belief subspace 
termination condition met spvi terminates outputs set vectors agent decision making 
algorithmic structure spvi designed anytime algorithm 
works subspaces determined sets histories 
consists basic steps step conduct value iteration subspace determined current set histories step expand subspace account histories 
subspace considered union simplexes determined histories set histories implies larger belief subspace 
algorithm design reflects intuition discussed earlier agent execute information rich action sequence actions 
difficult priori determine steps non informative actions agent execute informative action 
possible way overcome difficulty gradually increase length histories 
value iteration carried subspace determined set histories 
value iteration terminates current subspace checks see stopping criterion met 
spvi terminates 
increases length histories takes longer histories account 
value iteration conducted expanded subspace determined larger set histories 
notations order 
set histories th expansion denote subspace determined 
occasionally denote set 
value function constructed value iteration denoted emphasis step value function standard value iteration algorithm 
notations briefly characterize basic steps spvi value iteration step spvi construct value function set subspace subspace expansion step constructs subspace current set histories pseudo code table implements spvi solving near discernible pomdps 
line initializes set histories initial subspace value function threshold loop line line consists main steps line conducts value iteration subspace line expands subspace algorithm terminates stopping criterion met line 
note assume global variable 
procedure expanded procedure 
spvi 
initialize ffl gamma 




stopping condition met 
return table space progressive value iteration subsequent subsections dedicated value iteration set histories belief subspace expansion stopping criterion respectively 
value iteration subspace value iteration subspace set vectors subspace threshold intend compute improved set vectors 
value iteration subspace improves value function repetitively 
step referred dp update 
denote value function steps improvements initially set notations dp update computes set set subspace dp update computing considers simplex determined history set history computes set vectors 
union denoted set vectors representing value function 
dp updates consider belief states subspace set approximation real optimal value function step 
issue related value iteration subspace stopping criterion 
value function computed subspace subspace longer closed set contraction property residual necessarily hold 
touches issue convergence 
simple method overcome difficulty set union set sequence value functions fu monotonically increases 
hand set subset set representing value function belief space step sequence upper bounded optimal value function 
value iteration subspace converge 
due convergence value iteration proceeds residual value functions small simplex 
residual denoted max max ju gamma concise written max ju gamma nature criterion quantity smaller threshold value iteration terminates 
table presents pseudo codes value iteration subspace 
set representing value function subspace threshold line initializes line line constructs set vectors history line denotes basis simplex 
line set constructed union histories set line tests stopping condition 
condition satisfied line returns set gamma 






max ju gamma gamma 
return gamma table value iteration subspace pseudo codes procedure appendix implemented conducting dp updates simplex 
pseudo codes needs replace notations notation represents jaj delta jzj value functions set representing value function 
subspace expansion basic step spvi subspace expansion 
value iteration subspace terminates answers determine subspace value iteration conducted larger subspace 
discussing step look initialize subspace value iteration start 
suppose set information rich actions denoted ir set information poor actions denoted ip accordingly observations categorized classes ir ip relate set intuitively small size 
purpose set set step histories actions ir observations ir formally ir ir subspace small due informative property 
expand subspace set note subspace determined set histories 
ensure superset method incorporate histories superset expand set histories intuition agent execute information rich actions sequence information poor actions 
remember union set computed value iteration step 
say associated history vector history sufficiently long action associated vector information rich action due intuition 
case vectors extend history appending possible non informative pairs actions observations 
procedure said extending history 
extending history yields ja ip delta jz ir new histories said extensions possible strategy expand set histories follows 
vector set examined 
vector fi associated action information poor add extensions obvious difficulty expansion number histories increases exponentially size ip ip alleviate problem heuristic method 
extends maximal histories set history said maximal set extensions set 
heuristic method checks vectors set vector fi associated action information poor maximal extended extensions added set sure superset histories added set 
subspace expansion set implemented table 
table line adds histories set line consider vector fi set 
condition met line newly created histories added set line appending non informative pairs actions observations 
notation fi history means history associated vector fi fi action associated action 
line returns subspace determined expanded set 

fi set 
fi history maximal fi action information poor 
ip theta ip 

return table subspace expansion spvi note set pairs information rich actions observations 
approach expanding set histories information poor pairs appended histories 
set important characteristics 
histories start pair information rich actions observations 
second history pair remaining pairs 
characteristics important 
history begins information rich pairs belief simplex determined large 
second due restriction heuristic rule expanding sets histories number histories sets increase fast 
stopping criterion step spvi carries value iteration subspace 
time permits spvi increases subspace considered 
anytime algorithm spvi terminated hard deadline reached 
current set vectors purpose decision making 
approach decision making similar standard value iteration algorithm 
stopping criterion set follows 
sufficiently large amount time spvi take account histories possible 
case optimal policy requires information rich actions executed sequence information poor actions spvi able find policy 
optimal policy property consider set sufficiently expansions history sets subspaces vector maximal history prescribe information rich action belief state simplex determined history 
true vectors set spvi terminates 
optimality assume spvi eventually converge 
subsection argue spvi find near optimal policies 
final belief subspace second value functions greedy policy 
way spvi expands subspace fact final subspace imply closed sense starting inside policy lead belief states outside set policies closed 
prove near optimal policies close max pb belief state pomdp discussion transformed mdp belief space denote mdp define mdp state space possible actions belief state include lead belief states outside respectively restrictions imagine carrying value iteration starting value function obtained iteration 
fact closed implies legitimate policy greedy 
implies max jv gamma max jv gamma value iteration terminated quantity small near optimal policy fact policies restricted policies allows conclude near optimal original pomdp policies intuition near optimal policies prescribe information rich action belief states long gives reason believe set contains near optimal policies 
case policy near optimal policies 
wish note arguments rely strongly intuitions 
drawn true cases 
experiments indicate spvi find near optimal policies subspace expansions 
empirical results tested spvi number problems 
results encouraging 
discuss results simple maze game 
states locations plus terminal state 
agent needs move location declare goal 
actions move actions plus look declare goal 
look action information rich actions information poor 
move actions allow agent move nominal directions chance achieving intended effects moving agent step certain direction 
moving maze walls leaves agent original location 
actions rewards 
locations declare goal action yield rewards respectively moves game terminal state 
states cause state transitions reward 
look action rewards cause state transitions 
produces strings letters terminal state 
strings deterministically received agent 
spvi works anytime manner primary interest compare quality generated value function time cost optimal value function 
unfortunately availability optimality strongly depends tractability problem 
facilitate comparison modified maze problem tractable able compute near optimality 
modified problem referred maze original maze 
particular maze locations deleted maze 
result optimal value function computed modified value iteration algorithm chapter 
spvi value iteration converges subspace simulation conducted determine quality policy 
simulation consists trials 
trial starts random initial belief state allowed run steps 
average reward trials measurement policy quality 
maze chart depicts quality policies spvi belief subspaces time taken 
note data spvi integrated point improvements 
simulation time included 
data point belief subspace 
shown subspace necessarily quality policy subspace 
quality best policy far 
data way reason 
subspace grows spvi computes better better value functions 
known better value function necessarily imply better policy 
words policy larger subspace necessarily better smaller subspace 
knowing fact naturally want keep best policy far 
quality policy time seconds maze optimal spvi qmdp time seconds maze spvi qmdp performance spvi near discernible pomdps optimal policies computed modified value iteration algorithm seconds 
provides benchmark judge close policies spvi point integration optimal 
see spvi near optimal policy maze seconds subspace expansions time seconds 
spvi interesting study number subspace expansions number iterations value iteration converge subspace 
maze spvi converged expansions 
maximum length histories considered 
means agent needs execute look action steps 
spvi converges final number simplexes 
number histories considered 
see heuristic method reduce number histories compare numbers histories generated heuristic exhaustive approaches 
number non informative actions number non informative observation 
product 
exhaustive method number histories increase exponentially product 
number simplexes spvi start product number informative actions number informative observations th subspace expansion number histories generated exhaustive method second row table presents number histories generated heuristic method expansions experiments 
clear heuristic effective cutting number histories 
th expansion histories iterations vectors cpu seconds table detailed statistics maze spvi spvi starts initial subspace iteratively increases subspace 
notice policies spvi appear better optimal policy 
probably due randomness simulation 
subspace conducts value iteration starting value function obtained previous subspace 
value iteration subspace needs iterations converge spvi efficient 
third row table shows number iterations subspace grows 
note subspaces value iterations take dp updates iteration carried newly expanded subspace 
means value functions generated value iteration subspaces earlier serve approximations value functions generated subsequent subspaces 
forth row presents number vectors generated spvi subspace 
note number vectors grows slowly 
result modified value iteration generates vectors final iteration 
contrast spvi terminates generates vectors 
fact final set vectors optimal final subspace see spvi generates fewer vectors represent value function quality 
summary anytime algorithm spvi able compute near optimal value function bounded time requirement 
maze maze modified value iteration converge hours 
hand spvi able find policy average reward seconds subspace expansion policy average reward seconds subspace expansions 
optimal average reward get maze maze reasons believe value functions spvi near optimal 
due unavailability optimal value function compare quality policy generated spvi qmdp 
simple approximation method performance shown fairly compared approximation methods :10.1.1.126.4744
computationally cheaper spvi 
second chart clear spvi better policies qmdp 
poor quality qmdp approximation test problems easily explained 
symmetric nature domain mains agent easily confuse left right halves 
policies produced qmdp simply sophisticated information gathering strategy 
maze spvi converges expansions final number simplexes 
detailed statistics table 
second chart similar behaviors spvi observed 
reward obtained simulation second expansion quantity little changes believable spvi able construct near optimal value function bounded time requirements 
th expansion histories iterations vectors rewards cpu seconds table detailed statistics maze spvi generalization near discernible pomdps near discernible pomdps assume existence informative actions 
actions move world restrictive set states 
section relax assumption define general class pomdps show spvi adapted pomdps 
approximate spvi action informative observation action gives rise probability zjs close zero small number states 
words informative actions move world small range states high likelihood occasionally move world states 
informative actions non informative actions previous definition concept generalization informative actions 
study pomdps actions classified non informative informative ones 
pomdp class generalization near discernible pomdps 
intuitively pomdps uncertainty states vanishes informative actions executed 
adapt spvi pomdps 
due reasons algorithm called approximate spvi 
simplify exposition assume informative action denote action notation stands set observations action give rise 
difficulty applying spvi near discernible pomdps set dz possible states large cardinality 
case belief simplex dz oe previous notation large consequently complexity spvi high starts belief subspace dz overcome difficulty introduce number ffi close zero define ffi az fs ffig definition information actions set ffi dz small 
define ffi az fb ffi az spvi starts belief subspace ffi dz subspace smaller dz belief space way choosing initial belief subspace gives rise issue belief simplex current subspace new simplexes generated informative action necessarily subset initial belief simplex ffi dz belief subspaces expanded way spvi number simplexes increase quickly 
avoid problem new belief simplexes generated informative action simply discarded 
empirical studies evaluate performance approximate spvi modified problems described previous section 
experiments pomdp larger state space reported appendix maze problems changes observation probability look action 
original problems look produces location string characters probability 
say string ideal string location 
modified problems look produces location ideal string location probability 
probability produces null observation 
probability produces string ideal location differs ideal string current location characters 
modifications look longer information rich action 
produces null observation nonzero probability states 
modified maze specifically modified maze problem observation model look action 
seen action non informative problem 
conceivably problem solved spvi reasonable time limit 
approximate spvi set threshold ffi defining set ffi az locations null performance spvi modified maze shown chart 
results collected spvi integrated point improvements 
intuitively maximum average rewards get modified problems original problems 
quick comparison figures suggest policies spvi subspace expansions near optimal 
better policies qmdp 
spvi terminates subspace expansions seconds 
detailed statistics conducted results table 
third row gives number iterations spvi converge value iteration conducted subspace 
exclude iterations point improvements data 
fifth row gives reward obtained simulation 
note second subspace expansion rewards close quality policy time seconds maze spvi qmdp time seconds maze spvi qmdp performance spvi pomdps final expansion approximate spvi takes seconds 
confirms belief anytime algorithm approximate spvi able find value function bounded time requirement 
th expansion histories iterations vectors rewards cpu seconds table detailed statistics modified maze approximate spvi modified maze modified maze spvi converged subspace expansions cpu seconds 
observe reward obtained simulation second third subspace expansion close final expansion 
spvi takes thousands seconds convergence generates fairly policy seconds 
policy compared second chart 
clear policy generated spvi better qmdp 
detailed statistics gathered table 
results suggest approximate spvi able find policy bounded time requirement 
th expansion histories iterations vectors rewards cpu seconds table detailed statistics modified maze spvi related chapter develop anytime algorithm special class pomdps 
discuss related model applicability anytime planning algorithms anytime dynamic programming 
model applicability near discernible pomdps assume actions classified ones information poor ones 
assumption reasonable realistic domains 
domain robot path planning problems 
problems agent required reach goal state 
partially observable domain separate related tasks agent faces moving goal figuring current location 
task handled move actions second look actions 
class actions goal achieving ones usually information poor second gathering ones usually information rich 
problem class modeled pomdps 
second domain machine maintenance problems 
problems agent usually execute set actions manufacture examine inspect replace 
agent hardly gets information machine status examines quality manufactured products machine components 
extreme case machine components replaced agent surely knows machine excellent situation 
manufacture information poor replace information rich remaining actions medium ground 
near discernible pomdps suitable model problems 
anytime planning algorithms spvi anytime planning algorithm 
converges optimality limiting case possible histories considered optimal policy consists sequence information poor actions action 
anytime algorithms developed literature 
include anytime synthetic projection algorithm envelope algorithm planner 
anytime synthetic projection algorithm incrementally constructs conditional plans stochastic domains 
starts initial plan may executed error 
time permits improves plan able handle situations 
algorithm consists basic steps 
step traverse search sequence actions situations identify sequence lead agent goals 
second step discover possible deviations desired goal identify sequence actions situations agent recover deviations time permits 
envelope algorithm developed decision theoretical planner specifically markov environment 
envelope set states 
algorithm consists basic steps projection algorithm 
step restrict planning state space contains states envelope plus state regarded group states outside envelope 
step extend envelope include states agent plan quality states envelope state 
time permits agent interleaves basic steps 
envelope includes states algorithm converges optimality standard value iteration policy iteration 
envelope algorithm regarded special case general study time critical domains 
extended probabilistic logic planning uncertainty 
spvi works decision theoretic planner 
envelope algorithm works decision theoretic planning concerns completely observable domains spvi partially observable domains 
algorithms subspace considered grows including states belief states entire space 
new states belief states identified reachability analysis 
reachable current states belief states performing actions completely observable domains receiving observations partially observable domains 
spvi differs projection algorithm aspects 
example projection algorithm attempts maximize probability goal attainment spvi attempts maximize long term discounted accumulative rewards 
anytime dynamic programming belief subspace spvi works grows time 
time permits spvi takes belief states account 
dynamic growth subspace important characteristic algorithms real time dynamic programming reinforcement learning 
real time dynamic programming conducts value updates set belief states agent encounters fly :10.1.1.117.6173
set subset belief space 
time permits belief states encountered added set consideration 
set grows time 
algorithms reinforcement learning explore idea online updates ways 
dyna system developed sutton time point agent reaches state values associated state updated 
addition dyna randomly chooses constant states updates associated values 
values agent selects executes action reaches state 
procedure updating values repeats 
dyna queue algorithm prioritized sweeping maintain priority mechanism keep track priorities states :10.1.1.134.8196
time point randomly choosing states updates values associated states highest priorities 
mechanism viewed attempt concentrate limited computational resources states having largest errors 
prioritized sweeping algorithm extended generalized prioritized sweeping 
spvi differs algorithms ground 
spvi expands belief subspace newly included belief states step reachable current state 
discussed earlier belief states form simplex 
includes possibly uncountably belief states subspace expansion step 
contrast online updates time point belief state agent current added 
consequently number belief expansions spvi number trials agent need near optimal criterion met 
chapter studies near discernible pomdps 
problem characteristic actions categorized non informative ones informative ones 
conducting value iteration fixed subspace yields computational advantage 
propose anytime algorithm spvi pomdps 
basic steps value iteration subspace subspace expansion 
show conduct steps 
arguments spvi able find near optimal value function subspace considered bounded time requirement 
experiments show value function serves approximation value function entire belief space 
chapter chapter summarizes contributions thesis suggests extensions 
contributions pomdps provide elegant framework ai planning problems effects actions nondeterministic exact information states available 
finding optimal near optimal solutions pomdps challenging research problem 
inefficiency current solution algorithms limited realistic applications model 
thesis works speeding value iteration popular algorithm finding solutions pomdps 
thesis unified concept belief subspace 
subspace reduce number dp updates value iteration converge 
subspace finite set belief states 
starting proposed modified value iteration algorithm 
contribution thesis 
specifically ffl design point procedure improve set vectors subspace 
value function induced output set vectors improves input set belief space 
ffl concept uniform 
concept ensure improvements led point procedures standard dp updates consistent direction optimality 
ffl develop modified value iteration algorithm 
efficient standard algorithm guarantees near optimality 
second subspace reduce complexity dp updates value iteration 
subspace may vary finite set uncountable set belief states 
starting propose value iteration subspace 
second contribution thesis 
specifically ffl develop theoretical framework value iteration subspace 
framework pair action observation determine subspace union subspaces closed set 
mdp union formulated serves foundation value iteration subspace 
near optimal value function mdp derive near optimal value function policy belief space 
ffl algorithm value iteration subspace 
proved subspace determined pair action observation simplex subspace value iteration union simplexes 
subspace representation procedure developed compute parsimonious set set vectors simplex 
ffl identify condition determine subspace proper subset belief space 
case pomdp value iteration subspace expected take advantages space time 
framework motivates special pomdps 
regularities subspaces exploited design efficient value iteration algorithms 
studies special pomdps algorithms form third contribution thesis 
specifically ffl study informative pomdps observation restrict world small range states 
pomdp subspace determined model smaller belief space 
common advantages value iteration subspace pomdp class takes advantages value functions simplex represented lower dimensional vectors turn yields efficiency solving linear programs 
ffl study near discernible pomdps actions leading world small set states 
pomdp subspace determined model believed close belief space size 
propose anytime algorithm pomdp class 
starts small subspace gradually expands 
ffl study general class near discernible pomdps actions leading world small set states high likelihood 
anytime value iteration algorithm aforementioned adapted solving pomdp class 
extensions despite progress ability battle computational complexity pomdps limited 
extensions related thesis 
modified value iteration algorithm requires standard dp updates 
hand existence standard dp updates means guarantee near optimality algorithm 
hand limits capability solving larger pomdps single step dp update take long time 
direction investigate properties point value iteration approximation algorithm 
idea generate set belief states sets backup vectors able approximate step value functions better 
tested idea randomly generating set belief states 
preliminary experiments show quality approximation convergence problem 
alleviate problems needs avoid pure randomly generating set belief states 
connection possibility exploit ideas family grid algorithms 
studies turned generate belief states depending information pomdp model 
theoretical framework value iteration subspace provides foundations pomdp classes studied thesis 
addition study framework possible connections suggest interesting topics 
ffl informative pomdps oe subspace value iteration depends solely observation model expected smaller belief space 
general framework subspace depends transition model observation model 
possibilities theoretical perspective 
observation model informative transition model define subspace 
action moves world range states subspace small 
second transition model observation model informative subspace defined smaller belief space 
theoret ical possibilities practical applications worthwhile studies 
ffl various approaches accelerate value iteration asynchronous dynamic programming technique received attention mdp research see 
idea conduct dp updates subset state space sweep entire space 
crucial issue select subset 
idea directly integrated framework value iteration subspace 
simplexes subsets belief space 
manage conduct dp update simplexes union 
bellman residuals individual simplexes select simplexes dp step usually chooses simplexes larger residuals 
reason follows 
values belief states simplexes improved significantly potential improvements 
ffl integration point procedure framework subspace leads interesting variations 
reduce number dp updates value iteration subspace point procedure designed additional steps improving value functions subspace 
modified value iteration 
differences dp updates belief space replaced subspace argument applies point procedure 
second framework implications algorithms pomdp solving machine learning 
instance grid algorithms belief states outside subspace excluded grid affect values belief states 
algorithms reinforcement learning selection states belief states crucial issue value updates 
framework provide useful guidelines excluding belief states 
third case study second point tested simplification spvi direction pure point value iteration 
specifically step value iteration subspace spvi conduct entire subspace 
iteratively improve value functions backing extreme belief states simplexes 
simplification able find value functions quality extremely short time limit near discernible pomdps general model studied 
ffl currently framework subspace proposed pomdps represented 
take advantage compact representation direction adapt framework structured pomdps 
possible expects value iteration subspace able solve larger pomdps 
appendix proofs proof lemma proof denote value function induced singleton set 
belief state tv max max max gamma gamma gamma value function singleton set uniformly improvable 
proof theorem consider step dp updates 
dp update tv computes value function current dp equation 
right hand side belief state 
belong subspace notation interpreted value function subspace belief space explicit introduce notation condition belief state maps value 
fact value function subspace 
dp equation rewritten max fr dp equation subspace mdp 
subspace 
induction theorem follows 
proof theorem suffices show max jv gamma ffl gamma 
jv gamma max fr gamma max fr gamma gj jr gamma gamma gamma gamma gamma jzj max jv gamma gamma gamma jzj ffl gamma ffl step value functions replaced definitions ffl second step greedy action necessarily gamma greedy ffl forth step condition ffl steps trivial 
proof theorem suppose belief state 
seen fb delta delta delta basis belief space trivially belief state delta delta delta represented cardinality set jp 
loss generality enumerate set delta delta delta suffices show psi delta delta delta 
prove prove psi delta delta delta psi delta delta delta 
prove 
suffices show belief state belong simplex psi 
exist belief state 
purpose define constants follows 
ffl delta delta delta kg probability observing action executed belief state formally zjs js 
ffl probability observing action executed formally zjs js 
ffl delta delta delta kg define constants going prove 
true represented linear combination vectors basis proved 
start 
replaced definition state zjs js due property belief state rewrite equation delta delta delta kg zjs js trivially zjs js definition rewriting equation definition equation yields regarded form vector equation means prove belief state represented linear combination vectors basis 
means simplex psi 
prove prove belief state simplex psi subspace 
suffices show exists belief state 
psi exist set nonnegative 
replace definition state zjs js zjs js denote zjs js constant zjs js exchanging summation order making property bs zjs js define belief state follows bs bs seen zjs js zjs js proved psi exists belief state 
consequently 
prove 
proof lemma proof matrix az divide entry zjs probability observing agent starts executes action previous time point 
resulting matrix denoted proved exists belief state qb viewed vector form 
consequently bijection exists invertible 
invertible az invertible 
appendix sets parsimonious representation appendix discuss problem prune useless vectors set 
techniques monahan algorithm algorithm proposed 
monahan algorithm algorithm considers vector set 
vector lp set solved determining 
suppose vector considered fi set solves linear program set lp fi table 
returns belief state fi useful 
fi useless 
algorithm solves jvj linear programs program jvj constraints 
pseudo code algorithm table 
note temporary set initialized initialized empty 
procedure returns contains useful vectors parsimonious representation 
prune 

fi 
lp fi 
null 
ffig 
return table monahan pruning algorithm algorithm likewise algorithm maintains intermediate set increases useful vector added 
constraints intermediate set original set specifically vector fi constraints involve vectors intermediate set subset difference lies lp optimality reached vector fi considered directly added output set 
optimal belief point back vector see subsection 
new vector pruned original set added intermediate set 
pseudo code pruning procedure table 
note set applies 
prune 

fi 
lp fi 
null 

return table pruning algorithm algorithm solves number lps monahan 
number constraints varies jvj useful vectors identified 
clearly number smaller monahan algorithm 
algorithm efficient monahan 
appendix computing bellman residuals discuss computing bellman residual space subspace 
bellman residual space suppose sets note residual max ju gamma maximum max gamma max gamma 
say quantity difference dominates second difference dominates shows sets sets contain vectors fff ff ff ff ffi fi fi left shows areas dominates right shows areas dominates shaded areas 
difference dominates maximum vertical differences areas 
bellman residual sets vectors areas rely witness regions vectors 
notation ff denote witness region ff set notation ff vector quantity max gamma rewritten max ff max fi max ff fi ff gamma fi notation ff fi intersection witness regions 
means difference dominates maximum differences vectors intersection witness regions 
explain means 
left ffl area vectors ff fi 
corresponding region belief states ff fi 
differences denoted ff gamma fi intersection 
ffl second area divided subareas vertical dash dotted line ff fi ff fi 
third area divided subareas vertical line ff fi second ff fi 
subareas described similarly 
compute bellman residual needs compute residuals order 
ffl residual ff fi max ff fi ff gamma fi ff fi ffl residual vector ff set max fi max ff fi ff gamma fi ffl residual sets side max gamma ffl residual sets sides max ju gamma bellman residual sets 
easily seen compute bellman residual sets needs solve delta ju delta jvj linear programs 
show quantities computed 
quantity computed procedure ff fi table 
sets linear program purpose 
variables belief state additional objective difference ff fi 
sets constraints 
line sets constraints describing witness region ff set line sets constraints witness region fi set line trivial constraint defining belief state 
lp optimality reaches checks positive objective denotes quantity returned 
procedure returns zero 
second quantity computed procedure ff table 
computes maximum differences ff vector fi set considers fi set line 
line procedure ff fi called compute differences vectors 
third quantity computed procedure table 
computes maximum differences ff set set line considers vector line computes difference ff set procedure needs solve ju delta jvj linear programs 
bellman residual computed procedure residual table 
computes maximum differences sets sides 
line difference side computed line difference side computed 
obviously ff fi 
variables state 
maximize ff gamma fi 

constraints 
ff ff deltab ff 
fi fi deltab fi 
states ff 

fi 
ff fi 

return 

ff 
ff 

return residual 





return table bellman residual belief space procedure needs solve delta ju delta jvj linear programs 
bellman residual subspace section discuss computing bellman residual sets vectors subspace 
suppose arrays sets needs consider residual simplexes 
procedure computing residual simplex similar space 
specifically compute bellman residual needs compute residuals order 
ffl residual ff fi simplex max ff fi ff gamma fi ff restriction witness region ff simplex 
convenience denote similarly ffl residual vector ff set simplex max fi max ff fi ff gamma fi ffl residual sets side max gamma 
ffl residual sets sides max ju gamma bellman residual sets 
ffl residual subspace max ju gamma easily seen compute bellman residual sets needs solve ju delta jv linear programs 
show quantities computed 
quantity computed ff fi table basis simplex 
sets linear program purpose 
variables coefficients objective difference ff fi 
sets constraints 
line sets constraints describing witness region ff set simplex line sets constraints witness region fi set line trivial constraint defining coefficients 
lp optimality reaches checks objective 
positive returned 
procedure returns zero 
second computed ff table 
computes maximum differences ff vector fi set considers fi set line 
line procedure ff fi called compute differences vectors 
third quantity computed table 
computes maximum differences ff set set line considers vector line computes difference ff set procedure needs solve ju delta jvj linear programs 
forth quantity bellman residual simplex computed procedure table 
computes maximum differences sets sides 
line difference side computed line difference side computed 
obviously procedure needs solve delta ju delta jvj linear programs 
bellman residual subspace computed procedure subspace table 
computes maximum differences sets simplexes 
obviously solves ju delta jv linear programs 
ff fi 
variables 
maximize ff gamma fi delta 

constraints 
ff delta ff delta ff 
fi delta fi delta fi 

ff 

fi 
ff fi 

return 

ff 
ff 

return 





return 





return table bellman residual subspace appendix incremental pruning space versus subspace appendix pseudo codes value iterations belief space subspace 
implemented incremental pruning 
standard incremental pruning incremental pruning dp update uses operators matrix transformation cross sum union 
implement show construct parsimonious set representing value function representing matrix transformation takes set pair action observation returns transformed set 
pseudo codes procedure transform table 
input set transforms vector line added new vector set az transformation done set az pruned line returned line 
cross sum operators takes sets vectors returns set vector sum vector input set vector set 
pseudo codes procedure table 
returned set non parsimonious 
union operator takes union set returns parsimonious set union 
pseudo codes procedure table 
input jaj sets 
loop line line constructs union line union pruned 
pruned set returned line 
transform 
az 

ff 
fi fi 
az az fffg 
az prune az return az 

ff 
fi 
fff fig 
return fu 

jaj 

prune 
return table operators incremental pruning compute cross sums series sets incremental pruning interleaves procedures cross sum prune 
means useless vectors removed constructed 
procedure ip table illustrates technique 
input jzj sets 
loop line reflects idea 
line set cross sum operator line new set pruned 
procedure repeats sets considered 
returned set parsimonious 
incremental pruning construct set resulting dp update referred incremental pruning dp update 
dp update construct directly 
constructs set action sets built parsimonious representation obtained pruning union 
construct set incremental pruning uses matrix transformation cross sum operators 
fixed action set construct set az set built applying incremental pruning sets immediate reward vector 
procedure incremental pruning dp updates implemented subroutine table 
line set constructed line incremental pruning technique construct set line sets construct set ip fv az 
az 
jzj 
az 
prune 
return 


az transform 
fr delta phi ip fv az 
fv 
return table incremental pruning dp update algorithm incremental pruning subspace section show incremental pruning conduct value iteration subspace 
algorithmic structure showing exploit incremental pruning value iteration subspace look algorithmic structure 
value iteration subspace basic steps dp updates termination testing 
iteratively improves value function maximal difference value functions sufficiently small subspace 
algorithmic structure table 
algorithm referred 
takes arguments input value function set zero vector subspace policy precision ffl 
line value function set initial value function threshold ffl computed 
dp update line procedure discussed soon 
termination condition tested line procedure computes bellman residual value functions subspace 
procedure implemented appendix 
ffl 
ffl gamma jzj 





gamma 
return gamma 



return table value iteration subspace procedure computes array sets doing computes simplex 
step referred dp update simplex 
sets simplexes obtained form array table 
line procedure called conduct dp update simplex 
subsection show incremental pruning construct set incremental pruning simplex standard dp update incremental pruning constructs set vectors representing value function operations matrix transformation cross sum union purge 
dp update simplex discuss operations adapted construct set value function basis simplex matrix transformation 
set vectors transformed set computed transforming vectors 
approach transforming vector equation 
transformed set obtained parsimonious representation computed pruning set simplex 
table gives pseudo codes procedure 
fed set basis simplex returns transformed set 
set contain transformed set 
lines computes transformed vector add set contains transformed vectors line calls procedure return parsimonious representation simplex 
line outputs minimal set 
cross sum 
operator remains standard cross sum 
computes new set sets vectors 
distinguishing purpose procedure compute cross sum set sets 
pseudo codes table 
union 
operator applies array sets computes minimal representation union 
consists sub steps merge sets form union second prune union simplex 
pseudo codes procedure table 
arguments input set sets fu basis simplex 
conducts sub step line second sub step line 



ff 
fi fi 
fffg 
return 


return fu 

jaj 


return table operators dp update simplex incremental pruning technique compute parsimonious representation cross sum array sets vectors 
array sets vectors interleaves procedures cross sum prune compute minimal representation cross sum sets 
procedure table presents pseudo codes incremental pruning context simplex 
input array sets fu az jz zg basis simplex output minimal representation phi az line temporary initialized set array 
line sets array added consideration 
cross sum operator applies set temporary result recorded purge operator applies doing sets array obtain final result output 
fu az 
az 
upto jzj 
az 

return 


az 
fr delta phi fu az 
fu 
return table incremental pruning dp update simplex operators incremental pruning technique context simplex able conduct dp update simplex set basis simplex compute set standard dp update dp update simplex takes steps construct set incremental pruning simplex constructs set say action forms set pruning union action associated sets 
construct set uses matrix transformation operator operators 
transformation step set pool transformed matrix az determined action observation transformed set denoted az cross sum step sets az immediate reward vector construct set technique incremental pruning 
procedure incremental pruning simplex implemented table 
referred 
uses array sets construct minimal set matrix transformation step line incremental pruning line union purge line 
worthwhile mentioning line action set need transformed 
different transform set need transformed 
appendix experiments informative pomdps appendix provide informative pomdp examples somewhat large state space 
states 
problems value iteration subspace need take considerable amount time compute near optimality value function 
point procedure integrated compute value function quality significantly efficiently 
elevator problem problem formulation elevator operates floor building 
serves residents accommodating building 
patterns passengers arrival high arrival rate st floor low nd floor low arrival rate st floor high nd floor equal arrival rates 
time varies morning night day patterns change certain probability distribution 
keep track pick drop requests elevator sets buttons control panel buttons record pick drop requests st floor buttons keep information second floor 
elevator aware floor stays 
order fulfill requests floor elevator move upwards downwards reaches floor elevator stay floor passengers finish entering exiting 
objective elevator minimize certain penalty cost long run 
problem formulated pomdp framework 
state consists components arrival pattern pick requests floors drop requests floors elevator position 
variables denote components respectively 
state assignment variables 
arrival pattern takes possible values different patterns 
passengers wait lobby floor pick request set unset 
passengers elevator intend get st floor dropoff request st floor set unset 
similarly second floor variables pick drop requests set accordingly 
elevator st floor component set second floor component variable set second 
number states 
observation components components states component arrival pattern 
observations 
elevator may execute actions go go stay 
restriction floor perform go second floor action go performed 
uncertainty stems probabilities changes arrival patterns 
elevator executes go component evolves follows 
arrival pattern changes predetermined probability distribution 
components pick drop requests remain 
position changes second 
effects action go described similarly 
elevator performs action stay arrival pattern changes similarly 
requests floor fulfilled corresponding variables re versed 
instance passengers get st floor elevator floor performs stay passenger able get 
say elevator fulfills drop requests floor 
instance passengers enter elevator second floor elevator performs action stay second floor 
say pickup request second floor fulfilled case 
allowable elevator fulfill requests time point 
example pick drop requests st floor elevator performs action stay passengers enter exit time point 
say fulfills requests 
note action stay performed elevator fulfill request 
variable arrival pattern changes time moment elevator changes states probabilistically performing action 
elevator informed partial knowledge state transition 
elevator performs action knows changes components states variables pick drop floor position 
know arrival pattern component state observations reveal identities states 
partial observability formulation 
possible arrival patterns observation reveals elevator stays possible state enumeration arrival patterns 
pomdp informative 
performance elevator measured different ways diverse applications 
define measurement minimizing unsatisfactory degree service elevator provides 
encode reward model 
time point elevator serves requests pick requests st nd floor drop requests st nd floor 
performing action requests unfulfilled elevator receives penalty 
instance elevator un fulfills pick drop request set st floor receives penalty 
objective elevator minimize total discounted penalty long run 
setups convenience denote arrival patterns 
experiments transition probabilities set table 
basically pattern remains probability changes 
empirical studies collect time costs actual number vectors generated iteration algorithms vi ssvi infovi 
results 
chart shows time costs iterations 
algorithms set compute optimal value function 
exclude iterations point improvements 
see vi ssvi means solve problem infovi solve sufficient time able solve easily 
runs uses loose stopping criterion 
strict threshold close precision parameter 
iterations ssvi takes seconds infovi seconds 
performance difference drastic 
infovi proceeds takes number iterations vi space ssvi subspace infovi subspace infovi pb subspace number iterations vi space ssvi subspace infovi subspace infovi pb subspace performance vi ssvi infovi elevator seconds iteration 
evident infovi able compute near optimal value function sufficient time 
point improvements integrated able terminate seconds steps dp updates subspace 
algorithms terminate reasonable time limit compare data th iteration 
iteration able gather statistics vi 
iteration vi takes seconds ssvi seconds seconds 
second chart depicts number vectors generated iteration tested algorithms 
ssvi collect sum numbers vectors representing value functions jaj delta jzj simplexes 
infovi collect sum numbers representing vectors jzj simplexes 
problem simplex independent transition model 
chart see vi generates tremendously vectors ssvi infovi generates fewer vectors 
experiments terminates produces vectors 
reason compare numbers vectors th iterations algorithms 
iteration vi generates vectors 
ssvi number respectively 
dp updates proceed conceivable number vectors generated vi increase sharply dp updates extremely inefficient 
final number generated vectors small fact point improvement effectively reduces number iterations subspace possible compute near optimal value function small time limit turns 
regular grid problem formulation grid world problem 
states 
location marked goal state 
grid divided rows columns 
agent perform nominal direction moving actions declaring success action 
performing moving action agent reaches neighboring location probability stays location probability 
reasonable constraints imposed moving actions 
instance agent location moves north stays location 
declare success action change agent location 
performing action agent informed column number certainty 
problem observations 
move action incurs cost 
agent declares success location receives reward locations receives cost 
columns grid world pomdp informative observation restrict world locations 
empirical studies compare ssvi infovi dimensions time costs actual number vectors computed iteration 
comment stopping criterion applicable 
number iterations ssvi subspace infovi subspace infovi pb subspace number iterations ssvi subspace infovi subspace infovi pb subspace performance ssvi infovi regular grid results collected 
chart demonstrates difference time costs 
see infovi faster infovi turn infovi faster ssvi 
compute optimal value function terminates seconds iterations dp updates subspace 
exclude iterations point improvements 
run ssvi infovi convergence compare time costs available data 
instance iterations ssvi takes seconds infovi takes seconds 
data show infovi efficient ssvi significantly slower 
second chart helps explain performance algorithms 
depicts number vectors generated algorithms 
terminates generates vectors 
reason compare numbers iterations ssvi infovi 
data show number ssvi number infovi 
reason number infovi smaller ssvi follows 
infovi count sum numbers vectors representing value function jzj simplexes ssvi need consider jaj delta jzj simplexes 
difference infovi ssvi infovi solves linear programs smaller dimensions 
differences explain infovi faster ssvi 
appendix experiment discernible pomdps appendix reports experiments approximate spvi office environment 
environment modeled floor plan author home department layout shown 
main office csd office environment problem formulation black bars represents doors grey bars represent walls display boards 
states locations plus terminal state 
robot execute actions maze problem declare goal action replaced new action beep 
transitions probabilities specified way 
action look leads null observation 
look action yields observation strings letters location indicating directions door empty wall wall display board 
pairs locations identical ideal observations 
example locations ideal observation 
ideal observations locations unique 
total different strings 
location look produces ideal string location probability 
probability produces null observation 
probability produces string ideal location differs ideal string current location character 
robot receives reward location reward location don want robot lot noise 
move actions bring reward lead robot bump walls doors 
rewards 
reward look action 
robot needs get location beep main office come hand robot mail 
empirical studies run approximate spvi problem conduct simulations value functions generated 
simulation consists trials trial starts random initial belief state allowed run steps 
average reward trials measurement quality policies derived value functions 
presents results quality time costs 
see approximate spvi policy average reward seconds 
manually terminated algorithm conducted steps subspace expansion 
data second expansion steps rewards simulation 
far obtained third expansion step difficult say close polices optimal 
compared solutions generated qmdp policies generated approximate spvi clear better 
time seconds spvi qmdp performance approximate spvi office navigation problem table gives detailed statistics number histories iterations vectors subspace expansion 
note number iterations third column conducting value iteration subspace point improvements 
column number pointbased steps excluded 
value iteration subspace takes dp updates 
forth column number vectors provides idea approximate spvi takes long time problem 
generates great number vectors 
third expansion uses vectors represent value function subspace 
step expansion histories iterations vectors rewards time table statistics csd environment approximate spvi appendix computational environment experiments conducted ultrasparc ii machine 
dual cpus mb ram 
codes written executed unix operating system 
solving linear programs commercial package cplex 
parameters experiments discount factor set round precision set gamma andre friedman parr generalized prioritized sweeping proceedings advances neural information processing systems nips 
astrom optimal control markov decision processes incomplete state estimation journal mathematical analysis applications vol 
pp 

barto bradtke singh learning act real time dynamic programming artificial intelligence vol :10.1.1.117.6173
pp 

bellman dynamic programming 
princeton university press 
bertsekas gallagher data networks 
englewood cliffs prentice hall 
boddy anytime problem solving dynamic programming proceedings national conference artificial intelligence aaai 
boddy dean solving time dependent problems proceedings th international joint conference artificial intelligence ijcai 
bonet geffner planning incomplete information heuristic search belief space proceedings th international conference artificial intelligence planning systems aips pp 
aaai press 
boutilier brafman geib structured readability analysis markov decision processes proceedings th conference uncertainty artificial intelligence uai 
boutilier dean hanks decision theoretic planning structural assumptions computational leverage journal artificial intelligence research vol 
pp 

boutilier dearden goldszmidt stochastic dynamic programming factored representations artificial intelligence vol 
pp 

boutilier poole computing optimal policies partially observable decision processes compact representations thirteenth national conference artificial intelligence aaai portland oregon 
brafman heuristic variable grid solution method pomdps proceedings national conference artificial intelligence aaai pp 

de complexity partially observed markov decision processes theoretical computer science vol 
pp 

cassandra optimal policies partially observable markov decision processes tech 
rep cs department computer science brown university 
cassandra exact approximate algorithms partially observable markov decision processes 
phd thesis department computer science brown university 
cheng algorithms partially observable markov decision processes 
phd thesis university british columbia vancouver bc canada 
choi yeung zhang environment model nonstationary reinforcement learning advances neural information processing systems pp 

condon complexity stochastic games information computation vol 
pp 

crites barto improving elevator performance reinforcement learning advances neural information processing systems nips vol :10.1.1.17.5519
mit press cambridge ma 
dantzig wolfe decomposition principle dynamic programs operations research vol 
pp 

darrell pentland active gesture recognition partially observable markov decision processes proceedings thirteenth ieee international conference pattern recognition icpr 
dayan convergence td general machine learning vol 
pp 

dean givan model minimization markov decision processes proceedings national conference artificial intelligence aaai pp 

dean givan kim solving planning problems large state action spaces proceedings th international conference artificial intelligence planning systems aips pittsburgh pennsylvania 
dean kaelbling kirman nicholson planning deadlines stochastic domains proceedings th national conference artificial intelligence aaai pp :10.1.1.48.6957

dean kaelbling kirman nicholson planning time constraints stochastic domains artificial intelligence vol 
pp 

dean lin decomposition techniques planning stochastic domains proceedings th international joint conference artificial intelligence ijcai pp 

dearden boutilier abstraction approximate decision theoretic planning artificial intelligence vol 
pp 

dynamic programming models applications 
prenticehall 
finite state markovian decision processes 
cambridge university press new york 
drake observation markov process noisy channel 
phd thesis massachusetts institute technology 
drummond bresina anytime synthetic projection maximizing probability goal satisfaction proceedings national conference artificial intelligence aaai pp 

eagle optimal search moving target search path constrained operations research vol 
pp 

fikes nilsson strips new approach application theorem proving artificial intelligence vol 
pp 

varaiya multilayered control large markov chains ieee transactions automatic control vol 
pp 

geffner bonet solving large pomdps real time dynamic programming working notes fall aaai symposium pomdps pp 

givan dean model minimization regression propositional strips planning proceedings th international joint conference artificial intelligence ijcai 
goldsmith mundhenk complexity issues markov decision processes proceedings 
ieee conference computational complexity 
hanks utility models goal directed planners computational intelligence vol 

hansen improved policy iteration algorithm partially observable mdps proceedings advances neural information processing systems nips 
hansen finite memory control partially observable systems 
phd thesis dept computer science university massachusetts amherst 
hansen heuristic search cyclic graphs proceedings national conference artificial intelligence aaai 
hansen feng dynamic programming pomdps factored state representation proceedings th international conference artificial intelligence planning scheduling aips breckenridge colorado 
hauskrecht incremental methods computing bounds partially observable markov decision processes proceedings national conference artificial intelligence aaai pp 

hauskrecht planning control stochastic domains imperfect information 
phd thesis department electrical engineering computer science massachusetts institute technology 
hauskrecht value function approximations partially observable markov decision processes journal artificial intelligence research vol :10.1.1.126.4744
pp 

hauskrecht fraser modeling treatment heart disease partially observable markov decision processes american medical informatics association annual symposium computer applications health care pp 
orlando florida 
hauskrecht fraser planning treatment heart disease partially observable markov decision processes artificial intelligence medicine vol 
pp 

hauskrecht meuleau boutilier kaelbling dean hierarchical solution markov decision processes macro actions th conference uncertainty artificial intelligence uai pp 

horvitz breese henrion decision theory expert system artificial intelligence journal approximate reasoning vol 
pp 

jaakkola jordan singh convergence stochastic iterative dynamic programming algorithms neural computation vol 
pp 

jaakkola singh jordan reinforcement learning algorithm partially observable markov problems proceedings advances neural information processing systems nips vol 

kaelbling hierarchical reinforcement learning preliminary results proceedings international conference machine learning icml pp 
amherst 
kaelbling littman cassandra planning acting partially observable stochastic domains artificial intelligence vol :10.1.1.107.9127

kearns mansour ng approximate planning large pomdps reusable trajectories proceedings th international joint conference artificial intelligence ijcai 
kearns singh finite sample convergence rates learning indirect algorithms advances neural information processing systems nips 
koenig simmons xavier robot navigation architecture partially observable markov decision process models artificial intelligence mobile robotics case studies successful robot systems kortenkamp bonasso murphy editor pp 

koller parr policy iteration factored mdps proceedings sixteenth conference uncertainty artificial intelligence uai pp 

korf macro operators weak method learning artificial intelligence vol 
pp 

korf real time heuristic search artificial intelligence vol 
pp 

kushmerick hanks weld algorithm probabilistic planning artificial intelligence vol 
pp 

kushner 
chen decomposition systems governed markov chains ieee transactions automatic control vol 
pp 

kushner mathematical programming control markov chains international journal control vol 
pp 

optimization theory large systems 
macmillan 
littman witness algorithm solving partially observable markov decision processes tech 
rep cs department computer science brown university providence rhode island usa 
littman cassandra kaelbling learning policies partially observable environments scaling proceedings international conference machine learning icml pp 

littman goldsmith mundhenk computational complexity probabilistic planning journal artificial intelligence research vol 
pp 

singh eligibility traces find best memoryless policy partially observable markov decision processes proceedings international conference machine learning icml 
lovejoy survey partially observable markov decision processes annals operations research vol 
pp 

lovejoy computationally feasible bounds partially observed markov decision processes operations research vol 
pp 

lovejoy suboptimal policies bounds parameter adaptive decision processes operations research vol 
pp 

luce raiffa games decisions critical survey 
new york wiley 
mundhenk goldsmith results partially observable markov decision processes journal artificial intelligence research vol 
pp 

madani condon hanks undecidability probabilistic planning partially observable markov decision processes proceedings national conference artificial intelligence aaai 
mcallester rosenblitt systematic nonlinear planning proceedings th national conference artificial intelligence aaai pp 

mccallum hidden state reinforcement learning instancebased state identification ieee transactions system man cybernetics part cybernetics vol 
pp 

meuleau kim kaelbling cassandra solving pomdps searching space finite policies proceedings fifteenth international conference uncertainty artificial intelligence uai 
monahan survey partially observable markov decision processes theory models algorithms management science vol 
pp 

moore atkeson prioritized sweeping reinforcement learning data real time machine learning vol :10.1.1.134.8196
pp 

mundhenk goldsmith allender complexity finite horizon markov decision process problems tech 
rep department computer science university kentucky 
nilsson probabilistic logic artificial intelligence vol 
pp 

papadimitriou tsitsiklis complexity markov decision processes mathematics operations research vol 
pp 

parr flexible decomposition algorithms weakly coupled markov decision problems proceedings th conference uncertainty artificial intelligence uai 
parr russell approximating optimal policies partially observable stochastic domains proceedings th international joint conference artificial intelligence ijcai pp 

parr russell reinforcement learning hierarchies machines proceedings advances neural information processing systems nips mit press 
penberthy weld ucpop sound complete partial order planner adl proceedings third international conference principles knowledge representation reasoning pp 

peng williams efficient learning planning dyna framework adaptive behavior vol 
pp 

peot smith conditional nonlinear planner proceedings st international conference artificial intelligence planning systems aips pp 

optimal infinite horizon undiscounted control finite probabilistic systems siam journal control optimization vol 
pp 

finite memory estimation control finite probabilistic systems 
phd thesis department electrical engineering computer science massachusetts institute technology 
precup sutton multi time models temporally planning proceedings advances neural information processing systems nips mit press 
puterman markov decision processes sobel eds handbooks ms vol 
pp 

rummery niranjan line learning connectionist systems tech 
rep cued infeng cambridge university engineering department 
singh jaakkola learning state estimation partially observable markovian decision processes proceedings eleventh international conference machine learning pp 

smallwood sondik optimal control partially observable markov processes finite horizon operations research vol 
pp 

sondik optimal control partially observable decision processes 
phd thesis stanford university stanford california usa 
sondik optimal control partially observable decision processes infinite horizon discounted cost operations research vol 
pp 

sutton temporal credit assignment reinforcement learning 
phd thesis university massachusetts amherst ma 
sutton learning predict method temporal differences machine learning vol 
pp 

sutton integrated architectures learning planning reacting approximating dynamic programming proceedings international conference machine learning icml 
hertzberg schneider stochastic model actions plans anytime planning uncertainty current trends ai planning sandewall backstrom eds amsterdam ios press 
thrun schwartz finding structure reinforcement learning proceedings advances neural information processing systems nips pp 
mit press 
washington incremental markov model planning tai eighth ieee international conference tools artificial intelligence pp 

washington uncertainty real time therapy planning incremental markov model approaches proceedings aaai spring symposium artificial intelligence medicine 
washington bi pomdp bounded incremental partially observable markov model planning proceedings th european conference planning ecp 
watkins learning delayed rewards 
phd thesis cambridge university cambridge england 
watkins dayan learning machine learning vol 
pp 

white markov decision processes 
john wiley sons 
white iii optimal diagnostic questionnaires allow truthful responses information control vol 
pp 

white iii optimal inspection repair production process subject deterioration journal operations research vol 
pp 

white iii partially observed markov decision processes survey annals operations research vol 

white iii scherer solution procedures partially observed markov decision processes operations research vol 
pp 

white iii scherer finite memory suboptimal design partially observed markov decision processes operations research vol 
pp 

zhang lee zhang method speeding value iteration partially observable markov decision processes proceedings th conference uncertainty artificial intelligence uai 
zhang liu model approximation scheme planning partially observable stochastic domains journal artificial intelligence research vol 
pp 

zhang zhang fast value iteration goal directed markov decision processes proceedings th conference uncertainties artificial intelligence uai pp 

zhang zhang space progressive value iteration anytime algorithm class pomdps sixth european conference symbolic quantitative approaches reasoning uncertainty ecsqaru 
zhang zhang speeding convergence value iteration partially observable markov decision processes journal artificial intelligence research vol 
pp 

zhang value iteration belief subspace proceedings th european conference symbolic quantitative approaches reasoning uncertainty ecsqaru 
zhang zhang solving informative partially observable markov decision processes proceedings th european conference planning ecp 
zhou hansen improved grid approximation algorithm pomdps proceedings th international joint conference artificial intelligence 
dietterich pomdp approximation algorithm anticipates need observe proceedings pricai lecture notes computer science new york springer verlag 
zwick paterson complexity mean payoff games graphs theoretical computer science vol 
pp 


