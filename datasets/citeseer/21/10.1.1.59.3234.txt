omnidirectional modeling mobile robot graph cuts sven fleck florian peter biber wolfgang stra er wsi gris university bingen bingen germany fleck biber gris uni tuebingen de mobile robot natural task build model environment 
model useful planning robot actions provide remote human realistic visualization robot state respect environment 
acquiring models environments important task possible applications creating virtual interactive walkthroughs basis tv 
method acquire model mobile robot equipped laser scanner panoramic camera 
method calculating dense depth maps panoramic images pairs panoramic images taken different positions stereo matching 
traditional slam laser scan matching determine needed camera poses 
receive high quality results high quality stereo matching algorithm graph cut method 
describe necessary modifications handle panoramic images specialized post processing methods 
modeling system uses mobile robot activ media see fig 
convenient data acquisition platform 
robot platform equipped sick lms laser scanner panoramic camera consisting ordinary ccd camera resolution omnidirectional lens attachment remote reality 
panoramic camera viewing angle degrees small part image occluded camera support mounted top robot looking downwards height approximately meters ground plane 
data collection robot controlled remotely human operator teleoperation interface 
data processed offline 
result system point cloud 
point clouds representation dimensional models popular alternative meshed models nowadays computer graphics allow fast rendering large scenes 
point clouds easier handle connectivity topology reconstruct important argument especially automatically acquired large data sets case 
give brief overview system 
fig 
illustrates framework architecture 
discussing related detail main aspects especially omnidirectional stereo matching 
acquired data consists laser scans panoramic images taken synchronously robot moved cm turned henrik dept technology university sweden henrik tech se degrees 
panoramic camera calibrated section iii data collection starts 
offline process starts calculating robot pose recorded image 
slam algorithm purpose section iv 
step time consuming dense depth maps extracted panoramic images section vi 
post processing methods section vii enhance resulting point clouds considerably 
section viii briefly explains point clouds different images combined 
conclude outline results available download project website higher quality 
ii 
previous review stereo algorithms geometrical aspects omnidirectional vision give starting points respectively 
stereo algorithms classified method families local methods traditional ssd methods cooperative methods dynamic programming methods global methods 
times new sort algorithms graph cuts proposed perform promising 
graph cut methods introduced roy cox belong class global methods 
experimental comparative studies show graph cut methods perform better simulated annealing methods show approximately times smaller errors traditional methods normalized correlation 
due impressive performance publications cover graph cut 
contrast texturing extracted walls model general allows arbitrary point clouds 
point omnidirectional reconstruction mobile robotics graph cut 
lots realtime reconstruction area 
address high quality realtime place 
iii 
calibrating mirror geometrical shape mirror inside omnidirectional lens attachment known calibration procedure applied map metric coordinates pixel coordinates pp see fig 

assume shape mirror necessary stereo matcher combiner images images stereo matching prev post processing point cloud combiner data acquisition odometry stereo matcher point clouds laser scans localization unit stereo matcher localization unit final point cloud fig 

modeling framework architecture 
perform calibration direction map world coordinates coordinates 
images known positions measured corresponding pixels rp collected 
data camera height estimated tan handle mapping rp cubic polynomial fitted data 
polynomial function interpolate calibration measurements modeling 
camera mounted perfectly vertical utilize correction mechanism projecting laser range data image estimate error visually redundant information laser range scan points exactly wall meets floor 
iv 
getting robot poses approach belongs family techniques environment represented graph spatial relations obtained scan matching 
nodes graph represent poses laser scans recorded 
edges represent pairwise registrations scans 
registration calculated scan matching algorithm fig 

left geometry panoramic camera calibration represents surface mirror inside lens attachment 
right geometry panoramic images 
odometry initial estimate operating analysis synthesis style 
scan matcher calculates relative pose estimate scan match score maximal quadratic function approximating score optimal pose 
quadratic approximations build error function graph optimized poses simultaneously free parameters 
details method 
resulting map data discarded 
point positions orientations robot 
proposed method restricted situations laser range scanner employed 
fig 
shows final map 
part map graph illustrated fig 

fig 

final map 
fig 

part graph map consists 
stereo matching stereo matching pipeline consists stages pixel image epipolar curve second image created 
epipolar curve represented set points image space point denotes different disparity 
error value disparity epipolar curve computed saved 
stages provide data needed graph cut algorithm described detail 
epipolar curves epipolar curve generated calculating corresponding ray set different distances ray projecting resulting points second image 
distances fixed 
determined dynamically locally optimal matching respect scaling window curve reached 
means source pixel gets distinct set different disparity values 
calculation matching score rectangular image patch size actual position extracted see fig 
left 
fig 

left search window 
right comparison window 
extract rectangular window dimension second image specifies different disparities checked 
window locally rectified bilinear interpolation 
warping rectification determined epipolar curve corresponds straight line rectified window axis lines perpendicular epipolar curve omnidirectional image lines parallel axis 
rectified window longer need extra half search window curve 
curve expanded point infinity see fig 
right utilizing second order derivatives 
matching pixel illustrated fig 

dense epipolar curve shown blue 
green part curve part expanded infinity 
red cross denotes best match selected pixel 
fig 

top left 
equipped sick lms laser scanner panoramic camera 
top right epipolar curve omni directional image 
bottom selected pixel image 
ssd matching search window slid axis rectified window ssd matching performed position 
matching costs differences calculated ssd matching stored distances 
image processed compared previous image 
matching costs mixed big array containing matching costs pixel parts image curve contains points matching values longer curve 
fig 
shows winner takes result matching panoramic image fig 

results achieved matching source image previous image series 
fig 

source images matching examples 
fig 

results matching displaying winner takes solution 
array containing matching costs stereo algorithm described section 
vi 
graph cut graph cut algorithm follows kolmogorov zabih adapted omnidirectional imaging 
key formulating correspondence problem energy minimization problem 
done algorithm expansion moves 
minimization done iteratively transforming energy minimization problem minimum cut problems 
lead strong local minimum energy function computing best expansion lowest energy different values convergence reached 
ensure expansion succeeds key correspondence problem implemented graph cuts 
kolmogorov zabih investigated necessary characteristics energy functions binary values optimized graph cuts 
appropriate energy function form notation edata esmooth edata embodies ssd matching cost corresponding pixels edata ik ik occlusion term adds additional cost cp occluded pixel cpt np esmooth imposes penalty va neighboring pixels having different disparity values esmooth va utilized graph cut implementation starting point 
fig 
shows disparity map resulting graph cut algorithm 
solution improved postprocessing steps described section 
fig 

result graph cut algorithm post processing 
sub disparity refinement vii 
postprocessing sub disparity refinement applied get smooth surfaces 
refine solutions big gaps wall depth values jump depth pixel depth pixel matching costs near solution calculated graph cut algorithm perform simple sub disparity refinement compute weighted mean adjacent distances weight taken original matching cost 
fig 
shows solution sub disparity refinement 
stage crucial point clouds solution fig 
fan surfaces strips orthogonal camera due discretely quantized disparity steps 
fig 

result graph cut algorithm applying sub disparity refinement 
epipole removal epipoles omnidirectional images projections antipodal points separate epipole perspective image corresponds epipoles omnidirectional images side viewpoint 
matching near epipoles inaccurate mainly scaling translation 
matching results near epipoles discarded just add random noise point cloud produce points random location 
stored distance values near step epipolar curve determine pixel near epipole 
fig 
illustrates step epipoles removed 
fig 

refined solution removing epipoles 
floor correction algorithm assumes camera height constant known non transparent floor 
pixels lying floor lifted floor level 
pixels floor certain range robot lowered floor robot assumed drive 
especially fixes errors occur due lights reflected floor areas tend get mismatched 
fig 
shows result floor correction 
filling unknown values remains done solved 
filling unknown values epipole removal graph cut algorithm mark pixels unknown occluded 
distance values pixels interpolated surrounding known distances linear interpolation concentric circles 
fig 
shows final solution containing distance information extract point cloud 
distance information pixel considered image transformed point colored pixel rgb value 
fig 
rendering different pose point cloud 
viii 
combining data sets data sets point clouds combined big point cloud 
point point cloud image compared points images search radius 
color similar confidence counter point increased 
counter threshold certain amount images point compared marked discarded 
improves quality wrong matches find similar points near images fig 

solution floor correction 
fig 

final solution post processing 
removed hopefully leaving correct points cloud 
resulting point cloud filtered remove unnecessary points calculating point densities removing points areas high densities 
fig 
shows resulting final point cloud download higher resolution results web site get better impression 
fig 
shows different part building 
fig 

rendering single point cloud created stereo matcher 
fig 

final result rendering resulting point cloud 
fig 

different rendering 
ix 
addressed problem automatically generating realistically looking point clouds omnidirectional images came fully automatic system delivers quite convincing results 
combination omnidirectional vision graph cut methods 
algorithm relatively slow minutes image ghz machine 
especially post processing increases quality immensely 
focus set matching images instance combining resulting point clouds combiner identified starting point improvement 
matcher utilizes images absolute robot positions camera calibration data generate point clouds representing interior building decouples need laser range scanners long method acquiring pose available 
acknowledgment authors ck royal institute technology stockholm sweden implementation graph cut algorithm kolmogorov zabih basis 
wand fischer peter auf der heide stra er randomized buffer algorithm interactive rendering highly complex scenes siggraph 
project website www gris uni tuebingen de omni 
scharstein szeliski taxonomy evaluation dense stereo correspondence algorithms ijcv vol 
pp 

hartley zisserman multiple view geometry computer vision 
cambridge university press isbn 
kang panoramic vision sensors theory applications 
springer isbn 
roy cox maximum flow formulation camera stereo correspondence problem proceedings sixth international conference computer vision 
ieee computer society 
szeliski zabih experimental comparison stereo algorithms proceedings international workshop vision algorithms 
springer verlag pp 

boykov kolmogorov experimental comparison mincut max flow algorithms energy minimization vision ieee transactions pattern analysis machine intelligence pp 

kolmogorov zabih computing visual correspondence occlusions graph cuts international conference computer vision iccv july 
kolmogorov zabih energy functions minimized graph cuts ieee transactions pattern analysis machine intelligence 
paris quan surface reconstruction method global graph cut optimization asian conference computer vision january 
boykov veksler zabih fast approximate energy minimization graph cuts ieee transactions pattern analysis machine intelligence 
biber duckett schilling modeling indoor environments mobile robot laser scanner panoramic camera ieee rsj international conference intelligent robots systems iros 
kr se robust scene reconstruction omnidirectional vision system ieee transactions robotics automation pp 

konolige small vision systems hardware implementation eighth international symposium robotics research 
duckett multigrid approach accelerating relaxation slam proc 
ijcai workshop reasoning uncertainty robotics 

gutmann konolige incremental mapping large cyclic environments proc 
ieee international symposium computational intelligence robotics automation 
lu milios globally consistent range scan alignment environment mapping autonomous robots pp 

biber stra er normal distributions transform new approach laser scan matching international conference intelligent robots systems iros 
biber fleck stra er probabilistic framework robust accurate matching point clouds th pattern recognition symposium dagm 
ck robust stereo correspondence graph cuts 
online 
available www nada kth se pdf geyer conformal rectification omnidirectional stereo pairs workshop omnidirectional vision camera networks 
