journal grid computing 
kluwer academic publishers 
printed netherlands 
mapping complex workflows grid environments ewa deelman james blythe yolanda gil carl kesselman mehta kent blackburn albert adam richard scott information sciences institute university southern california marina del rey ca usa mail deelman isi edu california institute technology east california boulevard pasadena ca usa department physics university florida gainesville fl usa department physics university wisconsin milwaukee east blvd milwaukee wi usa key words complex applications planning reliability workflow management address problem automatically generating job workflows grid 
workflows describe execution complex application built individual application components 
developed workflow generators concrete workflow generator cwg maps workflow defined terms application level components set available grid resources 
second generator concrete workflow generator takes wider perspective performs concrete mapping enables construction workflow available components 
system operates application domain chooses application components application metadata attributes 
describe current ai planning technologies outline technologies play crucial role developing complex application workflows grid environments 
preliminary cwg map high energy physics applications grid 
particular experiment set production runs lasted days resulted generation events jobs 
additionally map gravitational physics workflows hundreds nodes available resources resulting tasks data transfers output files produced 

grid computing promises users ability harness power large numbers heterogeneous distributed resources computing resources data storage systems instruments resources distributed wide area belong testbeds europe asia australia 
vision enable users applications seamlessly access resources solve complex large scale problems 
scientific communities ranging physics gravitational wave physics geophysics astronomy bioinformatics embracing grid computing manage process large data sets execute scientific simulations share data computing resources 
scientific data intensive applications outlined longer developed monolithic codes 
standalone application components combined process data various ways 
applications viewed complex workflows consist various transformations performed data 
example astronomy workflows thousands tasks need executed identification galaxy clusters sloan digital sky survey 
large amounts computation data involved workflows require power grid execute efficiently 
nsf funded grid physics network griphyn project aims provide users seam access data computed exists form application level description 
class data referred virtual data 
griphyn user able request data simply submitting application specific description desired data product 
grid infrastructure able generate workflow selecting appropriate application components assigning required computing resources successful execution 
mapping optimized criteria performance reliability resource usage focus grid computing developing middleware provides basic functionality ability query information resources ability schedule jobs resources 
exceptions european data grid resource broker described section little done area automating job execution 
users need discover resources manually schedule jobs directly grid essentially composing detailed workflow descriptions hand 
leaves users struggling complexity grid weighing resources run computations access data goal automate workflow generation process possible 
introduce notion workflows specify application components input data concrete workflows include actual executables data files specific resources 
applicability various techniques perform workflow generation vary depending application characteristics complexity 
simple workflows current compact muon cms workflow concrete workflow generator cwg described sufficient 
cwg takes workflow simple mappings data location resource availability generate feasible concrete workflow 
cwg optimizes concrete workflow availability intermediate data products 
complex application workflows needed laser gravitational wave observatory ligo sophisticated mappings need employed 
believe complexity problem space grows sophistication desired optimizations increases greatly benefit artificial intelligence ai planning techniques search solutions 
additional benefit ai techniques ability problem level application 
allows map directly individual application components concrete workflow 
underline importance developing automatic workflow mapping systems show providing simple feasible mappings impact application domain 
specifically demonstrate cwg problem grid cms experiment 
effort building experimenting grid advance collecting data particle 
particular cms grid prepare cms detector due collecting data european center nuclear research cern 
time large amounts data collected need analyzed real time 
cms currently running grid enabled simulations physics events generated appearance cms detector simulated 
simulations geared verifying detector design design grid enabled real time event processing algorithms analyze data coming cms detector 
show usefulness applying ai techniques generating ligo workflows metadata description ligo pulsar search analysis frequently performed scientists 
ligo distributed network km scale occupying sites construction project funded nsf jointly built caltech mit 
observatory mission detect measure gravitational waves predicted general relativity einstein theory gravity gravity described due curvature fabric spacetime space 
ligo started collecting scientific data plans long duration runs coming years 
remainder organized follows 
section states problem point view application 
section describes concrete workflow generator produces feasible concrete workflow simple mapping techniques 
section describes alternative powerful approach exploits ai planning techniques 
section describes experiences system context cms ligo 
sections describe related provide elaborate challenges opportunities ahead 

problem description scientists seek specific data products obtained configuring available application components executing grid 
example suppose user goal obtain frequency spectrum signal instrument time frame placing results location addition user results intermediate filtering steps performed available location check filter results unusual phenomena extract salient features metadata final results 
process mapping type user request jobs executed grid environment decomposed steps 

generating workflow selecting configuring application components form workflow 
application components selected looking specification capabilities checking generate desired data products 
configured assigning input files exist gener ated application components 
workflow specifies order components executed 
specifically steps need performed find application components generate desired data products example frequency spectrum desired characteristics 
component cn 
find inputs component takes check inputs available corresponding files ij input required formats available find application components produce input component cn 
process iterated desired result generated composition available components operate available input data cn im respectively 
formulate workflow specifies order execution components cn 
call workflow 
please note level components files referred logical names 
process developing data intensive applications grid environments 
uniquely identify component terms functionality data files terms content single logical name correspond actual executables physical data files different locations 

generating concrete workflow selecting specific resources files additional jobs required form concrete workflow executed grid environment 
component workflow turned executable job specifying locations physical files component data resources assigned execution environment 
additional jobs may included concrete workflow 
example jobs transfer files appropriate locations resources available execute application components 
specifically steps need performed find physical locations physical files component cn pf cn pf 
check computational requirements pf cn pf specify locations ln execute required available resources 
determine physical locations input data files pf im pf select locations appropriate ln 
augment workflow description include jobs km move component input data files pf cn pf pf im pf appropriate target locations ln 
grid middleware allows discovery available resources locations replicated data users currently responsible carrying steps manually 
important factors automating process desirable necessary usability users required extensive knowledge grid computing environment middleware functions 
example user needs understand query information service monitoring discovery service mds find available appropriate computational resources computational requirements component step 
user needs query replica location service rls find physical locations step 
complexity addition requiring scientists grid enabled users process may complex time consuming 
notice step user choices alternative application components files locations available 
user may reach dead solution require backtracking undo previous choice 
different interdependencies may occur components result may hard determine choice change better option leads feasible solution 
solution cost lower cost solutions highly desirable light high cost computations user limitations terms resource access 
finding feasible solution time consuming users explore alternative workflows may reduce execution cost 
global cost users competing resources minimizing cost community virtual organization vo desirable 
requires reasoning individual user choices light user choices possible common jobs included user workflows executed 
addressing points enable wider accessibility grid users point handling global cost simply handled individual users need addressed architecture level 
addition policies limit user access resources needs taken account order accommodate users possible contending limited resources 
additional issue reliability execution 
today grid framework execution job fails recovery consists job execution resources 
shown retry 
desirable able choose different set resources tasks fail 
process needs performed workflow level 
currently mechanism opportunistically redoing remaining tasks workflow adapt dynamic situation environment 
job fails repeatedly desirable system assign alternative component achieve user goals 
need performed application level understanding different application components relate 
table describe different levels abstraction user specify workflow 
table 
levels abstraction describe workflows 
specification gridftp host home filea host home file usr local bin fft home file specification detail resource level physical files executables concrete workflow domain workflow domain application domain lowest level concrete workflow user needs specify explicit data movements exact executables resources 
workflow level user needs specify workflow logical files logical component names 
top level application level user needs specify metadata describing desired data products 
section describe implementation concrete workflow generator cwg 
cwg performs mapping workflow concrete workflow 
system automatically locates physical locations components data finds appropriate resources execute components generates executable workflow jobs submitted grid 
implementation isolates user details grid infrastructure requires user spell components input files required 
addition alternatives possible alternative physical files alternative resources random choice final result feasible solution necessarily low cost 
section describe implementation concrete workflow generator requires users description desired data products terms applicationspecific metadata 
approach exploit artificial intelligence planning techniques explore solution space search algorithms guided informed heuristics 

concrete workflow generator discuss concrete workflow generator cwg briefly describe grid environment jobs executed 
grid fft filea frequency spectrum signal instrument time frame logical file names logical component names application specific metadata resources computational data instruments distributed wide area 
manage information interactions resources globus toolkit deployed resources 
globus consists services allow discovery resources characteristics mds 
allows scheduling jobs resources gram 
terms data management globus provides information locating replicas files rls means highperformance data transfer gridftp 
part griphyn project developing transformation catalog provides mapping application components physical location 
component developed part griphyn virtual data catalog keep track components generate data products 
cwg performs mapping workflow concrete workflow represented directed acyclic graphs dags account previous calculation intermediate data products inserting data movement data publishing operations appropriate 
cwg termed algorithmic mapper encodes specific mapping procedure 
contrast approach ai planners provide generalized control structure manipulates domain specific rules 
simple example illustrate capabilities cwg 
shows simple workflow logical component extract applied input file logical filename resulting files logical filenames inputs components identified logical filename resample respectively 
results concatenated 
assume available storage system indicated rls 
cwg reduces workflow components extract resample concat 
adds transfer 
workflow 

reduced concrete workflow 
files transferring current locations 
adds transfer nodes jobs run different locations example resample concat available different locations transferred 
cwg adds output transfer nodes stage data registration nodes user requested resulting data published available particular location 
concrete workflow scenario shown 
workflow instantiated form dag software dagman directed acyclic graph manager condor schedule jobs described nodes dag specified resources specified order 
generally cwg described follows 
workflow information jobs needed done materialize required data 
order map concrete workflow cwg reduces workflow 
cwg assumes costly execute component job access results component data available 
example user vo may materialized part entire required data set 
information published replication service cwg utilize knowledge obtain data avoiding possibly costly computation 
result components appear workflow appear concrete workflow 
optimization rls queried availability output files jobs need executed identified 
antecedents redundant jobs descendents removed 
reduction algorithm performed nodes reduced 
cwg maps remaining workflow available resources 
currently information available resources statically configured 
near plan include dynamic information provided mds 

cwg checks feasibility workflow 
determines root nodes workflow queries rls existence input files components 
workflow executed input files components exist grid accessible data transport protocol 
transformation catalog queried determine components available execution environment identify locations 
currently cwg picks random location execute returned locations 

transfer nodes added files need staged component input files physical location 
input files replicated locations cwg currently picks source location random 

transfer nodes registration nodes publish resulting data products replica location service added user requested data published sent particular storage location 
order able execute workflow cwg generates submit files condor associated dagman execution 
cwg successfully mapping executing cms workflows shown section 
finding feasible mapping concrete workflows manageable task issue complicated application complexity increases size grid grows considers optimizations concrete workflow 
cms workflow example consisted stages stage composed job 
complexity cms comes execution multiple thousands workflows perform adequate analysis 
applications ligo similar number stages stages composed hundreds jobs 
complexity mapping magnified consider sophisticated optimizations 
example take account information network bandwidth scheduler queue size reliability resource processing speed storage capacity 
system information perform optimizations minimizing total runtime workflow maximizing probability execution successful minimizing expensive resources constraints execution workflow imposed user vo access privileges resources 
general case users able decide optimization criteria important 
order able support complexity workflow generation system needs able efficiently search large problem space apply local global optimizations 
needs compose various optimization strategies user resource requirements 
order minimize development cost needs able reuse resource component models 
continue incorporating support optimizations local global search heuristics cwg far efficient existing technologies ai planners platform mapping system 
ai planning research broad base generic implementation foundation efficient searches large problem spaces 
uses techniques backtracking domain specific domainindependent control rules focus search 
take account interdependencies choice points search incorporate optimality policy search solutions interleave resource assignment scheduling concerns take account job duration 
integrate generation workflows users policies vos 
ai planners flexible allow easy addition new system constraints rules 
section examine features ai planning solutions apply workflow mapping problem 

concrete workflow generator planning subfield artificial intelligence concerned finding sequence actions plan achieve desired goals 
ai planning successfully challenging practical applications including space mission planning manufacturing military logistics robotics 
typical planning system takes pieces input description current state world formal language called initial state description agent goals usually partial description world state library operators representing actions agent perform change state 
operator usually described set preconditions hold world state action applied set effects changes state take place action applied 
planners called task decomposition planners description includes partially ordered set lower level operators accomplished order achieve operator hand 
planning systems cast search algorithm find plan achieve goals initial state 
different search strategies planners search state space forwards initial state backwards goal specification search top operators search plan space state space 
section describe framed planning problem mention planning approaches best suited 
section show results applying techniques ligo pulsar search 
section describe needed planning better handle problem 

stating problem planning terms models application components data transfer data registration operators 
operator parameters include location component run 
output plan corresponds concrete workflow 
addition effects preconditions operators capture data produced components input data dependencies 
result planner create workflow 
state information planner includes description available resources files registered replica location service 
input goal description include metadata specification information user requires desired location output file specific components run intermediate data products 
issues application domain challenging touch describe domain model detail 
initial prodigy planner 
provides expressive language define search heuristics important 

state information planner world state includes information resources 
information changes slowly operating system total disk space available resource information change seconds minutes available memory queue length 
long run planner may need reason information change time initial implementation information simply captured planner startup 
previously created files currently modeled initial state care needs taken thousands millions files may available relatively small number relevant current plan 
planner handle requesting relevant information planning currently filter set files planning begins 
useful planning state include metadata files enable planner create concrete workflows 
appropriate reason level metadata level files represent data content 
search file appropriate characteristics component descriptions characteristics 
avoids quantifying set existing files may change planning objects created destroyed 

goal statements planning applications goals refer properties true plan executed 
goals include having file described desired metadata information host 
useful specify goals refer intermediate components data products registering certain files 
goal statement specify partial plan 
goals planning system may single user aggregated goals group users 
case planner may able create efficient plan computations required exploiting synergy users goals currently include capability 
example interplay planning algorithm policy settings briefly discussed 

operator descriptions operators represent concrete application component particular location generate particular file file movement network 
preconditions represent data dependencies component terms input information required 
operators capture information similar represented chimera virtual data language name component parameters 
operators contain additional information feasible resources running component including type resource minimal physical memory hard disk space software configuration 
operators define preconditions necessary component provide effect application component state system consumption resources 
plans generated response user requests may involve hundreds thousands files important manage process searching plans efficiently 
component needs run times different input files useful planner explicitly consider different orderings files 
planner reasons groups files treated identically 
auxiliary routines allocate files different groups looking locally optimal allocations 
number input files groups may vary component invocation preconditions modeled quantification possible files 
note type abstraction hard achieve non metadata systems chimera cwg 
example operator representing fft component ligo pulsar search described section 
operator defined set input files describes files resulting file terms metadata define interval time signal fft taken 
operator captures notion availability fft resource host 
effects show creation fft chosen host 
operator fft params file host preconds file file really block files current model host number number available fft host effects add created fft host host file add created file add file host 
solution space plan generation strategy initial approach seek high quality plans combination local search heuristics aimed preferring choices individual component assignments exhaustive search plan minimizes global estimated run time 
aspects necessary global measure locally optimal choices combine poor plan conflicts 
local heuristics planner may generate alternatives finding high quality plan 
local heuristics represented explicitly planner search control rules 
planner searches solution repeatedly chooses goal address operator achieve goal parameter assignments operator 
choice planner may need backtrack examine alternatives order find feasible plan search find best plan 
search control rules specify options exclusively considered choice point search algorithm 
change order options considered 
rules refer information current state choice goals planner 
example rule prefer allocate component location higher bandwidth connection location component output needed 
rule applicable problem 
application specific rules defined 
example control rule force planner choose host perform ligo pulsar search location host perform fft possible 
control rule select binding nearby mpi pulsar search current operator pulsar search true state available fft fft host true state physically fft host location true state physically mpi location type object mpi mpi select bindings host 
mpi host parameter pulsar search operator ai planner able produce results similar cwg test scenarios operators control rules currently supports broader range problems operators control rules 
takes half second find solution ligo pulsar search problem files locations requiring separate components seconds exhaustively search solutions problem 
worst case scales exponentially number resources depth plan domain time find plan scale linearly number files resources 
detailed planner description 

application experiences part developed configurable system pegasus planning execution grids integrated chimera 
chimera user specifies descriptions component arguments takes number input output files defined chimera virtual data language 
language defines derivations invocations particular component contain logical file names lfn parameters run component 
derivations construct workflows 
chimera driven configuration pegasus receives workflow description chimera uses cwg produce concrete workflow 
pegasus submits concrete workflow dagman execution monitors jobs described concrete workflow 
configuration map cms workflows grid 

applying cwg cms compact muon cms multipurpose particle physics detector currently constructed european center nuclear research 
workflow cms tuple production linear stage pipeline 
cern geneva switzerland 
begins operation cms detector expected record data produced high energy proton proton collisions occurring cern large collider lhc rate mb 
data recorded passed various filter stages transform reduce data formats easily analyzed physicists 
order better understand response detector different input signals large scale monte carlo simulations performed typically involve different computational stages 
simulations long running parallel multi stage processes ideally suited grid computation 
typically single workflow creates approximately gb data requires cpu hours depending type simulation 
typical production run may include thousands workflows 
variety different cases exist simulated cms data production 
simpler cases known tuple production consists stage computational pipeline shown 
generation stage simulates underlying physics event 
second stage simulation stage models cms detector response events created generation stage 
third stage formatting stage copies simulated detector data object oriented database oodb 
stage reconstruction stage transforms data database producing picture physicist see simulated data actual data recorded experimental apparatus 
final stage analysis stage selects user specific information database creates convenient easy file analyzed researching physicist 
tuple production file important piece data intermediate data may discarded 
log files intermediate data products needed quality assurance validation 
small scale tests cms tuple production pipelines successfully performed cwg 
cwg large scale test involved pipelines generation simulation 
cwg scheduled performed university florida computing cluster consisting pentium ghz machines 
course days jobs events submitted cwg 
jobs events successfully produced approximately cpu days computing power producing approximately gb simulated data 

applying ligo pulsar search ligo laser interferometer gravitational wave observatory www ligo caltech edu distributed network mission detect measure gravitational waves predicted general relativity einstein theory gravity 
studied source gravitational waves motion dense massive astrophysical objects neutron stars black holes 
signals may come supernova explosions neutron stars 
gravitational waves interact extremely weakly matter measurable effects produced terrestrial instruments passage expected 
order establish confident detection measurement large amount auxiliary data acquired including data microphones analyzed example eliminate noise strain signal measures passage gravitational waves 
raw data collected experiments collection continuous time series various sample rates 
amount data acquired cataloged year order tens hundreds terabytes 
gravitational wave strain channel data collected 
analysis data performed time frequency domains 
requirements able perform single channel analysis long period time multi channel analysis short time period 
investigate capability generate complex metadata driven workflows integrated pegasus applied specific ligo analysis pulsar search 
driven configuration pegasus driven metadata search implemented pipeline depicted 
element data archiving instrumental data stored archive 
raw data comes instrument short second duration frames data structure gravitational wave community channels processing geared removal cleaning certain instrumental signatures needs done 
example naturally occurring seismic vibration subtracted data channels sensitive part ligo data stream 
pulsar search gravitational wave strain channel extracted 
pulsar search conducted frequency domain fourier transforms performed long duration time frames produce datasets known short fourier transforms 
expected small frequency range frequency interval interest extracted 
resulting power spectra build time frequency image analyzed presence pulsar signatures 
candidate signal signal noise ratio placed ligo event database 

ligo pulsar search 
ligo pulsar search performed pegasus system configuration included 
compute storage resources caltech university southern california university wisconsin milwaukee 
run conducted sc pulsar searches performed resulting total tasks data transfers executed output files 
total runtime 

related ai planning techniques focus choosing set actions perform achieve goals scheduling techniques focus assigning resources chosen set actions 
approaches scheduling success iterative refinement techniques feasible assignment gradually improved successive modifications 
approach applied planning suited plan quality important 
done integrating planning scheduling techniques solve joint task 
central scheduling large complex workflows issue data placement especially data sets involved large 
cwg give preference resources input data set 
look data grid tiered system dynamic replication strategies improve data access 
significant performance improvement achieved scheduling performed data availability dynamic replication strategy 
running workflow grid possible perform large computations possible single system leads certain loss control execution jobs executed different administrative domains 
counter systems abramson buyya appear sample stanford database group try provide quality service guarantees required user submitting workflow grid 
uses information mds determine resource meets budget constraints specified user sample stanford database group monitors job progress time ensure guarantees met 
guarantee met schedules recalculated 
focused developing application specific schedulers maximize performance individual application 
apples scheduling done basis performance metric varies application application 
schedule jobs grid knowledge required resource usage 
leads customized scheduler application general solution 
schedulers focused parameter sweep applications single application run multiple times different parameters 
interdependencies jobs scheduling process far simpler addressed 
european data grid edg considered automatic scheduling jobs grid resulted development workload management package 
edg resource broker maps individual jobs information provided various grid services mds network weather service replica location services 
systems mentioned rigid fix set optimization criteria 
developing framework flexible system map workflow description concrete form dynamically change optimization criteria 

directions finding concrete workflows involves wide range issues investigated artificial intelligence planning including hierarchical planning temporal reasoning scheduling reasoning resources planning uncertainty interleaving planning execution 
near plan evaluate approaches plan reuse planning uncertainty increase level performance sophistication 
plan investigate applicability approach service level composition 
section describe ideas 

solution reuse important research area effective problem reuse solutions previously computed 
case planning powerful technique retrieve modify existing plans need slight changes adapted current situation 
approaches potential network topology resource characteristics fairly stable high quality solutions may take time generate principles starting points similar problems 

fault avoidance simple case planner creates plan subsequently executed hitch 
runtime failures may result need repair plan execution 
planning systems design plans reduce risk execution failure failures take place 
explicitly reason risks planning searching reliable plans possibly including conditional branches execution 
planners delay building parts plan execution order maintain lower commitment certain actions key information available 
approaches high impact grid computing domain decentralized nature means factors control planning agent 
current techniques handling uncertainty high complexity useable potential failure points need considered 

relevance open grid services architecture ontologies needs done area workflow generation believe framework designed foundation developing sophisticated techniques take account greater amount information applications execution environment 

general view mapping system information necessary models 
illustrates additional sources information integrate workflow generation process 
application level describe application components services facilitate integration new open grid services architecture ogsa 
services composed new sophisticated services 
ogsa provides syntactic description services wsdl assign semantic meaning 
propose augment service component descriptions developing ontologies application components data describe service behavior add semantic meaning service interactions 
ontologies allow generate workflows flexibly user requirements may partially complete specified higher levels abstraction current service descriptions 
additional information provided performance models services guide initial composition 
see ontologies playing important role generating concrete workflows 
ontologies grid resources allow system evaluate suitability resources provide particular application service instance 
resources allocated various tasks characterized domain independent way 
example computer system available task completed user allocation time particular machine permanently depleted 
ontologies resources capture qualities 
ontologies capture computer system capabilities job requirements key building planning domains quickly reliably generic components 
little area engineering planning domains example 

incorporating policy descriptions addition order generate feasible workflow information policies governing members virtual organization provided 
example resources vo decide resources particular individuals 
time resources need provide information policies enforce vo user levels 
resources provide information current state 
feasible solution cwg needs provide optimal solution considering policies part behavior application 

addressed issue composing complex applications mapping grid resources 
identified important steps need take place 
step map application requirements terms desired data products workflow specifies application components generate data 
second step maps workflow grid resources 
described mappings cwg takes workflow generates random feasible solution performs modest optimizations perform steps 
exploited adapted ai planning techniques express mapping problem application specific metadata 
operator plan generation combines local heuristics global measure look high quality plans 
applied cwg important application domain high energy physics experiment cms 
cwg cms physicists conduct production quality simulations grid resources 
complexity applications execution environment grow believe important able characterize build applications application dependent metadata attributes 
demonstrated capability applying ligo pulsar search 
laid foundation enable scientists reason desired data products level abstraction 
improvements hope develop increasingly sophisticated workflow generators 
gratefully acknowledge helpful stimulating discussions topics colleagues ian foster michael wilde yong zhao jens 
chimera system mentioned jointly developed university southern california information sciences institute university chicago argonne national laboratory 
ligo scientists contribution development grid enabled ligo software stuart anderson barnes philip phil ed greg mary lei isaac 
research supported part national science foundation itr griphyn ear itr 
ligo laboratory operates nsf cooperative agreement phy 
assigned ligo document number ligo 

ligo laser interferometer gravitational wave observatory large scale measurements science vol 
pp 


allcock secure efficient data transport replica management high performance data intensive computing mass storage conference 

ambite knoblock planning rewriting efficiently generating high quality plans proc 
th national conf 
artificial intelligence 

zhao applying chimera virtual data concepts cluster finding sloan sky survey technical report griphyn 

weiss ligo detection gravitational waves physics today vol 
pp 


berman wolski scheduling perspective application high performance distributed computing conference syracuse ny 

blythe decision theoretic planning ai magazine vol 


blythe deelman gil kesselman agarwal mehta role planning grid computing th international conference automated planning scheduling 

dean hanks planning uncertainty structural assumptions computational leverage journal artificial intelligence vol 


buyya abramson nimrod architecture resource management scheduling system global computational grid hpc asia 

buyya abramson economy driven resource management architecture global computational power grids international conference parallel distributed processing techniques applications pdpta las vegas usa 

casanova heuristics scheduling parameter sweep applications grid environments th heterogeneous computing workshop hcw cancun mexico 

chervenak deelman framework constructing replica location services proceedings supercomputing sc 

czajkowski fitzgerald grid information services distributed resource sharing th ieee international symposium high performance distributed computing 

czajkowski foster resource management architecture metacomputing systems th workshop job scheduling strategies parallel processing springer verlag pp 


deelman blackburn griphyn ligo building virtual data grid gravitational wave scientists th intl 
symposium high performance distributed computing 

deelman blythe pegasus planning execution grids technical report griphyn 

deelman kesselman transformation catalog design griphyn technical report griphyn 

deelman foster representing virtual data catalog architecture location materialization transparency technical report griphyn 

foster kesselman grid blueprint new computing infrastructure 
morgan kaufmann 

foster kesselman anatomy grid enabling scalable virtual organizations international journal high performance computing applications vol 
pp 


foster chimera virtual data system representing querying automating data derivation scientific statistical database management 

foster chimera virtual data system representing querying automating data derivation th international conference scientific statistical database management ssdbm edinburgh 

foster kesselman grid services distributed system integration computer vol 


foster kesselman physiology grid open grid services architecture distributed systems integration june 

frey tannenbaum condor computation management agent multi institutional grids cluster computing vol 
pp 


definition architecture technical plan evaluation criteria scheduling resource management security job description edg workload management draft 

gil blythe planet shareable reusable ontology representing plans aaai workshop representational issues real world planning systems 

globus www globus org 

griphyn www griphyn org 

hammond case planning integrated theory planning learning memory 

cms data grid system overview requirements cms note 

cms 

long fox recognizing exploiting generic types planning domains th international conference artificial intelligence planning scheduling breckenridge 

myers smith integrating planning scheduling adaptation resource intensity estimates proceedings th european conference planning ecp 

npaci https npaci edu 

ranganathan foster design evaluation dynamic replication strategies high performance data grid international conference computing high energy nuclear physics 

ranganathan foster identifying dynamic replication strategies high performance data grid international workshop grid computing 

ranganathan foster decoupling computation data scheduling distributed data intensive applications international symposium high performance distributed computing hpdc edinburgh 

integrating grid tools build computing resource broker activities datagrid wp chep beijing 

environment www org cme 

smith becker ontology constructing scheduling systems aaai spring symposium ontological engineering stanford university 

smith lassila development mixed initiative scheduling systems proceedings arpa rome laboratory planning initiative workshop tucson az 

veloso carbonell integrating planning learning prodigy architecture journal experimental theoretical ai vol 
pp 


veloso planning learning analogical reasoning 
springer verlag december 

wolski forecasting network performance support dynamic scheduling network weather service proc 
th ieee symp 
high performance distributed computing portland oregon 


cms concept physics potential nd latin american symposium high energy physics ii san juan puerto rico 

yang intelligent planning 
springer verlag 
