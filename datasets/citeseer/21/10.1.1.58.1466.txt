appears proceedings fourth ieee international conference peer peer computing ieee 
improving bandwidth efficiency peer peer storage patrick eaton emil ong john kubiatowicz computer science division university california berkeley berkeley california email eaton cs berkeley edu broaden applicability peer topeer storage infrastructures weakly connected clients 
client side technique exploits commonality consecutive versions file reduce bandwidth required store retrieve files peerto peer storage infrastructure 
novel data structure allows technique environment peers trusted perform operations unencrypted data 
implemented technique oceanstore prototype 
additionally simulations demonstrated technique reduce client perceived latency write read operations compared techniques current systems 

peer peer storage infrastructures promise provide globally accessible highly available storage 
early implementations systems evaluated assuming clients connected infrastructure high bandwidth low latency connection characteristic university corporate laboratory environments :10.1.1.12.2441:10.1.1.159.9358:10.1.1.11.3814
great amount research product development effort expended build networked distributed file systems environments organizations ones possess technological financial resources ensure availability high performance storage systems maintained full time professional staff 
furthermore measured performance peer peer storage infrastructures indicates attractive replacements systems currently place 
observations imply peer topeer storage infrastructures lack potential users 
believe systems empower different class users previously access highly available storage 
class users target home mobile users access network low bandwidth links 
despite promise increased availability broadband networking technologies residential small business users depend low bandwidth connections 
worse technologies touted broadband cable modems dsl modems wireless metropolitan networks offer fraction bandwidth technologies available larger organizations 
rural customers availability broadband technologies uncertain 
network connectivity increasingly available variety mobile devices mobile devices benefit highly available storage infrastructure prevent data loss due theft damage loss rely congested public wireless connections low bandwidth cellular modems 
examine improve access peerto peer storage infrastructures previously ignored class users 
recognizing home mobile users limited low bandwidth network connection focus reducing bandwidth required users peer peer storage infrastructures 
certainly challenge reducing bandwidth required communicate remote storage system benefit weakly connected clients studied 
traditional approaches problem applicable peer peer realm assume trusted server manipulate user data plaintext 
solution clientside technique recognizes commonality consecutive versions file reduce bandwidth needed store retrieve files 
relies novel data structure supports efficient insertion deletion indivisible blocks encrypted data 
rest organized follows 
section presents related 
section presents client side technique exploits commonality consecutive versions file conserve bandwidth 
section describes data structure allows technique peer peer environment limited trust 
section detail experimental implementation simulation results comparing effectiveness proposed scheme approaches current systems 
section proposes concludes 

related inspired number peer topeer storage infrastructures years 
draws research fields 

peer infrastructures number peer peer storage systems proposed years 
hope review describe notable systems salient features section 
peer peer storage systems share number common features 
individual machines infrastructure trusted protect integrity user data systems provide content addressable storage cas 
cas systems data named secure hash content 
clients verify data retrieved infrastructure comparing hash data name data retrieved 
large objects verifiable system divide object multiple blocks arrange blocks tree 
individual machines trusted protect privacy data 
protect data theft sensitive data appropriately encrypted 
respects peer peer storage systems differ significantly 
infrastructures act large virtual disk distributed block store 
systems client performs computation locally reading writing blocks infrastructure needed 
systems category include cfs past 
write file client divides file blocks submits blocks infrastructure storage 
read file client requests blocks infrastructure interpreting locally 
systems choose divide file treating file single block divide file fix sized blocks manner typical traditional file system 
systems provide infrastructural support managing objects stored system 
systems category include farsite oceanstore 
systems rely groups servers implementing byzantine agreement protocols manage stored objects 
modify object client submits signed update infrastructure 
byzantine group receives update serializes outstanding requests cryptographically verifies client write permission applies update 
client reads object group generates signature current version file actual data retrieved cas system 
machines comprising byzantine group trusted aggregate execute protocols trusted privacy data 
assume infrastructure farsite oceanstore provides point serialization infrastructure responsible committing updates capable verifying version data 

related borrow techniques fields research 
rabin computationally efficient approach generating unique fingerprints data subsequently projects 
manber technique find similar files large file system 
spring wetherall rabin fingerprints identity redundant network traffic 
muthitacharoen approach detect commonality consecutive versions files build low bandwidth file system lbfs 
due impact research discuss 
identifying commonality versions file lbfs reduced amount bandwidth clients communicating remote file server 
lbfs able support clients connected file server low bandwidth network connection 
technique assumed trusted file server view transform user data stored plaintext 
depending workload technique able reduce execution time 
exodus extensible database system developed data structure support efficiently insertion deletion data arbitrary offsets object 
data structure variation tree relative offsets handle operations bulk data 
algorithms required database server able subdivide data arbitrary offsets 

bandwidth efficient peer peer storage section describe assumptions peer peer storage infrastructure detail client side technique reduce bandwidth required store retrieve data infrastructure 
network inner ring app app weak link clients applications app client machine forward requests component transforms submission infrastructure 
inner ring machines contain components serialization applying updates 


storage infrastructure assumptions described section research literature presents wide variety peer peer storage systems 
presentation assume system oceanstore shown 
inner ring provides support managing objects infrastructure 
inner ring machine logically divided components 
serializer collaborates inner ring machines select serial order client update requests order announced rest system cryptographic certificates 
minimize impact malicious faulty inner ring servers collaborate byzantine agreement algorithm threshold signatures 
serial order chosen serializer passes updates updater transform data requests clients 
process invests aggregate trust inner ring perform updates serialization correctly individual trust members 
inner ring manages set files data objects 
modify data object client submits signed update inner ring responsible data object 
update ordered list actions guarded predicate 
serializer orders request passes updater signature verified determine signing principal permitted modify object 
update permitted updater evaluates predicate true applies actions create new version data object 
purpose predicate usually ensure consistency see section 
serializer signs result sends client response indicating update succeeded failed 
update applied blocks comprise data object named secure hash content immutable 
inner ring free move blocks servers infrastructure 
read data object client collect component blocks 
blocks immutable client retrieve blocks local cache remote block servers addition inner ring responsible object 
ensure collecting blocks current version data object client may request inner ring signed certificate current version 
large fraction complexity system serializer component 
consequently seek avoid altering mechanism 
focus data format predicates actions reduce bandwidth preserving privacy user data 

delta compressed updates certainly literature contains previous reducing bandwidth consumed client file server 
peer peer storage systems operate set constraints render previous techniques inappropriate 
example previous techniques assume trusted file server perform arbitrary transformations data stored plaintext 
peer peer systems communications channels machines untrusted sensitive data encrypted ensure privacy 
furthermore data encrypted infrastructure transform data arbitrary manner 
traditional schemes require file server modified participate new protocols require multiple rounds communication 
model complexity serializer search techniques retain high level request response protocol communicate client infrastructure 
constraints lead client side technique uses delta compression reduce size update transmitted inner ring 
technique designed unmodified applications accessing arbitrary data 
delta compression exploit commonality exists consecutive versions file 
compare new version data object previous version extract changes new version encode changes update 
ideal compression result updates minimum size 
provide ideal compression scheme provides reasonable compression remaining constraints peer peer systems maintaining storage computational overheads compression encryption indexing reasonable levels 
compression technique relies insertion deletion operations typically provided file system apis 
support set operations updater requires data stored specialized data format discussed detail section 
file summaries core technique file summary 
file summary condensed representation contents data object 
file summaries similar concept file recipes casper file system 
create file summary data object divided smaller pieces chunks 
identifier created chunk computing hash plaintext chunk data 
file summary records hash length offset data object chunk 
divide file chunks rabin fingerprints manner originally proposed low bandwidth file system 
rabin fingerprints identify chunk boundaries content sliding window file consequently tend identify boundaries modifications may shift data offsets change size file 
rabin fingerprints divide file chunks number chunks differ consecutive versions file roughly proportional amount data modified versions 
avoid pathological cases produce chunks unreasonably large small define minimum maximum chunk size 
boundaries ignored resulting chunk small boundary inserted chunk reaches maximum size 
updates file summaries data stored data object changes object file summary 
compute new file summary write operation client adopts write close approach afs 
client creates new file summary file close operation file originally opened writing 
client uses file summary modified file construct update send inner ring 
exploit commonality typical consecutive versions file client compares newly created file summary file summary previous version 
result comparison combined chunks containing new modified data create update forwarded inner ring 
procedure tends create efficient updates size update roughly equal amount data changed 
translating file system operations flexible set operations 
unmodified applications standard file system interface truncate append overwrite operations 
operations applications forced overwrite tail file small amount data changed 
naive translation file system operations updates result overwriting tail data object 
proposed translation process modification series insert delete operations succinctly describe changes file 
data structure enables inner ring support transformations section 
note fingerprinting creation file summaries performed plaintext data 
data encrypted standard cipher block chaining mode divided chunks chunks depend earlier chunks 
eliminate possibility detecting file commonality modification point file consequently increase size updates created client 
update predicates inner ring create new version data object intended client applies update version data object file summary comparison client 
applying update different version corrupt data 
ensure data object consistency update predicated condition current version data object managed inner ring version construct update 
condition hold inner ring processes update client receive update failure response 
client elect fetch new version data object construct new update overwrite entire file 
take optimistic approach file consistency constructing submitting updates current version file client machine contacting inner ring 
believe optimistic approach appropriate expect uncommon clients accessing peer peer storage weak network connection interactively sharing files system 
file summaries soft state committing update infrastructure file summary considered soft state 
common case client cache file summary write operation 
client may discard file summary time pare amount state record 
simply recreate file summary time application opens file writing 
certainly approach incurs significant computation cost clients computational capacity abundant compared scarce network bandwidth 
alternatively client may choose neglect altogether file summary previous version sending entire file update 
approach may appropriate small files 

caching read performance approach described section reduces latency commit updates inner ring decreasing amount data transferred network 
combining technique aggressive client side caching improves service clients 
obviously caching reduce latency read data cache contains stale data 
client previous version data object cached needs retrieve chunks newer cached version reconstruct current version 
process creates updates tends preserve unmodified chunks client version data object cached needs retrieve number new chunks proportional amount data changed 
caching help clients tolerate low bandwidth connectivity providing view data reflects updates certified inner ring 
caching allows clients speed local machine pipelining updates inner ring quickly network support 
believe important optimization study 

data structure efficient updates technique previous section assumes inner ring apply update created client 
unfortunately assumption trivially true 
complicating issue restricted trust assumptions inherent peer peer system operations update 
issues place requirements infrastructure represents user data 
section enumerate requirements representation data structure meets requirements 
simple extension allows storage infrastructure support simultaneously legacy applications approach described previously providing additional flexibility efficiency specialized applications 

requirements file summaries updates chunks varying sizes identified rabin fingerprints 
representation consequently needs index efficiently blocks unequal size 
requirement renders inode schemes inappropriate 
apply updates representation support flexible transformation operations 
addition truncate append representation support insert delete operations 
furthermore operations need incremental 
small portion data modified correspondingly small part data structure change 
trust model peer peer environment restricts representation 
data privacy ensured clients encrypt sensitive data 
previous approaches assumed blocks data server representation treat chunks opaque indivisible 

solution section data structure meets requirements listed 
data structure nodes data leaves root tree maintains index blocks data shown leaves 
root shows bytes data left subtree data offset accessed right subtree 
index records relative offsets note leaf nodes contain counts 

supports insert delete operations block boundaries 
sufficient apply updates created technique section 
extension allows arbitrary insert delete operations section 
solution inspired large object data structure exodus database system 
data structure variation tree balanced tree data stored leaves 
term balanced mean number children balanced amount data child 
tree composed types nodes 
base tree data nodes 
data node contains uninterpreted block potentially encrypted user data 
data encrypted data node contain initialization vector required decrypting data 
encrypted data rely data adjacent nodes cipher block chaining chaining terminate data node 
information needed decrypt data encryption algorithm stored data object metadata data node 
nodes called internal nodes combine form index data nodes 
top internal node called root internal nodes point directly data nodes called leaves 
internal nodes store count pointer tuples degree tree 
internal nodes root store non null tuples times root may contain fewer tuples 
count field integer records number bytes accessible current node children referenced tuple tuples left current tuple 
convention count 
key feature structure count field records relative absolute offset data structure 
pointer field secure hash identifies verifies child node 
pointer fields form merkle tree structure making self verifiable 
shows example data structure 
maintaining relative offsets enables efficient incremental insert operations 
shown result inserting bytes offset data structure shown 
blocks modified operation shaded 

describe algorithm insert block ciphertext data structure 
space constraints preclude defining algorithms operations operations implemented set basic techniques 
insert operation allows client insert chunk object 
data block potentially encrypted text inserted offset insert data 
recall insertion point lie existing block boundary current discussion 
discussion refer illustrates result insert operation data object 
algorithm descend node accommodate new child 
root full create new internal node root assign old root child split child 
split procedure works fashion similar traditional tree split operation 
node root proceed step 
node contains array tuples describing range data may reached child node 
state find child parent insertion point find count count 
count count data size mark child pointer modified 
node leaf node skip step proceed step 
prepare descend child 
child referenced pointer full split child adjust accordingly point new child parent insertion point 
node pointer 
handle relative offsets count 
recurse step 
insert new tuple offset count count data size pointer hash data 
operation complete 
new data inserted ability verify data structure lost 
restore verifiability actions update applied perform depth traversal data structure recomputing secure hash modified blocks storing result parent 
traversal need descend children modified 
amount data hashed update proportional amount modified 
algorithm extended maintain verifiability modification 
updates contain multiple operations save computation restoring verifiability modifications completed 

supporting arbitrary insertions solution previous section supports points modification existing block boundaries 
functionality sufficient support technique section simple extension enable flexible transformations 
extension allows data structure support insertion deletion arbitrary offsets 
leaf internal nodes add tuples additional field called offset 
added field point middle block encrypted data stored data node 
extension illustrated 
example update data structure holds chunks data bytes bytes 
count bytes starting offset set encrypted data stored data node 
bytes block referenced tuple shown unreferenced current version 
shows result updating data object 
inserting bytes offset bytes data starting offset data node 
bytes range data node starting offset 
algorithms modify data structure similar modify data structure section 
extension provide additional capabilities comes additional complications especially related security performance 
example data nodes may store data deleted current version data object 
manipulating blocks directly malicious attacker reconstruct information change history file 
course attacker need key decrypt data 
dead data performance liability 
retrieving data object infrastructure may require retrieving extra data longer relevant current version document 
despite complications extension opens possibilities 
example carefully defined data update offset insert bytes count offset offset count simple extension allows data structure support insertion deletion data arbitrary offsets 

mat application stale copy data object submit update retrieving current version merging changes 
alternatively application dynamically trade computation bandwidth depending current level connectivity 
low bandwidth conditions submit smallest update possible 
connectivity restored application retrieve data object data rewrite infrastructure efficient manner 
application written exploit asymmetric nature networking technologies 
example typical cable modem provides times amount downstream bandwidth upstream bandwidth 
application submit small updates uploaded infrastructure quickly result efficient storage data structure knowing extra downstream bandwidth enable quick retrieval document 
exploring applications techniques improve client perceived performance 

implementation evaluation validate approach described sections implemented scheme oceanstore prototype 
chose evaluate approach implementation performance variability components full design 
evaluate technique created model peer peer storage infrastructure 
modeling infrastructure able isolate control features relevant evaluation ignoring issues obscure results 
key abstraction model inner ring single server eliminating performance variability caused byzantine agreement 
abstraction conservative effect results 
full system client send request single inner ring member forward request inner ring members 
assume bandwidth inner ring machines greater weak connection client infrastructure 
system bottleneck client link able observe benefit simulating connection 
key client inner ring network link low bandwidth evaluation uses simple simulator emulated low bandwidth network link 

tion client inner ring communicate direct point point connection eliminate variable latency routing messages peer peer networking layer 
developed simple simulator model abstraction 
simulator written java eventdriven architecture toolkit developed part bamboo project 
client simulator executes traces file activity computes file summaries updates submits requests inner ring 
inner ring simulator serializes applies updates serves blocks read requests 
simulators communicate tcp emulated restricted network connection 
configuration shown 
comparison implemented alternative approaches current systems 
approach treats entire file single chunk 
single byte file changed data shipped inner ring update 
analogous approach employed past 
block approach divides file fix sized blocks traditional file system divides file blocks storage disk 
scheme inner ring represents data standard tree 
file modified blocks changed need submitted inner ring 
simulations block bytes 
similar approach cfs 
compare experimental results computed ideal latency 
ideal latency computed quantity assuming operation latency depends speed network transmission 
size update computed binary diff algorithm combination techniques rsync assumes inner ring perform arbitrary transformations data 
furthermore assumed computation infinitely fast data stored ciphertext storage overhead 
approach chunks identified rabin fingerprints minimum chunk size bytes maximum chunk size bytes 
sha algorithm secure hashing algorithm best known implementation unix diff utility comparing file summaries 
user data encrypted rijndael aes cipher bit keys 
technology latency ms bandwidth kb cellular modem telephone modem cable modem lan connection table 
parameters control weak link client inner ring 

experimental setup components simulator run simultaneously single dell dimension desktop ghz pentium processor gb ram running linux 
emulate low bandwidth network connections impose delivery delay messages receiver 
assume simple model bandwidth latency defined constant client server 
compute delay familiar formula corresponds latency corresponds bandwidth size current message bytes 
actual network connection components loopback network device ignore latency imposes 
table shows bandwidth latency parameters 
correspond roughly cellular modem telephone modem cable modem lan connection 
performance numbers mean trials 
variance negligible cases 

workloads evaluate scheme workloads summarized table 
workload composed consecutive versions document created microsoft word 
page document outlines engineering results public works design project includes figures graphs 
create second version performed global search replace operation change name city contracting project 
changed instances covering pages document 
called word workload 
second workload consecutive source code releases february bamboo dht event driven programming toolkit february th release modified files ranging size kb kb 
called bamboo workload 
current previous bamboo releases available www bamboo dht org 
name files total commonality size kb block rabin ideal word bamboo mbox table 
workloads evaluate effectiveness system varied size commonality consecutive versions different chunking strategies 
final workload uses versions user email folder stored mbox format 
user saves new messages folder increasing size folder 
mbox format messages appended mail folder leaving head file 
workload referred mbox workload 
table shows percentage commonality workloads different chunking techniques 
define commonality ratio bytes chunks previous version total bytes new version 
course approach shown table unable identify commonality workload 
block approach able detect little commonality word workload application modifies header update 
bamboo workload recognize commonality occurs insertion point files 
mbox workload appends data file successfully recognize nearly common data previous version 
approach able detect commonality workloads 
word workload recognizes data previous version despite change header 
similarly bamboo workload able extract additional commonality point modification block approach 
detects similar amount common data mbox workload 
slight variation due difference chunk boundaries techniques 
ideal computation able detect large amount commonality workloads 
able extract significantly commonality assumes inner ring perform arbitrary transformations define transformations byte chunk granularity 

experimental results evaluation measuring costs incurred client scheme 
cost additional storage required store file summaries 
overhead storing file summaries mb cable kb kb mb cable kb kb mb cable kb kb update latency relative block ideal word bamboo mbox impact client perceived write latency different workloads variety networking technologies 

studied workloads ranges megabytes gigabyte stored data 
client compute chunk boundaries translate file summaries updates 
unoptimized java code client detect chunks rabin fingerprints rate ms megabyte data 
cost creating update dependent length file number new chunks 
word workload example takes ms create update time ms spent unavoidable task encrypting data 
measure impact technique write latency 
shows client perceived latency writing various workloads server 
measure time update data object stored inner ring second version workload 
approach performs word mbox workloads 
word workload vastly outperforms variations recognizing larger amount commonality versions 
mbox workload block approach able recognize similar amount commonality scheme performs roughly equal simpler flexible block scheme 
approach slightly slower block scheme recognizes common data see table lower computational overhead 
workload tailored benefit block scheme approach performs competitively 
approach performs better approaches bamboo workload overhead compared ideal scheme higher 
bamboo workload small changes spread files 
slow performance scheme relative ideal represents cost ensuring privacy efficiency peer peer system approach modify chunks individual bytes data encryption restricts transformations performed inner ring ciphertext managed larger blocks efficiency 
measure impact technique read latency 
assume client copy version workload local cache 
requesting file client discovers newer version created retrieve chunks reconstruct new version locally 
situation arise user accesses data multiple machines devices 
presents results test 
scheme faster word workload 
block scheme performs slightly better scheme block scheme detects slightly commonality files 
bamboo workload scheme faster 
note reading data infrastructure block schemes pay penalty retrieving internal nodes data structure 
block approach performs worse method overhead coupled lack detected commonality 
scheme able detect sufficient commonality overcome penalty perform better approach 

peer peer storage infrastructures promise provide globally accessible highly available storage users 
infrastructures great benefit home mobile users currently access storage properties 
defining characteristic class users network connectivity low bandwidth links 
client side technique exploits commonality consecutive versions files reduce bandwidth required store retrieve objects developed novel data structure supports efficient insertion deletion ciphertext blocks variable size mb cable kb kb mb cable kb kb mb cable kb kb read latency relative block ideal word bamboo mbox impact client perceived read latency different workloads variety networking technologies 

support technique 
technique data structure integrate smoothly existing systems revealing user data infrastructure 
implemented scheme oceanstore prototype 
created simulator understand performance characteristics technique 
simulations show approach reduces read write latency compared techniques current systems 
hope measure performance improvement wider range real world workloads 
explore potential benefits extended features data structure 
acknowledgments authors steven czerwinski anonymous reviewers comments drafts 
oceanstore group development pond prototype 
adya bolosky castro douceur howell lorch theimer wattenhofer 
farsite federated available reliable storage incompletely trusted environment 
proc 
usenix osdi pages dec 
carey dewitt richardson shekita 
object file management exodus extensible database system 
proc 
vldb pages aug 
dabek kaashoek karger morris stoica 
wide area cooperative storage cfs 
proc 
acm sosp pages oct 
howard kazar menees nichols satyanarayanan sidebotham west 
scale performance distributed file system 
acm trans 
comput 
syst feb 
macdonald 
file system support delta compression 
master thesis university california berkeley 
manber 
finding similar files large file system 
proc 
usenix winter technical conference pages jan 
merkle 
digital signature conventional encryption function 
proc 
crypto pages 
muthitacharoen chen mazieres 
network file system 
proc 
acm sosp pages chateau lake louise banff canada oct 
myers 
nd difference algorithm variations 
algorithmica pages 
rabin 
fingerprinting random polynomials 
technical report tr department computer science harvard university 
rhea eaton geels weatherspoon zhao kubiatowicz 
pond oceanstore prototype 
proc 
usenix fast pages mar 
rhea geels roscoe kubiatowicz 
handling churn dht 
proc 
usenix technical conference june 
rowstron druschel 
storage management caching past large scale persistent peer peer storage utility 
proc 
acm sosp pages oct 
spring wetherall 
protocol independent technique eliminating redundant network traffic 
proc 
acm sigcomm pages aug 
satyanarayanan karp bressoud perrig 
opportunistic content addressable storage distributed file systems 
proc 
usenix technical conference pages june 
tridgell 
rsync algorithm 
technical report tr cs department computer science australian national university 
weatherspoon wells kubiatowicz 
naming integrity self verifying data peer peer systems 
proc pages june 

