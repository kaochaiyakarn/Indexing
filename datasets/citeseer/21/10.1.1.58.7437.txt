brian davison 
learning web request patterns 
poulovassilis levene eds web dynamics adapting change content size topology pp 
springer 
learning web request patterns brian davison department computer science engineering lehigh university memorial drive west pa usa email davison lehigh edu summary 
requests web behalf human users human computer interactions actions user characterized identifiable regularities 
patterns activity user users identified exploited intelligent mechanisms learning web request patterns 
focus markov probabilistic techniques predictive power popularity web modeling domains 
history mechanisms provide strong performance predicting requests performance improved including predictions additional sources 
chapter review common approaches learning predicting web request patterns 
provide consistent description various algorithms independently proposed compare performance techniques data sets 
discuss concerns accurate realistic evaluation techniques 
modeling user activities web value content providers consumers 
consumers may appreciate better responsiveness result pre calculating pre loading content local cache advance requests 
user requesting content served cache able avoid delays inherent web congested networks slow servers 
additionally consumers may find adaptive personalized web sites suggestions improve navigation useful 
likewise content provider appreciate insights modeling provide financial benefits happier consumer gets information desired faster 
requests web behalf human users human computer interactions actions user characterized having identifiable regularities 
patterns activity davison user users identified exploited intelligent mechanisms learning web request patterns 
prediction different data mining approaches web logs 
wish build relatively concise model user able dynamically predict action user take 
data mining web logs contrast typically concerned characterizing user finding common attributes classes users predicting actions purchases concern interactivity immediate benefit see kdd cup competition 
consider application machine learning techniques problem web request sequence prediction 
particular wish able predict web page user select 
chapter demonstrate machine learning models real world traces predictive accuracies better depending trace 
sequence prediction general studied problem particularly data compression field :10.1.1.51.7802
unfortunately web community rediscovered techniques leading islands similar dissimilar vocabulary 
re examine techniques offer modifications motivated web domain 
chapter describe implement experimentally evaluate number methods model usage predict web requests 
focus markov markov probabilistic techniques predictive power popularity web modeling domains 
prediction applied various types web workloads seen clients proxies servers 
location provides different view web activities context occur 
result different levels performance possible 
briefly consider information retrieval techniques allow content web pages help predict requests 
history mechanisms provide strong performance predicting requests find performance improved including predictions additional sources 
contributions chapter include consistent description various algorithms independently proposed development utilization generalized prediction codes implement techniques consistent comparison performance techniques data sets 
section detail concerns accurate realistic performance assessment describe approaches take empirical evaluation various web request prediction algorithms 
section review common approaches learning predicting web request patterns 
section describe workloads system summarized section 
discuss experimental results sections 
alternative history prediction proposed section 
section reviews findings chapter 
evaluation concerns approaches learning web request patterns existing learning web request patterns performed researchers disciplines discuss various aspects evaluate compare web request prediction algorithms 
high level concerns address questions modify typical evaluation approaches better fit domain modify predictions better fit domain 
type web logs important aspect experimental data sets experiments 
introduce web workloads section type workload evaluation issue 
high level simply concerned methods learn models typical web usage 
lower level models simply identifying occurrences resources ultimate goal accurate predictions resources requested particular context 
multiple types relationships web resources cause recognizable occurrences web logs 
possible relationship embedded object referring page object image audio java applet automatically retrieved browser referring page rendered 
relationship traversal user clicks link referring page page 
embedding solely aspect content prepared 
second traversal likewise existing link placed content creator function users navigate web hypertext 
researchers see example distinguish relationships choose predictions embedded resources :10.1.1.41.677
concerned click stream analysis just sequence requests user set automatically requested additional resources 
data provide distinction web server records referrer access logs captures traversal relationship 
referrer header required field available 
cases analysis data required label kind request example requests embedded links usually highly concentrated time near referring page 
unfortunately publicly available access logs provide sufficient detail allow distinctions conclusively 
addition methods click stream data exclusively require complex implementation assume embedded resources prefetched automatically requires parsing may resource retrievals easily parsed result javascript java execution 
result chapter chosen disregard davison type content question embedded resource logged requests data training prediction 
approach taken bestavros fan 
user request averaging calculate average performance user termed request basis 
performance treats users equally users active generate traffic 
contrast performance emphasizes requests highly active users 
predictions approaches examine user basis basis user previous request necessarily request system don build user predictive models 
individual models behavior require space tend accurate see data global model 
experiments build global models thought modeling typical user web servers proxies consider user models making predictions client 
comparison report request averages 
user request sessions session period sustained web activity user 
traces users request activities broken sessions 
practice may helpful mark session boundaries learn prefetch alternately may desirable prefetch page user request session 
analyzed data sets sessions purposes chapter trace treated set user strings tokens 
web log contains interleaved requests clients algorithms consider prediction client solely context requests client 
addition matter time passed previous request client actual request 
request received matches predicted request considered success 
batch versus online evaluation traditional approach machine learning evaluation batch approach data sets separated distinct training test sets 
algorithm attempts determine appropriate model learning training set 
model statically test set evaluate performance 
approach number web prediction papers 
certainly learning web request patterns case system validation normal approach apply predictive algorithms incrementally request serves update current user model assist making prediction request 
matches approach taken web prediction papers :10.1.1.41.677:10.1.1.43.33
model arguably realistic matches expected implementation system learns past improve predictions 
similarly approach test code requests just fraction assigned test set caveat performance poor initially user model acquired knowledge initial warming phase evaluation performed alleviate effect 
prediction system simulated actual system note predictions may cause user actual perceived behavior change 
prefetching user may request document faster delay fetching preloaded cache 
likewise proxy server model sends hints prefetch content browser change stream comes browser contents cache changed 
predictive system may adjust change activity caused operation 
alternatively appropriate extensions browser tell server requests served cache suggested 
helpful incorporate caching effects chapter limit models built requests evaluation 
model appropriate prefetching clients proxies long don depend server hints built additional data 
selecting evaluation data online user predictive model impossible proxy know predict request client connected previously 
note predictions server side optimization generic prefetch request user may helpful feasible similarly clients generic pre loading request helpful 
likewise test predictions user request sample trace 
question data evaluation arises 
track performance metrics generally plot performance broadest metric number correct predictions total number requests 
potentially underestimate performance requests unique requests requests repeated counted may factor time 
break data user sessions larger factor requests handled 
davison confidence support real world implementation scenarios cost prediction 
example cost cognitive predictions generate increased cognitive load user interface 
cost financial prefetching cost byte retrieved 
may wish consider exactly wish prediction words refrain guess opportunity 
consider mechanisms reduce limit likelihood making false prediction 
thresholds confidence 
confidence loosely defined probability predicted request typically fraction number times predicted request occurred context past 
methods probabilistic predictors possible prediction considered associated probability 
enforcing minimum threshold restrict predictions high expected probability correct 
thresholds type previously :10.1.1.43.33:10.1.1.31.8129
thresholds support 
support strictly number times predicted request occurred context 
prediction probability confidence high value small number examples 
providing minimum support limit predictions sufficient experience warrant prediction :10.1.1.46.5428
typically factors combined function 
calculating precision ability place minimum thresholds confidence support system may choose refrain making prediction 
addition accuracy correct predictions requests calculate precision accuracy predictions predictions 
exact selection denominator uncertain 
note choices requests prediction attempted requests prediction compared 
includes predictions requests received request received client 
judge predictions reporting precision definition 
fact su go requiring thresholds page popularity support ignoring sequences minimum length 
top predictions learning web request patterns variations described provide probabilities determine prediction 
typically multiple predictions possible varying confidence support 
may useful feasible predictions object simultaneously explore costs benefits various sets predictions 
long additional predictions exceed minimum confidence support values generate maximum prediction list length top predictions prediction example prefetching depending evaluation metric may matter successful long predictions chosen user 
systems direct limits number predictions 
effective limits achieved thresholds confidence support available transmission time embedded prefetching system 
chapter directly limit number predictions consider various threshold values 
limits typically needed trade resources expended versus benefits gained trade depends environment predictions 
prediction techniques section describe number prediction algorithms variations web researchers 
grams markov models typically term sequence describe ordered set actions web requests case 
name statistical natural language processing ordered set gram 
gram sequence items 
example ordered pair example gram bigram appeared followed prediction try match complete prefix length current context gram predict nth request item gram 
may multiple grams prefix requests grams natively provide means track frequency mechanism needed determine gram matching request prefix prediction 
markov models provide means tracking likelihood ngram state space encoding past 
approach explicitly markov assumption says request function strictly current state 
step markov model state represents sequence previous requests context probabilities davison fig 

sample node markov tree 
transitions possible states 
fixed states system number possible requests 
state markov model corresponds sequence requests comprise prefix gram 
nth element ngram request determines destination link state state label corresponding requests gram 
markov model encompass information multiple grams additionally tracks likelihood moving state 
typically fixed small practice limit space cost representing states 
system allow arbitrary size practice typically relatively small values primarily long sequences infrequently repeated web 
markov trees capable mechanism representing past activity form usable prediction markov tree transitions root node children represent probabilities zero th order markov model transitions children correspond order model 
tree stores sequences form trie data sequences different sessions followed 
fig 

sample trace simple markov tree depth built 
sequence initial tree possibly just root node learning web request patterns min ss subsequence containing items pointer ss increment ss ss increment exists child increment add new node list children point child ss increment fig 

pseudocode build markov tree 
structure stores elements tree path root leaf described key sequence case 
description individual node shown 
depicts example markov tree depth information recorded having visitors request sequences 
root node corresponds sequence context come 
zero th order markov model interpretation find naive probability item sequence items respectively 
context probability model 
probabilities calculated node divided parent 
process clear pseudocode build markov tree provided illustrates step process 
sequence steps taken update tree described get tree 
suffixes sequence starting empty sequence 
sequence length zero go root increment 
sequence length start root update child update node 
sequence length start root travel child update find need add new child 
update davison markov tree sequence 
markov tree sequence 
fig 

incrementally updating simple markov tree 
add new node 
assuming limiting tree depth finished process 
path point profiles building markov tree sufficient depth match sequences prediction 
schechter describes predictive approach effectively markov tree similar described 
authors call approach path profiles name borrowed techniques compiler optimization contrasted point profiles simply bigrams order markov models 
longest path profile matching current context prediction frequency occurrence select equal length profiles 
th order markov models markov tree general find th order markov probabilities traversing tree root order items current context 
researchers models roughly equivalent order markov models corresponding trees depicted web request prediction domains unix command prediction hardware memory address prefetching :10.1.1.48.3514
second order markov models give better predictive accuracy higher order models fourth order 
learning web request patterns non trivial markov model particular order instances current context model 
examples include context shorter order model contexts introduced new item known alphabet set requests seen far 
earlier mentioned longest matching sequence path profile prediction 
approach taken markov models 
data markov models high order typically provide high accuracy largest matching context commonly approach taken 
pitkow pirolli deshpande karypis take route consider variations prune tree reduce space time needed prediction implement thresholds confidence support testing validation set minimum differences confidence second predictions 
su combine multiple higher order gram models similar manner 
interestingly li argue contrast longest match best provide pessimistic selection method quinlan pessimistic error estimate choose context highest pessimistic confidence applicable contexts regardless context length 
show approach improves precision context gets larger 
ppm course ways incorporate context prediction mode 
ppm prediction partial matching typically powerful method data compression 
works similarly simple markov model approach largest permissible context encode probabilities item 
tracks probability item seen context called escape symbol compression explicitly says smaller matching context 
multiple versions ppm correspond different ways calculating escape probability ppm ppm ppm 
item sequence probability levels longest matching context matching contexts examined sum probabilities candidate prediction appropriately weighted preceding level escape probability 
accomplished merging current set predictions shorter context multiplying probabilities shorter context escape symbol confidence longer context multiplying longer context 
various escape probabilities calculated counts stored markov tree 
researchers ppm models web prediction 
fan go building markov trees larger contexts 
large contexts order prediction davison trace name described requests clients servers duration epa day music machines months months ucb days days ucb clients section days ucb servers section days table 
traces prediction characteristics 
context smaller say remaining portion tree predictions requests steps advance 
additional parameters addition varieties described prediction system vary number parameters motivated web domain 
explicitly test size prediction window window requests prediction tested 
typically evaluation performed measuring accuracy predicting request 
predicting request measure accuracy prediction match requests 
may useful matching utility preloading cache resource may useful 
prediction workloads primary types web workloads corresponding viewpoints traffic 
characterize describe datasets type 
summary datasets table 
proxy typically sitting set users web servers proxy sees limited user base origin web servers cases proxy may inherently group users overlapping interests users workgroup corporate proxy may view content 
typically records requests served browser caches logs may contain overlapping user requests proxies different users assigned ip address different times 
models built proxies vary typical user single model highly personalized models individual user 
case predictive model prefetch directly cache provide hints client cache prefetching 
learning web request patterns proxy trace experiments 
uc berkeley home ip traces record web traffic collected steve gribble graduate student november 
gribble snooping proxy record traffic generated uc berkeley home ip dialup wireless users kbps kbps kbps land line modems kbps bandwidth wireless modems 
large trace selected days comparison fan total close requests 
client client necessary participants web transaction 
researchers recorded transactions client browser making possible see exactly user clicking links typing urls navigational aids back forward buttons bookmarks 
typically necessary log level capture activity served browser cache 
individual client history build model client provides opportunity predictions highly personalized reflect behavior patterns individual user 
unfortunately logs augmented browsers rare 
subset requests captured upstream proxy ucb dataset understanding traces reflect user requests just served browser cache 
extracted individual request histories ucb proxy trace 
clients identified proxy traces unique ip addresses really individual users 
proxies configured hierarchy proxy caches concerned possibility proxy traces clients really proxy caches multiple users proxies 

likewise client corresponds particular non proxy system may correspond mechanized process repeatedly fetches resource small set resources 
correspond highly regular request patterns correspond overlapping request patterns attempt avoid worst concern fairness evaluation 
ranked clients total numbers requests ignored top selected second representative set active users 
server servers provide complementary view web usage clients 
seeing requests user see requests web sites 
know requests particular sites logs contain information client transitions davison systems 
technically referrer header provides information transitions particular site rarely provided publicly available logs 
learning predictive model server build individual model user 
useful personalize content web site individual user provide hints client browser resources useful prefetch 
difficulty relative scarcity information user visits repeatedly providing data typical site visit commonly contains requests handful resources 
alternative build single model typical user providing directions may say users request resource fetching resource trends common approach finds 
single model provide information site re design better navigation 
extremes lies potential collaborative filtering approach individual models users contribute suggest requests useful current user pointed zukerman clustering users 
experiments chapter generally build single model traffic seen model stored 
server build single model corresponding particular user effectively model typical behavior seen 
addition described predictive web server usage models improve server performance memory caching reduced disk load reduced loads back database servers 
similarly prefetching separate server specific reverse proxy cache similar benefits 
server logs widely available relative kinds logs limitations record requests non server resources see responses served downstream caches browser proxy 
experiments chapter traces servers 
epa server logs contain close requests corresponding hours service august 
second months usage music machines website collected september october 
web traces music machines website specifically configured prevent caching log represents requests just browser cache misses 
third trace approximately months non local usage website small software development 
site hosted dedicated modem non trivial contexts markov model order greater effectively clusters user users experienced context 
learning web request patterns collected 
additionally extracted popular servers ucb proxy trace 
experimental system section describe experimental prediction system subsequent experiments 
implementation implement various sequence prediction methods highly parameterized prediction system implemented approximately lines code 
markov tree data structure described section works complex algorithms just ignore aspects simpler ones 
effect built essentially laird saul call transition directed acyclic graph 
limit depth tree explicitly limit number predictions 
contrast additionally employ mechanism limit expansion tree eliminating nodes graph rarely visited 
mentioned section confidence support thresholds believed useful code incorporates thresholds general provides minimum maximum gram length prediction 
purposes tests focus potential predictive performance accuracy ignore certain aspects implementation efficiency 
particular codes designed generality necessarily efficiency 
validation order help validate prediction codes replicated extent possible server request prediction experiment 
experiment epa data set requests training data remainder testing 
set tests identically configured prediction codes order markov model gram size minimum support confidence needed predict 
remainder experiments chapter experiment builds model initial training data freezes test data 
static prediction model corresponds closely performance test markov chains reported 
approximately absolute increase predictive accuracy system allowed incrementally update model moves test set 
davison fraction requests predicted correctly ucb servers music machines ucb clients number predictions allowed fig 

predictive accuracy bigrams order markov models data sets varying numbers allowed predictions 
epa logs short especially test set consider performance prediction server logs subsequent tests figures 
provide realistic measure performance incremental predictive accuracy rest chapter 
experimental results section examine effect changes various model parameters predictive performance 
way determine sensitivity model data sets small large changes parameter values find useful settings parameters tested data sets 
increasing number predictions depending situation predictive system embedded may helpful predict set top possible actions described section 
examine incremental predictive performance simple bigrams varying single parameter number predictions permitted traces ucb servers music machines ucb clients 
initial case allowed prediction find performance ranges slightly close accuracy 
number predictions allowed increases predictive performance increases significantly relative improvement 
server traces show marked performance increases demonstrating traces contain sufficient data include choices user 
performance client trace conversely remains low demonstrating experience individual user insufficient include activities user perform 
relative improvement learning web request patterns music machines ucb servers ucb clients maximum gram size fig 

relative improvement predictive accuracy multiple data sets maximum context length grows compared context length 
note achieve high levels predictive performance systems need predictions come resource cost time bandwidth cpu usage 
increasing gram size potential way improve accuracy consider grams larger 
increase context allows model learn specific patterns 
shows relative improvement compared incremental predictive accuracy multiple traces making just prediction step 
accuracy accuracy relative improvement traces shown zero improvement 
case longest gram prediction ties broken selecting higher probability gram grams permitted corresponding predictions request popularity matches 
graph shows adding longer sequences help predictive accuracy improvement peaks longer rarer accurate sequences prediction 
shows larger grams useful largest grams prediction performance significantly harmed 
longer grams match fewer cases shorter grams able fewer correct predictions 
incorporating shorter contexts prediction partial match provides automatic way contexts shorter longest matching 
experiments find ppm result subsequent tests gram limit inclusion larger grams typically improve performance 
davison relative improvement ucb clients ucb servers music machines prediction window size fig 

relative improvement predictive accuracy window requests prediction tested grows 
variations able perform slightly better comparable longest gram match 
ppm gives best results relative improvements ranging best prediction 
multiple predictions permitted performance improvement smaller 
endow grams ability incorporate shorter grams 
alternative grams merge results prediction shorter context fixed weight opposed weight dynamically calculated escape probability ppm model 
experiments reveal similar relative improvements percent 
increasing prediction window way improve reported accuracy allow predictions match just request 
real web system prefetched content cached available satisfy user requests 
argue prediction match request incorrect 
prediction matches applied request count correct 
test apply web specific heuristic measuring performance 
graph relative performance improvement results allow predictions match subsequent requests 
requests performance continues increase rate growth tapering 
apparent boost potential performance suggests request predicted perfectly predicted requests potentially executed near 
predictive accuracy mechanisms described limited recurrence rates sequences examined 
section consider predicting history means unique request predicted introduced 
precision correct predicted learning web request patterns music machines ucb servers ucb clients fraction predicted correctly fig 

ratio precision accuracy minimum support varying confidence 
plot predictive performance scale possible graphs absolute percentage points higher 
considering mistake costs accuracy typically important researchers 
real world costs mistakes 
number allowed predictions request increases fraction predicted correctly grows number predictions needed get accuracy increases significantly 
prefetching scenario mistakes kept music machines average request bandwidth times non prefetching bandwidth 
note analysis consider positive extensive effects caching 
important point tradeoff case increasing coverage consume additional bandwidth 
worthwhile consider reduce limit likelihood making false prediction discussed section 
increased precision possible lower accuracy threshold increased 
likewise larger values precision possible come cost number requests predicted correctly 
provides combined view minimum support instances combined varying confidence threshold 
ideal performance right high precision accuracy 
combination minimum support varying threshold confidence able achieve precision exceeds possible threshold 
lesson high accuracy predictions quite achievable typically applicable smaller fraction trace 
davison discussion demonstrated various techniques improve predictive accuracy logs web requests 
methods combined leading significant improvements 
order markov model able get approximately top predictive accuracy trace 
top version increase predictive accuracy 
adjustments including ppm version maximum gram reducing predictions cache including past predictions weight accuracies possible 
put way constitutes reduction error 
consider predictions tested ignoring client requests get prediction accuracy 
performance course comes cost large number guesses 
case making guesses time 
alternatively lower accuracy higher precision possible modifications confidence support thresholds 
investigators focused issue 
simplistic model occurrence jiang kleinrock develop complex cost metric delay cost server resource cost determine threshold prefetching consider system load capacity costs 
likewise zukerman develop decision theoretic utility models balance cost benefit evaluation 
shown evidence patterns activity user change time :10.1.1.48.3514
true web users 
user interests change activity recorded may change need revisit site user remembers content user different concern 
users provide source change time patterns usage logs 
additional experiments traces second source change significant changes content :10.1.1.140.9353
user actions visiting page depend content pages 
pages change content links removed request stream generated user change corresponding relative cost accuracy 
conclude long web access primarily information gathering process server side changes drive changes user access patterns 
astute reader may noticed mentioned proxy workloads completeness back section included figures shown provide significant additional information 
running ucb client workloads calculating client side predictive accuracy report calculated accuracy proxy predictor achieved 
general accuracy higher relative client accuracy absolute terms 
learning web request patterns order markov model allowing just guess thresholds asymptotic predictive accuracy close ucb trace 
alternative prediction mechanisms history mechanisms discussed far significant flaw predict request previously 
worth considering alternative mechanisms combining predictions different algorithms 
motivating goal accurately predict request individual user www 
want know helpful web page content making predictions requested 
experimentally validated widespread assumptions web pages typically linked pages related textual content specifically anchor text reasonable descriptor page pointed :10.1.1.140.9353
applications take advantage web characteristic indexing terms target page extract high quality descriptions page exploit property web 
relatively researchers considered simplistic approaches prediction web page content 
web html contains links followed consider predicting links 
links 
predict links page number links page quite large 
slightly intelligent approach predict links page html source order corresponding generally links visible top bottom 
compare full content web log simple approaches information retrieval ranks list links measure textual similarity set pages accessed user 
summary textual similaritybased predictions outperform simpler approaches content approach better random link selection prediction better prefetching system infinite cache 
content approaches predictions history mechanisms combining predictions algorithms resulted increased predictive accuracy achieving sum individual accuracies 
summary chapter examined detail problem predicting web requests focusing markov markov algorithms build models davison past histories requests 
discussed problems evaluation provided consistent description algorithms researchers domain 
generalized codes implement various algorithms described test prediction algorithms set web traces facilitating performance comparisons 
demonstrated potential probabilistic markov methods web sequence prediction 
exploring various parameters showed larger models incorporating multiple contexts outperform simpler models 
cited evidence web content changes models learning user behavior provide emphasis activity adapt changes 
demonstrated performance changes result web inspired algorithm changes 
results recommend multi context predictor ppm multicontext gram approach described chapter 
web appears relatively contexts needed grams don need 
saw utilization thresholds prediction significantly reduce likelihood erroneous predictions 
noted history algorithms able predictions scenarios described experiments utility content predictions 
open questions chapter explored aspects learning web request patterns open questions remain 
list trade complexity storage versus predictive accuracy 
laird saul chen zhang started answer question 
role client side caching model accuracy 
proxy server model see requests satisfied browser cache model build entirely accurate 
mention section possibility tell upstream server requests satisfied downstream cache 
important question effect extra information performance prediction model 
effect referrer tags model generation 
previous question issue concerned part client cache 
referrer tag automatically provides view cache lists source link requested 
may page satisfied downstream cache part request stream seen model generator 
particular helps capture uses browser back button build better model current click credited page link request usage log 
learning web request patterns role request timestamps play model generation accuracy 
researchers assume non html requests received sufficiently near html request shown timestamps represent embedded objects considered separate clicks discussed section 
timestamps model links various types 
requests near time easily believed highly associated 
likewise sequential requests far apart assume new session started unrelated 
intermediate values association possible requests somewhat nearby possibly requests 
appropriate evaluation methods tied real world utility 
predictive models need evaluated context 
prefetching improvement user perceived response time realized various prediction approaches 
similarly improvements user satisfaction increased purchases occur personalized pages 
clear improvement performance system consistently matches improvement predictive performance 
effect prediction classifying user browsing modes 
user known performing regular activity reading daily sports headlines user specific model behavior appropriate global model 
past researchers attempted categorize browsing modes classes surfing searching may provide assistance predicting requests 
acknowledgments supported part nsf ani 
davison 
david albrecht ingrid zukerman ann nicholson 
pre sending documents www comparative study 
proceedings sixteenth international joint conference artificial intelligence ijcai volume pages stockholm sweden 
morgan kaufmann 

amitay 
common hypertext links identify best phrasal description target web documents 
proceedings sigir post conference workshop hypertext information retrieval web melbourne australia 

amitay paris 
automatically summarising web sites way 
proceedings ninth acm international conference information knowledge management cikm washington dc november 

timothy bell john cleary ian witten 
text compression 
prentice hall englewood cliffs nj 

azer bestavros 
speculation reduce server load service time www 
proceedings fourth acm international conference information knowledge management cikm baltimore md november 

azer bestavros 
speculative data dissemination service reduce server load network traffic service time distributed information systems 
proceedings international conference data engineering icde new orleans la march 

sergey brin lawrence page 
anatomy large scale hypertextual web search engine 
proceedings seventh international world wide web conference brisbane australia april 

carla brodley ronny kohavi 
kdd cup 
online www ecn purdue edu kddcup 

lara catledge james pitkow 
characterizing browsing strategies world wide web 
computer networks isdn systems 

xin chen zhang 
coordinated data prefetching utilizing information proxy web servers 
performance evaluation review september 
proceedings nd acm workshop performance architecture web servers paws 

xin chen zhang 
popularity prediction model web prefetching 
ieee computer march 

ken ichi yamaguchi 
interactive prefetching proxy server improvement www latency 
proceedings seventh annual conference internet society inet june 

chun wei choo brian don turnbull 
working web empirical model web 
rd hawaii international conference system science hicss maui hawaii january 

cohen balachander krishnamurthy jennifer rexford 
efficient algorithms predicting requests web servers 
proceedings ieee info com new york march 

mark crovella azer bestavros 
self similarity world wide web traffic evidence possible causes 
ieee acm transactions networking december 
learning web request patterns 
carlos cunha 
trace analysis applications performance enhancements distributed information systems 
phd thesis computer science department boston university 

carlos cunha azer bestavros mark crovella 
characteristics www client traces 
technical report tr computer science department boston university july 

carlos cunha carlos 
determining www user access application prefetching 
proceedings second ieee symposium computers communications iscc alexandria egypt july 

kenneth krishnan jeffrey scott vitter 
practical prefetching data compression 
proceedings acm sigmod conference management data pages may 

brian davison 
topical locality web 
proceedings rd annual acm international conference research development information retrieval sigir pages athens greece july 

brian davison 
design evaluation web prefetching caching techniques 
phd thesis department computer science rutgers university october 

brian davison 
predicting web actions html content 
proceedings thirteenth acm conference hypertext hypermedia ht pages college park md june 

brian davison haym hirsh 
predicting sequences user actions 
predicting ai approaches time series problems pages madison wi july 
aaai press 
proceedings aaai icml workshop published technical report ws 

brian davison 
pushing improving web responsiveness packet time extended 
performance evaluation review september 
performance architecture web servers paws workshop june 

mukund deshpande george karypis 
selective markov models predicting web page accesses 
proceedings siam international conference data mining sdm chicago april 

dan duchamp 
prefetching hyperlinks 
proceedings second usenix symposium internet technologies systems usits boulder october 

fan xiang gen xia 
maximum likelihood texture analysis classification wavelet domain hidden markov models 
proceedings th asilomar conference signals systems computers pacific grove ca 

li fan quinn jacobson pei cao wei lin 
web prefetching clients proxies potential performance 
proceedings joint international conference measurement modeling computer systems sigmetrics atlanta ga may 

dan dennis 
reducing web latency hierarchical prefetching 
proceedings international workshop scalable web services conjunction icpp toronto august 

steven gribble 
uc home ip traces 
online www acm org sigcomm ita july 
davison 
steven gribble eric brewer 
system design issues internet middleware services deductions large client trace 
proceedings usenix symposium internet technologies systems usits december 

jeffrey ed chi 
identification web user traffic composition multi modal clustering information scent 
proceedings workshop web mining siam conference data mining pages chicago il april 

john craig wills anja martel joel 
combining client knowledge resource dependencies improved world wide web performance 
proceedings eighth annual conference internet society inet geneva switzerland july 

eric horvitz 
continual computation policies utility directed prefetching 
proceedings seventh acm conference information knowledge management pages bethesda md november 
acm press new york 

tamer ibrahim cheng zhong xu 
neural net pre fetching tolerate www latency 
proceedings th international conference distributed computing systems icdcs april 

jiang leonard kleinrock 
adaptive network prefetch scheme 
ieee journal selected areas communications april 

doug joseph dirk grunwald 
prefetching markov predictors 
transactions computers february 

reinhard 
friendly client side web prefetching agent 
ieee transactions knowledge data engineering july august 

philip laird 
discrete sequence prediction applications 
proceedings tenth national conference artificial intelligence menlo park ca 
aaai press 

philip laird ronald saul 
discrete sequence prediction applications 
machine learning 

bin lan stephane beng chin ooi 
making web servers 
proceedings workshop web usage analysis user profiling san diego ca august 

ian li qiang yang ke wang 
classification pruning web request prediction 
poster proceedings th world wide web conference www hong kong may 

henry lieberman 
autonomous interface agents 
proceedings acm sigchi conference human factors computing systems atlanta ga march 

tom mitchell 
machine learning 
mcgraw hill new york 

ann nicholson ingrid zukerman david albrecht 
decisiontheoretic approach pre sending information www 
proceedings th pacific rim international conference artificial intelligence pri cai pages singapore 

laura duke university 
epa server logs 
available ita ee lbl gov html contrib epa html 

venkata padmanabhan 
improving world wide web latency 
technical report ucb csd uc berkeley may 
learning web request patterns 
venkata padmanabhan jeffrey mogul 
predictive prefetching improve world wide web latency 
computer communication review july 
proceedings sigcomm 

alberto mendelzon 
web prefetching partial match prediction 
proceedings fourth international web caching workshop wcw san diego ca march 
progress 

mike perkowitz oren etzioni 
adaptive web sites ai challenge 
proceedings fifteenth international joint conference artificial intelligence 

mike perkowitz oren etzioni 
adaptive web sites automatically synthesizing web pages 
proceedings fifteenth national conference artificial intelligence madison wi july 
aaai press 

mike perkowitz oren etzioni 
adaptive web sites 
communications acm august 

peter pirolli james pitkow 
distributions surfers paths world wide web empirical characterization 
world wide web 

james pitkow peter pirolli 
life death electronic frontier 
acm conference human factors computing systems atlanta ga march 

james pitkow peter pirolli 
mining longest repeated subsequences predict world wide web surfing 
proceedings second usenix symposium internet technologies systems october 

ross quinlan 
programs machine learning 
morgan kaufmann san mateo ca 

ramesh 
link prediction path analysis markov chains 
proceedings ninth international world wide web conference amsterdam may 

stuart schechter murali krishnan michael smith 
path profiles predict requests 
computer networks isdn systems 
proceedings seventh international world wide web conference 

sen mark hansen 
predicting web user request log data 
journal computational graphical statistics 

glenn shafer prakash shenoy 
propagating belief functions qualitative markov trees 
international journal approximate reasoning 

zhong su qiang yang ye lu hong jiang zhang 
prediction system web request gram sequence models 
international conference web information systems engineering conference pages hong kong june 

swaminathan raghavan 
intelligent prefetching www client behavior characterization 
proceedings eighth international symposium modeling analysis simulation computer telecommunication systems mascots 

linda tauscher saul greenberg 
people revisit web pages empirical findings implications design history systems 
international journal human computer studies 

ian witten alistair moffat timothy bell 
managing gigabytes compressing indexing documents images 
morgan kaufmann san francisco 
second edition 
davison 
yi hung wu chen 
prediction web page accesses proxy server log 
world wide web internet web information systems 

qiang yang henry zhang ian li 
mining web logs prediction models www caching prefetching 
proceedings seventh acm sigkdd international conference knowledge discovery data mining kdd san francisco august 

michael zhen zhang qiang yang 
model predictive prefetching 
proceedings nd international workshop management information web web data text mining munich germany september 

ingrid zukerman david albrecht 
predictive statistical models user modeling 
user modeling user adapted interaction 

ingrid zukerman david albrecht ann nicholson 
predicting users requests www 
proceedings seventh international conference user modeling um pages banff canada june 
index gram accuracy batch browser click stream client history occurrences collaborative filtering confidence content prediction data mining embedded object embedding relationship epa server log evaluation order history prediction machine learning markov assumption markov model markov tree mistake costs modeling music machines server log online path profile performance evaluation point profile ppm pre loading precision prediction prediction partial matching prediction window predictive accuracy prefetching proxy proxy cache referrer header referring page request patterns sequence sequence prediction server hints session boundaries sessions server log support test set thresholds top training set index traversal relationship ucb home ip trace user clustering utility model validation web client web logs web proxy web server workloads 
