solving cluster ensemble problems bipartite graph partitioning zhang fern xz ecn purdue edu carla brodley brodley ecn purdue edu school electrical computer engineering purdue university west lafayette critical problem cluster ensemble research combine multiple clusterings yield final superior clustering result 
leveraging advanced graph partitioning techniques solve problem reducing graph partitioning problem 
introduce new reduction method constructs bipartite graph cluster ensemble 
resulting graph models instances clusters ensemble simultaneously vertices graph 
approach retains information provided ensemble allowing similarity instances similarity clusters considered collectively forming final clustering 
resulting graph partitioning problem solved efficiently 
empirically evaluate proposed approach commonly graph formulations show robust achieves comparable better performance comparison competitors 

clustering unsupervised data exploration analysis investigated decades statistics data mining machine learning communities 
advance clustering techniques development cluster ensemble consensus clustering techniques strehl ghosh fern brodley monti seek improve clustering performance generating multiple partitions data set combining form final presumably superior clustering solution 
techniques shown provide generic tool improving performance basic clustering algorithms 
appearing proceedings st international conference machine learning banff canada 
copyright authors 
critical problem designing cluster ensemble system combine ensemble clusterings order produce final solution referred cluster ensemble problem 
approach problem reducing graph partitioning problem 
graph partitioning input graph consists vertices weighted edges 
goal partition graph roughly equal sized parts objective minimizing cut sum weights edges connecting different parts 
choose solve cluster ensemble problems graph partitioning techniques reasons 
graph partitioning studied area algorithms spectral clustering successful variety applications shi malik dhillon :10.1.1.140.3011
second cluster ensembles provide natural way define similarity measures computing weight edges graph important hard satisfy prerequisite success graph partitioning techniques bach jordan 
previously strehl ghosh proposed approaches formulating graph partitioning problems cluster ensembles 
formulation instance approach models instances vertices graph computes weight edge similarity pair instances connects frequently clustered 
second formulation cluster approach models clusters vertices computes weight edge similarity clusters percentage instances share 
note reconstruct original cluster ensemble graph formed instance cluster approach indicating approaches incur information loss ensemble 
proposes new graph formulation simultaneously models instances clusters vertices bipartite graph 
graph retains information ensemble allowing similarity instances similarity clusters considered collectively construct final clusters 
resulting graph partitioning problem solved efficiently 
experimentally compare proposed graph formulation instance cluster approaches data sets 
understand impact different cluster ensemble types different approaches generating cluster ensembles applied 
experiments show formulations proposed bipartite approach achieves robust clustering performance 
data set bipartite formulation comparable cases significantly better approaches 
addition point natural connection cluster ensemble problems document clustering 
connection raises interesting questions cluster ensemble research suggests directions research 
remainder arranged follows 
section introduces basics cluster ensembles followed brief review related 
section introduces problem graph partitioning 
section describe instance cluster graph formulations 
bipartite graph formulation section 
section describe experimental design results section 
section concludes overview contributions discussion connection cluster ensemble problems document clustering 

cluster ensembles related section introduces basics cluster ensembles briefly reviews existing techniques solving cluster ensemble problems involve graph partitioning 

cluster ensembles cluster ensemble system solves clustering problem steps 
step takes data set input outputs ensemble clustering solutions 
second step takes cluster ensemble input combines solutions produce single clustering final output 
assume hard clusterings form ensembles 
noted graph formulation approaches examined applied cluster ensembles soft clusterings directly minor modifications 
formally define cluster ensembles state cluster ensemble problem 
data set xn ensemble set clustering solutions represented ensemble size number clusterings ensemble 
clustering solution simply partition data set kr disjoint clusters instances represented cr cr cr cr kr kc generally speaking value kr different clustering runs different 
techniques study applied cases 
cluster ensemble number desired number clusters solve cluster ensemble problem information provided partition disjoint clusters final clustering solution 
note cases original features may produce final clustering solution 
study focuses case generate ensemble 

related combining clusterings focuses combining clusterings graph partitioning alternative approaches exist 
commonly approach fred jain fern brodley monti combines clusterings generating similarity matrix instances applying agglomerative clustering algorithms produce final clustering 

propose represent cluster ensemble new set features describing instances produce final clusters applying kmeans em new features 
see representative combining clusterings 
performing thorough comparison available techniques scope studies strehl ghosh graph partitioning approaches appear highly competitive compared techniques 

graph partitioning section describes basics graph partitioning 
weighted graph represented set vertices nonnegative symmetric similarity matrix characterizing similarity pair vertices 
input graph partitioning problem weighted graph number partition graph parts find disjoint clusters vertices pk kpk graph strongly connected components way partition cross graph edges 
sum weights crossed edges defined cut partition cut vertices belong cluster 
general goal graph partitioning find partition minimizes cut subject constraint part contain roughly number vertices 
practice various graph partitioning algorithms define different optimization criteria goal 
examples include normalized cut criterion shi malik ratio cut criterion hagen kahng 
see depth discussion 
defer discussion choice graph partitioning algorithm section 
basics cluster ensembles graph partitioning ready explore various techniques reducing cluster ensemble problem graph partitioning problem 

existing graph formulations cluster ensembles section introduces existing techniques proposed strehl ghosh formulating graphs cluster ensembles 
rename techniques instance cluster approaches characterize differences 

instance graph formulation instance graph formulation ibgf constructs graph model pairwise relationships instances data set recall commonly agglomerative approach fred jain fern brodley monti generates similarity matrix cluster ensemble performs agglomerative clustering similarity matrix 
ibgf uses matrix conjunction graph partitioning 
formally describe ibgf 
cluster ensemble ibgf constructs fully connected graph set vertices representing instance similarity matrix gr xi gr xj function returns argument true gr takes instance returns cluster belongs cr measures frequently instances clustered ensemble 
fern brodley monti similarity measure shown give satisfactory performance domains similarity note cases bias unwarranted 
distance metric hard find 
graph constructed solve graph partitioning problem graph partitioning technique resulting partition directly output final clustering solution 
note ibgf constructs fully connected graph resulting graph partitioning problem size number instances 
depending algorithm partition graph computational complexity ibgf may vary 
generally computationally expensive approach proposed approach key disadvantage ibgf 

cluster graph formulation note clusters formed different clusterings may contain set instances largely overlap 
clusters considered corresponding similar 
cluster graph formulation cbgf constructs graph model correspondence similarity relationship different clusters ensemble partitions graph groups clusters group correspond 
cluster ensemble rewrite cr cr kr ci represents jth cluster formed ith clustering run ensemble denote total number clusters kr 
cbgf constructs graph set vertices representing cluster matrix similarity clusters ci cj computed jaccard measure ci cj ci cj partition clusters obtained produce final clustering instances follows 
consider group clusters 
clustering instance considered associated contains cluster instance belongs 
note instance may associated different different runs assign instance frequently associated 
ties broken randomly 
basic assumption cbgf existence correspondence structure different clusters formed ensemble 
poses potential problem cases correspondence structure exists approach may fail provide satisfactory performance 
advantage cbgf cluster cluster instances cluster cluster cluster cluster cluster cluster clustering clustering bipartite graph 
example hybrid bipartite graph formulation computationally efficient 
size resulting graph partitioning problem total number clusters ensemble 
significantly smaller ibgf assuming strehl ghosh proposed approach models clusters hyperedges instances vertices hypergraph uses hypergraph partitioning algorithm produce final partition 
conceptually approach forms different type graph limitation model soft clustering 
practically observed performed worse ibgf cbgf data sets 
due reasons choose discuss approach 

hybrid bipartite graph formulation section presents hybrid bipartite graph formulation hbgf explains conceptual advantages ibgf cbgf 
description hbgf cluster ensemble hbgf constructs graph contains vertices representing cluster ensemble contains vertices representing instance data set defined follows 
vertices clusters instances instance belongs cluster 
note written connectivity matrix rows correspond instances columns correspond clusters 
indicator takes value instance belongs th cluster 
shows example hbgf 
particularly figures depict different clusterings instances shows graph constructed hbgf diamond vertices represent clusters round vertices represent instances 
edge instance vertex cluster vertex indicates cluster contains instance 
edges graph weight edges zero weights omitted graph 
graph cluster vertices connected instance vertices vice versa forming bipartite graph 
new clustering added ensemble new set cluster vertices added graph connected instances contains 
shown dashed line partition bipartite graph partitions cluster vertices instance vertices simultaneously 
partition instances output final clustering 
hbgf vertex set sum ibgf cbgf vertex sets shown dhillon due special structure real size bipartite graph partitioning problem number instances total number clusters ensemble significantly smaller compared size ibgf assuming conceptual advantages hbgf comparing hbgf ibgf cbgf argue important conceptual advantages :10.1.1.140.3011
reduction hbgf lossless original cluster ensemble easily reconstructed hbgf graph 
contrast ibgf cbgf property 
understand second advantage hbgf noted ibgf cbgf consider similarity instances similarity clusters independently shown independent treatment may problematic 
comparing pairs instances assume clustered ensemble true pair 
instances frequently clustered group instances ensemble frequently assigned clusters similar 
contrast true intuitively consider similar ibgf fail differentiate cases assign similarities zero 
ibgf ignores information similarity clusters computing similarity instances 
similar problem exists cbgf 
example consider pairs clusters 
assume 
assume instances clustered clustering runs case 
note cbgf assign similarities zero intuitively consider similar 
cbgf fails differentiate cases take similarity instances account 
constrast hbgf allows similarity instances similarity clusters considered simultaneously producing final clustering 
avoids problems ibgf cbgf 

experimental design section describe methods experiments generating cluster ensembles introduce graph partitioning algorithms experiments 

generating cluster ensembles cluster ensembles generated different ways 
resulting ensembles may differ approach solving ensemble problems may perform differently accordingly 
important experiments consider different ways generate cluster ensembles 
experiments approaches random subsampling random projection fern brodley generate ensembles 
note approaches means base clustering algorithm number pre specified data set remains clustering runs 
note examined third approach randomly restarting means produced similar results random subsampling 
omit results discussion experiments 

random subsampling clustering run randomly subsample original data set sampling rate 
subsampling performed replacement avoid duplicating instances 
cluster subsample assign instance absent current subsample closest cluster euclidean distance cluster centers ensure instances clustered clustering run 

random projection clustering run randomly generate projection matrix pd project data set lower dimensional space original dimension data set dimension project data 
cluster projected low dimensional data set 
fern brodley showed diversity quality cluster ensemble significantly impact achieved combining clusterings ensemble 
choose approaches expect produce ensembles different properties 
hand expect clusterings generated random projection diverse provides base learner different views data 
hand expect quality clusterings produced random subsampling higher provides base learner complete information data 

graph partitioning algorithms goal evaluate different graph formulation approaches 
reduce influence chosen graph partitioning algorithm evaluation known graph partitioning algorithms differ respect search best partition 

spectral graph partitioning spectral graph partitioning studied area successful applications 
choose popular multi way spectral graph partitioning algorithm proposed ng 
seeks optimize normalized cut criterion shi malik 
refer algorithm spec 
spec simply described follows 
graph computes degree ma trix diagonal matrix 
computes weight matrix finds largest eigenvectors uk form matrix uk 
rows normalized unit length 
treating rows embeddings vertices graph spec produces final clustering solution clustering embedded points means 
intuitively spec embeds vertices graph dimensional space performs clustering dimensional space 
graphs generated ibgf cbgf clusters instances embedded clustered separately 
interestingly hbgf clusters instances simultaneously embedded space clustered 
argue offers potential advantages ibgf cbgf 
compared ibgf inclusion cluster vertices may help define structure data easier means find structure dimensional space 
comparison cbgf expected robust cluster vertices structured possibly due lack correspondence structure clusters means perform reasonably instance vertices 

multilevel graph partition metis metis karypis kumar multilevel graph partitioning system approaches graph partitioning problem different angle 
partitions graph basic steps coarsen graph collapsing vertices edges partition coarsened graph refine partitions 
comparison graph partitioning algorithms metis highly efficient achieves competitive performance 
comparing metis spec practice observe mixed results approach consistently better indicating approaches different advantages weaknesses 
note goal experiments evaluate different graph representations generated ibgf cbgf hbgf search bias spec metis 
run spec metis graph report maximum nmi evaluation metric see section obtained 
done types graphs ensure fair comparison 

experimental results goal experiments evaluate graph formulations ibgf cbgf hbgf different cluster ensembles 
table 
summary data sets data set eos glass hrct isolet inst 
class org 
dim 
rp dim 
pca dim 

data sets parameter settings data sets experiments 
characteristics data sets summarized table related parameter choices 
hrct high resolution computed tomography lung image data set classes dy 
eos land cover data sets described different feature sets 
isolet glass uci machine learning repository blake merz iso subset isolet spoken letter recognition training set 
particular isolet contains instances classes letters randomly selected classes letters 
construct cluster ensembles random projection need specify number dimensions random projection uses data set 
numbers listed fifth row table 
random subsampling eos glass data sets construct cluster ensembles directly described section 
note data sets high dimensionality 
data sets reduce dimension principal component analysis pca prior generating ensembles 
dimensions pca uses listed sixth row table 
selected data variance preserved 
clustering runs include runs ensemble construction partitioning final graphs cluster number set number classes data set 
note class labels clustering 

evaluation criterion data sets labeled assess quality clustering solutions external criteria measure discrepancy structure defined clustering defined class labels 
choose information theoretic criterion normalized mutual information random projection cluster ensembles fern brodley eos hrct 
settings eos hrct arbitrarily selected values data sets 
nmi criterion strehl ghosh 
treating cluster labels class labels random variables nmi measures mutual information cover thomas shared random variables normalizes range 
note expected nmi value random partition data optimal value attained class labels cluster labels define partition data 

results table presents performance ibgf cbgf hbgf cluster ensembles generated random subsampling columns random projection columns 
ensemble generating method report results different ensemble sizes 
number reported obtained averaging random runs run spec metis partition generated graph record maximum nmi obtained result run 
row data set reports average performance base learner ensemble type 
comparing ibgf cbgf hbgf look performance approaches cluster ensembles generated random subsampling shown set columns table 
see performance ibgf cbgf comparable data sets eos glass mixed 
particular ibgf performs better hrct data set cbgf winner isolet data set 
hbgf observe cases performance comparable better approaches significantly better eos 
similar observations random projection ensembles cbgf appears competitive performs significantly worse ibgf hbgf eos hrct data sets 
conjecture random projection ensembles tend diverse correspondence structure exist clusters 
comparing base learner table observe hbgf graph formulation approach leads consistent performance improvement base learner cases 
cbgf appears stable approach graph formulations 
sizes omitted avoid redundancy 
experiments confirm random projection generates diverse ensembles random subsampling measured approach fern brodley 
table 
comparing ibgf cbgf hbgf random 
random proj 
eos ibgf cbgf hbgf glass ibgf cbgf hbgf hrct ibgf cbgf hbgf isolet ibgf cbgf hbgf ibgf cbgf hbgf interestingly see ibgf cbgf fail improve base learner eos random subsampling ensembles hbgf achieves significantly better clustering results cluster ensembles 
consider indication constructed cluster ensembles provide helpful information clustering captured ibgf cbgf graphs 
argue hbgf success may attributed fact retains information ensembles allows similarity instances similarity clusters considered simultaneously 
interesting fact eos data set types cluster ensembles performance hbgf degrades ensemble size increases 
plan explore issue inspecting behavior graph partitioning algorithms 
observations conclude hbgf robust ibgf cbgf 
experiments yields competitive better performance compared ibgf cbgf 

hbgf graph formulation reduces cluster ensemble problem bipartite graph partitioning problem 
hbgf simultaneously models instances clusters ensemble vertices bipartite graph 
achieves lossless reduction allows similarity instances similarity clusters considered simultaneously clustering 
resulting graph partitioning problem solved efficiently 
compare hbgf commonly graph formulations cluster ensembles 
experiments data sets show hbgf achieves comparable better performance comparison approaches results robust performance improvement base learner 
want point interesting connection cluster ensemble problems keyword document clustering 
document clustering set keywords represent document vector 
element vector indicates document contains specific keyword 
considering instance document clusters instance belongs keywords document contains clustering instances clusters related clustering documents keywords 
naturally relate cbgf document clustering approaches clustering keywords slonim tishby hbgf bipartite clustering approach proposed dhillon 
connection raises interesting question 
borrow ideas document clustering highly advanced area help solve cluster ensemble problems 
suggests directions 
document clustering keyword clustering shown yield better performance keyword clustering slonim tishby 
cluster ensemble problems cbgf appears inferior ibgf hbgf 
inconsistency merits exploration cluster approach 
secondly hybrid approach may benefit proposed information theoretic clustering technique dhillon 
acknowledgments reviewers helpful comments 
authors supported nasa award number ncc 
bach jordan 

learning spectral clustering 
nips 
blake merz 

uci repository machine learning databases 
www ics uci edu mlearn mlrepository html 
cover thomas 

elements information theory 
john wiley sons 
dhillon 

clustering documents words bipartite spectral graph partitioning 
kdd 
dhillon modha 

information theoretic clustering 
kdd 
hornik 

voting merging ensemble method clustering 
icann 


bagging improve accuracy clustering procedure 
bioinformatics 
dy brodley kak 

customized queries approach cbir em 
cvpr 
fern brodley 

random projection high dimensional data clustering cluster ensemble approach 
icml 


algorithms graph partitioning survey 
linkoping electronic articles computer information science 
fred jain 

data clustering evidence accumulation 
icpr 
hagen kahng 

new spectral methods ratio cut partitioning clustering 
ieee transaction cad 
karypis kumar 

fast high quality multilevel scheme partitioning irregular graphs 
siam journal scientific computing 
monti tamayo mesirov golub 

consensus clustering resampling method class discovery visualization gene expression microarray data 
machine learning 
ng jordan weiss 

spectral clustering analysis algorithm 
nips 
shi malik 

normalized cuts image segmentation 
ieee transaction pattern analysis machine intelligence 
slonim tishby 

document clustering word clusters information bottleneck method 
research development information retrieval 
strehl ghosh 

cluster ensembles knowledge reuse framework combining multiple partitions 
machine learning research 
jain punch 

combining multiple weak clusterings 
icdm 
jain punch 

mixture model clustering ensembles 
proc 
siam conf 
data mining 
