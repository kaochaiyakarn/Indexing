reversible jump markov chain monte carlo computation bayesian model determination peter green department mathematics university bristol bristol bs tw uk summary markov chain monte carlo methods bayesian computation restricted problems joint distribution variables density respect fixed standard underlying measure 
available application bayesian model determination dimensionality parameter vector typically fixed 
article proposes new framework construction reversible markov chain samplers jump parameter subspaces differing dimensionality flexible entirely constructive 
wide applicability model determination problems 
methodology illustrated applications multiple change point analysis dimensions bayesian comparison binomial experiments 
key words change point analysis image segmentation jump diffusion markov chain monte carlo multiple binomial experiments multiple shrinkage step function voronoi tessellation 
number challenging statistical problems involving inference curves surfaces images dimension object inference fixed 
example discussed detail article concerns multiple change point problem poisson processes assumed rate piecewise constant changes unknown number times 
times change different rates unknown 
object inference step function 
email green bristol ac uk 
workshop model criticism highly structured stochastic systems september 
written version december final revision august 
problems broadly similar vein general ingredients discrete choice set models parameter vector interpretation depending model question data influenced model parameter values basis inference 
examples factorial experiments prior allowing factor effects tie variable selection regression non nested regression models mixture deconvolution unknown number components bayesian choice models different numbers parameters multiple change point problems image segmentation dimensional analogue change point problem object recognition approached marked spatial point processes 
model criticism model choice model selection model averaging require basic computational tasks technology tasks focus 
aim article add weight assertions bayesian approach attractive problems computations inference handled markov chain monte carlo methods 
particular section introduce novel class methods capable jumping subspaces differing dimensionality 
considerably extends scope metropolis hastings methods applies varying dimension problems 
bayesian model choice hierarchical model suppose countable collection candidate models fm kg 
model vector unknown parameters assumed lie dimension may vary model model 
obvious changes methods apply arbitrary collection parameter subspaces 
observe data natural hierarchical structure expressed modelling joint distribution jk yjk product model probability prior likelihood 
convenient abbreviate pair lies fkg theta generally varies concrete example consider change point problem unknown number change points piecewise constant regression function interval 
model says exactly change points 
resulting step function need specify position change point value function subintervals divided 
vector length 
bayesian inference joint posterior jy target markov chain monte carlo computations described 
appropriate jy jk interpret terms separately avoiding model averaging 
inference model indicator may phrased terms bayes factor model relative jy jy xi depend hyperprior 
quantities readily estimated markov chain monte carlo sample obtained methods bayes factors required specified implement computation chosen grounds convenience 
note regarding posterior objective computation preclude model selection prediction ultimately non coherent principle advocated madigan raftery methods applicable analysis 
markov chain monte carlo computation application aspects bayesian model determination includes phillips smith samplers grenander miller carlin chib effectively product space unpublished devise embedding method fc mapped subsets single parameter space 
approaches merits disadvantages 
conflict minimising distortion caused positive time increment improving monte carlo efficiency 
jump diffusion principle really general range jump transitions discussed grenander miller phillips smith somewhat limited amounting conditional versions gibbs kernels hastings kernels proposals generated prior 
moves adequate grenander miller applications restricted general bayesian computation 
product space approach carlin chib requires irrelevant parameters different current need continually updated apparently limits approach small set models unpublished hagan author pointed need update irrelevant parameters ensure proper limiting distribution chain performance modified method encouraging 
embedding method cumbersome 
markov chain monte carlo reversible jumps dx denote target distribution interest 
bayesian inference posterior distribution parameters data context model determination parameters include indicator model parameter vector specific model 
markov chain monte carlo computation construct markov transition kernel dx aperiodic irreducible satisfies detailed balance dx dx dx dx appropriate simulate chain obtain dependent approximate sample dx 
detailed balance needed ergodicity correct limiting distribution practical design samplers convenient restriction impose 
straightforward cases dx discrete probability distribution joint density respect simple measure usually lebesgue methods constructing suitable transition kernels familiar 
popular methods gibbs sampler geman geman metropolis hastings method metropolis hastings 
full description comparisons tierney besag 

briefly method proceeds sweeping variables visiting subsets indices turn randomly systematically 
subset ng visited variables fx tg updated 
gibbs sampler new values drawn full conditional distributions jx gammat gammat fx tg 
hastings method proposed new values variables drawn essentially arbitrary distribution 
probability ff min jx gammat jx gammat proposed values accepted existing values retained 
gibbs sampler hardly sense length fixed elements need fixed interpretation models resample components conditional remainder rarely meaningful 
concentrate adapting wider class hastings algorithms situation approach outlined green discussion grenander miller 
gives framework dealing case simple underlying measure 
general case typical application multiple parameter subspaces fc different dimensionality necessary devise different types move subspaces 
combined form tierney calls hybrid sampler random choice available moves transition order traverse freely combined parameter space restrict attention markov chains detailed balance attained move type 
current state propose move type take state dx probability dx 
moment arbitrary sub probability measure probability gamma change state proposed 
moves available starting states usual hastings algorithms proposal automatically accepted 
probability acceptance denoted ff left undefined objective analysis derive expression ff achieves stated aim attaining detailed balance move type 
transition kernel defined written dx ff borel sets denotes indicator function dx gamma ff gamma probability moving proposed move rejected move attempted 
detailed balance relation requires equilibrium probability moving equal borel sets substituting need dx dx ff dx dx dx ff dx hold sufficient dx dx ff dx dx ff achieve choose ff follows 
suppose dx qm dx finite density fm respect symmetric measure theta dx dx ff dx dx ff dx dx fm ff dx dx ff required middle equality holding assumed symmetry provided ff ff fm shown proof finite state space case optimal sense reducing autocorrelation realised chain acceptance probability large possible subject retaining detailed balance 
take ff min fm fm satisfies 
possibility denominator ratio zero concern dx zero probability proposing move definition ratio safely set arbitrary value 
formally transparently write expression ratio measures ff min dx dx dx qm dx straightforward cases dimension matching requirement imposed fairly simply standard template 
give details subsection add remarks 

definition sampling method entirely constructive 
integration simulation needed set transition mechanism 

method allows great flexibility algorithm designer exploit structure problem hand 
intuition choose moves plausibly induce mixing behaviour imposing heavy burden algebraic analytic establish validity 

usual hastings methods distribution need normalised relative normalising constants different subspaces needed 
specifically necessary prior distributions jk properly normalised unknown multiplicative constant priors posteriors conditional needed 
detailed balance different subspaces achieved point apparently missed grenander miller 

general framework includes various familiar special cases 
parameter subspace single dominating measure just random scan hastings method 
framework provides natural generalisation hastings methods general parameter spaces 
case point processes method closely related spatial birth death process studied preston 
geyer ller developed hastings sampler point processes special case construction derive likelihood inference procedures point patterns prove results convergence 
jump diffusion processes grenander miller proposed bayesian computation certain computer vision problems provide special case method parameter subspace moves continuous time diffusion process discretised temporally computational purposes approximately maintains detailed balance 
range jump transitions grenander miller somewhat restricted 
switching simple subspaces obscure dimension matching assumption deserves interpretation intuitive terms 
suppose just subspaces theta theta having proper densities subspace conditional 
context suggest example point move move type equilibrium joint proposal probability dx dx ae ae density respect singular measure theta placing mass lebesgue measure detailed balance attainable necessary reverse move defined proposal distribution dx singular probability example draw random variable distribution independently current state set gamma ensure singularities sort arising self consistent 
describe detail implement dimension matching requirement standard cases consider setup little general example just described 
suppose subspaces jk jk proper densities consider just move type switches subspaces subscript suppressed 
probability choosing move denoted 
typical way accomplishing transition generating vector continuous random variables length independently setting deterministic function similarly switch back length generated set function dimension matching bijection 
particular lengths satisfy proposal distribution dx defined distributions suppose proper densities respect lebesgue measure respectively 
explicit condition context 
ae ae set theta theta bg denotes dimensional lebesgue measure 
general ae put theta theta theta symmetric required 
jy jy fi fi fi fi fi fi fi fi fi fi set 
density respect equilibrium joint proposal distribution dx dx 
appropriate acceptance probability proposed transition min jy jy fi fi fi fi fi fi fi fi fi fi restores anti symmetry lost particular representation 
practice moves set zero 
direction need generate corresponding expression acceptance probability simplifies 
example min jy jy fi fi fi fi fi fi fi fi fi fi example somewhat simplified compared real applications appropriate modifications may need 
example may generated dependently case replaced conditional density 
discrete variables generated making proposals probability functions realised values multiplied move probabilities 
change repeatedly applications article 
application dimensional multiple change point problems coal mining disasters application general construction previous section new bayesian model multiple change point analysis develop reversible jump markov chain monte carlo sampler compute posterior distribution 
data set frequently illustrating new methods change point analysis point process dates serious coal mining disasters raftery akman 
contrast previous analyses data continuous time points recorded days years 
displays dates disasters years days jittered dot plot cumulative counting process shown dotted line 
data points fy ng poisson process rate function log likelihood gamma dt prior model step functions develop bayesian multiple change point analysis point process data assuming rate function step function 
section formulate prior distribution suppose steps positions step function takes value call height subinterval writing convenience 
prior model specified supposing drawn poisson distribution gamma 
time days posterior mean rate 
coal mining disasters coal mining disaster data dates disasters cumulative counting process dotted curve posterior mean rate occurrence solid curve conditioned max step positions distributed numbered order statistics points uniformly distributed heights independently drawn gamma ff fi density fi ff ff gamma gammafi gamma ff prior model step functions intended close uninformative 
appropriate select improper gamma distribution gamma heights causes insurmountable difficulties normalisation differing numbers steps probability posterior assigned simplest model 
natural take step positions independently uniformly distributed sorting 
allows short steps gamma small 
may data interval short intervals barely penalised likelihood survive posterior giving complicated picture true step function really justified data 
modification effect probabilistically spacing step positions 
reversible jumps step functions developing reversible jump monte carlo sampler change point problem guided intuition designing appropriate moves coupled requirements dimensions balanced properly moves simulated conveniently acceptance ratio computed economically 
hastings methods flexibility process constrained fine details model question 
claim optimality particular choices 
object step function possible transitions change height randomly chosen step change position randomly chosen step birth new step randomly chosen location death randomly chosen step 
note involve changing dimension standard markov chain monte carlo theory apply 
general framework section transitions attained countable set moves denote fh means height change position change denotes birth death pair increases number steps steps reduces applications number steps fixed advance change point analysis assumes exactly step 
clear advantages efficient monte carlo computation allowing vary condition drawing information realisation 
allow better mixing 
describe transitions detail 
transition independent random choice attempting available move types gamma signifying height change position change birth death respectively 
probabilities gamma depending current number steps satisfying 
naturally kmax impose preassigned upper limit max number steps 
apart constraints probabilities chosen minf minf constant large possible subject max choice ensures condition guarantee certain acceptance corresponding simpler hastings sampler number steps 
took move type chosen remaining details straightforward 
change height attempted choosing random obtaining say proposing change log uniformly distributed interval gamma choice convenience proposal density ratio simple form 
acceptance probability move min likelihood ratio theta ff expf gammafi gamma usual way 
likelihood ratio means yjx yjx stand current proposed new values parameters 
position change move drawn random obtaining say proposed replacement value drawn uniformly gamma acceptance probability turns min likelihood ratio theta gamma gamma gamma gamma gamma gamma details birth step complicated follow prescription section 
choose position proposed new step uniformly distributed 
lie probability existing interval say 
accepted set corresponding changes labelling step heights 
wish propose new heights step function subintervals recognise current height union intervals typically supported posterior distribution completely discarded 
new heights perturbed direction way compromise 
preserve positivity maintain simplicity acceptance ratio calculations weighted geometric mean compromise gamma log gamma log gamma log define perturbation gamma drawn uniformly 
analysis section acceptance probability proposal calculated achieve detailed balance corresponding death move specify 
dimension matching achieved reversing calculation removed new height interval weighted geometric mean satisfying gamma log gamma log gamma log proposed removal simply drawn random pair birth death moves defined satisfies dimension matching requirement 
birth increases dimensionality difference accounted continuous variables new position separate deriving expression acceptance probability birth proposal helpful re write form minf likelihood ratio theta prior ratio theta proposal ratio theta jacobian noting xjy yjx 
context likelihood ratio straightforward prior ratio previously gamma gamma gamma theta fi ff gamma ff ff gamma expf gammafi gamma proposal ratio jacobian acceptance probability corresponding death step form appropriate change labelling variables ratio terms inverted 
previous proposals dealing step functions variable number steps markov chain monte carlo methods 
newton guttorp build model biological process hidden continuous time markov chain develop nonparametric approach survival analysis assuming step function form hazard rate 
applications step function tied right hand observation interval encoded way side steps varying dimensionality problem 
analysis coal mining disaster data number change points coal mining disaster data posterior distribution number change points presentation bayesian inference reasonably complicated object function partial 
displays taken examples word particular data set inference step functions general 
figures show different aspects particular analysis hyperparameters fixed max ff fi 
monte carlo simulation run updates burn period updates 
pilot run established confidence convergence taken place point 
computation took seconds sun sparc workstation 
solid curve shows estimated posterior mean curve efx step function 
shows posterior distribution number steps 
show posterior densities step positions conditional values graphs confusing interpret superimposed 
density estimates obtained gaussian kernel standard deviation days 
positions change points coal mining disaster data posterior density estimates positions changepoints conditional number change points solid curve dotted curves broken curves 
rate process coal mining disaster data posterior density estimates heights segments rate step function conditional number change points solid curves dotted curves broken curves 
similarly shows corresponding conditional posterior density estimates step height kernel standard deviation days gamma comparisons contrasts previous analyses data 
raftery akman assume single change point location assumed priori uniform interval 
step heights drawn independently improper gamma distribution gamma point process likelihood calculate posterior density relative change step height bayes factor comparing hypothesis change versus change numerical integration 
bayes factor turns overwhelming evidence change 
posterior mode time change march day credible interval may august days compare mode june day interval may may analysis conditional 
raftery akman give substantive interpretation inference context historical circumstances underlying data 
carlin gelfand smith develop hierarchical bayesian approach single changepoint problem regression 
apply poisson process data coal mining disaster data counts annual intervals 
position change taken discrete variable step heights drawn independently gamma distribution gamma ff fi notation ff fi gamma drawn third stage prior gamma 
produce posterior densities step heights position change gibbs sampling 
posterior modal year change 
barry hartigan analyse change point problems product partition models markov chain monte carlo methods change points coded discretely handled fixed set indicator variables 
stephens phillips smith develop bayesian analyses multiple change point regression problem positions change taken discrete variables computations performed gibbs sampling jump diffusion sampling respectively adapt methodologies point process problem 
approaches treats multiple change point problem genuinely continuous time proposed methodology 
see difficulty introducing hierarchical structure modelling desired 
image segmentation voronoi tessellation various dimensional analogues change point analysis 
problem discussed briefly section intended give idea possibility 
image segmentation process subdividing digital image homogeneous regions generally prelude analysis see sonka boyle 
regarded homogeneous depends context example involves texture intensity 
consider simplest version problem wish subdivide noisy image observations arranged regular rectangular grid regions homogeneous mean intensity 
additive noise occurring independently blur pixel natural specify regression model piecewise constant mean function form dimensional step function 
computational tractability consider step functions form regions constancy polygonal concerned polygonal lation part plane field view 
flexible convenient tessellation voronoi dirichlet tessellation individual polygon tile defined region plane nearer tile generating point 
tessellation specified coordinates generating points entire step function points heights function th tile 
step function satisfies gamma gamma general discussion voronoi tessellation algorithm computation see green sibson 
basic algorithm described subsequent development tile package sibson workers university bath ideally suited birth death markov chain monte carlo simulation methodology section dimensional change point problem appropriately modified 
general notation candidate models indexed parameter vector model dimension 
likelihood assumed independent gaussian noise yjk exp gamma oe fy gamma denotes observed intensity pixel centred sum pixels 
prior model illustration uninformative 
number tiles modelled poisson distribution parameter truncated max locations generating points independently uniformly distributed unit square representing field view heights drawn independently gamma ff fi distribution 
move types problem correspond closely section computationally convenient perform analogue move generating point 
tile package includes routines adding deleting generating points corresponding birth death step changing height tile detailed balance entirely straightforward 
explain birth death transitions detail notation needed 
probabilities proposing birth death current number steps viz 
tiles respectively 
consider proposed birth increase number steps suppose new generating point labelled location drawn uniformly unit square tessellation modified addition point modification done trial basis birth may accepted 
updated tessellation new point neighbours green sibson label compute old new areas tiles denote respectively 
total reduction gives area tile new point height assigned new point hv weighted geometric mean original heights neighbouring tiles drawn independently density function log distribution symmetric 
new heights tiles modified addition gammas motivation making particular assignments integral log unit square left unchanged height assigned new tile compromise heights previously assigned points tile modified small multiplicative perturbation 
death transition corresponding birth randomly chosen generating point deleted points tile re assigned neighbours 
denote old new areas neighbouring tile height changed effect reversing birth move exactly 
pair proposal mechanisms turns straightforward algebra acceptance ratio birth min death min gamma likelihood ratio theta fi ff gamma ff ff gamma ff gamma exp gamma theta theta 
displays results simple example testing methodology synthetic data 
true image consisting disc intensity background lower intensity degraded additive gaussian noise independently pixel theta grid standard deviation oe 
note disc perfectly fitted finite union voronoi polygons 
hyperparameters prior fixed max ff fi 
shows left data right posterior mean surface efx estimated run sampling method described sweeps burn period sweeps 
notwithstanding apparent complexity geometrical calculations maintain tessellation modifications computations described paragraphs entire sampler runs quite quickly 
sun sparc workstation run described takes approximately seconds 
partition models hierarchical model binomial probabilities contexts listed viz 
factorial experiments variable selection regression mixture deconvolution common feature discrete problem equivalent determining partition original data units labels applying data example factor levels 
describe synthetic segmentation problem left noisy data right estimated posterior mean 
upper plots show perspective views surfaces displayed images 
general partition sampler application anova problem binomial data discussed 
partition set ng collection fs subsets call groups disjoint union number groups divided called degree written 
emphasise dependence write suppose responses assumed drawn independently binomial distributions bin index parameters fw known probabilities unknown 
construct prior distribution acknowledges parameters may similar values groups defined partition ng 
group drawn independently beta distributions gamma ff group mean parameters fff turn drawn independently uniform distribution group precision parameter fixed known value drawn 
essentially model proposed took general beta distribution ff allowed separate group took fixed constants 
routine modify follows deal situation 
conventional numerical techniques fit model constrained conjugate distributions techniques practicable 
reversible jump markov chain monte carlo computation constraints need imposed 
prior distribution taken gamma fg giving equal probability partitions degree placing probability gamma set degree calculation prior straightforward 
necessary count number partitions degree set items count solution recurrence relation dc gamma gamma gamma 
counts large care needed avoid overflow 
alternative model partitions hartigan product partition model see barry hartigan favours unequal distribution items groups 
joint distribution variables determined ff ff jg ff yjg ff jg ff yj theta theta theta qff gamma gamma gammaff gamma gamma ff theta gamma gammay beta function 
general notation section model indicator parameter vector ff ff dimension 
reversible jump markov chain monte carlo partition problems discussion apply changes partition problems 
deal updating elements full conditionals independent beta distributions delta delta delta gamma ff gamma delta delta delta denote variables fg ff ff updated gibbs kernel 
find qj delta delta delta theta qff gamma gamma gammaff gamma standard distribution easily evaluated hastings step proposal log scale uniformly distributed current value 
group mean parameters conditionally independent ff delta delta delta qff gamma gamma gammaff gamma gamma ff application stirling formula shows full conditional normal approximation large ff delta delta delta gamma gamma geometric mean gamma 
approximation explicitly approximate gibbs sampler choose proposal distribution hastings step 
turning step updating partition say note prior specified partitions positive probability process jumps partitions making modest changes splitting group birth combining groups death irreducible 
quite natural included move changed partition reallocation items fixing number groups implemented 
mechanisms partition moves effective practice applied partitions dozen objects 
birth attempted probability current partition choose group split uniformly items 
group split random binomially item assigned daughter subgroups independently probability half conditional subgroup empty 
death attempted probability simply choose groups random combined 
jumping new partition necessitates change vector ff length increase decrease 
proposal additional component gaussian logit scale takes account numbers binary responses influenced relevant ff specifically suppose proposed birth splits subgroups ff current value ff ff new values subgroups 
set ff ff gamma ff ff ff ff gamma ff ff jr independent standard gaussian random variable oe spread parameter chosen 
corresponding death move ff ff merged form ff solves simultaneous equations 
completes specification jump proposal acceptance probability necessarily somewhat complicated form calculated usual 
birth death probabilities respectively min min gamma gamma ff gamma ff gamma ff theta gamma ff gammaff gamma ff gammaff theta theta fj fd gamma gamma theta ff gamma ff ff gamma ff ff gamma ff oe gamma gamma xi gamma exp gamma table mortality pine posterior means standard deviations parentheses reversible jump mcmc experiment random lh ld sh sd application pine mortality data apply methodology described small data set analysed 
concerns binomial responses trials 
data arise theta factorial experiment comparing treatments high deep varieties pine slash 
responses indexed order lh ld sh sd 
compare various statistical methods analysing data including bayesian method model described adaptive multiple shrinkage property see george 
data determine partition responses groups similar estimates probabilities group borrow strength shrinking common value ff alternative estimators considered include maximum likelihood estimators saturated model additive logistic regression parametric empirical bayes estimator shrinks nonparametric empirical bayes estimator multiple shrinkage property 
refer reader background including discussion philosophical issues arise modelling 
analysis confined repeating obtained reversible jump markov chain monte carlo analytic approximations 
extended results slightly allowing random fixed values 
adaptation prior log uniform interval log log proposal updating described previous section interpreted wrapped periodically interval 
unspecified hyperparameters model defined 
samplers completely specified scale factor oe took little experimentation probabilities assigned move type 
took birth death rates extreme partitions taken 
transition updated probability similarly pair ff 
results table run lengths attempted updates burn periods runs took seconds sun sparc 
posterior expectations close obtained 
case taken theta lh sh ld sd posterior density estimates pine mortality data raw data plotted tick marks random hyperprior specified posterior mean standard deviation estimated 
sampling computation permits information extracted displayed 
show posterior density estimates random version model raw data plotted tick marks points adaptive multiple shrinkage evident note estimates factor combinations ld sh sd shrunk correspondingly smaller posterior variance 
data suggest treatment increases mortality type subtle logistic regression analysis simply concludes treatment variety factors significant effects 
discussion theory applications article demonstrated advantages markov chain monte carlo computation extended new classes problems object inference dimension fixed including difficult bayesian model determination problems 
applications new markov chain monte carlo methodology implementations developed 
example jointly dr richardson author investigating bayesian mixture estimation unknown number components ph 
students bristol applying methods various image analysis problems ph 
thesis cambridge university dr morris developed new method removal scratches movie film 
remain number questions methodology resolved 
concerns development understanding moves effective generically aid intuition design moves 
secondly situations collection candidate models restricted practical statistical considerations question inventing additional models corresponding parameter subspaces may facilitate mixing effectively 
problems involving partitions larger sets items arising section need new jump proposal mechanisms 
proposals pine mortality study completely blind current values variables 
anticipated account fff allow construction efficient proposals borne experience mixture estimation 
complications multiple parameter subspaces differing dimensionality problems assessing convergence difficult urgent need research effective diagnostics broad applicability 
wish particularly sylvia richardson stimulating discussions making valuable suggestions 
acknowledge comments connections corrections correspondence julian besag andrew gelman charlie geyer paolo vincent andrew lawson jesper ller tony hagan marco david stephens mike titterington referee associate editor 

nonparametric bayesian inference right censored survival data gibbs sampler 
statistica sinica 
barry hartigan 
product partition models change point problems 
ann 
statist 
barry hartigan 
bayesian analysis change point problems 
amer 
statist 
assoc 
besag green higdon mengersen 
bayesian computation stochastic systems discussion 
statist 
sci 
carlin chib 
bayesian model choice markov chain monte carlo 
roy 
statist 
soc 
carlin gelfand smith 
hierarchical bayesian analysis changepoint problems 
app 
statist 

bayesian method combining results binomial experiments 
appear amer 
statist 
assoc 
george 
combining minimax shrinkage estimators 
amer 
statist 
assoc 
geyer ller 
simulation procedures likelihood inference spatial point processes 
scand 
statist 
green 
contribution discussion grenander miller 
roy 
statist 
soc 
green sibson 
computing dirichlet tessellations plane 
computer 
grenander miller 
representations knowledge complex systems discussion 
roy 
statist 
soc 
hastings 
monte carlo sampling methods markov chains applications 
biometrika 
madigan raftery 
model selection accounting model uncertainty graphical models occam window 
amer 
statist 
assoc 
metropolis rosenbluth rosenbluth teller teller 
equations state calculations fast computing machines 
chem 
phys 
newton guttorp 
bayesian inference simulation stochastic model 
computing science statistics 
newton editor 
interface foundation north america 

optimum monte carlo sampling markov chains 
biometrika 
phillips smith 
bayesian model comparison jump diffusions 
markov chain monte carlo practice ed 
gilks richardson spiegelhalter chapter london chapman hall 
preston 
spatial birth death processes 
bull 
int 
statist 
inst 

raftery akman 
bayesian analysis poisson process change point 
biometrika 
sonka boyle 
image processing analysis machine vision 
london chapman hall 
stephens 
bayesian retrospective multiple changepoint identification 
appl 
statist 
tierney 
markov chains exploring posterior distributions ann 
statist 
