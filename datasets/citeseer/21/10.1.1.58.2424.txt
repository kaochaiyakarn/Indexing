unsupervised model prediction user actions kevin dixon cs cmu edu pradeep khosla ece cmu edu department electrical computer engineering carnegie mellon university pittsburgh pa usa derive algorithms construct simple continuous density hidden markov models unlabeled observations user actions 
models predict actions user 
algorithms designed domains user generated training data costly obtain consequently number free parameters kept low 
speci cally derive algorithm constructs compact markov chains irreducible number states real valued observations users performing tasks 
show worstcase computational complexity algorithm second order polynomial number length tasks 
derive optimal estimator expectation observations observations give computational complexity estimator 
novel application predictive robot programming 
show algorithms derived recognize predict waypoints robot programs translation independent fashion derive maximum likelihood equations locally optimal scale invariant prediction 
experimental results performance algorithms predictive robot programming 

despite numerous advances human computer interaction hci automation systems require users convey knowledge computers robots procedural programming techniques 
vast majority population transfer knowledge limited programming expertise user 
expertise programming job skill 
users experience inclination program computers robots perform tasks 
industrial settings companies resources automate production 
example estimated arc welding performed hand due part complexity duration programming process 
downtime required reprogram facilities may interrupt production expense necessary obtain programming expertise may great 
system simpli es automation tasks increase computers robots variety elds previously limits raise productivity 
developed algorithms assist transfer knowledge observing users performing tasks leveraging information decrease time required automate tasks predicting observations 
general problem machine learning observing human long goal researchers 
learning observation paradigm characterized computer assimilating observations user performing task tasks synthesizing information computer perform task novel con gurations 
formulate problem stochastic source prediction ssp predicting values random process prior observations behavior 
ssp problem received quite deal attention applications prevalent statistics de nition random process indexed sequence random variables 
contrasts combinatorics cryptography implication random process sequence previous observations help predicting observations white process statistics jargon 
user hidden variables observations task repertoire estimate user hidden variables observations learning model prediction observations task 
conceptual diagram phase operation system 
take observations generate user model 
second model compute observations 
elds 
economists time series analysis recognize trends predict stock market 
engineers model predictive control stabilize systems achieve optimal performance 
computer scientists dynamic caching algorithms predict memory page faults operating systems 
applications ssp heart 
casting user system stochastic source reduces ssp 
predicting general random process intractable necessary apply assumptions behavior underlying stochastic source 
example random process modeled autoregressive moving average considered stationary ergodic markov 
assumptions dictated underlying physical system desired complexity model assumptions driven modeling human users observations activity 
conceptually system operates phases 
rst learning phase creates model prior observations user 
second prediction stage computes predictions user observations model 
diculties predicting synthesizing user actions 
observations obtained sensors general noise corrupted sensors uncertainty associated 
primary diculty predicting user actions inherent imprecision poor repeatability humans 
perfectly accurate sensors uncertainty task user trying perform 
unfeasible instrument fully realistic working environment consequence latent causes hidden variables certain user actions 
system attempts model user actions address types uncertainty 
furthermore observations system gathered human activity signi cant real world duration 
results low availability data train requires system keep number tunable parameters minimum 
discussed user model continuous density hidden markov model acyclic connectivity 
section overview key ideas modeling user actions 
develop learning algorithm theoretical perspective section derive optimal prediction estimator section 
outline novel application ssp problem section describing predictive robot programming detailing theoretical practical aspects problem 
place research context related section 
section 
modeling user actions section formally informally de ne terms 
user observation real valued vector sampled discrete time intervals 
account inherent user imprecision measurement inaccuracies user observations considered noise corrupted 
sequences user observations called tasks unknown set possible tasks user may perform called repertoire 
informally user generates robot program rst selecting task repertoire unknown priori distribution 
performing task user observation generated hidden state task 
assume user moves states task stationary arbitrary probability distribution depends current state task 
users tend think terms latent random processes impractical require user describe internal state generated observation 
user observations unlabeled sense ground truth mapping user observations internal state 
internal states user unknown information conveyed system noise corrupted real valued observations model user actions continuous density hidden markov models 
formally model user actions repertoire tuple nite set states non empty set starting states non empty set terminating states observation set dimension state transition pmf probability transitioning state jji cn jc jji observation pdf likelihood state generating observation xn xn xn jc xn xn dxn initial state pmf probability starting state jr 
random variable indicating current state time written tasks created humans necessarily nite duration underlying graph acyclic 

learning prior observations high level terms assimilate observations arbitrary number tasks estimate repertoire user 
general philosophical assertion desirable create simple compact model explains observations 
particular importance training data scarce simple models imply fewer free parameters assign 
furthermore interesting problems possible know priori general structure model 
central development algorithms low training data unknown graph topology 
section refer existing algorithms exploit large corpora data knowledge graph topology 
topology repertoire unknown system initialized tabula rasa 
blank slate appears approaches create compact models 
rst approach assume simple initial model incrementally increase complexity account inconsistencies simple model data 
second approach create complex model initially incrementally decrease complexity identifying similarities model 
graph models approaches known state splitting state merging respectively 
potential advantages disadvantages clear cut winner 
state merging schemes tend start sparse initial groupings data perspective relatively easy identify similarities small groupings data 
contrast state splitting schemes start large initial groupings data conse 
hypothetical dag assimilating set prior observations left state merging algorithm right 
quently tend bit dicult identify inconsistencies groupings 
approach clear cut winner 
derivation learning algorithm essentially algorithm operates rst building maximal state directed acyclic graph dag suggested prior user observations repeatedly merges statistically similar states simple results 
node dag comprised multiset observations denotes nite multiset set edges contain usage counts ev leveled dag node exists level depth 
leveled dags proper subset general dags 
set nodes depth written vn multiset tasks fx task sequence observations fx nk sample mean multiset written hai hai jaj de nition 
dag compact nodes vn vn common depth function hx hx 
essentially de nition provides precise meaning dag simple 
state merging perspective compact dag irreducible number nodes nodes merged yield compact dag 
compact dag imply globally minimal number nodes imply type locally optimal solution 
finding compact dags eciently state merging state splitting inherently useful problem searching simple graph models particularly training data limited 
compact dag converted translates fewer free parameters user model 
possible functions evaluate compactness de ne symmetric positive de nite pd matrix 
equation simply sum squared mahalanobis distances respect vector lemma 
proof 
de nition pd matrix function strictly positive lemma 
multisets 
proof 
lemma 
hyi arg min hyi sample mean non empty nite multiset 
proof 
symmetric cx cx cu jy jy hyi nal step requires invertible true de ned pd ensure minimum check hessian 
second derivative symmetric pd matrix de nition assumption jy 
implies hyi minimum 
note lemma similar derivation sample mean multivariate gaussian log ml approach 
lemma 
non negative threshold exists multiset yi hyi 
proof 
hyi clearly yi 
yi assumption hyi lemma hyi yn hyi lemma hyi lemma completes sides claim 
corollary 
non negative threshold multisets exist bi ha bi proof 
direct extension lemma 
rst lemmas mere properties equation 
nal lemma corollary provide road map derive algorithm construct compact dags ultimately simple 
essentially encounter observation sets nodes hx add observation xn node providing fxn hx fxn gi assured inequality equation hold 
algorithm learn hmm result intuition gained lemma corollary 
contains pseudocode constructing compact dags 
algorithm learn hmm similarity threshold 
fx multiset tasks 
fx assimilate task convert dag hmm 
complete hmm learning algorithm 
note learn hmm observation set exists purely mathematical construct simple show convex hull multiset observations fx convex hull closed linear operators section 
theorem compactness 
learn hmm algorithm produces compact dags 
proof 
algorithm creates edges nodes sequential depths line produce leveled dags proper subset general dags 
rst predicate de nition hx trivially true algorithm add observation xn node fxn hx fxn gi line 
initially line line fxg nodes hx point execution algorithm 
move second predicate de nition hx 
take nodes depth dag 
loss generality assume node created know created exists observation fx fx gi line 
lemma corollary shown fx fx gi hx remove observations nodes nodes corresponding non empty observation multisets line second predicate true point execution function assimilate task leveled dag 
fx task assimilate 
similarity threshold 
xn fx min min vn fxn hx fxn gi min arg min vn fxn hx fxn gi fxn min create empty node fv fxn vk fe vk vk fe vk ev ev return 
assimilating task leveled dag 
algorithm 
predicates de nition met claim holds 
learning algorithm learn hmm relies nonnegative scalar threshold 
mathematically correct approach threshold obvious real world analogue gives user insight operation algorithm 
step back formulation recast algorithm probably approximately correct pac learning 
pac learning paradigm probability threshold pr fd fxn hx fxn gi words distance function probability assume user errors independent tasks follows gaussian distribution hx 
notational convenience de ne hx fxn gi 
function convert dag hmm leveled dag 
maximum depth create repertoire state create jji nev fq fq fq return 
converting leveled dag hmm 
case xn xv xj xv exp exp xv fxn gj exp fxn fxn gj exp fxn gj probability threshold nd similarity threshold function area unit gaussian nity dt unique solution 
essentially equation determines observations latent state repertoire lie 
running time learning algorithm turn attention running time learn hmm algorithm 
impossible know priori nodes created algorithm appears type expectation average case constructed 
possible determine worst case running time algorithm 
worst case scenario nodes merged observation task node 
number nodes dag equal number observations assimilated time 
required algorithm simplify running time analysis assuming tasks common length number tasks worst case algorithm assimilated observations mn nodes dag 
learning algorithm operates decoupled steps rst assimilating observations dag line converting dag line 
glancing pseudocode clear cost computing equation dominates computation 
analysing cost assimilating observations take note sucient statistics computed 
observations assigned node denoted multiset 
sucient statistics equation cardinality observation multiset scalar weighted quadratic sum observations vector sum observations jx xv cx xv sucient statistics simple update rules union multiset 
de nition equation get expansion hx xv hx hx xv cx xv hx cx xv hx sucient statistics union multisets vk simply computed vk vk vk sucient statistics corresponding update equations computational cost computing equation independent cardinality multiset 
cost computing union dominated computing weighted quadratic sums operations cost dimension observation vector 
compute equation times number tasks assimilated line resulting arithmetic series mng ng result worst case cost assimilating tasks length observation vector dimension order ng 
second phase algorithm converts dag 
computation time converting dag dominated cost computing state transition probabilities line 
worst case scenario assumption mn nodes dag due leveled property dags know nodes depth 
inner loop computing transition probabilities line double arithmetic series pass loop create observation pdf line de ne cost 
implies computation complexity converting worst case mn node dag 
phase algorithm executes strict serial fashion respective complexities additive 
worst case scenario tasks length nb 
predicting user actions repertoire estimated model predict observations 
user performing current task compute prediction observation xn potential criteria optimal estimator maximum likelihood ml maximum posteriori map minimum entropy criterion expected value ev observation prior observations estimated user repertoire observations current task 
deriving estimator rst de ne notation 
current task fx subtask written fx forward variables jr xn jc jr xn jji probability state time step observations pmf jx jr jr jr jr cn jc jr jr jji qk de nitions ev estimator computed xn xjx fxg cn jx xjc fxg jx xp xjc dx xb dx essentially equation says expected value observation expected value state mean observation generation pdf xb dx weighted probability state generates observation 
repeatedly apply equation compute expectation observations point 
con dence regardless criterion ml map ev prediction exist observations consistent estimated repertoire 
prediction schemes incorporate value indicates con dent system prediction 
con dence value indicate internal model uncertainty arising observing current task 
con dence indicates observations perfectly model indicates minimum certainty 
con dence value independent number observations states estimated repertoire 
de ne con dence kullback leibler divergence taken log base jqj state pmf 
uniform distribution dkl 
jqj log jqj log jqj log jqj log jqj log log jqj log jqj log jqj log log jqj log log jqj cn log jqj discrete random variable jqj possible outcomes entropy cn log jqj implying 
loosely speaking distance current uncertainty model complete uncertainty uniform density 
con dence exceeds predetermined threshold xn considered valid prediction 
computational complexity prediction cost computing predictions equation components 
rst involves expectation observation pdfs 
pdfs parameterized mean expectation computed constant time 
second part involves computing state pmf equation 
equation computed standard dynamic programming time take advantage leveled sparse connectivity reduce computation time greatly 
number states jqj current time cost evaluating observation pdf jqj states costs time steps 
relation leads computational cost prediction 
predictive robot programming programming manipulator robot arduous task 
typical robot program consists main components sequence positions robot travel conditional branching statements process speci instructions 
constituent problems users spend bulk time merely de ning sequence positions called waypoints 
critical success robot programs de ning waypoints currently overly complex time consuming process 
robot programming evolved mutually exclusive paradigms ine online programming having advantages disadvantages 
ine programming users move simulated version robot waypoint cad model workspace 
online programming users move robot waypoint type control device actual workspace 
ine programming packages allow users design robot program simulation bringing production optimize imaginable criterion 
typical optimizations involve production speed material usage power consumption 
ine packages generally require programs written sophisticated procedural programming language 
transfer ine program robot controller requires translating ine programming language form robot understand 
surprisingly arcane problems occur translation especially process speci instructions controller models inverse kinematics 
achieve high accuracy required applications physical workspace calibrated simulated environment 
online ne tuning needed detracts largest bene ine programming lack production downtime 
despite advantages ine packages online programming far commonly practice 
online programming actual part placed workspace exactly production user moves ector waypoints type control device typically joystick push buttons 
online systems generate procedural programming code users create waypoints editing code result typically viewed intuitive ine programming 
potentially extreme disadvantage online systems production programming occur parallel meaning production halted reprogramming 
reprogramming completed normal downtime weekends incur cost form lost production 
set tasks viable online programming constrained programming time 
reduction programming time permit robots areas previously limits 
users generally view online programming spend inordinate amount time simply moving robot waypoints transferring real knowledge 
furthermore due dif cult robot positioning process users tend discard previous create waypoints scratch time 
wasteful robot programs tend contain repeated subtasks product designs contain similarities previous designs 
developed predictive robot programming prp system allows users leverage previous decrease programming time 
specifically system aims assist users predicting may move ector automatically positioning robot predicted waypoint 
premise prp previous actions useful predicting 
usually case mentioned earlier robot programs tend contain similarities common patterns 
complicating prediction scheme inherent imprecision poor repeatability humans 
perfectly accurate sensors uncertainty task user trying perform 
prp system incorporate notion uncertainty operation prp system directly addresses uncertainty modeling prediction 
user observations robot programming waypoints program 
general purpose degree dof manipulators described cartesian space location orientation ende ector 
surjective cartesian space description preferable bijective joint space representation cartesian space description forms kinematics free coordinate transform 
cartesian space ector description waypoint homogeneous coordinate transform matrix wg maps global frame frame nth waypoint 
robot program described sequence waypoints wn specify location orientation ector discrete intervals 
homogeneous coordinate frame transform de ned matrix orthonormal matrix describing rotation frame frame vector speci es translation frame frame coordinate frame 
craig derived properties de nitions product homogeneous coordinate transforms called compounding written essentially equation describes relative change rotation translation frames inverse transform undoes trans 
di erent global frame relative movement information programs 
form derived earlier properties note inverse transform exists matrix inversion involves orthonormal matrix full rank 
demonstrate shortly capturing information absolute position information distinct advantage yielding rotation translation independence 
example robot programs shown quite different absolute terms description 
relative waypoint representation prp system able recognize patterns predict waypoints independent rotation translation 
de nition 
sequence homogeneous coordinate frame transforms respect common frame wn sequential relative homogeneous transform wg wg wg wn wn theorem transform independence 
robot program speci ed independent initial rotation translation 
proof 
suppose robot program arbitrary number waypoints wn give robot program initial rotation translation premultiplying waypoint homogeneous coordinate transform wg yield wg wg wg wn wn rotation translated program wh wh wh wn wn note original robot program de nition wg wg wg wn wn irrespective initial arbitrary rotation translation robot program speci ed yields rotation translation independence 
theorem implies robot programs recognized independent initial rotation translation 
develop simple equations needed predict waypoints rotation manner 
task comprised relative waypoints robot program convenience rewrite relative waypoint stacked column vector xn vec wn 
ith robot program written fx sequence prior observations algorithm learn hmm sequence robot programs fx note requirement robot programs common length describe physical task 
algorithm assimilate tasks corresponding arc welding bed frame spot welding ship hull painting car robot programs assimilated user begins creating new robot program compute predictions waypoint xn equation 
xn stacked column vector relative waypoint wn speci es expected relative movement ector prp 
diagram physical setup prp 

patterns user demonstrations thirteen waypoints respectively 
current position wn expected position waypoint estimator wn current position ector global frame wn wn wn physical implementation system user presses button teach pendant indicate current ector position considered waypoint current program shown 
mentioned earlier robot programming commonality occurs subtasks entire tasks 
mind prp system considers observations horizon 
considering xed horizon observations changes initial conditions equation xn jqj 
experimental results collected user observations robot programs described di erent tasks 
terminology repertoire user consists tasks shown 
right programs comprised waypoints represent standard arc welding tasks 
left programs comprised thirteen waypoints respectively planar geometrical movements 
create program user moves robot ector joystick cf 

user feels 
creating waypoints patterns abb irb 
ector suciently close waypoint presses button teach pendant 
robot programs assimilated hmm described repertoire user 
algorithm took second construct estimated repertoire model programs 
give intuition regarding parameter cf 
equation constructed hmm states transitions small value states transitions constructed larger value typical larger results hmm states larger necessarily results smaller 
small generally gives algorithm fewer opportunities combine dag states line 
machine learning algorithm danger tting data large allow algorithm generalize corresponds merging states algorithm 
determine accuracy system computed prediction performance system human generated data 
data set small cross validation set computed leave oneout statistics called jackknife estimator duda cartesian prediction error summarized table 
appropriate value average prediction error system roughly centimeters 
mean linear movement waypoints centimeters meaning average prediction error system roughly terms total distance traveled ector 
low error indicates algorithms compute accurate predictions 
hmm constructed small tasks di erent lengths 
small mean std dev prediction error meters meters error percent states transitions large mean std dev prediction error meters meters error percent states transitions table 
leave estimates prediction performance hmms variations fairly sparse data 
knowing system computes accurate predictions mainly academic interest 
user system interested reduction time required create robot programs 
scenario user asked complete tasks estimated repertoire priori programs 
user allow controller move ector prp system valid prediction con dence equation exceeds threshold 
uncommon user decide prediction re ned joystick ne tuning time included 
obstacle path 
hmm constructed large tasks di erent lengths 
prediction mean std dev change criterion table 
programming time required complete tasks prediction high con dence prediction low con dence prediction respectively 
prediction user prp system moving robot releasing dead man switch teach pendant 
results summarized table 
rst row table time required user program tasks predictions prp system 
second row shows programming time prp system suggests high con dence predictions relatively long horizon observations 
third row shows programming time prp system allowed suggest sloppy predictions potentially low con dence relatively short horizon 
surprisingly allowing prp system suggest low con dence predictions generally results greater prediction error 
statistically sig ni cant worth noting allowing low con dence predictions high con dence predictions tended reduce programming time 
suggests users nd accurate predictions helpful 
represented table primary bene predicting waypoints comes automatically setting orientation ector cartesian location 
probably due tendency routines controllers tie robot knots 
normal operation user occasionally move joint individually prevent physical joint reached 
happen prp system computing waypoints user 
covariance matrix required equation equation model gaussian user errors computed asking users move known locations orientations workspace computing second moment residual error 
discuss covariance matrix assumed block diagonal block corresponding cartesian errors block corresponding errors orientation 
representing waypoints little detail needed representation waypoints 
mentioned earlier waypoint consists components location orientation 
locations de ned respect frame robot programming domain invariably represented cartesian coordinates 
orientations de ne rotation frames input output frame domain variety representations 
homogeneous versus non homogeneous previous section constrained discussion homogeneous transforms merely mathematical hard requirement location orientation information waypoint de ned respect frame 
earlier mentioned representing robot programs yield translation predictions 
usual recorded table number collisions obstacles 
surprisingly collisions prp system suggested low con dence predictions 
collisions uncommon humans program automation tasks 
example arc welding requires separation workpiece 
consequently industrial manipulators designed handle eventual collision icting damage 

error rotation results compounded error leg length 
free lunch 
left open loop basing predictions results accumulating error similar dead reckoning errors mobile robot thrun 
particular problem small errors rotation compound 
corrupt square rotating leg head fourth leg origin due compounding errors leg length away origin 
compounding errors certainly worst case scenario prp domain human controlling robot closes loop residual prediction error 
dimensional case trying eyeball robot ector humans errors larger predictions su er severely 
compounding errors pressing concern predictions accurate possible 
employ non homogeneous transforms minimize impact poor ability humans judge orientation errors 
obvious solution works practice remove orientation estimates computation predicted location 
accomplished specifying predicted location global frame orientation predict change orientation ector 
predicted change location predicted change orientation rn current location orientation ector pn rn respectively 
compute predicted location orientation predicted waypoint wn pn rn rn rn free lunch straightforward show equation yield predictions rotation independent predictions 
representation orientation second important aspect prediction represent dimensional orientation information needed prediction 
rotation matrices poor choice predicted rotation matrix expectation equation 
extremely weighted sum orthonormal matrices orthonormal matrix 
case predicted orientation certainly violate properties rotation matrix 
common representations dimensional orientation involve euler angles 
similar orientations may extremely di erent euler angle representations euler angles equivalent 
discontinuities euler angles somewhat unreliable 
solution dimensions sines cosines ensure angle continuity rotation matrix dimensional case 
reasons unit quaternion represent orientation information craig 
quaternions discontinuous representations tend problematic practice 
quaternion vector unit length renormalizing quaternion expectation equation yields loss information 
derivation scale invariance prp system assimilated robot program moving rectangle little help predicting waypoints di erent sized rectangles rectangles aspect ratio 
ability recognize predict scaled versions previously assimilated tasks called scaled invariance 
mentioned earlier prp system able recognize patterns independent pose location respect global frame rotation translation independent features 
approach recognizing scaled tasks feature transform appears feasible predicting waypoints scaled tasks 
instance reduce robot program sequence rays mathematical sense ray 
recognize task previously assimilated tasks compute likelihood various rays 
half nite lines little help trying predict position waypoint yield direction prediction 
considered scale invariant transforms yielded equally annoying quirks 
turned brute force approach iterative locally optimal maximum likelihood 
formulation want nd value scales observations current task fx likelihood scaled task maximized estimated repertoire user arg max arg max arg max transition pmf observation independent observation pdf function scale factor 
rewrite equation xn jji prp domain want multiply element observation vector xn scale factor typically scale cartesian coordinates waypoint leave orientation components 
observation pdf gaussian distribution implies covariance matrix symmetric block diagonal block corresponding cartesian coordinates block corresponding orientation information 
real world terms yields mild assumption user cartesian errors independent orientation errors 
mind de ne scale matrix scaled scaled scaled scaled scaled observation xn column vector cartesian elements scaled orientation elements unscaled 
xn jji observation pdf gaussian diagonal symmetric matrix xn xn jc exp xn xn xn jc xn xn xn jc xn xn xn xn xn need notation cn jc jji corresponding partial derivative jji partial derivative equation respect scale factor xn jc xn jc xn jc xn jc xn jc jji xn xn jji xn xn xn jji 
waypoints pattern right form scaled subtask waypoints pattern left 
equation recursive appropriate initial conditions time needed partial derivative equation 
solve optimal ml estimator scale factor explicitly equation sum transcendental terms 
hope nd locally optimal ml solutions iterative line search techniques cubic interpolation gradient ascent 
bertsekas 
nd locally optimal ml estimator scale compute predictions scaled task substituting equation equation 
incorporate notion horizon section identify scaled subtasks contained tasks cf 

scaled task computed premultiplying observation ml scale matrix equation able identify scaled sub tasks having model incorporate scaled tasks model 
execute learn hmm algorithm leads chicken egg problem model determine ml scale task tasks create model 
give algorithm uses tasks assimilated estimate ml scale 
scale task equation assimilate scaled task dag 
estimate unreliable scaled version task assimilated 
case assimilate task unscaled 
bracketing scale arise physical nature manipulator robots 
robots nite accuracy reachability numbers serve bracket ml scale 
algorithm learn scaled hmm similarity threshold 
fx multiset tasks 
min minimum bracket scale 
max min maximum bracket scale 
fx compute scale min max equation assimilate task convert dag hmm 
algorithm assimilating scaled tasks hmm 

related problem stochastic source prediction generally decomposed steps mentioned creating model source model predict 
optimal prediction model fairly mature subject duda 

hand modeling stochastic sources active area research 
typically source assumed markov property extended include kth order markov sources equivalent rst order markov sources 
information theoretic approaches give bounds nite state predictability positive entropy markov sources feder 
seminal hmm applications rabiner outlines basic problems hmms notes third far dif cult problem hmms determine method adjust model parameters maximize probability observation sequence model 
consider dicult problem discovering structure model addition determining optimal parameters 
rudich showed structure discrete symbol markov chains determined limit output 
results suggest probabilistic finite automata hmms optimally trainable globally time polynomial alphabet size random polynomial time equivalent non deterministic polynomial time rp np abe warmuth 
function compute scale leveled dag 
fx task assimilate 
min minimum bracket scale 
max min maximum bracket scale 
maximum depth jx convert dag hmm arg max min max scale outside bracket assume long return 
computing ml scale task 
lieu disappointing researchers focus attention special subclasses hmms deliver optimistic results 
ron 
derive algorithm constructs correct pac learning sense leveled acyclic probabilistic finite automata time polynomial pac learning parameters requires polynomial training set provided states target distinguishable 
carrasco oncina outline algorithm approximates pfa distributions limit 
algorithms need upper bound number states model low training data requirements 
running time training data results polynomial alphabet size 
clear approaches scale high dimensional continuous spaces needed predictive robot programming vector quantization techniques 
long standing problem forward backward algorithm tendency leave super uous parameters model reliance large corpora data 
standard tricks reduce amount training data required forwardbackward algorithm left right models assuming diagonal covariance matrices 
modi cations perform small training sets allowed prp 
brand derives entropy prior hmm parameters develops map extinction scheme reduce number parameters model large corpora data needed 
hmm training algorithms developed singh large crossvalidation sets determine locally optimal topology 
optimal control domain research partitioning state spaces markov decision processes mdps 
shown time complexity partitioning mdp dicult computing optimal policies original mdp ren krogh 
informative results rely full observability markov chain mdp cost function 
bulk computation spent inducing structure markov chain data interested nding simple models explain data simpler models nearly isometric properties 
hci domain prediction synthesis user observations goes name learning observation programming demonstration teaching example permutation thereof 
yang researchers standard hmm training techniques learn telerobotic manipulation skills 
skills open loop force visual feedback user demonstrating task finite state automata fsas node executing memoryless nonlinear control law transitions determined hmm training user examples 
ikeuchi researchers created system generates robot programs assembly tasks observations humans performing task 
pomerleau constructed system allowed users generate essentially limitless supply training examples steering car 
examples computer system learned imitate car steering skill user camera input 
skill memoryless nonlinear control law 
yang 
hmm training techniques decompose human telerobotic manipulation tasks sequence primitives 
primitive open loop memoryless nonlinear control law 
temporal sequences primitives comprised skills fsas state transitions determined hmm training algorithm 
friedrich 
time delay neural networks decompose human actions sequence prede ned primitives storing decomposition symbolic fashion 
search pre post condition strips model fikes nilsson executed determine sequence primitives describes sequence observed user 
segmentation derived serves initial bias search create automatically generated program 
programs run sensor input unsuitable realistic operating conditions 
kang ikeuchi dynamic time warping dtw decompose observations humans performing assembly tasks symbolic prede ned primitives 
matari neuroscience psychophysical models select basis set primitives 
observations users segmented determine primitives execute temporally sequenced additive fashion 
user observations incorporated prime iterative optimal control techniques tasks schaal 

algorithms unsupervised model prediction user actions 
modeling user actions noise corrupted real valued vectors cast problem ssp 
essentially ssp algorithms operate phases 
rst phase estimates repertoire user due formulation naturally results 
derived results showing learning algorithm produces compact graphical models second order polynomial computational complexity 
second phase ssp algorithms predict values user actions 
order decrease online robot programming time created novel application predictive robot programming 
algorithms able predict accurately waypoint robot program small training set 
furthermore system shown laboratory experiments reduce robot programming time signi cantly 
complete theoretical foundations algorithms bounding prediction error system 
appears result pac bound error naturally rise probabilistic sample size requirement 
develop modi ed versions algorithms allow task correction recognition 
task correction recognition involve linking multiple probabilistic grammar 
grammar possible identify user diverges pre determined set rules governing standard behavior speci task user performing similar phonemes speech recognition 
modi cations require partial labeling data 
acknowledgments mike seltzer chris paredis asking tough questions giving enlightening suggestions 
martin strand john dolan provided helpful comments application algorithms predictive robot programming 
graphviz dotty research display hmm topologies 
intel providing computing hardware 
sponsored abb corporate research 
abe warmuth 

computational complexity approximating probability distributions probabilistic automata 
machine learning 
bertsekas 

nonlinear programming 
athena scienti brand 

entropic estimator structure discovery 
advances neural information processing systems pp 

carrasco oncina 

learning deterministic regular grammars stochastic samples polynomial time 
theoretical informatics applications 
craig 

robotics mechanics control 
addison wesley 
second edition 
duda hart stork 

pattern classi cation 
wiley interscience 
second edition 
feder merhav gutman 

universal prediction individual sequences 
ieee transactions information theory 
fikes nilsson 

strips new approach application theorem proving problem solving 
arti cial intelligence 
friedrich unch 

robot programming demonstration rpd supporting induction human interaction 
machine learning 
ikeuchi 

assembly plan observation task recognition planar curved mechanical contacts 
proceedings ieee rsj international conference intelligent robots systems pp 

kang ikeuchi 

robot system observes replicates grasping tasks 
ieee fifth international conference computer vision pp 

matari 

visuo motor primitives basis learning imitation 
imitation animals artifacts 
cambridge ma mit press 
pomerleau 

neural network perception mobile robot guidance 
doctoral dissertation carnegie mellon university 
rabiner 

tutorial hidden markov models selected applications speech recognition 
proceedings ieee 
ren krogh 

state aggregation markov decision processes 
appear ieee conference decision control 
ron singer tishby 

learnability usage acyclic probabilistic nite automata 
journal computer system sciences 
rudich 

inferring structure markov chain output 
ieee symposium foundations computer science pp 

schaal 

learning demonstration 
advances neural information processing systems pp 

singh raj stern 

automatic generation sub word units speech recognition systems 
submitted ieee transactions speech audio processing 
thrun 

learning metric topological maps indoor mobile robot navigation 
arti cial intelligence 
yang xu chen 

hidden markov model approach skill learning application telerobotics 
ieee transactions robotics automation 

