semi supervised self training object detection models chuck rosenberg google mountain view ca chuck google com construction appearance object detection systems time consuming difficult large number training examples collected manually labeled order capture variations object appearance 
semi supervised training means reducing effort needed prepare training set training model small number fully labeled examples additional set unlabeled weakly labeled examples 
semi supervised approach training object detection systems self training 
implement approach wrapper training process existing object detector empirical results 
key contributions empirical study demonstrate model trained manner achieve results comparable model trained traditional manner larger set fully labeled data training data selection metric defined independently detector greatly outperforms selection metric detection confidence generated detector 


object detection object detection systems statistical models object appearance quite successful years 
systems directly model object appearance image large amount labeled training data needed provide coverage space possible appearance variations 
collecting large amount labeled training data difficult time consuming process 
case training data appearance statistical object detection typically entails labeling regions image belong object interest belong non object part image cases marking landmark points 
object detection techniques practical crucial streamlined approach training users able rapidly insert new object models systems 
goal approach proposed simplify collection preparation training data martial hebert carnegie mellon university pittsburgh pa hebert ri cmu edu henry schneiderman carnegie mellon university pittsburgh pa ri cmu edu combination data labeled different ways 
call weakly labeled training data labeling image regions take form probability distribution labels 
possible capture variety information training examples 
example possible indicate object interest center image 
possible encode knowledge specific image high likelihood containing object object position unknown 
refer type training weakly labeled semi supervised 
literature anecdotal evidence suggests semi supervised training provide performance improvement applied object detection problem 
perform comprehensive empirical evaluation goal characterizing understanding issues order facilitate broad practical application semi supervised training object detection problem 
practical reasons detector evaluation selected detector representative algorithms literature 
believe context computer vision comprehensive scale study semisupervised training techniques necessary practical application object detection algorithms 

training approaches order introduce general approaches semisupervised training describe generic detection algorithm classifies subwindow image member object class clutter class 
classification values feature vectors associated subwindow image 
designate image feature vectors data specific location image indexes image locations 
goal compute 
associated image class particular model equal foreground model background model 
indicate parameters foreground model background model 

schematic representation batch training approach em left incremental approach right 
set likelihood ratio entire window value likelihood ratio thresholded determine presence absence object 
practice detection performed subwindow image scanned possible locations input image 
generic object detector natural approach weakly labeled training expectation maximization em 
generic method generating estimates model parameters unknown missing data 
implemented iterative process alternates estimating expected values unknown variables maximum likelihood values model parameters left 
local maxima model selection issues em ideal approach semi supervised learning 
em context text classification em useful approach training models weakly labeled data 
nigam instances em perform 
reasons em may perform particular semisupervised training context 
reason em solely finds set model parameters maximize likelihood data 
issue fully labeled data may sufficiently constrain solution means may solutions maximize data likelihood optimize classification performance 
variety approaches attempt incorporate new information em design alternate algorithms utilize additional prior information may specific semi supervised problem 
alternative chose evaluate called self training incremental training 
self training initial model constructed fully labeled data 
model estimate labels weakly labeled unlabeled data 
selection metric decide weakly labeled examples labeled correctly 
examples added data training set process repeats 
obviously selection metric chosen crucial incorrect detections data included training set final answer may wrong 
issue explored 
discussing incremental addition training data labels useful define terms initial labeled training set initial set fully labeled weakly labeled training set current set weakly labeled current labeled training set initial training set addition weakly labeled examples assigned object detection framework detailed previous sections basis weakly labeled data approach 
approach begins initial set model parameters trained initial labeled training set provided 
serves starting point weakly labeled data approach modify foreground model 
weakly labeled data approach relies able estimate object training image current model 
initial model trained limited amount data may possible especially weakly labeled training data differs significantly appearance training images 
approach immediately add weakly labeled data training set incorrect labels potentially corrupt model statistics 
approach described attempt reduce impact issue labeling weakly labeled examples adding incrementally training set confidence labels similar methods described 
order images added critical allow model generalize images similar initial training set incrementally extending views quite different original training set 
schematic representation training procedure termed self training incremental semi supervised training right 
incremental training procedure combination weakly fully labeled data summarized follows initialization 
train parameters initial model consisting foreground background models fully labeled data subset 
initialize initial labeled training set provided fully labeled data 
iteration 
compute selection metric sel 

select weakly labeled example argmax highest score update current training set weakly labeled training set 

compute new foreground model 
iteration practical implementation semi supervised approach straightforward application techniques described section complex nature real world image data 
focus provide insight specific key issues fundamental practical implementation semi supervised training object detection systems metric deciding examples add training set incremental training 
performance detector affected size labeled weakly labeled sets 

previous years substantial amount addresses problem incorporating unlabeled data training process 
earliest context object detection described 
authors expectation maximization em approach 
selinger uses incremental approach similar approach 
main differences contour detection model 
model output scoring metric decide image add metrics tended better 
utilizes em approach 
similar described 
object detection system trained images labeled indicating presence absence object interest 
search approach find correspondences detected features model features 
described similar extends prior evaluation mix labeled weakly labeled data performed problem examined discriminative context incorporation types labeled data accommodated 
number authors taken approach representing relationships labeled unlabeled data graph edge weights inversely related similarity different examples feature space 
minimum cut algorithm decide labeling unlabeled data 
method augments graph training examples pair class nodes represent positive negative classes 
infinite weight edges connect labeled examples appropriate class nodes 
analysis showed particular graph structures edge weights correspond optimizing specific learning criteria 
set ideas area random walks graph capture notion examples similar feature space similar la search location scale wavelet transform feature construction classifier log 
schematic representation detection process single stage detector 

earliest area szummer jaakkola analyzed extended 
promising direction information regularization 
notion exactly capture information hope transfer unconditional underlying distribution class label likelihood 
idea unlabeled data constrain final hypothesis particular way 
specifically want hypotheses tend split high density regions underlying distribution 

experimental setup 
detector overview chose detector described conduct experiments 
successfully face detection rigid objects demonstrated accurate face detection 
detector able capture certain aspects appearance variation intra class variation 
handle large changes scale translation detector scanned image different scales locations corresponding subwindow run detector 
schematic representation detection process subwindow processed lighting correction level wavelet transform applied features computed groups wavelet coefficients 
subwindow classified thresholding linear combination log likelihood ratios features 
detector uses cascade architecture number detectors placed series image patches accepted detector passed 
single stage cascade simplify training process 
accordingly detection performance lower typically achieved detector 
chose limit processing stage facilitate repetitions training process experiments possible full detector long training times 

landmark typical training image left sample training images training examples associated right 

data object chosen experiments human eye seen full near frontal face 
fully labeled example landmark locations eye labeled 
labeled regions training image rotated canonical orientation scaled cropped result training example image 
full set images positive examples consists images 
images training examples image total training examples 
independent test set consisted images 
images testing examples total test examples 
addition object training examples set negative examples 
experiments described fixed set negative examples 
negative examples assumed plentiful collected cheaply 
training test images typically range pixels high pixels wide 
training examples normalized images scale invariance achieved scaling image detection process 
total synthetic variations applied training example including translation scale degrees rotation 

training training model fully labeled data consists steps 
training data landmark locations geometrically normalize training example subimages apply lighting normalization subimages generate synthetic training examples 
consists scaling shifting rotating images small amounts 

compute wavelet transform subimages 

quantize group wavelet coefficients build naive bayes model respect group discriminate positive negative examples 

adjust naive bayes model boosting maintaining linear decision function effectively performing gradient descent margin 

compute roc curve detector cross validation set 

choose threshold linear function final performance desired 
full detector cascade trained steps repeated setting threshold achieves low false negative rate stage 
positive examples iteration images current training set passed detection test previous iteration 
computational reasons limit stage 
goal experiments train detector different combinations fully labeled weakly labeled data evaluate resulting detector performance 
semi supervised incremental version training procedure experiments reported summarized follows 
train detector limited amount fully labeled positive examples full set negative examples 

run detector weakly labeled portion data set find locations scales corresponding maxima likelihood ratio 

output detector label unlabeled training examples assign selection score detection 

select subset newly labeled examples selection metric 

iterate go back step 
fixed number iterations training images added 
typically image added training set removed values latent variables fixed 

selection metrics type selection metrics selecting example add weakly labeled data set step 
crucial performance training 
evaluated difference performance selection metric classification confidence selection metric distance measure patches defined independently detector 
key observation independently defined second metric failure modes orthogonal failure modes detector leading better performance supported empirical results 
effect independently defined metric previously investigated appears contribute critical way training performance 
selection metric termed confidence selection metric computed iteration applying detector trained current set labeled data weakly labeled set 
detection highest detection confidence selected added training set 
second selection metric termed mse selection metric calculated weakly labeled example evaluating distance corresponding image window templates training data including original labeled examples weakly labeled examples added 
schematic representation computation mse score metric 
candidate image labeled images normalized specific set processing steps mse score metric computed 
prior iterations 
distance computed normalization detected template scale position orientation values computed detector high pass filtering normalization zero mean unit variance 
candidate image assigned score minimum distances 
candidate images smallest scores selected addition training set 
define weakly labeled image consideration index labeled images specific image set labeled images transformation performed image preprocessing step weights computing mahalanobis distance computation written score mahalanobis important note computation mse selection metric key information position scale returned currently detector 
result detector accurate localization need accurate detection false detection discarded due large large mse distances training examples 
crucial ensure performance training algorithm small initial training sets 
part reason mse outperform confidence metric requires detector accurate localization detection performance 

experiments analysis 
experiment scenarios quite bit variance final detector performance behavior semisupervised training process 
variance arose specific set images randomly selected small initial training subset 
overcome limitation experiment repeated different initial random subset 
call specific set experimental conditions experiment repetition experiment call run 
cases runs performed experiment 
parameter experiments number images added iteration 
ideally single image added iteration 
substantial training time detector image added iteration 
adding images reduces average training time weakly labeled image increases chance incorrect detection included weakly labeled data set 
typically weakly labeled images added training set iteration 
challenges performing experiments inner loop algorithm training detector specific training set takes order twelve hours ghz level machines 
detector trained iterations repetitions experiment performed experiment takes hours compute time 
result total computation time necessary investigate variations parameters training conditions increases rapidly approximately cpu years 

evaluation metrics run evaluated area roc curve auc 
different experimental conditions affect performance aucs normalized relative full data performance run 
reported performance level mean model evaluated performance labeled data utilized 
value mean model lower performance achieved full data set 
compute full data performance specific run trained full data set performance recorded 
performance runs specific experiment aggregated compute single set performance measures mean standard deviation significance interval computed mean plus minus times standard error mean 
plots show standard deviation significance interval error bars 

baseline training configuration important characterize sensitivity training set size want perform experiments conditions addition weakly labeled data difference 
performance detector maximum labeled training set specific size expect weakly labeled data reasons space summary experiments 
detailed analysis influence number features geometric variations training variations reported 
full data normalized area roc curve failure normalized test set performance versus training set size smooth saturated cv sts sig std dev number training images log scale 
normalized auc performance detector plotted training set size log scale regimes operation labeled 
inner error bars indicate significance interval outer error bars indicate standard deviation mean 
help 
order establish baseline typical number examples needed train detector ran detector different training set sizes recorded auc performance 
interpretation data regimes training process operates 
call saturated regime case appears approximately training examples 
regime examples sufficient detector learn requisite parameters data result better performance 
similarly variation performance relatively constant small range 
call second regime smooth regime appears case training examples 
regime performance decreases variation increases relatively smoothly training set size decreases 
third regime failure regime drop performance large increase performance variation 
third regime occurs training algorithm sufficient data estimate set parameters 
extreme case parameter estimation problem ill conditioned 
set experiments chose size labeled training set smooth regime experiments weakly labeled data 

selection metrics question choice selection metric substantial difference performance semi supervised training 
conducted experiments compare main options confidence metric natural approach selecting example highest detector confidence mse metric defined independently detector confidence 
result detector independent mse metric outperforms intuitive confidence metric 
norm auc confidence score training set iter mse score training set norm auc 
comparison training images selected iteration confidence mse selection metrics 
initial training set images metrics initial training set size 
comparison selection metrics summarized 
plots horizontal axis indicates frequency training data sampled order select initial labeled training set run means th full training data initial labeled training data rest unlabeled data 
plots show performance improved addition weakly labeled data range data set sizes 
improvements significant level confidence metric 
mse metric improvement performance significant data set sizes 
observation supported experimental variations mse metric consistently outperforms confidence metric 
shows montages examples selected weakly labeled training images selected iteration confidence metric mse metric single run 
performance detector trained mse metric improves iteration performance confidence decreases 
confidence metric clearly incorrect detections included training set past iteration 
contrast images mse metric selects valid outlier iteration 

relative size fully labeled data important evaluate number weakly labeled exemplars need added labeled set order reach best detector performance 
evaluation recorded number examples need added initial set order reach point performance detector change appreciably training run 
data summarized plotted ratio weakly labeled data labeled data training procedure converged full data normalized area roc curve normalized test set performance versus training set sampling rate confidence score cv sts fully labeled data sig cv sts best weakly labeled performance sig training set sampling rate full data normalized area roc curve normalized test set performance versus training set sampling rate mse score cv sts fully labeled data sig cv sts best weakly labeled performance sig training set sampling rate 
normalized performance detector incorporating weakly labeled data confidence metric mse metric fully labeled training set size varies 
bottom plot line performance labeled data top plot line performance addition weakly labeled data 
error bars indicate significance interval mean value 
ratio weakly fully labeled training set size sig weakly versus fully labeled training set size confidence score sampling rate training set sampling rate 
ratio weakly labeled fully labeled data fully labeled training set size increases 
size initial training set precisely sampling rate generating initial training set 
data shows expected ratio increases size initial training set decreases weakly labeled examples needed compensate smaller training sets 
importantly total size training set initial labeled training images examples added training saturated operating regime identified 
important shows small initial training sets total number examples order number needed train detector single set labeled examples 
words small set labeled examples cause pay penalty terms greater size total training set 

discussion experiments lead observations useful developing detection systems weakly labeled training 
results show possible achieve detection performance close base performance obtained fully labeled data small fraction training data initial training set 
observation remains valid account high degree variability performance different choices initial training sets illustrated error bars graphs fact normalize detector performance respect base detector trained labeled data 
second practical matter experiments show approach semi supervised training applied existing detector originally designed supervised training 
fact case detector highly optimized able integrate training framework 
suggests general procedure semi supervised training existing detectors 
fundamental observation mse selection metric consistently outperforms confidence metric 
experiments simulated data detectors reported reasons space show generally self training approach independently defined selection metric outperforms approach confidence metrics batch em approaches 
results bring light important aspect self training process overlooked 
issue training process distribution labeled data particular iteration may match actual underlying distribution data 
result confidence metrics may perform poorly labeled data distribution created metric quite different underlying distribution weakly labeled data selected metric correctly labeled 
illustrate observation shows simple simulated example labeled unlabeled examples drawn gaussian distributions plane 
comparing labels obtained iterations confidence metric euclidean metric see labeled points cluster existing data points 
believe closer examination issue theoretical practical standpoint important interesting topic research effective application semi supervised approaches object detection problems 

summary goal explore evaluate approaches semi supervised training weakly labeled data appearance object detection 
conducted extensive experiments state art detector led important including quantitative evaluation performance gained adding weakly labeled data initial small set labeled data demonstration feasibility modifying existing detector feature feature unlabeled class class feature feature unlabeled class unlabeled class labeled class labeled class feature unlabeled unlabeled class unlabeled class labeled class labeled class feature feature unlabeled unlabeled class unlabeled class labeled class labeled class feature 
original unlabeled data labeled data plot true labels unlabeled data points labeled incremental self training algorithm iterations confidence metric euclidean metric respectively 
weakly labeled data insights choice selection metric training 
important issues critical practical applications training ideas remain explored 
important different version detector initial training actual test images 
example position scale accuracy detector important semi supervised training may important detector application 
second alternative explanation success nearest neighbor approach appropriate selection metric performing type training 
interesting study relation semi supervised training approach evaluated training approaches 
shown experiments choice initial training set large effect performance 
performed experiments compare different selections initial training set useful develop precise guidelines selecting 
approach extended training examples labeled different ways 
example images may provided scale information 
additional information may provided rough shape object prior distribution location image 
baluja 
probabilistic modeling face orientation discrimination learning labeled unlabeled data 
nips 
bishop 
neural networks pattern recognition 
oxford university press 
blum chawla 
learning labeled unlabeled data graph 
icml 
blum mitchell 
combining labeled unlabeled data training 
colt 
jaakkola 
information regularization 
uai 
cozman cohen 
semi supervised learning model search 
icml workshop continuum labeled unlabeled data machine learning data mining 
fei fei fergus perona 
bayesian approach unsupervised shot learning object categories 
iccv 
fergus perona zisserman 
object class recognition unsupervised scale invariant learning 
cvpr 
joachims 
transductive inference text classification support vector machines 
icml 
levin viola freund 
unsupervised improvement visual detectors training 
iccv 
mccallum nigam ungar 
efficient clustering high dimensional data sets application matching 
kdd 
nigam 
unlabeled data improve text classification 
phd thesis carnegie mellon university computer science dept 
cmu cs 
nigam ghani 
analyzing effectiveness applicability training 
cikm 
nigam mccallum thrun mitchell 
learning classify text labeled unlabeled documents 
aaai 

general algorithmic framework discovering discriminative generative structure data 
master thesis ece dept carnegie mellon university 
rosenberg 
semi supervised training models appearance statistical object detection methods 
phd thesis carnegie mellon university computer science dept may 
cmu cs 
schiele crowley 
recognition correspondence multidimensional receptive field histograms 
ijcv 
schneiderman 
feature centric evaluation efficient cascaded object detection 
cvpr 
schneiderman 
learning restricted bayesian network object detection 
cvpr 
selinger 
minimally supervised acquisition recognition models cluttered images 
cvpr 
szummer jaakkola 
partially labeled classification markov random walks 
nips 
szummer jaakkola 
information regularization partially labeled data 
nips 
viola jones 
robust real time object detection 
technical report compaq cambridge research lab 
weber welling perona 
unsupervised learning models recognition 
eccv 
zhu ghahramani lafferty 
semi supervised learning gaussian fields harmonic functions 
icml 
