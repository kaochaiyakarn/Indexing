efficient stochastic part speech tagging hungarian research institute linguistics hungarian academy sciences budapest hu saarland university coli uni sb de methods developed western european languages widespread produce annotated language resources readily applied central eastern european languages due large number novel phenomena exhibited syntax morphology languages methods handle designed cope 
process morphological tagging applied hungarian data produce corpora annotated morphosyntactic level indicative problem algorithms rule statistical successfully domains readily applied language exhibiting varied morphology huge number hungarian 
describe robust tagging scenario hungarian relatively simple stochastic system augmented external morphological processing overcome problems complexity morphosyntactic descriptions importantly huge number possible 

part speech tagging considered cheap method produce language resources low level linguistic annotation usable various purposes serving preparatory phase complex language processing tasks 
western european languages tagging extensively described various methods developed merialdo brill ratnaparkhi daelemans combined van halteren brill wu producing results satisfactory suggest research level natural language processing longer interesting rewarding 
trying deal highly inflectional agglutinative languages successful methods face extra difficulties number different possible morphosyntactic descriptions msd apparent 
considerable research addressing issues highly inflectional languages haji experimenting procedure overcome problem large number morphosyntactic descriptions generating designing reduced tagset proper tagging texts 
process faced difficulty identifying features carry information relevant disambiguation task 
phenomenon particularly characteristic hungarian large number presents situation statistical models widely state art taggers lexical probabilities calculated lexicon generated training extremely large training corpus necessary derive reliable statistics possible unseen data training corpus fairly large words process inevitably result large number words seen training 
simple solution mentioned passing 
proposed haji basically amounts making list possible tags available tagger 
hungarian proves workable alternative adopted necessitating external morphological analyzer core component tagging system 
empirically investigate information supplied morphological analyzer utilized improve tagging performance goal build pos tagger hungarian high accuracy define architecture suitable disambiguation task simple stochastic tool cope particular characteristics highly inflectional languages 
section 
discuss main problem originates characteristics reflected hungarian data 
section 
give brief description data tools experiments 
section 
show stochastic tagging aided information morphological analyzer 
section 
give short summary error analysis 
suggestions follow section 
data sparseness highly languages computational linguistic common sense morphological tagging highly agglutinative languages difficult task example pos haji proposes preparation independent morphological dictionary automatic method 
hungarian feasible solution morphological analyzer provides necessary information line 
tagging morphologically rich languages english french german 
cf 
haji 
reason situation generally claimed data sparseness 
data sparseness manifests clearly different ways task morphological tagging addressed 
frequently discussed issues lead sparsity training data high cardinality tagset brants 
number tags non agglutinative languages generally systems agglutinative highly languages tagsets cardinality magnitude higher cf 

harris 
entails case ngram statistical model estimate times parameters need bigger training corpora languages 
contrary needs amount available annotated linguistic resources languages smaller researched languages english 
way problem caused huge tagsets internal set smaller cardinality tagging purposes 
propose automatic tagset reduction algorithm full recoverability word ambiguity class original tags mapped distinct ctags discuss effect size internal tagset morphological tagging hungarian 
results show significant reduction decrease accuracy tagger 
cited problem highly languages amount ambiguity morphological system relates tagset size 
uncertainty token fact taken ambiguous kind distinctions morphological specification 
decision specific token assigned morphological class depends factors ranging linguistic tradition projected processing 
tentative guidelines considered domain tagging ascribing different analyses full 
analysis unambiguous analyses substituted original specific environment 
ii distinctions features performance oriented 
features resolved reliably try handle post processing varying methods preserve introduce new criterion assign instance analyses genitive dative hungarian nominal forms nak suffix genitive construction unambiguous form analyzed genitive environment 
grounds deny presence genitive case hungarian fact 
distinctions resolved current model 
way primary objective try reduce error rate oracle available 
unfortunately standard methodology exists provide independent metric difficulty tagging task different settings standardly reported measures tagset size ratio ambiguous tokens average ambiguity little indication hard task classifier parameters set differently usual error rate performance measures entirely uninformative 
standard practice measures ambiguity considered percentage ambiguous tokens average number tags assigned tokens 
measure english difficult highly language amount ambiguous tokens english romanian czech haji 
respect hungarian easier tag tokens ambiguous obviously depends definition ambiguity refined analysis 
measure ambiguity average number tags tokens 
measure figures show variation czech tags token depending tagset corpus haji english romanian hungarian 
extent differences effect tagging far clear difficult test factors prevent controlling parameter 
measures things equal tagging hungarian easier tagging english 
case means factors come play 
fact relevant manifestation data sparseness mentioned 
principal reason poor performance fairly accurate taggers 
english inferred table hu en stand hungarian english respectively ac refer modified hungarian corpus word mapped ambiguity class see section 
generally case hungarian english twice different word types corpus size brief description data see section 
entails lexicalized taggers hungarian difficult data sparser unusual tagging highly languages morphological reflected underspecified values cases resulting disambiguation task easier resolving distinction inherently morphology language different ing forms english main verbs normally distinguished quite distinct distributions 
certain languages disambiguation problems just naturally regarded belonging domain tagging languages delegated levels analysis due presence morphological marking phenomena necessarily fact disambiguation task harder language 
hu en ac tags tags tags training corpus tokens training corpus types test corpus tokens test corpus types types test seen training tokens test seen training tokens test unseen tags training diff 
tags test seen training table comparison english hungarian corpora accurate estimation probability distribution tags word 
lines en hu shows different aspect phenomenon hungarian low frequency words words occurrences amount word tokens english low frequency words constitute total corpus numbers 
tokens frequency hu en ac tokens frequency hu en ac cumulative percentage tokens wrt 
type frequency difference striking case singletons hungarian add corpus english contribute words corpus 
straightforward consequence difference behavior languages different amount tokens test data previously seen training phase 
table shows hungarian word tokens training data seen training times corresponding amount english 
means suitable guessing method lexicalized taggers hungarian bound achieve worse results english 
put way round order able achieve acceptable tagging accuracy hungarian agglutinative languages apply suitable guesser handle previously unseen words 
experiments external morphological analyzer able return possible morphological analyses 

data tools data calculating results table tagging experiments discussed section 
consisted hungarian training corpus contained tokens 
similar sized part section wall street journal penn treebank pos tagset english corpus 
results obtained standard fold cross validation 
tagging experiments default tagset preserved basically morphological information cardinality occurred training corpus 
external morphological analyzer wide coverage rule morphological analyzer developed originally hungarian returns list possible morphological analyses word 
tagging experiments needed slightly modified version thorsten brants tnt tagger brants underlying architecture trigram hidden markov model 
model learn lexical probabilities training corpus fed inverted lexical probability distribution input token associated list possible tags augmented conditional probabilities tags token jw 
tagger calculated lexical probabilities jt required markov model bayesian inversion 

class guessing 
morphological analyzer mentioned case languages rich inflection accurate tagger proper guesser able provide possible tags words unseen training corpus 
experiments opt symbolic guesser morphological analyzer 
symbolic module stochastic nlp architecture answer important questions considering aim tagging experiments test tagging architecture guesser unknown words morphological analyzer test training corpora 
thorsten brants making modifications purposes 
symbolic module alternative stochastic ii incorporate symbolic module stochastic framework 
induce probabilities output symbolic module iii domain application symbolic module choice external morphological analyzer due fact suffix guessing algorithm samuelsson built tnt suitable english german brants hungarian cf 
table models 
opinion main reasons suffix guessing algorithm agglutinative languages data sparseness ii high level suffix ambiguity 
hand agglutinative languages carry considerable amount morphological information suffixes suffix sequence usually fairly long characters training corpus means worst case morphologically distinct endings 
course overestimation clearly shows long suffixes carry important morphological information occur training corpus sufficient number 
hand frequent suffix forms hungarian homographs 
tend participate inflectional paradigms 
ek attached verb noun 
interestingly words endings tend ambiguous stem generally takes reading suffix guessing algorithm disambiguate cases morphological analyzer 
problem complicated fact zero morph frequent morphemes stem generally disambiguates morphemes 
morphemes hungarian usually surface forms contribute sparse data problem 
findings motivated morphological analyzer relying suffix guessing algorithm 
table summarizes results experiments basic models 
baseline model tokens seen training phase assigned tags basis unigram frequencies calculated training corpus previously unseen tokens rudimentary strategy received nominal tag frequent training 
second model baseline strategy seen words augmented suffix guessing algorithm gave rise accuracy third model trigram tnt suffix guessing algorithm 
trigram model predictable accuracy previously seen tokens higher 
performance unseen tokens increase level comparable lan exclude specifically punctuation evaluation morphological analyzer utilized just unambiguous tokens unambiguous token 
guages 
symbolic morphological analyzer plugged system significant increase unseen consequently accuracy clearly noticeable model table 
hardly surprising provided fair number tokens assigned analysis analyzer 
striking high accuracy previously seen tokens obtained primitive unigram models table suggests hungarian frequent ambiguous items tend occur running text frequent analysis 

weighting output analyzer morphological analyzer assign probabilities tags address question incorporate knowledge tagging system 
described section underlying model architecture hidden markov model augment information tokens inverted lexical probabilities 
naive way get problem simply assuming uniform distribution tags proposed guesser word 
approach gives considerable rise accuracy compared suffix guessing method discussed cf 
model table model table 
propose approach yield higher accuracy architecture 
infer inverted lexical probabilities tags previously unseen word 
seen word training corpus seen words behave similarly sense occur similar environments take tag 
words example ambiguity class words show ambiguity behavior 
books loves ambiguous nns vbz candidates inferring information word question 
infrequent words morphology tend preferences 
determine distribution tags previously unseen word belonging ambiguity class motivated step inverted lexical probabilities words ambiguity class 
computational motivation ambiguity classes account step highly reduces sparse data problem 
table show ambiguity classes ac lexical words hungarian behaved language tokens amount training corpus tokens test unseen training 
knowledge idea ambiguity classes proposed kupiec pursued example radev 
methodology simple elegant training test corpora words substituted ambiguity class training test corpora contained tokens nns vbz books loves train test models modified corpora 
problem brants reports english german tnt 
model performance unseen seen acc 
unseen acc 
acc 

baseline 
baseline suffix guess 
tnt 
baseline morph 
analyzer table performance basic models model performance unseen seen acc 
unseen acc 
acc 

tnt ac 
tnt full ac 
tnt ma uniform 
tnt ma classbased 
tnt ma smoothed table performance tnt aided morphological analyzer ma move lose preferences frequent tokens 
example books looks share ambiguity class wsj tends prefer nominal tag verbal occurrence takes verbal tag cases 
results lexical information described table model 
remedy situation kupiec maps infrequent words ambiguity classes retain frequent tokens 
experiment tried similar scenario determine token mapped ambiguity class independent token frequency list prepared word corpus analyzed morphological analyzer allowing construction frequency list ambiguity classes 
conversion tokens equivalence classes token represented actual token occurred times corpus substituted ambiguity class 
clearly approach leaves room fine tuning expect different parameter settings influence performance significantly 
trained tested tagger new corpora result described table model 
interesting see slightly lexicalized model worse non lexicalized 
equivalence class approach improves tagging accuracy considerably important shortcomings 
important fact lose information training corpus 
word mapped ambiguity class contribute tagger knowledge tag distribution ambiguity class 
hand token frequent mapped ambiguity class lose lexical properties 
light high baseline accuracy suggests words generally occur frequent tags approach slightly penalized 
naturally lose information considering ambiguity classes propose method distribution tags lexical token ambiguity class 
approach ambiguity classes needs modification order able handle previously unseen ambiguity classes previous experiments built suffix guesser 
order avoid loss information train model lexical items ambiguity classes 
architecture means generation lexicons containing frequency counts tags word calculate inverted lexical probabilities jw 
lexicon quite similar containing frequency counts tags ambiguity class 
input tagger words ambiguity class optionally list possible tags 
tagger encounters previously unseen word uses tag distribution ambiguity class 
hand word seen training corpus take distribution tags lexical token 
possible word occur training corpus possible tag predicted ambiguity class 
cases give probability mass previously unseen tag 
exact add fixed frequency counts tag previously unseen tag low frequency tokens get higher conditional probability high frequency tokens 
algorithm formally described 
results experiment kind weighting method described table model show considerable increase approaches equivalence classes assuming uniform distribution tags 
unseen word return normalize dist class tags union tags dist word dist class num number tags tags foreach tag tags tag distrib word add tag freq dist word add tag freq num return normalize calculation tag distributions word ambiguity class note important welcome side effect tagging architecture type described 
apart ambiguity class input file word associated list possible tags system restricts calculation inverted lexical distribution tags 
enables external possibly symbolic modules order filter readings wider contextual semantic information making tagger suitable fast accurate shallow text processing 

smoothing third question concerning incorporation morphological analyzer stochastic nlp system addresses domain application symbolic module 
sight morphological analyzer encountering previously unseen word 
partly true algorithm described simple smoothing words occur training corpus possible unseen tags get probability mass depending number occurrences word training 
method really combine tag distributions word ambiguity class important factor word seen 
sophisticated approach try combine distributions example frequency dependent linear combination tag inverted lexical probability word ambiguity class infrequent tokens 
adopt model find determine word rare experiments words occurring times training corpus smoothing explicitly smoothing technique able robustly handle unseen data 
algorithm 
infrequent words 
options obvious fix independently word ambiguity class 
alternatively set parameter relative frequency word ambiguity class 
problem approach ambiguity class generally occurs lexical item ambiguity class get heavy weight 
chosen dependent number word types belonging ambiguity class frequencies word ambiguity class 
kind smoothing gives insignificant rise accuracy cf 
table model 

error analysis short overview main findings analysis tagging errors detailed account scope 
frequent errors fall basic categories consisting items information needed correct disambiguation captured model disambiguation information available local context model utilize 
particular typical type behavior system unigram frequency scores detriment bigram trigram values places local context definitely favors alternative unigram frequencies 
ii disambiguation information available higher levels linguistic analysis 
items practically model constitute candidates feature merger performance oriented tagset 
recourse context dependent linear interpolation standard practice parameters calculated various frequency groupings 
possible alternative analyses token related low frequency bigrams falling grouping distinct parameters calculated errors persist 
pursue issue elaborate partitioning parameter settings help solve problem opt small symbolic preprocessor data operates environmentally triggered deterministic rules 
built system filtering input stochastic classifier able achieve reduction average number errors rise accuracy settings 

discussed straightforward method hope demonstrated simple tagging scenario second order hmm effectively cope morphological disambiguation agglutinative language traditionally regarded unsuitable trivial model 
shown appropriate information provided external morphological analyzer solve ubiquitous data sparseness problem 
advantages system need huge dictionary resources fact practically impossible prepare independent morphological lexicon need contain billions entries architecture able tag running text robustly line language model built training corpus need extremely large allowing low cost manual preparation 
choice tagging tool motivated surprisingly high baseline performance brute force unigram relative frequency counts predicted relatively simple model able give sufficient performance real life applications exactly apply statistical learner trained labeled examples maximum likelihood estimates 
hmm tnt particular comfortable choice task contrary intuition suggest trigram hidden markov model suitable method hungarian relatively free word order language constituents ordered information structure argument structure predicates 
free word order lead crash hmm approach problems stemming highly inflectional nature hungarian overcome hmm tagger give results 
needed develop external guesser preprocess words genuinely unknown morphological analyzer provide possible analyses hungarian morphology allow form suffix approximating technique built tagger perform hungarian 
worth exploring results language specific applying method languages similar characteristics 

acknowledgments authors especially grateful thorsten brants modifying tnt enabled tagger architecture 
authors supported number si 

thorsten brants 

internal external tagsets part speech tagging 
proceedings eurospeech rhodes greece 
thorsten brants 

tnt statistical part speech tagger 
proceedings sixth applied natural language processing conference anlp seattle wa 
eric brill jun wu 

classifier combination improved lexical disambiguation 
proceedings coling acl pages montreal canada 
eric brill 

transformation error driven learning natural language processing case study part speech tagging 
computational linguistics 
walter daelemans zavrel peter steven 

mbt memory part speech tagger generator 
proceedings fourth workshop large corpora pages copenhagen denmark 


bottom tagset design maximally reduced tagset 
anne thorsten brants hans editors proceedings workshop linguistically interpreted corpora coling pages 
saso dzeroski zavrel 

morphosyntactic tagging slovene evaluating pos taggers tagsets 
technical report dept intelligent systems jozef stefan institute ljubljana 
jan haji 

tagging languages prediction morphological categories rich structured tagset 
proceedings th annual meeting acl coling montreal canada 
jan haji 
morphological tagging data vs dictionaries 
proceedings anlp naacl conference pages seattle washington usa 
papageorgiou harris 

unified pos tagging architecture application greek 
proceedings second international conference language resources evaluation athens 
julian kupiec 

probabilistic models short long distance word dependencies running texts 
proceedings darpa speech natural language workshop pages philadelphia 
morgan kaufman 
julian kupiec 

robust part speech tagging hidden markov model 
computer speech language 
bernard merialdo 

tagging english text probabilistic model 
computational linguistics 


humor morphological system corpus analysis 
proceedings seminar pages budapest 
adwait ratnaparkhi 

maximum entropy part ofspeech tagger 
conference empirical methods natural language processing university pennsylvania 
christer samuelsson 

handling sparse data successive abstraction 
proceedings coling denmark 
dan 

principled hidden tagset design tiered tagging hungarian 
proceedings second international conference language resources evaluation athens 
dan 

tiered tagging combined language models classifiers 
jelinek nth editors text speech dialogue lecture notes artificial intelligence pages 
springer 
dan 

large set eagles compliant morpho syntactic descriptors tagset probabilistic tagging 
proceedings second international conference language resources evaluation athens 
dragomir radev 

ing word class part speech disambiguation 
fourth workshop large corpora pages copenhagen denmark 
international conference computational linguistics 
hans van halteren zavrel walter daelemans 

improving data driven tagging system combination 
proceedings coling acl pages montreal canada 
