journal instruction level parallelism submitted published structure performance efficient interpreters anton ertl anton mips tuwien ac institut tu wien wien austria david gregg david gregg cs tcd department computer science trinity college dublin ireland interpreters designed high general purpose performance typically perform large number indirect branches executed instructions benchmarks 
branches consume half run time number configurations simulated 
evaluate accurate various existing proposed branch prediction schemes number interpreters mispredictions affect performance interpreters different interpreter implementation techniques perform various branch predictors 
suggest various ways hardware designers compiler writers interpreter writers improve performance interpreters 

advantages interpreters attractive ease implementation 
portability 
fast edit compile run cycle 
run time efficiency important secondary requirement interpretive language implementations 
romer studied performance interpreters mipsi java perl tcl 
identify performance issues common interpreters particularly striking results specific interpreters concluded performance interpreters improved software means specialized hardware 
study interpreters designed generalpurpose performance call interpreters efficient interpreters rest 
find perform exceptionally high number indirect branches higher proportion indirect branches benchmarks researchers indirect branch prediction 
may obvious interpreter writers necessarily hardware designers prominent interpreter performance characteristics misses point completely see section details 
partially supported enterprise ireland international collaboration scheme 
earlier shorter version appears euro par proceedings 
ertl gregg consequence high number indirect branches performance efficient interpreters highly dependent indirect branch prediction accuracy branch mispredict penalty magnitude performance impact probably surprises interpreter writers see speedup factors predictor predictor 
main contribution quantify effects indirect branches interpreters modern hardware affects different implementation techniques existing proposed indirect branch predictors interpreters 
important contribution counter impression readers may interpreters behave just specint benchmarks 
efficient interpreters 
may wonder expend effort speeding interpreters just write compiler native code 
main reason native code compiler requires significantly effort development maintenance particular support multiple platforms see section result native code compiler route language implementation runs platform misses usability features decent debugger takes noticeable time compile slow tracking developments language environment 
write compiler 
method addresses ease implementation retargeting issues acceptable interactivity quick non features run time code generation guaranteed tail call optimization required 
prepared pay costs native code compilation may care interpreter performance mixed mode jit compilers hotspot interpreter executions piece code interpreter produces profile data determining expend optimization effort 
faster interpreter longer wait native code compilation resulting compiling code compile time better optimization better profile information optimization 
hotspot system goes great lengths interpreter fast 
people argue efficiency important interpreters slow anyway 
attitude lead interpreter factor slower programs native code produced optimizing compiler slowdown efficient interpreters factor 
difference slow fast interpreter larger difference fast interpreter native code 
argument interpreted programs spend time libraries speeding interpretive engine provide speedup programs 
amount time spent libraries necessarily known start project prospect slowdown factor library cover significant amount computation performed simple operations daunting 
having efficient interpreter increases number applications library dominates run time 
consider application spend time libraries compiled optimizing native code compiler efficient interpreter slowdown factor non library code spend structure performance efficient interpreters time library slowdown optimized native code inefficient interpreter slowdown factor spend time library slowdown 
question may ask focus efficient interpreters 
look popular ones perl 
perl studied romer improved software means 
looking interpreters means applied 
perl community decides day interpreter efficiency important perl rewritten perl interpreter performance characteristics similar efficient interpreters looking useful version perl efficient interpreter 
native code compilers section compares interpreters native code compilers quantitatively speed implementation effort ocaml system candidate comparison contains native code compiler targets currently architectures fast interpreter 
look ocaml section 
compilers lines common code bytecode compiler additional lines native code compiler additional lines target independent code additional lines target 
addition native code needs lines target independent run time system code lines target specific run time system code target target os combination 
determining size interpreter specific run time system easy organized separately common run time system garbage collector bytecode interpreter lines 
interpreter works targets supported native code compiler additional ones target specific code 
target interpreter implementation significantly smaller native code implementation difference grows additional target architecture 
concerning execution speed ocaml faq caml inria fr ocaml speed html reports ocaml native code compiler average times faster ocaml interpreter 
concerning compilation speed mhz compiling line file tk ml takes cpu time bytecode compiler cpu time compiler bytecode compiler faster factor 
overview introduce interpreter implementation techniques section benchmarks basic performance characteristics particular high frequency indirect branches section introduce ways indirect branches fast section evaluate benchmarks cycle accurate simulator section 
suggest ways speed interpreters section 
discuss related section 
ertl gregg 
implementing efficient interpreters section discusses efficient interpreters implemented 
precise definition efficient interpreter fuzzy concept designed generalpurpose performance shows direct path specific implementation techniques 
want general purpose performance assume interpreted program spend large amounts time native code libraries 
prepare worst case interpreting program performing large numbers simple operations programs interpreters slowest relative native code programs require interpreter overhead amount useful 
avoid overhead parsing source program repeatedly efficient interpretive systems compile program intermediate representation interpreted design helps modularity 
minimize overhead interpreting intermediate representation efficient interpretive systems flat sequential layout operations contrast tree intermediate representations similar machine code intermediate representations called virtual machine vm codes 
efficient interpreters usually vm interpreter vm interpreters efficient 
designed vms tailored easy compilation source language fast interpretation real machines 
easy write fast compiler source language vm losing performance due interpretation overhead 
interpretation vm instruction consists accessing arguments instruction performing function instruction dispatching fetching decoding starting instruction 
dispatch common vm interpreters see section run time interpreter focuses dispatch 
direct threaded code efficient method dispatching vm instruction 
direct threaded code represents vm instruction address routine implements see fig 

vm instruction dispatch consists fetching vm instruction branching fetched incrementing instruction pointer 
unfortunately direct threading implemented ansi languages class labels guarantee tail call optimization 
fortunately widely available language class labels gnu version direct threading implemented portably see fig 

portability machines gcc concern easy switch direct threading ansi conforming methods macros conditional compilation 

romer virtual machine wider sense basically encompassing interpreters including string interpreters 

direct threaded code efficient method actual methods vm instruction dispatch indirect branch call branch address providing context branch prediction direct threaded code uses additional overhead 
interesting question tree conditional branches dispatch result faster dispatch indirect branch doubt vm instruction dispatch possible targets strong bias dispatch run conditional branches costs time correctly predicted guarantee fewer mispredictions indirect branches 
typedef void inst structure performance efficient interpreters void engine static inst program add 
inst ip program int sp goto ip dispatch vm inst 
add sp sp sp sp goto ip dispatch vm inst 
typedef enum add 
inst direct threaded code gnu labels values void engine static inst program add 
inst ip program int sp switch ip case add sp sp sp sp break 
instruction dispatch switch vm code vm instruction routines mul add add 
machine code mul dispatch instruction machine code add dispatch instruction ertl gregg lw get inst inst ptr 
addu advance instruction pointer execute instruction nop branch delay slot direct threaded code dispatch sequence mips assembly lw instruction pointer nop check upper bound bne addu branch delay slot sll multiply addu add switch table base lw nop nop 
switch target table word 
add nop switch dispatch assembly implementors restrict ansi usually giant switch approach fig 
vm instructions represented arbitrary integer tokens switch uses token select right routine 
show mips assembly code techniques 
methods perform indirect branch executed vm instruction interpreting programs simple vm instructions proportion executed indirect branches relatively high see section impact run time higher see section 
structure performance efficient interpreters execution time penalty switch method direct threading caused range check table lookup branch dispatch routine generated compilers see section processors higher indirect branch mispredict rate 

benchmarks section describes interpreters benchmarked gives numbers behaviour particular frequency indirect branches interpreters 
discusses perl xlisp representative efficient interpreters 
interpreters benchmarked gforth forth system uses virtual stack machine 
compiled indirect threaded code additional load instruction instruction load indirect branch 
workloads prims compiler little language bench gc conservative garbage collector 
ocaml objective caml bytecode interpreter implements virtual stack machine vm works tagged data associated overhead run time type checking ocaml uses tagged data support polymorphism garbage collection 
ran version direct threaded code switch version ocaml prepared just change configuration option 
workloads scanner generator ocaml compiler 
scheme interpreter switch uses virtual stack machine uses tagged data performs run time type checking 
scheme compiler workload instructions building scheme image 
yap prolog system uses interpreter wam virtual register machine uses tagged data performs run time type checking 
ocaml ran version direct threaded code version switch dispatch 
workloads boyer part theorem prover chat parser parser english 
perl spec benchmark 
interpreter uses linked list intermediate representation interprets 
spec train benchmark workload 
xlisp spec benchmark li 
xlisp interprets expressions list tree intermediate representation lisp data 
spec ref boyer program workload 

find benchmarks www tuwien ac anton interpreter arch 

compile gforth direct threaded code simplescalar 

instructions take bits 

lisp boyer related prolog boyer yap results probably comparable 
ertl gregg interpreter workload inst 
exec 
loads stores branches indirect branches inst ind gforth gforth prims ocaml ocaml switch ocaml ocaml switch scheme build yap boyer yap switch boyer yap chat yap switch chat perl xlisp boyer instruction class distribution benchmarks gforth ocaml scheme yap examples efficient interpreters believe interpreters efficient papers written indicate authors cared performance scheme performance important efficient interpreters fast system shares performance characteristics discussed efficient interpreters 
indication efficiency gforth ocaml bytecode interpreter fastest interpreters benchmarks computer language www org doug 
include perl xlisp comparison related spec benchmark suite indirect branch intensive benchmarks spec suite 
selected workloads non trivial size workloads interpreters order exercise significant portions interpreters avoid non representative aspect performance 
compiled interpreters simplescalar microprocessor simulator simulates mips architecture 
basic data behaviour benchmarks listed fig 

column inst 
exec 
contains number executed instructions simulation 
columns specify proportion loads stores branches control transfers indirect branches returns see absolute numbers indirect branches executed instructions indirect branch inverted indirect branch proportion column 
excluded returns indirect branch numbers interpreter dispatch easily accurately predicted return address stack 

may wonder absence interpreters 
reason don know efficient interpreter runs simplescalar 
structure performance efficient interpreters aspect data important extremely high proportion indirect branches efficient interpreters comparison benchmarks indirect branch prediction research perform indirect branches 
reason indirect branches vm instruction performs indirect branch uses threaded code switch dispatch 
vm instructions quite simple add top numbers stack implemented native instructions plus dispatch code 
complex vm instructions occur relatively rarely setup typically takes simple vm instructions complex operations split vm instructions allows optimizing special cases compiler simplifies interpreter similar cisc risc transition 
higher number native instructions vm instruction yap scheme explained dynamic typechecking required scheme prolog scheme uses switch dispatch yap vm register machine requires overhead instruction decoding operand access stack machine sophisticated compiler may generate fewer instructions 
scheme sacrificed efficiency goals 
issue seen nicely effect threaded code vs switch dispatch instruction count number indirect branches exactly cases total number instructions higher interpreters switch dispatch factor 
ocaml switch dispatch costs instructions threaded code yap difference instructions 
section shows differences affect execution time 
clearly visible perl xlisp share indirect branch characteristics efficient interpreters 

fast indirect branches branch instructions indirect branches potentially slow current cpus require flushing pipeline mispredicted 
unfortunately cpus predict indirect branches poorly 
look architectural microarchitectural ways predict indirect branches various vm interpreters 
special measures taken conditional branches indirect branches relatively expensive operations modern pipelined processors 
reason typically take effect reached execute stage stage pentium iii stage pentium pipeline result affects instruction fetch stage stage branch newly fetched instructions proceed pipeline cycles reaching execute stage 
resulting delay known nowadays misprediction penalty 
contrast result ordinary alu operation available execute stage usually needed instructions start execute stage resulting latency cycle alu instructions instructions 

note gforth requires load indirect branch uses direct threaded code resulting higher proportion indirect branches 
ertl gregg course problem attacked variety architectural microarchitectural methods 
efforts focussed conditional branches procedure returns indirect branches neglected today cpus sold way reduce cost indirect branches amd mips ultra sparc ii 
indirect branch prediction way avoid mispredict penalty correctly predict target branch execute instructions speculatively 
course prediction incorrect speculatively executed instructions canceled cpu incurs misprediction penalty 
profile guided prediction alpha architecture indirect branch target hints field jmp instruction specifies bits predicted branch target predict instruction cache 
compiler profile feedback predict indirect branches 
unfortunately compilers know don support way helps interpreters gcc arcs support computed gotos compaq compiler supports switch dispatch produces indirect branch limits prediction accuracy see section 
disadvantage prediction method branch decoded meaning correct prediction branch execution penalty cycles decode stage 
dynamic prediction dynamic branch prediction microarchitectural mechanism works architectural compiler software support software support help see section 
simplest dynamic indirect branch prediction mechanism branch target buffer btb caches target address branch uses address branch instruction key lookup 
improvement normal btb btb bit counters replaces btb entry twice halves mispredictions branch usually jumps just target exceptions 
kind btb introduced pentium sophisticated indirect branch prediction method available commercially available cpus 
best currently known indirect branch prediction mechanisms level predictors combine global history pattern indirect branch targets branch address looking target address table predictors proposed lzle studied variations predictors issue study probably trace driven execution driven simulator problem real target branch avail 
bit sufficient btb indirect branch prediction 
name corresponding structure conditional branch predictors uses bit saturating counters 
pentium bits entry entries conditional branch prediction 
structure performance efficient interpreters able long prediction immediately updating history pattern tables see section 
discuss effects various prediction mechanisms interpreters section 
mispredict penalty way reduce cost branches reduce misprediction penalty addition reducing number mispredictions 
approach delayed branches 
delayed branches fell favour architectures desktop server machines maximum benefit implementation dependent number delay slots break binary compatibility 
various cpus embedded systems delayed branches aggressively implementing interpreters 
flexible implementation dependent approach delayed branches split branches prepare branch instruction specifies branch target point branch takes effect specified explicitly 
power ppc hp ia architectures prepare branch instruction specifies branch register contain target address approaches possible 
example look power ppc architecture prepare branch instruction called actual control transfer instructions 
power implementation successors latency instructions cycles getting address branch unit start fetching decoding target actual control transfer takes place immediately 
delayed split branches processor fetch decode execute load instruction loads vm instruction address jump address take effect 
mean executing vm instruction takes long takes load get instruction fetch stage result stage processor 
problem reduced moving load previous vm instruction essentially software pipelining interpreter 
rename result register move load previous jump 
simple way move instruction prepare jump instructions powerpc ia kind move instruction extra instruction necessary move instruction fetched decoded executed jump take effect determining minimum vm instruction execution time fetch decode execute move execute indirect jump 
problem approaches suboptimal compiler support gcc schedule prepare branch instruction early 

pair blr uses branch register intended return addresses ppc predicts blr target return stack 

way duplicate interpreter perform modulo variable renaming quite complex especially threaded code 

evaluation ertl gregg section shows mispredict penalty indirect branches affects interpreters various branch prediction schemes help 
simulation setup added branch prediction methods simplescalar simulator ran interpreters prediction methods prediction processor just wait branch resolves 
profile guided predicts indirect branch jumps address frequent training run 
generally different interpreted program training run scheme gets low prediction accuracy 
btb predicts branch jumps target jumped time unlimited table size 
btb btb replaces prediction second unlimited table size 
level level predictors branch address history register containing target addresses key lookup table predicted targets counters 
bits address table unlimited size 
see btb level predictor target addresses history register 
predictor cycle accurate simulator processor know real target address instruction 
variants predictor level speculative level history register contains predicted targets 
history register updated speculatively predicted target instruction fetch predicted target occurs 
misprediction detected time history register stays roll back performed 
level level history register contains addresses note commit happen indirect branch predicted 
simplescalar vary mispredict penalty 
allows get idea effects various hardware techniques reducing misprediction penalty 
simplescalar simulates order processor short pipeline instruction fetch decode dispatch execute writeback commit 
indirect branch wait dispatch target address available proceeds execute writeback branch mispredicted fetches instructions correct address cycle instruction loading address performs writeback set mispredict penalty minimum usually called mispredict penalty cycles simplescalar calls cycle follow traditional usage note order execution raise real mispredict penalty higher mispredictions structure performance efficient interpreters prediction profile guided btb btb lev spec 
gforth prim switch switch yap boyer yap chat xlisp boyer gforth scheme build yap boyer sw yap chat sw perl mispredict rate various predictors interpreters reaching writeback stage delayed branch wait results instructions load providing target address 
set mispredict penalty higher corresponding number cycles elapse time branch execute time correct instructions fetched see emulating processor instruction fetch decode stages 
unlimited table size unrealistic hardware implementation think results interesting looking particular realistic configuration configuration produce confusing artifacts conflict misses occur configuration small code changes 
level predictors unlimited model quite close tuned realistic models large table sizes 
apart indirect branch predictor mispredict penalties default processor configuration simplescalar superscalar processor capable issuing instructions cycle usual additional restrictions cache ports load latency cache cycles 
conditional branch predictor configured little better default combined predictor consisting bimodal level adaptive predictor entries table history length level predictor 
increased size return address stack 
results prediction accuracy shows mispredict rates interpreters 
see different patterns indirect branch prediction accuracy cycles ind branch ertl gregg prediction profile guided btb btb lev spec 
gforth prim switch gforth switch yap boyer scheme build yap boyer sw yap chat yap chat sw xlisp boyer perl execution time various interpreters various branch prediction scheme mispredict penalty cycles cycle simplescalar terminology threaded code profile guided prediction produces mispredictions btb btb 
switch code profile guided prediction produces mispredictions 
btb btb produce mispredictions ocaml scheme yap 
li profile guided prediction btb btb perform quite mispredictions 
reason result dynamic indirect jumps li perform dynamic type resolution interpreter dispatch apparently boyer program deals mainly specific data type 
perl profile guided prediction btb btb produce mispredictions 
prediction accuracy level predictors relatively typically mispredictions interpreters 
reason difference accuracies threaded code switch code threaded code uses separate dispatch routine vm instruction allows profile guided prediction btb predict different target vm instruction 
separate dispatch routines predictor context predictions kind deep history 
contrast common dispatch jump predictors just predict thing irrespective coming leading worse performance 
profile guided predictor just predicts frequently vm instruction 
btb predicts executed instruction apparently prediction accurate register yap stack ocaml scheme interpreters 
effect execution time shows effect different prediction accuracies execution times assuming short misprediction penalty 
get better view details fig 
shows cycles ind branch structure performance efficient interpreters prediction profile guided btb btb lev spec 
gforth prim switch gforth switch yap boyer scheme build yap boyer sw yap chat yap chat sw execution time efficient interpreters various branch prediction scheme mispredict penalty cycles cycle simplescalar terminology cycles ind branch prediction profile guided btb btb lev spec 
gforth prim switch gforth switch yap boyer scheme build yap boyer sw yap chat yap chat sw execution time efficient interpreters various branch prediction scheme mispredict penalty cycles cycles simplescalar terminology data li perl different scale 
efficient interpreters nearly indirect branches perform vm instruction dispatch assume cycles indirect branch represent cycles vm instruction 
part difference prediction accuracy prediction level spec 
results execution time difference cycles cycles scheme build outlier cycles li boyer 
note differences larger pure branch prediction penalty indirect jump depend instructions resolved 
cycles ind branch ertl gregg predictor profile guided btb btb lev 
spec 
mispredict penalty execution time gforth varying penalties indirect branch predictors 
benchmarks show similar linear behaviour 
difference efficient interpreters efficient interpreters difference constitutes larger percentage execution time 
gforth level spec 
takes cycles indirect branch branch prediction takes cycles execution time factor gained branch prediction viewed differently indirect branch prediction benchmark spends time indirect branches 
contrast factor prediction level spec 
prominent li boyer perl 
longer realistic misprediction penalties fig 
effect mispredictions run time dramatic 
cycles misprediction penalty factor prediction level spec 
gforth time indirect branches 
varying mispredict penalty shows run time benchmarks varies mispredict penalty rises nearly linearly mispredict penalty 
benchmarks linear behaviour 
surprised originally expected string correct predictions sufficient fetch decode bandwidth interpreter dispatch get ahead rest vm instruction execution dispatch fewer dependences just instruction pointer update vm instruction overlap executing old vm instructions misprediction flatten curves low mispredict penalties fig 

overlap happen significant amounts looked traces experimented configurations resources confirm 
reason loads dispatch depend stores rest vm instruction execution particular stack spills stack vms result register writes register vms 
probably see somewhat different results processor speculatively execute loads stores unknown addresses 
structure performance efficient interpreters predictor cycles profile guided btb btb level spec 
speed difference threaded code switch dispatch various branch predictors nice thing linear behaviour analysing predicting behaviour easy halving number mispredictions kinds branches effect halving mispredict penalty including latencies unfinished instructions indirect branch depends 
starting current hardware btb style indirect branch predictors probably easier speed efficient interpreters adding level indirect branch predictor shortening mispredict penalty equivalent amount 
threaded code vs switch dispatch run time difference threaded code switch dispatch consists differences coming different mispredict rates differences due additional executed instructions 
shows difference threaded code switch dispatch simplescalar cycles mispredict penalty cycle simplescalar terminology 
difference larger profile guided btb btb predictor switch dispatch significantly mispredictions predictors 
difference smaller level predictor predictor switch dispatch threaded code similar mispredict rates predictor correct predictions allow hiding latencies switch code overlapping code 
short execution time threaded code vm instructions switch dispatch slower factor btb cycles mispredict penalty 
inefficient interpreters behaviour xlisp perl different interpreters 
xlisp low misprediction rate predictors 
examined code dynamically executed indirect branches choose operation execute switches type tags objects 
objects type switches quite predictable 
misprediction rates perl line interpreters fig 
shows improving prediction accuracy little effect perl 
indirect branches simply rare effect 
mispredictions ertl gregg level commit level spec 
history length level indirect branch predictor accuracy scheme build mispredictions level spec 
level commit history length level indirect branch predictor accuracy yap chat level predictors section diverge take closer look variations level indirect branch predictors 
note section deep wish indirect branch predictors main topic 
measured level speculative level predictors history lengths 
significant variations benchmarks think due differences interpreted programs interpreters 
show examples 
case predictors usually quite sufficient history length 
longer histories usually better explanation predictors train inner loops frequently executed procedures interpreted programs trip counts loops small longer histories overhead 
benchmarks speculative predictor better commit predictor 
suggests level speculative level useful components hybrid predictor 
structure performance efficient interpreters real world results section supports validity simulation results presenting data real machine 
produced data performance monitoring counters athlon 
data directly comparable results support simulation results 
differences athlon different architecture simplescalar counts different events particular count taken branches closest available approximation indirect branches newer version gforth supports optimization allows varying parameters 
gforth benchmark benchmark performs relatively direct branches counting taken branches approximation number indirect branches best benchmark 
measured taken branches mispredicted gforth optimization far indirect branch mispredict rate see btb simplescalar athlon uses btb 
activating superinstruction optimization see section reduces number executed real machine instructions factor number taken branches factor number taken branch mispredictions see execution time reduction factor higher reduction executed instructions taken branches 
indicates number mispredictions important execution time benchmark number executed instructions 
gforth superinstructions performs misprediction cycles 
athlon branch mispredict penalty cycles easy see benchmark spends half time mispredictions time waiting target address 

advice hardware designers useful hardware support feature efficient interpreters indirect branch prediction 
level predictors interpreters applications involving indirect branches indirect calls object oriented programs 
interpreters measured level predictor achieved speedup btb factor mispredict penalty cycles factor mispredict penalty cycles 
just having btb helps threaded code quite bit appropriate changes interpreter prediction accuracy 
compiler writers compiler writers improve performance switch interpreters possibly software replacing single shared switch dispatch code fragment copy dispatch fragment vm instruction 
achieved eliminating unconditional branches back switch code tail duplication 
optimization increase prediction accuracy level see threaded code 
ertl gregg estimate optimization provide speedup factor processor btb predictor 
way compiler help interpreter performance supporting gnu labels values extension allows implement threaded code 
threaded code provide speedup factor switch dispatch shared dispatch fragment see section 
alternatively guaranteeing tail call optimization way support threaded code 
supporting indirect branch target hints architectures support preferably profile feedback help little factor 
interpreter writers number techniques writing efficient interpreters described literature see section 
section focusses techniques reducing time spent indirect branches effect 
slow adoption past expect decade pass sophisticated indirect branch prediction hardware available cpus interpreter writers cater cpus possibly indirect branch prediction near 
interpreter writer support threaded code see section speedup factor switch interpreter maintain maximum portability switch ansi version interpreter available conditional compilation 
looked improve interpreters improved btb prediction accuracy 
replicating code indirect branch vm instructions different replicas different places reduce mispredictions significantly similar effect seen separate dispatch branch vm instruction 
particular separate replica instance vm instruction program mispredictions indirect branches mispredictions btb conflicts resulting prediction accuracy speedups factors celeron athlon 
combining common sequences vm instructions vm superinstructions helps introducing static indirect branches reducing number dynamically executed indirect branches effect helps processors :10.1.1.16.7676:10.1.1.23.8829
combination replication superinstructions produces speedups factor celeron 
ways implementing techniques statically compiling set replicas superinstructions interpreter dynamically copying code static copy interpreter 
dynamic methods adapt program hand produce better btb prediction accuracies processors celeron athlon better speedups 
somewhat easier implement require target specific code mainly flushing cache memory 
problems structure performance efficient interpreters acceptable application recommend dynamic superinstructions dynamic replication 

related discussed study romer section 
important difference interpreters studied representative efficient interpreters java uses vm efficient needs average native instructions fetch decode contrast native instructions threaded code dispatch hanoi native instructions rest instruction vm similar gforth ocaml vm need instructions vm instruction total des benchmark java times slower branch mispredictions took cycles benchmarks interpreters measured 
contrast studies interpreters written high performance performance improvements require significant increases complexity 
branch misprediction major component run time interpreters studied 
basis level indirect branch predictors lzle 
start level predictor explore happens add restrictions predictor implementable hardware 
major difference theirs efficient interpreters benchmarks higher indirect branch frequencies vs benchmarks object oriented programs particularly higher indirect branch frequencies typically potential targets indirect branch 
limited predictors exploring predictors primary goal explored issue study fact correct result available long prediction deal 
improvement multi stage cascaded prediction reduces size required tables 
promising approach takes advantage predictors data compression techniques predict target indirect branches 
authors demonstrate indirect branches accurately predicted classifying groups 
earlier approach level indirect branch prediction history conditional branch outcomes predict indirect branches 
results better btb schemes accurate 
accuracy profile guided conditional branch prediction improved code replication 
similarly replicating dispatch code improves performance profile guided indirect branch prediction btb performance providing context 
large body exists conditional branch prediction 
important level adaptive predictor invented independently time yeh patt pan 
important discovery link branch 
mipsi emulates real machine mips directly 
performance improved translation vm application tradeoff complexity performance favourable vm approach programming language interpreter 
ertl gregg prediction predictors data compression established theoretical basis branch prediction 
give existing direct branch prediction schemes 
knowledge interpreters folklore 
discussions usenet newsgroup comp compilers contain folk wisdom personal experience reports 
probably complete current treatment interpreters 
contains extensive bibliography 
book contains articles interpreter efficiency 
published literature interpreters concentrates decoding speed semantic content vm design time space tradeoffs 
papers interpreters discussing issues combining vm instructions software pipelining interpreters stack caching improving btb prediction accuracy various optimizations 

efficient interpreters execute large number indirect branches benchmarks indirect branch prediction resulting mispredictions take time processor short pipeline longer pipeline 
commercially available branch prediction mechanisms perform badly accuracy interpreter uses single shared dispatch routine vm instructions switch dispatch compilers 
copy dispatch routine vm instruction threaded code branch predictors perform somewhat better accuracy accuracy profile guided prediction 
level indirect branch predictors perform quite usually accuracy implemented widely available cpus 
interpreters threaded code twice fast interpreters switch dispatch switch dispatch executes native instructions prediction accuracy worse 
ways increase performance interpreters replicating vm instructions produces better btb prediction accuracy combining sequences vm instructions superinstructions reduces number btb mispredictions number indirect branches 
techniques combined providing speedups processors pentium iii athlon pentium relatives 
architectural mechanisms profile guided branch prediction prepare branch instructions help theory tend suffer lack compiler support practice particular gcc 
gcc compiler choice writing efficient interpreters labels values extension possible threaded code 
santos costa great help getting yap run simplescalar 
referees asplos cc euro par provided helpful comments earlier versions 
structure performance efficient interpreters romer lee voelker wolman wong 
baer bershad levy structure performance interpreters architectural support programming languages operating systems asplos vii pp 

ertl gregg behaviour efficient virtual machine interpreters modern architectures euro par pp 
springer lncs 
van de code compression system pipelined interpreters software practice experience vol 
pp 
sept 
bell threaded code communications acm vol 
pp 

ertl portable forth engine conference proceedings mari zn 
indirect threaded code communications acm vol 
pp 
june 
leroy zinc experiment economical implementation ml language technical report inria 
kelsey rees tractable scheme implementation lisp symbolic computation vol 
pp 

santos costa optimising bytecode emulation prolog lncs proceedings ppdp pp 
springer verlag september 
lzle accurate indirect branch prediction proceedings th annual international symposium computer architecture isca pp 

burger austin simplescalar tool set version technical report cs tr university wisconsin madison june 
das harmon branches speculative execution computer architecture morris ed vol 
australian computer science communications perth pp 
springer 

chang patt hybrid branch predictors improve branch prediction accuracy presence context switches rd annual international symposium computer architecture pp 

ertl gregg optimizing indirect branch prediction accuracy virtual machine interpreters sigplan conference programming language design implementation 
ertl gregg ertl stack caching interpreters sigplan conference programming language design implementation pp 

riccardi optimizing direct threaded code selective inlining sigplan conference programming language design implementation pp 

ertl gregg krall vmgen generator efficient virtual machine interpreters software practice experience vol 
pp 

lzle cascaded predictor economical adaptive branch target prediction proceedings st annual acm ieee international symposium microarchitecture micro pp 

lzle multi stage cascaded prediction europar conference proceedings vol 
lncs pp 
springer 
predicting indirect branches data compression proceedings st annual acm ieee international symposium microarchitecture micro pp 

indirect branch prediction data compression techniques journal instruction level parallelism dec 
improving accuracy indirect branch prediction branch classification workshop interaction compilers computer architectures interact held conjunction asplos viii 

chang hao patt target prediction indirect jumps th annual international symposium computer architecture pp 

krall improving semi static branch prediction code replication conference programming language design implementation vol 
sigplan orlando pp 
acm 
young smith improving accuracy static branch prediction branch correlation architectural support programming languages operating systems asplos vi pp 


yeh patt level adaptive training branch prediction proceedings th annual international symposium microarchitecture albuquerque new mexico pp 
acm ieee computer society tc micro nov 

pan improving accuracy dynamic branch prediction branch correlation proceedings th international conference architectural support programming languages operating system asplos pp 

structure performance efficient interpreters 
chen mudge analysis branch prediction data compression architectural support programming languages operating systems asplos vii pp 

branch effect reduction techniques ieee computer vol 
pp 
may 
van interpretation instruction path 
mit press 
krasner ed smalltalk bits history words advice 
addison wesley 
klint interpretation techniques software practice experience vol 
pp 

pittman level hybrid interpreter native code execution combined spacetime efficiency symposium interpreters interpretive techniques sigplan pp 

proebsting optimizing ansi interpreter superoperators principles programming languages popl pp 


