supporting cooperative caching ad hoc networks researches ad hoc networks focus routing done data access 
common technique improve performance data access caching 
cooperative caching allows sharing coordination cached data multiple nodes explore potential caching techniques 
due mobility resource constraints ad hoc networks cooperative caching techniques designed wired network may applicable ad hoc networks 
design evaluate cooperative caching techniques efficiently support data access ad hoc networks 
propose schemes cachedata caches data cachepath caches data path 
analyzing performance schemes propose hybrid approach hybridcache improve performance advantage cachedata cachepath avoiding weaknesses 
simulation results show proposed schemes significantly reduce query delay message complexity compared caching schemes 
wireless ad hoc networks received considerable attention due potential applications battlefield disaster recovery outdoor assemblies 
ad hoc networks ideal situations installing infrastructure possible infrastructure expensive vulnerable 
due lack infrastructure support node network acts router forwarding data packets nodes 
previous researches ad hoc networks focus development dynamic routing protocols efficiently find routes communicating nodes :10.1.1.113.555
routing important issue ad hoc networks issues information data access important ultimate goal ad hoc networks provide information access mobile nodes 
examples motivate research data access ad hoc networks 
example battlefield ad hoc network may consist commanding officers group soldiers officers 
officer relatively powerful data center soldiers need access data centers get various data detailed geographic information enemy information new commands 
neighboring supported part national science foundation career ccr itr 
yin cao department computer science engineering pennsylvania state university university park pa mail yin cse psu edu soldiers tend similar missions share common interests 
soldier accessed data item data center quite possible nearby soldiers access data time 
saves large amount battery power bandwidth time accesses data served nearby soldier data faraway data center 
example mobile infostation systems deployed provide information mobile users 
example deployed tourist information center may provide maps pictures history attractive sites 
infostation deployed restaurant may provide menus 
due limited radio range infostation cover limited geographical area 
mobile user say jane moves infostation range able access data provided infostation 
mobile users able form ad hoc network access information 
environment jane request forwarded infostation mobile users nodes path cached requested data 
node send data back jane save time bandwidth 
examples see mobile nodes able request forwarding routers bandwidth power saved delay reduced 
cooperative caching allows sharing coordination cached data multiple nodes widely improve web performance wired networks 
protocols classified message directory router 
wessels claffy introduced internet cache protocol icp standardized widely 
message protocol icp supports communication caching proxies query response dialog 
directory protocols cache digests summary cache enable caching proxies exchange information cached contents :10.1.1.153.5656
web cache coordination protocol router protocol transparently distributes requests cache array 
protocols usually assume fixed network topology require high computation communication overhead 
ad hoc network network topology changes frequently 
mobile nodes resource battery cpu wireless ieee ieee infocom channel constraints afford high computation communication overhead 
existing techniques designed wired networks may applied directly ad hoc networks 
design evaluate cooperative caching techniques efficiently support data access ad hoc networks 
specifically propose schemes cachepath cachedata hybridcache 
cachedata intermediate nodes cache data serve requests fetching data data center 
cachepath mobile nodes cache data path redirect requests nearby node data faraway data center 
improve performance design hybrid approach hybridcache improve performance advantage cachedata cachepath avoiding weaknesses 
simulation results show proposed schemes significantly improve performance terms query delay message complexity compared caching schemes 
rest organized follows 
section ii cachedata scheme cachepath scheme 
section iii presents hybridcache scheme 
performance proposed schemes evaluated section iv 
section concludes 
ii 
proposed basic cooperative cache schemes section propose basic cooperative cache schemes analyze performance 
system model fig 

ad hoc network fig 
shows part ad hoc network 
nodes ad hoc network may wireless interfaces connect wireless infrastructure wireless lan cellular networks 
suppose node data source center contains database items dn 
note may node connecting wired network database 
ad hoc networks data request forwarded hop hop reaches data center data center sends requested data back 
various routing algorithms designed route messages ad hoc networks 
reduce bandwidth consumption query delay number hops data center requester small possible 
routing protocols achieve goal limitation achieve 
propose basic cooperative caching schemes cachedata cachepath 
cache data cachedata cachedata node caches passing data item di locally finds di popular requests di free cache space 
example fig 
request di knows di popular caches locally 
requests orn served directly 
cachedata needs extra space save data 
suppose data center receives requests di forwarded 
nodes path may think di popular item cached 
wastes large amount cache space cache di 
avoid conservative rule followed node cache data requests data node 
previous example requests received turn 
new rule cache di 
requests received different nodes cache data 
requests come cache data cache 
certainly receives requests di may cache di 
note di cached requesting node serve query 
cache data path cachepath idea cachepath explained fig 

suppose node requested data item di 
forwards data di back knows copy di 
requests di knows data center hops away hop away 
forwards request 
note routing algorithms aodv dsr provide hop count information source destination 
caching data path data item bandwidth query delay reduced data obtained number hops 
recording map data items caching nodes increases routing overhead 
propose optimization techniques 
cachepath node need record path information passing data 
example di flows destination node path need cache path information di closer data center caching node 
node records data path closer defined caching node data center 
saving path information node need save node information path 
save destination node information path current ieee ieee infocom router destination underlying routing algorithm 
due mobility node caches data may move 
cached data may replaced due cache size limitation 
result node modified route reroute request original data center finds problem 
cached path may reliable may adversely increase overhead 
deal issue node ni caches data path caching node say nj close 
closeness defined function distance data center distance caching node route stability data update rate 
intuitively network relatively stable data update rate low distance caching node denoted lower distance data center denoted routing node cache data path 
note important factor 
small cached path broken data unavailable caching node problem quickly detected reduce overhead 
certainly smaller 
number hops cached path save denoted greater system tuning threshold called th cachepath 
maintain cache consistency cache consistency issue cachedata cachepath 
done maintaining strong cache consistency single hop wireless environment 
due bandwidth power constraints ad hoc networks expensive maintain strong cache consistency weak consistency model attractive 
simple weak consistency model time live ttl mechanism node considers cached copy todate ttl expired removes map routing table removes cached data ttl expires 
result requests data forwarded data center 
due ttl expiration cached data may invalidated 
usually invalid data removed cache 
invalid data may useful 
data cached node indicates node interested data 
node forwarding data item finds invalid copy data cache caches data 
save space cached data item expires removed cache id kept invalid state indication node interest 
certainly interest node may change expired data kept cache forever 
design expired data item refreshed duration original ttl time set data center removed cache 
performance analysis section analyze performance proposed schemes 
assumptions simplify analysis get 
simulation results section iv match analytical results verify assumptions reasonable 
performance measured number hops request expected travel reaches data 
reducing hop count reduce query delay bandwidth power consumption fewer nodes involved query process 
reducing hop count reduce workload data center requests served caches handled data center 
notations analysis follows average number hops mobile node data center 
probability data item cache cachedata scheme 
pdp probability data item cache cachepath scheme 
ppp probability path cache cachepath scheme 
pi probability cached item usable 
may caused ttl expiration broken paths node movement 
ld cachedata average length path request reach node original server valid copy data 
requester valid copy data ld easy presentation 
lp cachepath average length path request reach node original server valid copy data 
lp requester valid copy data 
notations obtain expected number hops request takes node ni node data 
pi ld 
pd pi equation approximation ld practice may different different nodes 
equation helps understand effects important factors believe approximation reasonable 
note ld bounded small line equation provides adequate approximation 
calculate lp cases need considered requested data item local cache 
path local cache indicates ni caches requested data 
sub cases possible valid data item ni 
ieee ieee infocom data item ni usable broken path ttl expiration 
data path local cache 
pdp pi 
probabilities cases ppp pi ppp respectively 
number hops needed request get data case lp case case 
case request need travel lp reach ni 
redirected data center away 
data item sent back requester hops 
average number hops needed request lp lp 
lp ppp pi lp pi lp ppp lp lp pp pp ppp pi ppp pp ppp pi ppp equation ppp specific cachepath 
needs fixed comparing ld lp 
lp pdp pi ppp lp pdp pi pi pi pdp pi pi ppp gives performance upper bound cachepath 
equations complex contain parameters 
fix parameters get better understanding relation ld lp 
suppose pi data items cache valid ld lp pdp cachepath needs cache space store extra data pdp cache size big means lp ld 
suppose pi cache size big pdp 
obtain ld lp ld lp dd dd note dd dd note cached path contains final destination node id explained section ii 
assume size data item larger size data id 
combining inequalities yields ld lp equations get schemes reduce average number hops requester node requested data 
example pi number hops reduced cache hit ratio greater cached data path available schemes fall back traditional caching scheme requests sent directly data center 
cache size small cachepath better cachedata cache size large cachedata better 
data items updated slowly mobile nodes move slowly pi small cachepath approach cases cachedata performs better 
iii 
hybrid caching scheme hybridcache performance analysis showed cachepath cachedata significantly improve system performance 
cachepath performs better situations small cache size low data update rate cachedata performs better situations 
improve performance propose hybrid scheme hybridcache take advantage cachedata cachepath avoiding weaknesses 
specifically node forwards data item caches data path criteria 
criteria include data item size si ttl time 
data item di heuristics decide cache data path si small cachedata adopted data item needs small part cache cachepath adopted save cache space 
threshold value data size denoted ts 
small cachepath choice data item may invalid soon 
cachepath may result chasing wrong path re sending query data center 
cachedata situation 
large cachepath adopted 
threshold value ttl system tuning parameter denoted 
large cachepath choice save large number hops cachedata adopted improve performance empty space cache 
adopt threshold value th cachepath threshold value 
fig 
shows algorithm applies heuristics hybridcache 
design caching data path needs save node id cache 
overhead small 
ieee ieee infocom data item di arrives di requested data current node cache data item di return data passing old version di cache update cached copy si ts invalid copy cache cached path di cache data item di th cache path di cache replacement necessary free space invalid data items cache remove invalid data item free space need space remove valid data item request data item di arrives valid copy cache send di requester valid path di cache forward request caching node forward request data center fig 

hybrid caching scheme hybridcache data item di needs cached cachedata path di cached 
cache replacement algorithm decides remove di removes cached data keeping path di 
point view cachedata degrades cachepath di 
similarly cachepath upgraded cachedata di passes 
comparing schemes effectively disseminate data ad hoc networks data replication caching 
data replication schemes ad hoc networks studied 
schemes may effective due reasons frequent node movement powering failure hard find stable nodes host replicated data second cost initial distribution replicated data cost redistributing data deal node movement failure high 
data replication caching rely finding stable hosts overhead 
traditional caching schemes referred simplecache query node caches received data 
query request cached data comes cache expires node uses cached data serve query 
case cache get data data center 
utilize caches neighbor nodes ds architecture users cache data share neighbors experiencing intermittent connectivity internet 
focus ds single hop environment multi hop 
result user broadcasts request neighbors see data served caches 
cooperative caching scheme designed specifically accessing multimedia objects ad hoc networks proposed 
query comes scheme relies flooding find nearest node requested object 
refer approach scheme 
flooding reduce query delay request may served nearby node data center faraway 
multimedia applications strict delay requirements 
benefit flooding multiple nodes contain requested data 
data size large link node fails requester switch nodes get rest requested data 
flooding incurs significant message overhead 
reduce overhead flooding limited nodes hops requester number hops requester data center overhead high 
wireless network nodes uniformly distributed average nodes hops range mobile node 
messages needed find data item method 
message broadcast network neighbors receive 
mobile node able identify drop duplicated messages node needs broadcast messages ensure full coverage 
node neighbors average total number messages needs processed message complexity constant factor may high especially network density high 
hybridcache scheme proposed flooding 
query delay may higher cases data cached nearby nodes route data center 
ad hoc networks may choice due high message overhead 
cooperative caching mobile nodes need cache data routing 
may involve cross layer optimization may increase processing overhead 
processing delay low compared communication delay 
ad hoc networks specific applications cross layer optimization reduce processing overhead 
considering performance improvement cooperative cache justified 
iv 
performance evaluation performance evaluation includes parts 
part section iv verify analytical results cache data cachepath compare simplecache hybridcache terms query delay 
second part section iv compares hybridcache simplecache terms query delay message complexity 
ieee ieee infocom simulation model simulation ns cmu wireless extension 
simulation aodv dsdv tested underlying routing algorithm :10.1.1.113.555
schemes rely specific routing protocols results aodv dsdv similar 
save space results aodv shown 
node density changed choosing number nodes fixed area 
assume wireless bandwidth mb radio range 
node movement model model group nodes moving rectangle area similar model 
moving pattern follows random way point movement model 
initially nodes placed randomly area 
node selects random destination moves destination speed selected randomly vmax 
node reaches destination pauses period time repeats movement pattern 
vmax values studied simulation 
client query model client query model similar previous studies 
node generates single stream read queries 
query generate time follows exponential distribution mean value 
query sent node generate new query query served 
access pattern zipf distribution frequently model non uniform distribution :10.1.1.12.2253
zipf distribution access probability ith data item represented follows 
pai 
follows strict zipf distribution 
follows uniform distribution 
larger results skewed access distribution 
choose studies real web traces 
access pattern mobile nodes nodes location tend access similar data local points interests 
simulate kind access pattern biased zipf access pattern simulation 
pattern simulation area divided axis axis grids 
grids named grid 
columnwise fashion 
clients grid follow zipf pattern nodes different grids different offset values 
example generated query access data id original zipf access pattern grid new id id mod mod database size 
access pattern sure nodes neighboring grids similar access pattern 
server model data servers server server placed opposite corners rectangle area 
data items server side server maintains half data 
data items ids saved server rests server 
data size uniformly distributed smin smax 
data updated server 
servers serve requests fcfs service basis 
server sends data item mobile node sends ttl tag data 
ttl value set exponentially mean value 
ttl expires node get new version data server nodes serving query 
table parameter simulation parameters default value range database size items smin kb smax kb number nodes vmax bandwidth mb ttl secs pause time secs client cache size kb mean query generate time secs th ts smin smax secs system parameters listed table second column lists default values parameters 
simulation may change parameters study impacts 
ranges parameters listed third column 
workload parameter mean ttl time mean query generate time mean value measured data obtained collecting large number samples confidence interval reasonably small 
cases confidence interval measured data sample mean 
simulation results hybridcache average delay seconds cachepath threshold th value fig 

fine tuning cachepath ieee ieee infocom average delay seconds hybridcache threshold size smin smax threshold ts experiments run different workloads system settings 
performance analysis designed compare effects different system parameters cache size ttl performance simplecache cachedata cachepath hybridcache 
schemes lru algorithm cache replacement 
effect cache replacement left 
fine tuning cachepath stated section ii performance cachepath affected threshold value th path cached value greater th 
small th means paths cached caching valuable paths may increase delay cached paths reliable 
large th means valuable paths cached 
th large paths cached high threshold 
shown fig 
th achieves balance rest simulations 
fine tuning hybridcache hybridcache data item size smaller ts cached cachedata 
ts small hybridcache fails identify small important data items large hybridcache caches data cachedata 
find optimal value ts measure query delay function ts 
asts related data size fig 
relative value ts smin smax give clearer idea threshold value 
shown fig 
threshold value increases query delay drops sharply data cached 
threshold value keeps increasing passing data cached cache space save accessed data 
result important data may replaced delay increases 
find threshold value gives best performance 
fig 
shows effect average query delay 
lowest query delay achieved seconds 
compared fig 
performance difference different significant 
average delay seconds fig 

fine tune hybridcache hybridcache threshold seconds threshold database studied heterogeneous data size 
data size varies kb kb 
data size important factor caching effect obvious 
effects cache size fig 
shows impacts cache size cache hit ratio average query delay 
cache hits divided categories local data hit means requested data item local cache remote data hit means requested data item intermediate node request forwarded network path hit means path request valid data item destination node path 
remote data hit path hit considered remote cache hit data retrieved remote nodes 
fig 
see local hit ratio simplecache lowest 
cache size small cachedata performs similar simplecache small cache size limits aggressive caching cachedata 
cache size large cachedata cache data nodes 
data locally local data hit ratio increases 
cachepath cache data nodes cached data refreshed data passing 
local data hit ratio slightly higher simplecache 
hybridcache prefers small data items caching data nodes 
accommodate data achieve high local data hit ratio 
cachedata cachepath similar local data hit ratio cases cachedata higher remote data hit ratio caches data nodes 
especially cache size large data cached cachedata remote data hit ratio significantly higher cachepath 
hybridcache high remote data hit ratio due similar reason high local data hit ratio 
path hit considered hybridcache highest cache hit ratio cases 
worth noticing cachepath hybridcache ieee ieee infocom cache hit ratio local data hit remote data hit path hit hybridcache cachepath cachedata simplecache hybridcache cachepath cachedata simplecache hybridcache cachepath cachedata simplecache hybridcache cachepath cachedata simplecache hybridcache cachepath cachedata simplecache hybridcache cachepath cachedata simplecache average delay seconds cache size kb reach best performance cache size kb 
demonstrates low cache space requirement 
particularly shows strength hybridcache provides best performance time 
high cache hit ratio proposed schemes perform better simplecache see fig 

comparing cachepath cachedata cache size small cachepath lower query delay path hit helps reduce average hop count 
cache size greater kb schemes similar total cache hit ratio cachedata higher local data hit ratio remote data hit ratio 
hop count local data hit average hop count remote data hit lower path hit cachedata achieves low query delay 
agrees performance comparisons cachepath cachedata section ii 
comparing proposed schemes see hybridcache performs better cachedata cachepath hybridcache applies different schemes cachedata cachepath different data items advantages cachedata cachepath 
result high local data hit ratio remote data hit ratio cache hit ratio hybridcache achieves best performance compared schemes 
effects query generate time fig 
shows average query delay function 
mobility vmax high mobility vmax settings studied 
notice trends similar cachepath 
cases cachepath performs worse simplecache 
due fact high node mobility causes broken paths affects performance cachepath 
high mobility setting cachedata performs better hybridcache performs best cases 
simplecache cachepath cachedata hybridcache cache hit ratio cache size kb query delay fig 

system performances function cache size small queries generated system workload high 
result average query delay high 
increases queries generated average query delay drops 
keeps increasing average query delay drops slowly increases slightly 
reason query generating speed low number cached data small cached data usable ttl expired queries generated 
fig 
verifies trend 
heavy system workload small hybrid cache reduce query delay compared cachedata cachepath 
system workload extremely light difference different schemes large 
extreme light workload cache hit ratio low 
queries served remote data center different schemes perform similarly 
find query generating speed increases decreases delay hybridcache increase fast schemes 
demonstrates hybridcache sensitive workload increases handle heavier workload 
effects ttl fig 
shows average query delay ttl varies seconds seconds 
ttl determines data update rate 
higher update rate smaller ttl cached data invalidated average query delay higher 
ttl small sec schemes perform similarly data cache invalid cache hit ratio low 
simplecache allow nodes cooperate nodes average query delay drop fast schemes ttl increases 
delay schemes drops ieee ieee infocom average delay seconds simplecache cachepath cachedata hybridcache mean query generate time seconds mean query generate time seconds vmax vmax fig 

average query delay function mean query generate time faster ttl increases nodes cooperate maximize benefit low update rate 
average delay seconds simplecache cachepath cachedata hybridcache mean ttl time seconds fig 

average query delay function ttl comparing cachepath cachedata cachedata performs better ttl small cachepath performs better ttl big 
result agrees performance analysis 
hybridcache reduces query delay 
effects node density fig 
shows average query delay function number nodes system 
node density increases delay schemes increases nodes compete limited bandwidth 
delay schemes increases slower simplecache 
explained fact data shared number nodes increases schemes helps reduce query delay 
total number nodes small hybridcache performs similar cachedata cachepath 
average delay seconds simplecache cachepath cachedata hybridcache number nodes increases hybridcache performs better schemes 
indicates hybridcache scales number nodes 
average delay seconds simplecache cachepath cachedata hybridcache number nodes fig 

average query delay different node density simulation results comparisons subsection compare performance hybridcache scheme simplecache scheme scheme terms query delay message complexity 
commonly message complexity metric total number messages injected network query process 
broadcast message processed received re broadcasted dropped node received number messages processed node message complexity metric reflect efforts battery power cpu time mobile node deal messages 
fig 
shows system performances cache size ieee ieee infocom average delay messages process node data replies query cache size kb query delay simplecache hybridcache cache size kb message overhead simplecache hybridcache simplecache hybridcache cache size kb reply messages query fig 

performance function cache size varies 
fig 
shows query delay decreases cache size increases 
cache size increases kb mobile nodes cache size query delay drop significantly 
simplecache scheme outperformed cooperative caching schemes different cache size settings 
demonstrates mobile nodes benefit sharing data 
comparing hybridcache see hybridcache perform terms query delay 
fig 
shows hybrid cache incurs message overhead 
message overhead hybridcache simplecache 
reason hybridcache gets data nearby nodes faraway data center possible 
data requests replies need travel number hops mobile nodes need process number messages 
cache size increases cache hit ratio hybridcache increases message overhead decreases 
uses flooding find requested data incurs higher message overhead compared simplecache hybridcache 
request sent flooding multiple copies data replies may returned requester different nodes requested data 
simplecache hybridcache happen request sent query case local cache fig 
shows copies data replies returned query 
number duplicated data replies increases slightly cache size increases data cached nodes 
simulation data size relatively small kb kb duplicated messages affect performance significantly 
environments multimedia accessing transmitting duplicated data messages may waste power bandwidth 
solution sending data requester receiving request mobile nodes data send back acknowledgment 
requester send unicast request nearest node get data 
drawback approach query delay significantly increased 
designed evaluated cooperative caching techniques efficiently support data access ad hoc networks 
specifically proposed schemes cachepath cachedata hybridcache 
cachedata intermediate nodes cache data serve requests fetching data data center 
cachepath mobile nodes cache data path redirect requests nearby node data faraway data center 
hybridcache takes advantage cachedata cachepath avoiding weaknesses 
simulation results showed proposed schemes significantly reduce query delay compared simplecache ieee ieee infocom significantly reduce message complexity compared 
das perkins royer performance comparison demand routing protocols ad hoc networks ieee infocom pp 

johnson maltz dynamic source routing ad hoc wireless network mobile computing pp 

perkins bhagwat highly dynamic destination sequenced distance vector routing dsdv mobile computers acm sig comm pp :10.1.1.113.555

wessels claffy icp squid web cache ieee journal selected areas communication pp 

wessels cache digests computer networks isdn systems vol 
pp 

fan cao almeida broder summary cache scalable wide area web cache sharing protocol acm sigcomm pp :10.1.1.153.5656

foster wilson web cache coordination protocol ietf internet draft 
www ietf org internet drafts draft wilson txt 
perkins belding royer ad hoc demand distance vector aodv routing ietf internet draft draft txt oct 
cao proactive power aware cache management mobile computing systems ieee transactions computer vol 
pp 
june 
cao scalable low latency cache invalidation strategy mobile environments ieee transactions knowledge data engineering vol 
september october preliminary version appeared acm mobicom 
hara effective replica allocation ad hoc networks improving data accessibility ieee infocom 
schulzrinne effects power conservation wireless coverage cooperation data dissemination mobile devices acm mobihoc oct 
lau kumar venkatesh cooperative cache architecture supporting caching multimedia objects manets fifth international workshop wireless mobile multimedia 
ns notes documentation www isi edu nsnam ns 
xu heidemann estrin geography informed energy conservation ad hoc routing acm mobicom pp 
july 
broch maltz johnson hu jetcheva performance comparison multi hop wireless ad hoc network routing protocols acm mobicom pp 
october 
yin cao cai generalized target driven cache replacement policy mobile environments international symposium applications internet jan 
zipf human behavior principle effort addison wesley 
breslau cao fan phillips shenker web caching zipf distributions evidence implications ieee infocom 
ieee ieee infocom 
