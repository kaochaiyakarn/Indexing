scaling accuracy naive bayes classifiers decision tree hybrid ron kohavi data mining visualization silicon graphics shoreline blvd mountain view ca ronnyk sgi com naive bayes induction algorithms previously shown surprisingly accurate classification tasks conditional independence assumption violated 
studies done small databases 
show larger databases accuracy naive bayes scale decision trees 
propose new algorithm nbtree induces hybrid decision tree classifiers naivebayes classifiers decision tree nodes contain univariate splits regular decision trees leaves contain naive bayesian classifiers 
approach retains interpretability naive bayes decision trees resulting classifiers frequently outperform constituents especially larger databases tested 
seeing requires wide angle lens requires multiplicity lenses hamel data mining tasks require classification data classes 
example loan applications classified approve classes 
classifier provides function maps classifies data item instance predefined classes fayyad piatetsky shapiro smyth 
automatic induction classifiers data provides classifier map new instances classes may provide human comprehensible characterization classes 
cases interpretability ability understand output induction algorithm crucial step design analysis cycle 
classifiers naturally easier interpret example decision trees quinlan easy visualize neural networks harder 
naive bayes classifiers langley iba thompson generally easy understand induction classifiers extremely fast requiring single pass data attributes discrete 
naive bayes classifiers simple easy understand 
kononenko wrote physicians induced classifiers easy understand log probabilities evidence adds favor different classes 
shows visualization naive bayes classifier fisher iris data set task determine type iris attributes 
bar represents evidence class attribute value 
users immediately see values petal width petal length excellent determiners middle range adds little evidence favor class 
naive bayesian classifiers robust irrelevant attributes classification takes account evidence attributes final prediction property useful cases main effect 
downside naivebayes classifiers require making strong independence assumptions violated achievable accuracy may asymptote early improve database size increases 
decision tree classifiers fast comprehensible current induction methods recursive partitioning suffer fragmentation problem split data split test dozen levels usually little data base decisions 
describe hybrid approach attempts utilize advantages segmentation naive bayes evidence accumulation multiple attributes 
built univariate splits node naive bayes classifiers leaves 
final classifier resembles utgoff perceptron trees utgoff induction process different geared larger datasets 
resulting classifier easy interpret visualization naive bayes classifier iris dataset 
decision trees naive bayes 
decision tree segments data task consider essential part data mining process large databases brachman anand 
segment data represented leaf described naive bayes classifier 
shown induction algorithm segments data conditional independence assumptions required naive bayes true 
induction algorithms briefly review methods induction naive bayes 
decision tree quinlan breiman commonly built recursive partitioning 
univariate single attribute split chosen root tree criterion mutual information gain ratio gini index 
data divided test process repeats recursively child 
full tree built pruning step executed reduces tree size 
experiments compared results decision tree induction algorithm quinlan state art algorithm 
naive bayes langley iba thompson uses bayes rule compute probability class instance assuming attributes conditionally independent label 
version naive bayes experiments implemented mlc kohavi 
data pre discretized entropy algorithm fayyad irani dougherty kohavi sahami 
probabilities estimated directly data directly counts corrections laplace estimates 
accuracy scale learning curves naive bayes classifier requires estimation conditional probabilities attribute value label 
discrete data parameters need estimated estimates tend stabilize quickly data change underlying model 
continuous attributes discretization form intervals data available increasing representation power 
continuous data discretization global take account attribute interactions 
decision trees non parametric estimators approximate reasonable function database size grows gordon olshen 
theoretical result may database size required reach asymptotic performance number atoms universe case 
practice parametric estimators naive bayes may perform better 
shows learning curves algorithms large datasets uc irvine repository murphy aha 
learning curves show accuracy changes instances training data shown algorithm 
accuracy computed data training represents true generalization accuracy 
point computed average runs algorithm intervals 
error bars show confidence intervals accuracy sample 
cases clear adult dataset census bureau task predict adult year attributes education hours week 
instances dna naive bayes instances waveform naive bayes instances led naive bayes instances shuttle naive bayes instances letter naive bayes instances adult naive bayes instances chess naive bayes instances mushroom naive bayes instances satimage naive bayes learning curves naive bayes 
top graphs show datasets naive bayes outperformed lower graphs show datasets outperformed naive bayes 
error bars confidence intervals accuracy 
data learning curves cross 
known algorithm outperform cases wolpert world tend smoothness conditions algorithms successful practice 
section show hybrid approach improve algorithms important practical datasets 
nbtree hybrid algorithm nbtree algorithm propose shown 
algorithm similar classical recursive partitioning schemes leaf nodes created naive bayes nodes predicting single class 
threshold continuous attributes chosen standard entropy minimization technique done decision trees 
utility node computed discretizing data computing fold cross validation accuracy estimate naivebayes node 
utility split weighted sum utility nodes weight node proportional number instances go node 
intuitively attempting approximate generalization accuracy naive bayes classifier leaf higher single naivebayes classifier current node 
avoid splits little value define split significant relative absolute reduction error greater instances node 
direct cross validation select attributes commonly large overhead involved general 
data discretized naive bayes cross validated time linear number instances number attributes number label values 
reason input set labelled instances 
output decision tree naive bayes leaves 

attribute evaluate utility split attribute continuous attributes threshold stage 

arg max attribute highest utility 

significantly better utility current node create naive bayes classifier current node return 

partition test continuous threshold split discrete multi way split possible values 

child call algorithm recursively portion matches test leading child 
nbtree algorithm 
utility described text 
remove instances update counters classify repeat different set instances 
see kohavi details 
instances attributes label values complexity attribute selection phase discretized attributes delta delta 
number attributes logm usually case number labels small time spent attribute selection cross validation time spent sorting instances attribute 
expect nbtree scale large databases 
experiments evaluate nbtree algorithm large set files uc irvine repository 
table describes characteristics data 
artificial files monk evaluated space possible values files instances evaluated left sample size third data specific test set came data shuttle dna satimage files evaluated fold cross validation 
complex mechanism dealing unknown values 
eliminate effects unknown values removed instances unknown values datasets prior experiments 
shows absolute differences accuracies naive bayes nbtree 
line represents accuracy difference nbtree methods 
average accuracy naive bayes nbtree 
absolute differences tell story accuracies may close cases 
increasing accuracy medical diagnosis may cut costs half number errors halved 
shows ratio errors error accuracy 
shuttle dataset largest dataset tested absolute difference nbtree error decreases huge relative improvement 
number nodes induced nbtree cases significantly smaller 
example letter dataset induced nodes nbtree induced adult dataset induced nodes nbtree induced dna induced nodes nbtree induced led induced nodes nbtree single node 
complexity leaf nbtree higher ordinary trees thousands nodes extremely hard interpret 
related attempts extend naive bayes restrict learning general bayesian networks 
approaches feature subset selection may help increase representation power done review 
kononenko attempted join pairs attributes cross product attribute statistical tests independence 
experimentation results disappointing 
pazzani searched attributes join cross validation estimates 
friedman goldszmidt showed learn tree augmented naive bayes tan bayes network restricted tree topology 
results promising running times scale approach restrictive 
example accuracy chess dataset contains high order interactions lower nbtree achieve accuracies 
described new algorithm nbtree hybrid approach suitable learning scenarios attributes relevant classification task attributes necessarily conditionally independent label 
nbtree induces highly accurate classifiers practice significantly improving constituents dataset train test dataset train test dataset train test attrs size size attrs size size attrs size size adult breast cv breast cv chess cleve cv crx cv dna flare cv german cv glass cv glass cv heart cv ionosphere cv iris cv led letter monk mushroom pima cv primary tumor cv satimage segment cv shuttle soybean large cv tic tac toe cv vehicle cv vote cv vote cv waveform table datasets number attributes training test set sizes cv denotes fold cross validation 
nbtree nbtree nb tic tac toe vehicle monk satimage led vote shuttle ionosphere crx german pima glass waveform primary tumor accuracy difference accuracy differences 
line represents accuracy difference nbtree nbtree naive bayes 
points zero show improvements 
files sorted difference lines cross 
nbtree nbtree nb tic tac toe letter vehicle segment satimage iris led adult shuttle dna ionosphere breast breast german glass cleve glass primary tumor error ratio error ratios nbtree naive bayes 
values indicate improvement 
cases 
classifier outperform domains nbtree real world datasets tested scales terms accuracy 
fact datasets instances adult letter shuttle outperformed naive bayes 
running time longer decision trees naive bayes dependence number instances creating split decision trees log indicating running time scale 
interpretability important issue data mining applications 
nbtree segments data univariate decision tree making segmentation easy understand 
leaf naive bayes classifiers easily understood displayed graphically shown 
number nodes induced nbtree cases significantly smaller 
acknowledgments yeo girl yun implemented original categorizer mlc dan sommerfield wrote naive bayes visualization routines mlc brachman anand 
process knowledge discovery databases 
advances knowledge discovery data mining 
aaai press mit press 
chapter 
breiman friedman olshen stone 
classification regression trees 
wadsworth international group 
dougherty kohavi sahami 
supervised unsupervised discretization continuous features 
prieditis russell eds machine learning proceedings twelfth international conference 
morgan kaufmann 
fayyad irani 
multi interval discretization continuous valued attributes classification learning 
proceedings th international joint conference artificial intelligence 
morgan kaufmann publishers fayyad piatetsky shapiro smyth 
data mining knowledge discovery overview 
advances knowledge discovery data mining 
aaai press mit press 
chapter 
friedman goldszmidt 
building classifiers bayesian networks 
proceedings thirteenth national conference artificial intelligence 
appear 

estimation probabilities essay modern bayesian methods 
press 
gordon olshen 
sure consistent nonparametric regression recursive partitioning schemes 
journal multivariate analysis 
hamel 
competing 
harvard business school press mcgraw hill 
kohavi john long manley pfleger 
mlc machine learning library 
tools artificial intelligence 
ieee computer society press 
www sgi com technology mlc 
kohavi 
wrappers performance enhancement oblivious decision graphs 
ph dissertation stanford university computer science department 
ftp stanford edu pub ronnyk ps 
kononenko 
semi naive bayesian classifiers 
proceedings sixth european working session learning 
kononenko 
inductive bayesian learning medical diagnosis 
applied artificial intelligence 
langley iba thompson 
analysis bayesian classifiers 
proceedings tenth national conference artificial intelligence 
aaai press mit press 
murphy aha 
uci repository machine learning databases 
www ics uci edu mlearn 
pazzani 
searching attribute dependencies bayesian classifiers 
fifth international workshop artificial intelligence statistics 
quinlan 
programs machine learning 
los altos california morgan kaufmann publishers utgoff 
perceptron trees case study hybrid concept representation 
proceedings seventh national conference artificial intelligence 
morgan kaufmann 
wolpert 
relationship pac statistical physics framework bayesian framework vc framework 
wolpert ed generalization 
addison wesley 
