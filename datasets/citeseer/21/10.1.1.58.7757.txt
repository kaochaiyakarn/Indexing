study behavior methods balancing machine learning training data aspects influence performance achieved existing learning systems 
reported aspects related class imbalance examples training data belonging class heavily outnumber examples class 
situation real world data describing infrequent important event learning system may difficulties learn concept related minority class 
perform broad experimental evaluation involving methods proposed authors deal class imbalance problem thirteen uci data sets 
experiments provide evidence class imbalance systematically hinder performance learning systems 
fact problem related learning minority class examples presence complicating factors class overlapping 
proposed methods smote tomek smote enn deal conditions directly known sampling method data cleaning methods order produce better defined class clusters 
comparative experiments show general sampling methods provide accurate results sampling methods considering area roc curve auc 
result contradict results previously published literature 
smote tomek smote enn results data sets small number positive examples 
random sampling simple sampling method competitive complex sampling methods 
sampling methods provided performance results measured syntactic complexity decision trees induced sampled data 
results show trees usually complex ones induced original data 
random sampling usually produced smallest increase mean number induced rules smote enn smallest increase mean number conditions rule compared investigated sampling methods 

learning systems usually assume training sets gustavo maria carolina instituto de ci matem de computa postal carlos sp brazil icmc usp br learning balanced 
case real world data class represented large number examples represented 
known class imbalance problem reported obstacle induction classifiers machine learning ml algorithms 
generally problem imbalanced data sets occurs class represents circumscribed concept class represents counterpart concept examples counterpart class heavily outnumber examples class interest 
sort data example medical record databases regarding rare disease large number patients disease continuous fault monitoring tasks non faulty examples heavily outnumber faulty examples 
years attempts dealing class imbalance problem field data mining knowledge discovery databases ml substantial contributor 
related papers published ml literature aiming overcome problem 
ml community agree hypothesis imbalance classes major obstacle inducing classifiers imbalanced domains 
observed domains instance sick data set standard ml algorithms capable inducing classifiers highly imbalanced training sets 
shows class imbalance problem responsible decrease performance learning algorithms 
developed systematic study aiming question class imbalances hinder classifier induction deficiencies explained ways 
study developed series artificial data sets order fully control variables wanted analyze 
results experiments discrimination inductive scheme suggested problem solely caused class imbalance related degree data overlapping classes 
results obtained previous motivated proposition new methods deal problem learning presence class imbalance 
methods ally known sampling method smote data cleaning methods tomek links wilson edited nearest neighbor rule 
main motivation methods balance training data remove noisy examples lying wrong side decision border 
removal noisy examples aid finding better defined class clusters allowing creation simpler models better generalization capabilities 
addition perform broad experimental evaluation involving methods proposed authors deal class imbalance problem thirteen uci data sets 
concluded sampling methods able aid induction classifiers accurate induced sampled data sets 
result contradict results previously published literature 
proposed methods performed practice particular data sets small number positive examples 
worth noting random sampling simple sampling method competitive complex sampling methods 
remainder organized follows section discusses learning imbalanced data sets difficult task 
section describes drawbacks accuracy error rate measure performance classifiers discusses alternative metrics 
section presents methods employed experimental evaluation including methods proposed authors 
section discusses methodology experiments results achieved 
section presents outlines research 

learning imbalanced data sets difficult learning imbalanced data sets reported difficult task 
order better understand problem imagine situation illustrated 
fig 
large imbalance majority class minority class data set presents degree class overlapping 
comfortable situation learning represented fig 
classes balanced defined clusters 
situation similar illustrated fig 
spare cases minority class may confuse classifier nearest neighbor nn 
instance nn may incorrectly classify cases minority class nearest neighbors cases examples belonging majority class 
situation imbalance high probability nearest neighbor minority class case case majority class high minority class error rate tend high values unacceptable 
negative cases spare positive cases balanced data set defined clusters 
decision trees experience similar problem 
presence class overlapping decision trees may need create tests distinguish minority class cases majority class cases 
pruning decision tree necessarily alleviate problem 
due fact pruning removes branches considered specialized labelling new leaf nodes dominant class node 
high probability majority class dominant class leaf nodes 

evaluating classifiers im balanced domains straightforward way evaluate performance classifiers confusion matrix analysis 
table illustrates confusion matrix class problem having positive negative class values 
matrix possible extract number widely metrics measuring performance learning systems error rate defined err accuracy defined acc err 
table confusion matrix class problem 
positive prediction negative prediction positive class true positive false negative negative class false positive true negative prior class probabilities different measures lead misleading 
error rate accuracy particularly suspicious performance measures studying effect class distribution learning strongly biased favor majority class 
instance straightforward create classifier having accuracy error rate domain majority class proportion corresponds examples simply forecasting new example belonging majority class 
fact accuracy error rate metrics consider different classification errors equally important 
highly imbalanced problems generally highly non uniform error costs favor minority class class primary interest 
point considered studying effect class distribution learning systems class distribution may change 
consider confusion matrix shown table 
note class distribution proportion positive negative examples relationship second lines 
performance metric uses values lines inherently sensitive class skews 
metrics accuracy error rate values lines confusion matrix 
class distribution changes measures change fundamental classifier performance 
things considered interesting performance metric errors hits occurred class 
table possible derive performance metrics directly measure classification performance positive negative classes independently false negative rate percentage positive cases misclassified belonging negative class false positive rate percentage negative cases misclassified belonging positive class true negative rate percentage negative cases correctly classified belonging negative class true positive rate percentage positive cases correctly classified belonging positive class 
performance measures advantage independent class costs prior probabilities 
aim classifier minimize false positive negative rates similarly maximize true negative positive rates 
unfortunately real world applications tradeoff similarly 
roc receiver operating characteristic graphs analyze relationship classifier 
classifiers na bayes classifier neural networks yield score represents degree example member class 
ranking produce classifiers varying threshold example pertaining class 
threshold value produces different point roc space 
points linked tracing straight lines consecutive points produce roc curve 
decision trees class distributions leaf score proposed ordering leaves positive class accuracy producing trees re labelling leaves time forecasting negative class forecasting positive class positive accuracy order 
roc graph characterizes performance binary classification model possible trade offs classifier sensitivity false alarm 
roc graphs consistent problem distribution positive negative examples highly skewed 
roc analysis allows performance multiple classification functions visualized compared simultaneously 
area roc curve auc represents expected performance single scalar 
auc known statistical meaning equivalent wilcoxon test ranks equivalent statistical measures evaluating classification ranking models 
method proposed laplace correction measuring leaf accuracy produce roc curves 
auc main method assessing experiments 

methods section describes notation implementation nn algorithm algorithm plays important role behavior methods considered 
explanation balancing method 
notation supervised learning inducer fed data set 
en example ei associated label 
label defines class example belongs 
example ei tuple ei xi yi xi vector feature attribute values example ei yi class value 
objective supervised learning algorithm induce general mapping vectors values learning system aims construct model unknown function known concept function enables predict values previously unseen examples 
practice learning systems able induce function approximates 
case called hypothesis concept function table data set examples attributes 
columns 
am represent attributes lines 
en represent examples 
instance line table refers ith example entry xij refers value jth attribute aj example classification problems class attribute qualitative attribute may assume set ncl discrete values 
cn cl 
table data set attribute value form 
am 
en xn xn 
yn stated earlier consider class problems represents circumscribed concept class represents counterpart concept 
furthermore examples negative class outnumber examples positive class 
implementation nn algorithm research papers euclidean distance distance metric nn algorithm 
distance function appropriate domain presents qualitative attributes 
domains distance qualitative attributes usually calculated overlap function value examples value attribute value values differ assigned 
implementation nn algorithm uses heterogeneous value difference metric hvdm distance function 
distance function uses euclidean distance quantitative attributes vdm distance qualitative attributes 
vdm metric provides appropriate distance function qualitative attributes compared overlap metric vdm metric considers classification similarity possible value qualitative attribute calculate distances values 
refinement basic nn algorithm weigh contribution neighbors distance query example eq giving greater weight closer neighbors 
vote neighbor weighed inverse square distance eq 

set nearest neighbors eq distance function final classification equation 
eq arg max eq 
balancing methods severe distance computations implemented indexing structure tree speed execution nn queries 
considers relative distances examples absolute positions multi dimensional space organize partition metric space 
metric space example proximity defined distance function satisfies positivity symmetry triangle inequality postulates 
methods evaluate different methods sampling balance class distribution training data 
methods random sampling random sampling non heuristic methods initially included evaluation baseline methods 
evaluated methods described 
random sampling non heuristic method aims balance class distribution random replication minority class examples 
random sampling non heuristic method aims balance class distribution random elimination majority class examples 
authors agree random sampling increase likelihood occurring overfitting exact copies minority class examples 
way symbolic classifier instance construct rules apparently accurate cover replicated example 
hand major drawback random sampling method discard potentially useful data important induction process 
remainder balancing methods heuristics order overcome limitations non heuristic methods 
tomek links tomek links defined follows examples ei ej belonging different classes ei ej distance ei ej 
ei ej pair called tomek link example el ei el ei ej ej el ei ej 
examples form tomek link examples noise examples borderline 
tomek links sampling method data cleaning method 
sampling method examples belonging majority class eliminated data cleaning method examples classes removed 
condensed nearest neighbor rule hart condensed nearest neighbor rule cnn find consistent subset examples 
subset consistent nearest neighbor correctly classifies examples algorithm create subset sampling method randomly draw majority class example examples minority class put examples 
nn examples classify examples misclassified example moved 
important note procedure find smallest consistent subset idea implementation consistent subset eliminate examples majority class distant decision border sorts examples considered relevant learning 
sided selection sided selection oss sampling method resulting application tomek links followed application cnn 
tomek links sampling method removes noisy borderline majority class examples 
borderline examples considered unsafe small amount noise fall wrong side decision border 
cnn aims remove examples majority class distant decision border 
remainder examples safe majority class examples minority class examples learning 
cnn tomek links methods proposed 
similar sided selection method find consistent subset applied tomek links 
objective verify competitiveness oss 
finding tomek links computationally demanding computationally cheaper performed reduced data set 
neighborhood cleaning rule neighborhood cleaning rule ncl uses wilson edited nearest neighbor rule enn remove majority class examples 
enn removes example class label differs class nearest neighbors 
ncl modifies enn order increase data cleaning 
class problem algorithm described way example ei training set nearest neighbors 
ei belongs majority class classification nearest neighbors contradicts original class ei ei removed 
ei belongs minority class nearest neighbors misclassify ei nearest neighbors belong majority class removed 
smote synthetic minority sampling technique smote sampling method 
main idea form new minority class examples interpolating minority class examples lie 
overfitting problem avoided causes decision boundaries minority class spread majority class space 
smote tomek links sampling minority class examples balance class distributions problems usually data sets skewed class distributions solved 
frequently class clusters defined majority class examples invading minority class space 
opposite true interpolating minority class examples expand minority class clusters introducing artificial minority class examples deeply majority class space 
inducing classifier situation lead overfitting 
order create better defined class clusters propose applying tomek links sampled training set data cleaning method 
removing majority class examples form tomek links examples classes removed 
application method illustrated 
original data set sampled smote balancing data set original data set oversampled data set tomek links identification borderline noise examples removal 
tomek links identified removed producing balanced data set defined class clusters 
smote tomek links method improve classification examples problem annotation proteins bioinformatics 
smote enn motivation method similar smote tomek links 
enn tends remove examples tomek links expected provide depth data cleaning 
differently ncl sampling method enn remove examples classes 
example misclassified nearest neighbors removed training set 

experimental evaluation main objective research compare balancing methods published literature proposed methods order verify methods effectively deal practice problem class imbalance 
comparison selected thirteen data sets uci different degrees imbalance 
table summarizes data employed study 
data set shows number examples examples number attributes attributes number quantitative qualitative attributes class attribute distribution majority class error 
data sets having classes chose class fewer examples positive class collapsed remainder negative class 
letter splice data sets similar number examples minority classes created data sets letter letter vowel splice splice ei 
experiments release symbolic learning algorithm induce decision trees 
firstly ran original imbalanced data sets calculated auc data set fold crossvalidation 
results obtained initial experiment shown graph 
plots proportion negative positive examples proportion negative positive examples versus auc 
auc pima german post operative haberman splice splice ei vehicle letter vowel proportion negative positive examples new thyroid coli satimage flag glass letter nursery versus mean auc values original data sets 
class imbalances systematically hinder performance imbalanced data sets expected auc decreases highly imbalanced data sets 
spite large degree imbalance data sets letter nursery obtained auc 
results obtained uci data sets compatible previous authors conducted series experiments artificial domains varied degree overlapping classes 
concluded class imbalance problem allied highly overlapped classes significantly decrease number minority class examples correctly classified 
domains non overlapping classes problematic learning matter degree imbalance 
japkowicz performed experiments artificial data sets concluded class imbalances systematically cause performance degradation 
concludes imbalance problem relative problem depending complexity concept size training set 
relationship training set size improper classification performance imbalanced data sets small imbalanced data sets minority class poorly represented excessively reduced number examples sufficient learning especially large degree class overlapping exists class divided subclusters 
larger data sets effect complicating factors reduced minority class better represented larger number examples 
trend confirmed graph shown shows auc affected number positive training examples data sets 
second stage sampling methods described section applied original data sets 
smote random sampling random sampling cnn methods internal parameters allow user set resulting class distribution obtained application methods 
decided add remove examples balanced distribution reached 
concept complexity corresponds number subclusters classes subdivided 
table data sets summary descriptions 
data set examples attributes class class majority quanti quali 
min maj 
min maj error pima german bad post operative remainder haberman die survive splice remainder splice ei ei remainder vehicle van remainder letter vowel vowels remainder new thyroid hypo remainder coli remainder satimage remainder flag white remainder glass win float proc remainder letter remainder nursery recom remainder number positive training examples versus auc 
auc pima german post operative haberman splice splice ei vehicle letter vowel number positive examples new thyroid coli satimage flag glass letter nursery decision motivated results shown auc performance measure best class distribution learning tends near balanced class distribution 
results obtained experiments summarized tables 
table shows performance results original sampled data sets 
table shows results obtained sampled data sets 
performance results reported terms auc 
numbers brackets corresponding standard deviations 
stated earlier results obtained fold cross validation 
aucs measured decision trees pruned default pruning parameter setting confidence level unpruned decision trees 
research papers state pruning helpful imbalanced data sets circumstances papers indicate target misclassification costs class distributions unknown pruning avoided 
reason avoid pruning pruning schemes including attempt minimize error rate 
pruning schemes detrimental minority class reducing error rate majority class stands examples result greater impact error rate 
hand question pruning lead performance im provement decision trees grown artificially balanced data sets 
argument pruning pruning allowed execute conditions learning system prune false assumption test set distribution matches training set distribution 
shows comparison effect pruning decision trees original balanced data sets 
line represents pruned unpruned decision trees obtain auc 
plots line represent unpruned decision trees obtained better results plots line opposite 
clearly shows pruning rarely leads improvement auc original balanced data sets 
auc pruned versus unpruned decision trees original balanced data sets 
auc unpruned original cnn cnn tomek tomek oss random sampling auc pruned random sampling ncl smote smote enn smote tomek tables results bold indicate best aucs obtained data set considering pruned unpruned decision trees independently 
order facilitate analysis results tables results ranking methods pruned unpruned decision trees respectively 
sampling methods highlighted light gray color results obtained original data sets dark gray color 
note general sampling methods better ranked sampling methods 
hsu multiple comparison best mcb test performed order verify significant differences exist confidence level table auc results original sampled data sets 
data set pruning original rand smote smote tomek smote enn pima german post operative haberman splice splice ei vehicle letter vowel new thyroid coli satimage flag glass letter nursery best ranked method remaining methods 
results summarized tables methods marked asterisk obtained statistically inferior results compared top ranked method 
conversely sampling methods general random sampling particular ranked remainder methods 
result diverge papers previously published literature 
drummond holte report default settings sampling surprisingly ineffective producing little change performance response modifications misclassification costs class distribution 
note sampling prunes generalizes sampling modification parameter settings increase influence pruning overfitting avoidance factors reestablish performance sampling 
experiments random sampling produce overfitted decision trees trees left unpruned confirmed higher auc values obtained method unpruned trees 
addition sampling methods perform sampling methods heuristics remove cases considered sampling 
domingos reports concerning concept learning problems rules produces lower cost classifiers sampling sampling 
ling li compare sampling boosted report sampling produces better lift index extreme sampling performs 
hand japkowicz stephen compare methods sampling series artificial data sets conclude sampling effective sampling reducing error rate 
opinion results obtained sampling completely unexpected 
stated loss performance directly related lack minority class examples conjunction complicating factors 
sampling class methods directly attack problem lack minority class examples 
worth mentioning proposed methods smote tomek smote enn generally ranked best data sets small number positive examples 
considering data sets positive examples experiments flag glass post operative new thyroid coli haberman proposed methods provided meaningful results data sets pruned trees table data sets unpruned trees table 
indicate methods appropriate domains having conditions 
sampling methods unpruned decision trees obtained performance results analysis focus results 
addition classifier performance results attempted measure syntactic complexity induced models 
syntactic complexity main parameters mean number induced rules branches mean number conditions rule 
tables respectively show mean number induced rules mean number condition rule sampling methods original data sets unpruned decision trees 
best results shown bold best results obtained sampling method considering results obtained original data sets highlighted light gray color 
shows results table graphical form observed sampled data sets usually lead increase number induced rules compared trees induced original data sets 
table auc results sampled data sets 
data set pruning rand cnn cnn tomek tomek oss ncl pima german post operative haberman splice splice ei vehicle letter vowel new thyroid coli satimage flag glass letter nursery table performance ranking original balanced data sets pruned decision trees 
data set pima smt smt tmk smt enn tmk ncl original cnn tmk cnn oss german smt tmk smt cnn cnn tmk oss original tmk ncl post smt original cnn cnn tmk oss tmk ncl smt tmk haberman smt tmk smt ncl tmk oss cnn original cnn tmk splice original tmk smt cnn ncl smt tmk smt enn cnn tmk oss splice ei smt smt tmk smt tmk cnn ncl original vehicle smt smt tmk oss cnn tmk tmk ncl smt enn letter vowel smt tmk smt tmk ncl original cnn cnn tmk oss new thyroid smt tmk smt cnn original tmk cnn tmk ncl oss coli smt tmk smt smt ncl tmk original oss cnn tmk cnn satimage smt smt tmk ncl tmk original oss cnn tmk cnn flag smt tmk cnn cnn oss tmk original ncl glass smt ncl smt smt cnn tmk oss cnn letter smt tmk smt oss cnn tmk ncl cnn nursery tmk original ncl cnn oss smt tmk smt cnn tmk smt enn table performance ranking original balanced data sets unpruned decision trees 
data set pima smt smt tmk smt ncl original cnn tmk cnn oss german original tmk ncl smt smt tmk smt enn oss cnn cnn tmk post cnn smt tmk cnn oss smt enn smt tmk ncl haberman smt tmk smt enn smt tmk ncl original oss cnn cnn tmk splice original smt tmk cnn ncl smt tmk oss smt enn cnn tmk splice ei smt smt tmk smt cnn ncl oss cnn vehicle smt smt tmk oss cnn original cnn smt enn ncl letter vowel smt smt tmk tmk ncl original cnn cnn tmk oss new thyroid smt smt tmk original tmk cnn cnn tmk ncl oss coli smt tmk smt smt original ncl oss cnn tmk cnn satimage smt smt tmk tmk ncl original cnn tmk oss cnn flag smt tmk oss cnn tmk smt enn original ncl cnn tmk smt glass smt ncl smt smt tmk oss cnn tmk cnn letter smt smt tmk smt tmk oss ncl original cnn cnn tmk nursery original ncl tmk cnn oss smt cnn tmk smt tmk smt enn comparing mean number rules obtained sampled data sets random sampling smote enn methods usually provide smaller increase mean number rules 
expected application sampling result increase mean number rules sampling increases total number training examples usually generates larger decision trees 
considered unexpected table number rules branches original sampled data sets unpruned decision trees 
data set original rand smote smote tomek smote enn pima german post operative haberman splice splice ei vehicle letter vowel new thyroid coli satimage flag glass letter nursery table mean number conditions rule original sampled data sets unpruned decision trees 
data set original rand smote smote tomek smote enn pima german post operative haberman splice splice ei vehicle letter vowel new thyroid coli satimage flag glass letter nursery random sampling competitive smote tomek smote enn number induced rules tomek enn applied data cleaning methods objective eliminating noise examples simplifying induced decision trees 
mean number induced rules original balanced data sets unpruned decision trees 
mean number rules balanced data original random sampling smote mean number rules original data smote enn smote tomek results table shown graph allowing clearer comparison mean number conditions rule sampled data sets 
smote enn method provided results 
fact best ranked data sets 
furthermore method able obtain smaller values achieved decision trees induced original data sets data sets 
considering sampled data sets method best ranked data sets 
mean number conditions rule original balanced data sets unpruned decision trees 
mean number conditions rule balanced data original random sampling smote mean number conditions rule original data smote enn smote tomek 
limitations analyze behavior sampling methods deal problem learning imbalanced data sets 
results show sampling methods general smote tomek smote enn methods proposed particular data sets positive minority examples provided results practice 
random sampling frequently considered method provided competitive results complex methods 
general recommendation smote tomek smote enn applied data sets small number positive instances condition lead classification performance problems imbalanced data sets 
data sets larger number positive examples random sampling method computationally expensive methods produce meaningful results 
noted allocating half training examples minority class provide optimal results 
plan address issue research 
furthermore sampling methods tomek links ncl originally allow user specify resulting class distribution improved include feature 
natural extension analyze roc curves obtained classifiers 
provide depth understanding behavior balancing cleaning methods 

wish anonymous reviewers le pinto helpful comments 
research partially supported brazilian research councils capes 

balancing training data automated annotation keywords case study 
wob pp 

bauer kohavi empirical comparison voting classification algorithms bagging boosting variants 
machine learning 
blake merz uci repository machine learning databases 
www ics uci edu mlearn mlrepository html 
chawla imbalanced data sets investigating effect sampling method probabilistic estimate decision tree structure 
workshop learning imbalanced data sets ii 
chawla bowyer hall kegelmeyer smote synthetic minority sampling technique 
jair 
ciaccia patella tree efficient access method similarity search metric spaces 
vldb pp 

domingos metacost general method making classifiers cost sensitive 
kdd pp 

drummond holte class imbalance cost sensitivity sampling beats sampling 
workshop learning imbalanced data sets ii 
ferri flach hern ndez learning decision trees area roc curve 
icml pp 

hand construction assessment classification rules 
john wiley sons 
hart condensed nearest neighbor rule 
ieee transactions information theory 
japkowicz class imbalances focusing right issue 
workshop learning imbalanced data sets ii 
japkowicz stephen class imbalance problem systematic study 
ida journal 
kubat matwin addressing course imbalanced training sets sided selection 
icml pp 

improving identification difficult small classes balancing class distribution 
tech 
rep university tampere 
ling li data mining direct mining problems solutions 
kdd pp 

mitchell machine learning 
mcgraw hill 
class imbalances versus class overlapping analysis learning system behavior 
pp 

lnai 
provost fawcett analysis visualization classifier performance comparison imprecise class cost distributions 
kdd pp 

quinlan programs machine learning 
morgan kaufmann ca 
stanfill waltz instance learning algorithms 
communications acm 
tomek modifications cnn 
ieee transactions systems man communications smc 
weiss provost learning training data costly effect class distribution tree induction 
jair 
wilson asymptotic properties nearest neighbor rules edited data 
ieee transactions systems man communications 
wilson martinez reduction techniques exemplar learning algorithms 
machine learning 
zadrozny elkan learning making decisions costs probabilities unknown 
kdd pp 

