combining linguistic knowledge acoustic information automatic pronunciation lexicon generation grace chung chao wang stephanie seneff min tang national research initiatives preston white drive suite reston va cnri reston va mit computer science artificial intelligence laboratory stata center street cambridge ma seneff csail mit edu describes experiments aimed long term goal enabling spoken conversational system automatically improve pronunciation lexicon time direct interactions users available web sources 
selected set rare words ogi corpus spoken names performed experiments combining spelling pronunciation information hypothesize phonemic baseforms words 
evaluated quality resulting baseforms series recognition experiments words isolated word recognition task 
report modification letter sound system utilizing letter phoneme gram language model combination original column bigram model additional linguistic constraint robustness 
experiments confirm expectation acoustic information drawn spoken examples words greatly improve quality baseforms measured recognition error rate 
ultimate goal allow spoken dialogue system automatically expand improve baseforms time users introduce new words supply spoken pronunciations existing words 

years addressed dynamic addition new words spoken dialogue system verbal entry 
objective develop systems intelligently handle incidence new words accurate detection deduction spellings pronunciations dynamic seamless incorporation system lexicon 
particularly pertinent narrow domain systems provide line information database contains large set proper names change frequently 
past reported system recognize spellings pronunciations open vocabularies proper names unified framework combines sublexical modeling bi directional letter sound conversion 
previous mainly addressed spelling extraction opposed phonemic extraction recognizing unknown words 
research cnri sponsored part ssc sd 
content necessarily reflect position policy government official endorsement inferred 
research mit supported part industrial consortium supporting mit oxygen alliance 
research examining quality phonemic baseforms derived letter sound capabilities comparing performance alternate ways extracting pronunciations unknown words user waveforms 
researchers addressing letter sound problem reported generation acoustic data distinguishes letter sound models applied directly recognition generate baseforms acoustic data :10.1.1.14.4718
envision system able acquire new words automatically interaction user web sources 
instance user asks book stores saint louis system immediately download candidate list web update recognizer dynamic vocabulary reflect immediacy words 
words unavailable large line lexicon entered pronunciation obtained letter sound system 
interaction user involve request originally missing words 
follow solicit spoken spelling word resource system 
subsequent confirmation user assure validity user spoken rendering 
system update lexical entry rare word user pronounced example 
time words lexicon refined manner quality pronunciation lexicon steadily improve 
scenario poses research questions attempt answer formally 
experiments focus set words ogi names corpus selected specifically appear pre existing word lexicon people names 
ask questions letter sound system proposing pronunciations words pronunciations improved advantage previously spoken instance word speaker difference previous pronunciation speaker happens spelling exact available recognition spoken spelling 
experiments evaluate performing recognition task summit speech recognizer lexicon consisting ogi words 
approximation situation exist dynamic vocabulary recognizer 
furthermore exact word stand previous instance word recognizing gives upper bound performance result scenario 
available corpus spoken spellings words synthesize spellings festival speech synthesizer 
aspect modification statistical letter sound model trigrams addition original column bigrams demonstration improves letter sound results experiments 
sections letter sound models column bigram joint grapheme phoneme gram model briefly described 
series experiments deriving pronunciations letter sound combination user waveforms 

approach 
column bigram method previous hierarchical framework known capturing subword structure predict phoneme grapheme mappings 
framework combines statistical methods explicit linguistic information generalize observation space unseen words 
previously developed paradigm hierarchical models converted finite state transducer fst representation providing sound mappings 
fst configuration captures bigram statistics units identified vertical columns parse table refer column bigram grapheme phoneme units enriched morph syllabic properties lexical stress 
probability model trained lexicon proper nouns containing names 
proper nouns semi automatic procedure described 
total unique graphemes th unique phoneme units 

letter phoneme gram models researchers employed joint modeling phonemic units address letter sound problem method employs various means finding alternate alignments phonemes graphemes 
take advantage parse trees align graphemes phonemes 
gram model trained alignments derived automatically parsing large training corpus 
pre terminal terminal units column parse chart concatenated form grapheme phoneme unit creating grapheme phoneme training datum 
joint probability distribution letters phoneme units modeled standard gram models lp stands letter phoneme represents unit number letter phonemes word 
unit determined strictly vertical columns parse table 
table illustrates example names baseforms training 
total 
underlying phoneme letter sequences easily extracted 
clarity henceforth refer units letter phoneme lp units recognizing unit may contain letter circumstances 

ah 
aor null iy ah middleton 
ih dd 
le el 
en null st st ee iy tmm 
ae table example baseforms names training set 
letter phoneme units comprise grapheme component phoneme component 
phoneme component may null set special units marked stress syllable onset 
lp gram model trained word training set column bigram method 
spelling highest scoring letter phoneme sequence gram model computed subsequent phonemic sequence extracted 
computations achieved fst operations 

extraction pronunciation waveforms letter sound systems encapsulated fst framework speech recognizer sum mit spelling word possible create fst supporting various phonemic sequences specified model corresponding input letter sequence 
achieved fst composition spelling fst constrain letter sound fst input spelling 
resulting fst accompanied scores probability model 
path constraint forced alignment waveform 
summit recognizer phonemic labels expanded phonological rules mapped contextdependent labels 
phonemic labels projected fst output extracted output alignment search 

experiments experiments formulated quality extracted baseforms evaluated recognition performance set names training 
waveform data sets words drawn ogi names corpus 
testing recognition accuracy deriving pronunciation baseforms 
note test data artificially excluded training corpus 
test set defined selecting words ogi corpus shown previous collections proper nouns line sources 
expect names quite rare dissimilar training data 
real dialogue application name introduced assume system consults dictionary search possible pronunciation prior invoking letter sound module 
argued measuring recognition performance test set better performance indicator comparison human transcribed name pronunciations difficult determine particular individual owner 
task consist recognizing isolated name waveforms derived pronunciations 
speech recognizer additional language models 
experiments address scenario spelling word known 
framework letter sound capability extract phonemic baseforms correct spelling 
third experiment addresses situation word question unknown assumed user provided spelled waveform 
spelling algorithm wer 
cb lp 
lp table recognition error rate isolated word task word vocabulary baseforms derived column bigram model cb letter phoneme trigram lp back letter phoneme trigram 
alternate pronunciations word 
note parsing align letters phonemes training set systems 
hypotheses letter recognizer combined letter capability propose pronunciation baseforms 

letter sound evaluation experiment pronunciations word derived solely letter sound mappings fsts 
information additional waveforms 
probability model generalize observation space unseen words column bigram fst compact representation capture generalization capability 
rare sequences seen training may occasionally result hard failures 
test set hard failures column bigram 
fair comparison recognition task examine baseforms column bigram fst cb performs letter sound conversion failed utterances resorting letter phoneme gram lp back letter sound conversion performed entirely lp gram fst 
results tabulated table show lp model fact performs better hybrid cb lp model 
note letter phoneme alignments derived parse tree trigram lp model deleted interpolation smoothing experiments 
investigations higher order grams yield gains 
system word test set causes hard failures baseforms subsequently obtained letter phoneme model 
consider varying number alternate pronunciations 
experiments variants appear ideal 
increasing number alternates rapidly deteriorates word accuracy 
examination correct pronunciation variant may occur second hypothesis 
letter phoneme model word word error rate wer 
variants generally afford superior performance parameter held constant remainder experiments 
independent benchmark compare letter sound performance decision tree framework described 
decision tree trained letter phoneme lexicon achieve word error rate derived baseforms recognition experiment 

pronunciation extraction waveforms second experiment examine extraction phonemic baseforms user waveforms incorporating letter fsts forced alignment described section 
conditions examined alternate waveform extract baseforms testing test corpus tools downloaded www cs cmu edu 
algorithm wer nd waveform derive pronunciation 
lp fst cb 
lp fst lp 
cb lp fst cb 
cb lp fst lp test waveform derive pronunciation 
lp fst cb 
lp fst lp 
cb lp fst cb 
cb lp fst lp table recognition error rates various configurations pronunciations derived waveform data assuming exact spellings words available 
see text details 
waveforms extraction testing 
speakers test sets overlap 
speakers names differed waveform sets 
table shows sets results 
systems refer extraction second waveform 
systems refer extraction waveform 
seen results deriving phoneme sequences waveform yield improved recognition compared letter sound algorithms wide margins 
acoustic data contributes greatly generation phonemic pronunciations anticipated 
considering extraction pronunciation waveforms ways combining methods explored 
important forced alignments waveforms failed result paths pruned away having fallen score thresholds alignment 
applicable column bigram letter phoneme methods 
case failed forced alignment phoneme derived direct letter sound conversion contribution acoustic waveform column bigram fst cb systems letter phoneme fst lp systems 
systems letter phoneme fst forced alignment phase 
utterances failed forced alignment procedure 
systems column bigram fst possible utterances fail column bigram letter sound phonemic derived column bigram fst performing forced alignment letter phoneme fst 
denoted cb lp fst table 
letter sound experiments trigram outperformed column bigram method dealing waveform data hybrid approach combining column bigram letter phoneme trigram acts smoothing mechanism column bigram fst yields better results 
optimal result wer resort letter phonemes trigram perform letter sound conversion forced alignment fails column bigram letter phoneme fsts 
waveform sets speakers vary pronunciations names differ 
pronunciation extracted test waveform results improve markedly 
expected pronunciation extraction 
optimal condition occurs hybrid method combining column bigram letter phoneme trigram yielding wer 
examination pronunciations proper nouns waveform sets quite variable names spelled algorithm wer nd waveform derive pronunciation 
cb 
cb concatenated test waveform derive pronunciation 
cb 
cb concatenated table recognition error rate isolated word task baseforms derived spoken synthesized spelling waveforms 
belonged different people pronounced differently 
baseforms derived waveform naturally matched test waveform pronunciation 

incorporating spoken spellings third experiment consider situation speech interface required elicit pronunciation unknown word spelling 
applicable verbally entered unknown word 
test corpus contain spelled versions words simulated conditions speech synthesizer generate spelled version names 
turned recognizer performance spelled synthetic data produced letter error rate 
previous letter error rates speech recognizer lower real user spelled data 
conjecture intelligibility naturalness synthesized waveforms quite poor causing poorer performance 
single spelling spelling graph recognition hypotheses input fst operations 
method column bigram fst create phoneme baseforms 
additional experiment method similar described earlier 
spoken waveform synthesized spelling waveform concatenated simultaneous search constrained hypothesis spellings spelled spoken parts identical 
explained output alignment phase set phonemic baseforms name recognizer evaluation 
results tabulated table 
systems waveform set extract pronunciations standard test set compute recognition accuracy 
systems waveforms deriving pronunciations testing recognition 
systems composed letter graph letter spelling recognizer column bigram fst conduct forced alignments 
systems augmented concatenation simultaneous constraint spellings spelled spoken parts identical 
general seen letter recognition accuracies quite poor phoneme extraction performed 
quality phonemes better obtained single letter sound converter true spelling known waveforms available 
wer ranged compared best wer sound derivation table 
waveform pronunciation extraction testing gives better recognition accuracy 
concatenating spoken waveform spelled produces improvement consistent previous results letter recognition different waveforms waveform 

examined performance combined knowledge data driven letter sound framework applied automatically generate pronunciation baseforms acoustic information full partial spelling knowledge 
extension explore migration domains concerning proper nouns applications restaurants hotels shopping city guides forth 
currently investigating semi automatic methods training framework joint letter phoneme modeling effort reduce time port new domains pool new data sets training 
optimized letter sound capabilities integrated spoken dialogue system splice spoken unknown words embedded sentences elicit spellings new words users 
features integrated ability dynamically update recognizer lexicon ongoing conversation 

chung seneff wang 
automatic acquisition names speak spell mode spoken dialogue systems 
proc 
hlt naacl edmonton canada 
allen 
name pronunciation joint ngram model bi directional grapheme phoneme conversion 
proc 
icslp denver colorado 
ney 
multigram grapheme conversion lvcsr 
proc 
eurospeech geneva switzerland 
chen 
conditional joint models grapheme conversion 
proc 
eurospeech geneva switzerland 
damper marchand adamson gustafson 
comparative evaluation letter sound conversion techniques english text speech synthesis 
proc 
third esca workshop speech synthesis pages blue mountains nsw australia 
font black 
knowledge language origin improves pronunciation accuracy proper names 
proc 
eurospeech aalborg denmark 
deligne 
lattices automatic generation pronunciations 
proc 
icassp hong kong china 

automatic generation acoustic data 
proc 
eurospeech geneva switzerland 
names ogi names corpus 
cse ogi edu corpora name 
glass 
probabilistic framework segment speech recognition 
computer speech language 
chung 
stage solution flexible vocabulary speech understanding 
proc 
icslp beijing china 
seneff chung wang 
empowering users personalize dialogue systems spoken interaction 
proc 
eurospeech geneva switzerland 
festival speech synthesis system 
www cstr ed ac uk projects festival 
chung 
dynamic vocabulary spoken dialogue interface 
proceedings 
