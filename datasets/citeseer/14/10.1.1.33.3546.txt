dimensionality human semantic space 
lowe center cognitive studies tufts university ma tufts edu 
mcdonald lowe showed cosines semantic space dimensions reflect human priming results wide range semantic associatively related words exp 
previously lowe argued intrinsic dimensionality semantic space lower high dimensional structure effectively captured just dimensions surface neural map 
provides replication mcdonald lowe results dimensions generative topographic mapping statistically motivated neural network architecture topographic maps 

semantic space semantic space model proved successful models semantic memory 
semantic space operationalizes idea initially introduced distributional linguistics words semantically similar extent behave way text verbs sorts arguments nouns modified kind adjectives extent semantically similar 
semantic space representations vectors surrounding word counts substitute knowing distributional profile argument structures advance 
words similar vector representations share similar linguistic contexts semantically similar 
success semantic space models modeling psycholinguistic phenomena large extent approach meaning underlying distributional linguistics raises number technical questions relating non parametric nature approximations constructing space 
argument structures known advance obvious measure similarity words look argument slot compare sorts words 
thinking words having subcategorization preferences may immediately intuitive explicit link dependency grammar helps connect semantic space syntactic perspectives 
argument frames known count surrounding words maximum window size 
question words need count get approximation 
semantic spaces vector spaces typically high dimensionality generalization question addressed appropriate dimensionality human semantic space 

previous landauer dumais argued optimal number dimensions psychological modeling data appropriate dimension generated large numbers word counts subjecting linear dimensionality reduction 
claim human semantic space fairly low dimension compared dimensionality vector data semantic space model 
estimate fig directions principal variance retained thousands generated model optimally predict human behaviour 
idea intrinsic dimensionality data typically lower observed dimensionality motivates multidimensional scaling mds factor analytic approaches psychology 
mds performs similar function neural models topographic map formation computational neuroscience 
development generative topographic mapping gtm non linear extension factor analysis models usefully distinguished 
ritter kohonen self organizing map project simple vector representations word cooccurrence counts dimensional map surface 
similar approaches taken scholtes lowe 
implicit assumption cooccurrence data inherently low dimensional 

interpreting semantic space models distinct ways interpret semantic space models 
space may description lexical semantic structure language 
sense constructing semantic space methodology finding semantic structure english distributional similarity measure 
alternatively semantic space may theory semantic representation people 
interpretation distances space correlate reliably human performance psychologically interesting measure infer sufficient statistical regularity linguistic environment able perform psychological task 
computational approach psychology half story needs theory information represented mind brain 
semantic spaces psychological models assert person vectors lexical associations performs similarity computations determine semantic similarity 
interpretation tested semantic distances correlated human experimental performance 
hyperspace analogue language hal latent semantic analysis compared human data analysis subjects items 
true previous semantic space 
subjects testing theory items 
reported treats neural network models subjects doubles theory semantic representation theory intrinsic dimensionality semantic space 
section briefly reviews earlier modeling associative multiple types semantic priming semantic space high dimension 
section shows substantially results obtained dimensionality data reduced dramatically 
consider implications estimating dimensionality human semantic space 
experiment priming high dimensional space moss colleagues showed semantic priming occurs wide range semantic relations association 
stimulus words named members taxonomic category category coordinates natural objects artifacts related functionally functional items script instrument relations 
moss colleagues showed separate semantic associative priming effects categories 
showed semantic priming effect greater presence association associative boost 
mcdonald lowe demonstrated moss results modeled high dimensional space 
briefly review details model construction results latest version model comparison low dimensional results described 
constructed semantic space words british national corpus bnc balanced corpus british english 
word vectors generated passing moving window corpus collecting occurrence frequencies reliable context words word window side stimulus item 
context words previous modeling graded mediated priming 
method choosing reliable context words described 
positive log odds ratios measure amount lexical association context word experimental stimuli 
odds ratio known measure association takes chance occurrence account 
created vectors filler words frequency ranks bnc occurrences 
stimulus frequencies ranged median frequency 
unrelated primes chosen randomly set filler words original experiment varied factors association associated semantic type category coordinate functional relation relatedness related unrelated 
semantic subtypes nested semantic type 
purposes modeling priming cosine prime target inversely proportional corresponding reaction time 
size priming effect calculated subtracting cosine unrelated prime target cosine related prime target 
cosines unrelated pairs taken cosine target prime condition 
cosines entered directly analyses variance 
results cosines semantic space shown table 
main effect relatedness association replicating associative priming 
interaction association relatedness 
replicates associative boost 
associated non associated related unrelated related unrelated cat 
coord 
functional table cosines high dimensional semantic space unrelated primes chosen randomly alternative source 
bold face numbers priming effects semantic type 
considered associated non associated items 
semantic priming occurred associated condition condition 
priming effect category coordinates appeared slightly larger functional items consistent human results difference significant 
category coordinates semantically related pairs similar unrelated pairs 
associative priming 
associative boost significant interactions 
associative boost occur due low level similarity associated artifact targets related primes 
boost follows human results 
functional pairs showed semantic priming effect main effect association reliable associative boost 
main effect subtype due steadily decreasing amounts similarity subtypes relative stable baseline associated related script associated related instrument non associated related script non associated related instrument 
detailed analyses semantic subtype reported 
discussion space replicates moss finding semantic priming occurs wide range semantic categories association 
see associative boost 
experiment priming low dimensional space experiment gtm networks subjects 
gtm models trained transformed semantic space vectors 
large number irrelevant word vectors intended give network better idea shape semantic space just small set words interest 
words filler experiment moss materials rest experimental stimuli priming experiments 
results reported 
entire augmented set dimensional semantic space vectors transformed linearly dimensions independently generated stochastic matrices gtm model 
gtm initialized random parameters saw distinct random mapping semantic space vectors 
ideally network trained vectors generated sampling larger corpus 
computationally extremely demanding corpus available 
newsgroups possible step research 
random mapping neural networks criticized relying crucially intelligent prior data 
consequently principal component analysis vectors reduce dimensionality tractable levels represent substantial modeling assumption obviously motivated neural perspective 
random mapping reduces dimensionality data level tractable reasonable network training times making fewest possible assumptions nature input save derives vectors lexical associations 
random mapping introduces variability input data ensures net trains data set 
psychological interpretation process networks subjects exposed roughly language data significant amounts noise 
test claim representing information topographic maps generates accurate predictions priming 
specific random mapping semantic space vectors dimensional space matrix zero mean normally distributed elements 
column normalized unit length create non orthogonal basis 
give idea structure preserved random mapping kaski shown inner product low dimensional projections rh rh high dimensional unit length vectors approximately 
result essentially defines error bar similarity estimates low dimensional space relative real values intuitively surprising similarities average preserved completely random mapping phenomena deserves attention 
generative topographic mapping gtm non linear extension factor analysis strong similarities self organizing map 
attempts build generative model variance structure see kaski error estimates non normalized high dimensional vectors detailed derivation 
data points assumption generated smooth non linear mapping dimensional manifold gtm explicitly assumes intrinsic dimensionality data dimensional manifold structure simply noise 
clearly extremely strong falsifiable assumption dimensional data 
gtm defines mapping low dimensional latent space data space straightforward invert mapping data point obtain 
mean distribution point estimate point latent space generated respect model similarly factor analysis 
specific predictions priming effects compute posterior means described related prime unrelated prime target vector 
mean element vector describes point dimensional space 
take cosine measures reduced space just high dimensional model 
results associated non associated related unrelated related unrelated cat 
coord 
functional table mean cosine similarity measures networks moss data independently chosen unrelated baseline 
bold numbers priming effects semantic category association 
mean similarity measures shown table 
main effect relatedness 
reliable effect association replicating associative priming effect 
associative boost significant subjects 
main effects semantic relatedness associated non associated conditions 
category coordinates showed semantic priming effect associative priming effect 
associative boost appeared analysis due surprisingly large priming effect artifacts 
semantic priming functional relations 
associative priming significant subjects marginally significant items analysis associative boost significant subjects approached significance items analysis 
separate analyses semantic subtype reported 
discussion table shows low dimensional simulation gave results similar original experiment replication high dimensions 
typically case dimensionality reduction related items similar 
seen table priming effects larger unrelated baseline essentially unchanged 
reduction brings previously weak trends data fact non associated semantic priming effects stronger category coordinates instrument relations require association prime strongly 

eigenvalues covariance matrix high dimensional semantic space vectors ordered size 
experiment suggests intrinsic dimensionality semantic space data quite low 
complementary way see look linear measures variance structure 
shows eigenvalues covariance matrix high dimensional data sorted size 
clear majority data variance extends directions 
handful values contain total variance 
way understand consider linear reconstructions data handful real numbers representing data projections principal eigenvectors necessary reconstruct data accuracy 
looking orthogonal directions variance useful baseline understanding success gtm intrinsic dimensionality data smaller linear estimate suggest 
hand procedure approximate interpretation eigenvalue structure terms variance component holds jointly normally distributed data 
assumption hold exactly semantic space vector elements 
case interesting compare landauer dumais claim dimensions necessary semantic space 
possible tasks require significantly different dimensionality spaces fairly detailed priming studies 
replicating landauer dumais tasks current framework current 
clearly case data 
shown priming results captured low dimensional models 
studies support claim dimensionality human semantic space may low 
daniel dennett supporting anonymous reviewers helpful comments 

agresti 

categorical data analysis 
john wiley sons 

bishop williams 

gtm generative topographic mapping 
neural computation 

burgess lund 

explorations context space words sentences discourse 
discourse processes 

dunlop 

encoding british national corpus 
papers thirteenth international conference english language research computerized corpora 

willshaw 

elastic net model ocular dominance stripe pattern monocular deprivation 
neural computation 

kaski 

dimensionality reduction random mapping fast similarity computation clustering 
proceedings international joint conference neural networks pages 

kohonen 

self organizing maps 
springer berlin 

lafferty sleator temperley 

grammatical trigrams probabilistic model link grammar 
technical report cmu school computer science 

landauer dumais 

solution plato problem latent semantic analysis theory induction representation knowledge 
psychological review 

lowe 

meaning mental lexicon 
proceedings th international joint conference artificial intelligence pages san francisco 
morgan kaufmann 

lowe 

semantic representation priming self organizing lexicon 
houghton editors proceedings fourth neural computation psychology workshop connectionist representations pages london 
springer verlag 

lowe 

topographic maps semantic space 
phd thesis institute adaptive neural computation division informatics edinburgh university 

lowe mcdonald 

direct route mediated priming semantic space 
gernsbacher editors proceedings nd annual meeting cognitive science society pages new jersey 
lawrence erlbaum associates 

lund burgess 

semantic associative priming high dimensional semantic space 
proceedings th annual conference cognitive science society pages 
mahwah nj lawrence erlbaum associates 

mcdonald lowe 

modelling functional priming associative boost 
gernsbacher editors proceedings th annual meeting cognitive science society pages new jersey 
lawrence erlbaum associates 

moss tyler marslen wilson 

accessing different types lexical semantic information evidence priming 
journal experimental psychology learning memory cognition 

ritter kohonen 

self organizing semantic maps 
biological cybernetics 

scholtes 

neural nets relevance information retrieval 
technical report cl university amsterdam institute language logic information department computational linguistics 
