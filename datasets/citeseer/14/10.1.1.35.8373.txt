fault tolerance scheduling aperiodic tasks hard real time multiprocessor systems ghosh rami melhem daniel moss department computer science university pittsburgh pittsburgh pa melhem cs pitt edu october keywords real time scheduling fault tolerance operating systems primary backup reliability redundancy real time systems increasingly applications time critical nature 
fault tolerance important requirement systems due catastrophic consequences tolerating faults 
study scheme provides fault tolerance scheduling real time multiprocessor systems 
schedule multiple copies dynamic aperiodic non preemptive tasks system techniques call deallocation overloading achieve high acceptance ratio percentage arriving tasks scheduled system 
compares performance scheme fault tolerant scheduling schemes determines deallocation overloading affects acceptance ratio tasks 
provides technique help real time system designers determine number processors required provide faulttolerance dynamic systems 
lastly formal model developed analysis systems uniform tasks 
basic concepts preliminary version analysis appeared supported part nsf ccr nsf cooperative agreement asc years computing systems applications stringent timing constraints autopilot systems satellite launch vehicle control 
result systems timing requirements increasingly studied researchers 
real time systems systems correctness depends logical functional behavior temporal properties behavior 
classified hard real time systems consequences missing deadline may catastrophic soft real time systems consequences relatively milder 
examples hard real time systems space stations radars tracking missiles systems monitoring patients critical condition examples soft real time tasks line transaction processors airline reservation systems banking tasks systems completed deadline value decreases 
real time applications fault tolerance important issue 
system faulttolerant produces correct results presence faults 
due critical nature tasks supported real time systems essential tasks complete deadlines presence processor failures 
fault tolerance inherent requirement hard real time systems 
multiprocessor system fault tolerance provided scheduling multiple copies tasks different processors 
primary backup pb approach triple modular redundancy tmr approach basic approaches allow multiple copies task scheduled different processors 
copies run ensure task completes deadline 
pb approach incorrect results generated primary task backup task activated 
tmr multiple copies usually run achieve error checking comparing results completion 
pb methodology advantage small hardware resource requirements capable masking faults 
noted approaches copies task scheduled timing constraints correct results generated task deadline presence faults 
study techniques providing fault tolerance non preemptive aperiodic real time tasks pb approach 
aperiodic tasks activated certain events occur non preemptive tasks interrupted execution tasks 
motivation non preemptive scheduling 
arrival times aperiodic tasks known priori scheduled dynamically arrive 
dynamic system scheduling tasks done tasks arrive 
contrasts static systems schedules tasks predetermined remain fixed system operation 
thrust study ways providing fault tolerance dynamic real time tasks develop advanced heuristic scheduling tasks 
proof concept simple slack dynamic scheduling algorithm schedule realtime tasks 
algorithm easily replaced complicated algorithm dynamic scheduling 
simplicity algorithm allows concentrate studying analyzing incorporation fault tolerance scheduling real time tasks 
motivation control applications strictly periodic examples systems aperiodic non preemptive hard real time tasks need scheduled providing faulttolerance 
describe 
consider multiprocessor system monitors condition patients intensive care unit hospital 
action taken soon patient condition changes 
example patient heartbeat rate decreases certain threshold corrective action taken injecting drug patient iv 
action taken certain hard deadline 
system ensure task executed deadline fault occurs processors 
second example consider space applications transient faults may occur board computers due electromagnetic interference 
real time tasks need executed faults occur 
third example flight control systems controllers activate tasks depending appears monitor 
point fault occurs system able recover deadline 
examples safety critical applications 
summarize real time tasks generated due events external system need scheduling algorithm dynamically schedule tasks 
system critical nature need fault tolerance schedule 
dynamic systems possible guarantee optimal performance arrival times known priori 
static approaches may suitable real time dynamic systems predictability required 
question need answer fault tolerance provided hard real time tasks arrival times known 
approach ensure processors system schedule multiple copies task peak load 
scheduling multiple copies fault tolerance provided 
approach minimum number processors required meet peak load needs determined 
finding number system load characteristics arriving tasks goals 
second approach reject tasks soon arrive guaranteed faulttolerance time inform user tasks rejected 
user take appropriate action rejection tasks 
instance hospital example described earlier system monitor patient critical condition due additional tasks generated nurse may required monitor patient 
system accepts monitoring tasks patient tasks executed timing constraints presence faults 
similarly airplane running autopilot experiencing wind turbulence additional tasks generated due disturbance executed providing fault tolerance pilot option manual control functions airplane navigational system 
possible approach user specify fault tolerance essential 
essential fault tolerance provided tasks arriving system possible 
example pb approach backup task scheduled may allow primary copy task scheduled system 
task scheduled inform user copies task primary scheduled 
user take necessary precaution copy task scheduled 
approach static nature provide fault tolerance dynamic real time tasks provided worst case combination arrivals known 
approaches dynamic nature adapt change parameters arriving tasks 
studies approaches knowledge guarantees fault tolerant dynamic non preemptive real time tasks 
remainder organized follows 
section representative previous done area real time fault tolerant scheduling existing fault detection mechanisms 
section describe problem 
section discuss general strategy solve problem 
section model scheduling uniform tasks system fault tolerance 
section extend model non uniform tasks algorithm fault tolerant scheduling tasks multiprocessor system 
simulation results section 
section discuss provide concluding remarks 
related related fault occurs extra time required task execution handle fault detection recovery 
real time systems particular essential extra time considered accounted prior execution 
methods explicitly developed fault tolerance real time systems take consideration number type faults ensure timing constraints violated 
section describe representative efforts direction 
fault tolerance typically approached hardware standpoint multiple replicas essential applications running separate hardware components 
hybrid approach proposed integrate software checks hardware computation cycles 
achieve fault masking permanent hardware faults redundant concurrent tasks may carry computations synchronously asynchronously 
approaches groups processes executing sequentially replicas execute parallel 
way providing fault tolerance scheduling 
scheduling algorithms developed real time tasks preemptive non preemptive systems 
general problem optimal scheduling tasks uniprocessor multiprocessor system np complete different heuristics schedule real time tasks aim maximizing performance measures acceptance ratio processor utilization 
heuristics attempted provide fault tolerance scheduling real time tasks 
fault tolerant scheduling algorithm proposed handle transient faults 
tasks assumed periodic copies task primary backup copy scheduled uniprocessor system 
restrictions approach period task multiple period preceding tasks 
assumes execution time backup copy shorter primary copy 
processor failures handled maintaining contingency backup schedules 
schedules event processor failure 
generate backup schedule assumed optimal schedule exists schedule enhanced addition ghost tasks function primarily standby tasks 
schedules permit additions scheme optimistic 
best effort approach provide fault tolerance discussed hard real time distributed computing systems 
primary backup scheme primary backup start execution simultaneously fault affects primary results backup 
scheme tries balance workload processor 
area multiprocessor systems fault tolerant scheduling strategy periodic tasks fault tolerant scheduling problem described 
strategy backup schedule created task primary schedule 
tasks rotated primary backup schedules different processors overlap 
possible tolerate processor failure worst case 
number processors required provide schedule tolerate single failure double number non fault tolerant schedule 
papers described algorithms static information tasks known scheduling 
studies generally concentrate analysis algorithms little done provide experimental simulation results 
concentrate fault tolerant scheduling non preemptive tasks real time systems 
reason short survey discussed systems built aim providing real time fault tolerance study scheduling specifically 
reason discussed scheduling techniques provide fault tolerance preemptive real time tasks 
fault tolerant scheduling problem section describe system fault task models 
introduce approach schedule dynamic real time tasks fault tolerance 
consider system consists identical processors assume task scheduling processor central controller maintains global schedule global shared memory test set instructions 
example system single node spring system 
faults need identified tolerated error detection essential 
approach error detection mechanisms developed various fault models ffl fail signal processors immediately notifies processors detected fault 
ffl alarms watchdogs detection timing failures assuming synchronized clocks 
ffl signatures detection hardware software faults 
ffl acceptance tests checks test results hardware software faults 
task modeled tuple ha arrival time ready time earliest start time task deadline maximum computation time assumption simplify presentation scheduling strategy implemented distributed schedulers 
fault tolerant scheduling problem called worst case execution time 
assume window task gamma twice large computation time 
assumption impossible schedule primary backup task time constraints 
define window ratio ratio task window computation time 
wr gammar assume tasks arrive dynamically system scheduled arrive 
ease presentation assume tasks independent precedence constraints 
tasks precedence constraints scheduled transforming precedence graph independent nodes new ready times deadlines 
example group tasks precedence constraints scheduled group ready time deadline computation time timing constraints 
task scheduled time remaining tasks group equal time task 
tasks immediately follow task scheduled process continued tasks scheduled scheduled 
task scheduled group rejected 
tasks scheduled system guaranteed complete processor fails instant time second processor fail system recovers failure 
completion guarantee assured task task rejected system try schedule task time 
permanent transient faults handled approach 
consider problem software faults correlated component failures 
deal faults scheduling processor ways failure processor handled 
scheduling processor duplicated prone failures 
solution schedule backups scheduling process processor system 
address fault tolerant scheduling problem primary backup approach 
task arrives system copies primary backup scheduled different processors task window 
backup copy task executes execution primary copy terminate correctly time fault detected backup activated 
assume dynamic systems possible release resources reserved backup copies tasks soon primary copies finish executing 
manner able better estimate system state available free time new tasks scheduled 
evaluate performance scheme compare results results single spare method processor allocated spare 
non spare develops fault tasks scheduled faulty processor executed spare 
simplicity description assumes backup copy primary 
scheduling strategy estimate overhead providing fault tolerance comparing system system provision fault tolerance call ft method 
case real time systems providing fault tolerance undesirable due possibility catastrophic consequences fault occurs 
comparison schemes performance technique terms acceptance ratio resiliency 
define acceptance ratio percentage arriving tasks accepted system scheduled fault tolerance 
rejection ratio defined ratio percentage arriving tasks rejected system 
note accepted task resources reserved accepted system guaranteed execute 
resiliency defined ability system recover fault resume normal operation fault occurs 
scheduling strategy scheduling scheme observations 
real time systems tasks memory resident time execution time taken fetch tasks secondary storage usually predictable 

processor functioning spare idle life time system faults occur 

hard real time systems reservation resources backup copies ensured backup copies different scheduling strategy primaries 
second observations steered away single spare processor approach 
comply real time constraints spare processor maintain main memory tasks system 
necessary condition tasks able execute timely fashion case processor fails 
implies scheduling algorithm take consideration total memory requirements tasks consider time load tasks executed case failures 
strain particular processor tasks loaded processor memory 
notice dedicated spare processor approach spare processor executing tasks intervals fault free operation 
wasted processor time task executed concurrently guarantee backup tasks executed needed 
third observation resources reserved backup copies re utilized motivated apply techniques achieve high acceptance ratio providing scheduling strategy fault tolerance ffl backup overloading scheduling backup time slot processor overlapping multiple backups 
ffl backup deallocation reclamation resources reserved backup tasks corresponding primaries complete successfully 
primary backup copies task referred simply primary pr backup bk 
time intervals primary backup copies scheduled called primary backup time slots respectively 
backup copies task scheduled run time slot processor backup slot said overloaded 
backups gamma tasks running different processors overloaded slot processor fail time 
concept overloading explained studied sections 
advantages scheme single spare scheme follows ffl show see section performance scheme better single spare scheme terms acceptance ratio 
ffl faults occur time interval backups re utilized backup deallocation example known backup task scheduled backup executed 
new tasks arrive scheduled currently running task 
difficult equivalent deallocation spare processor 
clear spare deallocated keeping track slots spare 
worst task running spare backup backups scheduled spare processor 
ffl due scheduling algorithm predictability increased 
spare scheme spare execute primaries decision task run spare runtime 
scheme task executed lieu deallocated backup known scheduling time 
ffl mentioned earlier scheme processors uniform memory requirements 
scheme provides symmetry respect memory requirements may aid reconfigurations needed desired 
advantages spare scheme overhead evaluated 
note scheduling primary backup tasks significantly increase running scheduling strategy time scheduling algorithm 
time proportional task window average execution time tasks 
applications window ratio tasks leads believe implementation scheme costly 
furthermore terms algorithm complexity cost searching schedule backup searching search tasks schedule primary 
nomenclature follows pr bk processor scheduled execute beg scheduled time scheduled time time interval slot scheduled 
notation necessary conditions tolerating single fault real time systems described follows pr bk scheduled task beg beg slot bk slot pr beg bk pr pr bk scheduled different processors tolerate permanent faults pr bk pr pr scheduled processor bk bk overlap processor tolerate permanent faults bk bk bk bk pr pr required primary backup copies satisfy task timing constraints 
needed assumed backup executed failure primary detected failure detected primary finishes executing 
condition relaxed backups executed parallel primary 
dynamic system preferable conserve processor time possible tasks arrive prefer execute backups primary fails 
ensures primary backup copies scheduled processor 
copies deadlines processor scheduled fails 
clearly transient faults overly conservative primary backup copies scheduling strategy scheduled processor 
possible execute backups tasks failure occurs processor primaries scheduled 
resiliency system defined section measured terms time takes system able tolerate second fault fault occurs processor call latency time time second fault 
time maximum time backups primaries scheduled backups processor time primary tasks processors backups example primary pr scheduled backup bk fault occurs pr executes tolerate fault bk completes 
second fault occurs bk bk copies lost 
similar logic tolerate second fault pr completes 
maximum combinations gives time tolerate second fault system 
argument formalized theorem fault pr pr pr bk bk bk overloaded portion backup legend primary backup tolerating second fault theorem permanent fault occurs time processor pb system able tolerate fault occurs time maxf max bk pr max pr bk proof permanent fault occurs time task arriving scheduled primary backup gamma non faulty processors 
tasks guaranteed complete second fault occurs 
task scheduled fault occurs consider cases 
pr bk case restriction guarantees bk pr respectively successfully execute second fault occurs 
part scheduling uniform tasks restriction guarantees second fault occur backups primary faulty processor executed 
second part ensures second fault occurs primaries backups faulty processor executed 

pr bk case guaranteed complete second fault occurs bk overlaps backup bk primary pr scheduled example 
due fault bk activated bk overlaps bk 
second fault tolerated pr pr executed 
case covered second part restriction second fault tolerated bk executed 
bk bk overlap pr scheduled earlier bk system 
means second fault tolerated pr completes proof case 
section uniform task model time discretized tasks unit length 
model amenable markov analysis approximation practical systems tasks non uniform 
section non uniform task model time continuous tasks variable lengths 
model amenable markov analysis simulations evaluate 
scheduling uniform tasks section assume tasks uniform worst case execution time tasks arrive unit time scheduled time unit 
unit length tasks backup slots may easily overloaded backup tasks length 
fact simple backup pre allocation policy reserve slot backup time slots processor 
backup slots processors staggered 
backup slot pre allocated time processor backup slot pre allocated time processor mod pre allocation allows simple assignment backups tasks way satisfies conditions 
specifically backup slot pre allocated time task scheduled run time gamma slot backup 
task scheduled run time gamma backup slot processor condition task backup slot time mod words task bk scheduled time slot immediately pr probability gamma gamma scheduled slots pr probability gamma note scheme gamma backup tasks potentially overloaded backup slot 
gamma primary tasks scheduling uniform tasks may scheduled backup slots processor backups different processors 
staggered backup slots multiprocessor system staggering backups equivalent spare processor created processors system 
mentioned section advantages scheme memory requirements processors uniform processors leading higher acceptance ratio task executed lieu deallocated backup known scheduling time 
staggering backups uniform task model closely approximate general model deallocation overloading achieving advantages 
example memory requirements uniform task case consider system processors 
consider consecutive unit time slots system 
processor spare processor maintain tasks memory time units processors need 
hand backups staggered processor maintain tasks memory primary tasks backup tasks 
pre allocation backups described may decrease acceptance ratio tasks primary tasks may scheduled slots reserved backups 
order estimate loss acceptance ratio caused addition fault tolerance capability backup slots consider simple come served scheduling primary tasks 
scheduling policy equivalent maintaining task queue arriving tasks appended 
gamma tasks scheduled time slot position task indicates scheduled execution time 
time slot task th task scheduled execute time slot gamma task arrives time acceptance probability depends length window task appended position gamma primary task pr guaranteed execute time task schedulable deadline 
gamma bk guaranteed execute dynamics system may modeled markov process 
simplicity presentation start modeling system deadlines system tasks slot reserved backups 
scheduling uniform tasks rejected 
system may modeled linear markov chain state represents number tasks transition represents change length time unit 
assume maximum max tasks arrive system unit time ar probability tasks arrive unit time 
probabilities different transitions may calculated rate task arrival 
specifically represents state contains tasks gamma probability transition gamma gamma ar 
max time unit gamma tasks consumed queue new tasks arrive probability ar 
gamma tasks consumed ar probability transition example shows transitions markov chain assuming max arrivals uniformly distributed 
transitions state linear chain arriving tasks finite window sizes tasks may rejected 
probability tasks rejected queue size value probability window task smaller gamma ffi ffi extra time needed schedule backup equal probability gamma gamma gamma respectively 
queue size probability rej arriving tasks rejected rej gamma gammar number possible ways select objects 
transitions state current queue length states gamman gamma amax gamman number tasks consumed gamma gamma 
probability transition gamman probability task arrives incoming tasks rejected 
probability equal amax rej 
general transition state state occurs tasks arrive amax gamma gamma tasks rejected adding newly accepted tasks system 
increases queue length tasks consumed queue 
probability transition scheduling non uniform tasks amax ar theta rej gamma gamma gamman 
amax gamma transition probabilities known calculate steady state probabilities state gamma max largest possible value queue 
steady state probabilities state known calculate rate rejection tasks equation number rejected tasks amax theta ar gamma gamma theta gamma theta part equation right side average number tasks arriving system unit time second part average number tasks consumed executed system unit time 
considered backup deallocation model 
backup deallocation means time fault occurred backup pre allocated time slot may schedule new task 
words tasks arrive slot tasks scheduled deallocated backup slot remaining gamma tasks treated 
define effective arrival rate ar ar ar ar ar compute transition probabilities equation ar replaced ar compute number rejected tasks equation ar replaced ar consider ar probability arriving task window uniformly distributed plot rate task rejection window ratios function number processors case max uniformly distributed backup deallocation 
decrease rejection ratio due backup deallocation clear 
note schedulability point view dedicating processors spare equivalent staggering backup slots processors slots deallocated 
looked comparison strategy spare method 
scheduling non uniform tasks task model scheduling section enhance model previous section respect execution times tasks 
consider case execution times tasks variable task scheduling non uniform tasks number processors processor load window ratio window ratio window ratio window ratio rejection ratio function number processors scheduled soon arrives 
execution times tasks fixed possible pre allocate backup tasks section 
analysis systems complex 
heuristic scheduling tasks arriving dynamically evaluate heuristic simulations 
new task arrives primary backup scheduled 
schedule primary early possible task window schedule backup task deadline 
primary task completes successfully corresponding backup deallocated 
primary backup scheduled primary finishes backup deallocated list existing slots updated 
list maintained central controller schedule tasks arriving 
example consider simple schedule tasks shown 
tasks assumed bk bk overloaded backup slot 
bk overloaded bk earlier time bk scheduled earlier task arrived 
backups overlap primary copies scheduled processor 
pr scheduled processor earliest possible schedule 
modification initial schedule shown completion tasks order causes deallocation respective backups 
arrival tasks causes modifications schedule 
bk overloaded bk due scheduling non uniform tasks primary primary backup backup primary time backup processor processor primary legend rescheduling task case primary fails backup copy task ready time deadline time dark part overloaded computation window task processor scheduled backup deadline scheduled early possible primary scheduling tasks processors processor backup primary processor processor backup primary completion tasks deallocation respective backups 
deallocation bk pr scheduled processor 
algorithm schedules primary scheduling corresponding backup difficult schedule primary backup want minimize number scheduling non uniform tasks backup proc proc primary primary primary backup primary backup proc new schedule arrival tasks constraints scheduling primary 
scheduling backup easier overload existing backups simply schedule available free slot 
backup scheduled added constraints schedule primary time primary earlier time backup mentioned earlier processor scheduling primary 
schedule primary backup processor condition 
constraint effect try schedule backup scheduling primary overload existing backups option exist primaries 
choices available schedule backup primary 
schedule primary early possible processor ensure maximum possible time span schedule backup 
system central controller existence global schedule easy determine earliest possible schedule primary 
schedule choose primary may affect acceptance probability backup task 
instance assume find earliest possible schedule primary processor call schedule may possible schedule backup task space backup order solve problem find second earliest schedule primary processor call schedule schedule backup look schedule backup primary 
solution complete 
specifically cases schedule backup backup scheduled primary scheduled processor show solution complete scheduling non uniform tasks assume pr processors interval bk scheduled processors contains backups primaries scheduled case schedule pr overload bk existing backups violate condition overload bk processors 
schedule pr overload bk violating condition 
solution complete find schedule primary processor try schedule backup primary schedule 
keeping track possible schedules primary increase scheduling costs considered simulation earliest second earliest schedules primary trying schedule backup 
similar approximation approach suggested focussed addressing scheme 
steps schedule task section scheduling algorithm 
primary task scheduled follows look processor find pr scheduled free slot larger processor know pr scheduled pr scheduled overlapping time slot slot check reschedule slot done checking slack slot slack defined maximum time start task delayed completes executing deadline 
function slack slack pr min beg slack beg bk gamma pr slack bk primary backup pr slack slot added preceding free slot greater pr scheduled shifting slot forward 
motivated earlier consider earliest tentative schedules different processors 
consider different possibility scheduling backup 
schedule backup may choices schedule late possible overload possible task deadline 
schedule backup late possible maximize chances space occupied backup schedule deallocated 
backup deallocated soon primary completes backup scheduled far away primary possible time available deallocated new tasks arriving may able space 
situation acceptance ratio increases 
option overloading available previous backups scheduling non uniform tasks scheduled prefer schedule late possible 
option overload backup possible 
increases acceptance ratio processor time reserved backups minimized time available schedule new tasks 
options available may able time 
try maximize overloading backups may scheduled late possible vice versa 
find factor overloading deallocation effective increasing acceptance ratio schedule backup cost function maximized cost backup theta overlap length overlap length length intersection new backup backup scheduled 
overloading overlap length zero 
user choose value infinity yield scheduling disciplines ranging scheduling backups late possible overloading possible 
scheduling time value fixed 
backup task scheduled follows earliest schedule primary processor examine possible schedules backup processors permanent faults 
depending value overload backup possible schedule late possible follow policy middle extremes 
maintain forward slacks primary slots allow moved forward necessary backup slots moved 
backup slot may supporting primary backup slot moved slacks primaries change 
may cascading effect movement backup slot costly terms time spent recalculate slacks 
possible schedule backup task earliest schedule look task second earliest schedule try schedule backup 
task committed follows schedules primary backup commit task 
guarantee task completed deadline presence single fault 
insert primary backup global schedule maintained central controller 
note slacks need recalculated processors new slots scheduled 
summarize steps schedule task 
find schedule primary early possible task window 

find schedule backup corresponding primary schedule step chosen heuristic late possible maximize overloading 

commit task guarantee meet deadline presence single fault 
scheduling non uniform tasks example simple schedule tasks shown 
tasks scheduled backups scheduled respectively 
note chose schedule tasks latest completion time deadlines 
consider fourth task bk scheduled processor earliest possible schedule task 
attempt schedule backup bk pr pr bk bk bk pr pr scheduling tasks processors 
black boxes depict possible schedules bk note backup scheduled processors primary processor backup placed processor 
question time processor schedule backup 
show depends parameter algorithm 
base example equation 
results tasks value shown table 
select specific positions bk complete partial overload illustrate possibilities heuristic works 
table highlighted cost chosen 
proc cost eq theta theta theta table cost scheduling different positions different processors different values notice value location backup different 
ranges remember task represented arrival time ready time computation time deadline 
simulation values weight influence scheduling backups 
situations depend task set current schedule 
example scheduling bk times processor yield cost 
algorithm maximum number comparisons done new task depends number tasks scheduled system 
average case depends average window ratio tasks system 
larger window ratio number tasks scheduled system larger number potential comparisons 
average number comparisons task average window ratio tasks theta number processors worst case may try fit incoming task pair existing slots scheduled system 
case total number comparisons equal number tasks system 
number bounded assume rate incoming outgoing tasks tasks completed execution average 
interval need compare incoming task scheduled tasks shift forward time average length interval remain constant 
runtime behavior tasks arrive system copies task primary backup scheduled 
primary executing faults occur processor primary scheduled primary run completion 
case backup deallocated newly generated free slot available scheduling task arrives deallocation 
results increase acceptance ratio 
permanent fault processor backups primaries scheduled running processor executed respective backups 
task arrives fault primary backup copies scheduled remaining non faulty processors 
second fault tolerated system settles explained theorem 
case transient fault soon fault detected backup copy currently executing primary activated 
tasks remain scheduled 
simulation study scheduling algorithm performed number simulations 
goals simulations follows simulation ffl compare acceptance ratio fault tolerant algorithm described section ft method 
fault tolerance capability schedule generated algorithm comes cost increasing number rejected tasks 
comparison estimate cost increased rejection 
ffl compare acceptance ratio scheme single spare method 
note spare method equivalent having backup copies primaries implicitly scheduled spare processor 
ffl find number processors needed schedule copies task system system load task characteristics 
result useful statically determining number processors required real time system 
ffl measure effect weight acceptance ratio 
tells preferable overload backup schedule late possible 
ffl measure time system tolerate second fault 
tells quickly system completely recover fault measure resiliency system 
ffl measure effect overloading deallocation individually acceptance ratio 
tells technique predominant effect acceptance ratio 
simulator simulation parameters evaluation done implementing discrete event simulator events driving simulation arrival start completion task occurrence faults 
generated task sets computation schedules ran different policies task sets 
note spare ft methods tasks scheduled algorithm primary copies method 
number processors weight simulation parameters controlled ffl average computation time computation time arriving tasks assumed uniformly distributed mean ffl processor load fl parameter represents average percentage processor time utilized tasks real time constraints fault tolerance requirements 
larger fl values leads smaller task inter arrival time 
specifically inter arrival time tasks assumed uniformly distributed mean ff fl 
simulation ffl average window ratio wr parameter defined section uniformly distributed mean wr minimum value wr task schedule copies task window 
ran simulations task sets tasks 
set parameters generated task sets calculated average results generated 
consistent model assumed yielding dynamic system 
formally gamma ff ff interval successive arrivals 
processor load ranges zero fl 
example fl task inter arrival rate 
means average task arrives system unit time processor load processors 
parameters summarized table 
compute fault injected arbitrarily chosen time instant theorem applied compute repeat experiment times average results obtain mean 
parameter name distribution values assumed number tasks fixed number processors fixed 
computation time uniform mean processor load fl uniform mean 
inter arrival time ff uniform mean fl window ratio wr uniform mean weight fixed table parameters simulations results analysis plot rejection ratio tasks method function processor load keeping number processors system constant 
expected rejection ratio increases increase processor load 
see due pb approach deallocation technique rejection ratio decreases window ratio increases 
compare rejection ratio schemes spare scheme scheme fault tolerance ft scheme different number processors 
ft scheme backups spares spare scheme primaries scheduled algorithm scheme backups implicitly scheduled spare processor 
note simulation processor load processors window ratio window ratio window ratio window ratio window ratio rejection ratio function processor load different windows ratios number processors processor load weight ft win ratio ft win ratio ft win ratio spr win ratio spr win ratio spr win ratio win ratio win ratio win ratio rejection ratio function processor load spare ft schemes scheme consistently performs better single spare scheme values window ratios 
mainly algorithm uses deallocation helps resource reserved earlier tasks completed 
tells dynamic systems simulation costly terms acceptance ratio provide fault tolerance pb approach single spare approach 
weight processor load window ratio procs win ratio procs win ratio procs win ratio procs win ratio procs win ratio procs win ratio versus weight different window ratios number processors rejection ratio algorithm close rejection ratio ft method 
means price pay provide fault tolerance quite low 
low cost due deallocation explained previous paragraph overloading minimizes amount resources reserved backups 
low cost providing fault tolerance algorithm useful practical purposes 
studied effect different values 
weight acceptance ratio 
small window ratios optimal weight larger window ratios maximum acceptance ratio obtained 
variation different weights relatively small 
instance window ratio equal processor load equal rejection ratio processors varies 
higher values window ratio difference smaller 
consider weight conjunction time second fault see weight little influence larger window ratio larger expected larger window ratio increases length schedule 
small sensitivity rejection ratio weight indicates simulation number processors weight window ratio window ratio window ratio window ratio window ratio window ratio window ratio window ratio task rejection rejection ratio different number processors varying system loads position backup task little influence acceptance ratio tasks 
means simple strategy scheduling backups complex policy increases run time scheduling algorithm 
fact noting best results obtained simple policy scheduling backups late possible recommended 
worst case equal maximum possible window tasks arriving system 
smaller mean time failure mttf processors safely say handle multiple faults system 
time th fault occurs tolerated th fault ready th plot rejection ratio different values system load 
system load fixed parameter inversely proportional inter arrival rate ff 
computed product processor load number processors fl theta 
example system load processor load processors processors processors 
system load statically determine number processors needed support dynamic real time tasks providing fault tolerance 
example see constant system load rejection ratio decreases number processors increases 
user requires rejection ratio system load simulation seen graph processors needed average window ratio greater processors needed average window ratio 
similarly number processors needed determined rejection ratio task characteristics 
number processors processor load window ratio technique overloading weight overloading weight deallocation techniques weight techniques weight rejection ratio function number processors different techniques show effect overloading deallocation acceptance ratio task sets plotted number processors 
shows varying rejection ratios overloading deallocation techniques 
note overloading overloading compare results 
clear method significantly improves acceptance ratio task sets difference deallocation techniques shows drastic improvement 
deallocation conjunction scheduling backups late possible causes time reserved backups reused 
processors utilized fullest extent possible scheduling backups primary 
overloading help case 
leads believe deallocation scheduling real time fault tolerant tasks enhance acceptance ratio gained overloading deallocation 
show results similar behavior exhibited processor load smaller larger 
concluding remarks concluding remarks developed analyzed fault tolerant scheduling method real time systems tolerates processor faults 
show overloading deallocation backup slots provide efficient utilization resources 
results show positive correlation acceptance ratio task sets load system acceptance ratio average task window ratio 
theoretical simulation results indicate reclaiming resources reserved backup tasks deallocation important factor scheduling tasks primary backup fashion 
backup deallocation elaborate methods increasing overloading backups small effect acceptance ratio resiliency 
fast simple scheduling algorithms backups 
method tolerate processor failure 
stands scheme tolerate successive permanent faults separated sufficiently large time interval 
time second failure system established easy relate mean time failure mttf reliability processors 
goal guarantee fraction mttf tasks existing time failure complete 
new tasks arriving failure primary backup copies scheduled non faulty processors second fault handled 
handle multiple simultaneous faults schedule backup copies task 
case resiliency overhead system increase 
note scheduling policy case different mechanisms developed remain 
currently extending scheduling algorithm distributed systems communication costs taken account 
plan study hybrid technique combining pb approach triple modular redundancy multiprocessor systems 
scheduling copies task system 
plan study fault tolerance scheduling tasks precedence resource constraints 
lawrence jenkins goel 
workload redistribution fault tolerance hard real time distributed computing system 
ieee fault tolerance computing symposium ftcs pages 
bertossi mancini 
scheduling algorithms fault tolerance hard real time systems 
technical report tr univ pisa corso italia pisa italy 
eric cooper 
replicated distributed programs 
acm editor th acm symp oper syst principles pages 
acm dec 
mok 
multiprocessor line scheduling hard real time tasks 
ieee trans 
soft 
eng dec 
stankovic 
dynamic guarantees distributed real time systems 
real time systems symposium 
garey johnson 
computers intractability guide theory npcompleteness 
freeman san francisco 
ghosh rami melhem daniel moss 
fault tolerant scheduling hard real time multiprocessor system 
international parallel processing symposium april 
jeffay martel 
non preemptive scheduling periodic sporadic tasks 
proc 
ieee real time syst 
symp pages december 
barry johnson 
design analysis fault tolerant digital systems 
addison wesley pub 

walter finn 
architecture distributed fault tolerance 
ieee trans computers april 
kim andreas damm 
fault tolerance approaches experimental real time systems 
seventh workshop real time operating systems software pages 
ieee may 
kopetz damm ch 
koza ch 

distributed fault tolerant real time systems mars approach 
ieee micro feb 
krishna kang shin 
scheduling tasks quick recovery failure 
ieee trans computers may 
harper 
architectural principles safety critical real time applications 
proceedings ieee jan 
campbell 
fault tolerant scheduling problem 
trans software engineering se nov 
mok 
multiprocessor scheduling hard real time environment 
texas conference computing systems 
ieee 
watson 
real time system scenarios 
th real time systems symposium pages lake vista fl dec 
ieee 
daniel moss rami melhem ghosh 
analysis fault tolerant multiprocessor scheduling algorithm 
th int symposium fault tolerant computing austin tx june 
ieee 
oh 
fault tolerant adaptive real time distributed systems 
external technical report department computing information science queen university kingston ontario canada january 
oh sang son 
multiprocessor support real time fault tolerant scheduling 
ieee workshop architectural aspects real time systems pages san antonio tx dec 
oh sang son 
fault tolerant real time multiprocessor scheduling 
technical report tr university virginia april 
mihir malek 
minimum achievable utilization fault tolerant processing periodic tasks 
technical report tr univ texas austin dept computer science 
pradhan 
fault tolerant computing theory techniques 
prentice hall nj 
ramamritham stankovic 
scheduling algorithms operating systems support real time systems 
proceedings ieee jan 
ramamritham 
dynamic task scheduling hard real time distributed systems 
ieee software pages july 
ramos 
transient server approach scheduling time critical recovery operations 
real time systems symposium pages san antonio tx dec 
randell 
system structure software fault tolerance 
ieee trans 
software engineering se june 
robert david 
application rate monotonic algorithm signal processing systems 
real time systems symposium development sessions 
shin ramanathan 
real time computing new discipline computer science engineering 
proceedings ieee jan 
stankovic ramamritham 
spring kernel new paradigm real time operating systems 
acm sigops operating systems review july 
tsuchiya 
fault tolerant scheduling algorithm distributed realtime systems 
third workshop parallel distributed real time systems 
weber 
operating systems enhancements fault tolerant dual processor structure control industrial process 
software practice experience may 
sift design analysis fault tolerant computer aircraft control 
proc 
ieee pages 
ieee oct 
craig 
local non preemptive scheduling policies hard real time distributed systems 
real time systems symposium pages 
ieee 
zhao ramamritham 
distributed scheduling bidding focused addressing 
proc 
ieee real time syst 
symp pages dec 
zhao ramamritham stankovic 
scheduling tasks resource requirements hard real time system 
ieee trans 
soft 
eng se may 
