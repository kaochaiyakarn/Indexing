appear international journal parallel programming special issue instruction loop level parallelism vectorizing compiler multimedia extensions microsoft supercomputer education research centre microsoft way dept computer science automation redmond wa indian institute science bangalore india microsoft com ernet implementation vectorizing compiler intel mmx multimedia extension 
compiler identify data parallel sections code scalar array dependence analysis 
enhance scope application subword semantics compiler performs code transformations 
include strip mining scalar expansion grouping reduction loop distribution 
inline assembly instructions corresponding data parallel sections generated 
stanford university intermediate format suif public domain compiler tool implementation 
evaluated performance code generated compiler number benchmarks 
initial performance results reveal compiler generated code produces reasonable performance improvement speedup code generated vectorizing transformations inline assembly 
certain cases performance compiler generated code hand tuned code mmx architecture 
key words mmx instruction set subword parallelism vectorizing compiler 
reported done author dept computer science automation indian institute science bangalore india 
multimedia integration visual video images animation audio music speech textual information 
basically information represented di erent ways di erent media data types 
media processing decoding encoding interpretation enhancement rendering digital multimedia information 
information typically form large volumes low precision short data types 
large volume data compression necessary step storage 
translates computational burden real time retrieval data 
late media processing applications dominating personal computing domain 
characterized small native data types large data set sizes large amount inherent data parallelism computationally intensive features multiple concurrent media streams large requirements applications traditionally supported special purpose chips known media processors rise fraction applications necessary enhance performance preferably increase cost support special hardware 
high computational demand short data types media applications ectively addressed modern processors subword parallelism 
subword parallelism speci instance data parallelism data word data set 
subword parallelism exhibited instructions act set lower precision data packed word resulting parallel processing data set 
current processors support bit words 
intel processors support bit words bit oating point units 
word size processors determines width general purpose registers data paths integer address calculations 
large word size facilitates higher precision arithmetic 
subword parallelism allows processor exploit large word size handling high precision data 
illustrates addition instruction exploiting subword parallelism 
instruction take amount clock cycles traditional add instruction ectively performs operations parallel bit data operands 
order support exploit subword parallelism modern processors extend instruction set architecture 
extensions popularly referred multimedia extensions accommodated processors vendors intel mmx multimedia extension sun vis visual instruction set hewlett packard max multimedia acceleration extension powerpc altivec 
instruction applies data elements word form small scale simd single instruction multiple data 
packed add application written high level language bene extensions isa compiler generates object code making instructions 
unfortunately case subword parallelism 
vectorization technique traditionally compilers vector simd machines applied purpose 
simple terms vectorizing compiler identi es instructions loop successive instances executed parallel ecting semantics program 
absence compiler support subword parallelism application programmer currently forced write application assembly level tedious error prone 
support extensions come vendors form enhanced system libraries selected library routines hand coded assembly exploit extended set instructions 
macro calls extended set instructions system header les de ne set macros provide higher level interface extended set instructions 
case hardware supported enhanced libraries programmer system version function calls exploits subword parallelism function 
loses certain opportunity vectorizing compiler achieve 
example inlining function may improve parallelism reduce function overhead 
compiler may able exploit enhanced parallelism inlining possible hardware enhanced library functions source code available 
macro calls program exploit subword parallelism require user aware code segment optimized multimedia extensions macros provided 
code transformations performed manually 
lastly programming macro calls hard assembly equivalent 
reasons strongly motivate need vectorizing compiler general approach exploiting subword parallelism 
supporting di erent architectures changes multimedia instruction set approach require modi cations code generation module 
allows easy portability application 
lastly compiler support approach process vectorizing transparent user reduce errors associated assembly coding improve performance applications 
designed implemented source source vectorizing compiler intel mmx 
compiler takes source le input 
various code transformations strip mining scalar expansion condition distribution applied 
output source le data parallel sections coded inline assembly 
allows rest code optimized native compiler leveraging optimization techniques implemented production compilers 
vectorizing compiler supports conditional constructs performs expression reduction 
stanford university intermediate format suif public domain compiler tool implementation 
evaluated performance code generated compiler number benchmarks kernels multimedia applications 
initial performance results reveal compiler generated code produces reasonable performance improvement speedup code generated vectorizing transformations inline assembly 
certain cases compiler generated code performance code code mmx architecture 
rest organized follows 
section necessary background required vectorization techniques multimedia extension 
section discusses vectorization techniques applied mmx 
section results obtained multimedia kernels 
discuss related works section 
concluding remarks directions provided section 
background section provides background required understand rest 
dependence relations control ow program represented control flow graph directed graph node statement sequence statements level abstraction edge represents control transfers pair nodes 
control dependence derived control ow graph restricts order execution statements program 
statement may may executed execution statement represents statement control dependent statements said data dependent access location accesses write 
data dependences represented data dependence graph nodes statements program directed edges represent dependences 
data dependences henceforth referred simply dependences classi ed true dependence ii anti dependence iii output dependence 
arcs data dependence graph classi ed forward backward arcs 
arc dependence said lexically forward follows program order said lexically backward follows program order 
long control ows program sequence dependence arcs lexically forward control transfers program sequence case loop introduce lexically backward arcs 
consider example code shown 
dependence graph code shown solid lines represent data dependences dotted lines control ow 
seen arc lexically forward arc lexically backward 
array elements typically de ned statements loop 
statements usually executed 
necessary talk instances execution statement 
instances identi ed iteration vector 
index variable iteration vector iteration vector form 

values loop indices enclosing statement ordered outer inner 
discussion consider normalized loops loops indices run unit loop index increment stride sake simplicity 
suif compiler framework takes care normalizing loops 


endfor endfor ddg cfg example code data dependence control flow graphs example normalized iteration vectors statement 



consider data dependence example 
seen dependence absence enclosing loops 
dependence said loop carried 
precisely data dependence said loop carried value produced statement current iteration statement iteration 
dependence arises pair di erent iteration vectors say access memory location 
dependence analysis studied extensively literature details summarized 
lastly level dependence de ned loop nest level numbered outermost innermost carries dependence 
dependence arc associated kind true anti output dependence direction lexically forward lexically backward level enclosing loop cause dependence distance separation distance level dependence valid constant 
data dependence graph rst attributes represented 
direction represented means directed arc attributes augmented arc symbol represents level dependence represents kind dependence rue 
brie review stanford university intermediate form suif compiler framework implementation 
suif compiler framework suif stanford university intermediate format compiler system platform research compiler techniques high performance machines 
suif research compiler experimenting developing new compiler algorithms 
fosters code reuse sharing modularity 
compiler structured small kernel plus toolkit consisting various compilation analysis optimizations built kernel 
kernel performs major functions de nes intermediate representation programs program representation designed support high level program restructuring transformations lowlevel analyses optimizations 
supports set program manipulation primitives routines performing transformations 
structure interface di erent compiler passes compilation passes implemented separate programs communicate les termed suif les 
suif les output format passes reordered simply running programs di erent order 
di erent passes communicate annotating program representation 
suif kernel provides object oriented implementation suif intermediate format 
intermediate format mixed level program representation 
low level constructs suif instructions representation includes high level constructs loops conditional statements array access operations 
suif passes scc driver suif ansi fortran compiler 
various transformations suif code 
purpose transformations allow subsequent passes simplifying assumptions assumption branches loop body try rearrange code easier subsequent passes get information getting rid particular construct 
read speci ed suif le print translation standard language 
augmented pass print inline assembly code data parallel sections 
intel mmx section overview intel mmx multimedia extension di erent facets register stack data types supported instruction set 
multimedia registers mmx register set consists bit registers aliased registers register stack 
mmx instructions access registers directly register names mm mm 
operating mmx mode aliasing mechanism ensure accessing registers oating point units result number 
multimedia data types intel introduced new bit quantities packed bytes bytes packed bits 
packed words bit words packed bits 
packed double words bit double words packed bits 
quad word bit quantity mmx instruction set mmx instructions classi ed data transfer instructions movd instructions move packed data respectively bit data mmx registers memory mmx registers 
bit data transfer instructions move low order bits mmx register 
register register version mov instruction implementation operation moving data mmx integer registers 
arithmetic instructions instructions include instructions perform add subtract multiply packed operand types 
instructions exist packed operand types byte bit word bit double word bit performing operations parallel illustrated 
operation independent comes modes unsigned saturation signed saturation 
wrap mode ow ow results truncation carry ignored 
saturation mode ow ow results clipping value data range limit value 
result operation exceeds range data type saturates maximum value range results range saturates minimum range 
example upper lower saturation limits ffh unsigned bytes fh signed bytes 
comparison instructions instructions independently compare respective data elements packed data types parallel 
generate mask depending condition true false 
masks logical instructions select elements 
logical instructions perform logical operations registers 
shift instructions mmx implements versions logical left right arithmetic right shift operations 
rst regular packed shift independently shifts element packed word bit double word bit 
second version shift operations logical shift right bit mmx register 
shift operations especially important enable re alignment packed data 
conversion instructions convert data elements packed registers pack instructions perform integer demotion unpack instructions perform integer promotion 
unpack instructions interleave elements source registers 
illustrates pack unpack low instructions 
entire instruction set summarized table appendix instructions typically pre xed packed byte word double word 
execution multimedia instructions shown exploit data parallelism subwords multimedia registers 
referred subword parallelism subword semantics 
pack unpack pack unpack instructions vectorization multimedia extensions vectorization earliest development eld parallel compilation 
traditionally vector simd machines 
compilers personal computers need techniques 
subword model changed situation forced review vectorization techniques 
domain constraints limited vectorization packed arithmetic instructions various multimedia extensions basically vector operations 
vectorization performed exploit instructions 
extensions built top scalar processors 
resulted constraining domain vectorization 
packed instructions operate multimedia registers aliased integer oating point registers 
size register bytes means data elements packed single register 
number data elements packed vector register referred vector length processor 
perform instances instruction parallel allowed dependence relations maximum speedup 
seen constraint vector length mean instances corresponding innermost loop performed parallel 
consideration resort limited vectorization try pull instruction innermost loop 
section discusses implementation vectorizing compiler intel mmx 
condition distribution cfg strip mine dependence graph processing reduction expansion scalar suif suif scc suif modified loop distribution assembly inline ud du chain asu process overview vectorization mmx compiler implemented suif compiler framework 
overview suif section 
compiler structured set passes 
application converted suif intermediate format passes applied intermediate format 
overview implementation 
gure rectangular boxes represent di erent compilation phases shaded ones representing passes written modi ed 
hypothetical example illustrate various passes compiler 
assume array bounds declared appropriately 
elements array declared short variables declared char data type 
identi cation data parallel sections motivation statements executed parallel subword semantics 
answer question help motivating example 
assume conjunction executed subword semantics operands successive instances packed multimedia registers operated parallel multimedia instructions 
operations executed parallel seen 
test 
test 
endfor test endfor endfor motivating example certain instances wrong value 
due fact kth instance executed parallel th instance waiting complete produce required result 
basically case violation true dependence 
waited instances complete violated control dependence 
clearly executed parallel subword semantics successive iterations write location test performed parallel result inconsistent state memory location 
case output dependence successive instances statement 
hand accesses memory location successive iterations instances involving successive iterations iteration executed parallel 
aim phase identify statements executed parallel violating semantics program 
method loop distribution rst step approach identi cation data parallelism 
loop distribution transformation distributes control loop groups statements body 
extract maximum parallelism presence dependence cycle loop control distributed strongly connected components dependence graph 
strongly connected component scc dependence graph maximal set vertices directed path pair vertices set 
non singleton scc data dependence graph represents maximum set statements involved dependence cycle 
performing loop distribution sccs known loop 
singleton scc self dependent candidate exploiting subword parallelism 
presence self dependence arc indicates successive instances executed parallel 
identifying sccs dependence graph vectorizable loops take account fact due domain constraint mentioned section perform limited vectorization allows statement pulled level 
means execution order statement ected respect outer loops 
allows ignore dependence arcs exception loop independent arcs ones carried innermost enclosing loop extracting parallelism performing loop distribution concerned 
may prevent exposing parallelism transformation loop interchange 
discussed section current implementation consider loop transformations 
statements conditional body executed conditional test 
statement pulled loop pulled conjunction test condition 
lexically backward dependence statement test equivalent self dependence 
order facilitate identi cation dependence loops condition distribution performed 
case loop distribution control distributed statements part part 
conditional distribution known literature conversion 
caveat 
arises statement de nes variable example condition 
avoid variable referenced test condition replaced new variable initialized correctly 
explained help motivating example 
loop distribution condition distribution number loop transformations loop splitting loop interchange loop peeling enable expose vectorizable loops 
considered transformation left 
implementation algorithm identifying data parallel sections involve steps 
run function code 

control flow graph constructed mach suif cfg library support 

module builds def ud def du chains iterative technique described 

data ow module rst builds scalar component data dependence graph 
arcs added corresponding reaching de nitions 
arcs added de ning set reached de nition may kill 
output dependence arcs added de ning reaching de nitions 

module builds array data ow component data dependence graph 
dependence vectors determined pair array 
note dependence vectors determined pair array de nitions ambiguous 
level dependence determined dependence loop independent carried innermost enclosing loop case arc added pair 

outer loop module identi es strongly connected component data dependence graph 

single statement strongly connected components self dependent annotated data parallel 
executed subword semantics provided result type suciently short 
illustration conditional distribution rst performed code transforming shown 
shows data dependence graph constructed hypothetical example conditional distribution 
mentioned earlier show loop independent dependence arcs loop dependent arcs carried innermost enclosing loop 
example concerned dependences carried level example concerned dependences carried outer loop level 
shows strongly connected component graph statements contained strongly connected component 
singleton sccs statements innermost loop level vectorizable 
considering level appropriate dependence graph nd statement forms singleton scc self arc level 
executed subword semantics 
temp temp 
test 
test 
endfor test endfor endfor condition distribution test test scc scc temp test test dependence graph strongly connected components scalar expansion strip mining motivation consider dependence graph shown 
seen executed subword semantics output dependence arc 
arc wouldn test array indexed successive iterations write di erent memory locations 
idea scalar expansion transformation 
method de nitions scalar variable loop results output dependence arc 
arc broken replacing scalar variable array essentially providing iteration memory location write 
known scalar expansion 
scalar expansion variable possible satis es constraints target de nition case gain self arc broken 
target single statement recurrence single statement recurrence involves anti dependence true dependence arc addition output dependence arc gain expanding scalar true dependence prevent vectorization 
induction variable case iteration index expanded correct results 
operation quite costly case 
discussed earlier mmx small number operations executed parallel 
iterations vectorizable loop executed parallel 
loops partitioned smaller sections handled parallel 
known strip mining 
number iterations handled parallel equal vector length processor 
strip mining results nested loop outer loop bounds original loop vector length stride inner loop performing iterations corresponding stride 
usually remainder section similar inner loop completing nal strip 
partition loops strips length 
vector length inner loop subject satisfying dependence constraints replaced single vector instruction corresponds parallel operations 
vector lengths size code generator handles appropriately discussed section 
look scalar expansion context strip mining seen providing iteration memory location provide just vector length memory locations 
speci cally variable scalar expanded expanded vector length 
approach scalar expansion performed strip mining inner loop 
reduces memory overhead time allows expanding variables loop bounds known 
considered privatization respect outer loop strip mining 
implementation variable expanded module scalar expansion perform 
declare array elements type size equal loop bound 
strip mining size reduce vector length 
note vector length strip mining implementation 

replace loop appropriate array 
suppose loop index lower bound loop lb uses de nition replaced expanded lb 
de nition subsequent uses replaced expanded lb 

adds initialization instruction form expanded loop 

adds nalization instruction form expanded vector length loop 
explanation needed including steps 
loop say may de ning 
avoid inconsistencies value stored appropriate array location nested loop 
loop de nes restored expanded loop 
module treats operations form initialization nalization respectively 
consider loop say nested loop 
may refer lead inconsistency 
handle approach similar nalization restore appropriate array location 
similarly may de ne handled storing array location restored 
array location identi ed treating case applying step algorithm 
illustration application strip mining loops scalar expansion transformation earlier example results code 
denotes vector length 
remainder loop shown example simplicity 
lastly due fact singleton scc loop level order exploit subword parallelism loop strip mined 
stride stride stride vl stride stride vl stride stride stride vl exp temp temp exp test test stride stride vl exp temp stride exp temp stride 
exp test stride 
exp test stride 
endfor test exp test vl temp exp temp vl endfor test endfor endfor endfor data dependence graph code shown levels 
note dependence levels arcs changed due strip 
broken arc broken arc show respectively output anti dependences broken scalar expansion 
longer scc consisting forms single scc self arc instances executed parallel subword semantics 
dependence graph scalar expansion reduction processing motivation expand scope statements loops vectorized grouping reduction techniques applied 
motivate need techniques vector dot product calculation example 
endfor statement example single statement recurrence true output dependence arc 
data dependence graph example shown 
scalar expansion removes arc associated output dependence leaves true dependence arc self loop 
help increasing scope parallelism case 
dependence graph reduction processing addition associative order summation ect result case ow 
data partitioned partial sums determined 
partial sums accumulated result 
strip mining partitions iterations loop partition data 
iteration inner loop computes di erent partial sums help 
strip mining recurrence innermost loop outer loop 
ect pulling true dependence arc inner loop allowing ignore vectorization inner loop concerned 
code section illustrates transformation 
method scalar expansion removes output dependence self arcs associated scalar variables reduction processing aims remove true dependence self arcs 
addition multiplication operations associative 
allows reordering grouping operations subsequently reducing get result 
variable expanded reduction operation source target de nition operation reduction operation add multiply maximum source instruction loop case expanded collapsed avoid inconsistency operation costly 
implementation variable expanded module reduction processing 
declare array elements type 
replace loop index lower bound lb lb 

adds initialization form enclosing loop case strip mined loop initialization pushed loop outwards reaching de nitions course exception current de nition 

adds nalization instruction form loop case strip mined loop nalization pushed loop outwards 

initialization nalization pulled enclosing loops contain reaching de nition reached illustration vector dot product computation transformed stride stride stride vl stride partial stride vl partial partial subword execution endfor endfor partial partial vl partial partial endfor data dependence graph example transformation shown 
level true dependence noted introduced inner loop executed parallel 
seen executed parallel self arcs removed 
statement represents accumulation partial sums 
reduction transformation may produce result di erent produced sequential execution case ow 
better enable transform user option 
option indicate ow exceptional condition 
loop distribution method code transformations loop control distributed 
mentioned earlier enable loop distribution presence back arcs strongly connected components body loop identi ed topologically sorted 
result graph arcs lexically forward 
loop control distributed strongly connected components 
mentioned earlier single statement strongly connected components self dependent annotated data parallel instructions 
implementation outer loop 
strongly connected components identi ed data dependence graph 

strongly connected components ordered topological sort 

statements reordered statements belonging strongly connected components grouped program order 
strongly connected components topologically sorted order 

loop control distributed strongly connected component 

single statement strongly connected components self dependent result type conducive subword execution annotated data parallel statements 
illustration applying loop distribution hypothetical example results code stride stride stride vl stride stride vl stride stride stride vl exp test test stride stride vl exp test stride 
stride stride vl exp temp stride exp temp stride 
exp test stride 
endfor test exp test vl endfor endfor stride stride vl test endfor endfor shows dependence graph strongly connected components grouped single node transformations 
seen graph executed subword semantics 
statements omitted code play signi cant part 
code generation extensive programming language system applications performance necessity luxury 
commercial open source compilers perform wide variety machine dependent machine independent optimizations 
sense compiler leverage scalar optimizations performed vectorizable sections handled modules 
propose generate inline assembly code vectorizable strongly connected components graph sections code 
inline assembly allows programmer introduce assembly instructions code 
code generator takes suif syntax tree le input emits inline assembly equivalent data parallel code fragments 
details inline assembly 
suif converter modi ed purpose 
take brief look issues involved code generation 
register management basically involves management sets registers general purpose multimedia registers 
native compiler assembler provides support management general purpose registers 
allows perform optimizations register allocation 
multimedia registers handled code generator 
simple stack register assignment scheme purpose register set treated stack 
request top stack returned release register pushed back stack 
subword size discussed earlier mmx allows subword sizes bytes 
subword size execution chosen result operation size 
subword size chosen operands promoted demoted respective sizes 
integral promotion unpack instruction 
added issue operand 
signed necessary perform signed extension operand 
integral demotion pack operation 
look integral promotion say byte word operation register mm currently holds byte subwords 

create zeroed register say mm usually performed subtracting register 

unpack lower bytes mm mm 
result register mm holding byte subwords mm left shifted word boundary refer 

operand mm signed perform arithmetic right shift sign extended mm perform logical right shift mm refer 

copy mm 
sequence illustrated 
mm mm mm mm mm mm mm mm arithmetic shift right mm logical shift right ign sign sign sign integral promotion subwords constants operation involving constants performed subword semantics 
necessary replicate value subwords 
similar scalar expansion expand constants 
performed unpack instruction 
basically register unpacked required number times 
alignment memory alignment deals access multi byte operands cross word boundary 
basically data bus able fetch word length bytes data access provided bytes word aligned 
processors movement memory word aligned addresses 
speci cally quad word expected aligned byte boundary 
may result error 
vectorizing compiler ensure performing packed memory operations addresses aligned additional involved loading word aligned data shifting get required non aligned data 
intel pentium processors hand support access non word aligned multi bytes 
case processor performs memory access operation may slower 
compiler deal alignment issues correctness 
performance deteriorate shown section 
issue alignment dealt 
implementation code generation phase expression tree traversal involves steps 

perform post order traversal expression tree 

node variable symbol emit instruction load variable general purpose register 
pop register stack 
move contents register multimedia register 
multimedia register destination register 
array instruction emit instruction load address general purpose register 
pop register multimedia stack 
array instruction emit code corresponding instruction register value returned children nodes 
register corresponding left child destination register 
left child parent push destination register back stack 
return destination register 
illustration applying code generation pass small fragment statement example elements array short test char data type results code shown 
asm mm load gp mm movd mm move gp mm mm mm zero mm mm mm unpack lower bytes mm mm mm mm mm copy mm mm mm arithmetic right shift mm integral promotion test completed mm mm replicating test mm mm subwords mm mm add mm mm mm store gp list test gp register loading instruction loaded gp address gp 
inline assembly code subword size execution bits 
example illustrates integral promotion test replication scalar value subwords 
seen general purpose register assignment left compiler 
code performs successive instances 
remarks couple remarks implementation order 
method directly handle conditionals 
transformation performed 
conditionals condition distribution transformation form test expr transformed test test expr original method applied operations included extensions 
test evaluated stored register operations 
second reasons simplicity implementation strip mines loop vector length 
subword size match vector length example word size operands re folding loop match vector length duplicate vector operation subject satisfying dependence constraints retain original 
words strip mined inner loop vector length accommodates vector operation vector length 
handled appropriately code generation algorithm re emitting instructions corresponding expression tree multiple times 
implementation suif framework techniques identi cation data parallel sections di erent code transformations implemented passes suif framework 
part constructing dependence graphs augmented cfg library compute ud du chain iterative algorithm 
developed array dependence analysis module uses suif dependence library 
lastly modi ed suif converter generate inlined assembly code 
di erent passes order applied shown 
retained suif interface di erent compiler passes 
compilation passes implemented separate programs communicate suif les 
di erent passes communicate annotating program representation 
code transformation passes involved extensive reordering cloning suif structures 
suif hierarchy facilitated reordering structures considerably 
reordering typically require node removed parent inserted node requirement 
internal mechanism change handled suif 
cloning structure handled similarly 
cloning node inserted di erent scope require scopes reconciled 
involves identifying symbols referenced node scope cloning symbols 
low level implementation operations handled suif 
vectorizing compiler suif infrastructure currently runs intel pentium ii processor workstation running redhat linux 
limitations implementation compiler considers loops candidates vectorization 
loops ignored 
loop transformations loop splitting loop interchange performed 
transformations enhance loop 
compiler generates overhead form unnecessary strip mining scalar expansions 
overhead incurred absence subsequent pass reverse ect unnecessary strip mining scalar expansion 
known reversing dicult implement 
code generation alignment issues ignored 
de nitely impact performance 
function calls presence pointers hamper vectorization 
inlining function possible solution overcome limitation 
compiler currently support function inlining 
language poses barriers exploiting extensions fully 
example saturating arithmetic supported vendor extensions natural way programmer specify need operation 
instructions multiply add supported implementation 
results discussion section initial performance results obtained vectorizing compiler 
experiments compile kernels media processing applications run intel mmx architecture measure performance 
reasons considering kernels multimedia application follows 
media processing applications typically spend major fraction execution time small data parallel kernels 
studying performance improvement kernel gives direct measure subword parallelism exploited vectorizing compiler 
complete applications typically contain sequential non vectorizable code code operate full words contribute improvement performance mmx architecture hand tuned exposed optimizing vectorizing compiler 
benchmarks consider kernels 
dissolve video processing application 
typically editing video sequence 
application takes video frames input computes weighted average pixels frame outputs new frame 
new frame ller input frames 
experiments considered pixel frames compute just average pixels 
seen dissolve extremely data parallel application 
chroma keying image processing utility 
basically replaces background image alternate background input 
experiments considered image chroma keying 
replaces pixels having background color rst frame corresponding pixel second frame 
vector dot product algebraic computation common signal processing applications 
inputs dimensional vectors output sum product individual elements vector 
purpose compute dot product element vectors 
dot product sum absolute di erences kernel require grouping reduction transformations performed exploit subword parallelism 
sum absolute di erence sad processing kernel motion estimation algorithm 
motion estimation mpeg encoder compress input stream implicit temporal coherence successive frames video 
sad kernel key target performance improvement mmx 
matter fact vis includes instruction perform operation 
considered sum absolute di erence block 
sad kernel integrated motion estimation code performance evaluated experimental setup kernels listed computationally intensive usually invoked times 
mentioned earlier usually results application spending signi cant fraction fair mentioned mmx version code fact bene extent due reduction loop control overheads 
execution time kernels 
means optimizing kernels translate signi cant improvement applications 
compare performance kernel compiled native compiler gcc kernel compiled vectorizing compiler 
referred non mmx code gcc compiler generate mmx extension instructions referred vectorized code mmx code 
generate mmx code compiler passes applied kernel get source code augmented inline assembly instructions 
code compiled native compiler gcc linked main routine 
similarly obtaining non mmx code kernel compiled native compiler linked main routine 
generating mmx non mmx code native gcc compiler pentium ii obtained optimized unoptimized versions 
report performance optimized unoptimized versions mmx non mmx code discussion concentrate mainly unoptimized versions reasons optimizations gcc compiler minor impact mmx code inlined assembly code left untouched compiler ii register allocation optimized mmx code inlined assembly turned poorer non mmx code 
full edged code generation approach inline assembly code generation eliminated di erences 
seen results performance non mmx code improves signi cantly optimizations turned compared mmx code 
main routine times times routine execution kernels intel ii processor running mhz 
accurate measurement execution time required call kernel functions times times average time executing kernel computed 
kernels dissolve chroma key run respectively times dot product sad run times respectively 
speedup measured speedup exec 
time non mmx code exec 
time vectorized code results discussion table presents speedup obtained compiler traditionally compiled code 
kernel report major data type kernel byte short word execution time microseconds unoptimized optimized versions mmx non mmx code speedup achieved expected speedup architecture data type leveraging just subword parallelism 
may possible improve expected speedup optimal mmx features saturation logic instructions multiply add consider 
unoptimized code optimized code kernel data exec 
time exec 
time theoretical type mmx non mmx speedup mmx non mmx speedup speedup code code code code video dissolve chroma keying byte dot product short dot product sum absolute di erence sad table speedup kernels observed speedups achieved unoptimized code signi cantly higher achieved optimized code 
discussed earlier may due poor code register allocation presence inlined assembly code 
partly due overheads generated aggressive strip mining scalar expansion 
interesting observe dot product kernel optimized non mmx version fact performs better optimized mmx version 
noticed case dot product case optimized version vectorized mmx code achieved roughly half speedup achieved unoptimized code 
turn attention performance unoptimized mmx non mmx code 
seen compiler able fully harness data parallelism case dissolve chroma keying sad kernels 
speedup obtained integrating sad kernel motion estimation module compare hand tuned version table 
kernel hand tuned sad saturated subtract bitwise saturated subtract involve conditionals common way computing sad mmx instructions 
refer version hand tuned sad sad 
compare speedup achieved hand tuned version measured ratio execution time original code compiled gcc execution time hand tuned version compiled gcc obtained vectorized code 
seen speedup obtained compiler comparable obtained hand tuned version 
kernel data exec 
time ms speedup types mmx unopt 
non mmx unopt 
sum absolute di erence sad motion estimation sad sum absolute di erence sad alternate hand code approach motion estimation sad table speedup motion estimation surprised performance dot product kernel 
mmx instruction set supports packed short word multiply 
meant byte length vector elements promoted short multiply operation 
initially result attributed overhead involved expansion 
led try dot product short word quantities 
seen short dot product performs better signi cantly 
inspection dot product code revealed array introduced grouping reduction module quad word aligned 
discussed section alignment cause problem terms correct execution code may incur performance penalties intel processors 
enforced array aligned measured performance kernel 
results reported table 
suspect overhead due sequential code signi cant dot product kernel 
con rm measured performance dot product di erent lengths input vectors 
seen table small vector lengths sequential section dominates causing loss speedup 
vector length increases speedup increases fraction execution time spent sequential section comes 
signi cance alignment re ected speedup gained unaligned version 
input exec 
time speedup size aligned un aligned aligned un aligned mmx mmx mmx mmx mmx table ect input size alignment performance dot product related vectorizing techniques discussed detail literature 
includes comprehensive coverage zima chapman wolfe 
suif vectorizing compiler implementation vectorization techniques suif platform 
target architecture ucb torrent architecture traditional vector architecture 
optimizer vis extension proposed 
optimizer suif vectorizing compiler backbone 
code generation completed parallel add parallel conditional copy 
focus alignment issues code generation 
operation packing proposed 
idea support packing operation hardware instructions reservation station 
technique may provide improvement applications speedup may measure static compiler analysis vectorizable applications 
multimedia extensions exploited java jit compiler 
vectorizing compiler vis proposed 
addition traditional vectorization techniques loop unrolling instruction scheduling employed exploit subword parallelism 
deals memory alignment essential vis sake correctness performance issue case intel processors 
lastly compare approach providing vectorizing compiler support provided vendors form enhanced system libraries macro calls 
consider sum absolute di erences example vectorizing compiler able perform necessary code transformation scalar expansion reduction 
case hardware supported enhanced libraries programmer system version absolute function say abs 
function abs performed subword semantics 
function may exploit subword parallelism computing absolute di erence elements sum calculated sequentially call losing parallelism 
system enhanced functions lined source code available 
hand macro calls requires user aware code segment optimized multimedia extensions macros provided 
code transformations performed manually 
lastly programming macro calls hard programming assembly 
presents implementation vectorizing compiler intel multimedia extension 
extension targeted data parallel kernels media processing applications 
goal provide compiler support enhancement instruction set transparent programmer 
vectorization techniques traditionally compilers vector simd processors compiler extract subword parallelism sequential code 
enhance scope application subword semantics compiler performs code transformations 
include strip mining scalar expansion grouping reduction loop distribution 
suif compiler tool implementing various passes compiler 
compiler generates inline assembly code data parallel sections identi ed 
noted compiler performs conditional distribution vectorization code generation 
target architecture intel techniques discussed applied multimedia extensions architectures 
report initial performance results code generated vectorizing compiler 
data parallel kernels multimedia application compiled compiler run intel pentium ii processor result signi cant speedup compared performance code compiled native compiler 
performance improvement achieved compiler performance hand tuned code applications viz sum absolute di erences 
reported performance achieved multimedia application motion estimation linking compiled code kernel application 
performance compiler applied various multimedia kernels encouraging 
scope vectorization enhanced loop transformations loop interchange loop splitting loop peeling 
compiler currently perform instruction scheduling 
instruction scheduling software pipelining instruction scheduling technique iterative computation de nitely lead improved performance due ecient usage available resources 
perform global register allocation 
allocation may trivial oating point multimedia registers overlapped 
extending compiler exploit features multiply add instructions increase instruction level parallelism exploited 
presence pointers conservative assumptions aliasing limit vectorization 
alias analysis improve situation maximum bene terms performance obtained better coding practices 
proposed restrict keyword part standard allow programmer provide guarantees regarding memory locations referenced pointer 
provides compiler freedom optimizing presence restricted pointers 
function inlining enhance scope vectorization considerably 
enable compiler perform optimizations reduce function call overhead 
considering data parallel kernels called frequently lead signi cant improvement 
function inlining currently supported compiler useful extension 
acknowledgments authors thankful anonymous reviewers constructive comments helped improve quality presentation organization 
authors acknowledge kumar help running experiments 
lee smith 
media processing new design target 
ieee micro pages july aug 
conte jennings lee peleg schlansker song wolfe 
challenges combining general purpose multimedia processors 
ieee micro pages december 
lee 
subword parallelism 
ieee micro july aug 
intel 
intel programmers user manual 
weiser peleg 
mmx technology extension intel architecture 
ieee micro pages july aug 
tremblay 
vis speeds new media processing 
ieee micro pages july aug 
lee 
subword parallelism max 
ieee micro pages july aug 

architectural design implication media processing 
tutorial lecture 
kennedy allen 
automatic translation fortran programs vector form 
acm transactions programming languages system oct 
zima chapman 
supercompilers parallel vector computers 
addisonwesley publishing reading ma 
wolfe 
high performance compilers parallel computing 
addison wesley publishing reading ma 
bacon graham sharp 
compiler transformation high performance computing 
acm computing surveys dec 
suif compiler group suif manual 
stanford university compiler group 
aho ullman sethi 
compilers principles techniques tools 
addison wesley publishing house reading ma 
ferrante ottenstein warren 
program dependence graph optimization 
acm transactions programming languages systems july 
banerjee 
dependence analysis supercomputing 
kluwer academic publishers boston ma 
burke cytron 
interprocedural dependence analysis parallelization 
proc 
acm sigplan symp 
compiler construction palo alta ca july 
kuck muraoka chen number operations simultaneously executable fortran programs resulting speedup 
ieee transactions computers dec 
go kennedy 
tseng 
practical dependence testing 
proc 
acm sigplan conf 
programming language design implementation pldi pages toronto ontario jun 
pugh 
practical algorithm exact array dependence analysis 
communications acm aug 
suif compiler group overview suif compiler system 
stanford university compiler group 
darte vivien 
optimality allen kennedy algorithm parallelism extraction nested loops 
journal parallel algorithms applications 
special issue optimizing compilers parallel languages 
allen kennedy porter eld warren 
conversion control dependence data dependence 
proc 
th sigact sigplan conf 
principles programming language popl pages austin tx jan 
kennedy mckinley 
loop distribution arbitrary control ow 
proc 
supercomputing pages new york ny nov 
smith 
extending suif machine speci optimizations 
technical report harvard university cambridge ma july 
cytron ferrante 
name 
value renaming parallelism detection storage allocation 
proc 
intl 
conf 
parallel processing pages 
underwood 
brennan guide inline assembly 
www rt com brennan asm html 
young 
suif control flow graph library 
harvard university cambridge ma 

digital video processing 
prentice hall englewood cli nj 

suif vectorizing compiler 
ieee micro pages july aug 
johnson 
torrent architecture manual 
technical report icsi 
lam 
optimizer multimedia instruction set 
suif workshop preliminary report 
brooks martonosi 
dynamically exploiting narrow width operands improve processor power performance 
proc 
th intl 
symp 
high performance computer architecture pages jan 
bik 
incorporating intel mmx technology java jit compiler 
scienti programming 
krall 
vectorizing techniques vis 
dagstuhl seminar instruction loop level parallelism report april 
muchnick 
advanced compiler design implementation 
morgan kaufmann publishers san francisco ca 
allan jones lee allan 
software pipelining 
acm computing surveys september 
rau 
scheduling techniques easily schedulable horizontal architecture high performance scienti computing 
proceedings th annual microprogramming workshop pages massachusetts october 
lam 
software pipelining ective scheduling technique vliw machines 
proceedings sigplan conference programming language design implementation pages atlanta georgia june 
mmx instruction set entire instruction set mmx summarized table 
category signed unsigned saturation saturation arithmetic addition subtraction multiplication multiply add comparison compare equal compare greater conversion pack unpack high unpack low distinction logical pand exclusive por shift shift left logical shift right logical shift right arith 
data transfer movd empty mmx state table mmx instruction set summary 
