curve numerical treatment inverse problems hansen department mathematical modelling technical university denmark dk lyngby denmark curve log log plot norm regularized solution versus norm corresponding residual norm 
convenient graphical tool displaying trade size regularized solution fit data regularization parameter varies 
curve gives insight regularizing properties underlying regularization method aid choosing appropriate regularization parameter data 
chapter summarize main properties curve demonstrate examples usefulness limitations analysis tool method choosing regularization parameter 
practically regularization methods computing stable solutions inverse problems involve trade size regularized solution quality fit provides data 
distinguishes various regularization methods measure quantities decide optimal trade quantities 
example discrete linear squares problem min ka gamma bk specializes square classical regularization method developed independently phillips tikhonov usually referred tikhonov regularization amounts general form solving minimization problem arg min ka gamma bk kl gamma real regularization parameter chosen user 
size regularized solution measured norm kl gamma fit measured norm ka gamma bk residual vector 
vector priori estimate set zero priori information available 
problem standard form identity matrix 
tikhonov solution formally solution regularized normal equations best way solve numerically treat squares problem arg min fl fl fl fl gamma fl fl fl fl regularization necessary solving inverse problems naive squares solution formally ls completely dominated contributions data errors rounding errors 
adding regularization able damp contributions keep norm kl gamma reasonable size 
philosophy underlies tikhonov regularization regularization methods 
various issues choosing matrix discussed section 
note regularization damping imposed solution fit data properly residual ka gamma bk large 
hand little regularization imposed fit solution dominated contributions data errors kl gamma large 
illustrates point tikhonov regularization 
having realized important roles played norms solution residual quite natural plot quantities versus curve ka gamma bk kl gamma parametrized regularization parameter 
precisely curve see fig 
example 
exact solution thin lines tikhonov regularized solutions thick lines values corresponding appropriate smoothing smoothing 
curve tikhonov regularization residual norm generic curve standard form tikhonov regularization points marked circles correspond regularization parameters gamma gamma gamma gamma gamma 
curve really tradeoff curve quantities controlled 
trade curves common applied mathematics engineering literature plots similar appeared years literature 
early curve plots lawson hanson miller 
interesting questions related curve 
properties curve 
information extracted curve problem regularization algorithm regularized solutions choice regularization parameter 
particular shall method choosing regularization parameter known curve criterion discuss practical 
method successfully number applications continuation problems geoscience tomography 
purpose chapter provide insight helps answer questions 
chapter focus tikhonov regularization curve exists methods start section historical perspective tikhonov method 
section introduce main analysis tool singular value decomposition svd 
sections various properties curve explain characteristic shape 
section describe curve criterion choosing regularization parameter amounts locating corner curve 
section describe limitations curve criterion considered parameter choice method 
tikhonov regularization author describe scheme equivalent tikhonov regularization james riley considered ill conditioned systems symmetric positive semi definite coefficient matrix proposed solve system ff ff small positive constant 
riley suggested iterative scheme known iterated tikhonov regularization cf 

devoted general problems published phillips 
square matrix obtained kind integral equation means quadrature rule tridiagonal matrix tridiag gamma 
phillips arrives formulation matrix notation proposes compute regularized solution gammat gamma notation 
clear phillips computed gamma explicitly recognize squares problem 
reformulated phillips expression regularized normal equations obtained known expression gamma tridiag gamma 
proposed include priori estimate connection choice identity matrix leading formula gamma tikhonov formulated general setting considered problem functions integral operator 
tikhonov proposed formulation arg min phi kk gamma gk omega gamma psi particular functional omega gamma ds positive weight functions 
turning computations tikhonov midpoint quadrature rule arrive problem min ka gamma bk kd xk kld xk jo dw diagonal weight matrices corresponding gamma 
regularized normal equations derived expression dw gamma gene golub propose modern approach solving squares formulation qr factorization associated coefficient matrix 
golub proposed approach connection riley iterative scheme includes computation step 
proposed qr approach computing 
joel franklin derived regularized normal equation formulation tikhonov regularization stochastic setting 
residual vector weighted cholesky factor covariance matrix perturbations matrix represents inverse covariance matrix solution considered stochastic variable 
mentioned franklin connection symmetric positive semi definite matrices proposed variant ff gamma ff positive scalar nicely connects back riley 
statistical literature tikhonov regularization known ridge regression date back papers 
marquardt setting basis analysis iterative algorithm solving nonlinear squares problems incorporates standard form tikhonov regularization step 
efficient way compute tikhonov solutions range regularization parameters case practice means algorithm due lars eld en combined transformation standard form iterative algorithms developed large scale problems shall go algorithmic details 
singular value decomposition purpose section derive explain various expressions lead understanding features curve tikhonov regularization 
simplify analysis considerably assume rest chapter matrix identity matrix 
case problem general brought standard form see section details algorithms 
alternatively analysis general matrix cast terms generalized svd cf 
sections 
assume priori estimate zero 
main analysis tool chapter singular value decomposition svd matrix decomposition general theta matrix form oe left right singular vectors orthonormal ffi ij singular values oe nonnegative quantities appear non decreasing order oe oe delta delta delta oe matrices arising discretization inverse problems singular values decay gradually zero number sign changes singular vectors tends increase increases 
smaller singular value oe oscillatory corresponding singular vectors appear cf 
section insert svd squares formulation straightforward show tikhonov solution oe tikhonov filter factors depend oe oe oe oe ae oe oe particular naive squares solution ls filter factors equal 
comparing ls see filter factors practically filter contributions corresponding small singular values leave svd components corresponding large singular values unaffected 
damping sets oe residual vector corresponding characterizes misfit terms svd gamma gamma vector gamma component lies outside range reached linear combination columns gamma oe 
note see filter factors close diminish corresponding svd components residual considerably small filter factors leave corresponding residual components practically unaffected 
equipped expressions write solution residual norms terms svd kx oe ka gamma bk gamma expressions form basis analysis curve 
svd analysis chapter shall assume errors problem min ka gamma bk restricted right hand side data written represents exact unperturbed data represents exact solution vector represents errors data 
tikhonov solution written gamma regularized version exact solution gamma solution vector obtained applying tikhonov regularization pure noise component right hand side 
consider curve corresponding exact data stage necessary assumption called discrete picard condition exact svd coefficients ju bj decay faster oe condition ensures squares solution unperturbed problem large norm exact solution coefficients jv xj ju oe decay 
discrete picard condition ensures exists physically meaningful solution underlying inverse problem ensures solution approximated regularized solution provided suitable regularization parameter 
details condition section 
assume regularization parameter lies oe oe small filter factors filter factors close 
denote number filter factors close 
easy see related expression oe thorough analysis 
follows kx kxk fact coefficients jv xj decay gamma terms contribute little sum 
expression holds long large 
kx 
hand kx kxk residual corresponding satisfies ka gamma bk showing residual norm increases steadily kb kbk increases increasing number terms included sum 
curve unperturbed problem flat curve kx kxk large values residual norm ka gamma bk curve approaches abscissa axis 
consider curve corresponding right hand side consisting pure noise assume noise white covariance matrix scalar times identity matrix case preferably scale problem scaled problem satisfies requirement 
assumption implies expected values svd coefficients independent ffl means noise component satisfy discrete picard condition 
consider vector gamma concerning norm obtain kx oe ffl oe ffl oe oe ffl ffl oe gamma gamma oe sum oe gamma expression dominated oe gamma gamma second sum oe dominated oe obtain approximate expression kx ffl quantity varies slowly see norm increases monotonically decreases reaches value ka ek ffl ka 
norm corresponding residual satisfies ka gamma bk ffl gamma ffl ka gamma ek gamma ffl slowly varying function lying range gamma ffl kek ffl 
curve corresponding steep curve located slightly left ka gamma ek kek small values approaches ordinate axis 
consider curve corresponding noisy righthand side depending noise free components pure noise components dominate resulting curve essentially consists leg unperturbed curve leg pure noise curve 
small values pure noise curve dominates dominated large values dominated unperturbed curve dominates 
range values correspond transition domination curves 
emphasize discussion valid plotted log log scale 
linear scale curve convex independently right hand side see theorem 
logarithmic scale hand emphasizes difference curves exact right hand side pure noise emphasizes different parts curve noisy right hand side issues discussed detail 
curvature curve shall see sections curvature curve plays important role understanding curve 
section shall derive convenient expression curvature 
kx ae ka gamma bk log ae log ae curve plot versus ae recall ae functions ae ae denote second derivatives ae respect curvature curve function ae gamma ae ae goal derive insightful expression analysis similar hanke vogel details omitted 
differentiated ae respect formulas different lead value step derive expressions derivatives ae respect called logarithmic derivatives ae ae ae ae ae turn gamma gamma fi oe ae gamma fi fi expressions follow relations gamma gamma gamma gamma fact oe oe gamma arrive important relation ae gamma step involves computation second derivatives ae respect gamma ae ae ae ae ae gamma ae ae suffices consider quantity ae gamma gamma gamma insert expressions ae ae formula ae ae vanish expression ae ae ae ae quantity 
curve concave section arguments exact right hand side satisfies discrete picard condition right hand side corresponding pure white noise leads curve concave plotted log log scale 
section new theory supports 
restrict analysis investigation circumstances log log curve concave 
clearly practical setting noisy right hand side curve guaranteed concave key issue fact curve convex corner right hand sides 
order understand basic features curve interesting investigate properties connection idealized right hand sides step analysis proved log log curve strictly concave oe smallest singular value oe largest singular value 
curve concave ends near axes 
analysis extends analysis 
db ae base analysis expression curvature particular negative curve concave 
obviously restrict analysis factor ae ae define ae ae insert definitions ae expression obtain gamma oe gamma gamma gamma fi fi introduced fi unfortunately way explicitly analyze eq 

approach replace discrete variables oe oe fi continuous variables oe oe fi fi oe oe oe oe replace double summation double integral study quantity xi oe oe oe oe gamma theta oe oe gamma oe oe gamma fi oe fi oe doe doe sign xi approximately determines curvature curve 
loss generality assume oe 
simplify analysis assumption fi simply fi oe oe real number denote corresponding integral xi model unrealistic models wide range applications 
basis studies model problems continuous discrete setting see section details 
quantity controls behavior right hand side 
case corresponds right hand side satisfies discrete picard condition example exact right hand side corresponds right hand side satisfy discrete picard condition 
particular gamma corresponds right hand side consisting white noise 
means maple easily derive results 
theorem xi fi respectively 
gamma gamma obtain xi gamma gamma gamma xi gamma gamma gamma ln gamma ln gamma delta delta xi gamma gamma xi gamma gamma delta ln gamma delta gamma gamma gamma delta ln gamma xi gamma gamma gamma quantities negative 
analysis long svd coefficients ju bj decrease monotonically increase monotonically constant reason believe log log curve concave 
curve criterion computing regularization parameter fact curve noisy right hand side distinct corner prompted author propose new strategy choosing regularization parameter corresponding point curve ae log ka gamma bk log kx lies corner 
rationale choice corner separates flat vertical parts curve solution dominated regularization errors perturbation errors respectively 
note called curve criterion choosing regularization parameter current methods involve residual norm ka gamma bk solution norm kx order provide strict mathematical definition corner curve hansen leary suggested point curve ae maximum curvature eq 

easy dimensional minimization procedure compute maximum various issues locating corner curves associated methods tikhonov regularization discussed section 
illustrates curve criterion left part shows curve corner clearly visible right part shows curvature curve function sharp peak curve corresponds course sharp corner curve 
experimental comparisons curve criterion methods computing notably method generalized curve curvature reg 
param typical curve left plot right corresponding curvature function regularization parameter 
cross validation gcv developed section 
test problem problem shaw regularization tools package test problem available author home page 
tests ensembles exact right hand side perturbed randomly generated perturbations represent white noise 
experiments curve criterion tikhonov regularization gives robust estimation regularization parameter gcv method occasionally fails 
hand gcv works usually gives estimate optimal regularization parameter curve criterion tends produce regularization parameter slightly smooths slightly large 
experiments correlated noise show curve criterion situation superior gcv method consistently produces severe smoothing 
actual computation function depends size problem turn algorithm compute tikhonov solution svd computed readily computed means eqs 

larger problems svd may prohibitive feasible compute squares formulation 
case need alternative way compute quantity straightforward show insertion svd gamma gamma compute need vector solution problem min fl fl fl fl gamma gamma fl fl fl fl computed algorithm software vector identical correction vector step iterated tikhonov regularization cf 
section 
large scale problems direct method computing tikhonov solution prohibitive iterative algorithms lanczos 
algorithms techniques compute envelopes ae plane include curve 
limitations curve criterion practical method advantages disadvantages 
advantages curve criterion robustness ability treat perturbations consisting correlated noise 
section describe disadvantages limitations curve criterion understanding limitations key proper curve criterion hopefully improvements method 
smooth solutions limitation discussed concerned reconstruction smooth exact solutions solutions corresponding svd coefficients jv xj decay fast zero solution dominated svd components 
solutions hanke showed curve criterion fail smoother solution faster decay worse computed curve criterion 
easy illustrate explain limitation curve criterion means numerical example 
shall test problem shaw see section dimensions consider exact solutions solution picard plot picard plot curve opt curve opt svd coefficients curves mildly smooth solution left smooth solution right 
generated shaw mildly smooth smoother solution oe gamma svd coefficients oe oe corresponding right hand sides elements normally distributed zero mean standard deviation gamma top plots fig 
show corresponding singular values svd coefficients cases note faster svd coefficients decay rightmost plot hit noise level 
bottom plots fig 
show curves cases 
located curves points corner computed means curve criterion indicated theta corresponding regularization parameter point corresponding optimal regularization parameter opt indicated ffi 
opt defined regularization parameter minimizes error kx gamma kx gamma problem mildly smooth solution curve criterion works sense opt problem smooth solution regularization parameter orders magnitude smaller opt behavior curve criterion due fact optimal regularized solution opt lie curve corner norm kx starts increase soon smaller opt recall controls roughly svd components included regularized solution filter factors 
exact solution mildly smooth optimal regularized solution includes svd components additional svd components required kx starts increase 
fig 
see delta gamma corresponds including svd components decreasing factor corresponds including additional large svd components increasing kx dramatically 
addition see opt corresponds including svd components optimal regularized solution opt produces solution opt lies corner curve 
exact solution smooth optimal regularized solution opt includes svd coefficients additional coefficients may required order increase norm kx significantly 
number additional coefficients depends decay singular values 
returning fig 
see optimal regularization parameter opt delta gamma corresponds including svd components right hand side svd components dominated noise 
hand regularization parameter delta gamma computed curve criterion corresponds including svd components svd components included norm kx starts increase significantly 
solution opt correspond point curve corner 
note smooth exact solutions regularized solution opt may yield residual norm ka gamma bk small kek 
seen bottom right plot fig 
ka opt gamma bk delta gamma kek delta gamma times smaller 
solutions opt residuals shown fig 
produces residual components reasonably uncorrelated 
importance quality fit size statistical behavior residual norm depends application dilemma fit reconstruction remains valid regularized solutions curve optimal residuals test problem smooth exact solution regularized solutions corresponding residuals gamma computed curve criterion opt minimizes kx gamma smooth solutions 
time writing clear smooth solutions arise applications 
asymptotic properties second limitation curve criterion related asymptotic behavior problem size increases 
pointed vogel regularization parameter computed curve criterion may behave consistently optimal parameter opt increases 
analysis situation complicated fact linear system min ka gamma bk depends discretization method way noise enters problem 
discussion assume underlying continuous problem kind integral equation generic form dt kernel known function right hand side represents measured signal solution 
assume ffl exact right hand side ffl represents errors 
assume errors white noise uncorrelated standard deviation 
problem discretized quadrature method elements essentially samples underlying functions noise components samples noise ffl 
increases quadrature weights included ensure singular values converge svd components increase magnitude proportional sampled noise consists realizations stochastic process modeled ffl ffl constant independent problem discretized means galerkin method orthonormal basis functions inner products chosen basis functions functions respectively 
proved see section quantities oe converge increases 
noise components considered inner products basis functions noise component ffl 
noise considered white obtain noise model ffl ffl constant 
assume norm errors ffl bounded ffl white noise noise model ffl gamma ffl constant 
vogel considered third scenario moment discretization oe increases converge ffl 
equivalent case ffl gamma immediately 
study various scenarios common framework simple model oe ff gamma fi gamma ffl fl ff fi ffl gamma fl gamma 
values ff yield condition number equal respectively fi produces mildly smooth solution 
fl model represents white noise discretization means galerkin method fl gamma model represents scenarios introduced 
combinations ff fl computed optimal regularization parameter opt parameter chosen curve criterion 
results shown fig 
solid dotted dashed lines correspond ff respectively 
recall smaller ff faster decay singular values 
problem size opt problem size 
plots crosses opt bullets functions problem size fl gamma values ff ff solid lines ff dotted lines ff dashed lines 
note behavior opt depends noise model discretization method 
fl parameter opt constant opt decreases fl gamma 
regularization parameter computed criterion increases fl fl gamma constant 
vogel came case fl gamma 
scenarios see curve criterion eventually leads regularization large regularization parameter increases 
amount smoothing depends decay singular values faster decay severe smoothing 
fl gamma computed optimal value opt factor factor fl 
smoothing inherent curve criterion may severe depends particular problem solved 
matter ideal situation studied vogel problem discretized increasing may arise practice 
problem size fixed particular measurement setup larger required new experiment 
golub reichel estimation curve lanczos bit pp 

overcoming holder discontinuity ill posed continuation problems siam numer 
anal pp 

chen chen 
hong chen application ces aro mean curve deconvolution problem soil dynamics earthquake engineering pp 

cullum effective choice smoothing norm regularization math 
comp pp 

eld en algorithms regularization ill conditioned squares problems bit pp 

franklin posed stochastic extensions ill posed linear problems math 
anal 
appl pp 

franklin minimum principles ill posed problems siam math 
anal pp 

maass fast cg methods tikhonov phillips regularization siam sci 
comput pp 

golub numerical methods solving linear squares problems numer 
math pp 

golub heath wahba generalized crossvalidation method choosing ridge parameter technometrics pp 

golub von matt quadratically constrained squares quadratic problems numer 
math pp 

golub von matt tikhonov regularization large scale problems golub lui luk plemmons eds scientific computing springer berlin pp 

hanke limitations curve method ill posed problems bit pp 

hanke vogel level preconditioners regularized inverse problems theory numer 
math pp 

hansen truncated svd method regularization bit pp 

hansen computation singular value expansion computing pp 

hansen discrete picard condition discrete ill posed problems bit pp 

hansen analysis discrete ill posed problems means curve siam review pp 

hansen regularization tools matlab package analysis solution discrete ill posed problems numer 
algo pp 

hansen regularization tools version matlab numer 
algo pp 

hansen rank deficient discrete ill posed problems siam philadelphia 
hansen leary curve regularization discrete ill posed problems siam sci 
comput pp 

ridge regression 
biased estimation nonorthogonal problems technometrics pp 

ridge regression 
applications nonorthogonal problems technometrics pp 

kaufman neumaier pet regularization envelope guided conjugate gradients ieee trans 
medical imaging pp 

lawson hanson solving squares problems hall englewood cliffs reprinted siam philadelphia 
marquardt generalized inverses ridge regression biased linear estimation nonlinear estimation technometrics pp 

marquardt algorithm squares estimation nonlinear parameters siam pp 

miller squares methods ill posed problems prescribed bound siam math 
anal pp 

neumaier solving ill conditioned singular linear systems tutorial regularization siam review pp 

phillips technique numerical solution certain integral equations kind assoc 
comput 
mach pp 

regularization parameter discrete ill posed problems siam sci 
comput pp 

regularisation pp 

riley solving systems linear equations positive definite symmetric possibly ill conditioned matrix math 
tables aids comput pp 

tikhonov solution incorrectly formulated problems regularization method soviet math 
dokl pp 
english translation dokl 
akad 
nauk 
sssr pp 

numerical solution integral equations kind inversion linear system produced quadrature assoc 
comput 
mach pp 

vogel non convergence curve regularization parameter selection method inverse problems pp 

wahba practical approximate solutions linear operator equations data noisy siam numer 
anal pp 


