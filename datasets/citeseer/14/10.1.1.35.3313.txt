case study machine learning quinlan basser department computer science university sydney sydney australia quinlan cs su oz au empirical machine learning develops methods formulating predictive theories observations drawing ideas artificial intelligence statistics 
discusses examples methods context modelling biomedical activity family compounds 
approaches compared standard multivariate linear regression piecewise linear models expressed model trees simple instance predictor combination instance learning model trees hybrid instance analogical learning 
methods evaluated predictive accuracy theories construct task 

people inclined associate artificial intelligence attempt replicate human intelligence 
valid longterm goal ai concerns highly restricted tasks practical importance intention developing heuristic methods accomplishing 
machine learning subfield ai addresses formulation modification theories result observations 
learning diverse encompassing activities explanation learning existing theory tweaked efficient light single new fact empirical learning develops theory scratch guided substantial number observations learning theory identifies classes theories easy difficult learn quantifies interrelationships learning variables learning time accuracy number observations 
discuss ai learning illustrates important ideas context particular task 

task quite common pharmaceutical companies devote great deal time resources developing evaluating new substances biomedical applications 
naturally synthesize substances random predictions properties hypothetical compounds synthesize appear promising 
subject case study group substances called peptides consist linear sequences amino acids 
peptides applications suppression 
particular subgroup peptides containing exactly amino acids studied extensively respect 
extensively means substances synthesised activity assessed amino acids small subset possibilities 
display ignorance biochemistry attempting explain significance activity measure noting just fractional number lying active relatively inactive 
data experiments peptide specified ffl definition names amino acids composed ffl description collection properties attributes peptide may relevant activity 
real valued features binary true false indicators 
task stated simply database peptides activities known develop model allow activity new unseen peptides predicted 
learned theory concerned predicting values class membership common kind learning task 

statistical considerations empirical learning eclectic incorporates ideas disciplines especially statistics 
fact distinction machine learning statistics directly relevant task 
methods similar cart breiman friedman olshen stone decision tree induction system highly regarded learning community developed statisticians 
attempt cover statistical approaches peptide modelling task 
point sensible try multivariate linear regression common starting point statistical data analysis 
set data points regression finds best linear model dependent variable peptide activity terms independent variables attributes constituting peptide description definition 
best linear model minimizes sum squares residuals residual difference true value predicted model 
attributes model directly inverting matrix modulo elaborations removing outliers coping singular matrices press flannery teukolsky vetterling 
multivariate linear models sense independent variables continuous binary valued 
attribute unordered values linear expression including interpreted ordering values index order place nominal value interpretation clearly depends heavily order chosen 
relevant peptide task description peptide involves continuous attributes presenting problem linear formalism attribute definition just name amino acid hard interpret linear model 
question belongs statistical umbrella compare alternative methods predicting activity peptides 
primary basis preferring accuracy predictions 
want consider insight provided predictive model 
second subjective focus commenting occasionally aspects intelligibility 
useful construct model peptides measure accuracy model data formed 
resubstitution estimates grossly underestimate error unseen cases breiman point constructing model predictions new peptides 
statisticians cross validation 
available data peptides divided blocks containing roughly equal number cases value distributions 
block turn model developed data remaining blocks training set evaluated cases hold block test set 
case tested model developed tests amalgamated case data tested exactly 
average performance tests predict true accuracy model developed data 
values estimate pretty reliable better resubstitution estimate 
limit set number cases data cross validation provides unbiased estimate true accuracy albeit significant computational cost 
question measurement summarise accuracy model 
common possibilities ffl average error jej average magnitude residual unseen cases 
ffl correlation actual predicted values unseen cases 
ffl relative error re defined ratio variance residuals unseen cases variance true values breiman 
perfect 
average error distorted bad predictions correlation really measures linearity relationship actual predicted values equivalence relative error insensitive systematic error predictions 
focus average error correlation intuitive interpretation give idea fit predictions 
way cross validation multivariate regression carried peptide data results jej descriptions definitions regression models capturing variation activity peptide peptide 
expected models worse attribute values unordered discrete linear combinations values relatively meaningless 
models descriptions fairly inaccurate average difference actual predicted accuracy percent activity range 

model trees second method described generalisation regression trees breiman call model trees quinlan family divide conquer algorithms includes categorical decision trees quinlan 
idea start collection known cases split subsets basis attributes activity levels subsets homogeneous 
process repeated subsets subset contains cases identical activity values small split 
node tree structure examined see simple multivariate linear model provide description data subtree subtree replaced linear model 
result tree leaf contains average value activity linear model predicting activity function attributes 
corresponds course piecewise linear model 
simple illustration ein dor collected data relative cpu performance 
cpu described terms measurements cache size cycle time minimum maximum channels minimum maximum memory 
collection cases yields model tree shown contains linear submodels average 
tree serves select prediction example value greater mmax greater predicted relative cpu rating rm 
rm mmax rm mmax rm average model rm rm rm cycle time min mem max mem cache size min max model tree returning peptide activity task results model trees way crossvalidation jej descriptions definitions show clear improvement multivariate linear regression models model tree just piecewise linear model 
attribute description peptides average error predicted accuracy unseen peptides reduced correlation actual predicted values increased 
benefit peptide definitions marked regression predictions definitions accurate descriptions reason 

instance approaches third method making predictions roots statistics ai particularly pattern recognition 
intuition want guess activity new peptide find similar peptide activity know predict unknown peptide activity 
easily generalised nearest neighbours averaging activities fixed number similar peptides 
feature methods forced construct explicit model cases know serve kind implicit model 
upside downside prototypical cases natural way represent accumulated experience insightful patterns revealed model hidden 
key issues instance learning ffl similarity cases measured 
ffl cases retained prototypes question customary treat distance description space measure dissimilarity 
presents difficulty attributes continuous values provided normalised way 
clear interpret distance attributes discrete values 
second question empirical studies aha kibler albert demonstrated retaining instances idea categorical prediction 
instance learner simple 
distance cases determined square root sum squares differences cases individual attribute values 
difference attribute values calculated aha ffl continuous attributes difference values divided difference maximum minimum values attribute appear training set 
ffl discrete attributes values 
peptides retained 
predict activity unseen case nearest known peptides average activity gives predicted value 
simple instance approach gives noticeable improvement results jej descriptions definitions compared model trees average error predicted activity unseen peptides reduced descriptions definitions 
predictions definitions suddenly competitive produced peptide descriptions correlation actual predicted activity unseen peptides reaching 

instances model trees risk attempting lily see improve result 
activity unseen peptide predicted instance method described similar peptides mean activities computed 
implicit assertion estimator activity differences ignored 
suppose produce model tree known peptides training set 
denote predicted activity peptide obtained model tree 
instance approach modified take advantage existence model tree 
recorded activity similar peptide predictor activity estimate adjusted light differences model tree predict difference activities adjusted estimate activity 
predicting activity unseen peptide similar peptides 
predicted value mean adjusted estimates peptides mean activities 
cross validation modification produces bitter sweet results jej descriptions definitions predictions derived peptide descriptions improved somewhat average error unseen cases falling 
peptide definitions average error increases sharply concomitant fall correlation actual predicted values 
explanation fall regression models model trees names constituent amino acids poor predictors result modified estimates trees accurate raw estimates formed 

instances transforms final method ai ish notion analogy essence regularity abstracted context employed 
winston excellent textbook artificial intelligence describes early evans solving perennial iq test problem winston system macbeth transfers explanations situation analogous 
regularities considered effect changing value specified attribute 
suppose know peptides differ value discrete attribute peptide value value difference ffi activities gives estimate effect changing vice versa 
pairs peptides differ attribute having value estimates effect formed 
estimates consistent plausible regularity independent context identified transform changing value effect ffi activity 
brief outline glossed details decide estimates consistent compare similar instances attributes continuous discrete 
step approach identify transforms training set 
procedure follows method adjusting estimates provided similar peptides 
selected ask identified transforms apply differences estimate adjusted accordingly 
adjustment estimates averaged give predicted activity 
effects transformations instancebased approach brought results jej descriptions definitions predictions peptide descriptions average error unseen cases reduced unmodified estimates smaller reduction obtained model trees adjust estimates 
peptide definitions see sharp reduction average error correlation improves slightly 

quickly review results peptide task 
commenced multivariate linear regression common step statistical data analysis 
best results method peptide descriptions predict activity average error unseen cases 
approach definitions peptides managed reduce average error time increasing correlation actual predicted activities 
fact look interesting peptides activities better change startling average error peptides falls regression instances plus transforms 
gain bought expense additional computation 
performing crossvalidation multivariate regression peptide descriptions requires orders magnitude cpu time crossvalidation instances plus transforms 
single task illustrate machine learning approaches 
just case impression techniques limited task state quite general applied domains 
observations trials ffl model trees accurate regression models 
ffl hybrid instances plus model trees method gives better results model trees 
may idea adjusting estimates general instance similar approach uses regression models model trees adjust estimates call instances plus regression proved accurate regression 
ffl instances plus model trees transforms complementary methods 
effective attributes continuous binary values linear submodels sensible 
particularly useful attributes unordered discrete values defeating attempt form linear models approach requires pairs training instances differ single attribute value 
believe results improved employing sophisticated methods identify similar cases postulating identifying alternative kinds transformations 
research possible australian research council assisted research agreement digital equipment 
am grateful members learning groups university sydney unsw particularly donald michie claude sammut mike cameron jones helpful comments discussion 
dr marvin national institutes health bethesda md pharmaceutical san francisco access peptide data 
aha kibler albert 
instance learning algorithms machine learning 
breiman friedman olshen stone 
classification regression trees belmont wadsworth 
ein dor 
attributes performance central processing units relative performance prediction model communications acm 
press flannery teukolsky vetterling 
numerical recipes cambridge university press 
quinlan 
learning continuous classes proceedings ai singapore world scientific 
quinlan 
programs machine learning san mateo morgan kaufmann 
winston 
artificial intelligence rd edition reading ma addison wesley 
