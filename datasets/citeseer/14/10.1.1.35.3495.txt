recommendation systems probabilistic analysis ravi kumar prabhakar raghavan sridhar rajagopalan andrew tomkins ibm almaden research center harry road san jose ca 
sridhar almaden ibm com recommendation system tracks past actions group users recommendations individual members group 
growth computer mediated marketing commerce led increased interest systems 
introduce simple analytical framework recommendation systems including basis defining utility system 
perform probabilistic analyses algorithmic methods framework 
analyses yield insights utility derived memory past actions memory exploited 

collaborative filtering known recommendation system process information preferences actions group users tracked system patterns observes tries useful recommendations individual users :10.1.1.30.6583
instance book recommendation system recommend jules interested isaac asimov fact number users expressed simultaneous interest authors 
see comprehensive listing collaborative filtering projects commercial systems 
research recommendation systems focused areas algorithms design algorithms past preferences users useful recommendations ii human factors gather information user preferences conveniently unobtrusively possible issue runs gamut user interface research marketing science iii privacy issues combine information gathered group users advantage individual users sensitive information users 
focus areas design analysis algorithms collaborative filtering quantitative evaluation 
areas just important treatment relatively orthogonal problem consider 
knowledge prior theoretical study important emerging application computing widely seen core computer mediated web marketing 
shardanand maes report cross validation study recommendations various algorithms measured real user preferences 
hill report statistical analysis correlations recommendations system users previously expressed preferences validation set training system 
prior know filtering algorithms designed followed ex post facto validation measure user satisfaction 
intent hand quantitative notion user satisfaction drive design algorithm enabling give provable guarantees usefulness recommendations generates 
main contributions 
analytical framework evaluating algorithms collaborative filtering including basis defining utility section 
focus called active collaborative filtering users explicitly actively rate items books movies encounter focus systems tacitly observe prior activity making recommendations 

probabilistic analyses simple algorithms collaborative filtering derive insights prior history useful exploit efficiently 

economic model model recommendation systems consists components 
component framework recommendation systems 
second notion utility defines objective recommendation system trying optimize 
final component simple probabilistic model user behavior 
tried keep components modular replaced sophisticated notions 
feel model simple tractable offer interesting insights 
describe component particular choices case 
framework recommendation systems 
set users fe sample items universe items purchased past 
address uniform case 
discussion denote set items purchased user 
jej items viewed nodes hyper graph samples corresponding users viewed hyper edges graph 
items may thought books movies webpages recommendation algorithm takes input sets items users outputs user remaining gamma items recommendation 
case restrict attention algorithms exactly recommendation user 
facilitate notion user prefers assume items partitioned disjoint clusters function item corresponding cluster 
clusters may thought instance topics books science fiction travel 
clustering may may known recommendation algorithm 
utility recommendations 
assume existence utility function theta giving utility recommending item user look utility functions uniform clusters 
note implicit simplification items cluster utility user see section 
objective recommendation algorithm output recommendation user utility recommendations summed users maximized 
simplification utility depends cluster recommended 
think algo purchase metaphor transaction represent browser clicks rithm choosing cluster choosing particular item 
probabilistic user model 
remainder adopt probabilistic model user behavior 
user characterized dimensional vector hp represents probability distribution clusters user 
naturally 
interpretation user sample prior purchases generated repeating procedure times independently user chooses cluster probability chooses item uniformly sample contain repetitions 
note clusters items need clusters instance samples drawn users may pronounced preferences clusters 
point crucial assume planted clusters data seek find 
final simplification relates user model utility function 
argue case point view corresponding vendor 
assume proportional analyses equal user item objective recommendation system generate recommendation user sum maximized 
notation 
denote recommendation problem users prior samples user clusters items set probabilistic preferences obvious context abbreviate denote pi expected total utility algorithm utility function probabilistic preferences expectation depend pi 
benchmarks 
may compare expected utility achieved alg achieved benchmarks weak benchmark intuitively benchmark knows partitioning items clusters ii strong benchmark knows partitioning precise probability vector user denote opt utility strong benchmark def jp max fp clearly opt upper bound utility algorithm 
denote utility weak benchmark 
strong benchmark utility weak benchmark depends complicated way particular choice see example section 
different choices demand differing methods knowledge limiting cases 
instructive consider limiting cases 
edges graph occur large multiplicities meaningful clusters apparent 
information available weak benchmark 
additionally algorithm estimate distribution particular user correct high probability information available strong benchmark 

related research areas model approach builds number research areas briefly explain connections ways differs 
marketing science rich models consumer behavior preferences models appear mathematically tractable frameworks 
user model tractable simplistic comparison hope model realistic 
computer science describe overlapping categories related 
category consists data analysis tools clustering data mining latent semantic indexing lsi learning 
cases goal infer learn structure characterizing data set 
clustering partitions data set groups similar measure data mining looks interesting patterns data lsi analyzes spectral properties term document matrix cluster closely related documents learning builds hypothesis perform cross validated data generated true concept 
differs fundamental way 
goal identify structures patterns data set exploit patterns exist necessarily inferring formally 
reader notice compared algorithms aforementioned situations different goal allows simpler approaches 
second category includes probabilistic methods boppana probabilistic analysis lsi 
departs respects seek simple algorithms eigenvector computations ii assumption overwhelming preference require users drawn small number types implicitly needed 
hand algorithm achieve strong document clustering results establishes lsi 
final category includes segmentation problems 
class closely related explicit notion value utility 
segmentation model described general analyzable context 
tractable special cases segmentation problem include facility location lsi clustering 
cases data embedded explicit metric similarity space plays central role proposed solutions 
absence space basic difference problems 

critique extensions model view user having fixed preference cluster utility proportional preference certainly simplistic 
believe step important lessons learned pave way study 
obvious refinements include reality clusters alike 
instance cluster science fiction different cluster java purchase large number science fiction books purchase large number books java 
assumed items cluster equally attractive buyer reality items popular 
easy augment model non uniform distribution cluster analysis appears harder 
seek algorithms maximize total utility enterprise operating system may wish 
variations maximizing minimum utility user model situation wish keep users happy 
assume users equally important 
reality may give greater weight frequent 
model user preferences indicated prior purchases boolean generally may model finely graded preferences 
particular extend model active collaborative filtering expressed preferences negative meaning user particular item 
interesting consider time dependent user preferences leading sequential collaborative patterns system tries infer user needs 
despite possible extensions feel model start simple tractable offers interesting insights 
time challenging interesting cases remain open 
reader may noticed model assume prior patterns preferences scientists tend science fiction 
hope collaborative filtering absence explicit sub populations 
fact algorithm recommendations user preferences similar users evident sample data 
sample data indicates strong sub populations fact exploit patterns apparent best algorithm information available strong benchmark able find exploit 

main results model designing measuring algorithms collaborative filtering main contributions 
addition results establish model 
section compare performance weak benchmark strong benchmark 
useful reasons weak benchmark represents limit algorithm achieve collaborative filtering manages learn clustering items sample possible improvement achieved larger sample size better understanding individual users preferences ii situations algorithm may access clustering information 
show opt 
extend result general case samples giving tradeoff information values number samples identities clusters 
give tight bounds special case clusters 
section consider recommendation algorithms weak benchmark enjoy knowledge clusters 
give algorithms competitive respect opt 
algorithms extremely simple 
fact show algorithms garner information truly collaborative way increases show performances algorithms approach 
collaborative information collaborative filtering yielded perfect information clustering extent information exploited 
address question study situation 
easy see assumption fairly simple algorithms identify clusters event vanishing probability clusters delineated user preferences important utility maximization 
issue information 
address different aspects question 
section addresses performance collaborative filtering function number clusters 
section examines improvements possible number samples user increases 
intuitively grows stays fixed value collaborative information decline 
grows stays fixed marginal benefit increasing decline 
prove results theorems formalize intuitions 
analyses depend characterizing worst case distribution user preferences facts useful evaluating benefits collaborative information actual user distribution truly adversarial 
section provide analysis gives tighter performance bounds function simple measurable parameters user preference distributions 
restrict complete analysis simplest case 

case effect clusters consider case 
smallest meaningful value correlation information items available collaborative filtering meaningless 
user edge graph nodes items 
denote edge corresponding user consider case 
case nodes partitioned clusters algorithm case take sequence edges decide edge recommend item fix problem assume 
straightforward see optimal algorithm vote item sees edge 
furthermore sees cross edge vote case may vote cluster 
case exists optimal algorithm votes cross edges 
edge optimal algorithm depends set fp vic algorithm vic vote cluster votes edge cross edge 
votes edge 
voc algorithm voc vote cluster votes input 
describe third algorithm called vrc better vic worse 
show problems induce worst case ratio opt vrc equivalent vic optimal problems 
furthermore vrc performs worse problems problem optimal worst case ratio problems 
simpler analyze vic 
vrc algorithm vrc vote randomly cross edges votes edge votes uniformly random 
example 
illustrative consider example voc performs better vic 
types users 
users distribution 
second users distribution 
expected utility voc edges cluster theta theta expected utility vic theta theta approximately times smaller 
extend definitions vic vrc general follows 
say heavier 
edge vic votes heavier heavier 
denotes cluster containing item 
vrc hand votes cluster chosen uniformly random endpoints edge 
voc generalizes family algorithms case 
ae alg pi alg pi opt 
show vrc achieves best possible worst case performance ratio compared opt theorem 
inf ae vrc inf ae pi vrc pi opt oe 
algorithm alg inf ae alg inf ae pi alg pi opt oe note 
theorem fact holds equal number clusters user non zero probability 
significant lessons ratio depends spread interests users 
ii users interests ratio user interested clusters reasonably realistic ratio 
extended case users probability distribution clusters 
proof recall pi opt 
second utility vrc sum users 
utility user depends edge sample distribution 
cross edge occurs probability generates utility vrc votes candidate clusters uniformly random cross edges 
edge occurs probability generates utility 
utility vrc written pi vrc jk utility opt depends assume loss generality worst case minimizes subject remaining unchanged 
concreteness favorite cluster user 
fixed seek minimize subject gamma 
symmetric concave function minimized 
worst case preference distribution user characterized quantities 
know gamma gamma 
understand nature distributions better require lemmas 
consider problem 
define symmetric closure follows user original problem replace 
users distributions oe permutation oe resulting distribution function 
lemma pi vic pi vrc vic optimal proof show pi vic pi vrc 
assume vic votes cross edges distribution symmetric user prefers paired user opposite preference 
utility vic users equivalent utility vrc 
show vrc optimal symmetric distribution 
alg cluster voted alg edge total utility alg edges oe sk oe gamma oe gamma oe gamma alg 
alg fi jg sum simply assume say alg vrc sum gamma 
straightforward differential calculus sum large 
lemma permutation lemma alg optimal algorithm knows clusters problem 
algorithm alg pi alg pi alg proof notice mean utility users opt unchanged assumption pi alg pi vrc 
lemma pi vrc pi alg 
show pi vrc pi vrc 
breaking vrc expected utility cluster edges cross edges write pi vrc 
clearly mean utility vic identical cluster edges 
cross edges expected utility rewritten clearly identical utility cross edges complete proof theorem 
shown distribution interesting issue 
denote fraction density users ae vrc written ae vrc vrc dx dx vrc gamma gamma gamma gamma gamma ratio minimized concentrating density particular value vrc minimized interval 
standard differential calculus shows vrc minimized consequently ae vrc 
exhibit distribution ae vrc 
consider user hq gamma gamma gamma gamma gamma problem equal size clusters symmetric closure vrc optimal distribution lemma 
utility vrc user distribution pi vrc delta gamma delta gammaq gamma gamma delta gamma gamma kq gamma gamma clearly utility opt user choose maximize kq gamma gamma yields gives ratio 

samples need 
consider values study behavior worst case performance ratio varies fixed continue assume 
primary question extent sample size distribution points benefit relative sample size 
simple extension vrc pick random point choose cluster containing point 
careful look reveals algorithm equivalent case improve competitive ratio 
algorithm study section called max 
algorithm looks sample votes cluster contains largest number elements sample 
cluster qualifies max chooses random 
notice specializes vrc 
arguments similar section deduce worst case distribution assumed symmetric gamma gamma 
denote fraction density users argue ae max min max max denotes expected utility max single user distribution gamma gamma performance max depends gap ffl gamma ffl small relative say regardless algorithm ae gamma 
need look case 
consider types bad events number samples cluster smaller gamma ffl second number samples cluster larger ffl event cluster largest number samples bad events guaranteed occurred 
probability bad event bounded exp gammaffl standard tail bound 
initial factor union bound bad events 
consequently log sufficient obtain ae gamma bound fact tight asymptotic theorem log user preference pi vrc gamma delta pi opt 

tighter analysis case section gives tighter performance bounds particular classes preference distributions 
moments taken users probability user buys def 
assume fixed determine worst case distribution corresponding competitive ratio 
performance vrc rewritten pi vrc gamma gamma words performance vrc completely characterized moments preference distribution 
extend permutation lemma fixed moment distributions obtain lemma proof omitted 
lemma fixed user preference distribution minimizes ae vrc contains distinct values 
candidate values gammay fraction users respectively 
show lemma 
lemma max pi vrc max fy gamma gamma gamma proof incorporating constraints lagrange multipliers obtain condition 
substituting back obtain gamma gamma gamma gamma gamma lemma follows 
observations ratio performance vrc opt obtained lemma gamma distributions moments pi vrc pi opt seen right side quantity gamma gamma 
expression lets write exact ratio various moments preferences expected ratio approaches large small values surprisingly bound function variable function 
algorithms previous section showed perfect collaborative filtering allows algorithm competitive respect benchmark knows user distribution 
study complementary question give simple algorithms perform collaborative filtering clusters known bounded 
continue focus basic case 
furthermore results section require clusters roughly equal sizes 
removing assumption challenging 
primary result section relatively simple algorithm call neighbor compares favorably opt knows clusters distribution user 
give results comparing neighbor vrc knows just clusters 
summarize show distribution pi neighbor delta pi vrc 
section pi vrc delta pi opt 
show pi neighbor delta pi opt 
note strictly greater showing neighbor vrc achieve worst cases different distributions 
propose new algorithm voting algorithm performs neighbor 

neighbor algorithm neighbor algorithm simple graph corresponding problem instance 
user sample fb recommend item fb fb despite simplicity performance algorithm far optimal opt 
prove theorem theorem set preferences pi neighbor delta pi opt proof proof consists steps 
prove theorem particular probabilistic distribution delta show lemma performance neighbor delta 
consider set probabilistic preferences delta gamma exactly classes users occurring equal probability denoted distributions hp hp lemma immediate lemma probability random edge adjacent inside probability cross edge compute expected utility neighbor delta 
consider hp user 
user may generate types edge edge probability case neighbor probability yields utility remaining probability yielding utility ii cross edge probability utility iii edge probability neighbor probability yielding utility remaining probability yielding utility summing obtain pi neighbor fact pi opt show pi neighbor delta pi opt 
show delta considered worst case neighbor 
precisely show lemma set preferences pi neighbor pi neighbor proof consider performance neighbor preference delta 
probability random edge edge theta gamma gamma probability cross edge 
denote edge density 
ff theta probability neighbor edge likewise fi theta probability neighbor edge write pi neighbor pi neighbor gamma gamma gamma ffp gamma fi gamma delta consider performance neighbor symmetric closure delta delta 
ff fi analogs ff fi respect delta 
note ff fi symmetry delta 
write pi neighbor ff gamma gammap show pi neighbor pi neighbor 
combining previous equations leads inequality gamma ff ffp gamma fi gamma converting expression central moments mean oe variance random variable get gamma ff oe ff gamma fi gamma fi derivation ff fi similarly derive value ff cluster density 
converting resulting expression central moments allows derive useful equality ff ff gamma fi substitution assuming ff fi lemma follows inequality gamma oe true 
combining performance neighbor vrc get corollary asserts knowledge clusters neighbor performs compared vrc 
corollary preferences pi neighbor delta pi vrc 

voting algorithm voting algorithm generalization neighbor algorithm graph corresponding problem instance 
user sample fb recommend item neighbor maximum multiplicity 
proof theorem assume set probabilistic preferences delta 
easy show leads worst case scenario voting 
note edge probabilities neighbor multiplicity respectively voting algorithm votes neighbor multiplicity analysis obtain utility voting pi voting theorem shows relationship voting performance theorem set preferences lim pi voting gamma delta pi opt proof expected multiplicity neighbor note 
lim quantities respectively 
theorem follows analyzing pi voting 
theorem asserts performance voting approaches 
voting generalization neighbor important study performance voting function suppose omega gamma gammaffl 
high probability nodes neighbor multiplicity omega gammam ffl 
corollary set preferences gammaffl pi voting pi voting ffl 

introduce framework studying algorithmic issues arising recommendation systems 
isolated modeling issues model user utility model user preferences central issues framework 
study basic cases arising simple probabilistic model utility user preferences 
show cases provide interesting insights recommendation systems start valuable relatively little data user 
value data related diversity interests user population 
ii simple algorithms effective best possible terms utility 
issues remain open notably extending analyses general models suggested section 
allen 
user models theory method practice 
international journal man machine studies 
berry 
data mining techniques 
john wiley 

information processing theory consumer choice 
addison wesley publishing 
little eds 
marketing information revolution harvard business school press 
bollobas 
random graphs 
academic press ny 
boppana 
eigenvalues graph bisection average case analysis proc 
ieee symp 
foundations computer science 
deerwester dumais landauer furnas harshman 
indexing latent semantic analysis 
journal society information science 
ed 
facility location survey applications methods springer 

marketing information intensive environment strategic implications knowledge asset journal marketing 
goldberg nichols oki terry 
collaborative filtering weave information tapestry 
communications acm pp 

golub van loan 
matrix computations johns hopkins university press 
hill stead rosenstein furnas 
recommending evaluating choices virtual community 
proceedings acm chi pp 

hoffman novak 
marketing hypermedia computer mediated environments conceptual foundations 
journal marketing 
howard 
consumer behavior marketing strategy prentice hall englewood cliffs nj 
kleinberg papadimitriou raghavan 
segmentation problems 
proceedings acm symposium theory computing 
miller riedl konstan 
experiences grouplens making usenet useful 
proceedings usenix conference 
papadimitriou raghavan tamaki vempala 
latent semantic indexing probabilistic analysis 
proceedings acm symposium principles database systems 
resnick iacovou suchak bergstrom riedl 
grouplens open architecture collaborative filtering netnews center coordination science mit sloan school management report wp 
shardanand maes 
social information filtering algorithms automating word mouth proceedings acm conference human factors computing systems pp 
may acm resource page collaborative filtering 
www acm org collab html 
valiant 
theory learnable 
cacm 
varian 
resources collaborative filtering 
www sims berkeley edu resources collab 
varian resnick eds 
cacm special issue recommender systems 
cacm 
