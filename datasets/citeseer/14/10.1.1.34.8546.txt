eddies continuously adaptive query processing ron avnur joseph hellerstein university california berkeley avnur com cs berkeley edu large federated shared databases resources exhibit widely fluctuating characteristics 
assumptions time query submitted rarely hold duration query processing 
result traditional static query optimization execution techniques ineffective environments 
introduce query processing mechanism called eddy continuously reorders operators query plan runs 
characterize moments symmetry pipelined joins easily reordered synchronization barriers require inputs different sources coordinated 
combining eddies appropriate join algorithms merge optimization execution phases query processing allowing tuple flexible ordering query operators 
flexibility controlled combination fluid dynamics simple learning algorithm 
initial implementation demonstrates promising results eddies performing nearly static optimizer executor static scenarios providing dramatic improvements dynamic execution environments 
increasing interest query engines run unprecedented scale widely distributed information resources massively parallel database systems 
building system called telegraph intended run queries data available line 
key requirement large scale system telegraph function robustly unpredictable constantly fluctuating environment 
unpredictability endemic large scale systems increased complexity number dimensions hardware workload complexity wide area environments variabilities commonly observable bursty performance servers networks ufa 
systems serve large communities users aggregate behavior hard predict hardware mix wide area quite heterogeneous 
large clusters computers exhibit similar performance variations due mix user requests heterogeneous hardware evolution 
totally homogeneous environments hardware performance unpredictable example outer tracks disk exhibit twice bandwidth inner tracks met 
data complexity selectivity estimation static eddy pipeline 
data flows eddy input relations eddy routes tuples operators operators run independent threads returning tuples eddy 
eddy sends tuple output handled operators 
eddy adaptively chooses order route tuple operators 
data sets fairly understood initial estimating statistical properties static sets data complex types methods bo 
federated data comes statistical summaries complex non alphanumeric data types widely object relational databases web 
scenarios traditional static relational databases selectivity estimates quite inaccurate 
user interface complexity large scale systems queries run long time 
result interest online aggregation techniques allow users control properties queries execute refining approximate results hac 
reasons expect query processing parameters change significantly time telegraph typically times single query 
result appropriate traditional architecture optimizing query executing static query plan approach adapt intra query fluctuations 
environments want query execution plans regularly course query processing allowing system adapt dynamically fluctuations computing resources data characteristics user preferences 
query processing operator called eddy continuously reorders application pipe lined operators query plan tuple tuple basis 
eddy ary tuple router interposed data sources set query processing operators eddy encapsulates ordering operators routing tuples dynamically 
eddy observes tuples entering exiting pipelined operators adaptively change routing effect different operator orderings 
initial experimental results demonstrating viability eddies reorder effectively face changing selectivities costs provide benefits case delayed data sources 
query execution pipeline fly requires significant care maintaining query execution state 
highlight query processing stages called moments symmetry operators easily reordered 
describe synchronization barriers certain join algorithms restrict performance rate slower input 
join algorithms frequent moments symmetry adaptive non existent barriers especially attractive telegraph environment 
observe ripple join family hh provides efficiency frequent moments symmetry adaptive nonexistent barriers alike 
eddy architecture quite simple obviating need traditional cost selectivity estimation simplifying logic plan enumeration 
eddies represent step larger attempt away traditional optimizers entirely hope providing run time adaptivity reduction code complexity 
focus continuous operator reordering single site query processor leave optimization issues discussion 
run time fluctuations properties vary query processing costs operators selectivities rates tuples arrive inputs 
third issues commonly occur wide area environments discussed literature ufa iff 
issues may common cluster shared systems scale thousands nodes bar 
run time variations selectivity widely discussed occur quite naturally 
commonly arise due correlations predicates order tuple delivery 
example consider employee table clustered ascending age selection salary age salary strongly correlated 
initially selection filter tuples delivered selectivity rate change older employees scanned 
selectivity time depend performance fluctuations parallel dbms clustered relations horizontally partitioned disks rate production various partitions may change time depending performance characteristics utilization different disks 
online aggregation systems explicitly allow users control order tuples delivered data preferences resulting similar effects 
architectural assumptions telegraph intended efficiently flexibly provide distributed query processing sites wide area parallel query processing large shared cluster 
narrow focus somewhat concentrate initial difficult problem run time operator reordering single site query executor changing effective order shape pipelined query plan tree face changes performance 
discussion assume initial query plan tree constructed parsing naive 
optimizer need exercise judgement reordering plan tree fly 
constructing query plan choose spanning tree query graph set table pairs join kbz algorithms joins 
return choice join algorithms section defer section discussion changing spanning tree join algorithms processing 
study standard single node object relational query processing system added capability opening scans indexes external data sets 
common base architecture available commercial object relational systems ibm db udb informix dynamic server udo federated database systems hsc 
refer non resident tables external tables 
assumptions limiting scale external sources may arbitrarily large 
external tables dynamic challenges described reside wide area network face bursty utilization offer minimal information costs statistical properties 
overview introducing eddies section discuss properties query processing algorithms allow disallow frequently reordered 
eddy architecture describe allows extreme flexibility operator ordering section 
section discusses policies controlling tuple flow eddy 
variety experiments section illustrate robustness eddies static dynamic environments raise questions 
survey related section section lay research program carry forward 
plans basic challenge run time reoptimization reorder pipelined query processing operators flight 
change query plan fly great deal state various operators considered arbitrary changes require significant processing code complexity guarantee correct results 
example state maintained operator hybrid hash join grow large size input relation require modification recomputation plan reordered state constructed 
constraining scenarios reorder operators keep minimum 
describing eddies study state management various join algorithms discussion motivates eddy design forms basis approach cheaply continuously 
philosophy favor adaptivity best case performance 
highly variable environment best case scenario rarely exists significant length time 
sacrifice marginal improvements idealized query processing algorithms prevent frequent efficient reoptimization 
synchronization barriers binary operators joins capture significant state 
particular form state operators relates interleaving requests tuples different inputs 
example consider case merge join sorted duplicate free inputs 
processing tuple consumed relation tuple lower value 
significantly constrains order tuples consumed extreme example consider case slowly delivered external relation low values join column high bandwidth large local relation high values join column processing postponed long time consuming tuples 
terminology parallel programming describe phenomenon synchronization barrier table scan waits table scan produces value larger seen 
general barriers limit concurrency performance tasks take different amounts time complete arrive barrier 
recall concurrency arises single site query engines simultaneously carry network disk computation 
desirable minimize overhead synchronization barriers dynamic static heterogeneous performance environment 
issues affect overhead barriers plan frequency barriers gap arrival times inputs barrier 
see upcoming discussion barriers avoided tuned appropriate join algorithms 
moments symmetry note synchronization barrier merge join stated order independent manner distinguish inputs property data deliver 
merge join described symmetric operator inputs treated uniformly case join algorithms 
consider traditional nested loops join example 
outer relation nested loops join synchronized inner relation vice versa tuple block tuples consumed outer relation barrier set full scan inner completed 
asymmetric operators nested loops join performance benefits obtained reordering inputs 
join algorithm reaches barrier declared scheduling dependency input relations 
cases order inputs join changed modifying state join true refer barrier moment symmetry 
return example nested loops join outer relation inner relation barrier join completed full inner loop having joined tuple subset tuple reordering inputs point done affecting join algorithm long duplicates merge join duplicates handled asymmetric usually small nested loop 
purposes exposition ignore detail 
tuples generated nested loops join reordered moments symmetry 
axis represents tuples corresponding relation order delivered access method 
dots represent tuples generated join may eliminated join predicate 
numbers correspond barriers reached order 
cr cs cursor positions maintained corresponding inputs time reorderings 
iterator producing notes current cursor position cr case new outer loop begins fetching tuple scanned cr 
repeated indefinitely joining tuples tuples position cr 
alternatively loop moment symmetry order inputs swapped remembering current position repeatedly joining tuple starting cr tuples cs 
depicts scenario changes ordering 
operators pipelined hash join wa barriers whatsoever :10.1.1.56.701
operators constant symmetry processing inputs totally decoupled 
moments symmetry allow reordering inputs single binary operator 
generalize noting joins commute tree binary joins viewed single ary join 
easily implement doubly nested loops join operator relations moments complete symmetry loop point inputs reordered say straightforward extension discussion cursor recorded input loop go recorded cursor position input 
effect obtained binary implementation operators swapping positions binary operators effectively plan tree transformation go steps approach treats operator right hand input unit unit swaps units idea previously static query optimization schemes ik kbz hel 
viewing situation manner naturally consider reordering multiple joins inputs join algorithms different 
query need mutually commutative require join algorithm 
discuss commutativity join algorithms section 
note combination commutativity moments symmetry allows aggressive reordering plan tree 
single ary operator representing plan tree attractive abstraction encapsulates ordering may subject change 
exploit abstraction directly interposing ary tuple router eddy input tables join operators 
joins indexes nested loops joins take advantage indexes inner relation resulting fairly efficient pipelining join algorithm 
index nested loops join henceforth index join inherently asymmetric input relation pre indexed 
indexes exist inputs changing choice inner outer relation fly problematic purposes reordering simpler think index join kind unary selection operator unindexed input join 
distinction index join selection respect unindexed relation selectivity join node may greater 
swap inputs single index join reorder index join indexed relation unit operators plan tree 
note logic indexes applied external tables require bindings passed tables may gateways web pages forms gis index systems ldap servers 
physical properties predicates commutativity clearly pre optimizer choice index join algorithm constrains possible join orderings 
ary join view ordering constraint imposed unindexed join input ordered necessarily directly indexed input 
constraint arises physical property input relation indexes probed scanned appear corresponding probing tables 
similar complex constraints arise preserving ordered inputs merge join preserving interesting orders 
applicability certain join algorithms raises additional constraints 
join algorithms joins cartesian products 
algorithms constrain reorderings plan tree require relations mentioned equijoin predicates handled 
consider ordering constraints aspect plan tree ensure hold 
section sketch initial ideas relaxing requirement considering multiple join algorithms query graph spanning trees 
join algorithms reordering order eddy effective favor join algorithms frequent moments symmetry adaptive nonexistent barriers minimal ordering constraints algorithms offer opportunities reoptimization 
ah summarize salient properties variety join algorithms 
desire avoid blocking rules hybrid hash join desire minimize ordering constraints barriers excludes merge joins 
nested loops joins unclustered indexes index ordering scan ordering 
reordering inputs difficult ensure terminology section lookups index new inner relation produce tuples cr infrequent moments symmetry imbalanced barriers making undesirable 
algorithms consider frequently symmetric versions traditional iteration hashing indexing schemes ripple joins hh 
note original pipelined hash join wa constrained version hash ripple join :10.1.1.56.701
external hashing extensions uf iff directly applicable hash ripple join hh treats index joins special case 
non block ripple join algorithm effective having frequent moments symmetry particularly processing hh 
illustrates block index hash ripple joins reader referred hh iff uf detailed discussions algorithms variants 
algorithms adaptive sacrificing performance uf iff demonstrate scalable versions hash ripple join perform competitively hybrid hash join static case hh shows block ripple join efficient nested loops join arrives moments symmetry frequently nested loops joins especially early stages processing 
ah discuss memory overheads adaptive algorithms larger standard join algorithms 
ripple joins moments symmetry corner rectangular ripple prefix input stream joined tuples prefix input stream vice versa 
hash ripple joins index joins scenario occurs consecutive tuple consumed scanned input 
ripple joins offer frequent moments symmetry 
ripple joins attractive respect barriers 
ripple joins designed allow changing rates input originally proactively expend processing input relation statistical influence intermediate results 
mechanism allows reactive adaptivity wide area scenario barrier reached corner corner adaptively reflect relative rates inputs 
block ripple join corner chosen reaching previous corner done adaptively reflect relative rates inputs time 
ripple join family offers attractive adaptivity features modest overhead performance memory footprint 
fit philosophy sacrificing marginal speed adaptability focus algorithms telegraph 
rivers eddies discussion allows consider easily reordering query plans moments symmetry 
section proceed describe eddy mechanism implementing reordering natural manner query processing 
techniques describe operators algorithms frequent moments symmetry allow frequent reoptimization 
discussing eddies introduce basic query processing environment 
river implemented eddies context river aat shared parallel query processing framework dy tuples generated block index hash ripple join 
block ripple tuples generated join may eliminated join predicate 
arrows index hash ripple join represent logical portion cross product space checked far joins expend tuples satisfying join predicate black dots 
hash ripple diagram relation arrives faster 
adapts fluctuations performance workload 
river robustly produce near record performance intensive benchmarks parallel sorting hash joins despite heterogeneities dynamic variability hardware workloads machines cluster 
details river adaptivity parallelism features interested reader referred original topic aat 
telegraph intend leverage adaptability river allow dynamic shifting load query processing data delivery shared parallel environment 
restrict basic single site features eddies discussions eddies parallel rivers deferred section 
discuss parallelism simple overview river framework suffices 
river dataflow query engine analogous ways gamma dgs volcano gra commercial parallel database engines iterator style modules query operators communicate fixed dataflow graph query plan 
module runs independent thread edges graph correspond finite message queues 
producer consumer run differing rates faster thread may block queue waiting slower thread catch 
ufa river multi threaded exploit algorithms reading various inputs independent rates 
river implementation derives sort aac features efficient mechanisms including pre fetching scans avoidance operating system buffering high performance user level networking 
pre optimization eddies reorder tables joins heuristic pre optimizer choose initially pair relations joins constraint relation participates join 
corresponds choosing spanning tree query graph nodes represent relations edges represent binary joins kbz 
reasonable heuristic picking spanning tree forms chain cartesian products tables known small handle star schemas base table cardinality statistics available picks arbitrary equijoin edges assumption relatively low selectivity followed arbitrary non equijoin edges required complete spanning tree 
spanning tree query graph pre optimizer needs choose join algorithms edge 
equijoin edge index join index available hash ripple join 
non equijoin edge block ripple join 
simple heuristics allow focus initial eddy design section initial ideas making spanning tree algorithm decisions adaptively 
eddy river eddy implemented module river containing arbitrary number input relations number participating unary binary modules single output relation eddy encapsulates scheduling participating operators tuples entering eddy flow operators variety orders 
essence eddy explicitly merges multiple unary binary operators single ary operator query plan intuition section symmetries easily captured ary operator 
eddy module maintains fixed sized buffer tuples processed operators 
operator participating eddy inputs fed tuples eddy output stream returns tuples eddy 
eddies named circular data flow river 
tuple entering eddy associated tuple descriptor containing vector ready bits done bits indicate respectively operators process tuple processed tuple 
eddy module ships tuple operators corresponding ready bit turned 
processing tuple operator returns eddy corresponding done bit turned 
done bits tuple sent eddy output sent eligible operator continued processing 
prevents ary operators eddy implementations atypical database query processing discuss 
eddy receives tuple inputs zeroes done bits sets ready bits appropriately 
simple case eddy sets ready bits signifying ordering operators acceptable 
ordering constraints operators eddy turns ready bits corresponding operators executed initially 
operator returns tuple eddy eddy turns ready bit operator eligible process tuple 
binary operators generate output tuples correspond combinations input tuples cases done bits ready bits input tuples ored 
manner eddy preserves ordering constraints maximizing opportunities tuples follow different possible orderings operators 
properties eddies merit comment 
note eddies represent full class bushy trees corresponding set join nodes possible instance pairs tuples combined independently different join modules routed third join perform way concatenation binary records 
second note eddies constrain reordering moments symmetry eddy 
operator carefully refrain fetching tuples certain inputs moment symmetry nested loops join fetch new tuple current outer relation finished inner 
requirement operators eddy moment symmetry occurs just operator fetching new tuple 
eddies quite flexible shapes trees generate scenarios logically reorder operators 
routing tuples eddies eddy module directs flow tuples inputs various operators output providing flexibility allow tuple routed individually operators 
routing policy eddy determines efficiency system 
section study promising initial policies believe rich area 
outline remaining questions section 
eddy tuple buffer implemented priority queue flexible prioritization scheme 
operator highest priority tuple buffer corresponding ready bit set 
simplicity start considering simple priority scheme tuples enter eddy low priority returned eddy operator high priority 
simple priority scheme ensures tuples flow completely eddy new tuples consumed inputs ensuring eddy clogged new tuples 
experimental setup order illustrate eddies initial experiments section pause briefly describe experimental setup 
experiments run single processor sun ultra workstation running solaris mb ram 
implementation river aat 
synthetically generated relations table byte tuples relation 
allow experiment costs selectivities selections selection modules artificially implemented table cardinality values column table cardinalities tables values uniformly distributed 
cost 
completion time secs naive lottery performance selections cost varies runs 
spin loops corresponding relative costs followed randomized selection decision appropriate selectivity 
describe relative costs selections terms delay units studying optimization absolute number cycles spin loop irrelevant 
implemented simplest version hash ripple join identical original pipelining hash join wa implementation exert statistically motivated control disk resource consumption hh :10.1.1.56.701
simulated index joins doing random os file returning average number matches corresponding pre programmed selectivity 
filesystem cache allowed absorb index os warming 
order fairly compare eddies static plans simulate static plans eddies enforce static ordering tuples setting ready bits correct order 
naive eddy fluid dynamics operator costs illustrate eddy works consider simple single table query expensive selection predicates traditional assumption performance selectivity properties change execution 
sql query simply select experiment wish see naive eddy account differences costs operators 
run query multiple times setting cost delay units selectivities selections 
run different cost varying delay units runs 
compare naive eddy selections possible static orderings selectivity completion time secs naive lottery performance selections cost selectivity varies runs 
selections lottery eddy say section imagine flexible routing naive eddy deliver tuples selections equally half tuples flow half resulting performance 
shows case naive eddy nearly matches better orderings cases explicit information operators relative costs 
naive eddy effectiveness scenario due simple fluid dynamics arising different rates consumption 
recall edges river dataflow graph correspond fixed size queues 
limitation effect back pressure fluid flow production input edge limited rate consumption output 
lower cost selection left consume tuples quickly spends time tuple result lower cost operator exerts back pressure input table 
time operator produces tuples relatively slowly low cost operator rarely required consume high priority previously seen tuple 
tuples routed lowcost operator costs explicitly exposed tracked way 
fast eddy learning selectivities naive eddy works handling operators different costs equal selectivity 
considered differences selectivity 
second experiment keep costs operators constant equal units keep selectivity fixed vary selectivity runs 
results encouraging showing naive eddy performing originally expected half way best worst plans 
clearly naive priority scheme resulting back pressure insufficient capture differences selectivity 
resolve dilemma priority scheme favor operators consumption production rate 
note consumption input rate operator determined cost production output rate determined product cost selectivity 
operator back pressure input depends largely consumption rate surprising naive scheme selectivity cumulative tuples routed naive lottery tuple flow lottery scheme experiment 
capture differing selectivities 
track consumption production time enhance priority scheme simple learning algorithm implemented lottery scheduling ww 
time eddy gives tuple operator credits operator ticket 
time operator returns tuple eddy ticket eddy running count operator 
eddy ready send tuple processed holds lottery operators eligible receiving tuple 
interested reader referred ww simple efficient implementation lottery scheduling 
operator chance winning lottery receiving tuple corresponds count tickets operator turn tracks relative efficiency operator draining tuples system 
routing tuples lottery scheme eddy tracks learns ordering operators gives efficiency 
lottery curve figures show intelligent lottery routing scheme compared naive back pressure scheme static orderings 
lottery scheme handles scenarios effectively slightly improving eddy changing cost experiment performing better naive changing selectivity experiment 
explain bit display percent tuples followed order opposed eddy schemes roughly represents average ratio lottery tickets possessed time 
note naive back pressure policy barely sensitive changes selectivity fact drifts slightly wrong direction selectivity increased 
contrast lottery scheme adapts quite nicely selectivity varied 
graphs see costs selectivities close equal percentage tuples cheaper order close 
observation intuitive quite significant 
eddy approaches cost optimal ordering concern strictly observing optimal ordering 
contrast earlier runtime reoptimization kd ufa iff traditional query optimizer runs processing determine optimal plan 
focusing cost finding optimal plan lottery scheme probabilistically provides nearly optimal performance effort allowing re optimization done extremely lightweight technique executed multiple times tuple 
related observation lottery algorithm gets closer perfect routing right left 
corresponding performance graph differences eddy optimal static ordering change settings 
phenomenon explained examining making ordering errors case 
consider left side graph selectivity costs delay units 
rate tuples routed erroneously case 
expected cost query 

ec 
contrast second case selectivity changed expected cost 

ec 
higher selectivity lottery aggressively favors optimal ordering selectivity 
joins discussed selections point ease exposition course joins common expensive operator query processing 
section study eddies interact pipelining ripple join algorithms 
moment continue study static performance environment validating ability eddies scenarios static techniques effective 
simple table query select experiment constructed plan hash ripple join index join data uniformly distributed table indicates selectivity rs join selectivity respect tuple entering join finds matching tuples average hel 
artificially set selectivity index join selectivity 
shows relative performance eddy schemes static join orderings 
results echo results selections showing lottery eddy performing nearly optimally naive eddy performing best worst static plans 
noted section index joins analogous selections 
hash joins complicated symmetric behavior merit additional study 
presents performance hash ripple versions query 
memory pipelined hash joins cost 
change data selectivity st join version 
runs selectivity rs join predicate fixed 
shows lottery eddy continues perform nearly optimally 
shows percent tuples eddy follow order join experiments 
eddy strict optimal ordering execution time plan secs hash lottery naive index performance joins selective index join hash join execution time plan secs st sr eddy sr st st sr eddy sr st performance hash joins selectivity selectivity varies runs 
quite close case experiment hash join precede index join 
case relative cost index join high choosing drives hash join nearly win lottery 
responding dynamic fluctuations eddies adaptively react time changes performance data characteristics described section 
routing schemes described point considered achieve 
particular lottery scheme weighs experiences equally observations distant past affect lottery observations 
result operator earns tickets early query may wealthy take great deal time lose ground top history 
avoid need modify point scheme forget history extent 
simple way window scheme time partitioned windows eddy keeps track counts operator number tickets number escrow tickets 
tickets running lottery 
escrow tickets measure efficiency window 
window value es cumulative tuples routed correct join index beats hash hash beats index hash hash hash hash percent tuples routed optimal order join experiments 
execution time plan secs sf eddy fs adapting changing join costs performance 
crow account replaces value account escrow escrow account reset es crow 
scheme ensures operators re prove window 
consider scenario table equijoin query tables external inner relations index joins 
third relation tuples 
assume index servers remote implement cost index module time delay gettimeofday spin loop better models behavior waiting external event network response 
phases experiment initially index call fs fast time delay sf slow seconds lookup 
seconds second phase indexes swap speeds fs index slow sf fast 
indexes return single matching tuple time 
shows performance possible static plans compared eddy lottery window scheme 
hope eddy faster static plan 
static plan sf fs initial index join plan slow phase processing tuples discarding 
remainder run plan quickly discards tuples passing expensive second join 
second static tuples seen 
cumulative tuples routed index 
adapting changing join costs tuple movement 
plan fs sf initial join begins fast processing tuples passing second slower join 
seconds second join fast handles remainder tuples quickly join slowly processes remaining tuples seconds tuple 
eddy static plans phase behaves identically second static plan consuming tuples queueing eddy pass sf just phase begins eddy adapts ordering passes tuples sf new fast join 
result eddy spends seconds phase phase tuples queued sf fast tuples process passed ifs slow 
similar controlled experiment illustrates eddy adaptability clearly 
run table join external indexes return match time 
read tuples scanned table toggle costs cost units tuples times experiment 
shows eddy adapts correctly switching orders operator costs switch 
cost differential dramatic lower eddy takes bit longer adapt 
despite learning time trends clear eddy sends tuples index starts cheap 
sends second tuples index causing percentage tuples reach reflected near linear drift second quarter graph 
pattern repeats third fourth quarters eddy eventually displaying orderings time favoring best ordering 
brevity omit similar experiment fixed costs modified selectivity time 
results similar changing selectivity operators results dramatic benefits adaptive scheme 
seen analytically operators cost swapped low hi manner analogous previous experiment 
lower bound performance static ordering selectivities toggled extremes equal amounts time half tuples go operators 
static plan takes nc nc time optimal execution time plan secs rs eddy st adapting initial delay performance tuples seen 
cumulative tuples routed st adapting initial delay tuple movement 
dynamic plan takes nc time ratio 
operators adaptivity changes selectivity significant 
delayed delivery final experiment study case input relation suffers initial delay ufa 
return table query shown left rs selectivity st selectivity 
delay delivery seconds results shown 
unfortunately see eddy lottery window forgetting scheme adapt initial delays 
tells story early part processing eddy incorrectly favors rs join tuples streaming rs join appear second normal execution 
eddy observes rs join produce output tuples tuples 
eddy awards tuples rs join initially places internal hash table subsequently joined tuples arrive 
st join left fetch hash tuples 
wastes resources spent joining tuples tuples delay primes rs join produce large number tuples rs appearing 
note eddy far better begins producing tuples axis values rs join burst forth eddy quickly rs join allowing st join process tuples 
scenario indicates problems implementation 
ticket scheme capture growing selectivity inherent join delayed input 
second storing tuples inside hash tables single join unnecessarily prevents joins processing conceivable hash input tuples multiple joins care taken prevent duplicate results generated 
solution second problem obviate need solve intend explore issues 
brevity omit variation experiment delayed delivery seconds case delay affects joins identically simply slows completion time plans seconds 
related knowledge represents general query processing scheme reordering flight operators pipeline considers special case unary operators 
characterization barriers moments symmetry appears new arising interest general pipelines 
papers consider queries ends pipelines ufa kd iff reordering operators temporary results materialized 
iff notes approach dates back original ingres query decomposition scheme swk 
inter pipeline techniques adaptive sense traditional control theory son machine learning mit decisions ongoing feedback operations optimize performing static optimizations coarse grained intervals query plan 
view efforts complementary eddies tuple scheduling pipelines techniques ufa kd iff pipelines 
course marriage sacrifices simplicity eddies requiring traditional complexity cost estimation plan enumeration ideas 
significant questions best combine techniques materialization operators put plan operators put eddy pipelines dec rdb subsequently oracle rdb competition choose different access methods az 
rdb briefly observed performance alternative access methods runtime fixed winner remainder query execution 
bears resemblance sampling cost estimation see bdf survey 
distantly related parameterized dynamic query plans postpone optimization decisions query execution inss gc 
initial query scrambling studied network processing queries widearea sources 
materialized remote data processing blocked waiting sources idea concert eddies 
note local materialization remove barriers done locally barrier quite significant 
focused rescheduling runnable sub plans initial delays delivery ufa attempt reorder flight operators 
core versions pipelined hash join proposed iff uf 
join uf enhances pipelined hash join handling outof core case exploiting delay time aggressively match previously received spilled tuples 
intend experiment joins eddies 
control project hac studies interactive analysis massive data sets techniques online aggregation online reordering ripple joins 
natural synergy interactive adaptive query processing online techniques pipeline best effort answers naturally adaptive changing performance scenarios 
need optimizing pipelines control project initially motivated eddies 
control project hac explicitly related field control theory son eddies appears link regards 
river project aat main inspiration 
river allows modules fast naturally balancing flow whichever modules faster 
carried river philosophy intial back pressure design eddies intend return parallel loadbalancing aspects optimization problem 
addition commercial projects section numerous research systems heterogeneous data integration iff query optimization traditionally viewed coarsegrained static problem 
eddies query processing mechanism allow fine grained adaptive online optimization 
eddies particularly beneficial unpredictable query processing environments prevalent massive scale systems interactive online query processing 
fit naturally algorithms ripple join family frequent moments symmetry adaptive non existent synchronization barriers 
eddies sole optimization mechanism query processing system obviating need complex code required traditional query optimizer 
alternatively eddies concert traditional optimizers improve adaptability pipelines 
initial results indicate eddies perform variety circumstances questions remain improving reaction time adaptively choosing join orders delayed sources 
sufficiently encouraged early results eddies rivers basis query processing telegraph system 
order focus energies initial explicitly postponed number questions understanding tuning extending results 
main challenge develop eddy ticket policies formally proved converge quickly near optimal execution static scenarios adaptively converge conditions change 
challenge complicated considering selections joins including hash joins absorb tuples hash tables section 
intend focus multiple performance metrics including time completion rate output plan rate refinement online aggregation estimators 
begun studying schemes allow eddies effectively order dependent predicates reinforcement learning sb 
related vein automatically tune aggressiveness forget past observations avoid introducing tuning knob adjust window length analogous constant hysteresis factor 
main goal attack remaining static aspects scheme pre optimization choices spanning tree join algorithms access methods 
az believe competition key run multiple redundant joins join algorithms access methods track behavior eddy adaptively choosing time 
implementation challenge scenario relates preventing duplicates generated efficiency challenge comes wasting computing resources unpromising alternatives 
third major challenge harness parallelism adaptivity available rivers 
massively parallel systems reaching limit manageability data sizes continue grow quickly 
adaptive techniques eddies rivers significantly aid manageability new generation massively parallel query processors 
rivers shown adapt gracefully performance changes large clusters spreading query processing load nodes spreading data delivery data sources 
eddies face additional challenges meet promise rivers particular queries intra operator parallelism entails repartitioning data adds expense reordering single site eddies 
additional complication arises trying adaptively adjust degree partitioning operator plan 
similar note explore enhancing eddies rivers tolerate failures sources participants parallel execution 
exploring application eddies rivers generic space dataflow programming including applications multimedia analysis transcoding composition scalable reliable internet services 
intent rivers serve generic parallel dataflow engine eddies main scheduling mechanism environment 
acknowledgments raman provided assistance course 
arpaci dusseau eric anderson noah implemented helped implement eddies 
mike franklin asked hard questions suggested directions 
stuart russell christos papadimitriou alistair sinclair kris hildrum lakshminarayanan subramanian helped focus formal issues 
kabra mitch cherniack initial discussions run time reoptimization database group berkeley feedback 
stuart russell suggested term eddy 
done authors uc berkeley supported ibm nsf iis sloan foundation fellowship 
computing network resources research provided nsf ri cda 
aac arpaci dusseau arpaci dusseau culler hellerstein patterson 
high performance sorting networks workstations 
proc 
acm sigmod international conference management data tucson may 
aat arpaci dusseau anderson culler hellerstein patterson yelick 
cluster river making fast case common 
sixth workshop parallel distributed systems pages atlanta may 
franklin tomasic urhan 
scrambling query plans cope unexpected delays 
th international conference parallel distributed information systems pdis miami beach december 
ah avnur hellerstein 
continuous query optimization 
technical report csd university california berkeley november 
aoki 
avoid building know value cost 
th international conference scientific statistical database management cleveland july 
az 
query processing optimization oracle rdb 
vldb journal 
bar barnes 
scale 
high performance transaction processing workshop asilomar september 
bdf barbara dumouchel faloutsos haas hellerstein ioannidis jagadish johnson ng poosala ross sevcik 
new jersey data reduction report 
ieee data engineering bulletin december 
bo ono 
cost estimation user defined methods object relational database systems 
sigmod record september 
dgs dewitt ghandeharizadeh schneider hsiao rasmussen 
gamma database machine project 
ieee transactions knowledge data engineering mar 
dewitt katz olken shapiro stonebraker wood 
implementation techniques main memory database systems 
proc 
acm sigmod international conference management data pages boston june 
florescu manolescu levy suciu 
query optimization presence limited access patterns 
proc 
acm sigmod international conference management data june 
gc graefe cole 
optimization dynamic query evaluation plans 
proc 
acm sigmod international conference management data minneapolis 
garcia molina papakonstantinou quass rajaraman sagiv ullman widom 
tsimmis project integration heterogeneous information sources 
journal intelligent information systems march 
gra graefe 
encapsulation parallelism volcano query processing system 
proc 
acm sigmod international conference management data pages atlantic city may 
gribble welsh brewer culler 
multispace evolutionary platform infrastructural services 
proceedings usenix annual technical conference monterey june 
hac hellerstein avnur chou olston raman roth haas 
interactive data analysis control project 
ieee computer august 
hel hellerstein 
optimization techniques queries expensive methods 
acm transactions database systems 
hh haas hellerstein 
ripple joins online aggregation 
proc 
acm sigmod international conference management data pages philadelphia 
haas kossmann wimmers yang 
optimizing queries diverse data sources 
proc 
rd international conference large data bases vldb athens 
hsc hellerstein stonebraker 
open independent enterprise data integration 
ieee data engineering bulletin march 
www com 
iff ives florescu friedman levy weld 
adaptive query execution system data integration 
proc 
acm sigmod international conference management data philadelphia 
ik ibaraki kameda 
optimal nesting computing relational joins 
acm transactions database systems october 
inss ioannidis ng shim sellis 
parametric query optimization 
vldb journal 
kbz krishnamurthy boral zaniolo 
optimization nonrecursive queries 
proc 
th international conference large databases vldb pages august 
kd kabra dewitt 
efficient mid query reoptimization sub optimal query execution plans 
proc 
acm sigmod international conference management data pages seattle 
met van meter 
observing effects multi zone disks 
proceedings usenix technical conference anaheim january 
mit mitchell 
machine learning 
mcgraw hill 
ng wang muntz 
dynamic query re optimization 
th international conference scientific statistical database management cleveland july 
pirahesh krishnamoorthy lapis tran 
heterogeneous query processing sql table functions 
th international conference data engineering pages sydney march 
raman raman hellerstein 
online dynamic reordering interactive data processing 
proc 
th international conference large data bases vldb pages edinburgh 
sb sutton 
reinforcement learning 
mit press cambridge ma 
stonebraker brown 
interoperability distributed applications distributed databases virtual table interface 
ieee data engineering bulletin september 
son sontag 
mathematical control theory deterministic finite dimensional systems second edition 
number texts applied mathematics 
springer verlag new york 
swk stonebraker wong kreps 
design implementation ingres 
acm transactions database systems september 
uf urhan franklin 
xjoin getting fast answers slow bursty networks 
technical report cs tr university maryland february 
ufa urhan franklin 
cost query scrambling initial delays 
proc 
acm sigmod international conference management data seattle june 
wa wilschut apers :10.1.1.56.701
dataflow query execution parallel main memory environment 
proc 
international conference parallel distributed info 
sys 
pdis pages 
ww waldspurger weihl 
lottery scheduling flexible proportional share resource management 
proc 
symposium operating systems design implementation osdi pages monterey ca november 
usenix assoc 
