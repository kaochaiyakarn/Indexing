model minimization markov decision processes thomas dean robert givan department computer science brown university box providence ri rlgg cs brown edu notion stochastic bisimulation homogeneity analyze planning problems represented markov decision processes mdps 
informally partition state space mdp said homogeneous action states block probability carried block 
provide algorithm finding coarsest homogeneous refinement partition state space mdp 
resulting partition construct reduced mdp minimal defined sense solve original mdp 
algorithm adaptation known automata minimization algorithms designed operate naturally factored implicit representations full state space explicitly enumerated 
show simple variations algorithm equivalent closely similar different published algorithms finding optimal solutions partially fully observable factored markov decision processes providing alternative descriptions methods results regarding algorithms 
planning problems characterized semantic level state transition graph model vertices correspond states edges associated actions 
model typically large represented compactly implicit representations avoid enumerating possible states 
exist efficient algorithms operate directly models algorithms determining reachability finding connecting paths computing optimal policies 
large size model typical planning problems precludes direct application algorithms 
planning systems reason symbolic level large groups states groups states behave identically relative action consideration 
systems incur computational cost having derive groupings repeatedly course planning 
author order purely alphabetical 
copyright fl american association artificial intelligence www aaai org 
rights reserved 
describe algorithms perform symbolic manipulations required group similarly behaving states preprocessing step 
output algorithms model reduced size states correspond groups states called aggregates original model 
aggregates described symbolically reduced model constitutes reformulation original model equivalent original planning purposes 
assuming certain operations required manipulating aggregates performed constant time algorithms run time polynomial size reduced model 
generally aggregate manipulation operations run constant time interesting tradeoffs occur consider different representations aggregates operations required manipulating representations 
consider planning problems represented markov decision processes mdps demonstrate model reduction algorithm just described yields insights published algorithms solving problems 
typically algorithm solving mdps implicit representation better understood realizing equivalent transforming original model reduced model followed applying standard method explicitly represented reduced model 
related papers examine relevance model reduction deterministic propositional planning demonstrate ideas approximation reachability analysis incorporated 
model minimization markov decision process tuple set states set actions reward function maps action state pair ff real value ff set state transition distributions ff pq ff pr qjx ff random variables denoting respectively state action time shows state transition graph states vertices edges probabilistic transitions 
state transition graph mdp fa bg delta delta delta delta transition probabilities indicated parentheses 
refer state transition graph model underlying dynamics planning problem boutilier dean hanks 
policy mapping states actions value function policy maps states expected value start state act policy fl pq fl discount rate fl assume simplicity objective function expected discounted cumulative reward puterman 
fb bn partition property stochastic bisimulation homogeneity respect ff pr ff qr ff conciseness say homogeneous 
homogeneous partition partition block stable see definition 
model aggregate states corresponding blocks transition probabilities defined ij ff pr ff state called quotient model respect partition refinement partition block subset block case say coarser term splitting refers process block partition divided sub blocks obtain refinement original partition 
introduce notion initial partition encode certain basic distinctions states 
traditional ai planning initial partition stochastic bisimulation homogeneity closely related substitution property finite automata developed hartmanis stearns notion markov chains kemeny snell 
consisting blocks states satisfy goal 
solving mdp distinguish states differ basis reward 
distinctions implied initial partition distinctions follow consequence dynamics 
particular homogeneous refinement initial partition preserves initial distinctions aggregates blocks behave 
particular initial partition homogeneous refinement particular interest 
theorem initial partition exists unique coarsest homogeneous refinement existence refinement follows analyzing algorithm described 
remainder section consider algorithm called model minimization algorithm simply minimization algorithm starts initial partition iteratively refines partition splitting blocks obtains coarsest homogeneous refinement refer refinement target partition 
discuss algorithm level leaving underlying representation partitions unspecified complexity measures terms number partition manipulation operations actual complexity depends underlying partition representation manipulation algorithms 
complexity measures relative number blocks resulting partition 
definition say block partition stable respect block action ff state probability carried block action ff 
formally pr bjx ff pr bjx ff pr qjx ff say stable stable respect block action partition homogeneous exactly block stable 
theorem implies unstable block initial partition split immediately resulting new partition retaining property refined target partition 
repeatedly finding unstable blocks splitting find target partition linearly splits target partition size split increases partition size exceed target partition 
algorithm adaptation algorithm lee yannakakis related algorithm bouajjani 

theorem partition blocks states block pr bjx bjx fall block coarsest homogeneous refinement theorem yields algorithm finding target partition linearly split operations quadratically stability checks simply check pair blocks stability splitting unstable block discovered 
specifically block unstable respect block action ff replace partition uniquely determined sub blocks maximal sub block stable respect ff 
denote resulting partition split ff partition just splitting theorem initial partition model minimization algorithm computes coarsest homogeneous refinement immediate reward partition partition states block rewards ff ff ff 
coarsest refinement initial reward partition 
resulting quotient model extended define reduced mdp defining reward ff block action ff ff state theorem exact solution reduced mdp induces exact solution original mdp 
algorithm independent choice underlying representation state space partitions 
note order algorithm guarantee finding target partition sufficiently expressive partition representation arbitrary partition state space represented 
typically partition representations may expensive manipulate may blow size 
reason consider partition manipulation operations exactly implement splitting operation described 
operations adequate purposes differ operation principled manner specifically split requested operation splits requested 
formally say block splitting operation split adequate split ff refinement split ff refer minimization algorithm split replaced observe stability block respect block action affected splitting blocks pair blocks need checked twice 
number blocks considered exceed twice number blocks target partition bounds number splits performed 
split adequate minimization 
refer adequate splitting operations properly refine split non optimal 
note operations may cheaper implement split split split 
theorem minimization algorithm split replaced adequate split returns refinement target partition solutions resulting reduced mdp induce optimal solutions 
published techniques operate implicit representations closely resemble minimization adequate non optimal splitting operations 
describe techniques connection minimization 
section introduce particular method implicit representation suited mdps basis discussion 
factored representations remainder bayesian networks pearl encode implicit factored representations methods apply factored representations probabilistic strips operators kushmerick hanks weld 
fx xm represent set state variables 
assume variables boolean refer fluents 
state time represented vector hx denotes ith state variable time stage temporal bayesian network tbn dean kanazawa directed acyclic graph consisting sets variables fx fx directed arcs indicating dependence allowed variables set variables second set variables second set 
state transition probabilities factored pr jx pr parents denotes parents tbn conditional probability distributions pr represented conditional probability table decision tree boutilier dearden goldszmidt 
enhance tbn representation include actions reward functions resulting graph called influence diagram howard matheson 
illustrates factored representation state variables fa cg describes transition probabilities rewards action 
factored form transition probabilities pr jx pr ja pr jb pr jc case ha pr pr pr factored representation state variables quotient models mdp represented factored representation shown immediate reward partition coarsest homogeneous partition computed minimization algorithm 
shows quotient model induced immediate reward partition mdp described blocks states reward states reward 
shows quotient model refined partition constructed model minimization algorithm 
consider different partition representations 
general representation represents partition set mutually inconsistent dnf boolean formulas block state block state corresponding truth assignment satisfies block dnf formula 
generality representation result surprising 
theorem factored mdp initial partition represented dnf problem finding coarsest homogeneous refinement np hard assumption refinement dnf representation size polynomial jx np hardness theorem lies maintaining dnf block descriptions simplest form 
minimization algorithm described run time polynomial size output simplifies block descriptions output simplest description coarsest homogeneous refinement second partition representation consider subset fluents representation partition represented dnf full set complete truth assignments note representation express partitions 
existing algorithms factored representations subsections briefly describe existing algorithms operate factored representations 
argue algorithm asymptotically equivalent applying minimization algorithm solving algorithm operates reduced mdp 
space limitations preclude detailed descriptions algorithms explication background necessary formalize arguments arguments provided sketches formal arguments provided longer version 
state space abstraction state space abstraction boutilier dearden means solving factored mdp generating equivalent reduced mdp determining superficial analysis fluents values necessarily irrelevant solution 
reduced mdp generated partition state space analysis viewed minimization splitting operation adequate non optimal 
ff coarsest refinement split ff representable 
adequate computable time polynomial size theorem minimization yields partition state space abstraction 
theorem shows optimal reduced mdp restriction partitions 
theorem mdp initial partition unique coarsest homogeneous refinement representable 
state space abstraction analysis quite sensitive factored representation mdp 
particular explicit mdp may different factored representations state space abstraction performs representation chosen represents independence properties fluents superficial analysis easily detect fluents relevant 
presentation boutilier dearden relies slightly expressive factored representation allow expression richer class independence properties action described multiple consistent aspects apply simultaneously aspect represented just action 
theorem shows expressive representation way factor explicit mdp optimal partition state space abstraction minimization 
theorem mdp initial partition factored mdp representation aspects state space abstraction finds coarsest homogeneous refinement structured policy iteration policy iteration known technique finding optimal policy explicitly represented mdp evaluating value state fixed policy values compute locally better policy iterating process converges optimum policy puterman 
explicit mdps evaluation fixed policy done known algorithm called successive approximation involves repeatedly computing value state just computed values neighboring states iterating process converges infinite limit true values stopping criterion designed indicate estimated values proceed step policy iteration puterman 
boutilier 
describe variants policy iteration successive approximation designed factored mdp representations called structured policy iteration spi structured successive approximation ssa respectively 
algorithms understood variants minimization particular non optimal adequate split operation 
remainder assume dnf partition representation 
definition say block partition stable respect fluent action ff state probability action ff carried state true 
formally pr jx ff say stable respect block action ff stable respect fluent mentioned dnf formula describing block ff coarsest refinement split ff stable respect ff 
adequate computable time polynomial number new blocks introduced plus size inputs 
structured successive approximation fixed policy mdp define restricted mdp mdp modified actions prescribed action ff taken state ff result state probability 
minimization restricted mdp equivalent ssa 
theorem mdp policy ssa applied produces resulting partition value convergence properties minimization followed traditional successive approximation resulting reduced mdp 
algorithms run time polynomial number blocks resulting partition 
structured policy iteration iteration structured policy iteration accepts input value function selects new policy considering possible advantages choosing actions step alternative indicated current policy assuming value subsequent steps determined cast policy iteration minimization problem considering special mdp pi pi stands policy improvement forces actions step chosen order distinguish step subsequent steps introduce new fluent 
actions executed step executed subspace true actions executed subsequent steps executed subspace false 
factored mdp fluents policy define pi mdp fluents ffl actions set false ffl true actions behave ffl false actions behave theorem mdp previous policy iteration spi computes partition partition subspace true produced minimization pi 
new partition computed method select improved policy choosing block new partition action maximizes immediate reward plus probability weighted sum values possible states 
explanation reinforcement learning splitting unstable block requires computing preimage block respect action 
basic operation fundamental regression planning explanation learning 
learning ebl techniques regression manipulate sets individual states 
reinforcement learning rl line method solving mdps barto sutton watkins essentially incremental line dynamic programming 
dietterich flann note computing preimages closely related iterative dynamic programming step policy iteration standard algorithms computing optimal policies 
describe rl algorithms regression combination standard rl mdp algorithms avoid enumerating individual states algorithms particular representation partitions rectangular regions state space 
direct application model minimization case complicated due line character rl 
line variant algorithm shown asymptotically equivalent computing reduced model adequate splitting operation rectangular partition representation followed application standard rl mdp algorithm reduced model 
suspect rest algorithms rl mdp algorithms handling multidimensional state spaces moore tsitsiklis van roy profitably analyzed terms model reduction 
partially observable mdps simplest way model reduction techniques solve partially observable mdps pomdps apply model minimization algorithm initial partition distinguishes basis reward observation apply standard pomdp algorithm resulting reduced model 
suspect existing pomdp algorithms partially understood terms 
particular conjecture factored pomdp algorithm described boutilier poole asymptotically equivalent minimizing underlying mdp monahan pomdp algorithm 
primarily concerned introducing method model minimization mdps presenting way analyzing understanding existing algorithms 
working approximation algorithms provable error bounds construct reduced models criterion approximate stochastic bisimulation homogeneity 
methods extend directly account reachability initial state set initial states 
working algorithms minimization reachability extend decomposition envelope techniques dean handle factored representations 
barto sutton watkins 
learning sequential decision making 
gabriel moore eds learning computational neuroscience foundations adaptive networks 
cambridge massachusetts mit press 
bouajjani fernandez halbwachs raymond 
minimal state graph generation 
science computer programming 
boutilier dearden 
abstractions decision theoretic planning time constraints 
proceedings aaai 
aaai 
boutilier poole 
computing optimal policies partially observable decision processes compact representations 
proceedings aaai 
aaai 
boutilier dean hanks 
planning uncertainty structural assumptions computational leverage 
proceedings third european workshop planning 
boutilier dearden goldszmidt 
exploiting structure policy construction 
proceedings ijcai 

dean kanazawa 
model reasoning persistence causation 
computational intelligence 
dean kaelbling kirman nicholson 
planning time constraints stochastic domains 
artificial intelligence 
dietterich flann 
learning reinforcement learning unified view 
proceedings twelfth international conference machine learning 
hartmanis stearns 
algebraic structure theory sequential machines 
englewood cliffs prentice hall 
howard matheson 
influence diagrams 
howard matheson eds principles applications decision analysis 
menlo park ca strategic decisions group 
kemeny snell 
finite markov chains 
new york van nostrand 
kushmerick hanks weld 
algorithm probabilistic planning 
artificial intelligence 
lee yannakakis 
online minimization transition systems 
proceedings th annual acm symposium theory computing 
monahan 
survey partially observable markov decision processes theory models algorithms 
management science 
moore 
parti game algorithm variable resolution reinforcement learning multidimensional state spaces 
hanson cowan giles eds advances neural information processing 
san francisco california morgan kaufmann 
pearl 
probabilistic reasoning intelligent systems networks plausible inference 
san francisco california morgan kaufmann 
puterman 
markov decision processes 
new york john wiley sons 
tsitsiklis van roy 
feature methods large scale dynamic programming 
machine learning 
