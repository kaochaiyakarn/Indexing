analysis visualization classifier performance comparison imprecise class cost distributions foster provost nynex science technology avenue white plains new york foster com tom fawcett nynex science technology avenue white plains new york fawcett com applications inductive learning algorithms realworld data mining problems shown repeatedly accuracy compare classifiers adequate underlying assumptions rarely hold 
method comparison classifier performance robust imprecise class distributions misclassification costs 
roc convex hull method combines techniques roc analysis decision analysis computational geometry adapts particulars analyzing learned classifiers 
method efficient incremental minimizes management classifier performance data allows clear visual comparisons sensitivity analyses 
mining data inductive methods experiment wide variety learning algorithms different algorithm parameters varying output threshold values different training 
experimentation yields large number classifiers evaluated compared 
order compare performance classifiers necessary know conditions accuracy inadequate class distributions misclassification costs rarely uniform 
decision theoretic principles may class cost distributions known exactly 
unfortunately real world problems target cost class distributions rarely specified precisely subject change 
example fraud detection ignore type distribution assume distribution specifications static precise 
need method management comparison multiple classifiers robust imprecise changing environments 
appear proceedings third international conference knowledge discovery data mining kdd huntington beach ca 
copyright fl american association artificial intelligence www aaai org 
rights reserved 
introduce roc convex hull method combines techniques roc analysis decision analysis computational geometry 
method decouples classifier performance specific class cost distributions may specify subset methods potentially optimal cost class distribution assumptions 
roc convex hull method efficient facilitates comparison large number classifiers 
minimizes management classifier performance data specify exactly classifiers potentially optimal incremental easily incorporating new varied classifiers 
inadequacy accuracy tacit assumption classification accuracy evaluation metric class distribution examples constant relatively balanced 
real world rarely case 
classifiers sift large population normal uninteresting entities order find relatively small number unusual ones example looking customers checking assembly line defective parts 
unusual interesting class rare general population class distribution skewed singh norton fawcett provost 
class distribution skewed evaluation accuracy breaks 
consider domain classes appear ratio 
simple rule classify maximum likelihood class gives accuracy 
presumably satisfactory non trivial solution sought 
skews common fraud detection skews greater reported classifier learning applications clearwater stern 
evaluation classification accuracy tacitly assumes equal error costs false positive error equivalent false negative error 
real world rarely case classifications lead actions consequences grave 
rarely mistakes evenly weighted cost 
hard imagine domain learn ing system may indifferent false positive false negative error 
cases accuracy maximization replaced cost minimization 
problems unequal error costs uneven class distributions related 
suggested high cost instances compensated increasing prevalence instance set breiman 
unfortunately little published problem 
exist dozen articles turney techniques suggested little done evaluate compare article pazzani 
exception 
literature provides guidance situations distributions imprecise change 
evaluating visualizing classifier performance discuss classifier evaluation terminology 
fp ng positive negative instance classes fy ng classifications produced classifier 
posterior probability instance positive 
true positive rate tp classifier tp positives correctly classified total positives false positive rate fp classifier fp negatives incorrectly classified total negatives classification class place error cost function cost false positive error cost false negative error classifier produces posterior probabilities decision analysis gives way produce cost sensitive classifications classifier weinstein 
classifier error frequencies approximate probabilities pazzani 
instance decision emit positive classification gamma delta delta regardless classifier produces probabilistic binary classifications normalized cost test set evaluated empirically cost fp delta fn delta set classifiers set examples precise cost function cost sensitive classification uses equation rank classifiers cost chooses minimum 
discussed analyses assume distributions precise static 
error costs include benefits realized 
false positive rate true positive rate roc graph classifiers receiver operating characteristic roc graphs long signal detection theory depict tradeoffs hit rate false alarm rate egan 
roc analysis extended visualizing analyzing behavior diagnostic systems swets visualization medicine beck schultz 
term roc space denote classifier performance space visualization roc analysis 
roc graph tp plotted axis fp plotted axis 
statistics vary threshold classifier continuous output varied extremes resulting curve called roc curve 
roc curve illustrates error tradeoffs available classifier 
shows plot performance classifiers typical see creation alarms fraud detection fawcett provost 
orientation points roc graph noted 
lower left point represents strategy alarming upper right point represents strategy alarming point represents perfect classification line shown represents strategy randomly guessing class 
informally point roc space better northwest tp higher fp lower 
roc graph allows informal visual comparison set classifiers 
curve better curve dominates points 
roc graphs illustrate behavior classifier regard class distribution error cost decouple classification performance factors 
unfortunately roc graph valuable visualization technique roc analysis poor job aiding choice classifiers 
classifier clearly dominates entire performance space declared better 
consider classifiers shown 
best 
answer depends performance requirements error costs class distributions effect classifiers 
researchers advocate choosing classifier maximizes product gamma fp delta tp geometrically corresponds fitting rectangles roc curve choosing rectangle greatest area 
approaches calculate average performance entire performance space swets beck schultz may appropriate costs class distributions completely unknown single classifier chosen handle situation 
choose suboptimal classifier situations 
roc convex hull method section combine decision analysis roc analysis adapt comparing performance set learned classifiers 
method high level principles 
roc space separate classification performance class cost distribution information 
second decision analytic information projected roc space 
third convex hull roc space identify subset methods potentially optimal 
iso performance lines separating classification performance class cost distribution assumptions decision goal projected roc space neat visualization 
formally prior probability positive example prior probability negative example gamma 
costs false positive false negative errors respectively 
expected cost classification classifier represented point tp roc space delta gamma tp delta delta fp delta points tp tp performance tp gamma tp fp gamma fp equation defines slope iso performance line classifiers corresponding points line expected cost 
set class cost distributions defines family iso performance lines 
lines northwest having larger tp intercept better correspond classifiers lower expected cost 
roc convex hull real world cases target distributions known precisely valuable able identify subset classifiers potentially optimal 
possible set distributions defines family iso performance lines family false positive rate true positive rate ch roc convex hull identifies potentially optimal classifiers 
false positive rate true positive rate lines ff fi show optimal classifier different sets conditions 
optimal methods lie iso performance line 
classifier potentially optimal lies northwest boundary line convex hull barber dobkin set points roc space 
space limitations prohibit formal proof see point lies convex hull exists line point line slope point larger tp intercept classifier represented point optimal distribution assumptions corresponding slope 
point lie convex hull family iso performance lines point lies iso performance line slope larger tp intercept classifier optimal 
call convex hull set points roc space roc convex hull corresponding set classifiers 
shows curves roc convex hull drawn ch border shaded unshaded areas 
clearly optimal 
surprisingly optimal points roc curve lies convex hull 
remove consideration points lie hull 
consider classifiers distribution scenarios 
negative examples outnumber positives 
scenario false positive false negative errors equal cost 
scenario false negative times expensive false positive missing case fraud worse false alarm 
scenario defines family lines 
lines corresponding scenario slope slope shows convex hull iso performance lines ff fi 
line ff best line slope intersects convex hull line fi best line slope intersects convex hull 
line identifies optimal classifier distribution 
generating roc convex hull call comparison classifier performance roc convex hull iso performance lines roc convex hull method 

classifier plot tp fp roc space 
continuous output classifiers vary threshold output range plot roc curve 

find convex hull set points representing predictive behavior classifiers interest 
classifiers done log time quickhull algorithm barber dobkin 

set class cost distributions interest find slope range slopes corresponding iso performance lines 

set class cost distributions optimal classifier point convex hull intersects iso performance line largest tp intercept 
ranges slopes specify hull segments 
roc convex hull figures demonstrate subset classifiers potentially optimal identified classifiers compared different cost class distributions 
demonstrate additional benefits method 
comparing variety classifiers roc convex hull method accommodates binary continuous classifiers 
binary classifiers represented individual points roc space 
continuous classifiers produce numeric outputs thresholds applied yielding series fp tp pairs comprising roc curve 
point may may contribute roc convex hull 
depicts binary classifiers added false positive rate true positive rate classifier may optimal extends roc convex hull 

previous hull 
may optimal circumstances extents convex hull 
classifiers extend 
new classifiers added incrementally roc convex hull analysis demonstrated addition classifiers new classifier extends existing hull 
case hull updated accordingly case new classifier ignored 
method require saving classifier saving statistics classifier reanalysis different conditions points convex hull 
classifiers optimal need saved 
classifier lie convex hull saved 
changing distributions costs class cost distributions change time necessitate reevaluation classifier choice 
fraud detection costs change workforce reimbursement issues amount fraud changes monthly 
roc convex hull method comparing new distribution involves calculating slope corresponding iso performance lines intersecting hull shown 
roc convex hull method scales gracefully degree precision specifying cost class distributions 
known distribution roc convex hull shows classifiers may optimal conditions 
showed classifiers optimal 
complete information method identifies optimal classifier 
saw classifier particular threshold value optimal scenario classifier optimal scenario see precise information roc convex hull show set possibly optimal classifiers 
sensitivity analysis imprecise distribution information defines range slopes iso performance lines 
range slopes intersects segment roc convex hull facilitates sensitivity analysis 
example segment defined range slopes corresponds single point roc space small threshold range single classifier sensitivity distribution assumptions question 
consider scenario similar negative examples times prevalent positive ones 
scenario cost dealing false alarm cost missing positive example 
defines range slopes iso performance lines depicts range slopes corresponding segment roc convex hull 
shows choice classifier insensitive changes range tuning classifier threshold relatively small 
depicts scenario wider range slopes 
shows scenario choice classifier sensitive distribution 
classifiers optimal subrange 
particularly interesting question domain strategy better available classifiers 
consider 
point corresponds doing issuing negative classifications regardless input 
set cost class distribution assumptions best hull intersecting iso performance line passes origin line ff defines scenario null strategy optimal 
example range scenarios small null strategy optimal slopes lines quantify range 
limitations implications simplified assuming classes costs vary type error 
assumption essential dimensional graph second assumption essential creation iso performance lines 
furthermore method maximization expected value decision goal 
decision goals possible egan 
example neyman pearson observer strategy tries maximize hit rate fixed false alarm rate 
framework neyman pearson observer find vertical line corresponding fp rate intersect non decreasing hull convex hull move left horizontally possible 
methods consider statistical tests comparing performance curves user confidence differences performance significant 
tradeoff tp fp rates similar tradeoff precision recall commonly information retrieval bloedorn mani macmillan 
precision recall take account relative size population uninteresting entities necessary deal changing class distributions 
existing cost sensitive learning methods brittle respect imprecise changing distributions 
methods categorized categories cost distribution building classifier choosing splits decision tree building rule sets breiman pazzani provost buchanan ii cost distribution post processing classifier pruning decision tree breiman pazzani finding rule subsets catlett provost buchanan setting output threshold iii estimate probability distribution decision analytic combination pazzani catlett duda hart iv search bias classifier learned turney provost buchanan 
probability estimation methods iii handle changes cost class distribution modifying classifier 
single method dominates roc convex hull needed comparison 
propose development methods search explicitly classifiers extend roc convex hull 
roc convex hull method robust efficient solution problem comparing multiple classifiers imprecise changing environments 
intuitive compare classifiers general specific distribution assumptions provides crisp visualizations 
minimizes management classifier performance data selecting exactly classifiers potentially optimal data need saved preparation changing conditions 
due incremental nature new classifiers incorporated easily trying new parameter setting 
noted times costs class distributions difficult specify precisely 
classifier learning research explore flexible systems perform range conditions part roc space 
hope method analysis classifiers help free researchers need precise class cost distribution information 
peter turney enlightening discussion application approach ir 
false positive rate true positive rate false positive rate true positive rate false positive rate true positive rate sensitivity analysis roc convex hull low sensitivity optimal high sensitivity optimal doing optimal strategy barber dobkin 
quickhull algorithm convex hull 
technical report university minnesota 
available ftp geom umn edu pub software qhull tar beck schultz 
roc curves test performance evaluation 
arch lab med 
bloedorn mani macmillan 
machine learning user profiles representational issues 
proceedings thirteenth national conference artificial intelligence 
menlo park ca aaai press 
breiman friedman olshen stone 
classification regression trees 
belmont ca wadsworth international group 
catlett 
tailoring rulesets costs 
proceedings conference ai statistics 
clearwater stern 
rule learning program high energy physics event classification 
comp physics comm 
duda hart 
pattern classification scene analysis 
new york john wiley 
egan 
signal detection theory roc analysis 
series perception 
new york academic press 
singh norton 
learning goal oriented bayesian networks telecommunications risk management 
proceedings 
san francisco ca morgan kaufmann 
fawcett provost 
combining data mining machine learning effective user profiling 
proceedings kdd 
menlo park ca aaai press 
pazzani merz murphy ali hume brunk 
reducing misclassification costs 
proc 
th international conference machine learning 
morgan kaufmann 
provost buchanan 
inductive policy 
proceedings aaai 
menlo park ca aaai press 
provost buchanan 
inductive policy pragmatics bias selection 
machine learning 
swets 
measuring accuracy diagnostic systems 
science 
turney 
cost sensitive classification empirical evaluation hybrid genetic decision tree induction algorithm 
jair 
turney 
cost sensitive learning bibliography 
ai iit nrc ca bibliographies cost sensitive html 
weinstein 
clinical decision analysis 
pa saunders 
