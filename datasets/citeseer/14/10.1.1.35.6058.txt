lightweight run time code generation mark leone peter lee carnegie mellon university pittsburgh pennsylvania usa cs cmu edu run time code generation alternative complement compile time program analysis optimization 
static analyses inherently imprecise interesting aspects run time behavior uncomputable 
deferring aspects compilation run time precise information program behavior exploited leading greater opportunities code improvement 
cost performing optimization run time paramount importance improved performance order obtain speedup 
describes lightweight approach run time code generation called deferred compilation compile time specialization employed reduce cost optimizing generating code run time 
implementation strategies developed prototype compiler discussed results preliminary experiments demonstrating significant speedup 
compiler optimizations depend compile time analysis approximate properties program run time behavior 
static analyses necessarily imprecise useful aspects run time behavior uncomputable 
compromises precision practice reduce complexity inefficiency analysis algorithms 
imprecision difficult compiler optimize programs thoroughly 
alternative approach defer analysis optimization code generation run time 
avoid fundamental problems inefficiency possible run time information improving code quality 
research partially supported national science foundation number ccr 
views contained document authors interpreted representing official policies expressed implied national science foundation government 
appear acm sigplan workshop partial evaluation semantics program manipulation june 
report experience new approach generating optimized code run time 
salient characteristics approach term deferred compilation follows ffl lightweight 
compile time specialization eliminates need process intermediate representation program run time 
part compiled program performs run time code generation hard wired optimize generate code small portion input program 
ffl largely automatic 
manual construction code templates run time code generators required 
syntactic cues programmer hints determine parts program subjected run time compilation 
ffl general 
standard optimizations strength reduction function inlining efficiently employed run time 
implemented prototype compiler call fabius evaluate approach 
preliminary experiments overhead deferred compilation quite small compared performance gain 
furthermore encountered unique design tradeoffs considering aspects optimization code generation performed statically deferred run time 
see encouraging signs deferred compilation practical find done 
motivation run time code generation beneficial programs exhibit multiple stages computation code late stages optimized values computed early stages 
multiple stages computation occur naturally functional imperative programs 
example strict curried function type applied argument closure representing value type typically constructed computations involving additional arguments proceed 
may profitable generate optimized code applied times 
run time code generation viewed alternative conventional implementation closures idea described appel app feeley lapalme fl 
stages computation arise conventional iteration constructs loop nests 
values computed outer loop usually fixed duration inner loops substantial benefits obtained optimizing inner loops iteration outer loop 
deeply nested loops lead stages computation 
example matrix multiplication commonly implemented nested loop outer loops select vector matrix innermost loop computes dot product 
run time may profitable specialize dot product loop vector selected outermost loop compute dot products 
dot product loop completely unrolled eliminating large number bounds checks branches 
arithmetic operations optimized contents fixed vector significantly improve performance sparse data 
optimizations usually performed compile time sizes contents matrices generally statically apparent 
run time code generation may reduce cost abstraction allowing structured programs written incurring undue performance penalty 
functional programming languages encourage small functions combined higher order constructs composition map fold programs written manner difficult optimize 
intraprocedural optimizations relatively ineffective small size basic blocks interprocedural optimizations difficult perform compile time control flow uncomputable 
compile time alternatives program staging exploited compile time program transformations 
see run time code generation desirable consider simple program repeatedly calls exponentiation function fixed exponent statically unknown fun raise exp bases map power exp bases power exp base exp base power exp base staging transformations various techniques staging transformation js han program bifurcation mog fold unfold transformations bd loop invariant removal asu employed compile time hoist computations depend base scope 
hoisting conditional test subtraction recursive call yields implementation power fun power exp exp fn base 
pow power exp fn base 
base pow base fn 
denotes strict function transformation reduces dynamic frequency hoisted operations repeated numerous times 
significant amount overhead introduced calling implementation power typically result creation large number closures containing code pointer pointer closure 
run time code generation reduce dynamic frequency loop invariant operations overhead 
addition optimize non loop invariant computations information available compile time 
static specialization alternatively specialization driving tur procedure cloning chk employed compile time transform power function fun exp nth exp fn base 
fn base 
base fn base 
base base fn base 
base base base 
handle nth 
power exp exponent value simply chooses table power functions specialized value exp gamma 
specialized functions highly optimized compiled high quality machine code expect approach useful situations run time code generation 
practical problems performing transformation automatically 
matter choosing set values specialize 
general possible predict range values result early computation values arbitrary data structures 
second problem due space constraints relatively small limit placed number specialized functions created compile time represented constant example key benefits run time code generation specialization occurs demand code space reused 
run time code generation run time code generation long history useful summary 
widely adopted primarily difficult automate cost optimization recovered large input sizes 
cost run time code generation reduced templates 
template manually constructed machine dependent representation code containing holes place values 
run time code generation simply requires copying template instantiating holes run time values yields run time constant propagation 
simple optimizations achieved low nth 
xn yields th element list 
exception called nth raised case returns closure containing value exp code unspecialized exponentiation function 
cost example loop unrolling implemented concatenating templates 
templates employed synthesis kernel mas mp reduce overhead kernel calls context switches 
applications benefit significantly run time template compilation include decompression cache simulation graphics primitive plr 
run time template compilation fast range optimizations may applied run time limited 
example instruction scheduling template boundaries difficult achieve 
general intermediate representation permits wider range optimizations results higher quality code higher cost 
keppel eggers henry explored tradeoff run time code generation costs code quality implementing template compiler general intermediate representation compiler applications 
engler proebsting ep investigated lcc compiler intermediate representation run time code generation 
intermediate code constructed ad hoc methods compiled lcc back run time directly executed 
run time compilation employed self hu dc cu compiler classless object oriented language general purpose intermediate representation 
runtime optimizations obtained automatically simply deferring bulk compilation run time 
similar approaches implemented smalltalk ds concurrent object oriented languages 
self primary run time optimizations inlining form specialization methods customized reduce cost dynamic type dispatch 
cost run time compilation reduced delaying compilation infrequently executed methods applying aggressive optimizations frequently executed methods dynamic recompilation 
compilation time consuming self run time compiler fast optimizing compiler cu 
deferred compilation deferred compilation employs compile time specialization reduce cost run time code generation 
intermediate representation program processed run time portions program compiled code hard wired perform optimizations generate native code run time 
goal run time code generation lightweight largely automatic greatly limiting range optimizations may applied run time 
close connections deferred compilation partial evaluation 
partial evaluator called mix historical reasons invoked run time specialize text function particular argument value mix fx closed term representing run time value fx called residual program representing specialization key aspect deferred compilation input known run time chambers ungar cu originally coined term deferred compilation describe strategy 
amount specialization carried run time 
text known compile time cost run time specialization reduced compile time specialization mix mix mix mix exhibits binding time separation specialize fx overhead processing run time 
deferred compilation employs similar form compile time specialization reduce cost optimizing generating code run time 
remainder section illustrate basic principles deferred compilation describing design prototype implementation 
connections deferred compilation partial evaluation discussed detail section 
implementation implemented prototype compiler called fabius investigate evaluate notion deferred compilation 
key issue costs optimization code generation compile time run time 
moment primary goal fabius reduce run time cost code generation minimum cost degradation quality generated code increase size generating generated code 
provides baseline evaluation aggressive run time optimizations 
extensions fabius discussed section section 
fabius source language time rudimentary strict order functional language 
integers pointers heap allocated structures run time values 
fabius generates native code mips 
major phases compilation follows ffl staging analysis identifies computation stages may profitable perform run time code generation 
process similar binding time analysis jss con subexpressions program annotated indicate belong early late stages computation 
ffl register allocation assigns registers program variables intermediate values 
usual notion lifetime ranges modified textually adjacent computations may belong different program stages may overlapping register sets 
ffl code generation compiles early computations usual way late computations compiled machine code generates optimized instruction sequences run time 
simple example illustrate steps detail 
mentioned section matrix multiplication suited run time code generation 
usually implemented nested loop outer loops select vector matrix innermost loop computes dot product 
consider tail recursive implementation dot product loop quintus fabius roman general best known defeat second war 
primary strategy delay confrontation repeated small attacks eventually led victory single decisive conflict 
fun dotprod sum nil sum dotprod tl tl sum hd hd simplify presentation assume vectors implemented linked lists integers 
point consider machine code generated dotprod function conventional compiler dotprod beq nil goto ld hd ld hd mul prod add sum sum prod ld tl ld tl jmp dotprod goto dotprod move result sum ret return section describes staging analysis identifies compilation deferred section describes fabius creates specialized code generator dotprod 
staging analysis implementation matrix multiply described vector selected outermost loop compute numerous dot products 
may profitable create optimized dot product function parameterized sum iteration outer loop 
situations say argument dotprod available early stage remaining arguments available late stage 
deferred compilation employs staging analysis identify computation stages track data dependencies 
subexpressions program annotated indicate depend results early computations rely late stage results 
example dotprod annotated follows indicate early computations underlines indicate late computations fun dotprod sum nil sum dotprod tl tl sum hd hd test nil computed early stage available early conditional branch performed early 
staging analysis labels recursive application early computation indicating function inlined run time see section 
case just stages labeling early late computations similar binding time analysis annotation jss con 
subtle difference 
binding time analysis guided externally imposed division program inputs specifies supplied compile time hd returns head list tl tail 
available run time 
setting deferred compilation program inputs supplied time execution compiled program 
distinction early late stages introduced compiler quite artificially hope obtaining faster code 
detecting program stages difficult problem 
syntactic features programming languages provide clear indications stages subjected deferred compilation 
applications curried functions obvious candidate deferred compilation nested loop constructs 
consel pu walpole proposed multi level programming language allow programmers express invariants established execution large system 
example operating system structured way permits specialization applied compile time link time boot time run time 
multi level language facilitate staging analysis 
addition detecting program stages staging analysis determine stages benefit run time compilation 
partial evaluators commonly adopt aggressive strategy performing specialization possible doing result significant code improvements 
deferred compilation requires conservative approach cost optimization improved performance 
quite difficult determine case especially optimizations applied run time may machine specific 
online strategies employ run time information guide optimization may necessary 
example online strategies employed cecil self compilers determine method specialization dcg inlining dc applied run time 
currently fabius relies programmer hints determine run time code generation profitable 
notation similar currying function definitions specify formal parameters early late 
calls functions require syntax similar curried application introduce division actual arguments 
parlance partial evaluation technique monovariant call sites supply compatible division actual arguments 
degree possible signature function fixed definition affected stages assigned actual arguments 
example curried application form 
em 
compatible division actual arguments constructed follows ffl late lifted late stage 
ffl late lifted late stage 
result staging analysis implemented fabius simple pass annotation algorithm 
currently stage divisions supported 
programs exhibiting stages execution benefit run time code generation stage late values may passed early arguments 
circumstances run time generated code contain calls statically compiled code generators 
code generation staging analysis fabius performs register allocation discussion postpone section code generation 
early computations compiled usual way late computations compiled code emits optimized instruction sequences run time 
annotated dotprod function shown fabius generates code beq nil goto ld hd emit ld emit hd emit mul emit prod emit add emit sum sum prod ld tl emit ld emit tl jmp goto emit move emit result sum ret return differences machine code dotprod earlier 
instructions emitted times executed 
second early late values assigned registers operations involving values belong non overlapping program stages 
optimization discussed section 
specialized code generator manipulate intermediate representation source program run time 
readers familiar partial evaluation may notice generating extension dotprod 
specialized code generators viewed executable data structures mas overhead eliminated merging code data 
effectively performs constant propagation conditional folding inlining run time 
example called vector 
xn code generated run time ld hd mul prod add sum sum prod ld tl 
ld hd mul xn prod xn add sum sum prod ld tl move result sum simple optimizations yield significant speedup small input sizes 
preliminary measurements reported section 
pseudo instruction emit simplify presentation 
expands sequence instructions allocates space dynamic code segment builds representation instruction opcode arguments writes instruction allocated space 
operands emitted instruction usually fixed value immediate operand may determined contents register 
example emit mul emit register immediate multiply instruction value small permit encoding 
clarity order arguments computed changed eliminates register shuffling code emits procedure linkage code omitted 
making deferred compilation practical wide variety programs challenge simple example imply 
see run time inlining highly profitable clearly limits pursued aggressively run time overhead may exceed performance gain dynamically generated code 
section discusses issues detail describes strategies employed address 
examine wider range optimizations code generation techniques adapted deferred compilation 
deferred compilation partial evaluation fabius code generator structured conventional code generator 
interesting note automatically derived principled way partial evaluation 
see accomplished consider conventional partial evaluator mix specialize function run time mix source code run time value 
conventional partial evaluators designed source program transformation specialized code results expressed high level language 
require run time compilation executed comp ffi mix fx single brackets indicate result form native code 
note known compile time specialize comp ffi mix short reduce cost run time specialization compilation mix result text program specializes compiles native code run time 
exhibits binding time separation intermediate representation processed run time 
unfortunately naive composition comp mix binding time separation run time compilation specialized 
known partial evaluators need express residual programs source code 
directly implement specializer generates native machine code 
compiler similar fabius obtained self application fabius best knowledge existing partial evaluator directly generates native machine code 
system comes close goal self applicable partial evaluator order functional language target stack machine hol 
machine code relatively high level language cost compiling native code run time substantial 
overhead compilation statically eliminated 
fabius viewed manually derived implementation 
bears strong similarity notion hand writing cogen eh hl 
deferred compilation differ partial evaluation 
fundamental difference discussed section deferred compilation driven externally imposed division program inputs staging inherent program 
addition deferred compilation incorporates low level optimizations considered conventional specializers strength reduction register allocation requires different heuristics determine specialization unfolding applied 
section discusses issues detail 
run time optimizations dot product example section demonstrated simply deferring code generation run time allows achieve run time constant folding loop unrolling dead code elimination 
conventional optimization code generation techniques adapted deferred compilation lack run time intermediate representation poses challenge 
optimizations staged way separates manipulation source program run time information 
partial evaluation terminology optimizations exhibit binding time separation 
fortunately case conventional optimizations 
local optimizations local optimizations strength reduction instruction selection easy adapt deferred compilation 
example emitting result early computation code generator check zero emit cheaper instruction beq goto emit mul emit jmp goto emit move emit fabius incorporates number local optimizations form 
increased cost run time optimizations weighed benefit 
case cost cycles multiplication benefits significant demonstrate section consider computation involving sparse data 
choice run time optimizations need globally specialized code generators individually tailored perform variety optimizations 
register allocation deferred compilation reduces register pressure complicates register allocation 
fewer registers required program stages interleaved overlapping register sets 
example dotprod computations involving vectors textually adjacent belong different stages register assigned vectors 
existing register allocation algorithms graph coloring cha ch adapted deferred compilation simply modifying construction interference graph 
interference graph contains nodes representing lifetime ranges variables edges indicating ranges intersect 
coloring graph valid assignment variables registers 
deferred compilation simply requires revised notion variable lifetime construction interference graph edges added overlapping lifetime ranges variables program stage 
fabius uses similar technique perform register allocation compile time significantly reduces cost run time code generation 
approach drawbacks 
inlining loop unrolling may occur run time exact interference graph constructed compile time 
fixing register assignments functions compile time run time inlining effective 
example code generated shuffle registers formal actual parameters function assigned different registers forth 
eliminating kind overhead primary motivations inlining desirable perform run time register allocation cases 
constructing exact interference graph run time prohibitively expensive investigating alternative technique register allocation performed compile time register assignment computations deferred run time 
compile time register allocation conservatively determine register spilling necessary static approximation interference graph described run time code generators parameterized register mappings 
example perform run time register assignment follows beq nil goto ld hd emit ld rr rr emit hd emit mul rr rr emit prod emit add rr rr rr emit sum sum prod ld tl emit ld rr rr emit tl jmp goto emit move rr rr emit result sum ret return function takes arguments value numbers registers assigned sum numbers available temporary register destination register 
emit pseudo instruction determines operands emitted instruction contents specified registers 
takes cycles emitting instructions fixed operands generated code efficient contexts require register shuffling described 
inlining loop unrolling inlining loop unrolling valuable optimizations conventional compilers yield increased opportunities optimization eliminate overhead function calls improve amortization computations range checks dh 
extent optimizations may performed compile time limited 
loop bounds usually unknown loop unrolled fixed number times 
special case code containing numerous branches required unrolling rtcg rtcg dense input rtcg sparse input cost rtcg included dimension instructions instructions multiply theta matrices loop actual number iterations multiple unrolling depth 
inlining impossible compiling languages higher order functions calls unknown functions common 
run time inlining loop unrolling solve problems 
fabius decides compile time run time inlining occur results staging analysis 
loops expressed tail recursive functions inlining yields loop unrolling 
aggressive heuristic currently guides inlining call function early late formal parameters marked run time inlining appear branch conditional controlled late stage value bd 
function inlined run time compiled specialized code generator emit procedure linkage code emits optimized code directly code generated calling context 
inlining strategy implemented fabius preserves termination behavior programs bd remains seen increased time space requirements aggressive run time inlining manageable large applications 
specialization contexts impractical inline function desirable specialize results early computations 
example function called different program points value early computation may preferable generate single optimized version function inlining body call site 
specialization permits run code reused regenerated saves space time 
determining specialization beneficial difficult problem 
fabius currently implements aggressive heuristic employed bd functions early late arguments inlined specialized 
functions compiled specialized code generators parameterized values early arguments generate optimized functions run time 
code generators memoized previously optimized code reused possible 
run time memoization structured data quite expensive mal fabius uses pointer equality 
form specialization yields significant speedups examples terminate bd 
preliminary experiments indicate strategy aggressive practice functions benefit significantly specialization 
results preliminary experiments fabius encouraging 
example return matrix multiplication algorithm introduced section 
measured number instructions executed execution time matrix multiply dense sparse inputs 
execution times measured unloaded decstation 
inputs square matrices dimension containing pseudo random untagged bit integers 
fabius support vectors arrays implemented matrices lists lists 
sparse input zero non zero values randomly located 
runtime optimizations applied dense sparse inputs 
purposes comparison measured performance statically optimized code obtained simply disabling fabius staging analysis 
quality code compile time inlining performed 
fabius prototype garbage collector measurements reflect cost reclaiming data code space account cost allocation 
code space reused run time evaluated cost instruction cache flushing 
issue discussed section 
instruction counts compares number instructions executed multiplying dense sparse matrices varying size 
top curve gives performance statically optimized rtcg dense input rtcg rtcg sparse input cost rtcg included dimension seconds time multiply theta matrices code middle curves demonstrate improvement obtained deferred compilation account cost generating code run time 
lowest curve represents cost run time code generation dense input 
sparse input resulted faster run time code generation fewer instructions emitted 
demonstrates deferred compilation significantly improve performance small problem sizes 
case cost optimizing generating code run time recovered dense matrices larger theta sparse matrices larger theta 
larger input sizes improvement obtained dense data asymptotically approaches improvement sparse data increases linearly 
deferred compilation reduced total number instructions executed dense data sparse data 
cost run time optimization code generation low accounting total number instructions executed 
dense input average cost instructions instruction generated run time average sparse input 
execution times predicted instruction counts time spent optimizing generating code run time brief totalling milliseconds dense input milliseconds sparse input 
execution times greater expected 
shown deferred compilation yield speedup dense matrices yielded speedup sparse matrices 
curious behavior caused instruction pipeline stall 
mips integer multiply instruction requires cycles complete instruction pipeline stall attempt access result ready 
statically optimized code large unrelated instructions scheduled multiplication dot product function pipeline stall occur 
run time code generation happens eliminate precisely instructions 
verified explanation measuring execution time variant benchmark code result multiplication discarded 
execution time improved significantly closely predicted instruction counts indicating pipeline stalls introduced deferred compilation 
better instruction scheduling reduce eliminate pipeline stalls 
example instructions iteration dot product loop scheduled multiplication th iteration 
dot product loop unrolled compile time may necessary perform instruction scheduling run time 
currently investigating feasibility optimizations 
caveats encouraging results experiment conclusive 
realistic implementation matrix multiply include special purpose code sparse inputs aggressive compile time loop optimizations able improve performance benchmark code resorting run time code generation 
performance improvements incompatible deferred compilation 
additional concerns addressed practice include space usage instruction caching 
compile time specialization run time code generators essentially trades space time 
example enabling run time code generation doubled static size matrix multiply code words words 
aggressive run time inlining loop unrolling dramatically increase space requirements 
example code generated run time single dot product function occupied approximately words code space reclaimed total space required exceeds megabyte 
run time code generation interact poorly instruction caching 
modern architectures prefetch instructions instruction cache automatically invalidate cache entries memory writes occur 
portions instruction cache may need flushed new code generated run time 
fortunately regularity code space allocation initialization simplifies amortizing cost operations 
fabius aligns newly allocated code object boundary mips instruction prefetcher guaranteed crossed executing previously generated code avoiding invalidation cached instructions 
cache flushing required garbage collection occurs 
implemented code space reclamation believe cost cache flushing significant 
example keppel reports flushing instruction cache decstation requires kernel trap plus approximately nanoseconds byte flushed 
add approximately milliseconds total cost run time code generation multiplying theta matrices 
research deferred compilation alternative complement compile time analysis optimization aspects optimization code generation deferred run time 
fast run time optimization code generation achieved eliminating compile time specialization overhead processing intermediate representations source programs run time 
preliminary experiments prototype compiler promising find experimentation required full assessment 
currently extending fabius prototype compile programs higher order functions mutable data structures 
exploring wider range optimization code generation techniques run time 
particular interest usefulness performing register assignment run time 
plan detailed study effectiveness different strategies controlling run time inlining specialization memoization 
matter staging analysis point poorly understood 
currently rely programmer hints determine run time code generation profitable clearly automatic approach desirable 
development theoretical foundations practical implementation automatic staging analysis subject research 
grateful chris stone provided valuable assistance implementation fabius adl tabatabai chris colby charles consel olivier danvy david keppel mark lillibridge greg morrisett chris okasaki amr sabry chris stone david tarditi time effort productive discussions 
vexing problem arises pointers propagated values optimization may embedded runtime generated code 
garbage collector update code flush instruction cache moves data 
embedded pointers may difficult locate update example mips constant bit pointer embedded instructions contain bit immediate values 
instruction reordering run time code generation locations instructions unpredictable 
app andrew appel 
re opening closures 
technical report cs tr department computer science princeton university 
asu alfred aho ravi sethi jeffrey ullman 
compilers principles techniques tools 
addison wesley reading massachusetts 
bd burstall john darlington 
transformation system developing recursive programs 
journal acm january 
bd anders bondorf olivier danvy 
automatic recursive equations global variables data types 
science computer programming september 
lennart beckman anders erik sandewall 
partial evaluator programming tool 
artificial intelligence 
ch frederick chow john hennessy 
register allocation priority coloring 
proceedings acm sigplan symposium compiler construction pages 
sigplan notices june 
cha gregory chaitin 
register allocation spilling graph coloring 
sigplan notices june 
chk keith cooper mary hall ken kennedy 
methodology procedure cloning 
computer languages april 
andrew chien vijay karamcheti john plevyak 
concert system compiler runtime support efficient fine grained concurrent objectoriented programs 
technical report department computer science university illinois urbana champaign june 
con charles consel 
polyvariant binding time analysis applicative languages 
proceedings symposium partial evaluation semantics program manipulation pages 
association computing machinery june 
charles consel calton pu jonathan walpole 
incremental partial evaluation key high performance modularity portability operating systems 
proceedings symposium partial evaluation semantics program manipulation pages 
association computing machinery june 
cu craig chambers david ungar 
making pure object oriented languages practical 
oopsla conference proceedings 
sigplan notices november 
anne de eddy karel de 
program bifurcation polymorphically typed functional language 
proceedings symposium partial evaluation semantics program manipulation pages 
sigplan notices september 
dc jeffrey dean craig chambers 
better inlining decisions inlining trials 
proceedings acm conference lisp functional programming june 
appear 
dcg jeffrey dean craig chambers david grove 
identifying profitable specialization object oriented languages 
technical report department computer science engineering university washington february 
dh jack davidson anne holler 
study function inliner 
software practice experience 
ds peter deutsch allan schiffman 
efficient implementation smalltalk system 
conference record th annual acm symposium principles programming languages salt lake city pages january 
eh par anders 
compiling embedded languages lisp 
acm conference lisp functional programming stanford california pages 
ep dawson engler todd proebsting 
dcg efficient retargetable dynamic code generation system 
preparation november 
fl marc feeley guy lapalme 
closure generation viewing lambda epsilon plus compile 
computer languages october 
han john hannan 
staging transformations machines 
proceedings symposium partial evaluation semantics program manipulation pages 
sigplan notices 
hl carsten kehler holst john launchbury 
handwriting cogen avoid problems static typing 
draft proceedings fourth annual glasgow workshop functional programming scotland pages 
glasgow university 
hol carsten kehler holst 
language triplets approach 
bjrner ershov jones editors partial evaluation mixed computation pages 
north holland october 
hu urs holzle david ungar 
optimizing calls run time type feedback 
acm sigplan conference programming language design implementation june 
appear 
neil jones carsten gomard peter sestoft 
partial evaluation automatic program generation 
prentice hall 
js ulrik william scherlis 
compilers staging transformations 
conference record th annual acm symposium principles programming languages pages january 
jss neil jones peter sestoft harald sndergaard 
mix self applicable partial evaluator experiments compiler generation 
lisp symbolic computation 
david keppel susan eggers robert henry 
case runtime code generation 
technical report department computer science engineering university washington november 
david keppel susan eggers robert henry 
evaluating runtime compiled value specific optimizations 
technical report department computer science engineering university washington november 
david keppel 
portable interface fly instruction space modification 
proceedings th international conference architectural support programming languages operating systems pages april 
mal 
efficient partial evaluation 
proceedings symposium partial evaluation semantics program manipulation pages 
association computing machinery june 
mas henry massalin 
synthesis efficient implementation fundamental operating system services 
phd thesis department computer science columbia university 
mog torben mogensen 
separating binding times language specifications 
fourth international conference functional programming languages computer architecture london england september pages 
reading ma addison wesley 
mp henry massalin calton pu 
threads input output synthesis kernel 
proceedings th acm symposium operating systems principles pages december 
plr rob pike bart john reiser 
hardware software trade offs bitmap graphics 
software practice experience february 
tur valentin turchin 
concept supercompiler 
acm transactions programming languages systems 

