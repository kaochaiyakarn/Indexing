dealing complexity economic calculations professor john rust yale university revised october essay response growing negative literature suggests economic theories hypotheses rationality equilibrium limited practical relevance require large number calculations 
negative results translations complexity bounds computer science literature 
show bounds constitute proofs difficult economic calculations impossible discuss type hardware software possible solve hard problems 
discuss different ways break curse dimensionality economic problems exploiting special structure decomposition randomization advantage knowledge capital 
methods may 
offer speculations role decentralization harnessing power massively parallel processors 
conjecture decentralization efficient operating system organizing large scale computations massively parallel systems 
economies immune systems brains types massively parallel processors decentralization solve difficult computational problems 
knowledge capital form effective institutions necessary ensure decentralization leads effective cooperation anarchy chaos 
suggest reason economists great difficulty computing approximate solutions detailed models individual behavior large scale models economy appropriate hardware software 
economists structure computations mimic key operating features brains economies parallel processing decentralized agent modeling strategies solve realistic economic models solutions arise endogenously emergent computations 
invited workshop fundamental limits knowledge economics santa fe institute july august 
financial support alfred sloan foundation gratefully acknowledged 
draft benefited comments albert ando kenneth arrow robert axtell dirk samuel steven durlauf eric friedman john stuart kauffman charles raj mehta danny ariel rubinstein peter tinsley joseph traub michael wellman wo 

fundamental limits knowledge economics 
countering distinguished tradition impossibility theorems economics essay attempt suggest positive answers different aspects called problem economic complexity 
computational complexity economic calculations required implement various economic concepts optimization equilibrium place inherent limits ability economists model behavior economies economic agents 

computational complexity economic calculations place inherent limits ability economic agents behave existing economic theories optimization equilibrium 
negative answer question economic problems computationally intractable force efforts economists guy build tractable realistic empirically estimable model economy futile 
negative view suggests economic science hope provide disjoint collection highly simplified toy models sufficiently stylized solved analytically simple approximately solved digital computers 
negative answer question equally serious implications economic science imply existing economic theories irrelevant misguided positive models economy individual economic behavior 
specifically inherent curse dimensionality underlying economic calculations realization actual economic agents limited computational capabilities operate complex environments extremely high dimensional state spaces choice sets appear force abandon standard rationality hypothesis economic agents behave making vast number computations implied existing economic theories 
section reviews key results literature computational complexity constitute logical underpinning argument difficult economic calculations impossible 
complexity bounds show economic problems ranging computing walrasian equilibrium economy nash equilibrium game lead team researchers failed ambitious attempt build bottom model economy social systems research institute university wisconsin early 
subsequent attempts model economy highly nonlinear economic models attempt deduce time series properties macro variables aggregation behaviorally motivated 
solving stochastic team decision dynamic programming problem non computable intractable 
section describes hardware software solutions problem economic complexity 
show fact economic problem computationally intractable necessarily imply impossible empirical question available hardware able compute sufficiently precise approximate solution specific problem available amount time 
second argue worst case complexity bounds highly misleading showing supposedly intractable problems tractable consider alternative measures complexity account different amounts prior information problem allow different ways assessing accuracy quality approximate solution 
discuss different ways break curse dimensionality economic problems exploiting special structure decomposition randomization advantage knowledge capital 
discussion importance knowledge capital suggest long term evolutionary forces enabled nature discover powerful hardware software capable solving extremely difficult large scale computational problems presently unable solve 
just appreciate understand methods nature uses solve hard problems 
examples include immune system able distinguish friend foe destroy potential pathogens human brain able solve highly complex problems image recognition language acquisition classification decision problems 
systems means perfect viruses immune system destroy mathematical problems humans unable solve ability behave sensibly perform wide range difficult tasks constantly changing environment truly remarkable 
researchers economics computer science artificial intelligence quite bit progress years exceptions unable write computer programs competent performing relatively mundane tasks highly controlled simplified environments navigating obstacles stacking blocks recognizing faces understanding spoken language 
believe efforts develop better hardware software solving complex economic problems accelerated try discover emulate methods nature uses solve hard problems 
section offer conjectures methods nature uses solve hard problems 
certainly don pretend complete answer question clear powerful information processing systems see nature share key features massive parallelism decentralization 
massive parallelism means system contains thousands millions billions relatively homogeneous processors agents 
decentralization means identifiable central planner controls individual agents system 
agents appear operate autonomously preferences objective function influenced messages competition types interactions agents 
observe collective outcome agents interactions appears cooperated solve defined problem 
adam smith note feature decentralized systems economic contexts described economy operating guided invisible hand 
paralleling theorems decentralization economic resource allocation processes leads outcomes efficient theorem economics informationally efficient mount reiter theorem size message spaces conjecture decentralization massively parallel computing devices leads outcomes sense computationally efficient 
argument ultimately infeasible adopt centralized approach computation massively parallel systems sufficiently large number processors analogous respects argument ultimately infeasible adopt centralized approach resource allocation large economies 

computational complexity limits knowledge economics fairly large literature formal informal arguments rational equilibrium behavior impossible parallel literature existence fundamental limits knowledge economics 
number informal impossibility arguments proposed response increasingly elaborate game theoretic rational expectations theories developed 
arguments follows brightest economists unable find exact analytic solutions models require supercomputers compute approximate numerical solutions models expect man street behave theories 
relatively easy dismiss sorts arguments depend implicit assumption intelligence man street quite limited power supercomputers intelligence best economists nearly unbounded 
difficulties researchers economics artificial intelligence encountered developing algorithms perform simple tasks man street effortlessly instantaneously suggests true state affairs nearly opposite informal arguments assume 
rest section focuses formal impossibility arguments arguments harder dismiss 
knowledge von mises von hayek provided formal arguments fundamental limits knowledge economics 
nobel memorial lecture knowledge hayek known argument impossibility central planning assumption impossible observe transmit information necessary compute equilibrium social planning solution economy 
interestingly appear question economists ability calculate optimal allocation possible transmit facts economy central planner theory essentially complex phenomena refer large number particular facts derive prediction test ascertain particular facts 
succeeded particular difficulty deriving testable predictions help modern computers easy insert data appropriate blanks theoretical formulae derive prediction 
real difficulty solution science little contribute insoluble consists particular facts 
von hayek pp 
similarly optimistic view power computers espoused lange chief proponents efficacy centralized planning response criticisms approach hayek answer hayek robbins trouble 
put simultaneous equations electronic computer shall obtain solution second 
lange 
main message essay computational problems insurmountable bold na ive claim trivial 
certainly agree hayek argument limits knowledge due fact information decentralized primary focus essay limits knowledge arising issue required computations hard 
remainder section summarizes key limits arguments various versions theory computational complexity 
roughly speaking arguments state inherent limits ability digital computers compute exact approximate solutions economic problems 
computational limits apply conceivable hardware software extent believe human brain highly elaborate chemical computer complexity bounds imply fundamental limits knowledge fundamental limits rationality economics 
hypothesis human brains subject fundamental limitations digital computers course subject long contested unresolved mind brain debate philosophy literature 
accessible synopsis debate see anderson 
see penrose argues essential non algorithmic component conscious thought processes sense phenomena creativity result quantum mechanical effects brain explained modeling human mind highly elaborate type turing machine 
economists appealed computational complexity theory levels attempts establish fundamental limits knowledge economics 
basic results appealed theory effective computability imposing minimal requirement economic problem interested solving effectively computable exists algorithm guaranteed terminate correct solution problem finite amount time run standard finite state computer turing machine 
extraordinarily weak requirement requires algorithm eventually return correct answer requirement algorithm produce answer realistic amount time currently available hardware 
classic example problem effectively computable halting problem 
roughly speaking effective method determining computer program running input eventually halt 
knowledge earliest translation impossibility results logic computer science logic problems economics due rabin proved exist games equilibrium strategies effectively computable 
binmore established similar result noting profound 
mathematically involved trivial adaptation standard argument halting problem turing machines 

isn clear results say narrower relevant issue rational behavior possible practical contexts rely non constructive arguments establish existence games equilibria effectively computable 
relevant question equilibria effectively computable games economic agents play 
partially addresses issue proving stronger impossibility result 
showed infinitely repeated player discounted games problem determining best response fixed strategy opponent effectively computable games discount factor sufficiently close 
concludes result casts doubt sense model fully rational decision making turing machines 

lewis proven addition person games key economic concepts individual demand correspondences walrasian general equilibria equilibria resource allocation problems effectively computable restrict attention class problems descriptions primitives problem endowments preferences choice sets recursively presentable functions related result odel incompleteness theorem states formal system computerized theorem proving program capable proving true statements axiomatic system sufficient richness arithmetic 
prove exist theorems arithmetic true proven true axioms arithmetic finite number steps computerized theorem prover 
describing preferences production technologies restricted effectively computable choice sets restricted recursively enumerable 
potential problem lewis results require computer produce exact solution problem consideration 
economic problems formulated terms continuous mathematical entities utility functions defined euclidean space generally impossible compute exact solutions turing machines type universal computer fundamentally finite state devices capable finite precision arithmetic perform finite number operations finite interval time 
complexity problems arise completely discrete economic problems variables restricted finite sets 
problems solved exactly turing machine 
example tsitsiklis athans considered superficially simple team decision problem tdp finite signal spaces finite action spaces discrete density compute decision rules ff minimize expected cost function ff ff ff ff difficult show tdp effectively computable athans tsitsiklis proved tdp np hard belongs equivalence class difficult computational problems traveling salesman problem computational complexity believed grow exponentially fast size problem case cardinalities sets 
note tdp hard restriction complete informational decentralization agents allowed communicate signals treated private information 
allow agents communicate signals central planner tdp easy sense solved polynomial time 
tsitsiklis result certainly suggests need caution claiming decentralization sense computationally efficient appears realistic examples assumption complete informational decentralization plausible 
recursively enumerable set exists effectively computable function enumerates elements set 
central planner observed signal pair simply choose action pair minimized 
minimization problem requires ka theta ka comparisons function evaluations 
optimal decision rules ff ff computed functions giving optimal action pair possible state pair 
total involved solving centralized version tdp bounded ky theta ky theta ka theta ka clearly grows polynomially size problem 
certainly true agents economic agents complete information partial information obtained messages economic agents 
example models competitive equilibrium agents access vector prices viewed public broadcasts set signals functions collective information economy 
theorem welfare economics tells competitive equilibrium price vector sufficient statistic collective private information economy sense individual agents right decision individual private information global information contained equilibrium price vector 
unfortunately results theory continuous information complexity show agents truthfully report private information auctioneer central planner impose demanding requirement computing ffl approximation solution exact solution computational problems involved computing walrasian equilibrium solution social planning problem shown intractable sense precise 
order briefly summarize key concepts theory information complexity referring reader excellent monograph traub complete account 
assume access idealized computer capable storing arbitrary real numbers performing infinite precision arithmetic solutions continuous mathematical problems integration optimization zeros nonlinear equations fixed points correspondences generally require information essentially infinite dimensional quantity entire graph function integrated optimized 
physical computer system realizable algorithm able store information finite number points domain costly acquire face situation solutions continuous mathematical problems computed exactly approximated 
addition circumstances don complete information function know belongs set functions set continuous uniformly bounded functions set ffl denotes measure distance approximate exact solution mathematical problem worst case ffl complexity mathematical problem comp ffl defined minimal cost computing ffl approximation true solution possible complexity function comp ffl represents minimal computation time cost function producing computer scientists studied average case complexity various mathematical problems prior distribution introduced set possible functions weaker requirement expected approximation error expectation taken respect prior distribution ffl 
ffl approximation cost calculations involved producing ffl approximation defined terms primitive model cpu time space costs involved elementary operations needed implement solution algorithms 
mathematical problems associated parameters represented denoting dimension euclidean space mathematical problem lives 
example consider problem integration optimization problem finding zeros functions variables 
cases customary write problem dimension extra argument complexity function comp ffl 
computer scientists say computational problem intractable complexity function takes form comp ffl ffl small symbol denotes lower bound complexity function 
intractable problem lower bound computation cost increases exponentially problem dimension economics problems property typically referred suffering curse dimensionality 
results information complexity theory summarized established large number mathematical problems subject curse dimensionality multivariate integration optimization finding zeros nonlinear functions finding brouwer fixed points solution partial equations integral equations problem finding fixed points certain classes contraction mappings includes problem solving infinite horizon continuous state dynamic programming problems special case worst case complexity functions form equation 
appears relatively straightforward exercise translate general complexity bounds corresponding complexity bounds economic problems utility maximization requires solution constrained optimization problems maximizing expected utility requires calculation multivariate integrals finding walrasian equilibria requires calculation zeros aggregate excess demand function finding brouwer fixed point calculation rational expectations equilibria involve solutions integral equations computation option values involve solutions pde solutions infinite horizon dynamic programming problems involve computation contraction fixed points calculation nash equilibria reduce calculation see results intractability multivariate integration nemirovsky intractability constrained optimization intractability zero finding chow tsitsiklis intractability dynamic programming hirsch vavasis intractability brouwer fixed points intractability pde integral equations 
see papadimitriou related results intractability fixed points problem finding approximate competitive equilibria discrete computational complexity framework 
fixed point correspondence 
date formal complexity bounds established relatively small number economic problems social planning friedman oren walrasian equilibrium papadimitriou dynamic programming chow tsitsiklis 
list quickly grow formal proofs soon available showing majority economic problems intractable 
step translate complexity bounds impossibility theorems stating rational optimizing behavior impossible 
reasons discuss section generally possible prove formal theorem effect strong argument rational optimizing equilibrium behavior isn impossible highly 
impossibility argument roughly follows 
real economic problems extremely high dimensional 
example refers number goods services actual economy certainly large probably closer depending narrowly define service 
problems function number agents view planet single integrated economy 
extent want compute reasonably accurate approximation competitive equilibrium solution level approximation error tolerated ffl small number ffl realistic values exponential complexity bounds ffl imply astronomical number calculations required 
simple logic exponential growth tells regardless values typically unspecified bounding constants complexity bounds increases number calculations quickly grows large world fastest supercomputers unable find approximate solution problem reasonable period time 
extent believe individual economic agents economy subject computational limitations complexity bounds constitute arguments impossibility rational equilibrium behavior 
simon satisficing behavior motivated exactly type argument person matter strong urge 
face real world complexity business firm turns procedures find answers question best answers 
real world optimization computers impossible real economic actor fact person accepts alternatives preferred choice 
economists milton friedman vocal argued gap satisfactory best great importance assumption actors optimize matter including believe matter matters great deal 
simon pp 

difficult dismiss impossibility arguments computational complexity bounds observed curse dimensionality empirically numerous numerical applica tions 
discovery mathematical problems computationally intractable provides compelling explanation researchers economics physics artificial intelligence fields forced limit computational experiments relatively small simple toy models despite having access large computational resources supercomputer centers clusters fast workstations 
furthermore complexity bounds tell problems just due fact computational methods early state development new methods ultimately discovered crack problem constitute lower bounds computation time possible algorithm regardless algorithms discovered 
section suggest ways dealing complexity context economic calculations 

strategies dealing complexity economic calculations section argue worst case complexity bounds described previous section constitute proofs rational optimizing behavior impossible 
outline different ways circumvent break curse dimensionality underlying economic calculations 
methods may eventually possible calculate approximate solutions detailed large scale economic models 
possible attempt provide empirical evidence general strategies outline successful enabling economists economic agents solve hard problems 
fairly obvious computational complexity bounds discussed section constitute proofs rational optimizing equilibrium behavior impossible question solution economic problem computationally feasible depends number particulars determined case case basis 
particulars include processing speed available hardware amount time available perform calculations level error ffl tolerated magnitudes bounding constants entering complexity bounds specific problem solved represents worst case best case average case 
ultimately empirical question possible solve specific economic problem available time required accuracy available hardware 
edged sword proposition intractability quite true theory discrete computational complexity famous np problem unresolved 
np breakthrough algorithm enables solve np complete problems including traveling salesman problem polynomial time 
date algorithm discovered computer scientists believe algorithm exists np unfortunately able prove assertion 
economic problems implies rational optimizing equilibrium behavior impossible reduces empirical issue truth falsity settled purely logical grounds proposition ways break intractability economic problems implies rational optimizing equilibrium possible empirical question settled deductive reasoning 
best convincing proof proposition show exist hardware software solve realistically specified optimization equilibrium problems 
want emphasize point fact rational behavior possible imply economic agents behaving approximately optimally markets approximately equilibrium empirical question scope essay 
objective section limited argue predictions economic theories impossible suggesting number ways dealing complexity economic calculations 
hardware solutions problem economic complexity hardware solution facts dimensions human brains orders magnitude powerful fastest man computers power man computers growing exponential rate 
fact opens possibility impossible solve realistic versions economic problems current computers reasonable amount time human brain may sufficiently powerful solve problems available time 
fact suggests man computers eventually catch exceed power human brain solving realistic versions economic problems may eventually possible various economic optimization decision problems subject curse dimensionality 
evidence fact comes research neuroscience shows despite fact switching times propagation speed electrical impulses neurons orders magnitude slower corresponding electrical signals silicon chips travel nearly speed light brain amazingly powerful chemical computer information processing capabilities orders magnitude faster fastest man computers constructed silicon microprocessors computation limited power consumption matter brain impressively efficient 
example neuron uses roughly theta gamma joules energy operation neuron activating synapse 
contrast efficient silicon technology currently requires theta gamma joules operation multiply add 
mead 
criterion joules operation orders magnitude power efficient best silicon chips 
direct consequence energy efficiency brains perform operations second newest supercomputers 
fastest digital computers capable theta operations second brain common example performs theta operations second merely resting 
churchland sejnowski 
fact primarily result advances enabled computer manufacturers integrated circuits leading exponential growth speed memory digital computers microprocessor performance increased years matching rate integrated circuit logic density predicted moore law 
example microprocessors times faster 
national science foundation 
generally recognized starting reach point diminishing returns amount computational power built single cpu partly due limits degree miniaturization due optical partly due limits short cpu clock cycle hazardous predict permanent slowdown growth rate cpu power known physical lower bounds amount energy required computation due new technologies optical quantum computing devices self assembling molecular scale organic computers lead circuit densities time greater current 
victory ibm deep blue computer top ranked human chess player gary kasparov appears day man computers able outperform human brain terms information processing capacity 
software solutions problem economic complexity obviously mere fact access powerful hardware doesn necessarily imply capacity solve hard problems 
possibility rational behavior compelling show ways circumventing breaking curse dimensionality underlying economic calculations 
section outline number software solutions succeed making intractable problems tractable 
specifically problem said tractable complexity comp ffl bounded polynomial problem dimension desired accuracy level ffl 
due logic exponential growth generally take orders magnitude solve high dimensional problem complexity increases polynomially fast problem complexity increases exponentially fast show alternative measures complexity problems appeared intractable definition complexity tractable alternative formulation 
different complexity measures simply clever trick designed define way problem different complexity measures correspond see reed 

development self assembling molecular computing devices proves economically viable highly brain computer hardware involves truly massively parallel architecture 
controlling programming systems formidable software challenges decentralization may prove essential discussed section 
different ways assessing quality approximate solution demand algorithm produces ffl approximation probability content method finds ffl approximation sufficiently high probability different amounts prior information problem solution 
particular show amount prior information disposal big impact types methods solve problem software solutions outlined imply rational behavior possible empirical question amount prior information possess problem 

exploitation special structure 
known lower bounds worst case complexity continuous mathematical problems derived context information complexity theory adversary principle 
rough terms adversary viewed opponent selects worst case problem set possible problems response algorithm level computational effort chosen level computational effort 
complexity problem minimax solution game adversary person performing computations 
complexity problem typically sensitive size set possible problems latitude give adversary choosing worst case scenario higher complexity problem 
conversely restricting smaller set problems time special structure reduce complexity problem dramatically 
example consider consumer problem max jp ffl approximation global optimization problem vector satisfying ju gamma ffl vector attains global maximum equation 
result nemirovsky theorem denote set times continuously differentiable functions lower bound worst case deterministic complexity consumer problem comp ffl ffl set concave functions worst case deterministic complexity consumer problem comp ffl theta log ffl theta denotes upper lower bound complexity 
words consumer problem intractable general case allow possible smooth utility function problem tractable exploit fact utility functions special structure concavity monotonicity 
fact optimization problem case fairly easy problem complexity polynomial linear number commodities reasonable believe utility functions concave empirical question don attempt address 
key point example calls question relevance worst case complexity bounds derived general classes problems practical situations worst case bounds may far pessimistic ignores possibility economic agents exploit prior knowledge special structure problem enabling solve far rapidly predicted worst case bounds 
worst case bounds relevant explaining observed performance algorithms number different problems 
example klee constructed subfamily linear programming problems essentially forced simplex algorithm visit nearly vertices constraint set find optimal solution 
number vertices increases exponentially fast number constraints variables lp increases counter example shows worst case problems simplex algorithm computationally intractable 
algorithms interior point methods known polynomial time performance worst case experience shown practical problems simplex algorithm efficient methods supposed guarantee works remarkably visiting small subset vertices locating optimal solution 
worst case results yield misleading difficulty linear programming efficacy simplex algorithm especially believe exploiting special structure problems typically encounter practice 
example high dimensional numerical integration 
discussed section known multivariate integration deterministic methods worst case complexity grows exponentially fast problem dimension bounds practical experience lead conventional wisdom see davis deterministic integration methods fairly low dimensional problems 
high dimensional integration problems arise regularly economics computing expected discounted values random required price various financial instruments 
nemirovsky result consider additional gains exploiting monotonicity utility function 
traub deterministic integration method compute expected values mortgage obligations cmos yield monthly cash flows year horizons amounting integration dimensions 
integration methods simple average integrand evaluated deterministically chosen points known points 
get accurate approximations dimensional integration problem small 
example suggests deterministic integration methods provably intractable worst case basis worst case complexity bounds irrelevant case 
don observe exponentially fast increase solution times problem dimension increases suggests behavior algorithm better approximated average case worst case analysis 

decomposition 
approach closely related strategy exploiting special structure 
idea certainly new similar ideas simon ando nearly decomposable systems 
decomposition method motivated fact generally far easier solve large problem breaking union approximately independent subproblems attempt solve problem directly 
clearest way illustrate potential gains adopting strategy consider example exhibiting perfect decomposability 
consider dynamic programming problem utility function transition probability choice sets js js theta delta delta delta theta example think problem consisting tasks 
vector represents state task boldface denote vectors states actions tasks 
equation states task states evolve independently 
practical example problem large rental car prove multivariate integration tractable average case basis particular typically gaussian priors represent likelihood encountering various types see 
determine optimal replacement policy vehicle fleet 
intuitively separability independence assumptions imply problem perfectly decomposable separate subtasks solved independently construct solution 
straightforward verify formally 
value function dynamic programming problem max fi ds js lemma additive decomposition js satisfies multiplicative decomposition constraints sets product structure value function additive decomposition max fi ds js lemma worst case complexity continuous state decomposable dynamic programming problem satisfying comp ffl theta ffl denotes dimension denotes dimension assumed dimension simplicity 
worst case complexity non decomposable dynamic programming problem doesn product structure comp ffl theta ffl lemma confirms intuition perfect decomposability allows independently solve subproblem combine solutions subproblems obtain solution problem 
lemma quantifies gains doing 
problem subject curse dimensionality easier solve separate subproblems dimensions solve large problem dimension delta delta delta complexity grows linearly number tasks problem solved decomposition exponentially 
principle decomposition closely associated parallel processing subproblems obviously solved separate processors 
technique widely physical engineering applications known domain decomposition method commonly solve pde problems spatial structure allows identify subproblems partitions domain 
course problems exactly decomposed completely independent subproblems 
challenge recognize problem nearly decomposable identify approximately independent subproblems determine solved separately ignoring possible interdependencies subproblems quasi separately summarizing feedbacks subproblems relatively low dimensional sets sufficient statistics 
simon notes natural world nearly decomposable systems far rare economics cases easy identify sufficient statistics summarize impact subsystems economy empirically true price commodity rate exchanged depend significant extent prices quantities commodities aggregate magnitudes average price level measure economic activity 
large linkage coefficients associated general main flow raw materials products industries 
input output matrix economy giving magnitudes flows nearly decomposable structure system qualification 
consumption subsystem economy linked strongly variables subsystems 
modify notions decomposability slightly accomodate role consumption subsystem analysis dynamic behavior economy 
simon pp 

introspection suggests brains extensive decomposition specialized areas brain highly optimized solving specific subproblems visual auditory processing speech coordination forth 
easy identify physical brain structures associated higher level mental processing cerebral cortex appears brain effective job solving different subproblems parallel assembling solutions subproblems yield coherent pattern behavior 
example course day quite number different activities reasonable treat approximately independent subproblems 
example problem deciding articles read morning newspaper independent problem route take 
imagine interdependencies arise say newspaper contained article construction delays expressway ordinarily may approximation assume don exist cost ignoring small 
quite solve single massive dynamic programming problem ex information literature see web site www ddm org 
ante provides contingency plan dealing possible eventuality 
doing closer solving fairly large number subproblems corresponding different activities engage accounting unexpected problems recomputing solution particular subproblem fly new information arrives suggests previous solution subproblem may 
believe high payoffs research help understand brain able decompose large complex problems number tractable subproblems reassemble individual solutions sensible solution problem 
economists particularly benefit better understanding brain succeeds piecing solutions subproblems help discover ways integrate insights gained numerous micro models provide relatively detailed models small aspects economic behavior insights highly macro models obtain detailed coherent models macroeconomic activity 
opinion economists unsuccessful interconnecting specialized models subcomponents economy sensible model economy failure key factors limiting rate advancement practical usefulness economic research 
suggest adoption high level protocol provides standard interface economic models go long way making economic science cumulative collective endeavor reducing need continually reinvent wheel allowing new researchers easily integrate build results previous researchers 

randomization 
certain problems known intractable worst case deterministic algorithms proven tractable randomized algorithms employed 
classic example randomized algorithm monte carlo integration 
central limit theorem implies monte carlo integral converges true integral rate number sample points monte carlo integral regardless number variables integrand drawback randomized algorithms capable generating ffl approximation probability settle weaker assurance expected error algorithm ffl 
cases substantial payoffs settling weaker guarantee summarized result details see appealing markov inequality easy show randomized algorithm capable generating ffl approximation probability gamma ffi ffl ffi arbitrarily small solution tolerances 
theorem consider problem multivariate integration class times continuously differentiable functions dimensional hypercube uniformly bounded st derivative 
worst case deterministic complexity comp wor det ffl theta ffl worst case randomized complexity comp wor ran ffl theta fl ffl restrict deterministic algorithms quadrature multivariate integration problem intractable complexity increases exponentially fast randomization problem tractable complexity ffl independent dimension curse dimensionality deterministic methods numerical quadrature observed practice 
standard texts numerical integration davis conclude deterministic integration methods fairly low dimensional problems recommend monte carlo integration higher dimensional problems 
high dimensional integration problems arise regularly economics computing expected utilities portfolio optimization problems expected discounted values uncertain monthly dividends coupons required price various long term financial instruments pricing example discussed section 
important note randomization succeed breaking intractability types mathematical problems 
example randomized complexity optimization problems deterministic complexity problem intractable worst case settings 
important open question optimization tractable average case setting 
results section suggest exploiting prior information special structure optimization problem dramatically reduce complexity 
difficult specify priors embody intuitive notions special structure monotonicity analytically deterministic low discrepancy method traub solve problem appear obey worst case complexity bounds substantially outperformed monte carlo integrals apparent contradiction theorem reader remember complexity bounds theorem worst case scenario may relevant understanding performance particular cases represent average best case scenarios 
tractable manner 
far research value prior knowledge optimization problems done worst case framework reflecting prior knowledge restricting class admissible functions monte carlo integration extended infinite dimensional integration problems path integration computation expected value functional wiener process similar logic applied show randomization breaks curse dimensionality problems see wo 
randomization shown break curse dimensionality involved solving functional equations arising rational expectations models dynamic programming problems 
case dynamic programming problems type problem involving conditional expectations depend state variables assume continuum values essentially infinitely integrals need approximated integral possible value order compute value function 
rust showed logic monte carlo integration extends naturally dynamic programming problems approximate unique fixed point bellman operator gamma gamma max fi js ds approximate fixed point random bellman operator gamma gamma max fi js iid uniform draws dimensional state space note gamma random function apply functional central limit theorem show gamma gamma gamma independent dimension state space result triangle inequality contraction mapping property imply kv gamma fixed point gamma turn implies result theorem constraint sets finite uniformly bounded number elements certain lipschitz regularity conditions comp wor det ffl gamma fi ffl comp wor ran ffl gamma fi ffl dynamic programming problems finite numbers possible actions randomization succeeds breaking curse dimensionality worst case deterministic complexity increases exponentially fast worst case randomized complexity increases polynomially theoretical predictions theorem verified numerical experiments rust showed randomized solutions problem outperformed standard deterministic solution methods relatively low dimensional test problems 
encouraging finding ordinary integration monte carlo methods generally recommended problems deterministic methods faster accurate low dimensional cases 
rust results show performance randomization critically dependent degree smoothness transition density problems lipschitz bound increases exponentially fast curse dimensionality reappears randomization 
advantage approximation strategy equation method dramatically reduces memory requirements necessary obtain uniform approximation true solution approximate value function summarized numbers values set random grid points computed value corresponding approximate decision ff computed fly alternative point operations 
calculate approximate value arbitrary standard approaches discretization dynamic programming problems involve interpolation approximate value function calculated grid containing ffl points 
randomization allows break curse dimensionality involved memory requirements cpu consumption simultaneously 
important memory constraints may just important time constraints motivating effective algorithms digital computers human brain 
example shows exist economical ways storing information allow agent bounded memory capacity processing speeds take nearly optimal actions states encountered need agents store elaborate contingency tables behave nearly optimally 
randomization solve high dimensional large scale problems long history physics chemistry pioneering ulam von neumann los alamos economists begun adopt monte carlo certain deterministic methods points outperformed randomized method 
example indicating worst case deterministic complexity bounds may relevant understanding performance algorithms specific cases 
problem specific convergence bounds derived rust provided accurate prediction actual behavior various algorithms worst case bounds 
techniques simulation methods comparatively 
methods large impact econometrics simulation estimators significantly extended size complexity models estimated 
stochastic learning algorithms learning temporal difference learning real time dynamic programming playing increasingly important role artificial intelligence literature 
formal proofs stochastic algorithms succeed breaking curse dimensionality numerical experiments similar methods solve class dynamic games mcguire suggest case 
problem table lookups states encountered integrating random bellman approach effective 
difficult determine extent nature employs randomization tool solving hard problems 
randomization play key role evolution genetic mutations serving driving force experimentation improvement 
brain signals appear large random component neurons spontaneously active spiking random intervals absence input churchland 
furthermore neuron cell body known cumulate add random inhibitory signals received neurons thousands synapses dendrites certain potential threshold achieved causes neuron fire 
suggests possibility form monte carlo integration may playing role operation brain 
randomization plays key role current theories memory problem solving 
theories model neural networks brain stochastic boltzmann machines hopfield networks essentially nonlinear dynamic systems implement versions simulated annealing search stable energy minimizing configurations network 
energy minimizing configurations thought represent memories solutions problems random shocks play key role simulated annealing preventing dynamic system converging local optima energy landscape 
noted randomization break curse dimensionality optimization soap film example section suggest thermodynamic systems viewed massively parallel processors succeed solving highly complex global optimization equilibrium problems extremely rapidly 
extent random noise plays important role dynamics systems ability find equilibrium energy minimizing configurations may reason observe prominent role played randomization natural systems 

knowledge capital 
problems solve completely scratch 
access solution similar problem provides initial guess starting point help solve problem hand 
cases previously discovered solutions don expend computational effort simply copy previously discovered solution thinking 
stated differently potentially difficult decisions economic calculations encounter daily life avoided economic agents access substantial amounts knowledge capital 
stock knowledge capital thought huge library previously discovered solutions various problems 
existing stock knowledge capital avoid expending substantial amounts computational effort reinventing wheel 
course library rarely contains solution problem exactly confronting situation provided problem hand different problems previously encountered solved case making relatively small modifications previously discovered solutions obtain approximation solution problem hand show save lot computational effort process 
different examples aspects relatively simple intuitive point discussing simple example formalizes potential gains knowledge capital 
consider dynamic version exchange economy sequence static temporary equilibria change day day result stochastic shocks preferences endowments 
demand function consumer period corresponding endowment 
equilibrium price vector day satisfies try compute equilibrium price vector scratch cases knowledge previous temporary equilibrium prices nearby problems problems times kx gamma ke gamma small uniformly applying worst case complexity bounds sikorski hirsch conclude worst case complexity temporary equilibrium problem ffl number commodities 
consider case market operation long time stationary environment adjustment process market able find ffl approximation equilibrium price gamma 
assume equilibria days gamma regular consumer unique utility maximizing bundle gradient excess demand function non singular equilibrium price assume consumers optimization problems solved exactly zero cost order simplify argument 
complexity problem increase accounted cost solving consumers optimization problems 
vector shocks affecting preferences endowments sufficiently small gamma domain attraction equilibrium price day worst case complexity finding ffl approximation equilibrium price vector day increases polynomially exponentially fast example polynomial time algorithm computing newton method gamma gamma gamma gamma gamma approximate solution iteration newton methods gamma gamma denote value gradient excess demand function day evaluated trial price vector gamma traub wo showed provided starting price vector gamma newton method domain attraction zero upper bound complexity newton iteration log log ffl polynomial exponential course claim decentralized price adjustment behaves newton method point simply illustrate exist price adjustment procedures circumvent curse dimensionality shocks market sufficiently small 
market mechanism doesn start scratch process computing approximate equilibrium price time previous price gamma ordinarily constitutes initial guess compelling examples knowledge capital vastly reduce amount computation required operate sensibly complex environment 
basic example biological evolution dna probably obvious form knowledge capital 
dna constitutes blueprint nature discovered constructing successful living organisms long run process ecological competition random trial error chance outcomes cross genetic mutations sexual reproduction effects stochastic changes environment 
addition serving blueprint construction organisms dna organism behavioral patterns form basic instincts 
result dna limits number things organism needs think helps organism solve potentially intractable problem choosing particular behavioral rule huge space possible behavioral rules order maximize fitness 
examples hardwired instincts include sex drive instinct nest young instinct children imitate parents apparent automatic development language skills humans forth 
extent hardwired behavior patterns simply stored need learned recomputed significantly reduce organism computational burdens 
importantly hardwired behavior patterns limit space possible decision rules alternative actions organism consider vastly reduce number new computations organism perform order take particular course action real time 
real time computations organisms perform restricted limited set actions need take day day second second survive 
success evolutionary processes suggests environment sufficiently stationary knowledge capital embodied dna usually provides starting value reduce complexities faced succeeding generation organisms surviving adapting environments 
dna example suggests reasons doubt relevance impossibility results worst case analyses 
argue evolutionary processes lead organisms capability solve average case necessarily worst case problems 
may exist worst case problems organisms unable solve limited real time available gazelle isolated herd may able think fast cheetah hunting meal matters fitness survival species organisms able solve average case problems typically encounter typically survive provided smart run middle herd 
suggests thinking impact dna forms knowledge capital evolutionary context relevant question problems organisms encounter tractable average case worst case setting 
species organisms unable quickly find solutions fitness relevant problems typically encounters evolutionary processes eventually drive species extinction possibly new species organisms able solve problems 
case evolutionary processes lead form selectivity bias species emerge successful long term survivors stationary environment capable solving fitness relevant computational problems typically confront 
suggests problems organisms solve tractable appropriate average case setting 
human economies societies large fraction knowledge capital fairly tangible obvious includes stock patents inventions accumulated history 
new generation inherits stock ideas inventions previous generation enabling concentrate limited problem developing new ideas inventions solve new existing unsolved problems adding stock knowledge capital 
obvious probably equally important form knowledge capital embodied economic institutions stock exchange commodity markets prominent counterexample 
legal institutions concepts limited liability private property rights government institutions social security social institutions family customs forth 
institutions viewed constituting approximate solutions various problems society facing 
similar dna institutions survived evolutionary process trial error competition 
institutions social insurance appear relatively early stage evolution undergoing frequent changes enable provide better solutions socio economic problems motivated 
result previous configuration institutions necessarily represent starting point solving today problems especially society economy changing rapidly 
institutions market institution appear converged relatively stable forms surviving relatively unchanged thousands years economic evolution 
just discussion dna argue evolutionary processes lead economic institutions tend simplify computational problems facing economic agents complicated institution imposes huge computational burdens participants tends reduce payoffs making persist 
believe impossibility results reviewed section mere existence artificial worst case games institutions force agents solve computationally intractable problems irrelevant thinking question agents capable finding rational optimizing solutions problems typically face 
relevant question actual institutions require agents solve intractable computational problems 
certain market institutions survived relatively unchanged centuries economic evolution 
argue success due fact efficient due fact computationally efficient sense attempt explain 
consider particular market institution double auction da market idealization ancient market institution buyers sellers homogeneous commodity meet common trading post conduct exchange 
da market opens specific times traders dynamically announce bids asks various quantities transactions endogenously determined set transaction prices 
sequence transaction prices determined holders best current bid asks advances communication storage dissemination information greatly accelerated rate social evolution relative natural evolution 
nature genetic mutation dna yields better blueprint successful organism may take generations hundreds thousands years new genetic innovation propagate species 
rapid rate communication human societies enables new innovations transform simplify lives billions humans span decades years 
highest bid lowest ask decide trade actual transaction price determined variety rules typically price interval current bid ask 
modern commodity markets chicago board trade continue specialized forms da institution basic institution new communications computer technologies rapidly leading electronic versions da market replacing traditional oral double auction conducted trading pits 
theoretical analyses da market focus role endogenous price formation markets central walrasian auctioneer goal clear market 
extensive experimental evidence shows transaction prices rapidly converge values close competitive equilibrium ce predictions observed allocations nearly efficient relatively thin markets buyers sellers 
economic theorists model da market non cooperative continuous time game incomplete information goal explain observed outcomes realizations bayesian nash equilibria games 
unfortunately game theoretic models analytic solutions problem computing approximate equilibria games appears computationally intractable equilibria require solving continuous time continuous state dynamic programming problems agents optimal trading strategies discussed section single agent dp problems shown intractable worst case deterministic algorithms 
result economic theory provides specific predictions trading behavior outcomes da markets 
sense da institution computationally efficient 
apparent intractability solving game theoretic models da square considerable experimental evidence demonstrates untrained undergraduates able quickly learn trade da markets observed outcomes close predicted competitive equilibrium outcomes 
research gode sunder gs rust miller palmer rmp suggests potential resolution paradox outcomes da market typically collectively rational traders individually rational 
robustness property da institution vastly simplifies computational problems traders 
solving complicated dynamic programming problems require keeping track entire history bids asks traders doing bayesian updating beliefs example gs studied da markets populated zero intelligence zi traders bids asks simply iid draws uniform distributions truncated reservation value enforce minimal requirement zi trader trades negative profit 
gs showed collections zi traders display collective rationality price trajectories converge ce outcomes probability close realized allocations nearly efficient 
rmp showed similar outcomes emerged collections heterogeneous strategies easily exploit vulnerability zi strategies 
winning strategy computerized double auction tournament simple rule thumb appears highly successful heuristic wide range environments performed experiments human opponents 
valuations individual traders rapid convergence ce outcomes implies transaction prices sufficient statistics expected profit maximizing strategy simple trader need compare previous transaction prices reservation value positive place bid ask close previous transaction order guarantee high probability trading realizing profit 
true rational traders potentially excess profits succeed identifying exploiting irrational noise traders results rmp suggest combination high levels noise limited amounts data individual da trading sessions difficult identify strategies employed individual opponents rational traders identify exploit irrational traders repeatedly trading agents market 
furthermore evolutionary computer tournaments conducted miller palmer rust show irrational traders rapidly driven extinction anyway absence steady stream noise traders long run outcomes da markets dominated intelligent rational traders 
unfortunately apparently intractable computational problem solving bayesian nash equilibria directly don know long run outcomes da market close approximations game theoretic predictions 
basic point combination knowledge capital embodied da trading rules evolutionary forces shaping long run trading strategies da market greatly reduce computational burdens individual traders leading collectively rational outcomes prices efficiency levels close predicted full information models competitive equilibrium 
wide variety market institutions addition da market 
general economists believe market institutions generally represent solutions economic allocation problem designed solve 
reasons extensively analyzed economic theory 
section wish explore new hypothesis success stability markets succeed solving extremely complex potentially intractable resource allocation problems decentralization decentralization computationally efficient 
detail institutions theory empirical evidence performance da market see friedman rust 

decentralization computationally efficient 
previous section offered hardware software solutions problem economic complexity 
think ideas help greatly extend class models solve 
don think ideas 
section speculations role decentralization additional method solving complex problems 
view decentralization interface hardware software type operating system constitutes efficient method performing large scale computations massively parallel hardware 
argument computational efficiency decentralization consists parts 
argue physical technological reasons nature powerful computers take form massively parallel processors millions billions individual processors 
second conjecture mathematical logical reasons nature relies decentralization operating system managing controlling massively parallel systems 
paradoxically argument computational efficiency decentralization impossibility result limitations centralized methods manage large scale systems 
limitations due informational problems stressed von hayek problems intractability stressed literature computational complexity 
issue define mean decentralization 
unfortunately entry new dictionary attempt define concept definition oxford english dictionary conveys basic idea sufficiently precise purposes 
turns quite difficult provide precise mathematical definition decentralization intuitive notion quite clear decentralized system identifiable center controls behavior dynamics individual agents processors particles consumers firms comprising system 
control information processing decentralized systems distributed agents comprising system agents autonomous sense behavior laws motion governed primarily objective functions objectives may affected messages competition types interactions agents system 
definition decentralization defined opposite centralization act centralizing concentrate administrative powers single head centre distributing local departments 
closely related concept informational decentralization arising literature resource allocation mechanisms hurwicz mount reiter information needed resource allocation decisions directly available place central planner distributed economy form private information economic agents endowments preferences technologies objective literature determine possible design game forms message processes implement various allocations social choice rules 
equilibria games thought decentralized methods solving social planning problems eliminate need central planner 
final requirement distinguishes decentralized system arbitrary collection particles processors agents system solves identifiable problem 
individual elements system behave autonomously may aware part larger system collective outcome interactions appears outside observer particles cooperated solve problem phenomenon referred emergent computation 
order intuitive definition clearer helpful illustrate examples emergent computation decentralization massively parallel systems 
soap films 
simplest examples decentralized system 
dip wire loop bucket water soap film typically form loop extracted bucket 
soap film solution global optimization problem arrange soap water molecules film energy minimizing configuration 
physicist richard palmer private communication tell central planner solves global optimization problem shape soap film emergent computation arises endogenously collective interactions soap water molecules individual objective function find energy minimizing positions electrostatic field created neighboring molecules 
important note decentralized system solves global optimization problem extremely rapidly analysis worst case complexity global optimization suggests problem intractable numerical experience alternative methods solving systems partial differential equations describing dynamics soap film lead intractable computational problems 
reason mathematicians studying types pde typically resort simply wire loops buckets water fastest computer studying effects different boundary conditions 
example shows exist decentralized massively parallel analog computers guided thermodynamic principles rapidly solve intractable global optimization problem 
immune system 
massively parallel system individual elements include various effector combat troops antibodies various specificities cells signal corps exemplified helper cells cytokines 
elements defined objectives functions example cells bear receptor molecules recognize mhc protein combination matches special shape receptor 
suitable recognition triggers intracellular molecular cascade leads killing cells signalling helpers 

immune system decentralized entirely distributed approximation fairly defined major mission destruction pathogens 
brain 
massively parallel system individual elements neurons communicate electrical nerve impulses various neurotransmitters synapses connecting neurons 
obvious hierarchical large scale structure brain various specialized processing areas visual cortex hippocampus cerebellum thalamus probably largely due central planning provided dna initial stages development operation adult brain appears best described decentralized system 
reason identifiable central planner coordinates activities nerve cells anatomy frontal cortex areas primary sensory areas information organization democracy ford assembly line 
hierarchies typically apex analogy expect find brain region sensory information converges motor commands emerge 
striking fact false brain 
convergent pathways convergence partial occurs places occurs places times motor control appears distributed vested central command center 
churchland pp individual neurons brain appear objective functions rough terms seek stimulation avoid inhibition see klopf 
number computer scientists developed theories cognition hypothesize brain operates sort society competitive economy intelligence emerge 
answer ll show build mind little parts 
ll society mind scheme mind smaller processes 
ll call agents 
mental agent simple thing needs mind thought 
join agents societies certain special ways leads true intelligence 
minsky 
obvious time brain defined objectives eating sex furthermore clear communications brain asynchronous depending appears random intervals firing adjacent neurons neurotransmitters inhibitors synapses 
economy 
competitive economy final type hardware characteristics 
individual processors human agents interact economy 
competitive economy decentralized central planner directs activity agent agents behave autonomously setting prices making production consumption decisions order maximize individual profit utility 
objective economy clear previous examples economic theory teaches outcome efficient allocation resources ideal conditions economy operates maximizing weighted sum individual utilities 
previous version conjecture decentralization computationally efficient feedback received initial draft realized unable provide precise mathematical definition decentralization prove computationally efficient 
intuitive definition decentralized system central control 
central planner mimics decentralized process 
example economic context central planner attempt mimic decentralized outcome shadow prices acting walrasian auctioneer broadcasting sequence trial prices allowing agents report preferred consumption bundles price vector property sum reported notional excess demands zero 
obvious price adjustment process regarded centralized decentralized 
believe key characteristic distinguishing centralized decentralized systems level synchronization autonomy individual agents decentralized systems ones agents substantial autonomy operate asynchronously 
unfortunately hard think simple definition enables draw clear cut dividing line distinguishing centralized decentralized systems agree 
possible provide case case classifications centralized decentralized algorithms situation know see 
conclude section providing number examples centralized decentralized algorithms computing competitive equilibria discuss computational advantages decentralized algorithms 
examples centralized algorithms classic example centralized method computing ces programming approach suggested described dixon section 
programming approach repeatedly maximizes weighted average individual utilities subject aggregate resource constraints 
normalized lagrange multipliers resource constraints serve shadow prices regarded trial values competitive equilibrium price vector 
welfare weights adjusted sa problem repeatedly re solved exists set welfare weights corresponding shadow prices holds consumer easy show solution ce economy initial endowments believe central planner mimics walrasian auctioneer centralized process reason classic tatonnement process centralized algorithm auctioneer controls sequence trial prices agents allowed consume trial consumption bundles agents reports truthful completely synchronized 
versions tatonnement describe centralized algorithms suggest may large gray area disagreement start arise algorithm centralized decentralized 
example walras algorithm proposed cheng wellman regarded asynchronous distributed version standard tatonnement process separate auctioneers goods economy 
algorithm operates discrete time time market agent required transmit demand function gamma gammai auctioneer market gamma gammai denotes fixed prices commodities generated walras algorithm previous period 
auctioneer adds transmitted demand functions compute aggregate excess demand function market prices commodities fixed 
auctioneer quotes new price sets excess demand market equal zero independently price adjustments auctioneers gamma markets 
auctioneers ignore feedback effects price adjustments markets cheng wellman prove commodities gross substitutes sufficient condition global stability ordinary tatonnement continuous price adjustment processes walras algorithm generates stochastic price sequence fp converges ce price vector probability 
walras algorithm centralized decentralized standard tatonnement process method assumes auctioneers market virtually equivalent central planners reason view centralized approach 
methods proposed economists operations researchers compute approximate ce including variations newton johansen method see dixon scarf algorithm see scarf elaborate methods solving variational inequalities sequences linear nonlinear problems see rutherford algorithms interpreted requiring strict coordination synchronization reporting requirements part individual agents regarded centralized approaches solving sa problem 
examples algorithms computing equilibria introduced explicitly referred decentralized reiter closer inspection reveals algorithms informationally decentralized necessarily computationally decentralized sense am trying convey 
particular reiter algorithm appears inherently serial parallel due fact agents required act sequentially agent unable act receiving message agent gamma complexity calculations required agent theta violating property computational constant returns scale 
examples decentralized algorithms 
discussed examples decentralized algorithms computing approximate ce discussion double auction market section knowledge capital gode sunder rust miller palmer 
example decentralized algorithm bilateral bargaining model general equilibrium price formation axtell epstein 
axtell epstein computational simulation exchange price formation population agents preferences continuous dimensional commodity bundles randomly matched allowed engage bilateral bargaining 
environment classical approximate equilibria calculated standard centralized solution methods reviewed previous section computer simulations demonstrate completely decentralized process repeated bilateral trade randomly selected pairs agents done sequentially parallel results approximate ce solution appearing emergent computation 
find solutions emerge quite rapidly bilateral trade processes meaningfully viewed kind distributed computation near pareto optimal allocations 
argued distributed trade processes provide faithful interpretations invisible hand welfare theorem walrasian general equilibrium 
shown number bilateral interactions required reach pareto optimality linear number agents number commodities 
argued non polynomial complexity algorithms computation walrasian equilibria unrealistic metaphors real markets 
axtell epstein axtell epstein model thought computational implementation gale theoretical model proves walrasian outcomes limit model random matching bargaining 
classify decentralized agents bargain goods right propose reject trial prices agents choose long bargain consume matching bargaining asynchronous typically done parallel 
part result due fact reiter model number choices agent equal total number agents economy 
notation equivalent assuming attempt survey growing literature decentralized agent approaches computation 
examples area include foley bell 
agent approach compute approximate equilibria dynamic games 
see example sargent mcguire 
important goal agent computational modeling understand large computational task solved cooperative efforts large number agents processors loosely coupled asynchronous decentralized fashion 
literature emergent computation computer science pursuing similar goals 
computer scientists baum holland huberman 
waldspurger 
come recognize role competition prices powerful means facilitating coordinating emergent computation 
believe key understanding decentralized algorithms understand provide right incentives processor design right institutions easy processor behave cooperatively solving small piece problem 
number researchers shown possible build decentralized agent models specific contexts general theory design agent models solve problems understanding sense sorts parallel decentralized algorithms may computationally efficient 
institutions place intuition decentralized methods efficient centralized methods controlling massively parallel systems intuitively clear hayek observation substantial problems making sure central planner sufficient information decisions communications costs delays central planner kept date sufficiently rapidly take decisions second second basis complexity problems associated determining break problem little subtasks assign individual processors reassemble solutions subproblems solution problem 
fact slow progress developing general purpose operating system massively parallel machines connection machine indication substantial difficulties involved 
typically great deal human insight intervention hand coding required order effectively parallelize particular problem 
hope truly decentralized system intelligence self organize solve particular problem confronts competitive principles way human brain able solve wide variety different tasks 
challenge provide right institutions decentralization competition succeeds harnessing power massively parallel systems resulting anarchy chaos clear having larger massively parallel systems really significant advantage 
minsky aptly summarized importance having effective institutions discussion evolution human thought ancestors diverged relatives chimpanzees years ago human brains grown years 
evolutionary interval brief genes brain structures remain nearly chimpanzees 
merely increase brain size capacity produced new abilities 
consider increase size brain cause disadvantage mental confusion inconvenience heavier head 
evolved ability manage memories take advantage memory 
similarly inserting new layers agents old agencies lead bad results mechanisms layers middle level managers disrupting older functions 
words evolution worked way came enhancements abilities feasible manage larger agencies 
capability machinery natural selection favor grew massive brains 
minsky 
concluding remarks essay turned philosophical tone liked probably inevitable debate fundamental limits knowledge rational equilibrium behavior possible satisfactorily resolved basis purely logical considerations 
ultimate goal really quite practical find new methods solve larger realistic models 
vein think compelling proof come talking issue generality building realistic large scale models agents behaving approximately optimally approximately equilibrium 
essay viewed attempt guy big science vision economics decentralized agent modeling approach met considerable skepticism economists 
criticism big science approach large scale computer simulations necessarily amount great deal understanding sheer complexity scale simulations quickly move realm easily understand 
acknowledge best circumstances expect get agent simulation computerized replica complexity real world economies point 
simply observe real economy dispense agent simulations 
answer fold 
want computerized agents economies study predict effects hypothetical policies scenarios typically cheaper discover bad policies computerized models try human pigs 
second understanding phenomenon requires multiple approaches 
certainly understanding assistance reasonably simplified theories toy models give insight essential features principles underlying real world 
call understanding 
example theoretical literature economics focused narrow question proving existence equilibrium games model economies 
fully understand assumptions proofs models really think theory gives complete understanding economics 
complete understanding need able calculate detailed implications predictions theories determine predictions models consistent observe real world 
pretend complete understanding real economies show detailed implications theories provide sufficiently accurate representations real world take models seriously forecasting policy analysis 
believe vision vision 
essay argued view fundamental computational limits prevent eventually obtaining sort understanding suggested ideas 
order really large breakthroughs think need structure computations faithfully mimic computational solution nature economy discovered thousands millions years social biological evolution 
particular means principles decentralization harness power massively parallel processors 
conclude motivational example illustrates supposedly intractable problems solved combination innovative algorithms massive parallelism decentralization 
particular computational breakthrough occurred mathematical problem determining prime factorization large integers 
known polynomial time algorithm prime factorization known prime factorization intractable mathematical problem 
prime factorization large integers generally regarded difficult problem formed basis rsa public key cryptography system employs pair prime numbers secret key public key consisting product integers known modulus integer known exponent 
encode message user converts text integer raised power determined public key exponent remainder computed public key modulus modulo arithmetic 
determine inverse encoding requires knowledge prime factorization modulus 
inventors rsa encryption system encrypted sentence digit modulus offered reward succeeded decoding sentence economic problem se serious economic implications prime factorization underlies public key cryptography systems currently considered implementing secure electronic commerce 
specifically known prime factorization problem exponential complexity number digits input integer factored 
known prime factorization problem np complete computer scientists mathematicians currently believe 
analysis computational complexity prime factorization problem suggested take years find prime factors digit modulus best known algorithms computer hardware 
bell communications research scientist lenstra cracked rsa code massively parallel algorithm known multiple polynomial quadratic sieve period months idle cpu cycles workstations connected internet 
total number calculations required break code quite large requiring computer instructions years ago code broken lenstra quoted 
example main points essay combination clever software design decentralization massive parallelism possible solve problem previously thought insoluble 
way encoded text consisted single sentence magic words 

foley decentralized dispersed exchange auctioneer journal economic behavior organization 
anderson 
ed 
minds machines prentice hall englewood arrow hurwicz econometrica 
axtell robert joshua epstein distributed computation optimal allocations bilateral exchange manuscript brookings institution washington baum 
theory mind faire economy manuscript nec research institute princeton new jersey 
bell 
bilateral trading network convergence optimality results manuscript vanderbilt university 
binmore 
modelling rational players part economics philosophy 
board tinsley smart systems simple agents industry pricing parallel rules finance discussion series federal reserve board washington cheng wellman walras algorithm convergent distributed implementation general equilibrium outcomes manuscript university michigan forthcoming computational economics 
chow tsitsiklis 
complexity dynamic programming journal complexity 
davis 
methods numerical integration academic press new york 
dixon computable general equilibrium modelling policy analysis forecasting rust eds 
handbook computational economics volume 
joshua epstein robert axtell growing artificial societies brookings press brookings institution washington friedman oren complexity resource allocation price mechanisms bounded rationality 
gale 
bargaining competition part characterization econometrica 
gode sunder lower bounds efficiency surplus extraction double auctions friedman rust eds 
double auction market institutions theories evidence volume xiv santa fe institute studies sciences complexity addison wesley reading massachusetts 
hayek 
knowledge society american economic review 
hayek 
knowledge reprint nobel prize memorial lecture american economic review 
hirsch papadimitriou vavasis exponential lower bounds finding brouwer fixpoints journal complexity 
huberman hogg behavior computational ecologies huberman ed 
ecology computation amsterdam elsevier 
hurwicz 
informationally decentralized systems radner mcguire eds 
decision organization volume honor jacob marschak amsterdam north holland 
klee 
simplex algorithm ed 
inequalities iii 
klopf 
neuron hemisphere publishing new york 
lange 
computer market feinstein ed 
capitalism economic growth cambridge university press 

scientific american 
lewis 
effectively computable realizations choice functions mathematical social sciences 
lewis 
minimum degree recursively representable choice functions mathematical social sciences 
lewis 
structure complexity recursion theory foundations theory games manuscript cornell university department mathematics 
lewis 
aspects effectively constructive mathematics relevant foundations mathematical economics theory games mathematical social sciences lewis 
turing degrees walrasian models general impossibility result theory decision making mathematical social sciences sargent money medium exchange economy artificially intelligent agents journal economic dynamics control 
minsky 
society mind simon schuster new york 
mount reiter informational size message spaces journal economic theory 

computability infinitely repeated discounted games washington university manuscript 

parallel computation rust eds 
handbook computational economics amsterdam elsevier 
national science foundation desktop exploiting lead high performance computing report nsf blue ribbon panel high performance computing national science foundation washington dc 
nemirovsky problem complexity method efficiency optimization wiley new york 
papadimitriou 
complexity parity argument inefficient proofs existence journal computer systems sciences 

average case complexity multivariate integration smooth functions journal complexity 
traub faster valuation financial derivatives journal portfolio management 
penrose 
new mind new york penguin 
reed zhou muller tour conduction single molecules science reiter 
decentralized process finding equilibria linear equations proceedings national academy sciences 
rust miller palmer behavior trading automata computerized double auction market friedman rust eds 
double auction market institutions theories evidence volume xiv santa fe institute studies sciences complexity addison wesley reading massachusetts 
rust 
randomization break curse dimensionality econometrica 
rutherford 
mps ge user guide department operations research stanford university 
scarf 
computation equilibrium prices exposition arrow eds 
handbook mathematical economics volume ii amsterdam elsevier 

immune system prototype autonomous decentralized systems manuscript weizmann institute science rehovot israel 
sikorski 
optimal solution nonlinear equations satisfying lipschitz condition numerische mathematik 
sikorski 
optimal solution nonlinear equations journal complexity 
simon ando aggregation variables dynamic systems econometrica 
simon 
sciences artificial mit press cambridge massachusetts 

point scientific american 
traub 
breaking intractability scientific american 
traub wo information complexity new york academic press 
tsitsiklis athans complexity decentralized decision making detection problems automatic control ac 
waldspurger hogg huberman kephart spawn distributed computational economy ieee transactions software engineering 
wo tractability path integration journal mathematical physics 
