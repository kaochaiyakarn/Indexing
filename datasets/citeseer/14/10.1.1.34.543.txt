ultra summarization statistical approach generating highly condensed non extractive summaries michael witbrock mittal just research henry street pittsburgh pa lycos com mittal com current extractive summarization techniques impossible produce coherent document summary shorter single sentence produce summary conforms particular stylistic constraints 
ideally prefer understand document generate appropriate summary directly results understanding 
absent comprehensive natural language understanding system approximation 
presents alternative statistical model summarization process jointly applies statistical models term selection term ordering process produce brief coherent summaries style learned training corpus 
summarization important capabilities required writing 
effective summarization effective writing easy innate skill developed instruction practice anderson hooper generating effective summary requires summarizer select evaluate order aggregate items information relevance particular subject particular purpose 
absence comprehensive natural language understanding system approximation 
previous computational implementations summarization focused extractive summarization selecting text spans complete sentences paragraphs original document 
extracts arranged linear order usually order original larger document form new summary document 
drawbacks approach focus addressing particular important limitation inability extractive summarizers generate summaries shorter text spans evaluated ranked 
extractive summarizers past considered sentence minimal unit extracted text means shortest summaries systems produce sentence long 
problematic cases especially short headline desired 
due fact sentences selected summaries tend longer researchers looked extracting paragraphs sentences strzalkowski mitra average sentence document important information document scattered multiple sentences extractive summarization combine syntactically semantically concepts mentioned different text spans source document spans 
describes alternative approach summarization sentence extraction capable generating summaries desired length statistically learning models content selection realization appropriate training corpus generate summaries similar training ones desired length 
approach advantages novel applications compared text span extraction approaches 
rest discusses framework pros cons technique illustrates preliminary examples working examples training test corpora concludes brief description ongoing 
background related previous summarization focused extractive methods 
starting earlier luhn luhn researchers focused issues lexical occurrence statistics positional indicators document versus document instance edmundson possible negative factors instance words indicate lesser significance mathis salton colleagues experimented probabilistic measures word importance salton marcu looked learning structural importance marcu hovy lin looked machine learning approaches positional importance hovy lin contrast large amount undertaken extractive summarization generative model summarization 
earliest approaches generative models discussed context system dejong possessed set templates extracting information news stories presenting form summary 
content selection part generation part learned system extraction templates handcrafted particular application domain generation process required set manually specified sentence templates 
systems topic reimer hahn scisor rau similar experimenting different aspects underlying knowledge representation structures number features considered reported generative summarization consists columbia summarizer radev mckeown uses manually specified generative grammar english construct english sentences underlying knowledge representation uses manually crafted rules content selection 
systems generate summaries may single noun phrase complete sentence learn rules procedures templates content selection generation suitable training corpus 
reported closely related statistical machine translation summarization 
instance candide system ibm brown uses translation model describing correspondences sets words source language sets words target language ordering model describing likelihood sequences target language achieve goal natural language translation 
sense system considered translating languages verbose succinct 
analogy holds general level important differences systems 
important system principle produce variety derived documents chiefly summarizations brief characterizations larger documents document sets derivations need semantically equivalent complete 
ibm system designed translation system forced statistically capture complete set correct senses nuances concepts source document express target document 
discuss relaxing constraint allows considerable flexibility 
system design operation high level view system shown 
main steps processing 
suitable corpus documents corresponding headlines summaries assembled 
case news wire articles reuters associated press available ldc 
target documents summaries system needs learn translation mapping headlines accompanying news stories 

documents preprocessed identify items determining summary contents 
system described pre processing included tokenization 
currently tokens contiguous character sequences including punctuation symbols spaces carriage returns 
principle tokens may include words additional information parts speech tags semantic tags applied words phrases 
conceivably long distance relationships words phrases document structural information obtained document preliminary version system takes advantage part speech tags completed evaluation 
headline article translation models article translation models generate headlines 
training documents translation model generator translation model words characters grams syntactic semantic tags documents summarized summary control parameters generated summaries summary search selection sequences tokens jointly maximizes information content retained document summarized conformance learned summary structure 
corresponding training summaries language model generator summary language model lexical gram syntactic patterns high level view system architecture 
positions words phrases mark information obtained document existence different font 

pre processing model applied target documents 

statistical model built describing relationship source text units document target text units summary document 
model describes order likelihood appearance tokens target documents context certain tokens source partial target document 

statistical models generated step information user task requirements produce headline summary document 
ms detail believed telling truth relationship president 
ms told psychologist dr irene affair shortly began 
related details sexual encounters soon occurred calling white house office 
example document starr report consider document shown 
goal get system generate summary document set training documents corresponding summaries 
possible headlines summaries imagine article include nature president clinton relationship monica ms 
actual section headers starr report 
clinton affair headline style summary 
generation conceptually sub tasks system undertake content selection information summary level detail include summary surface realization linearization phrase syntactically valid coherent fashion 
goal system learn operational metrics sub tasks automatically training data corpora containing large numbers matched source target documents documents headlines case mechanisms selecting contents summaries particular length generating coherent english language text express content selected step 
content selection training corpus learn model relationship appearance features document appearance features summary 
simplest case model consists mapping appearance word document likelihood word appearing summary 
computational reasons early implementation evaluated simply models conditional probability word occurring summary word appeared document 
table shows part mapping words example excerpt 
content selection score phrase details sexual reordering words political inferences drawn 
features word tokens initial experiments text spans labels syntactic semantic features document 
word probability details sexual white house table conditional probability word appearing summary appears document 
scheme simply product individual probabilities details details document 
document 
sexual sexual document clearly trivial extend approach model complex relationships arbitrary subsets tokens source target documents 
relationships need just tokens characterizations tokens pos tags token lengths derived statistics proportion nouns document average sentence length noted consequence freedom choosing content selection model system capable learning relationships target summary terms document terms document apply relationships new documents introducing new terms summary 
content selection model trained suitable document summary corpus compute selection scores candidate summary terms terms occurring particular source document 
conjunction summary structure model described scores compute summary candidates particular parameters summary length rankings 
probability word appearing summary considered independent structure summary probability particular summary candidate computed multiplying probabilities content summary probability content expressed particular summary structure 
worth noting limitation types relationships expressed pragmatic constraints lack sufficient memory test approach corpus far prevented producing model reason model learned fact improve quality mappings learned 
note necessarily independence assumption modeling choice 
word log probability word reuters headlines details sexual white house table probability finding particular words summary case reuters headline 
word pair word word log probability word word details sexual white house table probability finding pairs words sequence training summaries reuters headlines 
content selection model variations approach appropriate training corpora produce cross lingual summaries 
case model probability english word appear summary japanese document containing certain set terms simultaneously translate summarize japanese documents 
conducted preliminary experiments task details obtained witbrock mittal speculatively imagine cross media summarization inventory spoken word forms concatenative synthesis algorithm table conditional probabilities speech segments spoken summary particular document generate spoken summaries 
similarly corresponding video media chosen represent content document 
surface realization probability particular surface form headline candidate details sexual computed modeling probability word sequences 
simplest models bigram language model probability word sequence approximated multiplying probabilities seeing term left context 
case candidate value log details log details log sexual house beam white house beam white house beam white house affair beam white house sexual affair beam white house sexual affair beam white house sexual affair beam white house sexual affair soon beam white house sexual affair soon beam sample output system word level mappings 
figures right log probabilities proposed summaries number terms considered average emitted word 
values tables yields log probability 
alternative sequences words sexual details probabilities calculated similarly 
case sequence sexual details appeared training data estimated back weight katz log log sexual log backoff sexual log details yielding estimated log probability sequence indicating sequence times part headline previous 
mentioned earlier calculations extended take account likelihood additional information semantic tags named entities syntactic tags pos information word phrase level carried respect textual spans characters 
course extended higher order grams providing sufficient numbers training headlines available estimate probabilities 
search content selection summary structure generation separately reason occur independently fact current implementation simultaneously contribute weighting scheme ranks possible summary candidates 
case phrase discussed weighting ranking obtained time beam new customers beam dell computer products beam new power macs strategy beam apple sell macintosh users beam new power macs strategy internet beam apple sell power macs distribution strategy beam new power macs distribution strategy internet products beam apple sell power macs distribution strategy internet beam sample output system word level mappings 
weighted combination content structure model log probabilities log details details doc log doc log sexual sexual doc log details log details log sexual generate summary necessary find sequence words maximizes probability content selection summary structure models generated document summarized 
initial implementation summary term selected independently summary structure model order markov viterbi beam search forney efficiently find near optimal summary 
statistical models require different heuristic search algorithm 
example results commanding search output highly ranked candidate variety values summary length control parameter shown 
shows set headlines generated system run real news story discussing apple computer decision start direct internet sales comparing strategy computer makers 
current implementation set weights 
implementation beam width minimum beam size states 
markov assumption violated backtracking state strongly discourage paths repeated terms bigrams start repeating overwhelm search 
experiments discussion gain better understanding approach works section briefly discusses sets experiments conducted 
trained system approximately news articles reuters dated 
contained unique tokens articles slightly tokens headlines stripping punctuation marks 
representing conditional probabilities pair words required matrix entries computer resources training data limited decided take simpler approach initially investigate effectiveness training smaller set words words appeared headlines 
system calculated conditional probabilities words headlines appeared article bodies 
keep model simple possible limited system learn bigram transition probabilities headline syntax 
sample output runs system shown 
simple system performed surprisingly 
course obvious problems relatively straightforward fix sufficient training data 
ignoring grammatical problems system able pick main issues stories white house affair apple internet distribution respectively 
problem obvious stopping point system generate longer longer headlines 
believe possible learn model headline length function story content simply parameterizing length straightforward initial experiments 
evaluate version system decided compare output actual headlines untrained set input reuters news stories 
compare phrasing compared generated headlines actual headlines ii top ranked summary sentence story 
system currently mechanism determine optimal length headline generated headlines story ranging length words measured term overlap generated headlines test standard actual headline summary sentence 
story maximum overlap noted length overlap maximal 
measured stricter measure effectiveness headlines matched completely words generated headline alternative approach limiting size mappings need estimated top words small value hundreds thousands 
perfect headline affair white house 
done effort overcome problems headlines different vocabulary story 
overlap actual overlap top gen headline headline summary sentence percentage length words min max min max complete matches table evaluating system effectiveness generating headlines reuters news articles 
actual headline noted lengths generated headline 
statistics illustrate system selecting content words headlines 
phrasing quality difficult impossible measure objectively 
actual headlines ungrammatical incomplete phrases 
expect longer gram models part speech models help system generate headlines similar phrasing real headlines 
statistics experiments shown table 
noted system defense headlines generated system penalized match original ones 
instance case story nasa satellite rescue mission system generated headline space shuttle satellite rescue bid 
scored headline compared standard nasa considers satellite rescue bid 
results probably err stricter side 
alternative extractive summarization approach possible generate coherent summaries shorter single sentence conform particular stylistic constraints 
approach applies statistical models term selection term ordering processes produce novel brief summaries desired length 
strength approach enables summaries compact previously possible furthermore summaries need contain words original document previous statistical summarization systems 
sufficiently quality training corpora approach generate headline style summaries variety formats various applications instance experimenting corpora contain japanese documents english headlines 
corpora constructed running extremely unsophisticated lexical translation system japanese headlines results 
experiments approach currently way 
clear short system need addressed 
shortcomings fixed better training data 
corpus suitably annotated data requisite mark indicate additional information focus discourse structure anaphoric information help greatly evaluating improvements possible 
able incorporate model external information user interactions biases optimize content form generated summaries 
deficiencies addressed sophisticated content selection summary structure models 
step direction begun system uses automated part speech markup allow better modeling summary structure 
working model uses distance words original story condition probability appear separated distance headline 
hope extend example subject verb relationships story constrain subject verb relationships generated headlines 
speculatively may permit application summarization scheme problem learning summaries indicative content evaluation 
system learn mappings documents assessments essay choice terms improved punctuation missing editorial column 
aone aone larsen 
scalable summarization system robust nlp 
proceedings acl eacl workshop intelligent scalable text summarization pages madrid spain 
brown peter brown stephen della pietra vincent della pietra robert mercer 
mathematics statistical machine translation parameter estimation 
computational linguistics 
dejong gerald dejong 
overview system 
wendy lehnert martin editors strategies natural language processing pages 
lawrence erlbaum associates hillsdale nj 
edmundson edmundson 
problems automatic extracting 
communications acm 
similar intent automatic essay grading lsa larkey forney forney 
viterbi algorithm 
proceedings ieee pages 
tasso 
tailoring importance evaluation reader goals contribution descriptive text summarization 
proceedings coling pages 
anderson anderson 
producing written summaries task demands cognitive operations implications instruction 
review educational research 
hooper hooper sales 
generating summaries analogies pairs 
contemporary educational psychology january 
hovy lin eduard hovy chin yew lin 
automated text summarization summarist 
proceedings acl eacl workshop intelligent scalable text summarization pages madrid spain 
katz katz 
estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech signal processing 
kupiec kupiec pedersen chen 
trainable document summarizer 
proceedings acm sigir pages 
acm 
larkey larkey 
automatic essay grading text categorization techniques 
proceedings st acm sigir sigir pages 
acm 
luhn luhn 
automatic creation literature abstracts 
ibm journal pages 
marcu daniel marcu 
discourse structures text summaries 
proceedings acl eacl workshop intelligent scalable text summarization pages madrid spain 
mathis mathis rush young 
improvement automatic abstracts structural analysis 
journal american society information science 
mitra mitra amit singhal chris buckley 
automatic text summarization paragraph extraction 
proceedings acl eacl workshop intelligent scalable text summarization madrid spain 
radev mckeown dragomir radev kathy mckeown 
generating natural language summaries multiple online sources 
linguistics 
rau lisa rau paul jacobs udi 
information extraction text summarization linguistic knowledge acquisition 
info 
proc 
management 
reimer hahn reimer hahn 
text condensation knowledge base abstraction 
proceedings fourth conference artificial intelligence applications pages march 
salton gerard salton singhal mitra buckley 
automatic text structuring summary 
info 
proc 
management march 
strzalkowski strzalkowski wang wise 
robust practical text summarization system 
aaai intelligent text summarization workshop pages stanford ca march 
witbrock mittal michael witbrock mittal 
statistical approach generating summaries headlines synopses representing reasoning translation models 
technical report pittsburgh research center pittsburgh pa december 

