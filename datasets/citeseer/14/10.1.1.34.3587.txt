bayesian time series models computations analysis time series physical sciences mike west institute statistics decision sciences duke university durham nc 
articles discusses developments bayesian time series modelling analysis relevant studies time series physical engineering sciences 
illustrations discuss bayesian inference computation various state space models examples analysing quasi periodic series isolation modelling various components error time series decompositions time series significant latent subseries nonlinear time series models mixtures auto regressions problems errors uncertainties timing observations development non linear models stochastic deformations time scales 
key words dynamic linear models markov chain monte carlo mixture models non linear auto regression state space models stochastic time deformations time series decomposition timing errors 
article catalogues aspects time series modelling analysis relevance exploration univariate time series structure physical sciences 
specifically briefly review variants dynamic linear models state space models bayesian forecasting years mentioning practical aspects handling missing data values additive measurement sampling errors time series outliers time series decomposition investigate latent component sub series consequence 
markov chain monte carlo mcmc methods posterior simulation state space models discussed analysis deep sea oxygen record related patterns variability historical climate change 
kind analysis wider interest connection exploring particularly quasi periodic structure time series physical sciences generally 
decomposition oxygen series latent components illustrated connection isolation investigation key email mw isds duke edu web www isds duke edu invited xv th workshop maximum entropy bayesian methods santa fe new mexico july august 
research supported part nsf dms 
mike west sub cycles driven earth orbital dynamics 
connections drawn component state space structures 
practical issues time series analysis subject uncertainties timing observations arise physical sciences discussed approaches incorporating timing errors time series analysis briefly reviewed 
leads wider area potential research bayesian time series connection general models stochastic time deformations 
related non linear auto regression semi parametric mixture models bayesian density estimation mentioned 
models potential identifying systematic non linearities smooth threshold auto regressive structure essentially arbitrary forms observed series 

dynamic linear models normal state space framework linear state space models central bayesian time series analysis short term forecasting years 
applications socio economic forecasting control engineering exploited modelling flexibly contexts time varying non stationary time series structure 
advances computation begun extend framework allow coherent inference variance components model parameters non gaussian errors models model features opening new application areas result 
brief review illustration 
consider scalar time series observed equally spaced time points assumed follow dlm gz gamma components assumptions theta state vector time column known constants regressors fixed constant observation noise distributed known known theta matrix state evolution matrix fixed constant state evolution noise innovation time distributed 
known variance matrix noise sequences independent mutually independent initialising state vector specified normal prior jm initial information set standard normal linear distribution theory provides known linear filtering algorithms easily computing derived normal distributions collections state vectors observations conditional subsets observed series 
key examples include line priors jx gamma posteriors jx step jx lag filtered posteriors gammak jx fx general dynamic models time varying elements case constant elements quite far ranging 
problems learning elements addressed various ad hoc ways new mcmc methods see provide major breakthrough 
bayesian time series 
examples auto regressive components suppose 
delta delta delta oe oe oe delta delta delta oe gamma oe delta delta delta delta delta delta 
delta delta delta delta delta delta ffl 
deltaj independently ffl deltaj entries zero denote second elements respectively simple firstorder polynomial trend random walk process gamma standard zero mean ar process oe gammaj ffl observed trend plus auto regression subject measurement sampling errors example appear 
note replaced dlm forms complex trends regression terms direct extension notion model superposition 
class auto regressive component developed applied various geological time series analyses 
models combine distinct ar components exhibiting time varying periodic structure persistent unit root components 
provides approach bayesian spectral analysis sustained sinusoids distinct periods subject stochastic changes amplitudes phased 
case example just components plus locally constant trend model structure fi gamma fi gamma models components obvious generalisations 
defining parameters oe foe oe model class corresponding fi parameters appear primary elements state evolution matrix consequence structure bayesian analyses simulation methods simplified important practical ways illustrated 

latent structure time series decomposition central objective time series analysis decomposition observed series estimated latent components exploration interpretation components 
dlm context latent component structure central model building development chapters developments mike west area lead simple useful methods posterior component analysis elaborated context example provided autoregressive dlm 
developments closely linked developments similar canonical models dlm framework chapter 
special model eigenvalues reciprocal roots auto regressive characteristic polynomial 
assume commonly case roots distinct non zero occurring pairs complex conjugate pairs gamma real distinct values write complex eigenvalues exp sigmai 
real values simply latent ar process representation tj tj tj latent subseries corresponding eigen structure 
tj quasi periodic ar process time modulated sinusoid stochastically varying amplitude phase fixed period 
modulus tj ar process modulus innovations driving latent component processes highly dependent 
major point component representation computable specified oe vector determining oe elements specified set values series see 
analysis delivering posterior inferences oe series inferences latent subseries tj follow 
direct analyses posterior simulation posterior samples oe generated corresponding posterior samples tj terms may directly computed averaged produce approximate posterior means components summarised ways 
exploring time trajectories components usefully elucidate latent structure raw series illustrated 
note connections decomposition structure related models 
equivalent decomposition explicitly sum periodic components time varying amplitudes phases damping whatsoever 

measurement error models important feature state space modelling explicit recognition sources error measurement errors sampling errors outlier recording errors forth directly corrupting observations underlying physical process purely observational error terms explicitly distinct process system noise innovation terms biases distortions inferences arise models confuse ignore distinction 
example measurement error corrupting pure ar process leads shrinkage estimated coefficients zero posterior distributions favour ar parameter value closer zero error modelled standard errors variables effect 
error bayesian time series processes dominated outliers naturally serious practical concern chapters 
traditional extensions basic normal error assumption realistic forms include outlier accommodating models normal mixture distribution gamma admits background level routine measurement error variance occasional extremes outliers inflated variance component small probability section 
background variation measured may small negligible applications degenerate mixture gamma ffi default additive outlier model robust time series fitting functions plus 
extent basic observational errors may impact inference assessed modelling estimating routine measurement sampling errors quite substantial enormous significance physical sciences 
non degenerate version tends preferred 
extension routine dlm analyses incorporate kinds practically important error models feasible mcmc simulation methods kinds modelling extensions important stimuli early simulation models state space approaches 
similar mixture models interest evolution equation connection modelling stochastic changes state vectors abrupt marked expected routine implied basic normal distributions terms chapters particularly 
fact early developments bayesian forecasting largely predicated applied problems commercial forecasting led development mixture errors models multi process chapter 
concepts various methods approximation resulting analyses years simulation methods implement exact bayesian analyses kinds realistic error modelling assumptions point analyses set routine applied 

posterior computations bayesian time series analysis early development mcmc simulation methods state space frameworks growing rapidly 
note ranges related developments outside state space framework typified example appear review 
mcmc methods permit monte carlo inference kinds models exemplified variants basic gibbs general metropolis hastings algorithms generate approximate posterior samples collections state vectors dlm parameters 
structure basic algorithm briefly illustrated auto regressive component dlm see details models 
concreteness take model 
mixture observational error models incorporated assuming independent normal vh constant scale factor individual variance weights instance basic mike west contamination model assumes drawn independently gamma ffi ffi assumptions possible 
initial information summarised independent priors variance components independence necessary assumed 
define zn fz complete set state vectors times notation consistent earlier definition observation set xn fx xn mcmc proceeds iteratively sampling collections conditional posterior distributions quantities interest 
ar parameters oe set state vectors zn variances weights hn fh hn subset quantities write gamma remaining parameters variables oe gamma hn various gibbs sampling algorithms may constructed iteratively sample conditional distributions gamma appropriate choices algorithm detailed basic structure 
sampling zn gamma fixing model parameters variance components gamma standard normal dlm theory applies delivers useful normal distributions 
particular efficient algorithms reverse sampling sequence gamma followed gamma gamma turn gamma conditioning values stage values sampled 
distribution gamma computed follows 
filter forward time compute usual sequence kalman filter moments conditional distributions jx gamma jm note elements gamma state vector known known simply elements 
replace entries gamma accordingly 
sample remaining elements gammap resulting bivariate normal distribution gammap jx gamma may done efficiently precise algorithmic details laid appendix 
complete process results sequence gamma represents sample posterior distribution zn gamma required 
sampling oe gamma reduces standard problem computing sampling posterior ar parameters observed data yn plus essential initial values gamma gamma ar process 
example standard prior produces normal posterior priors 
sampling variance components fixing zn leads current fixed values errors innovations ffl provide sequences independent observations vh ffl known means inform variances respectively 
independent inverse gamma priors variances conjugate sampling resulting posteriors gamma gamma gamma straightforward priors 
priors finite range corresponding standard deviations 
bayesian time series sampling hn gamma gamma conditionally independent sampled individual posteriors proportional exp gamma vh gamma 
repeatedly iterating conditionals leads markov chain sampler full space uncertain state vectors model parameters stationary distribution full joint posterior 
posterior samples elements translate directly posterior samples underlying smooth trend samples latent ar process parameter samples produce direct approximations posterior margins 
issues establishing convergence results mcmc schemes especially connection mixture error models discussed example 

illustration analysis oxygen record briefly summarised illustration state space analysis latent auto regression mixture error model implemented simulation analysis just summarised 
kinds analysis means standard accessible computationally routine 
discuss data modelling questions arising studies forms quasi periodic components recorded geological time series connection investigating patterns historical climate change 
discusses deep ocean oxygen series previous analyses 
series explored upper frame plots data representative oxygen series cores various geographical locations measures relative abundance ffi timed approximately equally spaced scale 
background details appear 
series stretches back roughly 
time varying periodicities evident nature structure periodicities geological interest especially connection ice age cycle 
analyses models explored reported 
uses locally constant trend plus latent ar component mixture observational error model traditional uniform prior oe priors variances finite range uniform priors standard deviations 
burning simulation iterations posterior sample draws saved summarised 
approximate posterior means oe elements zn evaluate decomposition latent process representing decomposition key quasi cyclical components 
parts decomposition appear displaying approximate posterior means acyclic trend observational errors dominant quasi cyclical components ordered wavelengths sum remaining components latent autoregression 
posterior samples periods quasi periodic components support values precisely approximate posterior quartiles respec mike west reversed time 
estimated oxygen data decomposition ar state space model analysis 
components displayed series estimated smooth trend estimated observation errors quasi cyclical components periods approximately kr respectively sum remaining components latent auto regression 
raw series sum trend plus components displayed 
tively 
directly interpretable terms responses forcing mechanisms earth orbit period earth axis period 
called ice age cycle major current geological interest connection debates genesis roughly ago particularly questions onset gradual inherent result significant structural climatic change 

marked observational outliers apparent level baseline measurement error appears small scale raw data approximate posterior quartiles approximately 
changing form terms primarily amplitude key component bayesian time series period evident major factor determining change appearance raw series ago 
components sustained amplitudes 
addition estimated innovations sequence ffl displayed consistent form full stretch data clear indication changes variance 
geological focus marked changes nature major longer term oscillations period 
ties onset ice age cycle period range marked change form component suggested 
notice model accommodates predicts real structural change series assuming fixed auto regression entire time period changes key quasi cyclical components evident decomposition graphical display 
analyses focussed issue separate models subsets series apparent change point confirm suspected change point materially impact estimated decomposition displayed 

random observation times timing errors uncertainties application areas suffer problems errors uncertainties timing time series observations 
example series quantity deep lake sediment proxy indicator local climatic conditions interest studying climatic change time 
data timed measures depth sediment cores mapped calendar ages complex uncertain process involving carbon calibration 
detailing modelling calibration process elaborate model true uncertain times observations constructed provides class prior distributions times 
analyses incorporate uncertain times model parameters state variables 
study describes focuses particularly limited data result realistic measures timing uncertainties 
simple measurement errors truncation rounding errors timing may subject assessment similar approaches 
bayesian inference implemented mcmc analysis illustrated application feasible conceptual basis follows 
generally denote observed data series write true uncertain timing back known equally spaced case 
specific time series model write theta model parameters state variables tn set times observations 
model implies likelihood function xn jt theta usual analysis proceeds conditional tn induce explore posteriors xn defined prior tn theta representing timing errors uncertainties prior information timings couple conditional analyses priors tn may depend model parameters theta represented notation prior independence simplify prior tn theta tn assume sample theta vectors xn specified timings assume corresponding conditional posterior tn theta xn tn theta theta tn may simulated specified theta 
mike west mcmc analysis proceeds iteratively resampling conditional posteriors usual manner 
specific models xn jt theta priors tn studied various gibbs metropolis hastings algorithms sampling exercises developed applied 
issue note problems require time series models arbitrary spacings observations 
dlm framework achieved refining nominal time scale finer equally spaced scale traditional dealing unequally spaced randomly missing data chapter 
alternative involves embedding series underlying continuous time model progress develop bayesian analyses various contexts 

random observation times time deformation models conceptual technical developments dealing uncertain observation times opening novel area involving inference stochastic time deformations 
builds basic ideas 
demonstrates certain deterministic deformations traditional linear models mapped models characteristics similar common non linear models arch models threshold ar models 
basic approach assumes underlying linear time series model process operational time observed series discretely sampled version represents transformation operational real time inverse time deformation function 
connections modelling uncertainties timings evident technical level machinery developed extended provide framework bayesian inference time deformation functions 
current studies include stochastic time deformations approach modelling chirp effects harmonic processes modification traditional bayesian spectral methods result 
various classes priors including non parametric models explored time deformation functions 
applications include modelling irregular waveform patterns long series eeg recordings collaboration duke reported preliminary discussion appears 

mixture models non linear auto regression different sense traditional approach non linear time series modelling initiated :10.1.1.54.803
interest identifying inferring departures linearity auto regressive context developed state space framework practical issues dealing observational errors lead extensions 
basic idea simple 
non linear ar model determined specifying class conditional distributions jx gamma gammap theta theta denotes model parameters 
building flexible classes dirichlet mixture models developed semi parametric bayesian density estimation develops models defining conditionals flexible mixtures bayesian time series specifically mixtures normal distributions jx gamma gammap theta jb suitable gamma regression functions linear gamma gammap differ component variances vary depend conditioning past gammaj values gamma multivariate kernel factor implying higher conditional weight mixture components best support current conditioning values state variables gamma gammap approach inference described largely predictive :10.1.1.54.803:10.1.1.54.803
posterior computations deliver approximate posteriors model parameters theta model interpreted predictively exploring features resulting sets conditional predictive distributions data just averages mixtures respect posterior 
technically posterior computations involve variants gibbs metropolis hastings mcmc algorithms invented bayesian density estimation mixture models extensions time series context cover various hyper parameter problems 
obvious connections standard kernel methods conditional mean function jx gamma gammap theta kernel auto regression function bayesian model foundation provides 
example aspects parameter uncertainty naturally reflected analysis problems smoothing parameter estimation subsumed posterior inference corresponding variance parameters hyper parameters 
terms modelling flexibility development set full conditional mixture distributions state gamma gammap varies provides adaptation may substantial patterns variation state space just conditional mean 
examples include cases conditional distributions regions gamma gammap space unimodal regions clearly multi modal :10.1.1.54.803
cases conditional predictive means bayesian kernel regression functions poorly summarise location conditional distributions inherently smooth continuous functions state gamma gammap contrast traces conditional modes informative capturing important distinct components conditional structure mean obscures smoothing 
sense models capable capturing abrupt threshold effects tar models chapter smooth transitions star models section ranges non linearities 
modelling entire distributions allows adaptation changing patterns variation spread features conditional predictive distributions series evolves 
example illustrate features :10.1.1.54.803
models include mixtures quasi cyclical ar components designed allow explore evident departures linearity periodic series specific class state dependent models naturally allows variation mike west period wavelength parameters quasi cyclical processes function past values series state variables 
model developments exploration applications subject current study 

west harrison bayesian forecasting dynamic models springer verlag new york 

pole west harrison applied bayesian forecasting time series analysis chapman hall new york 

west bayesian inference cyclical component dynamic linear models amer 
statist 
assoc appear 

west statistical issues discussion bayesian statistics berger bernardo dawid smith eds oxford university press oxford press 

west time series decomposition analysis study oxygen records isds discussion duke university 

west modelling robustness issues bayesian time series analysis discussion bayesian robustness berger wasserman eds ims monographs appear 

martin thompson robust estimation power spectra discussion roy 
statist 
soc 
ser 
pp 


west robust sequential approximate bayesian estimation roy 
statist 
soc ser 
pp 


statistical sciences plus guide statistical mathematical analysis version division seattle 

fruhwirth data augmentation dynamic linear models time series analysis pp 


carter kohn gibbs sampling state space models biometrika pp 


harrison stevens bayesian forecasting discussion roy 
statist 
soc ser 
pp 


berliner bayesian statistical inference nonlinear dynamical systems proceedings bayesian statistical science section american statistical association washington dc 

carlin polson stoffer monte carlo approach nonnormal nonlinear state space modelling amer 
statist 
ass pp 


mcculloch bayesian analysis autoregressive time series gibbs sampler time series analysis pp 


west bayesian forecasting encyclopedia statistical sciences kotz read banks eds wiley new york press 

park time evolution cycle marine records geophys 
res pp 


stock estimating continuous time processes subject time deformation application gnp amer 
statist 
ass pp 


muller west maceachern bayesian models non linear auto regressions isds discussion duke university 

west muller escobar hierarchical priors mixture models application regression density estimation aspects uncertainty tribute lindley smith freeman eds wiley new york 

tong non linear time series oxford university press oxford england 
