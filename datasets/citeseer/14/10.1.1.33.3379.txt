visual path catadioptric panoramic camera jos jos santos victor instituto de sistemas rob instituto superior av 
pais lisboa portugal 

describe catadioptric panoramic system built spherical mirror navigation tasks visual path 
define visual path method robot arrived start previously specified path perform path location relying visual tracking features landmarks 
geometry catadioptric sensor method image obtain bird eye view ground plane 
ground unwarp representation significantly simplifies solution navigational problems image coordinates differ ground coordinates simple scale factor eliminating perspective effects 
preliminary experiments mobile robot described catadioptric panoramic sensor detailed 
encouraging promising results obtained 
real world mobile robot applications home assistance office mail delivery require high levels autonomy industrial applications environment altered suit task 
typically robot autonomy cover large areas example offices entire house 
building complete metric description large areas expensive computing power sensor allocation 
alternative solutions qualitative topological properties environment navigation mainly robot travel large distances 
different approach necessary regions precise guidance localisation requirements docking station 
described addresses precise navigational problems method call visual path complement systems topological maps 
define visual path method robot arrived start previously specified path perform path location relying visual tracking features landmarks 
visual tracking achieved catadioptric panoramic images 
catadioptric panoramic cameras useful visual tracking 
combine conventional cameras mirrors primarily obtain specific fields view 
panoramic sensing possible convex mirrors conic mirrors spherical mirrors hyperbolic mirrors 
panoramic sensor allows track single feature varying viewpoints field view fixed classical camera 
advantage standard pan tilt camera lies simplicity system moving parts robot sensor relative position remains fixed orientation sensor related robot rigid transformation 
describe image formation model catadioptric panoramic camera spherical mirror method obtain model parameters 
catadioptric sensor single projection centre severe limitation approach 
describe method image obtain bird eye views ground plane 
representation allows algorithmic simplifications perspective effects ground floor eliminated 
example position information ground points available reconstruction uncalibrated reconstruction ground features move rigidly images easier track 
algorithm email jag isr ist utl pt isr ist utl pt tracking ground features corners utilising mobile robot self localisation shown achievable 
addition suitable controller visual path experiment real environment performed results detailed 
currently path specified image coordinates relative artificial landmark 
organised follows section describes geometry catadioptric panoramic camera spherical mirror section presents image obtain bird eye view ground plane section presents feature tracking algorithm 
section describes path experiments preliminary results obtained 

panoramic camera spherical mirror section detail model image formation spherical mirror 
experimental setup shown drawing illustrating image projection 
spherical mirror image plane projection center fig 
catadioptric panoramic camera spherical mirror projection geometry 
symmetry axis simplifies geometry 
relevant parameters see ff angle vertical axis ray point reflection point max ff system vertical view angle fi angle camera sees reflection point max fi camera lens view angle relative system vertical axis spherical mirror support sphere radius distance camera projection centre mirror support sphere centre radial coordinate distance camera optical axis vertical coordinate fl fl incidence reflection angles relative local mirror normal fl identifies reflection point 
geometry image formation obtained relating coordinates point coordinates projection mirror surface pm image projection shown 
shown drawing point pm mirror surface fulfill equations tan gamma gamma fi delta gamma fl fl arctan rm gammaz ff gamma fi equations reduced vertical plane containing vertical axis system rotationally symmetric axis 
equation expressed function vertical viewing angle ff expressed coordinates point 
parameters involved equation fixed physical setup ff fi depend coordinates observed point 
projection point denote coordinates general point 
want find image projection catadioptric panoramic camera spherical mirror 
determine pm mirror surface project point image plane 
coordinates expressed cylindrical coordinates theta theta arctan noting vertical viewing angle ff expressed ff arctan gamma gamma denote coordinates pm mirror surface replace ff equations solve resulting non linear system equations determine 
notice knowing determines value fi 
remains done project point pm image plane 
perspective projection model account camera intrinsic parameters get tan fi cos sin ff ff ff ff denote vertical horizontal image scale factors position principal point image coordinate system 
model parameters estimation previous section derived projection operator coordinates point allows obtain image projections contains intrinsic extrinsic parameters catadioptric panoramic vision sensor ff ff mirror radius measured easily assume known cm 
assume pixel aspect ratio known 
camera mirror distance image scale factor ff principal point measured measurement error ffi cm ff ff ffi ff ffi ffi define adjustment ffi required correct nominal parameter vector ffi ffi ff ffi ffi estimate ffi set known points corresponding image projections minimize cost function ffi arg min ffi gamma ffi point defined projection operator catadioptric panoramic images mirrors described procedure estimate model parameters starting initial nominal settings 
bird eye view ground plane images acquired panoramic sensors naturally distorted due geometry mirror perspective camera projection 
different world areas mapped different image resolutions 
general straight lines projected curves image 
instance horizon line projected image circle 
lines belong vertical planes containing camera mirror axis project straight lines 
section method unwarp catadioptric panoramic image bird eye view ground plane 
firstly rewrite projection operator ae order map radial distances ae ground measured ground plane radial distances ae img measured image ae img ae ae ground information build look table maps radial distances ground plane image coordinates 
inverse function expressed analytically image point search look table determine corresponding radial distance ground plane 
image bird eye view done efficiently way 
shows example ground 
ground pattern shown original image rectangular pattern ground image desired 
fig 
image bird eye view 
left right original remapped images 
features tracking self localisation described geometric transformations required obtain bird eye view ground floor catadioptric panoramic camera mirror 
step images order track environmental features allow estimation robot position orientation drive robot pre specified trajectory 
section describe features purpose method adopted tracking 
features selected tracking image corners defined intersections edge segments 
edge segments usually indoor environments detection benefit larger spatial support opposed local corner detection filters 
result identifying corner points intersections tracked edge segments leads better accuracy stability 
additionally easier track long edge segments corner points directly 
shows definition corner point intersection lines ab cd 
way corners correspond necessarily image points extreme brightness changes 
approach beneficial dealing information loss due occlusions filtering roundness corners due image smoothing 
track corner points tracking corresponding support edge lines 
edge segments represented fixed number sampled points typically ranging 
track points searching fig 
definition corner point intersection lines ab cd segment ae adjusted image directions perpendicular line segment guided local photometric geometric criterion 
shows points adjusted 
search criterion evaluation local gradient information distance original edge position 
correct edge points new edge segment obtained fitting procedure detected points 
tracked edge segments new image update corner points positions 
new corner positions determine rigid transformation relates neighboring images 
corners points required estimate transformation 
line segments repositioned corner points verify transformation rejected outliers 
repeating estimation procedure remaining points obtain robust estimates 
illustrates successful feature tracking results 
known pattern located ground plane navigation landmark acquired image sequence robot moves 
chosen landmark defined line segments intersecting corner feature points tracked method described 
contains results tracking different time instants illustrating initial final positions tracked edges 
fig 
features tracking 
left right dashed solid lines show landmark original final positions respectively 
current stage implementation relevant features track feature coordinate system initialized user 
order detect loss tracking operation tracking process continuously self evaluated robot 
evaluation gradient modules obtained specified areas landmark edges 
gradients decrease significantly compared expected recovery mechanism launched 
having successfully tracked visual features estimate robot position orientation relative pre defined coordinate system 
greatly simplified having bird eye image representation provides orthographic projection ground plane image angles equal angles measured ground plane image lengths differ uniform scale factor ground plane distances 
visual path section show information available tracked points design control system drives robot pre described trajectory 
dynamic model robot degrees freedom linear angular velocities mobile platform state vector state space model cos sin describe robot position pixels denotes robot orientation indicate robot linear forward angular velocities 
path psi followed defined collection points psi psi psi psi expressed coordinate system units robot state vector time instant depending robot position motion planning module determine point trajectory ref psi ref psi determine position orientation errors correct robot motion ref psi ref psi arg min ref psi ref psi ref psi ref psi gamma cases problem ill posed may multiple solutions 
reason regularization term selects path point ref psi closest previous time instant ref psi gamma 
current state robot desired path point computed signed distance path error orientation error defined gamma ref psi gamma ref psi gamma ref psi normal path chosen point 
geometry simple kinematic motion planner shown 
ref ref ref fig 
kinematic motion planner points define control error visual path system 
dynamic controller generate robot angular velocity proposed path stability proof gammak jvj gamma sin cos gamma constants tuned accordingly specific vehicle desired system response distance designates path length local path curvature 
order operate safely impose wmax control law indicates larger values just thresholding increase overshoots narrow turns reduce wmax 
current control law noise self localisation measurements directly imply noise control outputs 
prevent direct noise transmission include temporal integration measurements extended kalman filter 
inputs outputs ekf poses dynamics wheeled mobile robot type state vector augmented velocities 
velocities assumed constant driven white noise 
forward velocity noise covariance assumed low due control characteristics 
experimental results experiments conducted catadioptric panoramic vision system built institute mounted trc labmate mobile robot 
processing carried board pc pii mhz equipped image acquisition board 
shows simulation wheeled mobile robot performing visual path tracking 
self positioning simulated mobile robot model integration 
start executed paths pix fig 
visual path tracking shown simulated trajectory robot moving anti clockwise 
dotted solid lines correspond robot trajectories respectively 
shows error signals control actions input kinematic planner dynamic controller described 
example illustrates forward velocity reduction complement angular velocity saturation 
distance path pix vs sec orientation error deg vs sec forward velocity mm sec vs sec angular speed deg sec vs sec fig 
visual path tracking simulated trajectory 
left right distance path orientation error controller inputs forward angular velocities controller outputs 
real world experiment undertaken 
trajectory specified image coordinates mobile platform controlled input vision sensor 
figures show estimates self localisation 
noise estimates mainly due small size chosen landmark poor image resolution 
implemented filtering effective reducing noise mainly smooth paths 
choosing widely separated landmarks expect significant improvements accuracy filtering effective sharper paths 
possibility tracking widely separated image features key advantages panoramic images localisation 
shows trajectory dots results visual self localisation solid line 
shows mobile robot final position completion desired navigation task 
processing time approximately sec image image processing remaining consumed displaying debugging information image acquisition serial communications mobile robot 
xy measurements pix orientation measurements deg start fig 
real world visual path trajectory specified image coordinates 
positions filtering dotted line filtering solid line 
orientation filtering dotted line filtering solid line 
dashed dotted line shows landmark defines origin 
dotted line specified trajectory 
solid line shows filtered position estimates obtained visual input 
image mobile robot path 
described catadioptric panoramic system built mirror navigation tasks visually path 
main advantages lies acquiring panoramic images environment moving parts physical setup 
described image formation model method adopted estimating model parameters 
projection model method obtaining ground images bird eye view ground floor 
representation significantly simplifies navigation problems image coordinates differ ground plane coordinates simple scale factor eliminating perspective effects 
ground images method track image corner points defined support edge segments 
tracking features done robust manner allows estimation robot position orientation relative known navigation landmark 
showed framework perform call visual path 
trajectory follow simply specified image plane suitable controller drive robot desired path 
described kinematic motion planner dynamic controller 
experiments shown simulated environment real robot 
focus self localisation system widely separated landmarks remain visible panoramic images 
extension ground plane landmarks include vertical lines straightforward intersection vertical lines ground plane define ground plane feature points calculations self localisation 
implemented extended kalman filter currently filtering noise estimated self may improve feature tracking considering ekf predictions adding accuracy robustness system 
aim integrate global navigation system 
navigation system may rely qualitative topological properties environment travelling relatively large distances approach fit precise guidance localisation negotiating door entrance accurate positioning navigation tasks 
partially funded project praxis 

simon baker nayar 
theory catadioptric image formation 
iccv pages january 

james crowley 
mathematical foundations navigation perception autonomous mobile robot 
workshop reasoning uncertainty robotics dec 
imag fr prima homepages navigation tutorial word ps 

de wit samson 
chap nonlinear control design mobile robots 
yuan zheng editor nonlinear control mobile robots 
world scientific series robotics intelligent systems 

faugeras 
dimensional computer vision geometric viewpoint 
mit press 

martin fischler robert bolles 
random sample consensus paradigm model fitting applications image analysis automated cartography 
communications acm june 

hager kriegman ben shahar 
domain independent navigation dynamic vision control 
ieee cdc dec 

robert haralick linda shapiro 
computer robot vision vol 

addison wesley 


visually guided navigation 
lisbon portugal july 

jos santos victor hans jorg 
topological maps visual navigation 
st international conference computer vision systems pages 

ac 
epipolar geometry panoramic cameras 
eccv pages freiburg germany july cmp cz publications html 

shih wei yasushi yachida 
building local floor map ultrasonic omnidirectional vision sensor 
icra pages leuven belgium may 
article processed macro package style 
