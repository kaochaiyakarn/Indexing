contributions transform coding system implementation jiang dissertation faculty graduate school university southern california partial ful llment requirements degree doctor philosophy electrical engineering may copyright jiang increasing dominance transform coding technique virtually image video coding schemes proposed date cient transform coding system implementation important research topic 
sis addresses system issues may arise practice cient architecture designs discrete wavelet transform ii cient transform coding robust communication erasure channels 
rst contribution thesis develop overlap state technique cient multilevel wavelet decompositions memory delay constraints strictly observed 
case wavelet transform computed block block fashion input data segmented blocks block processed separately sequentially parallel 
proposed technique enables cient data exchange consecutive data blocks required memory bu er size communication overhead signi cantly reduced compared existing techniques 
second contribution provide cient loss data recovery techniques robust communication erasure channels 
problem multiple description transform coding propose structured correlating transform design making available channel formation 
enforced structure enables signi cant reduction number design parameters results signi cantly reduced design implemen tation complexities compared existing approaches 
alternative technique loss recovery explicit redundancy proposed 
achieved splitting source di erent components quantize di erently primary information nely quantized relative high rate redundant information relative low rate 
primary information lost redundancy information recovery 
performance analysis ii simulation results show proposed technique competitive compared previously published works 
iii iwould rst express gratitude advisor friend professor ortega continuous guidance support kept lifting years usc making challenging fun experience 
iwould professors alvin despain 
jay kuo serving qualifying committee professors gerard medioni zhen zhang serving qualifying defense committees 
years usc pleasure number friends including hua xiao ce mates 
enjoyable collaborations including sharing week competing couch lab 
holiday parents brother years encouragement kept going 
wife sharing years love support faith iv contents ii iv list tables viii list figures ix motivation overview dwt system design robust communication contributions chapter organizations dwt architecture design problem de nition sequential architecture design parallel architecture design preliminaries standard algorithm lifting algorithm practical dwt system design overlap state technique finite state machine model overlap state performance analysis delayed normalization proposed dwt architectures systems systems sequential architectures parallel architectures experimental results delayed normalization strip parallel constrained transform design multiple description coding problem de nition proposed design approach geometric interpretations parametric transform factorizations stage transform design mdtc design examples equal rate channels sequential protection channels simulation results gaussian sources karhunen loeve vector transform multiple description coding erasure channels erasure channel model problem de nition mdc explicit redundancy base system context adaptive extension optimal redundancy bit allocation gaussian sources implicit channel modeling explicit channel modeling experimental results image mdc example speech mdc example summary overlap add overlap save dwt fsm examples mdtc transform design algorithm redundancy bit rate side distortion ds vector space partition vi bibliography vii list tables standard algorithm 
costs comparison multilevel wavelet decompositions proposed sequential dwt algorithm 
overlap bu er size bs dwt level decompositions tap wavelet 
proposed parallel dwt algorithm 
comparison memory requirements width image scanline comparison memory requirements dwt cpu time di erent sequential algorithms seconds 
proposed parallel dwt algorithm 
dwt running time di erent parallel algorithms seconds 
reconstruction nmr comparison db draw reconstruction nmr comparison db viii list figures simpli ed image video coding system 
level tree decomposition 
example data ow chart level wavelet decomposition 
solid lines completely transformed data dashed lines boundary samples neighboring block 
operations communicate boundary data samples neighboring blocks operations transform current level 
atypical sequential dwt system diagram 
mesh processor network corresponding data partition 
bus connected processor network corresponding strip data partition 
channel wavelet polyphase representation 
wavelet transform lifting 
forward transform 
inverse transform 
boundary processing dwt 
lter length moves right boundary block needs input data samples block 
sequential architecture block reside memory time 
parallel architecture block allocated di erent processors 
state transition diagram dwt fsm 
state transitions block boundary 
partial computations near boundaries 
updating boundary samples stay states 
new boundary separates fully updated output coe cients partially computed ones 
ix sequential dwt overlap state 
input initial state 
block consists samples 
state transition samples near block boundary partially updated anti causal ltering results available 
partially updated samples state information overlapped block input samples 
completely updated adding anti causal ltering results 
completely transformed updated input state 
parallel dwt overlap state 
input initial state 
input partitioned processors 
block transformed separately state information appearing near block boundary 
state information exchanged processors partially updated samples fully updated 
completely transformed updated input state 
example data ow chart level wavelet decomposition proposed overlap state technique 
solid lines completely transformed data dashed lines partially transformed data 
operation block transforms allocated data independently state information bu ered operation state information communicated neighboring blocks operation complete transform boundary data samples 
illustration delayed normalization 
channel lifting 
channel lifting delayed normalization 
dwt example delayed normalization 
joint design transform quantization reduce computation 
independent transform quantization 
joint transform quantization 
normalization operation merged quantization 
proposed sequential dwt architecture 
proposed parallel dwt architecture 
split stage processor computes allocated data independently required decomposition level 
merge stage way communication initiated communicate state information neighboring processors 
postprocessing operation started complete transform boundary samples 
dwt fsm illustration 
shaded areas represent state information row column state information level 
input block rst row transformed column transformed level downsampled ll subband row transformed level column transformed level 
strip sequential dwt system diagram 
input segmented data strips transformed sequentially top bottom 
block sequential dwt system diagram 
input segmented blocks transformed left right top bottom 
merge operations mesh processor network 
transfer row state information pi pi transfer column state information pi pi transfer newly generated row state information pi pi complete transform boundary samples 
notice total amount data processor nal state di erent original uniform allocation due merge operations 
merge operations strip parallel implementation 
transfer row state information pi pi complete transforms boundary samples processor 
atypical mdtc system redundancy rate distortion curve mdtc system gaussian vector 
distributions independent gaussian variables variance 
original rotation correlation coe cient 
scaling scaling rotation correlation coe cient 
clearly see data correlated 
lattice structure rs transform transform search space 
comparisons di erent transforms 
proposed mdc system 
context mdc system rate distortion performances comparison gaussian source optimal bound 
optimal results 
proposed lloyd max quantizer results xed length code 
optimal results rate distortion function gaussian source 
example con guration di erent polyphase transforms level wavelet decomposition input matrix 
subbands samples constitute polyphase component remaining samples constitute polyphase component 
plain polyphase transform 
vector polyphase transform 
xi experimental results lena gray level image 
descriptions 
polyphase plain polyphase transform 
polyphase vector polyphase transform 
performances independent packet losses 
reconstructed lena images total rate bps channel information 
original image redundancy bit rate bps psnr db redundancy bit rate bps psnr db redundancy bit rate bps psnr db proposed rat schemes robust packet speech coding 
reconstructed nmr distribution plot draw sentence di erent packet loss probabilities 
rat proposed jay overlap save 
overlap add 
state transitions daubechies lters factorization 
state information consists samples overlap bu er size shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx state transitions lters factorization 
state information consists samples shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx state transitions cdf lters factorization 
state information consists samples shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx xii chapter motivation overview motivate thesis rst consider simpli ed communication system shown fig 

coding decoding procedures described follows 
redundancy data removed applying decorrelating transform karhunen loeve transform klt approximations discrete cosine transform dct discrete wavelet transform dwt 
transform coe cients quantized entropy coded meet bit budget constraint 
encoded bitstream sent channel transmission 
receiver inverse procedure applied reconstruct original data 
coding framework constitutes core part virtually existing image video coding standards mpeg mpeg forward transform dct dwt inverse transform idct quantization entropy coding entropy decoding simpli ed image video coding system 
channel mpeg 
standards designed target di erent data compression applica tions 
result practical system designs implementations tobe subjected di erent constraints 
example jpeg standard mainly compression im ages pictures digital cameras printers scanners 
important issue reduce algorithm memory usage consumer electronics products reduce price 
transform quantization entropy coding blocks fig 
implemented memory possible 
standards hand com pression moving pictures television video signals 
case fast algorithms including fast transform fast quantization fast entropy coding important applications stringent time constraints require real time encoding decoding video conferencing live digital broadcasting 
see important design implement cient systems various application constraints 
fast development internet multimedia signals image video audio signals communicated packet network 
internet service providers deliver best ort services current available network technologies packets transmitted may get lost arrival destination 
happen network congestion occurs link failures intermediate routers 
achieve robust com munication unreliable channels important topic 
thesis practical issues addressed cient dwt sys tem design memory delay constraints ii robust communication packet erasure channels 
give detailed review topics 
dwt system design years considerable research activities centered building cient systems computing discrete wavelet transform dwt 
certainly due part fact wavelet transform powerful tool multiscale time frequency signal decomposition analysis applications areas signal processing digital communications numerical analysis computer graphics 
practical system design challenging problem may stringent constraints bu er size delay power chip area control complexity imposed speci dwt applications 
cases sequential architecture dwt computed splitting input blocks processor operating block time 
reason limited amount memory available transform computation 
example scenarios include image compression decompression systems dsp asic chip products consumer electronics products digital cameras space borne instruments 
applications reducing memory bu er size helps maintain low costs reduce chip design area volume nal product 
alternative parallel architecture split input processors speed transform computation 
typical applications large volume data processed rea short time 
instance seismic data processing illumination computations computer graphics potential applications 
obviously fast dwt computation meet stringent delay constraints critical success wavelet techniques 
problem system design constraints memory delay new encountered design traditional transforms fft dct system design wavelet transform poses particular di culties 
consider example level wavelet decom position depicted fig 
respectively lowpass highpass lters 
input rst ltered lowpass output downsampled ltered 
multilevel decompositions process ltering downsampling operations performed recursively input data 
ltering operations dwt implemented block transform exception trivial haar transform recursiveness nature dwt computation poses special challenges stringent memory delay constraints observed practical dwt system designs 
level tree decomposition 
consider example level wavelet decomposition formed processors processor allocated half input data 
problem arises dwt computed near data boundaries processors refer fig 

dwt block transform correct wavelet coe cients computation near data boundaries processor need ac cess data allocated processor 
case processors exchange data level decomposition processors su cient overlapped data carry computation com munication 
rst approach demands frequent data exchanges processors increases communication overhead adversely ect system scalability parallel architectures particularly slow communication links example network workstations local area multicomputers lams 
second approach avoiding frequent communication needs overlap data processor 
overlap due recursive nature dwt ltering operations large expensive number levels decomposition increases 
provides motivation investigate cient dwt system design un der memory delay constraints 
factors possibly ect memory delay dwt computation see memory requirement complete dwt compression decompression systems interprocessor communication required data transposition dwt focus memory interprocessor com munication constraints imposed segmentation input data sequential parallel architecture designs demonstrated exam ple 
consequently parameters measure performance amount data transmitted processors stored processor sequential computation number times data communicated processors 
robust communication second part thesis devoted study robust communication techniques delay constrained applications erasure channels 
examples applications techniques crucial include videoconferencing realtime audio speech packet networks 
best ort service model currently implemented internet service providers isps guarantee timely lossless packet delivery 
packets dropped delayed number scenarios 
example packets delayed congested network segments dropped packet dropping policies random early drop red implemented relieve congestion 
packets corrupted useless receiver sent hostile channels mobile radio channel su ering severe multipath fading 
observed works packet losses dealt appropriately cause annoying quality changes received signal 
numerous research orts aiming providing quality service qos redesigning network infrastructure rsvp providing bounds packet losses avoiding losses altogether 
study techniques enable recovery packet losses mitigate losses signal quality due underlying erasure channel 
motivation fold applications study image video audio communications require lossless data recovery degradation tolerated long degradation certain threshold ii techniques complement qos transmission especially packet losses occur bounded serve near term solutions wide deployment qos networks 
goal design techniques enable signal quality degrade gracefully presence packet losses 
problem robust communication erasure channels new studied thoroughly context channel coding theory data communication protocols 
error correcting codes block convolutional codes increase information redundancy resulting bandwidth ine ciency achieve robust communication 
retransmission mechanisms arq schemes achieve robust communication expense increase communication delay 
existing techniques quite successful past tobe applied caution communications packet network di erences underlying channel models 
example packet losses occur due network congestion bit errors due channel noise assumed conventional channels 
case immediate retransmission attempts aggravate situation lead packet losses 
ectiveness retransmission decreases multicast applications users su er uncorrelated losses 
case appropriate choice forward error control fec schemes 
users may experience di erent levels packet loss due network heterogeneity provides single level error protection insu cient users redundant 
examples show robust communication lossy packet network deserves study 
contributions chapter organizations chapter dwt system architecture design 
start overview previous works dwt computations including algo rithm studies architecture designs 
nite state machine fsm model proposed characterize dwt behavior especially data bound aries 
dwt fsm model overlap state technique proposed correctly transform boundary samples multilevel wavelet decomposition reduced interprocessor communication memory usage 
various sequential parallel dwt system designs proposed technique show transform bu er size communication overhead reduced 
main contribution part provide new technique overlap state compute multilevel wavelet decompositions way signi cantly re duce memory communication overhead compared existing technologies 
believe greatly help practical dwt system designs mem ory delay constraints strictly observed 
second part thesis study techniques achieve robust communication packet erasure channels internet 
speci cally study techniques help signal quality degrade gracefully case packet losses 
di erent approaches taken study 
constrained correlating transform design multiple description coding 
correlating transform add redundancy encoded data lost transform coe cients estimated recovered correlation existing correctly received coe cients 
starting review related works multiple description transform coding mdtc provide detailed analysis non orthogonal correlating transforms perform better orthogonal correlating transforms mdtc system design 
address di culties existing mdtc system designs arbitrary non orthogonal transforms 
stage transform design approach structure design magnitude design drastically reduce design implementation complexities 
provide design examples proposed technique design transforms equal rate sequential protection channels 
chapter devoted di erent technique packet loss recovery 
correlating transform implicitly add redundancy data loss recovery redundancy explicitly added source splitting selective quantization 
source splitting performed polyphase transform example forms possible 
selective quantization achieved quantizing primary information redundant information di erent resolutions 
performance analysis proposed system provided detail gaussian sources comparisons existing approaches provided 
experimental results image speech coding communication independent packet loss channels provided 
main contribution part propose simple design implementation cient competitive coding performances compared pre reported works techniques adding redundancy encoded data loss recovery 
believe important practical system implementa tions robust communication required unreliable channels 
chapter dwt architecture design chapter study cient dwt architecture designs memory delay constraints various investigations cient wavelet transforms implementation reported 
popular dwt algorithm recursive lter ing approach corresponding wavelet called standard algorithm computational output coe cient lter length 
fft dwt algorithm proposed reduce complexity log large lter lengths short lters fast running fir ltering technique achieve saving computations 
lattice structure shown complexity reduced factor orthogonal wavelet 
ladder structure marshall lifting algorithm daubechies sweldens show cally large lter lengths savings computations achieved fir wavelet including orthogonal biorthogonal 
sequential architecture designs approaches adopt standard fft ltering techniques overlap add overlap save 
include part chapter represents published see 
level level level block block example data ow chart level wavelet decomposition 
solid lines completely transformed data dashed lines boundary samples neighboring block 
operations communicate boundary data samples neighboring blocks operations transform current level 
recursive pyramid algorithm rpa spatially segmented wavelet transform reduced line com pression system 
overlaps data start transform overlap bu er size increases exponentially increase decomposition levels 
alternative implemented data overlapped level decomposition bu er size reduced 
parallel architecture designs approaches proposed require com munication boundary data level decomposition see example works fridman nielsen 
design level decompositions shown fig 

reduce overhead caused frequent inter processor communication yang el 
proposed boundary extensions dwt system con gured cluster sgi workstations 
computes incorrect wavelet coe cients near data boundaries causes performance degradation applications ex ample low bit rate image coding 
chapter technique overlap state dwt computation help achieve signi cant memory communication savings 
idea motivated standard overlap add technique performs ltering operations neighboring data blocks independently rst completes computation summing partial boundary results 
extend idea case multilevel wavelet decompositions lifting framework formulated daubechies sweldens 
dwt rst modeled nite state machine fsm lifting algorithm multilevel partial computations intermediate states performed samples near block boundaries 
show correct transform near data boundaries intermediate states preserved original storage spaces extension place computation feature lifting algorithm exchanged neighboring data blocks arbitrary level decompositions 
works explored independently lifting factorizations memory savings dwt implementations 
novelty rst introduce partial computations boundary samples multiple decomposition levels preserve partially computed results intermediate states original locations pro cessing second propose processors exchange data multilevel decompositions decomposition level 
show overlap state technique reduce memory requirement interprocessor communication overhead sequential parallel architecture designs 
chapter organized follows 
section de ne problem memory delay constrained dwt system design 
respectively sequential parallel architectures 
section overview various dwt algorithms including standard dwt algorithm lifting algorithm provided 
dif culties computing dwt near data boundaries detailed memory delay perspective 
section presents overlap state technique idea partial computation multiple levels process dwt com putation 
shown proposed technique help signi cantly reduce memory communication need practical system designs 
delayed technique introduced speedup multilevel dwt computations 
section examples dwt system designs data provided detail 
experimental results section 
section concludes chapter 
problem de nition section de ne problem sequential parallel architecture designs separable dwt example 
types dwt system de ned similarly 
sequential architecture design sequential system dwt shown fig 

transform working bu er chip memory cache memory usually small size compared data size 
original data stored secondary storage space hard disk frame bu er segmented segment loaded working bu er transform computed segment time 
variations generic system include 
block system com wavelet transform image block time 

line system computes wavelet transform basic input units image lines 
dwt fsm working buffer data storage wavelet typical sequential dwt system diagram 
assume blocks size bytes processor bytes input data loaded working bu er time 
de ne overlap bu er size bs bytes memory space taken overlapped data kept memory correct transform block input data 
case line systems bs minimum bu er size needed transform 
transform block bs bytes freed wavelet coe cients generated transfered processing stage quantization 
de ne system throughput bs bs intuitive explanations follows 
indicates original data samples fully transformed corresponds case pure block transforms dct haar transform 
bu er complete decomposition performed data level decompositions 
mention case possible wavelet coe cients high frequency bands generated 
problem formulated xed working bu er size compute dwt maximize system throughput obviously increase system throughput reduce overlap bu er size bs possible 
parallel architecture design mesh processor network rst consider mesh connected processor network depicted fig 
processor connected immediately neighboring processors similar model studied 
communications processors single port model processors may send receive message communication link time multi port model processor may send receive multiple messages multiple links time 
model natural partition data block partition strategy shown fig 

processor pm allocated input samples indices mnr nr mnc nc 
loss px px px mesh processor network corresponding data partition 
generality assume mnr nnc nr nc block row column length number processors row column direction respectively 
bus processor network consider type processor network processor communicate processor common bus 
example lam local area multicomputer systems see fig 
locally connected machines recon gured parallel system similar model 
possible data partitioning approach strip partition depicted fig 
processor pn allocated input samples indices nnc nc 
message passing mechanisms processor networks modeled follows 
communication time tc size message nc tc ts mtw tp ts time takes establish connection 
tp propagation time tw time transmit size message 
message unit integer tw time transmit integer 
cases de ned similarly 
notice bus processor network tp taken average propagation time mesh processor network tp lth number links nr px pp bus connected processor network corresponding strip data partition 
th propagation time link 
nc design problem formulated communication model de ned minimize communication overhead parallel dwt system 
clearly reduce overhead reducing number commu reducing amount data exchanged 
preliminaries lay foundation proposed architecture designs rst give review dwt algorithms including standard lifting algorithms 
dif culties applying traditional techniques meet system design constraints memory delay outlined previous section explained detail 
mention chapter focus tree structured multilevel octave band wavelet decomposition system critical sampling channel wavelet 
extensions study systems standard multichannel wavelet wavelet packet de compositions straightforward 
px standard algorithm theoretically wavelet transform signal decomposition technique projects input signal space constructed dilated translated versions prototype wavelet function mother wavelet 
computationally wavelet transforms implemented recursive lter ing operations corresponding wavelet shown fig 

implementation refered standard algorithm 
emphasize ltering operations performed sample channel subsample ltering approach fast algorithm 
pseudo code implementation table 

table standard algorithm 
input input sequence length decomposition level lter length output xj pl xj yj pl xj practical applications memory delay constraints standard algorithm may choice reasons requires bu er size input store intermediate results lowest subband recursive ltering operations ii large latency outputs subband generated output subband iii computation cost high 
de ne algorithm computation cost number multiplications additions output point 
wavelet lters taps multiplications additions needed output point level 
cost cs standard algorithm level wavelet decomposition computed lifting algorithm size polyphase transform signal de ned mapping generates subsequences shifted downsampled version 
xi nn 
subsequences called polyphase components signal 
case transform simply divides input sequence polyphase components consist samples odd indices samples indices respectively 
transform domain polyphase representation xi 
de ne polyphase matrix hi ith polyphase component similarly de ned 
dwt polyphase domain written plot shown fig 
dwt channel wavelet operating polyphase domain 
channel wavelet polyphase representation 
main advantage polyphase domain transform computation polyphase matrix factored factorization leads fast dwt algorithms 
euclidean algorithm daubechies sweldens shown polyphase matrix ofany pr fir factored product form elementary matrices ti si si ti prediction updating lters respectively stage shown lifting factorization dwt algorithm asymptotically long lters twice fast standard algorithm theorem 
fig 
forward inverse dwt lifting factorization illustrated schematically 
tm sm sm tm wavelet transform lifting 
forward transform 
inverse transform 
notice elementary matrices lifting factorization upper lower triangular constants diagonal entries 
elementary matrices enables implementation dwt place see section details key factor di erent types factorizations lattice ladder factorizations 
factor reduce dwt computation place feature reduce transform memory 
consequently lifting algorithm chosen baseline dwt algorithm proposed architecture designs 
practical dwt system design practical dwt system design memory delay constraints choosing fast algorithm lifting algorithm may su cient 
complexity lifting algorithm linear size input data 
parallel system speed computation rst problem solve ciently access data allocated processors correct boundary transform 
second place feature lifting algorithm eliminates bu er intermediate results address problem extra bu er requirement input data transformed block block basis 
input output boundary processing dwt 
lter length moves right boundary block needs input data samples block 
sequential architecture block reside memory time 
parallel architecture block allocated di erent processors 
fig 
show situation dwt near block boundaries level decomposition 
obviously extra bu er communication needed ensure correct computations near data block boundaries 
problem exists cases conventional linear ltering long data sequences dealt overlap add overlap save techniques see appendix 
dwt consists recursive ltering operations multilevel sampled data direct applications existing techniques may increase signi cantly cost terms memory communication 
consider level wavelet decomposition block size lter length overlap add overlap save require extra bu er boundary ltering operations size level decomposition 
overlap done decomposition levels approach total overlap bu er size increases exponentially increase signi cant deep decomposition long wavelet lters 
level 
case overlap bu er size level decompositions 
causes delay parallel architectures processor wait send new data level decomposition approach described 
third approach boundary extension symmetric extension approximate data neighboring blocks 
completely eliminates overlap bu er eliminates communication data exchanges tween processors 
unfortunately dwt coe cients near block boundaries computed incorrectly 
analysis shows ine ciencies terms memory communication overhead dwt system designs adopt existing techniques 
section introduce novel overlap state technique dwt computation block boundaries help re duce communication overhead parallel architectures overlap bu er size sequential architectures 
overlap state technique section rst introduce fsm model dwt lifting factorization 
overlap state technique dwt computation consecutive data blocks help reduce signi cantly memory communication overhead dwt system designs 
finite state machine model lifting point view elementary triangular matrices factorization classi ed prediction lifting updating dual lifting operations respectively 
computational point view big di erence elementary matrices essentially updates polyphase component time linear convolutions 
loss generality weintroduce notation represent ele matrices 
si ti input polyphase components frequency domain time domain respectively 
de ne intermediate states process transformation fx resulting signal rst elementary matrices applied 
consider lifting stage lower triangular elementary matrix update follows 
xi xi xi see transformation step polyphase component unchanged polyphase component updated adding quantity computed polyphase component 
time domain means samples preserved odd samples updated 
input vector size assuming state transition written xi denote iti updating quantity computed lti upper triangular odd samples unchanged samples updated 
case denote isi updating quantity upper triangular matrix ls xi important observation polyphase component updated state transition updating quantity depends samples polyphase component 
updating samples odd samples needed vice verse 
leads states updating stage 
updated need keep old value updating need 
words time generate need store set values need know order compute output nal wavelet coe cients 

updated value sample stored memory space allocated old value contribute updating neighbors stage updating 
example written ecting updating 
called place property lifting algorithm 
obviously bu er size transform standard algorithm needs bu er size original input transform outputs 

updating sample implemented independently updating samples 
ordering updating samples 
example update updating obtain result 
polyphase matrix factorization necessary su cient condition properties elementary matrix form lower upper triangular matrices constants diagonal entries mentioned 
key property lifting factorization guarantees dwt computed place 
raw input data sample initial state progressively updated coe cient nal state samples neighborhood 
wavelet transform polyphase factorization modeled fsm elementary matrix updates fsm state higher level forward wavelet transform written inverse transform inverse 
schematic plot dwt fsm depicted fig 

formal de nition follows 
ei state transition diagram dwt fsm 
de nition discrete wavelet transform modeled finite state ma chine tuple nite set states fx determined factorization 
nite set events fe lifting operations lifting stage 
initial state raw input data 
nal state wavelet transform output 
transition function mapping qx overlap state assume elementary matrices fe factor ization polyphase matrix total states fsm de nition 
fsm modeling tells compute transform needs help sample complete state transitions state state sequentially 
means compute updating quantities stages 
un fortunately accomplished samples near block boundaries 
happens input transformed block block basis due bu er size limit purpose parallel processing 
consider operation data boundary upper triangular el matrix 
current state input sequence segmented point refer fig 

state transition indexed samples updated odd indexed samples updating quantity xi xi ai bi xi respectively contributions causal anti causal part lter 
boundary block block new boundary new boundary state state new boundary state new boundary state transitions block boundary 
partial computations near boundaries 
updating boundary samples stay states 
new boundary separates fully updated output coe cients partially computed ones 
obviously samples near block boundary compute due segmentation 
avail able 
result samples updated state 
fig 
example block updated fx right block available time block transformed 
consequently updating factor sample com puted 
updated 
leaving state partially update asx computed causal neighborhood function fx 
signi cance partial updating free samples casual past processing save memory 
case samples fx need bu ered fully updating contribution added partial result 
hand choose partially update fx bu ered 
partial updating happens samples fx left block samples fx gin right block 
complete state transition need bu er block samples 
partially updated samples left block fx gin right block 

contributing samples required partially updated samples block complete transform left block fx gin right block 
simplicity partially updated samples contributing samples called state information 
obviously long state information preserved stage transform completed time 
exactly fsm supposed 
mention processing possible partial updating right block updating implemented independently partial updating left block updating discussed 
partial updating remove information needed block updates samples inputs th state transition stage 
state application shown fig 

see partially updated samples processing size compute reduced ective boundary reached sample block sample block 
ectively physical boundary splits extends inwards blocks 
state transition operate samples state 
samples new boundaries state information procedure repeats state transition stage 
complete transform samples near block boundary state formation neighboring blocks need exchanged 
done states consecutive blocks 
propose overlap state method dwt computation consecutive data blocks 
overlap state procedure shown fig 

case parallel processing implementation shown fig 

state transition shown gures overlap state design easily generalized multiple state tran sitions multiple decomposition levels state transitions share properties see section 
boundary sequential dwt overlap state 
input initial state 
block consists samples 
state transition samples near block boundary partially updated anti causal ltering results available 
partially updated samples state information overlapped block input samples 
completely updated adding anti causal ltering results 
completely transformed updated input state 
block boundary block parallel dwt overlap state 
input initial state 
input partitioned processors 
block transformed separately state information appearing near block boundary 
state information exchanged processors partially updated samples fully updated 
completely transformed updated input state 
performance analysis bu er size analysis lifting factorization polyphase matrix wenow show state information need store dwt computation overlap bu er size 
key factor memory constrained sequential architecture design 
shown stage partially updated samples contributing samples need stored 
denote total number partially updated samples total number contributing samples bi writing si si si 
number samples bu ered stage isb assume state transitions factorization bu er size bs level decomposition bs lifting factorization polyphase matrix unique ob choose factorization gives minimum bs amount memory limited 
alternative way nd bu er size graphically plot state transitions factorization 
see appendix details 
communication communication delay time exchanging data adjacent processors 
existing parallel algorithms level decom position boundary samples need communicated adjacent processors lter length 
communication model total communication time dold level wavelet decomposition dold ts tw tp proposed parallel algorithm overlap state technique data exchange delayed independent transform block communication necessary 
example level decompositions shown fig 
compare fig 

furthermore size state information stage bs upper bounded 
communication time proposed algorithm upper bounded dnew ts tw tp level level level state state block block state state state state example data ow chart level wavelet decomposition proposed overlap state technique 
solid lines completely transformed data dashed lines partially transformed data 
operation block transforms allocated data independently state information bu ered operation state information communicated neighboring blocks operation complete transform boundary data samples 
see communication overhead reduced proposed par algorithm number communication times reduced ii amount data exchanged reduced 
essentially overlap state tech nique enables exchange data communication setup exchanging small amount data multiple communication setups 
important emphasize communication overhead reduction contributes reduction total computation time strongly depend parallel system communication link design 
clearly slower inter processor communication larger gain vice versa 
delayed normalization lifting dwt algorithm shown twice fast standard standard algorithm daubechies sweldens true general asymptotically long lters 
section introduce simple technique delayed normalization help reduce computation multilevel wavelet decompositions 
may noticed matrix factor polyphase tion form normalization factor scales coe cients respectively 
normalization factor appear level de composition multilevel wavelet decomposition 
wavelet transform linear operation multiplication commutative linear operations normalization multiplication operation delayed level decomposition 
doing computations saved 
illustration delayed normalization 
recursive channel lifting 
channel lifting delayed normalization 
example level octave band wavelet decomposition shown fig 

interestingly normalization operations coe cients eliminated provided wavelet applied stage 
di erent wavelet di erent levels decomposition general normalization multiplication operation necessary wavelet transform coe cients 
obviously delayed normalization technique multidimensional wavelet decompositions wavelet packet decompositions 
fig 
level wavelet decomposition shown recursive normalization delayed normalization 
row column dwt example delayed normalization 
give performance analysis octave band wavelet sition 
input data sequence length decomposition level computational costs standard algorithm lifting scheme lifting scheme delayed normalization denoted respectively 
cost unit average number multiplications additions output point 
cm number multiplications additions output point level decomposition standard algorithm 
accordingly li ng cost lifting scheme delayed normalization wavelet transform decomposed parts 
normal lifting operation part table costs comparison multilevel wavelet decompositions wavelet standard lifting lifting delayed normalization cost speedup cost speedup haar spline lasts levels normalization 
part level average cost cl normalization multiplication saved coe cient 
second part nal normalization part coe cients 
part incurs cost multiplication output point 
total average cost cl large large limit average operation fewer pure lifting scheme 
table show ect algorithm relative speedup lters daubechies sweldens 
performance analysis applies transforms di erent wavelet lters stage 
assumption large negligible 
decomposition stages assumption relaxed 
recall normalizations coe cients eliminated see fig 

savings quarter total input data samples scaled 
average cost normalization part output point 
consideration long large cost estimation cl accurate 
equivalent reasonable assumption practical wavelet applications 
reduction normalization operation possible jointly de sign dwt system immediate data processing system 
exam ple wavelet data compression system wavelet coe cients quan immediately transform 
system shown fig 

qi quantizers designed wavelet coe cients di er ent subbands 
obviously normalization operation done jointly quantization operation completely eliminated transform point view 
shown fig 

applications noise reduction thresholding computation reduction possible 
compared independent transform quantization computation saved designed jointly 
joint design transform quantization reduce computation 
independent transform quantization 
joint transform quantization 
normalization operation merged quantization 
proposed dwt architectures section rst generic sequential parallel architecture designs dwt overlap state technique 
variations detailed separable dwt systems 
systems sequential fig 
proposed sequential dwt system shown teh code sequential algorithm table 
input data sequence rst segmented non overlapping blocks length fed fsm block time 
state information saved block computed 
transformation wavelet coe cients concatenated give nal result 
input data stream input samples section point dwt fsm output samples output data stream dwt state information proposed sequential dwt architecture 
see general system structure dwt computation essen tially standard overlap add approach 
dwt fsm acts state machine memory state information partially com puted boundary samples previous block multiple decomposition level overlapped 
helps reduce memory requirement transform computation 
overlap leads output delay practice output samples shown fig 
delayed relative input samples 
table proposed sequential dwt algorithm 
initialize state level wavelet transform block update state table 
required overlap bu er size bs di erent sequential dwt algorithms 
point input data block lifting algorithm implemented total bu er size bs 
system throughput bs obviously proposed sequential dwt algorithm overlap state tech nique requires smaller overlap bu er size bs improves system throughput 
jl relative improvement small 
hand completely transformed coe cients immediately transfered line system savings memory signi cant details section 
table overlap bu er size bs dwt level decompositions tap wavelet 
rpa proposed tap cdf input data stream point dwt fsm intermediate result point dwt fsm output data stream point dwt fsm point dwt fsm point dwt fsm point dwt fsm point dwt fsm point dwt fsm proposed parallel dwt architecture 
split stage processor computes allocated data independently required decomposition level 
merge stage way communication initiated communicate state information neighboring processors 
postprocessing operation started complete transform boundary samples 
parallel fig 
proposed parallel dwt architecture shown code algorithm table 
input data uniformly segmented non overlapping blocks allocated available processors 
processor computes allocated data required wavelet decomposition level 
stage called split 
output stage consists completely transformed coe cients ii state information partially updated bound ary samples 
second stage merge way communication initiated state information transfered neighboring processors 
state information neighbor processor combined corresponding state information complete dwt transform 
shown proposed parallel architecture requires commu nication neighboring processors level decompositions 
amount data exchanged direct overlapping approaches 
communication delay reduced 
table proposed parallel dwt algorithm 
transform processor pg transform current level store state information 
send state information processor receive state information processor transform boundary data samples current level systems fig 
example dwt level decompositions shown 
data row transformed rst column transformed 
naturally data sam ples block boundaries fully transformed due lack neighboring samples 
constitute row column state information level 
introduce notations rst 
nr nc width height data block respectively 
decomposition level de ne fw numbers partially transformed samples near left right boundaries respectively row 
fw de ned similarly column 
fn nj cg length row column respectively start decomposition level 
fm mj cg number completely transformed samples row col umn respectively 
total number partially updated samples size bu er hold state information processing 
row level wc mc wc nc col level dow wr wr sample nr col level wr nr row level dwt fsm illustration 
shaded areas represent state information row column state information level 
input block rst row transformed column transformed level downsampled ll subband row transformed level column transformed level 
identities de ned quantities level derived refer fig 

bm nr bm nc nr nc mc wr wc mc wc nc completion level decompositions bs bs bs total bu er size necessary store state information decomposition levels ective block size number wavelet coe cients transfered stage processing freeing memory 
sequential architectures strip sequential case bu er organized hold strip data time 
equivalently xh original data size 
scenario depicted fig 

input data segmented column direction state information partially transformed samples appear column direction 
certainly type boundary extension techniques symmetric extensions transform near left right row boundaries 
transform rst strip extension needed upper lower boundaries column 
strip takes state information left previous strip transform data 
completion generates state information strip 
strip slides dwt calculated strip strip state information overlapped strips 
bottom fig 
blow version state information shown 
level decomposition state bu er size bs calculated bs ww nc bs bs wc wc strip current strip state info 
sliding strip strip sequential dwt system diagram 
input segmented data strips transformed sequentially top bottom 
obviously bs proportional row length case depicted fig 

reduce state bu er size segmentation choose dimen sion large data size 
segment row direction wc segment column direction 
table comparisons proposed algorithm ones minimum memory requirements 
see proposed system produce signi cant memory savings 
consider color image size color component sample stored bytes oating point number dwt computation 
case image scanline requires kb 
daubechies wavelet level decomposition total memory kb rpa algorithm approach 
overlap state technique bu er size reduced kb 
wc table comparison memory requirements width image scanline rpa proposed tap cdf block sequential case bu er divided parts holding state information new input samples sliding transform window 
equivalently bs 
scenario depicted fig 

see data segmented blocks size trans formed block time 
boundary extensions applied left boundaries rst block state information far appear right side block completion transform 
far acg correspond respectively partially transformed row column samples 
window slides right position block row state information ar overlapped 
shows ar fully trans formed overlapping ac bu ered processing 
block column state information generated bu ered 
process continues completion transforms blocks rst block row 
time column state information accumulated size bs exactly sequential strip dwt refer 
turns state bu er size bs increase point 
veri ed checking rst block second block row 
clarity illustration second row separately rst block row fig 

overlapped part state information 
block takes state information ac complete transform 
transform stops state information appears right boundaries block ac fully transformed transfered cc written locations nc ar br sliding ac nr ac bc cr cc bc dc dr sliding state info 
block sequential dwt system diagram 
input segmented blocks transformed left right top bottom 
ac increase total state bu er size bs 
general case sequential block dwt depicted block block overlaps previously generated state information row column directions fcr bcg 
nishes transform leaves fdc processing 
transform block block row boundary extension column direction 
study system throughput consider problem large bu er order transform block data size nxn time 
typical transformed image coding applications images coded block block basis 
assume bu er size 
table nb level wavelet decompositions di erent wavelet overlapping techniques 
daubechies example 
assume decomposition level 
block size 
nb means bu er size needed compute dwt data block 
throughput case approximately 
rpa nb throughput increases 
overlap state technique nb throughput increases 
table comparison memory requirements rpa proposed tap cdf parallel architectures block parallel shown rst phase split processor allocated por tion data starts transform way required decomposition level completion data con guration processor shown fig 

center part block completely transformed boundaries left partially transformed samples state informa tion 
stage merge communicate state information complete transform boundary samples 
single port model communications necessary complete transform row state column intersection row column state 
multi port model row column state information exchange implemented simultaneously reducing communication 
merge pro cess shown fig 
single port model 
multi port model combined simultaneously transmit receive row column state information neighboring processors 
contrast observation dwt algorithms able ectively utilize single communication port time analysis show multi port model communication overhead reduced compared single port model 
data transfered data processor communication row state row col state merge operations mesh processor network 
transfer row state information pi pi transfer column state information pi pi transfer newly generated row state information pi pi complete transform boundary samples 
notice total amount data processor nal state di erent original uniform allocation due merge operations 
strip parallel rst stage split processor allocated strip transforms required level decomposition segmentation done row direction state information obviously appear boundaries block 
shown fig 

merge communication necessary transfer receive column state information neighboring processors 
col state data transfered nc data processor communication col state merge operations strip parallel implementation 
transfer row state information pi pi complete transforms boundary samples processor 
experimental results section experimental results provided show computation reduc tion delayed normalization technique sequential lifting algorithms 
results parallel dwt system overlap state tech nique 
wavelet daubechies lters 
input image size 
delayed normalization experiment dwt algorithms lters implemented 

recursive standard algorithm see table 
computation cost adds output point 

lifting dwt algorithm 
computation cost adds output point 

lifting dwt algorithm delays normalization level decompositions 
computation cost approximately adds output point 
experiment separable wavelet transforms implemented 
algorithms tested ultra sun workstation clock speed mhz 
algorithm running cpu time measured clock function call average cpu time running instances algorithm listed table 
compare performances standard algorithm basis relative speedup calculated tnew 
observations seen experiment results 
lifting scheme coupled delayed scaling standard algorithm level decompositions lifting gives improvement 
second lifting algorithms achieve performance gain predicted table 
second observation tells number multiplications additions algorithm factor contributing total dwt running time 
algorithm speed may ected ciently code written memory usage 
obviously important factor consider building real dwt system reduction numbers multiplications additions 
table dwt cpu time di erent sequential algorithms seconds 
level standard lifting lifting delayed normalization time speedup time speedup strip parallel experiment di erent parallel dwt algorithms implemented tested sequential dwt algorithm 

sequential lifting algorithm 

processor computes dwt standard algorithm 
data exchanges processors follow direct overlapping technique processors exchange data level decompositions 

processor computes dwt fast li ng algorithm 
data exchanges processors follow direct overlapping technique processors exchange data level decompositions 

processor computes dwt fast lifting algorithm 
data exchanges processors follow proposed overlap state technique 
rst issue parallel system designs allocate data di er ent processors 
experiment strip partition strategy adopted simplicity appropriateness parallel system ex periment 
image segmented strips size loaded machine transform 
parallel platform lam ohio supercomputer center runs ethernet connected sun ultra workstations 
workstations simulate parallel system processors 
algorithm running time measured mpi time function call mpi libraries 
code algorithm shown table 
relative speedup calculated sequential lifting algorithm tseq 
algorithms tested running instances average dwt running times di erent decomposition levels table 
seen results proposed parallel algorithm sig ni cantly reduce dwt computation time compared fastest available parallel algorithm parallel lifting algorithm 
notice improve ment linear increase decomposition level 
reason communication overhead increases decomposition level total numerical computation increases 
interesting observation level decomposition proposed algorithm outperforms parallel lifting algorithm 
algorithms require data exchange processors amount data exchanged di erent 
lters proposed algorithm needs exchange approximately table proposed parallel dwt algorithm 
mpi barrier mpi comm world start mpi transform processor pg transform current level store state information 
send state information processor receive state information processor transform boundary data samples current level mpi barrier mpi comm world nish mpi nish start half amount necessary parallel lifting algorithm 
chapter overlap state technique proposed multilevel wavelet de compositions 
basic idea model dwt nite state machine factorization polyphase matrix 
model raw input data sample initial state progressively updated coe cient nal state help samples neighborhood 
bene fsm model transform state transition sample stopped intermediate stage long state information break point preserved 
state information raw data samples needs stored communicated shown helps reduce bu er size se architecture communication overhead parallel architecture 
table dwt running time di erent parallel algorithms seconds 
level sequential parallel standard parallel lifting parallel proposed time speedup time speedup time speedup detailed analysis bu er size calculation factorization communi cation overhead reduction provided 
reduce computations delayed normalization technique multilevel wavelet decompositions 
overlap state technique new sequential parallel dwt architec tures designed 
system variations separable dwt provided analyzed detail include dwt systems strip sequential block sequential random sequential block parallel strip parallel 
performance analyses experimental results shown proposed sequential architecture requires memory runs faster existing sequential algo rithms 
proposed parallel architecture reduces interprocessor communi cation overhead reducing number communication times amount data exchanged 
result dwt running time proposed parallel architecture faster best parallel algorithm available parallel lifting algorithm 
important advantage traditional overlapping techniques overlap add overlap save suited fast implementations fft 
naturally research needed search fast dwt algorithms com proposed overlap state technique 
increase chances wide application wavelet transform achieved 
chapter constrained transform design multiple description coding chapter studied architectures transform coding system 
problem simple sense transform thing needs done compute transform ciently 
chapter raise problem higher level design compute unknown transform ciently 
speci cally study transform compute ciently input data needs compressed needs delivered robustly receiver finding transform long key issue various transform coding system designs 
traditionally transform de ned maximally decorrelate input data removing redundancy achieving maximum energy data compaction 
perfor mance optimization data compression communication unreliable channel mobile wireless channel best ort network maximum decorrelation may best choice 
part chapter represents published see 
consider case communication channel perfect en coded bitstream may arrive receiver error refer fig 

happens received bitstream decoded correctly 
result receiver able recover transform coe cients 
estimates lost coe cients received ones transform removed correlation output coe cients 
lost coe cients non principle com ponents small variances reconstructed distortion small 
suppose principle components large variances lost distortion high 
communications unreliable chan nels quality variation received signal vary annoying 
conventionally channel coding applied cases error protection recovery 
chapter study alternative way error recovery redesigning transform introduce correlation transmitted cients technique multiple description transform coding mdtc proposed wang orchard goyal 
complete mdtc system shown fig 

input data rst lated conventional transform coding system see fig 

quantization coe cients correlated transform 
af ter data encoded di erent bitstreams called descriptions mdtc terminology sent di erent channels transmission 
channel failures result data loss receiver estimate lost coe cients received ones exists correlation 
reconstruction distortion reduced compared case correlation exists 
clearly description transform coding system coding ciency lower system shown fig 
due correlation introduced extra bits needed encode correlated output 
design goal mdtc system focuses problem searching optimal correlating transform achieve error recovery minimum possible redundancy 
pair gaussian random variables output channels op transform provided analytically goyal decorrelating typical mdtc system entropy coder entropy coder special case reported orchard 
shown non orthogonal correlating transforms perform better compared orthogonal correlating transforms terms redundancy rate distortion gain case transform invertible mapping integers integers 
mdtc systems inputs outputs optimal transform de sign performance analysis open problem near optimal solutions channels goyal 
orchard suggested redundancy allocation strategy pairs input vari ables optimal pairing readily available 
numerical optimization algorithm proposed goyal design transforms arbitrary number channels 
exhaustive search space non orthogonal transforms computationally intensive leads implementation di culties arbitrarily structured non orthogonal transform 
chapter rst address problem correlating transform design designing refer fig 
optimize operational redundancy rate distortion performance 
approach propose stage transform design technique separating design structure design ii magnitude design 
observation error protection properties mdtc system fully characterized output correlation matrix correlation matrix coe cients generated 
output correlation matrix immediately see descriptions correlated structure extent correlated magnitude 
magnitude information correlation matrix general quanti ed speci redundancy rate distortion constraints structural information directly inferred speci channel conditions protection requirements provided 
example common technique error protection robust audio tool rat lossy packet networks packet protect previous packet vice verse 
case mdtc system designed possibility band diagonal correlation matrix coe cient correlated neighboring coe cients 
packing coe cient packet send packets sequentially network similar error protection scheme rat completed 
case key transform design rst nd transforms admissible transforms generate band diagonal correlation matrix search admissible transform set optimal solution 
show admissible transform simply output correlation matrix 
structural information available band diagonal structure case transform pre designed advantage existing results area decorrelating transform design 
structural information output correlation matrix nd admissible transforms output correlation matrix 
meet nal redundancy rate distortion constraints optimization algorithm similar applied complete magnitude design 
major advantage stage design approach en force structure transform designed 
optimal redundancy rate distortion performance transform design previously search non orthogonal transforms starting arbitrary non orthogonal trans form shown 
transform structural information derived available channel information search space drastically reduced 
result complexity optimization algorithm drastically reduced 
enforced structure design phase leads structured optimal transforms implemented existing fast algorithms shown 
second part chapter address problem designing single transform decorrelate input time 
see fig 
mdtc system con guration redundant input rst decorrelated reduce system implementation complexity propose replace single transform loeve vector transform 
proposed take input group vectors generate decorrelated vectors preserving correlation vector components vector 
vector components grouped form description sent di erent channels 
error recovery mechanism case channel failures mdtc system refer fig 
system con gured simply fig 

idea similar vector transform vt proposed li preprocess data vector quantization 
maximize coding ciency vt required maximally remove inter vector correlation 
optimal vt required maximally preserve intra vector correlation compression designed vary intra vector correlation channel statistics loss data recovery 
remainder chapter organized follows 
section brief review mdtc provided problem optimal correlating trans form design de ned 
section propose stage transform design approach parametric scaling rotation transforms design mdtc systems inputs outputs 
section provides correlating trans form design examples equal rate channels sequential protection channels respectively 
simulation results gaussian vectors 
section proposed karhunen loeve vector transform de ned analysis possible applications mdtc system design 
conclude section 
problem de nition assume source descriptions fci mg generated 
tations introduced 
central distortion dc average reconstruction error descrip tions 
side distortion ds average reconstruction error subset descriptions 
redundancy di erence actual coding rate rx dc source rate distortion function evaluated dc 
redundancy rate distortion function ds dc amount extra bits redundancy necessary achieve desired side distortion ds central distortion dc 
input source vector encoding procedure mdtc system shown fig 
described 
decorrelated 
transform coe cients generated quantized uniform scalar quantizer 

quantized vector transformed invertible discrete transform introduces correlation vector components 
components transform output vector indepen dently entropy coded 

encoded bitstreams separated di erent channels 
assume correlation information delivered decoder correctly 
decoding procedure 
entropy decode received 

descriptions received inverse transform plied 
inverse transformed data 
ap subset descriptions received received data de quantized rst 
lost descriptions estimated available descriptions correlation information received en coder 
reconstructed vector including received reconstructed descriptions inverse transformed 
output previous stage inverse transformed get reconstruction nal reconstruction distortion xjj central distortion ds case side distortion dc case 
multiple description coding problem formulated objective design transform minimize side distortion ds central distortion dc subject redundancy constraint side distortion mse orthogonal transform nonorthogonal transform redundancy bits vector redundancy rate distortion curve mdtc system gaussian vector 
mdtc pairs independent gaussian random variables important result non orthogonal transforms better orthogonal transforms terms redundancy rate distortion gain 
central tion non orthogonal transform average side tion amount extra bits extend redundancy rate distortion function region orthogonal transform reach see fig 

non orthogonal transforms pose challenges mdtc system design 
lossless implementation transform lossless cient quan 
nite precision implementation means transform integer mapping mapping integers integers 

design complexity numerical optimization algorithm goyal computationally intensive increase dimensional ity transform necessary 
channel mdtc system trans form size mxm entry design parameter complexity 

implementation complexity optimal transform arbitrary struc ture practice fast implementation di cult 
section start intuitive geometric explanation non orthogonal transforms perform better orthogonal transforms 
propose structured non orthogonal transform framework optimal cor relating transform design 
proposed design approach geometric interpretations equal rate channels optimal pairing transform ta goyal kovacevic form ta little math derived 
ta see optimal pairing transform concatenated scaling rotation transform 
obviously rotation transform orthogonal self introduce correlation uncorrelated inputs 
scaling transform enhances ability 
write optimal transform parametric form ta ta cos sin sin cos rotation scaling cos sin sin cos denote original orthogonal basis vectors fu new basis vectors transform ta fv 
write ta inner product cos sin sin cos sin easy see inner product new basis vectors equal zero new basis orthogonal scaling factor 
case ta equivalent orthogonal transform 
orthogonal trans formation amounts plane hyperplane rotation introduce correlation case eigenvalues input vector correlation matrix equal 
geometrically random vector directional preference eigenvectors joint distribution circular sym metric hyper spherical higher dimensions 
scaling factor chosen smaller larger inner product nonzero assuming nonzero new basis correlated 
case input vector components variances correlated scaling rotation transform 
scaling rotation structure partially explains non orthogonal transforms greater exibility introduce correlation orthogonal transforms 
fig 
data distribution plots shown pair independent gaussian random variables di erent transforms 
seen clearly scaling rotation transform introduce stronger correlation orthogonal counterpart 
original scaling rotation distributions independent gaussian variables variance 
original rotation correlation coe cient 
scaling scaling rotation correlation coe cient 
clearly see data correlated 
parametric transform factorizations decomposition optimal transform scaling rotation frame accidental re ects general structure non orthogonal trans forms 
matrix factored product orthogonal matrix upper triangular matrix called qr decomposition matrix theory 
notations write ru orthogonal transform upper triangular matrix 
upper triangular matrix decomposed product scaling matrix upper triangular matrix diagonal entries 
words transform written concatenation transforms upper triangular trans form scaling transform rotation transform orthogonal transform 
rsl note non square transform case frame expansions adding redundancy 
reduce design complexity study non orthogonal square transforms scaling rotation factorization trs rs 
non orthogonal transform mdtc rst constraint implemen tation cient quantization 
require determinant det trs det rs det 
wenow show transform trs factored lifting steps implemented 
rst factorization results rotation scaling transforms adapted follows 
cos sin sin cos cos sin sin cos sin results show basic rotation scaling transforms imple mented 
mxm rotation transforms known orthogonal matrix qm factored product orthogonal matrices givens rotation rotates components time 
factorization givens rotation matrix equivalent basic rotation 
mxm orthogonal transform implemented integer mapping 
factorization scaling transform straightforward factor ization result basic scaling transform 
show mxm scaling transform written product transforms scales components time 
example show decomposition scaling transform follows 
note constraint applied ai 

lattice structure rs transform shown trs factored lifting steps fore implemented 
general implementation structure trs shown fig 
lattice structure similar biorthogonal 
perfect reconstruction property guaranteed transform framework 
derive inverse transform needs change rotation angles opposite sign multiply inverses scaling factors 
analysis previous section propose parametric form trs design mdtc 
parametric form trs written trs scaling factors givens rotation angles 
analyzed scaling transform changes relative energy distribution input vector components rotation introduces correlation vector components 
net ect operation orthogonal basis transformed non orthogonal 
result correlation introduced vector components decomposition non orthogonal basis orthogonal basis 
stage transform design trs enjoys structured lattice implementation number design parameters transform increases quadratically dimensional input vector 
section propose stage design technique making available channel information constrain trs reduce design implementation di culties 
recall transform designed transform equiv tot shown fig 

denote uncorrelated input trs correlated output rx iig input correlation matrix ry output correlation matrix transform output rs fa ii ry trs rs rsr ii mg diagonal matrix rotation transform output correlation matrix ry output correlation matrix prob lem correlating transform design formulated inverse matrix diagonalization problem 
orthogonal solution correlating trans form simply inverse kl transform 
general pre design output correlation matrix subject redundancy distortion constraints 
select structural information speci channel conditions protection requirements 
example equal rate channels require output correlation matrix equal diagonal entries gaussian inputs 
ad transforms able generate correlation matrices equal diagonal entries 
observations propose stage transform design approach structure design magnitude design 
structure design nds admissible transforms output correlation matrix speci channels trs factorization framework 
fig 
show transform search space reduced gradually available channel information 
start transform space consists transforms orthogonal non orthogonal determinant 
reduce search space enforcing transforms scaling rotation factorization 
re duce complexities design implementation described 
scaling rotation transform space application speci constraints imposed reduce space admissible transforms details section 
structure transform magnitude design searches optimal transform admissible transforms algo rithm described derivation details average side distortion ds redundancy bit rate 
di erent derivation optimization algorithm appendix perform redundancy constrained transform design lagrangian multiplier cost function ds 
varying scan operational redundancy rate distortion points ds 
nonorthogonal transforms det sr sh transform search space 
mdtc design examples give design examples important channels equal rate channels sequential protection channels characterized output correlation matrix ry turns special channels xed rotation transforms xed transforms fast algorithms 
xed rotation transform reduce number design parameters 
optimization converge faster reduces amount information conveyed decoder 
hand fast algorithms reduce encoding decoding complexities 
equal rate channels equal rate channels case requires output descriptions rates helps bu er management packetization packet network encoder decoder 
stated equal rate interpreted statistical sense 
example gaussian sources variances viewed equal rate sources quantized quantizer 
say gaussian random variables equal rate requires correlation matrix ry equal diagonal entries 
provide trs transform generates equal rate descriptions arbitrary number channels equal rate transform propose scaling hadamard transform 
hs hadamard transform 
need show transform input ry equal diagonal entries equal variances rii constant 
hadamard transform real symmetric output correlation ry 
denote ji 
output component variance rii written rii mx jj jj ji shown scaling hadamard sh transform generates equal rate descriptions 
correlation coe cients output vector components rij jointly designed scaling transform meet rate distortion requirements optimization algorithm appendix scaling hadamard structure equal rates output reduces number design non orthogonal mxm transform scaling factors required scaling transform 
mention scaling hadamard transform reduces optimal equal rate transform goyal kovacevic demonstrates descriptions coding rs transform compromise optimality mdtc system 
note cascaded structure goyal equivalent scaling hadamard transform 
mx jj jj sequential protection channels example channel sequential protection channel descrip tions sent sequentially description protect losses immediate predecessor immediate successor 
lossy packet net example scenario packet carries information recovery previous packets similar case robust audio tool technique applied audio transmission 
mdtc system indicates output correlation matrix ry tridiagonal matrix descriptions sequentially correlated 
ry assumes form ry matrix theory know type symmetric tridiagonal toeplitz matrices discrete sine transform dst 
transform propose sequential protection channels scaling dst trans form dst simulation results gaussian sources experiment compare results di erent con gurations cor relating transform gaussian vector source standard deviations 
compare side distortion description lost equal channel failure probabilities 
di erent transforms rotation ii scaling rotation iii scaling hadamard iv scaling dst 
con guration scaling hadamard equivalent cascaded structure goyal kovacevic fig 
input vector 
op timization done powell direction set technique 
initial scaling factors set initial rotation angles set scaling rotation con guration 
side distortion db scaling rotation scaling hadamard scaling dst rotation redundancy bits vector comparisons di erent transforms 
comparison con gurations shown fig 

clearly non orthogonal transforms achieve better performances compared transform case 
indicates non orthogonal transforms perform better orthogonal transforms mdtc systems channels 
observe performance degradations impose constraints rotation transform scaling hadamard scaling dst transform specially higher redundancy bit rates 
structured transforms simplify de sign implementation complexities 
case hadamard transform dst implemented existing fast algorithms 
drawback non orthogonal transform complete mdtc system refer fig 
requires transforms decorrelation quan quantization encoder decoder 
obviously increases system implementation complexity 
orthogonal transform merge transform reduce computation 
section transform show possible applications mdtc system design 
karhunen loeve vector transform random sequence size nx generated stationary ergodic source zero mean 
assume sequence decomposed subvectors size mx fx ml denote correlation matrix correlation matrix subvectors xi xj identities 
ri xm rl rl de nition unitary transform block diagonalize lation matrix de ned kl vector transform vector random sequence fxi lg 
trt rl ri autocorrelation matrix transformed subvector yi tx lg 
existence transform arbitrary inputs obvious easily see karhunen loeve transform special case 
de nes transform set properties follow klt 
properties property set de nes unitary transform set ft includes trans forms form bk klt arbitrary block unitary matrix long sizes subblocks agree sizes subblocks cardinality set nity 
bi unitary krk trt block diagonal matrix 
bl bl lb property decorrelation assume transform set tx lg fxi lg ri ri diagonal klt arbitrary symmetric 
property directly derived de nition 
property energy compaction unitary transforms transforms pack maximum average en ergy subvectors energy vector de ned mean squared length size energy equals variance assuming zero mean 
yg tr mx size subvector mg eigenvalues autocorrelation matrix tr denotes trace matrix property easily proved klt maximum energy compaction property 
transform related klt block unitary transform preserves eigenvalues transformed vector pre serve energies corresponding scalar components klt case 
scalar components ordered klt case energy ordered order block unitary transform 
probe provide view vector space partition 
see de nes transform set includes transforms block diagonalize autocorrelation matrix decorrelate corresponding vector signal applied original data 
non uniqueness property misinterpreted non uniqueness decorrelation vector space partition signal see appendix 
decorrelation vector space partition vec tor signal unique permutation corresponding eigenvalues 
autocorrelation matrix eigenvalues uniquely de ned 
di erence transforms residue intra vector correlation transform 
klt transform removes completely inter vector correlation intra vector tion 
exists nite number transforms maximally remove inter vector correlation keeping intra vector correlation level 
intra correlation obviously error protection discussed mdtc system 
shown possibility combine decorrelating transform mdtc system design 
compared system con guration shown fig 
reduce design implementation complexity 
chapter studied problem constrained transform design robust communication multiple description transform coding 
stage transform design approach proposed mdtc system design 
approach enables nd structured transform solutions available channel information 
helps reduce system design implementation complexities 
provided example transform designs equal rate channels sequential protection channels 
reduce mdtc system complexity loeve vector transform proposed possibilities application mdtc system designs illustrated 
study redundancy rate distortion performance mdtc system 
chapter multiple description coding erasure channels chapter correlating transform coding system recover lost data correlation existing correctly received data 
chapter take di erent approach loss data recovery adding redundancy explicitly implicitly correlating trans form chapter encoded data loss recovery 
motivation simple tohave simple system design years number approaches error control protection audio video communication packet networks reported literature 
majority works chosen receiver strategies avoid retransmission reduce communication delay 
include various fec schemes variations error conceal ment techniques exploit residual correlation encoded data 
example jayant subsample interpolation scheme odd samples input speech signal sent di erent packets 
packet lost missing samples interpolated neighboring samples part chapter represents published see 
received correctly 
unequal error protection schemes studied davis sherwood error correction codes applied importance data provide di erent levels protection 
robust audio tool rat proposed hardman multicast teleconferencing 
rat packet carries explicitly redundant version previous packet loss recovery 
similar ideas explored extended video coding bolot podolsky 
deal network heterogeneity issue broadcast multicast applications hierarchical layered fec scheme proposed tan chou users subscribe di erent number channel layers error protection observed packet loss statistics :10.1.1.33.2192
renewed interest technique multiple description coding mdc error protection control packet net 
formulated el gamal cover basic idea mdc encode input signal multiple descriptions constraint descriptions render acceptable reconstruction signal 
furthermore requires descriptions better reconstruction quality 
assume description sent packet acceptable signal reconstruction guar long packet received correctly 
reasonable networks qos available way give priority certain packets 
assumption matched mdc philosophy packets carry equally important information 
proposed mdc techniques cite dpcm diversity system packet speech wavelet image mdc coding scheme multiple description scalar quantizer designed vaishampayan multiple description perceptual audio coder uses multiple description transform coding mdtc technique proposed wang orchard de veloped goyal 
mdc techniques usually involve complex system designs implementations may ect ectiveness real time applications 
example requires careful index assignment di cult descriptions necessary 
build complete transform coding system mdtc approach necessitates correlating transform conventional decorrelating transform 
chapter propose new mdc scheme packet loss recovery packet networks 
di erent previous mdc works data loss recovery achieved redundancy explicitly carried encoded data idea inspired hardman bolot robust packet speech audio internet 
proposed scheme input rst split di erent components component quantized separately di erent resolutions 
polyphase transform source splitting 
polyphase component coded independently relatively high quality nely quantized 
redundancy explicitly added description coding polyphase components lower coding rate 
case packet losses descriptions missing lost data recovered redundancy carried correctly received packets 
approach adding redundancy explicitly leads simple system design implementation 
polyphase transform enables incorporate context adaptive coding techniques improve system coding ciency 
show proposed mdc system simple yield competitive coding performance compared previously published 
time writing chapter improved performance results reported increasing granularity redundancy addition varying amount redundancy importance data unequal loss protection 
may noticed mdc approaches combined fec schemes better error protection 
example send redundant packets data packets loss recovery packet protected error correcting codes 
hybrid error control schemes reported mdc fec puri generalized mdc scheme unequal error loss protection mohr 
improving performance error protection codes goes outside scope chapter 
remainder chapter organized follows 
section provide characterization erasure channel de ne problem 
section proposed mdc system polyphase transform selective quantization detailed 
performance analysis terms optimal redundancy bit allocation comparisons gaussian sources section 
section provides image speech coding results proposed mdc technique 
conclude section 
erasure channel model problem de nition erasure channel model going study simpli ed 
packet transmitted data assumed completely lost case channel failures received correctly channel 
terms layer osi network model essence consider bit errors introduced physical layer assume corrected packet discarded possible correct errors 
consider alternative data recovery technique application layer smallest data unit single packet information source 
channel packet erasure channel 
erasures occur largely due network congestion link failures 
assumptions event channel failure occurs independently examples include mobile channels spaced coherence bandwidth time slots separated larger coherence time packets routed di erent paths network 
receiver knows channel fails receiver knows description lost 
achieved inserting synchronization points bitstream tagging packets sequence numbers 
independent packet failure assumption simpli cation serve approximation network tra su ciently multiplexed dif ferent sources random dropping policy relieve congestion details see 
failure probability single channel large cases rst assumption ensures probability simultaneous multiple failures tend small 
multiple description coding system advantage reasonable assumption generates inde pendent bitstreams descriptions di erent channels 
channel diversity helps greatly increase probability event description arrives successfully receiver 
recover lost description description carry addition information extra information redundancy descriptions 
assume total descriptions generated source 
de ne central distortion dc reconstruction error descriptions 
side distortion ds reconstruction error descriptions 
xed bit budget prefer descriptions independent ofeach minimize dc 
loss recovery introduce redundancy descriptions reduce ds 
goal objective total bit rate channel failure model design multiple description coding system minimize average central distortion dc average side distortion ds 
mdc explicit redundancy base system proposed mdc system shown fig 

quantizers respectively ne high rate coarse quantizers low rate 
input source rst split 
case polyphase transform applied choices possible 
description coding system consists indexed samples consists proposed mdc system 
odd indexed samples 
polyphase components nely quantized packed corresponding packets error protection recovery packet carries coarsely quantized version polyphase component 
example consists nely quantized coarsely quantized 
packet obtained similarly 
receiver packet received nely quantized polyphase component coarsely quantized polyphase component reconstruction 
example received reconstruction 
packets received nely quantized data signal reconstruction 
sense called redundant information function solely provide packet loss protection 
context adaptive extension obviously improve bandwidth ciency bits possible encode redundant information 
motivates consider context adaptive coding techniques 
basic idea context coding technique knowledge neighborhood statistics data encoded 
polyphase components generated input strong correlation expected exist 
true natural speech image signals correlation taken advantage achieve compression gain number coding standards speeches jpeg images 
input subband data dct wavelet transform output linear correlation approximately removed cases 
strong structural similarities exist polyphase components 
example large magnitude coe cients tend cluster case smaller magnitude coe cients 
feature exploited extensively proven successful context adaptive codecs developed image coding applications 
incorporate idea context adaptive coding redundant information proposed mdc system quantized coded conditioned data 
shown fig 
coarse quantizer input data 
result cient quantization redundant information achieved 
note limit context coding operate packet packet loss ect decoding packets 
context mdc system optimal redundancy bit allocation gaus sian sources give performance analysis proposed mdc system gaus sian random sources 
answer question total bit rate optimal bit allocation source coding primary formation channel coding redundant information minimize central distortion side distortions 
implicit channel modeling consider rst traditional mdc problem explicit channel modeling 
problem descriptions coding goal nd operational optimal regions tuple rs rs dc ds ds ds side distortion description rate rs 
study equal rate mdc systems descriptions coded bit rate rs rs 
assume zero mean random source pdf variance high resolution quantization assumption rate distortion function approximated integral constant de ned nr dx 
gaussian sources 
obviously applying polyphase transform memoryless source change distortion rate function 
subsampling scrambling change statistics data random 
polyphase components distortion rate functions bit rate primary information redundant bit rate side distortion description lost ective bit rates ds rs corresponding central distortion achieved dc total bit rate simple formulation optimal bit allocation primary information redundant information constrained optimization problem 
lagrange multiplier de ne cost function dc ds optimal redundancy bit rate analytically solved leads log optimal redundancy intuitive explanation 
range total bit rate side distortion counts description lost high probability optimal redundancy rate shows primary information redundant information part coded rate half total bit rate 
fact minimum possible achievable side distortion ds system obtained expense maximum possible central distortion dc 
central distortion counts descriptions arrive destination high probability redundancy set zero 
means channel carry half total information 
receiving data channels get minimum possible central distortion bit rate side distortion maximum case redundancy 
extreme cases freedom ne tune side distortion respect central distortion choosing di erent redundancy bit allocations 
redundancy allocation achievable pair side central distortion ds dc total bit rate dc log ds log log practical example consider mdc unit variance zero mean memo gaussian source 
simulation rst generate sequence gaussian samples 
samples quantized lloyd max quantizer source coding rate odd samples quantized lloyd max quantizer redundancy coding rate description 
description formed way odd samples quantized rate samples quantized rate central distortion dc mse achieved rate original source side distortion ds average mses achieved description description 
xed length codes index coding bit allocation simple constraint xed total coding rate constant 
example total coding rate bps possible bit allocations measure central distortions side distortions 
optimal lower bound achievable set tuple rs rs ds ds dc unit variance zero mean gaussian source ds rs ds rs dc rs rs ds ds ds ds rs rs total bit rate rs rs 
asymptotic results optimal level constrained vaishampayan bit rates 
dc ds comparisons shown fig di erent see results proposed system lloyd max quantizer average comparable achieved optimal level constrained 
better redundancy rates low relatively low total bit rates 
interesting determine improve proposed system performance cient quantizers central distortion db central distortion db bps proposed optimal side distortion db bps proposed optimal side distortion db central distortion db central distortion db bps proposed optimal side distortion db bps proposed optimal side distortion db rate distortion performances comparison gaussian source optimal bound 
optimal level constrained results 
proposed lloyd max quantizer results xed length code 
optimal results rate distortion function gaussian source 
lloyd max quantizer 
useful establish best achievable performance proposed mdc system frame 
example gaussian source design quantizer operates exactly rate distortion function approach mdc bounds 
optimal bit allocation derived achievable central side distortions dc log ds log log optimal results plotted gure see fig 

see performance gap narrows drastically approaches lower bounds lower redundancy rates 
indicates proposed system achieve lower bounds operational range performance greatly improved design better quantizers 
low redundancy rates cient introduce explicit redundancy standard quantizers 
mention quantizer design exactly single description coding 
state art results single description coding reach multiple description coding goals 
result system design implementation complexity expected reduced compared specially designed mdc systems mdtc systems 
experimental results mdc image transmission illustrate point 
explicit channel modeling consider channel model analysis 
assume de sent di erent channels independent channel failure probability di erent situations receiver descrip tions received happens probability results tion dc description lost happens probability distortion ds descriptions lost happens probability distortion db average distortion receiver channel model dc ds db reconstruction distortion case ected allocation optimal bit allocation needs minimize rst terms notice total rate derivative ofd respect redundancy rate solving equation minimize average distortion presence channel failures optimal bit allocation log may notice optimal bit allocation computed directly result derived case implicit channel modeling 
notice average distortion independent loss channel written dc ds db optimization 
optimal redundancy computed new indicates explicit channel model changes weighting factor side distortion cost function true mdc system encoding completed possible decoding scenarios enumerated corresponding side distortions computed 
channel model determines probability decoding scenario providing weighting function compute average distortion 
arbitrary multiplier optimization cost function subsumes cases explicit channel models 
sense say proposed mdc system easily extended non independent loss channel models bursty erasure channel modeled markov chain loss process 
experimental results image mdc example section image mdc example 
shown analysis cient quantization scheme better performance mdc system 
state art wavelet coders choose said pearlman wavelet coder due simplicity fact code available example con guration di erent polyphase transforms level wavelet decomposition input matrix 
subbands samples constitute polyphase component remaining samples constitute polyphase component 
plain polyphase transform 
vector polyphase transform 
experiment input image rst wavelet transformed polyphase components extracted 
case polyphase transform wavelet cients original image data extracted 
di erent types polyphase transforms tested wavelet coe cients see fig 

plain polyphase transform descriptions coding consists simply grouping coe cients description odd coe cients description 
done row subband 
second polyphase transform strict sense viewed generalized polyphase transform vector form 
subband rst grouped vectors size vectors indices polyphase transform 
example successive wavelet coe cients grouped vector size vectors subband rst decomposition level refer fig 

denoted vectors fv 
author dr said prof pearlman providing image coder 
polyphase component fv polyphase component fv 
vector size increased subbands 
motivation introducing generalized polyphase transform pre serve spatial structures subbands coder improve coding ciency 
polyphase components 
rst description second description 
said pearlman wavelet coder quantize entropy code polyphase components 
example means coded bit rate said pearlman coder 
description lost reconstruct received data gives side distortion 
cen distortion derived 
total coding rate said pearlman coder zerotree structure sub bands second type polyphase transform generates slightly better coding results 
fig 
show mdc results lena gray level image size said pearlman wavelet coder 
results descriptions plotted comparison mdc wavelet coder 
xed total coding rate mdc coder achieves better rate distortion performance redundancy range 
fig 
show reconstructed lena images channel informa tion di erent redundancy rates total coding rate bps vector form polyphase transform 
second experiment measure average achieved independent packet losses 
input image rst wavelet transformed polyphase transform zerotree vector form implemented wavelet coe cients 
downsampling factor total polyphase components 
protect channel failures redundancy car sequential way rat 
packet carries redundancy protect packet packet carries redundancy protect 
polyphase component constitutes primary part packet carries redundancy protect polyphase component sequence 
central distortion db bps bps bps polyphase polyphase results side distortion db average reconstructed psnr db number packets lost experimental results lena gray level image 
descriptions 
polyphase plain polyphase transform 
polyphase vector polyphase transform 
performances independent packet losses 
example packet carries parts information polyphase component coded rate polyphase component coded rate emphasize apply pixels total rate experiment coding rates bps bps total coding rate bps 
total number wavelet coe cients packet packets size 
measure reconstruction error assuming independent packet losses 
example assume packets lost transmission rst gen erate loss pattern independently erasures 
loss pattern representing received packets represent lost packets 
case packet reconstructed redundancy carried packet 
true packet packet lost reconstruction 
tested loss patterns case packets lost 
fig 
show image mdc results total rate bps bps rate 
di erent number independent packets losses average plotted star symbols standard deviations vertical bars 
see reconstructed deviate mean values average standard deviation db 
quality changes due changes original redundancy redundancy redundancy reconstructed lena images total rate bps channel information 
original image redundancy bit rate bps psnr db redundancy bit rate bps psnr db redundancy bit rate bps psnr db di erent loss patterns consecutive losses lead worst reconstruc tions 
case packet loss average psnr db standard deviation db 
due fact assume rst packet loss recovered experiment 
rst packet recovered redundancy carried packet average psnr db standard deviation db 
experimental results show system performance degrades gradually packet loss rate increases 
indicates simple sequential packet protection perform cases consecutive losses 
miguel shown better error protection achieved increasing granularity redundancy addition incorporating idea unequal error protection 
amount redundancy varied importance data redundancy important data unimportant data 
improvement proposed mdc technique idea unequal error protection certainly worth explored 
speech mdc example experiment show example context adaptive mdc system robust speech coding lossy packet network compare results rat scheme 
speech materials consist sentences recorded khz bps male speaker squirrel nice pet female speaker draw outer line rst ll interior 
ms speech segment sent packet samples packet 
bits sample pcm coder ne quantizer bit adpcm coder coarse quantizer simulation 
bps pcm coder obtained removing lsb bits original speech 
plot speech coding packetization shown fig 
proposed scheme polyphase components samples odd samples input vector independently quantized ne scalar quantizer packed respectively packets toachieve loss protection needs carry coarse version polyphase component 
quantize directly coarse quantizer rst predict data quantize prediction residue 
prediction residues respectively 
prediction residues quantized coarse quantizer 
see simple average interpolation prediction sophisticated techniques applied 
speech rat proposed proposed rat schemes robust packet speech coding 
gure show rat scheme segments input sample frames 
frame quantized coded packed independently packet 
packet carries coarsely quantized data previous samples loss protection 
di erent schemes implemented tested simulation 
subsample interpolation method jayant 
interpolation average neighboring samples shown 
frame bps pcm coded 

rat scheme packet carries bit adpcm coded data previous packet loss protection main part bps pcm coded 

frames polyphase transformed coded bps pcm coder 
interpolation average neighboring samples shown 
prediction residues coded bit adpcm 
measure reconstruction quality speech signal noise mask ratio nmr measures relative energy noise components experiment illustration purpose pcm coder chosen encoding primary information adpcm coder chosen encoding redundancy 
advanced coders certainly gains expected delicate context adaptive techniques needed 
signal audible masking threshold 
nmr de ned nmr log cb kh kl jd total number frames number critical bands cb cb number frequency components cb jd power spectrum noise frequency bin frame kl kh respectively low high frequency bin indices corresponding cb choose nmr criteria mean opinion score formance reasons 
nmr objective measure human hearing system high degree correlation subjective tests 
second mos re sult subjectively better indication speech audio quality mos results published limited tests authors research group department di cult compare 
third important point focus see relative performance variations di erent algorithms nmr easy compute 
table reconstruction nmr comparison db jay rat proposed loss prob mean std mean std mean std table show reconstruction nmr results squirrel sentence independent packet losses di erent loss rates 
loss rate simulated times results taken ensemble averages 
seen proposed scheme achieves lowest mean nmr loss rates 
standard deviation reconstruction nmr larger compared rat scheme 
reason consecutive packets lost proposed scheme recover packets polyphase noise mask ratio db components speech frame 
rat scheme recover packet 
observations seen nmr results draw sentence table fig 
possible solution introduce descriptions coding example descriptions coding long delay constraints observed 
provided number consecutive packet losses smaller number descriptions avoid catastrophic case descriptions lost 
loss prob number tests noise mask ratio db loss prob number tests noise mask ratio db loss prob number tests noise mask ratio db loss prob number tests reconstructed nmr distribution plot draw sentence di erent packet loss probabilities 
rat proposed jay table draw reconstruction nmr comparison db jay rat proposed loss prob mean std mean std mean std summary chapter mdc system polyphase transform selective quan proposed chapter 
gaussian sources give detailed analysis optimal bit allocation achieve minimum average cen distortion side distortion xed total coding rate 
experimental results shown system implementation compared previous pro posed systems simple achieved mdc results image coding better especially lower redundancy rates 
interesting question consider mdc techniques ap robust multicast applications multimedia communications preliminary shown mdc provides better reconstruc tion signal quality compared layered coding network heavily loaded delay constraints critical 
believe mdc system designed implemented way layered coding scheme cope network heterogeneity issue 
description sent multicast group users subscribe di erent number groups bandwidth availability observed channel statistics 
words users choose receive descriptions subscribing corresponding multicast groups 
doing deal bandwidth heterogeneity issue goal lc packet loss heterogeneity issue goal hierarchical layered fec schemes 
appendix overlap add overlap save standard techniques linear fir ltering long data sequences include overlap save overlap add block approaches 
input sequence segmented blocks ltered frequency domain dft idft 
outputs block processing concatenated form nal result identical sequence obtained input sequence processed time domain 
input sequence 
denote block length lter length overlap save method block consists samples previous block ii new samples sequence 
data blocks fx fx 
see actual block size needed samples previous block 
ltering output yi idft fft bi fft 
rst samples discarded due aliasing remaining samples constitute desired result linear convolution 
overlap add method block consists nonoverlapping samples input sequence 
data blocks fx fx fx 
see input block actual block size padded zero samples 
ltering output yi idft fft bi fft free aliasing 
points overlapped added rst points succeeding block form nal result 
fy input data stream input samples section point cyclic convolution select second value output samples discard discard output data stream input data stream input samples section point linear convolution overlap save 
overlap add 
add output samples output data stream appendix dwt fsm examples daubechies lters extensively image compression algorithms proposed literature 
factorization analysis polyphase matrix adapted pa 
factorization forward transform inverse transform see wavelet lters total state transitions needed transform raw input sample wavelet coe cient 
process fig 

assume samples fx loaded memory initially 
rst elementary matrix triangular state transition update odd samples neighboring samples 
example updated 
updating occurs samples fx notice samples fx remain un updated needed neighboring blocks needed needed shown gure 
consequently preserved state information state 
state transitions daubechies lters factorization 
state information consists samples overlap bu er size shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx elementary matrix upper triangular updates samples odd samples 
example updated samples fx preserved state information state 
process continues updated nal transform coe cient 
state information near right boundary consists samples shown shaded boxes gure fx overlap bu er size level wavelet decomposition daubechies lters samples 
partially updated samples constitutes information needs bu er transform new input data pair fx operations shown dashed lines gure 
see operations state information preserved memory bu er 
lters lter give excellent performances lossless image compression 
factorization analysis polyphase matrix pa factorization forward transform inverse transform see rst state transitions basically lters 
assume initially samples memory shown fig 

transition interesting detailed 
elementary matrix lower triangular matrix odd samples get updated 
example state transitions lters factorization 
state information consists samples shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx updated hand fully updated available bu er 
partially updated partial updating frees sample bu er 
words fully update samples indices smaller needed 
partially updating performed sample samples bu ered fx overlap bu er size samples 
new input pair fx comes operations dashed lines executed 
result samples fx completely transformed removed bu er 
samples fx partially updated bu ered 
process continues inputs transformed 
cdf lters scaling function cdf lters cubic spine frequently computer graphics interpolation 
factorization analysis polyphase matrix adapted pa factorization forward transform inverse transform case state transition basically lters 
overlap bu er size samples shown fig 

state transitions cdf lters factorization 
state information consists samples shaded boxes 
dashed lines represent operations necessary transform new input sample pair fx appendix mdtc transform design algorithm basic algorithm described 
provide di erent derivation special channel model 
assume channel fails independently equal channel failure probability description loss probability 
example best ort network independent packet loss reasonable model individual connection 
mention straightforward generalize algorithm cases unequal channel failures probabilities 
constrained optimization problem transformed unconstrained lagrangian multiplier cost function written ds rx iig correlation matrix input vector ry correlation matrix transform output rs fa ry rsr ii ii diagonal matrix 
redundancy bit rate rst derive redundancy rate correlating transform assume coding rate rx input vector components identically distributed 
optimal bit allocation high resolution quantization achieved distortion nr dx rx nent density function constant integral determined compo geometric mean component variances 
transformation distortion remain unchanged implemented 
bit rate increased ry qm ii bit rate rx ry side distortion ry redundancy bit rate derived increased ry rx log rii derive side distortion erasures descriptions lost 
rst need recover lost descriptions received descriptions 
assume descriptions lost 
loss generality partition received lost portions notational simplicity assume yr dimensional vector isavailable decoder yl dimensional vector available decoder 
denote decoder reconstructed descriptions yr yl yr yl mmse estimator yl yl yr conditional mean yl 
jointly gaussian vectors reduces estimator yl rr yr mean squared estimation error mse tr ree tr trace matrix rrr rll rl ree eye rll rr rrl estimated obtained inverse correlating transform simplicity denote transpose nal mean squared reconstruction error xk tr tr write partitioned forms partition correspondingly eye ree trl tlr tll lr simpli cations nally get reconstruction mean squared error side distortion dm descriptions lost dm rl tr rl tr ll average side distortion ds weighted sum ds mx pm probability lost 
summarize list steps side distortion calculation 
ll 
mis number lost descriptions 
calculate side distortion dm 
partition ry nd rrr rll 
partition nd trl tll 
calculate correlation estimation error ree rll rr rrl 
calculate side distortion dm tr rl tr ll 
calculate event probability pm pm descriptions lost 

calculate average side distortion ds 
appendix vector space partition denote vector space basis set fai ng 
vector represented linear combination basis vectors 
called expansion basis set 
consider random sequence fxi ng 
assuming correlation matrix en fei ng eigenvectors ng corresponding eigenvalues 
written nx called spectral decomposition eigenspace en context signal processing 
fact constitutes dimensionality correlation 
merge consecutive eigen subspaces form new set eigen subspaces en set uncorrelated fei dimensionality union eigenspace ei ei ej projected new set expanded en ei iei fei ng matrices rank column space dimensionality 
notices fei special partition eigenspace subspace having eigenvectors basis set diagonal matrices 
matter fact eigen subspaces fei basis set eigenvectors 
words need diagonal 
long subspaces valid decorrelation partition block diagonalized 
ortega line reduced memory wavelet image compression proc 
data compress 
conf 
zeger image compression memory constrained printers proc 
icip oct 
zeger memory constrained wavelet image coding ieee signal processing letters sept appear 
misra prasanna parallel computation wavelet transforms proc 
th intl 
conf 
pattern recognition 
fast algorithms discrete continuous wavelet transforms ieee trans 
information theory vol 
pp 
mar 
recursive pyramid algorithm discrete wavelet transform ieee trans 
signal proc vol 
mar 
chakrabarti cient realizations discrete continuous wavelet transforms single chip implementations mappings simd array computers ieee trans 
signal proc vol 
pp 
mar 
van dyck marshall chin wavelet video coding ladder structures entropy constrained quantization ieee trans 
circuits systems video technology vol 
pp 
oct 
downtown clark parallel pipeline implementation wavelet transform proc 
inst 
elect 
eng vision image process vol 
pp 
dec 
fridman discrete wavelet transform data dependence analysis synthesis distributed memory control array architectures ieee trans 
signal processing vol 
pp 
may 
fridman scalability discrete wavelet transform multidimensional systems signal processing pp 

lopez zapata memory system supporting cient simd computation dimensional dwt proc 
icassp pp 

chakrabarti mumford cient realizations encoders decoders discrete wavelet transform ieee transactions vlsi systems 
jiang ortega parallel architecture dwt lifting factorization proc 
spie parallel distributed methods image processing iii july 
ortega jiang fernandez implementations discrete wavelet transform complexity memory parallelization issues proc 
spie wavelet applications signal image processing vii july 
jiang ortega cient dwt system architecture design factorizations proc 
icip oct 
marino jr parallel implementation discrete wavelet transform interprocessor communication ieee trans 
signal proc vol 
pp 
nov 
proc 
ieee special issue wavelets number 

vlsi architectures discrete wavelet transforms ieee trans 
vlsi system vol 
pp 
june 
lewis knowles vlsi architecture daubechies wavelet transform multipliers electronic letters vol 
pp 
jan 
vlsi architectures lattice structure orthonormal wavelet transforms ieee trans 
cas vol 
pp 
feb 
yang misra coarse grained parallel algorithms multidimensional wavelet transforms journal supercomputing vol 
pp 

bowers keith integrated controller electronics tech 
rep jet propulsion laboratory pasadena ca usa jan 
nielsen scalable parallel wavelet transform algorithm tech 
rep australian national university dec 
yang misra parallel wavelet transforms image processing workshop application parallel processing image processing aug 
anderson culler patterson team case networks workstations ieee micro feb 
www osc edu lam html 
spatially segmented wavelet transform tech 
rep ubc jtc sc wg wg 
hardman sasse handley watson reliable audio proc 
inet 
kovacevic goyal multiple description perceptual audio coding correlating transforms ieee trans 
speech audio processing 

tan zakhor multicast transmission scalable video receiver driven hierarchical fec proc 
packet video workshop new york apr 
zhang deering estrin shenker zappala rsvp new resource reservation protocol ieee network mag vol 
pp 
sept 
lin costello error control coding fundamentals applications prentice hall 
tanenbaum computer networks prentice hall 
davis joint source channel coding internet image transmission proc 
spie conf 
wavelet applications digital image processing xix aug 
davis song fast lossy internet image transmission proc 
acm multimedia conference san francisco ca 
sherwood zeger joint source channel coding internet image transmission proc 
dcc 
voice mobile radio ieee trans 
communications vol 
pp 
feb mar apr 

hsu ortega rate control robust video transmission burst error wireless channels ieee journal selected areas communications special issue multimedia network radios vol 
pp 
may 
jiang ortega parallel architecture dwt lifting factorization proc 
spie parallel distributed methods image processing iii denver july 
ortega jiang fernandez implementations discrete wavelet transform complexity memory parallelization issues proc 
spie wavelet applications signal image processing vii denver jul 
jiang ortega cient dwt system architecture design factorizations proc 
intl 
conf 
image processing japan oct 
jiang ortega lifting discrete wavelet transform system architecture design submitted ieee trans 
oct 
mallat theory multiresolution signal decomposition wavelet representation ieee trans 
patt 
anal 
mach 
intell vol 
pp 


lattice structures optimal design robust implementation channel perfect reconstruction qmf banks ieee trans 
acoust speech signal processing vol 
pp 
jan 
multirate digital lters lter banks polyphase networks applications tutorial proceedings ieee vol 
pp 
jan 
marshall zero phase lter bank wavelet coder matrices properties triangular decompositions fast algorithm multidimensional systems signal processing vol 
pp 

daubechies sweldens factoring wavelet transforms lifting steps fourier anal 
appl vol 
pp 

blahut fast algorithms digital signal processing addison wesley publishing 
report core experiment code complexity reduction tech 
rep motorola australia ubc jtc sc wg wg 
low memory line wavelet lifting scheme tech 
rep hp labs jtc sc wg wg 
low memory line wavelet transform lifting scheme tech 
rep canon research center france jtc sc wg wg 
engels optimal memory organization scalable texture codecs mpeg ieee trans 
circuits systems video technology vol 
pp 
mar 
adaptive non separable lifting transforms image compression proc 
icip kobe japan oct 
ortega line reduced memory wavelet image compression ieee trans 
image processing may accepted publication 
beylkin coifman rokhlin fast wavelet transforms numerical algorithms vol 
pp 

vetterli kovacevic wavelets subband coding prentice hall ptr englewood cli new jersey 
sweldens lifting scheme new philosophy biorthogonal wavelet constructions wavelet applications signal image processing iii laine unser eds 
pp 
proc 
spie 
hopcroft ullman automata theory languages computation addison wesley publishing reading massachusetts 
jiang ortega multiple description coding scaling rotation transform proc 
intl 
conf 
acoustics speech signal processing phoenix az mar 
jiang ortega karhunen loeve vector transform vector quantization tech 
rep signal image processing institute university southern california 
wang orchard reibman multiple description image coding noisy channels transform coe cients proc 
ieee workshop multimedia signal processing 
orchard wang vaishampayan reibman redundancy rate distortion analysis multiple description coding pairwise correlating transforms icip 
goyal kovacevic optimal multiple description transform coding gaussian vectors proc 
ieee data compression conference 
goyal kovacevic vetterli multiple description transform coding robustness erasures tight frame expansions proc 
ieee int 
symp 
info 
th aug 
goyal kovacevic vetterli multiple description transform coding images icip 
kovacevic multiple descriptions joint source channel codes 
li vector transform image coding ieee trans 
cas vt vol 
pp 
dec 
xia vector kl transform ieee trans 
cas vt vol 
pp 
aug 
ding optimal vector transform vector quantization ieee signal processing letters vol 
pp 
july 
golub van loan matrix computations john hopkins university press 
anil jain fundamentals digital image processing prentice hall information system sciences series 
prentice hall englewood cli nj 
press teukolsky vetterling flannery numerical recipes cambridge university press nd edition 
jiang ortega multiple description coding polyphase transform selective quantization proc 
visual communication image processing san jose ca jan 
jiang ortega multiple description speech coding robust communication lossy packet networks proc 
intl 
conf 
multimedia engineering new york ny july 
jayant christensen ects packet losses waveform coded speech improvements due odd sample interpolation procedure ieee trans 
communications vol 
com pp 
feb 

bolot garcia control mechanisms packet audio internet proc 
ieee infocom pp 


bolot garcia case fec error control packet audio internet appear acm multimedia systems 

bolot towsley adaptive fec error control internet telephony proc 
ieee infocomm vol 
pp 

podolsky romer mccanne simulation fec error control packet audio internet infocom san francisco ca mar 
tan zakhor real time internet video error resilient scalable compression tcp friendly transport protocol ieee trans :10.1.1.33.2192
multimedia vol 
pp 
june 
chou mohr mehrotra wang fec pseudo arq receiver driven layered multicast audio video proc 
data compression conf mar 
el gamal cover achievable rates multiple descriptions ieee trans 
information theory vol 
pp 
nov 
wolf wyner ziv source coding multiple descriptions bell system technical journal vol 
pp 
oct 
source coding problem channels receivers bell system technical journal vol 
pp 
dec 
jayant subsampling dpcm speech channel provide self contained half rate channels bell system technical journal vol 
pp 
dec 
zhang berger new results binary multiple descriptions ieee trans 
inform 
theory vol 
pp 

zhang berger multiple description source coding excess marginal rate ieee trans 
inform 
theory vol 
pp 

vaishampayan dpcm system design diversity systems applications packetized speech ieee trans 
speech audio processing vol 
pp 

ramchandran vaishampayan nahrstedt multiple description wavelet image coding icip 
vaishampayan design multiple description scalar quantizers ieee trans 
information theory vol 
pp 

vaishampayan 
asymptotic analysis multiple description quantizers ieee trans 
information theory vol 
pp 
jan 
ortega cient context entropy coding lossy wavelet image compression proc 
dcc snowbird ut mar 
miguel mohr generalized multiple description coding proc 
icip 
puri ramchandran multiple description source coding forward error correction fec codes 
mohr ladner generalized multiple description coding unequal loss protection proc 
icip 
said pearlman low coding alphabet sample set partitioning proc 
san jose ca jan 
gersho gray vector quantization signal compression prentice hall information system sciences series 
prentice hall englewood cli nj 
ramchandran orchard wavelet image coding rate distortion optimized backward adaptive classi cation proc 
san jose ca jan 
wang wu lin zerotree multirate wavelet image coding method acta sinica vol 
pp 
apr 
said pearlman new fast cient image codec set partitioning hierarchical trees ieee transactions circuits systems video technology vol 
pp 
june 
kokkinakis speech enhancement audio noise suppression ieee trans 
speech audio processing pp 

jiang adaptive speech noise removal tech 
rep microsoft research aug 
mccanne scalable compression transmission internet multicast video tech 
rep ph thesis ucb csd university california berkeley 

