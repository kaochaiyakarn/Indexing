reprinted international journal computer simulation vol 
pp 
efficient simulation parallel computer systems covington jet propulsion laboratory ms oak grove drive pasadena ca dwarkadas jump sinclair department electrical computer engineering rice university houston texas coherent systems bay area blvd suite houston tx ongoing research project involves design evaluation software system simulating parallel computers 
major goal development system avoid high overhead associated conventional instruction level simulation sequential computers retain accuracy technique derived execution real programs 
resulting system program driven overhead significantly reduced profiling program get timing estimates basic blocks run time generate process execution times dynamically avoiding detailed emulation instruction execution 
number experiments dealing message passing computer systems performed order determine level accuracy expected performance predictions measure overhead 
index terms architecture models efficiency parallel computers parallel programs performance simulation testbed validation 
research supported texas instruments 
ti rj nsf onr 
contract 
nasa 
nag shell doctoral fellowship 

significant trends high performance computing development widespread parallel processing systems 
created need accurate efficient tools evaluate performance parallel systems realistic workloads 
tools allow system designer programmer study interactions hardware software goal obtaining better match parallel computing system programs executes 
describes design evaluation set software simulation tools called rice parallel processing testbed rppt developed purpose 
conventional way simulate execution programs computer host computer emulate detail effect executing instructions target computer 
approach commonly referred instruction level simulation 
advantage detailed information behavior proposed target architecture obtained 
programs written target processor executed instruction level simulator determine behave executed target processor 
timing information execution programs target processor obtained required degree accuracy increasing detail individual instructions target processor emulated 
main disadvantage type simulation number host instructions executed emulate single target instruction overhead increases level emulation detail implemented 
uncommon hundreds host instructions just emulate target instruction 
consider simulation parallel computing systems composed interacting processors amount overhead incurred instruction level simulation intolerable 
number instructions emulated increase number processors time required simulate interconnection structure provide communication paths processors significant additional factor 
parallel computing systems nontrivial processors currently available systems proposed 
instruction level simulation parallel systems need simulation techniques produce accurate performance predictions prohibitively large overhead instruction level simulation 
way reduce complexity instruction level simulation parallel computers probabilistic models represent behavior program 
call approach distribution driven simulation 
eliminates entirely high cost emulating target processor instructions 
simulation driven statistical approximation program behavior execution actual program approach predict detailed execution behavior system usually limited high level comparisons different architectures 
technique effectively study uniprocessor architectures trace driven simulation 
program executed computer instruction set target processor trace program execution information event record collected 
trace data drive simulation proposed architecture 
highly accurate form simulation trace data derived actual execution program instruction driven approach 
simulate architectures similar produce trace 
technique useful study memory organizations especially cache memories 
unfortunately technique extend simulation parallel computers processors generate trace 
efficient parallel simulation multiprocessor caches address traces problem variations timings delays system affect ordering events events occur traces longer valid 
execution driven simulation relatively new simulation technique produce performance predictions nearly accurate obtained instruction level simulation fraction overhead method 
combines properties trace driven instruction level simulation 
program driven execution real program drive simulation 
instruction level simulation execution individual target machine language instruction emulated execution host instructions host target machines identical nearly execution driven simulation simply executes machine language instructions program directly simulation host 
similar techniques basic concept exploited execution driven simulation proposed 
principle disadvantage execution driven simulation timing details instruction execution lost individual instructions emulated 
result time required execute sequence instructions predicted accurately simulation 
errors due usually quite small 
simulation offers compromise high cost accuracy instruction level simulation speed relatively lower accuracy distribution driven simulation 
reports research aimed evaluating effectiveness simulation 
goal develop complete simulation testbed technique perform experiments provide quantitative evaluation accuracy efficiency 
major result effort rice parallel processing testbed rppt sophisticated powerful simulation system investigate number performance issues concerning execution concurrent programs parallel computing systems 
rppt simulation models architectures written different levels detail permitting user trade accuracy computational efficiency 
architecture models driven executions real programs data dependent computation times interprocess communications synchronization delays architecture specific timing information accounted high degree accuracy 
important feature rppt flexibility 
architecture models parallel programs decoupled algorithm designer test different algorithms fixed architecture model 
possible study performance single algorithm systems fundamentally different basic architectures shared bus multiprocessor vs multiprocessor multistage interconnection network hypercube 
especially important study new concurrent architectures particularly intended specific dedicated applications 
major advantage claimed execution driven simulation compared simulation efficient small loss accuracy important evaluate claim 
conducted number experiments rppt measure accuracy efficiency 
efficiency investigated measuring time required simulate single processor execution parallel program parallel system 
time compared time required simply execute program pseudo concurrent environment testbed host 
ratio simulation time execution time called slowdown ratio gives indication amount overhead introduced simulator 
investigate accuracy rppt measured time required execute parallel programs algorithms real parallel system compared times predicted rppt simulating programs simulation model parallel system 
section presents definition description execution driven technique including process profiling insert timing instructions parallel program drive simulation 
section describes organization rppt 
results experiments validate performance measure efficiency rppt section 
execution driven simulation execution driven simulation execution program simulation model architecture interleaved 
process selected executed process interaction point encountered 
process interaction point state process execution immediate behavior timing potentially depends actions process es 
examples process interaction points include sending receiving messages distributed memory systems access shared variables shared memory multiprocessors 
second data movements processors due interaction simulated simulation time advanced 
steps repeated servicing processes process terminates simulation stopped 
major advantage approach overhead required simulate activity processor interactions processors simulated detail 
words logical process activity internal single processor accounted simply executing parts process host computer 
overhead due need maintain event list simulate data movement encountered points processes interact 
fig 
illustrates execution driven simulation differs instruction level simulation 
term basic block third box refers sequence assembly language instructions instructions sequence executed order exactly time block entered sequence contained larger basic block 
basic blocks labeled instruction immediately branch instruction terminate branch instruction just labeled instruction 
basic blocks defined hll source programs analogous way 
boxes marked asterisks simulation techniques differ 
instruction level simulation replaces execute emulate basic block instruction indicated parenthesized words boxes 
box shows simulator performs detailed emulation instruction execution driven simulation simply executes instructions basic block reached 
emulation single target instruction requires execution host instructions complex processors 
accounts significant reduction simulation overhead execution driven simulation relative instruction level simulation 
instruction level simulation overhead associated instruction labeled branch instruction require interaction process 
instructions branch labeled incur small overhead increment cycle count 
simulated process needs interact process significant overhead incurred 
time event queue insertion processed user supplied program defines interconnection network structure executed 
way elapsed time accumulated process interaction points cycle count variable accounts high accuracy execution driven simulation 
guarantees conditional branches program evaluated executed data dependent properties program taken account simulation 
gives rise accurate representation system workload process interaction points occur proper sequence proper simulation time 
increment cycle count number cycles needed execute basic block instruction switch process processor schedule delay current processor time proportional accumulated cycle count 
program reached process interaction point 
execute emulate basic block instruction start set cycle count select process processors fig 

execution driven instruction level simulation execution cycle 
instructions manipulate cycle count variable inserted start basic block source program utility program called profiler 
profiler perform functions 
detects basic blocks assembly language source 
basic block profiler examines instructions uses information instruction timings compute estimate amount time required execute instructions block 
estimate inserted source program form instructions basic block boundary increment cycle count amount estimate block 
program executed inserted instructions executed dynamically maintain timing estimate sequence basic block executions program 
call standalone native profiling modified assembly language program executed directly processor basic block timing estimates obtained 
run time overhead occurs basic block boundaries typically results relatively low slowdown ratio usually 
accuracy limited profiler ability estimate accurately time required basic block 
important consequence standalone profiling instruction set target processor instruction set host processor 
possible convenient host processor instruction set target processor cross profiling technique developed 
approach compilers common source language target host machines required 
target compiler cross compiler run host machine native compiler running target machine 
call assembly language outputs target host compilers target assembly language representation host assembly language representation respectively 
cross profiling assumes close correspondence basic blocks source code level basic blocks assembly language level 
correspondence rarely exact practice usually close establish nearly correspondence blocks different assembly language representations 
basic block source code corresponding block 
correspondence assembly language representations incorporate information timing analysis assigning cycle counts derived basic blocks corresponding basic blocks 
differences basic block structures source program assembly language representations frequently due redundant basic blocks assembly code correspond basic block source program unlabeled 
similar type mismatch basic blocks caused compiler producing unnecessary basic blocks produced compiler 
example basic block entered result jump basic block consequently executed sequence 
differences eliminated performing basic block reduction coalesces certain blocks graphs changing control flow 
note basic block reduction value standalone profiling removes dynamic time accounting overhead basic blocks combined 
experiments sun workstation host processor cross profilers different target processors different compilers compared total accumulated cycle counts sequential programs cycle counts native profiling programs data 
experiments showed errors due mismatched basic blocks block reduction ranged 
cross profiling technique illustrated fig 

step detect basic blocks hll source program mark unique label 
source program compiled twice 
basic block labels source program passed assembly language code unchanged compiler 
correspondence basic blocks assembly language representations established matching identical labels representations 
host assembly language program timing estimates profiled target assembly language program insertion cycle counting instructions basic block matching timing profiler target processor basic block analyzer target processor basic block analyzer host processor source program compiler target processor compiler host processor target assembly language representation host assembly language representation source code marking fig 

cross profiling 
basic block structures identified reduced basic block analyzers timing analysis performed produce estimates number cycles needed execute basic block 
timing analysis performed timing estimates simulation performed 
basic blocks paired basic block labels 
instrumented cycle counting instructions way standalone profiler 
cross profiling incremental values counting instructions produced timing analyses 
simulation model executed timing estimates provided profiled program reflect program execution time target processor simulation host 
simulators utilize execution driven simulation fujimoto simon simulation system 
uses form execution driven simulation called native mode execution allow efficient evaluation performance parallel programs executing multiprocessors 
fujimoto developed technique simulating systems host target processors different instruction sets 
approach dealing heterogeneous host target processor instruction sets similar utilized rppt described 
basic concept inherent execution driven simulation williams simulate processor cray mp simulator running processors cray mp 
measured user code execution times drive simulation 
execution driven approach proposed means dynamically generating interleaving multiprocessor traces 
discuss methods trace interleaving uniprocessor simulations multiprocessor systems refer approach execution driven simulation fly tracing 
computer architect workbench uses execution driven simulation techniques study relative performances variety uniprocessors 
program source language compiled intermediate code analyzed basic blocks timing estimates set assumptions target processor architecture code translated assembly language code simulation host processor 
important feature workbench offers user choice application source languages pascal fortran 
simple care developed knowledge systems laboratory stanford eventbased simulation system studying performance multiprocessors multicomputers processors primary focus parallel expert systems 
applications programming interface simple care built 
execution objects applications assigned fixed execution times simulation host clock dynamically determine 

rice parallel processing testbed perform simulation rppt user supply components program module architecture model process mapping rppt assign processes parallel program physical processors architecture 
specified rppt assembles rppt simulation module executed perform actual simulation obtain performance timing information specified program executing specified architecture 
module executed produces types output data 
generates trace data characterizes history program execution primarily debugging 
second produces information event times resource utilizations generate performance metrics interest 
types trace timing data collected specified user part program architecture models 
program modules architecture models developed placed libraries 
rppt user assemble simulation module selecting program modules architecture models libraries 
may programs appropriate architectures usually written general way relatively independent 
true programs architectures message passing communication processors 

rppt architecture models parallel architecture model rppt consists processor modules usually local memory global memory modules interconnection structure provides communication paths processor memory modules 
rppt simulate internal behavior processors major component specified define architecture model interconnection structure 
fact architecture model rppt defined specifying number processor memory modules writing simulation program named specifies behavior interconnection structure processor memory modules interconnected 
type processor thought part architecture specification select appropriate profiler part program module 
written simulation language called csim 
general purpose discrete event simulation language uses process interaction approach implemented extension concurrent see section set procedures event queue manipulation statistics collection 
primarily library subroutines implement various simulation functions processes simulation model 
instance process may suspend execution specific simulation time may schedule process activated simulation time may delay execution particular condition true 
ability delay condition value csim powerful features 
conditions language expressions involving state variables defined user variables describing states csim objects semaphores queues 
csim provides statistics collection mechanisms simulation trace facility 
models overhead accessing interconnection network effects contention due multiple simultaneous users network transmission time message 
simple case shared bus communications channel modeled fifo queue service time proportional message length may quite complex example describe activity multistage interconnection network 
writing concerned details implementation parallel system 
written parameters characterize behavior structure interconnection structure bus channel bandwidth specified run time parameters 
parameters specified rppt just assembles simulation module allowing user collect data range program parameters architecture module time parameter changed 
processor modules constructed writing simulation code emulates internal operation processor 
timing profiler knows instruction times processor modifies program simulated inserting cycle counting instructions described section 
effect processor module embedded program module described section rppt user needs specify number processors architecture module 
global shared memory modules difficult simulate efficiently access times predicted accurately profiler due contention interconnection module memory modules 
consequently detailed memory simulator called access global memory happen times basic block 
significantly reduce efficiency gains derived execution driven approach 
result concentrated initially message systems global memory 
discussion simulation problems due global memory proposed solutions 

rppt program modules process mappings parallel programs rppt usually written language called concurrent cc presto parallel version fortran message passing paradigm 
concurrent extension programming language provides primitives process control communication 
implemented library subroutines predefined data types extend standard language provide pseudo concurrent execution environment 
processes defined concurrent run address space context switches incur relatively little overhead 
user create activate suspend fork join processes 
process interact processes sending receiving messages asynchronous synchronous message passing supported semaphores 
processes created global data declared concurrent program assigned logical nodes specific processors memory modules allowing user write concurrent program prior knowledge specific details architecture program executed 
greatly simplify task evaluating performance single parallel program different architectures 
user specifies mapping logical nodes physical nodes processors memory modules basic components rppt simulation module 
processes assigned logical node guaranteed execute physical node 
assigned different logical nodes may assigned physical node logical physical node mapping 
concurrent programs written run time parameters simplify simulation program range data sizes program options 
architecture models parameters rppt assemble specific simulation module 
fig 
shows procedure converting concurrent program rppt program module 
uses rppt components serve translators converting programs form inserting information needed simulate execution original program 
operation translators summarized 
architecture simulation preprocessor source code translator modifies concurrent programs inserting primitives simulate architecture delays due communication synchronization processors 
essentially converts parallel program simulation program knows architecture simulated 
scanning program find points process interacts process accesses global memory module 
point inserts code logical physical node mapping run time decide operation requires data communication including access shared variables synchronization processors 
inserted code call procedure simulate data movement 
complete operation calling appropriate concurrent routine 
profiled assembly language program rppt program module assembly language program assembler compiler csim program concurrent program fig 

conversion concurrent program program module 
timing profilers standalone profiler cross profiler type described section 
combination accurately accounts simulation time resource contention interprocessor communication accounts elapsed time due instruction execution processors 
modified source language program produced compiled compiler timing profiler analyzes assembly language output compiler inserts counting instructions accumulate execution time basic blocks 
profilers bb profiler developed bell labs 
separate cross profiler needed target instruction set different simulation host 
processor rppt host target processor need standalone profiler 
rppt ported new host system need new profiler host need new target code profilers 
cases desirable allow user directly specify execution time procedure 
example may way user account amount simulation time various operating system calls require source code unavailable 
implement profilers designed selected procedures left unprofiled 
user specify function calculate time taken execute procedure time executed 

rppt simulation modules construction rppt simulation module illustrated fig 

done basic rppt component simulation tool interface 
main user interface rppt 
menu driven window oriented program runs sun workstation simplifies task combining program module architecture model node mapping simulation module 
developed provide user structured guide process constructing simulation module 
prompts user select program module architecture model libraries 
simulate architecture program available libraries user construct modules described place libraries 
prompts user parameters needed architecture model program module 
asks specification node mapping 
specifying file contains mapping entering formula translate logical node number physical node number 
possible specify trace data generated directed 
collected file analysis piped process level debugger run time display process activity 
rppt simulation module linker architecture library program library architecture parameters process mapping program parameters user entered fig 

construction simulation module 
inputs entered assembles simulation module passes linker links unprofiled procedures implement concurrent csim primitives 
final result module executed perform simulation produce trace timing data 

simulation tracing debugging debugging parallel programs considerably difficult debugging serial programs 
multiple threads execution synchronization add complications normally finds serial programs 
traditional symbolic debuggers serial programs typically allow user step execution program examine modify state program point 
straightforward application strategy debugging parallel programs results flooding user large amount information 
true parallel system possible take snapshot state processes simultaneously require global synchronizing mechanism 
problems due multiple threads execution imply effective debugger able help user keep track multiple processes information usable manner 
user glance able perceive state important processes able specify information processes considered relevant 
instance experience suggests incorrect synchronization processes common error parallel programs 
parallel debugger allow programmer select information synchronization points process lifetime display 
trace debug tool rppt programs 
takes trace information generated simulation displays traces different processes separate windows sun workstation 
trace information consists significant events lifetime process process creation termination synchronization processes means semaphores message passing 
event displayed process window time stamped simulation time occurrence 
generation input data simulation non intrusive approach offers significant advantages techniques generating similar data real machines 
addition instructions necessary produce collect trace information change behavior simulated system affecting process execution times occur real system 
monitor program architecture activity program modules architecture models include statements generating various types trace information 
simulations rppt deterministic repeatable 
parallel program execute correctly information produces sufficient isolate problem simulation repeated generate additional trace information sure behavior simulated system change 
contrast debugging real parallel systems insertion additional code attempt find bug may fact mask original bug create problems 

rppt performance rppt effective tool studying parallel systems produce accurate performance measurements reasonable efficiency 
consequently major ways difficult part rppt development validation simulator performance predictions measurements obtained real systems 
section describes validation experiments conducted presents results accuracy efficiency simulations 
choices real systems validation studies limited parallel systems available 
node intel ipsc hypercube multiprocessor lcmp set sun workstations interconnected ethernet running distributed system kernel 
system ideal purpose 
major problem common lack high resolution clock 
ipsc difficult interprocessor communication mechanism caused interference delayed user processes executing processor nodes 
especially true multi hop interprocessor communications communications source destination nodes directly connected 
workstations system studies connected ethernet served large number systems possible completely sure background communication traffic biasing validation results 
large number parallel programs developed rppt chose numeric non numeric programs validation effort 
case algorithms executed real system input data set sizes 
usually largest number processors available systems cases smaller numbers processors 
algorithm executions simulated rppt running sun workstation 
architecture simulation model timing profiler fixed 
studies required cross profiling 
processors ipsc intel pairs 
compiler runs ipsc assembly language output inserted native profiler marks cycle counts transferred hypercube sun workstation basic block matching 
processors running system identical host processor system compiler unix compiler identical requiring cross profiling step performed 

hypercube validation intel ipsc hypercube distributed memory multiprocessor nodes pair local memory 
node physically connected nodes 
nodes communicate message passing 
messages longer kbyte broken packets length kbyte transmission 
node sends message node directly connected sender packets relayed node multi hop path sender receiver 
hop packet completely received intermediate node forwarded hop 
act relaying packet requires intermediate processor interrupt currently executing process time required examine received packet arrange forward 
csim architecture model ipsc studies uses fixed message routing scheme ipsc 
correctly breaks message packets necessary 
time transmit message includes software overhead break message packets sender reassemble receiver time transmit packets communication links paths time process packet intermediate nodes path 
model correctly take account delay experienced user process interrupted packet forwarded node process executed 
overhead apparently roughly constant packet length performance predictions algorithms involve transmission relatively large number multi hop packets strongly affected modeling inaccuracy 
number algorithms implemented ipsc simulated rppt ipsc model 
validation results representative parallel programs executed ipsc 
eigenvalue eigenvector computation lu decomposition radix fft fast fourier transform mergesort global distribution local sort gdls 
algorithms numerically intensive include little arithmetic simple integer comparisons 
details algorithms theses 
eigenvalue eigenvector computation eigen characterized single packet communication patterns occasionally multi hop transmissions 
program broken components 
tridiagonal reduction splits data number processors parts processed 
small data sizes communication aspects dominate data sizes get larger processor relatively computation unit communication eventually computation dominates 
second component eigenvalue estimation phase communication occurs infrequently third component qr iteration phase entirely computation intensive 
components iterative run times determined data convergence criteria 
tridiagonal reduction takes time proportional size data 
lu decomposition algorithm largely characterized single packet single hop message transmissions occasional multi hop communications 
consists parts lu decomposition behaves somewhat tridiagonal reduction described back forward substitution step communication intensive 
fft algorithm highly compute bound communication nearest neighbor directly connected nodes 
parallel mergesort algorithm involves partitioning data sets sorted sequentially processors 
goes log iterations data merged successively larger sets 
iteration begins communication phase single packet messages sent paths grow longer successive iterations 
phase followed series message transfers involving large amounts data fairly random number hops 
communication real computation real data size communication simulation computation simulation fig 

validation eigenvector eigenvalue ipsc processors 
fig 
shows results eigen algorithm input matrix size varying 
graph breaks total execution time computation time communication time real system program execution simulated execution 
expected computation time dominates entire range 
contrast results obtained lu decomposition fig 
communication time dominates small data sizes arrays significant factor computation component increasing rapidly communication 
fft algorithm fig 
completely dominated computation time accuracy rppt simulations determined entirely timing profiler accuracy 
simulation accuracy floating point intensive algorithms shown figures 
relative error difference execution times predicted simulator measured ipsc normalized measured execution time 
relative error algorithms eigen error virtually constant 
communication real computation real data size communication simulation computation simulation fig 

validation lu decomposition ipsc processors 
data size communication real computation real communication simulation computation simulation fig 

validation fft ipsc processors 
eigen procs 
lu procs 
data size fig 

relative errors numeric algorithms ipsc 
data size fig 

relative errors fft ipsc processors 
results non numeric algorithms shown figures 
figures compare measured simulated execution times sorting algorithms implemented ipsc 
parallel mergesort algorithm communication time dominates problem sizes inaccuracies ipsc model greater impact simulator predictions seen fig 
relative error approximately 
results look somewhat better gdls especially large data sizes error remembered may cancellation architecture modelling profiling errors 
data size real simulation fig 

validation gdls ipsc processors 
data size communication real computation real communication simulation computation simulation fig 

validation merge sort ipsc processors 
gdls procs 
ms procs 
data size fig 

relative errors sorting algorithms ipsc 

lcmp validation lcmp difficult validation purposes 
workstations lcmp connected public ethernet communication times greatly affected non lcmp traffic 
architecture model lcmp shared bus collision detection backoff take account possibility collisions non lcmp traffic 
minimize modeling discrepancies possible validation experiments performed ethernet expected lightly loaded 
experiment run times minimum execution time run chosen match results rppt model 
data size real simulation fig 

validation fft lcmp processors 
addition radix fft gdls algorithms described fast hadamard transform fht 
fht utilizes floating point adds extensively relatively little communication fft 
lcmp best suited algorithms coarse grain type parallelism 
results fft fht similar figures 
primarily reflection accuracy timing profiler cross profiling technique architecture model 
clearly shown fig 
relative accuracy stays exception 
somewhat inconsistent point data set size fht may largely due background traffic ethernet 
relative errors tend larger gdls figures larger data sizes error approaching 
data size real simulation fig 

validation fht lcmp processors 
fft procs 
fht procs 
data size fig 

relative errors transforms lcmp 
data size real simulation fig 

validation gdls lcmp processors 
data size fig 

relative errors gdls lcmp processors 

rppt efficiency rppt simulation introduces types overhead execution parallel program 
profiling overhead instructions inserted timing profiler accumulate cycle counts process interaction points 
simulating distributed memory multiprocessors caches overhead generally fairly small vary great deal program 
function average size basic block program programs frequently instructions larger execution times example floating point 
second type overhead due architecture simulation 
process interaction point message send receive inserts call routine determines interaction remote process invokes architecture model account time accomplish remote interaction 
type overhead highly variable influenced heavily structure program complexity architecture model 
programs processes communicate frequently incur significantly higher overheads rppt applications programs processes computation intensive 
overhead depend strongly amount data transferred 
rppt efficiency measured slowdown ratio determined ratio time required execute rppt simulation program execution time required execute parallel program standalone cc application 
cc provides pseudo parallel runtime environment unprofiled user program executed 
message passing parallel programming primitives incur little overhead pseudo parallel processes share address space architecture simulation overhead incurred 
table presents slowdown ratios algorithms described 
brevity included single data point algorithm maximum number processors algorithm large data size 
slowdown ratios smaller data sizes tend larger overhead involved starting rppt simulation independent length simulation 
slowdown ratios range exception 
result lu decomposition algorithm slowdown ratio due poor structure algorithm sends large numbers relatively short messages processors decomposition phase especially subsequent back forward substitution phase 
note parallel mergesort algorithm slowdown ratio fig 
shows worse computation communication ratio lu decomposition algorithm 
mergesort uses relatively long message transfers account large amount simulated time take little time simulate 
radix fft fht gdls eigen mergesort lu decomposition radix fft gdls algorithm number processors size problem slowdown table 
rppt slowdown results 

main goal research reported demonstrate effectiveness relatively new simulation technique called execution driven simulation simulating parallel computer systems 
technique characterized higher accuracy distribution driven simulation better efficiency instruction level simulation 
effectiveness technique demonstrated implementing sophisticated powerful simulation system called rice parallel processing testbed rppt 
rppt confirms claimed advantages execution driven simulation useful tool investigating relationships structures parallel algorithms different parallel computer organizations 
study effect system performance major minor changes structure parallel architecture 
architecture evaluate relative performance different parallel algorithms effect minor changes algorithm 
result provides powerful quantitative tool matching parallel algorithms architectures optimize total system performance 
experimental results section major contribution 
result extensive experiments designed measure accuracy efficiency execution driven approach 
variations different message architectures hypercube loosely coupled distributed system investigated 
numeric non numeric parallel programs drive simulations 
results verify advantages claimed execution driven technique 
accuracies rppt predictions determined comparing measurements time execute parallel programs real parallel systems predictions execution times produced rppt 
comparisons demonstrated differences cases equal cases size data manipulated programs large mask startup effects 
efficiency rppt evaluated measuring overhead added program execution time simulation code added preprocessors 
represented ratio time required execute program inserted simulation statements time required execute 
ratio called slowdown ratio shown range architectures programs 
compares favorably slowdown instruction driven simulations range hundreds 
execution driven simulation limited accuracy primarily degree detail incorporated architecture model ability profiler determine basic block timings precisely 
especially important dealing cache memories range tradeoffs efficiency accuracy 
simulation parallel processor sequential processor means execution parallel program driving simulation necessarily serialized 
affect correctness results affect time execute simulation 
serious problem real program executed memory needed hold program text data parallel processor 
may limit size simulation experiment virtual memory environment constraints amount physical memory swap space 
rogers george norton pfister system parallel simulation execution parallel programs research report rc ibm watson research center jan axelrod dubois simulator mimd performance prediction application multiprocessor parallel computing vol 
pp 

butler facility simulating multiprocessors ieee micro vol 
pp 
oct 
archibald 
baer cache coherence protocols evaluation multiprocessor simulation model acm trans 
computer systems vol 
pp 


lin 
baer lazowska tailoring parallel trace driven simulation technique specific multiprocessor cache coherence protocols proc 
scs multiconference distributed simulation 
eggers lazowska 
lin techniques trace driven simulation cache performance proc 
winter simulation conference dec pp 

dubois briggs patil balakrishnan trace driven simulations parallel distributed algorithms multiprocessors proc 
international conference parallel processing aug pp 

covington mehta jump sinclair rice parallel processing testbed proc 
acm sigmetrics conf 
measurement modeling computer systems santa fe nm may pp 

fujimoto simon simulation development system proc 
summer computer simulation conference july pp 

flynn mitchell mulder case complex instruction sets computer vol 
pp 
sept 
williams speedup predictions large scientific parallel programs cray mp architectures proc 
international conference parallel processing aug pp 

covington validation rice parallel processing testbed applications ph dissertation electrical computer engineering department rice university dec 
covington jump sinclair cross profiling efficient technique simulating parallel computer systems proc 
ieee th ann 
int 
computer software applications conf orlando fl jan pp 

fujimoto campbell direct execution models processor behavior performance proc 
winter simulation conference dec 
lang block actions generator alternative simulator collecting architecture measurements proc 
sigplan symposium interpreters interpretive techniques st paul mn july pp 

nishimura byrd instrumented architectural simulation system rept 
ksl knowledge systems laboratory computer science department stanford university jan nishimura byrd care applications interface knowledge systems laboratory computer science department stanford university jan covington jump csim users guide tech 
rpt 
tr electrical computer engineering department rice university feb dwarkadas jump sinclair efficient simulation cache memories proceedings winter simulation conference washington dec pp 

concurrent users manual tech 
rept 
electrical computer engineering department rice university oct bershad lazowska levy presto system object oriented parallel programming tech 
rept 
computer science department university washington sept weinberger cheap dynamic instruction counting bell systems technical vol 
pp 
oct 
cheriton kernel software base distributed systems ieee software vol 
pp 
apr 
validation rice parallel processing testbed sorting algorithms thesis electrical computer engineering department rice university april 
mehta performance prediction fast fourier transform algorithms loosely coupled multiprocessors thesis electrical computer engineering department rice university may 
lauderdale performance prediction packet switched multistage interconnection networks execution driven environment thesis electrical computer engineering department rice university sept 
