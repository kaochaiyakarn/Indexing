transparent dynamic optimization bala evelyn duesterwald sanjeev banerjia hp laboratories cambridge hpl june mail vas hpl hp com dynamic optimization compilers code cache runtime optimization performance copyright hewlett packard dynamic optimization refers runtime optimization native program binary 
describes design implementation dynamo prototype dynamic optimizer capable optimizing native program binary runtime 
dynamo realistic implementation simulation written entirely user level software runs pa risc machine operating system 
dynamo depend special programming language compiler operating system hardware support 
program binary instrumented left untouched dynamo operation 
dynamo observes program behavior interpretation dynamically select hot instruction traces running program 
hot traces optimized low overhead optimization techniques emitted software code cache 
subsequent instances traces cause cached version executed resulting performance boost 
contrary intuition demonstrate possible piece software improve performance native statically optimized program binary executing 
dynamo speeds real application programs performance improvement quite significant 
example performance optimized specint binaries running dynamo comparable performance optimized version running dynamo 
transparent dynamic optimization bala evelyn duesterwald sanjeev banerjia hewlett packard labs cambridge ma dynamic optimization refers runtime optimization native program binary 
describes design implementation dynamo prototype dynamic optimizer capable optimizing native program binary runtime 
dynamo realistic implementation simulation written entirely user level software runs pa risc machine operating system 
dynamo depend special programming language compiler operating system hardware support 
program binary instrumented left untouched dynamo operation 
dynamo observes program behavior interpretation dynamically select hot instruction traces running program 
hot traces optimized low overhead optimization techniques emitted software code cache 
subsequent instances traces cause cached version executed resulting performance boost 
contrary intuition demonstrate possible piece software improve performance native statically optimized program binary executing 
dynamo speeds real application programs performance improvement quite significant 
example performance optimized specint binaries running dynamo comparable performance optimized version running dynamo 
trends software technology increased obstacles effective static compiler optimization 
object oriented programming languages resulted greater degree delayed binding modern software reducing size static scope available traditional compiler 
shrink wrapped software increasingly shipped collection dlls dynamically linked libraries monolithic binary 
dlls offer advantage able ship software patches customer product sale addition easing integration third party middleware product 
unfortunately traditional compiler optimization operates statically bound scope program difficult 
compiler optimization performance delivery mechanism complicated prevalence legacy binaries 
recompilation clearly impractical means improving performance huge volumes legacy software 
emerging internet mobile communications marketplace 
networked device code downloaded linked fly role traditional performance delivery mechanisms static compiler optimization unclear 
effectiveness conventional model performance delivery task divided microprocessor hardware static compiler software limited emerging computing environment 
propose radically different performance delivery mechanism applied time native bits executed microprocessor native bits created compiler 
refer dynamic optimization principle similar superscalar reorder buffer modern microprocessor runtime optimization native instruction stream 
contrast hardware dynamic optimizer scheme works entirely software retains transparent nature hardware dynamic optimization 
implemented realistic prototype called dynamo demonstrates feasibility idea represents culmination years research conducted hewlett packard labs bala freudenberger bala 
dynamo transparent dynamic optimizer performs optimization runtime native program binary 
dynamo depend special compiler operating system hardware support rely annotations input program binary 
uses interpretation means observing program behavior having instrument 
information written program execution consultation run 
profiling information consumed fly dynamically select hot instruction traces program 
hot traces optimized low overhead optimizer placed software code cache 
subsequent occurrences traces cause cached version executed giving performance boost 
loaded binary image program code untouched dynamo allowing handle programs modify text image 
input program may arm signal handlers 
operation dynamo essentially transparent enduser 
dynamic optimization intended replace static compiler optimization part complementary 
static compiler optimizer performs optimizations static scope program dynamic optimizer operates dynamic scope program runtime objects bound 
contrast just time jit compiler translation component involved input native instruction stream 
dynamic optimizer viewed performing minute optimization frequently executed instruction sequences running program 
allows perform optimizations dynamically linked procedure call boundaries virtual function calls difficult static compiler 
perform runtime path specific optimizations having extensive code duplication separate path surrounding control flow 
dynamic optimization opportunities exist programs compiled highest static optimization levels 
presents overview dynamo system highlights technology innovations 
comprehensive treatment bala 
dynamo prototype implemented pa risc platform pa workstation running 
written combination assembler entire code footprint kbytes 
implementation takes advantage features pa instruction set architecture improve efficiency certain functions rely operation 
data integer benchmarks running dynamo compare performance identical binary running directly processor 
chose integer benchmarks inherent control flow complexity optimization challenging relatively regular floating point codes 
show selected specint benchmarks running inputs code called deltablue incremental constraint solver configured solve constraints sannella 
specint benchmark gcc included benchmark set shown spec version script repeatedly invokes gcc number different inputs 
program run mins pa dynamo able provide performance benefit gcc benchmark long running dynamo sees collection separate runs gcc short optimize profitably 
behavior custom monolithic version gcc benchmark running dynamo closely matches go data shown 
programs exception deltablue compiled product hp compiler default optimization level equivalent 
deltablue compiled produced faster running binary hp compiler 
performance data actual wall clock times running binary dynamo compared identical binary running directly pa 
dynamo works shows high level outline dynamo works 
dynamo starts interpreting input program instructions box 
input program native executable supervisor mode programs create complications current prototype handle reliably 
invoke dynamically linked libraries shared libraries system calls 
arm signal handlers 
interpreter native instruction interpreter implemented software 
interpretation primarily means observing program behavior having instrument program binary 
side effect interpretation dynamo increments counters associated certain program addresses satisfy start trace condition interpretation backward taken branch boxes 
path counter update path represent operation interpreter normal mode 
counter value exceeds hot threshold box interpreter toggles state goes trace generation mode box 
interpreting mode native instruction corresponding interpreted instruction emitted buffer 
path represents trace generation interpretive loop 
condition reached contents buffer optimized fast lightweight optimizer box 
optimizer trace instructions executable unit called fragment performs lightweight optimizations fragment hands linker box 
linker emits optimized fragment code software code cache called fragment cache links fragments cache 
fragment tagged program address corresponding instruction sequence 
start interpret branch signal handler signal lookup branch target cache hit jump top fragment cache context switch fragment cache emit cache link fragments recycle associated counter start trace condition 
increment counter associated branch target addr create new fragment optimize dynamo works counter value exceeds hot threshold interpret codegen branch trace condition 
dynamo time interpreter interpreting normal mode interprets branch instruction fragment cache lookup done check fragment exists tag equal branch target pc box 
program addresses satisfy start condition entry points control fragment cache 
control jumps interior fragment 
fragment cache hit control jumps top fragment causing fragment code may linked execute directly underlying processor box 
point execution dynamo effectively suspended program instructions optimized version software fragment cache executing directly processor 
optimized fragments fragment cache gradually start populating underlying processor instruction cache giving performance boost 
eventually branch exits fragment cache address space causing control trap dynamo 
execution dynamically optimized program fragment cache suspended dynamo code executing underlying processor 
counter associated exit branch target incremented box counter exceeds hot threshold interpreter invoked trace generation mode causing produce fresh trace 
interpreter invoked normal mode operation completing dynamo execution loop 
rationale exit hot trace gets hot new trace formed starting exit branch target 
gradually hot traces materialize fragment cache increasingly greater time spent executing fragment cache correspondingly smaller proportion time spent dynamo 
dynamo overhead clearly strategy provide performance boost significantly greater amount time spent executing fragment cache executing dynamo 
means dynamo afford interpret cold parts program code 
hot parts code quickly materialized fragment cache execute directly underlying processor incurring overhead 
ksim compress li perl deltablue ijpeg go vortex average dynamo overhead percentage total execution time lightly shaded bars indicate dynamo choice threshold start trace address considered hot box critical controlling dynamo overhead 
intuitively slower interpreter quicker program working set captured fragment cache cached code executes directly underlying processor incurring overhead 
smaller hot threshold value speculative trace selection scheme dynamo get observe program behavior long judicious choice 
programs decreasing hot threshold may undesirable side effect increasing number traces hot 
ripple effect fragment cache design order compensate potentially high rate fragment generation sized large keep cache replacement overhead low 
furthermore increase number hot traces may increase optimization overhead incurred dynamo 
tradeoffs kept balance choosing hot threshold value 
prototype threshold sweet spot 
start interpreted times trace starting address selected optimization code generation fragment cache 
overhead offset sufficient performance boost just break performance input native program running directly processor 
hot traces generated fragment cache executed long offset overhead creating order dynamo provide performance benefit 
short running programs running time mins pa happen 
benchmark ijpeg example case 
longer running programs rule applies approximately execution time spent code dynamo highly effective 
shows dynamo overhead percentage total program execution time dynamo 
average overhead benchmarks 
nearly execution time typically spent executing fragment cache 
programs behaved sense spend significant amount time stable working set 
time dynamo captured current hot traces fragment cache program working set changes 
benchmarks go vortex fall category 
order recognize situation dynamo constantly monitors rate new fragment creation rate exceeds tolerable threshold prolonged interval dynamo assumes program ill behaved 
point dynamo lets input program run directly underlying processor 
possible input dynamo native program binary 
illustrates effect benchmark go 
relatively behaved program li shown comparison 
allows dynamo deliver close break performance ill behaved programs go 
drawback bail strategy dynamo control program 
may cause dynamo give early programs 
time secs go go bail li effect fragment creation rate starting dynamo entire execution input program done dynamo control 
original application program instructions execute original program text addresses 
program instructions interpreted dynamo optimized version executed software fragment cache managed dynamo 
true instructions dynamically linked libraries may invoked program 
operating system calls hand execute directly underlying processor 
dynamo attempt follow call operating system code 
intercepts operating system call modifies context call ensure control return dynamo system call completes 
shared memory region crt program text program data bss program heap dynamo data bss process local dynamo mmap ed area stack code cache dynamic objects process local program stack dynamo text process shared low memory high memory memory layout program executing dynamo ways set dynamo gain control program binary image loaded memory program instructions executed 
approach special version crt execution start prologue top program binary image 
dynamo compiled shared library pre loaded shared memory segment virtual address space 
prior jumping program entry point crt checks dynamo shared library currently mapped memory 
crt call dynamo entry point defined start symbol program entry point program execute dynamo control 
jump program entry point program execute normal manner 
alternative approaches require custom version crt allow legacy binaries run dynamo 
details bala 
actual program instructions unaltered technique 
program loaded identical address memory ran directly processor 
essential order meet transparency goal 
example certain classes program bugs dependent mapping program text segment memory reproduced mapping altered original 
dynamo shared library unique respect shared libraries 
part program data segment executes 
control enters dynamo shared library initialization routine separate area memory allocate internal data structures custom runtime stack 
recursive routines dynamo longest call chain dynamo known priori 
allows dynamo allocate fixed amount room runtime stack 
dynamo malloc style heap separate mmap ed area allocate dynamic objects custom memory allocator part dynamo 
dynamo operation interfere application program runtime stack heap area critical requirement meeting transparency goals 
illustrates typical memory layout program running dynamo 
context switching moment program execution dynamo control fragment cache dynamo code 
different machine contexts exist corresponds execution dynamo execution dynamically generated code fragment cache 
control dynamo underlying machine registers contain dynamo context application program context kept context save area dynamo data segment 
control transferred fragment cache application program context loaded underlying machine registers dynamo context discarded 
dynamo resumes execution control leaves enters fragment cache 
saving restoring program context done dynamo operating system 
keeps context switch fast 
dynamo saves restores partial program context keeping register permanently context save area available implementing context switch exit fragment cache 
trace selection dynamo granularity hot spot selection dynamic instruction trace 
trace selected dynamically program execution trace instructions non contiguous program memory 
trace go statically dynamically linked procedures indirect branches virtual function calls 
dynamo uses novel approach hot trace selection highly speculative nature involves minimal profiling 
essence idea program address gets hot sequence addresses executed immediately statistically hot trace 
expensive branch path profiling techniques ball larus dynamo profiles small set special program addresses considered candidates start trace 
special program addresses meet start trace conditions target backward taken branch loop head target exit branch previously selected hot trace fragment cache 
counter incremented start trace address interpreted control dynamo 
counter update kind profiling done control fragment cache 
counter associated start trace address exceeds threshold prototype interpreter toggles code generation mode emitting interpreted native instruction buffer 
allows dynamic sequence instructions executed immediately hot start trace instruction selected hot trace 
advantage approach trace grown past indirect branch dynamically linked library call 
interpreter continues emit hot trace buffer reaches trace conditions backward taken branch interpreted buffer full 
trace condition reached counter associated start trace address reset recycled profiling start trace addresses interpreter toggles back normal state operation 
ksim compress li perl deltablue ijpeg go vortex smallest number fragments accounting total execution time lightly shaded bars programs dynamo normally bail data collected bail disabled profile information associated address consumed discarded soon address gets hot box 
online profiling strategy contrast conventional offline profiling techniques accumulate profile information test run feed profile information back compiler analysis tool 
furthermore case conventional techniques counter associated profiled address storage locked address profiling run terminates 
ability recycle counter storage counter value gets hot allows scheme economical counter memory 
speculative trace selection scheme outlined selects hot dynamic traces kind path profiling 
effective illustrated data 
data shows smallest number fragments fragment cache account total program execution time dynamo top fragments account total execution time 
programs dynamo bail cover set typically contains fragments 
go vortex larger number fragments cover set dynamo direct native execution cases long fragments generated fragment cache 
extensive experiments alternative region selection schemes unable find matched performance overhead ratio speculative trace selection scheme bala 
fragment creation optimization instructions comprising hot trace non contiguous memory may part static program scope available compiler created program binary 
dynamic trace expose new optimization opportunities statically optimized program binary 
task optimizer box fix taken branches trace fall direction remains trace taken direction exits trace 
allows trace instructions placed contiguously fragment cache memory executable fragment 
branch may redundant trace removed altogether 
example occurrence procedure call corresponding return trace 
call return redundant branches 
side effects branch instruction setting link register preserved branch removed 
creating executable fragment trace optimizer inserts special blocks called linker stubs serve targets branches exit fragment 
exit branch fragment targets unique linker stub 
purpose linker stub trap control back dynamo 
jumping context switch routine saves program context dynamo context save area transfers control dynamo 
linker stub communicates actual target exit branch dynamo dynamo resume interpretation starting target address 
shows trace input program shows corresponding executable fragment fragment cache 
call return trap dynamo trap dynamo control flow snippet input program hot trace blocks shown lightly shaded fragment corresponding hot trace laid fragment cache linker stubs shown shaded illustration branch linking fragments indirect branches branches value register target trace handled special way 
trace contains indirect branch instruction immediately branch indirect branch target encountered time trace interpreted 
trace automatically contains inlined indirect branch target 
indirect branch replaced conditional branch tests value target address register address inlined target 
test fails branch exits trace special fragment permanently kept fragment cache 
special fragment hand coded sequence tag lookup fragment cache 
fragment actual target control jumps exits fragment cache dynamo invoke interpreter 
fragment single entry multi exit executable sequence 
control enter fragment top 
internal control join points fragment 
simplicity control flow allows fast non iterative optimizer design highly effective 
dynamo form staged optimization 
number path specific optimization passes performed trace 
optimizations divided classes conservative aggressive 
optimizations termed conservative lead modified program memory register contents 
elimination redundant branches result side effect trace selection copy propagation constant propagation strength reduction fall class 
aggressive optimizations include redundant load store removal dead code elimination loop transformations 
aggressive optimizations unsafe certain situations 
example redundant load may volatile memory accesses removal result incorrect program 
aggressive optimizations difficult undo 
instance program arm signal handler examines modifies program machine context instant signal 
signal arrives control middle fragment fragment cache dynamo reconstruct original signal context program running directly processor 
may difficult aggressive optimizations applied fragment 
dynamo capable starting aggressive mode switching conservative mode accompanied fragment cache flush encounters suspicious code prototype exercise 
source program information volatile memory access preserved pa risc binary 
decision perform conservative aggressive optimizations dynamo started 
shows actual wall clock speedups dynamo achieves optimized native program binaries running dynamo 
average dynamo achieves speedup 
comparison average speedup binaries achieved static compiler optimization 
performance binaries running dynamo faster average compiled versions running dynamo 
importantly dynamo achieves speedup transparent fashion resorting kind profile feedback mechanism 
equivalent default optimization level hp compiler 
highest optimization level require profile feedback run hp compiler 
global optimizations including procedure inlining performed level 
compile time significantly slower 
speedup relative native execution ksim compress li perl deltablue ijpeg go vortex average aggressive conservative optimization dynamo performance relative direct execution input native program indicates significant portion performance gains come trace selection 
primarily due compact layout program hot spots fragment cache memory desirable side effects improved instruction cache utilization lower virtual memory pressure bala 
trace optimization accounts approximately total gains 
time spent performing optimizations negligible fraction dynamo overhead average 
overhead invested efficiently optimization attempted dynamic hot code 
branch linking new fragment inserted fragment cache exit branches linked jump directly fragments cache tags match original exit branch addresses box 
involves simple modification branch instruction 
branch linking significantly lowers number fragment cache exits context switch overhead incurred dynamo 
linking critical dynamo deliver performance 
linking disabled dynamo performance slow significantly factor average slowdown current prototype 
fragment cache management performance data shown dynamo fragment cache sized kbytes 
dynamo afford fancy management fragment cache storage overheads incur 
approach simply size cache large hold entire working set typical input program 
approach followed contemporary dynamic translator implementations 
dynamo hand uses pre emptive flushing scheme periodically remove entire contents fragment cache 
flushing triggered dynamo recognizes sharp increase fragment creation rate 
rationale sharp rise new fragment creation indicative change working set program currently fragment cache 
new working set built fragment cache flush displace useful fragments pre emptive flushing technique permits reduction fragment cache footprint performance loss performance achieved kbyte fragment cache 
allowing smaller size fragment cache achieve performance larger pre emptive flushing mechanism interesting side effects 
fragment related data structures maintained internal bookkeeping dynamo tied flush causing memory pools reset side effect pre emptive flush 
pre emptive flush serves cheap garbage collecting mechanism free dynamic objects associated fragments dropped current working set 
fragments belonging new working set inadvertently flushed result simply regenerated dynamo program addresses encountered execution 
system calls signal handling dynamo examines system calls program code 
usually necessary identify situations kernel directly invoke program routine undercutting dynamo causing lose control program 
example system calls install signal handlers 
dynamo intercepts signal handler installation calls sigaction substitutes handler place program handler 
kernel transfer control dynamo signal arrives box program handler code executed dynamo control 
situation get quite complicated dynamo decision continue maintain control program compromising performance 
example situation program code contains call fork exec 
principle possible dynamo inject executable image child process similar way current process set run dynamo 
deal additional complication creates prototype currently direct program execution fork exec encountered code 
related lot done dynamic translation technique non native system emulation may insignia cmelik keppel witchel rosenblum 
basic idea simple interpretation expensive way emulate long running program host machine 
caching native code translations frequently interpreted regions lower overhead 
sufficient time spent executing cached translations offset overhead interpretation translation caching strategy generally beat pure interpretation performance 
implementations bypass interpreter completely translate native code prior executing unit conte cramer ebcioglu altman griswold 
dynamo employ blend interpretation native execution fragment creation rate continues remain high dynamo bail illustrated 
ebcioglu 
hybrid dynamic translation systems emerging combination software custom hardware kelly 
dynamic optimization different dynamic translation input native program binary translation step involved 
goal dynamic translator beat performance pure interpretation goal dynamic optimizer beat performance input program executing directly host machine 
dynamic optimization different dynamic compilation generally defined literature 
dynamic compilation programmer explicitly requests specific part program compiled runtime program annotations auslander consel noel leone lee leone dybvig uses language allows efficient runtime compilation holzle engler 
code generated compile time contains stubs transfer control runtime compiler dynamically generates native executable code 
contrast view dynamic optimization transparent process 
special programming language compiler annotations necessary trigger activation 
compiled native code need additional processing including instrumentation binary 
case dynamic compilation runtime compiler necessary step execution program case dynamic optimization 
moment dynamic optimizer option letting input program execute directly underlying processor 
implementations offline binary translators perform native code optimization sites chernoff 
generate profile data initial run emulation perform background translation optimization hot spots profile data 
strategy transparent sense dynamic optimizer benefit optimization available subsequent runs program 
case dynamic optimizer hand profile data generated consumed run data written offline run 
hardware implementations dynamic optimizers commonplace modern microprocessors kumar keller 
optimization unit fixed size instruction window optimization logic operating critical execution path 
trace cache hardware alternative extended superscalar optimization critical path peleg weiser rotenberg friendly 
unaware attempts implement transparent dynamic optimizer entirely software 
software dynamic optimizer advantage patched similar bios pc 
bound particular hardware implementation custom tuned specific application domains easily 
indiana project called dynamo 
regret name collision 
project started winter unaware dynamo project 
dynamo name numerous internal documents memos presentations patent making task renaming project stage somewhat difficult imagine 
dynamo offers novel software performance delivery technology performance optimization done time bits executed client machine time bits created compile time 
advantage approach need rely software vendor enable optimization level 
prototype demonstrated significant performance wins achieved integer benchmarks compiled static optimization 
addition delayed binding dynamic linking favor obstacles dynamic optimizer operates objects bound runtime 
dynamo prototype shown possible get significant speedups dynamic optimization statically optimized native binaries 
demonstrated feasibility engineering realistic transparent dynamic optimizer spite severe constraints operating runtime 
auslander philipose chambers eggers bershad 
fast effective dynamic compilation 
proceedings sigplan conference programming language design implementation pldi 
bala duesterwald banerjia 
transparent dynamic optimization design implementation dynamo 
hewlett packard laboratories technical report hpl june 
available www hpl hp com techreports hpl html 
bala freudenberger 
dynamic optimization dynamo project hp labs cambridge project proposal 
hewlett packard laboratories internal memo feb 
ball larus 
efficient path profiling 
proceedings th annual international symposium microarchitecture micro paris 


fast accurate multicomputer simulation 
proceeding acm sigmetrics conference measurement modeling computer systems 
chernoff reeve rubin yates 
fx profile directed binary translator 
ieee micro vol march april 
cmelik keppel 
shade fast instruction set simulator execution profiling 
technical report dept comp 
science engineering univ washington 
consel noel 
general approach run time specialization application proceedings th annual symposium principles programming languages 

conte 
technique object code compatibility vliw architectures 
proceedings th annual international symposium microarchitecture micro 

cramer friedman miller wilson wolczko 
compiling java just time 
ieee micro may jun 
ebcioglu altman 
daisy dynamic compilation architectural compatibility 
proceedings th annual international symposium computer architecture 

ebcioglu altman 
execution scheduling vliw architectures 
appear euro par august toulouse france 
engler 
vcode retargetable extensible fast dynamic code generation system 
proceedings sigplan conference programming language design implementation pldi 
friendly patel patt 
putting fill unit optimizations trace cache microprocessors 
proceedings st annual internation symposium microarchitecture micro dallas 

griswold 
java hotspot virtual machine architecture 
sun microsystems mar 
available java sun com products hotspot whitepaper html 

complete machine simulation understand computer system behavior 
ph thesis dept computer science stanford university 
reese 
cpu emulation 
proceedings hot chips viii 
holzle 
adaptive optimization self reconciling high performance exploratory programming 
phd thesis computer science dept stanford university available technical report stan cs tr 
available sun microsystems lab technical report 
insignia 
macintosh unix 
www insignia com 
keller 
superscalar alpha processor order execution 
th ann 
microprocessor forum san jose ca 
kelly cmelik wing 
memory controller microprocessor detecting failure speculation physical nature component addressed 
patent nov 
kumar 
hp pa risc cpu high performance order processor 
proceedings hot chips viii palo alto ca 
leone dybvig 
dynamo staged compiler architecture dynamic program optimization 
technical report dept computer science indiana university 
leone lee 
optimizing ml run time code generation 
proceedings sigplan conference programming language design implementation 

may 
mimic fast system simulator 
acm sigplan symposium interpreters interpretive techniques 

tuning pentium pro microarchitecture 
ieee micro apr 

peleg weiser 
dynamic flow instruction cache memory organized trace segments independent virtual address line 
patent 
engler kaashoek 
tcc system fast flexible highlevel dynamic code generation 
proceedings sigplan conference programming language design implementation 

rotenberg bennett smith 
trace cache low latency approach high bandwidth instruction fetching 
proceedings th annual international symposium microarchitecture micro paris 

sannella maloney freeman benson borning 
multi way versus oneway constraints user interfaces experiences deltablue algorithm 
software practice experience may 

sites chernoff kirk marks robinson binary translation 
digital technical journal vol special issue 

emulating dos windows risc environments 
proceedings microprocessor forum san jose ca 
witchel rosenblum 
embra fast flexible machine simulation 
proceedings sigmetrics conference measurement modeling computer systems 


