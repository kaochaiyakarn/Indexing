hierarchical multiprocessor scheduling system dsp applications jos luis pino bhattacharyya edward lee pino eal eecs berkeley edu dept electrical engineering computer sciences university california berkeley semiconductor research laboratory hitachi america discusses hierarchical scheduling framework reduces complexity scheduling synchronous dataflow sdf graphs multiple processors 
core framework clustering algorithm decreases number nodes expanding sdf graph precedence directed acyclic graph dag 
internals clusters scheduled uniprocessor sdf schedulers optimize memory usage 
clustering done manner leave ample parallelism exposed multiprocessor scheduler 
developed sdf composition theorem testing clustering step valid 
advantages framework demonstrated practical real time examples 
motivation dataflow natural representation signal processing algorithms 
strengths exposes parallelism expressing actual data dependencies exist algorithm 
applications specified dataflow graph nodes represent computations data tokens flow arcs graph 
ptolemy framework supports dataflow programming computational models discrete event 
forms dataflow defined ptolemy 
synchronous dataflow sdf number tokens produced consumed firing node constant 
property possible determine execution order memory requirements compile time 
systems overhead run time scheduling predictable run time behavior 
shows simple sdf graph 
graph node produces tokens node consumes tokens firing 
periodic sdf schedule fifo buffer arc returns initial state schedule period 
node properly constructed sdf graph exists positive integer node invoked times period periodic schedule 
example sdf specification construct periodic schedule compile time iterated indefinite number times requiring unbounded memory 
schedule constructed invoking actor exactly times ensuring data precedences defined sdf graph respected 
schedule schedule sdf graphs multiple processors precedence dag simply dag constructed original sdf graph 
node original sdf graph corresponding nodes precedence graph 
unfortunately expansion due repetition count sdf node lead exponential growth nodes dag 
growth undesirable especially considering known optimal multiprocessor scheduling algorithms precedence constraints complexity exponential number nodes dag 
uniprocessor sdf schedulers hand require dag generated 
limit explosion nodes translating sdf graph dag graph apply clustering connected subgraphs larger grain composite nodes 
composite nodes scheduled available uniprocessor schedulers 
cluster nodes simple sdf graph 
ninth annual asilomar conference signals systems computers october manner simplifies dag hiding exploitable parallelism 
important note resultant cluster mapped single processor 
observation motivates modification execution time minimizing clustering heuristics sdf graph 
multiprocessor scheduling clustering heuristics resultant clusters mapped single processor 
clustering sdf graph opportunity specialized uniprocessor sdf schedulers optimize parameters code size buffer memory context switch overhead 
structure follows 
introduce sdf composition theorem allows test legal cluster adjacent nodes sdf graph 
discuss clustering heuristics framework 
detail hierarchical scheduling algorithm performance measures practical dsp examples scheduled framework 
sdf composition unfortunately clusterings adjacent nodes sdf graph possible 
fact clusterings alter sdf graph semantics introducing deadlock graph 
sdf graph deadlock acyclic precedence graph 
likewise sdf graph deadlock cycle precedence graph 
introduce cycles precedence graph clusterings 
sdf precedence graph expansion detailed 
developed theorem called sdf composition theorem establishes clustering criteria provide sufficient condition clustering operation involving adjacent nodes introduce deadlock 
condition prevents new cycles sdf graph precedence graph 
conditions prevent cycles precedence graph 
criteria significantly general previous sdf clustering tested efficiently 
due lack space refer proof sdf composition theorem 
notation notational conventions working sdf graphs 
directed graph set nodes set arcs number samples consumed sdf arc sink invocation 
number samples produced sdf arc source invocation 
number initial samples delay sdf arc node produces tokens arc node consumes tokens produced arc adjacent nodes sdf graph view number times node invoked single invocation cluster figures illustrate sdf graph clusterings violate conditions sdf composition theorem introduce deadlock 
sdf graphs figures arcs exception 
figures cycle introduced precedence graph depicted wider arcs 
sdf composition theorem suppose connected sdf graph ordered pair distinct adjacent nodes graph results clustering single node introduce cycles precedence graph conditions hold 

cycle condition simple path contains arc simple path visit node path 
depicts clustering violates condition 
src snk gcd example violation condition 
cycle introduced sdf precedence graphs 
sdf graph precedence graph 
hidden delay condition strongly connected component hold true 
depicts clustering violates condition 
arc zero delay positive integer 
precedence shift condition nontrivial strongly connected component hold true 
depicts clustering violates condition 
exists integers exists integers 
second precedence shift condition nontrivial strongly connected component hold true 
exists integers exists integers note conditions sdf composition theorem may satisfied ordered pair satisfied general orderings tried declaring clustering operation valid 
clustering techniques section review clustering techniques sdf graphs 
clustering technique far simplest allow user specify clusters mapped single processor 
clustering technique empowers user fundamental scheduling decisions 
implemented technique ptolemy enabled development multiprocessor applications previously impossible synthesize sdf multiprocessing techniques 
clustering technique takes account resource constraints 
mapping sdf graphs heterogeneous processors group connected nodes may required mapped particular processor 
free cluster sdf subgraphs long introduce artificial deadlock 
third clustering technique groups nodes ordered uniform repetition count sdf subgraph nodes internal state 
acyclic graph ordered topological sort sdf subgraph subgraph kq kq sdf graph precedence graph example violation condition 
cycle introduced precedence graph 
snk src src src snk snk snk src src src snk snk sdf graph precedence graph example violation condition 
cycle introduced precedence graph 
values nodes identical 
clustering hide available parallelism exposed final dag 
clustering technique adaptation sarkar multiprocessor dag scheduling heuristic sdf graphs 
outlined section 
hierarchical scheduling algorithm section detail hierarchical scheduling algorithm 
algorithm stages 
stage initialization simple clustering heuristics hide exploitable parallelism 
stage main loop clustering occurs 
wrap stage individual schedulers invoked 
initialization 
cluster nodes sdf ordered subgraphs internal state 

cluster nodes share resource constraints satisfy sdf composition theorem 

compute node 
construct acyclic sdf graph involves removing arc cluster strongly connected components 

compute total ipc cost arc acyclic sdf graph 
main loop 
apply step sarkar multiprocessor clustering heuristic acyclic sdf graph 

sdf composition theorem test resulting cluster candidate sure introduce deadlock 

cluster candidate introduce deadlock perform corresponding clustering operation update accordingly 

repeat precedence graph limited certain size legal candidate clusters 
stopping condition limits precedence graph tractable size equation constant number nodes original sdf graph number processors target architecture 
wrap 
schedule sdf uniprocessor clusters loop scheduler 

schedule user specified clusters scheduler 

schedule clustered system user specified multiprocessor scheduler 
performance hierarchical scheduling framework user specified clustering implemented ptolemy 
signal processing applications synthesized heterogeneous multiprocessor consisting risc dsp processor 
table comparing results user specified hierarchical scheduling versus full dag expansion multiprocessor scheduling table 
examples scheduling time improved orders magnitude makespan significantly increased 
uniprocessor snk kmax system sdf graph size dag size scheduling time cpu seconds makespan dsp code size assembly sparc code size fm synthesis pt 
spectrum smaller faster difference smaller bpsk bps smaller faster smaller smaller qam bps eye diagram smaller faster difference smaller smaller qam bps smaller faster smaller smaller table performance hierarchical scheduling framework user specified clustering 
schedulers final clusters able realize significant improvement memory usage 
improvement memory particularly evident acoustic bps quadrature amplitude modulation qam acoustical modem multiprocessor schedule generated fully expanded dag function call lined procedure nodes compared function calls hierarchical schedule 
case modem examples dsp card access memory framework enabled synthesis applications previously possible full dag expansion multiprocessor scheduling techniques 
developed hierarchical scheduling framework sdf graphs mapped multiple processors 
user specified clustering framework dramatically improved scheduling time reduced memory requirements needed generated system 
cases hierarchical scheduling framework enabled synthesis applications previously impossible 
test clustering step valid developed sdf composition theorem 
theorem significantly general developed previous tested efficiently 
plan implement automated clustering heuristics sdf graph sdf dag translation 
adaptation sarkar clustering heuristic inspired dag clustering heuristics multiprocessor schedulers 
objective hide parallelism exploited final multiprocessor scheduling phase doing simplifying dag 
acknowledgments research part ptolemy project supported advanced research projects agency air force program contract semiconductor research project dc national science foundation mip office naval technology naval research laboratories state california micro program companies bell northern research cadence hitachi mentor graphics mitsubishi nec pacific bell philips rockwell sony synopsys 
jos luis pino supported bell laboratories part cooperative research fellowship program 
buck ha lee messerschmitt ptolemy framework simulating prototyping heterogeneous systems international journal computer simulation special issue simulation software development vol 

ptolemy eecs berkeley edu papers lee messerschmitt synchronous data flow proceedings ieee vol 

pino bhattacharyya lee hierarchical multiprocessor scheduling framework synchronous dataflow graphs ucb erl electronics research laboratory university california berkeley may 
ptolemy eecs berkeley edu papers erl yang comparison clustering heuristics scheduling directed acyclic graphs multiprocessors journal parallel distributed computing vol 

kim browne general approach mapping parallel computations multiprocessor architectures international conference parallel processing vol 
university park pa usa pennsylvania state univ 
sarkar partitioning scheduling parallel programs multiprocessors cambridge mass mit press 
multiprocessor scheduling account interprocessor communication ph dissertation ucb erl electronics research laboratory university california berkeley 
automatic mapping large signal processing systems parallel machine ph dissertation cmu cs carnegie mellon 
bhattacharyya buck ha lee generating compact code dataflow specifications multirate signal processing algorithms ieee transactions circuits systems fundamental theory applications march 
bhattacharyya murthy lee complementary heuristics translating graphical dsp programs minimum memory implementations memorandum ucb erl electronics research laboratory university california berkeley january 
ritz meyr optimum vectorization scalable synchronous dataflow graphs proceedings international conference application specific array processors october 
bhattacharyya compiling dataflow programs digital signal processing ph dissertation ucb erl university california berkeley 
pino lee hierarchical static scheduling dataflow graphs multiple processors ieee international conference acoustics speech signal processing detroit michigan ieee 
ptolemy eecs berkeley edu papers 
