appear european transactions telecommunications ett october 
decoding equalization analog non linear networks joachim hagenauer elke offer cyril matthias institute communications engineering munich university technology munchen elke lnt technik tu muenchen de july 
analog non linear highly parallel networks attempt perform decoding block convolutional codes equalization certain frequency selective channels decoding multi level coded modulation reconstruction coded pcm signals 
contrast common practice tasks performed sequentially operating processors 
advantage operate fully soft values input output similar done turbo decoding 
explicit iterations networks float freely continuous time 
decoder latency time restricted time constants parasitic rc values integrated circuits 
simulation results simple examples shown cases achieve performance conventional map detector 
complicated codes indicate promising solutions complex analog networks simple ones 
furthermore discuss principles analog vlsi implementation networks 
due dramatic success representing transmitting analog waveforms continuous time value digital means subsequent reconstruction digital signal processors fact source signals analog especially interface humans fallen 
furthermore signals send transmission channels analog 
throw bits air transform analog waveforms 
receiver takes analog signals cases outputs analog waveforms question arises going digital 
reasons common practice prominent digital vlsi principle need convert digital 
course want preserve rich algebraic structure digital representations error correcting coding 
learnt case soft values better binary values fact suggested information theory 
step back analog 
big success iterative socalled turbo decoding pioneered due exchange soft information constituent decoders 
turbo decoding approaches shannon limit closely code rate gap narrows db 
processing digital means iterations discrete time 
perform decoding received soft samples continuous time generate output decisions samples waveforms real analog values 
analog networks want perform task described 
highly parallel non linear feedback ways 
feedback useful old analog world fm 
case turns analysis networks difficult 
similar turbo decoding theoretical results proof optimality convergence stability 
performance demonstrated solving network non linear differential equations 
simulations show simple codes channels performance reaches maximum posteriori map performance achieved digital processors 
discuss steps implementation analog vlsi circuits 
implementation produced prototype albeit trivial memory tail biting convolutional code 
claim replace digital modules receivers analog networks believe borderline analog digital shift analog direction 
instance receiver perform quick dirty decoding inner code submission hagenauer offer analog network 
step powerful digital decoder reed solomon decoder rest 
anyway full swing backward forward 
analog world 
previous related literature find approaches develop analog network decoding 
literature survey 
group mention working artificial neural networks 
neural network consists connection set simple processing units 
unit neuron performs simple algebraic operations adding weighted input signals outputting result specific activation function sum weighted inputs 
standard operational amplifiers realize neurons 
activation function kind threshold function sigmoid function 
weights input signals determined training network 
due problem large training sets results reported small codes hamming code convolutional codes memory equal efficient neural decoders fixed weight training free networks 
neural network design known digital decoding algorithms fully exploits algebraic structure codes 
neural networks built realize majority logic decoding viterbi decoding 
furthermore classical recurrent feedback neural network analog hopfield network local optimization algorithm special class codes balance check codes 
binary codes fulfill restriction codeword positions checked parity check equations number 
analog hopfield network works balance check codes codes indication codes class 
non algorithmic approach channel decoding published davis loeliger 
diode decoder trellis representation code consists diodes switches 
received symbols determine number diodes corresponding trellis section significant current flows path similar received sequence 
diode decoder suffers number practical problems easily overcome attention 
class iv partial response disk drive applications analog viterbi decoder popular see 
maximum likelihood read channel allows simplifications viterbi decoding facilitate analog realization hand limit analog decoder certain applications hand 
new circuit design general viterbi decoder published corresponding analog parts decoder fabricated process 
add compare select function viterbi decoder implemented simple analog circuit diodes main parts 
memory management necessary viterbi decoding process order trace back survivor path performed digitally 
decade lot successful iterative decoding techniques developed 
different algorithms main common attribute split decoding process code separate decoders component codes sub codes 
soft decoders exchanging called extrinsic information working alternately component sub codes 
soft soft decoders viewed decimating digital filters improve signal noise ratio 
view caused berrou introduce famous turbo decoding scheme 
description state art turbo decoding schemes 
lucas introduced iterative soft decision decoding algorithm linear binary block codes 
years ago gallager introduced efficient iterative decoding algorithm low density parity check ldpc codes see section 
tanner graphs connected interleaver explain parallel serial concatenated turbo decoding process wiberg loeliger koetter forney 
different graphical model bayesian networks describe iterative decoding algorithm belief propagation algorithm 
new graphical model called factor graphs subsumes tanner graphs bayesian networks 
descriptions assume algorithm discrete timing iterations processors performing certain tasks 
learned lesson important performance decoding system works soft values words operate continuous values 
want go step continuous time replacing step step algorithms real analog highly parallel networks 
searching developments soft soft iterative decoding strategy implementing decoding techniques analog hardware 
parallel loeliger started similar approach implement sum product algorithm analog vlsi 
cycle free factor graphs sum product algorithm equivalent symbol map decoder 
gilbert multiplier modified versions implement probability multiplications sum product algorithm 
inputs outputs transistor circuit currents representing probabilities 
necessary probability normal ett decoding equalization analog non linear networks ization follow ideas 
outline follows 
describe log likelihood values bits channels 
factor graphs useful simple notation describe approaches analog decoding networks 
give short factor graphs 
furthermore section analog network joint equalization decoding section introduce analog network decoding coded multi level psk modulation 
analog networks extended source decoding corresponding networks discussed section 
log likelihood algebra network elements log likelihood algebra soft values binary random variable gf elements null element addition xor operation 
simplicity different notations random variable value log likelihood ratio defined log denoted value random variable sign hard decision magnitude jl reliability decision 
stated logarithm natural logarithm 
tanh called soft bit ranging 
addition bits view simultaneously gf real integer number 
addition statistically independent random variables written 
respectively 
corresponding soft bits real number operation efx 
efx 
efx obtain 

gf addition element respective elements network multiplication box plus addition 
multiplication performed real numbers 
values log tanh 
tanh sign 
sign 
min jl jl box plus symbol 

defined abbreviation 
reliability sum 
determined smallest reliability terms 
box plus element 
important building block analog networks 
order avoid multiplications log function log log 
tanh inversely 
get simple addition real positive numbers magnitude obtain sign soft output 
want emphasize transformation jl vice versa function log exp exp 
shows addition inputs corresponding elements range respectively 
extension inputs straightforward 
submission hagenauer offer transmission non frequency selective channels detection decoding maximum posteriori probability app map symbol symbol estimation symbols vector vector received encoding distortion gauss markov process distribution yjx 
addition possibly available priori probability input estimator 
output estimator provides posteriori probability jy subsequent processing 
binary random variable conditioned different random variable conditioned loglikelihood ratio xjy 
transmission binary symmetric channel bsc gaussian fading channel calculate log likelihood ratio transmitted bit conditioned matched filter output xjy log jy jy log yjx yjx yjx obtain xjy log exp es exp es log 

fading channel denotes fading amplitude additive white gaussian noise awgn channel set 
bsc cross probability log transmission frequency selective channels channel model frequency selective channel shown 
transmitting symbol channel gaussian noise channel time varying data block write impulse response length 
usually assume largest magnitude 
rearranging normalization es jh time discrete model frequency selective fading channel 
noise jn log likelihood ratio binary data obtain jx log jx jx jz jz es lc re app metric jy jx apriori corresponding soft bit tanh jy principles analog decoding design factor graphs definition factor graph bipartite graph expresses global function ett decoding equalization analog non linear networks factor graph hamming code parity check matrix tanner graph 
variables factors product local functions 
description generalized tanner graphs hidden variable nodes introduced 
graph subsumes graphical models markov random fields bayesian networks belief networks graphs fields signal processing 
factor graphs applied codes design analog decoders 
furthermore factor graphs describe factorization probability distributions 
factor graphs tool helpful describing channel decoding algorithms 
factor graph obtained connecting variable nodes represented circles function nodes variable nodes connected function nodes vice versa 
usually function node connected variable node 
simple case graph binary variable nodes function nodes performing xor operation connected variable nodes box plus operation 
corresponding values 
function node representation parity check equation particular code set variables fulfilling parity check equations form set codewords 
example parity check matrix hamming code ch determine factor graph 
rows define variable nodes code bits connected function nodes simple parity checks 
case factor graph equivalent tanner graph representation code shown 
decoder network operates values symbol converted box plus symbol 
length code bits allow words 
information bits code bits subset possible words set valid codewords ch define binary indicator function ch ch ch ch determine word valid codeword 
word satisfy parity check equations rows parity check matrix reason factor binary indicator function ch follows ch 



denote parity check indicator functions corresponding rows matrix 
word valid codeword ch ch local parity checks satisfied 
factor graphs low density parity check codes low density parity check ldpc codes introduced gallager defined sparse parity check matrix general non systematic matrix constructed random fulfilling certain constraints column small fixed number ones weight row small uniform 
addition class codes gallager introduced non optimal decoding algorithm uses basic concept separating intrinsic extrinsic information soft soft iterative decoding strategy see section 
ldpc codes decoder forgotten long time mackay neal showed computer simulations long code length performance comparable remarkable performance turbo codes 
ldpc codes decoders attracting interest 
concept ldpc codes extended convolutional codes powerful component codes single parity check code 
observed turbo codes special case generalized ldpc codes 
furthermore theoretical analysis ldpc codes transmitted binary input memoryless channel 
analysis powerful new class ldpc codes irregular factor graphs designed 
ldpc code called submission hagenauer offer factor graph low density parity check code 
irregular numbers fixed certain value 
shows tanner graph simple ldpc code code length ones column ones row 
code poor error correction performance serve introductory example 
example variable node reached lines parity check node connected lines 
matrix code zeros shown tanner graph shown 
row parity check matrix corresponds binary local check parity check function variables 
ldpc code split single parity check spc codes component codes 
ensemble component spc codes checking certain code bit independent possible 
useful construct matrix ensemble spc codes checking certain code bit digit common pair rows matrix position common 
matrix sparse happen large block length randomly chosen positions ones row 
factor graphs memory convolutional code consider convolutional code cm rate memory 
implementing code length tail biting structure obtain parity check matrix hm parity check matrix binary indicator function cm code factors local check functions cm 
simplifies notation structure 
corresponding factor graph shown 
factor graph code cm tail biting form circle size information bits parity check matrix tanner graph 
ett decoding equalization analog non linear networks factor graphs memory convolutional code consider convolutional code cm rate memory generator polynomials 
block length information bits tail biting form obtain parity check matrix hm 
parity check matrix obtain binary indicator function cm cm zn 
gives illustration factor graph 
generator matrix code cm gm 
non systematic encoders factor graphs generator matrix different graphs parity check matrix 
gm obtain binary indicator function cm cm cm zn zn corresponding factor graph shown 
tanner graphs extended graphs hidden auxiliary variables variables necessarily binary 
trellis representation factor graph cm parity check matrix hm tanner graph 
factor graph cm generator matrix gm code hidden variables marked double circles correspond trellis states local check represents trellis section 
trellis section convolutional code corresponding factor graph fragment shown 
factor graph fragment corresponding trellis section convolutional code generator polynomials 
focus attention tail biting convolutional codes reasons shown convolutional codes achieve minimum distance best known block codes short medium block sizes 
furthermore need termination bits avoiding higher error rate submission hagenauer offer trellis 
analog decoder complicated tail biting codes terminated codes 
obtain full error correction capabilities code circle size block length code fulfill certain constraints 
convolutional code circle size information bits necessary exploit full error correction capability code awgn channel 
wanted combine channel source decoding pcm signals quantized bits interested multiples circle size 
decided investigate circle size information bits combination convolutional code circle size information bits combination convolutional code 
analog decoder networks factor graphs binary variable nodes consider different approaches analog decoder networks 
start simple proposal restrict binary variable nodes factor graph representation code 
corresponding analog decoder network strongly related gallager iterative decoding algorithm ldpc codes 
unfortunately long block lengths great challenge analog technique 
shorter ldpc codes decoded analog network inner code decoder system perform quick clean channel errors 
start brief overview gallager iterative decoding technique ldpc codes 
gallager iterative decoding algorithm consider transmission selective channel memoryless awgn channel 
working binary codes values leads efficient description decoding algorithm 
considering example ldpc code section digit checked sixth row matrix 
row corresponds spc code checking digits positions sixth row check notation fi jr indicate row set columns fj jc indicate column set rows 
example ldpc code 
parity check equations digit orthogonal table gallager iterative soft output decoding algorithm ldpc codes 
notation 
initialization 

qth iteration 
part parity check node variable node 


part variable node parity check node 


soft output 
get result soft output adding independent results component spc codes 


lot better gallager iterative decoding algorithm 
summarize gallager iterative decoding algorithm ldpc codes table log likelihood algebra defined section 
variable node initialized corresponding channel output 
iterations consist parts 
part message passing parity check node 
variable node calculated 
equal extrinsic information variable node received parity check node 
extrinsic information notation 

spc codes parity check nodes parity check node perform different calculations evaluate extrinsic information passed different directions 
second part iteration comprises calculations message passing variable nodes parity check nodes 
variable nodes evaluate different log likelihood sums parity check nodes connected 
algorithm follows rule information passed node iterations independent possible information received node 
true variable nodes parity check nodes 
iterations soft output position sum incoming information variable node ett decoding equalization analog non linear networks original gallager described iterative decoding algorithm log likelihood ratios 
box plus notation defined equation recommend decoding algorithm implemented log function defined equation 
words realization box plus log function equations gallager ldpc codes published years ago 
gallager notation sign jl definition function obtain message passing parity check node 
variable node simulation results ldpc codes generalized ldpc codes ldpc convolutional codes respectively 
bit error rate gaussian channel achieved signal noise ratio db ldpc code db ldpc code 
performance compares maximum likelihood decoding classical convolutional codes memory respectively 
mackay shown block length ber achieved db db respectively 
building blocks analog decoder networks analog decoder network factor graphs binary variable nodes gf xor addition bits performed function nodes transformed box plus operation respective values 
likewise corresponds multiplication soft bit values addition values 
consider spc code block length check equation decoding values belonging symbol fed box plus function information symbols receive extrinsic value 


draw line arrow values fed node extrinsic values delivered node 
arrow indicates transfer direction values 
example spc code length showing mentioned representation detailed tanh tanh gf sum bits respective bidirectional network element decoding spc code 
example channel inputs 
outputs box plus function le le 
detailed notation short notation non directed variable element 
realization bidirectional box plus 
function associated box plus symbol analog decoder network shown corresponds part gallager iterative decoding algorithm see table 
similar way define network element algebraic sum values 
analog network examined different called variable elements 
output non directed variable element direction received values summed distributed directions 
delivered information privileged orientation 
short notation detailed notation possible realization non directed variable element shown 
hand directed variable element constructed perform directed connection informations 
output certain direction sum extrinsic informations incoming values 
connected line directed variable hagenauer offer detailed notation short notation directed variable element 
notation detailed short notation bidirectional network elements 
ement incoming values line added 
short notation detailed notation possible realization directed variable element shown 
directed variable element seen analog realization equivalent message passing variable node parity check node gallager iterative decoding algorithm see table 
shows combination box plus operation directed variable element simple example 
realized network add resistors lines capacitors ground 
time constant rc order nanoseconds determines speed transient responses highly parallel non linear network 
components analog implementation need analog circuit operations performed box plus variable nodes 
consider box plus operation defined equation 
basis vlsi realization bipolar transistor naturally exponential characteristic 
moll equations derive equation collector current bipolar transistor function base emitter voltage qv kt denotes transport saturation current kt mv temperature dependent quantity 
forward active mode base emitter bias kt approximate equation obtain qv kt exponential function transistor non linear function exploited purpose 
gilbert cell known multiplier implementation allows quadrant operations 
assuming bipolar transistors easy show differential output current multiplier determined product hyperbolic tangent functions 
characteristic non linear functions directly employed implementation 
order gilbert cell analog multiplier restricted small input signal range hyperbolic tangent approximated linear function 
main effort circuit design decades fight transistor non linearities order extend linear range circuit operations 
loeliger gilbert multipliers modified versions implementation analog decoder 
purpose exploit fight exactly transistor non linearities 
turned box plus operation exactly save approximation realized analog circuits non linear extension gilbert cell order achieve behavior equation 
box plus operation need analog circuit performs operation variable nodes algebraic sum values 
known circuit example summing voltages operational amplifier external resistors 
disadvantage realization vlsi applications resistors occupy large chip area approximated transistors 
possibility adding necessary voltages turned efficient 
circuit variable nodes gilbert cell quite similar circuit box plus 
similarity great advantage layout vlsi chip 
typically box plus circuit variable sum circuit realized transistors 
details circuit design publication 
ett decoding equalization analog non linear networks simple examples analog decoders factor graphs binary nodes tested simple codes analog decoder approach factor graph representation particular code 
notation introduced section obtain decoder network simply changing operation function node gf addition box plus operation 
operation performed variable nodes implemented directed non directed strategy 
directed variable nodes tested decoder network considered analog realization sum product algorithm restricted binary variable nodes gallager iterative decoding algorithm 
theoretical proofs observations mainly computer simulations particular analog decoder 
transmission channel model awgn channel decoding results obtained solving corresponding nonlinear differential equation systems runge kutta method 
analog decoder networks tail biting convolutional codes performance analog decoder depend number edges connected variable node 
edges leaving variable node case convolutional code section simulated bit error rate ber analog decoder reaches decoding results ml decoding 
ml decoding performance achieved terminated convolutional code convolutional code tail biting structure non directed directed variable node elements 
addition directed variable node elements analog realization forward backward algorithm algorithm 
example convolutional code cm tail biting form circle size information bits obtain channel values corresponding information symbol parity symbol respectively 
channel values loaded decoder network floats freely continuous time steady time solution output values shown 
information word awgn channel db assumed 
transmission channel hard weak low magnitude channel errors occurred rd th th information bit 
observed analog decoder capable correct errors 
extensive simulations shown results converged 
integrated circuit implementation time decoder output values bit bit bit bit bit bit bit bit simulation analog decoder convolutional code information bits 
decoder designed analog vlsi produced 
analog vlsi realization normalized time order nano seconds resulting data rate order mbits order obtain decoding results decoder network generator matrix edges leaving variable node initialized additional information corresponding channel values 
case hamming code convolutional code shown respectively 
additional information initialization obtained quick look properties codes 
analog decoder network convolutional code cm generator matrix see initialization init 

denotes scaling factor depends noise channel 
scaling factor choice large range signal noise ratios 
presents simulation results convolutional code tail biting form circle size information bits awgn channel 
implemented analog decoder non directed variable elements 
directed variable elements observed zero stability decoder soft outputs converged zero sequence stayed stable 
tried solve problems elaborate initialization network decoder network complex directed variable nodes get improvement ber performance compared results shown 
comparison ber performance ml decoding codes added 
parallel viterbi algorithms forced start particular trellis state 
obtained decoding result submission hagenauer offer db uncoded analog decoding network ml decoding simulation results analog decoder network convolutional code tail biting form circle size information bits generator polynomials 
selecting best path viterbi algorithms independently decisions 
convolutional code tested analog decoder network factor graph parity check matrix shown 
decoding results log likelihood ratio transmitted code bits corresponding reliabilities 
order get log likelihoods transmitted information symbols need additional circuit implementing operation analog hardware 
example property code get soft output information bits 
simulated ber performance close results shown 
analog decoder network hamming code hamming turbo code hamming code variable node information bit initialized init 

property code 
matched filter outputs information symbol parity symbols respectively 
starting value information bits set zero 
tested analog decoders non directed directed variable node elements obtaining ber performance map decoding cases 
simpler non directed solution preferred 
furthermore tested performance analog decoder parallel concatenated hamming codes awgn channel 
decoding network turbo init init input values output values analog decoder network hamming code 
decoder hamming decoder hamming hamming decoder hamming decoder hamming decoder hamming decoder hamming hamming decoder decoder information bits block interleaver interleaver analog decoder network turbo coding scheme hamming codes component codes 
code shown 
interleaver component codes block interleaver illustrated bottom part 
parallel concatenation simple block codes interpreted special case generalized ldpc codes introduced 
component decoders non directed information processing strategy vari ett decoding equalization analog non linear networks encoder realization rate feed forward convolutional code generator polynomials 
db ber uncoded analog decoding network turbo decoding simulation results analog decoder network turbo coding scheme hamming code component code 
code rate 
able nodes connection different component decoders directed information processing strategy 
corresponding simulation results shown performance classical turbo decoding technique iterations added 
analog decoding principle performs classical iterative decoding technique 
tested block codes convolutional codes higher number connections leaving variable nodes great success 
cycle structure analog decoder ml decoding performance achieved variable nodes sparsely connected 
example analog decoding network hamming code corresponding dual code convolutional code efficient binary factor graphs short cycles 
observed efficient ldpc codes turbo coding schemes characterized sparsely connected variable nodes 
limitation factor graphs binary variable nodes restrictive extend concept analog decoding non binary variable nodes chapter 
analog decoder networks binary codes concept box plus operations extended analog decoding 
analog decoder loeliger suggested vlsi circuits focused implementation probability multiplications considered probability normalization 
implement analog decoder values box plus operation naturally transistor non linearities 
long trellis code preserves butterfly structure easily achieve message passing equivalent forward backward algorithm algorithm trellis combining circuits 
assume binary convolutional code rate memory feed forward realization 
higher code rates obtained puncturing 
encoder convolutional code includes information bit time steps delayed information bit determine code bits 
shown 
position encoder refer information bit left side information bit right side respectively 
bits 
characterize trellis butterfly 
trellis section code split structure 
xw denotes tuple generated information bits see 
submission hagenauer offer xw xw xw xw butterfly structure trellis representation binary feed forward convolutional codes 
butterfly structure interpreted binary symmetric channel corresponding box plus element differential outputs 
encoder output labeling transitions butterfly expressed xw butterfly structure reduced trellis binary symmetric channel input variable transition variable output variable shown 
ideas shown log likelihood ratio transition butterfly time expressed 

decoder network value forward backward recursion performed parallel 
calculate butterfly output loglikelihood ratio forward recursion 
fraction analog decoder trellis representation code 
example convolutional code generator polynomials 
backward recursion determined 
entire trellis built separately forward backward recursion 
simple example convolutional code generator polynomials trellis representation chosen 
trellis consists transition log likelihood ratios calculated 



inputs trellis section obtained simple rearrangement output values box plus operations 
shuffle principle shown 
general obtain trellis section corresponding information bit log likelihood ratio values forward recursion log likelihood ratio values backward recursion 
values delivers information estimate information bit 
relation shown soft output information bit calculated log exp exp commonly approximated max max ett decoding equalization analog non linear networks circuit implementation need approximation transistor non linearities allow straightforward implementation 
similar slightly different networks set code implemented systematic feedback encoder 
analog network joint equalization decoding main tasks receiver equalization incoming signal 
standard techniques equalization linear equalization quantized feedback maximum likelihood equalization known 
called soft soft equalizers employed soft output values channel deliver soft outputs subsequent decoder 
existing ml map techniques algorithmically sequentially digital processor viterbi algorithm soft output viterbi algorithm bahl algorithm approximations algorithms 
step called turbo equalization involves feedback iterations outer decoder inner equalizer 
system description introduce new method joint equalization decoding frequency selective fading channels highly parallel analog feedback network 
analog network continuous time naturally accepts delivers soft values 
particularly efficient combination equalization channel decoding analog network 
equalizer network decoder network connected networks permanently exchanging information floating freely steady state solution 
steady state values voltages certain points analog network constitute equalized decoded soft values 
sign values hard decision magnitude reliability decision 
main advantages new method latency naturally soft values equalization decoding processes network delivers soft values output 
preliminary results indicate cases performance joint equalizer decoder reasonably approaches ml results 
derive network simple multipath channels small codes show simulation results 
formulas frequency selective fading channel section transfered analog network shown 
basically performs soft decision feedback operation 
analog network loaded soft values channel outputs values 
analog equalizer combined analog channel decoder delivers tanh 
channel 
re equalized soft bit decoder network network analog equalizer 
extrinsic values analog decoder network 
time analog decoder feeds analog equalizer extrinsic values 
networks equalization channel decoding interact operate simultaneously exchange information transition process network 
non linearity feedback tanh suitable approximation limiting magnitude maximum value delivering soft bit back equalizer network 
equalizer network decode blocks data terminated known bits zero bits 
denotes maximum length impulse response 
priori log likelihood value known bits corresponding channel bits network loaded highest possible system value 
alternatively equalizer decode blocks data bits bits block prefix 
prefix data transmitted corresponding received channel values cut 
ofdm transmission theory block length called guard interval 
equivalent convolutional code tail biting form difference encoding performed frequency selective channel 
analog equalizer forms closed ring elements 
note equalizer ring preferred direction causality minimal maximal phase obsolete tail biting implementation 
channels higher memory number connections increases linearly trellis hagenauer offer tion number nodes increase exponentially 
principles analog decoder network section 
channel coding convolutional code tail biting form 
channel decoder uses concept directed variable node elements analog realization algorithm forward backward algorithm tail biting circle 
network analog decoder network analog equalizer connected interleaver ring shown 
networks exchange extrinsic information interleaver ring tries maintain independence individual values 
decoder network decoded bits equalized channel values received interleaver ring conv 
code interleaver ring interleaver ring interleaver ring 
network joint equalizer decoder convolutional code tail biting form 
simulation results decoder equalizer network results network performance obtained solving non linear differential equations numerical methods kutta method 
order test joint equalization decoding channel taps 
data transmitted blocks symbols tail biting technique channel code equalization 
decoder ring connects information symbols equalization ring contains coded symbols 
code rate entire system 
simulation results shown 
performance turbo equalization method added 
turbo equalization performed viterbi equalizer combined symbol symbol map decoder channel code 
shows gain classical method iterations iterations turbo scheme 
structure analog equalizer simpler viterbi equalizer attain performance multiple iteration turbo scheme 
analog equalization decoding outperforms ml equalization decoding feedback zero iteration transfer soft values today mobile receivers 
performance analog equalizer decoder network depends lot taps 
certain tap combinations hard achieve convergence network 
currently investigated 
db analog network turbo equalization iteration turbo equalization iteration simulation results channel convolutional code tail biting technique channel code equalization bits sequence sent guard interval initialize channel interleaver size 
multi stage decoding analog feedback networks multi level coded psk multi level coded modulation introduced imai hirakawa decoded multi stage decoders 
iterative process advantageous soft values feedback different stages 
show example decoding function realized analog network 
sub networks perform analog decoding codes various levels feedback results extrinsic information metric calculation networks decoding sub networks turbo principle 
demonstrate network example psk modulation levels yielding rate bits psk symbol 
ett decoding equalization analog non linear networks method applicable multi level codes especially binary component codes 
psk signal set split binary decisions subsets method 
bits generating subsets protected binary codes equal length decoding performed metric control analog decoder network turbo feedback decoding coded multi level psk modulation 
decoders dec decoder decodes instantaneously result fed back turbo feedback immediately priori information decoders metric 
metric calculation th stage done jy log exp es exp es define euclidean distance received signal point signal point euclidean distance received signal point signal point fed back priori information values bit approximation metric jy max max max max max max max max delay connection network metric determination coded psk modulation 
approximation realized psk shown connection network received signal point connection networks 
connection network loaded 
example 
received weighted distances 
output delay connection network immediately relayed decoders 
simple example goes back uses psk repetition code protection partition spc code protection second partition 
third state left uncoded 
psk code achieves asymptotic gain db 
trivial case partition realized directed variable element second partition box plus element albeit inputs outputs 
short transition period soft output values information bits readily available decoder outputs including uncoded bits 
inputs received psk symbols 
network evaluated solving nonlinear differential equation inputs received psk symbols 
case map solution code representable time varying state trellis 
performance curves coincide showing satisfactory behavior simple analog decoder network 
analog networks source decoding analog networks equalization channel decoding extended source decoding 
analog decoder produces soft outputs get slight improvement performance analog output values soft bits channel decoder submission hagenauer offer hard decisions 
furthermore pcm reconstruction analog output channel decoder implemented simple analog circuit 
analog techniques channel decoding source decoding combined analog vlsi chip 
pulse code modulation way analog values bits simple understood digitizing technique pulse code modulation pcm 
versatile coding system limited speech signals 
speech encoders involve kind pcm encoders 
order get digital representation time amplitude continuous source signal perform time discretization amplitude discretization 
main parts pcm encoder consists waveform sampler followed amplitude quantizer 
sampling band limited analog source signal represented time discrete continuous signal sake simplicity assume values uniformly distributed limited magnitude uniformly distributed signals advantageous linear quantization bits represent quantized value vq vq quantization error derive ratio signal variance quantization error variance called signal quantization noise ratio 
db 
pcm reconstruction channel decoding transmission awgn channel described section 
making hard decisions matched filter output get binary values probability making wrong decision statistically independent calculated erfc es variance error ef vq vq analog network pcm reconstruction bit quantized signal 
rearrange equation get expected value efg eq fe fgg taken source bits channel values 
expect variables mutually independent 
square sum equal sum squares 
channel error occurs probability eq expected value eq power quantized signal pq get variance error snr pcm signal snr pcm making hard decisions matched filter output lose information 
concept soft bits section improve pcm reconstruction 
hard decision take corresponding soft bit defined equation 
analog network pcm reconstruction bit quantized signal shown 
channels high values jl yj change hard decided ett decoding equalization analog non linear networks bit tanh function runs saturation 
variance error soft bits pcm reconstruction calculated tanh transmission awgn channel conditioned probability density function written ju larger values dy smaller term equal smaller terms subtracted 
get small improvement snr middle snr region analog values pcm reconstruction 
simulation results showing gain table 
table signal noise ratio snr pcm signal concept hard bits comparison concept soft bits 
db snr pcm db snr pcm db hard bit soft bit joint channel decoding pcm reconstruction start simple channel code single parity check spc code 
compare different systems 
consists pcm signal quantized bits transmitted awgn channel channel coding 
second system quantize pcm signal bits th bit db snr pcm db uncoded pcm uncoded pcm uncoded pcm coded pcm spc code soft bits memory conv 
code hard bits memory conv 
code soft bits signal noise ratio uncoded pcm signals coded pcm signals 
channel coding spc code convolutional code information bits tail biting form 
channel coding spc code 
entire system consist preferably parallel transmission coded bits originating pcm bits 
analog decoder loaded weighted channel values network produces delay soft pcm bits fed analog pcm reconstruction similar shown 
simulation results shown 
middle part notice improvement simple channel code channels lose db due quantization errors 
tested convolutional code information bits tail biting form 
examined difference hard decided bit channel decoder soft bit analog decoder network pcm reconstruction 
corresponding simulation results 
see small improvement due saturation non linearities advantage lies completely analog realization channel source decoder operating delay 
note correlated samples analog source previous values priori information decoder 
summary performing tasks equalization channel decoding signal reconstruction receiver digital processors developed analog non linear highly parallel decoder networks purpose 
networks contain fundamental non linear functions directly implemented analog vlsi 
key element box plus element corresponding binary addition xor operation bits nonlinear building block links log likelihood ratios bits designed utilizing naturally hagenauer offer linearities bipolar transistor circuits 
circuit design typically requires transistors box plus operation 
investigations analog decoder networks binary codes start description code factor graphs design simple vlsi decoder chip 
network loaded soft matched filter output values channel loglikelihood ratios 
runs continuous time continuous values reaches steady state solution soft values 
realizes soft soft decoder similar map decoder turbo decoding 
analyzed behavior decoding network solving non linear differential equations memory convolutional codes terminated blocks bits simple block codes turbo codes formed simple block codes 
performances analog decoders close map performance achieved sequential digital processing 
complicated codes convergence network difficult 
networks operate trellis structure code generator parity connections best low density parity checks 
straightforward mapping binary trellis box plus circuits 
allows build decoder networks factor graphs non binary variable nodes 
box plus elements trellis section forward network backward network 
combined form map soft output 
developed network soft decision feedback equalizer tail biting guard interval block transmission multipath channels 
network operates ring connected interleaver channel decoder network 
novelty equalizer decoder operate simultaneously exchanging extrinsic values interleaver 
simulation results encouraging analog networks perform better classical sequential digital implementation certain types multipath channels turbo equalization iterations 
system oriented example discuss coded pcm transmission decoding sample reconstruction performed analog networks full soft analog values 
analog vlsi implementation decoder chip manufactured 
measurement results chip available soon 
expect analog circuit faster consumes power digital circuit 
course research preliminary phase 
investigated simple circuits 
theoretical practical questions remain open analysis network proof convergence stability 
anyway full swing backward analog world 
acknowledgment acknowledge early simulations max support wireless circuits systems research department lucent bell labs murray hill particular ran yan thad realization analog vlsi 
van wijngaarden detailed comments final draft 
manuscript received berrou glavieux 
near shannon limit error correcting coding decoding 
proc ieee int 
conf 
commun geneva switzerland pages may 
young hagenauer 
separable map filters decoding product concatenated codes 
proc ieee int 
conf 
commun geneva switzerland pages may 
wiberg 
approaches neural network decoding error correcting codes 
linkoping studies science technology thesis linkoping university department electrical engineering 

wang wicker 
artificial neural net viterbi decoder 
ieee trans 
commun vol 
pages feb 
johns martin 
circuits analog viterbi decoders 
ieee trans 
circuits systems ii analog digital signal processing vol 
pages dec 

efficient neural decoder convolutional codes 
ett european trans 
vol 
pages jul aug 
hopfield tank neural computation decisions optimization problems 
biological cybernetics vol 
pages 
davis 
loeliger 
nonalgorithmic maximum likelihood decoder trellis codes 
ieee trans 
inform 
theory vol 
pages july 
hagenauer 
soft soft benefits soft decisions stages digital receivers 
proc rd int 
workshop dsp techniques applied space communications netherlands sept 
hagenauer 
turbo principle tutorial state art 
proc int 
symp 
turbo codes related topics france pages sept 
lucas 
iterative soft decision decoding linear binary block codes product codes 
ieee journal selected areas commun vol 
pages feb 
ett decoding equalization analog non linear networks gallager 
low density parity check codes 
ire trans 
inform 
theory vol 
pages jan 
tanner 
recursive approach low complexity codes 
ieee trans 
inform 
theory vol 
pages sept 
wiberg 
loeliger koetter 
codes iterative decoding general graphs 
ett european trans 
vol 
pages sept oct 
forney 
iterative decoding way algorithm 
proc int 
symp 
turbo codes related topics france pages sept 
kschischang frey 
iterative decoding compound codes probability propagation graphical models 
ieee journal selected areas commun vol 
jan 
mceliece mackay 
cheng 
turbo decoding instance pearl belief propagation algorithm 
ieee journal selected areas commun vol 
feb 
kschischang frey 
loeliger 
factor graphs sum product algorithm 
submitted ieee trans 
inform 
theory july 
available www comm utoronto ca frank factor 

loeliger 
iterative sum product decoding analog vlsi 
proc 
isit cambridge ma usa page 

loeliger 
probability propagation analog vlsi 
unpublished manuscript 
available www ch papers html 
gilbert 
precise quadrant multiplier response 
ieee journal solid state circuits pages dec 
gilbert 
new wide band amplifier technique 
ieee journal solid state circuits pages dec 
hagenauer offer 
iterative decoding binary block convolutional codes 
ieee trans 
inform 
theory vol 
pages march 
wiberg 
codes decoding general graphs 
linkoping studies science technology thesis linkoping university department electrical engineering 
mackay neal 
near shannon limit performance low density parity check codes 
electronic letters vol 
pages march 
reprinted printing errors pages 
jimenez 
time varying periodical convolutional codes low density parity check matrix 
submitted ieee trans 
inform 
theory feb 

soft iterative decoding generalized parity check codes map decoding component hamming codes 
master thesis university ulm nov 
richardson urbanke 
capacity low density parity check codes message passing decoding 
submitted ieee trans 
inform 
theory nov 
richardson shokrollahi urbanke 
design provable low density parity check codes 
submitted ieee trans 
inform 
theory 
stahl anderson 
optimal near optimal short moderate length 
accepted publication ieee trans 
inform 
theory 
anderson 
properties error performance decoder 
techn 
report lund university oct 
mackay 
error correcting codes spares matrices 
ieee trans 
inform 
theory jan 

analog decoders implementation vlsi 
master thesis munich university technology depart 
commun 
engineering feb 
bahl cocke jelinek raviv 
optimal decoding linear codes minimizing symbol error rate 
ieee trans 
inform 
theory vol 
pages march 
sh 

fundamentals convolutional codes 
ieee press 

von block und 
master thesis munich university technology depart 
commun 
engineering feb 

analog decoding graphs cycles 
master thesis munich university technology depart 
commun 
engineering feb 
offer 
mit bei 
phd thesis munich university technology july published berichte vdi verlag series 
proakis 
digital communications 
new york mcgraw hill book 
berrou didier glavieux 
iterative correction intersymbol interference turbo equalization 
ett european trans 

vol 
pages sept oct 
hagenauer 
iterative equalization decoding mobile communications systems 
proc 
european personal mobile communications conference 
itg mobile kommunikation pages vde itg sept oct 
le 
digital sound broadcasting mobile receivers 
ieee trans 
consumer electronics vol 
aug 
imai hirakawa 
new multilevel coding method error correcting codes 
ieee trans 
inform 
theory vol 
pages 
hagenauer 
vom zum bit und 
vol 
pages sept oct 
jayant noll 
digital coding applications speech video 
englewood cliffs prentice hall 
submission hagenauer offer ett 
