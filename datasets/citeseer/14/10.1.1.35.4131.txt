international computer science institute center street ffl suite ffl berkeley california ffl ffl fax interior point methods semidefinite programming applications combinatorial optimization alizadeh tr september study semidefinite programming problem sdp problem optimization linear function symmetric matrix subject linear equality constraints additional condition matrix positive semidefinite 
review classical cone duality specialized sdp 
interior point algorithm converges optimal solution polynomial time 
approach direct extension ye projective method linear programming 
argue known interior point methods linear programs transformed mechanical way algorithms sdp proofs convergence polynomial time complexity carrying similar fashion 
study significance results variety combinatorial optimization problems including general integer programs maximum clique maximum stable set problems perfect graphs maximum partite subgraph problem graphs various graph partitioning cut problems 
result barrier oracles certain combinatorial optimization problems particular clique stable set problem perfect graphs linear programming formulation requires exponentially inequalities 
existence barrier oracles refutes commonly believed notion order solve combinatorial optimization problem interior point methods needs linear programming formulation explicitly 
research supported part nsf 
cda air force office scientific research afosr national science foundation dcr minnesota supercomputer institute 
preliminary version appeared proceedings nd integer programming combinatorial optimizations ipco held carnegie mellon university pittsburgh pa title combinatorial optimization semidefinite matrices current version appear siam journal optimization 
currently international computer science institute berkeley ca 
mail alizadeh icsi berkeley edu ii consider optimization problem call standard semidefinite programming problem sdp minfc ffl ffl delta delta delta theta matrices symmetric ffl operation inner product matrices ffl ij ij trace inequality constraint indicates partial order real symmetric matrices respectively gamma positive semidefinite respectively positive definite 
semidefinite programming problem extension linear programming lp 
specifically condition diagonal matrix added constraint set reduces linear programming 
semidefinite programs arise wide variety applications control theory see vb fan combinatorial optimization see section structural computational complexity theory see fl 
oldest form semidefinite programming evaluation eigenvalues symmetric matrix 
fact reformulate classical theorems rayleigh ritz largest eigenvalue fan sum eigenvalues symmetric matrix semidefinite programs see ow ow section 
special cases techniques appropriate exist better algorithms theoretical practical points view 
nontrivial semidefinite programs simply equivalent evaluation eigenvalues symmetric matrix arise form minimizing largest sum largest eigenvalues matrix subject linear constraints early example problems studied donath hoffman connection graph bisection graph partitioning problems dh dh see section 
cullum donath wolfe studied problem minimizing sum eigenvalues linearly constrained matrix cdw 
analyzed problem nonsmooth optimization point view 
fletcher studied similar problem point view nondifferentiable optimization 
particular derives expressions subgradients sum eigenvalues symmetric matrix formulates optimality conditions problem 
spirit fletcher overton ove studies largest eigenvalue symmetric matrix convex nondifferentiable function 
earlier ove derives quadratically convergent algorithm problem minimizing largest eigenvalue affinely constrained matrix 
extended ove second order methods sequential quadratic programming order methods sequential linear programming large scale problems developed 
algorithms contained works spirit simplex method linear programming active set methods traverse boundary feasible set converge optimal solution 
reason worst case computational complexity bad simplex method practice may quite 
semidefinite programs polynomial time solvable priori bound size solution known 
point implicit lov special instance sdp problem 
proved grotschel lov asz schrijver gls 
polynomialtime solvability sdp direct consequence general results ellipsoid method convex programming 
main point essentially optimization linear function convex set endowed separation oracle priori bound objective achieved polynomial time ellipsoid method see gls thorough treatment 
ellipsoid method proven practical applications including sdp 
development possibility interior point methods obtain polynomial time algorithms semidefinite programs 
earliest direction knowledge nesterov nemirovskii nn 
important authors develop general approach interior point methods solving convex programming problems concept barrier functions 
see nn complete treatment subject 
nesterov nemirovskii show convex set endowed barrier function interior point algorithm optimizes linear function furthermore iterations algorithm results interior point half distance optimal solution 
special case nesterov nemirovskii show linear programs inequality constraints quadratic programs convex quadratic constraints semidefinite programs theta matrices admit barriers 
authors extend revolutionary result karmarkar kar general class convex programs 
article study interior point methods semidefinite programs alternative point view 
ali started somewhat independent nn 
nesterov nemirovskii obtain complexity theorems specializing general results sdp 
hand take specific interior point algorithm linear programming ye projective potential reduction method ye extend sdp 
furthermore argue essentially known interior point linear programming algorithm transformed algorithm sdp mechanical way proofs convergence polynomial time computability extend similar fashion 
jar vandenberghe boyd vb developed similar interior point algorithms special forms sdp 
polynomial time interior point methods sdp interesting consequences combinatorial optimization problems 
order solve problem ellipsoid method explicit listing inequalities linear programming formulation needed 
needs separation oracle initial ellipsoid containing feasible region start process 
generally believed order apply interior point methods combinatorial optimization problem needs explicit listing inequalities lp formulation see gls gt 
instance goldfarb todd survey article linear programming write appears karmarkar new algorithm theoretical implications far limited ellipsoid method 
karmarkar algorithm requires linear programming problem explicitly constraints variables listed appear directly susceptible column constraint generation 
provide polynomial algorithms combinatorial optimization problems successfully analyzed ellipsoid method 
article examples combinatorial optimization problems lp formulations require exponentially inequalities design interior point algorithms solve polynomial time 
fact emphasize general results nesterov nemirovskii imply principle apply interior point methods solve combinatorial optimization problems explicit knowledge lp formulation 
required self concordant barrier oracle polynomially bounded parameter 
interesting example clique stable set problem class graphs known perfect graphs 
section construct barrier indirectly sdp formulation problem due lov asz 
particularly interesting presently linear programming formulation stable set clique problems perfect graphs polynomially bounded number facets known 
linear programming interior point methods goldberg derive sublinear time parallel algorithms bounded weight assignment problem 
show maximum stable sets perfect graphs computed randomized sublinear parallel time 
furthermore lov asz schrijver ls argue branch bound scheme programs interior point sdp algorithms may efficiently yield sharper bounds possible linear programming relaxations problems 
section review called cone duality theory specialized semidefinite programs 
theory quite classical somewhat forgotten optimization literature 
turns sdp cone duality generalization linear programming duality appropriate interior point methods point view expressed latest edition nesterov nemirovskii nn 
section develop interior point algorithm mentioned direct extension ye projective potential reduction method 
furthermore propose recipe extend mechanically known interior point algorithms lp similar algorithms sdp 
section go differences sdp lp far interior point methods polynomial time algorithms general concerned 
section build results overton ow ow derive semidefinite programming formulation various eigenvalue optimization problems 
state complementary slackness results problems 
section study applications sdp interior point methods various combinatorial optimization problems 
notation lower case boldface letters name column vectors upper case letters name matrices 
refer members vectors 
vector th coordinate 
denote vector ones zero vector respectively 
denote identity zero matrices respectively 
thetan set symmetric theta matrices 
th largest eigenvalue symmetric matrix lower case greek letter th largest eigenvalue absolute value wise 
partial order dot product ffl defined symbol component wise comparison matrices vectors 
diag denotes diagonal matrix vector diag vector diagonal entries matrices kxk kxk frobenius spectral norms respectively recall case symmetric matrices kxk equals spectral radius ae 
vectors kxk kxk euclidean maximum norms kxk jx norm theta matrix vec pq column vector columns stacked 
pq vector mat pq theta matrix th column entries gamma ip clear context drop subscript 
instance set relations ffl delta delta delta may rewritten thetan row vec 
mat omega kronecker product matrices thetan omega np theta block matrix block ij facts repeatedly omega omega ac omega bd vec abc omega vec see gra 
subsets integers respectively submatrix rows taken rows indexed columns indexed indicate rows indexed columns indexed respectively 
thetap ajb theta matrix columns columns followed columns semidefinite programming problem refers optimization problem mixture symmetric matrix scalar valued variables linear objective function combination linear equality component wise inequality constraints 
define name left hand side terms right hand side algorithms assignment 
convex cone polar cone set fx stated cone positive semidefinite matrices 
note fact direct consequence theorem hj 
simple undirected graph loops multiple edges 
stable set subset vertices mutually nonadjacent 
clique subset vertices mutually adjacent 
partite graph vertices partitioned subsets delta delta delta stable set 
clique covering collection delta delta delta sets vertices clique duality theory duality theory quite similar linear programming may constructed semidefinite programming problem 
section state theory standard form sdp problem 
result general form follows exactly linear programming 
theory developed general context works 
easy see cone ae closed pointed gammak convex induces partial order iff gamma instance nonnegative orthant positive semidefinite matrices induce component wise partial orders respectively 
duality theory linear programming extended generalized linear programming problems replaces primal problem replaces dual problem 
study generalized duality theories 
hurwicz hur ben israel charnes borwein wolkowicz bw bw wolkowicz wol developed general formulations duality theory 
comprehensive treatment generalized duality theory point view infinite dimensional linear programs see text anderson nash alternative extensions refer bw bw 
worth mentioning study duality theory point view basic feasible solutions extend tableau proofs lp duality 
latest version nesterov nemirovskii text nn treats cone duality general convex programs 
papers overton ow fletcher fle treat duality theory eigenvalue optimization problem point view 
approach related duality theory relies derivatives subgradients 
lov asz lov grotschel lov asz schrijver gls gls gls shapiro sha study duality theory treatment restricted special forms sdp 
convenient assume symmetric 
loss generality assumption 
symmetric ffl ffl replace 
argument holds 
assumptions symmetry allow formulate pair primal dual standard sdp problems primal min ffl ffl delta delta delta dual max gamma notice similarity primal dual sdp pair corresponding linear programming pair 
state weak duality lemma 
lemma feasible matrix primal feasible vector dual 
ffl proof ffl gamma ffl gamma ffl gamma ffl inequality true inner product positive semidefinite matrices nonnegative due self polarity positive semidefinite cone 
state generalizations farkas lemma 
generalizations arbitrary convex cones studied early hurwicz hur 
see history various extensions farkas lemma cones 
study relevant forms lemma special case sdp 
possible generalize classical farkas lemma cones additional qualifications 
difficulty arises fact affine transformations closed cones necessarily closed appropriate strong forms separation theorems invoked polyhedral cones closedness preserved affine transformation 
purposes need set closed class sufficient conditions closedness assuming certain sets associated nonempty interiors 
conditions referred slater type constraint qualifications 
conditions weakest possible sufficient purposes 
need case assume interior primal dual problems valid interior point algorithm 
furthermore section show pair primal dual semidefinite programs may transformed equivalent pair nonempty interior primal dual problems 
lemma slater type constraint qualifications lemma mat closed 
recall mat proof condition lemma says int translate linear subspace intersects interior 
equivalent saying symmetric theta matrix written sum matrices positive semidefinite belongs thetan polar set fx 
solution system roc theorem implies closed 
state common form farkas lemma schrijver text sch extended positive semidefinite cone alternative extensions closedness assumption treated bw bw wol lemma extended farkas lemma thetan matrix rows symmetric delta delta delta furthermore vector mat 
exists symmetric matrix mat 
proof part mat ffl inequality due self polarity positive semidefinite cone 
prove part suppose system infeasible 
fa 
lemma closed cone exist hyperplane specifically linear halfspace separates exists vector see roc theorem pp 
means ffl mat equivalent mat part theorem proved 
may formulate prove variants farkas lemma similar vain extensions lemmas component wise inequalities example schrijver text sch 
related extensions infinite programs studied hur ck case matrix variables cm 
extensions need assume closedness criteria dual problem modified cones wol instance 
mention lemma thetam matrix columns linearly independent form symmetric thetan assume exists symmetric matrix 
mat ax solution ffl 
lemma thetan thetam suppose exist matrix 
system solution iff symmetric matrices implies ffl 
lemma thetan thetam suppose exist matrix 
system solution iff symmetric matrices implies ffl 
lemma thetan thetam suppose exist matrix 
system solution iff symmetric matrices implies ffl 
strong duality theorem similar linear programming holds sdp 
say primal problem feasible set fx thetan nonempty say infeasible 
feasibility defined similarly dual 
recall infimum empty set definition similarly supremum empty set gamma 
furthermore primal respectively dual problem unbounded infimum respectively supremum feasible set gamma respectively 
theorem inf fc ffl sup fb gamma mat assume vector 
proof notice dual problem feasible proof lemma showed thetan particular mat gamma primal problem unbounded weak duality lemma gamma dual problem infeasible contradiction 
dual problem unbounded weak duality lemma primal infeasible theorem proved 
conversely primal problem infeasible extended farkas lemma implies vector matrix mata implies dual problem unbounded dual feasible pair add arbitrarily large positive multiple obtain feasible pair larger objective function value 

may assume finite 
suppose system ffl infeasible 
extended farkas lemma exists scalar vector th row 
equivalent mat extended farkas lemma implies infeasible 
dividing relations get gamma mat gammay gamma gammay means optimal solution dual problem 

dividing relations gammay get gammac mat gammay gamma gammay fact strict inequality gammac mat gammay gamma gammay gammaffl ffl 
optimality exist gamma mat gamma ffl adding sets relations get mat gammay gamma gammay gamma extended farkas lemma implies primal problem infeasible 
assumption results contradiction 
weak duality lemma conclude possible derive complementary slackness theorem 
fact grotschel lov asz schrijver gls shapiro sha mention complementary slackness theorem restricted form sdp 
note strong duality theorem true primal dual problems bounded feasible duality gap ffl vanishes 
sdp linear programming stronger form complementary slackness results observation 
note easy lemma lemma symmetric theta matrices 
ffl ab 
proof omega eigenvalue decomposition omega diag 
delta delta delta set au particular diagonal elements ii 
need show omega 
ffl ffl omega ii 
summands nonnegative follows zero 

ii entire row column zero 

ii 
suppose ij ij entire column zero ij contradiction 
complementary slackness theorem immediate theorem feasible matrix primal feasible vector dual 
define gamma mat 
primal dual optimal respectively notice contrast linear programming component wise multiplication complementary slackness theorem replaced ordinary matrix multiplication 
complementary slackness theorem sdp restated way quite similar lp variant corollary feasible matrix primal problem eigenvalues delta delta delta gamma mat feasible dual problem eigenvalues delta delta delta primal dual optimal respectively commute permutation eigenvalues delta delta delta recall convention th largest eigenvalues respectively point necessitates permutation statement corollary 
proof optimal 
commute share system eigenvectors 
columns joint system orthonormal eigenvectors delta delta delta 
delta delta delta knuth anonymous referee suggested slightly shorter proof ffl trace ba ba trace zero matrix product equal zero ab 
feel proof better underscores similarity proof linear programming complementary slackness theorem 
permutation corollary follows immediately multiplying right hand sides identities 
extend notion linear programming sdp requiring strict complementarity condition 
stated saying preceding corollary exactly corresponding eigenvector zero delta delta delta equivalently may require rank rank standard linear programming absence say precisely components optimal solution nonzero clear general predict rank rank solving sdp problem 
say optimum primal sdp problem attained boundary semidefinite cone 
section encounter negative effect unpredictability rank optimal solution context interior point methods 
similar linear programming complementary slackness theorem may basis primal dual algorithms 
interior point algorithm primal dual method maintains primal feasible dual feasible iteration moves closer zero matrix 
norm kx indication close current solution optimum 
general set equations xs system equations number unknowns 
absence degeneracy apply instance newton method quasi newton method solve system 
sdp convex program real solutions system global optima corresponding sdp problem 
linear programming semidefinite programs may arise variety forms standard form just type 
may positive semidefinite constraints imposed linear combinations matrices dual problem example 
may component wise inequalities scalar matrix variables addition inequalities 
may matrix expressions constrained positive semidefinite 
may 
course linear programming possible convert problems standard form usually introducing new scalar matrix variables new constraints 
convenient apply duality directly linear programs general form 
easy show rules obtaining dual straightforward extension rules linear programming problem 
main addition constraints involve semidefinite relations matrix valued expressions give rise matrix valued dual variables semidefinite constraints 
rules summarized table table direct generalization similar table text jarvis sherali bjs 
interior point algorithm 
section develop potential reduction method solving primal problem nj log fflj iterations get approximate solution ffl relative accuracy ffl sufficiently small 
development closely follows ye projective technique linear programming ye 
ye complexity analysis extended semidefinite programs 
min max matrix scalar 
matrix scalar matrix scalar 
matrix scalar matrix 
matrix matrix 
matrix matrix scalar unrestricted 
matrix scalar matrix scalar 
matrix scalar matrix scalar 
matrix scalar matrix 
matrix matrix 
matrix matrix scalar 
matrix scalar unrestricted duality rules semidefinite programming 
potential functions projective transformations 
recall interior cone positive semidefinite matrices set positive definite matrices interior points nonsingular 
boundary cone consists singular semidefinite matrices eigenvalues boundary matrices zero 
particular optimal solutions primal problem singular 
assume primal dual problems non empty interiors initial primal dual points finite optimal solutions 
section show transform primal dual pair equivalent initial interior primal dual solution available 
constant known lower bound optimal value primal problem 
interior primal feasible matrix interior dual feasible vector gamma 
define primal potential function oe ln ffl gamma gamma ln det primal dual potential function ln ffl gamma ln det xs motivation may think semidefinite constraints expressed delta delta delta standard logarithmic barrier applied constraints get ln ln det strategy algorithm generate sequence interior primal feasible matrices sequence interior dual vector matrix pairs sequence decreases arithmetic progression 
appropriate choice imply duality gap ffl gamma decreases geometric progression particular constant fraction original gap iterations 
describing algorithm state lemma direct generalization similar lemma appears analysis interior point linear programming methods 
recall ae spectral radius matrix equals largest eigenvalue positive semidefinite 
lemma symmetric theta matrix 
oe oe ln det trace gamma gamma trace gamma gamma ae gamma proof interior point linear programming algorithms shown kx gamma ln gamma gamma kx gamma gamma kx gamma easily proved expanding ln see example karmarkar kar ye ye 
prove lemma simply substitute projective transformation bring current iterate center center identity matrix contrast linear programming center 
important point transformation map set symmetric matrices 
needed transformed problem remains meaningful sdp problem 
current interior primal feasible point 
find symmetry preserving projective transformation maps identity matrix theta matrix infinitely choices instance cholesky factor square root shall see shortly matter select affect algorithm behavior performance 
fix integer define thetan thetan theta 
gamma xl gammat gamma ffl gamma ffl inverse transformations gamma xl primal sdp problem transformed min ffl avec ax trace cl gamma omega gamma note theta rank matrix 
transformed problem may viewed mixed linear semidefinite program 
may define primal potential function transformed problem oe ln ffl gamma ln det gamma ln invariant property holds potential functions projective transformations lemma delta delta delta gamma oe gamma oe oe gamma oe result easily proved expanding oe applying lemma prove reduction primal dual potential function 
corollary oe gamma oe ln ffl trace kx gamma ik kx gamma gamma kx gamma ik kx gamma potential reduction algorithm 
similar linear programming replace inequality constraints inscribed ball constraint sdp problem ball centered 
replaced ball optimization problem min ffl avec ax trace kx gamma ik kx gamma fi fi fixed constant determined shortly 
solve problem map result back original space get point serves candidate iterate 
solution gamma fi kp candidate new primal iterate gamma pa vec pa projection vector null space expansion projection pa gamma vec ij vec ij gamma gamma aja aja aja gamma aja delta define gamma aja aja delta gamma aja gamma omega bb delta gamma avec cx gamma mat serve candidates new dual iterates 
terms quantities may written vec gammaz gamma ffl gamma observe independent fact actual computation need explicitly 
show primal candidate dual candidates reduce value primal dual potential function constant amount 
observe pa projector pa get ffl gamma gamma noting ln nonnegative corollary implies corollary 
oe gamma oe gamma fi kp trace fi gamma fi delta size duality gap current iterate delta ffl gamma delta ffl ffl gamma delta interpreted value duality gap choose new dual iterate 
deriving amount reduction potential function prove lemma lemma real number ff ff kp ff delta furthermore fl fl fl fl gamma delta fl fl fl fl delta ff gamma ff fi fi fi fi delta delta gamma fi fi fi fi ff proof suppose 
positive definite eigenvalues equal 
kp ae delta gamma delta contradiction 
kp delta gamma gamma delta contradiction 
theta vec gamma delta gamma delta gamma delta delta gamma delta gamma delta ffl gamma delta kp fl fl fl fl gamma delta fl fl fl fl delta gamma delta delta gamma delta gamma delta fl fl fl fl gamma delta fl fl fl fl delta gamma delta false kp delta ff gamma ff delta gamma delta ff delta inequality proved right hand side inequality quadratic function delta minimizing 
contradicts assumption lemma true 
false delta gamma delta ff delta follows 
may prove potential reduction theorem 
theorem interior feasible matrix primal problem interior feasible dual 
gamma gamma 
exist absolute constant ffi gamma ffi gamma ffi furthermore set ff fi ffi 
proof constant ff kp ff delta gamma oe gamma oe oe gamma oe fi gamma fi inequality true corollary 
conditions lemma satisfied 
applying lemma delta setting fl ff gammaff ln ffl gamma ln det ln nx ffl delta gamma ln det nx delta ln gamma ln det nx delta ln delta gamma ik gamma delta gamma ik ln ffl gamma ln det fl gamma fl relation results applying arithmetic geometric mean inequality eigenvalues real 
lemma delta gamma gamma ff delta ln ffl ffl ln delta delta gamma ff adding get gamma gamma ff fl gamma fl easily verified choice ff fi ffi consistent conditions theorem 
result projective version algorithm displayed 
note algorithm fi obtained line search potential function 
justify subsection 
potential reduction polynomial time solvability 
show starting pair interior primal dual feasible points tolerance ffl get pair duality gap ffl running algorithm number times depends polynomiality ln ffl error initial pair 
theorem gamma mat initial interior points primal dual semidefinite programming problems 
primal dual potential function assume ne constant algorithm generates sequence interior primal dual points ffi fixed number ffi nj log fflj iterations primal dual solutions ffl gamma ffl algorithm sdp input theta matrix interior feasible primal problem vector interior feasible dual problem constant ffl 
output primal feasible solution dual feasible solution ffl gamma ffl 
method set ff 
set set gamma mat 
ffl gamma ffl compute 
kp ff ffl gamma find fi argmin fi gamma fil line search procedure 
set gamma fi set gamma 
set find argmin zz line search 
set 
set 
set 

projective potential reduction algorithm 
proof iteration reduces potential function ffi ne nj log fflj iterations gamma ne gamma nj log fflj delta log gamma log fflj nj log ffl ln ffl gamman ln ffl ln det nj log ffl gamman ln nj ln ffl inequality comes applying arithmetic geometric inequality eigenvalues real matrices positive definite 
ln ffl log ffl ffl ffl gamma theorem follows 
theorem essentially says start potential reduction algorithm pair primal dual points initial error value potential function ne log fflj iterations solution duality gap ffl 
ffl gammae term log fflj dominates number iterations bounded nj log fflj 
observe proof solely depends reduction potential function 
guarantee reduction ffi iteration larger reductions may speed algorithm affecting worst case complexity 
steps algorithm allow line search find step length fi maximizes reduction potential function 
feasibility boundedness polynomial time computability 
complete analysis study feasibility sdp problem bounds norms optimal primal dual solutions 
situation somewhat different linear programming 
assume entries primal dual problems integers 
contrast linear programming optimal solution necessarily rational number 
need specify error tolerance ffl ask pair primal dual solutions duality gap ffl ffl 
ffl rational number define size sdp problem number bits binary representation ffl entries see gls complete definition 
expect interior point method developed previous sections leads algorithm runs time polynomial true general solution may exponentially large 
see consider optimization problem gamma delta delta delta ng clearly xn solution problem requires exponential number bits 
written semidefinite program min xn gamma gamma delta delta delta sdp problem easily turned standard form sdp input size ffl say polynomial output requires exponential number bits 
algorithm solve polynomial time cases including combinatorial optimization problems described may able put priori bound norms optimal solutions 
instance special cases may able prove kxk nm kyk nm 
cases show interior point algorithm developed earlier produce polynomial time primal dual solutions duality gap smaller ffl 
notice ellipsoid method priori bound assumed requiring initial ellipsoid containing feasible solution supplied 
number bits binary expansion integer known bound kx ky similar linear programming transform pair primal dual problems pair initial interior feasible points readily available 
extend construction suggested kojima mizuno turn megiddo meg 
solution algebraic system equations xs algebraic solutions optimal solutions sdp problem integral input 
am indebted joshi ramana bringing attention error ali ali claimed norm solution sdp problem bounded joshi essentially provided counter example 
consider pair primal dual problems min ffl mx avec gamma avec mat gamma ffl max gamma ny mat gamma mat gamma gamma avec arbitrary positive definite theta matrices arbitrary vector large positive numbers ensure 
clearly gamma mat gamma ffl interior feasible primal large gamma gamma avec interior feasible dual problem large 
choosing suffices choose max gamma ii ii gamma ffl max gamma trace instance may set easy see optimal value zero original primal infeasible proof exactly kojima 
similarly optimal value zero original dual infeasible 
optimal optimal original primal dual problems respectively 
furthermore easily verified value primal dual potential function initial point bounded 
general sdp problem algorithm reduces primal dual potential function constant amount may find nmax log fflj iterations pair primal dual feasible solutions duality gap ffl ffl gammal gammal number iterations bounded nj ln fflj 
correspondence proofs linear semidefinite programming 
remarkable similarity algorithm ye lp algorithm ye suggests lp interior point methods may extended sdp problems 
proofs convergence polynomial time complexity may extended 
correspondence summarized 
interior point algorithm linear programming may construct mechanical way algorithm sdp problem replacing entries lp column corresponding entry sdp column 
proofs convergence polynomial time complexity may extended mechanically manner 
verified claim approaches gon ye ye see ali monteiro lp sdp unknown vector unknown symmetric matrix inequality constraints constraints dual variable dual variable dual slack vector dual slack symmetric matrix linear scaling linear scaling 
diag gamma gamma xl gammat mat gamma omega gamma vec projective scaling projective scaling diag gamma diag gamma gamma xl gammat trace gamma xl gammat barrier function barrier function ln ln det norms norms kxk kxk kxk kxk kxk correspondence linear programming semidefinite programming adler ma 
table may summarized rule linear programming algorithm replace implicit explicit 
furthermore scaling replace affine projective transformations corresponding symmetry preserving transformation matrices 
notice rules implicitly derive various duality complementary slackness theorems sdp corresponding theorems lp 
differences sdp lp interior point algorithms 
far emphasized similarity linear semidefinite interior point methods 
important distinctions favorable circumstances lp extend sdp 
seen differences lp sdp studied priori bounds number bits optimal solutions 
list distinctions studied carefully serious practical implementation interior point sdp algorithms attempted 

absence degeneracy predict precisely entries optimal vector nonzero standard linear program coefficient matrix thetan recall iteration primal interior point algorithm main computational effort obtaining gamma vector 
rank reasonably computation fairly straightforward typically numerical difficulties arise 
sdp assume strict complementarity rank rank know rank going solving sdp problem 
furthermore rank main computational sdp interior point methods computing omega gamma full rank reasonably omega may converge singular matrix means guaranteed 
issue arises dual primal dual interior point algorithms 

main reason interior point methods linear programming practically competitive aside small number iterations matrix aa sparse ada diagonal matrix fact ada aa precisely nonzero structure 
order elimination obtained aa order subsequent iterations interior point algorithm 
case sdp 
general aa sparse matrix omega may sparse 
clear factorization omega factoring omega 
karmarkar kar gives nice amortized method updating factors ada develops technique differ entries iterations bounded 
observation manages reduce number operations factor clear extend karmarkar amortized scheme sdp interior point algorithms 
eigenvalues semidefinite programs 
cases semidefinite programs arise form minimizing maximizing linear combination eigenvalues symmetric matrix subject constraints matrix 
section study problems form show appropriate assumptions special case semidefinite programs 
give primal dual characterization problem examine complementary slackness theorem specialized problem 
minimizing sum eigenvalues 
consider minimizing sum eigenvalues symmetric matrix subject linear constraints matrix 
consider variations minf delta delta delta bg min show problems semidefinite programs elegant characterization overton ow ow 
theorem sum eigenvalues symmetric matrix semidefinite programming characterization holds delta delta delta max ffl trace proof see overton ow ow 
worth mentioning result beautiful convex hull characterization known early see fw unfortunately remained somewhat obscure 
statement result lemma fy thetak ig fw trace ig conv exactly set extreme points historical account result connection known computationally useful theorem ky fan interesting connections theorem birkhoff von neumann concerning convex hull doubly stochastic matrices refer overton ow 
express semidefinite program derive characterization sum eigenvalues dual 
constraint gives rise dual variable rd line table satisfies 
variable satisfies line table gives rise constraint zi theorem sum eigenvalues symmetric matrix semidefinite programming characterization holds delta delta delta min kz trace zi easy incorporate equality constraints replacing equivalent min kz trace zi gamma dual dual characterization max mat trace complementary slackness result primal feasible dual feasible states optimal gamma gamma similarly may expressed primal dual pair min kz trace zi gamma max ffl trace ffl delta delta delta characterizations simpler case constraint variable redundant 
problem minf bg may expressed solution primal dual sdp pair min zi gamma max trace mat mat complementary slackness theorem indicates primal dual optimum solution satisfy addition primal dual feasible mat gamma minimizing weighted sums eigenvalues 
section consider weighted sum eigenvalues matrix 
delta delta delta set fixed real numbers 
interested problem minfm delta delta delta bg note condition delta delta delta necessarily convex program 
formulate problem semidefinite program technique originally employed donath hoffman dh 
rewrote sum follows delta delta delta gamma gamma delta delta delta gamma gamma delta delta delta gamma delta delta delta observed right hand side nonnegative combination convex functions convex 
formulation allows write semidefinite programming problem 
partial sums eigenvalues may relations subsection obtain primal min iz trace gamma gamma delta delta delta delta delta delta dual max gamma gamma trace delta delta delta delta delta delta formulations 
complementary slackness condition feasible delta delta delta optimal may stated gamma gamma gamma delta delta delta notice primal dual characterizations contain semidefinite constraints involving theta matrices interior point methods discussed earlier require kn iterations new significant digit accuracy 
interesting improve complexity 
minimizing sums absolute value wise largest eigenvalues 
results preceding sections may extended sum absolute value wise largest eigenvalues 
overton derived max characterization similar applying duality result obtain theorem symmetric matrix sum delta delta delta equal optimal solution pair primal dual semidefinite programs max ffl gamma ffl trace min kz trace trace zi gamma zi recall th largest eigenvalue absolute value sense 
solve optimization problem delta delta delta bg may simply add equality constraints min formulation take dual get pair primal dual semidefinite programs min kz trace trace zi gamma zi max gamma trace complementary slackness theorem indicates primal feasible dual feasible optimal gamma gamma gamma results may generalized weighted sums absolute value wise largest eigenvalues 
words problem minfm delta delta delta bg may expressed primal dual pair semidefinite programs 
ignore equality constraints assume fixed matrix theorem sum delta delta delta symmetric matrix equals optimal solution primal program min iz trace gamma gamma delta delta delta gamma delta delta delta delta delta delta delta delta delta dual program max gamma ffl gamma ffl trace delta delta delta delta delta delta delta delta delta may replace impose equality constraints min characterization 
dual pair primal dual formulation min iz trace gamma gamma delta delta delta gamma delta delta delta delta delta delta delta delta delta max gamma gamma trace delta delta delta delta delta delta delta delta delta complementary slackness theorem problem states primal feasible dual feasible delta delta delta optimal gamma gamma gamma gamma gamma delta delta delta characterization max part overton ow 
fletcher fle derives closely related result result incorrect fletcher 
min characterizations primal dual formulation variants equality constraints believe new 
similar formulations derived maximizing weighted sums smallest eigenvalues symmetric matrices sum largest singular values arbitrary matrix omit formulations see sub 
maximizing smallest eigenvalues symmetric matrix absolute value wise sum smallest singular values arbitrary matrix formulated sdp problems convex programs 
applications combinatorial optimization 
semidefinite programming problem studied previous sections applications combinatorial optimization especially graph theory 
connection usually spectral properties graphs 
sections examine general approach lov asz schrijver applies semidefinite programming general zero integer programming problem 
study applications maximum stable set maximum induced partite subgraph graph partitioning particular graph bisection problems 
nonlinear relaxations programming 
consider integer programming problem maxfc ax gg lp relaxation results replacing 
relaxation serves approximation solution 
general approximation may far actual solutions 
effective methods integer programming consist adding new cutting planes lp relaxation 
little done generating nonlinear convex cuts feasible region lp relaxation 
generally cuts may produce far better approximations planar cuts 
ingenious approach creating class nonlinear cuts proposed lov asz schrijver ls 
idea lift space vectors theta symmetric matrices convenient integer program introducing new variable multiple imposing constraint 
transformation homogenized integer programming problem linear programming relaxation written ip max delta delta delta delta delta delta lp max delta delta delta delta delta delta convex cone feasible region lp relaxation constraint integer hull convex cone generated vectors 
decompose set constraints sets possible overlap multiply inequality set inequality second set obtain quadratic constraints replace occurrence new variable ij get linear constraints impose matrix ij positive semidefinite constraints 
cones defined second sets constraints space matrices just defined denoted 
formally subsets cover index set inequality constraints lp 
define set fx 
require constraints subsets 
fx thetan xe diag omega vec space diagonals matrices main result lov asz schrijver purposes discussion clear optimizing linear function mixed linear semidefinite programming problem interior point techniques may applied long explicit system inequalities 
process just described may quite powerful certain combinatorial presentation restrictive ls 
lov asz schrijver assume matrix explicitly 
assume lp relaxation endowed separation oracle 
optimization problems 
instance general branch bound algorithm may interior point algorithms solve optimization problem maxfc solution may bound resulting necessarily satisfies 
coordinate branch solving subproblems additional constraints respectively 
practical point view subproblems polynomial time solvable interior point methods computationally expensive classical branch bound approach linear programming relaxations 
advantage bounds sharper hopefully sharper corresponding lp bounds total number subproblems solved may considerably smaller 
lov asz schrijver show applying operator lp relaxation stable set polytope graph gives bounds stronger combination known classes linear cuts 
recall stable set graph subset vertices pair vertices nonadjacent 
weight vector vertices weight vertex weighted maximum stable set problem graphs formulated program max fi jg adding new variable apply operator fx fx gamma intersect result hyperplane 
resulting set stab 
optimization set semidefinite program done polynomial time interior point methods lov asz schrijver ellipsoid method establish polynomiality 
furthermore clear stab stab stab stab convex hull vectors characterize stable set stab polytope associated lp relaxation polytope obtain replacing constraints 
set stab convex generally 
lov asz schrijver show set points stab stab satisfy classes known valid inequalities stab 
clique constraints 
clique subset vertices pair adjacent 
stable set clearly js kj characteristic vectors respectively 
observation implies cliques inequality valid stab set stab polytope defined inequalities 

odd hole constraints 
cycle hole edges stable set know jc sj cycles constraint valid stab set stab polytope defined induced cycles 
odd anti hole constraints 
graph edge complement set odd cycle 
maximum stable set vertices jc sj stable sets inequality valid stab set stab polytope defined inequalities 
odd wheel constraints 
graph vertices vertices delta delta delta gamma induce cycle vertex adjacent vertices 
called odd wheel 
shown see gls wheels inequality gamma gamma gamma valid stab set stab polytope defined set inequalities 
turns see ls stab stab stab stab stab stab stab stab provides sharper relaxation stab polytopes defined 
optimization stab sdp problem interior point methods developed may yield practical ways achieving strong bounds maximum stable set problem 
barriers polytopes exponentially facets 
strong property ellipsoid method combinatorial optimization problems generally need linear programming formulation problem explicitly 
required existence separation oracle initial ellipsoid start process 
instance certain classes graphs stable set polytope may characterized completely stab graphs called perfect 
classes may stable set polytope characterized stab perfect graphs stab stab perfect graphs general combination polytopes mentioned items 
stable set polytopes graphs general exponentially facets 
gls ls shown construct separation oracles polytopes find maximum stable set corresponding graphs polynomial time 
common belief contrast ellipsoid method interior point methods require explicit knowledge facets polytope wish optimize see instance gls quotation gt 
polynomial time interior point methods optimize stab special cases mentioned number facets polytopes may exponentially large 
fact ground breaking nesterov nemirovskii implies principle listing inequality constraints lp formulation necessary 
needs separation oracle required ellipsoid method barrier oracle polynomially bounded self concordance parameter 
instance indicated optimize stab polynomial time stab stab classes graphs mentioned 
fact results nesterov nemirovskii imply directly compute barrier function theorem intn stab 
function defined minf gamma ln det diag stab interior point algorithm uses barrier finds stab nmax kwk ln ffl iterations error ffl 
proof nesterov nemirovskii prove ln det cone positive semidefinite theta matrices 
see nn definitions 
show existence self concordant barrier convex set general implies optimize linear function set iterations yielding significant bit 
furthermore proposition pp 
nn show convex set endowed self concordant barrier affine transformation mapping function self concordant gamma int kg theorem follows immediately definition stab ls affine transformation replaced projection elements stab diagonals 
fact result shows convex set lifted convex set lifting endowed polynomial time computable self concordant barrier polynomial time computable self concordant barrier combinatorial optimization examples polytopes exponentially facets lifted polytopes higher dimensions fewer polynomially facets 
polytopes apply interior point methods optimize polynomial time 
thorough discussion liftings polyhedra associated combinatorial optimization problems consult yan ls cited 
interesting problem look easily computable instance nc computable polynomial time computable barriers combinatorial optimization problems linear programming formulation contains exponentially inequalities 
concrete open problem find easily computable barrier matching polytope property suitable interior point algorithm barrier requires iterations number edges graph 
problem especially interesting yannakakis shows certain symmetry preserving conditions lift operator impossible lift matching polytope higher dimensional polytope polynomially facets yan 
matching polytope lifted convex set endowed self concordant barrier remains open 
maximum cliques perfect graphs 
particularly nice application semidefinite programming solution maximum clique problem perfect graphs 
graph called perfect induced subgraphs size maximum clique equals size minimum proper coloring 
proper coloring vertices graph assignment colors vertex adjacent vertices color 
clear graphs needs colors just cover vertices maximum clique 
interesting properties perfect graphs noted 
perfect graph theorem lov asz indicates graph perfect complement perfect lov 
statement equivalent saying induced subgraphs ff ae ff size largest stable set ae size smallest number cliques cover vertices effect studying cliques perfect graphs equivalent studying sets algorithm valid simply applying complementary graph 
consequence perfect graph theorem show equality maximum cliques minimum coloring extends weighted graphs 
precisely integral weight vector defined vertices proper coloring assignment colors vertices vertex colors adjacent vertices color sets disjoint 
minimum number colors proper colorings maximum weighted clique clique sum weights vertices maximum sum denoted 
graph perfect weight vectors 
restating complements graphs graph perfect ff ae ff weight maximum weighted stable set ae minimum number cliques required cover vertices vertex cliques 
results equivalent statement theorem graph perfect iff stab stab 
see gls 
results preceding section imply computing maximum cliques maximum independent sets perfect graphs accomplished polynomial time interior point methods 
case derive slightly stronger result 
lov asz lov discovered invariant graphs desirable properties polynomial time computable second simultaneously upper bound lower bound 
invariant defined pair primal dual semidefinite programs 
fx thetan ij jg fy thetan ij weighted lov asz number defined primal dual sdp pair minf mg ffl trace vector th component min max equality proved directly gls follows easily duality theory stated earlier see 
lemma vertex weighted graph ff ae see gls chapter thorough treatment lov asz number graphs including characterization interesting properties 
interior point algorithm compute polynomial time case perfect graphs ff ae gls ellipsoid method establish polynomial time computability maximum cliques perfect graphs 
show interior point methods give slightly stronger result ellipsoid method 
precisely show computing maximum cliques maximum stable sets perfect graphs accomplished randomized parallel time ram model computation kwk constant straightforward 
recall showed standard sdp problem solved nmax ln fflj iterations number bits input sdp priori bound norm solution ffl accuracy required size duality gap 
case perfect graphs need set ffl fact current primal dual estimates integer ffl declare dz bw ffl furthermore log coefficients primal dual characterization zero logn graph may clique weight computing requires iterations 
iteration essentially involves solving system linear equations known complexity class nc requires time polynomial number processors 
computing polynomially bounded requires operations ram model computation 
remains show computing maximum clique accomplished 
self reducibility process may require time ram machine 
observe maximum clique unique compute parallel time 
remove vertex graph compute remaining graph 
vertex unique maximum clique 
testing simultaneously vertices get set vertices maximum clique 
uniqueness may randomized perturbation scheme mulmuley vazirani vazirani 
recall isolating lemma lemma fx delta delta delta xng family subsets fs delta delta delta sn elements assigned integer weights chosen uniformly independently random 
pr unique maximum weight set see proof 
get maximum clique perfect graph follow procedure similar adopted mulmuley vazirani vazirani constructing minimum weighted perfect matching graphs 
idea assign weights vertices randomly high probability maximum clique new weights unique time clique maximum cliques original weights 
give weight vertex weight maximum weighted cliques largest clique weight 
perturb weight vertex adding integer uniformly independently chosen integers 
means log constant vertex weight notice clique maximum impossible maximum assigning new weights 
maximum clique respect new weights maximum cliques respect original weights 
isolating lemma implies clique unique probability may scheme mentioned section find parallel 
mention scheme fact results las vegas type randomized algorithm 
randomization involved computing size oracle constructing maximum clique involves probabilistic choices 
weights generated result unique maximum weighted clique scheme mentioned section may return set clique 
checked parallel algorithm returns message failure set returned algorithm genuine maximum clique possibility error 
summarize results theorem theorem perfect graph integral weight vector vertices 
kwk log constant compute maximum weighted clique maximum weighted stable set las vegas randomized parallel time ram model computation 
time lifting stable set polytope perfect graphs polytope polynomially facets known 
stab perfect graph serves example polytope exponentially facets optimize linear function polynomial time interior point methods 
fact mentioned subsection compute self concordant barrier polytope polynomial time 
maximum induced partite subgraph problem 
nm narasimhan manber generalized concept lov asz number graphs follows ff size largest induced partite subgraph recall ae minimum number cliques cover vertices narasimhan manber show ff min kae matrix 
reduces lov asz number 
clear computing sdp problem may solved interior point methods 
dual get max ffl trace difficult extend bound narasimhan manber weighted case 
weight vector vertices ff maximum weight colorable induced subgraph theorem integral weight vector vertices ff defined minf ffl trace ig proof proof essentially gls case 
transform weighted graph unweighted gw replacing vertex mutually nonadjacent vertices connecting vertices arising vertex vertices arising vertex adjacent clearly size unweighted maximum partite subgraph gw equals ff 
suffices show gw 
gw vertices respectively edges uv kl equivalent automorphism gw mapping respectively uv kl 
particular vertices arising vertex equivalent corresponding edges 
clear vertices respectively edges uv kl equivalent corresponding variables ii jj respectively uv kl equivalent sense exchanging variables change 
turn implies optimal solutions graph gw solutions equivalent vertices respectively edges identical optimal values corresponding variables 
words optimal solutions gw solution property partitioned theta block matrix block theta matrix entries equal say ij matrix entry ij feasible max problem theorem easy verify gw gw 
converse inequality easily verified reversing construction 
class graphs ff induced subgraphs sublinear parallel time algorithm theorem may extended solve largest induced partite subgraph problem graphs class 
remains interesting open problem fully characterize 
graph partitioning problem 
important class combinatorial np hard optimization problems lend sdp methods finding upper lower bounds arise graph partitioning cut problems 
class problems result semidefinite programs variables 
interior point methods may especially efficient iteration requires solving theta systems equations 
problem general graph partitioning problem prescribed size blocks 
suppose set integers delta delta delta denote vector 
complete edge weighted graph vertices edge fi jg weight ij want partition vertices subsets th subset cardinality sum weights edges endpoints different subsets minimized 
denote minimum number 
computing course np hard 
hoffman donath dh dh derive lower bound size minimum partition see barnes hoffman bh 
matrix ij ij ii 
donath hoffman prove relation dh gamma min diag gamma ij clear computing bound sdp problem 
results section simplification get pair primal dual sdp programs min iz trace gamma gamma delta delta delta delta delta delta max ffl gamma trace delta delta delta gamma jj delta delta delta delta delta delta barnes hoffman bh describe eigenvectors associated largest eigenvalues optimal matrix diag generate partition nodes graph 
see barnes bar bar 
important special case graph partitioning problem case equal 
case graph partitioning problem simplifies min trace diag max ffl ii delta delta delta boppana bop considers graph bisection problem derives characterization sharper max ffl diag gamma diag ps gamma projection operator linear space fx 
characterization equivalent primal dual sdp pair min nz zi gamma diag gamma ja aj max ffl ii ij delta delta delta boppana min characterization max characterization results simply dual 
find actual bisection boppana uses eigenvector corresponding largest eigenvalue ps diag outputs bisection largest component eigenvector side 
primal characterization boppana shows unweighted case matrix simply adjacency matrix graph may get optimal bisection high probability 
graph bisection problem important applications vlsi routing problem 
combining sdp formulation hoffman donath favorable average case analysis boppana interior point technique developed may result effective practical method solving problem 
generalizations ideas see rw 
related graph bisection problem maximum cut problem partition nodes graph sets number edges endpoints different sets maximum 
course obvious way finding bounds problem solve graph partitioning problem gamma delta delta delta bn notice graph partitioning problem max min characterizations essentially equivalent simply changing weights gamma 
dp pr sdp bound proposed minf diag ag mc mc size maximum cut 
equivalent primal dual pair min zi gamma diag max ffl ii may solved interior point methods 
related treatment maximum cut graph bisection see pr 
acknowledgment discussions stephen boyd don knuth lov asz yuri nesterov nemirovskii joshi ramana rob particularly michael overton ye useful preparing article removing errors preliminary versions 
comments anonymous referee instrumental removing errors statements farkas lemma duality theory earlier versions 
ali alizadeh 
combinatorial optimization interior point methods semi definite matrices 
phd thesis university minnesota minneapolis minnesota 
ali alizadeh 
optimization positive semi definite cone interior point methods combinatorial applications 
pardalos editor advances optimization parallel computing 
north holland 
anderson nash 
linear programming infinite dimensional 
john wiley sons 
bar barnes 
algorithm partitioning nodes graph 
siam alg 
disc 
meth 
bar barnes 
partitioning nodes graph 
lick wall editors graph theory applications algorithms computer science 
john wiley 
bh barnes hoffman 
partitioning spectra linear programming 
pulleyblank editor progress combinatorial optimization 
academic press 
ben israel charnes 
duality asymptotic solvability cones 
bulletin american mathematical society 
bjs jarvis sherali 
linear programming network flows 
john wiley 
bop boppana 
eigenvalues graph bisection average case analysis 
proc 
th ieee annual symposium foundations computer science 
bw borwein wolkowicz 
characterization optimality convex program finite dimensional range 
austral 
math 
soc 
series 
bw borwein wolkowicz 
facial reduction cone convex programming problem 
austral 
math 
soc 
series 
cdw cullum donath wolfe 
minimization certain nondifferentiable sums eigenvalue problems 
mathematical programming study 
ck craven 
generalizations farkas theorem 
siam math 
anal 
cm craven mond 
linear programming matrix variables 
linear algebra applications 
dh donath hoffman 
algorithms partitioning graphs computer logic eigenvectors connection matrices 
ibm technical disclosures bulletin 
dh donath hoffman 
lower bounds partitioning graphs 
ibm journal research development 
dp delorme poljak 
laplacian eigenvalues maximum cut problem 
technical report de paris sud centre orsay 

infinite programs 
kuhn tucker editor linear inequalities related systems pages 
princeton university press princeton nj 
fan fan 
quadratically convergent local algorithm minimizing largest eigenvalue symmetric matrix 
linear algebra applications 
fl lov asz 
server round proof systems power problems 
proc 
th annual acm symposium theory computing pages 
fle fletcher 
semi definite matrix constraints optimization 
siam control optim 
nocedal overton 
formulation analysis numerical methods inverse eigenvalue problems 
siam numer 
anal 
fw fillmore williams 
convexity theorems matrices 
glasgow mathematical journal 
gls grotschel lov asz schrijver 
ellipsoid method consequences combinatorial optimization 
combinatorica 
gls grotschel lov asz schrijver 
polynomial algorithms perfect graphs 
berge editors perfect graphs 
north holland 
annals discrete mathematics 
gls grotschel lov asz schrijver 
geometric algorithms combinatorial optimization 
springer verlag 
gon 
algorithm solving linear programming operations 
megiddo editor progress mathematical programming pages 
springer verlag berlin 
goldberg plotkin shmoys tardos 
interior point methods parallel computation 
siam comput 
gra graham 
kronecker products matrix calculus applications 
ellis horwood london 
gt goldfarb todd 
linear programming 
nemhauser rinnooy kan todd editors optimization handbooks operations research management sciences 
north holland 
hj horn johnson 
matrix analysis 
cambridge university press 
hur hurwicz 
programming linear spaces 
arrow hurwicz editors studies linear non linear programming ii pages 
stanford university press stanford ca 
jar 
interior point method minimizing maximum eigenvalue linear combination matrices 
technical report sol department operations research stanford univeristy june 
appear siam control optim 
kar karmarkar 
new polynomial time algorithm linear programming 
combinatorica 
kojima 
primal dual interior point algorithm linear programming 
megiddo editor progress mathematical programming 
springer verlag berlin 
lov lov asz 
normal hypergraphs weak perfect graph conjecture 
discrete mathematics 
lov lov asz 
shannon capacity graph 
ieee trans 
info 
theory january 
ls lov asz schrijver 
cones matrices optimization 
siam optimization 
ma monteiro adler 
polynomial time primal dual affine scaling algorithm linear convex quadratic programming power series extension 
technical report industrial engineering operations research department university california berkeley march 
meg megiddo 
pathways optimal set linear programming 
megiddo editor progress mathematical programming 
springer verlag berlin 
mulmuley vazirani vazirani 
matching easy matrix inversion 
combinatorica pages 
nm narasimhan manber 
generalization lov asz function 
cook seymour editor polyhedral combinatorics volume dimacs series discrete mathematics theoretical computer science pages 
american mathematical society association computing machinery 
nn nesterov nemirovskii 
self concordant functions polynomial time methods convex programming 
moscow 
nn nesterov nemirovskii 
interior point polynomial methods convex programming theory applications 
siam 
published 
ove overton 
minimizing maximum eigenvalue symmetric matrix 
siam matrix anal 
appl 
ove overton 
large scale optimization eigenvalues 
siam optimization 
ow overton 
optimality conditions duality theory minimizing sums largest eigenvalues symmetric matrices 
report nyu computer science department june 
appear math 
prog 
ow overton 
sum largest eigenvalues symmetric matrix 
siam matrix anal 
appl 
pr poljak rendl 
solving max cut problem eigenvalues 
technical report fur mathematik institut fur und operations research friedrich wilhelms universitat bonn november 
pr poljak rendl 
relaxations graph bisection problems 
technical report dimacs november 
roc rockafellar 
convex analysis 
princeton university press 
rw rendl wolkowicz 
projection technique partitioning nodes graph 
technical report corr report department combinatorics optimization university waterloo waterloo ontario canada 
sch schrijver 
theory linear integer programming 
wiley sons 
sha shapiro 
problems set nonnegative definite matrices 
linear algebra applications 
sub 
sums singular values 
master thesis school mathematic university new south wales australia 
vb vandenberghe boyd 
primal dual potential reduction method problems involving matrix inequalities 
technical report information systems laboratory department electrical engineering stanford university stanford ca january 
appear math 
prog 
wol wolkowicz 
applications optimization matrix theory 
linear algebra applications 
yan yannakakis 
expressing combinatorial problems linear programs 
proc 
th ieee annual symposium foundations computer science pages 
ye ye 
class projective transformations linear programming 
siam comput 
ye ye 
potential reduction algorithm linear programming 
math 
prog 

