appear proceedings ieee th international conference tools artificial intelligence chi feature selection discretization numeric attributes huan liu rudy setiono department information systems computer science national university singapore kent ridge singapore nus sg discretization turn numeric attributes discrete ones 
feature selection eliminate irrelevant attributes 
describes chi simple general algorithm uses statistic discretize numeric attributes repeatedly inconsistencies data achieves feature selection discretization 
empirical results demonstrate chi effective feature selection discretization numeric ordinal attributes 
feature selection task select minimum number attributes needed represent data accurately 
relevant features classification algorithms general improve predictive accuracy shorten learning period result simpler concepts 
abundant feature selection algorithms 
adopts approach selects subset original attributes virtues serves indicator kind data selected features collected 
feature selection algorithms divided data types operate 
basic types data nominal attribute color may values red green yellow ordinal attribute winning position values attribute salary values 
feature selection algorithms shown effectively discrete data strictly binary data binary class value 
order deal numeric attributes common practice algorithms discretize data conducting feature selection 
provides way select features directly numeric attributes discretizing 
numeric data common real world problems 
classification algorithms require training data contain discrete attributes better discretized binarized data 
numeric data automatically transformed discrete ones classification algorithms readily disposal 
chi effort goal discretize numeric attributes select features 
problem tackles follows data sets numeric attributes irrelevant range numeric attribute wide find algorithm automatically discretize numeric attributes remove irrelevant ones 
stems kerber chimerge designed discretize numeric attributes statistic 
chimerge consists initialization step bottom merging process intervals continuously merged termination condition determined significance level ff set manually met 
improvement obvious simple methods equal width intervals equal frequency intervals 
defining width frequency threshold easy attribute knowing chimerge requires ff specified 
big small ff discretize attribute 
extreme example discretization continuous attribute 
discretization introduce inconsistencies nonexistent change characteristics data 
short easy find proper ff chimerge 
ideal data determine value ff take 
leads phase chi 
naturally discretization continues generating inconsistencies original data possible attributes discretized interval 
removed 
chi algorithm chi algorithm summarized statistic consists phases 
phase begins high significance level numeric attributes discretization 
attribute sorted values 
performed 
calculate value equation pair adjacent intervals pattern put interval contains value attribute 
merge pair adjacent intervals lowest value 
merging continues un inconsistency mean patterns classified different categories 
til pairs intervals values exceeding parameter determined initially corresponding value degree freedom 
process repeated decreased inconsistency rate ffi exceeded discretized data 
phase matter fact generalized version chimerge kerber 
specifying threshold chi wraps chimerge loop automatically increments threshold decrementing 
consistency checking introduced stopping criterion order guarantee discretized data set accurately represents original 
new features chi automatically determines proper threshold keeps fidelity original data 
phase finer process phase 
starting determined phase attribute associated takes turns merging 
consistency checking conducted attribute merging 
inconsistency rate exceeded decremented attribute round merging attribute involved merging 
process continued attribute values merged 
phase attribute merged value simply means attribute relevant representing original data set 
result discretization ends feature selection accomplished 
chi algorithm phase set inconsistency data ffi numeric attribute sort attribute data chi sq initialization attribute data chi sq calculation attribute data merge data phase set attribute attribute merged attribute merged sort attribute data chi sq initialization attribute data chi sq calculation attribute data merge data inconsistency data ffi attribute merged formula computing value ij gamma ij ij number classes ij 
patterns ith interval jth class 
patterns ith interval ij 
patterns jth class ij total 
patterns ij expected frequency ij ij set 
degree freedom statistic number classes 
experiments sets experiments conducted 
set experiments want establish 
chi helps improve predictive accuracy 
chi properly effectively discretizes data eliminates irrelevant attributes 
extension id verify effectiveness chi 
reasons choice 
id works problems known requiring description 
selects relevant features tree branching benchmark verify effects chi 
second set experiments closer examination chi ability discretization feature selection introducing synthetic data set adding noise attributes existing data set 
controlled data sets better understand effective chi real data data sets experiments iris wisconsin breast cancer heart disease different types attributes 
iris data continuous attributes breast cancer data ordinal discrete ones heart disease data mixed attributes numeric discrete 
controlled data extra data sets designed test noise attributes removed 
synthetic iris data added noise attributes 
synthetic data consists items described attributes attribute determines item class label 
values attribute generated uniform distribution lower bound upper bound item class label determined follows class class class 
add noise attributes values generated normal distribution oe 
values generated obtained university machine learning repository anonymous ftp ics uci edu 
int class freq int class freq table initial intervals class frequencies values length 
normal distributions oe respectively items distribution 
values generated uniform distribution 
second data modified version iris data 
noise attributes added iris training data corresponding original attributes 
values noise attribute determined normal distribution ave oe max gamma min ave average value max min maximum minimum values original attribute 
choice oe approximate corresponding original attribute uniform distribution 
total attributes 
number patterns 
example section steps chi processing iris data shown demonstrate behavior chi 
table shows intervals class frequencies values length initialization phase 
results length phase phase shown table 
inconsistency rate ffi allowed experiment means inconsistencies acceptable 
phase stops 
means introduce inconsistencies 
phase terminates values width merged value removed attributes petal length petal width discretized discrete values 
threshold example discrete values needed attribute length 
reads numeric value greater equal quantized 
empirical results real data show discretization number attributes decreases data sets 
iris data number attributes int class freq int class freq table intervals class frequencies values attribute length phase phase 
thresholds 
data sets number attributes legend iris heart breast number attributes original vs chi processing 
reduced petal length petal width values 
breast cancer data attributes removed original attributes 
remaining attributes discrete values respectively 
heart disease data discrete attributes left discretization feature selection consistency checking 
continuous attributes attributes remain suggested chi having discrete values respectively 
cancer disease data sets default inconsistency rate 
second run original data sets dimensionally reduced ones 
run default setting 
chi discretizes training data generates mapping table testing data discretized 
shown predictive accuracies tree sizes data sets 
predictive accuracy improves tree size drops half breast cancer heart disease data 
iris data accuracy tree size remain attributes values 
way shows works pretty chi data set 
accuracy iris heart breast size iris heart breast predictive accuracy size decision trees data sets chi processing 
empirical results controlled data purpose experimenting controlled data verify effective chi removing irrelevant attributes discretizing numeric attributes 
necessary see chi discretize relevant attribute properly remove irrelevant attributes 
chi merged discrete values corresponding classes merged attributes value 
means remain noise irrelevant attributes removed 
modified iris data chi merged attributes 
attributes 
length width 
added noise irrelevant attributes 
remaining attributes merged discrete values respectively real data experiment 
set controlled experiments shown chi effectively discretizes numeric attributes removes irrelevant attributes 
discussions chimerge requires user specify proper significance level ff merging values attributes 
definite rule choose ff 
words matter trial clearly easy find proper significance level problem 
phase chi extends chimerge automated 
ff automatically varied merging discontinued stopping criterion inconsistency rate 
chi special capability feature selection big step forward discretization 
phase chi attribute significance level merging round robin fashion 
merging stops inconsistency rate exceeds specified ffi phase chi accomplishes feature selection 
feature chi applied data mixed attributes heart disease data 
addition chi multi data 
advantage statistic feature selection algorithms relief applicable class data 
issues selecting ffi limitations chi computational complexity 
chi simple general algorithm automatically select proper value determine intervals numeric attribute select features characteristics data 
guarantees fidelity training data remain chi applied 
empirical results real data controlled data shown chi useful reliable tool discretization feature selection numeric attributes 
almuallim dietterich 
learning boolean concepts presence irrelevant features 
artificial intelligence november 
catlett 
changing continuous attributes ordered discrete attributes 
european working session learning 
fayyad irani 
attribute selection problem decision tree generation 
aaai proceedings ninth national conference artificial intelligence pages 
aaai press mit press 
kerber 
chimerge discretization numeric attributes 
aaai proceedings ninth national conference artificial intelligence pages 
aaai press mit press 
kira rendell 
feature selection problem traditional methods new algorithm 
aaai proceedings ninth national conference artificial intelligence pages 
aaai press mit press 
liu setiono 
discretization ordinal attributes feature selection 
technical report department info sys comp sci national university singapore april www nus sg chi ps 
quinlan 
induction decision trees 
machine learning 
quinlan 
programs machine learning 
morgan kaufmann 
rendell 
lookahead feature construction learning hard concepts 
machine learning proceedings seventh international conference pages 
morgan kaufmann pub 
san mateo california 
