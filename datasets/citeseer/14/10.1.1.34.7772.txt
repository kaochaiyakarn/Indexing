decision theoretic high level agent programming situation calculus craig boutilier dept computer science university toronto toronto cs toronto edu ray reiter dept computer science university toronto toronto reiter cs toronto edu mikhail soutchanski dept computer science university toronto toronto mes cs toronto edu sebastian thrun school computer science carnegie mellon university pittsburgh pa thrun cs cmu edu framework robot programming allows seamless integration explicit agent programming decision theoretic planning 
specifically dtgolog model allows partially specify control program highlevel logical language provides interpreter logical axiomatization domain determine optimal completion program viewed markov decision process 
demonstrate utility model results obtained office delivery robotics domain 
construction autonomous agents mobile robots software agents paramount artificial intelligence considerable research devoted methods ease burden designing controllers agents 
main ways conceptual complexity devising controllers managed 
provide languages programmer specify control program relative ease high level actions primitives expressing necessary operations natural way 
second simply specify goals objective function provide agent ability plan appropriate courses action achieve goals maximize objective function 
way need explicit programming 
propose framework combines perspectives allowing partially specify controller writing program suitably high level language allowing agent latitude choosing actions requiring planning decision making ability 
viewed differently allow seamless integration programming planning 
specifically suppose agent programmer knowledge domain able specify necessarily structure details possibly optimal controller 
aspects left unspecified filled agent satisfy constraints imposed program partially specified controller 
controllers easily designed hand planning role play 
hand certain problems easily tackled specifying goals declarative domain model allowing agent plan behavior 
copyright fl american association artificial intelligence www aaai org 
rights reserved 
framework synthesis markov decisions processes mdps golog programming language :10.1.1.54.7045
key proposal extension golog language interpreter called dtgolog deal uncertainty general reward functions 
planning ability provide decision theoretic planner choices left agent maximizing expected utility 
framework motivated ways 
viewed decision theoretic extension golog language 
golog high level agent programming language situation calculus clear semantics standard programming constructs sequencing nondeterministic choice write highlevel control programs 
different standpoint contribution viewed language methodology provide advice decision theoretic planner 
mdps conceptually computationally useful model decisiontheoretic planning solution intractable 
provide means naturally constrain search ideally optimal policies golog program 
agent adopt policies consistent execution program 
decision theoretic golog interpreter solves underlying mdp making choices regarding execution program expected utility maximization 
viewpoint fruitful considers agent designer idea general structure optimal policy may unable commit certain details 
run risk program may allow optimal behavior model clear advantage decision problem faced generally tractable need choices left open programmer 
contrast existing models constraining policies mdps concepts local policies finite state machines dtgolog provides natural understood formalism programming behaviors :10.1.1.54.7045
approach specifically targeted developing complex robotics software 
robotics major paradigms planning programming largely pursued independently 
approaches advantages flexibility generality planning paradigm performance programmed controllers scaling limitations computational complexity planning approaches task specific design conceptual complexity programmers programming paradigm 
mdp style planning core range fielded robot ap plications tour guide robots 
ability cope uncertain worlds essential feature real world robotic applications 
mdp planning scales poorly complex tasks environments 
programming easy code routines leaving choices mdp planner difficult program programmer easily determine appropriate optimal behavior complexity planning reduced tremendously 
note difficult program behaviors may quite easy implicitly specify goals objectives 
demonstrate advantage new framework developed prototype mobile office robot delivers mail combination pre programmed behavior decision theoretic deliberation 
analysis relative trade offs shows combination programming planning essential developing robust scalable control software robotic applications described 
give brief overviews mdps golog sections 
describe dtgolog representation mdps programs dtgolog interpreter section illustrate interpreter describing implementation office robot section 
markov decision processes basic background mdps see details 
assume stochastic dynamical system controlled agent 
mdp hs pr ri comprises components 
finite set states system controlled 
agent finite set actions influence system state 
dynamics pr theta theta pr denotes probability action executed state induces transition 
real valued bounded reward function 
process fully observable agent predict outcome action certainty observe state precisely reached 
decision problem faced agent mdp forming optimal policy mapping states actions maximizes expected total accumulated reward horizon interest 
agent finding state time choose action expected value course action depends specific objectives 
finite horizon decision problem horizon measures value expectation taken pr 
mdp horizon nonstationary policy theta delta delta delta tg associates state stage go action executed stages remaining 
optimal policy maximum expected value state stage pair 
planning problem faced agent forming states actions maximizes expected total accumulated reward horizon 
dynamic programming methods solve focus finite horizon problems keep presentation short describe applied little modification discounted infinite horizon mdps 
mdps difficulty facing classical versions algorithms reliance explicit statespace formulation complexity exponential number state variables 
logical representations strips dynamic bayesian networks specification solution mdps easier 
dtgolog representation goes direction specifying state transitions order logic 
restricting attention reachable states decision tree search circumstances alleviate computational difficulties dynamic programming 
search approaches solving mdps heuristics learning sampling pruning improve efficiency :10.1.1.117.6173
declarative search control knowledge successfully classical planning prune search space 
mdp viewed restricting set policies considered 
type approach explored general context value iteration mdps local policies finitestate machines model partial policies techniques devised find optimal policy consistent constraints imposed 
section develop dtgolog interpreter capture similar intuitions adopt golog programming language means specifying constraints natural programming constructs 
situation calculus golog situation calculus order language axiomatizing dynamic worlds 
years considerably extended classical language include concurrency continuous time cases basic ingredients consist actions situations fluents 
actions order terms consisting action function symbol arguments 
approach representing time situation calculus arguments action function symbol typically argument time action occurrence 
example startgo denote action robot starting move location time 
actions instantaneous zero duration 
situation order term denoting sequence actions 
sequences represented binary function ff denotes sequence resulting adding action ff sequence special constant denotes initial situation empty action sequence 
situation term endgo startgo denotes sequence actions startgo endgo 
axioms situations time 
relations truth values vary state state called relational fluents denoted predicate argument situation term 
durations captured processes shown 
full exposition time possible 
example closet relational fluent meaning robot performs action sequence denoted situation term close domain theory axiomatized situation calculus classes axioms action precondition axioms action function syntactic form poss pi pi formula free variables preconditions action successor state axioms relational fluent syntactic form phi phi formula free variables characterize truth values fluent situation terms current situation embody solution frame problem deterministic actions 
unique names axioms actions state actions domain pairwise unequal 
initial database set sentences situation term specifies initial problem state 
examples axioms seen section 
golog situation calculus programming language defining complex actions terms set primitive actions axiomatized situation calculus described :10.1.1.54.7045
standard standard control structures algol languages 

sequence ff fi action ff followed action fi 

test actions 
test truth value expression current situation 

nondeterministic action choice ff fi ff fi 

nondeterministic choice arguments ff 
nondeterministically pick value value action ff 

conditionals loops 

procedures including recursion 
semantics golog programs defined ternary relation 
ffi abbreviation situation calculus formula intuitive meaning situations reached evaluating program ffi situation program ffi proves situation calculus axiomatization background domain formula ffi compute plan 
binding obtained constructive proof sentence legal execution trace involving primitive actions ffi golog interpreter situation calculus time implemented prolog described 
interpreter choices possible lead successful computation execution trace program 
nondeterministic choice specification postconditions corresponding goals golog viewed integrating planning programming deterministic domains 
see examples golog programs section 
dtgolog decision theoretic golog planning model mdps quite flexible robust dealing uncertainty multiple objectives suffer key limitations 
dtp focused development compact natural representations mdps little gone development order languages specifying mdps see exceptions 
importantly computational complexity policy construction prohibitive 
mentioned way circumvent planning complexity allow explicit agent programming little directed integrating ability write programs constrain space policies searched planning 
done fails provide language imposing constraints certainly offers tools programming agent behavior 
believe natural declarative programming languages methodologies partially specifying agent behavior necessary approach find successful application real domains 
golog hand provides natural means agent programming 
nondeterministic choice programmer leave certain amount planning interpreter agent controlled 
applications robotics programming usefulness golog severely limited inability model stochastic domains reason decision theoretically appropriate choices 
despite limitations deterministic golog successfully provide high level control museum tour guide robot controlling user interaction scheduling exhibits 
developed dtgolog decision theoretic extension golog allows specify mdps order language provide advice form high level programs constrain search policies 
program viewed partially specified policy semantics viewed informally execution program completion policy highest expected value 
dtgolog offers synthesis planning programming fact general accommodate extremes 
write purely nondeterministic programs allow agent solve mdp optimally purely deterministic programs leave decisions agent hands whatsoever 
see fact point ends spectrum useful way write robot programs 
dtgolog allows appropriate point specific problem chosen relative ease 
space precludes presentation technical details try provide basic flavor dtgolog 
dtgolog problem representation specification mdp requires background action theory section background optimization theory consisting specification reward function optimality criterion require horizon 
unique names axioms initial database form standard golog 
background action theory decision theoretic setting distinguishes deterministic agent actions stochastic agent actions 
types form programs policies 
situation resulting execution stochastic action determined action stochastic agent action associated finite set deterministic actions nature chooses stochastically 
successor state axioms provided nature actions directly deterministic stochastic agent actions successor state axioms mention stochastic agent actions 
stochastic action executed nature chooses associated actions specified probability successor state nature action chosen 
predicate stochastic relates stochastic agent action nature action situation prob denotes probability chosen deterministic agent actions axiomatized exactly precondition successor state axioms 
methodology allows extend axiomatization domain theory described previous section minimal way 
example imagine robot moving different locations process going initiated deterministic action startgo terminating action endgo stochastic robot may location say hallway 
give nature choices successful arrival hall failure include axioms stochastic endgo prob successful movement occurs probability situation 
going relational fluent meaning situation robot process moving locations robotloc relational fluent denoting robot location 
precondition successor state axioms characterize fluents actions startgo poss startgo going robotloc poss going poss going going startgo going going background action theory includes new class axioms sense conditions axioms assert atomic formulae predicate oe holds oe logical condition agent uses determine specific nature action occurred stochastic action executed 
require axioms order implement full observability 
standard mdp model simply assumes successor state known practice force agents disambiguate state sensor information 
sensing actions needed determined sense condition axioms 
distinguish successful unsuccessful movement robotloc robotloc hall dtgolog optimization theory contains axioms specifying reward function 
simplest form reward axioms function reward assert costs rewards function action taken properties current situation note action taken recovered situation term 
instance assert reward jill primitive actions explicit temporal argument describe time dependent reward functions easily associated behaviors extend time 
dealt interpreter situation terms states time derived having explicitly encoded state 
proves useful practice 
temporal golog program temporal occurrence certain actions uniquely determined temporal constraints programmer 
actions may occur time certain interval determined temporal inequalities action instantiate time argument maximizing reward reaching situation 
example suppose robot receives reward max gammat distance doing action reward function robot encouraged arrive destination soon possible encouraged go nearby locations reward inversely proportional distance 
representation stochastic actions related somewhat representations proposed 
dtgolog semantics follows assume provided background action theory optimization theory 
interpret dtgolog programs relative theory 
dtgolog programs written program operators golog programs 
semantics specified similar fashion predicate bestdo described playing role 
structure bestdo prolog implementation different 
difference reflects fact primitive actions stochastic 
execution traces sequence primitive actions need simple linear situation terms branching trees 
reflects fact dtgolog distinguishes legal traces expected utility 
choice actions subprograms point program interpreter chooses action highest expected value mirroring structure mdp search tree 
interpreter returns policy expanded golog program nondeterministic choice point grounded selection optimal choice 
intuitively semantics dtgolog program optimal execution program 
semantics dtgolog program defined predicate bestdo prog pol val prob prog golog program starting situation pol optimal conditional policy determined program prog require optimality criterion specified 
assume finite horizon 
situation val expected value policy prob probability pol execute successfully prespecified horizon 
generally implementing definition called program prog situation horizon arguments pol val prob instantiated interpreter 
policy pol returned interpreter golog program consisting sequential composition agent actions sensing actions serve identify nature choices stochastic agent action conditionals oe pol pol 
assume mdp finite horizon program fails terminate horizon reached interpreter produces best partial step execution program 
interpreter easily modified deal programs guaranteed terminate finite amount time bound need imposed discounted problems returning optimal policies 
bestdo defined inductively structure argument golog program 
zero horizon 
bestdo pr def il reward pr give program horizon reaches 
null program bestdo il pr def il reward pr 
program action deterministic 
bestdo pr def oss pr reward oss pr bestdo pr reward pr pr program begins deterministic agent action possible situation optimal execution defined optimal execution remainder program situation 
value expected value continuation plus reward action cost included difficulty success probability success probability continuation 
optimal policy followed optimal policy remainder 
possible policy simply action success probability zero value simply reward associated situation zero cost action takes agent zero cost absorbing state 

program action stochastic 
stochastic agent action nature selects actions set fn bestdo pr def fn pr viewed having agent simply give attempt execute policy await instruction 
resulting policy policy delivered 
intuitively policy says agent perform action point nature selects perform probabilities prob agent sense outcome action tells nature actions occurred execute policy delivered 
pr def pr suppose 
suppose oe sense condition nature action meaning observing oe true necessary sufficient agent conclude nature performed action choices fn available virtue agent having done stochastic action fn pr def oss fn pr oss pr fn pr pr bestdo pr oe delta prob pr pr pr delta prob determines policy form conditional plan oe pol oe pol delta delta delta oe pol nature actions fn possible pol policy returned program situation 

program action test 
bestdo oe pr def oe bestdo pr oe pr reward 
program action nondeterministic choice programs 
bestdo pr def pr bestdo pr pr bestdo pr pr pr pr pr pr 
pr pr pr choice subprograms optimal policy determined subprogram optimal execution 
note subtlety interpretation dtgolog program hand wish interpreter choose course action maximal expected value follow advice provided program 
certain choices may lead abnormal termination action cor sensing actions implement assumption mdp fully observable 
responding incomplete execution program varying probabilities success probability associated policy loosely viewed degree interpreter adhered program 
multi problem requiring tradeoff success probability expected value policy 
predicate compares pairs form success probability expected value 

conditionals 
bestdo oe pr def bestdo oe oe pr simply says conditional oe abbreviation oe oe 
nondeterministic finite choice action arguments 
bestdo pol pr def bestdo pj delta delta delta pj cn pol pr programming construct requires nondeterministic choice element finite set fc ng program abbreviation program pj delta delta delta pj cn pj means substitute free occurrences 
associate sequential composition right 
bestdo pr def bestdo pr needed massage program form action forms suitable application rules 
suitable expansion rule program action procedure call 
identical rule golog procedures requires second order logic characterize standard fixed point definition recursive procedures :10.1.1.54.7045
bit complicated side central specification policies dtgolog omit expansion rule 
loops defined procedures 
computing optimal policies bestdo prog pol val prob analogously case golog abbreviation situation calculus formula intuitive meaning pol optimal policy resulting evaluating program prog situation val value prob probability defines predicate depends interprets advice embodied program 
implementation mild lexicographic preference 
agent choose execution guarantees failure 
zero greater zero terms comparison 
important note certain multiattribute preferences violate dynamic programming principle case search procedure revised form dynamic programming case lexicographic preference 
successful execution policy 
program ffi horizon proves situation calculus axiomatization background domain described section formula pol val prob bestdo ffi il pol val prob binding pol val prob obtained constructive proof sentence determines result program computation 
implementing dtgolog interpreter just interpreter golog trivial implement prolog situation calculus specification interpreter dtgolog 
simply translates rules identical prolog clause 
example implementation rules action deterministic 
bestdo pol prob deterministic poss pol prob reward poss bestdo prob reward pol 
nondeterministic choice bestdo pol bestdo pol bestdo pol pol pol greater pol pol 
entire dtgolog interpreter style extremely compact transparent 
robot programming key advantage dtgolog framework robot programming planning ability allow behavior specified convenient point programming planning spectrum 
allowing specification stochastic domain models declarative language dtgolog allows programmer specify programs naturally robot actions base level primitives permits programmer leave gaps program filled optimally robot 
functionality greatly facilitate development complex robotic software 
planning ability allows scheduling complex behaviors difficult 
obviates need reprogram robot adapt behavior reflect environmental changes changes objective functions 
programming contrast crucial alleviating computational burden uninformed planning 
illustrate points developed mobile delivery robot tasked carry mail coffee office building 
physical robot rwi robot equipped laser range finder 
robot navigates software package includes methods map acquisition localization collision avoidance online path planning 
shows map delivery path main office recipient office 
initially robot moves main office loads mail robot shown 
dtgolog chooses recipient utility optimization 
shows robot traveling autonomously hallway 
person office acknowledges receipt mail delivery person loads mail coffee robot 
dtgolog sends robot office 
recipient accepts mail coffee acknowledging successful delivery pressing button 
map learned robot robot path main office recipient 
items pressing button robot shown waiting certain period time robot marks delivery attempt unsuccessful continues delivery 
task dtgolog schedule individual deliveries face stochastic action effects arising fact people may may office time delivery 
contend different priorities different people balance domain uncertainty 
underlying mdp relatively simple domain grows rapidly number people requiring deliveries increases 
state space characterized fluents person person robotloc loc 
domain people locations maximum number pieces mail ignoring temporal aspect problem mdp state space size delta delta formulated appropriate way 
restricting mdp piece bundle mail person state space complexity delta grows exponentially actions include picking mail moving location location giving mail 
uncertainty associated endgo action described outcome giving mail see 
robot objective function reward function associates independent additive reward person successful delivery 
person different deadline reward decreases linearly time deadline zero 
relative priority associated different recipients function reward ray gamma initial reward rate decrease indicates relative priority 
situation term corresponding branch tree straightforward maximize value respect choice temporal arguments assigned actions sequence 
delve details 
robot provided simple dtgolog program attempted people attempted 
endwhile intuitively program chooses people finite range people mail delivery delivers mail order maximizes expected utility coffee delivery incorporated readily 
complex procedure items person moving person office giving items returning 
sequence obvious domain optimal ordering delivery change ll see 
included guard condition attempted program prevent robot repeatedly trying deliver mail person office 
program constrains robot just attempted mail delivery person nice example programmer easily impose domain specific restrictions policies returned dtgolog program 
things emerged development code 
program determines different policies different qualitative behavior model changed reward function changed 
simple example probability ray high priority office delivery scheduled craig low priority probability lowered craig delivery scheduled 
changes domain require change control program planning ability provided dtgolog 
computational requirements decision making capability allow completely arbitrary policies searched decision tree 
full mdp planning implemented dtgolog running program allows feasible action chosen time 
causes full decision tree constructed 
domain complexity unconstrained search tree completely evaluated problems maximum horizon minute depth barely complete construction policy serve person 
program interpreter finds optimal completions person domain second producing policy success probability person domain seconds success probability person domain minutes success probability 
corresponds horizon clearly decision tree search infeasible program constraints size 
note mdp formulation problem people locations require states 
dynamic programming solve mdp program constraints exploiting form structure 
note example programs restrict policy robot implement leaving choice choice person deliver mail available robot rest robot behavior fixed program 
programs quite natural structuring program way may preclude optimal behavior 
instance restricting robot serving person time simultaneous delivery mail people nearby offices won considered 
circumstances interleaving impossible robot carry item time program admits optimal behavior describes deliver item leaving robot decide order deliveries 
settings simultaneous interleaved deliveries feasible nonoverlapping program may sufficiently high utility restricting robot choices acceptable allows mdp solved quickly 
experiments illustrate benefits integrating programming planning mobile robot programming 
conjecture advantage framework evident scale complex tasks 
example consider robot serves dozens people making decisions recharge batteries 
mail coffee requests arrive sporadically random points time just day case current implementation 
today best planners complexity tasks tackled reasonable time 
dtgolog powerful accommodate scenarios 
supplied programs type described expect dtgolog remaining planning problem tractable minimal effort programmer side 
concluding remarks provided general order language specifying mdps imposing constraints space allowable policies writing program 
way provided natural framework combining decision theoretic planning agent programming intuitive semantics 
framework flexible robot programming tool integrating programming permitting developer choose point spectrum best suited task hand 
golog proven ideal vehicle combination ideas transcend specific choice language 
number interesting directions remain explored 
decision tree algorithm dtgolog interpreter clearly subject computational limitations 
basic intuitions foundations dtgolog particular computational model 
currently integrating integrating efficient algorithms techniques solving mdps framework dynamic programming abstraction sampling 
emphasize note program constraints intractable mdps reasonably easy solve search methods 
methods ability naturally constrain search policies explicit programs crucial 
avenues include incorporating realistic models partial observability key ensuring wider applicability model extending expressive power language include extensions defined classical golog model concurrency incorporating declaratively specified heuristic search control information monitoring line execution dtgolog programs automatically generating sense conditions stochastic actions 
bacchus halpern levesque 
reasoning noisy sensors situation calculus 
ijcai pp montreal 
bacchus kabanza 
temporal logic control search forward chaining planner 
ghallab eds new directions planning pp ios press 
barto bradtke singh 
learning act realtime dynamic programming 
art 
intel 
boutilier dean hanks 
decision theoretic planning structural assumptions computational leverage 
art 
intel 
res 
burgard cremers fox lakemeyer schulz steiner thrun 
experiences interactive museum tour guide robot 
art 
intel 
dearden boutilier 
abstraction approximate decision theoretic planning 
art 
intel 
geffner bonet 
high level planning control incomplete information pomdps 
aaai fall symp 
cognitive robotics orlando 
kearns mansour ng 
sparse sampling algorithm near optimal planning large markov decision processes 
ijcai stockholm 
koenig simmons 
real time search nondeterministic domains 
ijcai pp montreal 
levesque reiter lesperance lin scherl :10.1.1.54.7045
golog logic programming language dynamic domains 
logic prog 
parr russell :10.1.1.54.7045
reinforcement learning hierarchies machines 
nips pp 
mit press 

poole 
logic modelling multiple agents uncertainty 
art 
intel 
puterman 
markov decision processes discrete stochastic dynamic programming 
wiley new york 
reiter 
natural actions concurrency continuous time situation calculus 
kr pp cambridge 
reiter 
sequential temporal golog 
kr pp trento 
reiter 
frame problem situation calculus simple solution anda goal regression 
lifschitz ed artificial intelligence mathematical theory computation papers honor john mccarthy pp 
academic press 
soutchanski 
execution monitoring high level temporal programs 
ijcai workshop robot action planning stockholm 
sutton 
td models modeling world mixture time scales 
icml pp lake tahoe 
thrun burgard cremers dellaert fox rosenberg roy schulte schulz 
minerva second generation mobile robot 
icra 
