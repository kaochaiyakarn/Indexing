pnrule new framework learning classifier models data mining case study network intrusion detection ramesh agarwal mahesh joshi march developed new solution framework multi class classification problem data mining 
method especially applicable situations different classes widely different distributions training data 
applied technique network intrusion detection problem kdd cup 
framework new rule classifier model target class 
proposed model consists positive rules rules predict presence class negative rules rules predict absence class 
model learned phases 
phase discovers rules capture positive cases target class keeping false positive rate reasonable level 
goal second phase discover rules remove false positives introduced union rules keeping detection rate acceptable level 
sets rules ranked certain statistical measures 
gather statistics rules training data develop mechanism assign score decision classifier 
process repeated target class 
misclassification cost matrix consolidate scores binary classifiers arriving final decision 
describe details proposed framework 
real life network intrusion detection dataset supplied part kdd cup contest 
dataset training records highly skewed distribution classes largest class records smallest records 
describe applied framework problem 
aside describe controversy triggered contest proved original test data labels wrong 
compare results approach 
subset test data consisting known subclass labels technique achieves best performance terms accuracy misclassification cost penalty 
ibm thomas watson research center box yorktown heights ny agarwal watson ibm com department computer science university minnesota minneapolis mn cs umn edu 
done author visited ibm research summer 
motivation learning classifier models important problem data mining 
observations recorded set records characterized multiple attributes 
associated record categorical attribute called class 
training set records known class problem learn model class terms attributes 
goal model predict class set records certain objective function predicted actual classes optimized 
traditionally goal minimize number misclassified records maximize accuracy 
various techniques exist today build accurate classifier models 
emerged research fields machine learning neural networks pattern recognition statistics 
single technique proven best situations techniques learn rule models especially popular domain data mining 
forms models decision trees neural networks post processed build rule model 
contributed easy interpretability rules humans competitive performance exhibited rule models application domains 
general rule model set conditions attributes arranged disjunctive normal form dnf means disjunction union rules rule conjunction intersection conditions imposed different attributes 
learning rule models directly training data studied great detail past couple decades 
research far concentrated developing techniques different search directions general specific specific general different performance metrics rule evaluation different stopping criteria search review section 
common goal discover small number rules low cardinality cover positive examples target class high coverage negative examples high accuracy 
general specific search techniques start general rule empty rule progressively add specific conditions 
conjunction conditions added accuracy rule increases coverage support decrease 
note support total number records rule applies coverage number positive examples covered rule 
ideal situation exactly conjunctive rule gives desired accuracy entire coverage target class 
rarely happens real world usually class consists multiple subsets unique signatures 
especially occurs class consists multiple distinct subclasses 
disjunction rules necessity 
disjunctions discovered iteratively 
iteration high accuracy conjunctive rule discovered 
records covered rule removed iteration starts remaining examples 
tolerance rule accuracy usually tight iteration 
called sequential covering algorithms widespread rule modeling 
face problem 
algorithm proceeds data rules learned decreases size 
support rules learned decreases 
support allowed reduce substantially rules may specific overfitting training data may overly general noise data 
stops iterations remainder data size falls threshold rare subclasses missed 
rules small coverage learned small datasets called small disjuncts 
identified show rules tend contribute generalization error rate compared large disjuncts rules high coverage 
detailed scenarios occur discussed 
remedy avoid problem specific general search techniques start record specific rule progressively generalize rule set 
shown techniques better ability learn complex models involving small disjuncts suffer specific conditions generalize 
condition generalized exhaustively computational complexity scales poorly large training data sets quadratic training set size cubic number attributes 
approach selecting random positive examples generalize shown avoid exponential complexity imposing restrictions types rules learned relying heavily background knowledge :10.1.1.35.951
specific general type techniques suitable real life problems today data mining applications involving large datasets 
concentrate general specific strategies remedies proposed solve problem small disjuncts far 
remedy relax emphasis generality rules making specific iterations 
shown reduce error rate small disjuncts cost increased error rate large disjuncts 
solution proposed assign probabilistic measures rules discovered hope assigning lower measures small disjuncts :10.1.1.34.2014
solutions proposed estimating generalization accuracy accuracy training data decide retain remove small disjuncts 
solutions considered workarounds actual problem trade support accuracy rules discovered 
suspect problem occurs relatively tight accuracy constraints iterations 
causes rules small support discovered algorithm progresses leading problem 
believe accuracy constraints relaxed gradually required keep finding rules sufficiently large support positive examples covered 
precisely crux proposed approach 
propose stage general specific framework learning rule model handles small disjunct problem prescriptive effective manner compared existing methods 
proposed method runtime linear number training data records linear number attributes iterations 
call framework pnrule finding rules predict presence target class rules rules predict absence target class rules 
handle multi class problems learning binary classifiers individual classes shown better handling small disjunct problems building single model classes :10.1.1.34.2014
think approach especially desirable small classes treated noise performance metrics 
key idea learn set rules cover positive examples sufficient support rule covers large number examples maintain statistical significance 
initially highly accurate rules selected accuracy compromised favor support 
differentiates method previous approaches second stage 
learns rules essentially remove negative examples collectively covered union rules 
existence second stage helps making algorithm sensitive problem small disjuncts stage 
rank rules accuracy support statistics assign score decision classifier 
feature proposed framework cost sensitive 
words suitable account different costs misclassifying different classes 
example cost identifying mailing responder certainly identifying non responder direct marketing applications 
various approaches proposed adjusting distribution training data cost matrix called stratification approaches adding cost framework top existing accuracy driven classifiers 
framework uses scores generated individual binary classifiers misclassification cost matrix arrive predictions bayes optimality rule minimum expected cost 
order validate proposed framework applied real life dataset network intrusion detection application 
data set supplied part kdd cup classifier contest 
dataset contained records attributes continuous categorical belonging attack classes normal attack class 
contest challenging respects 
training dataset wide distribution class populations largest class smallest class 
second misclassification cost evaluation criterion smallest classes having highest penalty getting misclassified 
third told test data set evaluated different distribution classes training data set 
attack classes consisted different subclasses training data rest test data 
participated contest 
matter fact technique proposing evolved participation contest 
applied proposed pnrule framework dataset 
compare results participants hoping known state ofthe art techniques 
subset test data belonged subclasses training data set technique performs best terms accuracy misclassification cost 
especially technique substantially better class small proportion carries high misclassification penalty 
aside mention controversy test data quality triggered initial set results announced 
conducted detailed analysis test data proved original test data class labels wrong 
related various rule classification algorithms proposed literature far cn family aq algorithms ramp rise ripper cba :10.1.1.50.8204:10.1.1.48.8380
algorithms cn aq ripper sequential covering techniques called separate andconquer cn aq run small disjuncts problem exposed extensively section 
ripper technique differs slightly cn aq algorithms 
discovering growing highly accurate rule immediately prunes estimating generalization error separate prune set 
stops growing rule set description length encoding rule set training data large mdl principle 
essentially mdl principle allows balance generality rules error rate training data 
ripper intention mdl generality rules guard small disjunct problems 
similar remedy controlling specificity rule discussed earlier 
techniques ramp combine general specific general search directions single step learning attempt annealing optimization 
ramp simultaneously strives minimality rule set perfect accuracy rules training dataset 
predictive capabilities keeping rule set small general underlying hypothesis occam razor 
techniques grow rules incrementally differ search stopping criterion 
usually search stops improvement performance metric stops small 
performance metric accuracy coverage rule set training data cardinality rule set 
ripper ramp techniques rely occam razor principle implies smaller set general rules generalizes better 
role occam razor data mining debated :10.1.1.126.1376
irrespective thing remains true larger support rules generalization capability smaller support rules 
traced back early arguments large sample theories statistics 
pnrule framework main emphasis rule discovery process rule satisfy support requirements reasonable accuracy 
specifically strive small set rules cases occam razor applies believe pnrule discover small set rules 
measure techniques accuracy 
tolerance accuracy quite strict algorithms algorithms allow negative examples covered depending expected noise training data 
equivalent sense pnrule tries reduce emphasis accuracy favor support stage 
technique ensures accuracy regained removing false positives second stage 
proposed technique differs decision tree induction techniques sense 
consider binary classification problem 
grow rules detect presence target class 
gather records collectively covered rules learn rules 
assume decision tree algorithm splitting decisions rules sequence 
achieved rule evaluation metric restricting rule contain similar format conditions framework 
low accuracy rules seen decision tree algorithm learn rules individual rules 
ability learn rules collection records covered rules 
inability believe decision tree algorithms susceptible small disjunct problems learn smaller set records 
technique ability discover general rules span records covered different rules 
class techniques models constrained association rules 
models possible rules training data satisfying support accuracy thresholds 
allows possibly avoid local techniques fall greedy strategy proper ways utilizing discovered rules established 
outline rest organized follows 
give details pnrule framework binary multi class classification problems section 
section case study application framework kdd cup intrusion detection dataset 
concludes section research directions 
pnrule classification framework pnrule framework stage process rule induction training data starting general rule empty rule 
misclassification cost matrix training data set multiple class labels learns multiple binary classifier models class 
model class represented kinds rules rules rules 
rules predict presence target class rules predict absence target class 
start section illustrating concept stage learning approach 
give detailed algorithms various steps framework 
conceptual illustration learning method consider binary classification problem 
training data set target class rule records rule form conjunction conditions formed different attributes values 
denote subset applies true 
said cover denote subset class label support rule defined jsj jt jsj denotes cardinality set 
accuracy defined js jsj 
set definitions conceptually illustrate framework 
part shows entire training data set target class distributed shown shaded region 
framework operates stages 
stage starts entire training set finds rule highest combination support accuracy defined 
rule indicated 
part shows covers portion shaded area small portion unshaded region 
remove set covered repeat process remaining set part 
dataset 
high support fairly high accuracy 
process continues increasingly difficult find rules high support high accuracy 
cases give preference support illustrated part preferred 
process able capture sufficiently large portion original shaded region part start running rules low accuracy 
accuracy threshold set higher cover remaining positive examples part 
chosen despite lower accuracy covers positive examples compared 
parts show data set covered rules combined depending algorithm stops 
seen preference support iterations covered quite examples negative class commonly referred false positives 
shown shaded areas 
dataset consisting records covered union rules start inverse learning process 
goal learn rules cover remove false positives collectively covered rules 
follow similar steps described new target class absence original target class 
shown restricted universe shaded portion new target class 
rule tries capture positive examples new target class high accuracy 
iterations progress give preference support rules closely monitoring accuracy 
point note accurate rule stage strictly removes false positives covered stage rule accuracy removes true positive examples original target class captured stage 
call phenomenon false negatives 
goal stage remove false positives possible introducing false negatives 
choosing rules high combination support accuracy helps achieve goal 
rules discovered stage called rules 
positive examples stage second negative examples positive examples negative examples examples removed pnrule works 
original training set discover rule discover second rule remaining examples choice third rule 
chosen support 
accuracy threshold low selected 
chosen support 
starting data set second stage stage stops 
starting data set second stage stage stops 
stages higher accuracy large support rules discovered lower accuracy rules discovered 
rank rules order discovered rules significant rules 
stage process expect captured positive examples target class negative examples false positives 
false positives getting covered attributed lower accuracy rules 
similarly positive examples missing coverage attributed lower accuracy rules 
observation design scoring mechanism allows recover false negatives introduced low ranked rules 
scoring mechanism try assign low scores negative examples covered low accuracy rules 
note afford aggressive keeping final accuracy threshold low stages rely scoring mechanism correct additional errors introduced 
stage learning approach illustrated scoring mechanism elaborated section key novel features method 
main learning algorithm model format pseudo code main algorithm learning binary classifier model 
details subroutines subsections 
points note main algorithm 
algorithm parametrized support accuracy thresholds applied stage 
experience case study problem wide variation class distributions usually support thresholds stages quite strict higher 
accuracy thresholds relaxed lowered depending characteristics target class 
especially smaller target classes need lowered substantially stage support thresholds set higher 
scoring mechanism absent model simply mean rule applies rule applies record record belongs target class 
formally means pnp gamma nnn gamma equivalently dnf model form nnn gamma nnn gamma pnp gamma nnn gamma seen model restrictive sense conjunctions conditions common 
restrict kinds functions learn model 
see section scoring mechanism allows relax restriction selectively deciding ignore effects certain rules choosing evaluating rules steps subroutine called main algorithm 
seen algorithm rule quite general sense involves conjunctions 
rules categorical attributes straightforward 
numerical attributes mechanism find interesting ranges values crucial formation rules 
currently simple clustering mechanism 
start forming small number ranges equal span 
merge split ranges number records range satisfy certain pre specified minimum maximum requirements cluster size 
evaluate strength range merge adjacent ranges similar strengths 
sophisticated algorithm simple algorithm produce promising ranges 
promising ranges systematically extended reduced maximize performance metric rule 
define performance metrics evaluating comparing rules 
attempt capture distinguishing capability rule class support rule accuracy target class training set class class stage stage discover rules np empty pn records covered pn gamma np np accuracy pn gamma support pn gamma second stage stage discover rules nn nnn records covered nnn gamma nn nn accuracy nnn gamma support nnn gamma gather pnrule statistics np nn number records apply number records apply class nn number records applies rule applies nn number records applies rule applies class output rules np rules nn algorithm learn pnrule model binary classification rs empty attribute type pair type type categorical distinct value form rules compute strengths add rs strengths endfor endif type continuous form interesting ranges values range low high form rules low high low high compute strengths add rs strengths endif endfor sort rules rs increasing order strength return rule having highest strength algorithm choose best rules iteration rule single metric 
rule higher value metric imply statistically significant capturing target class 
ffl number ar denote accuracy rule denote support 
refer section definitions 
ac denote mean target class defined ac js jsj current training data set subset true 
oe denote standard deviation target class binary problem consideration oe ac gamma ac 
notations number defined zr gamma ac oe metric measures standard deviations away mean rule mean target class 
farther away ar ac better distinguish examples class weighing distance gives weight high support rules 
number similar test test statistics depending value rule high positive number ae ac predicts presence high confidence 
similarly rule high negative number ac predicts absence high confidence 
metric similar test statistics 
ffl number class mean ac closer discovering rules large classes number defined capable distinguishing high accuracy rules 
tends give little weight support 
cases define measure computes ratio far away ac ar ideal mean weighs ratio support 
goal assign weight high accuracy rules 
yr min gamma ac gamma ar illustrate necessity number consider example ac 
rule ar rule ar 
zr zr 
numbers yr yr 
number preference lower accuracy rule compared despite supports order 
number choose desired rule 
note situation happen iterations stage pnrule strives high accuracy rules just rule induction techniques 
conversely small ac values target class small iterations number starts getting biased excessively high accuracy low support rules larger gamma ar term 
example ac ar ar get zr zr yr yr 
clearly statistical support compared reflected accurately number 
low ac values revert back number 
pnrule classification strategy scoring algorithm learned rules rules class describe classify unseen record 
indicated section rules rules arranged decreasing order significance order discovery 
record consisting attribute value pairs classifier applies rules ranked order 
rule applies prediction false 
rule applies accepted rules applied ranked order 
rule applies accepted 
default rule applies discovered rules apply 
reason having default rule clear little section 
classifier simple true false decision predict record true rule applies rule applies 
useful especially multi class framework may need resolve conflicts true decisions multiple classifiers 
need mechanism assign score decision 
depending rule rule combination applies predict record true certain score interval 
score interpreted probability record belonging target class 
scores individual classifiers combined cost matrix decide cost effective class record 
classification strategy 
light describe classifier determines scores assign rule rule combination 
motivation design scoring mechanism weigh effect rule rule 
remember rules learned set records collectively covered rules 
rule significant removing collective false positives 
rule may effective removing false positives subset rules 
low accuracy rule may introducing excessive false negatives rules possibly primary contribution remove false positives lower accuracy rules 
excessive false negatives recovered assigning correspondingly low score 
need properly judge significance rule rule 
starting point scoring mechanism defined 
entry nn gives number records true predictions rule converted false rule entry row gives number records applied rule applied 
reflects prediction errors combination 
entries nn give false negatives introduced predictions gives number false positives rules able remove 
column effectively corresponds rule states rule applies 
example shown 
look entries matrices 
imply records training dataset covered rule rule applied records decision remove false positives wrong records 
means removed false positives introduced false negatives 
goal come nn gives score record rule rule apply gives score rule applies rule applies 
algorithm minsupport np nn nn nn nn nn nn nn nn nn nn gamma gamma gamma gamma endfor endfor np nn minsupport assign gamma nn go number left node parent distribution minsupport endif endfor nn nn endfor return algorithm constructing mechanism assign scores decisions see section details arrive 
illustrate idea algorithm example 
construct matrices 
rule captures positive examples true positives tp negative examples false positives fp discovered 
give initial accuracy tp tp fp 
look init columns 
rules applied successively accuracy varies depending false positives removed false negatives introduced rule 
precisely variations reflected matrices 
matrices understood better decision tree rule 
shows tree rule 
root node records applies 
records tps fps accuracy 
records rule applies records tp fp 
determine significance specific applying criterion states support decision satisfy threshold 
example threshold statistically insignificant support decide ignore effect 
decision reflected assigning accuracy parent node location 
recalculate tp fp accuracy statistics records apply 
propagate statistics root node node decide ignore effect 
reason sequential covering nature way rules learned implies decisions rule rules significant population records rule apply 
applied new set records tp fp applies tp fp 
satisfies support criterion significance 
calculate number formula zn np gamma ap oe np support parent node tp fp 
ap accuracies rule node parent respectively oe gamma ap standard deviation parent population 
second criterion significance states absolute value zn sufficiently high decision rule significant rule 
test similar test test statistics depending value np 
point note rule significant number discovered learning process computed collection records covered rules 
determining significance specific rule 
example specific jzj value high decide effect significant 
decision reflected assigning accuracy node location 
applies record predicted true say probability record belonging target class 
process continues find decision significant support sufficient distinguishing capability low jzj 
ignore effect assign location accuracy parent 
rule applies assign accuracy leaf location row 
entire process repeated 
node decision tree determine rule significant rule 
significant accuracy rule score decision accuracy parent 
verified rules statistically significant support rule significant support criterion 
points note algorithm illustrated example 
node support falls ignore effect assign score nearest ancestor having statistically significant support 
second allow perfect decision node scores exact 
score gets adjusted tp score gets adjusted fp reason doing give importance perfect decisions small population compared perfect decisions larger population 
moment parent node perfect adjusting scores splitting assign adjusted score remaining locations row 
parameters usually fixed problems statistical arguments 
essential effect scoring mechanism selectively ignore effects certain rules rule 
reflects adjusted probability record belongs target class combination applied 
init init init final result rule applies low 
low support parameters illustration rule format true positives false positives accuracy illustration constructing scoring mechanism making pnrule cost sensitive misclassification cost matrix fc cost predicting class class goal predict classes data set minimize total misclassification cost penalty 
record actual probability sjx record belonging class known bayes optimality rule implies assigning class record minimizes sjx gives cost 
scores generated binary classifiers estimation sjx formula predict class strategy may scores generated classifier close estimates sjx 
analyzed issue detail plan 
preliminary concept scoring strategy seen test data training data similar class distributions scores closer true estimates 
section discuss possible ways handling situations scores close true estimates 
case study applying pnrule detect network intrusions order validate pnrule framework applied classification problem domain network intrusion detection 
training test data sets supplied part kdd cup contest 
participated contest 
section explain problem challenges 
describe strategy initially 
analyze strategy critically give reasons explain suspected original test data quality proved wrong 
pnrule framework proposed improved automated version original strategy 
show pnrule approach promising yields best performance certain scenarios 
data set challenges network intrusion detection problem provided part kdd cup classifier learning contest follows 
training data set close records belonging classes misclassification cost matrix goal learn classifier model achieve total misclassification cost predicting labels supplied test data records 
description data set training test data collected real life scenario military computer network intentionally various attacks hackers break 
record represents connection network hosts 
characterized attributes continuous valued discrete valued 
exemplary attributes duration connection number bytes transferred number failed login attempts network service connection record represented intrusion attack normal connection 
categories attack denial service dos surveillance probe remote local user root 
seen data set quite large represented real world problem 
salient features problem data set contest challenging goal mere accuracy misclassification cost matrix 
cost matrix table 
attack category subclasses attacks 
told total total attack subclasses appear test data training data 
distribution training records attack categories subclasses varied dramatically 
table shows counts representative classes subclasses 
misclassification cost penalty infrequent classes 
told test data completely different distribution classes compared training data 
dos probe normal probe dos normal smurf dos neptune dos back dos teardrop dos probe satan probe buffer overflow dos probe normal actual class predicted class count class subclasses count table characteristics problem training data 
misclassification cost matrix 
class subclass distribution training data 
days submit results 
evaluation criterion misclassification costs announced weeks prior submission date 
original strategy results critique method submitting results contest 
describe roots pnrule framework 
developed week period starting scratch existing classifiers 
summary strategy 

decided domain knowledge 
decided evolve rule model rules high support accuracy training data 
underlying bias assumed rules yield model better generalization capability 

observed peculiar behavior class labels training data 
labels appearing bursts large number consecutive records class label 
fact records training data appeared bursts 

classes distributed widely decided learn separate binary model class starting frequent classes smurf neptune normal 
observed smurf single rule capturing positive examples 
high accuracy 
applied burst analysis remove records occur large bursts bring accuracy 
find rule model neptune sufficiently high accuracy training data 

find high accuracy rules class decided remove smurf neptune records learn models classes remainder data 
done increase relative proportion really tiny categories 

class smurf find set rules capture large portion positive examples high accuracy 
formed rule model stages similar pnrule 
rules single attribute manner described section 
ranked number 
rules high positive number hand picked cover positive examples class 
rules similarly hand picked rules having low negative numbers rules predict absence target class high confidence 
rule observed false positives getting removed rule 
rule observed false positives removing false negatives introducing 
measures went iterations adding deleting reordering rules rules arrive final set sufficiently low false positive rate high detection rate achieve 
decision model follows rule applies rules applies predict class true predicted false 
normal fp rate normal probe dos probe dos misclassification cost accuracy acc normal probe dos probe dos misclassification cost accuracy acc normal fp rate results obtained original stage strategy 
corrupt test data supplied initially 
proved test data wrong 
correct test data 
disputed records test normal test ds normal smurf description labels disputed records distinct values atr duration max value atr distinct values atr src bytes normal training max value atr smurf training times strong smurf model applies times simple smurf rule applies labels disputed records dataset ds dataset ds dataset ds dataset ds counts smurf table proved original test data labels wrong 

forming models applied burst analysis remove bursts having small size lower accuracy 
appeared training data predictions rules test data exhibit bursty behavior especially large classes smurf 

brought costs ad hoc manner 
conflict decisions decided give preference classes order misclassification cost penalties 
results came th rank confusion matrix shown 
test data labels available observed assumption similar bursty behavior training test data wrong classes 
done analysis predictions models directly improved misclassification cost rank gone th place 
thing struck confusion matrix false alarm rate dos high 
led trigger controversy test data quality issue describe subsection 
test data quality issue proved wrong high false alarm rate dos quite surprising high accuracy models smurf neptune prominent subclasses dos 
fact quite accurate predicting neptune records test data records predicted smurf normal test data labels 
smurf model low false positive rate rule attribute 
added conjunctions rule consist attributes 
stronger model false positive rate gone capture smurf training 
statistical chances false positive rate blowing way upto test data 
high data mining technique fail 
analysis 
tried domain knowledge 
observed behavior basic attributes duration connection bytes transferred source host 
normal connection attributes vary possible range values attack connections exhibit standard pattern hackers strategy attack 
separated data sets observed behavior basic attributes 
definition data sets results shown table 
seen datasets ds ds similar datasets ds ds similar making case records ds disputed data set smurf normal 
argument statistically stronger model case test data labels especially disputed data set wrong 
right 
proof reached just time hold results announcements people prepared data agreed mistake labeling test data 
new corrected test data supplied re evaluated 
rank improved th new test data 
new confusion matrix shown 
seen false alarm rate dos close 
fact labels disputed data set smurf 
applying pnrule results original strategy main shortcomings 
rule models formed hand picked rules 
took iterations choosing rules give low false positive rate high detection rate 
second decision classifier model binary 
rules equally strong influence rule 
binary decision score means putting confidence decision classifier 
pnrule framework section developed noticing shortcomings 
main deviations pnrule framework pre pnrule strategy systematic automated way finding rules rules sequential covering strategy scoring mechanism 
usual criticism sequential covering algorithms regarding small disjunct problem elaborated section 
apart differences algorithm things differently applying pnrule network intrusion detection data set kdd cup contest 
obvious thing rely burst analysis 
required learning stage pnrule model smurf order remove false positives rule 

developed models smurf neptune entire training set removing record smurf neptune predicted true removed records score greater classes 
refer filtered training data set 
prominent classes remaining normal probe 
remaining classes remaining subclasses dos really tiny 
formed subset 
subset refered record belonging classes sample records belonging normal probe 
goal increase statistical significance classes 
learned rules normal probe entire 
learned rules normal probe entire models rules smaller classes 
scores classifiers misclassification cost matrix final decisions procedure section 
describing results illustrate scoring mechanism works 
model formed consists rules rules 
scores individual pn rule combinations formed data set 
matrices formed algorithm shown 
parameters minsupport 
variations true false positives illustrate rules improve accuracy removing false positives 
locations init init scoring mechanism action 
normal probe dos probe dos acc normal fp rate performance models data set 
note data set contains smurf neptune records 
see text detailed description data set formed 
contest runner contest winner contest winner contest runner normal probe dos probe dos misclassification cost accuracy acc normal fp rate normal probe dos probe dos misclassification cost accuracy acc fp rate normal normal probe dos probe dos misclassification cost accuracy acc normal fp rate normal probe dos probe dos misclassification cost accuracy acc normal fp rate normal probe dos probe dos misclassification cost accuracy acc normal fp rate normal probe dos probe dos misclassification cost accuracy acc normal fp rate pnrule pnrule results subset test data known subclasses results entire test data comparing pnrule results winner runner kdd cup contest 
rows perfect rules assigned adjusted scores refer section decision gets scored higher larger support 
rule effects rules taken account assigned score accuracy left node rules 
satisfy support requirement left node significantly distinguished parent jzj 
rule left node distributions low 
parent statistics combinations 
rule prominent effect 
shows accuracy false positive rates models applied training data set statistics computed combining scores individual classifiers cost sensitive manner 
seen models recall high detection rate accuracy precision low false positive rate 
model difficult learn training cases available class close records 
records divided subclasses records 
numbers small give statistical significance decisions 
despite able identify signatures records false positive rate 
pnrule performance quite class small number records close 
matter fact conceptually pnrule suited handle small statistically significant classes 
models applied corrected test data contest obtained results shown 
results rank th 
certainly improvement previous technique 
show results winner runner entries contest figures respectively 
seen far away misclassification cost winning entry 
matter fact pnrule best detection rate 
peculiar thing observe large numbers column confusion matrices 
misclassified large number dos records normal 
happens records test data belonging subclasses completely absent training data job capturing unknown subclasses 
fair comparison decided remove records 
remainder test data bearing known class labels show confusion matrices entries right half 
pnrule results part 
seen pnrule performs better entries terms misclassification cost accuracy 
number records misclassified pnrule second best part 
pnrule misclassification cost penalty better second best part 
safely assume applied different techniques solve problem pnrule method performs better best conclude pnrule certainly promise effective classification technique problems similar nature network intrusion detection problem studied detail 
concluding remarks research proposed new framework pnrule multi class classification problem 
key novel idea pnrule learning rule model stages find rules predict presence class find rules predict absence class 
believe help overcoming problem small disjuncts faced sequential covering algorithms 
second novel idea pnrule mechanism scoring 
allows selectively tune effect rule rule 
shown case study network intrusion detection proposed pnrule framework holds promise performing classification problems especially ones wide variation class distributions 
proposed framework opens avenues testing improvement 
currently process testing pnrule various datasets different domains 
particular plan analyze behavior data sets sequential covering problems faced small disjuncts problem 
aspect proposed framework needs regards choice support accuracy thresholds phases 
case study application decided thresholds observing behavior stage target class 
primary factor size class learned rate support accuracy newly discovered rules varied 
automated techniques need developed encode heuristics 
possibility despite efforts learning rules collection rule covered records second phase face small disjunct problem 
cases possible solutions include pruning mechanisms generalization framework multi phase framework 
scoring mechanism proposed possibilities improvement 
especially training data distributions different know test data scenario similar transduction modify mechanism scores reflect true probability class record justifying bayes optimality rule 
possibility try estimates generalization errors scoring pn rule combinations 
possibility imposing framework metacost top pnrule cost sensitive 
possibility replacing scoring mechanism different technique explored 
example rules learned pnrule classification strategy encoded functionally equivalent decision tree rules rules form decisions nodes 
tree pruned decision tree pruning method mdl example 
currently pnrule uses rules attribute 
restricts framework rules having conditions conjunction rules formed frequent sets association rules 
current mechanism form clusters ranges numerical attributes scope improvement 
kamal ali pazzani :10.1.1.34.2014
reducing small disjuncts problem learning probabilistic concept descriptions 
petsche hanson shavlik editors computational learning theory natural learning systems knowledge discovery data mining 
mit press cambridge 
apte hong prasad rosen 
ramp rule abstraction modeling prediction 
technical report rc ibm research division 
cherkassky 
learning data 
john wiley sons 
clark niblett 
cn induction algorithm 
machine learning 
william cohen 
fast effective rule induction 
proc 
twelfth international conference machine learning lake tahoe california 
andrea foster provost 
small disjuncts action learning diagnose errors local loop telephone network 
proc 
tenth international conference machine learning pages 
morgan kaufmann 
pedro domingos 
rise system separating 
proc 
sixth ieee international conference tools artificial intelligence pages new orleans louisiana 
pedro domingos 
metacost general method making classifiers cost sensitive 
proc 
fifth international conference knowledge discovery data mining kdd pages san diego california 
pedro domingos 
role occam razor knowledge discovery 
data mining knowledge discovery 
duda hart 
pattern classification scene analysis 
wiley new york 
charles elkan 
kdd classifier learning competition 
www epsilon com kdd harvard html september 
charles elkan 
results kdd classifier learning contest 

ucsd edu elkan html september 
wei fan salvatore stolfo zhang philip chan 
misclassification cost sensitive boosting 
proc 
sixth international conference machine learning icml bled slovenia 
appear 
robert holte acker porter 
concept learning problem small disjuncts 
proc 
eleventh international joint conference artificial intelligence ijcai pages 
levin 
kernel miner takes second place kdd classifier learning competition 
www com kdd cup html october 
bing liu hsu yiming ma 
integrating classification association rule mining 
proc 
fourth international conference knowledge discovery data mining kdd new york city 
mehta rissanen agrawal 
mdl decision tree pruning 
proc 
int conference knowledge discovery data mining pages montreal quebec 
michalski hong lavrac 
multi purpose incremental learning system aq testing application medical domains 
proc 
fifth national conference ai aaai pages philadelphia 
tom mitchell 
machine learning 
mcgraw hill 
muggleton feng :10.1.1.35.951
efficient induction logic programs 
proc 
conference algorithmic learning theory alt ohmsha tokyo 
bernhard pfahringer 
results known classes 
private communication authors october 
ross quinlan 
improved estimates accuracy small disjuncts 
machine learning 
ross quinlan cameron jones 
oversearching layered search empirical learning 
proc 
fourteenth international joint conference artificial intelligence ijcai pages montreal canada 

classification strategies association rules 
plan project report department computer science university minnesota 
turney 
cost sensitive learning bibliography 
ai iit nrc ca bibliographies cost sensitive html 
vladimir vapnik 
statistical learning theory 
john wiley sons 
gary weiss 
learning rare cases small disjuncts 
proc 
twelfth international conference machine learning pages lake tahoe california 

