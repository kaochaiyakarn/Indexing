predicting data cache misses non numeric applications correlation profiling todd mowry chi luk department computer science department computer science carnegie mellon university university toronto pittsburgh pa toronto canada tcm cs cmu edu luk toronto edu maximize benefit minimize overhead software latency tolerance techniques apply precisely set dynamic suffer cache misses 
unfortunately information provided state theart cache profiling technique summary profiling inadequate intermediate ratios results failing hide latency inserting unnecessary overhead 
overcome problem propose evaluate new technique correlation profiling improves predictability correlating caching behavior associated dynamic context 
experimental results demonstrate roughly half non numeric applications study potentially enjoy significant reductions memory stall time exploiting forms correlation profiling consider 
disparity processor memory speeds continues grow memory latency increasingly important performance bottleneck 
cache hierarchies essential step coping problem panacea 
tolerate latency number promising techniques proposed 
example compiler tolerate modest latencies scheduling non blocking loads early relative results consumed tolerate larger latencies inserting prefetch instructions 
software techniques provide latency hiding benefits typically incur runtime overheads 
example aggressive scheduling non blocking loads increases register lifetimes copyright ieee 
proceedings micro december research triangle park north carolina 
lead spilling software controlled prefetching requires additional instructions compute prefetch addresses launch prefetches 
benefit technique typically outweighs overhead tolerated overhead hurts performance cases enjoyed cache hit anyway 
maximize performance apply latency tolerance technique precise set dynamic suffer misses 
previous addressed problem numeric codes focuses difficult important case isolating dynamic instances non numeric applications 
predicting data cache misses non numeric applications overcome compiler inability analyze data locality non numeric codes profiling information 
simple type profiling information precise ratios static memory 
remainder refer approach summary profiling ratio memory summarized single value 
summary profiling indicates significant memory instructions executed frequently non trivial contribution execution time ratios close isolating dynamic misses trivial simply apply latency tolerance technique static suffer misses 
contrast important intermediate ratios sufficient information distinguish dynamic instances hit information lost course summarizing ratio 
current state art approach dealing inter load context context context context example correlating cache misses dynamic context may improve predictability 
means misses dynamic 
mediate ratios treat static memory ratios certain threshold hit respectively 
strategy fail hide latency predicted hit induce unnecessary overhead predicted hit 
settling sub optimal performance prefer predict dynamic hits misses accurately 
correlation profiling exposing caching behavior directly user informing memory operations enable new classes lightweight profiling tools collect sophisticated information simply ratios 
example cache misses correlated information control flow paths cache outcomes previous help predict dynamic cache behavior 
refer approach correlation profiling 
illustrates correlation profiling information exploited 
load instruction shown ratio 
depending dynamic context load may see predictable behavior 
example contexts result high likelihood load missing contexts 
apply latency tolerance technique contexts dynamic contexts shown viewed simply non overlapping sets dynamic instances load grouped share common distinguishable pattern 
consider different types information distinguish contexts 
control flow information sequence basic block numbers preceding load 
sequences cache access outcomes hit previous memory self correlation considers cache outcomes previous dynamic instances static global correlation refers previous dynamic entire program 
note analogous forms types correlation profiling explored previously context branch prediction objectives overview goal determine correlation profiling predict data cache misses accurately non numeric codes summary profiling translate significant performance improvements applying latency tolerance techniques greater precision 
focus specifically predicting load misses load latency fundamentally difficult tolerate store latency hidden buffering pipelining 
rely simulation capture profiling information study correlation profiling practical technique performed relatively little overhead informing memory operations 
remainder organized follows 
section discussing different types history information correlation profiling 
sections experimental methodology experimental results quantify performance advantages correlation profiling 
discuss related sections 
correlation profiling techniques section propose motivate new correlation profiling techniques predicting cache outcomes control flow correlation self correlation global correlation 
control flow correlation profiling technique correlates cache outcomes control flow paths 
collect information profiling tool maintains basic block numbers fifo buffer matches pattern hit outcomes memory 
intuitively control flow correlation useful detecting cases data reuse cache displacement 
path leads data reuse temporal spatial cache hit 
consider example shown graph traversed recursive procedure walk 
cyclic paths result code data reuse struct node int data struct node left right void walk node data go left data left elsif go right data right elsif go data elsif go data null null walk example graph left right code cache displacement foo examples control flow correlation detect data reuse cache displacement 
control flow profiled loads underlined 
temporal reuse data 
example controlflow correlation potentially detect traversal decisions lead cycle right left high probability data enjoy cache hit 
control flow paths may increase likelihood cache displacing data line reused 
example condition true subsequent loop displace primary cache loaded 
note paths access large amounts data obvious problems displacement due mapping conflict 
self correlation self correlation profile load correlating cache outcome previous cache outcomes 
approach particularly useful detecting forms spatial locality apparent compile time 
example consider case tree constructed preorder assuming consecutive calls memory allocator return contiguous memory locations cache line large hold exactly 
depending traversal order extent tree modified created may experience spatial locality tree subsequently traversed 
example tree traversed preorder expect data suffer misses cache line boundaries crossed 
despite fact ratio data compiler difficulty recognizing form spa example code preorder null data preorder left preorder right tree constructed traversed preorder hit preorder traversal self cache outcomes data example self correlation profiling detect spatial locality data 
consecutively numbered nodes adjacent memory 
example code int hash get listnode curr curr null curr data curr curr hash table accesses hit data data data data data data 




memory accesses global cache outcomes global example global correlation profiling detect bursty cache misses curr data 
tial locality self correlation profiling accurately predict dynamic cache outcomes data 
global correlation contrast self correlation idea global correlation correlate cache outcome load previous cache outcomes regardless positions program 
profiling tool maintains pattern single deep fifo updated dynamic cache accesses occur 
note earlier instances may appear global history pattern global correlation may capture behavior self correlation particularly extremely tight loops 
intuitively global correlation particularly helpful detecting bursty patterns misses multiple 
example situation move new portion data structure accessed long time displaced cache case fact access object suffers indication associated neighboring objects illustrates case large hash table large fit cache organized array linked lists 
case expect strong correlation list head pointer misses subsequent accesses curr data list elements similarly entry accessed twice short interval fact head pointer hits strong indicator list elements data data hit 
summary correlating cache outcomes context occurs surrounding control flow cache outcomes prior potentially predict dynamic caching behavior accurately possible summarized ratios 
experimental methodology evaluate potential performance benefit correlation profiling measured impact non numeric applications entire spec integer benchmark suite additional integer benchmarks contained spec suite uniprocessor versions graphics applications splash applications olden suite pointer intensive benchmarks standard unix utility awk :10.1.1.104.6469
table briefly summarizes applications including input data sets run completion case 
compiled application optimization standard mips compilers irix 
mips pixie utility instrument binaries piped resulting trace detailed performance simulator 
increase simulation speed simplify analysis model perfectly pipelined single issue processor similar mips 
reduce simulation time simulator performs correlation profiling selected subset load instructions 
criteria profiling load rank top loads terms total cache count ratio 
attempt maintain history information possible sake correlation 
controlflow correlation typically maintained path length basic blocks cases resulted large number distinct paths forced measure basic blocks 
self global technical report model modern superscalar processor mips space constraints prevent showing data 
table benchmark characteristics 
suite name input data set cache size spec ksim train kb integer perl train kb go train kb ijpeg train kb vortex train kb compress train kb gcc train kb li train kb spec sc kb integer espresso cps kb eqntott int pri eqn kb splash raytrace car kb radiosity batch kb olden bh bodies kb mst nodes kb perimeter image kb health max 
level kb max 
time tsp cities kb integers kb em nodes kb nodes voronoi points kb unix awk extensive test kb utilities awk capabilities correlation experiments maintained patterns previous cache outcomes self global 
focus predictability single level data cache levels analysis complicated choice data cache size important large small relative problem size predicting dynamic misses easy hit 
operate near knee ratio curve predicting dynamic hits misses presents greatest challenge 
potentially reach knee altering problem size greater flexibility adjusting cache size reasonable range 
chose data cache size follows 
summary profiling collect ratios loads application different cache sizes ranging kb kb 
chose cache size resulted largest number significant loads having intermediate ratios sizes shown table 
cases model way set associative cache byte lines 
experimental results shows correlation profiling schemes control flow self global improve prediction accuracy correlation profiled loads 
due space constraints show eleven cases significant cases cases technical report 
bar predict actual hit predict hit actual normalized misprediction awk basic blocks normalized misprediction basic blocks normalized misprediction compress basic blocks normalized misprediction eqntott basic blocks normalized misprediction espresso basic blocks normalized misprediction li basic blocks normalized misprediction ksim basic blocks normalized misprediction mst basic blocks normalized misprediction perimeter basic blocks normalized misprediction raytrace basic blocks normalized misprediction tsp basic blocks number mispredicted correlation profiled loads normalized summary profiling summary profiling control flow correlation self correlation global correlation 
maximum path lengths control flow correlation indicated benchmark names 
normalized respect number mispredicted summary profiling broken categories 
top section pre dict hit actual represents lost opportunity predict hits attempt tolerate latency misses 
predict actual hit section accounts wasted overhead apply latency tolerance hits 
decision apply latency tolerance technique load works follows 
certain granularity dictated ability statically isolate different contexts choose single strategy set dynamic instances load apply 
apply net gain dynamic ml gamma ratio average cache latency average latency tolerance overhead 
breakeven point occurs apply 
summary profiling threshold applied ratio instruction correlation profiling applied groups dynamic instances distinguishable contexts 
shows results values 
summary profiling tends apply latency tolerance aggressively resulting noticeable amount wasted overhead 
contrast summary profiling tends conservative resulting misses 
correlation profiling significantly reduce types misprediction 
quantify performance impact improved prediction accuracy shows resulting execution time profiling schemes assuming cache latency cycles 
bar normalized execution time latency tolerance broken categories 
bottom section busy time 
section predict actual useful overhead paid tolerating normally top sections represent misprediction penalty including wasted overhead predict actual hit latency predict hit actual 
degree improved prediction accuracy translates reduced execution time depends relative importance load stalls fraction loads correlation profiled 
factors favorable eqntott predict hit actual predict actual hit predict actual busy normalized exec time awk basic blocks normalized exec time basic blocks normalized exec time compress basic blocks normalized exec time eqntott basic blocks normalized exec time espresso basic blocks normalized exec time li basic blocks normalized exec time ksim basic blocks normalized exec time mst basic blocks normalized exec time perimeter basic blocks normalized exec time raytrace basic blocks normalized exec time tsp basic blocks impact profiling schemes execution time assuming cycle latency 
summary profiling control flow correlation self correlation global correlation 
see large performance improvements factor small perimeter tsp performance gains modest despite large improvements prediction accuracies 
failing hide expensive wasting overhead possible improve performance replacing expensive expensive mispredictions total misprediction count increases raytrace control flow correlation 
lessons learned carefully studied memory access patterns application hand develop deeper understanding correlation profiling succeeds 
space constraints prevent presenting full details briefly summarize major results detail refer reader earlier publication 
global correlation excellent predictions cases correlating behavior different load instructions eqntott cases essentially self correlation perform quite records history load 
self correlation successful recognizes forms spatial locality recognizable compile time li perimeter mst long runs hits misses eqntott mst tsp raytrace 
find previous cache outcomes sufficient achieve predictability self correlation 
capturing call chain information control flow correlation distinguish behavior call sites eqntott espresso vortex ksim go mst voronoi depth recursion traversing tree perimeter tsp 
roughly half applications enjoy significant improvements control flow self correlation cases observe load successfully predicted forms correlation 
news control flow correlation profiling easiest case exploit practice procedure cloning distinguish call chain dependent behavior 
applied technique software controlled prefetching observed correlation profiling offers superior performance summary profiling prefetching modern superscalar processor 
related abraham investigated summary profiling associate single latency tolerance strategy attempt tolerate latency profiled load 
approach reduce cache ratios spec benchmarks including integer floating point programs 
follow study report improvement effective cache ratio 
contrast earlier study focused correlation profiling novel technique provides superior prediction accuracy relative summary profiling 
ammons path profiling techniques observe large fraction primary data cache misses spec benchmarks occur relatively small number frequently executed paths 
forms correlation explored study control flow self global inspired earlier correlation enhance branch prediction accuracies 
branch outcomes cache access outcomes quite different interesting observe correlation prediction works cases 
help achieve full potential software latency tolerance techniques proposed correlation profiling technique isolating dynamic instances static memory suffer cache misses 
experiments demonstrate exploiting forms correlation information consider control flow self global correlation profiling outperforms summary profiling improving prediction accuracy reducing memory stall times 
observe self correlation works cache outcome patterns individual repeat predictable ways control flow correlation works mainly cache outcomes call chain dependent 
global correlation offers superior performance cases typically effective job capturing behaviors self correlation 
informing memory operations techniques procedure cloning exploit correlation profiling information practice 
hope promising results lead innovations optimizing memory performance non numeric applications 
acknowledgments supported natural sciences engineering research council canada ibm canada centre advanced studies 
todd mowry partially supported faculty development award ibm 
chi luk partially supported canadian commonwealth fellowship 
abraham rau 
predicting load latencies cache profiling 
technical report hpl hewlett packard november 
abraham rau gupta 
predictability load store instruction latencies 
micro pages december 
ammons ball larus 
exploiting hardware performance counters flow context sensitive profiling 
pldi june 
chang hao yeh patt 
branch classification new mechanism improving branch predictor performance 
micro november 
cooper hall kennedy 
methodology procedure cloning 
computer languages april 
horowitz martonosi mowry smith 
informing memory operations providing memory performance feedback modern processors 
isca pages may 
mowry lam gupta 
design evaluation compiler algorithm prefetching 
asplos pages october 
mowry 
luk 
predicting data cache misses non numeric applications correlation profiling 
technical report cmu cs carnegie mellon university september 
pan 
improving accuracy dynamic branch prediction branch correlation 
asplos pages october 
rogers carlisle reppy hendren 
supporting dynamic data structures distributed memory machines 
acm trans 
programming languages systems march 
rogers li 
software support speculative loads 
asplos pages october 
smith 
tracing pixie 
technical report csl tr stanford university november 
woo singh gupta :10.1.1.104.6469
splash programs characterization methodological considerations 
isca pages june 
:10.1.1.104.6469
yeh patt 
comparison dynamic branch predictors levels branch history 
isca pages may 
young smith 
improving accuracy static branch prediction branch correlation 
asplos vi pages october 
