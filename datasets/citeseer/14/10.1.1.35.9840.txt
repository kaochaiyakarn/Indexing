cross validation bootstrap estimating error rate prediction rule bradley efron robert tibshirani training set data construct rule predicting responses 
error rate rule 
traditional answer question cross validation 
cross validation estimate prediction error nearly unbiased highly variable 
article discusses bootstrap estimates prediction error thought smoothed versions cross validation 
particular bootstrap method rule shown substantially outperform cross validation catalog simulation experiments 
providing point estimates consider estimating variability error rate estimate 
results nonparametric apply possible prediction rule study classification problems loss detail 
simulations include smooth prediction rules fisher linear discriminant function ones nearest neighbors 
article concerns estimating error rate prediction rule constructed training set data 
training set delta delta delta consists observations predictor feature vector response 
basis statistician constructs prediction rule wishes estimate error rate rule predict responses predictor vectors 
cross validation traditional method choice problem provides nearly unbiased estimate error rate 
low bias cross validation paid high variability 
show suitably defined bootstrap procedures substantially reduce variability error rate predictions 
gain efficiency catalog simulations roughly equivalent increase size training set 
bootstrap procedures smoothed versions cross validation adjustments correct bias 
training set consisting observations labelled labelled 
left panel linear discriminant function predicts lower left solid line upper right 
right panel nearest neighbor rule predicts indicated islands 
mainly interested situation response dichotomous 
illustrated observations training set consist bivariate feature vector gamma response points labeled labelled 
different prediction rules indicated 
left panel shows prediction rule fisher linear discriminant function ldf efron 
rule predict lies lower left ldf boundary lies upper right 
right panel shows nearest neighbor nn rule vectors predicted label nearest observation training set 
wish estimate error rates prediction rules 
data shown generated part extensive simulation experiments described section 
case selected randomly bivariate normal vectors means depended prob jy gamma independently delta delta delta 
table shows results simulations 
cross validation compared bootstrap estimator described section 
cross validation nearly unbiased estimator true error rate rules ldf nn bootstrap estimator root mean squared error rms large 
results fairly typical simulation experiments reported section 
bootstrap estimator experiments run bootstrap replications training set turns purposes internal variance calculations section show 
ldf nn exp rms exp rms cv true table 
error rate estimation situation cv cross validation estimate omitting observation time training set bootstrap estimator described section 
table shows expectation root mean squared error estimates ldf nn prediction rules 
cases rms rms cv 
bootstrap important advantages providing accurate point estimates prediction error 
bootstrap replications provide direct assessment variability estimated parameters prediction rule 
example efron gong discuss stability significant predictor variables chosen complicated step wise logistic regression program 
section provides bootstrap replications estimate variance point estimate prediction error 
section begins discussion bootstrap smoothing general approach reducing variability nonparametric point estimators 
applied prediction problem bootstrap smoothing gives smoothed version cross validation having considerably reduced variability upward bias 
bias correction discussed section results estimates table 
estimator shown substantially outperform ordinary cross validation catalog sampling experiments described section 
section shows bootstrap replications provide point estimate prediction error provide assessment variability estimate 
distance argument underlying rule discussed section bias correction techniques 
results nonparametric apply possible prediction rule study classification problems loss detail 
regression problems may exhibit qualitatively different behavior statistical approach may differ 
sample prediction error focus regression especially model selection 
constrast error study called extra sample error 
efron studied estimates sample prediction error problem including generalized cross validation wahba cp statistic mallows 
note section clear distinction extra sample prediction error 
considerable literature cross validation bootstrap error rate estimation 
general discussion mclachlan 
key cross validation stone allen 
efron proposed number bootstrap estimates prediction error including optimism estimate 
cross validation bootstrap model selection studied breiman breiman spector shao zhang 
breiman spector demonstrated leave cross validation high variance prediction rule unstable reason leave training sets similar full dataset 
fold cross validation displayed lower variance case 
study cross validation bootstrap methods tree structured models carried crawford 
substantial prediction error problem machine learning pattern recognition fields see example simulation studies jain dubes chen murthy 
kohavi performed particularly interesting study renewed interest problem 
cross validation leave bootstrap section discusses bootstrap smoothing cross validation reduces variability error rate estimates 
notation indicate discrepancy predicted value actual response particularly interested dichotomous situation 
employ shorter notation indicate discrepancy predicted value response test point rule training set suppose observations training set random sample distribution delta delta delta independent draw called test point 
true error rate rule err err notation indicating random fixed 
compare error rate estimators terms ability predict err 
section briefly discusses estimating expected true error results case somewhat favorable bootstrap estimator 
apparent error rate resubstitution rate err err indicating empirical distribution puts probability observation delta delta delta err tends biased downward estimate err training set twice construct rule test 
cross validation stone avoids problem removing data point predicted training set 
ordinary cross validation estimate prediction error err cv training set ith observation removed 
err cv leave oneout cross validation fold version err partitions training set parts predicting turn observations part training sample formed remaining parts 
statistic err cv discontinuous function training set discontinuous 
bootstrap smoothing way reducing variance functions averaging 
suppose unbiased estimate parameter interest say fz definition nonparametric maximum likelihood estimate mle parameter fz random sample delta delta delta bootstrap sample 
bootstrap expectation smooths discontinuities usually reducing variability 
may biased estimate breiman introduces similar idea bagging 
consider applying bootstrap smoothing fixed 
nonparametric mle fq bootstrap sample empirical distribution probability gamma delta delta delta gamma delta delta delta argued bootstrap samples size gamma advantage 
follows take bootstrap samples size indicate fq notice sample drawn contains point applying case turn leads leave bootstrap err fq smoothed version err cv estimate predicts error point bootstrap samples contain point actual calculation err straightforward bootstrap exercise 
ordinary bootstrap samples delta delta delta generated random draw size replacement fx delta delta delta total samples independently drawn say delta delta delta simulations discussed 
number times included bth bootstrap sample define 
define err definition agrees bootstrap sample bootstrap sample see efron 
slightly different definition appears efron err ffl definitions agree produced nearly results simulations 
way view cross validation err estimates average error 
direct application bootstrap gives plug estimate 
estimate discussed section tends biased downward 
reason twice population say bootstrap training sets drawn population test points drawn 
write explicitly function fe convenience switched order expectation second expression 
assume unknown true state affairs plugging test distribution gives remaining task estimate training sample distribution ideally take notice continuous populations probability test point appearing training sample drawn zero 
plug estimate uses choice probability appears training sample gamma gamma 
uses training samples close test points leading potential underestimation error rate 
cross validation uses leave training samples ensure training samples contain test point 
cross validation estimates hand estimate term gives leave bootstrap estimate err efficacy bootstrap smoothing shown solid line plots standard deviation ratio sampling experiments section 
horizontal ratio standard deviations expectations leave bootstrap err compared cross validation err cv sampling experiments described section 
median sd ratio experiments median expectation ratio 
plotted versus expected true error 
axis expected true error experiment 
see err smaller standard deviation err cv median ratio experiments 
going err cv err roughly equivalent multiplying size training set 
improvement bootstrap estimators crossvalidation due mainly effect smoothing 
cross validation bootstrap closely related argument section efron shows 
smoother prediction problems example continuous gamma expect little difference err cv err dotted curve expectation ratio ef err ef err cv see err biased upwards relative nearly unbiased estimate err cv surprising 
indicate expected true error sample size ordinary cross validation produces unbiased estimate gamma fold crossvalidation estimates gammak smaller training sets produce bigger prediction errors larger gives bigger upward bias gammak gamma amount bias depend slope error curve sample size bootstrap samples typically supported original sample points expect err estimating precise calculations section efron show err closely agrees half sample cross validation repeatedly split equal sized training test sets expectation err second order 
section concerns bias corrected version err called rule reduces upward bias 
choice bootstrap replications simulation experiments assessment internal error monte carlo error due infinity replications efron 
bootstrap replications give err give jackknife estimate internal error 
estimate err bth bootstrap replication removed err gamma gamma jackknife estimate internal standard deviation err sd int gamma err gamma err delta err delta err simulations sd int typically 
external standard deviation err standard deviation due randomness typically 
section discusses estimation external error set bootstrap replications 
gives corrected external standard deviation gamma indicating sufficient 
note definition prediction error err called extra sample error test point chosen randomly training sample efron investigated restrictive definition prediction error 
dichotomous problems prob fy 
sample error rule defined err fq oi notation indicating oi binomial random fixed 
situation similar standard regression problem predictors treated fixed observed values random 
sample error prediction mathematically simpler extra sample case leads quite different solutions error rate prediction problem see efron 
estimator efron proposed estimator err delta err delta err designed correct upward bias err averaging biased estimate err coefficients gamma suggested argument fact bootstrap samples supported approximately original data points 
efron err performed better competitors simulation studies include highly overfit rules nearest neighbors err 
statistics err biased 
example equals probability independently useless predictor vector err prediction rule expected value err nearest neighbor rule delta 
err err cv correct expectation case 
breiman friedman olshen stone suggested example 
section proposes new estimator err designed biased compromise err err rule puts greater weight err situations amount overfitting measured err gamma err large 
order correctly scale amount overfitting need define information error rate fl apply independent example previous paragraph 
ind probability distribution points having marginals independent define fl ind ind expected prediction error rule test point ind estimate fl obtained permuting responses predictors fl dichotomous classification problem observed proportion responses observed proportion predictions 
fl gamma gamma rule nearest neighbors value fl gamma 
multicategory generalization fl gamma 
relative overfitting rate defined err gamma err fl gamma err quantity ranges overfitting err err overfitting equals information value fl gamma err 
distance argument section suggests biased version weights err err depend err gamma delta err delta err gamma weight ranges err ranges err err express err err err gamma err delta delta gamma emphasizing err exceeds err amount depending may happen fl err err fl err case fall outside 
take care possibility modify definitions err err min err fl err gamma err fl gamma err err fl err 
rule simulation experiments section err err err gamma err delta delta gamma shows err reasonably successful compromise upwardly biased err biased err plotted values relative bias experiments measured mean gamma 
dashes indicate information experiments independent err 
values experiments spread clarity 
cases definitions effectively truncate err near 
gives relative bias err experiments solid curve compared err top curve err bottom curve plotted values mean gamma 
dashes indicate information experiments err 
accurate estimate err case case basis yields downward bias 
put things way improve accuracy err cv truncating fl err cv longer nearly unbiased 
better bias adjustments err available discussed section 
reducing bias err lose half reduction variance enjoyed err offer dramatic improvements err cv note err requires additional applications prediction rule computation err bootstrap samples sufficient err err costly err cv large 
sampling experiments table describes sampling experiments performed study 
experiment involved choice training set size probability distribution giving dimension prediction vectors prediction rule experiments dichotomous involved classes gamma error experiments 
experiments comprised monte carlo simulations independent choices training set experiments comprised simulations 
bootstrap samples balanced sense indices bootstrap data points obtained randomly permuting string copies integers see davison 
balancing little effect results 
simulation study excessive large order investigate effects different classifiers training set sizes signal noise ratio number classes number observations 
explanatory comments concerning experiments ffl experiments response equals probability conditional distribution jy multivariate normal 
example experiment described jy gamma information form jy independent prediction rule err 
experiment response equals probability jy gamma gamma gamma gamma 
table sampling experiments described text 
results experiments table table table table table table 
experiments appear table ffl experiments taken friedman 
classes dimensions training observations 
tors class independent standard normal class independent normal mean variance delta delta delta 
predictors useful ones higher index 
ffl experiments refer real data sets taken machine learning archive uc irvine 
dimensions datasets respectively removing incomplete observations classes respectively 
followed kohavi chosen random subset data act training set training set size chosen sloping downward 
idea large error curve flat error rate estimation problem easy potential biases arising changing training set size small 
chose training set sizes respectively 
soybean data categorical predictors having possible values 
keep computations manageable binary predictors 
ffl prediction rules ldf fisher linear discriminant analysis nn nn nearest neighbor nearest neighbor classifier trees classification tree tree function plus quadratic discriminant function estimation separate mean covariance class gaussian log likelihood classification 
tables report performance error rate estimators sampling experiments readability tables deferred 
table exp sd columns give means standard deviations rms square root average squared error estimating err 
bootstrap estimators bootstrap replications simulation 
error rate estimators include err err err different crossvalidation rules cv cv cv leave fold fold cross validations cv fr fold cross validation averaged random choice partition making total number recomputations equal bootstrap rules 
shown bias corrected versions err called bc bc err see section 
tables give statistical summaries err err eq 

table results ldf classifier ind ind exp sd rms exp sd rms exp sd rms exp sd rms err cv cv cv fr bc bc results vary considerably experiment experiment terms rms error table results nn classifier ind ind exp sd rms exp sd rms exp sd rms exp sd rms err cv cv cv fr bc bc rule winner 
solid line graphs err err cv versus true expected error 
median value ratio experiments 
dotted line rms ratio estimating err measure slightly favorable rule median ratio 
simulation results viewed caution especially area broadly defined prediction problem 
smoothing argument section strongly suggests possible improve cross validation 
mind says err full decreased standard deviation seen 
decrease rms dependable decrease standard deviation part rms decrease due truncation fl definitions 
truncation effect particularly noticeable information experiments 
estimating standard error err set bootstrap replications gives point estimate prediction error assess variability estimate 
useful inference purposes model selection comparing models 
method called delta method bootstrap efron works estimators err smooth functions difficult obtain standard error estimates solid line err err cv rms ratio table plotted versus expected true error dotted line rms ratio estimating err 
dashes indicate information experiments 
vertical axis plotted logarithmically 
cross validation estimator study estimators section 
discuss estimating usual external standard deviation err meaning variability err caused random choice internal variability due random choice bootstrap samples section discussed affects assessment external variability 
discuss estimating standard deviation difference err rule err rule rule rules different prediction rules applied set data 
nonparametric delta method estimate standard error applies symmetrically defined statistics invariant permutation points delta delta delta 
case write statistic function empirical distribution 
form depend smoothly defined sense ffl version puts extra probability ffl probability gammaffl ffl gammaffl 
need derivatives ffl ffl exist ffl 
defining ffl ffl nonparametric delta method standard error estimate se del see section efron 
vector delta delta delta times empirical influence function prediction rule symmetric function points usually err symmetrically 
expectation guarantees err smoothly defined apply formulas 
consider ideal case err possible bootstrap samples delta delta delta delta delta delta ng 
notation delta delta notation err define bootstrap covariance gamma delta lemma proved section lemma 
derivative err gamma gamma err gamma gamman naive estimate standard error err gamma err false assumption independent 
amounts gamma err 
actual influences usually result larger standard error naive estimates 
practice bootstrap samples smaller case set gamma gamma err gamma delta err balanced set bootstrap samples 
bootstrap expectation equals gamma goes approach ideal case jackknife assess internal error estimates monte carlo error comes limited number bootstrap replications 
indicate value calculated gamma bootstrap samples including bth 
simple computational formulas available lines 
internal standard error jackknife formula delta gamma gamma delta delta total internal error se int delta leads adjusted standard error estimate err se gamma delta formulas applied single realization experiment having points table 
bootstrap replications generated standard error formulas calculated results appear table 
replications gave se del nearly se 
compared actual standard deviation err experiment course expect data standard error estimate vary sample sample 
se del se int se se del se int se mean st dev table 
bootstrap replications single realization experiment table standard error estimates portions replications 
right side table shows se del se successive groups bootstrap replications 
values se del remarkably stable biased upward answer replications bias adjusted values se biased twice variable group group 
example se del se gave useful results small 
delta method directly applied find standard error err rule involves err function reasonable estimate standard error err obtained multiplying err err reasonable coefficient variation estimators nearly experiments 
suppose apply different prediction rules training set wish assess significance difference diff err gamma err error rate estimates 
example ldf nn respectively 
previous theory goes change definition gamma delta method estimate standard error diff gamma diff gamma diff diff defined 
proof lemma efron tibshirani 
distance bias corrections way understand biases various error rate estimators terms distance test points training set err error rate test points zero distance away training set true value err error rate new test point may lie distance away expect error rate rule increase distance err underestimates err 
cross validation test points nearly right distance away training set nearly unbiased 
leave bootstrap err far way bootstrap training sets supported points producing upward bias 
quantitative version distance argument leads rule 
section presents argument really quite rough goes discuss careful bias correction methods 
better methods produce better estimators experiments reduced bias paid great increase variance 
efron distance methods motivate err 
brief review arguments lead motivation err system neighborhoods points delta indicate neighborhood having probability content delta delta delta section capital letters indicate random quantities distributed lower case values considered fixed 
delta assume neighborhood delta shrinks point distance test point training set defined distance nearest point ffi inff delta delta shows neighborhoods probability content delta realization problem 
chosen delta circles planes 
delta gamma jj rg chosen holds 
notice neighborhoods grow smaller near decision boundary occurs probability refers distribution joint distribution delta jffi deltag expected prediction error test points distance delta training set 
true expected error delta delta delta delta density ffi 
reasonable conditions delta approaches exponential density delta ne gamman delta delta see appendix efron 
important fact just way saying err error rate test points zero distance away gaussian classes dimensions problem 
circles represent neighborhoods probability content delta training point 
dotted line represents ldf decision boundary 
define bootstrap analogue delta delta jffi deltag expectation choice delta delta delta delta delta delta notice ffi equal points definition give ef err delta delta delta delta density ffi ffi ffi 
bootstrap samples supported points training set argument gives delta ne delta shows delta ne gamma delta efron supposes delta delta delta fi delta value fi intercept coming 
combining approximations gives fi fi delta curves experiment left right linearity assumption delta fi delta reasonably accurate ldf rule nn 
histogram distance ffi supports exponential approximation 
substituting err err results err 
shows delta experiments estimated data set simulations 
linearity assumption fi delta reasonably accurate ldf rule experiment nearest neighbor rule 
expected apparent error equals nearest neighbors producing sharp bend near delta curve 
rule section replaces linearity exponential curve better able match form delta seen 
assume delta fl gamma gamma ff fi delta ff fi positive parameters fl upper asymptote delta delta gets large 
formulas taken literally produce simple expressions fi fi combined fl gamma gammaff gives gamma gamma gamma fl gamma err obtained substituting err err fl fl 
reasonable plausibility argument rule 
assumption delta delta particularly vulnerable criticism example shown efron quite accurate 
theoretically defensible approach bias correction err anova decomposition arguments see appendix 
studies show leave cross validation reasonably unbiased suffer high variability problems 
fold cross validation exhibits lower variance higher bias error rate curve sloping training set size 
similarly leave bootstrap low variance noticeable bias 
new estimator best performer combining low variance moderate bias 
feel bias major problem err simulation studies attempts correct bias expensive terms added variability 
time possible research succeed producing better compromise cross validation reduced variance leave bootstrap 
ronny kohavi interest problem jerry friedman trevor hastie richard olshen enjoyable fruitful discussions editor referee helpful comments 
second author supported natural sciences engineering research council canada 
appendix asymptotic analysis error rate estimators define gamma gamma delta delta delta delta delta delta usually positive 
formal anova decompositions section efron give gamma ef err cv ef err letting denote nonparametric mle eq ef err gamma combine obtain bias corrected version err err cv bias order err err gamma err err terms bootstrap covariances notation turns err err cov cov gamma delta formula says bias correct apparent error rate err adding times average covariance absence presence incorrectly predicts covariances usually positive 
despite attractions err efron appears table 
experiments 
generally speaking gains half rms advantage err cv enjoyed err bias correction powers fail cases experiment formal expansions misleading 
estimator called tables defined err err gamma cov efron standing bootstrap optimism 
cov gamma section shows rule err cv err bias order keep badly biased downward sampling experiments particularly nn rules 
tried bias correct err second level bootstrapping 
training set second level bootstrap samples drawn resampling time original bootstrap samples 
number distinct original points appearing second level bootstrap sample approximately delta compared delta level sample 
err sec err statistic computed second level samples 
rules called bc bc tables linear combinations err err sec err bc delta err gamma err sec err bc err gamma err sec suggested usual formulas bootstrap bias correction 
second linearly err sec err estimate bias correction works reasonably tables substantial price variability 
breiman 

bagging predictors 
technical report university california berkeley 
breiman spector 

submodel selection evaluation regression random case international statistical review 
breiman friedman olshen stone 

classification regression trees 
wadsworth pacific grove california 
murthy 

application bootstrap resampling methods evaluation classifier performance pattern recognition letters 
murthy 

correction note application bootstrap methods evaluation classifier performance 
pattern recognition letters 
olshen gray 

training sequence size vector quantizer performance th asilomar conference signals systems computers nov ray chen iee computer society press los alamitos ca pp 

dawid 

efficient bootstrap simulations biometrika 
efron 

bootstrap methods look jackknife annals statistics 
efron 
estimating error rate prediction rule improvements cross validation journal statistical association 
efron 

jackknife bootstrap standard errors influence functions discussion royal statist 
society 
efron tibshirani 

bootstrap 
chapman hall 
efron tibshirani 

cross validation bootstrap estimating error rate prediction rule 
technical report dept statistics stanford univ friedman 

flexible metric nearest neighbour classification 
technical report stanford university 


predictive sample reuse method applications journal american statistical association 
jain dubes chen 

bootstrap techniques error estimation ieee trans 
pattern analysis mach 
intell 

kohavi 

study cross validation bootstrap accuracy assessment model selection technical report stanford university 
mallows 

comments cp technometrics 
mclachlan 

discriminant analysis statistical pattern recognition 
wiley new york 
stone 

cross choice assessment statistical predictions journal royal statistical society 
wahba 

spline bases regularization generalized cross validation solving approximation problems large noisy data proceedings international conference approximation theory honour george lorenz academic press austin texas 
table results nn classifier ind ind exp sd rms exp sd rms exp sd rms exp sd rms err cv cv cv fr bc bc table results problem ldf nearest neighbor trees qda exp sd rms exp sd rms exp sd rms exp sd rms err cv cv cv bc bc table ldf ind problems ind exp sd rms exp sd rms exp sd rms err cv cv cv fr bc bc table results real data examples veh ldf veh nn breast lda breast nn soybean nn exp sd rms exp sd rms exp sd rms exp sd rms exp sd rms err cv cv cv 
