chameleon hierarchical clustering algorithm dynamic modeling george karypis hong sam han vipin kumar department computer science engineering university minnesota eecs bldg union st se minneapolis mn usa technical report appear ieee computer special issue data analysis mining karypis han kumar cs umn edu clustering data mining discovery process groups set data intracluster similarity maximized intercluster similarity minimized 
existing clustering algorithms means pam clarans dbscan cure rock designed find clusters fit static models 
algorithms breakdown choice parameters static model incorrect respect data set clustered model adequate capture characteristics clusters 
furthermore algorithms breakdown data consists clusters diverse shapes densities sizes 
novel hierarchical clustering algorithm called chameleon measures similarity clusters dynamic model 
clustering process clusters merged inter connectivity closeness proximity clusters high relative internal inter connectivity clusters closeness items clusters 
merging process dynamic model facilitates discovery natural homogeneous clusters 
methodology dynamic modeling clusters chameleon applicable types data long similarity matrix constructed 
demonstrate effectiveness chameleon number data sets contain points space contain clusters different shapes densities sizes noise artifacts 
experimental results data sets show chameleon discover natural clusters existing state art clustering algorithms fail find 
keywords clustering data mining dynamic modeling graph partitioning nearest neighbor graph 
clustering data mining sad chy discovery process groups set data intracluster similarity maximized intercluster similarity minimized jd kr pas chy 
discovered clusters explain characteristics underlying data distribution serve foundation data mining analysis techniques 
applications clustering include characterization different customer groups purchasing patterns categorization documents world wide web grouping genes proteins similar functionality hhs nrs scc grouping spatial locations prone earth data br existing clustering algorithms means jd pam kr clarans nh dbscan cure grs rock grs designed find clusters fit static models 
example means pam clarans assume clusters hyper ellipsoidal globular similar sizes 
dbscan assumes points genuine clusters density reachable points different clusters 
agglomerative hierarchical clustering algorithms cure rock static model determine similar cluster merge hierarchical clustering 
cure measures similarity clusters similarity closest pair representative points belonging different clusters considering internal closeness density homogeneity clusters involved 
rock measures similarity clusters comparing aggregate inter connectivity clusters user specified static inter connectivity model ignores potential variations inter connectivity different clusters data set 
algorithms breakdown choice parameters static model incorrect respect data set clustered model adequate capture characteristics clusters 
furthermore algorithms breakdown data consists clusters diverse shapes densities sizes 
novel hierarchical clustering algorithm called chameleon measures similarity clusters dynamic model 
clustering process clusters merged inter connectivity closeness proximity clusters comparable internal inter connectivity clusters closeness items clusters 
merging process dynamic model facilitates discovery natural homogeneous clusters 
methodology dynamic modeling clusters chameleon applicable types data long similarity matrix constructed 
demonstrate effectiveness chameleon number data sets contain points space contain clusters different shapes densities sizes noise artifacts 
rest organized follows 
section gives overview related clustering algorithms 
section presents limitations proposed state art clustering algorithms 
new clustering algorithm section 
section gives experimental results 
section contains directions 
related section give brief description existing clustering algorithms 
point density reachable point connected chain points point minimal number data points including point chain fixed radius 
partitional techniques partitional clustering attempts break data set clusters partition optimizes criterion jd kr nh cs 
centroid approaches typified means jd isodata bh try assign points clusters mean square distance points centroid assigned cluster minimized 
centroid techniques suitable data metric spaces euclidean space possible compute centroid set points 
medoid methods typified pam partitioning medoids kr clarans nh similarity data data arbitrary similarity space grg 
techniques try find representative points medoids minimize sum distances points closest medoid 
major drawback schemes fail data points cluster closer center cluster center cluster 
happen natural clusters grs example large variation cluster sizes cluster shapes convex 
clusters widely sizes clusters convex shapes data sets centroid medoid approaches fail 
hierarchical techniques hierarchical clustering algorithms produce nested sequence clusters single inclusive cluster top single point clusters bottom 
agglomerative hierarchical algorithms jd start data points separate cluster 
step algorithm involves merging clusters similar 
merge total number clusters decreases 
steps repeated desired number clusters obtained distance closest clusters certain threshold distance 
different variations agglomerative hierarchical algorithms jd 
algorithms primarily differ update similarity existing clusters merged clusters 
methods jd cluster represented centroid medoid points contained cluster similarity clusters measured similarity centroids medoids clusters 
partitional techniques means medoids method fail clusters arbitrary shapes different sizes 
single link method jd cluster represented data points cluster 
similarity clusters measured similarity closest pair data points belonging different clusters 
centroid medoid methods method find clusters arbitrary shape different sizes 
method highly susceptible noise outliers artifacts 
cure grs proposed remedy drawbacks methods combining advantages 
cure single centroid represent cluster constant number representative points chosen represent cluster 
similarity clusters measured similarity closest pair representative points belonging different clusters 
new representative points merged clusters determined selecting constant number scattered points data points shrinking centroid cluster shrinking factor 
centroid medoid methods cure capable finding clusters arbitrary shapes sizes represents cluster multiple representative points 
shrinking representative points centroid helps cure avoiding problem noise outliers single link method 
desirable value shrinking factor cure dependent cluster shapes sizes amount noise data 
agglomerative hierarchical algorithms similarity clusters captured aggregate similarities interconnectivity pairs items belonging different clusters 
rationale approach subclusters belonging cluster tend high interconnectivity 
aggregate inter connectivity clusters depends size clusters involved general pairs larger clusters higher inter connectivity 
schemes normalize aggregate similarity pair clusters respect expected inter connectivity clusters involved 
example widely group average method jd assumes fully connected clusters scales aggregate similarity clusters size clusters respectively 
rock grs developed agglomerative algorithm operates derived similarity graph scales aggregate inter connectivity respect user specified inter connectivity model 
algorithms discussed implicitly explicitly nn similarity matrix element matrix represents similarity data items 
algorithms derive new similarity matrix original matrix jp gk jd grs apply existing techniques derived similarity matrix 
cases new derived similarity matrix just version original similarity matrix certain entries value threshold deleted 
cases derived similarity matrix entirely different values jp gk grs 
derived matrix help eliminate reduce noise data substantially reduce execution time algorithms 
cases provide better model similarities problem domain 
example mutual shared method jp helps remove noise outliers shown provide better model capture similarities transactions grs 
sparse similarity matrix represented sparse graph tightly connected clusters graph divisive hierarchical clustering algorithms minimal spanning tree mst jd graph partitioning algorithms kk kk 
mst algorithms highly susceptible noise artifacts just single link method 
graph partitioning methods robust tend break genuine clusters large variations cluster sizes 
limitations existing hierarchical schemes major limitation existing agglomerative hierarchical schemes group averaging method jd rock grs cure grs merging decisions static modeling clusters merged 
words schemes fail take account special characteristics individual clusters incorrect merging decisions underlying data follow assumed model noise 
example consider sub clusters points shown 
selection mechanism cure single link method prefer merging clusters merging clusters minimum distances representative points smaller clusters 
clusters better candidates merging minimum distances boundary points order average minimum distances points clusters points 
merging lead homogeneous natural cluster merging 
example clusters merging choices 
agglomerative schemes group averaging jd related schemes rock connectivity pairs clusters scaled respect expected connectivity clusters 
key limitation schemes assume static user supplied inter connectivity model inflexible easily lead wrong merging decisions model estimates inter connectivity data set different clusters exhibit different inter connectivity characteristics 
schemes allow connectivity different different problem domains rock grs clusters irrespective densities shapes 
consider pairs clusters shown cluster depicted sparse graph nodes indicate data items edges represent vertices similar 
number items clusters 
assume example edges equal weight represent equal similarity 
rock selection mechanism irrespective assumed model connectivity group averaging method select pair merging pair better choice 
example clusters merging choices 
selection mechanism cure related algorithms single link method jd considers minimum distance representative points clusters consider aggregate interconnectivity clusters 
similarly selection mechanism algorithms rock considers aggregate inter connectivity pairs clusters appropriately scaled expected value interconnectivity ignores value strongest edge edges clusters 
looking characteristics algorithm easily select merge wrong pair clusters 
instance example illustrates algorithm focuses closeness clusters incorrectly prefer merge clusters clusters 
similarly example illustrates algorithm focuses inter connectivity clusters incorrectly prefer merge cluster cluster 
assume aggregate interconnectivity items clusters greater items clusters 
border points cluster closer 
example clusters merging choices 
example clusters merging choices 
summary major limitations agglomerative mechanisms existing schemes 
schemes information nature individual clusters merged 
second set schemes cure related schemes ignore information aggregate interconnectivity items clusters set schemes rock group averaging method related schemes ignore information closeness clusters defined similarity closest items clusters 
section novel scheme addresses limitations 
chameleon clustering dynamic modeling overview section chameleon new clustering algorithm overcomes limitations existing agglomerative hierarchical clustering algorithms discussed section 
provides overview approach chameleon find clusters data set 
chameleon operates sparse graph nodes represent data items weighted edges represent similarities data items 
sparse graph representation data set allows chameleon scale large data sets operate successfully data sets available similarity space grg metric spaces grg 
chameleon finds clusters data set phase algorithm 
phase chameleon uses graph partitioning algorithm cluster data items large number relatively small sub clusters 
second phase uses agglomerative hierarchical clustering algorithm find genuine clusters repeatedly combining sub clusters 
data set nearest neighbor graph final clusters sparse graph construct merge partitions partition graph framework chameleon 
key feature chameleon agglomerative hierarchical clustering algorithm determines pair similar sub clusters account inter connectivity closeness clusters overcomes limitations discussed section result 
furthermore chameleon uses novel approach model degree inter connectivity closeness pair clusters takes account internal characteristics clusters 
depend static user supplied model automatically adapt internal characteristics clusters merged 
rest section provide details model data set dynamically model similarity clusters computing relative inter connectivity relative closeness graph partitioning obtain initial fine grain clustering solution relative inter connectivity relative closeness repeatedly combine sub clusters hierarchical fashion 
modeling data similarity matrix methods find graph representation jp gk jd grs 
fact modeling data items graph common hierarchical clustering algorithms 
example agglomerative hierarchical clustering algorithms single link complete link group averaging method jd operate complete graph 
rock grs constructs sparse graph data similarity matrix similarity threshold concept shared neighbors performs hierarchical clustering algorithm sparse graph 
cure grs implicitly employs concept graph 
cure cluster representative points determined graph containing representative points implicitly constructed 
graph edges connect representative points different clusters 
closest edge graph identified clusters connected edge merged 
chameleon sparse graph representation data items commonly nearest neighbor graph approach 
vertex nearest neighbor graph represents data item exists edge vertices data items corresponding nodes similar data points data point corresponding node 
illustrates nearest neighbor graphs simple data set 
note chameleon operates sparse graph cluster sub graph original sparse graph representation data set 
advantages representing data nearest neighbor graph firstly data points far apart completely disconnected secondly captures concept neighborhood dynamically 
neighborhood radius data point determined density region data point resides 
dense region neighborhood defined narrowly sparse region neighborhood defined widely 
compared model defined dbscan global neighborhood density specified captures natural neighborhood 
thirdly density region recorded weights edges 
edge weights dense regions edge weights representing similarities tend large edge weights original data nearest neighbor graph nearest neighbor graph nearest neighbor graph nearest graphs original data 
sparse regions tend small 
consequence min cut bisection graph represents interface layer sparse region graph 
provides computational advantage full graph algorithms operating graphs including graph partitioning partitioning refinement algorithms 
modeling cluster similarity address limitations agglomerative schemes discussed section chameleon determines similarity pair clusters looking relative inter connectivity relative closeness rc 
chameleon hierarchical clustering algorithm selects merge pair clusters rc high selects merge clusters inter connected close respect internal inter connectivity closeness clusters 
selecting clusters criteria chameleon overcomes limitations existing algorithms look absolute inter connectivity absolute closeness 
instance examples shown figures discussed section chameleon select merge correct pair clusters 
remaining section describe relative inter connectivity relative closeness computed pair clusters 
relative inter connectivity relative inter connectivity pair clusters defined absolute inter connectivity normalized respect internal inter connectivity clusters absolute inter connectivity pair clusters defined sum weight edges connect vertices vertices essentially edge cut cluster containing cluster broken denote ec internal inter connectivity cluster easily captured size min cut bisector ecc weighted sum edges partition graph roughly equal parts 
advances graph partitioning technology possible find bisector quite efficiently kk kk 
relative inter connectivity pair clusters ec ec ec normalizes absolute inter connectivity average internal inter connectivity clusters 
focusing relative inter connectivity clusters chameleon overcome limitations existing algorithms static inter connectivity models 
instance example shown discussed section chameleon correctly prefer merge clusters clusters relative inter connectivity clusters higher relative inter connectivity clusters pair clusters higher absolute inter connectivity 
relative inter connectivity able take account differences shapes clusters differences degree connectivity different clusters 
relative closeness relative closeness pair clusters defined absolute closeness normalized respect internal closeness clusters absolute closeness pair clusters captured number different ways 
existing schemes capture closeness focusing pair points points representative points grs closest 
key drawback schemes relying single pair points tolerant outliers noise 
reason chameleon measures closeness clusters computing average similarity points connected points connections determined nearest neighbor graph average strength provides measure affinity data items interface layer sub clusters time tolerant outliers noise 
note average similarity points clusters equal average weight edges connecting vertices vertices internal closeness cluster measured number different ways 
possible approach look edges connecting vertices edges internal cluster compute internal closeness cluster average weight edges 
argue hierarchical clustering setting edges agglomeration early stronger stages 
average weights edges internal bisection tend smaller average weight edges clusters 
average weight edges better indicator internal closeness clusters 
chameleon relative closeness pair clusters computed rc ec ec ec ec ec average weights edges belong min cut bisector clusters respectively ec average weight edges connect vertices vertices note weighted average internal closeness clusters normalize absolute closeness clusters favors absolute closeness cluster contains larger number vertices 
focusing relative closeness clusters chameleon overcome limitations existing algorithms look absolute closeness 
instance example shown discussed section chameleon correctly prefer merge clusters clusters 
relative closeness clusters higher relative closeness clusters pair clusters higher absolute closeness 
looking relative closeness chameleon correctly prefers merge clusters resulting cluster exhibits uniformity degree closeness items cluster 
note relative closeness clusters general smaller edges connect vertices different clusters smaller weight 
chameleon phase clustering algorithm dynamic framework modeling similarity clusters discussed section applied cluster contains sufficiently large number vertices data items 
order compute relative inter connectivity relative closeness clusters chameleon needs compute internal interconnectivity closeness cluster 
accurately calculated clusters containing data points 
reason chameleon uses algorithm consists distinct phases 
purpose phase cluster data items large number sub clusters contain sufficient number items allow dynamic modeling 
purpose second phase discover genuine clusters data set dynamic modeling framework merge sub clusters hierarchical fashion 
remainder section algorithms phases chameleon 
phase finding initial sub clusters chameleon finds initial sub clusters graph partitioning algorithm partition nearest neighbor graph data set large number partitions sum weight edges straddle partitions minimized 
edge nearest neighbor graph represents similarity data points partitioning minimizes edge cut effectively minimizes relationship affinity data points resulting partitions 
underlying assumption links clusters stronger plentiful links clusters 
data partition highly related data items partition 
research graph partitioning lead development fast accurate algorithms multilevel paradigm kk kk 
extensive experiments graphs arising application domains shown multilevel graph partitioning algorithms effective capturing global structure graph capable computing partitionings small edge cut 
partition nearest neighbor graph effective finding natural separation boundaries clusters 
example shows clusters produced applying multilevel graph partitioning algorithm nearest neighbor graphs spatial data sets 
see partitioning algorithm effective finding low density separating region example small connecting region second example 
example bisections produced multilevel graph partitioning algorithms spatial data sets 
partitioning algorithm cuts sparse region 
partitioning algorithms cuts small connecting region 
chameleon utilizes multilevel graph partitioning algorithms find initial sub clusters 
particular uses graph partitioning algorithm part hmetis library kk 
hmetis shown kk kk alp quickly produce high quality partitionings wide range unstructured graphs hypergraphs 
chameleon primarily hmetis split cluster sub clusters edge cut minimized sub clusters contains nodes note requirement referred balance constraint integral part graph partitioning approach find sub clusters 
hmetis effective operating allowed balance constraints find bisection minimizes edge cut 
balance constraint force hmetis break natural cluster 
chameleon obtains initial set sub clusters follows 
initially starts points belonging cluster 
repeatedly selects largest sub cluster current set sub clusters uses hmetis bisect 
process terminates larger sub cluster contains fewer specified number vertices refer minsize 
minsize parameter essentially controls granularity initial clustering solution 
general minsize set value smaller size clusters expect find data set 
time minsize sufficiently large sub clusters contain sufficiently large number nodes allow evaluate inter connectivity closeness items sub cluster meaningful fashion 
data sets encountered setting minsize number data points worked fairly 
phase ii merging sub clusters dynamic framework soon fine grain clustering solution produced partitioning algorithm phase chameleon switches agglomerative hierarchical clustering combines small sub clusters 
discussed section key step agglomerative hierarchical algorithm finding pair sub clusters similar 
chameleon agglomerative hierarchical clustering algorithm utilizes dynamic modeling framework discussed section select similar pairs clusters looking relative inter connectivity relative closeness 
ways develop agglomerative hierarchical clustering algorithm takes account measures 
different schemes implemented chameleon 
scheme merges pairs clusters relative inter connectivity relative closeness user specified threshold rc respectively 
approach chameleon visits cluster checks see adjacent clusters satisfy conditions rc rc 
adjacent clusters satisfy conditions chameleon selects merge cluster connected selects cluster absolute inter connectivity clusters highest 
cluster opportunity merge adjacent clusters combinations selected performed entire process repeated 
note algorithm different traditional hierarchical clustering algorithms allows multiple pairs clusters merged iteration 
parameters rc control characteristics desired clusters 
particular parameter allows control variability degree inter connectivity items cluster 
parameter rc allows control uniformity similarity items belong particular cluster 
depending choice rc parameters chameleon merging algorithm may reach point proceed adjacent clusters satisfy conditions equation 
point choice terminating algorithm output current clustering solution try merge additional pairs clusters successively relaxing parameters possibly different rates 
second scheme implemented chameleon uses function combine relative inter connectivity relative closeness selects merge pair clusters maximizes function 
goal merge pairs relative inter connectivity relative closeness high natural way defining function take product 
select pair clusters merge maximize rc 
formula gives equal importance parameters 
quite may prefer clusters give higher preference measures 
reason chameleon selects pair clusters maximizes rc user specified parameter 
chameleon gives higher importance relative closeness gives higher importance relative inter connectivity 
experimental results section second approach allows easily generate entire dendrogram hierarchical clustering 
performance analysis computational complexity chameleon depends amount time requires construct nearest neighbor graph amount time requires perform phases clustering algorithm 
amount time required compute nearest neighbor graph depends dimensionality underlying data set 
particular low dimensional data sets algorithms trees sam quickly compute nearest neighbors 
shown items average cost inserting expected nearest neighbor search time log leading complexity log 
high dimensional data sets schemes trees applicable bbk 
data sets amount time required find nearest neighbors data item leading complexity 
amount time required chameleon phase clustering algorithm depends number initial sub clusters produced graph partitioning algorithm phase 
simplify analysis assume initial sub cluster number nodes ii successive merging step chameleon selects merge single pair clusters 
analysis focused chameleon second scheme combining relative inter connectivity relative closeness described section 
complexity similar scheme 
amount time required phase chameleon depends amount time required hmetis 
graph hmetis requires kk kk time compute bisection 
chameleon operates nearest neighbor graph computational complexity hmetis 
chameleon phase algorithm obtains clusters repeatedly partitioning successively smaller graphs computational complexity log bounded log 
note potentially faster partitioning algorithm obtain initial clusters time log multilevel way partitioning algorithm described kk 
amount time required second phase depends amount time needed compute internal inter connectivity internal closeness initial intermediate cluster amount time needed select similar pair clusters merge 
internal inter connectivity internal closeness particular cluster computed bisecting corresponding nearest neighbor sub graph cluster complexity proportional number items cluster 
particular amount time required bisect initial clusters leading complexity 
merging steps chameleon needs bisect resulting cluster total steps initial sub clusters merged 
worst case complexity obtained merging algorithm repeatedly selects cluster merges grows single large cluster 
corresponds worst case merging step algorithm needs bisect cluster largest possible number data items 
case amount time required bisect intermediate sub clusters nm 
amount time required find similar pair clusters log heap priority queue 
worst case initial clustering solution cluster connected remaining clusters 
case takes log time insert similarity possible pairs sub clusters priority queue 
merging step pair residing top priority queue selected similarity combined cluster remaining sub clusters updated 
update operations requires log time leading complexity log total updates needs performed pair clusters gets merged 
complexity chameleon phase clustering algorithm nm log log 
experimental results section experimental evaluation chameleon compare performance publicly available version dbscan locally implemented version cure 
chameleon applicable data set similarity matrix available constructed chose perform evaluation data sets containing points dimensional space reasons 
similar data sets evaluate performance state art algorithms dbscan cure 
second clusters data sets easy visualize making comparison different schemes easier 
report results rock grs interconnectivity agglomerative schemes group averaging method jd tend perform worse algorithms cure metric space data sets 
results available url www cs umn edu han chameleon html 
data sets experimented different data sets containing points dimensions geometric shape shown 
data set ds clusters different size shape density contains noise points special artifacts 
second data set ds contains clusters close different regions clusters different densities 
third data set ds clusters different size shape orientation random noise points special artifacts running clusters 
fourth data set ds clusters different shape size orientation inside space enclosed clusters 
ds contains random noise special artifacts collection points forming vertical 
fifth data set ds clusters different shape size density orientation random noise 
particularly challenging feature data set clusters close different densities 
size data sets ranges points exact size indicated 
note ds obtained grs synthetically generated remaining data sets 
ds points ds points ds points ds points ds points data sets experiments 
qualitative comparison chameleon cluster data set chameleon need specify parameters value computing nearest neighbor graph value minsize phase algorithm choice scheme combining relative inter connectivity relative closeness associated parameters 
experiments section set parameter values data sets 
particular minsize total items data set second scheme combining ri rc equation combining relative inter connectivity relative closeness pair clusters 
performed parameter study determine sensitivity chameleon set parameters minsize 
results shown show chameleon sensitive choice parameters able discover correct clusters combinations values minsize 
shows clusters chameleon data sets 
points different clusters represented combination different colors different glyphs 
result points belong cluster color points drawn glyph 
example clustering solution shown ds clusters cyan color contains points region circles inside ellipse contains points form line horizontal bars shaped cluster clusters dark blue color corresponds upside shaped cluster corresponds circle inside candy cane points represented different glyphs bells squares pair squares bells second pair denote different clusters 
chameleon hierarchical nature creates dendrogram possible clustering solutions different levels granularity 
clustering solutions shown correspond earliest point agglomerative process chameleon able find genuine clusters data set 
correspond lowest level dendrogram genuine clusters data set identified placed cluster 
result number clusters shown data sets larger number genuine clusters additional clusters contain points outliers 
looking see chameleon able correctly identify genuine clusters data sets 
case ds chameleon finds clusters correspond genuine clusters data set sixth shown brown colored glyphs corresponds outlier points connecting ellipsoid clusters 
case ds chameleon finds clusters corresponding genuine cluster data set 
case ds chameleon finds eleven clusters correspond genuine clusters data set rest contain outliers 
case ds chameleon finds eleven clusters correspond genuine clusters rest contain outlier points 
case ds chameleon finds clusters corresponding genuine cluster data set 
experiment illustrate chameleon effective finding clusters arbitrary shape density orientation tolerant outlier points artifacts running clusters 
cure evaluated performance chameleon cure described section shown effective finding clusters dimensional point data sets grs 
cure able find right clusters ds ds failed find right clusters remaining data sets 
shows results obtained cure ds ds ds data sets 
cure hierarchical clustering algorithm produces dendrogram possible clustering solutions different levels granularity 
data sets shows different clustering solutions containing different number clusters 
clustering solution column corresponds earliest point agglomerative process cure merges sub clusters belong different genuine clusters 
see case ds cure selects wrong pair clusters merge going clusters resulting red colored sub cluster contains portions shaped clusters 
similarly case ds cure mistake going clusters selects merge circles inside ellipse portion ellipse 
case ds cure mistake going clusters merging small circular cluster portion upside shaped cluster 
second clustering solution corresponds solutions contain clusters discovered chameleon 
solutions considerably worse set solutions especially ds ds indicating merging scheme cure performs multiple mistakes 
results shown experiments shrinking factor number representative points default values recommended grs 
performed experiments shrinking factor varying number representative points varying 
experiments showed similar trends shown 
furthermore facilitate fair comparisons removed noise suggested grs identifying slowly growing clusters noise point removed 
comparison purposes reassigned noisy data points back final clusters assignment method discussed grs noise points assigned cluster closest representative points 
note assignments affect clustering results 
dbscan dbscan known spatial clustering algorithm shown find clusters arbitrary shapes 
dbscan defines cluster maximum set density connected points 
core point cluster minimum number points minpts radius eps 
dbscan find arbitrary shape clusters right density clusters determined priori density clusters uniform 
dbscan finds right clusters data sets ds ds long supplied right combination eps minpts 
minpts fixed default value specified algorithm works fine long eps range ds ds 
fails perform ds ds ds data sets contain clusters different densities 
shows clusters dbscan ds ds different values eps parameter 
recommendation minpts fixed eps changed experiments 
clusters produced ds illustrate dbscan effectively find clusters different density 
clustering solution eps dbscan puts ellipses cluster outlier points connecting satisfy density requirements dictated eps minpts parameters 
clusters separated decreasing value eps done clustering solution shown eps 
dbscan keeps ellipses fragmented lower density cluster large number small sub clusters 
experiments shown dbscan exhibits similar characteristics ds 
clusters produced ds illustrate dbscan effectively find clusters internal density varies 
sequence clustering solutions decreasing values eps parameter illustrates decrease eps hope separating clusters natural clusters data set fragmented large number smaller clusters 
ds ds dbscan managed find genuine clusters right parameter values 
shows sensitivity dbscan respect eps parameter 
concluding remarks novel hierarchical clustering algorithm called chameleon takes account dynamic model clusters 
chameleon discover natural clusters different shapes sizes merging decision dynamically adapts different clustering model characterized clusters consideration 
experimental results data sets varying characteristics show chameleon discover natural clusters existing clustering algorithms fail find 
data sets space partly similar data sets extensively authors nh grs partly easy evaluate quality clustering data sets 
note schemes grs specifically suited spatial data data metric spaces 
noteworthy scheme outperforms metric space spatial nature data 
methodology dynamic modeling clusters agglomerative hierarchical methods applicable types data long similarity matrix available constructed 
chose model data nearest neighbor graph entirely possible graph representations suitable particular application domains mutual shared neighbors gk jd grs 
furthermore different domains may require different models capturing relative closeness inter connectivity pairs clusters 
situations believe twophase framework chameleon highly effective 
research includes verification chameleon different application domains study effectiveness different techniques modeling data cluster similarity 
ignored issue scaling large data sets fit main memory 
issues orthogonal ones discussed covered bfr grs grg 
ester kriegel sander xu providing dbscan program 
alp alpert 
circuit benchmark suite 
proc 
intl 
symposium physical design pages 
bbk berchtold bohm 
kriegel 
pyramid technique breaking curse dimensionality 
proc 
acm sigmod int 
conf 
management data 
berchtold bohm keim 
kriegel 
cost model nearest neighbor search highdimensional data space 
proc 
symposium principles database systems tucson arizona 
bfr bradley fayyad reina 
scaling clustering algorithms large databases 
proc 
fourth int conference knowledge discovery data mining 
boley gini gross han hastings karypis kumar mobasher moore 
document categorization query generation world wide web webace 
ai review accepted publication 
boley gini gross han hastings karypis kumar mobasher moore 
partitioning clustering web document categorization 
decision support systems accepted publication 
bh ball hall 
fundamental concepts procedures pattern recognition preprocessors 
international conference circuit theory information theory 
br simon byers adrian raftery 
nearest neighbor clutter removal estimating features spatial point processes 
american statistical association june 
chy chen han yu 
data mining overview database perspective 
ieee transactions knowledge data eng december 
cs cheeseman stutz 
baysian classification autoclass theory results 
fayyad piatetsky shapiro smith uthurusamy editors advances knowledge discovery data mining pages 
aaai mit press 
ester 
kriegel sander xu 
density algorithm discovering clusters large spatial databases noise 
proc 
second int conference knowledge discovery data mining portland 
friedman bentley finkel 
algorithm finding best matches logarithmic expected time 
acm transactions mathematical software 
gk krishna 
agglomerative clustering concept mutual nearest neighborhood 
pattern recognition 
grg ganti ramakrishnan gehrke powell french 
clustering large datasets arbitrary metric spaces 
proc 
th int conf 
data eng 
grs sudipto guha rajeev rastogi kyuseok shim 
cure efficient clustering algorithm large databases 
proc 
acm sigmod int 
conf 
management data 
grs sudipto guha rajeev rastogi kyuseok shim 
rock robust clustering algorithm categorical attributes 
proc 
th int conf 
data eng 
hhs harris hunter states 
mega classification discovering motifs massive 
proceedings tenth international conference artificial intelligence aaai 
han karypis kumar mobasher 
clustering association rule hypergraphs 
technical report tr department computer science university minnesota minneapolis 
han karypis kumar mobasher 
hypergraph clustering high dimensional data sets summary results 
bulletin technical committee data engineering 
jd jain dubes 
algorithms clustering data 
prentice hall 
jp jarvis patrick 
clustering similarity measure shared nearest neighbors 
ieee transactions computers november 
kk karypis kumar 
hmetis hypergraph partitioning package 
technical report department computer science university minnesota 
available www url www cs umn edu metis 
kk karypis kumar 
metis unstructured graph partitioning sparse matrix ordering system 
technical report department computer science university minnesota 
available www url www cs umn edu metis 
kk karypis kumar 
multilevel way partitioning scheme irregular graphs 
journal parallel distributed computing 
available www url www cs umn edu karypis 
kk karypis kumar 
fast highly quality multilevel scheme partitioning irregular graphs 
siam journal scientific computing 
available www url www cs umn edu karypis 
short version appears intl 
conf 
parallel processing 
kk karypis kumar 
multilevel way hypergraph partitioning 
proceedings design automation conference 
kr kaufman rousseeuw 
finding groups data cluster analysis 
john wiley sons 
nh ng han 
efficient effective clustering method spatial data mining 
proc 
th vldb conference pages santiago chile 
nrs newman chi 
arabidopsis expressed sequence tags generation analysis dissemination 
plant genome iii international conference status plant genome research san diego ca 
pas hubert arabie de 
clustering classification 
world scientific 
sad stonebraker agrawal dayal neuhold reuter 
dbms research crossroads vienna update 
proc 
th vldb conference pages dublin ireland 
sam samet 
design analysis spatial data structures 
addison wesley 
scc chi riedl dalton newman 
implementation testing automated est processing analysis system 
lawrence hunter bruce shriver editors proceedings th annual hawaii international conference system sciences volume pages 
ieee computer society press 
xu ester 
kriegel sander 
distribution clustering algorithm mining large spatial databases 
proc 
th int conf 
data eng 
zhang ramakrishnan 
birch efficient data clustering method large databases 
proc 
acm sigmod int 
conf 
management data montreal quebec 
ds ds ds ds ds clusters discovered chameleon data sets 
ds clusters ds clusters ds clusters ds clusters ds clusters ds clusters clusters cure shrinking factor number representative points 
ds eps minpts ds eps minpts ds eps minpts ds eps minpts ds eps minpts ds eps minpts ds eps minpts ds eps minpts dbscan ds ds ds data sets different values eps parameter 

