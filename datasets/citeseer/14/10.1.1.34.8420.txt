overdetermined blind source separation sensors source signals noisy mixture marcel heinz mathis russell lambert signal information processing laboratory swiss federal institute technology zurich switzerland pivotal technologies lake ave suite pasadena ca usa isi ee ethz ch mathis isi ee ethz ch russ com independent component analysis blind signal separation ica june helsinki finland pp 
addresses blind source separation problem case sensors source signals available 
noisy sensor model assumed 
proposed algorithm comprises stages stage consists principal component analysis pca second independent component analysis ica 
purpose pca stage increase input snr succeeding ica stage reduce sensor dimensionality 
ica stage separate remaining mixture independent components 
simulation example demonstrates performance algorithm proposed 


problem description blind source separation bss problem posed applications related acoustics communications 
usually bss problem analyzed case just sensors source signals 
furthermore ideal sensors usually assumed additive sensor noise 
little done analysis algorithms case noisy sensors 
usually hopes sensor noise low influence performance bss algorithm considerably 
concentrates case low snr sensors shows possible way enhance performance separation sensors source signals 
situation referred overdetermined blind source separation problem bases problem 
overdetermined sense sources interest observations necessary reconstruction original signals available 
referring linear algebra system finding separation matrix mixing matrix term underdetermined unknowns equations 
divide task hand stages 
starting input sensors stage performs singular value decomposition producing virtual sensors contain noisy mixture source signals higher snr true sensors 
remaining gamma virtual sensors contain mixture sensor noises discarded second stage 
second stage consists ordinary blind source separation algorithm theta problem 
separated sources sources sensors mixing process separation process blind source separation setup 

notation notation vectors written lower case matrices upper case 
matrix vector transpose complex conjugation hermitian transpose denoted respectively 
sample index denoted identity matrix denoted vector matrix containing zeros 
denotes expectation operator 
vector matrix dimensions superscript 
frobenius norm matrix denoted 
overdetermined blind source separation 
problem description mixing process described sm contains samples unknown source signals time xm samples sensor signals sample time samples sensor noise time thetam delta delta delta am unknown mixing matrix 
overdetermined case sensors source signals 
solving blind source separation problem means find separation matrix thetam output separation process wx ps wn retrieves waveform preserving estimates unknown source signals time series sensor signals ica pca sensors virtual sensors noise mixture separated sources sources mixing process overdetermined blind source separation setup proposed stage algorithm 
denotes total transfer matrix global system 

assumptions addition problem proposed assumptions time invariant mixing matrix full rank source signals sm mutually independent iid 
source signals sm possibly non gaussian 
source signals unknown power oe sensors source signals 
sensors noise characteristics 
sensor noise additive white gaussian noise power oe sensor noise sensors mutually independent 
source signals sensor noise mutually independent 
consequence imply rss oe im implies rnn oe im 

proposed algorithm proposed algorithm stages 
stage principal component analysis pca algorithm project sensor signals dimensional signal plus noise subspace gamma dimensional noise subspace 
second stage performs independent component analysis ica signal plus noise space obtain estimates source signals 

stage principal component analysis pca want decorrelate sensor signals 
decorrelation necessary sufficient condition independence 
transform sensor signals unitary transformation matrix phi psi diagonal matrix 
applying svd singular value decomposition sigma sigma sigma sigma sigma sigma thetam thetam unitary matrices sigma sigma sigma thetam sigma sigma sigma thetam diagonal matrices contain singular values oe sigma sigma sigma diag oe oe oe oe delta delta delta oe inequality comes assumption 
svd input correlation matrix rxx gives rxx rnn oe aa oe im oe sigma sigma sigma sigma sigma sigma oe im oe sigma sigma sigma sigma sigma sigma oe im oe sigma sigma sigma oe uu oe sigma sigma sigma oe im sigma sigma sigma xx sigma sigma sigma thetam diag oe oe sigma sigma sigma xx diag oe oe oe oe diag gamma oe oe oe oe oe oe oe oe delta 
term contains contribution source signals second contains contribution sensor noise 
choosing thetam gammam thetam gamma obtain correlation matrix rxx oe sigma sigma sigma oe im sigma sigma sigma xx 
diagonal matrix containing singular values rxx descending order oe delta delta delta oe oe delta delta delta oe oe diagonal matrix signals mutually uncorrelated necessarily independent 
furthermore signals ordered powers unitary matrix elements contain signal power source signals received sensors xm remaining gamma elements contain mixture sensor noise 
assuming knowledge number source signals partition vector principal gamma minor components gammam 
doing second stage discard elements contain components source signals 
principal components processing 
procedure corresponds principal component analysis pca 
note principal components unknown source signals 
furthermore principal components mutually uncorrelated 
generate virtual sensors true sensors 

second stage independent component analysis ica second stage ica algorithm find separation matrix estimate scaling permutation elements 
perfect separation occurs output signals mutually independent 
joint density product marginal densities um pum um independence source signals assumed psm sm 
pca stage reduced overdetermined theta bss problem theta bss problem additive sensor noise 
known bss algorithm regular theta case natural gradient learning algorithm proposed im gamma algorithm proposed im gamma gamma infomax algorithm gammah gamma blind stochastic gradient algorithm multichannel blind lms gamma nonlinear function known nonlinearity score function depends pdf source signals :10.1.1.10.7237
alternatively batch algorithm separation see instance explicitly uses higher order 

combining stages stages combined shown fig 

obtain thetam 
stage seen preprocessing step sensor signals reduces input dimension 
know rxx time invariant adapted 
computed iterative learning algorithm 
obtain total transfer matrix global system close scaled permutation matrix attain signal separation 
course available simulation environment mixing matrix unknown assumption 

minimum norm solution noiseless case underdetermined system equation wa im fulfilled infinite number possible separation matrices matrices form sigma sigma sigma gamma arbitrary theta gamma matrix 
additional constraint necessary separation matrix unique 
possibility constrain minimal possible frobenius norm 
solution referred minimum norm mn solution 
unitary invariance property frobenius norm kwk sigma sigma sigma gamma sigma sigma sigma gamma ke ek minimal minimum norm solution mn sigma sigma sigma gamma sigma sigma sigma gamma denotes moore penrose pseudoinverse see 
contained mn see proposed pca preprocessing stage part minimum norm solution 
furthermore define mn sigma sigma sigma gamma 

minimum mean squared error solution mean squared error mse cost function write cost minimize phi ks gamma psi 
setting cost derivative respect separation matrix zero arrive simplifications solving eq 
separation matrix yields minimum mean squared error mmse solution mmse rss rnn gamma inserting rss rnn respectively written mmse aa oe oe im gamma 
inserting longer calculation obtain mmse sigma sigma sigma gamma sigma sigma sigma diag oe oe oe oe oe oe oe oe 
recognize oe goes zero sigma sigma sigma converges sigma sigma sigma mmse approaches mn contained mmse clearly see proposed pca preprocessing stage part mmse solution mmse furthermore define mmse sigma sigma sigma gamma 

estimation number sources assumed know number unknown source signals involved mixing process 
unknown estimated 
input correlation matrix rxx dominant singular values gamma minor singular values value oe see number source signals involved mixing process evaluated choosing threshold just oe number active source signals changes visible analyzing distribution singular values 
alternatively information theoretic criterion estimate number source signals 

simulation give simulation example analyze behavior algorithm proposed 

performance measurement order describe performance algorithm proposed signal noise ratio snr signal interference ratio sir signal interference plus noise ratio sinr convergence rate criteria 
define performance measurements snr xm snr input sensor signal xm snr total input snr snr vm snr virtual sensor signal vm snr total snr virtual sensors snr um snr output signal um snr total output snr sir um sir output signal um sir total output sir sinr um sinr output signal um sinr total output sinr 

simulation simulation source signals qam signal 
compare behavior proposed algorithm sensors 
complex mixing matrices set theta theta theta theta theta theta random complex submatrix oe condition number oe oem logarithmically distributed singular values 
respective condition numbers theta theta theta 
update block algorithm block length step size nonlinearity gm um um simulation set oe oe db 
fig 
top shows snr xm resulting snr true sensors 
fig 
middle shows snr vm snr virtual sensors pca stage 
fig 
bottom shows snr um snr output signals convergence constellation diagram um convergence fig 

learning curves sinr sir snr shown fig 

input snr output snr sir sinr convergence table values minimum norm table snr source signals oe oe db system pca ica minimum norm mn mmse mmse snr snr snr sir sinr snr sir sinr snr sir sinr db db db db db db db db db db db db db db db db db db db db db db db db db db db db db db input sensor virtual sensor snr db output snr convergence top snr xm middle snr vm bottom snr um 
output signals um sorted snr 
solution mn mmse solution mmse defined respectively 
see sensors separation quality convergence time poor 
doubling number sensors improves situation considerably 
main difference sensors higher output snr convergence rate separation quality differ marginally 
improvement snr sensors stems fact smaller case sensors output snr improvement just db doubling number sensors 
small singular value oe results small snr vm noisy virtual sensor vm blind algorithm consideration steers output signals um equal power noisy signal vm strongly amplified causes noisy output signals 
table see minimum norm solution mn forces perfect separation sir irrespective iteration sinr sir snr iteration sinr sir snr iteration sinr sir snr convergence behavior snr sir sinr ms top middle bottom 
constellation plot convergence qam signals top middle bottom 
output signals um sorted snr 
resulting output snr 
leads poor sinr sensors caused low output snr 
conclude minimum norm solution preferred solution low snr especially communication system minimizing sinr major interest 
mmse solution mmse achieves highest sinr snr typically small difference note adaptive algorithm increase final sir achieved reducing step size furthermore fig 
table see final output sinr mainly limited output snr output sir 
sensor noise limiting factor quality output signals 

stage algorithm solve overdetermined blind source separation problem noisy sensors proposed 
preprocessing step pca divides input space noise space noise space 
signals noise space propagated subsequent ica stage 
proposed preprocessing stage implicit part minimum norm solution mmse solution 
furthermore advantage sensors source signals demonstrated simulation example show faster convergence rate higher steady state sinr achieved 

constant modulus blind source separation technique new approach int 
symp 
signal processing app gold coast australia august pp 

zhang 
amari cichocki natural gradient approach blind separation mixtures proc 
ica france jan pp 


zhang cichocki amari natural gradient algorithm blind separation overdetermined mixture additive noise ieee signal processing lett pp 
nov 

amari natural gradient learning bases ica neural computation vol 
pp 
nov 
papoulis probability random variables stochastic processes mcgraw hill rd edition 

amari cichocki yang new learning algorithm blind signal separation advances neural information processing systems vol 
pp 


cardoso laheld equivariant adaptive source separation ieee trans 
signal processing vol 
pp 
dec 
bell sejnowski information maximization approach blind separation blind deconvolution neural computation vol 
pp 

lambert blind deconvolution multipath mixtures unsupervised adaptive filtering haykin ed 
vol 
john wiley sons 

cardoso blind signal separation statistical principles proc 
ieee vol 
pp 
oct 

lee independent component analysis kluwer academic publishers 
comon independent component analysis new concept signal processing vol 
pp 
apr 
haykin adaptive filter theory prentice hall rd edition 
horn johnson matrix analysis cambridge university press 

cardoso moulines blind source separation technique second order statistics ieee trans 
signal processing vol 
pp 
feb 
wax kailath detection signals information theoretic criteria ieee trans 
acoust speech signal processing vol 
pp 
apr 
echoes noise seamless acoustic man machine interfaces challenge persists proc 
pennsylvania usa sept pp 

douglas cichocki amari bias removal technique blind source separation noisy measurements electron 
lett vol 
pp 
july 
lambert difficulty measures figures merit source separation proc 
ica france jan pp 

mathis performance comparison combined blind non blind source separation algorithms proc 
ica france jan pp 

mathis fft algorithm multichannel blind deconvolution proc 
iscas orlando fl may june pp 
iii 
comon jutten blind separation sources part ii problems statement signal processing vol 
pp 
july 

amari cichocki adaptive blind signal processing neural network proc 
ieee vol 
pp 
oct 
