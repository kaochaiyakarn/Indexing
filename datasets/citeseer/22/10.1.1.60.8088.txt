making tree kernels practical natural language learning years tree kernels proposed automatic learning natural language applications 
unfortunately show inherent super linear complexity lower accuracy traditional attribute value methods 
show tree kernels helpful processing natural language provide simple algorithm compute tree kernels linear average running time study classification properties diverse tree kernels show kernel combinations improve traditional methods 
experiments support vector machines predicate argument classification task provide empirical support thesis 
years tree kernels shown interesting approaches modeling syntactic information natural language tasks syntactic parsing collins duffy relation extraction named entity recognition roth sorensen semantic parsing 
main tree kernel advantage possibility generate high number syntactic features learning algorithm select relevant specific application 
contrast major drawback computational time complexity superlinear number tree nodes accuracy produce alessandro department computer science university rome tor rome italy info uniroma lower provided linear models manually designed features 
solve problem linear complexity algorithm subtree st kernel computation designed vishwanathan smola 
unfortunately st set poorer generated subset tree sst kernel designed collins duffy 
intuitively st rooted node target tree contains descendants leaves 
hold leaves internal nodes 
solve problem study different tree substructure spaces carried derive tree kernel provide highest accuracy 
hand provide learning algorithms richer information may critical capture syntactic properties parse trees shown example 
hand sst space contains irrelevant features overfitting may occur decrease classification accuracy roth 
consequence fewer features st approach may appropriate 
aim solve problems 
algorithm evaluation st sst kernels runs linear average time study impact diverse tree kernels accuracy support vector machines svms 
fast algorithm computes kernels syntactic parse trees average time number nodes trees 
low complexity allows svms carry experiments hundreds thousands training instances higher complexity polynomial ker nel widely large experimentation 
pradhan 
confirm hypothesis measured impact algorithm time required svms learning predicate argument examples annotated propbank kingsbury palmer instances annotated framenet fillmore 
regarding classification properties studied argument labeling accuracy st sst kernels combinations standard features gildea jurafsky 
results show propbank framenet datasets sst kernel richest terms substructures produces highest svm accuracy 
combined manual designed features obtain best classifier 
suggests fragments included sst space relevant manual design may problematic requiring higher programming effort deeper knowledge linguistic phenomenon tree kernels provide remarkable help feature engineering 
remainder section describes parse tree kernels fast algorithm 
section introduces predicate argument classification problem solution 
section shows comparative performance term execution time accuracy 
section discusses related section summarizes 
fast parse tree kernels kernels consider represent trees terms substructures fragments 
define feature spaces turn mapped vector spaces associated kernel function measures similarity trees counting number common fragments 
precisely kernel function detects tree subpart common trees belongs feature space intend generate 
purpose fragment types need described 
consider important characterizations subtrees sts subset trees 
subtrees subset trees study consider syntactic parse trees consequently node children associated grammar production rule symbol left hand side corresponds parent node symbols right hand side associated children 
terminal symbols grammar associated leaves tree 
example illustrates syntactic parse sentence mary brought cat school 
root leaf mary subtree brought vp np cat vp vp np pp pp pp school school syntactic parse tree 
define subtree st node tree descendants 
example line circles subtree rooted node 
subset tree sst general structure 
difference subtrees leaves associated non terminal symbols 
satisfy constraint generated applying grammatical rule set generated original tree 
example vp sst tree non terminal symbols leaves 
mary brought vp np cat brought cat vp np cat brought np cat mary syntactic parse tree subtrees sts 
brought vp np cat vp np cat vp np np np cat cat np brought tree subset trees 
np cat mary syntactic tree feature representation set sts 
example shows parse tree sentence mary brought cat sts shows subtree rooted vp 
high different number substructures gives intuitive quantification different information level tree representations 
tree kernel functions main idea tree kernels compute number common substructures trees explicitly considering fragment space 
purpose slightly modified kernel function proposed collins duffy introducing parameter enables st sst evaluation 
set fragments 
defined indicator function ii equal target fi rooted node 
define nt nt nt nt sets nodes respectively ii ii 
equal number common fragments rooted nodes 
compute follows 
productions different 
productions leaf children pre terminals symbols 
productions pre terminals nc nc number children th child node note productions nc nc 
equal cj productions associated children identical 
recursively applying property follows subtrees identical 
eq 
evaluates subtree st kernel 
evaluates number common proved collins duffy 
additionally study variations kernels include leaves fragment space 
purpose add condition 
leaves associated symbols equal recursive rule set evaluation zhang lee 
refer extended kernels st bow sst bow bag 
add decay factor modifying steps follows 

nc cj 
computational complexity eq 
nt nt 
refer basic implementation quadratic tree kernel qtk 
observed collins duffy worst case quite syntactic trees natural language sentences design algorithms run linear time average 
function evaluate pair set tree returns node pair set list node pair set np ordered list ordered list lists sorted loading time extract get head element extract remove list null production production extract production production extract production production production production add np get elem get head element move pointer element extract reset set pointer element return np table pseudo code fast evaluation node pair sets fast tree kernel 
fast tree kernel compute kernels defined previous section sum function pair nt nt eq 

pro associated different avoid evaluate 
similarity score apply normalization kernel space mary arg 
brought predicate vp np cat arg 
pp school arg 
mary brought vp brought vp np cat brought tree substructure space predicate argument classification 
look node pair set np nt nt returns production rule associated efficiently build np extract lists production rules ii sort alphanumeric order iii scan find node pairs 
step iii may require nt nt time appears times repeated times need consider pairs 
formal algorithm table 
note list sorting done data preparation time training nt log nt 
algorithm shows worst case occurs parse trees generated production rule internal cycles carry nt nt iterations 
contrast identical parse trees may generate linear number non null pairs groups nodes associated production rule 
approach perfectly compatible dynamic programming algorithm computes 
fact difference original approach matrix entries corresponding pairs different production rules considered 
entries contain null values affect application original dynamic programming 
order pair evaluation established run time starting root nodes children 
semantic application parse tree kernels interesting application sst kernel classification predicate argument structures defined propbank kingsbury palmer framenet fillmore 
shows parse tree sentence mary brought cat school pred vp pp school argument annotation proposed prop bank project 
verbs considered predicates arguments labeled sequentially arg arg 
framenet predicate argument information described purpose richer semantic structures called frames 
frames schematic representations situations involving various participants properties roles word may typically 
frame elements semantic roles arguments predicates called target words 
example sentence annotated ar rest frame time saturday night authorities police brooklyn target suspect sixteen teenagers 
roles suspect authorities specific frame 
common approach learn classification predicate arguments relates extraction features syntactic parse tree target sentence 
gildea jurafsky different features aim capture relation predicate arguments proposed 
example parse tree path pair brought arg syntactic tree vp np 
encodes dependency predicate argument sequence nonterminal labels linked direction symbols 
alternative tree kernel representation proposed selection minimal tree subset includes predicate arguments 
example substructures inside frames semantic syntactic structures associated arguments verb bring 
feature representation predicate ar phrase type parse tree path predicate word head word governing category position voice 
build individual vs ova classifier ci argument final decision select argument type associated maximum value scores provided ci score ci set argument types 
adopted ova approach simple effective showed pradhan 
note representation quite intuitive conceive designer requires linguistic knowledge semantic roles necessary define relevant features manually 
understand point step back gildea jurafsky defined set features semantic role labeling srl 
idea syntax may useful derive semantic information inspired linguists machine learning point view decide tree fragments may useful semantic role labeling easy task 
principle designer select experiment possible tree subparts 
exactly tree kernels automatically designer just need roughly select interesting subtree correlated linguistic phenomenon tree kernel generate possible syntactic features 
task selecting relevant substructures carried kernel machines 
experiments aim experiments twofold 
hand show running time linear average case faster qtk 
accomplished measuring learning time average kernel computation time 
hand study impact different tree kernels predicate argument classification accuracy 
experimental set different corpora propbank www cis upenn edu ace bank marcus framenet 
propbank contains sentences fixed split training testing researches 
gildea palmer pradhan 
split sections training section testing sections developing set 
considered total arguments arg arg training testing respectively 
tree structures extracted penn treebank 
noted main contribution global accuracy arg arg 
framenet corpus www icsi berkeley edu framenet extracted sentences frames selected automatic labeling semantic roles task senseval www senseval org 
mapped semantic roles having name considered frequent roles associated verbal predicates total arguments 
randomly selected sentences testing training 
additionally training 
note framenet data include deep syntactic tree annotation processed framenet data collins parser collins consequently experiments framenet relate automatic syntactic parse trees 
classifier evaluations carried svm light tk software available ai nlp info uniroma encodes st sst kernels svmlight software joachims 
default linear linear polynomial poly kernels evaluations standard features defined gildea jurafsky 
adopted default regularization parameter average tried cost factor values adjust rate precision recall validation set 
st sst kernels derived best see section respectively 
classification performance evaluated measure single arguments accuracy final 
choice allows compare results previous literature 
gildea jurafsky pradhan 
time complexity experiments section compare fast tree kernel approach quadratic tree kernel qtk algorithm 
refers naive evaluation eq 
collins duffy 
assigns equal importance precision recall shows learning time svms qtk sst structures classification large argument arg different percentages training data 
note training data times faster qtk 
training data terminated hours qtk required week 
hours training data qtk arg classifier learning time different training percentages 
seconds number tree nodes qtk average time seconds qtk evaluations 
accuracy st sst st bow sst bow linear poly training data accuracy different training set percentages 
run experiments pentium ghz gb ram 
results quite interesting show tree kernels svms huge training sets instances time needed converge approximately required svms polynomial kernel 
shows minimal complexity needed dual space 
study running time extracted bank trees containing exactly nodes evaluated possible tree pairs 
point shows average computation time tree pairs fixed size figures trend lines best interpolates experimental values shown 
clearly appears training time quadratic svms quadratic learning time complexity see running time linear behavior 
qtk algorithm shows quadratic running time complexity expected 
accuracy tree kernels experiments investigate kernel accurate predicate argument classification 
run st sst st bow sst bow linear poly kernels different training set size propbank 
shows learning curves associated kernels 
note higher accuracy sts bow improve st sst kernels final part plot sst shows higher gradient st linear poly 
produces best accuracy line literature findings standard features polynomial svms pradhan 
second tables report results available training data propbank framenet test sets respectively 
row tables shows measure individual classifiers different kernels column illustrates global accuracy 
measured computation time incomplete trees associated predicate argument structures see section obtained results 
small difference mainly due different treatment built single class subclasses loc tmp pradhan evaluated separately 
note single arguments different kernels follows behavior global accuracy 
framenet bow impact st sst accuracy higher propbank produces improvement 
suggests detect semantic roles lexical information important bow give higher contribution errors pos tagging word pos fragments reliable framenet trees obtained collins syntactic parser tree kernels robust incorrect parse trees 
third point polynomial kernel flat features accurate tree kernels design effective features required noticeable knowledge effort gildea jurafsky 
contrary choice subtrees suitable syntactically characterize target phenomenon easier task see section predicate argument case 
combining polynomial sst kernels improve classification accuracy tree kernels provide learning algorithm relevant fragments hardly designed hand 
fact predicate argument structures quite large nodes contain fragments 
args st sst st bow sst bow linear poly arg arg arg arg arg acc 
table evaluation kernels propbank 
roles st sst st bow sst bow linear poly agent theme goal path manner source time reason acc 
roles table evaluation kernels framenet semantic roles 
study combined kernels applied formula linear poly kernel st corpus poly st linear sst linear st poly sst poly propbank framenet table accuracy kernel combinations 
sst kernel 
table shows results kernel combinations 
note sts improve poly percent points propbank framenet respectively linear kernel uses fewer features poly enhanced sts example propbank vs linear takes advantage richer feature set 
noted results kernel combinations framenet contrast improvement obtained 
explanation fast evaluation carry adequate parameterization 
related tree kernels designed 
highlight differences properties 
collins duffy sst tree kernel experimented voted perceptron parse tree reranking task 
combination original pcfg model improved syntactic parsing 
additionally alluded average execution time depends number repeated productions 
vishwanathan smola linear complexity algorithm computation st kernel provided worst case 
main idea suffix trees store partial matches evaluation string kernel lodhi 
compute st fragments tree converted string 
knowledge application st kernel natural language task 
interesting algorithm speeds average running time 
algorithm looks node pairs common large number trees malicious nodes applies transformation trees rooted nodes faster kernel computation 
results show increase speed similar produced method 
kernels syntactic shallow parser structures devised extraction linguistic relations 
measure similarity nodes contiguous string kernel sparse string kernel lodhi 
sorensen kernels slightly generalized providing matching function node pairs 
time complexity computation limited experiments data set just news items 
note tree kernels convolution kernels proposed article 
shen tree kernel lexicalized tree adjoining grammar ltag parse reranking task proposed 
qtk kernel computation high learning complexity forced authors train different svms different slices training data 
adapted ltag tree kernel allowed svms trained data 
roth feature description language extract structural features syntactic shallow parse trees associated named entities 
experiments named entity categorization showed description language selects adequate set tree fragments voted perceptron algorithm increases classification accuracy 
explanation complete tree fragment set contains irrelevant features may cause overfitting 
shown tree kernels effectively adopted practical natural language applications 
main arguments efficiency accuracy lower traditional feature approaches 
shown fast algorithm evaluate tree kernels linear average running time converging time required svms compatible large data sets 
regarding accuracy experiments support vector machines propbank framenet predicate argument structures show richer kernel term substructures sst higher accuracy tree kernels effective case automatic parse trees kernel combinations improve traditional feature models best approach combine scalar structured kernels 
acknowledgments ai group university rome tor 
eacl anonymous reviewers roberto basili giorgio satta provided valuable suggestions 
research partially supported presto space eu project fp 
michael collins nigel duffy 

new ranking algorithms parsing tagging kernels discrete structures voted perceptron 
acl 
michael collins 

generative lexicalized models statistical parsing 
proceedings acl madrid spain 
aron jeffrey sorensen 

dependency tree kernels relation extraction 
proceedings acl barcelona spain 
chad dan roth 

kernel methods relational learning 
proceedings icml 
washington 
charles fillmore 

frame semantics 
linguistics morning calm 
daniel gildea daniel jurafsky 

automatic labeling semantic roles 
computational linguistic 
daniel gildea martha palmer 

necessity parsing predicate argument recognition 
proceedings acl philadelphia pa joachims 

making large scale svm learning practical 
sch lkopf burges smola editors advances kernel methods support vector learning 


speeding training tree kernels node relation labeling 
proceedings emnlp toronto canada 
paul kingsbury martha palmer 

treebank propbank 
proceedings lrec spain 
lodhi craig saunders john shawe taylor nello cristianini christopher watkins 

text classification string kernels 
nips vancouver canada 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
alessandro 

study convolution kernels shallow semantic parsing 
proceedings acl barcelona spain 
sameer pradhan wayne ward james martin daniel jurafsky 

support vector learning semantic argument classification 
machine learning journal 
shen anoop sarkar aravind joshi 

ltag features parse reranking 
proceedings emnlp sapporo japan 
ben taskar dan klein mike collins daphne koller christopher manning 

max margin parsing 
proceedings emnlp barcelona spain 
vishwanathan smola 

fast kernels strings trees 
proceedings neural information processing systems 
aone 

kernel methods relation extraction 
journal machine learning research 
dell zhang wee sun lee 

question classification support vector machines 
proceedings si gir acm press 
