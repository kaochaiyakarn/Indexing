overt visual attention humanoid robot vijayakumar rg shibata stefan schaal computer science neuroscience university southern california los angeles ca usa institute university eth zurich 
ch zurich kawato dynamic brain project japan science technology kyoto japan goal research investigate interplay oculomotor control visual processing limb control humans primates exploring computational issues processes biologically inspired artificial oculomotor system anthropomorphic robot 
investigate computational mechanisms visual attention system 
stimuli environment excite dynamical neural network implements saliency map winner take competition stimuli smoothing noise suppressing irrelevant inputs 
real time system computes new targets shift gaze executed head eye system robot 
redundant degrees freedom head eye system resolved learned inverse kinematics optimization criterion 
address important issues ensure coordinate system saliency map remains correct movement robot 
attention system built principled modules generally applicable sensory modality 
visual attention involves directing spotlight attention interesting areas extracted multitude sensory inputs 
commonly attention require move body head eyes combination order acquire target interest high resolution foveal vision referred overt attention opposed covert attention involve movement 
order provide high resolution vision simultaneously large field peripheral vision humanoid robot employs cameras eye foveal camera wide angle camera strategy mimics log polar retinal resolution numerous biological species 
similar biology overt visual attention prerequisite system order move cameras target inspected foveal field view 
extensive modeling attention understanding neurobiological mechanisms generating visual spotlight attention top bottom perspective albeit mainly static images :10.1.1.40.4697
perspective overt shift saccadic eye motion generation spatial filters saccadic motor planning integrating visual information social robotics humanoid robotics 
contrast previous research focus lies creating biologically inspired approach visual attention oculomotor control employing theoretically sound computational elements derived models cortical neural networks serve comparisons biological behavior 
emphasize real time performance integration attention system humanoid robot stationary world coordinates 
shown features require additional computational consideration remapping saliency map attention body movement 
sections give overview attentional system modules explain computational principles module provide experimental evaluations humanoid robot 
overt visual attention control system computations involved overt visual attentional mechanism modularized broadly distinct subparts sensory processing module motor planning module module charge interaction issues 
fig 
represents schematic block diagram distinctions 
sensory processing module receives input raw bottom sensory signals modalities vision audition haptics top town volitional inputs 
appropriate computations module outputs new desired focus attention camera coordinates target saccade 
motor planning module takes saccade target camera coordinates converts sequence motor commands necessary drive oculomotor system head gaze location 
interaction issues module needed camera camera visual flow computation top inputs interaction issues coordinate maintenance self motion sensory processing pre process visual input shifts saliency computation saccade target motor planning trajectory planning resolving kinematic redundancies inverse dynamics motor commands schematic diagram various modules involved system implementing overt visual attention take care higher level issues overt attention 
instance saccade necessary re map saliency maps amount eye movement self motion needs canceled potential attentional target perturbations body need factored 
sections provide details module 
sensory input visual flow currently employed computed reliably real time dedicated hardware 
sensory modalities handled way described visual flow 
sensor pre processing integration key element sensory pre processing block fig 
competitive dynamical neural network derived amari arbib neural fields approach modeling cortical information processing 
goal network take input spatially localized stimuli compete saccade target output winning target 
purpose sensory input pre processing stage takes raw visual flow vf inputs stimulus dynamics order dynamical system 
denote position stimulus camera coordinates stimulus dynamics exp dx vf vf eq enhances raw visual flow vector increasing emphasize new stimuli scene eq implements gaussian spatial smoother stimuli reduce effects noise 
variable set value experiments 
top fig 
shows example typical stimulus pattern dimensional neural network due moving object top left camera image 
general multimodal sensory inputs color detectors edge detectors audio input feeding eq sensory signal 
suggested niebur itti koch useful weight inputs importance scene usually top feedback task specific biasing know color important motion :10.1.1.40.4697
stimulus dynamics feeds saliency map essentially winner take wta network decides winner simultaneous stimuli camera field 
winning stimulus saccade target focus overt attention 
wta network realized theory neural fields spatial neural network inspired dynamics short range excitatory long range inhibitory interactions neo cortex 
activation dynamics saliency map expressed base line activation level field external stimulus input eq describes coupling strength units network controls local threshold population code computation saccade target stimulus dynamics activation dynamics inhibition return stimulus dynamics activation dynamics snap shot stimulus activation dynamics just saccade activation 
depending choice parameter form activation dynamics eq various stable equilibrium points 
interested solution uniform activation base line level absence external stimuli forms unimodal activation pattern significant stimulus presence stimuli possibly dispersed spatial network 
achieved choosing transfer function cu constant interaction kernel short range excitation long range inhibition ke constants fixed values decided magnitude stimulus dynamics outlined 
addition stimulus driven dynamics activation attended location adding large negative activation eq location saccade target 
strategy implements inhibition return ensures robot keep attending location continuous presence interesting stimuli 
plots bottom fig 
illustrate behavior activation dynamics just attention shift including effect negative activation saccade 
planning generation motor commands new saccade target extracted saliency map direction gaze needs shifted center target 
fifth order splines biological movement trajectories model compute desired trajectory current position target xf expressed camera coordinates disp xf disp disp movement duration chosen maximal movement velocity saccade disp implementation 
camera space trajectory converted joint space inverse kinematics computations resolved motion rate control 
assume head eye motion needed shift gaze visual target assumption justified target visible field view 
time inverse kinematics computation performed right eye left eye performs exactly motion right eye 
need map camera space right eye joint space comprised pan tilt camera dofs robot neck 
obtain unique inverse employ pseudo inverse optimization jj jj gradient optimization criterion joint angles 
second term eq part controls movement null space head eye system 
contribution term change direction gaze change head eye dofs realize gaze 
optimization criterion chose resulting wi def wi def keeps redundant dofs close possible default posture def 
adding weights wi allows giving importance enforcing optimization criterion certain dof feature useful create natural looking head eye coordination 
desired trajectory converted joint space tracked inverse dynamics controller learned inverse dynamics model 
interaction issues issues visual attention system require special consideration 
problem maintaining frame saliency map 
robot overt shift attention camera coordinates changed locations current stimulus activation dynamics need updated accordingly 
current implementation camera centric frame shift stimulus activation patterns relative center visual field 
locations fall saliency map discarded 
obviously remapping strategy guarantee accurate re mapping chain movements 
inaccuracy time scale dynamics stimulus saliency map dynamics 
important problem stabilize image cameras body robot moves external perturbations 
demonstrated image stabilization achieved learning approaches integrate strategy attentional system 
result re mapping saliency map stimulus dynamics necessary robot head moves 
difficult issue attention arises need neglect self motion stimuli visual flow caused motion oculomotor system body parts robot view camera eyes 
currently circumvent problem discarding stimuli time robot moves eyes head 
address predict optical flow self motion actively suppress false stimuli 
experimental setup fig 
shows degree freedom dof humanoid robot testbed 
dof robot actuated torque control loop 
concentrating oculomotor specifications eye robot oculomotor system consists cameras wide angle degrees view angle horizontally color camera peripheral vision second camera foveal vision providing narrow viewed degrees view angle horizontally color image 
setup mimics foveated retinal structure primates essential artificial vision system order obtain high resolution vision objects interest able perceive events peripheral environment 
eye independent dof pan tilt motion 
fig 
shows oculomotor system detail 
subsystems control learning subsystem vision subsystem setup vme rack carry necessary computations real time operating system vxworks 
cpu boards motorola movement control sensory processing subsystem cpu boards motorola dedicated vision subsystem 
movement control sensory processing subsystem cpu boards respectively sensory processing saccade target generation ii dynamics learning task execution behaviors overt shifts attention iii low level motor control head eye body joints robot compute torque mode 
communication cpu boards carried vme shared memory communication implemented hardware fast 
vision subsystem cpu board controls fujitsu tracking vision board order calculate visual flow 
optical flow calculations block matching method performed fujitsu tracking vision board real time 
experiments visual flow computed grid nodes spread evenly entire peripheral visual field 
resolution decided real time data transmission computation bounds current setup scaling just require faster processor faster data transmission 
flow computation nodes pixel window compared best fit surrounding neighbouring locations video frame vision tracking hardware gives optical flow vector direction magnitude best fit matrix confidence bounds distributions 
confidence information helps getting rid noise ambiguities arising plain non textured background 
ntsc video signals binocular cameras synchronized ensure simultaneous processing eyes vision data 
raw extracted vision data case optical flow sent serial port bps control learning module 
sensory processing described detail section take place 
experimental dof humanoid robot testbed implementation experimental setup humanoid vision head system tions image peripheral camera processed visual flow computations motion eyes coupled horizontal pan vertical tilt degrees 
multiple degrees freedom camera multiple eyes just require duplication circuits correction vergence small focal length 
order mimic canal biological systems attached axis gyro sensor circuit head murata manufacturing 
sensors circuit head angular velocity signal acquired bit board active image stabilization performed head perturbed 
oculomotor head control loop runs hz vision control loop runs hz 
results discussion implemented visual attention system humanoid robot 
stimulus dynamics saliency map nodes twice length width nodes visual flow grid peripheral vision 
extended size assured saccade remapping saliency map stimulus dynamics maintain stimuli outside peripheral vision time 
jacobian needed inverse kinematics computation estimated linear regression data collected moving head eye system randomized periodic trajectories minutes 
due limited range motion eye head dofs jacobian assumed constant entire range motion head eye system confirmed excellent coefficient determination regression jacobian 
approach directly learned inverse kinematics described souza yielded equally results analytical method regressed jacobian 
saliency map able determine winning targets hz comparable capabilities human attentional system 
illustration working attentional system provided fig 

top image shows robot right eye peripheral view lab focussing person middle image 
bottom left part image person waving attract robot attention 
motion elicited saccade recognizable middle image fig 
shows visual blur robot experienced movement 
bottom image fig 
demonstrates saccade robot correctly focusing new target 
note images sampled hz indicating robot performed fast head eye saccade ms duration comparable human performance 
augment attentional system sensory modalities including learning sensor modality weighting different tasks 
snap shots robot peripheral view attentional head eye saccade taken hz sampling rate 
superimposed images visual flow field 
amari 
dynamics pattern formation type neural fields 
biological cybernetics 
amari arbib 
competition cooperation neural nets 
metzler ed systems neuroscience pp 

academic press 
barnes 
visual vestibular interaction control head eye movement role visual feedback predictive mechanisms 
progress neurobiology 
breazeal scassellati 
context dependent attention system humanoid robot 
proceedings ijcai 
dahm jansen steinhage von seelen 
complex behaviour means dynamical systems anthropomorphic robot 
neural networks 
driscoll peters ii cave 
visual attention network humanoid robot 
proceedings international conference intelligent robots systems iros pp 

souza vijayakumar schaal 
learning inverse kinematics 
international conference intelligent robots systems iros press 
inoue inaba mori 
real time robot vision system correlation technology 
proceedings international symposium industrial robots pages 
itti koch 
comparison feature combination strategies saliency visual attention systems 
proc 
spie human vision electronic imaging iv hvei vol 
pp 

itti koch 
saliency search mechanism overt covert shifts visual attention 
vision research 
kawato 
internal models motor control trajectory planning 
current opinion neurobiology 
koch ullman 
selecting simple network implementing shifts selective visual attention 
memo mit 
schoner 
saccadic motor planning integrating visual information pre information neural dynamic fields 
biological cybernetics 

automatic supervisory control configuration behavior multibody mechanisms 
ieee transactions smc 
koch 
computational architectures attention 
ed attentive brain pp 

mit press cambridge ma 

attentive brain 
mit press cambridge ma 
rao ballard 
learning saccadic eye movements multiscale spatial filters 
advances neural info proc 
systems pp 
mit press 
shibata schaal 
biomimetic gaze stabilization fel nonparametric regression networks 
neural networks 
vijayakumar schaal 
lwpr algorithm incremental real time learning high dimensional space 
proc 
intl 
conference machine learning icml pages 
