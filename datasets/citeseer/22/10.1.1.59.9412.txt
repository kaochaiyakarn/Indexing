optimization storage capacity allocation content distribution ioannis december addition storage capacity network nodes caching replication popular data objects results reduced user delay reduced network traffic improved scalability 
problem allocating available storage budget nodes hierarchical content distribution system formulated optimal algorithms fast efficient heuristics developed solution 
innovative aspect approach combines relevant subproblems concerning node locations node sizes object placement solves jointly single optimization step 
developed algorithms may utilized content distribution networks employ replication caching replacement 
addition reducing average fetch distance requested content cater load balancing workload constraints node 
strictly hierarchical hierarchical peering request routing models considered 
efforts improve service offered increasing internet population strive supplement traditional bandwidth centric internet non traditional network re source storage 
trend evident number new technologies service paradigms 
users employ local caches web browsers participate peer peer networks share storage content users 
organizations install dedicated proxy servers cache popular documents shared local populations 
clusters networks cooper ate allowing proxy servers communicate forming large hierarchical caches nlanr cache 
similar steps taken regarding content provision distribution 
popular web sites employ reverse proxies load balancing purposes maintain multiple mirrors geographically dispersed locations 
content distribution networks cdns operate large numbers servers push content subscribed clients close users 
aforementioned cases storage capacity memory employed bring valuable information close proximity users 
benefits tactic quite diverse users experience smaller delays load imposed network web servers reduced scalability entire content provisioning distribution chain internet improved 
dissemination efforts supported part ist program european union contract ist broadway 
authors department informatics tions university athens athens greece email di uoa gr vassilis di uoa gr di uoa gr 
cases engagement memory resource done ad hoc manner 
organizations select location capacity dedicated proxy servers little coordination organizations case proxies connect hierarchical cache 
similarly web servers replicated geographical criteria europe asia site crude statistics total number requests coming certain network region 
uncoordinated deployment memory seriously impair effectiveness 
attempts answer question allocate storage capacity budget nodes generic hierarchical content distribution system 
system materialize hierarchical cache comprising cooperating proxies different organizations content distribution network offering hosting services leasing storage may implement hosting services top dedicated electronic media system hierarchical structure video demand distribution 
dimensioning web caches content distribution nodes received limited attention compared related issues replacement policies proxy placement algorithms request redirection mechanisms :10.1.1.129.1970:10.1.1.153.5656
observation researchers publications 
fact published dimensioning web proxies aware due kelly reeves majority related works field disregarded storage dimensioning issues assuming existence infinite storage capacity 
limited attention paid problem probably owes fact rapidly decreasing cost storage combined small size typical web objects html pages images finitely large caches web objects realizable practice potentially need storage allocation algorithms 
support storage allocation algorithms marginally useful considering typical web objects median size just kb feel changes internet traffic mix prompt development algo rithms 
large scale characterization traffic saroiu shown internet traffic generated applications employ protocol kazaa gnutella :10.1.1.127.6039
median object size systems mb represents fold increase kb median size typical web objects 
furthermore access objects highly repetitive skewed popular ones making highly amenable caching demonstrated authors :10.1.1.127.6039
similar case stored audio video files distributed standard web servers dedicated video demand vod servers 
object usually short videos advertisements news amount mb 
study traffic represents limited percentage total aggregate traffic internet percentage shown increased significantly follow measurement study just years 
trend persisted studies shown stored video audio files pervasive 
objects exhaust capacity cache cdn node low price storage 
probably just matter time caching systems move accommodate traffic video traffic dedicated protocols vod servers reap benefits web objects new class applications dominate traffic 
reality case cdns stored video files 
traffic storage requirements content highly doubtful infinitely large cache realizable storage allocation algorithms ones developed prove useful 
application storage capacity allocation algorithms wireless caching system possibly employing hierarchical structure employing cluster head nodes increased capacity compared ordinary nodes storage capacity scarce resource typical web content 
approach storage capacity allocation current addresses problem allocating storage resource differently previous attempts consideration related resource allocation subproblems affect 
previous attempts broken problem designing content distribution network number subproblems consisted deciding install proxies possibly number deciding storage capacity allocate installed proxy deciding objects place proxy 
solving problems independently assuming solution bound lead suboptimal solution due dependencies 
instance different storage allocation may obtained assuming different object placement policies vice versa 
dependencies subproblems neglected current approach optimal solution subproblems concurrently derived guaranteeing optimal performance 
current approach considers memory fluid commodity decides fluid allocate node system 
placing fluid unit decides kind identity object hold combining resource allocation decisions place storage object placement decisions issue sect 

treating storage capacity fluid provisioned small granule serves paradigm optimization existing systems re organize effectively allocation storage hierarchical cache hopefully approach followed developing systems 
provisioning memory continues materialize past near memory pools cdn nodes local proxy servers place systems constitute internet 
building adaptive overlay content distribution systems top memory pools significant alternative static provisioning memory materialized current replication schemes employ large granules memory entire mirror site 
memory pools exist marketed content creators intermediaries build distribution systems leasing storage capacity dynamically dictated needs 
main advantage scenario memory utilized efficiently finer granularity potential user application able demand release longer necessary making available users may request pay protocols currencies resource trade paradigms proposed 
re organizing memory possible current dedicated mirrors proxies fixed locations fixed capacities 
believed ability reorganize existing resources central intelligent information systems see ibm autonomic computing initiative 
environments proposed algorithms useful regulate utilization storage memory pool fast may execute frequently required address sudden changes demand transient hot spot demand 
current distinct contributions realization mentioned objectives introduces idea provisioning memory small granule alternative extension known paradigms mirror placement proxy placement formulates optimal solution problem 
derived solution provides joint optimization storage capacity allocation object placement exploited systems perform replication perform caching 
develops fast efficient heuristic algorithms approximate closely optimal performance execute fast required self organizing systems opposed plan ning processes employ slow algorithms 
algorithms may executed incrementally need re optimization scratch 
supplements algorithms optimization storage capacity allocation ability take consideration load balancing load constraints maximum demand may serviced node 
load balancing important issue right jointly addressed 
techniques may avoid overloading nodes time done known filtering effect hierarchical caches 
filtering effect addressed allocating storage popular objects evenly nodes hierarchy 
models studies effect request peering ability forward request peer nodes level hierarchy opposed pure hierarchical systems forward requests upstream ancestor nodes 
focuses hierarchical topologies 
reasons infor mation distribution systems inherent hierarchical structure owing administrative scalability reasons examples include hierarchical web caching hierarchical data storage grid computing hierarchical peer peer networks internet perfect tree contains multiple routes cycles parts trees due actual physical struc ture consequence routing rules overlay networks top reason take form tree called known algorithms exist tree may applied appropriately handle general graph topologies :10.1.1.20.6836
gives example hierarchical content distribution overlay network built flat network clients proximity administration clustering 
client nodes depicted solid black squares storage nodes overlay content distribution infrastructure de empty squares 
left fig 
shows possible proximity administration clustering physical topology right resulting level content distribution overlay institution isp national levels 
hierarchical overlay may benefit algorithms developed despite fact physical topology tree 
remainder article organized follows 
section formally defines storage capacity allocation problem presents exact approximate solutions 
sec tion contains number numerical results discussion concerning implementation issues 
level level level physical topology hierarchical overlay level national level isp level institution client nodes level hierarchical content distribution overlay built set client nodes proximity administration clustering 
section algorithms exact approximate modified order able handle load balancing request peering 
second set numerical results pertaining modified algo rithms included 
related field sect 

sect 
concludes article 
storage capacity allocation problem problem statement storage capacity allocation problem defined distribution available storage capacity budget nodes hierarchical content distribution system known access costs client demand patterns 
users request specific objects storage units solution storage capacity allocation problem include solution related object placement problem 
coupling challenging problem 
related works overcome difficulty provisioning entire web server replicas assuming hit rate installed proxy priori known 
case node holds content object placement problem needs solved cooperation nodes case nodes potentially different content cooperate handle local misses 
reduces studied median problem tree graph exact solutions exist 
second case known hit ratio leads median problem locations proxies required object set proxy implicitly modeled known hit ratio 
solution approximate exact hit ratio proxy depends parameters including actual content proxy demand existence proxies path clients known typical values hit ratio may introduce significant error factor 
algorithms proposed allocate storage units may contain object set distinct objects multi commodity problem opposed single commodity median objective functions representative exact content node 
additionally assumed node hold entire set available objects fact set need contain objects single web server potentially includes object different web servers outside hierarchy 
compared works study object placement problem proxy known capacity current approach adds additional degree freedom performing dimensioning proxies object placement 
note may lead significant improvement performance optimal object placement policy perform poorly poor storage capacity allocation decisions preceded large amount storage allocated proxies receive requests proxies service lot requests allocated limited storage capacity 
input problem consists set distinct unit sized objects available storage capacity budget storage units set clients client having distinct request rate distinct object demand distribution pj tree graph node set nodes distance function dj associated jth leaf node node distance captures cost paid client retrieves object node remainder assumed total number objects exceeds available storage budget client located leaf node represents local user population size proportional 
client issues request object request serviced ancestor node holds requested object origin server 
case client receives object unique node 
storage capacity allocation problem amounts identifying set elements node object pairs set contains node object pairs 
chosen minimize expression cost min pj min min min dj os dj ancestors dj os distance jth client located jth leaf node origin server dj distance jth leaf node ancestor node function captures mean cost unit time 
non linear cost function involves non linear operator min definition dmin note cost models read operations clients 
adding write update operations content creators possible stated frequency writes negligible compared frequency reads seriously affect placement decisions 
output storage capacity allocation problem prescribes objects place node achieve minimal cost terms fetch distance subject capacity constraint 
solution implemented directly real world content distribution system performs replication content 
notice exact specification objects node produces storage capacity allocated node 
alternative strategy disregard exact object placement plan just derived node capacity allocation order dimension nodes hierarchical cache operates dynamic caching replacement algorithm lru lfu variants 
concern current hierarchical caches appropriately dimensioned storage underutilized upper level caches 
produced results utilized systems employ replication employ caching 
replication caching offer different advantages considered complementary technologies rivals 
unit size assumption merely simplify presentation 
proposed heuristic algorithms transformed handle non unit sized objects 
case handled algorithms 
minor technical changes required proof proposition 
integer linear programming formulation optimal solution section storage capacity allocation problem modeled integer linear programming ilp problem 
xj denote binary integer variable equal client gets object node ancestor client including located jth leaf node excluding origin server zero 
denote binary integer variable equal object placed ancestor node zero 
types variables related follows leaves xj equation expresses obvious requirement object placed node clients access node 
ilp gives optimal solution storage capacity allocation problem 
maximize subject pj ancestors leaves dj os dj xj ancestors xj xj xj binary decision variables maximization objective operates cumulative gain incurred placement storage units tree 
gain captures difference cost accessing cached copy object ancestor node excluding origin server accessing original object origin server see parenthesis 
maximization equivalent minimization 
chosen definition xj allows linear gain function exact modeling non linear cost function 
notice xj contribute objective function 
constraint enforces requirement client fetches object ancestor node 
constraint guarantees storage units allocated exactly optimal solution 
adoption decision variables addition xj facilitate formulation constraint 
notice xj requiring sum xj lead allocation storage units placement single copy object consumes exactly storage unit permits multiple clients share copy allowing variables xj assume value 
auxiliary decision variables allows correct formulation storage capacity constraint produces non linearity form conditional relationship relates types variables 
constraint guarantees object placed node clients access 
upper bound number clients may fetching object node smallest sufficient value total number clients 
constraint combined objective function enforce conditional relationship xj holds optimal solution 
permits formulation non linear relationship linear functions 
validity linearization technique established proposition 
proposition optimal solution ilp 
leaves xj xj optimal solution 
proof constraint guarantees xj xj non negative numbers 
proof inverse assume node object optimal solution leaves xj 
easy see removing flipping placing objects reside origin server object exist assumed new solution may constructed incurs higher value holds true flipping allows xj leaves flip increasing value contradicts initial assumption optimal 
proof inverse fetching unreplicated object server object ancestor node higher hierarchy replicated lower improving solution 
sequel mentioned ilp employed purpose obtaining bound performance optimal storage capacity allocation 
bound derived considering lp relaxation ilp removing requirement decision variables assume integer values solution derived rapidly linear programming solver 
complexity optimal solution ilp formulation sect 
generally np hard practical purposes 
findings aforementioned storage capacity allocation problem modeled special type problem belongs family multicommodity resource allo cation problems generalize single commodity median problem 
shown generalized problems solved polynomial time case tree graphs described step algorithm reaches optimal solution multi commodity resource allocation problem including max 
solu tion sought solving series medians different objects known dynamic programming techniques combining solutions various medians order solve packing problem modified version knapsack problem dynamic programming 
theoretical point view max result attractive involves small powers input 
practice result prove difficult apply 
main complication owes term indicating quadratic dependence complexity number distinct objects real applications may assume large values represents number distinct web pages files typically larger values assumed number nodes content distribution infrastructure 
common case complexity ranging tens hundreds rarely thousands large cdns akamai size order multiple thousands millions depending exact application 
quadratic complexities large inputs generally treated complicated practical purposes systems need re allocate storage frequently 
solutions possible apply 
additionally aforementioned optimal algorithm jointly consider load balancing sect 
request peering sect 

cases exact polynomial algorithm known 
reasons primarily focused development efficient approximate algorithms 
employ natural greedy heuristics address basic problem variations considering load balancing request peering 
developed algorithms easy implement incur complexity worst case linearly dependent provide close approxima tion optimal lend incremental common circumstances involving time varying input need arising considering dynamic adaptive systems 
greedy heuristic greedy heuristic begins empty hierarchy enters loop placing object iteration exactly iterations storage capacity allocated 
objects placed greedy fashion gain produced placement past placement decisions subject placement decisions subsequent iterations 
gain object certain node depends location node popularity object aggregate request rate object clients leaves subtree rooted selected node prior iterations placed object lower subtree 
iteration algorithm selects node object pair yields maximal gain places 
subsequent decisions place object node maximal pairs selected leaves path dj os dj pj greedy detail table 
lines describe initialization algorithm 
node gain placing object computed values inserted max heap data structure max heaps node 
iterations algorithm steps executed node object pair produces maximum gain node object pairs placed selected removed max heap re organized lines ancestor hold potential gain incurred selected iteration updated corresponding max heap re organized lines 
update potential gain necessary clients belonging subtree fetching subtree effectively reducing previous potential gain max heap needs re organized elements changes value order able guarantee maximum value root heap 
initial creation max heaps done nn time max heap containing values 
step iteration requires highest value max heaps selected 
finding largest value max heap requires time largest value insert max heap select re organize max heap ancestor caching re organize max heap table greedy algorithm 
max heaps identified simple linear search log additional max heap maintained containing highest value max heaps unnecessary typically small 
second step worst case requires update ancestors cache potential value nodes reduced corresponding max heap re organized order maintain heap property done log heap objects 
result iterations algorithm require log time simplifies log noting complexity greedy initialization iterations max nn sn log linear salient feature greedy executed incrementally available storage budget changes storage available user access patterns changed significantly re optimization scratch required suffices continue greedy iteration add remove objects 
significant advantage algorithm executed frequently different improved greedy heuristic igreedy previous greedy algorithm simple observation 
object placed children node meaningless store request reach 
situation leads waste storage units stale objects 
greedy algorithm introduces stale objects result greedy mode operation object point placed father time children store subsequent iterations placed children rendering stale copy father 
situation occasional repeated quite frequently resulting wasting substantial amount storage budget 
situation may resolved executing additional check placing peers cached break cached father remove set table additional step igreedy algorithm 
executed lines basic greedy algorithm 
object node improved algorithm checks peer nodes level belonging father finds store check father stores 
case removes freeing storage unit 
resulting algorithm called improved greedy igreedy outperforms basic greedy algorithm 
additional step igreedy table executed lines basic greedy algorithm 
igreedy performs slightly processing compared greedy due additional actions iteration maximum peers need examined denoting maximum node degree tree eviction stale object increases number iterations freeing storage unit allocated subsequent iteration 
searching peers affect asymptotic iteration complexity greedy log 
increase number iteration somewhat larger impact required processing 
proposition establishes exact upper bound number iterations performed igreedy 
proposition maximum number iterations performed igreedy exceed 
proof note worst case additional iteration may introduced new objects placed denoting minimum node degree hierarchy 
corresponds case object placed node minimal outdegree children freeing stale object father turn increases number iterations 
denote maximum number iterations may performed igreedy starts available storage units 
previous observation easy see 
worst case recursive relationship leads 
worst case igreedy perform iterations iteration incurring complexity basic greedy 
means asymptotic complexity igreedy identical greedy 
numerical results igreedy section numerical results attempt accomplish demon strate effectiveness igreedy approximating optimal performance possible applications developed algorithms 
stated clients assumed sharing common zipf demand distribution pj typical skewness parameter equal request rates zipf distribution power law dictating ith popular object requested probability ia ja skewness parameter captures degree concentration requests values approaching mean distinct objects receive vast majority requests small values indicate progressively uniform popularity 
zipf distribution generally recognized model characterizing popularity various types measured workloads web objects multimedia clips :10.1.1.12.2253
popularity cdn content shown quite skewed popular documents approaching zipf behavior :10.1.1.127.6039
evidence zipf behavior observed distribution gnutella queries 
far topology experiments concerned regular ary trees exam ples 
regular ary trees commonly derivation numerical results algorithms operating trees seen numerical results regular tree topologies accordance experimental results actual internet tree topologies 
entire set parameters demand topology experiment indicated title corre sponding graph 
purpose numerical study distance function dj capture number hops client located jth leaf dj node distance origin server dj os level hierarchy 
notice hop count metric merely simplify presentation numerical results 
means necessary order apply algorithms allow arbitrary weights associated link 
quality approximation shows average cost request greedy igreedy expressed number hops reach object 
performance heuristic algorithms plotted bound corresponding optimal performance obtained lp relaxation ilp sect 
axis indicates number available storage units hierarchy storage unit able host single object mp file video file 
graph may seen igreedy away optimal greedy may deviate results 
performance gap owes waste significant amount storage stale objects greedy 
asymptotic performance best performing igreedy rigorously proved claimed constant distance away optimal typical workloads approach infinity 
intuitively argued noting value objects belong tail popularity distribution tends insignificant point onwards adding capacity reduce cost 
effect means suboptimal placement decisions involving invaluable objects cached abundant storage capacity increase performance gap created suboptimal decisions placement initial valuable objects 
average cost number hops lambda ones storage capacity allocated greedy igreedy lp relaxation total level capacity lambda ones skewness zipf distribution level level level average cost greedy igreedy effect skewness popularity lp relaxation 
level allocation storage igreedy 
psfrag replacements total level capacity lambda ones level level level average cost number hops lambda ones lru big top lru equal share lru igreedy igreedy replication allocated storage capacity overlap degree simulated performance lru effect non homogeneous demand igreedy equal share big top storage allocation level allocation storage igreedy 
equal request rates 
effects skewness non homogeneous demand figures focus vertical allocation storage igreedy attempting provide new insights effect user access patterns dimensioning hierarchical distribution systems 
shows effect skewness demand distribution level allocation storage 
highly skewed distributions skewness parameter approaching lead allocation storage lower levels skewed distributions lead allocation storage higher levels 
effect explained follows 
highly skewed distribution small number popular objects attracts majority requests objects intensively replicated lower levels leading allocation storage lower levels 
distribution tends flat better limit number replicas object increase number distinct objects replicated 
achieved sharing objects placing higher hierarchy leads allocation storage higher levels 
equal request rate clients leads equal allocation storage node level 
horizontal symmetry disturbed unequal client request rates employed results shown point 
illustrates effect degree homogeneity access patterns different clients 
clients non homogeneous employ different demand distributions 
results client objects objects common clients remaining referenced client zipf distribution created client randomly choosing object set assigning higher value zipf distribution repeating action objects assigned probabilities 
parameter referred overlap degree values approaching mean objects common clients client may request common object potentially different probability small values mean client potentially different set objects 
shows upper levels hierarchical system assigned storage substantial amount overlap client patterns 
storage goes lower levels 
behavior explained follows 
storage effectively utilized upper levels placed object receives aggregate request stream clients 
aggregation may exist substantial amount objects common clients better allocate storage lower levels sacrificing ineffective aggregation effect reduce distance clients objects 
igreedy caching replacement aforementioned results examples igreedy useful dimensioning distribution system operates replication content 
systems igreedy prescribes amount storage allocated node exact set objects replicated 
second interesting igreedy 
discussed sect 
choose retain node dimensioning igreedy disregarding object placement plan dimension system operates request driven caching replacement hierarchical cache 
caching replacement strategies try approximate result optimal replication plan achieve line priori knowledge demand patterns 
optimized node dimensioning originates replication benefit online caching replacement systems 
interesting note works question appropriateness dimensioning current operational hierarchical caches noting higher level caches unnecessarily 
results tend agree concerns indicating optimized storage allocation produces gain compared empirical storage allocations plans equal share node gets equal share storage approximately units big top nodes tend get bigger higher levels done practice questioned 
big top units allocated follows leaf node takes units second level node takes units general level node takes units 
empirical rules sound simplistic employed practice aforementioned concern higher level nodes points 
case aware storage allocation method fit described problem statement comparison 
examine potential gain caching replacement systems assumed operate lru replacement algorithm 
demonstrates kelly reeves considers tradeoffs communication costs storage ownership costs differing current setting amount available storage fixed 
assumes clients generate identical request streams homogeneous terminology 
lru igreedy avg 
hit dist lru equal share avg 
hit dist lru big top avg 
hit dist table simulated performance lru igreedy lru equal share lru big top unequal client request rates 
server name urbana champaign type nlanr root trace date hours requests distinct objects table properties nlanr trace simulations sect 

performance lru hierarchical cache dimensioned igreedy empirical rules 
performance static replication igreedy simulated plotted 
previous analytical results refer object replication results fig 
refer request driven caching lru 
produced simulation model synthetically generated requests zipf distribution see title fig 
param eters 
results show lru operates hierarchy storage allocation optimized igreedy achieves reduction cost equal share reduction big top 
percentages larger unequal client request rates table presents examples taken uniform distribution 
reduction large equal share big top achieved allocation igreedy 
performance gap widens degree asymmetry request rates 
effect perfor mance gap may grow arbitrarily various demand distributions request rates small overlap demand distributions clients larger request rate 
comparing performance lru irrespectively capacity allocation method static replication igreedy shows replication priori knowledge object achieves significantly better performance online algorithms need object adapt automatically changes demand patterns 
trace driven simulation study issue discussed far temporal correlation usually char actual measured workloads 
igreedy replication leads system immune temporal correlations 
see consider request sequence permute arbitrarily 
hit ratio average hit distance unaffected replication strategy permit nodes change content response received input 
quality replication provided igreedy depends quality estimation request frequencies individual objects unaffected temporal correlation 
temporal correlation relevant extent igreedy limited storage di network operates caching replacement 
dimensioning procedure immune temporal characteristics replacement algorithm affected usual manner 
case lru positively correlated request stream lead improved performance compared request stream composed independent requests 
quality dimensioning gain compared empirical rule remains matter replacement algorithm best handle correlation produce gain 
request probability uc trace object popularity rank popularity profile request probability object rank trace table 
average cost number hops uc trace lambda ones allocated storage capacity lru lru lru igreedy igreedy average hit distance various storage allocation schemes trace table 
order substantiate aforementioned observations conducted simulation ex periment evaluating performance lru igreedy lru equal share lru big top igreedy replication real workload captures characteristics notably degree temporal correlation synthetically generated stream requests 
due lack publicly available workload traces employed trace nlanr root proxy server urbana champaign abbreviated uc properties trace summarized table 
motivation trace approximation actual trace trace captures properties workloads popularity objects trace approximates satisfactorily popularity objects measurements studies shows deviation zipf model numerical evaluation enriched wells captures new artifact 
depicts log log plot request probability object rank popularity objects accessed trace 
visual inspection suffices show distribution partially deviates zipf appears straight line log log scale 
divergence popular objects initial part appear uniformly requested observe initial plateau plot compared zipf distribution 
measurement study oct research group university washington group produced previously cited measurement studies reported plateau appears consistently measured traces :10.1.1.127.6039
attributed fact web objects objects accessed client web user constantly downloads popular web pages google rarely downloads mp file 
case nlanr trace plateau due different reason probably owing fact corresponding proxy server high nlanr hierarchy root server requests reaching filtered lower levels 
means requests popular objects serviced lower levels making request distribution root uniform initial part 
take advantage coincidental fact order approximate trace 
shows average hit distance hierarchy operates optimized storage capacity allocation empirical rules 
lru replacement curves replication curve depicted 
results identical ones depicted fig 
produced workload discussion achieved gain applying 
suggest time real workload optimized storage capacity allocation result reduced average hit distance lru replacement replication 
obtained similar results traces different nlanr servers time periods different topologies report due length considerations 
discussion implementation discussed possible applications storage allocation gorithms re organize current hierarchical caches drive operation content distribution systems dynamically lease memory 
case offline optimiza tion resource allocation problem 
required input demand distributions rates extracted proxy log files 
interesting question useful solution derived historical data 
krishnan answered question related cache location problem 
showed solutions fairly stable time estimation cies despite optimization carried input past snapshot workload including estimation error 
stability derived solution owes fact user access patterns fairly stable 
fact published measurement study reported top popular documents day requests week 
allows possibility historical data input making replication decisions 
case somewhat challenging perspective implementation 
main difficulty due need online estimation demand distributions aforementioned pj 
various methods doing efficiently keeping track requested objects fraction popular ones 
owing aforementioned stability demand distributions necessary keep re estimating frequently occasionally 
demand distributions change slowly request rates trigger changes storage capacity allocation plans 
notice stable demand distributions ones reported changes request rates require re optimization allocation storage sensitive request rates 
changes occur users activate deactivate various access points 
allows accommodating case mobile users show access resources leaf access points affecting request rate 
perspective implementation complexity request rates may obtained easily maintaining counter node task easier compared frequent estimation request distributions 
fact igreedy complexity linearly dependent input problem frequent re optimization necessary systems re organize cope changes request intensity possible re optimization intervals ranging minutes hours 
optimization algorithm centralized executed node administrative duties overlooks operation cdn 
purpose estimates demand distri butions communicated administrative node leaf nodes access points hierarchical distribution infrastructure 
order reduce bandwidth overhead reporting demand distributions compact representations provide succinct summaries actual demand leaf 
leafs simple techniques sending numerical value encoded bytes representing estimate request probability distinct objects 
alternatively advanced techniques employed reduce bandwidth overhead transmitting relevant information 
example bloom filters sum mary cache employed succinctly represent set distinct objects requested leaf information accompanied approximate representation corresponding demand distribution exploiting spectral representation :10.1.1.153.5656
additionally due aforementioned stability demand distributions possible report back required information relatively infrequently retransmissions days suffice limiting bandwidth overhead 
hand request rates may reported frequently needed overhead negligible single number leaf sent 
frequent reporting request rates intensity crucial adapting changes demand due activation deactivation clients mobile users 
summing possible re organize effectively allocation storage afore mentioned architecture accommodate possible changes request intensity access points infrastructure owing volatility users 
variations load balancing request peering sections igreedy heuristic modified cater load balancing request peering 
additional section presents relevant numerical results 
load balancing commonly sought ability distributed systems case system avoid nodes 
request peering employed hierarchical systems positive effects user perceived performance 
load balancing optimal heuristic wv denote maximum number requests unit time may serviced node metric captures maximum load assigned node load balancing congestion avoidance caching nodes 
ilp model sect 
modified respect maximum load node addition constraint 
leaves pj xj wv similarly igreedy algorithm sect 
augmented handle load constraints addition extra steps 
brief algorithm maintains load counter node selects node objects pairs decreasing order respect gain 
contrary basic igreedy load balancing version algorithm considers feasible node object pairs placing objects selects objects violate load limit node selected placement 
new algorithm igreedy greedy 
table gives additional lines pseudocode 
lines new added pseudocode table lines lines substitutes corresponding lines table 
line initializes zero load counter node 
line creates set comprises node object pairs eligible placement requires new load imposed node object pair violate maximum load wv wv re organize find closest ancestor caches loadu loadu cached loadu wu re organize max heap table additional steps algorithm 
node 
function defined follows leaves pj 
path line updates load node object chosen placement line updates removing node object pairs infeasible due increment load necessitates update max heap 
line identifies closest ancestor caches excluding origin server 
load node reduced leaves longer fetch line 
due reduction loadu objects cached previously infeasible due load constraint feasible added line corresponding max heap re organized line 
contrary load unaware practices load balancing ilp heuristic allocate storage capacity evenly nodes hierarchy place popular objects higher level nodes opposed common intuition popular objects placed lower levels hierarchy 
done order preserve load constraints distributed load evenly hierarchy 
tactic results worse performance terms average distance bandwidth consumption case hop count distance metric considered numerical results sect 

may case delay metrics 
placing memory popular objects higher hierarchy admittedly increases propagation delay accessing increment expected small compared delay reduction incurred accessing non congested proxy servers 
system delay part dominates propagation delay part delay budgets congested systems arise load balancing considered 
modeling request peering optimal heuristic replication caching schemes permit peer nodes nodes level father cooperate 
node receives request downward node service locally cache forwards upstream node peer nodes level 
occasions may lead significant reduction delay peer node usually closer upstream nodes quickly return requested object 
general peering meaningful fast direct links exist peer nodes delay links smaller delay links lead higher level nodes 
environment request peering leads higher utilization cached object object services larger population turn reduces number replicas necessary object 
reducing number replicas object allows caching larger number distinct objects larger initial part tail object popularity distribution fits hierarchy resulting better performance terms cost bandwidth delay 
section describes integrate request peering study storage capacity allocation problem 
ilp formulation sect 
augmented handle request peering 
larger number variables xj required due peering client may receive object larger set nodes including ancestors peers 
objective function change pj ancestors peers dj os dj xj peers denotes set nodes peers including 
fixed cost paid transmitting object peers cost typically smaller cost accessing ancestor higher level 
indicator function returns expression brackets true 
constraint change xj peers leaves constraint re written xj ancestors peers similarly igreedy algorithm sect 
converted handle request peering resulting algorithm referred 
request peering effects basic igreedy algorithm 
gain function updated follows dos dj pj peers peers leaves peers path pj leaves peers path expression corresponds case peer caches placing attract requests descendants descendants peer nodes fetch node peer path second line corresponds case cached peer gain caching equal extra distance spared crossed additional copy placed descendants fetch peer caches incurring additional cost 
second modification refers removal stale objects higher level nodes 
suffices copy child node remove placed 
motivated fact due request peering single copy peer service peers immediately rendering stale copy father requiring children cache case igreedy 
table contains pseudocode 
lines initialize algorithm computing initial gains node object pair storing max heaps node 
communication cost peers depend exact peers communicate cost typically smaller cost going higher level modeled constant order simplify presentation 
insert max heap select re organize max heap peer caching re organize max heap peers ancestors caching re organize max heap cached father remove father table algorithm 
iteration algorithm executes code lines 
node object pair returns maximum gain selected removed lines 
potential gain incurred caching selected object updated nodes affected selection nodes peers lines ancestors peers lines 
father includes removed freeing storage unit increases number iterations lines 
numerical results section presents number numerical results pertaining variations igreedy load balancing request peering 
examine efficiency heuristic algorithms perfor mance plotted bound corresponding optimal performance compared lp relaxation load balancing ilp sect lp relaxation ilp peering sect 

shows effect different degrees load balancing optimal solution load balancing 
cases approximates closely optimal 
average cost number hops lambda ones lp relaxation lp relaxation lp relaxation igreedy lp relaxation allocated storage capacity effect load balancing average effect load balancing max cost lp relaxation ilp imum load may imposed node load balancing 
standard deviation workload lambda ones igreedy allocated storage capacity max workload lambda ones igreedy hierarchy 
allocated storage capacity effect peering average cost effect load balancing stan incurred lp relaxation ilp dard deviation load nodes hierarchy un peering different peering costs indicated der 
parentheses graph 
average cost number hops lambda ones igreedy lp relaxation lp relaxation lp relaxation lp relaxation allocated storage capacity maximum load parameter capture maximum amount load node may service 
setting means node able service fraction total load 
smallest fraction nodes selected setting avoid request blocking due load constraints 
larger values mean node may service fraction total load fraction equal share load igreedy single node potentially service entire load 
shows plain igreedy performs better terms average cost various load constrained 
increasing helps approximate best performance load balancing 
smallest value leads best load balancing situation nodes get approximately equal amount load results increased cost optimal allocation storage deviates due load constraints optimal unconstrained 
maximum average cost gap load unaware igreedy load constrained 
figures depict positive effects load balancing 
shows load balancing effective suppressing maximum load may imposed node 
different values maximum load node eventually stabilized highest allowed value increases continuously igreedy storage added 
shows standard deviation load computed nodes hierarchy different degrees load balancing 
load balancing leads smaller values standard deviation nodes load close mean load hierarchy 
means load evenly distributed nodes utilized better opposed unconstrained case nodes congested severely underutilized especially higher levels 
notice adding storage load constrained achieves perfect load balancing total load evenly shared nodes 
load balancing techniques may help addressing known underutilization problem higher levels hierarchical caches due filtering requests lower levels 
note increase average cost number hops igreedy results reduction maximum load reduction standard deviation load hierarchy 
results may lead substantial reduction average delay noting propagation delay increases linearly distance number hops system delay delay fetch object disk transmission increases aggressively system congested thrashing effect 
shows approximates closely optimal request peering 
em request peering significant reduction average cost may achieved 
reduction grows peers able communicate economically cost accessing peer reduces smaller values 
notice cost incurred half corresponding cost igreedy direct links peers lead reduction cost communication peer links incurs zero cost frequently actual case peer links usually local direct connections geographically neighboring networks approximately cost 
related placement web server replicas mirrors commonly employed way adding storage capacity internet 
number works addressed fundamental questions mirrors needed place :10.1.1.129.1970
web proxies mirrors store fraction content web site multiple web sites 
content statically replicated proxy refreshed dynamic request driven caching replacement algorithms lru lfu variants 
web proxy placement studied assumed proxies replicate set popular objects cooperation different proxies exist allowed assumed proxy known hit ratio 
dimensioning level hierarchical cache operates lru studied special case homogeneous demands clients request objects rate common popularity distribution entire object universe 
works performance hierarchical caching assume proxies infinite storage capacity 
attention paid closely related object placement problem proxy locations storage capacities known challenge fill proxy appropriate set objects optimize performance delay bandwidth consumption 
authors terms proxy mirror interchangeably 
clear distinction terms 
object placement studied hierarchical caches 
compared add additional degree freedom deriving cache capacities avoid approximate distance metrics 
authors combined study proxy object placement 
differs number ways important guarantee allocation exact amount storage constrain allocation storage implicitly considering write costs 
considers problem best allocate available storage budget nodes hierarchical content distribution system 
current addresses problem allocating storage resource differently previous attempts consideration related resource allocation subproblems affect 
dependencies subproblems neglected current approach optimal solution subproblems concurrently derived guaranteeing optimal performance 
complexity deriving optimal solution high fast efficient heuristic algorithms derived 
proposed igreedy linear time efficient heuristic algorithm 
igreedy variants workload balancing request peering shown achieve performance close optimal 
igreedy may derivation joint storage capacity allocation object placement plan employed system performs replication cdn 
alternatively just derived node storage capacity allocation may dimensioning hierarchical system operates request driven caching replacement algorithm 
provisioning storage igreedy compared empirical methods gain demonstrated 
additionally igreedy derivation numerical results provide insight effects user request patterns skewness demand homogeneity demand vertical dimensioning hierarchical system 
igreedy modified cater load balancing request peering 
load balancing shown able provide spread load hierarchy cost small increase average distance users objects may compensated substantial reduction delay result accessing uncongested systems 
request peering shown able provide significantly reduced cost 
request peering may lead halving cost utilizing inexpensive direct peer links 
interesting line investigate mechanisms provide efficient storage capacity allocation distributed manner 
distributed computation advantages including better scaling properties reduced exchange information particularly suitable networks operating central authority cdn having cater multiple local utilities 
shown optimal storage capacity allocation tree derived polynomial time remains seen possible considering node load constraints sect 
allowing cooperating peers sect 

cao irani cost aware www proxy caching algorithms 
proceedings usenix symposium internet technologies systems 
fan cao almeida broder summary cache scalable wide area web cache sharing protocol :10.1.1.153.5656
ieee acm transactions networking krishnan raz shavit cache location problem 
ieee acm transactions networking li golin italiano deng optimal placement web proxies internet 
proceedings conference computer communications ieee infocom new york qiu padmanabhan voelker placement web server replicas 
pro ceedings conference computer communications ieee infocom anchorage alaska cronin jamin jin raz shavitt constraint mirror placement internet 
ieee journal selected areas communications pan hou li overview dns server selection content distribution networks 
computer networks fonseca almeida crovella intrinsic locality properties web streams 
proceedings conference computer communications ieee infocom san francisco kelly reeves optimal web cache sizing scalable methods exact solutions 
com puter communications rodriguez spanner biersack analysis web caching architectures hierarchical distributed caching 
ieee acm transactions networking gadde chase rabinovich web caching content distribution view interior 
computer communications saroiu gummadi dunn gribble levy analysis internet content delivery systems :10.1.1.127.6039
proceedings th symposium operating systems design implementation osdi 
wolman voelker levy measurement analysis streaming media workload 
proceedings usits 
gribble brewer system design issues internet middleware service deductions large client trace 
proceedings usenix symposium internet tech systems 
wolman voelker sharma cardwell brown karlin levy organization analysis web object sharing caching 
proceedings second usenix symposium internet technologies systems 
gibson van meter network attached storage architecture 
communications acm turner ross lightweight currency paradigm market submitted 
ibm autonomic computing initiative www research ibm com autonomic 
cohen kaplan balanced replication algorithms distribution trees 
proceedings th annual european symposium algorithms esa rome italy williamson filter effects web caching hierarchies 
acm transactions internet technology wessels claffy icp squid web cache 
ieee journal selected areas communications ranganathan foster identifying dynamic replication strategies high performance data grid :10.1.1.20.6836
proceedings international workshop grid computing denver colorado biersack ross felber keller cal systems 
proceedings acm ifip international conference parallel distributed computing euro par klagenfurt austria bartal approximating arbitrary metrics tree metrics 
proceedings th annual ieee symposium foundations computer science ieee focs 
guha meyerson hierarchical placement network design problems 
proceedings st annual ieee symposium foundations computer science ieee focs redondo beach ca algorithmic approach network location problems part ii medians 
siam journal applied mathematics charikar guha shmoys tardos constant factor approximation algorithm median problem 
proceedings st annual symposium theory computing acm stoc 
plaxton rajaraman placement algorithms hierarchical operative caching 
proceedings th annual symposium discrete algorithms acm siam soda 
rabinovich issues web content replication 
data engineering bulletin invited joint object placement node dimensioning internet content distribution 
information processing letters appear 
gao golin italiano li algorithm finding median directed tree 
information processing letters pn algorithm median related problems tree graphs 
operations research letters papadimitriou steiglitz combinatorial optimization algorithms complex ity 
dover publications new york cormen leiserson rivest stein algorithms nd edition 
mit press cambridge massachusetts breslau cao fan philips shenker web caching zipf distributions evidence implications :10.1.1.12.2253
proceedings conference computer communications ieee infocom new york sripanidkulchai popularity gnutella queries implication scalability white online www cs cmu edu research gnu 
patel networking requirements interactive video demand 
ieee journal selected areas communications biersack performance modelling reliable multicast transmission 
proceedings conference computer communications ieee infocom kobe japan gummadi dunn saroiu gribble levy zahorjan measurement modeling analysis peer peer file sharing workload 
proceedings nineteenth acm symposium operating systems principles acm press chen qiu chen nguyen katz efficient adaptive web replication content clustering 
ieee journal selected areas communications che tung wang hierarchical web caching systems modeling design experi mental results 
ieee journal selected areas communications bloom space time trade offs hash coding allowable errors 
communications acm kamath gao hierarchy aware algorithms cdn proxy placement internet 
computer communications xu li lee placement problems transparent data replication proxy services 
ieee journal selected areas communications 
