chapter proxy caching media streaming internet liu school computing science simon fraser university british columbia canada cs sfu ca xu department computer science hong kong university comp edu hk streaming media contributed significant amount today internet traffic 
conventional web objects html pages images media objects benefit proxy caching unique features huge size high bandwidth demand imply conventional proxy caching strategies substantially revised 
article discusses critical issues challenges cache management proxy assisted media streaming 
survey classify compare state art solutions 
investigate advanced issues combining multicast caching cooperating proxies leveraging proxy caching overlay networks 
keywords streaming media video proxy caching overlay networks multicast widespread penetration broadband internet multimedia service getting increasingly popular users contributed significant amount today internet traffic 
media objects accessed similar extended version survey article liu xu proxy caching media streaming internet ieee communications feature topic proxy support streaming internet august 
conventional text images download play mode users prefer quickly initiate continuously play back media object downloaded real time streaming mode 
witnessed initial incremental deployment streaming applications microsoft windows media player years 
performance applications far satisfactory especially peak hours 
reduce client perceived access latencies server network loads effective means cache frequently data proxies close clients 
enhances availability objects mitigates packet losses local transmission generally reliable remote transmission 
proxy caching vital components virtually web systems 
streaming media particularly pre stored benefit significant performance improvement proxy caching static nature content highly localized access interests 
existing proxies generally optimized delivering conventional web objects html pages gif images may meet requirements applications 
list important unique features streaming media discuss implications proxy cache design 
huge size conventional web object typically order bytes 
binary decision works proxy caching caching object entirety caching 
contrast media object high data rate long playback duration combined yield huge data volume 
illustration hour standard mpeg video volume mb caching entirely web proxy clearly impractical large streams exhaust capacity cache 
solution cache portions object 
case client playback needs joint delivery involving proxy origin server 
cache portions objects carefully managed benefit caching outweighs synchronization overhead joint delivery 
intensive bandwidth streaming nature delivery requires significant amount disk network bandwidth sustaining long period 
minimizing bandwidth consumption primary consideration proxy cache management precedence reducing access latencies cases 
bandwidth bottleneck limits number clients proxy simultaneously support employing multicast delivery cooperation proxies particularly attractive media streaming applications 
high interactivity long playback duration streaming object enables various client server interactions 
example studies nearly media terminated prematurely clients 
addition playback client expects vcr operations proxy caching media streaming internet fast forward rewind 
implies access rates different different portions stream potentially complicates cache management 
unique features media objects novel caching algorithms developed literature 
objective article review state art caching techniques dedicated streaming media caching 
discussions generic proxy caching architecture protocol considerations 
caching strategies streaming media classified examined compared section 
section investigates advanced issues 
section concludes article 

architecture protocols streaming caching streaming applications generally support diverse client server interactions stringent demands packet delay jitter ensure playback 
meet requirements internet engineering task force ietf developed rtp rtcp rtsp protocol suite 
generic system diagram proxy assisted media streaming suite depicted fig 

client player buffer control channel rtsp rtcp enterprise network data channel rtp assembler switcher media proxy proxy manager cache control channel rtsp rtcp backbone network data channel rtp server scheduler media repository 
generic system diagram proxy assisted media streaming rtp rtcp rtsp 
system basic functionalities data transferring provided real time transport protocol rtp including payload identification sequence numbering loss detection time stamping playback control 
running top udp rtp guarantee quality service qos relies companion real time control protocol rtcp monitor network status provide feedback application layer adaptation 
real time streaming protocol rtsp coordinates delivery media objects enables rich set controls interactive playback 
proxy assisted streaming proxy relay control messages client server 
problem particularly involved part media object cached proxy 
case proxy reply client play request initiate transmission rtp rtcp messages client cached portion request uncached portion server 
fetching achieved rtsp range request specifying playback points illustrated fig 

range request enables clients retrieve different segments media object multiple servers proxies needed 
rtsp rtp rtcp rtsp options describe ok setup ok play ok portion cached portion uncached teardown ok setup ok play range ok portion teardown client proxy server 
operations streaming partial caching 
classical client server paradigm peer peer streaming overlay streaming paradigms attracted attention discussed section 
caching strategies homogeneous clients heterogeneous clients due aforementioned features streaming media objects media caching distinct focuses conventional web caching 
hand content media object rarely updated management issues cache consistency coherence critical media caching 
hand high resource requirements media objects effective management proxy cache resources space disk network ok proxy caching media streaming internet challenging 
section survey state art media caching strategies homogenous clients heterogeneous clients emphasis strategies minimize resource demands 
stream caching homogeneous clients existing caching algorithms focus homogeneous clients identical similar configurations capabilities proxy 
single version object match bandwidth format demands requests object 
cache portions objects manage cache cache placement replacement proxy remain challenges 
selection portions cache classify existing algorithms categories sliding interval caching prefix caching segment caching rate split caching 
sliding interval caching algorithm caches sliding interval media object exploit sequential access streaming media 
illustration consecutive requests object request may access object server incrementally store proxy cache second request access cached portion release access 
requests arrive close time small portion media object needs cached time instance second request completely satisfied proxy see fig 

general multiple requests object arrive short period set adjacent intervals grouped form run cached portion released request satisfied 
cached proxy 
illustration sliding interval caching 
object consists frames requiring unit time deliver proxy client 
requests arrive times respectively 
serve request frames need cached time instance 
time request arrives time frames accessed request cached request arrives time frame accessed request cached frame read request released 
cached portion dynamically updated playback caching involves high disk bandwidth demands worse case double disk due concurrent read write operations 
ef utilize available cache resources tewari proposed resource caching rbc policy 
policy characterizes object space bandwidth requirements models cache constraint knapsack 
heuristic algorithm developed dynamically select caching granularity object objective balancing bandwidth space usages 
depending object characteristics available resources selected granularity sliding interval sliding run full object 
sliding interval caching significantly reduce network bandwidth consumption start delay subsequent accesses 
cached portion dynamically updated playback sliding interval caching involves high disk bandwidth demands worse case double disk due concurrent read write operations 
chen proposed shared running buffer srb approach argues falling price memory possible allocate memory buffers accommodate media data avoiding intensive disk read write 
effectiveness sliding interval caching diminishes increase access intervals 
access interval object longer duration playback algorithm degenerated full object caching 
address issue preferable retain cached content relatively long time period 
caching algorithms discussed rest section fall category 
prefix caching algorithm caches initial portion media object called prefix proxy 
receiving client request proxy immediately delivers prefix client fetches remaining portion suffix server relays client see fig 

proxy generally closer clients origin server start delay playback remarkably reduced 
cached prefix current playback prefetched 
snapshot prefix caching smoothing 
ensure discontinuity free playback start delay proxy store prefix length max dmax dmax maximum delay server proxy 
cache space abundant proxy proxy caching media streaming internet devote space assist performing smoothing rate vbr media 
smoothing cache proxy prefetch large frames advance burst absorb delay jitter bandwidth fluctuations server proxy path 
delay prefetching prefix caching 
similar sliding interval caching content smoothing cache dynamically updated playback 
purposes different improve cache hit subsequent requests facilitate smoothing 
segment caching segment caching generalizes prefix caching paradigm partitioning media object series segments differentiating respective utilities making caching decision accordingly see fig 

various segment caching algorithms proposed literature employing different segmentations utility calculations 
wu suggested grouping frames media object variable sized segments length increasing exponentially distance start media size segment consists frames 
motivation proxy quickly adapt changing access patterns cached objects discarding big chunks needed 
utility segment calculated ratio segment frequency distance segment favors cache initial segments higher access frequencies 
chen argued predefined segment length favorable caching initial segments best strategy reducing network traffic 
suggested postponing segmentation late possible called lazy segmentation allowing proxy collect sufficient amount access statistics improve effectiveness 
cached segments 
illustration segment caching 
salient feature segment caching support vcr operations random access fast forward rewind 
example proposed cache key segments media object called hotspots identified content providers 
client requests object proxy delivers hotspots provide overview stream client decide play entire stream quickly jump specific portion introduced hotspot 
furthermore fast forwarding operations corresponding hotspots delivered displayed portions skipped 
load server backbone network greatly reduced client important segments media object 
rate split caching aforementioned caching algorithms partition media object time axis rate split caching partitions media rate axis upper part cached proxy lower part remain stored origin server see fig 

type partitioning particularly attractive vbr streaming lower part nearly constant rate delivered backbone network 
qos network resource reservation bandwidth reserved equal peak rate stream caching upper part proxy clearly reduces rate variability improves backbone bandwidth utilization 
critical issue select cut rate equivalently size upper part caching 
zhang studied impact cut rate single stream empirical evaluation significant bandwidth reduction achieved reasonably small cache space 
formulated multiple stream case knapsack problem constraints disk bandwidth cache space developed heuristics caching popular objects caching high bandwidth reduction 
cached proxy cut rate 
illustration rate split caching 
summary comparison tab 
summarizes caching algorithms reviewed homogeneous clients 
features metrics provide general guideline algorithm selection choice specific streaming system largely depends number practical issues particular complexity implementation 
fact simple algorithms employed commercial systems built prototypes practically demonstrated viability superiority intelligent algorithms lazy segmentation 
proxy caching media streaming internet sliding interval prefix segment rate split caching caching caching caching cached portion sliding intervals prefix segments portion higher rate vcr support disk high moderate moderate moderate resource disk space low moderate high high demand sync overhead bandwidth low moderate high high performance reduction high moderate moderate moderate improvement start latency reduction high high high moderate reduction request run 
assume initial segment cached 
table 
comparison caching algorithms homogeneous clients addition emphasize algorithms necessarily exclusive combination may yield better performance 
example segment caching combined prefix caching segment reduce start latency vcr random playback key segment 
combination conventional data caching algorithms examined 
stream caching heterogeneous clients owing diverse network models device configurations clients proxy quite different requirements media object terms streaming rates encoding formats 
accommodate heterogeneity straightforward solution produce replicated streams different rates formats targeting subset clients 
widely commercial streaming system storage bandwidth demands approach prohibitively high 
alternative media form lower rate different encoding format demand fashion 
intensive computation overhead transcoding prevents proxy supporting large diverse client population 
efficient approach problem layered encoding transmission 
layered coder compresses raw media object layers significant layer called base layer contains data representing important features object additional layers called enhancement layers contain data progressively refine quality 
client subscribe subset cumulative layers reconstruct stream commensurate capability 
layered caching assumed cached portions semi static completed layers cached 
maximize total revenue developed effective heuristics analytical stochastic knapsack model determine cache content 
model client population distribution capacities known priori 
layered streaming dynamic conditions rejaie studied segment cache replacement policies achieve efficient utilization cache space available bandwidth see fig 

main objective deal congestion problem individual clients 
proxy keeps track object layer basis 
quality cached layers lower maximum deliverable quality interested client proxy sends requests server missing segments sliding prefetching window 
cache replacement victim layer identified cached segments flushed tail sufficient space obtained 
critical drawback existing layered streaming systems number layers pretty small typically adaptation granularity remains coarse 
fortunately development coding area demonstrated possibility fine grained post encoding rate control 
example mpeg fine grained scalable fgs coder coding generates embedded streams containing partitioned specific rate 
narrowband clients proxy reduce streaming rate filter wideband clients proxy fetch uncached portion higher order server assemble cached portion generate high rate stream 
illustrated fig 
available bandwidth client fully utilized importantly filtering assembling operations fgs done fast response 
envision fgs streaming caching promising solution media internet comprising highly heterogeneous systems 
caching algorithms proposed minimize bandwidth consumption improve client utility 
fgs video facilitates qos quality cache replacement 
example yu showed differentiating utilities different video blocks cache replacement noticeably reduce quality distortion 
advanced scalability tools particular mpeg object scalability investigated 
implemented quality intelligent proxy gateway performs caching filtering functionalities 
acts general broker accommodating heterogeneous user requirements video variations 
addition proxy caching media streaming internet mpeg mpeg standards employed ensure inter operability 
system enables desired need get video services delivers videos users exactly quality expected 
layer layer layer base available bandwidth streaming rate cached proxy available bandwidth 
caching layered streaming 
coarse grained layering fine grained layering 

advanced issues far consider standalone proxy unicast delivery 
significantly reduce access latencies backbone bandwidth demands scalability robustness simple architecture restricted 
discuss effective enhancements multicast proxy cooperation address role proxy popularized overlay communication paradigms 
combining proxy caching multicasting caching multicasting explores temporal locality client requests 
specifically allows media server accommodate concurrent client requests shared channels batching patching periodic broadcast 
multicast delivery suffers important deficiencies 
save bandwidth better accommodate requests multicast channel large batching patching window leads long start latencies 
second ip multicast enabled virtually local area networks deployment global internet remains limited scope reach 
multicast streaming protocol geographically dispersed servers clients 
interestingly deficiencies alleviated proxies 
specifically request instantaneously served cached prefix waiting data multicast channel proxies bridge unicast networks multicast networks employing unicast server proxy delivery batching patching local accesses 
wang derived optimal length prefix cached typical multicast protocols showed careful coupling caching multicasting produce significant cost savings unicast service ip multicast supported local networks 
cooperative proxy caching general proxies grouped achieve better performance independent standalone proxies 
specifically group proxies cooperate increase aggregate cache space balance loads improve system scalability 
typical cooperative media caching architecture middleman operates collection proxies scalable cache cluster 
media objects segmented equal sized segments stored multiple proxies replaced granularity segment 
local proxies responsible answer client requests locating relaying segments 
note cooperative web caching critical issue efficiently locate web pages minimum communication costs proxies 
major concern cooperative media caching bandwidth consumption streaming objects orders magnitude higher object indexing discovering 
consequently middleman centralized coordinator works keeping track cache states 
hand segment caching different proxies facilitates distribution balance proxy loads incurs significant amount overhead switching proxies reconstruct media object 
reduce effects achieve better load balance fault tolerance suggested data layout partitions media object segments increasing sizes stores copies popular segments guarantees copy stored segment 
streaming caching overlay networks far focused client server paradigm media streaming proxies act intermediaries 
generalizing proxy functionalities host shift system popularized overlay communication paradigms peer peer communication application layer multicast 
pioneering efforts overlay streaming demonstrated superior scalability deployability overlay systems example experimental overlay streaming software attracted distinct user terms unique ip addresses simultaneously proxy caching media streaming internet online 
enormous buffer capacities distributed hosts enable efficient client side caching sharing improve content availability support asynchronous streaming 
aware contrast reliable dedicated servers proxies loosely coupled autonomous hosts easily crash leave notice refuse share data 
media playback lasts long time consumes huge resources believe dedicated proxies play important role building high quality media streaming systems particular strategically placed proxies may effectively assist construction maintenance large scale overlays 
hand may leverage overlay paradigm proxy design 
example guo suggested proxy clients structured peer peer system collaboratively serve local streaming requests 
focused local area collaboration 
ip extended level streaming overlay called cooperative proxy client caching system 
cluster proxies forms overlay wide area networks proxy collaborates local client caches form local overlay 
overlays complement proxy level overlay provides dedicated storage reliable service local overlay provides scalable storage caching reduces load proxy 
embeds efficient indexing searching algorithm video contents cached different proxies clients signature verification mechanism effectively identify block malicious clients 
effective multicast delivery local regions reduce cost system 

summary proxy caching effective means reduce access latencies resource consumptions networked applications 
due unique features media objects huge size high bandwidth demand number novel streaming caching solutions reported literature 
article serves pioneer survey field means covers aspects 
plenty research issues addressed caching wireless mobile internet large scale dynamic overlays advanced video coding indexing schemes multiple description coding mpeg standards security privacy cached media objects name 
envision streaming media caching remains fertile area theoretical practical solutions listed problems urged rising demands ubiquitous multimedia services world 
chen shen wee zhang 

designs high quality streaming proxy systems 
proceedings ieee infocom hong kong 
tewari vin dan sitaram 

resource caching web servers 
proceedings spie acm conf 
multimedia computing networking mmcn san jose ca 
sen rexford towsley 

proxy prefix caching multimedia streams 
proceedings ieee infocom new york ny 
wu yu wolf 

segment proxy caching multimedia streams 
proceedings world wide web conference www hong kong 
ortega 

scalable proxy caching video storage constraints 
ieee journal selected areas communications vol 
pp 
sep 
ali liu hsu 

proxy servers scalable interactive video support 
ieee computer 
zhang wang du su 

video staging approach video delivery wide area networks 
ieee acm transactions networking 
liu chu xu 

proxy cache management fine grained scalable video streaming proceedings ieee infocom hong kong 
tang zhang 

streaming media caching algorithms transcoding proxies 
proceedings st international conference parallel processing icpp 
reisslein ross 

distributing layered encoded video caches 
ieee transactions computers pp 

rejaie yu handley estrin 

multimedia proxy caching mechanism quality adaptive streaming applications internet 
proceedings ieee infocom tel aviv israel 
ramesh rhee guo 

multicast cache mcache adaptive zero delay video demand service 
proceedings ieee infocom anchorage ak 
wang sen adler towsley 

optimal proxy cache allocation efficient streaming media distribution 
proceedings ieee infocom new york ny 
proxy caching media streaming internet acharya smith 

middleman video caching proxy server 
proceedings th international workshop network operating systems support digital audio video nossdav 
guo suri zegura 

rainbow caching token schemes scalable fault tolerant stream caching 
ieee journal selected areas communications pp 

xu bhargava 

peerto peer media streaming 
proceedings ieee international conference distributed computing systems icdcs wien austria 
jin bestavros 

cache relay streaming media delivery asynchronous clients 
proceedings th international workshop networked group communication ngc boston ma usa 
padmanabhan wang chou sripanidkulchai 

distributing streaming media content cooperative networking 
proceedings th international workshop network operating systems support digital audio video nossdav miami fl usa 
cui li nahrstedt 

ostream asynchronous streaming multicast application layer overlay networks 
ieee journal selected areas communications pp 

guo chen ren chen jiang 

prop scalable reliable assisted proxy streaming system 
proceedings ieee international conference distributed computing systems icdcs tokyo japan 
hofmann ng guo paul zhang 
caching techniques streaming multimedia internet 
technical report bell labs 
chen shen yan basu zhang 

srb shared running buffers proxy exploit memory locality multiple streaming media sessions 
proceedings th ieee international conference distributed computing systems icdcs 
zhang liu li 


driven overlay network live media streaming 
technical report chinese university hong kong 
ip liu lui 
cooperative caching system demand media streaming 
technical report chinese university hong kong 
yu zhang zhu zhang 

qos adaptive proxy caching multimedia streaming internet 
ieee trans 
circuit system video technology 
sz 

quality intelligent proxy gateway 
em technical reports institute information technology university klagenfurt tr 
sz 

architecture quality intelligent proxy mpeg videos 
proceedings acm world wide web conference www budapest hungary 
sz 

replacement strategies quality video caching 
proceedings ieee international conference multimedia expo icme lausanne switzerland 
