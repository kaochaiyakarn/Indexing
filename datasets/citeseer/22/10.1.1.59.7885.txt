real time hierarchical pomdps autonomous robot navigation panos technical report ics tr institute computer science foundation research technology forth box heraklion crete greece january proposes new hierarchical formulation pomdps au robot navigation solved real time memory efficient 
referred robot navigation hier pomdp rn hpomdp 
rn hpomdp utilized unified framework autonomous robot navigation dynamic environments 
localization planning local obstacle avoidance 
rn hpomdp decides time step actions robot execute intervention external module obstacle avoidance localization 
approach employs state space action space hierarchy effectively model large environments fine resolution 
notion pomdp introduced 
holds information re motion sensor uncertainty proposed hierarchical structure memory efficient enables fast learning 
rn hpomdp experimentally validated real dynamic environments 
autonomous robot navigation problem studied thoroughly robotics research community years 
contemporary methods robot navigation considerably take account robot motion uncertainty sensor uncertainty 
incorporating uncertainty methods planning crucial performance 
uncertainty cause direct robot executing false actions 
probabilistic methods integrate uncertainty motion planning studied con trast probabilistic methods mapping localization 
introduce hierarchical pomdp hpomdp probabilistic navigation 
hpomdp formulation simultaneously addresses probabilistically aspects navigation motion planning localization local obstacle avoidance 
partially observable markov decision processes pomdp provide math framework probabilistic planning 
pomdps model hidden state robot completely observable maintain belief distribution robot state 
planning pomdps performed belief distribution 
actions dictated pomdp drive robot goal implicitly reduce uncertainty belief 
pomdps successfully meet purpose tractable solve exact methods applied real world environ ments modelled fine resolution 
approximation methods solving pomdps literature applied robotics problems :10.1.1.35.8467:10.1.1.12.7112:10.1.1.12.192
due involved computational com plexity approximation methods deal problems size state space limited thousands states 
result approximation methods model large real world environments fine resolution pomdps mainly high level mission planners 
propose hierarchical representation pomdps au robot navigation rn hpomdp effectively model large real world environments fine resolution 
proposed rn hpomdp solved real time 
utilized unified framework autonomous robot navigation implying external modules drive robot 
rn hpomdp integrates modules localization planning local obstacle avoidance solved line time step decides actual actions robot performs 
section necessary theoretical background pomdps followed formulation element pomdp autonomous robot navigation problem section 
section structure rn hpomdp 
learning planning rn hpomdp sections 
hpomdp approaches currently literature employ state space hierarchy applied high level mission planner action state space hierarchy applied high level robot control dialogue management :10.1.1.12.2140
independently concurrently works come hpomdp applies state space action space hierarchy 
specifically designed autonomous robot navigation preliminary versions hpomdp 
problem term rn hpomdp offers specific advantages approaches mentioned 
comparison rn hpomdp previously mentioned approaches section 
ex results section shown applicability rn hpomdp autonomous robot navigation large real world dynamic environments humans moving objects effectively avoided robot follows optimal paths reach destination 
con directions section 
partially observable markov decision processes pomdps pomdps model agent interacting synchronously environ ment 
agent takes input state environment generates output actions affect state environment 
pomdp framework system acting world guaranteed time know state world state environment occupies 
states partially observable 
formally pomdp tuple finite set possible states environment agent occupy partially observable 
finite set actions 
finite set observations 
state transition function giving state agent action probability distribution states 
probability state agent starts state takes action 
distribution state space depends current state action pair previous state action pairs 
requirement ensures markov property process 
reward function giving expected immediate reward gained agent action state 
observation function giving state agent action probability distribution observations 
probability observing state action 
belief state pomdp agent composed components state estimator com ponent policy component 
state estimator component maintains times belief state bt agent 
belief state discrete prob ability distribution set environment states representing state agent belief currently occupying state 
bt probability agent state time pt 
set possible belief states state estimator updates belief state agent time executes action action executed observation perceived explained section 
policy component maps belief state optimal action explained section 
belief update state estimator component pomdp updates belief state agent time executes action 
belief state agent time bt compute belief state time bt transition process agent occupies state executes action perceives observation belief agent resulting state derived bt bt bt bt bt bt bt bt bt bt bt bt bt essence equation evaluates probability state agent belief state bt executed action perceived observation predefined observation transition functions pomdp respectively 
bt normalizing factor equal total probability perceiving observation previous belief state agent action executed bt solving pomdp bt bt solving pomdp amounts computing optimal policy 
policy mapping specifies action agent execute possible state occupy 
pomdp formulation true state agent occupies completely known agent maintains belief possible states 
computed policy provides mapping belief states actions 
optimal action executed agent occupies state st maximum expected accumulated reward st discount factor determines important rewards robot receive 
zero robot maximize reward receive time step 
expected accumulated reward computed specific number steps finite horizon case agent reaches goal state infinite horizon case 
function maps state belief corresponding expected accumulated reward called value function 
step optimal value function constructed iteratively value iteration 
case markov decision processes mdps agent state fully observable step optimal value function formulated max vt pomdps agent state partially observable value function defined belief state single state mdps 
pomdps step optimal value function max set possible belief states 
vt observed equation defined transition reward functions replaced functions respec tively 
transition reward functions defined belief state single state true state agent completely known 
new functions defined 
iterative construction optimal value function set possible belief states extremely computational expensive procedure 
shown finding exact solution pomdp infinite horizon intractable 
number techniques proposed approximating value function 
approximation methods solving underlying fully observable markov decision process mdp :10.1.1.35.8467
approximation methods state space compression belief compression point value iteration pomdp solved sampled set belief points :10.1.1.12.7112
commonly mdp heuristics approximating value function state mls heuristic qmdp approxi mation 
mls heuristic solves underlying mdp state highest assigned probability 
value function max vt qmdp method solves underlying mdp defining functions qt vt optimal value function determined max qt approximation methods mentioned applied suc problems states 
nav problem realistic environments problem considered orders magnitude larger approximation methods handle hierarchical representation pomdps robot navigation proposed 
formulation pomdps autonomous robot navigation problem formulation pomdps autonomous robot navigation unified framework 
pomdp decides actions robot perform reach goal robustly tracks robot location probabilistic manner 
interested dynamic envi ronments pomdp performs obstacle avoidance 
functionalities carried intervention external module 
elements pomdp instantiated follows set states state corresponds discrete entry cell environment occupancy grid map orientation angle robot respect global system 
set actions consists possible rotation actions termed action angles 
discretization robot orientation angles action angles depends number levels pomdp hierarchy see section 
set observations observation set element pomdp assists localization robot belief update action taken 
set observations instantiated output iterative dual correspondence idc algorithm scan matching 
time step observation obtained feeding idc current scan robot scan envi ronment robot operates 
idc requires estimate robot position current scan obtained robot position performed action 
position taken state robot belief state 
reason able assume robot move far previous state single time step 
output idc algorithm dx dy estimated location provided certain limits 
output idc algorithm discretized set observations remains small manageable 
reward function proposed pomdp unified frame robot navigation provide actual actions robot perform carry local obstacle avoidance moving objects reward function updated time step 
reward function built updated time step reward grid maps static dynamic 
defined grid map environment analogy 
cells corre sponds specific area environment discretization value associated cell represents reward assigned robot specific cell 
static built calculating distance cell goal position incorporating information cells belonging static obstacles 
dynamic responsible incorporating model information current state environment objects moving unmapped objects 
implementation robot perceives envi ronment horizontal laser scans 
time step current laser scan detect location objects map 
location detected objects form dynamic corresponding cell values zeroed 
superimposing static dynamic provides reward function updated time step 
noted choice including reward function information moving objects alleviated need modelling moving objects observations 
modelling position moving objects observations increase dramatically size ob equal size grid modelled environment 
transition observation functions initially defined motion model robot learned explained section 
observations defined depend robot motion action executed observation function defined motion model 
robot navigation hierarchical pomdp rn hpomdp studied approaches proposed theocharous pineau :10.1.1.12.2140:10.1.1.13.3361
approach hpomdp developed independently concurrently approaches pre versions 
pomdp solution methods suffer curse dimensionality curse history :10.1.1.12.7112
applying state space action space hierarchy rn hpomdp harnessed 
structure rn hpomdp learning planning rn hpomdp sections 
detailed comparison approach approaches literature section 
rn hpomdp structure rn hpomdp built automated procedure input map environment desired discretization state action space 
map environment probabilistic grid map obtained desired discretization cad map 
determining number levels hierarchy rn hpomdp rn hpomdp structure built decomposing flat pomdp large state action space multiple pomdps significantly smaller state action spaces 
levels bottom level pomdps composed states actions coarse discretization represent actual state robot occupies actual action robot perform 
termed states actions 
process building hierarchical structure performed top approach 
number levels hierarchical structure determined desired discretization action angles orientation angles discretization rn hpomdp structure 
discretization orientation action angles chosen rn hpomdp structure designer choice compromising affect performance rn hpomdp 
desired discretization action angles orientation angles number levels rn hpomdp structure log 
explained sections top level rn hpomdp discretization angles subsequent level discretization doubled 
number levels hierarchical structure log ratio top level discretization desired discretization plus level top level 
number levels rn hpomdp structure conjunction desired discretization state space affects size top level pomdp effect performance rn hpomdp time complexity explained sections 
choice number levels rn hpomdp structure considering desired discretization state action space resulting size top level pomdp 
construction top level rn hpomdp top level hierarchical structure composed single pomdp coarse resolution 
represent environment small number states 
grid resolution top level states equal desired discretization rn hpomdp structure number levels structure 
tion angle robot action angles discretized coarse resolution represent basic directions 
total number states top level pomdp equal number states corresponding flat pomdp 
num ber states top level pomdp reduced coarser grid resolution coarser resolution orientation angle compared corresponding flat pomdp respectively 
summarize top level composed single pomdp predefined discretization orientation action angles state space size top level pomdp variable dependent tion corresponding flat pomdp number levels hierar structure 
number levels hpomdp structure ensures size top level pomdp remains small 
construction intermediate levels rn hpomdp subsequent levels hpomdp composed multiple pomdps representing small area environment specific range orientation angles 
actions intermediate level pomdp subset actions corresponding flat pomdp 
detail state top level pomdp corresponds pomdp immediate level go hierarchical structure 
pomdp intermediate level states represent grid locations environment resolution current intermediate level 
going hierarchical structure grid resolution level pomdp twice resolution previous level 
top level state corresponds specific grid location decomposed represented immediate level pomdp area cells double resolution top level resolution 
orientation angle decomposition going hierarchical structure resolution orientation angle doubled 
resolution orientation angle increased go hierarchical structure range possible orientation angles represented intermediate level pomdp 
dramatically increase size state space state space hierarchy decomposition 
depicts decom position top level state lower level states 
top level state corresponds pomdps level decomposing location top level state locations orientation ranges denoted shaded region circles pomdp 
state decomposition contin ues lower levels desired discretization environment reached 
choose pomdps represent grid location different range orientation angles 
range orientation angles represented intermediate level pomdp expressed terms orientation angle previous level state decomposed equal current intermediate level 
expression range orientation angles intermediate level pomdp distinct orientation angles 
example state top level pomdp orientation angle range orientation angles level equal 
mentioned earlier angle resolution top level equal level double resolution range orientation angles represented distinct orientation angles 
shown grid location represented top level state decomposed pomdps represents different range possible orientation angles 
consequently size state space intermediate level pomdp constant equal possible orientation angles represents area grid locations 
easily deduced expression determines range orientation angles intermediate level pomdp grid location represented state correspond level pomdps 
action angle decomposition action angles decomposed top level pomdp inter mediate level manner orientation angles 
resolution action angles level resolution orientation angles 
equal result top level state de composed multiple pomdps different range orientation angles different range action angles 
range action set equal ap ap ap previous level action current intermediate level 
action angles set composed distinct actions expression 
construction bottom level rn hpomdp procedure described previous section built intermediate levels hierarchical structure bottom level reached 
bottom level pomdps state action space discretized desired resolution flat pomdp discretized 
bottom level composed multiple pomdps having properties intermediate levels pomdps grid location bottom level pomdps represent overlapping region overlapping regions required able solve bottom level pomdps border location states 
table summarizes properties rn hpomdp structure 
pomdp rn hpomdp described previous section cope com putational time requirements address memory requirements 
flat pomdp require hold transition matrix size observation matrix size size state space action space respectively flat pomdp 
size observation space flat pomdp rn hpomdp observation space hierarchy 
rn hpomdp structure requires hold transition observation matrices pomdps levels 
seen table number table properties rn hpomdp structure levels 
top level intermediate level bottom level pomdps size range orientation angles resolution orientation angles size range action angles ap ap ap ap resolution action angles pomdps level large dependent size action space state space 
consequently thought pomdp observation trans lation matrix small total memory requirements extremely large 
rn hpomdp larger memory requirements flat pomdp flat pomdp memory requirements hard manage large environments 
reason notion pomdp introduced 
transition observation matrices hold probabilities carry infor mation regarding motion sensor uncertainty 
formulation autonomous robot navigation problem pomdps described section transition observation probabilities action obser vation depend relative position orientation robot 
transition probability robot state new state performed action dependent action robot executing action transition probability state resulting state defined relatively initial state probability robot observes feature state performs action defined manner transition probabilities set features result scan matching algorithm laser scan actual scan robot perceived cf 
section 
perceived features dependent motion robot action performed 
built defining small state space defined square grid implementation representing possible locations robot orientation angles robot assigned flat pomdp 
center location state space represents invariant state sr robot 
action observation spaces defined manner defined corresponding flat 
requires hold transition observation matrices size respectively 
size matrices dependent size set actions observations number levels hierarchy number levels defines discretization robot orientation angle 
obvious matter big environment modelled rn hpomdp allows reasonably sized matrices depending choice easy maintain learn 
transition observation probabilities pomdp rn hpomdp hierarchical structure obtained translating ro transition observation probability distributions current pomdp state space shown 
transfer probabilities performed line pomdp solved robot belief updated 
transition probability pomdp hierarchical structure equivalent transition probability tr sr ar 
result state determined equation xr yr fr translation rotation pomdp transition proba bilities matrix 
states sr decomposed location tion triplets xr yr fr respectively 
action determined ar fr 
manner observation probability pomdp hierarchical structure equivalent observation probability sr zr ar 
observation determined dfr cos fr ar sin fr ar df observations zr decomposed dx dy df dfr respectively observations defined position angle difference laser scans distance dx dy rn hpomdp learning pomdp probabilistic model learning parameters model transition observation matrices crucial performance pomdp model specifically performance keeping track robot true position orientation 
proposed hpomdp structure learning performed pomdp transfers learned parameters hierarchical structure described section 
learning pomdp parameters performed initializing probability matrices adjusting parameters iteratively execution trace composed action observation pairs maximize execution trace obtained model 
baum welch algorithm utilized purpose 
learning performed collecting data execution trace observation action pairs converted observations actions 
conversion performed inverse procedure described section 
consequently learning performed fast small state space 
evaluation learned model order test validity learning procedure set ex periment aiming quantitative evaluation model results learning session specific environments 
learning sessions formed learning session simulated environment ground truth available real environment 
environment chosen experiments forth main entrance hall shown 
experiments execution traces collected robot goes start state goal state 
start goal states different execution trace 
rn hpomdp experiments built discretizing environment cm cells levels hierarchy results discretization step orientation action angles model appropriateness evaluated fitness entropy measures defined fitness ln entropy ln ln 
fitness entropy indicative measures model explains execution trace certain robot position respectively 
baum welch algorithm repeated number epochs converges 
fitness entropy measures graphically shown training epoch 
ideally fitness entropy converge zero sufficiently large number training epochs 
expected convergence zero achieved case learning procedures 
small number epochs fitness entropy converge low values indicating validity learned model 
order provide additional quantitative results model accuracy position orientation accuracy maintaining robot state measured shown table 
peak pomdp belief distribution model estimate robot current state 
observed figures indicate increased accuracy learned model 
simulated environment experiments ground truth avail able position orientation errors measured time step execution start goal points 
real environment experiments distinct robot locations man marked floor forth main entrance hall shown 
robot driven manually accurately possible marked locations marked location set goal position robot reach 
error location orientation robot position executing trace obtained pomdp model marked location reach measured manually accurately possible 
mean position orientation error experiments close discretization pomdp indicated entropy fitness measures learned models 
experiments validated learned pomdp models consistent execution terms maintaining robot belief reaching goal position 
rn hpomdp planning solving rn hpomdp obtain action robot perform solving pomdp level 
intuition rn hpomdp solution obtain coarse path robot follow reach evaluation learned rn hpomdp model 
table position orientation accuracy learned model 
mean error real environment simulated environment deg marked locations environment experimental evaluation rn hpomdp model performed 
goal position refine path subsequent level area robot current position lies 
algorithm implements table details explained 
rn hpomdp planning procedure belief distribution corresponding flat pomdp maintained times 
distribution denoted full belief 
solving pomdp level full belief compressed functions obtain belief distribution pomdp solved 
belief compression performed state abstraction level rn hpomdp structure discretization reduction level compared discretization corresponding flat pomdp 
belief assigned state state coarse discretization level hierarchical structure bottom level correspond average belief corresponding flat pomdp states named state integrated 
belief distribution obtained pomdp normalized solving 
top level pomdp solved function infinite horizon goal state reached 
top level pomdp produces actions actions coarse resolution infer general direction robot follow actual action perform 
action executed ap dictated top level pomdp solu tion determines pomdp immediate level hierarchical structure solved obtain new refined action finer discretization actual action robot perform 
reached goal state top level table rn hpomdp planning ap top level ap ap ap ap full belief pomdp solved level determined function 
function searches level pomdp pomdps level satisfies criteria zero moment full belief distribution area defined candidate pomdp states maximum 
set actions candidate pomdp contains action minimum distance previous level solution action ap 
structure rn hpomdp described section ensures solving intermediate level pomdp action obtained pre vious level refined new action action subset range equal ap ap solution intermediate level pomdp bounded previous level solution 
described procedure continues bottom level reached action refined actual action action robot perform 
robot executes action obtained bottom level pomdp solution observation obtained belief distribution bot tom level pomdp updated 
bottom level pomdps composed actual states actions subsets states actions compose corresponding flat pomdp 
updating belief bottom level pomdp amounts updating specific region full belief 
planning rn hpomdp 
belief distribution bottom level pomdp solved transferred full belief function 
current implementation pomdps levels solved voting heuristic explained section 
inherent feature rn hpomdp structure pomdp solution method 
furthermore pomdp solution method different level hierarchical structure 
complexity analysis complexity analysis follows execution times evaluated pomdp solution exact methods heuristics 
voting mls heuristic complexity assumed heuristic solving pomdp 
assist comparison rn hpomdp hierarchical approaches literature mentioned heuristics 
mentioned implementa tion voting heuristic solve pomdps levels 
approximate solution flat pomdp solution solved mls voting heuristic time complexity single step pomdp solution intractable dealing real world environments acceptable resolution having states application 
obtaining solution rn hpomdp dramatically improve computation time required 
referring table properties rn hpomdp structure detailed solution top level pomdp requires computational time number levels hierarchical structure 
solution intermediate levels pomdps requires time size state space action space constant predefined 
bottom level pomdp solution state space action space constant predefined 
total computational time required solve rn hpomdp complexity top level pomdp 
top level pomdp state action space size remain small regardless size environment increasing number levels hierarchical structure 
exact solution solving pomdp exactly single step time time complexity vt vt number linear components required represent value function time 
size value function time equal vt vt explained previously time complexity solving rn hpomdp equal time complexity solving top level pomdp 
top level pomdp hierarchical structure reduced state space equal number levels 
furthermore action space constant equal 
time complexity size rn hpomdp solved exactly vt vt vt respectively 
apart notable reduction computation time due reduced size state action space noted mentioned times single time step 
infinite horizon solution flat pomdp require computations repeated number time steps goal point reached dependent number states flat pomdp 
rn hpomdp case top level pomdp solved infinite horizon number time steps goal point reached dependent number states top level pomdp 
complexity analysis may conclude proposed approach takes care curse dimensionality curse history :10.1.1.12.7112
comparison hpomdp structures section compare rn hpomdp hpomdp approaches literature terms time complexity solving hpomdp state space action space abstraction methodology appli cation framework hpomdp 
comparison rn hpomdp approximation methods solving flat pomdp pre sented 
comparison theocharous approach theocharous approach uses topological map environment state abstraction high levels hpomdp physical meaning environment 
states manually defined represent corridor junction 
hand rn hpomdp built automated procedure requires input probabilistic occupancy grid map cad map environment 
theocharous hpomdp high level planner pomdp solved obtain shortest path goal position 
result state space resolution set action space resolution approach models environment fine resolution cm action resolution discretized number levels hierarchy 
rn hpomdp global planner solved time step provide actual actions robot perform intervention intermediate modules 
rn hpomdp integrates modules planning localization local obstacle avoidance 
theocharous approach uses mls heuristic time complex ity see see hpomdp constructed 
time required solve rn hpomdp depth tree maximum number entry states state 
size action space added time complexity theocharous approach comparison complexity flat pomdp approach direct approach constant equal 
complexity reduction approach signifi cantly greater dependent quality measure hierar structure 
comparison pineau approach pineau hpomdp approach actions grouped actions called subtasks :10.1.1.12.2140
subtasks defined manually state abstraction performed automatically 
states reward value executing action belongs predefined subtask clustered 
observation abstraction performed eliminating observations zero probability state clusters actions belonging specific subtask 
planning pineau hpomdp involves solving pomdp defined action subtask 
pomdps solved exact pomdp solution method 
hpomdp proposed pineau guaranteed reduction action space state space dependent action tion defined manually 
authors performed experiments real simulated problems high level behavior control 
clear approach state abstraction applied problem autonomous robot navigation context defined importantly perform efficiently approach guaranteed reduction state space equal hand authors state approach performs terms state space abstraction :10.1.1.12.2140
hpomdp proposed pineau real world application high level robot control dialogue management :10.1.1.12.2140
application modelled states observations actions categorized subtasks 
problems encountered approach orders magnitude larger solved real time 
approximation methods solving flat pomdps short discussion performance approximation methods solving flat pomdps follows section 
discussion allow elaborate performance rn necessitate need proposed hierarchical structure considering autonomous robot navigation problem 
review approximation methods solving pomdps 
complexity methods reviewed seen table 
furthermore methods approximation point value itera tion pbvi method :10.1.1.12.7112
time complexity pbvi vt size finite set belief points remains constant iterations 
summarize time complexity approximation methods best case polynomial size pomdp 
mentioned meth ods applied problems pomdp comprised table complexity solving pomdp approximation methods reviewed 
approximation method complexity mdp qmdp fast informed bound umdp vt vt grid interpolation extrapolation size finite set grid points update value updates computational cost evaluating interpolation extrapolation rule points cases cost eliminated 
states 
problem consider consists orders magni tude larger state space 
result reduction state space rn hpomdp offers reduction action space crucial performance 
furthermore proposed hierarchical structure restricted specific method solving underlying pomdps combina tion approximation method solving flat pomdp proposed hierarchical structure dramatically improve performance 
computational time comparison theoretical comparison previous section comparison purposes provide cpu times required solve rn hpomdp theocharous pineau hpomdp approaches tables 
stressed times referring table computation time required solve hpomdp compared approaches 
pomdp size cpu time sec theocharous pineau pineau approach ones initial version hpomdp action space hierarchy :10.1.1.13.3361
noted cpu times mentioned ones authors state obtained computers power 
point theocharous ap proach solved mls heuristic approach pomdps solved voting heuristic computational complexity mls heuristic 
pineau hpomdp solved exact methods 
regardless mentioned differences superior computational performance approach easily extracted tabulated results size problem orders magnitude larger 
results rn hpomdp tested extensively real world environment 
robot set operate hours forth main entrance hall shown 
environment modeled rn hpomdp table computation time required solve rn hpomdp varying grid size levels 
grid size pomdp size cpu time sec cm cm cm cm cm cm cm cm cm cm cm cm table computation time required solve rn hpomdp varying number levels grid size cm cm 
levels pomdp size cpu time sec forth main entrance hall 
size 
rn hpomdp built levels 
experiments performed dynamic environment people moving 
cases proposed navigation model shown robust behavior reaching assigned goal points avoiding humans objects 
sample path robot followed reach goal performed local obstacle avoidance avoid human shown 
avoiding human reach goal position 
robot track marked black dots human track marked grey dots 
introduced new approach hierarchical pomdps 
proposed approach designed specifically autonomous robot gation problem termed robot navigation hpomdp rn hpomdp 
rn hpomdp utilized unified model caters planning local ization local obstacle avoidance 
formulated manner depend external modules localization local obstacle avoidance 
best knowledge time pomdp provide actual actions robot executes high level mission planner 
rn hpomdp offers significant state space action space reduction compared hierarchical approaches liter 
furthermore state space action space reduction guaranteed dependent environment robot operates 
additionally rn hpomdp conjunction approximation method solving flat pomdps improve performance 
novel approach proposed storing model parameters pomdp 
rn hpomdp experimentally validated real world environment 
involves integrating rn hpomdp prediction motion humans obstacles perform efficient effective obstacle avoidance predictive manner 
furthermore application rn hpomdp multi robot navigation cooperation examined 
bibliography anthony cassandra leslie pack kaelbling james kurien 
acting uncertainty discrete bayesian models mobile robot navigation 
proceedings ieee rsj international conference intelligent robots systems 

predictive autonomous robot navigation 
pro ceedings ieee rsj international conference intelligent robots sys tems iros 

predictive control robot velocity avoid ob dynamic environments 
proceedings ieee rsj international conference intelligent robots systems iros 
gordon pineau thrun :10.1.1.12.7112
point value iteration time algorithm pomdps 
proceedings international joint con ference artificial intelligence ijcai 
hauskrecht 
planning control stochastic domains im perfect information 
phd thesis mit 
hauskrecht 
value function approximations partially observable markov decision processes 
journal artificial intelligence research 
leslie pack michael littman anthony cassandra 
planning acting partially observable stochastic domains 
artificial intelligence 
vijaya kumar 
path planners wave expansion neural network 
robotics autonomous systems 
khatib sean quinlan david williams 
robot planning control 
robotics autonomous systems 
sven koenig reid simmons 
unsupervised learning probabilistic models robot navigation 
proceedings international conference robotics automation pages 
jean claude latombe 
robot motion planning 
kluwer academic publish ers 
michael littman anthony cassandra leslie 
learning poli cies partially observable environments scaling 
proceeding th international conference machine learning pages 
michael littman judy goldsmith martin mundhenk 
compu tational complexity probabilistic planning 
journal artificial intelli gence research 
lu milios 
robot pose estimation unknown environments matching range scans 
journal intelligent robotic systems 
monahan 
survey partially observable markov decision processes theory models algorithms 
management science 
nehmzow owen 
robot navigation real world experiments unmodified large environments 
robotics autonomous systems 
daniel nourbakhsh 
learning probabilistic models decision theoretic navigation mobile robots 
proc 
th international conf 
machine learning pages 
morgan kaufmann san fran cisco ca 
pineau thrun :10.1.1.12.2140
integrated approach hierarchy ab pomdps 
technical report cmu ri tr carnegie mellon university 
pineau gordon thrun 
applying metric trees belief point pomdps 
neural information processing systems nips 
pineau montemerlo pollack roy thrun 
robotic assistants nursing homes challenges results 
robotics autonomous systems 
poupart boutilier 
value directed compression pomdps 
neural information systems nips 

poon 
fast heuristic algorithm decision theoretic planning 
master thesis hong kong university science technology 
roy pineau thrun :10.1.1.13.3361
hierarchical approach pomdp planning execution 
workshop hierarchy memory reinforcement learning icml 
roy gordon 
exponential family pca belief compression pomdps 
neural information systems nips 
simmons sven koenig 
probabilistic robot navigation partially observable environments 
proceedings international joint confer ence artificial intelligence pages 
spaan vlassis 
point pomdp algorithm ro bot planning 
proceedings ieee international conference robotics automation icra 
theocharous 
hierarchical learning planning partially observ able markov decision processes 
phd thesis michigan state university 
thrun beetz burgard cremers dellaert fox rosenberg roy schulte schulz 
prob algorithms interactive tour guide robot minerva 
international journal robotics research 

