hierarchical time series clustering data streams pedro rodrigues jo gama jo pedro computer science department faculty science university porto artificial intelligence computer science laboratory university porto dcc fc pt pt 
presents time series clustering system incrementally constructs hierarchy clusters 
online divisive agglomerative clustering system incremental implementation divisive analysis clustering correlation timeseries similarity measure 
system tests existing clusters descending order diameters looking possible binary split 
cluster deserves division system searches possible aggregation clusters 
time step splitting aggregation occur 
main features include splitting criteria supported hoeffding bound stopping criteria divisive coefficient agglomerative phase decreases number unneeded clusters divisive coefficient measures amount divisive structure 
preliminary results show competitive performance clustering time series compared simple batch divisive analysis clustering algorithm 
days information grown importance web spread communications improved global network interaction 
facing feature efficient information extraction data major goal sorts applications 
usual problems include classification examples regression predictors pattern recognition rule extraction data clustering example clustering time series clustering 
aim study time series clustering meaningful try cluster subsequences time series 
traditional data mining knowledge extraction problems gathering data difficult tasks efficient performance due lack information 
nowadays face opposite situation 
fact rarely amount data available source huge traditional batch systems successive passes data prove efficient 
real world applications data flows continuously part ongoing msc thesis informatics university porto data stream high speed producing examples time usually time 
context quicker responses usually requested 
problem address hierarchically cluster fixed number time series new values arriving continuously time 
address problem adding new time series description 
time series clustering system incrementally constructs hierarchy clusters divisive point view 
related frequent data available learning consists set variables time series characterization feature 
algorithms determine variable importance minimize cost processing variables time new example learned 
approach group variables clusters cluster centroid original variables 
apply clustering variables examples change fung definition clustering procedure definition 
set time series nominal variables vj set items representing set points xi goal clustering divide clusters ck way variables belonging cluster similar variables different clusters 
result procedure injective attribution variable vj cluster ck 
known solving clustering problem equivalent find global optimal solution non linear optimization problem np hard forcing need apply optimization heuristics 
clearly divide clustering algorithms major paradigms parametric non parametric approaches 
parametric approaches parametric procedures tend minimize cost function reconstructive models assume instances observations set unknown distributions generative models 
examples generative models gaussian mixture model expectation maximization em data assumed appear different gaussian distributions means fuzzy clustering clusters boundaries defined extending square error criterion fuzziness concepts 
hand better known reconstructive models means medians instances assigned clusters minimizing simple euclidean distance instances clusters centers means medians instances belong simulating annealing estimates relevant expectation values variables reducing global solution search space optimization problem 
non parametric approaches non parametric models usually set basis dissimilarities elements cluster 
called hierarchical models methods agglomerative divisive 
agglomerative methods 
start clusters variables build tree successive join nearest clusters 
hand divisive methods 
diana start big cluster successive splits largest cluster dissimilar variable 
diana fully described chapters 
approaches major advantages parametric approaches require user predefined number target clusters assumptions data distribution need explicit representation pair wise dissimilarity matrix 
restrictions measure compute dissimilarities comply distance measures characteristics 
calculations dissimilarity matrix proved perform poorly data set size enlarges overlapping clusters definitions 
hierarchical approaches 
data streams knowledge discovery systems usually constrained limited resources time memory sample size 
traditional applications sample size limitation proves dominant leads overfitting 
nowadays time memory bottleneck machine learning applications mainly 
reason traditional memory models multiple passes data virtually impossible achieve high performances failing adapt high speed production examples 
new approaches process data real time capable gather compact description data time processing example constant time memory 
hierarchical clustering different clustering techniques known literature hierarchical models great versatility require human predefined number clusters parameter 
divisive methods appropriated data stream applications perform top strategy 
diana hierarchical clustering technique constructs hierarchy top large cluster bottom clusters 
initially large cluster contains variables step cluster largest diameter selected divided new clusters clusters contain variable steps 
agglomerative clustering objects possible fusions different objects divisive clustering possibilities splitting data clusters 
avoid considering hypothesis diana uses algorithm sketched fig 

diana splits clusters single objects 
provides divisive coefficient stopping criteria 
divisive coefficient explained 
splitting criteria hierarchical models level hierarchy split means techniques em 
reader note concentrates clustering variables clustering examples 
select cluster ck highest diameter 
find object ck highest average dissimilarity objects ck start new cluster cs group object 
object cs compute di average cs average cs 
find object largest difference dh 
dh average closer group old group move cs 
repeat steps di negative 
cluster ck ck goto fig 
diana global algorithm type relevant models kohonen self organizing maps hierarchical variants proposed 
problem usually arise sort models definition minimum number observations necessary assure convergence 
techniques hoeffding bound applied solve problem fact successfully online decision trees 
online divisive agglomerative clustering section time series clustering system incrementally constructs hierarchy clusters divisive point view 
system tests existing clusters descending order diameters looking possible binary split 
cluster deserves division system searches possible aggregation clusters 
nmin examples splitting aggregation occur 
main features include correlation distance measure splitting criteria supported hoeffding bound stopping criteria divisive coefficient agglomerative phase decreases number unneeded clusters 
fig 
presents global algorithm 
distance measure previously stated dissimilarity matrix needed perform divisive analysis clustering concentrate efforts matrix efficiency 
originally diana uses real dissimilarity timeseries va vb abs vi vi vi time series number examples 
really keep system independence variables distributions want hoeffding bound forward system 
criterion forces evaluated function case distance measure scaled 
goal obtained maintaining maximum minimum values time series 
approach 
correlation time series similarity measure mentioned 
get nmin examples 
update sufficient statistics variables 
compute hoeffding bound 
choose cluster ck descendant order diameters 
cluster ck 
split point goto 
exists cluster ci tested splitting goto 
choose cluster ck order diameters 
cluster ck 
aggregation goto 
exists cluster ci tested aggregation goto 
data goto fig 
global algorithm 
correlation time series calculated corr nab na nb size window compute correlation 
factors compute correlation updated incrementally need sum time series compute sample means sum squared time series sum time series ab 
sufficient statistics needed perform clustering easily updated time step 
dissimilarity variables va va ab va vb corr va vb range 
step dissimilarity matrix cluster ij dt vi vj number time series cluster diana clustering system consider highest dissimilarity time series belonging cluster cluster diameter 
online incremental update system data stream approach achieved incrementally update sufficient statistics needed compute dissimilarity matrix 
nmin examples sufficient statistics time series updated clusters ordered diameters computed previous time step dissimilarity matrix updated needed cluster 
splitting stopping criteria diana splits clusters single objects 
prevent behavior splitting criteria enhanced 

update dissimilarities cluster ck 
choose variables va vb descendant order average dissimilarities 

move va group cs 
goto 
remove va ordered list 
goto 
vi compute di average cs average cs 
di move vi cs 
return 
return fig 
algorithm splitting cluster time time series closer group step diana criteria observed 
purpose hoeffding bound divisive coefficient 
independent observations variable vk mean vk range hoeffding bound states probability true mean variable vk ln hoeffding bound property independent probability distribution generating observations 
divisive coefficient represents strength clustering structure algorithm 
dd diameter cluster time series vi belongs split single variable divided diameter data set 
divisive coefficient cluster definition clust dd scaled distance measure range change step algorithm create group da db vb variable largest average dissimilarity va process ordering variables average dissimilarity getting da db dc 
dk 
hoeffding bound verified state multiple variables clearly dissimilar remaining variables 
cases assign va possible group search split point remaining variables 
process repeated split point 
split point reported usual process splitting performed maintaining assigned variables group 
multiplication introduced achieve measure range equal dissimilarity measure hoeffding bound purposes 
choose cluster ci descendant ck parent 
move va ci ck parent 
delete cluster ci 
exist cluster cj descendant ck parent goto 
return 
return fig 
algorithm split point state closed cluster 
new cluster definition new created splitting decision decide maintain 
decision sets basis quest cluster definition really gathers divisive structure variables trying prevent unneeded clusters 
fig 
presents algorithm 
focus simpler splitting criteria increase performance erasing need multiple calculations dissimilarities 
agglomerative phase split current cluster definition curr search clusters represent structure data 
search clusters ascent order diameters ci smallest remaining test divisive coefficient different cluster definition test clusters descending ci parent aggregated 
lost divisive structure hoeffding bound keep test cluster definition decreasing number clusters assuming previous division longer reflects best divisive structure data 
fig 
presents algorithm 
gather concept drift detection methods improve search changes cluster structure 
experimental results evaluation proposed system tested dataset different time series clean observations missing values willing compare resulting cluster definition clusters described batch divisive clustering algorithm 
dataset global diameter 
batch divisive clustering clearly compare system batch clustering algorithm applied diana system dataset dissimilarity measure correlation 
dendrogram resulting clustering definition left hand side fig 
reveals divisive coefficient measure dc 
results running managed detect effects algorithm resulting dendrogram 
fig 
see sample fig 
evolution cluster definition system produced dendrograms state capability adapt changes time series means dynamically splitting aggregation iterations 
experiments minimum number examples test splitting nmin 
system consecutively splits largest cluster algorithm fig 

example till example divisive coefficient criteria triggers starts checking possible aggregations 
examples algorithm fig 

right hand side fig 
see resulting dendrogram system resulting definition dc 
presents time series clustering system works online 
system hierarchically builds clusters time series divisive point view capable adaptability changes time series means posterior agglomeration 
examples processed arrive single scan data 
system uses correlation similarity measure 
sufficient statistics needed incrementally compute correlation time series maintained updated nmin examples 
system tests existing clusters descending order diameters looking possible binary split 
cluster deserves division system searches possible aggregation clusters 
time step splitting aggregation fig 
diana left right final dendrograms occur 
important feature system dissimilarity matrix updated cluster currently tested erasing unneeded computations 
contributions hoeffding bound decide splitting point divisive coefficient decide system divide aggregate clusters 
experimental results suggest system exhibit dynamic behavior adapting changes time series 
focus simpler splitting criteria increase performance erasing need multiple calculations dissimilarities 
concept drift detection methods implemented improve search changes cluster structure 
agglomeration phase better studied order prevent cyclic behaviors 
important feature clear performance measure enable real comparisons systems 
acknowledgments authors reveal gratitude financial support feder support attributed 
developed context project posi sri 

keogh lin clustering time series subsequences meaningless implications previous research 
proceedings ieee international conference data mining ieee computer society press 
fung comprehensive overview basic clustering algorithms 
fraley raftery clusters 
clustering method answers model cluster analysis 
technical report dept statistics 
university washington seattle 
bezdek pattern recognition fuzzy objective function algorithms new york 
kirkpatrick gelatt vecchi optimization simulated annealing 
science number may 
kaufman rousseeuw finding groups data cluster analysis 
john wiley sons new york 
analysis clustering algorithms 
ng han efficient effective clustering methods spatial data mining 
jarke zaniolo eds th international conference large data bases september santiago chile proceedings los altos ca usa morgan kaufmann publishers 
pampalk widmer chan new approach hierarchical clustering structuring data self organizing maps 
intelligent data analysis 
gratch sequential inductive learning 
proceedings thirteenth national conference artificial intelligence portland aaai press 
webb opus efficient admissible algorithm unordered search 
journal artificial intelligence research 
domingos hulten mining high speed data streams 
proceedings sixth international conference knowledge discovery data mining boston ma acm press 
barbar requirements clustering data streams 
sigkdd explorations special issue online interactive anytime data mining 
hastie tibshirani friedman elements statistical learning data mining inference prediction 
springer verlag 
heckerman meek thiesson accelerating em large databases 
technical report microsoft 

neal hinton view em algorithm justifies incremental sparse variants 
kluwer academic press jordan ed learning graphical models 

kohonen self organizing maps 
rd edn 
volume springer series information sciences 
springer berlin 
villmann mer nyi extensions modifications kohonen som applications remote sensing image analysis 
springer verlag 
hoeffding probability inequalities sums bounded random variables 
journal american statistical association 
gama rodrigues concept drift decision tree learning data streams 
proceedings fourth european symposium intelligent technologies implementation smart adaptive systems aachen germany verlag mainz 
probability random processes 
mcgraw hill 
similarity measures author cocitation analysis information theory 
journal american society information science technology forthcoming 

kernel method hierarchical non hierarchical clustering 
advanced internet classroom 
zhang zha wang clustering time course gene expression data 
pennsylvania state university 
wang wang efficient evaluation composite correlations streaming time series 
proceedings th international conference web age information management china 
castillo gama adaptation drifting concepts 
abreu eds th portuguese conference artificial intelligence lnai springer verlag 
