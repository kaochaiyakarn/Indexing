semi automatic semantic annotations web documents nicola james cordy mich john mylopoulos department information communication technology university trento sommarive povo tn italy nicola mich dit unitn school computing queens university kingston ontario canada cordy cs ca centre information technology university toronto ontario canada jm cs toronto edu 
semantic annotation web documents way semantic web vision reality 
considering scale dynamics worldwide web largest knowledge base built clear afford annotate web documents manually 
propose generic domain independent architecture semi automatic semantic annotation basing lightweight robust techniques proven effective source code processing software analysis field 
demonstrate feasibility method applying annotation documents tourism domain 
results experiment validated stage evaluation scheme 
semantic annotation process inserting tags document assign semantics text fragments allowing create documents processable humans automated agents 
considering scale dynamics worldwide web application traditional natural language processing techniques annotate documents semantically revised 
engineering perspective number requirements important faced designing text processing system leidner boguraev accuracy performance estimated access ability tool retrieve correct answers flexibility robustness features characterize viability system abnormal conditions stability different text types domains scalability space run time limitations overcome data sparseness dependence expensive training resources obstacle porting tool different domain complexity long response time render system unacceptable human users multilinguality independence character encodings lexicographic sorting orders display numbers dates needs ensured 
similar problems faced software analysis field developing tools design recovery source code analysis markup 
reason exploit large heritage gained field developed number techniques enable process billions lines source code 
propose apply methods base new lightweight tool semi automatic semantic annotation web documents 
demonstrate preliminary experiment employment technical solutions domain tourism describe framework evaluate quality annotations 
structured follows section introduces text processing txl section provides details approach section describes setup experiment section presents evaluation framework results experiment section reviews related projects field final section summarizes results outlines directions 
semantic annotation design recovery lightweight method text processing technology proven efficient instrument help software analysis area particular reverse engineering design recovery 
software reverse engineering process identifying engineers software components inter relationships representing entities higher level abstraction nelson 
method combined conceptual modeling source code 
specialization reverse engineering design recovery implies static analysis source code large software system identify entities relationships software design model 
result normally design database source code marked design relationships 
software design recovery highly successful technical business level semantic markup large scale software systems written wide variety programming languages 
interestingly different domains document analysis semantic web design recovery source code pose similar problems need robust parsing techniques real documents match grammars languages written need understand semantics source text semantic model semantic clues drawn vocabulary semantic domain contextual clues drawn syntactic structure source text inferred semantics exploring relationships identified semantic entities properties contexts related entities 
propose source analysis transformation system txl basis new lightweight method sa 
txl allows expressing solutions structural source transformation input output 
structure imposed input specified ambiguous context free grammar 
transformation rules applied transformed results returned text 
txl uses full backtracking ordered alternatives heuristic resolution allows efficient flexible general parsing 
grammars transformation rules specified example 
transformation process txl considered term rewriting functional control 
functional programming control provides abstraction parametrization scoping 
txl allows grammar overrides extend replace modify existing specifications 
grammar overrides express robust parsing technique allow errors exceptions input explained grammar 
overrides express island grammars 
island parsing recognizes interesting structures islands embedded sea uninteresting unstructured background 
txl supports agile parsing customization parse individual transformation task 
simple example txl program realizing island parsing paradigm input sequence items redefine program repeat item redefine items interesting uninteresting define item declaration statement uninteresting define define uninteresting token key txl idiom input item define transform aspect rest input remains rule main replace declaration statement code declaration statement code rule originally txl designed experimenting programming language dialects soon realized useful tasks static www txl ca analysis interpreters preprocessors theorem provers source markup language translation web migration txl successfully applications programs handwritten math recognition document table structure recognition business card understanding 
semantic annotation methodology methodology ls software analysis architecture dean contains passes 
lightweight robust parse get basic structure transformation rules vocabulary structural patterns infer source markup basic facts 
facts externalized database inference 
transformation rules inferences structural patterns infer semantic markup design facts marked source ready design aware transformations 
designed tool performs semantic annotation similar manner fig 
input system consists textual documents conceptual fig 
workflow semantic annotation method ls software analysis system scheme 
conceptual scheme part existing domain ontology 
entities scheme generate tags annotation 
workflow main phases 
phase consists lightweight parsing semantic markup basic entities email web addresses monetary formats date time formats language structures object document paragraph sentence phrase structure 
second phase externalization facts database search engine queries 
transformations third stage implemented tool plan explore technique verify quality automatic annotations improved imposing constraints conceptual scheme 
section explains detail stages algorithm example application tourism domain 
experiment setup prove viability method results preliminary experiment domain travel documents particular ads popular tourist destinations italy fig 
fig 
example announcement web site goal provide users browsing line ads relevant information example location price accommodation availability facilities provided purpose accommodation ads marked domain conceptual model fig 
fig 
conceptual model domain accommodation ads order realistic test generality method restricted constraints proper nouns location dependent phrases vocabulary raw uncorrected text formatting structural cues 
methodology described previous section experiment adopted multi level process fig 
fig 
architecture semantic annotation process architecture explicitly factors reusable domain independent knowledge structure basic entities language structures shown left hand side allowing easy change semantic domain characterized vocabulary conceptual scheme shown right 
way facilitate reusability tool different domains document types 
text parsed sentences text unit basic objects detected 
objects usually described small set patterns reused different domains 
far list objects includes mail addresses web addresses phone numbers dates prices 
instance grammar phone numbers represented way part price grammar tokens number tokens define money amount opt hyphen amount space currency currency opt opt space amount repeat hyphen amount repeat number dot dot opt space currency define phrase grammar block carries structural information delimit text units want markup 
unit short phrase sentence paragraph depending required granularity annotation 
experiments accommodation advertisements sentence grammar text short user interested complete answer 
objects previous stage checking presence category keywords related phrases identified marked 
xml grammar component markup phase grammar tags inserting markup documents grammar xml open tag identifier xml closing tag identifier 
category wordlist domain dependent component including set categories keyword lists corresponding category 
keyword list consists positive markers simply word combination words example information system negative markers 
category positive markers detected text unit sentence current experiment unit annotated category negative markers 
annotated documents provided mapping phase fills database scheme annotations 
domain independent component stage scheme grammar xml grammar 
scheme grammar reading database scheme file xml grammar extracting markups output documents previous stage 
xml markups mapped correspondent fields database 
important emphasize complex text processing objects recognition sentence delimiting phase repeated 
phases perform fast superficial processing simple grammars 
evaluation framework choice evaluation method verify quality automatic annotation additional difficulty 
purpose specially designed steps evaluation framework 
step compared system output directly human annotations 
assume human performance upper bound automatic language analysis 
type evaluation applied large scale obviously afford human annotators tagging gigabytes text 
case take account annotators disagreement order obtain realistic evaluation calibrate system performance relative human performance 
purpose calculated system performance manual annotation performance human annotator 
subtracting difference performances conclude human done tool 
second step check automatic tool increases productivity human annotators 
noted time manual annotation original textual documents compared time manual correction automatically annotated documents 
percentage difference measures shows time saved human annotator assisted tool 
third step compares system results human corrections done previous step 
distinction phase human annotator works directly original document errors items lack attention working document annotated tool easily note defects produces higher quality annotation 
estimate system performance applied metrics definitions provided yang recall precision fallout accuracy error tp tp fn tp tp fp fp fp tn tp tn fp fn calculated measure harmonic mean recall precision measure total number test items recall precision recall precision tp fp fn tn tp number items correctly assigned category true positives fp number items incorrectly assigned category false positives fn number items incorrectly rejected category false negatives tn number items correctly rejected category true negatives 
evaluation human annotation stage evaluation tool human annotators marked sample set advertisements different training set tune tool domain 
tool compared human markers set separately table calibrated definitive table 
table 
system performance semantic category entity recall recall recall precision precision precision avg avg location facility price type term contact table 
calibrating system performance human annotators measure vs tool vs vs tool vs recall precision fallout accuracy error measure order thoroughly compare human system performances necessary observe differences measure aggregate characteristic 
obtained variance leads tool able complete human 
productivity measures stage evaluation compared times spent annotator perform annotation blank page correct system annotation 
results showed tool saved annotator time sample set data 
appropriate interface doing corrections easily time savings significantly greater observed 
evaluation human annotation correcting system third stage gave human annotators advantage correcting automatically marked text create markups compared final human markup original opinion tool table 
table 
system performance manually corrected annotations rome ads rome ads rome ads venice ads measure training set test set test set test set recall precision fallout accuracy error measure comparing results different test sets performance decreases slightly test set recall value changes significantly 
shortcoming explained high dissimilarity documents training documents content structure 
example case location names represented string exact postal address textual description accommodation difficult detect phrases related locations especially experiment sake generality gazetteers 
concluding experimental study say method software design techniques potential 
local knowledge small vocabulary able demonstrate accuracy comparable best heavyweight methods albeit far limited domain 
performance untuned experimental tool fast handling advertisements example second ghz pc 
related development different semantic web applications area intensive research 
review list tools consider methodologies exploited system requirements declared 
attempts allow semantic annotation web documents done shoe system sean enabling web page authors manually annotate documents machine readable metadata 
pioneering tool assisting insert semantic markups manual way ontobroker decker 
tool applied natural language information extraction techniques automatically generate daml annotations web pages 
project karlsruhe university cimiano uses statistical pattern matching techniques automatically discover relevant concepts document 
variety tools going underline projects oriented large scale text markup 
semtag dill application performs automated semantic tagging large corpora 
seeker platform large scale text analysis 
tags large numbers pages terms standard ontology 
centralized application corpus statistics improve quality tags 
far tap knowledge base standard ontology 
tap contains lexical taxonomic information music movies authors sports autos health popular objects 
goal semtag annotator detect occurrence entities web pages 
methodology 
semtag flow consists steps spotting pass documents retrieved tokenized processed find instances approximately kb labels tap knowledge base 
learning pass sample data scanned determine distribution terms 
tagging pass disambiguated record inserted database 
evaluation 
semtag evaluated set web pages tool able generate disambiguate semantic tags approximately judged topic 
experiment human judgments training set algorithm human judgments applied estimate performance 
system realized dual processor ghz machines 
total time taken process web hours 
kim knowledge information management platform kiryakov tool automatic ontology named entities annotation indexing retrieval gate general architecture text engineering university sheffield uses lightweight upper level ontology consisting named entity classes classes properties encoded rdf 
kim knowledge base approximately entities general importance allow information extraction inter domain web content 
methodology 
kim build top gate architecture 
text processing gate fulfilled steps including number nlp techniques tokenization splitting sentences part speech tagging 
semantic gazetteer generate lookup annotations 
ontology aware pattern matching grammars allow precise class information handled rules optimal level generality 
grammars recognize named entities class instance information referring kim ontology knowledge base 
recognized semantic constructions template relation construction performed means grammar rules 
result knowledge base enriched recognized relations entities 
final phase previously unknown aliases entities added knowledge base specific types 
gate ac uk evaluation 
kim tested flat named entities types popov date person organization location percent monetary amounts reporting high accuracy metrics experiment average recall precision 
kim platform requires pentium ghz computer acquire performance rates annotation kb indexing kb storage kb popov 
time grows logarithmically depending size input documents 
kim semtag annotation considered process assigning entities test links semantic descriptions provided ontology focus mainly recognition named entities categorization larger text fragments scope projects 
cream semi automatic creation metadata provides annotation authoring framework integrates learnable information extraction component handschuh 
methodology 
domain ontology basis annotation different types documents 
user define part ontology relevant learning task 
user perform crawl collect necessary documents 
users manually annotate corpus training learner 
text preprocessed annie shallow information extraction system included gate package text tokenization sentence splitting part speech tagging gazetteer lookup named entity recognition 
document corpus processed learning plugin generates extraction rules 
induced rules applied semi automatic annotation 
evaluation 
evaluation provided publications 
tool tried large scale score sheth 
integrates information extraction methods including probabilistic learning knowledge techniques combines results different classifiers 
information extraction community aimed rule learning automating creation extraction patterns previously tagged semi structured documents nobata unsupervised extraction etzioni 
issues address actual application patterns documents ways similar method particular ontology method embley als 
major differences lie implementation method relies primarily regular expressions approach combines high speed context free robust parsing combined simple word search 
similar wrappers approach intended processing preferably semi structured web pages multiple records structured page better annotation results 
wrapper induction methods stalker muslea bwi freitag try infer patterns marking start points fields extract relate 
learning stage methods applied effect quite similar results identifying complete phrases related target concepts 
results achieved fundamentally different way predicting start points phrase parsing advance phrase induction 
biggest advantage wrappers need small amount training data hand strongly rely contextual clues document structure 
case source document reorganized tool retrained newly annotated examples 
contrast method uses context independent parsing require strict input format 
approach fundamentally differs tools uses extremely lightweight robust context free parse place tokenization part ofspeech recognition method learning phase tuned manually ported particular application substituting extending domain dependent components necessarily require gazetteer knowledge base known proper entities infers existence structural vocabulary context style software analyzers 
advantage tool fast dependent additional knowledge sources 
demonstrated applying software design recovery techniques semantic annotation documents feasible potential 
clear techniques retain efficiency bigger inputs exhibiting fast linear performance tuning 
consider contribution cost effective evaluation scheme proposed measure quality annotations 
plan prove method larger documents richer conceptual models different domains 
additionally intend experiment number techniques software analysis area far taken advantage alias resolution unique naming architecture patterns markup refinement 
boguraev boguraev tait editorial natural language engineering issn cimiano cimiano handschuh staab self annotating web 
proceedings th international conference world wide web acm press cordy cordy language programming language tools applications 
proc 
acm th int 
workshop language description tools applications barcelona april decker decker erdmann fensel studer ontobroker ontology access distributed semi structured 
ds database semantics semantic issues multimedia systems ifip tc wg eighth working conference database semantics new zealand dill dill eiron gibson gruhl guha mccurley rajagopalan tomkins tomlin zien case automated large scale semantic annotation 
journal web semantics dean dean cordy schneider experience design recovery techniques transform legacy systems 
proc 
th int 
conference software maintenance etzioni etzioni cafarella downey popescu shaked soderland weld yates unsupervised named entity extraction web experimental study 
artificial intelligence freitag freitag kushmerick boosted wrapper induction 
proc 
th national conference artificial intelligence handschuh handschuh staab ciravegna cream semi automatic creation metadata 
th international conference knowledge engineering management ekaw ed 
gomez perez springer verlag kiryakov kiryakov popov semantic annotation indexing retrieval 
elsevier journal web mich mylopoulos experimenting linguistic tools conceptual modelling quality models critical features 
proc 
leidner leidner current issues software engineering natural language processing 
proc 
workshop software engineering architecture language technology systems joint conf 
human language technology annual meeting noth american chapter association computational linguistics hlt naacl edmonton alberta canada holmes applying information extraction generate daml annotations web pages 
international conference knowledge capture cap 
workshop knowledge markup semantic annotation victoria canada october muslea muslea minton knoblock active learning strong weak views case study wrapper induction 
proc 
th int 
joint conference artificial intelligence nelson nelson survey reverse engineering program comprehension nobata nobata sekine automatic acquisition patterns information extraction 
proc 
international conference computer processing oriental languages shea blostein web validate document recognition results experiments business cards 
proc 
spie popov popov kiryakov semantic web information extraction 
human language technologies workshop nd international semantic web conference iswc october florida usa popov popov kiryakov kim semantic platform information retrieval 
journal web semantics cambridge university press sean sean lee handler ontology web agents 
proceedings international conference autonomous agents agents eds 
johnson hayes roth marina del rey ca usa acm press sheth sheth bertram avant hammond kochut managing semantic content web 
ieee internet computing liddle embley generalized framework ontology data extraction system 
proc 
th int 
conference information systems technology applications yang yang evaluation statistical approaches text categorization 
journal information retrieval blostein cordy recognizing mathematical expressions tree transformation ieee transactions pattern analysis machine intelligence blostein cordy survey table recognition models observations transformations inferences 
international journal document analysis recognition sept 
