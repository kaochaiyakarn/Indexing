significance recall automatic metrics mt evaluation alon lavie kenji jayaraman language technologies institute carnegie mellon university cs cmu edu 
research shown balanced harmonic mean measure unigram precision recall outperforms widely bleu nist metrics machine translation evaluation terms correlation human judgments translation quality 
show significantly better correlations achieved placing weight recall precision 
may unexpected bleu nist focus gram precision disregard recall experiments show correlation human judgments highest weight assigned recall 
show stemming significantly beneficial just simpler unigram precision recall metrics bleu nist 
automatic metrics machine translation mt evaluation receiving significant attention past years ibm bleu metric proposed available 
bleu closely related nist metric extensively comparative evaluation various mt systems developed darpa tides research program mt researchers 
automatic metrics mt evaluation proposed early 
include various formulations measures edit distance mt produced output translation similar measures word error rate position independent word error rate 
utility attractiveness automatic metrics mt evaluation widely recognized mt community 
evaluating mt system automatic metrics faster easier cheaper compared human evaluations require trained bilingual evaluators 
addition utility comparing performance different systems common translation task automatic metrics applied frequent ongoing basis system development order guide development system concrete performance improvements 
comparison widely bleu nist metrics set easily computable metrics unigram precision recall 
empirical evaluation methods proposed literature concrete means assess level correlation automatic metrics human judgments show higher correlations obtained fairly simple straightforward metrics 
researchers shown balanced combination precision recall measure improved correlation human judgments compared bleu nist claim better correlations obtained assigning weight recall precision 
fact experiments show best correlations achieved recall assigned weight 
previous lin hovy shown recall automatic metric evaluating summaries outperforms bleu metric task 
results show case evaluation mt demonstrate stemming mt output strings prior comparison allows different morphological variants word considered matches significantly improves performance metrics 
describe metrics evaluation section 
discuss certain characteristics bleu nist metrics may account advantage metrics unigram recall 
evaluation methodology data experimentation described section 
experiments results described section 
directions extensions discussed section 
evaluation metrics metrics evaluations addition bleu nist explicit word word matches translation evaluated translations 
single translation available translation matched independently best scoring match selected 
allow simultaneously match different portions translation different supports recall component scoring possible match 
metric including bleu nist examine case matching requires matched word translation identical standard behavior bleu nist case stemming applied strings prior matching second case stem translation prior matching require identity stems 
plan experiment strict matching schemes consider matching synonymous words cost described section 
bleu nist main principle ibm bleu metric measurement overlap unigrams single words higher order grams words include bleu nist evaluations stemmed data includes stemming part metric resulting bleu stemmed nist stemmed scores truly bleu nist scores 
serve illustrate effectiveness stemming mt evaluation 
translation evaluated set translations 
main component bleu gram precision proportion matched ngrams total number grams evaluated translation 
precision calculated separately gram order precisions combined geometric averaging 
bleu take recall account directly 
recall proportion matched grams total number grams translation extremely important assessing quality mt output reflects degree translation covers entire content translated sentence 
bleu recall notion recall unclear simultaneously matching multiple translations single 
compensate recall bleu uses brevity penalty penalizes translations short 
nist metric conceptually similar bleu aspects including weaknesses discussed lack recall believe brevity penalty bleu adequately compensate lack recall 
experimental results strongly support claim 
lack explicit word matching translation gram counts don require explicit word word matching result counting incorrect matches particularly common function words 
advanced metric currently developing see section uses explicit word matching assess grammatical coherence translation 
geometric averaging grams geometric averaging results score zero component gram scores zero 
consequently bleu scores sentence level meaningless 
bleu intended aggregate counts entire test set sentence level metric exhibits high levels correlation human judgments sentence level highly desirable 
experiments conducted modified version bleu uses equal weight arithmetic averaging gram scores better correlation human judgments sentence system level 
metrics unigram precision recall metrics evaluations 
unigram precision mentioned consider exact toone matches words 
precision calculated follows wt number words translation match words translation wt number words translation 
may interpreted fraction words translation translation 

unigram precision stemming translation stemmed precision computed 

unigram recall precision exact word matches considered 
recall calculated follows wr number matching words wr number words translation 
may interpreted fraction words appear translation 

unigram recall stemming translation stemmed recall computed 

harmonic mean precision recall 
computed follows 
stemming stemmed version precision recall 

similar recall weighted times heavily precision 
precise amount recall outweighs precision important fact weight placed recall 
balance estimated development set translations report results large test set way determine parameters metrics 
calculated follows mean evaluating mt evaluation metrics data evaluated metrics described section compared performances bleu nist large data sets darpa tides chinese english mt evaluation sets 
data cases consists approximately sentences translations 
evaluations corresponding human assessments human judges evaluating translated sentence 
human judges assign adequacy score fluency score sentence 
score ranges poorest grade highest 
adequacy fluency scores judges sentence averaged average adequacy average fluency score calculated evaluated system 
total human score system sum average adequacy average fluency scores range 
data evaluation contains system output human evaluation scores systems 
data includes system output human evaluation scores systems 
set determining weights precision recall metric 
evaluation methodology goal evaluation mt scoring metrics effectively quantify metric correlates human judgments mt quality 
different experimental methods proposed various researchers 
experiments reported methods assessment 
correlation automatic metric scores human scores system level plot automatic metric score assigned tested system average total human score assigned system calculate correlation coefficient metric scores human scores 
melamed suggest spearman rank correlation coefficient appropriate measure type correlation experiment 
rank correlation coefficient abstracts away absolute scores measures extent scores human automatic similarly rank systems 
feel rank correlation sufficiently sensitive evaluation criterion poor automatic metrics capable correctly ranking systems different quality 
opted evaluate correlation pearson correlation coefficient takes account distances data points optimal regression curve 
method various researchers official darpa tides evaluations 

correlation score differentials pairs systems pair systems calculate differentials systems human score metric score 
plot differentials calculate pearson correlation coefficient differentials 
method suggested 
provides significantly data points establishing correlation mt metric human scores 
reasonable assumption differentials automatic metric human scores highly correlate 
assumption reasonable human scores metric scores linear nature generally true metrics compare 
mentioned values pearson correlation coefficients consequently range representing strong association automatic score human score 
different metrics assessed primarily looking metric higher correlation coefficient scenario 
order validate statistical significance differences scores apply commonly bootstrapping sampling technique estimate variability test set establish confidence intervals system scores correlation coefficients 
table 
correlation coefficients human judgments metric darpa tides chinese data set metric pearson coefficient confidence interval nist nist stem bleu bleu stem stem stem stem stem metric evaluation correlation automatic metric scores human scores system level compare various metrics terms correlation total human scores system level 
metric plot metric total human scores assigned system calculate correlation coefficient scores 
tables summarize results various metrics data sets 
metrics show higher levels correlation human judgments data compared data 
data exhibits anomalies identified discussed researchers 
systems output contains significantly higher amounts noise non ascii characters upper cased words detrimental automatic metrics 
variability set higher set reflected confidence intervals various metrics 
levels correlation different metrics quite consistent data sets 
unigram recall mean significantly higher levels correlation bleu nist 
unigram precision hand poor level correlation 
performance inferior mean data 
data inferior stemmed equivalent 
stemming improves correlations metrics data 
data stemming improves correlation metrics recall correlation coefficients high stemming longer statistically significant effect 
recall nist exhibit stability metrics reflected confidence intervals 
table 
correlation coefficients human judgments metric darpa tides chinese data set metric pearson coefficient confidence interval nist nist stem bleu bleu stem stem stem stem stem correlation score differentials pairs systems calculated score differentials pair systems evaluated assessed correlation automatic score differentials human score differentials 
results evaluation summarized tables 
results system pair differential correlation experiments consistent system level correlation results 
unigram recall mean significantly higher levels correlation bleu nist 
effects stemming somewhat pronounced evaluation 
discussion clear results unigram recall strong correlation human assessment mt quality stemming strengthens correlation 
follows intuitive notion mt system output contain system output contain meaning input possible 
surprising unigram precision hand low correlation 
important factor precision final score assigned system prevent systems output long translations receiving inflated scores extreme example system outputs word vocabulary translation consistently score high unigram recall regardless quality translation 
metric effective combining precision recall 
recall weighted heavily scores high correlations 
data sets tested recall performed equally differences statistically insignificant precision performs worse 
weighted harmonic mean precision recall multiplied low table 
correlation coefficients pairwise system comparisons darpa tides chinese data set metric pearson coefficient confidence interval nist nist stem bleu bleu stem stem stem stem stem levels precision properly penalize score disallowing case system scoring high simply outputting words 
feature bleu nist included simple metrics approximate notion word order grammatical coherence achieved higher level grams 
begun development new metric combines score explicit measure grammatical coherence 
metric meteor metric evaluation translation explicit word ordering performs maximal cardinality match translations uses match compute coherence penalty 
computation done assessing extent matched words translation constitute ordered coherent chunks 
preliminary experiments meteor yielded promising results achieving similar levels correlation far statistically significantly superior compared simpler measures recall 
current currently process enhancing meteor metric directions expanding matching translation experiments indicate stemming significantly improves quality metric expanding matching 
plan experiment expanding matching include synonymous words information synsets wordnet 
reliability matches somewhat reduced consider assigning matches lower confidence taken account score computations 
table 
correlation coefficients pairwise system comparisons darpa tides chinese data set metric pearson coefficient confidence interval nist nist stem bleu bleu stem stem stem stem stem combining precision recall sort penalty results far indicate recall plays important role obtaining high levels correlation human judgments 
currently exploring alternative ways combining components precision recall coherence penalty goal optimizing correlation human judgments exploring optimized combination factors data set persistent performance different data sets 
utility multiple translations metrics described multiple translations weak way compare translation separately select best match 
necessary order incorporate recall metric shown highly advantageous 
process quantifying utility multiple translations metrics measuring correlation improvements function number translations 
consider exploring ways improve matching multiple 
pang knight marcu provides mechanism producing semantically meaningful additional synthetic small set real 
plan explore synthetic improve performance metric 
matched words created equally current metrics treats matched words system translation equally 
safe assume matching semantically important words carry significantly weight matching function words 
plan explore schemes assigning different weights matched words investigate schemes improve sensitivity metric correlation human judgments mt quality 
acknowledgments research funded part nsf number iis 

papineni kishore salim roukos todd ward wei jing zhu 

bleu method automatic evaluation machine translation 
proceedings th annual meeting association computational linguistics acl pages philadelphia pa july 

doddington george 

automatic evaluation machine translation quality gram occurrence statistics 
proceedings second conference human language technology hlt 
san diego ca 
pp 



su 
wu 
chang 

new quantitative quality measure machine translation systems 
proceedings fifteenth international conference computational linguistics coling 
nantes france 
pp 


sumita 

multiple edit distances automatically rank machine translation output 
proceedings mt summit viii 
santiago de spain 
pp 


och ney 

evaluation tool machine translation fast evaluation machine translation research 
proceedings second international conference language resources evaluation lrec 
athens greece 
pp 


gregor nicola herman ney 

string string distance measure applications machine translation evaluation 
proceedings mt summit ix 
new orleans la sept 
pp 


dan melamed green 

precision recall machine translation 
proceedings hlt naacl 
edmonton canada 
may 
short papers pp 


joseph luke shen dan melamed 

evaluation machine translation evaluation 
proceedings mt summit ix 
new orleans la sept 
pp 


chin yew lin eduard hovy 

automatic evaluation summaries gram occurrence statistics 
proceedings hlt naacl 
edmonton canada 
may 
pp 


van rijsbergen 

information retrieval 
butterworths 
london england 
nd edition 

deborah 

correlating automated human assessments machine translation quality 
proceedings mt summit ix 
new orleans la sept 
pp 


bradley efron robert tibshirani 

bootstrap methods standard errors confidence intervals measures statistical accuracy 
statistical science 
pp 


george doddington 

automatic evaluation language translation gram occurrence statistics 
presentation darpa tides mt workshop 
nist md july 

bo pang kevin knight daniel marcu 

syntax alignment multiple translations extracting paraphrases generating new sentences 
proceedings hlt naacl 
edmonton canada 
may 
pp 

