hierarchical multi classification predictive clustering trees functional genomics jan sa zeroski hendrik blockeel amanda clare katholieke universiteit leuven dept computer science celestijnenlaan leuven belgium jan hendrik blockeel cs kuleuven jozef stefan institute dept knowledge technologies ljubljana slovenia saso dzeroski ijs si university wales dept computer science sy db wales uk afc aber ac uk 
investigates predictive clustering trees predict gene function genome yeast saccharomyces cerevisiae 
consider mips classification scheme gene annotated classes selected functional class hierarchy 
setting presents important challenges machine learning instance labeled set classes just class classes structured hierarchy ideally learning algorithm take hierarchical information account 
predictive clustering trees generalize decision trees applied wide range prediction tasks plugging suitable distance metric 
define appropriate distance metric hierarchical multi classification experiments evaluating approach number data sets available yeast 
saccharomyces cerevisiae baker brewer yeast biology classic model organisms subject intensive study years 
genes annotations provided munich information center protein sequences mips scheme classifying functions products genes 
hierarchical system functional classes 
small part hierarchy shown fig 

yeast genes annotated functional class 
classification setting presents main challenges machine learning instance gene labeled set classes just class classes structured hierarchy ideally learning algorithm take hierarchical information account 
simple approach ignore hierarchy learn separate models class indicating single instance belongs class 
metabolism amino acid metabolism nitrogen metabolism 
energy 
fig 

part hierarchical classification scheme 
toy hierarchy example text 
note class labels indicate position hierarchy subclass class 
consider task learning model classes 
advantage total size predictive theory typically smaller dependencies different classes membership taken account may 
advantages learning single model multiple related prediction tasks reported times literature see decision trees neural networks text classification 
account hierarchical structure classes important learning 
hierarchy concisely conveys relevant information similarity differences classes expresses constraint instance belonging class belongs parent class 
combination multi classification hierarchical classification known hierarchical multi classification 
blockeel show predictive clustering trees applied hierarchical multi classification 
form general framework prediction instantiated particular prediction task defining distance metric prototype 
distance metric generic distance sets classes subsequently instantiated hierarchical classification plugging weighted shortest path distance individual classes 
set distance major disadvantages distance sets difficult interpret involves computation kernel guaranteed positive kernel matrix positive definite 
impact difficult evaluate 
take approach similar 
introduce new distance metric specific hierarchical disadvantages distance metric 
extension introduced clare capable hierarchical multi classification 
accomplished adapting definition entropy take account multi class aspect hierarchical relationship classes 
experimental evaluation included compare approach results 
organized follows 
define hierarchical multi classification formally section 
follows brief description section 
section shows instantiated hierarchical 
approach validated experimentally section 
section discusses section states main 
hierarchical multi classification represent hierarchy set classes tree defined set top level classes parent function maps children tree node node defined top level classes 
valid set set classes closed respect parent function parent denotes power set denotes set valid sets constructed example 
fig 
parent valid set classes 
note valid set classes corresponds subtree hierarchy 
case hierarchical single classification subtree reduces path 
problem hierarchical multi classification stated follows 
instance space class space hierarchy defined set labeled instances quality criterion find function maps instance valid set classes maximizes quality criterion hierarchy concisely conveys relevant information similarity differences classes 
intuitively distance classes smaller closer hierarchy 
siblings node equidistant distance node parent nodes level 
distance metric introduce section fulfills criteria 
quality criterion need distance 
instance just average precision different classes predicted take account fact predicting smaller mistake instance labeled instance labeled 
representing labels subtrees hierarchy natural constraints class membership belonging specific class automatically belongs general ancestor classes automatically honored 
guaranteed independent models learned different classes 
predictive clustering trees variety algorithms predictive modeling exists 
better known algorithms induce decision trees 
compared known techniques neural networks decision trees advantage interpretable clearly factors influence outcome strongly 
decision trees context classification regression represent model value single variable predicted 
decision tree naturally identifies partitions data course grained top tree fine grained bottom consider tree hierarchy clusters 
cluster hierarchy individuals cluster similar respect number observable properties 
leads simple method building trees allow prediction multiple target attributes 
define distance measure tuples target variable values build decision trees multi target prediction 
similarly distance hierarchical target values defined build decision trees hierarchical classification 
methodology successfully variety applications conceptual clustering simultaneous prediction multiple parameters ranking tasks :10.1.1.50.3353
algorithm inducing called predictive clustering trees essentially standard tdidt top induction decision trees algorithm 
general idea recursively partition set data clusters way intra cluster variation minimized 
heuristic selecting test include node tree sum intra cluster variations subsets induced test 
intra cluster variation defined sum squared distances members cluster prototype defined arg xi roughly point closest instances cluster distance defined 
prototype may may valid prediction 
instance prediction prototype mean target values making prediction specific instance converted valid prediction 
result induction process decision tree leaf contains prediction derived prototype examples covered leaf 
detailed description :10.1.1.50.3353
main point proposed method inducing relies entirely definition distance measure prototypes mapping prototypes valid predictions 
issues focus section 
hierarchical multi classification section show applied hierarchical multi classification 
indicated comes defining suitable distance metric prototype 
representing valid set classes vector hierarchical multi classification setting instance annotated valid set classes ci selected hierarchically structured set classes distance metric prototype vector representation ci 
representation constructed follows 
vector vi representing ci vector components 
component corresponds class components vi correspond classes ci take value set 
example 
consider class hierarchy shown fig suppose instance annotated valid set ci 
assuming vi corresponds class position preorder traversal hierarchy indicated numbers parenthesis fig vector representing ci vi 
distance metric prototype valid set classes represented vector euclidean distance distance metric define distance valid sets ci cj euclidean distance vector representations 
ci cj vi vj wk vi vj hierarchical relationship classes taken account setting weights wk appropriate values 
weight classes deeper hierarchy smaller classes closer top distance top level classes large distance sibling classes deeper hierarchy small 
experimental evaluation weights decrease exponentially hierarchy depth wk depth ck parameter set ad hoc 
easily verified choice fulfills criteria listed section 
example 
consider instances annotated ci second cj 
distance ci cj ci cj note distance interpreted square root sum penalty class occur cj penalty class occur cj 
consider set vectors prototype pv corresponding euclidean distance vector mean pv vi vi 
set instances set vectors representing target values component pv represents proportion instances belong corresponding class 
table 
data set properties 
number instances genes number attributes 
data set sequence seq phenotype secondary structure struc homology search hom spellman 
roth 
church data set derisi 
derisi eisen 
eisen 

chu 
spo microarray expr example 
consider instances example 
prototype pv indicates instances belong class belong classes 
intra cluster variation heuristic building computed sum squared distances members prototype pv euclidean distance advantage distance metrics defined sets distance prototype computed efficiently 
important context distance prototype computation heuristic heuristic evaluated possible split instances considered system 
mapping prototype prediction prediction associated leaf set classes occur training examples belonging leaf 
note set valid set 
computed prototype set classes correspond components greater equal 
experimental evaluation section experiments evaluating hierarchical prototype distance metric discussed previous section plugged 
describe data sets evaluation define experimental setup discuss obtained results 
data sets data sets clare table 
reason compare hierarchical multi classification hierarchical extension 
data sets describe different aspects genes saccharomyces cerevisiae genome baker brewer yeast 
gene included data sets annotated classes selected mips hierarchical classification scheme 
annotations classification scheme available 
hierarchy classes level second third fourth level 
types data yeast considered data sets sequence statistics phenotype predicted secondary structure homology expression 
different sources data highlight different aspects gene function 
describe data set turn 
note relevant literature omitted space restrictions 
available obtained data sets www aber ac uk research bio dss 
sec sequence statistics recorded depend amino acid sequence protein produced gene 
include amino acid ratios sequence length molecular weight 
properties calculated tool listed mips part description sequence chromosome gene located simply calculated directly 
attributes real valued chromosome number strand discrete 
phenotype data represents growth lack growth knock mutants missing gene question 
gene removed disabled resulting organism grown variety media determine modified organism sensitive resistant 
phenotype data taken mips triples 
attributes dataset discrete dataset sparse knock outs grown conditions 
seq secondary structure protein known influence function protein 
secondary structure caused hydrogen bonding protein backbone main classes secondary structure elements alpha helix beta sheet 
structure classified alpha beta usually termed coil 
yeast known structure genes secondary structure predicted protein sequences reasonable precision 
program prof generate predicted secondary structure gene 
due relational nature type data preprocessing step relational association mining employed generate frequent associations data 
discovered associations included binary attributes 
hom genes homologous share common ancestor 
determining function yeast gene information homologous gene species provide clues possible role gene 
homology usually determined sequence similarity 
genes similar sequences deemed homologous standard software exists finding similar sequences large database 
psi blast compare yeast genes yeast genes genes proteins indexed swissprot version database annotated genes species 
provided yeast gene list homologous genes homologous genes various properties extracted keywords sequence length names databases known listed 
relational dataset mined frequent associations way secondary structure data produce binary attributes 

microarrays gather information expression genes currently popular biology bioinformatics 
microarray chips provide means test expression levels genes entire genome single experiment 
expression data sets exist yeast 
attributes datasets real valued representing fold changes expression levels 
method implementation distance metric prototype hierarchical introduced section implemented clus system clus system building essentially propositional version tilde system 
clus parameter controls minimum number instances leaf 
parameter set ad hoc 
clus considers tests yield significant reduction intra cluster variation 
significance level test tuned experiment fold cross validation training set maximize average class wise precision see 
parameters set default values 
obtaining validated predictions said interested comparing method hierarchical extension introduced 
predictions validated separate validation set obtain higher precision expense coverage 
class predicted leaf decision tree significance test performed 
suppose leaf covers validation instances proportion instances belonging predicted class precision prediction 
test computes probability proportion instances predicted class random sample size greater hypergeometric distribution 
probability significance level prediction considered insignificant removed 
significance level set bonferroni correction 
divides significance level number tests performed case sum predicted number classes leaves decision tree 
correction advised number tests large 
significance level perform experiments bonferroni correction 
note validation step predictions longer guaranteed valid sets 
clus available authors request 
table 
average precision coverage data sets percent 
precision coverage clus clus clus clus name seq struc hom church precision coverage clus clus clus clus name derisi eisen spo expr data set partition experiments way split data set training set validation set test set 
test set contains data 
remaining split split create training validation set 
split 
training set induce pct validation set remove predicted classes significant test set measure predictive precision coverage 
note large number classes validated predictions obtained 
predictive precision computed predicted class individually class wise precision average precision computed predicted classes 
coverage defined proportion instances class predicted 
results table presents obtained average precision coverage data set 
contains results clus clus system bonferroni correction enabled clus bonferroni correction hierarchical extension 
average precision obtained clus clus generally higher obtained clus yields higher precision data sets clus increased precision comes cases expense lower coverage coverage obtained clus lower data sets 
note domain experts prefer precise predictions high coverage domain 
disabling bonferroni correction coverage increases data sets 
data sets clus yields larger coverage seq struc hom expr 
precision obtained clus higher 
hand data sets higher coverage clus precision obtained higher case 
table lists class wise precision data set clus 
cases set classes predicted clus similar 
table 
class wise precision 
predicted class prior probability precision obtained clus percent 
prior clus prior clus derisi prior clus prior clus expr prior clus struc prior clus church prior clus eisen prior clus prior clus spo prior clus seq prior clus hom prior clus data sets predicts classes clus usually extra classes predicted 
clus usually yields higher class wise precisions 
observations consistent higher average precision obtained clus larger coverage obtained 
result favor clus system obtained homology data set 
clus predicts classes including level class 
predicts classes data set 
discussed average precision coverage obtained data set higher clus 
pct data set shown fig 

bottom right leaf example represents cluster genes predicted functions 
note tests nodes leaf provide description cluster 
compared pct rules 
number similarities knowledge discovered systems considered complementary 
hom class group interpro hom class keyword hom class hom class hom aarhus ghent hom class alpha subdivision subtree nodes shown fig 

part pct obtained homology data set 
recall attributes binary relational features 
node contains feature expressed order logic 
variable represents gene refer homologous genes 
details 
leaf pct shows predicted set classes number training examples belonging leaf 
item investigating trade coverage precision 
ideally possible specify trade means parameter 
possible extent altering significance level validation step test selection pruning mechanism induction algorithm influence trade 
effects studied 
propose system building predictive clustering rules 
plugging distance metric prototype introduced system suitable hierarchical multi classification 
rules better suited trees situations high precision required coverage tolerated 
interesting evaluate approach domains hierarchically structured classes occur 
ecological modeling samples soil river water collected species occurring samples classified hierarchical scheme 
method cluster samples 
predictive clustering trees form generic framework prediction instantiated particular task defining distance metric prototype 
introduced distance metric prototype task hierarchical multi classification 
task occurs domains notably functional genomics gene annotated set classes selected hierarchical classification scheme 
experimentally validated approach implemented clus system data sets available yeast saccharomyces cerevisiae means comparison hierarchical extension proposed 
results show clus generates precise predictions 
investigate trade precision coverage 

bakker heskes 
task clustering learning learn 
proceedings th belgium netherlands conference artificial intelligence pages amsterdam 

bishop 
neural networks pattern recognition 
university press oxford 

blockeel bruynooghe zeroski ramon 
hierarchical multi classification 
proceedings acm sigkdd workshop multi relational data mining pages 

blockeel de raedt 
top induction order logical decision trees 
artificial intelligence june 

blockeel de raedt ramon 
top induction clustering trees 
proceedings th international conference machine learning pages 

blockeel zeroski 
simultaneous prediction multiple chemical parameters river water quality tilde 
proceedings rd european conference principles data mining knowledge discovery volume lecture notes artificial intelligence pages 
springer 

breiman friedman olshen stone 
classification regression trees 
wadsworth belmont 

caruana 
multitask learning 
machine learning 

clare 
machine learning data mining yeast functional genomics 
phd thesis university wales 

langley 
elements machine learning 
morgan kaufmann 

quinlan 
programs machine learning 
morgan kaufmann series machine learning 
morgan kaufmann 

ramon bruynooghe 
polynomial time computable metric point sets 
acta informatica 

todorovski blockeel zeroski 
ranking predictive clustering trees 
proceedings th european conference machine learning volume lecture notes artificial intelligence pages 
springer verlag 

zeroski 
learning predictive clustering rules 
submitted workshop knowledge discovery inductive databases th european conference machine learning ecml 

wang zhou 
building hierarchical classifiers class proximity 
vldb proceedings th international conference large data bases september edinburgh scotland uk pages 
morgan kaufmann 
