proc 
iccv pp 
beijing china october 
efficient model tracking deformable objects mu oz jos luis facultad de inform tica univ polit cnica madrid univ rey juan carlos campus madrid spain tulip spain dia fi upm es fi upm es efficient incremental image alignment topic renewed interest computer vision community applications model fitting model object tracking 
successful compositional procedures aligning models weak perspective imaging conditions proposed 
mixed compositional additive algorithm applicable full projective camera case 

tracking non rigid objects particular human heads topic intense research computer vision community application construction advanced computer interfaces achieving graphical models realistic animation 
early approaches modelled face rigid textured object tracked corner features model face texture mapped planar ellipsoidal cylindrical models :10.1.1.147.629
generative linear models face appearance active appearance models aams morphable models mms successfully respectively real time tracking accurate modelling human faces changes facial expressions scene illumination 
fitting generative linear model image nonlinear optimisation problem successfully solved incrementally aligning model target image 
efficient minimisation procedures proposed literature real time tracking factorisation additive approach hager belhumeur inverse compositional image alignment algorithm baker matthews :10.1.1.147.629
approaches drawbacks 
hager belhumeur requires jacobian matrix factored 
possi ble appearance affine projective planar models investigated applicable sophisticated generative linear models 
baker matthews approach requires warping function closed inverse composition hold aams mms 
approximation composition aams matthews baker realtime algorithm tracking faces aams 
limitation approach aams intrinsically models track object achieved expense requiring shape parameters 
consequence minimisation properly constrained order achieve robust tracker 
vetter efficiently adjusting mm image static face problem similar tracking 
important drawback approaches weak perspective imaging conditions 
limitation example track face imaged camera short focal length strong perspective distortion low cost web cam 
efficient incremental image alignment procedure non rigid object tracking generative linear model object appearance 
separating image projection target motion introduce simple non rigid motion model rigid non rigid motion parameters easily decoupled independently camera projection model 
enables write exact inverse composition function 
demonstrate technique tracking synthetic real image sequences human head target 
main contributions tracker independent camera model experiments full projective camera 
exact inverse composition function contrary previous approximations 
rigid non rigid motion parameters easily decoupled important issue terms compu tational efficiency 

model goal simple target model easily acquired suitable tracking arbitrary non rigid object experiments human head 
order achieve goal model set images target sparse representation composed set small planar textured patches set shape bases encode modes deformation set texture bases represent variations brightness caused changes illumination scene see fig 


model human face 

patches patch model tangent volume object patch centre 
texture patch result orthogonally projecting underlying object texture small plane 
patches similar wiles 
main difference related corner regions face individually searched registered frames 
patches necessarily attached corner features track globally aperture problem applies set patches 
case human face texture patches distributed face see fig 


motion model motion point composition rigid motion caused translation rotation object space non rigid motion caused deformation object 
xi xi yi zi denote ordinates point space structure represented set points space 
non rigid motion 
non rigid motion point xi described linear combination ks basis points bs ij plus mean component ks csj cs csj weight linear combination 
shape configuration non rigid object expressed linear combination set ks basis shapes stored matrix plus mean vector ks ks ks vector shape configuration weights 
mean vector called rigid component represents rigid configuration object basis represents allowed modes deformation 
rigid motion 
shape rotate translate rigidly space 
letr rotation matrix translation vector representing motion 
rigid motion point xi denote rs result applying translation point shape producing new shape motion model configuration object space generated motion model moves deforms average shape tx ty tz vector motion parameters 
note conversely average shape reached object configuration 
shape projection projection point xi image represented xi xi vector projection parameters 
similarly object shape projected image denoted assumption projection model experiments assume projective camera 
previous approaches motion model included implicitly explicitly projection point image plane :10.1.1.147.629
general choice complicates unnecessarily computation inverse shape see sec 
prevents closed 
approximated inverse composition 
collateral advantage having simpler motion model rigid non rigid motion parameters decoupled easily identified 

texture model denote xi brightness value rgb values assigned projection point xi image 
depends object colour colour intensity illumination source relative orientation source object surface xi 
factors modelled kt xi xi ij ct ct ct kt vector texture configuration weights bt ij th component texture base associated point xi xi average texture point 
texture base models changes brightness pixel caused illumination scene 
texture model deformable object represented structure vector ct kt kt matrix storing texture basis shapes ct ct ct ks vector texture configuration weights 
assume gray level image similar model built rgb colour values 
general projected point xi may coincide integer position 
case brightness value xi computed interpolation neighbouring pixels 
tracking procedure described section constancy constraint brightness values normalised respect illumination 
define average texture point normalised brightness xi xi normalised texture object configuration 

tracking section describe efficient procedure tracking non rigid object image sequence object model section 
introduce brightness constancy constraint pose tracking problem parametric minimisation constraint 
show mixed compositional additive algorithm efficiently computing best set parameters 

problem statement rigid component deformable object set parameters aligns image acquired time texture configuration weights normalise brightness values 
time instants brightness constancy equation holds generalisation called image constancy assumption :10.1.1.147.629
assume fixed image denote ir target image varies time object moves deforms 
assume motion model parameters related target object way 
tracking amounts finding time instant set parameters equation holds 
achieved solving squares problem min ct ir qr 
complex minimisation problem cost function non convex 
similar problems traditionally solved linearly estimating model parameters incrementally 
achieve making taylor series expansion computing increment motion parameters gauss newton iterations 
different solutions proposed literature depending term taylor expansion motion parameters updated 

efficient tracking computational cost tracking approach due mainly cost estimating jacobian image brightness values motion model parameters pseudo inverse needed gauss newton iterations 
factorisation additive approach hager belhumeur compositional approach baker matthews efficient solutions similar problems :10.1.1.147.629
introduce efficient minimisation procedure uses compositional approach estimating motion parameters additive texture configuration weights 
minimisation solved tracking min ir qr term represents normalised brightness values obtained projecting configuration general images may requirement represent non rigid deformation 
object time image acquired time second term incremental non rigid motion changes texture take place set normalised brightness values term obtained image 
parameters represent respectively motion deformation target object time instants changes texture caused illumination 
estimating increment motion texture parameters linearly estimated making taylor series expansion second term ir qr ir qr mc ct ir qr mc bt minimisation rewritten min ct solved squares ir qr error projecting configuration time image acquired andm jacobian image respect motion texture parameters 
note constant inverse precomputed line 
key efficiency algorithm 
minimisation performed making columns orthogonal reported introduce perturbations decrease accuracy shape recovery 
explicitly solve sets parameters 
jacobian matrix models brightness xi changes target moves infinitesimally 
represents information provided point tracking process 
singular motion recovered 
generalisation called aperture problem estimation optical flow 
reason track object patches non corner patch contributes minimisation aperture problem applies set 
estimating introducing change variable rewritten min ir qr 
convention comparing conclude ct 
model approximation strict equality model 
order obtain expand rt rb tt rt comparing conclude rt rt tt tt rt note rotated corrected rb previously decoupling rigid non rigid motion parameters motion model possible camera model required complex procedure 
final algorithm follows line 


compute 
compute store ir ir qr online 
ir 

compute 
update ct 
rt tt tt rt 
update cs 
experiments order evaluate algorithm empirically set experiments synthetic real image sequences 
synthetic experiments aim validate theoretical basis algorithm real ones intend demonstrate suitability approximation tracking live sequences 

synthetic experiments developed framework creating synthetic sequences deforming head model 
head model previous parke includes vertices encodes different muscles face 
generate facial expressions frame frame frame frame frame frame 
synthetic sequence key frames tracking results 
different facial muscles 
rigid body transformation orientation change plus translation computed model determines head pose orientation 
map photorealistic texture face model project image free ray tracing tool raytracer simulates projective camera located units distance head model depth units 
fig 
shows key frames frames synthetic sequence 
starting position head translates horizontal image axis rotating main axis 
sequence comprises total facial expressions includes mouth opening eyebrows raising left scene placed light source pointing directly head assumed head surface lambertian 
obtained basis shapes frames sequence comprised possible facial expressions model 
place patches polygon vertices distributed face 
performing pca matrix stores tracks patches sequence obtain modes deformation 
modes deformation encoded variance data 
orbiting light source head model neutral position obtained image sequence representing different lighting conditions 
obtained texture performing pca matrix storing brightness values projections head model image 
fig 
show results frames synthetic sequence 
shows computed parameters plotted ground truth values 
ground truth values ones create synthetic sequence 
estimated values tracking algorithm rotation horizontal axis translation horizontal axis tx linear coefficients shape texture deformations see www povray org plotted ground truth 
results show motion texture parameters accurately estimated quite noticeable changes illumination facial expressions 
degrees value parameter frame number parameter frame number value translation units parameter tx frame number parameter frame number 
estimated vs ground truth values 
row rotation head vertical axis left horizontal translation right 
second row fist shape configuration weight left texture configuration weight right 
red continuous line stands estimated values frame blue dashed line stands ground truth data 

real experiments preliminary results seconds real video sequence 
imaged actor performing expressions anger sadness surprise calibrated fc colour camera located roughly meter away actor 
video sequence different previous motion capture system tracked markers actor face 
motion total patches interpolated tracks markers stored motion matrix 
obtained shape basis actor head performing pca motion matrix 

real sequence key frames tracking results 
show fig key frames real video sequence estimated location patches overlayed 
spite sparseness low quality model tracker performs 

new formulation efficient image alignment algorithm non rigid generative linear models object appearance 
separating projection motion models enables build tracker independent image projection model 
shown performs correctly sequences captured projective imaging conditions 
introduce simple deformable motion model inverse shape composition exactly computed 
directly identify rigid non rigid motion parameters 
tracker interesting right theoretical simplicity ease programming 
experiments sparse patch model target appearance algorithm applicable generative linear models aams mms 
authors gratefully acknowledge funding spanish ministry science technology tic 
mu oz funded fpu ministry education 
grateful alessio del helpful discussions providing model real video sequences 
baker matthews 
equivalence efficiency image alignment algorithms 
proc 
cvpr volume pages 
ieee 
basu essa pentland 
motion regularization model head tracking 
proc 
icpr 
belhumeur kriegman 
set images object possible illumination conditions 
ijcv 
blanz vetter 
morphable model synthesis faces 
proc 
siggraph pages 
acm press addison wesley publishing 
mu oz 
efficient appearance tracking 
proc 
cvpr workshop nonrigid articulated motion volume 
ieee june 
gee cipolla 
fast visual tracking temporal consensus 
image vision computing 
hager belhumeur :10.1.1.147.629
efficient region tracking parametric models geometry illumination 
pami 
horn 
computer vision 
mit press cambridge mass 
la cascia sclaroff athitsos 
fast reliable head tracking varying illumination approach robust registration texture mapped models 
pami april 
lucas kanade 
iterative image registration technique application stereo vision 
proc 
image understanding workshop pages 
matthews baker 
active appearance models revisited 
ijcv 
parke waters 
computer facial animation 
ak peters 
vetter 
efficient robust accurate fitting morphable model 
proc 
iccv volume pages 
ieee 

shum szeliski 
construction panoramic image mosaics global local alignment 
ijcv 
wiles 
model acquisition tracking 
pami 
xiao baker matthews kanade 
real time combined active appearance models 
proc 
cvpr washington june 
ieee 
