statistical learning techniques costing xml queries ning zhang peter haas guy lohman chun zhang university waterloo ibm almaden research center university ave waterloo canada harry road san jose ca usa uwaterloo ca lohman ibm com developing cost models query optimization significantly harder xml queries traditional relational queries 
reason xml query operators complex relational operators table scans joins 
propose new approach called comet modeling cost xml operators knowledge comet method proposed addressing xml query costing problem 
relational cost estimation comet exploits set system catalog statistics summarizes xml data set simple path statistics propose new suited xml setting 
traditional approach comet uses new statistical learning technique called transform regression detailed analytical models predict cost 
rendering cost estimation problem tractable xml queries comet advantage enabling query optimizer self tuning automatically adapting changes time query workload system environment 
demonstrate comet feasibility developing cost model proposed navigational operator 
empirical studies synthetic benchmark real world data sets show comet quickly obtain accurate cost estimates variety xml queries data sets 
management xml data especially processing xpath queries focus considerable research development activity past years 
wide variety join navigational hybrid xpath processing techniques available see example 
techniques exploit structural indexes 
xml query optimizer permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings st vldb conference trondheim norway choose large number alternative plans processing specified xpath expression 
traditional relational database setting optimizer needs accurate cost estimates xml operators order choose plan 
unfortunately developing cost models xml query processing harder developing cost models relational query processing 
relational query plans decomposed sequence relatively simple atomic operations table scans nested loop joins forth 
data access patterns relational operators predicted modeled fairly straightforward way 
complex xml query operators path holistic twig join hand lend decomposition 
data access patterns tend markedly non sequential quite difficult model 
reasons traditional approach developing detailed analytic cost models painstaking analysis source code proves extremely difficult 
propose statistical learning approach called comet cost modeling evolution training cost modeling complex xml operators 
previous research cost xml query optimization centered primarily cardinality estimation see 
knowledge comet method proposed addressing costing problem 
current oriented xml repositories consisting large corpus relatively small xml documents large collection relatively small customer purchase orders 
believe repositories common integrated environments 
setting problems encountered modeling costs relatively similar encountered relational setting assessing effects caching comparing random versus sequential disk accesses forth 
hand accurate modeling cpu costs xml operators especially challenging problem relative traditional relational setting due complexity xml navigation 
experiments db xml indicated cpu costs significant fraction higher total processing cost 
initial focus cpu cost models 
demonstrate feasibility approach develop cpu cost model operator adaptation 
ideas insights experiences useful complex operators queries xml relational 
comet methodology inspired previous statistical learning methods develop cost models complex user defined functions udfs see remote autonomous database systems multidatabase setting 
basic idea identify set query data features determine operator cost 
training data comet automatically learns functional relationship feature values cost resulting cost function applied optimization time estimate cost incoming production queries 
setting udfs features fairly obvious values arguments udf simple transformations values 
multidatabase setting determining features complicated example zhu larson identify numerically valued features determine cost executing relational query plans 
authors group queries type effect defining additional categorically valued feature 
xml setting feature identification complex 
features greatest impact cost tend posterior features number data objects returned number candidate results inserted memory buffer depend data observed operator finished executing 
situation analogous happens relational costing relational setting comet estimates values posterior features set catalog statistics summarize data characteristics 
propose novel set simple path sp statistics suited cost modeling complex navigational xml operators corresponding procedures 
comet approach hybrid traditional relational cost modeling statistical learning approach analytical modeling required analytical modeling task relatively straightforward complicated aspects operator behavior modeled statistically 
manner take advantage relative simplicity adaptability statistical learning methods exploiting detailed information available system catalog 
note query features user queries training queries query plan optimizer runtime engine cost model comet training data executes xml operator comet self tuning systems defined relatively rough manner long features important cost determining factors ignored discussed section comet statistical learning methodology automatically handles redundancy features 
statistical learning method comet satisfy key properties 
fully automated require human statistical expertise highly efficient seamlessly handle numerical categorical features able deal discontinuities nonlinearities inherent cost functions 
contribution proposal new transform regression tr method introduced pednault 
method satisfy criteria 
key advantage comet statistical learning methodology xml query optimizer process query feedback exploit comet order self tuning 
system automatically adapt changes time query workload system environment 
idea illustrated user queries fed optimizer generates query plan 
plan execution runtime engine executes operator interest runtime monitor records feature values subsequent execution costs 
comet learner uses feedback data update cost model 
approach leverage existing self tuning technologies :10.1.1.100.9995
observe model initially built feedback loop described training queries user queries 
training phase ends satisfactory initial cost model generated standard techniques fold cross validation see sec 
assess model quality 
rest organized follows 
section provide background information xml query optimization operator 
section describe application comet cost modeling 
section empirical assessment comet accuracy execution cost 
section summarize findings give directions 
background motivate xml query optimization problem give overview operator 
xml processing query optimization running example motivate query optimization problem comet description concrete 
example xquery cases document minor modifications 
example consider expression finds titles books having author named stevens published 
bib doc bib xml bib book authors stevens year return book title book bib path expressions constitute matching part corresponds construction part 
order answer matching part xml query processing engine may generate query plans 
navigate bib xml document find book elements root element bib book element evaluate predicates navigating attribute year element authors 

find elements values stevens value indexes navigate find parent ancestor element book verify structural relationships check remaining predicate 

find twig index tree structures descendant authors book child bib year attribute book 
book check value predicates 
plans best plan depending circumstances 
compute cost plan optimizer estimates cost operator plan index access operator navigation operator join combines costs appropriate formula 
example denote path expressions doc bib xml bib book authors stevens year respectively 
cost plan may modeled formula denotes estimated cost evaluating path expression navigational approach denotes cardinality path expression costing path expression evaluation crucial costing alternative query plans choosing best plan 
algorithm pattern matching match buf root document event traversal event xml node matches match buf set status true non leaf set children status false add children match buf output node add buf predicate tree node add pred buf elseif match buf connected axis skip sibling elseif event xml node matches match buf remove match buf pred buf set status result evaluating predicate status children false remove buf operator slight adaptation stream algorithm described pre parsed xml stored paged trees 
algorithm processes path query single pass pre order traversal document tree 
copies content stream manipulates xml tree returns tree nodes satisfy specified input xpath expression 
difference traversing xml document tree skips portions document relevant query evaluation 
behavior cost modeling highly challenging 
detailed description algorithm scope give highly simplified sketch suffices illustrate costing approach 
behaves approximately pictured algorithm 
parse tree representation path expression xml document matches incoming xml elements parse tree traversing xml data document order 
xml element matches parse tree node element name matches node label element value satisfies value constraints node predicate tree node element satisfies structural relationships previously matched xml elements specified parse tree 
example parse tree shown 
represents path expression bib book authors stevens year title 
parse tree unshaded node corresponds path expression node labeled special node representing starting stevens book authors title year bib parse tree node evaluation document root internal node document tree 
doubly circled node output node 
value constraint predicate associated predicate tree 
shaded 
edges parse tree nodes represent structural relationships axes 
solid dashed lines represent child descendant axes respectively 
predicate attached anchor node book example represents xpath step predicate appears 
brevity simplicity consider path expressions contain axes wildcards branching value predicates 
comet extended handle position predicates variable incorporating features learning model 
comet methodology comet comprises basic approach identify algorithm query data features important determinants cost features unknown priori estimate feature values statistics simple analytical formulas learn functional relationship feature values costs statistical machine learning algorithm apply learned cost model optimization adapt self tuning procedures 
comet approach general apply operator 
section apply specific task modeling cpu cost operator 
describe features determine cost executing provide means estimating feature values set sp statistics describe transform regression algorithm learn functional relationship feature values cost 
briefly discuss approaches dynamic maintenance learning model environment changes 
feature identification determined pertinent features analyzing algorithm experience experimentation 
believe possible identify features automatically part 
seen algorithm employs kinds buffers output buffers predicate buffers matching buffers 
elements inserted buffers performed algorithm higher cost 
chose query features total number elements inserted output predicate matching buffers respectively query execution 
denote corresponding feature variables preds match 
addition number buffer insertions cpu cost influenced total number nodes xml document algorithm visits skip line algorithm 
included number feature denoted visits 
important feature identified results number xml elements returned 
feature affects cpu cost number ways 
example cost incurred entry output buffer removed due invalid predicates line number removed entries roughly equal results 
generates page request cpu cost incurred page cache searched 
cost may incurred page cache 
included number page requests feature denoted requests 
note requests subsumed visits different data layouts may result different page access patterns number visited nodes held constant 
final key component cpu cost postprocessing cost incurred lines 
cost captured feature post process defined total number events trigger execution lines 
statistics feature estimation observe features identified posterior feature feature value determined operator executed 
comet needs estimate features optimization time prior operator execution 
relational setting comet computes estimates posterior feature values set catalog statistics summarize important data characteristics 
describe novel sp statistics comet uses procedures estimating feature values 
simple path statistics describing new sp statistics introduce terminology 
xml document rep xml tree path tree sp statistics xml tree path tree sp statistics resented tree nodes correspond elements arcs correspond step child relationships 
path expression xml tree cardinality denoted simply clear context number result nodes returned evaluated xml document represented simple path expression linear chain non wildcard connected child axes 
example bib book year simple path expression book title book year publisher 
simple path simple path expression 
denote set simple paths simple path comet maintains statistics 
cardinality cardinality 

children number children 

descendants number descendants 

page cardinality number pages requested order answer path query denoted 

page descendants number pages requested order answer path query denoted 
denote sp sp 
sp statistics enumerated order 
sp statistics xml document represented tree defined sp 
sp statistics stored path tree captures possible simple paths xml tree 
example shows xml tree corresponding path tree sp statistics 
note relationship nodes path tree tp simple paths xml tree alternatively store sp statistics sophisticated data structure simply table 
detailed comparisons storage space retrieval update efficiency current scope 
feature estimation algorithm estimation functions visits non leaf node depth order path simple path axis children connected axis skip descendants traversal return results trunk return pages list root leaf paths depth order pair consecutive paths li li add common subpath li li return buf inserts recursive return recursive node return match buffers non leaf node path buf inserts fanout return pred buffers predicate tree node path buf inserts return buffers trunk return buf inserts post process possible paths parse tree rooted buf inserts return algorithm lists functions estimate feature values sp statistics 
estimation functions allow path expressions include arbitrary number axes wildcards branches value predicates 
parameter functions special root node parse tree labeled 
outline rationale function illustrate example shown 
visits function visits algorithm straightforward 
step path expression current followed traversal children ensues 
followed traversal subtree rooted ensues 
parse tree visits bib bib book bib book authors term sum corresponds document root matched node parse tree 
results estimate results cardinality trunk simple path obtained original path expression removing branches 
estimate expensive methods proposed literature 
experiments indicate rough estimate suffices purposes mainly due comet bias compensation section see section empirical verification 
parse tree estimate simply results bib book title 
page requests function pages computes number pages requested evaluating particular path expression 
buffering assumption navigating xml tree depth traversal page read visiting node kept buffer pool descendants visited 
assumption observe 



observation generalized path expressions branches function pages algorithm 
parse tree feature estimate requests bib book authors bib book title bib book year bib book bib book bib book authors buffer insertions recursive queries explain values preds match estimated describe comet method calculating number buffer insertions recursive query 
buffer insertions occur incoming xml event matches nodes matching buffer line algorithm 
xml event create matching buffer entries single parse tree node parse tree nodes connected axes name 
case number buffer insertions induced recursive parse tree node estimated follows nodes returned inserted buffer prefix path root nodes returned inserted nodes returned forth path expression returns results 
total number nodes inserted computed depth xml tree denotes fold concatenation string 
function buf inserts algorithm calculates number buffer insertions specified linear path expression may may contain recursive nodes 
path recursive nodes function simply returns cardinality path 
function returns sum number insertions recursive node 
buf inserts called functions algorithm 
matching buffers feature match total number entries inserted matching buffer stores candidate parse tree nodes expected match incoming xml nodes 
algorithm incoming xml event matches parse tree node entry created child parse tree 
estimate match summing fanout non leaf parse tree node fanout denotes number children 
parse tree recursive nodes match estimated match bib bib book bib book authors bib book authors factor fanout node book parse tree 
predicate buffer output buffer derivation function buffers similar results derivation pred buffers straightforward 
post processing algorithm postprocessing potentially triggered event line 
closing xml node matched parse tree node actual processing needed buffers need maintained lines 
feature post process estimated total number xml tree nodes matched parse tree nodes 
parse tree post process estimated post process bib bib book bib book authors bib book authors bib book title bib book year term results matching root node 
statistical learning discuss comet statistical learning component 
general learning problem set features goal statistical learner determine function approximation cost 
vd query 
vd feature values associated comet uses supervised learning approach training data consists points 
xn xi 
vd ci vj value jth feature ith training query qi ci observed cost qi 
discussed learner initialized starting set training queries obtained historical workloads synthetically generated 
time learner periodically retrained queries actual workload 
posterior feature comet uses estimates feature value computed catalog statistics described section building cost model 
ith training point form xi 
vd ci vj estimate vj alternative approach uses actual feature values training model 
advantage method automatically compensates systematic biases feature estimates allowing comet relatively simple feature estimation formulas 
desirable feature experimentally verified section 
transform regression reasons discussed previously transform regression tr method fit function 
published description tr readily available expend effort outlining basic ideas underlie algorithm details statistical theory implementation current scope 
tr incorporates number modeling techniques order combine strengths decision tree models computational efficiency nonparametric flexibility full automation low estimation errors neural network approach 
discussion suppress fact feature values may estimates discussed section 
fundamental building block tr method linear regression tree lrt 
tr uses having single level lrt feature 
jth feature corresponding lrt splits training set mutually disjoint partitions feature value 
points partition cost vj partition partition partition cost vs vj cost cost vs wj feature linearization projected form reduced training points form vj ci reduced training points fit univariate linear regression model cost function vj 
combining functions partition leads piecewise linear function vj predicts cost function jth feature value 
typical function displayed reduced training points 
standard classification tree methodology automatically determine number partitions splitting points 
observe feature cost approximately linear function transformed feature wj vj see 
corresponds hypothetical scenario plotted pairs wj ci wj vj value transformed jth feature query qi 
statistical learning terminology transformation vj wj linearizes jth feature respect cost 
key advantage methodology completely automated determination transformation 
cost linear respect transformed feature obtain order cost model multiple linear regression transformed training points 
wd ci 
current implementation tr algorithm uses greedy forward stepwise regression algorithm 
resulting model generalized additive form 
vd ajh vj 
initial attempt learning true cost function appears yields order model note step stepwise regression algorithm automatically deals redundancy features features added regression model time features highly correlated features included model 
main deficiency order model feature treated isolation 
true cost function involves interactions order model properly account interactions systematic prediction errors result 
approach problem explicitly add interaction terms regression model extremely hard automate determination precisely terms add 
tr algorithm uses alternative approach gradient boosting determining order model tr algorithm computes residual error test query ci 
vd tr uses methodology described develop generalized additive model predicting residual error cost 
vd 
second order model process iterated times obtain final mth order model form tr algorithm uses standard cross validation techniques determine number iterations manner avoids model overfitting 
tr algorithm uses additional techniques improve speed convergence capture nonlinear feature interactions accurately 
trick output previous iterations regressor variables lrt nodes 
performing simple linear regression analysis kth boosting iteration pairs form vj predict residual error function jth feature tr performs multiple linear regression tuples form vj 

vd order approx imation cost 
technique viewed form successive orthogonalization accelerates convergence see sec 

second trick treat outputs previous boosting iterations additional features current iteration 
generalized additive model kth iteration form 
vd 
vj ad hk function hk obtained lrt jth feature multivariate regression 
emphasize features 
vd need numerically valued 
categorical feature partitioning feature value domain corresponding lrt general form correspond sequential splitting standard classification tree techniques effect partitioning 
categorical feature regressor lrt node means multivariate regression model node degenerate equal fixed constant 
nodes degenerate lrt strictly speaking write hk vj 
hk vj similarly hk 
reduces classical regression tree sense sec 

updating model comet potentially exploit number existing techniques maintaining statistical models 
key issues model maintenance include update model select appropriate training data efficiently incorporate new training data existing model 
discuss issues briefly 
aggressive policy updates model system executes query 
discussed approach incur unacceptable processing time overhead 
reasonable approach updates model periodic intervals cost estimation errors exceed specified threshold analogy example 
describe system architecture scheduling statistics maintenance ideas adapted current setting 
ways choose training set updating model 
possibility queries seen far approach lead extremely large storage requirements large cpu overhead 
suggest alternatives including backing sample queries seen far 
approach responsive changes system environment uses queries arrived time window sample queries 
possible maintain sample queries contains older queries biased queries 
updating statistical model involves recomputing model scratch current set training data incremental updating method 
examples approach statistical model classical multiple linear regression model incremental formulas available updating regression coefficients 
currently method incrementally updating tr model research topic underway 
fortunately experiments indicate recomputing tr model scratch extremely rapid efficient operation experiments indicate tr model constructed training points fraction second 
performance study section demonstrate comet accuracy variety xml datasets queries 
study comet sensitivity errors sp statistics 
examine comet efficiency size training set requires 
data sets total size nodes avg 
depth avg 
fan simple paths rf xml mb rd xml kb nf xml mb nd xml kb tpc mb xmark mb nasa mb dc md mb tc md mb table characteristics experimental data sets experimental procedure added predicted cost actual cost data points obtained path expressions testing sets fold cross validation 
performed experiments different platforms running windows xp configured different cpu speeds ghz mhz ghz memory sizes mb mb gb 
results consistent different hardware configurations 
synthetically generated data sets data sets known benchmarks real world application 
motivating scenario xml processing large corpus relatively small documents experimented data sets containing large xml documents see comet performs 
results promising 
data set generated types queries simple paths sp branching paths bp complex paths cp 
type query contains instance value predicate 
generated possible sp queries random bp random cp queries 
randomly generated queries non trivial 
typical cp query looks text 
data set computed sp statistics 
query data set computed feature value estimates measured actual cpu cost 
estimated feature values actual cpu costs constituted training data set 
measure cpu time query accurately ran query times warm cache elapsed time final run cpu measurement 
applied fold cross validation training data order gauge comet accuracy 
crossvalidation procedure follows randomly divided data set equally sized subsets 
subset served testing set union remaining subsets served training set 
yielded training testing pairs 
pair comet learned model training set applied testing set 
combined predicted cost actual cost data points training testing pairs assess comet accuracy 
procedure carried way synthetic benchmark workloads benchmark data set synthetic queries path expressions benchmark queries testing 
specifically accuracy comet metrics measure comet accuracy 
metric defined set test queries 
qn query qk denote ck actual predicted cpu costs 
normalized root mean squared error nrmse metric normalized measure average prediction error defined nrmse ci average 
cn 
coefficient determination sq metric measures proportion ity cost predicted comet sq ci ci average 
order preserving degree opd metric tailored query optimization measures comet preserves ordering query costs 
pair queries qi qj order preserving provided ci cj set queries 
qn set opd opp opp set order preserving pairs 
maximum prediction error metric defined max ci measures worst case error 
metric frequently commercial optimizers strive average behavior avoiding costly query plans 
costing plans concern practice 
figures follow plot predicted versus actual values cpu cost 
point plot corresponds query 
solid line corresponds accuracy 
display plot accuracy measures defined 
ease comparison display parentheses error percentage actual cpu cost 
actual msec 
actual msec 
actual msec 
predicted vs actual values nrmse sq opd predicted msec 
rf xml cp queries predicted vs actual values nrmse sq opd predicted msec 
nd xml cp queries predicted vs actual values nrmse sq opd synthetic data predicted msec 
xmark mixed queries actual msec 
actual msec 
predicted vs actual values nrmse sq opd predicted msec 
rd xml cp queries predicted vs actual values nrmse sq opd predicted msec 
mixed data sets cp queries actual msec 
predicted vs actual values nrmse sq opd predicted msec 
tpc mixed queries actual msec 
actual msec 
predicted vs actual values nrmse sq opd predicted msec 
nf xml cp queries predicted vs actual values nrmse sq opd predicted msec 
mixed data sets mixed queries actual msec 
predicted vs actual values nrmse sq opd predicted msec 
tc md mixed queries accuracy comet synthetic benchmark real world workloads figures illustrate accuracy comet synthetic workloads systematically stress test comet 
show results cp queries results queries similar 
synthetic datasets generated recursiveness depth xml tree 
combinations produce xml data sets rf xml rd xml nf xml nd xml stand recursive non recursive flat deep 
combinations represent wide range usually extreme cases different properties documents 
table displays various characteristics synthetic data sets 
figures show results cp queries relatively homogeneous data sets 
comet accuracy respectable errors ranging 
shows results cp queries mixed data sets shows results mixed sp bp cp queries mixed data sets 
note presence heterogeneous xml data appear degrade accuracy queries type 
suffices single mixed set data train comet 
comparison figures indicates presence different query types adversely impact comet accuracy 
result borne experiments reported suggests query type fruitfully included additional qualitative feature 
benchmarks real world data tpc benchmark relational data wrapped xml tags 
schema regular recursion tree quite flat 
xmark data set generated scale factor 
fair amount recursion tree fairly deep 
nasa data set real world data having small degree recursion medium depth 
data sets 
multi document dc md data set models web commerce transactional data tpc 
consists small files size kb kb 
documents non recursive quite flat 
text centric multi document tc md data set statistical properties similar reuters news corpus springer digital library 
data set consists files various sizes kb kb 
documents contain recursion quite deep 
characteristics data sets table 
figures show comet accuracy xmark tpc tc md data respectively mixed sp bp cp queries 
omit figures nasa dc md data similar 
comet performs consistently data sets 
synthetic case comet accuracy fairly insensitive type data making suitable environment heterogeneous data changing schemas 
effect errors sp statistics test comet sensitivity errors sp statistics multiplied statistic random nonnegative error ratio prior training testing 
observed values nrmse sq opd varied expected value error ratios 
displays results mixed queries nasa data results scenarios similar 
seen comet remains accurate despite perturbation sp statistics 
key reason mentioned previously comet trained tested estimated feature values 
long feature value estimates err consistent way tend practice comet automatically compensate bias produce accurate cost estimates 
feature allows fairly simple statistics efficient algorithms available www cs washington edu research www repository html accuracy metric sensitivity random errors sp stats nasa expected error ratio nrmse sq opd sensitivity accuracy sp stats errors nasa mixed queries estimate feature values compromising accuracy cost prediction 
efficiency comet types cost incurred comet system usual costs incurred query optimizer cost collecting training data cost building prediction model training data 
self tuning scenario discussed section test queries generated part production workload type cost reduces overhead recording maintaining query feedback results 
experience query feedback systems suggests additional monitoring cost small practice overhead 
assess magnitude second type cost tested training sets sizes 

case time build tr model second ranging second 
fast performance greatly simplifies issue update cost model optimizer simply build new model scratch necessary 
size training set investigated comet learning rate cp queries heterogeneous synthetic data set comprising training points 
selected random queries test queries 
rest data set randomly chose points training set built tr model computed nrmse test queries 
added queries training set rebuilt tr model recomputed nrmse test queries 
continuing manner generated learning curve displayed 
seen accuracies achieved training set size training queries discussed number queries tr model built second 
nrmse number training queries effect training set size accuracy query operators elaborate data complex traditional approach detailed analytical models estimate query costs increasingly unworkable 
outlined comet statistical learning approach cost estimation demonstrated feasibility applying operator 
knowledge comet represents proposed solution problem xml cost modeling 
comet avoids need detailed cost models problem reduced simpler task identifying sufficient usually small set cost determining features developing relatively simple method estimating feature 
key advantage approach permits adaptation flexibility face changing workloads changing computing environment 
flexibility increasingly important light current trends highly distributed systems composed extremely heterogeneous possibly remote unreliable data sources 
plan apply comet problem estimating costs devise mechanisms automatic feature identification 
plan refine methods dynamically maintaining learning model order minimize overheads dealing effectively multiuser environments 
acknowledgment wish edwin pednault help advice respect tr algorithm 
naughton 
estimating selectivity xml path expressions internet scale applications 
vldb 
haas lohman raman 
automated statistics collection db udb 
vldb 
jagadish koudas patel srivastava wu 
structural joins primitive efficient xml query pattern matching 
icde 
barton charles goyal 
streaming xpath processing forward axes 
icde 
chamberlin fernandez kay robie sim 
xml path language xpath 
available www org tr xpath 
ono 
neural networks approach query cost evaluation 
ipsj journal 
bruno koudas srivastava 
holistic twig joins optimal xml pattern matching 
sigmod 
chamberlin fankhauser marchiori robie 
xml query cases 
available www org tr cases 
freire roy sim 
making xml count 
sigmod 
gibbons matias poosala 
fast incremental maintenance approximate histograms 
vldb 
halverson burger krishnamurthy rao tian wang naughton dewitt 
mixed mode xml query processing 
vldb 
hastie tibshirani friedman 
elements statistical learning 
springer 
lee 
self tuning udf cost modeling memory limited quadtree 
edbt 

querying xml streams 
vldb journal 
lee chen 
regression self tuning modeling smooth user defined function costs object relational database management system query optimizer 
computer journal 
natarajan pednault 
segmented regression estimators massive data sets 
sdm 
pednault 
transform regression kolmogorov superposition theorem 
technical report rc ibm thomas watson research center 
garofalakis ioannidis 
approximate xml query answers 
sigmod 
zhu larson 
evolutionary techniques updating query cost models dynamic multidatabase environment 
vldb journal 
schmidt waas kersten florescu manolescu carey busse 
xml benchmark project 
technical report ins cwi 
selinger astrahan chamberlin lorie price 
access path selection relational database management system 
sigmod 
lohman 
leo db learning optimizer 
vldb 
wang jiang lu yu 
bloom histogram path selectivity estimation xml data updates 
vldb 
yao zsu 
benchmark performance testing xml dbmss 
icde 
zhang zsu 
succinct physical storage scheme efficient evaluation path queries xml 
icde 
zhu larson 
building regression cost models multidatabase systems 
pdis 
