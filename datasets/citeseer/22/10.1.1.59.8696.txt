query chains learning rank implicit feedback filip department computer science cornell university ithaca ny usa filip cs cornell edu presents novel approach clickthrough data learn ranked retrieval functions web search results 
observe users searching web perform sequence chain queries similar information need 
query chains generate new types preference judgments search engine logs advantage user intelligence reformulating queries 
validate method perform controlled user study comparing generated preference judgments explicit relevance judgments 
implemented real world search engine test approach modified ranking svm learn improved ranking function preference data 
results demonstrate significant improvements ranking search engine 
learned rankings outperform static ranking function trained considering query chains 
categories subject descriptors information storage retrieval information search retrieval general terms algorithms experimentation measurement keywords search engines implicit feedback machine learning support vector machines clickthrough data 
designing effective ranking functions free text retrieval proved notoriously difficult 
retrieval functions designed collection application collections additional time consuming modifications 
led interest machine learning methods automatically learning ranked retrieval functions 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
kdd august chicago illinois usa 
copyright acm 
thorsten joachims department computer science cornell university ithaca ny usa tj cs cornell edu learning task training data collected ways 
approach relies actively soliciting training data recording user queries asking users explicitly provide relevance judgments retrieved documents :10.1.1.20.378
users willing making significant amounts data difficult obtain 
alternative approach extract implicit relevance feedback search engine log files :10.1.1.12.3161:10.1.1.30.9676
allows virtually unlimited data collected low cost interpretation complex 
irrespective approach best knowledge previous research learning retrieval functions considered query independently 
show ignores valuable information hidden sequence queries clicks search session 
instance repeatedly observe query special collections followed rare books library search system may deduce web pages relevant second query may relevant 
additionally log information allow learn correct spelling mistakes similar way 
example observed users searching lexis nexis repository search lexis nexus mistake 
users search documented reformulate queries :10.1.1.34.5131:10.1.1.26.4691
previous attempted predict query reformulations best knowledge reformulations learn better retrieval functions 
refer sequence reformulated queries query chain 
queries considered independently log files provide implicit feedback results top result set query users rarely look list 
advantage query chains deduce relevance judgments documents seen entire search session 
key contribution recognizing successfully evidence query chains search engine log files learn better retrieval functions 
demonstrate simple method automatically detecting query chains query clickthrough logs 
data show infer preference judgments relative relevance documents individual query results documents returned different queries query chain 
method generate preference judgments validated controlled user study 
adapt ranking svm learn ranked retrieval function preference judgments 
doing propose general retrieval model learn associate individual documents specific query words words occur documents 
differs previous learned ranked retrieval functions method learn general class functions 
demonstrate effectiveness approach real world web search system cornell university library web search 
name implementation search engine available download research community 
name derived word learning implicit feedback opinion learning users 

related learning rank method training data collected offers important way distinguish different approaches 
data usually consists set statements relevance document set documents query 
relevance judgments collected explicitly asking users implicitly observing user behavior drawing 
statements absolute relative 
absolute feedback involves statements particular document relevant query 
relative feedback involves statements particular document relevant query document 
previous learning rank assumed absolute relevance judgments 
hand number methods ordinal regression explicit feedback learn rank crammer singer herbrich 
explicit feedback expensive collect users willing spend additional time provide real world setting 
typical labeled data sets small difficult 
number researchers collected absolute relevance judgments implicitly clickthrough logs :10.1.1.41.9172:10.1.1.30.9676
postulate documents clicked search results highly relevant 
example kemp learning search engine document transformation 
assume results clicked relevant query append query documents 
implicit clickthrough data shown biased relative retrieval function quality ordering :10.1.1.12.3161
interpretation absolute feedback questionable accuracy 
cohen freund propose log data generate relative preference feedback 
approaches consider learning ranking function preference judgments similar lines 
contrast method learned function limited combination rankings fixed set manually constructed experts 
approach learning combination functions area :10.1.1.12.3161
joachims refined interpretation clickthrough log data relative feedback 
suggests ranking clicked document document ranked clicked relevant evaluate validity construction extend query chains 
general ranking function extend learning algorithm query chains 
library cornell edu percentage rank looked clicked percentage time viewed clicked depending rank result 
abstracts viewed rank clicked link mean number abstracts viewed clicked link depending rank 
important innovation learn general ranking function previous associating query words specific documents 
approach previously learn generate abstracts document transformation learn ranking functions 
prior approaches learn associate new documents query combine re order results obtained static ranking functions 
particular query learn retrieve document originally returned coming closest solving limitation previously method kemp extended query chains 
assume implicit absolute feedback making approach susceptible bias noise 

analysis user behavior order infer implicit preference judgments log files need understand users assess search results 
clearly derive valid feedback results user looked assessed 
section explore question 
eye tracking study performed observe users formulate queries assess results returned search engine select links click 
undergraduate student volunteers instructed search answers navigational informational queries 
involved finding specific web page involved finding specific information 
subjects asked start google search page find answers 
restrictions queries may choose reformulate queries links follow 
users told goal study observe people search query 
smg smg html 
smg smg html 
smg smg html 
smg smg html 
smg smg html 
query cornell residence dear uncle questions tuesday may 
dear uncle questions thursday 

cornell close ties 
october years age 
cornell competes housing market example queries result sets 
web told specific interest behavior results page google 
clicks results returned google pages connected results recorded proxy 
movement eyes recorded asl commercial eye tracker applied science technologies bedford ma 
details experimental setup provided 
shows fraction time users looked clicked top search results query 
tells users usually look top result abstracts 
interestingly note despite top documents receiving equal attention users click result 
adapted shows number abstracts viewed result clicked 
tells users usually scan results order top bottom 
see users usually look click 
analysis showed usually immediately clicked 
conclude users typically look results clicked 
previous studying web search behavior observed users rarely run single query immediately find suitable results 
tend perform sequence queries question 
query chains observed eye tracking study 
mean query chain length queries particular questions asked laboratory environment expected influence value 
number papers successfully learn predict query reformulations 
success task suggests problem detecting query chains address feasible 

log files feedback section details approach generating relative preference feedback query clickthrough logs implemented search engine 
evaluation approach results eye tracking study 
consider queries shown examples demonstrate value query chains 
shows results user running query click skip click skip click skip earlier query click click click click second click second top earlier query feedback strategies 
consider single query query preceded query query dot represents result document indicates result clicked 
generate constraint arrow shown respect query marked 
cornell university library search page 
user searching national digital library foundation website retrieved meeting notes people working 
desired page results probably contain word 
second query search performed google participant eye tracking study attempting find name house cornell built 
get results fact top contain relevant information 
cases single query feedback informative relevant documents retrieved 
case results simply contain documents relevant query 
relevant document user look far results see 
hand queries observed user continued running queries 
queries successful 
user finds relevant document query reasonable assume user preferred seen relevant document results returned earlier 
recognizing information necessary deductions search engine log files propose specific strategies generating preference feedback query chains 
defer discussion group queries query chains section 
implicit feedback strategies generate preference feedback strategies 
strategies illustrated 
strategies show preferences inferred query chains 
sample query chain feedback generated feedback strategies 
queries run returned documents 
document query clicked 
di dj means di preferred dj respect query click skip proposed :10.1.1.12.3161:10.1.1.30.9676
strategy proposes clicked document marked higher ranked document clicked relevant 
preference indicated arrow labeled query show preference respect query 
expect valid eye tracking study showed users view results order user click document considers relevant document observed 
note preferences stating clicked document relevant relevant ones clicked 
second strategy click click second fact users typically view top results clicking 
states document clicked second relevant second 
reasonable assume having considered options user click relevant 
strategies identical generate feedback respect previous query 
intuition queries belong query chain user looking information 
user new results earlier query preferred clicked document skipped 
strategies query chains 
strategy click skip earlier query states clicked document preferred result clicked earlier query query chain 
judgment respect earlier query eye tracking study revealed users usually look document past clicked generate preference document 
event documents clicked earlier query fact users usually look top results 
exploited feedback strategy click top earlier query generating preferences top results 
unusual case results earlier query strategies select random document results 
ultimately query chain strategies generate preference feedback 
unnecessary state thing respect query presumably preference satisfied user seen result earlier 
strategy accuracy click skip click click second click skip earlier query click top earlier query inter judge agreement table accuracy strategies generating pairwise preferences clicks 
base comparison explicit page judgments 
note cases cover preferences strategies 
gives sample query chain feedback generated case 
accuracy feedback strategies feedback strategies proposed intuitively appealing quantitative evaluation necessary establish degree validity 
determine accuracy individual strategy conducted controlled experiment setup eye tracking study described section additional subjects 
subjects evaluated far preferences derived feedback strategies agree explicit relevance judgments independent judges 
subjects collected results associated web pages returned google cache recorded sessions 
grouped results query chain subject collected explicit relevance judgments judges 
judges asked weakly order results encountered query chain relevance question 
avoid biasing judges order results judges randomized judges abstracts google presenting results 
query chains assessed judges inter judge agreement verification 
agreement judges reasonably high 
judges expressed strict preference pages agree direction preference cases 
evaluate extent preferences generated clicks agree explicit judgments 
table summarizes results 
table shows percentage times preferences generated clicks strategies agree direction strict preference relevance judge 
lines table show accuracy strategies exploit query chains 
click skip strategy accurate substantially significantly better random baseline 
furthermore reasonably close accuracy average agreement explicit judgments different judges serve upper bound accuracy ideally expect explicit user feedback 
second query strategy click click second appears accurate 
produces fewer preferences queries user clicked exclusively link confidence intervals large 
independent accuracy preferences strategy probably informative confirm current ranking suggest reordering 
lines table show accuracy strategies exploit query chains 
click skip earlier query click top earlier query significantly accurate random 
particular accuracy click top earlier query close average agreement judges 
note strategy produces particularly informative preferences associates documents query words may occur document 
possible explanation difference accuracy tween query chain strategies apply different types query chains 
click skip ear query applied previous query received click strategy click top earlier query applied precisely opposite case 
investigate ef fect difference evaluated variant click top earlier query 
variant generates preferences analogous click top earlier query chains previous query receive click excluding clicked results 
accuracy strategy indicating absence click followed query click particularly strong evidence regarding relevance results earlier query 
conclude preferences generated clickthrough logs reasonably accurate convey information regarding user preferences 

evaluation environment previous section showed preferences generated logs files accurate learn improved retrieval system 
address question constructed publicly accessible real world search engine 
search engine implements full text search web pages maintained cornell university library cul 
collection includes web pages 
nutch search engine starting point search engine effectively wrapper nutch implements logging log analysis learning reranking evaluation functionality 
designed allow number different ranking functions plugged 
experiments chose nutch built retrieval function baseline compare build 
nutch retrieval function cosine distance incorporates modifications suitable web search including special cases phrase matches html fields 

detecting query chains order query chains method identify 
section propose heuristic demonstrate effectiveness 
basis evaluation created dataset search logs cul search engine 
manually labeled query chains logs period weeks 
search logs recorded query date ip address results returned number clicks results session id uniquely assigned user 
extracted list queries grouped ip address sorted chronologically 
queries ip address queries hours automatically marked www nutch org doc ids doc ids abstracts abstracts seconds seconds table features learn classify query chains 
queries times 
respective result sets top results 
belonging query chain 
resulted queries 
judges authors individually grouped queries query chains manually search engines resolve uncertainties query person followed department person faculty member 
judges combined identified query chains resolving small number disagreements investigation 
pair queries ip address half hour generated training example constructing feature vector 
training example labeled query chains identified manually 
queries belonged query chain example labeled positive 
labeled negative 
led training examples labeled positive 
feature vector generated queries consisted features shown table 
data trained number svm classifiers various parameters 
classifiers learned tended label examples positive 
best performing models svm rbf kernel 
evaluating fold cross validation gave average accuracy precision 
compares accuracy precision simple non learning strategy assume pairs queries ip address half hour query chain 
difference relatively small computing feature vector query pair relatively expensive particular depends abstracts retrieved decided rely simply heuristic measure 
judged precision sufficient purposes 
considered extending half hour window training data order increase recall decided recognizing sufficient number query chains doing 
gain insight properties query chains trained linear svm data computed total weight feature 
features largest positive weight measures cosine distance doc ids doc ids measures overlap documents top results 
indicates queries similar retrieve documents query chain 
feature largest negative weight measures minimum number results returned query normalized 
indicates queries returns results queries query chain 
interpretation returns results user run second query 
conclude possible segment log files query chains reasonable accuracy 

learning ranking functions log files recording user behavior web search engine shown transform log records preference judgments section identifying query chains method section 
algorithm learn preferences evaluate search engine described earlier 
assume input preference judgments documents di dj query form 
di dj preference judgment indicates di preferred dj retrieval model chose linear retrieval function rel di di di define function maps documents queries feature vector 
intuitively thought feature vector describing quality match document di query weight vector assigns weights features giving real valued retrieval function higher score indicates document di estimated relevant query task learning ranking function learning optimal ranking svms modified ranking svm learn equation 
briefly introduce ranking svms generalize ordinal regression svms 
start rewriting equation di dj add margin non negative slack variables allow preference constraints violated done classification svms 
yields preference constraint di dj ij efficiently find minimizes number violated constraints minimize upper bound number violated constraints ij 
simultaneously maximizing margin leads convex quadratic optimization problem minw ij ij ij subject di dj ij ij add constraints optimization problem advantage prior knowledge learning rank setting 
retrieval function model specify mapping di 
definition key determining class ranking functions learn particularly important determining usefulness method 
define types features rank features rank term document features terms 
rank features serve exploit existing retrieval functions rel term document features allow learn fine grained relationships particular query terms specific documents 
need definitions 

tn terms words dictionary 
query set terms 

dm set documents collection 
assume original search engine number available retrieval functions rel define ordered set results ranked query experiments consists single ranking function provided nutch sake simplicity 
rank rank terms rank terms rank rank rank rank dm tn indicator function 
looking term features terms explore rank features fi rank 
retrieval function rel fi rank features ranks 
set rank document fi specified rank 
rank features allow learn weights rankings original search results 
allows learned ranking function combine different retrieval functions different weights done prior described earlier 
consider specific scores assigned rel order account potentially different magnitudes scores different retrieval functions 
ensures method generalize settings access scores assigned documents document ranks 
example document rank query retrieval function rank 
document ranked top retrieval function features rank 
means documents ranked top results retrieval function rel indistinguishable rank features increase maximum rank considered arbitrarily 
chose cutoff extremely rare users look top results 
nm term document features 
convenience term correspond term di tj terms 
term document pair term document features allow ranking function learn associations specific query words documents assigning non zero value appropriate weight 
usually extremely large number features appear training data ignored 
furthermore feature vector terms sparse 
particular docu ment query terms term features set 
specifically terms value di tj non zero 
sparsity problem suited solving support vector machines 
positive value weight term associated feature term indicates di relevant queries containing term tj negative value means opposite 
adding prior knowledge learning rank additional prior knowledge incorporated problem 
absent information documents higher rank original ranking ranked higher learned ranking system 
intuitive average expect document relevance decreasing function original rank documents original ranking function particularly poor 
define additional constraints section 
practical importance add constraints training data relevance judgments generated state lower ranked document preferred higher ranked document 
additional constraints trivial undesirable solution optimization problem equation reverses original ranking assigning negative value weights corresponding rank features 
see consider 
click skip preferences satisfied rankings reversed 
preferences common click click second preferences 
preferences classes preferred document presumably lower results results think bottom results preferences satisfied entire ranking reversed 
add additional hard constraints optimization problem specified equation 
constraints require weights rank features greater constant positive value wmin 
wmin intuitively wmin limits quickly original ranking changed training data 
see briefly consider setting single ranking function query returns results 
di ranking ranking combined example rankings results combined outputs generate starting top ranked document ranking document ranked position 
case rank 
rank 
rank 
calling part corresponds rank features equation get rank wmin rank wmin rank wmin say document preferred original results 
ranked highest rel rel 
know section term non zero terms 
expanding simplifying imply terms wmin terms term wmin terms term corresponds term 
larger wmin larger magnitude term term happens 
ranking svm minimizes ij terms large sufficient training data support reordering 
evaluation methodology order evaluate results need unbiased method comparing ranked retrieval functions 
purpose method detailed 
method shown give accurate assessment retrieval quality reasonable assumptions 
ranking functions users combination results 
know users scan results top bottom results presentation bias favoring ranking function 
evaluation method built search engine 
shows example rankings different retrieval functions combination combined 
seen seen number results user seen rankings respectively looking top results combined ranking 
seen seen defined smallest number results combine produce top results combined ranking 
generate combined ranking seen seen seen 
example user looks top results combined ranking satisfied seen seen 
user looks top results seen seen 
compensate bias results seen bigger seen randomly switch half time 
means expectation seen seen 
property proved rigorously 
user combined ranking need evaluate rankings preferred 
determine results user looked lowest ranked clicked document user stopped scanning results conservative estimate 
rankings equally expect user click just results seen equal number expectation 
measure clicks number documents clicked top seen results similarly clicks 
example say user clicked 
infer user looked top results 
seen seen 
clicks clicks 
expectation clicks clicks conclude user prefers ranking evaluating ranking functions count clicks clicks clicks clicks 
binomial sign test verify difference counts clicks clicks clicks clicks statistically significant 
say ranking preferred 
training ranking svm collected training data cul search engine original ranking function june december 
time recorded user queries clicks observing queries clicks 
collecting data users saw results ranked built nutch retrieval function denote rel 
gave preferences constraints applying strategies introduced 
call preferences 
preferences generated query chain strategies 
call subset preferences pnc 
adding hard constraints described trained ranking svm sets preferences linear kernel default value sv light 
set wmin 
preferences learned retrieval function preferences pnc learned 
model support vectors 
ranking model learned query chains instantiated features 
number features instantiated expected grow linearly size document collection sub linearly amount training data collected depending user search behavior 
pose problem svm solver preference judgments sparse 
evaluation user prefers mode chains indifferent vs rel vs table results cornell library search engine 
rel original retrieval function trained query chains trained query chains 
results discussion evaluated ranking functions cul search december february evaluation method described section 
user connected search engine randomly selected evaluation mode user 
user saw ranking combining rel ranking combining 
consistency kept combination duration user session user immediately re ran query may confusingly get different results 
evaluation collected queries evaluation mode 
results evaluation modes shown table 
results show number interesting properties 
firstly time ranking function trained query chains performs differently original ranking function rel 
time trained ranking functions perform differently 
particular values indicates method difference search engine performance 
original ranking function reasonable surprising values higher 
long method cause relevant documents ranked highly rel lowered rank see identical performance cases rel performs 
secondly table see outperforms rel expect random ranking functions equally 
binomial sign test null hypothesis ranking functions equally effective able reject null hypothesis confidence 
establishes learned ranking function improvement original 
course new ranking function collecting new training data re run learning process 
expect produce continued improvement ranking performance 
model trained query chains outperforms model trained query chains confidence test 
demonstrates exploiting information query chains log files able see measurable additional improvement search engine performance see extra information 
may wonder sense learn associations specific query words documents 
initial training queries table shows top words appear frequently queries 
see queries tend repetitive 
ignoring stopwords top words remaining words appears queries 
top words removing stopwords appears word fraction queries library bibliography annotated reserve citation web course table common words appear queries training data fraction queries occur 
word document weight lexis nexis academic universe cul collection reuleaux cul digital collections printable news notes oed dictionaries encyclopedias management meeting notes management meeting notes management meeting notes management meeting notes instruction library research workshops table positive negative feature weights ranking function learned query chains cornell university library cul search engine queries 
popular queries appear documents truly relevant query 
surprising learning individual query word document associations see significant improvements ranking results 
order understand improvements coming useful look word document features largest positive negative weights 
top bottom features table 
consider top features part describe sensible associations 
feature associated main homepage lexis nexis library resource 
clearly spelling correction search originally returning results 
search places correct document top results 
feature returns main web page 
search previously returned results particularly useful 
top titled answers frequent job searching research questions happened mention access campus 
feature reuleaux associated faq page page cul digital collections 
web page provides clear link site describes models designed professor reuleaux 
contrasts original top result broken link second result newsletter passing model collection 
feature little practical interest remove stopwords 
fifth word oed acronym oxford english dictionary 
associated document clearly links contrast original top result information bulletin showing set screen shots get oed things 
features negative weights table equally interesting 
relate meeting notes mentioning national digital library foundation 
original ranking function search generated just results meeting notes 
learned system search returns similar results search national digital library foundation 
results appear slightly useful short abstracts 
discovered fact search engine indexed main web page 
see search system recognized users running chains queries looking website successful finding 
despite worst results query pushed results list 
fifth feature harder interpret log files appears users looking department learning instruction saw result repeatedly skipped 
document appear top result query instruction 

demonstrated query chains extract useful information search engine log files 
presenting algorithm infer preference judgments log files showed preferences judgments valid independent learning method 
method identify query chains algorithm uses preference judgments learn improved ranking function 
model ranking function general previous 
particular allows algorithm learn include new documents originally initial search results learned rankings 
evaluation shows approach effective learn highly flexible modifications original search results 
search engine available research community natural question arises setting tolerance method noise training data particularly users click malicious ways 
noisy real world data plan explicitly study effect noise words meanings click spam approach 
strategies section give equal weight pair queries query chain 
suspect additional information position query chain click sequence clicks chain 
particular possible query clicks may informative earlier ones 
thirdly exploiting fact possible collect virtually unlimited amounts search engine log data believe methods extended learn personalized ranking functions 
currently refining search engine arxiv org print archive order conduct experiments 
practical perspective approach pushes www cs cornell edu filip www arxiv org limit problems current svm implementations solve reasonable time due number constraints generate 
believe room improvement learning methods efficiently deal large numbers constraints example incremental optimization approach 
alternative learning methods svms optimize preference constraints able learn sufficiently general ranking functions 

acknowledgments undergraduate masters students alex cheng patel working initial implementation cul search engine 
colleagues laura bing pang gay collaboration eye tracking study 
paul help support regarding full text search engine cornell university library web pages simeon warner paul interesting discussions topic 
subjects eye tracking study relevance judges 
funded nsf career award iis kd 

bartell cottrell 
learning retrieve information 
proceedings swedish conference connectionism 
bartell cottrell belew 
automatic combination multiple ranked retrieval systems 
annual acm conference research development information retrieval sigir 
beeferman berger 
agglomerative clustering search engine query log 
acm international conference knowledge discovery data mining kdd 
boyan freitag joachims 
machine learning architecture optimizing web search engines 
aaai workshop internet information systems august 
broder 
taxonomy web search 
sigir forum 
cohen shapire singer 
learning order things 
journal artificial intelligence research 
crammer singer 
ranking 
proceedings conference neural information processing systems nips 
brill 
spelling correction iterative process exploits collective knowledge web users 
proceedings conference empirical methods natural language processing emnlp pages 
freund iyer schapire singer 
efficient boosting algorithm combining preferences 
international conference machine learning icml 
furnas 
experience adaptive indexing scheme 
proceedings conference human factors computing systems chi pages 

eye tracking analysis user behaviors online search 
master thesis cornell university 
joachims gay 
eye tracking analysis user behavior www search 
poster proceedings conference research development information retrieval sigir 
herbrich graepel obermayer 
large margin rank boundaries ordinal regression 
editor advances large margin classifiers pages 
joachims 
making large scale svm learning practical 
burges smola editors advances kernel methods support vector machines 
mit press 
joachims 
optimizing search engines clickthrough data 
proceedings acm conference knowledge discovery data mining kdd 
acm 
joachims 
evaluating retrieval performance clickthrough data 
franke renz editors text mining pages 
physica springer verlag 
joachims pang gay 
accurately interpreting clickthrough data implicit feedback 
annual acm conference research development information retrieval sigir 
jones 
query word deletion prediction 
annual acm conference research development information retrieval sigir pages 
kemp ramamohanarao 
long term learning web search engines 
editor pkdd pages 
lau horvitz 
patterns search analyzing modelling web query refinement 
proceedings th international conference user modeling 
karypis kumar 
expert agreement content reranking meta search environment 
proceedings th international conference world wide web www pages 
garg zhou huang 
classification approach ranking sorting problems 
lecture notes artificial intelligence volume pages september 
williams 
query association effective retrieval 
proceedings th international conference information knowledge management pages 
silverstein henzinger marais 
analysis large altavista query log 
technical report digital src 
tan chai ng 
lee 
applying training clickthrough data search engine adaptation 
proceedings th international conference database systems advanced applications dasfaa 
