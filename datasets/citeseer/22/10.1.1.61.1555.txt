learning extract entities labeled unlabeled text rosie jones may cmu lti school computer science carnegie mellon university pittsburgh pa submitted partial fulfillment requirements degree doctor philosophy 
thesis committee tom mitchell chair alex hauptmann roni rosenfeld ellen riloff university utah copyright rosie jones research supported part national science foundation lis rec darpa research contract 
views contained document author interpreted representing official policies expressed implied government 
keywords information extraction machine learning semi supervised learn ing graph properties labeled unlabeled data imagine trying build system identify people locations arbitrary types human language familiar 
knew kinds words represent classes peo ple locations organizations examining text data occur learn recognize contexts occur 
knew kind contexts occur recognize instances classes 
address chicken egg problem assigning computer giving small number examples class initial examples learn 
explore algorithms alternating looking noun phrases local contexts lows learn recognize members semantic class context 
examine active learning algorithms eliciting useful labels ex pert improve learning performance customized domain 
explore graph structure underlying labeled unlabeled data showing properties graph structure explain performance inform design choices applying methods new tasks 
ii mentors advisor carnegie mellon tom mitchell manager yahoo dan taught research 
owe great deal authors collaborators ghani ellen riloff mladenic 
committee members alex hauptmann roni rosenfeld making suggestions improve thesis valuable input thesis received fernando diaz ghani se slattery dave hershberger chris madani 
benefitted groups students discuss state theses 
se slattery joseph sullivan thom formed core lti stu dents laura mayfield greg aist jade goldstein yan qu klaus zechner kathy baker formed 
tom pierce jacob benjamin rey providing seed words short notice 
appreciate general advice encouragement support way richard plunkett orna raz nathaniel daw francisco pereira paul bennett paul 
various pittsburgh hosts rachel collins jimi shanahan ann funge probst guy lebanon helped get 
paul gorman cathy jones 
iii iv contents problem description 
thesis statement 
summary results 
contributions 
dissertation roadmap 
background linguistic terminology 
noun 
noun phrase 
head noun phrase 
verb 
verb phrase 
prepositional phrase 
lexico syntactic context 
sundance autoslog 
supervision machine learning 
supervised learning 
unsupervised learning clustering 
semi supervised learning 
information extraction problem 
semantic class finding 
dictionary construction 
semantic class labeling 
semantic relation finding 
anaphora coreference resolution 
automating 
clustering semantic class labeling 
training data bottleneck automating 
scope problem address 
target classes 
inputs 
outputs 
related 
information extraction 
active learning 
graph structure semi supervised learning 
chapter 
comparison bootstrapping algorithms information extrac tion 
data representation 
data sources 
data preprocessing 
task representation 
weak initial labeling seeds 
seeds 
vi fixed initialization 
active initialization 
algorithms 
algorithm inputs 
single view bootstrapping algorithms 
feature set bootstrapping algorithms 

cotraining 
coem 
assumptions biases 
initialization seeds assumption 
feature sets redundancy assumption 
relevance training data assumption 
syntactic semantic correlation assumption 
summary assumptions biases 
empirical comparison bootstrapping algorithms 
extraction test corpus 
evaluation metrics precision recall breakeven 
results comparing view bootstrapping algorithms 
bootstrapping improves seeds 
stopwords important coem 
benefits stopwords increased pre cision 
small gains correcting labels coem 
initial seed choice influential results 
training set size distribution affects results 
transductive learning sensitive errors head labeling results comparing coem em 
vii initialization conditions 
frequency information 
effect stopwords em 
corpus size em 
em versus coem 
chapter 
chapter 
active learning semi supervised 
related 
training set size distribution 
example labeling versus single feature set labeling 
number examples labeled active learning 
active learning selection methods 
initialization conditions 
properties model 
bootstrapping algorithms 
choice bootstrapping algorithm 
combining bootstrapping active learning 
results 
uniformly selected labeled examples little utility 
example selection density 
single feature set labeling 
disagreement density active learning 
active learning compensates infrequent seeds 
number examples labeled 
active learning useful active initialization coem viii active learning em 
chapter 
analysis analyzing results experiments 
breakeven score summary result 
spearman rank correlation test 
small world nature noun phrase context cooccurrence graph small world graphs data 
graph samples underlying distribution 
small world power law graph properties 
measuring graph properties noun phrase context data predicting performance graph properties 
number unique seeds head matching np graph number unique seeds exact matching np graph number unique seeds head matching nps largest com ponent 
number unique examples labeled sum seed node degrees total examples labeled seeds 
number components containing seed 
number unique seed labeled examples largest component unique contexts covered seeds 
combinations predictors multivariate regression 
cross class comparison node degree predictor 
graph features active learning 
feature set independence 
algorithm desiderata small worlds 
questions designing bootstrapping algorithms 
ix know set seeds lead successful bootstrapping 
select seeds bootstrapping 
decide classes represented seeds confusable 
know data 
correct examples labeled seeds forming active learning 
properties active learning algorithm 
chapter 
held task task selection 
seed selection 
choice training data 
seed selection introspection 
select seeds training data 
active initialization 
bootstrapping active learning algorithm 
bootstrapping algorithm 
number examples labeled active learning 
active learning algorithm 
evaluation 
results 
products 
dates times 
chapter 

active learning impact correcting initial ex amples 
highly connected noun phrases important learning graph structure important learning 

pre existing dictionaries 
applicability range semantic classes 
applicability languages 
alternative data representations sources 
automatically acquiring relevant training data 
applicability domains data types 
predicting improving algorithm performance data structure 
xi xii list tables common prepositions english 
summary issues consider chapter 
top level economic sectors hierarchy 
pages col lected sectors sector data set 
trec wt data subsets experiments number documents data subset parsing 
heuristic algorithm inserting periods web pages subsequent pars ing 
html stripped pages algorithm applied 
lexico syntactic contexts 
notation referring instances 
descriptive statistics corpora 
seed words initialization 
density seed words instances fixed corpus web pages percent training collection positive sample instance pairs 
locations task random sets country names matched variable numbers instances corporate web page data 
shown average number instances matching sets exact number instances matching original country names entire list country names 
country names basic experiments frequently occurring 
country names list country names match initial examples 
xiii precision recall labeling examples automatically seed heads 
recall estimated percentage positive examples sample instances training corpus 
precision labeling examples automatically seed heads people 
precision labeling examples automatically seed heads organizations 
precision labeling examples automatically seed heads locations 
distribution nps test set 
distribution contexts test set 
conditions inter rate evaluation stands np context entire sentence np context pair appeared 
ambiguity contexts noun phrase context pairs test set training set coverage 
stopwords experiments 
examples probabilities class membership multinomial binomial occurrences 
binomial occurrence counts calculate probabilities removing frequency information higher ini tial probabilities class membership assigned contexts greater diversity seeds 
trec wt data subsets experiments number doc uments subset number examples extracted subset 
see number examples matching seeds increases corpus size 
number positive examples size vocabulary positive examples test set classes locations organizations people 
initialization conditions people class em 
initialization conditions locations class em 
initialization conditions organizations class em 
summary dimensions vary performing active learning bootstrapping semantic classes noun phrases 
xiv noun phrases selected labeling frequent examples noun phrase context pairs selected labeling 
frequencies number different contexts noun phrases occurred selection number occurrences contexts 
people locations classes feature set disagreement se lected examples seeds heads 
eliminate effect performing active initialization excluding examples seeds heads pool available active learning 
summary experiments 
comparison single number summary statistics experimental results high level graph properties data examine tures test effect algorithm performance 
training examples feature vector format 
example fea tures noun phrase context 
examples labeled positive examples unlabeled 
average node degree class sector test set noun phrases contexts 
see nodes target classes tend higher average degree average node degree test set 
explained fact pronouns included classes 
presence may explain high average node degree noun phrases organizations people classes 
higher average node degree contexts locations class may explained fact varied ways referring locations people organizations 
high degree noun phrases contexts 
power law coefficients node degree noun phrases connected con texts graph largest component 
see mea power law coefficient graph give different result measuring largest component 
xv clustering coefficients graphs noun phrases contexts entire graph largest component 
cluster ing coefficient random graph size shown parentheses largest component 
characteristic path length average average path length graph clustering coefficient largest component graph 
see paths short similar path length random graph clustering coefficient higher random graph 
means graph small world properties 
features predictive algorithm performance spearman correlation coefficients 
number contexts labeled seed predictive algorithm performance 
see sample contexts selected seed appear unambiguously indicative target class locations 
interactions multiple predictor variables obtain correlation rank algorithm breakeven higher correlation obtained best predictor unique contexts covered seed isolation 
features predictive algorithm performance spearman correlation coefficients consider experiments conducted active learning combinations random sets locations seeds number example labeled active learning active learning method 
correlations significant level 
combination features predicting algorithm performance boot strapping active learning random seeds sets locations 
correlation model algorithm performance greater correlation individual feature isolation 
joint marginal probabilities np context pairs 
mutual information noun phrases contexts 
xvi mutual information noun phrases contexts class labels test examples 
shown parentheses maximum possible value mutual information min class class 
minimum possible value 
sets seeds products class chosen introspection labelers 
set chosen difficult 
indicates examples training corpus matched seed set 
seeds products task 
seeds selected examining top frequent noun phrases identifying terms unambiguously products 
shown number times seed words occurred noun phrases nps number times seed words occurred heads noun phrases np heads number unique noun phrases seed head np heads number unique contexts labeled seed contexts common contexts labeled seed 
examples total labeled seeds 
results extracting test examples models obtained bootstrap ping products class seeds created introspection seeds chosen frequency freq 
set matched seeds seen baseline reflecting prior distribution products terms test corpus 
set chosen ambiguous containing brand names may names 
set performed worse baseline 
frequency seeds freq instances labeled active learning perform best remove test examples match seed freq 
precision dictionary extraction products 
results extracting test examples models obtained bootstrap ping dates times class seeds created looking frequent noun phrases training corpus seeds years 
xvii xviii list figures document marked results information extraction sub tasks unlabeled document pro active semantic class finding shown finding box boundaries textures af ter semantic class labeling shown labeling boxes location finding semantic relations generating ar row labels location anaphora resolution arrow labels identity 
automatically labeling data seeds head labeling correcting labels active initialization 
comparison bootstrapping coem meta bootstrapping ing classes locations people organizations 
comparison effects seeds noun phrases seeds heads head labeling models learned bootstrapping coem extract unseen test set 
seeds head labeling lead pre cision poor recall 
bootstrapping coem improves recall loss precision 
comparison allowing stopwords model ignoring frequency information forbidding stopwords frequency information coem 
best results obtained allowing stopwords model frequency information appear affect results greatly 
comparison allowing stopwords model 
allowing stopwords gives improvement results coem 
xix comparison effects hand labeling examples matching seed words commencing bootstrapping active initialization boot strapping assuming correct coem 
small gain obtained labeling data input 
seeds chosen baseline experiments effective 
country names substantially improve results 
original seeds cover large number instances country names sector training corpus 
seed set corresponding instances seeds training data generally produces better results coem 
effects corpus size coem 
larger training set significantly better locations 
organizations training set matches distribution test set appears better fit 
people class training set matches distribution test set appears slightly better fit low recall scale 
coverage positive test examples noun phrase context training set 
transductive learning versus standard learning coem classes locations organizations people 
initialization unlabeled examples small values random values output coem affect head labeled examples labeled seeds 
results em frequency information 
results em stopwords 
log likelihood plotted breakeven point 
see log likelihood predictive accuracy organizations class people locations classes 
results em large corpora 
comparison em baseline coem algorithm 
initialization con ditions shown em 
stopwords permitted model frequency information em coem 
xx automatically labeling data seeds head labeling optionally cor labels active initialization performing active learning interleaved bootstrapping 
unlabeled head labeled examples candidates active labeling 
active initialized examples treated active labeled examples candidates relabeling 
compare baseline active learning adding labeled examples examples selected uniformly random locations people tions interleaved bootstrapping coem 
compare models allow disallow stopwords 
adding labeled examples examples selected density locations people organizations 
adding labeled noun phrases selected density locations people organizations 
adding labeled noun phrases selected context disagree ment locations people organizations 
adding labeled examples selected density feature set disagreement locations people organizations 
active learning compensates infrequent seeds 
left randomly cho sen locations seeds infrequent training corpus 
center randomly chosen seeds relatively frequent training corpus 
right frequent seeds near complete list country names seeds 
cases active learning produces comparable results examples labeled active learning 
active learning compensates infrequent seeds 
random seeds active learning produce considerable improvements 
left infrequently occurring seeds right frequently occurring seeds 
labeling examples improves results 
people density selection labeling just examples greatly improves results 
labeling examples improves results disagreement active learning people locations organizations little improve ment seen 
xxi breakeven point iteration 
see gains active learning come iterations examples labeled labeling continues improve results 
organizations class dip iterations 
may due ambiguity examples containing labeled positive organizations may lead model incorrectly identify people organizations examples labeled 
data important labels 
labeling active learning impact active initialization 
combining active initialization active learning provides modest incre mental gains people class 
adding labeled examples examples selected uniformly random locations people organizations 
coem em benefit greatly examples selected uniformly random random ini initialization coem 
em select examples labeling density see large improvements results people class organizations class 
transcends initialization condition uniform ac tive labeling 
breakeven versus iteration density active learning 
single feature set labeling reasonably successful em 
provided great benefit organizations people classes 
select examples labeling disagreement noun phrase context see largest improvements organizations class half examples selected original head labeled examples 
eliminating manual relabeling automatically labeled examples active initialization see im classes 
different initial seed sets labeling examples frequency 
starting random country names performs extremely poorly con starting country names 
different initial seed sets random country names perform feature set disagreement active initialization examples labeled compared country names 
different initial seed sets random country names reasonably ef em label examples context disagreement 
classes labeling examples greatly improves results em 
particular people class labeling examples provides biggest gains model effectiveness 
organizations locations adding examples continues improve effectiveness model 
examples labeled people locations classes perform slightly better disagreement labeling 
breakeven score versus iteration number em examples la iteration 
people locations class perform slightly better disagreement labeling 
organizations better density labeling 
large corpus different distribution label examples density selection recover losses accuracy due train test corpus mismatch 
instance represents edge joining nodes graph 
ex ample instance flew china represented nodes flew china edge joining 
graph shown left 
take sample graph may wind graph shown right 
edges nodes missing general structure similar 
noun phrase context degrees follow power law 
fit line log log plot find power law parameter noun phrases contexts respectively 
asymptotic values power law coefficient 
sector component size 
total node degree examples labeled seeds versus breakeven xxiii number components covered seeds versus breakeven 
number contexts labeled multiple seeds versus breakeven 
total node degree examples labeled seeds versus breakeven classes 
asymptotic values mutual information 
example graphs attain lower bound mutual formation noun phrases contexts class upper bound min 
positive examples shown bold edges 
list algorithms active initialization 
general procedure single feature set bootstrapping algorithms weakly labeled positive data 
algorithms vary select automat ically labeled examples 
general procedure feature set bootstrapping algorithms weakly labeled positive data 
algorithms vary select automat ically labeled examples 
results may differ depending start fnt fct 
algorithm 
cotraining algorithm information extraction setting 
coem algorithm information extraction setting 
chapter problem description imagine able find organizations mentioned document gether locations people involved organizations 
tasks type known information extraction problems 
type infor mation extracted defined advance goal extract information new previously unseen documents 
dissertation describe approaches training information extrac tors input example words may belong target class col lection unlabeled text documents 
give details task chapter 
thesis statement thesis research efficiently automate information extraction learn tens examples labeled training data requiring thousands exploiting redundancy separability features noun phrases contexts 
exploit redundancy separability ways algorithms learning semantic classes novel algorithms active learning leading better extractors amount user labeling effort 
summary results goal learn extract noun phrases particular semantic types classes sentences text documents 
perform depth experiments identifying semantic classes locations people organizations sentences text documents 
represent instances semantic classes ordered pair consisting noun phrase local lexico syntactic context 
identify noun phrases contexts documents sundance shallow parser 
take small set words user believes may examples target class call seeds perform weak labeling providing noisy partial labels relatively small number examples collection documents identifying noun phrase containing words positive example 
weakly label examples negative examples perform semi supervised learning weakly labeled data 
describe algorithms coem em show applicable semi supervised learning information extraction task 
find cotraining representation task 
break algorithms employ separation feature sets combine feature sets 
show performance affected set seeds chosen frequently occurring seeds leading better extraction performance 
correcting errors weak labeling performed seeds lead substantial performance improvement 
show stopwords part model best performance classes 
details chapter 
goal optimizing trade user training time algorithm performance important see improve results active learning 
describe novel active learning algorithms algorithmically coupled separable feature sets 
addition describe novel labeling technique single feature set labeling 
single feature set labeling user sees partial example example noun phrase isolation context 
labeled noun phrase label contexts 
technique provides economy labeling show cases effective standard example labeling 
novel active learning algorithms feature set disagreement select examples labeling features disagree strongly target label contributions noun phrase context disagree target label context disagreement select noun phrases single feature set labeling contexts disagree example noun phrase occurs different contexts differ confidence representing positive example 
compare selecting frequent examples important classes represented pronouns 
show judicious selection examples labeling lead greatly increased accuracy greatly increas ing burden user 
particular show feature set redundancy allows selection examples labeling effective examples chosen randomly feature set redundancy 
addition results show active learning compensate bad choice initial seeds labeling effort better spent active learning process 
details experiments chapter 
perform deeper analysis results 
measure properties noun phrase context connectivity graph show exhibits small world graph structure random graph structure 
analyze explains failure cotraining tasks pronouns certain common nouns form hubs connectivity graph 
measure mutual information noun phrases contexts class order test conditional independence hypothesis 
perform spearman rank correlation tests multiple experiments finding correlations algorithm breakeven point features including number contexts labeled initial seeds percent examples labeled positive active learning 
features correlated learning performance help pinpoint important properties active learning bootstrapping algorithms information extraction 
comparing classes highlights different desiderata active learning algorithms classes sparse feature sets extremely small priors 
detail analysis chapter 
contributions contributions research depth experiments bootstrapping algorithms multiple semantic classes 
adaptation existing semi supervised learning algorithms task formation extraction 
novel active learning algorithms take account feature set split sets 
analysis noun phrase context occurrence graph show exhibits small world power law structure 
demonstration correlation graph features algorithm perfor mance 
suggestions seed selection bootstrapping algorithms informed graph structure data 
suggestions active learning bootstrapping algorithms informed graph structure data 
dissertation roadmap chapter give background terminology dissertation describe kind machine learning perform define information extraction problem detail 
chapter describe algorithms learning perform information extraction task describing data 
explicit assumptions algorithms measure properties data see assumptions hold 
give results bootstrapping algorithms task 
chapter describe active learning extensions algorithms described chapter 
chapter analyze results terms underlying graph structure data 
chapter describe experiment learning extract new class insights gained dissertation 
chapter summarize give suggestions 
chapter background chapter provide background dissertation 
define linguistic syntactic categories 
introduce data representation semantic classes represented ordered pair consisting noun phrase local syntactic context 
describe sundance parser extract noun phrases syntactic contexts documents 
give background machine learning supervised unsupervised semi supervised learning define weak labeling employ dissertation 
give general overview information extraction task tackling dissertation learning extract noun phrases particular semantic types sentences text documents 
linguistic terminology section give brief linguistic terminology dissertation 
general method describing linguistic syntactic categories derived descriptions radford 
general difficult give precise definitions linguistic syntactic categories exceptions descriptions give sufficient detail fluent english recognize category 
background noun noun roughly speaking word describes object thing cat computer city things love 
mor nouns words plural adding apart exceptions 
appear word sentences fun fun 
noun phrase frequently nouns occur part longer groups words called noun phrases 
noun phrase modified possessive food fat cat mouse cat hat noun phrases replaced pronouns sentences really job am working really 
noun phrase abbreviated np 
head noun phrase dissertation refer head noun phrase 
head noun phrase noun contains core meaning phrase 
words deleted phrase sentence sense head noun essential word 
examples noun phrases head shown bold job am working fat cat favorite things person met week shiny new telephone handset dogs coats remove relative clauses start words prepositional phrases start words head linguistic terminology noun phrase generally right word english 
example take noun phrase person met week remove phrasal modifier met week left person 
right word person head noun phrase 
verb verb described doing having word 
examples verbs include eat read buy think give keep 
english verbs change form action event refer past 
example say write refer past say wrote refer say write 
verb phrase verb phrase contains verb plus modifiers 
verb phrase may contain noun phrase 
example verb phrase eat quickly contains modal verb main verb eat object verb noun phrase adverb quickly 
generally noun phrase subject sentence person thing doing action described part verb phrase noun phrase object sentence part verb phrase 
dissertation concerned primarily modal verb parts verb phrases example eat describe eat tense active verb 
ignore adverbs 
prepositional phrase prepositional phrase situate object situation space time manner introduced preposition 
table gives examples common background amidst beneath despite inside near opposite outside past till underneath english prepositions 
table common prepositions english part prepositional phrase noun phrase 
examples tional phrases include week hammer table family near 
lexico syntactic context syntactic information language refers grammatical properties example word noun verb described 
refer noun subject sentence direct object verb past tense active passive voice 
lexical information refers properties words isolation 
lexical information may information listed word dictionary 
example word dogs property refers species canine commonly occurs bark 
lexico syntactic context combination syntactic lexical information 
example lexico syntactic context dobj 
spec ified context know direct object active verb syntactic part context active verb direct object ate lexical part context 
sundance autoslog sundance autoslog text syntactic categories assigned sundance 
sundance robust heuristic shallow parser produced university utah ellen riloff students 
sundance identifies noun phrases verb phrases tional phrases sentences 
autoslog riloff uses syntactic categories identified sundance recognize lexico syntactic patterns 
example autoslog identify patterns form read book book read may semantic constraints noun phrase filling slot 
describe autoslog preprocess sentences text documents give lexico syntactic contexts chapter section 
freely available parser kind task link grammar parser sleator temperley 
supervision machine learning way characterizing approaches machine learning degree super vision required approach 
supervised learning algorithm provided label example uses information learn mapping examples labels 
unsupervised learning labels provided 
algorithm sorts data related clusters measures proximity example features 
semi supervised learning examples provided labels approximate labels provided 
algorithm iteratively uses labels data learn approximate models re label better models 
subsections describe paradigms supervision explain weak labeling method providing supervision semi supervised learning dissertation 
assume algorithms provided set examples 
xn drawn universe possible examples distribution 
example may associated label universe possible labels giving pairs 
goal learn function information provided set training examples 
set background labels discrete finite call set target classes 
example xi properties call features 
features describe properties examples learning predictors target class label 
describe features particular data representation section 
general assume labels yl represent accurate represen tation function wish learn cases may noisy label see may true label part function wish learn 
may imperfect sensors reading label errors human labelers errors introduced labeling processes ways 
supervised learning supervised learning process learning mapping examples labels inferring models sets labeled examples provided input 
examples drawn distribution set possible examples labels set labeled example pair 
training set set examples space denote 
xn yn 
overview supervised learning mitchell 
unsupervised learning clustering form unsupervised learning known clustering task discovering groups underlying examples 
case examples universe wish assign finite set discrete groups 
provide explicit description groups implicit assumption exist coherent groups data correspond potentially useful categories 
typical approach clustering algorithm distance metric compare examples 
output clustering grouping examples sets call clusters 
may know advance clusters inherent data 
way characterize examples distance metrics provide features strong impact actual clusters discovered kamvar 
methods clustering natural language tasks manning schutze 
supervision machine learning semi supervised learning semi supervised learning assumption learn classifiers small number labeled examples unlabeled data 
set examples labels xl yl 
set examples labels xu 

examples labels learn target func tion examples labels learn relationships examples helping understand distribution examples relationships features examples 
technique successfully document classification naive bayes em nigam support vector machines joachims 
proved effective learning named entity classifiers collins singer 
weak labeling machine learning labels typically assigned examples explicitly measured example features human examined example assigned label 
text classification domain document conference may label conference proceedings appeared example proceedings international conference machine learning 
alternatively human may inspect assign label corresponding subject matter example machine learning 
weak labeling labels derived separate source assigned examples automatically 
text classification example weak labels may assigned automatically labeling documents belonging class machine learning contain words machine learning 
note may leave examples unlabeled belong class assign examples classes belong 
lead larger proportion noisy incorrect labels 
summarize weak labeling providing learning algorithm data labeled partially labeled possibly small number labeled examples 
background supervised machine learning examples assume regularities features labels allow generalization learning 
semi supervised learning assume regularities features examples provide sufficient information overcome fact labels instances 
weak learning case noisy labels structure inherent data need supply information missing labels incorrect labels 
weak labeling extremely useful permits supply training signal inspecting data 
example research small set words source labels jones 
documents phrases containing words labeled positive human inspection 
weak labeling done learning hidden markov models information extraction document headers lists names seymore 
craven learn gene terminators weakly labeled examples 
liu 
perform partially supervised text classification assuming unlabeled examples negative inserting known positive examples negative class spies help identify true positive examples unlabeled data learn appropriate thresholds distinguishing classes 
dissertation weakly labeled examples pairs noun phrases combined lexico syntactic contexts 
describe exactly perform weak labeling chapter section 
perform semi supervised learning examples remaining unlabeled examples 
information extraction problem section describe information extraction problem addressing 
problem common chapters dissertation details training information datasets varying chapter chapter 
information extraction problem address identifying noun phrases particular semantic class contexts sentences 
part larger information extraction system composed phases 
describe phases return define narrower scope address dissertation 
information extraction divided number subtasks described information extraction problem cardie appelt israel 
subtasks illustrated consist identifying classes semantically related words phrases semantic class finding ii labeling classes name meaningful user semantic class labeling iii semantic relation labeling labeling relationships individual semantic entities iv anaphora resolution determining object referred way point text referred 
semantic class finding information extraction task relies assumption interesting target se mantic classes identified task 
muc terrorism domain proceedings semantic classes victim perpetrator weapon identified interest 
muc management succession domain muc proceedings semantic classes takeover event iden interest 
classes chosen priori inspection target corpus 
dictionary construction semantic class useful dictionary terms belong class associated probability class membership 
dictionary input algorithms identifying potential class members document dictionary items seen 
thelen riloff construct dictionaries extrapolating contexts initial sample class members assuming noun phrase single type context 
semantic class labeling region text semantic class labeling involves assigning label meaning possibly predetermined set region text 
text clas problem freitag view instances labeled contexts texts tokens noun phrases context viewed cluster labeling problem cluster texts seek background yesterday rio de janeiro chosen new site disc golf headquarters 
production continue mali jaco founded 
location yesterday rio de janeiro chosen new site disc golf headquarters 
location production continue mali person jaco founded 
yesterday rio de janeiro chosen new site disc golf headquarters 
production continue mali jaco founded 
location yesterday rio de janeiro location chosen new site disc golf headquarters 
location production location continue mali director person jaco anaphor founded 
document marked results information extraction sub tasks unlabeled document pro active semantic class finding shown finding box boundaries textures semantic class labeling shown labeling boxes location finding semantic rela tions generating arrow labels location anaphora resolution arrow labels identity information extraction problem assign labels clusters 
sub problem semantic class labeling referred grishman name recognition involve recognizing names rio de janeiro disc golf jaco mali people place names sentences 
semantic relation finding semantic relation finding assign labels pairs groups instances se mantic classes 
output sentences may include director jaco disc golf location mali disc golf 
described template filling literature information extraction cluding califf califf mooney huffman huffman assumes fields assigned semantic types operation performed 
identifies relationships objects interest 
huffman system allows training corpus built interactively user presenting pairs user labeling 
soderland soderland assumes training corpus marked semantic classes desired relation ships 
described examines active learning permit simultaneous acquisition semantic classes 
anaphora coreference resolution anaphor noun phrase refer real world entity refers earlier text real world entity 
example character introduced text tall woman may referred woman 
pronominal anaphora resolution involves replacing instance pronoun full name identified text 
means identifying second sentence referring disc golf view special case semantic relation finding 
relation wish find identity relation 
previous interest includes dagan 
dagan stresses importance syntactic features lexical features resolving pronominal anaphora 
suggests lexical information derived corpus statistics contribute resolving ambiguities remaining syntactic resolution contributed possible background information 
generally coreference resolution refers identifying mentions refer entity example dr mitchell tom mitchell may referring entity allan bean riloff automating attempts improve development time information extraction systems focused piece wise application machine learning algorithms sub components generally corpus marked target output applying variety traditional machine learning algorithms 
muslea muslea surveys automating learning extraction patterns free text structured documents concludes trend combination syntactic semantic delimiter approaches systems learn multi slot rules preferable 
glickman jones glickman jones survey relevant literature entire information extraction problem conclude parts basic information extraction problems addressed machine learning approaches 
suggest missing step integration pieces complete system learning part informs corresponding reduction amounts training data required 
clustering semantic class labeling general goal clustering techniques group things 
euclidean spaces accomplished defining cluster centroids points feature space distance metric feature space 
optimization objec tive function performed example minimize intra cluster distances distances cluster elements closest centroids maximizing inter cluster distances 
modeling data distributions parameterized mixture gaussian distributions clustering performed find means component distribu tions 
cluster maximum intra cluster distances proportional component variances 
general clustering performed unsupervised way feature space objective function chosen priori automating target function data generally function hoped correlate intended clusters generated 
frequent problem expressed objective function correlate task hand 
collocational regularities exploited produce classes language mod eling word sense disambiguation classes produced clustering data external labels lee rooth 
kind distributional clustering feature reduction text classifiers hofmann baker mccallum 
agglomerative clustering performed brown brown 
similarity metrics clustering intended language models trigram bigram statistics generally performed conducting bottom clustering clusters merged merge causes smallest loss class mutual information 
word wi similar wj wi predict probability unseen word pairs involving wj dagan 
similarity measures include kl divergence jensen shannon divergence 
problem unsupervised discovery word classes referred clustering lee factor analysis hofmann 
clustering traditionally term word classes hard boundaries word single class 
factor analysis assigns words soft classes particular word modeled set weights mixture distribution 
concrete examples semantic classes reliably produced completely unsupervised clustering include weekdays names words referring people syntactic classes definite indefinite articles 
seeding target examples riloff jones able cluster groups locations weapons titles information extraction reasonable accuracy 
training data bottleneck automating unsupervised clustering focused classes useful language modeling word sense disambiguation information extraction 
rest mentioned section requires large amounts labeled train ing data human hours hand writing rules 
rapid deployment information extraction system new domain provide system examples target concepts automatically background infer examples relevant learn rules expanded set 
collins singer collins singer done reducing training data requirements named entity classification task semantic class la 
compared variety boot strapping algorithms named entity clas 
algorithms rich feature set including string identity context identity context type pp versus appositive capitalization con tains word non alphabetic chars 
direct approach sub set examples full information extraction system need label labeling nps containing identified proper noun appositive pp perform way classification person location organization noise 
achieved results conservative approach adding new examples bootstrapping algorithm step 
autoslog ts riloff automates learning semantic relations requiring user involved filtering stage algorithm identified relations interest 
scope problem address focus simultaneously addressing problems semantic lexicon construction semantic class labeling 
goal find words phrases potential instances target class correctly classify way particular context text 
particular attempt learn probability distributions dictionary entries assign probabilities possible instances new documents reason need address semantic class labeling context dictionary entries may ambiguous example leader ambiguous people organizations 
see context occurs attempt assign correct class 
target classes target classes people locations organizations 
goal correctly identify instances text documents 
simple system identifies instances dictionary entries positive may appear tempting practice ambiguity terms example arizona name state paris name city related person 
inputs inputs small lists words 
describe detail chapter 
text documents parsed noun phrases lexico syntactic contexts 
detail chapter 
exclusively small lists words dissertation reasonable long lists disposal 
outputs outputs learning probability distributions noun phrases con texts 
evaluate identify target classes new documents 
details extraction performed chapter 
related included descriptions related chapter described information extraction problem 
give related chapters cover topics detail 
section include summary salient related related covered sections guide sections related discussed 
information extraction introduced related learning cluster similar word types chapter section learning specific word classes information extraction chapter section chapter section 
relevant kou kou large dictionary converted hmm high precision extraction dictionary entries variants entries 
application pre existing dictionary required background contrast approach learns dictionary contexts small amount additional data 
require shallow parser pre process data sarawagi cohen sarawagi cohen allow incorporation segmenting text identification named entities 
active learning describe related active learning chapter section 
addi tion raghavan raghavan show users able efficiently label features independent context documents contributes greater efficiency learning document classification 
approach similar single feature set labeling describe chapter section 
graph structure semi supervised learning introduced related semi supervised learning chapter sec tion 
describe related semi supervised learning chapter sections 
describe related graph structure chapter 
intersection theory graph structure semi supervised learning show cotraining effectiveness related graph properties underlying labeled unlabeled data 
particular expect cotraining algorithms perform data expander property 
perform probability mass examples algorithm confident feature sets greater probability mass example algorithm confident 
blum blum give algorithm randomized min cuts semi supervised learning describe way constructing graph data amenable 
suggest data connected large component data largest component 
compare joining nodes edges function similarity 
contrasts simple approach joining nodes single cooccurrence 
show chapter active learning compensate cases satisfy connectivity conditions selecting examples components covered chapter labeled examples 
threshold criterion adding edges interesting extension 
joachims joachims models data semi supervised learning fixed number nearest neighbors node edges graph 
way setting graph means graph may power law properties 
agichtein dissertation agichtein related spirit 
task agichtein addresses identifying relations 
snowball system bootstrap small number labeled examples 
system constructs queries identify new relations training 
agichtein evaluates influence graph structure learning task showing data power law structure measuring reachability target examples graph 
chapter chapter overview background terminology linguistics machine learning 
briefly defined information extraction task tackling thesis gave pointers related thesis 
chapter give concrete details information ex traction task including data training information evaluation methods 
describe experiments performing information extraction improve chapters active learning chapter 
background chapter comparison bootstrapping algorithms information extraction goal minimize effort required train information extrac tion systems 
chapter described information extraction task learning identify locations organizations people context desired outputs training 
chapter show train information extraction system small amount training data form example words target class 
describe properties data examine algorithms exploit separation multiple feature sets data strapping cotraining coem 
examine em separation feature sets 
concern selves identifying semantic classes locations people organizations sentences text documents 
describe set assumptions properties data task task possible little training data 
addition investigate effects different seeds bootstrapping performance effects unlabeled training set size frequency information stopwords 
comparison bootstrapping algorithms information extraction chapter show train information extraction system small amount training data form example words target class seed words described detail section 
order describe data representations algorithms assumptions algorithms 
questions attempt answer chapter 
represent data learn extract instances semantic classes 

algorithms bootstrapping 

bootstrapping contribute seeds boot strapping 

matter seeds choose 

correct errors introduced seeds 

learn classes equally representation 

corpus size affect learning 

assumptions algorithms data representation assumptions satisfied 
table summarize dimensions explore chapter 
give detail sections 
data representation recall chapter wish learn extract locations people organizations context text documents 
section describe kinds text documents experiments represent target classes contexts web pages 
data representation dimension instantiations data representation output shallow parser training corpus web pages trec web collection target classes people locations organizations algorithm cotraining coem em number seeds seed selection method thoughtful random list treatment errors labeling uncorrected corrected corpus size moderate large table summary issues consider chapter 
note address extraction information sentences text documents 
extraction tables semi structured layout require different tech niques described cohen hurst knoblock 
data sources experiments chapter data sources web pages web pages trec wt collection 
details 
web pages web pages come crawling top level economic sectors hierarchy published www com 
sectors shown table 
web sites crawled 
data subset data described mccallum 
consists corporate web pages training set aside test set 
refer data sector data 
obtained www cs cmu edu afs cs project theo www data 
trec wt web collection trec wt web collection bailey set web pages collected trec information retrieval evaluation 
information obtaining comparison bootstrapping algorithms information extraction basic materials sector energy sector financial sector healthcare sector technology sector transportation sector utilities sector table top level economic sectors hierarchy 
pages collected sectors sector data set 
wt name num docs wtx wtx wtx wtx table trec wt data subsets experiments number docu ments data subset parsing 
data www ted csiro au access data 
html 
data consists gigabytes html text web pages crawled 
identify number subsets shown table order larger larger collections documents ranging documents just documents 
data preprocessing html stripped pages 
representation task described section need able identify sentences sentence fragments 
web pages include noun phrases headings lists attached sentences sentences headings include punctuation 
order separate sentences sentence fragments punctuation missing added periods heuristically 
algorithm adding periods due mike thelen university utah table 
data representation periods added lines 
line ends punctuation period added 
final word line click period added 
line blank add period 
fewer words line add period 
table heuristic algorithm inserting periods web pages subsequent parsing 
html stripped pages algorithm applied 
adding periods identify sentence boundaries parsed sentences sundance riloff phillips parser university utah ran autoslog riloff sentences 
results corpus noun phrases paired local context form lexico syntactic pattern 
described lexico syntactic patterns section 
patterns come small set possible patterns table 
version sundance autoslog version 
ran autoslog exhaustive fashion possible lexico syntactic patterns occurring noun phrase identified flag employed 
extraction contexts domain terrorism shepherd output format selected shepherd 
task representation instance noun phrase lexico syntactic context produced autoslog 
lexico syntactic contexts introduced section way obtained web pages described section table 
refer lexico syntactic contexts contexts remainder thesis 
example xi pair ni ci ni refers noun phrase instance xi ci refers context 
instance space aiming learn functions refers set possible class labels instances 
table summarizes notation 
take wide set values values appear training corpus 
training corpus sample set possible values sampled underlying probability distribution comparison bootstrapping algorithms information extraction pattern example subj passive verb murdered subj active verb bombed subj verb infinitive attempted kill subj noun victim subj noun talent active verb dobj bombed infinitive dobj kill verb infinitive dobj threatened attack noun dobj noun dobj farmers noun pp obj prep bomb active verb pp obj prep killed passive verb pp obj prep aimed subj active verb dobj declare dividend infinitive pp obj prep expand table lexico syntactic contexts 
instantiated words shown examples 
noun phrases head noun instantiated part noun phrase context match noun phrases different determin ers adjectives part noun phrase 
extracted portion subj entire noun phrase extracted 
data representation symbol meaning set possible instances sample instances sample instances training sample instances testing size training set number instances xi yi zi th example sample instances label associated xi pair xi yi set possible noun phrases bag noun phrases projection ni th noun phrase sample set unique noun phrases mn number unique noun phrases set possible contexts bag contexts projection ci th context sample set unique contexts mc number unique contexts table notation referring instances 
comparison bootstrapping algorithms information extraction corpus name num docs num unlabeled examples mn mc sector wtx wtx wtx wtx table descriptive overview statistics corpora thesis number documents number noun phrase context pair instances number unique noun phrases mn contexts mc set 
pn language probability distribution generating words phrases zipf means possible values seen rarely may occur sample 
refer sample pn xk 
refer sample noun phrases occurring nk sample contexts ck 
chance features may seen training set interested distribution noun phrase context features training test sets 
specifically interested size training set number instances size noun phrase context sets appearing training set mn mc 
table shows values number documents sector corpus trec corpora training data thesis 
sections discuss overlap training test corpora terms values taken noun phrase context attributes 
learning task address learning function noun phrases contexts binary classification indicating instance noun phrase belongs particular semantic category 
fclass ni cj practice meaning noun phrase context pair may partially depend larger context person labeling test examples may label example ni cj positive negative depending occurs 
discuss weak initial labeling seeds measurements inter rater agreement section 
wish map noun phrase context target class probability class 
function trying learn written fclass value fclass class ni ci 
viewed statistical estimation problem wish estimate class ni ci class ni ci fclass ni ci arbitrary pairs noun phrases contexts 
weak initial labeling seeds interested minimizing burden user training extraction system method providing initial information easy possible 
employ weak labeling introduced section form necessarily require user inspect data 
specific method propose consists asking user provide small set nouns noun phrases may representative target class call seeds 
experiments described chapter initial words provided user 
sections describe types seeds experiments seeds automatically label unlabeled corpus data ways addressing possible ambiguity initial seeds set 
seeds order characterize target class ask user small set words may occur positive examples part noun phrases examples example user wants train system recognize class locations may provide list country names 
positive examples feature set majority experiments described thesis run seeds shown table 
locations seeds riloff jones 
section compare comparison bootstrapping algorithms information extraction class seeds locations australia canada china england france germany japan mexico switzerland united states organizations companies marine group xerox people customers subscriber people users shareholders individuals clients leader director customer table seeds weak labeling data initialization bootstrapping 
effects different seeds task 
seeds organizations people chosen sorting noun phrases training set frequency asking trainer select matching target class 
note method necessarily lead best choice seeds simple method requiring skill experience 
ask user think words may occur target class avoiding need inspect data 
seeds provided user label data methods fixed initialization head labeling active initialization 
describe methods 
fixed initialization fixed initialization uses form approximate weak labeling call head labeling 
pairs noun phrase head right word described section matches seed word considered positive training instances regardless context appeared 
approach riloff jones 
frequently correct may introduce errors 
example word canada seed correctly labeled example locations eastern canada positive example class locations incorrectly labeled example royal bank canada technology positive example 
cases word identified automatically head word canada 
section discuss detail accuracy obtained seed diamond strong network approximately locations southwestern states eastern canada royal bank canada smart card technology access control bank line electronic business banking services 
algorithms words weak labeling datasets providing examples correctly incorrectly labeled approach 
active initialization address occasional errors introduced ambiguity automatic labeling phase implemented novel method labeling training data incorporates active learning 
active initialization examples matching seed words task interactively labeled trainer learning process 
process shown algorithm 
algorithm active initialization inputs set seeds feature set xi ni ci ni fclass xi xi note contrasts fixed initialization additional examples labeled user 
contrasts regular batch labeling random subset examples examples labeled user 
examples selected labeling algorithm asks confirmation labeling positive bootstrapping 
hypothesize actively labeling examples outset provide learning algorithms better initial examples improve ex traction performance 
reasonably frequent seed words requires significant numbers examples labeled outset examples locations organizations people seed words table sector training data 
summarizes labeling process 
algorithms section describe algorithms learning extract semantic classes noun phrases contexts weak labeling type described section 
algorithms differ way treat feature sets comparison bootstrapping algorithms information extraction unlabeled data seed words head labeling head labeled data unlabeled data active initialization head labeled data head labeled data unlabeled data automatically labeling data seeds head labeling correcting labels active initialization 
unlabeled data 
referred groups features set noun phrases set contexts algorithms apply feature sets applicable domains 
algorithms fall naturally classes 
collapse features single feature set algorithms learn model label relabel unlabeled data model 
refer class algorithms single view bootstrapping algorithms discuss fully section 
second set algorithms uses feature set split explicitly learning models feature sets separately models separately label relabel unlabeled data 
class algorithms described class cotraining algorithms refer view bootstrapping algorithms discuss class algorithms section 
algorithm inputs algorithms inputs 
seed words nouns examples target class 
unlabeled data xk sampled example xk pair consisting exactly feature value ni set feature value cj set ni cj number examples values ni feature cj 

function xi specifies example xi matches seeds algorithms single view bootstrapping algorithms single view set bootstrapping algorithm uses single model constructed features learning 
general algorithm algorithm 
instantiation type algorithm self training described nigam ghani 
algorithm trained initial labeled data assigns labels unlabeled examples confident predictions 
retrained initial examples labeled 
nigam ghani self training perform expectation maximization em document classification task 
thesis em full description em instantiation information extraction domain 
algorithm general procedure single feature set bootstrapping algorithms weakly labeled positive data 
algorithms vary select automatically labeled examples 
initial training set xi yi xi yi xi em repeat train ft ni cj lt xi ft ni cj update lt xi xi change models reached expectation maximization em algorithm iterative hill climbing procedure finding parameterization probability density function pdf locally maximizes likelihood observed data 
useful situations form probability density function known observed data provide information need estimate parameters 
case calculating parameters mixture distributions class membership observations unknown 
call unknown class membership labels observed data hidden data 
em algorithm iteratively estimate values hidden data estimates update estimates model parameters 
statistical terms observed data provide means calculating sufficient statistics model iteratively improve estimates sufficient statistics 
comparison bootstrapping algorithms information extraction description em algorithm follows initialization initialize parameters model non singular values 
step calculate expected values hidden data current model parameters 
step update model parameters observed data expectations hidden data calculated step 
likelihood test calculate likelihood observed hidden data 
likelihood converged return step 
probabilistic model setting assume data generated mixture model components 
component positive component generates noun phrase context multinomial distribution 
multinomial distribution noun phrases example positive class 
multinomial distribution contexts example positive class 
assume multinomials noun phrases contexts conditionally independent class label pdf joint distribution just product multinomials 
practice noun phrases contexts completely conditionally independent 
examine assumption detail chapter 
write pdf component similarly fpos addition mixture parameter determines probability selecting component generate observation 
bayesian terms prior probability class 
class membership example determined algorithms random variable follows bernoulli distribution determined 
probability model complete data note observe noun phrases contexts observe class memberships directly 
hidden data 
complete set individual parameters learned fully specify classifier ni cj initialization initialization phase set initial parameters model 
partial information form seed words assumption pair seed head noun phrase positive example 
assume unknown examples negative 
pinit pos ni ni cj section discuss ways initializing pinit pos ni cj experiments 
labeling calculate multinomial parameters class prior 
recall ni cj number examples values ni feature cj mn number unique noun phrases sample comparison bootstrapping algorithms information extraction mc number unique contexts number instances sample avoid zero probabilities laplace smoothing step ni pos cj pos ni neg cj neg pos ni cj pos nk cl pos mn ni cj pos nk cl pos mc ni cj neg nk cl neg mn ni cj neg nk cl neg mc pos step calculate expected labels data model parameters 
specifically step pair update estimate probability example positive class parameters model estimated step pt pos ni cj pt ni cj pos pt pos pt ni cj pt ni pos pt cj pos pt ni pos pt cj pos pt ni neg pt cj neg expectations hidden class labels note instances xm ni cj xr ni cj distinct examples features ni cj zm zr 
algorithms step step estimate parameters labeling data 
particular estimate class prior parameters feature ni pos ni neg cj pos cj neg 
laplace smoothing find expected number occurrences examples class estimated class labels pos ni cj place hidden true labels examples noun phrase seed head assumed label positive expectation label 
words examples initially labeled positive remain unchanged em process 
pt ni pos pt cj pos pt ni neg pt ci neg ni cj nk cl mn ni cj nk cl mc ni cj nk cl mn ni cj nk cl mc ni cj sample ni cj pt pos ni cj ni cj pt pos ni cj calculated step ni pt pos ni cj ni similarly termination condition ni cj pt neg ni cj ni cj pt pos ni cj ni cj check termination condition calculating log likelihood observed data model parameters 
comparison bootstrapping algorithms information extraction log log pt ni cj pos pt ni cj neg log pt ni pos pt cj pos pt ni neg pt cj neg log likelihood converged return step 
feature set bootstrapping algorithms just finished discussing algorithms infer new updated labels partially labeled examples current set labels considering examples entirety 
contrast feature set bootstrapping algorithms treat feature sets separately 
algorithm learns model fn ni fc cj 
models separately labeling unlabeled training data 
algorithm provides general algorithm view bootstrapping algorithms 
differs single feature set bootstrapping views alternation label unlabeled data 
chapter describes experiments view bootstrapping algorithms coem cotraining described 
algorithm general procedure feature set bootstrapping algorithms weakly labeled positive data 
algorithms vary select automatically labeled examples 
results may differ depending start fnt fct 
initial training set xi yi xi yi xi repeat train fnt ni lt xi fnt ni update lt xi xi train fct ci lt xi fct ci update lt xi xi change models reached algorithms riloff jones simple level bootstrapping algo rithm features sets label alternation 
customized information extraction 
notion negative examples features positive features unlabeled features 
feature sets noun phrases contexts asymmetrically 
noun phrase ni label fn ni change assigned 
context label fc cj change different steps algorithm 
heuristics score noun phrases ni contexts cj iteration 
noun phrases ni scores occurrences positive contexts cj frequency occurrence diversity occurring features 
similarly contexts score depends cooccurring noun phrases scores 
highest scoring features labeled acquire label fn ni fc cj 
treats noun phrases contexts asymmetrically permanence labeling described way noun phrases contexts contribute labeling 
context labeled positive occurring noun phrases assumed positive 
noun phrase labeled positive part committee noun phrases voting context selected 
phase bootstrapping contexts learned discarded best noun phrases retained permanent dictionary 
bootstrapping expanded list noun phrases 
noun phrase added permanent dictionary assumed representative positive class confidence 
asymmetries may derive empirical development algorithm 
see section contexts ambiguous noun phrases viewed isolation 
alternative algorithm may effective reverse asymmetry permitting contexts labeled positive identified single noun phrase requiring voting contexts labeling noun phrases 
pseudocode algorithm shown 
comparison bootstrapping algorithms information extraction algorithm algorithm 
initialize seeds ni fnt ni outer repeat inner st outer initialize context list repeat score contexts fct cj ni fnt ni ni cj nk nk cj log ft ni ni cj ni cj indicator function ni cj cooccur training set argmax ci ci fct ci add noun phrases cooccurring context fct update inner st inner ni ni outer st outer argmax ni fct cj ni cj reached ni algorithms cotraining cotraining blum mitchell bootstrapping algorithm originally developed combining labeled unlabeled data text classification successfully named entity classification collins singer 
high level uses feature split data starting seed examples labels unlabeled data adds confidently labeled examples incrementally 
collins singer collins singer treat noun phrases contexts atomic units match substrings properties apart ni operator 
means cotraining access view data algorithms described feature 
cotraining requires negative examples negative seeds provided form stopwords 
information extraction setting algorithm details algorithm 
note cotraining assumes accurately model data assigning noun phrases contexts single class 
add example entirely member class assigned positive class probability assigned negative class probability belonging target class 
see section noun phrases contexts inherently ambiguous 
cotraining may harm performance hard binary non probabilistic class assignment 
coem coem hybrid algorithm proposed nigam ghani combining fea tures cotraining expectation maximization em 
coem iterative em uses feature split data cotraining 
tion feature sets noun phrases contexts implementations cotraining 
coem proceeds initializing noun phrase classifier fn ni class ni labeled data 
fn ni probabilistically label unlabeled data 
context classifier fc cj class cj trained original labeled data plus unlabeled data labels provided fn 
similarly fc data fn process iterates classifiers converge 
final predictions test set fn fc predictions combined assuming independence assigning comparison bootstrapping algorithms information extraction algorithm cotraining algorithm information extraction setting initialize seeds ni fn ni ni pos neg repeat fnt score contexts labeled data fct cj ni fnt ni ni cj ni ni cj select single new positive context argmax ci ci fct ci repeat select new negative context argmin ci ci fct ci kt neg kt neg new contexts added fct score contexts ni fct cj ni fct score noun phrases labeled data fnt ni cj fct cj ni cj cj ni cj select single new positive noun phrase argmax ni ni fnt ni st pos st pos repeat select new negative noun phrase argmin ni ni fnt ni neg neg new negative noun phrases added change models reached assumptions biases test example probability proportional fn ni fc cj 
note coem perform hard clustering data assigns noun phrase context probability belonging positive class 
may reflect inherent ambiguity terms 
algorithm coem algorithm information extraction setting initialize seeds ni fn ni repeat label fn ni ni cj fc cj ni cj label ni fn ni fc cj ni cj cj iterations change ni 
algorithm shown algorithm 
assumptions biases bootstrapping algorithms described section number assumptions common initialization seeds leads labels accurate target class seeds data distribution simi lar phrase contexts correlates semantic similarity noun phrases contexts redundant unambiguous respect semantic classes attempting learn 
introduce model selection bias generalization possible reduces complexity learning 
violation assumptions may affect learning 
section assesses validity assumptions examining data 
initialization seeds assumption algorithms considered seed words source information target class 
assumption algorithms seed words comparison bootstrapping algorithms information extraction corpus class seed density positive positive noun phrases instances sector locations wtx sector organizations wtx sector people wtx table density seed words instances fixed corpus web pages percent training collection positive sample instance pairs 
suggested user data 
assess comparing seed density different tasks types data collected specifically task hand sector consider drawn uniform random distribution documents world wide web wtx 
seeds initializing bootstrapping algorithms shown table 
density seed words different corpora shown table 
note people organizations classes prevalent data working random documents 
addition assess assumption looking different candidate seeds task 
took list country names list country domain names took subsets size list 
number occurrences words list quite variable shown table 
accuracy head labeling assumption arises seeds labeling accurately labels items target semantic class 
algorithms initialize unlabeled data seeds perform head labeling 
noun phrase seed word head labeled positive 
example canada seed word list eastern canada canada labeled positive examples 
table shows precision estimated recall head labeling sector training set 
tables show precision classes assumptions biases seed num seeds examples matching examples matching set average sets sets random random orig table locations task random sets country names matched variable numbers instances corporate web page data 
shown aver age number instances matching sets exact number instances matching original country names entire list country names 
country names basic experiments frequently occurring 
country names list country names match initial examples 
class examples true precision estimated labeled positives recall locations people organizations table precision recall labeling examples automatically seed heads 
recall estimated percentage positive examples sample instances training corpus 
broken seed word 
people seed words generally unambiguous exception instances 
example customers unambiguous phrases industrial customers 
seed word people led training examples questionable utility example invest people 
learn context invest may help learning extract words people general case 
seed words people class proved ambiguous leader describe sentence world leader digital document management services 
discuss results correcting errors bootstrap ping active initialization section 
comparison bootstrapping algorithms information extraction head word correct labeled precision clients customer customers director individuals leader people shareholders subscriber users table precision labeling examples automatically seed heads people 
head word correct labeled precision companies xerox table precision labeling examples automatically seed heads organizations 
assumptions biases head word correct labeled precision australia canada china england france germany japan mexico switzerland united states table precision labeling examples automatically seed heads locations 
feature sets redundancy assumption bootstrapping algorithms discuss assume sufficient infor mation feature set noun phrases contexts label example 
look ambiguity noun phrases test set table see noun phrases ambiguous classes ambiguous classes group ambiguous organization people class facility ambiguous location organization class 
means noun phrases unique noun phrases occurring test set instances test instances fact sufficient identify class 
dis may hurt cotraining meta bootstrapping assume classify noun phrases class accuracy 
examine information contexts table see ambiguity 
contexts ambiguous classes 
suggests best results may obtained algorithm requires stronger evidence class membership contexts noun phrases 
algorithm type proposed thelen riloff thelen riloff adds words lexicon multiple contexts classify positive 
arguably similar scoring imposed coem 
exploration issue greater depth outside scope thesis warrants examination 
comparison bootstrapping algorithms information extraction ambiguity class es number nps unambiguous loc belonging class org person loc org belonging classes person loc org org person belonging classes loc org org person table distribution nps test set ambiguity class es number contexts unambiguous loc belonging class org person loc org belonging classes person loc org org person belonging classes loc org org person belonging classes loc org person table distribution contexts test set assumptions biases labeler set condition set condition np context np context np np table conditions inter rate evaluation stands np context entire sentence np context pair appeared inter rater agreement measure inherent ambiguity noun phrases making target class measure inter rater labeler agreement test set 
randomly sampled examples test collection broken subsets size examples 
labelers label subsets different amounts information 
conditions noun phrase local syntactic context full sentence noun phrase local syntactic context np context noun phrase np 
labelers asked label example labels organization person location 
hand labeled exam ples separate described condition discussed ways resolving ambiguous cases agreeing example count person organization referring organization individuals 
distribution conditions labelers shown 
labelers access noun phrase context full sentence occurred agreed labeling time 
sentence noun phrase context agreement dropped 
algorithms noun phrase contexts learning 
agreement human labelers conjecture algorithms better information 
comparison bootstrapping algorithms information extraction noun phrase context np context pair ambiguous vocabulary test set instances test set vocabulary seen training data instances table ambiguity contexts noun phrase context pairs test set training set coverage 
seen versus inherent ambiguity saw tables number phrases contexts ambiguous test set 
ambiguity may measures 
combination noun phrase context may greatly reduce examples test set 
test set may contain possible label example inherently ambiguous 
addition ex amples test set seen noun phrase context training 
table shows ambiguity noun phrases context combination test set coverage test set vocabulary sector training set 
see examples ambiguous access noun phrase context 
test instances seen training set 
relevance training data assumption assume noun phrases contexts test set modeled information learned training set 
fact find domain web pages unique noun phrases test set occurred training set 
unique contexts test set appear training set 
training test data drawn distribution 
random data expect discrepancies greater 
see section having train test sets sampled distribution helps bootstrapping adding extra documents organizations class 
assumptions biases saw section noun phrases ambiguous contexts 
see noun phrases modeled training data aware asymmetry feature sets 
phrase context play role determining correct classification test set way algorithm bias handles asymmetry may great importance effectiveness 
syntactic semantic correlation assumption algorithms address assumption phrases similar syntactic distributions similar semantic meanings distri bution similar phrase contexts correlates semantic similarity 
shown dagan syntactic cooccurrence leads clusterings useful natural language tasks 
seek extract items single semantic target class time syntactic correlation may sufficient represent desired semantic similarity 
mismatch syntactic correlation semantic similarity mea directly measuring context ambiguity section 
consider context visit ambiguous classes location person organization 
occurs location visit area am person organization visit visit website 
similarly examining ambiguous noun phrases see occurring particular noun phrase necessarily determine semantics context 
way ambiguous noun phrases test set group 
adding model learning class may cause algorithm add contexts belong different class 
see section different classes sensitive stopwords differing ways 
meta bootstrapping deals problem specifically forbidding list words mainly pronouns added dictionaries 
examine algorithm performs stopwords permitted model section 
addition heuristic context selected different noun phrases seed list helps prevent addition single ambiguous noun phrase strong influence bootstrapping 
probabilistic labeling coem helps prevent problems ambiguity 
comparison bootstrapping algorithms information extraction mine percent table stopwords experiments 
implemented list cotraining labeling means ambiguous words list group may strong influence bootstrapping 
stopwords stopwords shown table words frequently removed natural language tasks frequent may contribute meaning section text 
bootstrapping seeds may wish avoid learning stopwords part model may appear contexts 
word example may appear contexts related task 
time adding model may cause model learned noisier labeling unlabeled examples 
discussed section word particularly ambiguous respect tasks people organizations locations 
frequency information frequently occurring phrase may dominate model merely frequent 
collapses repeated occurrences noun phrase context pair ni ci single example coem cotraining em respect frequency information training data 
section see effects models ignoring frequency information 
analogy term frequency versus binary term weight models document classification mc nigam filtering lewis 
document classification filtering document length issue single occurrence word long document may suggest topic word occurs multiple times word occurs single time short document 
bootstrapping information extraction case examples fixed size single noun phrase single context described section 
table assumptions biases context occurrences seeds distinct nps distinct seeds pos pos located markets developed table examples probabilities class membership multinomial binomial occurrences 
binomial occurrence counts calculate probabil ities removing frequency information higher initial probabilities class membership assigned contexts greater diversity seeds 
shows examples different probabilities class membership representations contexts initial head labeling 
see located markets higher probabilities class membership consider occurrences compared considering binary occurrence counts 
developed higher probability class membership consider binary occurrence counts 
deciding representative class noun phrase ni con sider examples occurs 
ignore frequency example high probability class membership suggests ni indicative target class majority contexts occurs 
frequency information example high probability class membership suggests ni indicative target class majority examples occurs 
high frequency negative context may dwarf influence plurality positive contexts 
predictive accuracy model takes account frequency examples expected better 
summary assumptions biases saw section training corpus affects density seeds data head labeling relatively accurate 
hand saw data noun phrase context feature sets redundant respect task greater ambiguity respect target class contexts noun phrases 
addition examine section noun phrases contexts test set may appear training set 
anticipate best performing algorithms robust violations theoretical assumptions 
comparison bootstrapping algorithms information extraction empirical comparison bootstrapping algo rithms running bootstrapping algorithm models set noun phrases associated probabilities scores set contexts probabilities scores 
models extract examples target class held hand annotated test corpus 
able associate scores test example sort test results score calculate precision recall curves 
extraction test corpus ways models produced bootstrapping extract test corpus 
described 

noun phrases 
corresponds bootstrapping acquire lexicon terms probabilities weights reflecting confidence signed bootstrapping algorithm 
may advantage lists terms proper names probabilities associated 
probabilities allow sort extracted phrases control obtain highly probable members target class obtain coverage expense accuracy 
saw section noun phrases gives information test instances sectors task training set vocabulary completely cover test set 

contexts 
case discard noun phrases learned bootstrapping contexts extraction patterns ex test set 
extract noun phrase occurs contexts model score assigned context 
may advantage allowing greater generalization 
unseen words phrases extracted test corpus training corpus avoided 
saw test examples cov ered context training set ambiguous 
empirical comparison bootstrapping algorithms 
models 
score noun phrase context pair test set assume independence multiply model noun phrase context scores get probability example 
noun phrases contexts seen training corpus score prior probability 
advantage combining information acquired training 
method effective methods assign probability scores coem cotraining 
meta bootstrapping natural way combining scores 

bootstrap test corpus models 
models initialize test corpus run bootstrapping 
surprisingly preliminary experiments suggested approach 
examine related approach transduction section 
experimented extraction methods algorithms method extracting contexts far best meta bootstrapping results meta bootstrapping extraction method 
coem cotraining performed best method combining information noun phrase context models results reported coem cotraining extraction method 
evaluation metrics precision recall breakeven evaluate assign scores test examples 
sort examples score calculate precision recall 
precision defined respect threshold value possible thresholds calculate number examples classify correctly belonging class true positives tp number examples incorrectly classify belonging class false positive fp number examples incorrectly classify negative false negative fn 
precision recall recision pi pi pi pi recall pi ni comparison bootstrapping algorithms information extraction precision locations coem cotraining recall precision people coem cotraining recall precision organizations coem cotraining recall comparison bootstrapping coem meta bootstrapping cotraining classes locations people organizations 
intuitively precision tells proportion ones chose correct recall tells proportion positive examples 
want summarize results experiment single number breakeven score 
breakeven score value precision recall equal curve 
higher breakeven score better 
results comparing view bootstrapping algorithms section give results view algorithms bootstrapping semantic classes 
see results single view algorithm em section 
compares models obtained bootstrapping coem meta bootstrapping cotraining extracting held test set 
coem performs better meta bootstrapping cotraining poorly 
bootstrapping improves seeds shows bootstrapping unlabeled documents gives significant gains just seeds noun phrases seeds heads extracting test corpus 
difference marked class people ambiguous seed words 
results comparing view bootstrapping algorithms precision locations coem recall precision people coem recall precision organizations coem recall comparison effects seeds noun phrases seeds heads head labeling models learned bootstrapping coem extract unseen test set 
seeds head labeling lead precision poor recall 
bootstrapping coem improves recall loss precision 
precision locations coem allowstopwords coem allowstopwords nofreq coem recall precision people coem allowstopwords coem allowstopwords nofreq coem recall precision organizations coem allowstopwords coem allowstopwords nofreq coem recall comparison allowing stopwords model ignoring frequency formation forbidding stopwords frequency information coem 
best results obtained allowing stopwords model frequency infor mation appear affect results greatly 
stopwords important coem see allowing stopwords model improves results greatly people organizations classes having deleterious effect locations class 
indicator organizations indicators people 
subsequent results allow stopwords frequency information coem noted 
benefits stopwords increased precision allow stopwords model gains achieved high precision precision recall curve improvement recall 
algorithm perform coem 
results comparison bootstrapping algorithms information extraction precision locations allowstopwords recall precision people allowstopwords recall precision organizations allowstopwords recall comparison allowing stopwords model 
allowing stopwords gives improvement results coem 
precision locations allowstopwords coem allowstopwords coem recall precision organizations allowstopwords coem allowstopwords coem recall precision people allowstopwords coem allowstopwords coem recall comparison effects hand labeling examples matching seed words commencing bootstrapping active initialization bootstrapping assuming correct coem 
small gain obtained labeling data input 
shown 
small gains correcting labels coem shows small gain obtained hand labeling unique examples matching location seeds commencing bootstrapping ex amples matching organization class examples matching people class commencing bootstrapping 
see slight improvement precision low recall organizations slight improvements precision locations people class precision hurt low recall range recovering little higher recall 
shows head labeling effective way initializing correcting errors introduced substantially improve results 
examine intelligent ways selecting additional examples label provide leverage chapter 
results comparing view bootstrapping algorithms precision seed selection initial locations initial recall seeds chosen baseline experiments effective 
country names substantially improve results 
original seeds cover large number instances country names sector training corpus 
initial seed choice influential results shows effects seed choice bootstrapping accuracy locations task coem 
initialize country names obtain best re sults country names shown table nearly effective frequent training set accounting instances country names 
producing random subsets country names obtain seed sets varying numbers examples training set 
saw table seed sets vary greatly number initial examples cover sector training set 
figures show results random seeds 
results suggest best frequent seed words 
seed words fixed may set unlabeled documents contain examples seed words 
way doing may automatically constructing training corpus retrieving documents containing seeds automatically constructing search queries retrieve similar documents 
ghani showed effective identifying documents specific language ghani may effective finding documents matching target domain 
comparison bootstrapping algorithms information extraction precision locations seed selection random country names locations initial random initial random initial random initial recall precision locations seed selection random country names locations initial random initial random initial random initial random initial random initial recall seed set corresponding instances seeds training data generally produces better results coem 
precision locations wtx docs wtx docs wtx docs wtx docs sector docs recall precision precision people recall wtx docs wtx docs wtx docs wtx docs sector docs organizations wtx docs wtx docs wtx docs wtx docs sector docs recall effects corpus size coem 
larger training set significantly better locations 
organizations training set matches distribution test set appears better fit 
people class training set matches distribution test set appears slightly better fit low recall scale 
results comparing view bootstrapping algorithms training set size distribution affects results frequently case machine learning increasing training set size increases accuracy learned models 
performing semi supervised learning changes training set size may number effects 
firstly larger training set may contain instances seeds choose provided initial training information 
secondly larger training set may contain larger vocabulary semi supervised learning may learn model applicable test instances 
note machine learning expect algorithms perform best training test data drawn distribution 
data different distribution may task vocabulary cooccurrence statistics vary greatly test set 
original sector training set fixed collection increase size data different distribution 
see larger training set significantly better locations 
organizations training set matches distribution test set appears better fit 
larger larger mismatched training sets get closer accuracy achieved matched test set 
people class training set matches distribution test set appears slightly better fit low recall scale 
reasonable question different classes benefit differently increasing corpus size 
may conjecture explanations difference effect corpus size learned model accuracy 
may conjecture number seeds matching training corpus differs classes 
see table number seeds matching large people organizations locations reasonable explanation 
second potential explanation vocabulary size target class test set 
target class represented wider vocabulary may benefit increased training set size target class represented narrow vocabulary 
table see vocabulary size class test set 
see organizations people larger positive test set vocabulary sizes locations 
test set vocabulary explain locations benefits increased training set size different domain 
third possible explanation vocabulary intersection training comparison bootstrapping algorithms information extraction wt name num docs num unlabeled num instances examples matching seeds locations sector organizations people locations wtx organizations people locations wtx organizations people locations wtx organizations people locations wtx organization people table trec wt data subsets experiments number documents subset number examples extracted subset 
see number examples matching seeds increases corpus size 
class positive unique positive unique positive test set instances test set nps test set contexts locations organizations people table number positive examples size vocabulary positive examples test set classes locations organizations people 
results comparing view bootstrapping algorithms test set example coverage sector wtx wtx coverage test instances np context seen training data wtx training corpus size examples locations organizations people test examples wtx coverage positive test examples noun phrase context training set 
test sets 
test set contains vocabulary training set algorithm may trouble learning model class 
expect higher intersection train test set vocabulary training test set drawn distribution training set large 
learned section greater proportion test contexts seen sector training data nps 
independent target class 
shows training set instance overlap positive examples test set classes training corpora 
see locations increasing corpus size corresponds increasing coverage positive test examples noun phrase context training set 
examples organizations smaller corpora trec wtx data cover positive test examples 
organizations increasing trec corpus size approaches coverage achieved sector training corpus comes distribution 
people class size corpus big effect coverage positive test examples 
effects match effects increasing corpus size extraction accuracy 
expect learn test set vocabulary covered training set 
suggests transductive learning may effective 
look effects transductive learning section 
comparison bootstrapping algorithms information extraction precision locations sectors sectors transductive recall precision organizations sectors sectors transductive recall precision people sectors sectors transductive recall transductive learning versus standard learning coem classes locations organizations people 
transductive learning sensitive errors head labeling transductive learning learning test data part training data 
joachims joachims showed effective results transductive learning text classification 
implement transductive learning combined training test corpora single unlabeled training set performed head labeling trained coem extracted test corpus usual way 
recall training corpus sector dataset consists noun phrase context pairs test set consists just examples 
adding test set significantly increase amount unlabeled data available training give algorithms possibility learning model data distribution accurately test set 
shows results transductive learning sector dataset 
organizations class benefits greatly transductive learning test examples covered nps contexts training corpus 
adding test examples helps model class 
locations improvements precision higher recall levels loss precision low recall 
people class hurt transductive training 
may wonder precision harmed locations class 
find damage caused head labeling 
example examples containing altos de mexico labeled positive transductive learning hurts precision 
addition context morgan morgan learned high confidence transductive case twice occurs mexico 
original training set morgan occurs place name 
appears transductive learning overfitting test set 
solution may perform head labeling training set learn train test sets train training set results comparing coem em run iterations bootstrapping test set 
case people class find issues known problematic head labeling resulting positive labels corporate clients industry leader 
may need correct examples labeled seeds active initialization de scribed enable full power transductive learning 
leave experiments 
results comparing coem em saw section coem successful view algorithms described thesis 
wish compare coem em collapses feature sets single model 
addition compare effects varying parameters em including initialization stopwords frequency information 
initialization conditions different initialization conditions em 
different ways unlabeled examples source initial information negative class fourth uses output coem initialization 
zero initialization unlabeled examples initialized pinit pos ni cj shown em algorithm initialization equation section 
small initialization unlabeled examples initialized score 
random initialization unlabeled examples initialized random score 
shows initialization affects unlabeled examples head labeled examples initialized seeds 
see initializing zero small scores slightly better initializing random scores 
may suggest strat egy coem cotraining treating unlabeled examples having score initially may reasonable 
initializing output coem models gives best results 
tables show results sorted final breakeven score various initialization conditions 
tables show number iterations em ran convergence reaching iterations final log likelihood training data model 
comparison bootstrapping algorithms information extraction head labeled data head labeled data unlabeled data zero random small np context np context 
initialized unlabeled data models coem initialization unlabeled examples small values random values output coem affect head labeled examples labeled seeds 
examine relationship log likelihood model breakeven scores section 
frequency information description em section probability estimates calculated examples counts ni cj 
collapse repeated occurrences pair features single count reduce impact frequent occurrences 
em seeking maximize likelihood data model examples frequent occurrences strong effect model 
target class contain frequent instances example target class contain pronouns dates wish frequent instances strong effect model learned 
experiments counting method designated nofreq 
shows organizations class best frequency information locations people classes major difference discernible em 
remaining experiments em frequency information model 
results comparing coem em final breakeven iter final ll init freq stopwords freq stopwords freq nofreq stopwords zero init freq stopwords small init freq stopwords random init freq stopwords nofreq zero init freq small init freq random init freq random init nofreq random init nofreq stopwords zero init nofreq stopwords zero init nofreq small init nofreq small init nofreq stopwords table people em best results obtained initializing coem frequency information allowing stopwords model 
precision people em small init nofreq em small init recall precision organizations em small init nofreq em small init recall precision locations em small init nofreq em small init recall results em frequency information 
comparison bootstrapping algorithms information extraction final breakeven iter final ll init freq stopwords random init freq stopwords random init freq freq freq stopwords zero init freq stopwords zero init freq random init nofreq random init nofreq stopwords small init freq stopwords small init freq nofreq stopwords nofreq small init nofreq small init nofreq stopwords zero init nofreq stopwords zero init nofreq table locations em best results obtained random tion frequency information allowing stopwords model 
results comparing coem em final breakeven iter final ll init freq stopwords freq stopwords nofreq stopwords freq small init freq stopwords zero init freq stopwords zero init freq small init freq random init freq stopwords random init freq nofreq random init nofreq stopwords random init nofreq zero init nofreq small init nofreq zero init nofreq stopwords small init nofreq stopwords small init freq stopwords table organizations em best results obtained initializing coem frequency information allowing stopwords model 
comparison bootstrapping algorithms information extraction precision people em small init em small init stopwords recall precision organizations em small init em small init stopwords results em stopwords 
recall effect stopwords em precision locations em small init em small init stopwords coem experiments em show little difference allowing disallowing stopwords model 
shows small initialization condition 
saw tables initialization conditions results slightly better allowing stopwords model 
subsequent experiments em allow stopwords model 
likelihood data em em class accuracy correlates log likelihood training data model 
show breakeven score test set plotted log likelihood training data model training iterations em 
see increase log likelihood correlates increase breakeven score organizations class people locations classes 
locations class breakeven point drops slightly increased log likelihood training data model 
results explain em successful organizations class 
corpus size em see larger corpus helps little em people class 
locations class clear adding documents helps em 
contrasts coem benefited greatly added documents locations saw 
recall results comparing coem em breakeven loglikelihood model versus breakeven loglikelihood organizations locations people log likelihood plotted breakeven point 
see log likelihood predictive accuracy organizations class people locations classes 
precision people em small init wtx docs wtx docs wtx docs sector recall precision organizations em small init wtx docs wtx docs wtx docs sector recall results em large corpora 
precision locations em small init wtx docs wtx docs wtx docs sector recall comparison bootstrapping algorithms information extraction precision precision people allowstopwords coem em random init em small init em zero init em recall locations allowstopwords coem em random init em small init em zero init em recall precision organizations allowstopwords coem em random init em zero init em small init em recall comparison em baseline coem algorithm 
initialization condi tions shown em 
stopwords permitted model frequency information em coem 
em versus coem coem outperforms em locations people tasks 
stopwords permitted model frequency information em coem 
coem outperforms em initialization conditions locations people tasks 
organizations task initialize em output coem breakeven point somewhat better em random zero small initialization 
chapter chapter go questions raised start chapter light knowledge provided experimental results 
represent data learn extract instances semantic classes 
representing data pairs noun phrases local syntactic contexts allowed learn extract instances semantic classes small number initial examples 
noted section labelers access noun phrase context full sentence occurred agreed labeling time 
sentence noun phrase context agreement dropped 
algorithms noun phrase contexts learning 
agreement human labelers conjecture algorithms better information 
representations example grams sarawagi cohen 
augment representation incorporating examples capital letters punctuation collins singer 
won experiment alternative data representations thesis worth noting amount context information augmented possibility improved results 
algorithms bootstrapping 
general coem outperformed em coem output initialization increases breakeven point class cor related increased log likelihood training data model case organizations class 
suggests em effective organizations class initialization conditions 
advantage coem meta bootstrapping cotraining may reflect match probabilistic treatment data inherent ity classes 
permits ambiguous example labeled probability reflects true ambiguity committing class overly influenced presence class 
meta bootstrapping repeatedly discards comparison bootstrapping algorithms information extraction contexts ambiguity contexts hurt algorithm hurts cotraining 
bootstrapping contribute seeds bootstrapping 
see comparison gains bootstrapping seeds head labeling see classes ambiguous seeds words people class benefit bootstrapping relatively unambiguous seed words 
benefit bootstrapping 
may noise introduced ambiguous seed words somewhat mitigated presence ambiguous seed words 
matter seeds choose 
seed words datasets saw seed density training corpus appears affect accuracy results 
select seeds corpora occurrences seeds training corpus 
correct errors introduced seeds 
locations people saw correcting hand exam ples labeled seed words significant impact results 
means relatively unambiguous seed words hand labeling context give advantage automatic head labeling 
transductive learning sure correct examples labeled seeds 
learn classes equally representation 
people organizations classes sensitive presence absence stopwords 
may due pronouns correlated class 
example may predictor organizations may predictor people 
examine question detail chapter 
locations class adversely affected allowing stopwords model data representation classes 
chapter saw section classes varied greatly test vocabulary covered training corpus 
expect learn better test set vocabulary covered training set 
corpus size affect learning 
saw sections number seeds training corpus corpus size affect results 
may wonder way increasing number seeds training corpus greatly increasing corpus size greater computational efficiency 
way may label examples 
address question chapter examining efficient ways choose examples labeling active learning 
different approach motivated related acquiring documents target language ghani involve automatically acquiring training data contain instances seeds target class 
may promising direction 
assumptions algorithms data representation assumptions satisfied 
assumed extraction models described chapter noun phrases contexts conditionally independent class labels expect hold completely 
interesting measure actual level independence examine gains dropping assumption 
perform measurement chapter 
discussed related chapter section showed conditional target class may necessary bootstrap ping 
algorithms assumed seeds data saw depends choice seeds 
implicit assumption addressed bootstrapping algorithms employ able modify labels examples modifying labels cooccurrence cooccurrence links allow reach relevant examples 
examine assumption deeply chapter 
comparison bootstrapping algorithms information extraction chapter chapter explored number variations initialization algorithms bootstrapping information extraction 
combinations prove interesting pursue 
include extending algorithm initialization permit user specify verbs prepositional phrases nouns 
interesting try negative seeds coem em active initialization em 
chapter examine improve results incorporating active learning 
look active learning algorithms customized feature set split may lead efficient learning 
chapter active learning semi supervised saw chapter coem effective bootstrapping learning semantic classes small collection seed words 
requires minutes user training time 
user time labeling may useful user spend time labeling leads increased accuracy 
chapter show judicious selection examples labeling lead greatly increased accuracy greatly increasing burden user 
particular show feature set redundancy allows selection examples labeling effective examples chosen randomly feature set redundancy 
addition results show active learning compensate bad choice initial seeds labeling effort better spent active learning process 
active learning seeks efficient trainer time having learner intelligently select examples label anticipated value label learner 
bootstrapping approaches considered chapter fact example described distinct sets features active learning semi supervised sufficient approximate function fit cotraining problem setting 
discuss range active learning algorithms show feature set disagreement select examples active learning leads improvements extraction performance regardless choice initial seeds 
active labeling performed interleaved manner bootstrapping 
described chapter initialize data seeds head labeling head labeled unlabeled examples data bootstrapping candidates active labeling 
shows schematic process 
questions attempt answer chapter 
effective correct head labeled examples actively label new ex amples 

effective way select new examples actively label 

effective actively label just noun phrases actively label noun phrase context pairs active learning 

larger corpus choose examples lead greater accuracy amount user labeling effort 

increasing number actively labeled examples improve accuracy 
improvements tail continue get increased accuracy increase number labeled examples 

active learning bootstrapping algorithms robust set seeds chosen head labeling 

active learning bootstrapping algorithms robust way unlabeled examples initialized 
table summarizes dimensions experiment chapter 
dimensions training set size addressed chapter may interplay different ways add active learning 
give details sections 
unlabeled data initialization head labeled data head labeling optional active unlabeled data bootstrapping algorithm active label active labeled data head labeled data unlabeled data automatically labeling data seeds head labeling optionally cor labels active initialization performing active learning interleaved bootstrapping 
unlabeled head labeled examples candidates active labeling 
active initialized examples treated active labeled examples candidates relabeling 
dimension instantiations training set size examples training set distribution test set different test set user labels example just noun phrase number examples labeled algorithm uniform random density feature set disagreement select examples context disagreement initialization conditions unlabeled examples small random choice properties model frequency stopwords algorithm bootstrapping coem em table summary dimensions vary performing active learning boot strapping semantic classes noun phrases 
active learning semi supervised related pool unlabeled examples prompting user actively label examples high anticipated value reduces number examples required tasks text classification lewis gale parsing information extrac tion thompson soderland 
bootstrapping algorithms similar learning problems fall cotraining setting blum mitchell collins singer muslea 
property example described multiple feature sets independently sufficient approximate function 
cotraining problem structure lends variety active learning gorithms 
na testing muslea classifiers trained available labeled data run unlabeled data 
contention set examples created consisting unlabeled examples classifiers disagree 
examples contention set selected random label requested trainer classifiers retrained process repeats 
testing algorithm shown quite effective represents just possible approach active learning training setting 
training classifiers labeled examples earlier collins singer blum mitchell riloff jones shown unlabeled data bootstrap accurate classifiers 
selecting new examples uniformly random contention set rank examples contention set criterion reflecting value obtaining label 
chapter propose experiment active learning algorithms unlabeled data training addition determine unlabeled example trainer 
consider variety strategies selecting best example contention set 
training set size distribution saw chapter larger training set effective locations domain train test mismatched 
ex active learning increase accuracy bootstrapping algorithm see section example 
background empirical facts example labeling versus single feature set labeling wish find greater win obtained increasing training set size increasing size pool unlabeled examples available bootstrapping selecting examples increasing number examples labeled 
example labeling versus single fea ture set labeling typically active learning labeler examines example order assign label call standard labeling paradigm 
context information extraction task standard labeling ask user label pair consisting noun phrase context 
may easy actively label noun phrases independent context noun phrase may occur contexts may lead greater economy labeling 
example italy occurs centers operations introduced partners offices labeling italy provides information contexts 
call approach labeling noun phrases applying labels example single feature set labeling 
number examples labeled active learn ing labeling examples provides information target function expect increases number examples labeled active learn ing improve performance 
different example selection methods may effective finding informative examples labeling increase performance different rates 
may find labeling exam ples provides great deal benefit making active learning attractive addition bootstrapping user little time labeling 
compare active learning zero examples labeled tiny numbers examples labeled examples labeled examples labeled examples sector dataset 
active learning semi supervised active learning selection methods uniform random selection baseline method selects examples uniform distribution 
noun phrase context pair occurs training set selected equal probability 
example frequency ignored 
method applicable standard labeling single feature set labeling 
single feature set labeling noun phrase selected equal probability 
density selection frequent unlabeled example selected la step 
method applicable standard labeling single feature set labeling 
standard labeling frequent unlabeled noun phrase context pair selected 
single feature set labeling frequent unlabeled noun phrase selected 
feature set disagreement learn distinct classifiers apply instance way select instances human trainer provide useful information identify instances classifiers disagree 
approach viewed form query committee qbc freund liere tadepalli muslea uncertainty sampling lewis gale thompson committee consists models different feature sets similar mccallum nigam 
selection criterion kullback leibler kl divergence 
gives example density weighted kl score multiplying kl pg pg frequency example 
set predictors gn mean scores assign example class class score assigned kl kl class class class log class class class log class class active learning selection methods score kl freq examples selected deterministically highest ranked unlabeled exam ple taken time 
total committee members committee member represent probability assigned noun phrase second committee member represent probability assigned context 
pos sible extension motivated earlier query committee committee members noun phrase context 
commit tee members differ sampled probability distribution derived different initialization conditions 
method applicable standard labeling paradigm 
variant applicable single feature set labeling context disagreement described 
context disagreement noted earlier noun phrase may occur contexts may lead greater economy labeling 
exam ple italy occurs centers operations introduced partners offices labeling italy provides information contexts 
addition may find contexts noun phrase suggest positive suggest classified negative 
take probabilities assigned different contexts votes committee members label noun phrase 
disagreement committee members may suggest labeling noun phrase informative 
selecting noun phrase context disagreement may provide informative labeling 
thought query committee qbc committee consisting different cooccurrences elements feature set elements feature set 
quantify context disagreement density weighted kl divergence mean feature set disagreement contexts noun phrase input kl divergence measure 
classifiers gi simply scores assigned model probability class membership context contexts noun phrase occurs active learning semi supervised kl class log class class class log class class frequency noun phrase density weight kl divergence 
score kl freq user labeled noun phrases single feature set labeling 
initialization conditions saw chapter section initialize unlabeled examples bootstrapping em different ways initialize unlabeled examples score zero small constant random value scores assigned coem 
saw chapter way initialize unlabeled examples affects performance em bootstrapping task 
examples labeled active learning expect influence initialization unlabeled examples impact performance 
examine extent active learning reduces impact initialization conditions unlabeled examples 
saw chapter section choice seeds initial labeling positive examples head labeling lead quite different numbers examples labeled different algorithm effectiveness section 
examine chapter active learning bootstrapping robust initial choice seeds 
properties model saw chapter section including disallowing stopwords model substantial effect bootstrapping effectiveness factor example frequency model 
examine properties model come play add active learning bootstrapping algorithms 
precision bootstrapping algorithms locations coem active learning uniform active learning allowstopwords uniform allowstopwords recall precision people coem active learning uniform active learning allowstopwords uniform allowstopwords recall precision organizations coem active learning uniform active learning allowstopwords uniform allowstopwords recall compare baseline active learning adding labeled examples examples selected uniformly random locations people organizations interleaved bootstrapping coem 
compare models allow disallow stopwords 
bootstrapping algorithms choice bootstrapping algorithm chapter examine active learning coem em 
chose coem performed reasonably bootstrapping human annotated data chapter em performs semi supervised tasks see 
nigam ghani 
experiments chapter em performed poorly bootstrapping head labeled data may perform better add little labeled data active learning 
combining bootstrapping active learning interleave active learning bootstrapping algorithm 
coem em bootstrap iteration actively label examples iteration target number examples labeled active learning 
continue running bootstrapping algorithm till convergence till iterations total 
sort test instances score assigned extraction method calculate precision recall values 
active learning semi supervised precision locations coem coem density allowstopwords allowstopwords density recall precision people coem coem density allowstopwords allowstopwords density recall precision organizations coem coem density allowstopwords allowstopwords density recall adding labeled examples examples selected density locations people organizations 
results uniformly selected labeled examples little utility allowing stopwords influence model greater effect people class adding labeled examples selected uniformly random 
adding uniformly selected examples model allowing stopwords provide additional leverage seen 
supported research literature shows model assumptions distribution data greatly divergent empirical data distribution benefits unlabeled data cozman cohen 
amounts data labeling small compared size unlabeled data set contains examples size test set contains examples 
examine effect labeling examples section 
example selection density see selecting examples density provides improvement baseline 
shows selecting examples non uniform distribution help learn particularly people class 
allow stopwords influence model examples selected way aid greatly learning people class 
stopwords pronouns tend frequent examples 
selection criterion example frequency model target class examples chosen labeling experiments training set 
examine examples selected labeling results noun phrase number total frequent unique examples examples labeled context frequency believe contact share share increased operates press provides ended ended trademarks registered trademarks table noun phrases selected labeling frequent examples noun phrase context pairs selected labeling 
frequencies number different contexts noun phrases occurred selection number occurrences contexts 
density active learning find distinct noun phrases appeared 
table shows noun phrases occurred examples selected labeling 
labeler labeled different noun phrase context examples con tained noun phrase different examples contained noun phrase 
learned chapter noun phrases relatively unambiguous respect classes attempting learn 
may able labeling time avoiding redundancy noun phrases labeled 
way doing ask labeler actively label noun phrases single feature set labeling 
describe experiments results examining approach section 
single feature set labeling ask labeler actively label noun phrases labeled noun phrases assigned probability class membership depending label 
find labeling frequently occurring nps effective people active learning semi supervised precision locations coem allowstopwords coem density recall precision people coem allowstopwords coem density recall precision organizations coem allowstopwords coem density recall adding labeled noun phrases selected density loca tions people organizations 
precision locations coem allowstopwords coem recall precision people coem allowstopwords coem recall precision organizations coem allowstopwords coem recall adding labeled noun phrases selected context disagreement locations people organizations 
companies best labeling entire examples 
locations class labeling nps isolation harms precision 
surprising examples location class examples labeled labeled positive 
find ambiguity noun phrases leads incorrect labeling oracle 
example capital labeled positive test set capital refers 
organizations find similar effects 
noun phrases obviously refer companies seen isolation including energy solutions vcs technologies names dataset 
capital letters part model aid mitigating problem noun phrases occurring titles start sentences remain ambiguous 
context disagreement see results labeling examples selected context disagreement 
people class context disagreement works np density selecting examples actively label 
locations class context disagreement effective 
examine examples chosen labeling find capital longer selected labeling 
results precision locations allow stopwords coem active learning density disagreement recall precision people allow stopwords coem active learning density disagreement recall precision organizations allow stopwords coem active learning density disagreement recall adding labeled examples selected density feature set disagreement locations people organizations 
disagreement density active learning see results labeling examples selected dis agreement feature sets 
see locations slightly effective density selection organizations people density selection provides leverage 
matches intuition gained chapter features people organizations classes frequently occurring ones stopwords frequent important model 
active learning compensates infrequent seeds shows feature set disagreement active learning infrequent seeds 
recall chapter section seeds actively label positive examples head noun phrase matches seed process call head labeling remaining examples unlabeled 
infrequently occurring seed words lead fewer examples labeled outset head labeling 
left different sets randomly chosen country names led examples labeled outset head labeling 
center randomly chosen seeds commonly occurring training data occurring total times 
examples chosen active learning difference initial seed sets virtually eliminated 
see graph right starting riloff jones frequent country names nearly complete list country names gives virtually results examples labeled active learning 
precision active learning semi supervised random countries coem random instances random instances random random disagreement random disagreement random disagreement recall precision precision versus locations coem disagreement locations locations disagreement recall random countries coem random instances random instances random instances random disagreement random disagreement random disagreement recall active learning compensates infrequent seeds 
left randomly chosen locations seeds infrequent training corpus 
center randomly chosen seeds relatively frequent training corpus 
right frequent seeds near complete list country names seeds 
cases active learning produces comparable results examples labeled active learning 
precision results random coem random instances random instances random instances random disagreement random disagreement random disagreement recall precision random coem random instances random instances random instances random disagreement random disagreement random disagreement recall active learning compensates infrequent seeds 
random seeds active learning produce considerable improvements 
left infrequently occurring seeds right frequently occurring seeds 
shows double number randomly selected seeds active learning provide significant improvement results 
suggests active learning bootstrapping robust poor initial choice seeds 
number examples labeled figures see labeling examples improves results locations disagreement labeling examples labeled change great density labeling 
contrast effect labeling examples people organizations see density disagreement labeling effective people class organizations disagreement labeling shows effect labeling examples 
fur thermore look learning curves showing breakeven score number iterations clear bulk benefit obtained examples labeled 
shows breakeven point iteration density disagreement active learning 
recall label examples iteration 
see largest gains obtained iterations continued labeling contributes improvements 
see larger corpus helpful location class having examples labeled 
precision precision breakeven point active learning semi supervised locations coem density density density density density density density active learning recall precision people coem density density density density density density density active learning recall precision organizations coem density density density density density density density active learning recall labeling examples improves results 
people density selection labeling just examples greatly improves results 
locations coem disagreement disagreement disagreement disagreement disagreement disagreement disagreement disagreement active learning recall precision people coem disagreement disagreement disagreement disagreement disagreement disagreement disagreement active learning recall precision organizations coem disagreement disagreement disagreement disagreement disagreement disagreement active learning recall labeling examples improves results disagreement active learning people locations organizations little improvement seen 
locations coem breakeven number iterations breakeven point people coem breakeven number iterations breakeven point organizations coem breakeven number iterations breakeven point iteration 
see gains active learning come iterations examples labeled labeling continues improve results 
organizations class dip iterations 
may due ambiguity examples containing labeled positive organizations may lead model incorrectly identify people organizations examples labeled 
results precision precision locations coem wtx docs labeled wtx docs labeled wtx docs labeled wtx docs labeled sectors labeled sectors labeled sectors labeled recall locations active init versus active learning active learning active init active init examples labeled active init examples labeled active init examples labeled recall data important labels precision people active init versus active learning active learning active init active init examples labeled active init examples labeled active init examples labeled examples labeled recall precision organizations active init versus active learning active learning active init active init examples labeled active init examples labeled active init examples labeled examples labeled recall labeling active learning impact active initialization 
combining active initialization active learning provides modest incremental gains people class 
active learning useful active tion coem labeling pairs noun phrases contexts matched seeds outset perform significantly better active learning 
active learning method provided set initial instances clean unambiguous extraction performance improve 
suggests active learning methods robust ambiguous noisy training data recover poor initial seeds 
shown 
find active learning method examples labeled locations performed better bootstrapping coem active initialization examples labeled 
important result fixed amount time actively label instances active learning effective time labeling instances outset 
active learning semi supervised precision locations em uniform active uniform active coem init uniform active random init coem init random init recall precision people em uniform active uniform active coem init uniform active random init coem init random init recall precision organizations em uniform active uniform active coem init uniform active random init coem init random init recall adding labeled examples examples selected uniformly random locations people organizations 
coem em benefit greatly examples selected uniformly random random initialization initialization coem 
active learning em recall chapter sections coem uses split feature set label noun phrases contexts alternation em uses noun phrases contexts label iteration 
examples labeled automatically seeds head labeling see section coem provided accurate results 
reason may em attempts maximize likelihood data model target classes may better represented models give lower likelihood data 
opportunity provide labels algorithm active learning change distribution data em attempts maximize likelihood 
particular examples definitive labels human labeler active learning known class label affect data likelihood 
may expect performance em improve active learning 
uniform labeling influential initialization condition em coem find em benefit greatly adding labeled examples examples selected uniformly random shown 
see particular organizations results markedly better ini coem random initialization difference holds regardless label examples selected uniformly random 
precision breakeven results people em examples labeled active density labeled small init active density labeled coem init active density labeled random init active learning small init active learning coem init active learning random init recall precision locations em examples labeled active density labeled small init active density labeled coem init active density labeled random init active learning small init active learning coem init active learning random init recall precision organizations em examples labeled active density labeled small init active density labeled coem init active density labeled random init active learning small init active learning coem init active learning random init recall em select examples labeling density see large improvements results people class organizations class 
transcends initialization condition uniform active labeling 
people em breakeven active density labeled small init active density labeled coem init active density labeled random init active learning small init active learning coem init active learning random init iteration breakeven locations em breakeven active density labeled small init active density labeled coem init density labeled random init active learning small init active learning coem init active learning random init iteration breakeven organizations em breakeven active density labeled small init active density labeled coem init density labeled random init active learning small init active learning coem init active learning random init iteration breakeven versus iteration density active learning 
density example selection effective regardless initialization select examples labeling density see substantial im results people class organizations class shown 
mirrors results saw coem substantial gains density example selection realized people class 
results shown small random coem initialization examples matching seeds 
interestingly gains labeling examples selected den sity transcend differences due initialization condition 
look breakeven graphs see early iterations labeling substantial impact breakeven score 
single feature set labeling effective em saw forms single feature set labeling reasonably successful coem np density selection context disagreement selection 
see reasonably successful em regardless tion condition 
people organizations appear equally successful 
precision active learning semi supervised people em single feature set labeling small init small init coem init coem init small init random init recall precision locations em single feature set labeling small init small init coem init coem init small init random init recall precision organizations em single feature set labeling small init coem init small init coem init coem init small init random init recall single feature set labeling reasonably successful em 
provided great benefit organizations people classes small init small init feature set disagreement coem init feature set disagreement active random init active init labeled feature set disagreement small init active init labeled feature set disagreement precision people em context disagreement active recall small init small init feature set disagreement coem init feature set disagreement active random init active init labeled feature set disagreement small init active init labeled feature set disagreement precision locations em context disagreement active recall small init small init feature set disagreement coem init feature set disagreement active random init active init labeled feature set disagreement small init active init labeled feature set disagreement precision organizations em context disagreement active recall select examples labeling disagreement noun phrase context see largest improvements organizations class half examples selected original head labeled exam ples 
eliminating manual relabeling automatically labeled examples active initialization see improvements classes 
locations context disagreement performs somewhat better 
feature set disagreement selects seeds improves active tion select examples labeling disagreement contexts see biggest improvements organizations class 
observe examples selected labeling see examples contain original 
eliminate effect combining active initialization active learning 
see substantial gains accuracy active learning classes 
suggests focus active learning effort examples labeled head labeling 
table shows people locations classes feature set disagree ment selected examples seeds heads 
active initialization elim results class num examples chosen seed heads locations organizations people table people locations classes feature set disagreement selected examples seeds heads 
eliminate effect performing active initialization excluding examples seeds heads pool available active learning 
effect 
seen active initialization general important improving results 
expect get similar improvements excluding examples seeds heads active learning 
em robust choice initial seeds single feature set labeling wish examine effect different seed sets em coem 
baseline locations seed set examples labeled density labeling 
density example selection set labeled examples seed sets 
difference initial conditions em 
em tends find local maxima may expect different initial conditions may important effect final model 
shows starting random seed sets performs extremely poorly label examples density selection 
active initialization improve results 
reason may density active learning select examples labeling positive class random seed sets may training data permits model positive class 
may expect feature set disagreement perform better selects examples feature sets disagree class membership may provide better range training examples 
shows starting random seed sets performs extremely poorly label examples feature set disagreement selection 
surprisingly context disagreement labeling greatly improves results 
may context disagreement works locations task providing labels different noun phrases possible 
recall chapter locations task large vocabulary partially precision precision active learning semi supervised random em random density random density random density random density random density random density recall precision random em random density random density random density random density random density random density recall precision locations em density density em locations density em density em locations density em recall different initial seed sets labeling examples frequency 
starting random country names performs extremely poorly contrasted starting country names 
random em random disagreement random disagreement random disagreement random disagreement random disagreement random disagreement recall precision random em disagreement random disagreement em random disagreement em random disagreement em random disagreement em random disagreement em random disagreement em recall precision locations em disagreement disagreement em locations disagreement em recall different initial seed sets random country names perform feature set disagreement active initialization examples labeled compared country names 
precision precision results random em disagreement random em random em random em random em random em random em recall precision random em disagreement random em random em random em random em random em random em recall precision locations em em locations em recall different initial seed sets random country names reasonably effective em label examples context disagreement 
people em density active learning active density labeled active density labeled active density labeled active density labeled active density labeled active density labeled recall precision locations em density active learning active density labeled active density labeled active density labeled active density labeled active density labeled active density labeled recall precision organizations em density active learning active density labeled active density labeled active density labeled active density labeled active density labeled active density labeled recall classes labeling examples greatly improves results em 
particular people class labeling examples provides biggest gains model effectiveness 
organizations locations adding examples continues improve effectiveness model 
covered training set 
labeling examples improves results em shows classes labeling examples greatly improves results em 
particular people class labeling examples provides biggest gains model effectiveness 
organizations location adding examples continues improve effectiveness model 
see label examples disagreement labeling somewhat better locations people classes 
examine breakeven curves see locations active initialization disagreement selection dominates density selection iterations examples labeled results methods quite similar 
people class seeing opposite effect 
cases label just unlabeled examples available labeling exact method labeled importance 
precision breakeven active learning semi supervised people em active learning active disagreement labeled active density labeled recall precision locations em active learning active disagreement labeled active density labeled active disagreement labeled active init recall precision organizations em active learning active disagreement labeled active density labeled recall examples labeled people locations classes perform slightly better disagreement labeling 
people em active learning active disagreement labeled active density labeled active disagreement labeled iteration breakeven locations em active learning active disagreement labeled active density labeled active disagreement labeled active init iteration breakeven organizations em active learning active disagreement labeled active density labeled active disagreement active init labeled active density active init labeled iteration breakeven score versus iteration number em examples labeled iteration 
people locations class perform slightly better disagree ment labeling 
organizations better density labeling 
corpus size mismatch see labeling just examples greatly improves results people organizations class trec wtx corpus comes different distribution test set 
suggests active learning may help compensate training set comes different distribution test set 
chapter recall questions raised section 
go answers provided experimental results chapter 
chapter precision people em small init wtx docs active sector active wtx docs density active sector density active recall precision locations em small init wtx docs active sector active wtx docs density active sector density active recall precision organizations em small init wtx docs active sector active wtx docs density active sector density active recall large corpus different distribution label examples density selection recover losses accuracy due train test corpus mismatch 
effective correct head labeled examples actively label new examples 
automatically labeled examples outset head labeling effective label different examples active learning phrase 
recall saw chapter correcting labels automatically assigned head labeling greatly improve bootstrapping results 
chapter see benefit derived labeling examples selected active learning correcting head labeled examples active initialization 
important point reap benefit active learning primarily selects different examples labeled head labeling 
reason active learning algorithms tend select head labeled examples perform better coupled active initialization redundancy labeling removed 
efficient equally effective strategy force active learning algorithm select examples labeling part initial head labeling set 
effective way select new examples actively label 
labeling examples density selection effective organizations people locations feature set disagreement effective 
label examples gap accuracy methods narrowed may effective label examples feature set disagreement 
active learning semi supervised effective actively label just noun phrases actively label noun phrase context pairs active learning 
saw section coem single feature set labeling asking users label noun phrases context occasionally leads incorrect label 
coem lead poor performance bootstrapping em problem saw section 
particular single feature set labeling context disagreement effective locations class infrequent seeds 
appears effectiveness single feature set labeling depends algorithm bootstrapping classes diverse vocabulary single feature set labeling effective em 
larger corpus choose examples lead greater accuracy amount user labeling effort 
saw coem locations class larger cor pus different distribution effective labeling examples smaller corpus distribution test set 
people organizations changing distribution harmed accuracy saw labeling examples active learning larger corpus improved accuracy active learning performance performed active learning smaller corpus distribution test set 
increasing number actively labeled examples im prove accuracy 
improvements tail continue get accuracy increase number labeled examples 
coem em active learning methods saw increased accuracy increased number examples labeled active learning 
increases accuracy continued examples maximum number examples labeled experiments 
largest improvements generally examples labeled 
suggests worth performing active learning tiny amount user time disposal 
goal maximize accuracy label examples possible 
chapter active learning bootstrapping algorithms robust set seeds chosen head labeling 
active learning bootstrapping examples robust choice seeds em context disagreement selection eliminated difference performance different seed sets coem feature set disagreement eliminated difference performance 
conclude active learning need concerned quality initial seeds initialization head labeling 
active learning bootstrapping algorithms robust way unlabeled examples initialized 
em number choices initialize unlabeled examples 
chapter choices significant effect bootstrapping accuracy 
chapter active learning methods eliminated differences 
summary showed employing redundancy feature sets designing algorithms exploit redundancy enables combination bootstrapping active learning effective training information extractors 
compared different metrics selecting examples actively label disagreement classifiers built feature sets worked 
manually correcting initial examples mislabeled due ambiguous seeds effective providing active learning algorithm arbitrary set seeds labeling examples learning process 
algorithms may select examples labeled initial phase reducing effectiveness labeling 
context disagreement single feature set labeling setting perform methods standard labeling coem effective em label examples 
single feature set labeling may allow inaccuracies creep labeled set examples ambiguous respect feature set 
addition disagreement members single feature set may reflect inherent ambiguity example uncertainty learner 
active learning setting able active learning semi supervised multiple view feature sets provided experimental evidence effectiveness 
results shown specific information extraction setting approach framework useful designing active learning algorithms settings natural redundant division features exists 
chapter analysis chapters saw empirical results bootstrapping learning extract information form semantic classes specified seed words 
chapter perform deeper analysis results 
measure properties noun phrase context connectivity graph show exhibits small world power law graph structure random graph structure 
show pro nouns certain common nouns form hubs connectivity graph explains importance stopwords frequent seeds models 
measure mutual information noun phrases contexts class order test conditional independence hypothesis 
perform spearman rank correlation tests mul tiple experiments find correlation algorithm breakeven point features including number contexts labeled multiple seeds percent examples labeled positive active learning 
help pinpoint important properties active learning bootstrapping algorithms information extraction 
comparing classes highlights different desiderata active learning algorithms classes sparse feature sets extremely small priors 
chapter analyze results experiments chapters 
summarize results describe tools analysis section 
section analyze data small world power law properties 
section show graph theoretic properties analysis predictive algorithm performance 
kind analysis novel sets stage research selecting appropriate algorithms labeling techniques examining properties unlabeled data 
machine learning algorithms assume feature set independence 
common trait acknowledge feature set independence hold show algorithm effective anyway exactness generative model essential classification see 
domingos pazzani 
section quantify feature set dependence measuring mutual information features suggest differences conditional dependence classes may translate different algorithmic performance classes 
novel analysis opens spectrum algorithm performance prediction labeled training data absence labeled test data 
analyses add concrete suggestions algorithm design informed properties data explore section 
give basic advice seed selection assessing data tasks section 
analyzing results experiments chapter saw results experiments algorithms bootstrapping semantic classes initializing small sets seed example words 
chapter saw results experiments adding variety active learning algorithms top basic bootstrapping algorithms 
chapter step back examine lessons learned experiments examining trends exploring possible explanatory factors 
table provide overview experimental conditions explored chapters tentative drew 
sections explore issues stopword example frequency examining data graph theoretic terms 
tease apart effect adding examples positive examples examining effect different active learning methods 
examine degree data fails exhibit class conditional independence assumed measuring mutual information noun phrases contexts classes 
analyzing results experiments bootstrapping experimental condition summary results section bootstrapping algorithm poor cotraining poor em mixed coem okay seed word labels corrected unimportant train test distribution people important organizations important locations important allow stopwords pronouns model important people organizations example frequency organizations important em frequency training set high frequency important training set size locations large training set best transduction organizations helpful people deleterious bootstrapping active learning experimental condition summary results section train test distribution important active learning user labels example labeling effective noun phrase labeling effective number examples labeled improvements just labeled examples increasing number labeled gives continuing improvements algorithm select examples uniform random poor density effective feature set disagreement effective context disagreement effective initialization conditions em large effect frequency training set important active learning seed word labels corrected unimportant allow stopwords model important labeling random instances algorithm bootstrapping coem effective conditions em sensitive class active learning algorithm table summary experiments chapters general trends saw 
analysis breakeven score summary result section defined evaluation metrics precision recall breakeven experiments thesis showed results plotting entire precision recall curve 
looking results experiments si summarize results experiment just number 
single number capture nuances experimental result captures performance allows compare experiments 
single number evaluation scores compare exper iments 
describe candidates summarize pros cons table 
accuracy accuracy measure commonly machine learning 
generally assume prediction example test set accuracy percentage test examples correction prediction 
ac draw back accuracy measure efficacy classes sparse example locations class constitutes test instances naive classifier classifies example negative appear perform say accuracy wrong examples class interest 
measure measure van rijsbergen combines precision recall parameter quantifies importance user attaches 
general form measure weighted harmonic mean precision recall analyzing results experiments accuracy insensitive performance sparse class measure score dominated lower precision recall breakeven score precision recall equal table comparison single number summary statistics experimental results precision recall defined section chapter 
weight precision recall equally important obtain set pairs precision recall scores combine calculating average precision average recall 
calculate average precision take recall values intervals interpolating necessary average precision points 
average recall calculated similarly averaging fixed precision points 
breakeven point precision recall curve find breakeven point finding point precision recall equal interpolating necessary 
note breakeven score specific value measure equal 
breakeven optimal measure score system 
chose breakeven score simplicity computation 
spearman rank correlation test understand extent variety experimental conditions predict formance consolidate results chapters see general trends emerge 
focusing different properties experiments number examples labeled seeds number examples labeled active learning aggregating multiple experiments measure degree property affects results 
individual experimental result affected combination conditions different experiments see general trends 
analysis measure trends perform spearman rank correlation test results experiments combination candidate predictive property experiments 
ranking function ranking function formula spearman correlation test rs ri ri si si ri ri si si ri rank point si rank point spearman rank correlation test non parametric test assumptions form relationship variables 
example chapter spearman rank correlation test test rank algorithm performance predicted rank number examples labeled 
means detect positive relationship algorithm formance number examples labeled active learning making assumptions form relationship example assuming relationship linear 
spearman rank correlation test related pearson correlation test uses rank value value 
ex ample measuring number examples labeled active learning predicts performance order number examples labeled experiment rank ordering order results experiment position ordering results 
experiments th experiment gives pair 
experi ment find rank ri rank rank number examples labeled active learning si rank 
ties assigned average rank 
formula spearman rank correlation test ranks pearson linear correlation formula equation press 
spearman correlation score rs close shows positive correlation ranks 
spearman correlation score close shows negative correlation scores close show little correlation 
gives percentage variability rank ordering explained predictor variable 
example rs variability rank ordering datapoints explained see measured value rs significantly different null small world nature noun phrase context cooccurrence graph hypothesis measure variable rs rs distributed distribution degrees freedom number points spearman correlation test 
standard tables obtain significance score 
significance score near shows measurement correlation statistically significant 
typically see significance scores confidence correlation score 
test difference correlation coefficients rs rs significant test transformation zf ln assuming transformed rs zf transformed correlation coefficient null hypothesis compute test statistic zf rs differs 
significance tests compare different properties data find properties predictive algorithm performance 
small world nature noun phrase context cooccurrence graph analyze experimental results focusing attention different aspects data labeled examples small world nature noun phrase context cooccurrence graph 
section describe data terms cooccurrence graph test small world power law properties defined 
section analyze effects graph properties algorithm performance 
analysis graph property brief description hypothesis small world short path lengths nodes component reachable steps probabilistic labeling best power law large component small components distribution seeds components affects learning power law skewed distribution node degrees node degree labeled examples affects learning table high level graph properties data examine conjectures test effect algorithm performance view data consisting pairs noun phrases contexts graph represent noun phrase context node pair edge graph 
give detail mapping sections 
bootstrapping algorithms explored chapter exploited cooccur rence information propagate evidence class membership 
examining graph structure data may provide insight expected effectiveness algo rithms data 
addition extent nodes connected components affect performance algorithms cooccurrence information provide evidence nodes component 
presence seeds different components may provide insight performance bootstrapping algorithms seed set 
tendency active learning pick examples different components may explain active learning con tributes bootstrapping data initially labeled seeds 
examine consequences structure section 
table see brief summary graph properties think may affect learning performance 
sections define properties correlations performance appropriate possible experimental data chapters test hypothesized effect learning performance holds examining related graph properties 
small world graphs data accustomed thinking examples machine learning vectors features example xi features xi xi xin may accompanied label yi 
section describe view set examples xm graph 
describe representations examples examples splittable feature sets represent bipartite graphs ii general representation examples nodes edges graph 
small world nature noun phrase context cooccurrence graph label australia flew australia australia broadened china flew france thailand broadened thailand gulf director multinational leader industry table training examples feature vector format 
example features noun phrase context 
examples labeled positive examples unlabeled 
consider unique instantiation feature features node graph cooccurrence features feature sets edge graph 
bipartite graphs examples represented feature sets table shows training examples semantic labeling task described chapter section 
example features noun phrase context 
examples labeled positive examples unlabeled 
see bipartite graph representing instances 
instance represented edge joining nodes graph 
example instance flew china represented nodes flew china edge joining 
graph node australia connected nodes degree 
represents fact australia occurred unique examples unique different contexts flew broadened 
supervised machine learning viewed graphical perspective set nodes edges label provided edges training set 
labels learn predict labels edges held test set graph 
analysis china australia france thailand director leader flew broadened gulf multinational industry instance represents edge joining nodes graph 
example instance flew china represented nodes flew china edge joining 
concerned semi supervised learning 
training set collection documents parse noun phrases contexts identify nodes graph cooccurrences forming edges graph 
small number labeled examples small number labeled edges algorithm infer labels edges partially labeled initial set 
held test set set distinct web pages parsed manner form graph cooccurring noun phrases contexts edges assigned class labels 
set nodes edges test set graph may identical training set 
may nodes edges seen training 
measured degree overlap train test set chapter section labeled test noun phrases labeled test contexts seen training set 
learned model infer labels held test set 
general graph incomplete sample underlying distribution discussed section 
example feature sets contain exactly feature 
generally bipartite graph representation multiple features feature set 
blum mitchell blum mitchell described small world nature noun phrase context cooccurrence graph data graph theoretic terms splitting feature set redundant sets 
example xi xi xik xik xin view instantiations features xi xik node graph example second set features xik xin second node 
nigam ghani nigam ghani formed similar bipartite graphs data dividing feature set randomly sets showed improvements semi supervised learning feature set split 
graphs example features generally consider unique feature instantiation node graph edge nodes represents cooccurrence feature instantiations example consists set nodes feature values fully connected graph 
graphs single feature set projections working bipartite graph project graph considering feature sets set nodes ni ck projecting follows ni nj create edge eij ni nj exists context bipartite graph ck eik 
remove context nodes ck 
ck 
projection analogous creating graph context nodes graph samples underlying distribution working set data collected running experiments 
size dataset limited constraints disk space algorithm run time 
specifically sample web pages web page contributes multiple noun phrase context edges graph 
sampled web pages wind graph nodes edges 
think underlying true distribution dataset sample distribution 
shows sample differ underlying distribution containing fewer nodes edges general structure similar 
analysis china australia france thailand director leader flew broadened gulf multinational industry china australia france thailand director leader flew broadened gulf multinational industry graph shown left 
take sample graph may wind graph shown right 
edges nodes missing general structure similar 
number samples random graph affects sample contains full connectivity information karger 
graph may random measure effects sampling checking graph properties different size graphs 
small world power law graph properties naturally occurring graphs networks identified interesting properties small world power law scale free graphs albert barab si 
small world graphs graphs nodes steps nodes 
power law graphs degree distribution nodes observed obey power law 
looking small world characteristics characterize graphs behavior respect properties clustering coefficient extent nodes tend form fully con nected cliques connected cliques small world nature noun phrase context cooccurrence graph characteristic path length shortest path pair nodes averaged pairs nodes looking graphs power law property measure power law coefficient node degrees fit power law 
section describe graph properties detail highlight expect algorithms affected data run exhibit properties 
small world properties clustering coefficient path length see data exhibits small world property examine clus tering coefficient newman 
intuitively clustering coefficient mea sures densely connected graph measuring node neighbors neighbors 
node vi set neighbors vi calculate percentage connected neighbors vi vi vi ijk vi vi ijk 
formula clustering coefficient graph averaging nodes vi vi set nodes graph 
note alternative definition clustering coefficient weights edge equally 
averaging node averaging nodes alternative definition perform average edges 
gives greater weight higher degree nodes 
stick formulation equation 
definition clustering coefficient bipartite graph perform projection bipartite graph graph joining pair noun phrases common context calculating clustering coefficient noun phrases 
perform analogous projection obtain clustering coefficient contexts 
analysis random graph clustering coefficient number nodes graph 
characteristic path length average distances pairs shortest paths entire graph 
note disconnected graph multiple components path length pair nodes different components infinite 
characteristic path length graph multiple components infinite 
calculate characteristic path length largest component graph 
characteristic path length random graph ln number nodes graph average node degree graph 
watts strogatz relate characteristic path length clustering coefficient watts strogatz graph 
define small world graph characteristic path length random graph size clustering coefficient random graph size 
small world graphs lie extreme regular graphs require large number steps move arbitrary pairs nodes locally highly clustered extreme random graphs require small number steps move arbitrary pairs nodes 
shown word cooccurrence graphs synonymy relationships exhibit random graph structure small world structure nodes reachable nodes steps ferrer sol sigman 
noun phrase context pairs exhibit kind structure pronouns common nouns form hubs connectivity graph may explain importance stopwords frequent seeds models 
recall chapter section permit stopwords including pronouns model deleterious effect learning small world nature noun phrase context cooccurrence graph people organizations classes 
understanding effects removing stopwords connectivity graph may help explain 
steyvers tenenbaum studied graph structure semantic relation ships wordnet miller constructed great care word associations people prompted respond spontaneously word cues nelson 
graphs exhibited small world power law structure hypothesized model language acquisition newly learned concepts attached known concepts greater likelihood 
average node degree average node degree simple measure local connectivity graph 
average nodes connected edges bootstrapping algo rithm labeling node affect nodes average steps 
average node degree small bootstrapping steps may required impact nodes graph 
power law distribution node degree power law graphs distribution node degrees follows power law probability pk node having neighbors pk ck constant power law coefficient reflects extreme disparity node degree graph means nodes connected nodes nodes connected large number nodes 
data property expect degree nodes representing labeled examples importance predicting algorithm effectiveness data set 
affect propagation accuracies inaccuracies model 
example cotraining setting correctly label high degree node obtain correct labels different adjacent nodes 
different examples sharing half part split feature set labeled correctly node 
conversely incorrect label high degree node propagate error examples 
analysis smaller exponent extreme difference node degree high degree nodes low degree nodes 
graph word cooccurrence data ferrer sol sigman coefficient power law measurement restricted largest connected component graph 
sol explain terms core vocabulary main connected component specialized vocabulary falls components 
node degree perspective see considering components outside connected component adds low degree nodes computation 
graph divided underlying groups communities may explain degree cor relations degree adjacent nodes positive correlated clustering 
newman park show value power law predictive clustering coefficient 
particular expect see large values clustering coefficient increases increasing system size 
strogatz suggests nodes graph form large fully connected component high degree hubs network forms connected component 
steyvers tenenbaum men tion typically lies systems www metabolic networks 
semantic networks wordnet roget thesaurus asso networks 
calculated calculating node degree separately words classes largest connected component 
graph consisting header files included files ranged tween de moura 
graphs linking users access data resource iamnitchi graphs small world degree distribution necessarily follow power law 
analysis cotraining blum mitchell assume random graphs connected sub components blum mitchell disjoint 
see data power law distribution 
pastor vespignani pastor vespignani showed infectious ness disease increases scale free power law graphs show gradual rates infection random graphs 
think properties labeling component semi supervised learning algorithms analogous 
labeling algorithm requires information labeling viewed infectious 
small world nature noun phrase context cooccurrence graph connected components chapter discussed bootstrapping algorithms cooccurrence noun phrases contexts propagate label information labeled ex amples entire unlabeled set 
section drew attention assumptions underlying approach seeds chosen user data 
measured variable density seeds seed set chosen 
draw attention critical assumption underly ing algorithms remained implicit till 
algorithms described cooccurrence noun phrases contexts propagate labels 
hope learn phrase cooccurrences algo rithms transmit information likelihood class membership cooccur rence links dependent existence links portions graphs labels edges portions graphs labels edges 
portion graph contains leader industry separate component 
labeled edges component 
data need learn disconnected component region labeled initial seeds examples labeled active learning algorithm connectivity information able learn true labels disconnected examples 
connectivity cooccurrence graph key success bootstrapping algorithm 
agichtein 
measured reach ability data query sampling strategies account power law distribution data large connected component smaller com ponents quantified learnability different tasks corpora 
examine reachability examine correspondence distribution labeled data connected graph components algorithm perfor mance 
graph connectivity initialization conditions propagate label information edges graph 
particular propagate label information component graph disconnected component 
labels portions graph learn label edge disconnected component contains analysis leader industry 
set initial examples distribu tion components graph key effective semi supervised learning algorithm 
graph connectivity active learning connectivity graph may explain importance active learning algorithm effectiveness 
active learning may compensate lack component coverage initial examples selecting examples labeling lie different components graph 
measuring graph properties noun phrase context data section measure graph theoretic properties data appropriate show graph properties labeled examples predictive algorithm performance 
average node degree mean degree noun phrases sector training data mean degree contexts 
indicates class information noun phrase propagated just different contexts average class information context propagated different noun phrases 
labeling noun phrase isolation affect fewer nodes labeling context isolation 
expect variety sources information label context average different noun phrases connected providing information contexts connected average ran selected noun phrase 
suggests bootstrapping algorithm labels noun phrases cooccurring context propagate information noise quickly graph 
examined average node degree class sector test set noun phrases contexts 
see table nodes target classes tend higher average degree average node degree test set 
explained fact pronouns included classes 
small world nature noun phrase context cooccurrence graph class locations organizations people test set table average node degree class sector test set noun phrases contexts 
see nodes target classes tend higher average degree average node degree test set 
explained fact pronouns included classes 
presence may explain high average node degree noun phrases organizations people classes 
higher average node degree contexts locations class may explained fact varied ways referring locations people organizations 
presence may explain high average node degree noun phrases organizations people classes 
higher average node degree contexts locations class may explained fact varied ways referring locations people organizations 
power law distribution node degree look just noun phrases corpus see distribution number contexts linked follows power law 
table see noun phrases highest degree connected different contexts hubs graph 
note examples customers common nouns members target classes 
pronouns members target classes example member people class 
shows distribution outdegrees contexts 
table shows contexts highest degree 
list contains mixture ambiguous contexts including occur noun phrase quite unambiguous ones said occur primarily people occasionally organizations 
find coefficient power law fitting line log log graph 
probability pk node having neighbors formula analysis noun phrase outdegree information products site customers time context outdegree including including provides provides provide include include provide offers offers said includes provide variety includes table noun phrases contexts highest degree 
degree number different contexts noun phrase 
noun phrase list contains mixture pronouns anaphora common nouns 
context list contains mixture ambiguous contexts including occur noun phrase quite unambiguous ones said occur primarily people organizations 
small world nature noun phrase context cooccurrence graph frequency outdegree power law distribution node degree bipartite graph noun phrases contexts outdegree noun phrases occur different contexts occur distribution links follows power law suggesting small world graph structure 
pk ck log pk log ck log pk log log constant accounts intercept 
slope line fit data points plotted log log axes 
contexts coefficient power law express formula number noun phrases context pk noun phrases constant power law pk shows lines fit graph node degrees noun phrase context graph 
fitting power laws graphically difficult due sparsity counts high frequency elements goldstein lines fit manually adjusting cut node degree considered fitting line 
coefficients adjustment may significant bias 
comparisons power law analysis log degree lines fit power law distribution node degrees nps power law nps alpha contexts power law contexts alpha log degree fit line log log plot find power law parameter noun phrases contexts respectively 
coefficients calculated kind bias 
able examine questions effect sample size consider nodes component coefficients measure may reliable 
measured value power law coefficient related sample size 
discussed section exact set nodes edges graph may differ depending sample size 
test effects sample size data calculated power law parameter samples different sizes sector data trec wtx data 
see coefficient converges datasets contexts converges corpora noun phrases converges just sector data just trec data 
may suggest properties context distribution independent corpus type origin properties noun phrase distribution depend corpus type 
note measured power law coefficients entire graph researchers restricted attention largest component 
nodes smaller components may tend lower degree measuring degree largest component may lead smaller power law parameter 
able compare measurements researchers calculated largest component 
table shows numbers 
see larger larger subsamples graph independent 
small world nature noun phrase context cooccurrence graph noun phrases sample size trec data sector data contexts sample size trec data sector data asymptotic values power law coefficient calculated corpora 
coefficient converges datasets 
contexts converges corpora noun phrases converges just sector data just trec data 
may suggest properties context distribution independent corpus type origin properties noun phrase distribution depend corpus type 
noun phrase degrees context degrees node degrees table power law coefficients node degree noun phrases connected contexts graph largest component 
see measuring power law coefficient graph give different result measuring largest component 
coefficients vary greatly 
contrasts results obtained sol graph word cooccurrence data ferrer sol sigman suggests data extreme power law properties degrees frequent nodes higher highest degree nodes 
may explained different types underlying data data includes edge pair phrases cooccurrence sol include edges words cooccur probability greater chance 
recall graph power law property means nodes connected nodes nodes connected large number nodes 
data property expect analysis degree nodes representing labeled examples importance predicting algorithm effectiveness data set 
affect propagation accuracies inaccuracies model 
example cotraining setting correctly label high degree node obtain correct labels different adjacent nodes 
different examples sharing half part split feature set labeled correctly node 
conversely incorrect label high degree node propagate error examples 
simple observation suggests hybrid approach semi supervised learning proposed previously greater confidence required labeling high degree nodes low degree nodes 
power law structure may explain poor performance strapping cotraining data 
cotraining la bel examples positive negative probabilistic labeling cotraining coem 
addition power law distribution node degree explanatory factor different behavior bootstrapping classes 
people organizations contain high degree nodes pronouns members class leading volatile behavior depending nodes labeled positive negative 
examine effect labeling examples high node degree section 
clustering coefficient sector training data find clustering coefficient noun phrases contexts 
means noun phrases exhibit transitive behavior noun phrases tend share common neighbors 
restrict attention largest component clustering coefficients noun phrases contexts respectively 
table see results results characteristic path length 
see paths short similar path length random graph clustering coefficient higher random graph 
means graph small world properties 
small world nature noun phrase context cooccurrence graph noun phrases contexts graph largest component table clustering coefficients graphs noun phrases contexts entire graph largest component 
clustering coefficient random graph size shown parentheses largest component 
noun phrases contexts bipartite table characteristic path length average average path length graph clustering coefficient largest component graph 
see paths short similar path length random graph clustering coefficient higher random graph 
means graph small world properties 
characteristic path length measured characteristic path length graph noun phrases largest component graph contexts largest component 
contexts characteristic path length average number context steps pair contexts 
noun phrase uni partite graph characteristic path length 
bipartite graph characteristic path length 
means algorithm alternates suggestions noun phrases contexts relabel nodes largest component steps 
table shows values largest component graph bipartite graph projections 
see paths short similar path length random graph clustering coefficient higher random graph 
means graph small world properties 
labeling node may affect node graph just steps node may acquire labels tightly coupled neighbor hood 
mean need bootstrapping algorithms accurate cautious label assignment errors easily propagated 
analysis frequency component size sector component size component size frequency component size sector component size np graph sector component size context graph component size sector data components nodes 
project graphs see distribution holds noun phrases contexts 
connected components connectivity cooccurrence graph key success bootstrap ping algorithm 
hope learn phrase cooccurrences algorithms transmit information likelihood class membership cooccurrence links dependent existence links labeled unlabeled portions graph 
measuring connectivity sector train corpus find separate connected components 
nodes largest component nodes connected 
leaves nodes part large connected component 
second largest component contains nodes components containing nodes 
see graphically shown log log scale 
sector data components nodes 
project graphs see distribution nodes components similar noun phrases contexts largest component smaller components containing nodes 
viewed graphs noun phrases contexts majority components contain single isolated node 
labeling node singleton component affect nodes graph 
predicting performance graph properties predicting performance graph proper ties previous section showed graph shows small world power law properties 
examine interaction properties training data algorithm performance 
recall section initialize bootstrapping algorithms small set seed words examples target class 
conjecture seed set frequency important graph consists uncon nected components seeds occur largest connected component different components 
observed frequently occurring examples important algorithm effectiveness 
thinking data small world graph theoretic terms see frequently occurring terms hubs connected examples 
find basic seed sets classes people locations organizations table chapter seeds main connected component graph 
difference performance algorithms tasks explained differing presence main connected component 
random sets country names described section varied distribution training set 
showed chapter table different sets seeds quite large variance number examples label training set absolute numbers examples number unique examples 
note number unique examples labeled seeds exactly sum node degrees noun phrases labeled unique example labeled corresponds edge noun phrase context 
consider predictive algorithm performance contrast number seeds large connected component 
shows scatter plot total node degree seeds final breakeven score multiple experiments random subsets country names seeds 
left scatter plot node degree seeds breakeven score 
right converted ranks allow find correlations may non linear 
see node degree seeds correlated algorithm performance linearly left pearson correlation ranks analysis final algorithm breakeven sum node degree seeds predicts algorithm performance sum node degree seeds rank sum node degree seeds predicts rank algorithm performance rank final algorithm breakeven rank sum node degree seeds total node degree examples labeled seeds correlated algorithm performance linearly left pearson correlation ranks right spearman correlation 
correlations scores significant level 
right spearman correlation 
correlations scores significant level 
case linear correlation stronger rank correlation continue rank correlations predictive variables allow non linear monotonic correlations 
table see list features predictive algorithm perfor mance spearman correlation scores 
correlations significant level 
go explaining may relevant 
number unique seeds head matching np graph choose set seeds initial labeling assumption seeds appear data 
choose seeds inspecting data may find seeds 
addition may better results matching seeds graph 
fact weak statistically significant positive correlation number unique seeds matching noun phrases heads graph 
spearman correlation coefficient 
predicting performance graph properties feature rs number unique seeds head matching np graph number unique seeds exact matching np graph number unique seeds head matching nps largest component number unique examples labeled sum node degree total examples labeled number components containing seed number unique seeds examples positive example largest component number unique contexts covered seeds number unique contexts covered seed table features predictive algorithm performance spearman cor relation coefficients 
number unique seeds exact matching np graph seed matches noun phrase exactly modifier may unambiguously correct initial example 
fact number unique seeds exact matching noun phrases statistically significantly correlated breakeven score spearman correlation 
slightly higher unique seeds head matching noun phrase graph differ ence statistically significantly different 
number unique seeds head matching nps largest component examples largest component saw section may expect distribution seeds largest component may predictive algorithm performance 
positive correlation correlation stronger number seeds total graph 
analysis number unique examples labeled sum seed node degrees discussed number unique examples labeled seeds total unique pairs labeled seeds correlated performance correlation score 
total examples labeled seeds machine learning customary measure relationship examples labeled algorithm performance 
total examples labeled slightly higher number unique examples examples occur 
obvious feature predictive algorithm performance unique examples labeled strictly speaking introduce new information example types introduce information distribu tion 
find fact number examples labeled seeds correlated algorithm performance score 
higher score number unique examples labeled statistically significantly different 
strongly correlated spearman correlation score 
number components containing seed knowing data falls multiple components albeit disparate sizes expect number components containing seeds predictive algorithm performance 
recall section examples outside largest component seeds label examples largest component may sufficient 
hand bootstrapping propagate labels examples component 
shows breakeven score number components covered seeds locations class variety sets country names seeds 
experiments seeds components appear better results experiments seeds components 
correlation larger correlation number seeds graph correlation 
difference statistically significant predicting performance graph properties final algorithm breakeven number components containing seeds versus algorithm performance number components containing seeds find number components covered seeds spearman rank cor relation predictive total number seeds graph spearman rank correlation 
means may important choose seeds spanning multiple components graph 
number unique seed labeled examples largest component examine number seeds contained largest component random country seeds sets 
bulk data largest component important seeds providing initial labels members largest component 
clearly expect having having single seed largest component better having 
addition seeds better examples ambiguous occurring informative contexts training data having seeds largest component increases chance having seed largest component 
seeds noisy ambiguous having multiple seeds provides different types noise amplification useful signal learn 
seeds disjoint components interact labeling contexts multiple seeds component particularly largest component interact ways may counteract effects ambiguity noise 
look number unique examples labeled seeds largest component find strong positive correlation 
may reflect fact doing job providing initial examples propagate majority analysis final algorithm breakeven num contexts labeled multiple seeds predicts algorithm performance rank num contexts labeled multiple seeds predicts rank algorithm performance number contexts labeled multiple seeds final algorithm breakeven number contexts labeled multiple seeds number contexts labeled seed strongly predictive algorithm performance linearly left pearson correlation rank right spearman correlation examples due short path lengths power law distribution node degrees 
unique contexts covered seeds example labeled seed implicitly assigns label associated context 
number unique contexts labeled seeds correlation number unique contexts covered seed 
looking back table see number contexts labeled multiple seeds strongest predictor algorithm performance spearman correlation 
understand better show scatter plots raw counts scores ranked equivalents 
table show example contexts extracted multiple seeds original locations seed set table chapter contexts extracted seeds 
see selected seed appear unambiguously indicative target class locations 
combinations predictors multivariate sion know combination features shown table predictive features individually 
performed predicting performance graph properties context num seeds selected operations locations comments updated offices operates facilities customers owned originated grown filed due targeting covering table number contexts labeled seed predictive algorithm performance 
see sample contexts selected seed appear unambiguously indicative target class locations 
analysis feature coefficient number unique seeds head matching nps largest component total examples labeled number unique seed labeled examples largest component number unique contexts covered seed table interactions multiple predictor variables obtain correlation rank algorithm breakeven higher correlation obtained best predictor unique contexts covered seed isolation 
multiple linear regression ranks features 
gives spearman correlation linear combinations ranks features rank algorithm breakeven 
performed backwards regression features greedily removed removing feature changes correlation score small amount 
final set feature model shown normalized coefficients table 
interactions multiple pre variables obtain correlation rank algorithm breakeven higher correlation obtained best predictor unique contexts covered seed isolation 
coefficients show line fit ranks variables interactions variables mean draw precise 
strong correlation breakeven scores means combination features design better seed selection algorithms 
cross class comparison node degree predictor find total node degree examples labeled predictive algorithm performance number components find seeds number seeds find largest component 
comparisons locations class 
measure node degree algorithm performance classes locations people organizations 
see node degree predictive performance classes 
number data points calculate spearman rank correlation meaningfully visual inspection see correlation hold predicting performance graph properties feature rs number unique seeds head matching np graph number unique seeds exact matching np graph number unique seeds head matching nps largest component number unique examples labeled sum node degree total examples labeled number components containing example number components containing seed positive example number unique seed examples positive example largest component number unique contexts covered seeds number unique contexts covered seed number examples labeled active learning number positive examples labeled active learning percent positive examples labeled active learning number examples labeled active learning number examples labeled positive active learning percent examples labeled positive active learning table features predictive algorithm performance spearman cor relation coefficients consider experiments conducted active learning combinations random sets locations seeds number example labeled active learning active learning method 
correlations significant level 
cases 
graph features active learning check features correlated algorithm performance perform active learning 
seed dependence may reduced examples selected active learning compensate poor initial seeds 
table shows seed features stronger active learning features 
see correlation number contexts covered seed reduced correlation active learning active learning important factor 
perform multivariate regression experiments active learn ing 
table see variables selected inclusion model coefficients 
correlation model algorithm performance analysis feature coefficient number unique seeds head matching nps largest component number unique examples labeled total examples labeled number unique contexts covered seeds number unique contexts covered seed number positive examples labeled active learning table combination features predicting algorithm performance bootstrap ping active learning random seeds sets locations 
correlation model algorithm performance greater correlation individual feature isolation 
greater correlation individual feature isolation 
see number contexts selected seed continues important number positive examples labeled active learning 
feature set independence switch gears examining relationship graph properties algorithm performance looking way feature sets lated information theoretic sense 
specifically examine assumption features noun phrases contexts conditionally indepen dent target class 
kind independence assumption common machine learning generally stated examined 
exceptions nigam ghani muslea performed empirical evaluations manipulating level independence features 
jensen neville examine effects feature dependence relational learning 
examine independence assumption greater detail measuring mutual information feature sets exploring dependence sample size drawing tentative importance task 
assumed features noun phrases contexts condi independent target class 
means assumed class classes class class class feature set independence final algorithm breakeven score node degree examples labeled seeds predicts algorithm performance people locations organizations total node degree noun phrases labeled seeds final algorithm breakeven score total examples labeled seeds predicts algorithm performance people organizations locations total examples labeled seeds node degree examples labeled seeds versus breakeven classes left total number examples labeled seeds versus breakeven right 
find classes total node degree examples labeled seeds predictive algorithm performance 
table see examples noun phrases contexts joint marginal probabilities target class locations 
see empirically conditional independence target class hold class class class 
section measure far ideal distributions measuring mutual information feature sets target class 
assumption class conditional feature independence ways assign probability class membership example described section chapter basis multiview algorithms underlies coem algorithm nigam ghani probabilistic model em described section 
examine assumption closely way understanding performance algorithms explored chapter performance active learning explored chapter 
explore degree dependence nps contexts calculating mutual information 
mutual information discrete probability distributions defined log note independent 
independent log analysis noun phrase context class class class class class class united states plants united states united states organizations united states experienced united states called markets mines offers operates owns produced produces allows enjoy table examples noun phrases contexts joint marginal probabilities target class locations 
see empirically conditional inde target class hold class class class 
section measure far ideal distributions measuring mutual information feature sets target class 
united states organization location example united states experienced 
feature set independence 
mutual information variables bounded variables completely independent 
dependence vari ables increases mutual information increases 
find upper bound observe rewritten terms entropies similarly log log log log log log log log definition entropy min mutual information bounded minimum entropy random variables ignoring class variable time measure mutual formation noun phrases contexts corpora different sizes 
table gives mutual information noun phrases contexts different training corpora 
note mutual information grow strictly size corpus 
analysis dataset size examples sector test sector train wtx wtx wtx table mutual information noun phrases contexts consider joint distribution noun phrases contexts 
consider corpus noun phrase context pairs sample underlying distribution 
calculate corpus estimating finite sample 
large sample small may underestimate sample estimate may instances pairs see sample 
view cooccurrences pairs links bipartite graph described section measurement measurement connectivity structure graph 
karger showed place bound number examples see sampled graph find spanning tree high probability 
karger assumed random graph showed section data exhibits small world graph properties 
estimate bounds number examples see reliably estimate mutual information empirically measuring changes changes corpus size 
order understand sample size affects measured value mutual information took random samples instances test data contains instances samples sample size instances instances 
calculated mutual information noun phrases contexts sample calculated mean standard deviation mutual information sample size 
see estimates mutual information noun phrases contexts dependent sample size samples instances 
note classes interest represented instances test set locations people organizations expect mutual information measure samples smaller larger samples 
standard deviations sample sizes small expect feature set independence mutual information mutual information versus sample size test set number pairs sample mutual information noun phrases contexts random subsets test set 
sample size random subsets sampled error bars standard deviation shown 
see sample size increases pairs mutual information close converging 
sample size error bars relatively small 
estimates mutual information noun phrases contexts class fairly reliable 
conditional mutual information conditioned class label defined equation cover thomas class class log compare estimate mutual information noun phrases contexts class size upper bounds calculated entropy variables mean value computed random sample size 
recall equation upper bound min 
class find upper bound analogously class log log log log analysis log log log log log log class log class class class class class log definition entropy class class class 
similarly class class class min class class lower upper bounds mutual information noun phrases contexts class 
consider values extrema mean bootstrapping approaches learning semantic classes 
lower bound variables completely independent target class mutual information variables 
example graph structure state affairs shown 
dis connected components graph class 
component bipartite graph fully connected 
clearly graph structure ideal bootstrapping algorithm assigning labels edge example label nodes lead correct assignment 
addition existence correct label component examples reachable steps 
argument interesting consider small world properties data described section 
data observes small world properties small average path length propagation labels rapid 
graph small path lengths zero mutual informa tion noun phrases contexts shown 
labels shown edges bold positive 
graph bootstrapping algorithm learn model classes 
feature sets sufficient 
low feature set independence example graphs attain lower bound mutual formation noun phrases contexts class upper bound min 
positive examples shown bold edges 
mutual information feature sets target class sufficient expect learning performance bootstrapping algorithms 
example graph attaining upper bound mutual information class see step ladder graph configuration 
knowing noun phrase uniquely determines context 
bootstrapping configuration require seed example component labels examples 
mutual information attains maximum lack feature set redundancy means learning difficult 
consider relate mutual information target class back small world power law graph properties data saw section 
short path lengths discussed may predictive high mutual information labeling edges class information may increase mutual information 
know graph large clustering coefficient meaning node neighborhoods tend tightly connected 
suggest higher mutual information edge labeling may affect 
power law distribution shows graph great degree disparity 
low degree nodes contribute higher mutual information 
notice table mutual information noun phrases contexts positive class lower mutual information neg ative class 
observation smaller samples lead lower estimates analysis task pos max neg max class max locations organizations people table mutual information noun phrases contexts class labels test examples 
shown parentheses maximum possible value mutual informa tion min class class 
minimum possible value 
mutual information shown assume completely explained fact positive class small prior small sample 
compare uniform random subsample data size positive class see mutual information random sample higher 
assumption statistical independence positive class label somewhat true classes 
negative class mutual information higher negative class similar sized random subsample data 
suggests negative class assumption independence class label hold 
negative class reality consists subclasses specifically negative class organizations example contains classes people locations classes examined 
expect independence class label negative class 
mutual information nps contexts class label lowest people class organizations locations 
class conditional statistical independence important expect people class outperform organizations outperform locations 
observe ordering classes label examples examples actively labeled coem em chapter 
suggests examples actively labeled models reliable levels statistical dependence noun phrases contexts difference importance 
suggests violations statistical independence important factor predicting algorithm importance ordering emerges examples labeled active learning 
algorithm desiderata small worlds algorithm desiderata small worlds basis arguments empirical results chapter sug gest semi supervised learning data exhibiting small world prop erties algorithm sensitivity node degree hybrid approach greater con required labeling high degree nodes low degree nodes initial examples selected high degree initial examples selected span components graph examples selected active learning chosen high degree node degree part feature set selection criteria questions designing bootstrapping gorithms know set seeds lead suc bootstrapping 
set seed words sk dataset np context 
npn measure seeds heads noun phrases 
seeds heads noun phrases dataset seeds heads noun phrases dataset combination seeds data lead learning target class 
training information learning 
seeds heads noun phrases largest component knowing data exhibits small world properties described section know bulk examples largest component 
seeds analysis heads noun phrases largest component able learn properties tiny fraction data 
seeds heads noun phrases dataset saw performance improves seeds heads noun phrases dataset particular heads noun phrases largest component 
bootstrapping may perform seeds dataset 
seeds ambiguous dataset seeds chosen ambiguous may lead poor bootstrapping performance 
sets seeds distinct classes measure overlap contexts select 
high overlap may lead poor performance 
seed set seeds intersecting sets contexts cooccur may lead improved performance eliminating ambiguous seeds 
saw contexts cooccur different seeds improved performance 
seeds basic level category psycho linguistic notion basic level categories rosch captures standard names apply objects dog chair categories learned children 
superordinate categories 
animal furniture generalizations categories easily visualized 
subordinate cat egories 
dalmatian specific required general conversation learned children 
examples worked super ordinate categories 
seeds descriptions super ordinate category category members basic level subordinate level categories 
learned basic level subordinate members 
attempts learn specific general categories may require larger corpora cover instances phrases 
questions designing bootstrapping algorithms select seeds bootstrapping 
saw node degree noun phrases labeled heads predictive algorithm performance 
order select seeds arbitrary new learning task identify heads noun phrases sort node degree number unique contexts occur examine list order frequency 
continue labeling seeds till seen seeds target class till seen seed largest component 
decide classes represented seeds confusable 
ambiguity seeds measured calculating intersection contexts occur 
high degree occurrence contexts seeds ambiguous 
know data sufficient data represent underlying graph 
measuring connectivity structure measure sufficient data sampled underlying graph 
sufficient data bulk nodes form large connected component 
large connected component may sufficient data 
sufficient data learn target class 
examining high frequency head nouns lead identifying candidate seeds data 
way remedy gather data specifically containing seed terms 
systems proposed agichtein ghani jones 
analysis correct examples labeled seeds performing active learning 
learned chapter great deal utility correcting examples labeled seeds 
extra labeling time better spent labeling active learning saw chapter 
properties active learning algo rithm 
active learning algorithm learning semantic classes text choose frequently occurring examples examples positive 
example uncertainty sampling choose examples algorithm uncertain examples near decision boundary 
order select positive examples select examples slight positive side decision boundary 
chapter chapter explored experimental results detail 
total node degree examples labeled seeds initialization important predictor algorithm performance 
explained small world graph structure data established chapter 
data conditional independence 
addition number examples labeled positive important predictor performance active learning particularly locations class skewed distribution 
laid set properties data sets examine applying semi supervised learning description impact learning performance 
shown real world data set explored context semi supervised learning exhibits small world graphs properties 
measured algorithm performance terms graph theoretic properties showing node degree initial examples predictive algorithm performance distribution labeled examples components graph predictive performance 
suggested ways chapter algorithms labeling customized properties opening range approaches algorithm design application sensitive underlying distribution data 
analysis chapter held task making suggestions methods bootstrapping semantic classes basis classes worked different datasets sector trec wtx 
risk kind learning great deal specifics dataset tasks producing method generalize new tasks datasets domains 
chapter describe short experiment applying new domains methods explored recommended 
exercise applying recommendations diagnostics learnability developed 
task selection experiments conducted classes largely open ended vocabularies 
classes obtaining exhaustive list dictionary class members unrealistic 
example may new companies people haven heard misspellings novel ways referring locations points interest 
classes expect find instances training test corpora consist web pages 
recall chapter section number examples labeled seeds highly predictive performance 
wish perform bootstrapping experiment data advised choose class held task examples training corpus 
learn class occur training data advised collect new training data 
detect instances target class training corpus seeing find seeds extract examples 
expect products class reasonably represented general web pages wtx training collection sector test set 
addition products class consists relatively open ended vocab may difficult write obtain benefit bootstrapping approach 
choose perform experiments products class 
general expect bootstrapping approach learning semantic classes classes disambiguated immediate context 
useful classes difficult obtain exhaustive list class members may utility cases class members exhaustively enumerated described may ambiguous 
class dates times may represented regular expressions 
list exhaustively months days months years write common ways composed 
may expression expect third quarter 
general representation ideally suited learning time data expressions general feature representing digits 
conduct brief experiment extraction dates times class see general framework applicable 
seed selection selected semantic categories products dates times 
need small number noun phrases think may examples target class small number words may products dates times appropriate provide training information 
called seeds 
recall chapter assumption bootstrapping approach set seed words choose data 
section random subsets country names seed words highly variable distribution seed words training corpus 
chapter section seed selection number examples labeled seeds highly predictive performance 
seed words relatively frequently occurring training data 
ways ensuring collect training documents correspond seed examples suggested previous agichtein ghani jones select seed words training data 
held experiment select seed words training data products class conduct baseline experiment asking people supply seeds target class 
choice training data decided fixed corpus select seeds training corpus collect corpus specifically pre selected seeds 
reason training corpus collected contain seeds may special properties representation seeds representation vocabulary general data may need test generalization power may reduced 
remains question training corpus 
recall chapter section compared smaller corpus sector larger corpus wtx training data 
smaller corpus drawn distribution test data test data subsampled original sector crawl websites training corpus disjoint subsample data 
wtx corpus larger different general distribution web pages selected specifically web pages 
locations task larger disjoint corpus effective people organizations smaller corpus distribution effective 
may overlap organization people names training test collections 
realism products class wtx corpus described detail chapter section held task 
disjoint test set show methods perform applied brand new test collection sampled separately training collection may quite realistic setting system deployed 
dates times class sector training corpus 
held task seeds gb ii dlp projector sony psp construction kodak speed color film commute messenger bag sony mdr stereo headphones mp player maytag palm pilot home theater projector psp mm film messenger bag headphones disposable razor toyota suit mocha matari cheese hp compaq nc tips lipton tea buckshot loose leaf shoes basil seeds toyota se laptop battery ms sofa electric violin chocolate cake mountain bike pair glasses dress shirt headphones table sets seeds products class chosen introspection labelers 
set chosen difficult 
indicates examples training corpus matched seed set 
digit features allow generalize outside vocabulary learning training mismatched train test corpus may harmful 
seed selection introspection asked employees web search supply lists possible products 
lists shown table 
seed set indicates number examples wtx training corpus seeds 
set chosen specific product names matching examples training corpus 
set consisted somewhat general names products set matched examples training corpus 
set chosen difficult contain ambiguous words 
matched examples training corpus 
set chosen unambiguous matched examples training corpus 
labeler chose list objects purchased planned purchase 
set seeds matched examples training corpus 
seed selection select seeds training data chosen select seeds wtx training corpus 
chapter section know frequency seeds predictive algorithm performance active learning 
specifically know active learning algorithm performance predicted 
number unique seeds head matching np graph spearman tion 
number unique seeds exact matching np graph spearman cor relation 
number unique seeds head matching nps largest component spear man correlation 
number unique examples labeled sum node degree spearman correlation 
total examples labeled spearman correlation 
number components containing example spearman correlation 
number components containing seed positive example spear man correlation 
number unique seed examples positive example largest component spearman correlation 
number unique contexts covered seeds spearman correlation 
number unique contexts covered seed spearman tion list best criterion seed selection optimize number unique examples labeled criterion includes examples labeled active learning 
item total number examples labeled statistically significantly different predictive power 
held task choose seeds maximize number examples labeled providing starting point bootstrapping 
sorted noun phrases wtx corpus frequency labeled members 
task products examined frequent noun phrases labeled unambiguously correspond example products relevant seed relevant 
frequent noun phrases seeds thought unambiguously correspond example products services software products 
numbers relating distribution seed words wtx table 
examples total labeled seeds 
contrasts seeds chosen introspection matched examples training corpus 
looking top contexts labeled high frequency seeds see overlap range covered ser vices products variation services selects provides software selects provides 
intuitive sense product provide utility customer pro vided 
suggests contexts cooccur noun phrases represent vendors customers 
distinguish may need context example adding disambiguating noun phrase provides 
contexts may extensive expressive power 
dates times class years frequent noun phrases sector corpus seeds 
matched examples sector training corpus 
contexts occurring frequently seeds include increased months 
active initialization recall chapter section correcting examples labeled automatic labeling seed words contribute substantially learning performance 
correct examples labeled seeds 
bootstrapping active learning algorithm seed word nps exs np heads np heads cont ex 
cont services provides offers range software provides products information range line table seeds products task 
seeds selected examining top fre quent noun phrases identifying terms unambiguously prod 
shown number times seed words occurred noun phrases nps number times seed words occurred heads noun phrases np heads number unique noun phrases seed head np heads number unique contexts labeled seed contexts common contexts labeled seed 
examples total labeled seeds 
bootstrapping active learning algorithm bootstrapping algorithm iterations coem described chapter section robust classes 
chapter section allowing stopwords model improves results greatly people organizations classes having deleterious effect locations class 
indicator organizations indicators people 
plausible may weak positive predictor products negative predictors 
allowed stopwords model 
number examples labeled active learning chapter section benefit active learning comes iterations 
saw statistically section chapter number examples labeled positively correlated performance label just examples active learning real test minimally supervised training products class 
dates times class labeled examples contexts class relatively ambiguous dates held task times occur similar contexts locations 
earlier experiments described thesis excluded numbers labeled active learning 
dates times experiments removed exclusion 
active learning algorithm section chapter saw number positive examples labeled correlated algorithm performance 
active learning algorithm access true labels examples selecting modify algorithm select examples thinks positive 
simplify matters disagreement noun phrases context select examples feature set disagreement described chapter section 
selects examples uncertainty label example positive 
method performed experiments classes saw chapter section 
order remove redundancy relabeling seeds saw section restricted set possible examples labeled contain seeds 
evaluation model extract sector test set 
sorted extracted examples confidence score labeled top examples contained member target class product date time depending task 
calculated precision 
examined dictionary noun phrases produced training similarly scored obtain precision 
products class test set contained noun phrases heads words services products software 
noun phrases extracted just seed words fuller evaluation effects bootstrapping active learning performed analogous evaluation removed examples services products software head noun phrase labeled top remaining examples 
results freq freq table results extracting test examples models obtained bootstrapping products class seeds created introspection seeds chosen frequency freq 
set matched seeds seen baseline reflecting prior distribution products terms test corpus 
set chosen ambiguous containing brand names may names 
set performed worse baseline 
frequency seeds freq instances labeled active learning perform best remove test examples match seed freq 
results products table see results extracting test examples models obtained bootstrapping products class seeds created introspection seeds chosen frequency freq 
set matched seeds seen baseline reflecting prior distribution products terms test corpus 
set chosen ambiguous containing brand names may names 
set performed worse baseline 
frequency seeds freq instances labeled active learning perform best remove test examples match seed freq table show detail results frequency selected products seeds 
observing dictionary construction see including seeds evaluation see correct noun phrases dictionary original seeds 
remove examples seeds precision dictionary ranges top noun phrases 
range achieved thelen riloff learned categories building precision event precision human precision location precision time precision weapon precision 
results obtained bootstrapping multiple classes held task nps nps non seed examples examples non seed table precision different numbers extracted test examples training dictionary noun phrases examined bootstrapping products coem initial examples selected candidates examples labeled active learning noun phrase context disagreement 
test examples contained seed words show results examples filtered remove seeds non seed 
improved results learning single class time 
consider detail examples extracted held test set combined noun phrase context pair evaluated correctness 
top ranked extracted examples extracted noun phrases con texts minority seed set services products software 
correct 
remove examples aided presence seeds correct extraction held unseen data 
results promising extra constraints bootstrapping multiple classes simultaneously assuming sense discourse 
constraints lead better results 
dates times table see results bootstrapping learn extract dates times web pages years seeds 
see needing write rules defining form date able identify dates times highest scoring extractions precision 
exceeds accuracy achieved thelen riloff 
errors extraction resulted ambiguous contexts growth occurred revenue founded occurred london 
kinds date time expressions able extract included chapter active active table results extracting test examples models obtained bootstrapping dates times class seeds created looking frequent noun phrases training corpus seeds years 
generic words time frames month year century business time frames learned quarter quarter second ter third quarter fourth quarter approximate dates early spring summer digit years learned digit years initial seeds relative time descriptions previous year year year month names concatenated years march february month names isolation learned month name days week isolation learned day week precise times jan date formats fy suggests approach way initializing date extractor 
order build complete date extractor generalize example digit years represented regular expression 
chapter shown methods demonstrated dissertation extract data held test set new task algorithm held task development 
products task human labeled input noun phrases examined obtain seed words additional examples labeled active learning obtain precision correct extraction held unseen data 
disjoint training set different distribution test set full set information information extraction features incorporating presence digits capital letters learning multiple classes simultaneously 
adding kind information lead stronger results 
dates times tasks input digit years selected frequent non phrases sector training corpus examples labeled active learning 
learned days week months year combinations days dates 
learned patterns lower precision date time extraction initialize hybrid extractor rules added identify digit years 
results generalize classes data conservative selection training data amount data labeled 
chapter examined depth bootstrapping algorithms active learning learning extract entities belonging particular semantic class 
summarize main reached result depth study 
addition depth sacrificed breadth 
chapter describe interesting follow ons 
tie results chapter bootstrapping algorithms assumptions chapter incorporating active learning boot strapping algorithms chapter measuring graph properties labeled unlabeled data tying back learning performance 
active learning impact correcting ini tial examples weak labeling labels assigned examples example presence single seed word manual examination labels 
natural think correcting labels manually inspecting improve performance better labelers time label new examples active learning 
conclude choice examples label key fixed amount labeling 
highly connected noun phrases important learn ing experimentally chapter removing pronouns model bootstrapping lead reduced learning performance 
statistically chapter predict learning performance node degree examples labeled seeding active learning number contexts connected seeds distribution seeds components 
conclude results useful take account graph structure connecting noun phrases contexts bootstrapping information extractors 
pronouns form highly connected nodes graph highly influential weakly predictive 
nodes useful depending connectivity graph 
graph structure important learning distribution labeled examples components graph affected learning outcome 
suggests take account graph structure particular distribution data components selecting examples labeling 
pre existing dictionaries worked exclusively small lists words input 
sense start large dictionaries available 
looked longer list country names chapter saw slight improvements differences lessened active learning saw chapter 
larger pre existing dictionaries may benefits interactions considered 
applicability range semantic classes chapter mentioned psycho linguistic notion basic level categories rosch captures standard names apply objects dog chair categories learned children 
superordinate categories 
animal furniture generalizations categories easily visualized 
subordinate categories 
dalmatian specific required general conversation learned children 
examples worked super ordinate categories 
seeds descriptions super ordinate category category members basic level subordinate level categories 
learned basic level subordinate members 
attempts learn specific general categories may require larger corpora cover instances phrases 
useful conduct experiments see characterize set semantic classes learnable approach terms rosch categories categories semantic classes 
applicability languages looked learning identify semantic classes english text 
may find transferring approach languages requires different treatment words phrases 
example languages complex morphology english interaction tokenization extraction explored 
alternative data representations sources area examining implications simplification performed having features 
noted chapter section labelers access noun phrase context full sentence occurred agreed labeling time 
sentence noun phrase context agreement dropped 
algorithms noun phrase contexts learning 
agreement human labelers conjecture algorithms better information 
examine effect adding features results analyses 
ignored capital letters syntactic clues useful identifying entities 
useful generalize representation noun phrases local lexico syntactic contexts sequences words ngrams 
allow approach applied example web search queries text types grammatical structure 
automatically acquiring relevant training data saw sections number seeds training corpus corpus size affect results 
may wonder way increasing number seeds training corpus greatly increasing corpus size greater computational efficiency 
way may label examples 
addressed question chapter examining efficient ways choose examples labeling active learning 
different approach motivated related acquiring documents target language ghani relevant semantic relationships agichtein involve automatically acquiring training data contain instances seeds target class 
may promising direction 
applicability domains data types explored learning examples domain entity extraction text documents 
methods explored may applicable text classification document level extraction classification completely different data image data time series data 
predicting improving algorithm performance data structure showed kind machine learning task find correlations structure labeled unlabeled data learning performance 
kind analysis may usefully applied learning tasks 
bibliography agichtein 

extracting relations large text collections 
doctoral dissertation columbia university 
agichtein ipeirotis gravano 

modeling query access text databases 
proceedings sixth annual workshop web databases 
albert barab si 

statistical mechanics complex networks 
reviews modern physics 
xxx lanl gov abs cond mat 
appelt israel 

information extraction technology 
tutorial prepared ijcai 
bailey craswell hawking 

engineering multi purpose test collection web retrieval experiments 
information processing management 
baker mccallum 

distributional clustering words text clas 
proceedings annual international acm sigir conference research development information retrieval sigir 
yang 

training expansion bridging theory practice 
proceedings eighteenth annual conference neural infor mation processing systems nips 
bean riloff 

unsupervised learning contextual role knowledge coreference resolution 
proceedings human language technology conference north american chapter association computational linguistics annual meeting hlt naacl 
hall bezdek clarke 

partially supervised clustering image segmentation 
pattern recognition 
blum lafferty reddy 

semi supervised learning randomized 
proceedings international conference machine learning icml 
bibliography blum mitchell 

combining labeled unlabeled data training 
proceedings th annual conference computational learning theory colt 
craven 

exploiting relations concepts acquire weakly labeled training data 
proceedings nineteenth international conference machine learning icml 
brown pietra desouza lai mercer 

class gram models natural language 
linguistics 
califf mooney 

relational learning pattern match rules information extraction 
proceedings acl workshop natural language learning pp 

cardie 

empirical methods information extraction 
ai magazine 
cohen hurst jensen 

flexible learning system wrapping tables lists html documents 
proceedings eleventh international world wide web conference www 
collins singer 

unsupervised models named entity classification 
proceedings emnlp vlc 
cover thomas 

elements information theory 
new york john wiley sons 
cozman cohen 

unlabeled data degrade classification performance generative classifiers 
fifteenth international florida artificial intelligence society conference pp 

dagan justeson lappin 

syntax lexical statistics anaphora resolution 
applied artificial intelligence 
dagan lee pereira 

similarity models word cooccurrence probabilities 
xxx lanl gov abs cs 
de moura lai 

signatures small world scale free properties large computer programs 
physics review 
domingos pazzani 

optimality simple bayesian classifier zero loss 
machine learning 
bibliography ferrer sol 

small world human language 
proceedings royal society london 
freitag 

multistrategy learning information extraction 
proceedings fifteenth international conference machine learning icml 
freund seung shamir tishby 

selective sampling query committee algorithm 
machine learning 
ghani jones 

automatic training data collection semi supervised learning information extraction systems technical report 
technology labs 
labs com techreports ghani jones tr pdf 
ghani jones mladenic 

building minority language corpora learning generate web search queries 
knowledge information systems 
glickman jones 

examining machine learning adaptable information extraction systems 
aaai workshop machine learning information extraction 
goldstein morris yen 

problems fitting power law distribution 
arxiv org abs cond mat 
allan 

cross document coreference large scale corpus 
proceedings human language technology conference north american chapter association computational linguistics annual meeting hlt naacl 
grishman 

nyu system muc syntax 
proceedings sixth message understanding conference muc 
columbia md 
morgan kaufmann 

hofmann 

probabilistic latent semantic indexing 
proceedings second annual sigir conference research development information retrieval 
huffman 

learning information extraction patterns examples 
wermter riloff eds connectionist statistical symbolic approaches learning natural language processing 
springer verlag berlin 
hurst 

interpretation tables texts 
doctoral dissertation university edinburgh 
iamnitchi ripeanu foster 

small world file sharing communities 
rd conference ieee communications society infocom 
hong kong 
bibliography jensen neville 

linkage autocorrelation cause feature selection bias relational learning 
proceedings nineteenth international conference machine learning icml pp 

joachims 

learning classify text support vector machines 
doctoral dissertation university dortmund 
joachims 

transductive learning spectral graph partitioning 
proceedings international conference machine learning icml 
jones nigam mccallum riloff 

bootstrapping text learning tasks 
ijcai workshop text mining foundations techniques applications 
kamvar klein manning 

interpreting extending classical ag clustering algorithms model approach 
proceedings th international conference machine learning icml 
karger 

random sampling cut flow network design problems 
pro ceedings sixth annual acm symposium theory computing pp 

knoblock lerman minton muslea 

accurately reliably extract ing data web machine learning approach 
ieee data engineering bulletin 
kou cohen murphy 

high recall protein entity recognition dictionary 
proceedings th annual international conference intelligent systems molecular biology 
lee 

similarity approaches natural language processing 
doctoral tation harvard university 
lewis 

naive bayes independence assumption information retrieval 
proceedings th european conference machine learning ecml pp 

chemnitz de springer verlag heidelberg de 
lewis gale 

sequential algorithm training text classifiers 
proceedings seventeenth annual international acm sigir conference research development information retrieval sigir pp 

liere tadepalli 

active learning committees text categorization 
proceedings fourteenth national conference artificial intelligence aaai pp 

bibliography liu lee yu li 

partially supervised classification text documents 
proceedings nineteenth international conference machine learning icml 
manning schutze 

foundations statistical natural language processing 
mit press 
mccallum nigam 

comparison event models naive bayes text classification 
aaai workshop learning text categorization 
tech 
rep ws aaai press 
mccallum rosenfeld mitchell ng 

improving text shrinkage hierarchy classes 
proceedings fifteenth international conference machine learning icml pp 

mccallum nigam 

employing em pool active learning text classification 
machine learning proceedings fifteenth international confer ence icml pp 

miller beckwith fellbaum gross miller 

papers wordnet technical report csl 
cognitive science laboratory princeton university 
mitchell 

machine learning 
new york mcgraw hill 
muc proceedings 
proceedings sixth message understanding conference muc 
san francisco ca morgan kaufmann 
muslea 

extraction patterns information extraction tasks survey 
aaai workshop machine learning information extraction 
muslea minton knoblock 

selective sampling redundant views 
proceedings seventeenth national conference artificial intelligence twelfth conference innovative applications artificial intelligence aaai iaai 
nelson 

university south florida word association norms 
www udf edu 
newman park 

social networks different types networks 
physics review newman watts strogatz 

random graph models social networks 
proceedings national academy sciences usa 
bibliography nigam ghani 

analyzing effectiveness applicability training 
ninth international conference information knowledge management cikm pp 

nigam mccallum thrun mitchell 

learning classify text labeled unlabeled documents 
aaai 
pastor vespignani 

epidemic spreading scale free networks 
physical review letters 
press teukolsky vetterling flannery 

numerical recipes cambridge university press 
second edition edition 
proceedings 

proceedings third message understanding conference muc 
san mateo ca morgan kaufmann 
radford 

transformational grammar course 
cambridge university press 
raghavan madani jones 

interactive feature selection 
proceedings nineteenth international joint conference artificial intelligence ijcai 
riloff 

automatically constructing dictionary information extraction tasks 
proceedings eleventh national conference artificial intelligence aaai pp 

aaai press mit press 
riloff 

automatically generating extraction patterns untagged text 
proceedings thirteenth national conference artificial intelligence aaai pp 

aaai press mit press 
riloff 

empirical study automated dictionary construction information extraction domains 
artificial intelligence 
riloff jones 

learning dictionaries information extraction multi level boot strapping 
proceedings sixteenth national conference artificial intelligence aaai pp 

aaai press mit press 
riloff phillips 

sundance autoslog systems technical report uucs 
university utah school computing 
rooth riezler carroll 

inducing semantically annotated lexicon em clustering 
proceedings th annual meeting acl 
bibliography rosch mervis gray johnson 

basic objects natural categories 
cognitive psychology 
sarawagi cohen 

semi markov conditional random fields informa tion extraction 
proceedings eighteenth annual conference neural information processing systems nips 
seymore mccallum rosenfeld 

learning hidden markov model struc ture information extraction 
aaai workshop machine learning information extraction 
sigman 

global organization wordnet lexi con 
proceedings national academy sciences usa 
www pnas org cgi reprint pdf 
sleator temperley 

parsing english link grammar 
third international workshop parsing technologies 
soderland 

learning information extraction rules semi structured free text 
machine learning 
steyvers tenenbaum 

large scale structure semantic net works statistical analyses model semantic growth 
cognitive science 
arxiv org abs cond mat 
strogatz 

exploring complex networks 
nature 
thelen riloff 

bootstrapping method learning semantic lexicons extraction pattern contexts 
conference methods natural language processing emnlp 
thompson califf mooney 

active learning natural language parsing information extraction 
proceedings th international conference machine learning icml 
van rijsbergen 

information retrieval nd edition 
dept computer science university glasgow 
watts strogatz 

collective dynamics small world networks 
nature 

