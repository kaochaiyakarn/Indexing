nonblocking concurrent data structures condition synchronization william scherer iii michael scott department computer science university rochester rochester ny scherer scott cs rochester edu 
apply classic theory linearizability operations wait thread establish precondition 
model operation request follow linearization point 
linearization request marks point thread wishes visible peers linearization follow marks point request fulfilled operation takes effect 
placing linearization points purview object semantics specify effects operations order pending requests fulfilled 
term dual data structure describe concurrent object implementation may hold data reservations registered requests 
reasoning separately request successful follow period obtain meaningful definitions nonblocking dual data structures 
concrete examples lock free experimentally compare performance lock nonblocking alternatives 
nearly fifteen years ago linearizability standard means reasoning correctness concurrent objects 
informally linearizability provides illusion operation 
takes effect instantaneously point invocation response 
linearizability nonblocking sense requires call total method precondition simply true wait execution method 
certain correctness criteria serializability may require blocking enforce coherence multi object system 
fact nonblocking linearizability particularly attractive reasoning nonblocking implementations concurrent objects provide guarantees various strength regarding progress method calls practice 
wait free implementation contending thread guaranteed complete method call bounded number time steps 
lock free implementation contending thread guaranteed complete supported part nsf numbers eia ccr ccr darpa afrl contract number sun microsystems laboratories 
method call bounded number steps thread point view 
obstruction free implementation thread guaranteed complete method call bounded number steps absence contention threads execute competing methods concurrently 
various progress conditions assume method total 
herlihy puts restrict attention objects operations total unclear interpret wait free condition partial operations 
example natural way define effects partial deq concurrent system wait queue nonempty specification clearly admit wait free implementation 
avoid problem designers nonblocking data structures typically methods returning error flag current state object admit method intended behavior 
partial methods important 
applications need dequeue pop deletemin operation waits structure empty countless examples condition synchronization fundamental concurrent programming 
nonblocking data structure methods obvious strategy embed call loop retry succeeds 
strategy important drawbacks 
introduces unnecessary contention memory communication bandwidth may significantly degrade performance careful backoff 
second provides fairness guarantees 
consider total queue dequeue method waits return successfully sequence calls threads enqueues enqueues calls dequeue call returns calls dequeue call returns clearly bad execution history returns results wrong non fifo order implies incorrect implementation 
clearly history calls dequeue calls dequeue enqueues enqueues call returns call returns calls dequeue calls dequeue enqueues enqueues call returns call returns line known occurred second may case example waiting threads identified querying scheduler examining thread control block reading object specific flag intuition suggests history returns results right order returns wrong threads 
implement queue wrapping nonblocking dequeue loop third questionable history may certainly occur 
section show apply theory linearizability way object semantics specify order pending requests fulfilled 
propose data structures implement semantics explicitly representing set pending requests 
borrowing terminology bbn butterfly parallel processor early define dual data structure may hold reservations registered requests addition data 
nonblocking dual data structure operation completes registers request nonblocking fashion fulfilled requests complete nonblocking fashion threads waiting requests fulfilled interfere progress threads 
concrete examples introduce lock free dual data structures section 
returns results fulfills requests lifo order fifo order 
structures attractive candidates bag tasks programming multiprocessor systems 
subsumes scalable queue spin locks semaphores conjunction small scale test set lock obtain limited contention spin lock embodies explicit tradeoff fairness locality distributed shared memory machines 
preliminary performance results appear section 
summarize findings suggest directions section 
definitions linearizable objects herlihy wing history object potentially infinite sequence method invocation events args response return events val name method return condition usually ok identifies thread 
invocation matches response sequence thread id invocation matching response called operation 
invocation response operation may denoted inv res respectively 
event precedes event history write 
history sequential response immediately follows matching invocation 
non sequential history concurrent 
thread subsequence history consisting events thread 
histories equivalent thread identical 
consider formed concurrent histories thread sequential begins invocation 
assume semantics object consider formally uniquely determine set legal sequential histories 
queue example items inserted removed fifo order 
nth legal history return value inserted 
point number prior enqueues equal exceed number successful dequeues 
permit dequeue calls occur time dequeue total method precondition simply true allow unsuccessful dequeues deq appear history number prior enqueues equals number prior successful dequeues 
possibly concurrent history induces partial order operations oi oj res oi inv oj 
linearizable equivalent legal sequential history 
departing slightly herlihy wing introduce notion augmented history object 
formed augmented history obtained history inserting linearization point ml args val denoted lin response previous matching invocation inv lin res 
equivalent legal sequential history linearization points appear order corresponding operations embodies linearization order linearization points defines total order operations consistent partial order induced put way res oi inv oj lin oi lin oj 
notion augmented histories define legality resort equivalent sequential histories say augmented history legal sequence linearization points permitted object semantics 
similarly linearizable augmented produce legal augmented history implementations define implementation concurrent object pair 
set valid executions operational system possible interleavings machine instructions threads executing specified body code commercial multiprocessor 
execution takes form series steps instructions identified particular thread occurs atomically 
implementations nonblocking concurrent objects real machines typically rely atomic loads stores universal atomic primitives swap linked conditional completes single step 

interpretation maps execution augmented object history events including linearization points identified steps way event step identified say implementation correct legal augmented history concurrent object 
practice course steps execution observable order executed thread data dependence 
particular general observe inv oi inv oj oi oj performed different threads observe res oi inv oj oi thread may write value response read oj thread invocation 
power linearizability lies insistence semantic order operations concurrent object consistent externally observable orderings 
addition correctness implementation may variety properties interest including bounds time steps space remote memory accesses suite required atomic instructions various progress conditions 
implementation wait free bound executions invocations inv number steps steps identified inv res 
implementation lock free invocations inv oi bound number steps steps identified inv oi necessarily matching subsequent response res oj 
implementation obstruction free threads invocations inv performed bound number consecutive steps performed intervening steps thread steps identified inv res 
note definitions lock freedom obstruction freedom permit executions invocation matching response threads may starve 
adaptation objects partial methods object partial methods divide method request method follow method invocations responses 
total queue example provide dequeue request dequeue followup methods 
analogy lamport bakery algorithm request method returns ticket passed argument follow method 
follow part returns desired result method precondition satisfied error indication 
history concurrent object consists invocation response events args ok val total methods request invocation response events preq args ok tik follow invocation response events pfol tik val partial methods request invocation matching response called request operation follow invocation matching response called follow operation 
request invocation response operation may denoted inv res follow invocation response may denoted inv res 
follow ticket argument matches previous request returned follow operation said successful response event ok val said unsuccessful response event consider formed histories thread sequential prefix string regular set ru request unsuccessful follow matches preceding successful follow matches preceding consists sequence operations request successful response call partial method sequence linearization points including initial linearization point args invocation response request final linearization point val invocation response successful matching followup 
initial final linearization points may denoted fin 
say augmented history legal sequence linearization points determined semantics object 
definition allows capture partial methods object semantics 
previous section suggested semantics queue require nth successful dequeue returns value inserted nth enqueue number prior enqueues point equals exceeds number prior 
require nth final linearization point dequeue contains value linearization point nth enqueue number prior linearization points enqueue equals exceeds number prior final linearization points dequeue linearization point unsuccessful dequeue followup number prior linearization points exactly equals number prior final linearization points dequeue linearization points successful dequeue 
rules ensure queue returns results fifo order pending requests partial methods permitted fulfilled fifo order 
history linearizable augmented produce legal augmented history implementation correct legal augmented history concurrent object 
definition formedness thread wishes execute partial method call request call followup loop succeeds 
different calling traditional method succeeds linearization distinguished request operation hook allows object semantics address order pending requests fulfilled 
practical matter implementations may wish provide demand method waits return successfully plain method equivalent demand request 
obvious implementation demand contains loop implementations possible 
particular implementation may choose scheduler synchronization put sleep semaphore signaled precondition met allowing processor purposes interim 
require possible provide request follow methods defined trivial modifications implementation 
algorithms section provide plain interface internal busy wait loops 
progress conditions reasoning progress deal fact partial method may wait arbitrary amount time perform arbitrary number unsuccessful follow ups precondition satisfied 
clearly wish require requests follow ups nonblocking 
prevent unsuccessful follow ups interfering progress threads 
prohibiting operations accessing remote memory 
cache coherent machine access thread operation said remote writes memory may execution read written threads constant number times inv res reads memory may execution written threads constant number times inv res 
non cache coherent machine access thread remote refers memory allocate 
dual data structures define dual data structure concurrent object implementation may hold reservations registered requests addition data 
reservations correspond requests fulfilled object satisfies necessary precondition 
reservation may removed call follow method may return call thread precondition true 
nonblocking dual data structure 
correct implementation linearizable concurrent object defined 

operations including requests follow ups nonblocking 

unsuccessful follow ups perform remote memory accesses 
nonblocking dual data structures may classified wait free lock free obstruction free depending guarantees respect condition 
section consider concrete lock free implementations 
example data structures space limitations preclude inclusion pseudocode conference proceedings 
example data structures line www cs rochester edu scott synchronization pseudocode duals html 
double swap cas instruction provided example sparc create counted pointers avoid aba problem vulnerable pointer paired serial number incremented time pointer updated non null value 
assume thread stall long see serial number repeat 
machine single word load linked store conditional ll sc instructions serial numbers needed 
cas takes address expected value new value argument 
expected value address replaced new value atomically boolean return value indicates replacement occurred 
aba problem arise system memory dynamically allocated freed reallocated thread performs load followed cas may succeed value location question changed changed back 
ll reads memory location note having done 
sc stores new value location accessed ll provided thread modified location 
boolean return value indicates store occurred 
standard lock free stack treiber 
long number calls pop exceed number calls push behaves non dual cousin 
stack empty contains reservations pop method pushes reservation spins node field 
method pushes data node 
previous top node reservation adjacent nodes annihilate thread finds data node underlying reservation top stack attempts write address node field pop nodes stack 
time stack contains reservations data datum top followed reservations 
head pointer pointers stack nodes tagged indicate node list reservation datum reservation beneath stack 
assume nodes word aligned tags fit low order bits pointer 
presentation purposes line pseudocode assumes data values integers obviously changed type including pointer fit serial number target double width cas single word machine ll sc 
differentiate cases topmost data node fulfill request stack contains data pushes case set data reservation tags pushes set data tag 
mentioned section code provides method subsumes sequence operations pop request successful follow 
initial linearization point linearization point cas modifies top stack pointer 
pops stack non empty cas final linearization point 
spin final linearization point cas thread writes node field requester reservation terminating spin 
code push lock free code pop initial linearization point final linearization point read terminates spin pop 
spin pop comprise body unsuccessful follow operation provided separate method entirely local reads requester reservation node requester allocated thread write terminate spin 
satisfies conditions section 
offer proof inspection code confirms satisfies usual lifo semantics total methods number previous linearization points push exceeds number previous initial linearization points operation succeed immediately return value provided operation numbers pushes pops linearized equal 
similar fashion satisfies pending requests lifo order number previous initial linearization points pop exceeds number previous linearization points push push operation provide value returned operation numbers pushes pops linearized equal 
condition section 
spin terminated cas thread possibly fulfilling thread possibly helper updates data node field reservation 
cas final linearization point spinning thread 
final linearization point fulfilling thread occurs earlier fulfilling thread successfully updates top stack pointer point fulfilling datum 
linearized thread able progress spinning pop reaches final linearization point 
possible spinning thread perform unbounded number local spinning steps legal execution happens need separate linearization points fulfilling fulfilled operations 
tempting consider simpler implementation fulfilling thread pops reservation stack writes fulfilling datum directly reservation 
implementation incorrect leaves requester vulnerable failure stall fulfilling thread subsequent pop reservation prior write datum 
reservation longer stack arbitrary number operations performed threads returning subsequently pushed data linearize requester successful follow 
possible application implement bag tasks parallel execution system 
newly created tasks share data completed tasks may sense thread execute newly created task created long ago needs 
similarly insufficient threads may sense newly created tasks executed threads idle threads idle long time 
addition enhancing locality allow power aware processors enter low power mode running spinning threads potentially saving significant energy 
lifo ordering implement policies 
lock free queue 
long number calls dequeue exceed number calls push behaves non dual cousin 
initialized single dummy node real datum reservation second node 
time second subsequent nodes reservations data 
queue empty contains reservations method enqueues reservation spins request pointer field tail node 
method part fulfills request head queue enqueue datum 
fulfilling thread uses cas update reservation field pointer node outside queue containing provided data 
simultaneously fulfills request breaks requester spin 
thread finds fulfilled request head queue removes frees 
nb acting head queue requires obtain consistent snapshot tail pointers 
extending technique original queue stage check ensure sufficient consistency prevent race conditions 
queue nodes tagged requests setting low order bit pointers point 
assume loss generality data values integers provide method subsumes sequence operations request successful follow 
code lock free code initial linearization point final linearization point read terminates spin dequeue 
spin dequeue comprise body unsuccessful follow accesses node thread write terminate spin 
satisfies conditions section cache coherent machine 
non cache coherent machine need modify code provide extra level indirection spin dequeue reads node requester allocate 
offer proof inspection code confirms satisfies usual fifo semantics total methods number previous linearization points exceeds number previous initial linearization points dequeue new operation return value provided nth enqueue 
similar fashion satisfies pending requests fifo order number previous initial linearization points dequeue exceeds number previous linearization points new operation provide value 
condition section 
spin terminated cas thread method cas linearization point final linearization point dequeue 
note simpler algorithm enqueue method remove request queue fulfill correct cas operation removal constitute final linearization point enqueue corresponding dequeue continue spin arbitrary amount time thread performing stall 
applications versatile 
obviously traditional bag tasks producer consumer buffer 
uses mutual exclusion 
initialized hold single datum previously unknown variety queue mutual exclusion lock 
widely mcs lock lock spin release code mcs lock updates tail pointer queue pointer predecessor node lock updates pointer swings tail cover 
semaphores 
initialized data nodes constitutes spin semaphore 
example allocate interchangeable resources set competing threads 
limited contention lock 
noted strict fairness queue locks may desirable non uniform memory access distributed shared memory multiprocessor 
time test set lock tends requests physically nearby threads unacceptably unfair mention slow contention threads high threads physically distant may starve 
attractive compromise allow waiting threads bypass line limited extent 
paired test set lock provides straightforward implementation limited contention lock 
initialize tokens permission contend test set lock 
value determines balance fairness locality 
acquire operation dequeues token contends test set lock 
release operation enqueues token releases test set lock 
starvation possible ordinary test set lock 
eliminate entirely desired reducing periodic basis 
experimental results section compare performance treiber lock free stack lock free queue lock alternatives 
treiber stack queue embed calls dequeue respectively loop repeats operations succeed 
alternatives locked stack locked queue employ similar loops 
remaining alternatives lock dual data structures 
nonblocking dual locked stack dual locked queue contain data requests 
updates protected test set lock 
experimental platform processor cache coherent multiprocessor ghz ultrasparc iii processors 
benchmark creates threads thread test 
thread executes follows time expired insert data structure repeat pause data structure empty pause threads run time expired remove val data structure val insert data structure pause conventions arrange series rounds data structure alternates full requests full data 
threads chosen random prime structure round join peers emptying 
ran test seconds report minimum operation run time trials 
spot checks longer runs revealed anomalies 
choosing minimum effectively discards effects periodic execution kernel daemons 
code various algorithms written embedded assembly cas compiled version level optimization 
fast local memory allocator podc 
stack results appear 
lock lock free algorithms dualism yields significant performance improvement worker threads dual locked stack faster takes time locked stack retries calls repeatedly nonblocking faster counterpart 
case lock stack faster corresponding lock free stack due believe reduced contention top stack pointer 
ns operation threads dual locked stack locked stack stack fig 

benchmark time operation stack algorithms 
queue results appear 
dualism yields significant improvements worker threads dual locked queue faster locked queue retries calls repeatedly nonblocking faster non dual counterpart 
stacks nonblocking outperforms dual locked queue significant margin attribute difference potential concurrency enqueues dequeues 
queue slightly faster locked queue low thread counts slightly slower threads significantly faster number threads exceeds number processors lock algorithm begins suffer preemption critical sections 
performance nonblocking flat threads size machine reasonable despite extremely high level contention benchmark recommend algorithm reservation cache coherent machine 
ns operation threads dual locked queue locked queue queue fig 

benchmark time operation queue algorithms 
linearizability central study concurrent data structures 
historically limited restriction methods total 
shown encompass partial methods introducing pair linearization points registration request fulfillment 
reasoning separately request successful follow period obtain meaningful definitions wait free lock free obstruction free implementations concurrent objects condition synchronization 
concrete lock free implementations 
performance results commercial multiprocessor suggest dualism yield significant performance gains naive retry failure 
par ticular appears eminently useful algorithm outperforming queue experiments factor large thread counts 
nonblocking dual data structures undoubtedly developed double ended queues priority queues sets dictionaries abstractions 
may turn variants embody different policies pending requests fulfill matching operation precondition true 
imagine example stack pending requests fifo order conceivably queue lifo order 
plausibly imagine arbitrary system thread priorities matching operation fulfills highest priority pending request 
useful structures may obtained altering behavior request subsequent successful follow 
noted section waiting threads effectively incorporating scheduler condition synchronization nonblocking data structures 
real time database systems combine dualism timeout allowing spinning thread remove request structure waits long 
acknowledgments grateful anonymous referees helpful suggestions particular referee suggested requests follow ups full fledged operations significantly simplifying description progress conditions initial final linearization points 
bbn laboratories 
butterfly parallel processor overview 
bbn report version cambridge ma march 
herlihy moir 
obstruction free synchronization double ended queues example 
proceedings third international conference distributed computing systems providence ri may 
herlihy wing 
linearizability correctness condition concurrent objects 
acm transactions programming languages systems july 
herlihy 
wait free synchronization 
acm transactions programming languages systems january 
system principles operation 
ibm 
lamport 
new solution dijkstra concurrent programming problem 
communications acm august 
lamport 
time clocks ordering events distributed system 
communications acm july 
mellor crummey scott 
algorithms scalable synchronization shared memory multiprocessors 
acm transactions computer systems february 
michael scott 
simple fast practical non blocking blocking concurrent queue algorithms 
proceedings fifteenth acm symposium principles distributed computing pages philadelphia pa may 
papadimitriou 
serializability concurrent database updates 
journal acm october 

hierarchical backoff locks nonuniform communication architectures 
proc ninth international symposium high performance computer architecture pages anaheim ca february 
scott 
non blocking timeout scalable queue spin locks 
proceedings second acm symposium principles distributed computing pages monterey ca july 
treiber 
systems programming coping parallelism 
rj ibm almaden research center april 
