modeling time information automatic genre recognition systems audio signals nicolas giorgio signal processing institute lts cole polytechnique rale de lausanne epfl lausanne ch switzerland nicolas epfl ch creation huge databases coming restoration existing analogue archives new content demanding fast reliable tools content analysis description searches content queries interactive access 
context musical genres crucial descriptors widely years organize music catalogues libraries shops 
despite musical genres remain poorly defined concepts automatic classification problem non trivial task 
automatic genre classification models rely pattern recognition architecture extracting features chunks audio signal classifying features independently 
focus low level temporal relationships chunks classifying audio signals terms genre words investigate means model short term time structures context information music segments consolidate classification consistency reducing ambiguities 
detailed comparative analysis different time modelling schemes provided classification results reported database songs evenly distributed genres 
keywords musical genres content analysis indexing machine learning features extraction 
musical genres main top level descriptors music dealers librarians organize music collections 
may represent simplification artist musical discourse great interest summaries shared characteristics music pieces 
electronic music distribution emd music catalogues tend huge context associating genre musical piece crucial help users finding looking 
fact amount permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
queen mary university london signal processing institute lts cole polytechnique rale de lausanne epfl lausanne ch switzerland giorgio epfl ch digital music data urges new means automatic annotation manual labeling timeconsuming 
time terms jazz rock pop widely remain poorly defined concepts problem automatic genre classification non trivial task 
assume genre taxonomy focus ways uniquely automatically associate song genre 
specifically improve results far reported literature special attention paid different approaches model inner temporal structure music approaches described compared impact classification results evaluated 
sense analyzes different machinelearning algorithms encode explicitly relationships successive audio chunks 
relationships represent attempt identify temporal structural patterns inside music excerpts patterns hidden appearing surface set clear rules emerge music machine training processes allow obtaining robust results general non constrained data base 
organized follows section briefly review state art genre classification 
section describe extraction features characterizing audio signal 
section classification schemes evaluated section devoted discussion results obtained database songs evenly distributed genres 
section reach 
related unsupervised clustering music collections similarity measures gaining interest music information retrieval community see works related classification music titles genres supervised techniques 
methods suppose taxonomy genres try map database songs machine learning algorithms 
compared hidden markov model new classification architecture etm nn explicit time modelling neural networks classification experiment involving songs distributed genres 
tzanetakis cook li worked database songs genres compared different audio features timbral features rhythmic features pitch features wavelet features different classifier support vector machines gaussian mixtures linear discriminant analysis nearest neighbours time independent chunks 
lerch proposed hierarchical classification scheme evaluated database songs classes including speech classes background noise west cox maximal classification binary tree linear discriminant analysis classify set songs genres 
dixon extracted main pattern song classify features derived pattern tempo plus timbral features 
evaluate system database files standard latin dance music 
feature extraction step analysis systems consists extracting features audio data manipulate meaningful information reduce processing classification task 
focus classification strategies account far possible time structure musical piece 
consequently select fixed set low level features characterize analyzed audio signals allow direct comparison classification schemes 
clear particular features discriminative trying isolate particular genre 
matter fact feature selection techniques systematically trying build robust classifier 
segmentation analysis frames audio content experiments sampled hz converted mono signal 
resulting signal analyzed sliding windows ms overlapped 
analysis frame multiplied hamming window zero padded power 
timbre features mel frequency cepstral coefficients mfcc computed analysis frames 
analysis frame parameterized mfccs 
mfccs proved successful speech recognition applications widely music genre classification 
choice case try select features characterizing optimally genre 
rhythmic features klapuri introduce beat measure bars tempo tracker audio signals 
induces tempo called periodicity function summarizes strength different periodicities region pulse sensation 
simple statistical descriptors including mean standard deviation skewness kurtosis maximum periodicity function computed periodicity function describe shape characterizes strength different periodicities relations 
texture window timbre rhythmic features may computed analysis frame rate ms 
information contained time scale sufficient variations occur 
solution average features frame rate texture windows greater portions signal considered 
experiments compare types window vector seconds vector second musical modelling vector centred beat averaging frames local beat period beats beat rate extracted system proposed 
mean standard deviation skewness mean absolute value timbre feature computed size considered window 
periodicity function averaged considered window mean standard deviation skewness maximum evaluated 
vector features characterizes texture window 
classification schemes audio signals parameterized terms feature vectors genre classification problem reduced typical pattern classification task 
goal associate audio signal class priori defined set supervised approach 
reviewed papers literature genre classification obtained statically analysing excerpt feature vector subdividing excerpt chunks considered time uncorrelated 
similar problems speech recognition natural language analysis temporal relationships phoneme word provide important hooks improve recognition obtain robust results 
moving similar approach special attention paid ways represent temporal progression contextual information classification process 
classification schemes evaluated purpose mind support vector machine svm support vector machines delayed inputs recurrent neural network elman network explicit time modelling neural network etm nn hidden markov model hmm 
support vector machines underlying idea svm classification project data high dimensional space easier separate classes 
simple linear nant function maximizes margin classes high dimension space 
svms proved efficient classification tasks able handle temporal sequences 
matter fact classify statically vector class 
solution consider temporal evolution musical signals consider texture windows shifted time 
features associated texture window classified independently majority vote decide class complete excerpt done literature 
svm classifiers radial basis kernels built 
multi class classification achieved error correcting codes 
classifier trained seconds windows referred svm 
trained second windows svm windows centred beats length beat rate svm beats 
feature vector associated window classified independently final decision song taken represented class song 
svm stands case single feature vector complete song working excerpts seconds 
support vector machines delayed inputs said svms neural networks number machine learning algorithms process static patterns 
solution handle temporal sequences build spatial representation input classifier 
tapped delay line classifier sequence feature vectors 
notice scheme suffers number weaknesses 
delay large contain significant sequence implies number parameters classifier larger large number examples needed training 

classifier invariant time shifting large number examples needed output class position delay line 

classifier sensitive time variation requires delays precisely match input time intervals may corrected having feature vectors synchronized beats musical signal 
experiments conducted delay line feature vectors pattern svm concatenation feature vectors corresponding adjacent texture windows 
denote svm delay svm trained feature vectors corresponding second texture windows svm delay beats svm texture windows corresponding beats length equal beat rate 
recurrent neural networks widely artificial neural network multi layer perceptron 
neural networks suffer weakness svms process static patterns svms proved suited classification tasks neural networks 
neural networks may manner previously svms texture windows delayed inputs 
alternative recurrent partially recurrent network layers network output connected input 
specifically evaluate performance elman network typically network feedback layer output layer input 
feedback connections allow close past account classifying new feature vector 
fully connected networks neurons 
cases considered elm refers elman network fed vectors corresponding second windows elm beats refers elman network vectors corresponding windows centred beats length equal beat rate 
final decision complete song obtained integrating time output selecting maximal integrated output correct class 
explicit time modelling neural networks introduced context recognition music genres original method explicit time modelling temporal structure music 
new architecture referred etm nn explicit time modelling neural networks 
architecture multi layer perceptron trained recognize input feature vectors seconds long 
main idea hidden layer perceptron output supposed give genre 
matter fact known half feed forward network performs specific nonlinear transformation input data space discrimination simpler 
activation hidden neurons corresponds compact representation input feature vector 
hidden neuron understood musical event necessarily related actual musical meaning 
event ei occurs hidden unit highest activation hidden units 
sequence events time analysed build single feature 
specifically number events ei unigram number pairs ei ej bigram number triplets ei ej ek trigram evaluated event durations mean maximum variance event activations 
features normalized length sequence combined single vector neural network implements final decision genre musical piece 
consider cases evaluation events second windows beats evaluation events beat 
considered neural networks single hidden layer number neurons equal number genres considered 
hidden markov models hidden markov models extensively speech recognition capacity handle time series data 
hmms may understood doubly embedded stochastic process process observable hidden observed stochastic process observable produces time set observations 
hmm defined number states transition probability states initial state distribution observation symbol probability distribution 
hmm trained musical genre mixtures gaussians model state probability densities 
hmm states ergodic transition model 
topologies briefly explored additional needed find best topology depending genre 
consider cases hmm sequence second windows hmm beats sequence windows centred beats 
experimental results experimentations run compare performances main classification schemes type bag frames 
dataset dataset contain songs genres songs genre 
song seconds initial seconds 
genres blues classical jazz soul rap rock 
songs assigned genre label guide 
experiment setup reported results obtained cross validation 
classification scheme experiments run times time characterized different random split database training data testing data 
reported results give average runs 
results table shows accuracy different classification schemes 
recognition rates percentage genres complete set best result classifiers specific genres bold 
comparison remembered accuracy random guess dataset 
www com human performance genre classification studied college students able classify songs correctly cases listening seconds songs database chance give 
result understood upper boundary automatic classification accuracy expected accuracy 
analysis different classifiers svm delayed inputs texture windows synchronised beats gives best results correct classification 
methods show significantly better results specific genres 
matter fact likewise features suitable classifying set classification schemes may suited particular genre 
discuss depth pros cons classification scheme 
results svms support vector machines known give excellent results classification tasks including musical genre classification svms successfully 
interesting notice experiments size texture window influences results 
case jazz soul better results obtained considering window frames smaller chunks data 
may understood case smaller chunks may locally misclassified samples genres jazz soul funk 
beat synchronised texture windows improves results rock svms 
may explained course fact beats extracted perfectly 
reason faster detected tempo smaller texture window 
may harmful tzanetakis cook report window small classification accuracy drops 
results svms delayed inputs svms delayed inputs give best classification results 
inherent weaknesses architecture see section probably overcome large amount data experiments songs genre 
fact svms delayed inputs beat simple svms genre classification task interesting result confirms importance time structure musical genre understanding 
svms delayed inputs encode simple non explicit representation time structure considering adjacent texture windows delay windows unigrams bigrams trigrams encoded 
training time model considerably larger training svm single texture windows 
blues classical jazz soul rap rock genres svm svm svm beats svm delay svm delay beats elm elm beats beats hmm hmm beats table 
recognition rate different genres classifiers results elman networks elman networks give worst results 
modelling time structure may simple comparable modelling networks delayed inputs 
texture window classified feature vector plus feedback previous state hidden units network 
recurrence hidden units decreased multiplicative constant determines memory depth network 
network models local structure account adjacent windows decaying integration factor similar case networks delayed inputs considering time integration factor memory depth fixed size delay 
words neural networks delayed inputs may compared finite impulse response filters recurrent networks may compared infinite impulse response filters architectures able model problems long parameters properly estimated 
recurrent networks may efficient networks svms delayed inputs 
general weakness systems feedback loops tendency instable applies recurrent networks 
matter fact possible instability problems elman networks particularly tricky train properly 
experiments elman networks certain classes weak classes average noticeable results 
results results obtained little disappointing compared reported reports architecture significantly outperforms hmms occur case 
fact implementation differs slightly initially proposed feature vectors previous experiments vectors dimension uses vectors composed concatenation cepstral coefficients adjacent frames ms vectors dimension 
case results terms hmm performances difficult compare reported database songs genres rock pop techno classical database songs genres 
case architecture different hmm architecture 
matter fact network selecting event terminology event correspond hmm state notice way neural networks model probability densities hmm states 
events unigrams bigrams correspond connections states standard hmm 
model trigrams consider second order relations states hmm usually case hmms hmms settings called order markovian assumption supposed probability state depends solely previous state 
results hmms hmms suited model time sequences experimented model 
outperformed svms performance 
matter fact number hypotheses possible optimize models limit generality root weaknesses 
hmms low discriminative power usually trained maximum likelihood criterion optimal maximum aposteriori criterion 
words training likelihood model genre produce observation maximised likelihood models minimized 
number alternative solutions training hmms proposed ensure better discrimination power 
experiments modelled emission probability different states mixtures gaussians 
implies strong assumption distribution emission probability 
assumption may relaxed modelling emission probabilities neural networks see 
compared different methods lowlevel short term time relationships account classify audio excerpts musical genres 
svms delayed inputs proved give best results simple modelling time structures 
claim svms perform better classifiers multi layer perceptrons linear discriminant analysis main outcome simple model context synchronisation musical rhythm improves musical genre classification results cases 
reported results may greatly improved considering hierarchical classification techniques model underlying genre taxonomy 
feature selection node hierarchy allow optimization classification task specific set genres 
classification algorithms suitable particular genres consider different classifiers node hierarchy multiple classifiers combining results architectures mixture experts 
rauber pampalk merkl psycho acoustic models self organizing maps create hierarchical structuring music sound similarity proc 
rd int 
conf 
music information retrieval ismir paris france 
shao xu 
kankanhalli unsupervised classification musical genre hidden markov model ieee int 
conf 
multimedia explore icme taiwan china 
schultz waibel recognition music types proc 
ieee int 
conf 
acoustics speech signal processing icassp seattle usa 
tzanetakis cook musical genre classification audio signals ieee transactions speech audio processing vol 
july 
li ogihara li comparative study content music genre classification proc 
th annual int 
acm sigir conf 
research development information retrieval toronto canada 
lerch hierarchical approach automatic musical genre classification proc 
th int 
conf 
digital audio effects dafx london uk 
west cox features classifiers automatic classification musical audio signals proc 
th int 
conf 
music information retrieval ismir barcelona spain 
dixon gouyon widmer characterization music rhythmic patterns proc 
th int 
conf 
music information retrieval ismir barcelona spain 
klapuri astola analysis meter acoustic musical signals ieee trans 
speech audio proc 
burges tutorial support vector machines pattern recognition data mining knowledge discovery 
huang weng lin generalized bradley terry model group competition individual skill th int 
conf 
neural information processing systems 
elman finding structure time cognitive science vol 
pp 

rabiner tutorial hidden markov models selected applications speech recognition proc 
ieee 
scanning dial exploration factors identification musical style proc 
society music perception cognition evanston il usa 
lee juang new discriminative training algorithms generalized probabilistic descent method ieee proc 
workshop neural networks signal processing pp 

morgan bourlard continuous speech recognition hybrid hmm connectionist approach ieee signal processing magazine vol 
pp 


