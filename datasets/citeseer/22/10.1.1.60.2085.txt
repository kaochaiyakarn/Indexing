bayesian multinomial logistic regression author identification david madigan alexander david lewis dimacs rutgers university department statistics rutgers university david lewis consulting department computer science rutgers university 
motivated high dimensional applications authorship describe bayesian multinomial logistic regression model associated learning algorithm 
keywords multinomial logistic regression logistic regression bayesian estimation classification author identification stylometry pacs sk rr kf feature rich authorship attribution requires multiclass classification learning method scaleable implementation 
popular methods multiclass classification machine learning research variants support vector machines boosting combined error correcting code approaches 
rifkin provide review 
focus multinomial generalizations logistic regression 
important advantage approach outputs estimate probability object documents application belongs possible classes 
bayesian perspective training multinomial logistic regression model allows combine training data prior domain knowledge 
multinomial logistic regression xj xd vector feature values characterizing document identified 
encode fact document belongs class author dimensional valued vector yk yk coordinates 
multinomial logistic regression conditional probability model form yk exp exp parameterized matrix 
column parameter vector corresponding classes kd direct generalization binary logistic regression multiclass case 
classification new observation vector conditional probability estimates produced model 
simply assign class highest conditional probability estimate argmax yk 
consider set training examples xi yi xn yn 
maximum likelihood estimation parameters equivalent minimizing negated log likelihood xi ln exp xi probabilities sum yk vectors set affecting generality model 
statistical model avoid overfitting training data multinomial logistic regression model accurate predictions unseen data 
bayesian approach prior distribution assigns high probability entries values near 
describe priors 
widely bayesian approach logistic regression model impose univariate gaussian prior mean variance parameter exp 
small values represents prior belief close zero 
assume priori components independent prior product priors components 
finding maximum posteriori map estimate prior equivalent ridge regression multinomial logistic model 
map estimate minimizing 
ridge logistic regression widely text categorization see example :10.1.1.20.5553
gaussian prior favoring values near favor exactly equal 
multinomial logistic regression models author identification easily millions parameters dense parameter estimates lead inefficient classifiers 
sparse parameter estimates achieved bayesian framework remarkably easily double exponential laplace prior distribution exp 
prior product priors components 
typical data sets choices parameters map estimate zero 
map estimate minimizes 
tibshirani suggest laplace priors regression context 
subsequently constraints penalties absolute values coefficients achieve sparseness variety data fitting tasks see example including multinomial logistic regression 
algorithmic approaches multinomial logistic regression largest scale studies occurred computational linguistics maximum entropy approach language processing leads multinomial logistic regression models 
malouf studied parsing text chunking sentence extraction problems large numbers classes sparse inputs features 
largest problem limited memory quasi newton method times faster second best method polak positive version conjugate gradient 
sha pereira studied large noun phrase chunking problem classes features limited memory bfgs pairs previous gradients updates saved preconditioned conjugate gradient performed similarly better iterative scaling plain conjugate gradient 
gaussian penalty loglikelihood 
goodman studied large language modeling grammar checking collaborative filtering problems exponential prior 
claimed find consistent advantage conjugate gradient iterative scaling experimental details 
krishnapuram carin figueiredo experimented small dense classification problems irvine archive multinomial logistic regression penalty equivalent laplace prior 
claimed cyclic coordinate descent method beat conjugate gradient orders magnitude provided quantitative data 
base cyclic coordinate descent algorithm binary ridge logistic regression zhang oles 
previous modified algorithm binary lasso logistic regression fast easy implement 
similar algorithm developed keerthi 
coordinate decent algorithm modify binary logistic algorithm apply ridge lasso multinomial logistic regression 
note objectives convex smooth derivative ll need take special care 
initialize convergence compute tentative step vk min max vk reduce step interval step max update interval 
generic coordinate decent algorithm fitting bayesian multinomial logistic regression 
idea smooth case construct upper bound second derivative objective interval current value objective convex give rise quadratic upper bound objective interval 
minimizing bound interval gives step algorithm guaranteed decrease objective 
upper bound second partial derivative negated loglikelihood respect neighborhood current value 
implementation upper bound inference straightforward formula omitted lack space 
upper bound ridge objective quadratic function minimum function located vk replacing vk 
vk guaranteed reduce objective vk falls inside trust region 
step size direction reduce objective 
algorithm general form 
solution ridge regression formulation compute tentative step step algorithm 
size approximating interval critical speed convergence small intervals limit size step having large intervals result loose bounds 
update width trust region step algorithm suggested 
lasso case slightly complicated objective differentiable 
long compute vk js sign 
vk tentative step size case reduce step size new outside trust region different sign 
sign change set 
case starting value handled specially 
compute positive negative steps separately right hand left hand derivatives see gives decrease objective 
due convexity decrease occur direction 
decrease direction stays 
presents algorithm computing vk step algorithm lasso regression case 
software implementing algorithm publicly available scales classes features observations 
compute vk formula vk trying cross vk endif endif compute vk formula vk trying cross vk endif endif 
algorithm computing tentative step lasso multinomial logistic regression replacement step algorithm fig 

strategies choosing upper bound similar coordinate descent algorithm fitting lasso multinomial logistic regression models krishnapuram carin figueiredo www stat rutgers edu madigan bmr 
bound hessian negated loglikelihood dk dk hessian matrix identity matrix vector dimension kronecker matrix product matrix inequality means negative semi definite 
coordinate descent algorithm care diagonal elements hessian 
bound implies bound diagonal elements 
tentative updates ridge lasso case obtained substituting righthand side 
note really depend beta lasso update cause change sign reduced 
contrast bound jk jk need recomputed changes trust region needed 
downside looser bound jk jk 
experiments author identification data sets data set draws rcv text categorization test collection data released reuters selected authors stories collection 
collection contained authors wrote stories total 
split data randomly training documents test documents sets 
data sets research produced archives discussion groups diverse topics 
different groups included postings authors 
group split randomly postings training test 
representations data sets listed 
feature set sizes ranged features 
forms postprocessing indicated name representation tokens appearing list common names discarded processing 
www ai mit edu projects jmlr papers volume lewis rcv readme htm reuters com corpus characters word 
characters word 
pos portion word concatenated part speech tag 
consecutive sequences part speech tags 
bow word portion bow bag words 
special subsets defined bow 
set function words previous author identification study 
set set words automatically extracted web page common errors english usage large set stylometric characteristics text authorship attribution literature gathered 
includes features derived word character distributions frequencies function words listed 
results bayesian multinomial logistic regression laplace prior build classifiers data sets different representations 
performance classifiers test sets 
see error rates vary widely data sets representations lines correspond representations crossings 
order representations error rate produced model data set order stable different data sets 
instance representation words bag words denoted bow chart results lowest error rate pairs consecutive part speech tags chart produces highest error rates 
crossings representation lines near right column reflects rcv hinting data set essentially different groups 
rcv stories produced professional writers corporate environment postings discussion groups written people uncontrolled environment topic interest 


multinomial logistic regression algorithm 
annals institute statistical mathematics 


analysing mail text authorship forensic purposes 
master information technology research thesis 

efron hastie johnstone tibshirani 
angle regression 
ann 
statist 
www edu errors errors html 
test set error rates different data sets different representations 

figueiredo 
adaptive sparseness supervised learning 
ieee transactions pattern analysis machine intelligence 

lewis madigan 
large scale bayesian logistic regression text categorization 

girosi 
sparse approximation support vector machines 
neural computation 

goodman 
exponential priors maximum entropy models 
proceedings human language technology conference north american chapter association computational linguistics hlt naacl pages 

argamon 
automatically categorizing written texts author gender 
literary linguistic computing 

krishnapuram carin figueiredo 
sparse multinomial logistic regression fast algorithms generalized bounds 
ieee trans 
pattern anal 
mach 
intell 

li yang 
loss function analysis classification methods text categorization 
international conference machine learning icml pages 

malouf 
comparison algorithms maximum entropy parameter estimation 
proceedings sixth conference natural language learning conll pages 

rifkin 
defense vs classification 
journal machine learning research 

sha pereira 
shallow parsing conditional random fields 

keerthi 
simple efficient algorithm gene selection sparse logistic regression 
bioinformatics 

tibshirani 
regression shrinkage selection lasso 
journal royal statistical society series 

tipping 
sparse bayesian learning relevance vector machine 
journal machine learning research june 

zhang yang 
robustness regularized linear classification methods text categorization 
proceedings sigir sixth annual international acm sigir conference research development information retrieval pages 

zhang oles 
text categorization regularized linear classifiers 
information retrieval april 
