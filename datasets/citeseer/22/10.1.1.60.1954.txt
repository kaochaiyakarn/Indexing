generative modeling continuous non linearly embedded visual inference cristian sminchisescu cs toronto edu allan jepson jepson cs toronto edu university toronto department computer science king college road toronto ontario canada difficult visual perception problems human motion estimation formulated terms inference complex generative models defined high dimensional state spaces 
despite progress optimizing models difficult prior knowledge flexibly integrated order reshape initially designed representation space 
nonlinearities inherent sparsity high dimensional training sets lack global continuity dimensionality reduction challenging lowdimensional search inefficient 
address problems learning inference algorithm restricts visual tracking automatically extracted non linearly embedded lowdimensional spaces 
formulation produces layered generative model reduced state representation estimated efficient continuous optimization methods 
prior flattening method allows simple analytic treatment low dimensional intrinsic curvature constraints allows consistent interpolation operations 
analyze reduced manifolds human interaction activities demonstrate algorithm learns continuous generative models useful tracking reconstruction human motion monocular video 

successful visual tracking approaches high dimensional physically inspired non linear generative models shape intensity motion 
usually hard construct models offer intuitive representations counterpoint coherence image clutter offer analytical advantage global coordinate system continuous optimization sampling 
despite progress inference frameworks re appearing proceedings international conference machine learning banff canada 
copyright authors 
mains difficult due lack learning representation adaption initial design choice 
inflexibility leads high dimensional ill conditioned state spaces lack representational power restricts model usage oversimplified scenarios 
priors original state space may alleviate problem conserving continuous representations state space dimension search complexity remains unchanged 
approach forms non linear dimensionality reduction lose global nature representation continuity generative mapping efficient optimization possible 
propose algorithm learns reduced generative models global continuous consistent inference 
properties motivated follows learning non linear low dimensional global models requires dimensionality reduction method recovers manifolds having intrinsic curvature holes 
arise practical modeling settings physical constraints articulated occlusion 
preserve local manifold geometry low dimensional representation extracted laplacian eigenmaps methods similar properties apply :10.1.1.19.9400:10.1.1.111.3313
estimating intrinsic dimensionality model hausdorff dimension demonstrated 
ii continuous generative model 
continuous optimization low dimensional space requires reduced global coordinate system globally continuous generative mapping 
assuming original highdimensional model continuous obtained reducing dimensionality 
estimate smooth mapping learned original model state space kernel regression 
smoothness allows efficient continuous methods high dimensional optimization 
aim dimensionality reduction complex processes reduced representations large dimensionality 
iii consistent estimates require prior probable regions low dimensional manifold pre typical training data density separating holes produced insufficient sampling genuine intrinsic space curvature 
inherent sparsity high dimensional training sets disambiguation difficult 
analysis training data distribution usually requires restrictive sampling assumptions 
propose analytic solution combines smoothing gaussian mixture prior flattening method 
exploits layered structure learned generative model order push sharp curvature constrains low dimensional space 
iv geodesics interpolation obtain complete lowdimensional generative model analysis synthesis interpolation necessary 
geodesic cost function computation 
related important involving tracking constrained generative models aware algorithms allow continuous optimization learned non linear manifold 
bregler track lip contours highdimensional gaussian mixture prior gmm learned training data gradient descent 
optimize original high dimensional space regularize estimates gmm projection 
toyama blake track exemplars gmm index euclidean similarities discrete method set local coordinate system charts 
globally post coordinating local mixture representation manifold applicable continuous optimization coordinates uniquely defined considered training set 
coordinates new configurations sampled optimization may unique 
wang isometric embeddings restrict variations highdimensional shape coordinate sets low dimensions case compute local non parametric necessarily continuous mappings intrinsic embedding spaces 

learning non linearly embedded continuous generative model consider generative model fig 
representing smooth non linear transformations reproduce variability strong correlations encountered observation domain model defined original state space subject additional parameters prior example consider possible articulated generative human modeling rotational state parameters skeleton articulations various internal body shape surface color parameters transformations construct body limbs position skeletal kinematic chains project common difficulty intuitive physically inspired generative models usually general high dimensional state spaces difficult estimate prior knowledge flexibly model state inference 
additional difficulty vision problems caused nonlinearity non convexity original representation space 
may produced physical domain constraints model 
learn consistent reduced model laplacian eigenmaps non linear embedding method principle reconstruct low dimensional manifolds having intrinsic curvature methods :10.1.1.19.9400:10.1.1.111.3313
algorithms recover embeddings minimally distort local geometry typical distribution geometry approximated training set resulting embedded set coordinates reduced manifold convex alternative embeddings preserve global geometry apply 
advantage spectral embeddings generalization :10.1.1.19.9400
continuous embedded generative model fig 
obtained learning parameters global smooth mapping ing prior embedded manifold fig 

consistent inference prior reflect data density training set intrinsic curvature induced existing priors layers generative model 
details sections 
construct 
globally smooth generative mappings construction learned generative model requires estimation forward mapping embedded embedding spaces points training set column wise matrix corresponding points stored embedded space stored matrix 
consider row operator extracts th row matrix corresponding column operator 
employ sparse kernel regressor estimate mappings sparsity generalization important efficient low dimensional generative models 
con sider representatives kernels points 
constraint vec resulting body image space physical priors penalize states implausible anatomical constraints limbs penetrating body 
gaussian kernels means diagonal covariances representatives subsample cross validate means obtained clustering 

left learned generative model allows continuous optimization low dimensional embedded space 
enclosing solid boxes label functions circles label variables 
embedded model state original model state inferred input observations data 
right prior flattening mechanism allows consistent optimization manifolds intrinsic curvature 
tors map dimension map dimension consequently kernel matrix size dimension training set 
parameter vector mapping derived pseudo inverse computed mappings differentiation generative mapping second order continuous optimization obtained chain rule derivation jacobian damped 
embedded layered generative priors consistent inference embedded space requires prior probable regions low dimensional manifold determined training data density 
mixture prior gaussian functions parameters obtained means clustering embedded training set 
sampling artifacts problem domain constraints may interact way difficult separate particular constraints may generate unfeasible regions having intrinsic curvature 
geometrically holes human kinematic representations joint angles intrinsic curvature produced limits articulations body non self intersection constraints 
exclude certain state variable combinations see 
domain models ana characterizations unfeasible regions may available directly separating sampling artifacts experimented sparse lasso cost indi vidual components constraint full dimensional tests comparable subset selection having kernel set dimensions crossvalidation loop 
tends predictable requires iterative optimization expensive sampling kernel subsets 
select larger number models 
mixture centers line estimation roadmap initializing geodesic calculations 
curvature nearly impossible general sampling assumptions 
reason assume training data available sampled uniformly densely unknown prior simply blind effects smooths 
fact may assign unfeasible regions moderately high probability especially surrounded densely sampled zones 
learned model layered sharper curvature constraints may induced embedded space existing priors original representation space may available simple analytic form 
layered continuous generative model exploit modular structure forward transformation chain 
evaluation differentiation respect state variables main computational machinery model analytic forms intermediate function values derivatives generative transformation chain available 
layer embedded embedding model slice pri respectively combine dis probable regions flattened priors embedding space see fig 

notice resulting prior normalized requires state dependent jacobian scaling factor 
analytically differentiating possible parametric form mapping 
mechanism allows consistent inference embedded space see 
priors subsequent layers discarded absorbed 
geodesics interpolation construction geodesics framed optimal inference synthesize trajectory smooth consistent prior manifold sume trajectory endpoints discretization knots en ergy function geodesics written order dif ference operator square matrix dimension con band diagonal blocks dimensional iden matrices priors encoding higher degree smoothness obtained self multiplication second order function differentiable sampled optimized local map solution trivial initialization points uniformly distributed straight line 
avoid unrepresentative local optima initialize floyd dynamic programming algorithm dp 
run line find shortest paths set mixture centers obtained clustering see 
roadmap effectively geodesic query time known endpoints link closest mixture component precomputed road see fig 
oriented bounded box decomposition nearest neighbor queries 
dp trajectory refined consistent geodesic function 
temporal inference apply bayes rule compute static total probability learned manifold space data observation prior model state space observation likelihood computed terms probability observation predicted generative model feature configuration see fig 

tracking dynamic observations prior time combines previous posterior dynamics collected observations time vector defined posterior gether form time prior static bayes equation 
approximate propagating density covariance scaled sampling css 
probabilistic method represents posterior distribution hypotheses state space gaussian mixture weights centers covariances obtained follows 
random samples generated temporal prior opti mized nonlinear local optimization respecting prior constraints maximize local posterior likelihood encoded optimized likelihood value position gives weight center new component inverse hessian log likelihood gives scale matrix adapted contours cost function ill conditioned problems monocular human tracking 
likelihood temporal prior distributions composed pruned maximum number mixture components order produce posterior current timestep see details 
encode simple dynamic rules prior order ensure dynamics remains inside feasible manifold region 
prior manifold 
human representation learning visual tracking representation learning physically inspired body model consists kinematic skeleton articulated joints controlled angular joint variables covered flesh built superquadric ellipsoids deformations 
model internal proportions shape surface color parameters state space consists joint angle variables shoulder elbow hip knee joints global rigid motion variables encoded state learn low dimensional representation training vector slices include rigid components manifold embedding set body joint angle training data obtained motion capture system courtesy motion capture database cmu graphics laboratory 
es mixture model means clustering embedded eigenvectors build prior learn parameters forward mapping original joint angle space gaussian kernel regression 
model superquadric surfaces discretized meshes mesh nodes colors updated tracked image texture mapping mapped points knowledge kinematic state variables predicted configuration map body kinematic chain predict image positions pixel colors perspective image projection transformations encoded 
observa tion model sums predicted image matching likelihoods gradient hessian metrics evaluated model feature prediction image features robust combination intensity alignment metrics silhouettes normalized edge distances 
flattened embedded priors consist soft joint angle limits body non self intersection constraints 
experiments negative log likelihood energy function prior normalized scaled 
temporal state inference tracking css explained 

experiments experiments show include image visual tracking human activities monocular video 
underlines importance prior knowledge global rigid state representation learned embedding people move directions seen viewpoint restrictive learn preferential subspaces global translation rotation 
implies slice variables part inferred state mapped simply technicality avoided making explicit notational simplicity 
practice inference augmented hidden state embedded coordinate global rigid motion need add trivial identity component map motion subsets body limbs unobserved long periods tracked subject sideways facing camera 
information unobserved variables indirectly observed ones constrains probability distribution 
learning global non linear low dimensional representation produces model couples state variables 
derive models various training datasets including walking running human interaction gestures conversations 
analysis walking manifold involves corpus frames coming subjects contains significant variability 
fig 
shows walking data analysis various structures necessary optimization 
fig 
left gives estimates data intrinsic dimensionality hausdorff dimension radius sphere centered point number points neighborhood plot averaged nearby points 
slope curve linear domain roughly hypothesis 
fig 
plots embedding distortion computed normalized euclidean sse neighborhood training set graph 
notice stability different neighborhood sizes contrast larger distortion variate training sets fig 

fig 
fig 
show embeddings 
representation flexible allows variability 
results correspond spherical neighborhood sizes gaussian standard de figures show embedded manifold defined gmm prior corresponds shape similarities position velocity plot harmonic oscillator 
fig 
shows spatial decomposition data oriented bounding boxes obb 
fast nearest neighbor queries geodesic calculations 
embedded generative model tracking forward mapping kernels 
stdev 
notice image tracking walking video subject moving cluttered background monocular sequence fig 

state model consisting embedded coordinate walking dataset rigid motion 
track css hypotheses 
aside clutter sequence difficult due self occlusion left side body 
occasionally state variables associated invisible limbs close singular 
singularity artificially resolved stabilization priors serious problem prior knowledge related state variables making recovery failure extremely 
notice elimination timescale dependence classical dynamic predictive models 
manifold traversed speed driven image evidence opposed prespecified 
embedded vs original model comparison walking fig 
frames left test motion capture data synthesized articulated model 
select joint positions shoulders hips elbows perturb cm spherical noise simulate modeling errors project virtual monocular camera image plane pixels 
input data define ssd reprojection error gaussian likelihood body joints 
track hypotheses original model having joint angle limit body non self intersection priors embedded walking model 
left middle figures show average pixel reprojection error joint fig 
gives average joint angle error respect ground truth embedded model plot estimated ans average range uncertainty kernel sor 
models maintain track original overfits data leading low tion errors larger variance joint angle estimates 
caused tracks follow equivalent class monocular reflective neighboring minima ground truth clearly noticeable sequence 
region frames corresponds moments model puppet situated sideways straight stand positions respect camera ray sight 
accuracy original model improves period depth ambiguities eliminated due physical constraints 
embedded model biased walking larger reprojection error significantly smaller variance having error uniformly distributed joint angles 
average error fig 
maximum error tracking left hip joint angle 
original model tends large localized errors caused reflective ambiguities particular limbs 
average error fig 
maximum error right shoulder joint angle 
limited computational resources limited walking task learned embedded model clearly accurate 
analysis running walking human interaction manifold illustrated fig 
show point training set consisting samples drawn activity set consisting walks runs conversations 
left plots fig 
show projections neighborhood graphs embeddings leading laplacian eigenvectors 
note submanifolds activities mix pathways probable qualitatively checked connected component analysis training set graph 
circular structures related periodic walks runs observable embeddings clearly visible ones 
plot fig 
confirms embedded neighborhood distortion decreases monotonically increasing dimension 
practice stability optimization embedded space satisfactory data hypothesis hypothesis hypothesis distance distortion dimension 
analysis walking data 
estimates intrinsic dimensionality hausdorff dimension 
plots average local geometric embedding distortion vs neighborhood size notice stability 
figures show embeddings large walking data set manifold mixture prior 
shows spatial decomposition data nearestneighbor queries geodesic calculations see text 

tracking monocular video sequence walking subject optimization mixed state space consisting embedded coordinate walking data rigid motion 
way search complexity significantly reduced tolerate missing observations occluded limb monocular side view 
average joint reprojection error original model frame average joint reprojection error embedded model frame average joint angle error embedded model original model 
embedded vs original model comparison walking 
show average joint reprojection error pixels 
plots joint angle angle error vs ground truth radians average uncertainty range map 
original model overfits data low reprojection errors larger variance estimates 
embedded model higher bias larger reprojection error superior accuracy 
original model right shoulder joints 
embedded left hip joints 
ruling low dimensional models 
performance optimizer latent space structure accuracy map ping constrained topology low dimensional spaces collapses data em runs walks nearly overlapping cycles shown leads estimation instability 
fig 
show accuracy mapping kernels embedded data fig 
original training set 
tracking human activities exemplified fig 
analyze video model consisting frame average error maximum error average error maximum rigid state embedded coordinate obtained element training set consisting walking running human interaction samples 
mapping kernels 
fig 
shows snap shots original sequence image tracking monocular reconstructions probable configurations rendered synthetic scene viewpoint 
algorithm tracks reconstructs motion accuracy hypotheses 
missing data resulting frequent occlusion limbs monocular tracking quasi global cost sensitive search optima enumeration methods difficult prior knowledge distance distortion dimension reconstruction error joint angle forward map accuracy kernel regression sample index 
analysis sample dataset consisting mixed walking running conversation samples best viewed color light red green blue local graph neighborhood connections originate points set respectively 
left show projections embeddings respectively 
shows neighborhood distortion plot dimension range plots average joint angle accuracy map radians maximum see text 
image limb detector 
hand presence multiple activities complex scenarios human interaction demands flexible learned representation dedicated dynamic predictors walking running difficult apply 
fig 
show various components failure modes 
fig 
shows behavior system run flattened embedded priors physical constraints 
useful notice unfeasible configurations right hand inside back right upper arm inside torso 
effects missing training data tracking behavior explored fig 
embedded model computed conversation training data track sequence 
model tracks part sequence conversation eventually looses lock arms gestures deviate significantly training set 

learning inference framework reduces visual tracking low dimensional spaces computed non linear embedding 
existing approaches optimization learned constrained generative representations locally valid models easily exploit convenience lowdimensional modeling efficient continuous search 
may operate discretely hybrid non convergent regimes 
address difficulties introduce layered generative model having learned embedded representation estimated efficient continuous optimization methods 
analyze structure reduced manifold representations variety human walking running conversational activities demonstrate algorithm providing quantitative qualitative results human tracking motion reconstruction learned low dimensional models monocular video 
ongoing explore construction flexible dynamic predictors tracking low dimensional shape representations activity recognition 
acknowledgments special kutulakos nigel morris generous help video capture 
cmu human motion capture database 
available online cs cmu edu search html 
belkin niyogi :10.1.1.19.9400
laplacian eigenmaps spectral techniques embedding clustering 
nips 
bengio vincent 
sample extensions lle isomap mds eigenmaps spectral clustering 
nips 
bregler omohundro 
non linear manifold learning visual speech 
iccv 
choo fleet 
people tracking hybrid monte carlo filtering 
iccv 
deutscher blake reid 
articulated body motion capture annealed particle filtering 
cvpr 
donoho grimes 
hessian eigenmaps locally linear embedding techniques high dimensional data 
proc 
nat 
acad 
arts sciences 
donoho grimes 
isomap recover natural parameterization families articulated images 
technical report dept statistics stanford university 
gottschalk lin manocha 
obbtree hierarchical structure rapid interference detection 
sig graph 
howe leventon freeman 
bayesian reconstruction human motion single camera video 
nips 
isard blake 
condensation conditional density propagation visual tracking 
ijcv 
ng jordan weiss 
spectral clustering analysis algorithm 
nips 
osborne 
lasso dual 
comput graphical statist 
roweis saul 
nonlinear dimensionality reduction locally linear embedding 
science 
sidenbladh black sigal 
implicit probabilistic models human motion synthesis tracking 
eccv 
silva tenenbaum 
global versus local methods nonlinear dimensionality reduction 
nips 
sminchisescu jepson 
variational mixture smoothing non linear dynamical systems 
cvpr washington 

tracking monocular video sequence mixed running walking conversational activities state space 
top row original sequence 
middle row probable model configuration wireframe projected image time step 
bottom row reconstructed poses rendered synthetic scene viewpoint 
clutter motion variation missing data resulting frequent self occlusion monocular tracking difficult motion tracking reconstruction accuracy 
prior knowledge occluded limbs reliably estimated 

exploring system component failure modes 
left shows unfeasible configurations right hand inside back right upper arm inside torso run flattened embedded priors physical constraints 
middle right show pairs image projection configurations tracking embedded model computed conversation data 
model tracks conversation eventually looses lock arms gestures deviate significantly training set 
sminchisescu triggs 
estimating articulated human motion covariance scaled sampling 

sminchisescu triggs 
kinematic jump processes monocular human tracking 
cvpr volume pages madison 
sminchisescu welling hinton 
mode hopping mcmc sampler 
technical report csrg university toronto submitted machine learning journal september 
teh roweis 
automatic alignment hidden representations 
nips 
tenenbaum silva langford 
global geometric nonlinear dimensionality reduction 
science 
tibshirani 
regression shrinkage selection lasso 
roy 
statist soc 
toyama blake 
probabilistic tracking metric space 
iccv 
wang xu ai 
learning object intrinsic structure robust visual tracking 
cvpr 
weinberger saul 
unsupervised learning image manifolds semidefinite programming 
cvpr 
