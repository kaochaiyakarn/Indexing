flexible update management peer peer database systems david del sang son department computer science university virginia dad son cs virginia edu promising combination flexible dynamic configuration high scalability built redundancy peer peer networks garnered tremendous interest years 
long potential sharing disparate databases fashion apparent 
explored data placement coordination difficulties involved systems effort database sharing reality 
far fewer examined unique challenges involved updating data items distributed numerous nodes 
addressing problem adapted version traditional quorum consensus approach better suited domain 
explore tradeoffs introduced flexible update scheme especially areas data freshness data availability access latency redundancy 
simulation results instance demonstrate possible achieve probability stale data access near zero data replication quorum levels sufficiently high 
cost high data confidence slower data access time nodes involved quorum building 
keeping theme flexibility philosophy leave control hands users individual peers allowing choose parameters performance tradeoffs meet unique needs 

notable french pilot poet author antoine de saint wrote perfection achieved add left take away spirit peer peer networks notable add lack case central server 
systems aim achieve completely decentralized network relying individual hosts communicate negotiate maintain connections store transfer data perform distributed computations 
peer peer architectures generated great deal interest late accompanied increased level activity shows signs 
justifiably skeptical individual ask enthusiasm 
benefits networks fairly straightforward fact direct consequences eliminating central server 
observe removing server means expensive setup maintenance needed typically crucial component 
nodes peer peer system heterogeneous different hardware platforms operating systems languages unreliable provided speak protocol 
big part systems dynamic configuration nodes join leave network time network nodes able seamlessly reconfigure fly 
assuming works intended peer peer systems remarkably low maintenance 
large number participating nodes networks achieve high level availability redundancy little extra effort 
important benefit peer peer architectures scalability 
traditional systems server capacity bottleneck 
spreading computation data storage message transfers nodes network system scale effectively resource demands network size grow 
improved redundancy scalability achieved setup configuration costs lower usual 
sounds true clearly ignoring major challenges addressed 
databases number applications suggested peer peer networks particularly intriguing area databases 
consider key concerns traditional distributed databases data availability redundancy concurrency 
happen fit pretty nicely benefits peer peer systems just discussed 
organizations large number largely disparate database systems valuable meaningfully linked 
instance retail database record history customer purchases transactions separate database track store inventory third containing important suppliers 
customer purchasing patterns influence desired inventory levels desired inventory levels affect product quantities requested suppliers sense link databases 
fact organizations just rigid way database basis 
peer peer database systems offer promise dynamic fly configuration addition flexibility regard adding removing data nodes 
unsurprisingly achieving goal simple flexible data resource sharing challenges alluded earlier 
chief obstacles effective databases problems data placement data coordination 
goal data placement defined gribble distribute data computation peers queries executed smallest possible cost terms response time bandwidth usage criteria :10.1.1.27.8638
data placement design choices tradeoffs include level shared global knowledge autonomy peers decisions dynamic network regard peer membership level data replication data granularity freshness consistency requirements 
data coordination problem involves managing data dependencies data semantics database peers 
challenge reconciling numerous individual data schemas associate semantically related data stored different names formats 
data updates described focuses updates peer peer database systems 
updating data multiple copies locations difficult studied somewhat traditional distributed database research 
extreme flexibility systems causes traditional approaches break 
database systems central location metadata stored updates synchronized 
networks highly dynamic nodes join leave anytime highly autonomous peers expect able change local data connected network 
asks question data updates handled predictably environment 
predictable mean peer making update request reasonably certain outcome update nodes reflect updated value long take 
key concern kind update consistency achieved peer peer environment 
don deal directly data placement configuration problems discussed 
assume reasonable primitive solutions problems employed 
adapt weighted voting quorum consensus update scheme peer peer architecture explore conditions consistency guaranteed absolutely probabilistically 
reviewing related database field section give overview traditional quorum consensus section move specifics update scheme section 
discuss flexible nature weighted voting strategy allows users trade variety factors including consistency availability query latency convenience 
presenting results performance simulations explore tradeoffs section ll touch challenges consideration section 

related relatively nascent field database research experienced rapid growth making strides addressing data placement coordination challenges mentioned 
step query locate relevant data network 
note true network just databases 
simplest lookup method broadcast node forwards requests nearest neighbors relevant data query reached maximum time limit 
variation scheme gnutella network 
due large number message transfers involved pure broadcast schemes tend scale poorly 
common modification add hierarchy network form super peers set reliable nodes manage greater number connections 
building data summaries hierarchies possible support efficient semantic level searching 
research distributed hash tables quickly locate data distribute evenly network 
merely locating data peer peer database systems seek possible dynamically establish communication links heterogeneous database systems see example data mapping 
particular bernstein propose local relational model lrm framework managing differences various local databases data contained meaningfully linked peer peer setting :10.1.1.17.2221
lrm introduces domain relations way map data items different databases coordination formulas specify semantic dependencies data 
mappings inherently local created benefit global schema 
kementsietsidis demonstrated algorithmic implementation dynamic mapping distinct relations established 
piazza system takes fairly similar approach hierarchical supporting arbitrary collection interconnected peer schema mappings 
order process query reformulated defined mappings defined entirely terms underlying data 
peerdb system gets inspiration information retrieval creates kind data keyword thesaurus store name mappings 
standard search techniques locate data relevant keyword query 
sample data mapping different schemas 
addressing data placement problem gribble propose hierarchical spheres cooperation :10.1.1.27.8638
nodes sphere share information arrive data placement decisions cooperatively 
spheres try consolidate queries adjust data placement sphere means optimization 
zhang pursue hierarchical approach data placement mapping hierarchical structured path names underlying flat data storage structure peers 
authors encounter tradeoff performance terms latency fair efficient resource distribution try strike balance 
research promising tends consider local databases peer peer network fairly static fails address possibility individual want update data stored local databases 
manage data updates heterogeneous databases different structures schemas access policies means straightforward 
ability change values updates managed predictable way crucially important realizing full power peer peer database system 
lamarca aim achieve sequential consistency data updates propose weighted voting scheme 
assumptions odds typical networks highly dynamic number copies data item rarely known certainty 
providing strict sequential consistency impossible guarantee typical systems scheme provides probabilistic guarantees 
perfect knowledge number replicas longer needed decent estimate sufficient easily obtainable underlying protocol 
scheme users allowed tradeoffs effectively choosing important areas performance consistency response time evaluate implications tradeoffs 

traditional quorum consensus quorum consensus flexible variation majority consensus technique ensuring consistency multiple data copies distributed environment :10.1.1.12.6256
basic idea copy particular data item pieces information associated certain number votes version number 
order access data item reading writing minimum number votes quorum obtained 
node requesting data access typically send request nodes containing data item 
properly functioning node received request respond indicating votes version data node stored locally 
original requestor collects votes meet threshold read value copy version number update data item 
vote threshold quorum level chosen important implications consistency behavior system 
typically system separate quorum levels reading call rq writing call wq 
thresholds indicate number votes required reading writing respectively 
read quorum write quorum set level fact desirable different 
instance system frequent reads relatively writes sense set read quorum rw low write quorum wq high 
effect making frequent reads fast making writes slower votes collected 
order maintain data consistency key restrictions placed quorum values chosen rq wq greater total number votes data item available system wq greater half number votes available 
guarantees read quorum write quorum overlap read operation see data copy reflects write operation 
long conditions maintained impossible read stale data value 
additional benefit approach node failures affect data consistency long quorum obtained set working nodes transaction safely proceed 
nodes fail longer possible obtain votes continue read write operation 
consistency longer guaranteed operation abandoned 

peer peer quorum consensus remarkably traditional quorum consensus scheme adapted fairly easily peer peer networks 
changes implications technique meanings quorum levels chosen 
traditional weighted voting distributed systems described assumed centralized location existed storing list data item replicas version numbers vote distributions :10.1.1.12.6256
networks lack centralization approach handle locally 
master replica list individual node responsible finding set accessible copies data item 
typically done lookup strategy supported network infrastructure 
lookup strategies surveyed broadcast commonly ideal approach 
node established copies data item access distribute votes assigning copy certain number 
vote allocation stored locally request data item target nodes respond vote timeout interpreted 
requesting node tally votes local vote allocation decide access proceed quorum levels node chosen follow 
enforcing consistency observe scheme consistency local global 
data accesses appear sequentially consistent node provided conditions met peer knows total number copies exist data item 
just number copies currently accessible network total number copies 
version numbers globally unique 
difficult achieve especially form clock synchronization 
individual peers read update data items disconnected 
clearly nodes connected network obtain quorum jeopardize consistency 
requirements mind basic steps peer node follow trying update data value 
requestor tries establish write quorum locally set threshold discussed 

peers vote lock replicas send back global version number 

requestor sends new data value new version number copies quorum 

peers update value unlock copies 
effectively version phase commit protocol sure quorum copies agrees commit proceeding 
nodes fail committing new values update proceed long write quorum exists nodes 
loss nodes quorum longer exists transaction abort 
updated values propagated copies data item casting votes voting 
updates propagated number different ways lazy propagation possibility 
exploration update propagation alternatives important left 
relaxing consistency situations global knowledge total number copies existence simply isn available peers 
global knowledge required somewhat odds true system totally decentralized shared global information 
global knowledge guaranteeing kind consistency impossible 
consider happen client chooses quorum thresholds current knowledge number replicas network scenario depicted 
lack global replica knowledge lead accessing stale data values 
peers truly free join leave network time number copies data items available network changing 
node old version data item joins quorum level stays obtaining quorum longer guarantees copy contains version 
possible solution problem force node joins network update data items versions 
additionally node joins leaves network peers notified adjust quorum levels accordingly 
problem crop substantial number node failures cause network partitioning 
number data replicas dropped nodes half partition revise quorum levels downward 
different updates happen simultaneously halves network 
partitions reunite confront different equally valid versions reality 
versions data values need way reconcile 
things starting look pretty quorum consensus approach 
problem strict consistency re trying support unreasonable dynamic decentralized peer peer environment 
relax strict sequential consistency allow possibility reading old data values 
example shows reading old values possibility probability happens 
right half different replica quorums possible result reading old value 
assuming replicas vote chance old value read 
typically expect replicas respond responded impossible read old data value scenario 
flexible quorum consensus approach powerful individual peers control kind risk consistency violations re willing tolerate adjusting quorum levels 
quorum values better thought level confidence data accessed higher quorum levels greater confidence 
key idea peers choose tradeoff data freshness variety factors availability higher quorum threshold greater chance attempted access fail due lack votes 
price paid better data freshness 
access time smaller quorum tend improve data access response times fewer peers consulted operation proceed 
convenience desired disconnected peers continue read write local copies data items 
inherently risky node knowledge updates occurring network easy read stale value 
peer reconcile disconnected writes rest network reconnection 
disconnected updates possible relaxed consistency provided 
approach basically swaps firm guarantees probabilistic guarantees achieving great deal flexibility process 
strategy fit better flexible nature peer peer networks lack strong guarantees regard locating data message delivery 
choosing write quorum levels traditional quorum consensus approach requires half copies data item available update succeed 
relaxed quorum consensus scheme restriction important ensuring different data updates occur simultaneously different write quorums 
fact node local estimates number copies data item available slightly shy total number probably idea require write quorum levels somewhat higher half number votes wq estimated total 
presence large number node failures high percentage nodes reachable ll see section probability update conflicts relatively low 
course peers network administrators adjust write quorum restriction update conflict risk level tolerable application 
alternative quorum types quorum consensus majority voting scheme considering just quorum approaches proposed time 
grid quorums example organize sites kind geometric pattern rectangle simplest restrict quorum formation properties grid elements column element column 
structuring doesn really map dynamic network connections set data copies peer links changes better suited static networks globally available information 
tree quorums similar grid quorums impose logical tree structure set data replicas 
concerns dynamically reconfiguring structure apply tree quorums significant reliance root upper level nodes tree 
fact tree quorum approaches write operations go root 
placing large load small set nodes significantly reduce scalability benefits peer peer networks 
quorum approach promising applications hierarchical quorum consensus 
sites organized hierarchically ary tree hierarchical quorum consensus doesn root node dependence tree quorums better fit scalable nature 
hierarchy map nicely network superpeer nodes see section sadly relegated 
jimenez comparison various quorum approaches simple read copy write available strategy best terms scalability availability communication overhead 
assumptions homogenous fully replicated sites failure detection abilities don necessarily mesh networks worth pointing peers flexible quorum consensus certainly choose read write available strategy setting read write quorum levels appropriately 
terms maintaining goals dynamic reconfiguration heterogeneity scalability redundancy database applications simple adaptable strategies flexible quorum consensus way go 

evaluation get better understanding effectiveness flexible quorum consensus approach ramifications various tradeoffs engenders constructed basic implementation simulated operation 
neurogrid peer peer simulator experiments 
neurogrid capable simulating variety different underlying peer peer protocols including gnutella freenet neurogrid protocol fairly high level abstraction 
result simulate fairly large number nodes relatively quickly 
opted gnutella protocol experiments 
advanced efficient gnutella protocol established extensively millions people years 
possible optimize performance depending underlying protocol general findings hold regardless 
give brief overview gnutella protocol 
gnutella protocol gnutella protocol defines peers basic actions fundamental operation network 
include joining network pinging locate peers querying locate data stored peers 
order join gnutella network peer know address peer connected 
successfully establishing connection peer new node joined network sends ping requests active connection try locate additional peers network 
joining node cache list peers responded ping requests initiate maintain connections small number peers 
point time active connections broken node proceed connect node cache peers 
way locating peers resources interest gnutella node send query message direct neighbors maintains active connections 
query message time live ttl hop count field peer receives query message take actions check query matches node local resources 
match peer send message back original sender query 
travel backward path original query message took 
decrement message ttl field 
field reaches propagate message 
gnutella protocol limits query lifetimes prevent running forever 
ttl field forward query message node active connections 
purposes experiments settled basic parameters node network node maintains active connections messages initial ttl hops number active connections message ttl chosen due suggestions gnutella protocol documentation fairly typical settings gnutella clients 
network size little small side gnutella file sharing networks reasonable database sharing involve fewer peers 
mainly owing fact far fewer people tend interesting databases willing share interesting files 
consistent real networks simulator uses randomly assembled network topology result bunch peers joined left network random 
queries data accesses originate randomly selected nodes diffuse outward 
data replicas distributed randomly network total number copies fraction number peers network 
experiments simulation trial runs performed configuration data point averaged 
additionally confidence intervals sided distribution displayed point 
reachability node failure simulation sought determine functioning nodes network reachable certain percentage nodes failed 
reachable nodes percentage failed nodes network reachability node failure working nodes nodes reached confidence intervals results show impact fairly large fraction nodes failing simultaneously really pretty catastrophic situation 
network happened unreachable network partitioned result relatively small number node failures nearly impossible obtain consensus rendering network fairly useless 
see results network fully operational entire network reachable close 
primarily restriction nodes peers maintain connections 
peers probably connections set nodes reducing chance query message reach entire network ttl runs 
general increasing number active connections message start ttl improve reachability expense messages flooding network 
percentage failed nodes grows working nodes stay reachable failure rate reaches things really start deteriorate 
nodes failed half remaining nodes stay reachable opening possibility non overlapping write quorums 
functioning peers revise quorum levels downward adjusting failures inconsistent parallel write operations occur different subsets nodes 
may problematic really possibility fairly extensive level node failure peers aware reduced node set adjusting quorum levels 
detecting catastrophe peers choose maintain current quorum levels increase message ttl reduce eliminate risk inconsistent writes 
message transfers quorum building effort messages sent read write transactions involve obtaining quorum copies 
experiment examines network traffic total message transfers required build consensus different consensus levels degrees data replication 
set replication levels tested enormous general trends tradeoffs different levels readily apparent 
expected behavior replication quorum levels tested easily extrapolated 
number messages data replicated peer peers peers peers confidence intervals quorum level percentage nodes relevant data message transfers involved quorum building volume network traffic involved quorum building important determining concurrency volume transactions network support 
plays role influencing query response time ll look 
see data replicated nodes nodes need involved obtain consensus messages need exchanged 
price greater redundancy 
interestingly data sparsely distributed peers large volume messages sent just coordinate far nodes 
relatively low quorum levels hand high degree replication penalty matching nodes near vicinity sending messages 
best performance achieved extremes particular replication level appears strike balance redundancy quorum building effort 
greater redundancy needed messages needed trying lower quorum building effort reducing redundancy appears self defeating replication level shows 
query response time long take read update value distributed network 
directly related time takes build quorum 
take different view measure elapsed response time opposed number message transfers 
response time multiple message transfer time quorum level percentage nodes relevant data data replicated peer peers peers peers confidence intervals query response time different quorum replication levels experiment time measured seconds measured relative long takes transfer message single hop 
assumes message transfer different nodes relatively consistent reasonably approximated average 
benefit simplification results relatively independent performance underlying communication network 
see trade offs data replication response time 
high degree replication desired low quorum level ends faster peer quickly find nodes meet quorum threshold immediate neighbors 
unsurprisingly quorum levels increase response times tend trade latency data freshness 
replication levels response times quorum levels low quorum levels increase data confidence differences due redundancy start emerge 
response times lower replication levels tend better merely fewer nodes terms absolute numbers needed achieve quorum 
high data freshness spectrum re forced settle worse response times need redundancy 
note data replicated peers nodes held data quorum levels percent unattainable explaining missing data points 
indicates difficult impossible achieve high data confidence low redundancy 
probability stale data access clearly order decide quorum levels appropriate peer important understand consequences choice particularly terms probability reading old data value 
experiment explored data confidence quorum threshold tradeoff detail 
simulations assumed worst case scenario copy data item replicated minimum possible number nodes needed obtain quorum 
quorum level set relevant nodes assumed hold value 
relatively real world network useful illustrating general relationship quorum thresholds data confidence 
expect probabilities reading stale values real network decent update propagation scheme lower shown 
probability stale access data replicated peer peers peers peers confidence intervals quorum level percentage nodes relevant data probability stale data access different quorum data replication levels results experiment relatively straightforward 
level data replication goes chances reading old value quorum level reduced 
primarily larger number nodes involved quorum far nodes possess date copy 
stale access probabilities fairly high drop quite dramatically 
relatively sparse data redundancy quorum level needed achieve stale access probability practically zero 
stale access node churn nodes join leave network anytime network configuration rarely remains static 
investigated flexible quorum consensus scheme perform network fast changing set peers 
modeled nodes joining leaving network terms churn rate 
churn rate represents percentage network experiencing changes membership queries 
instance churn rate simulate current peers nodes node network leaving network nodes joined network 
way simulated network stays size data replication rate stays constant queries 
versions different data items change 
assume worst case probability stale access scenario minimum quorum nodes copy 
set nodes leaving randomly chosen leaving nodes take date copies network 
set joining nodes assumed bringing stale copies network 
data replicated peer peers peers peers quorum level confidence intervals churn rate probability stale data access affected network churn rate 
results shown different quorum levels varying degrees data replication set adverse network conditions expect probability accessing old data values rise happens 
show results different quorum levels general trends pretty clear 
network churn rates increase stale access probability due fact newly joining nodes old values 
low quorum levels data replicated large percentage nodes chance accessing old value low 
churn rates increase high data replication schemes perform inspiring confidence data accessed 
trend see increasing quorum level network resistant node churn degree replication stays 
quorum level network able maintain high data confidence churn rates reach provided data replicated peers 
pretty remarkable considering node turnover queries highly real network 
worth pointing effective update propagation scheme improve performance sending updated values newly joining nodes propagating updates just minimum quorum 
data replicated peer peers peers peers quorum level confidence intervals churn rate summary tradeoffs flexible quorum scheme tradeoffs summary quorum data replication levels adjusted meet performance goals degree data replication high low network traffic fastest access time medium data confidence low network traffic short access time lowest data confidence network traffic slowest access time highest data confidence moderate network traffic short access time high data confidence low high quorum level table structured key parameters users control degree replication quorum level 
quadrants indicate performance effects expected result parameter levels chosen 

managing updates peer peer database systems challenging important task 
database systems practical value predictable updates nearly essential prerequisite 
weighted voting quorum consensus scheme significant potential adapted databases area original designers surely envisioned 
global replica knowledge known quorum consensus approach provide localized consistency guarantees 
common case information known quorum consensus strategy allows peers tradeoff desired level data freshness redundancy availability response time 
technique rich possible tradeoffs resulting highly flexible adaptable approach 
instance desiring high data redundancy increase level data replication level network traffic query response time increase result 
latency important low quorum level chosen course chances reading old values increase 
number facets data updates remain unexplored provide worthwhile opportunities pursuit 
area mentioned update propagation 
variety strategies employed solve problem doubt impact update performance areas network traffic query response time stale access probability 
promising extension quorum consensus scheme involves incorporation superpeers 
typically reliable nodes add hierarchy network provide optimization opportunities 
example data important higher availability requirements located superpeers 
special nodes expected larger allocation quorum votes reflect superior reliability 
affect strategies performance entirely clear 
related note worth exploring underlying network protocol affects performance 
new protocols developed years better data updates 
looked adjusting quorum data replication levels affect response times data confidence 
ideally things way 
users specify stale access probability willing tolerate ask network individual peers optimally choose quorum data replication levels minimize response times 
typical situation user control small set nodes entire network case global optimization difficult 
addition statically choosing parameters tradeoffs conceivably adjusted real time 
peers dynamically adapt quorum vote distribution data replication levels improve performance meet changing needs time 
intelligent peer behavior challenges currently understood 
advanced behavior peer peer quorum consensus suited flexible dynamic heterogeneous world peer peer networks 

agrawal abbadi 
tree quorum protocol efficient approach managing replicated data 
proceedings sixteenth international conference large databases september pp 

balakrishnan kaashoek karger morris stoica 
looking data systems 
communications acm 
vol 
pp 


technologies sharing collaborating net 
proceedings international conference peer peer computing august pp 

bernstein data management peer peer computing vision :10.1.1.17.2221
webdb workshop databases web madison usa june 
breitbart rastogi seshadri silberschatz 
update propagation protocols replicated databases 
proceedings acm sigmod international conference management data june pp 

cheung ammar ahamad 
grid protocol high performance scheme maintaining replicated data 
proceedings sixth international conference data engineering february pp 

halevy piazza peer data management system 
ieee transactions knowledge data engineering july pp 

gifford :10.1.1.12.6256
weighted voting replicated data 
proceedings seventh symposium operating system principles december pp 

giunchiglia 
making peer databases interact vision architecture supporting data coordination 
proceedings conference information agents cia madrid september 
gribble halevy ives suciu :10.1.1.27.8638
peer peer databases vice versa 
fourth international workshop web databases webdb 
kumar 
hierarchical quorum consensus new algorithm managing replicated data ieee transactions computers september pp 

jimenez peris martinez alonso kemme 
quorums alternative data replication 
acm transactions database systems tods september pp 

joseph 
adaptive routing distributed decentralized systems neurogrid gnutella freenet 
proceedings workshop infrastructure agents mas scalable ms autonomous agents montreal 
joseph 
documentation neurogrid peer peer simulation software 
available www neurogrid net bin view main 
revised april 
kementsietsidis arenas miller 
mapping data peer peer systems semantics algorithmic issues 
proceedings acm sigmod international conference management data june 
rfc gnutella 
available sourceforge net developer testing index html 
lu callan 
content retrieval hybrid peer peer networks 
proceedings th international conference information knowledge management november pp 

ng ooi tan zhou 
peerdb system distributed data sharing 
th international conference data engineering icde 
ozsu valduriez 
distributed database systems 
ieee computer august pp 

lamarca 
decentralized weighted voting data management 

san diego ca september 

peer peer scale analysis traffic patterns 
proceedings second international conference peer peer computing september pp 

shen shu yu 
efficient semantic content search network 
ieee transactions knowledge data engineering july pp 

stoica chord scalable peer peer lookup protocol internet applications 
ieee acm transactions networking february 
tatarinov mork 
piazza peer data management project 
sigmod record 
thomas 
majority consensus approach concurrency control multiple copy databases 
acm transactions database systems june pp 

zhang mahalingam xu tang 
scalable structured data placement storage utilities 
hewlett packard labs technical report hpl 
available www hpl hp com techreports hpl pdf 
