word sense induction triplet clustering automatic evaluation stefan natural language processing department university leipzig germany informatik uni leipzig de novel solution automatic unsupervised word sense induction wsi introduced 
represents instantiation sense collocation observation gale 
existing approaches utilizes clustering word occurrences 
approach differs approaches wsi enhances effect sense collocation observation triplets words pairs 
combination step clustering process sentence occurrences features allows accurate results 
additionally novel likewise automatic unsupervised evaluation method inspired sch tze idea evaluation word sense disambiguation algorithms employed 
offering advantages independency biased gold standard enables automatic parameter optimization wsi algorithm 
aim word sense induction wsi find senses target word automatically possible unsupervised manner 
wsi akin word sense disambiguation wsd methods employed problems encountered vagueness sense distinctions kilgarriff 
input wsi algorithm target word disambiguated called word sense discovery word sense discrimination space output number word sets representing various senses 
dimensional locate office building square 
results empirically grounded suggestions lexicographers input wsd algorithms 
possible uses include automatic thesaurus ontology construction machine translation information retrieval 
usefulness wsi real world applications tested proved 
related substantial number different approaches wsi proposed far 
occurrence statistics albeit different context representations occurrence words phrases pantel lin bigrams sch tze neill small windows word gauch larger contexts sentences rapp large windows words ferret 
employ clustering methods partition occurring words sets describing concepts senses 
algorithms aim global clustering words concepts pantel lin 
majority algorithms local clustering words occurring target word grouped various senses target word 
immediately clear approach favor aiming global senses inherent property produce uniform granularity distinctions senses desired rapp 
graph algorithms differ majority algorithms aspects 
words taken nodes occurrence words defines edge respective nodes 
activation spreading resulting graph employed barth order obtain distinctly activated areas vicinity target word 
possible graph clustering techniques obtain sense representations sub graph density measures 
clear kind approach differs qualitatively standard clustering approaches 
generally notion sub graph density intuitive compared clustering 
different types polysemy significant distinction probably syntactic classes word plant vs plant conceptually different senses power plant vs green plant 
known unsupervised part speech tagging rohwer freitag rapp size window words similar target word plays decisive role 
significant direct neighbours context representations compare words results predominantly syntactical similarity 
hand significant sentence cooccurrences results semantical similarity curran 
various context representations similarity measures clustering methods compared evidence far various window sizes parameters influence type ambiguity see manning sch tze 
pantel lin introduced evaluation method comparisons obtained word senses senses provided word net 
method successfully authors ferret straightforward produces intuitive numbers help directly estimate output wsi algorithm meaningful 
hand gold standard wordnet biased lacks domainspecific sense definitions providing abundance sense definitions occur rarely corpora 
example british national corpus bnc sense male capital wordnet represented single sentence 
furthermore comparing results algorithm wordnet automatically implies algorithm matches senses senses wordnet 
similar task wsd assumed similarly error prone 
reasons led researchers opt manual evaluation algorithms neill rapp 
manual evaluation disadvantages notably poor results 
pseudoword evaluation method similar sch tze pseudoword method employed 
automatic easy reproduce adapts domain specificity corpus 
triplet algorithm algorithm proposed sense collocation observation gale 
essentially means pair words occurs significantly corpus collocation concept referenced pair unambiguous growing plant vs power plant 
pointed yarowsky observation hold uniformly possible occurrences words 
stronger adjacent occurrences word pairs predicate argument relationship arbitrary associations equivalent distance plant clear cut 
alleviate problem step algorithm build triplets words target word cooccurrences pairs target word occurrence 
means plant restricted word word rules possibilities interpretation plant lot improbable 
algorithm applied types cooccurrence data 
order show influence window size significant occurrences direct neighbour cooccurrences computed word 
significance values obtained loglikelihood measure assuming binomial distribution hypothesis dunning 
word significant occurrences kept 
threshold follow chosen experiment ing algorithm 
shown section exact set numbers matter 
evaluation method enables find optimal configuration parameters automatically genetic algorithm 
core assumption triplet algorithm words uniquely identify topic concept sense 
previously acquired significant occurrences types lists cooccurrences words triplet intersected retain words contained lists 
words cover topic space nasa mars intersection empty launch probe 
words identify meaningful topic space nasa intersection contain words 
intersections triplets built function words contain occurrences identify unique topic 
socalled words removed occurrences triplets built occurrences features 
straightforward create possible triplets occurrences target word compute intersection cooccurrence lists 
intersections features triplets possible group triplets words similar features means standard clustering algorithm 
order tie referenced meanings triplets target word resulting set triplets restricted contain target word 
useful side effect reduces number triplets cluster 
reduce remaining number items clustered iterative incremental windowing mechanism added 
clustering triplets step occurrences significant ones taken step build triplets intersections 
resulting elements triplets intersections respective occurrences features clustered clusters remaining previous step 
step clustering algorithm words triplets features merged overlap factor similarity measure curran similar overlapping words 
element space nasa mars orbital satellite 
space launch mars orbit satellite astronaut 
similar merged space nasa mars launch orbital satellite orbit astronaut 
measure utilizes features comparisons result contain clusters having identical key sets result merging triplets 
post clustering step applied order compare clusters triplet words merge spurious sense distinctions 
having established final clusters words remain unclustered classified resulting clusters 
classification performed comparing occurrences remaining word feature words sense 
overlap similarity similar sense word classified 
entire cluster algorithm summarized follows target word step take occurrences build possible pairs cooccurrences add triplets compute intersections cooccurrences triplet cluster triplets intersections features clusters remaining previous step clusters belong words triplets features merged increasing counts cluster results loop merged words triplets features classify unused words resulting clusters possible order reduce noise example introduced triplets unrelated words containing words threshold minimum intersection size set 
parameter worth mentioning clustering step clusters removed contain words 
keeping track times word hit certain cluster merging step enables add post processing step 
step word removed cluster hit cluster significantly 
issues open questions arise entire approach 
obviously particular similarity measure particular clustering method merge vectors creating proper centroids 
possible combination decisions kind produce better results 
observation results fairly stable respect decisions parameters frequency target word size corpus balance various senses greater impact 
evaluation sch tze introduced pseudoword evaluation method wsd algorithms 
idea take arbitrarily chosen words banana door replace occurrences word new pseudoword 
wsd applied sentence amount correctly disambiguated sentences measured 
disambiguation case correct sentence ate banana assigned sense banana door 
words sentences words occurs viewed set wsd algorithm supposed sort correctly apart 
fact similar wsi task supposed sort set words apart occur target word refer different meanings 
possible take words view occurrences set wsi algorithm sort apart 
example word banana cooccurrences apple fruit coconut word door occurrences open front locked 
wsi algorithm disambiguate pseudoword occurrences apple open fruit front locked 
short method merges occurrences words set words 
wsi algorithm applied set occurrences evaluation measures result comparing original occurrence sets 
order find sense correctly identified wsi algorithm retrieval precision rp similarity sense original sense overlap measure computed 
evaluations threshold chosen means words sense overlap original sense order counted correctly sense 
average numbers similarity higher ranging 
informative measure retrieval recall rr amount words correctly retrieved correct sense 
words merged pseudoword meaning words represented occurring words happen senses correctly wsi algorithm containing words overlap similarity 
means words representing original sense retrieved resulting retrieval recall 
retrieval recall upper bound reasons 
average overlap ratio cooccurrences word pairs evaluation 
factor lowering upper bound unknown amount fact words ambiguous 
algorithm correctly finds different senses original words senses chosen represent original meaning original word 
words assigned sense lost sense 
terms information retrieval sense task reformulated follows set words word senses try retrieve words belonging sense retrieval recall retrieving wrong ones retrieval precision 
sense defined correctly wsi algorithm retrieval precision retrieval recall 
number implies words retrieved correctly initial occurrence sets contained words 
assumes words sufficient characterize sense wsi algorithm evaluate 
reason set minimum retrieval precision value avoid strong baseline see 
prerequisites possible define precision recall retrieval precision retrieval recall measure quality wsi algorithm 
precision defined number times original occurrence sets properly restored divided number different sets 
precision unknown upper bound words chosen ambiguous 
algorithm finds meanings pseudoword words ambiguous meanings precision algorithm operated 
recall defined number senses divided number words merged create pseudoword 
example recall words create pseudoword senses correctly retrieval precision retrieval recall 
possible baseline introduced measures 
algorithm resulting single set occurrences pseudo word 
set retrieval precision rp compared original senses senses half retrieved words match 
allowed count correctly sense 
means retrieval recall rr recall precision case correctly retrieved wrong retrieved defined 
mentioned previous sections parameters strong impact quality wsi algorithm 
interesting question quality disambiguation depends type ambiguity wsi sentence occurrences bag words model produce better results syntactically different senses senses differing topic predicted sch tze 
simulated choosing words different word classes create pseudoword noun committee verb accept 
interesting question concerns influence frequency word sense 
example simulated choosing high frequent word low frequent word representing represented vs poorly represented sense 
aim evaluation test described parameters produce average precision recall time completely third parties 
raw bnc reduction lemmatization introduces additional ambiguity pos tags groups containing words picked semi randomly avoiding extremely ambiguous words respect wordnet possible high frequent nouns nh picture average blood committee economy medium frequent nouns nm substrate thirst low frequent nouns nl gravitation pharmacology high frequent verbs vh avoid accept walk agree write medium frequent verbs vm rend confine evoke low frequent verbs vl memorize typify high frequent adjectives ah useful deep effective considerable traditional medium frequent adjectives am normative phenomenal inactive low frequent adjectives unrepresented groups design tests focussing different variable 
high frequent nouns occurrences medium frequent low frequent 
influence word class frequency run tests sentence cooccurrences features 
test words equal word class viewed set words 
results possibilities combine words pseudoword test results wsi algorithm 
purpose test examine tendency senses certain word classes easier induced 
seen table sense induction verbs sentence occurrences performs worse compared nouns 
explained fact verbs semantically specific need syntactic cues generalizations hardly covered underlying bag words model order disambiguated properly 
time nouns adjectives better distinguishable topical key words 
results unison prediction sch tze 
rp rr table influence syntactic class input word test 
showing precision recall average retrieval precision rp recall rr 
second test types possible combinations word classes tested pseudowords consisting noun verb nouns adjective verb adjective 
combination possibilities combining word word class word word class 
purpose test demonstrate possible differences wsi different word class combinations 
corresponds cases word form verb walk walk noun adjective example nice color color tv 
results table show clear tendencies wsi adjectival senses verb senses slightly difficult 
rp rr table influence syntactic classes senses test 
third test designed show influence frequency input word 
words equal frequency taken group possible combinations 
results table show clear tendency word combinations achieve better quality wsi lower frequency words 
steep performance drop recall immediately clear looking retrieval recall senses 
surprising low frequency words occuring times bnc algorithm runs data sparseness problem pointed problematic wsi ferret 
rp rr high med 
low table influence frequency input word test 
fourth test shows influence sense wsi 
purpose possible combinations frequency classes high frequent middle high low middle words created possible word pairs 
table demonstrates steep drop recall low frequent word part pseudoword 
reflects fact difficult algorithm find sense represented frequent word 
unusually high precision value high low combination explained fact case sense frequent word 
recall close precision closer 
rp rr table influence different representation senses frequency constituents pseudoword test 
possible provide averages entire test runs comprising tests 
macro averages tests rp rr micro averages 
thresholds pairs triplets results rp rr 
words sense retrieved triplets compared pairs confirm improvement triplets 
window size second run tests direct neighbors features failed due data sparseness problem 
word pairs occurring significantly sentences bnc log likelihood measure 
words low frequency showed strong performance loss compared high frequent words 
compared word pairs occurring directly 
results second run macro averages rp rr reiterated detail highly inconclusive due data sparseness 
derives fact contrary results run results vary strongly various parameter settings considered stable 
results insufficient show influence context representations type induced senses supposed allow insights 
firstly corpus size obviously matter wsi data probably alleviated sparseness problem 
secondly context representation theoretically superior neighbor occurrences vs sentence occurrences effect various representations data richness far stronger tests 
examples light pseudoword evaluations real examples help reduce abstractness results 
words sheet line space chosen arbitrarily words representing induced senses listed 
sheet beneath blank blanket bottom canvas cardboard accounts amount amounts asset assets attributable balance line space angle argument assembly axis bottom boundary cell circle column lines link locomotive loop metres mouth north parallel astronaut launch launched mission orbit rocket satellite air allocated atmosphere blank breathing buildings ceiling confined examples show senses words intuitive 
show senses distinguishable ones senses missing appear bnc frequently 
finer grained distinctions bag words model appropriate prove sufficient applications information retrieval 
varying contextual representations prove complementary approach enable detection syntactic differences collocational usages word 
shown approach enables automatic knowledge free word sense induction corpus high precision sufficient recall values 
induced senses words inherently domain specific corpus 
furthermore induced senses apparent ones type ambiguity matters expected 
clear preference topical distinctions syntactic ambiguities 
effect due underlying bag words model alternative contextual representations yield different opposed better worse results 
bag words limitation implies senses considered spurious circumstances 
example word challenger induces senses describing opponent game 
differences strong senses distinguished chess challenger grand prix challenger challenger boxing large set specific words distinguishing senses 
questions remain open 
frequency word great impact possibility disambiguate correctly methods question extent corpus size plays role equation compared corpus senses 
question connected limitation algorithm requires sense induced representable large amount words 
question similar algorithm improved discern small senses random noise 
combination algorithms finding collocational usages words probably offers feasible solution 
evaluation method employed automatic optimization algorithm parameters genetic algorithms 
interesting employ genetic programming order optimal word sense induction algorithm design 
michael barth 

von mittels spreading activation 
master thesis university leipzig 
stefan 

sentence occurrences small world graphs solution automatic lexical disambiguation 
proceedings lncs pages 
springer 
james richard curran 

distributional semantic similarity 
ph thesis institute communicating collaborative systems school informatics 
university edinburgh 
dominic 

discovering corpus specific word senses 
proceedings eacl pages budapest hungary 
ted dunning 

accurate methods statistics surprise coincidence 
computational linguistics 
olivier ferret 

discovering word senses network lexical cooccurrences 
proceedings coling pages geneva switzerland august 
william gale kenneth ward church david yarowsky 

statistical methods word sense disambiguation 
intelligent probabilistic approaches natural language fall symposium series fs march 
susan gauch robert 

experiments automatic word class word sense identification information retrieval 
proceedings rd annual symposium document analysis information retrieval pages 
adam kilgarriff 

don believe word senses 
computers humanities 
christopher manning hinrich sch tze 

foundations statistical natural language processing 
mit press 
daniel neill 

fully automatic word sense induction semantic clustering 
master thesis cambridge university 
patrick pantel dekang lin 

discovering word senses text 
proceedings acm sigkdd pages edmonton 


word sense discrimination clustering similarity contexts 
master thesis department computer science university minnesota 
reinhard rapp 

mining text word senses independent component analysis 
proceedings siam international conference data mining 
reinhard rapp 

practical solution problem automatic part speech induction text 
proceedings acl interactive poster demonstration sessions pages ann arbor june 
acl 
richard rohwer dayne freitag 

full automation lexicon construction 
proceedings hlt naacl computational lexical semantics workshop boston ma 
hinrich sch tze 

context space 
working notes aaai fall symposium probabilistic approaches natural language pages menlo park ca 
aaai press 
hinrich sch tze 

automatic word sense discrimination 
computational linguistics 
dave anthony davis tim 

noun sense induction web search results 
proceedings th acm sigir pages salvador brazil 
erik 

fuzzy clustering approach word sense discrimination 
proceedings th international conference terminology knowledge engineering copenhagen denmark 
david 

unsupervised word sense disambiguation rivaling supervised methods 
acl 
