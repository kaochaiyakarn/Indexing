probabilistic dynamic optimization job partitioning grid infrastructure johan montagnat xavier pennec laboratoire informatique syst mes cnrs france inria sophia antipolis france production grids potential parallel execution large number tasks introduce high overhead significantly impacts execution short tasks 
strategy optimize partitioning jobs grid infrastructure 
method takes account variability difficulty model multi user large scale environment production 
probabilistic estimations grid overhead 
study analytically modeled environments show results real grid infrastructure 
demonstrate method leads significant time speed substantial saving number submitted tasks respect blind maximal partitioning strategy 
keywords grid computing models tools heterogeneous systems parallel systems distributed systems 
problem sharing independent tasks set known amount computing resources connected reliable high performance network tremendously studied field parallel computing 
addressing similar problem arising considering execution set independent tasks computing grid 
grid understood set individual computers connected reliable wide area network topology dynamically change time 
grid resources user get access considerable potentially infinite amount distributed computing power 
ideally user split computing jobs independent tasks computing resources available 
practice usage grid resources introduces overhead computing time due time needed reach remote resources scheduler working time queuing time 
infrastructure course limited performance decrease total number submitted tasks exceeds certain limit 
optimal computation time usually obtained maximum splitting trade splitting grid overhead tend grow number tasks deal 
context grid computing problem tasks splitting impacted new parameters grid resources highly volatile topology grid network changing status grid fully known instant 
rest study underlying hypotheses survey literature 
quick overlook literature satisfy propose probabilistic approach estimate grid computation overhead 
demonstrate relevance model analytical study show results real full scale grid production 

hypothesis context grid term covering broad area 
different approaches distributed systems qualified grids currently investigated research focusing early grid systems originating cluster computing put production today 
system grid aggregation clusters classical batch system handle local computing load middleware software layer offering interface potentially heterogeneous batch systems resources single sign entry point users 
grid merely super batch system capable handling tremendous amounts computations particularly efficient processing independent large grain computations 
batch computing restrictive compared modern highly dynamic systems 
systems robust able deal legacy code requiring rewriting instrumentation 
grid deployed wide area network proves highly volatile resources prob ability hardware failure growing amount resources network instability temporarily disconnect full fragments infrastructure 
resources may appear disappear depending needs maintenance operations addition infrastructure full grid topology status known instant grid information providers rely past possibly outdated data resources 
production grids multi users multi community systems continuously loaded 
evolution load put grid resources hardly predictable parameter 
production systems accessible users user interface giving minimal access internal mechanisms 
production grids access core middleware mainly submit computing tasks monitor evolution collect results obtain information grid status 
conducting experiments egee infrastructure corresponds description see section 
best suited application infrastructure called embarrassingly parallel applications computing tasks high level inherent parallelism synchronization constraints 
high energy physics computing famous kind applications example field medical imaging described literature 
particular french project aims deploying medical image applications grids 

formalization problem description 
real large scale grid infrastructures overhead due submission scheduling minutes 
submission short running tasks slow global application 
tasks grouped larger sets reduce impact penalty 
optimizing tasks granularity reduces total number tasks submitted infrastructure respect default maximal partitioning strategy 
potential improvement grid performance obtained user adopts strategy 
consequently trade submitting high number short tasks maximizes parallelism may leads grid overhead prevail running time submitting small number longer tasks 
context ultimate goal propose optimization strategy tuning granularity tasks submitted grid fixed job execute 
strategy aims 
lowering total execution time job user point view 
reducing total number tasks submitted job infrastructure point view 
problem modeling 
total job corresponding known cpu time supposed divisible number independent tasks grid infrastructure introducing overhead corresponding submission scheduling queuing time tasks consider execution task completed tasks completed 
hypothesis task affected single processor number submitted tasks strictly corresponds number processors involved execution 
goal minimize total execution time defined maxi assume fixed value solution straightforward high possible 
assumption realistic cases due infrastructure nature 
realistic view assume dependent time 
section review works related problem 

related complete comparative study allocation strategies task execution times modeled random variables known mean variance 
author demonstrates need dynamic allocation strategy points associated overhead assumed fixed study 
considers system initially idle processors notices trade overhead idle time 
assumptions compares allocations strategies presenting simulation results 
problem entirely addressed methods allocation strategies consist optimizing size batches allocated processors trying optimize total number processors processor cpu time ii assume overhead fixed varies time case iii production infrastructure processors idle 
leads queuing time take account random variable 
scheduling techniques largely studied literature 
detailed review heuristics study impact performance estimation scheduling strategy 
authors assume scheduler knowledge current topology grid number location copies input files list computations file transfers currently underway completed 
kind solution hardly usable case assume priori knowledge infrastructure concerning computations progress current grid topology 
scheduling method account stochastic nature time compute unit data distant processor supposing distributions gaussian 
particular authors notice penalizing highly variable processors leads significant speed 
variability resources taken consideration see section approach totally suit problem distribution assumed gaussian described section ii distribution dynamically estimated multi users infrastructure consider 
author presents decision rules sequential resource allocation dynamic programming 
consider problem consisting allocating machines sequentially arriving tasks 
kind solution constitute interesting perspective problem dynamic programming methods consider set independent tasks submitted parallel time infrastructure 
works address task granularity issue noticing optimal number processors determine minimize total execution time account computation time communication time 
heuristics determine close optimal configuration tasks assigned specific processors reduce communication overhead induced routing contention 
provides results scope solution strictly deterministic models communication function linearly number processors properly describe overhead need consider 
authors determine optimal number tasks submit determining analytical model overhead grid submission queuing system batch architecture 
analytical model hard determine complex dynamic multi users grid infrastructure 
works inside propose performance analysis methods task scheduling embedded systems considering probabilistic models task execution times 
authors model task execution generalized continuous probability distribution propose method restricted specific scheduling policy 
consider execution time memory aspects 
method construction underlying stochastic process analysis 
approach entirely probabilistic assumption nature probability function execution time suits hypotheses assume tasks executed concurrently single processor 
methods completely match hypotheses 
propose dedicated model rest 
adopted probabilistic approach cope variation overhead tasks 
approach detailed section 
address problem dependency time dedicated infrastructure monitoring system section 
section shows results evaluation proposed model production grid 

probabilistic model section investigate problem described considering random variable 
assume probabilistic density function random variable fg fh fh fh df dt fg fg fg problem formulated minimization respect expectation eh random variable eh fh dt fg fg dt fg fg dt fg fg dt 
application synthetic distributions section investigate problem analytically considering synthetic distributions order demonstrate relevance method controlled environment 
example assume uniformly distributed minimum value maximum value explicit solution provided fg fg eh dt eh result coherent eh execution time single cpu execution suffers penalty mean overhead introduced infrastructure 
lim eh infinite amount resources corresponds worst possible overhead introduced grid best computation time 
number submitted tasks increases probability tasks suffer high overhead increases 
lim eh limit eh zero corresponds execution task zero machine 
case execution time course tends infinity 
step minimization expectation consider derivative respect de dn nw de dn positive wand negative negative 
positive unique optimal number tasks minimizing eh wand configuration represented left graph plotted eh uniform distribution 
hand de dn eh strictly decreasing optimal number tasks corresponds maximal 
configuration represented right graph plotted eh uniform distribution 
de nw dn positive root optimal number tasks corresponds maximal 
conclude particular example relative variability grid overhead plays strong role optimization procedure actual mean low looking optimal job partitioning sense 
case seen fixed value respect problem straightforward explained 

representation eh uniform distribution suppose distribution gaussian mean standard deviation fg exp fg eh exp exp du exp du dt case relative variability overhead denoted minimizing eh hardly analytically feasible estimate minimum numerically 
example consider displays evolution eh respect different values ranging 
see figures higher relative variability deeper minimum eh conclude optimization procedure particularly suited environments high variability respect applying model synthetic distributions showed coherent particularly adapted 
eh gaussian distribution 
top bottom highly variable environments 
stated assume known 
section method estimate measures 

experimental distributions section describes method estimate measures 

measuring task times optimization method evaluation infrastructure latency pri mary goal determine robust procedure measure 
ideally grid infrastructure provide measure tasks submitted users 
user point view access statistics concerning tasks submitted infrastructure 
experimental method adopted submit waves dedicated ping tasks infrastructure 
tasks process probes measure grid latency monitoring submission scheduling queuing times 
main problem raises fact status infrastructure may disrupted measure 
submitting waves measure tasks cause additional load infrastructure leading inconsistent measures 
face problem initially submit limited set ping tasks instantaneously submit new time ping task completed total number measure tasks running infrastructure constant leading fixed perturbation 
grid potentially provides infinite number resources allows theoretical infinite number task submission real infrastructure limited maximum number simultaneous connections submission entity maximum number tasks scheduler 
empirically tuned number ping tasks trade accuracy measure induced overhead 
target grid infrastructure measure tasks 
true kind method quite unfair introduces significant overload infrastructure 
ultimately middleware provide users statistics computed submitted tasks method invasive 

timeouts real large scale multi users grid infrastructure task losses may occur waiting queues execution failures distant heterogeneous machines network problems 
setting timeout tasks required avoid unreasonable waiting times 
account timed tasks optimization procedure require propose fault tolerant system handling task 
know important problem part 
focus validation global principle decided neglect tasks measure scope validation study 
setting timeout tasks get consistent measures straightforward 
measure comes back infrastructure describes infrastructure status measure submission instant 
timeout 
examples inferior duration consider infrastructure status vary 
hand timeout large discard tasks 
experiments fixed timeout tasks total cpu time value task timed tasks ones lead slowing task grid execution 

estimating minimizing probabilistic density function latency measures step determine infrastructure latency considering ping measures gathering seconds bins 
obtaining corresponding straightforward 
provide idea overhead times sample examples instant displayed 
see strongly vary time 
notice distributions clearly gaussian 
mono modal symmetric respect mean 
estimated computation minimization eh straightforward section 
just computed eh ranging min max avg median seconds normalized table 
errors model measures maximum value corresponding maximum number tasks infrastructure single user interface 

experiments results 
infrastructure evaluated proposed model grid infrastructure provided egee european project platform offered pool thousands computing standard pcs storage resources accessible lcg middleware resources assembled computing centers running internal batch scheduler 
tasks submitted user interface central resource broker distributes available resources 
infrastructure strictly matches hypothesis section 
application point view infrastructure behaves batch scheduler information resources 

experiments experiments evaluate model egee infrastructure 
evaluated model capability correctly predict execution time set tasks grid infrastructure 
measured total execution time job having previously estimated time eh 
job composed tasks seconds long leading total cpu time seconds 
second quantified benefit induced model optimal strategy compared naive strategy consisting submitting maximal number tasks maximal strategy 
total cpu time submitted hand optimal number tasks resulting minimization eh hand fixed number tasks corresponds maximum number tasks submit concurrently infrastructure hitting performance loss 
avoid bias resulting evolution grid status submission processes alternatively repeated www eu egee org lcg web cern ch min max avg expected measured table 
time speed maximal optimal strategies strategies times various day times mornings nights spread week different resource brokers 

results experiment model vs measures 
table shows upper line statistics concerning difference seconds model prediction effective measure 
order quantify accuracy model normalized error predicted standard deviation random variable normalized table shows lower line minimum maximum average median ratios measured errors random variable notice median ratio close say measured error close standard deviation conclude proposed model effectively able predict execution time set tasks grid infrastructure 
experiment optimal strategy vs maximal strategy 
different experiment 
task saving experiments estimated optimal number tasks differed maximal times say experiments 
remaining correspond experiments computed optimal 
total number submitted tasks maximal strategy optimal 
see optimal strategy leads total saving tasks representing tasks submitted maximal strategy 
time speed table shows statistics executions differences seconds maximal optimal strategies cases computed optimal differs maximal 
negative values show maximal strategy faster optimal 
notice average speed introduced optimization strategy represents total submitted cpu time 
detailed strategy optimize job partitioning real grid infrastructure 
method takes account dynamic probabilistic nature infrastructure perpetually refreshing grid overhead minimizing expectation total task time 
show experimental results demonstrating significant speed ii substantial task saving obtained method 
parameters data transfer time random nature computing power resources considered model 
including partitioning strategy part 
plan consider timeouts fault tolerance elements order propose complete strategy optimization job partitioning grid infrastructure 

partially funded french research program aci masse de donn es labri fr project www aci org 
casanova berman wolski 
apples parameter sweep template user level middleware grid 
acm ieee conference supercomputing 
chr lenstra liu editors 
scheduling theory applications 
john wiley sons 
condor high throughput computing 
www cs wisc edu condor 
european ist project fp enabling grids escience apr mar 
www eu egee org 
feitelson rudolph 
parallel job scheduling status report 
th workshop job scheduling strategies parallel processing new york ny june 
foster kesselman 
globus metacomputing infrastructure toolkit 
international journal supercomputer applications 
breton loomis montagnat 
pennec 
medical image analysis 
th ieee acm international symposium cluster computing grid ccgrid bio grid workshop cardiff uk may 
ieee press 
hagerup 
allocating independent tasks parallel processors experimental study 
journal parallel distributed computing 
legion worldwide virtual computer 
legion virginia edu 
eles peng 
memory schedulability analysis task sets stochastic execution time 
th euromicro conference real time systems delft netherlands 
montagnat breton 
medical image databases content queries partitioning grid 
france jan 

optimal asymptotically optimal decision rules sequential screening resource allocation 
ieee transactions automatic control 
schopf berman 
stochastic scheduling 
supercomputing portland usa 

distributed indexation mammographic database grid 
international 
workshop grid computing science th annual acm international conference supercomputing san francisco usa june 
uniform interface computing resources 
sourceforge net 
weissman zhao 
scheduling parallel applications distributed networks 
journal cluster computing 
wolski 
dynamically forecasting network performance network weather service 
cluster computing 
