survey clustering data mining techniques pavel accrue software clustering division data groups similar objects 
representing data fewer clusters necessarily loses certain fine details achieves simplification 
models data clusters 
data modeling puts clustering historical perspective rooted mathematics statistics numerical analysis 
machine learning perspective clusters correspond hidden patterns search clusters unsupervised learning resulting system represents data concept 
practical perspective clustering plays outstanding role data mining applications scientific data exploration information retrieval text mining spatial database applications web analysis crm marketing medical diagnostics computational biology 
clustering subject active research fields statistics pattern recognition machine learning 
survey focuses clustering data mining 
data mining adds clustering complications large datasets attributes different types 
imposes unique computational requirements relevant clustering algorithms 
variety algorithms emerged meet requirements successfully applied real life data mining problems 
subject survey 
content categories subject descriptors 
artificial intelligence learning concept learning image processing segmentation pattern recognition models pattern recognition clustering 
general terms algorithms design additional key words phrases clustering partitioning data mining unsupervised learning descriptive learning exploratory data analysis hierarchical clustering probabilistic clustering means 

notations 
clustering bibliography glance 
classification clustering algorithms 
plan presentation author address pavel accrue software forest dr san jose ca mail accrue com 
hierarchical clustering 
linkage metrics 
hierarchical clusters arbitrary shapes 
binary divisive partitioning 
developments 
partitioning relocation clustering 
probabilistic clustering 
medoids methods 
means methods 
density partitioning 
density connectivity 
density functions 
grid methods 
occurrence categorical data 
clustering techniques 
constraint clustering 
relation supervised learning 
gradient descent artificial neural networks 
evolutionary methods 
developments 
scalability vldb extensions 
clustering high dimensional data 
dimensionality reduction 
subspace clustering 
clustering 
general algorithmic issues 
assessment results 
clusters 

data preparation 
proximity measures 
handling outliers 
goal survey provide comprehensive review different clustering techniques data mining 
clustering division data groups similar objects 
group called cluster consists objects similar dissimilar objects groups 
representing data fewer clusters necessarily loses certain fine details akin lossy data compression achieves simplification 
represents data objects clusters models data clusters 
data modeling puts clustering historical perspective rooted mathematics statistics numerical analysis 
machine learning perspective clusters correspond hidden patterns search clusters unsupervised learning resulting system represents data concept 
clustering unsupervised learning hidden data concept 
data mining deals large databases impose clustering analysis additional severe computational requirements 
challenges led emergence powerful broadly applicable data mining clustering methods surveyed 

notations fix context clarify prolific terminology consider dataset consisting data points synonymously objects instances cases patterns tuples transactions xi xi xid attribute space component numerical nominal categorical attribute synonymously feature variable dimension component field 
discussion attributes data types see han kamber 
point attribute data format conceptually corresponds matrix majority algorithms reviewed 
data formats variable length sequences heterogeneous data popular 
simplest attribute space subset direct cartesian product subranges cl called segment cube cell region 
unit elementary segment sub ranges consist single category value small numerical bin 
describing numbers data points unit represents extreme case clustering histogram actual clustering takes place 
expensive representation revealing 
user driven segmentation commonly practice data exploration utilizes expert knowledge regarding importance certain sub domains 
distinguish clustering segmentation emphasize importance automatic learning process 
il cl ultimate goal clustering assign points finite system subsets clusters 
usually subsets intersect assumption violated union equal full dataset possible exception outliers 
clustering bibliography glance general regarding clustering include hartigan spath jain dubes kaufman rousseeuw dubes everitt jain han ghosh 
contemporary data mining clustering techniques textbook han kamber 
close relationship clustering techniques disciplines 
clustering statistics arabie hubert science massart kaufman 
classic pattern recognition framework duda hart 
typical applications include speech character recognition 
machine learning clustering algorithms applied image segmentation computer vision jain flynn 
statistical approaches pattern recognition see dempster fukunaga 
clustering viewed density estimation problem 
subject traditional multivariate statistical estimation scott 
clustering widely data compression image processing known vector quantization gersho gray 
data fitting numerical analysis provides venue data modeling daniel wood 
survey emphasis clustering data mining 
clustering characterized large datasets attributes different types 
try review particular applications important ideas related specific fields 
clustering data mining brought life intense developments information retrieval text mining cutting steinbach dhillon spatial database applications example gis astronomical data xu sander ester sequence heterogeneous data analysis cadez web applications cooley chi foss dna analysis computational biology ben dor yakhini 
resulted large amount application specific developments scope general techniques 
techniques classic clustering algorithms relate surveyed 

classification clustering algorithms categorization clustering algorithms straightforward canonical 
reality groups overlap 
reader convenience provide classification closely followed survey 
corresponding terms explained 
clustering algorithms hierarchical methods agglomerative algorithms divisive algorithms partitioning methods relocation algorithms probabilistic clustering medoids methods means methods density algorithms density connectivity clustering density functions clustering grid methods methods occurrence categorical data constraint clustering clustering algorithms machine learning gradient descent artificial neural networks evolutionary methods scalable clustering algorithms algorithms high dimensional data subspace clustering projection techniques clustering techniques 
plan presentation traditionally clustering techniques broadly divided hierarchical partitioning 
hierarchical clustering subdivided agglomerative divisive 
basics hierarchical clustering include lance williams formula idea conceptual clustering classic algorithms cobweb newer algorithms cure chameleon 
survey section hierarchical clustering 
hierarchical algorithms build clusters gradually crystals grown partitioning algorithms learn clusters directly 
doing try discover clusters iteratively relocating points subsets try identify clusters areas highly populated data 
algorithms kind surveyed section partitioning relocation methods 
categorized probabilistic clustering em framework algorithms autoclass medoids methods algorithms pam clara clarans extension means methods different schemes initialization optimization harmonic means extensions 
methods concentrate points fit clusters tend build clusters proper convex shapes 
partitioning algorithms second type surveyed section density partitioning 
try discover dense connected components data flexible terms shape 
density connectivity algorithms dbscan optics algorithm exploits space density functions 
algorithms sensitive outliers discover clusters irregular shapes 
usually low dimensional data numerical attributes known spatial data 
spatial objects include points extended objects algorithm 
algorithms data indirectly constructing summaries data attribute space subsets 
perform space segmentation aggregate appropriate segments 
discuss section grid methods 
frequently hierarchical agglomeration phase processing 
algorithms bang sting idea fractal dimension discussed section 
grid methods fast handle outliers 
grid methodology step algorithms example clique mafia 
categorical data intimately connected transactional databases 
concept similarity sufficient clustering data 
idea categorical data cooccurrence comes rescue 
algorithms rock snn cactus surveyed section occurrence categorical data 
situation gets aggravated growth number items involved 
help problem effort shifted data clustering pre clustering items categorical attribute values 
development hyper graph partitioning algorithm exemplify approach 
clustering techniques developed primarily machine learning theoretical significance traditionally outside data mining community fit previously outlined categories 
boundary blurred 
section clustering techniques discuss relationship supervised learning gradient descent ann som evolutionary methods simulated annealing genetic algorithms ga algorithm amoeba 
start emerging field constraint clustering influenced requirements realworld data mining applications 
data mining primarily works large databases 
clustering large datasets presents scalability problems reviewed section scalability vldb extensions 
talk algorithms birch data squashing techniques chernoff bounds 
trait real life data high dimensionality 
corresponding developments surveyed section clustering high dimensional data 
trouble comes decrease metric separation dimension grows 
approach dimensionality reduction uses attributes transformations dft pca wavelets 
way address problem subspace clustering algorithms clique mafia enclus proclus orclus 
approach clusters attributes groups uses derived proxies cluster objects 
double clustering known 
issues common different clustering methods overviewed section general algorithmic issues 
talk assessment results determination appropriate number clusters build data preprocessing attribute selection data scaling special data indices proximity measures handling outliers 

important issues properties clustering algorithms concerned data mining 
properties include type attributes algorithm handle scalability large datasets ability high dimensional data ability find clusters irregular shape handling outliers time complexity confusion term complexity data order dependency labeling assignment hard strict vs soft fuzzy reliance priori knowledge user defined parameters interpretability results try keep issues mind realistically mention algorithm discuss 
list way exhaustive 
example discuss properties ability pre defined memory buffer ability restart ability provide intermediate solution 

hierarchical clustering hierarchical clustering builds cluster hierarchy words tree clusters known dendrogram 
cluster node contains child clusters sibling clusters partition points covered common parent 
approach allows exploring data different levels granularity 
hierarchical clustering methods categorized agglomerative bottom divisive top jain dubes kaufman rousseeuw 
agglomerative clustering starts point singleton clusters recursively merges appropriate clusters 
divisive clustering starts cluster data points recursively splits appropriate cluster 
process continues stopping criterion frequently requested number clusters achieved 
advantages hierarchical clustering include embedded flexibility regarding level granularity ease handling forms similarity distance consequently applicability attribute types disadvantages hierarchical clustering related vagueness termination criteria fact hierarchical algorithms revisit constructed intermediate clusters purpose improvement classic approaches hierarchical clustering sub section linkage metrics 
hierarchical clustering linkage metrics results clusters proper convex shapes 
active contemporary efforts build cluster systems incorporate intuitive concept clusters connected components arbitrary shape including algorithms cure chameleon surveyed sub section hierarchical clusters arbitrary shapes 
divisive techniques binary taxonomies sub section binary divisive partitioning 
sub section developments contains information related incremental learning model clustering cluster refinement 
hierarchical clustering regular point attribute data representation secondary importance 
hierarchical clustering frequently deals matrix distances dissimilarities similarities training points 
called connectivity matrix 
linkage metrics constructed see elements matrix 
requirement keeping large matrix memory unrealistic 
relax limitation different devices introduce connectivity matrix sparsity 
done omitting entries smaller certain threshold certain subset data representatives keeping point certain number nearest neighbors 
example nearest neighbor chains decisive impact memory consumption olson 
sparse matrix represent intuitive concepts closeness connectivity 
notice way process original dis similarity matrix construct linkage metric reflects priori ideas data model 
connectivity matrix associate connectivity graph vertices data points edges weights pairs points corresponding positive matrix entries 
establishes connection hierarchical clustering graph partitioning 
striking developments hierarchical clustering algorithm birch 
scalability major achievement blend strategy algorithm discussed section scalable vldb extensions 
data squashing birch achieve scalability independent importance 
hierarchical clustering large datasets sub optimal data fits memory 
compressing data may improve performance hierarchical algorithms 

linkage metrics hierarchical clustering initializes cluster system set singleton clusters agglomerative case single cluster points divisive case proceeds iteratively merging splitting appropriate cluster stopping criterion achieved 
appropriateness cluster merging splitting depends dis similarity cluster elements 
reflects general presumption clusters consist similar points 
important example dissimilarity points distance 
proximity measures discussed section general algorithm issues 
merge split subsets points individual points distance individual points generalized distance subsets 
derived proximity measure called linkage metric 
type linkage metric significantly affects hierarchical algorithms reflects particular concept closeness connectivity 
major inter cluster linkage metrics murtagh olson include single link average link complete link 
underlying dissimilarity measure usually distance computed pair points point set point second set 
specific operation minimum single link average average link maximum complete link applied pair wise dissimilarity measures operation early examples include algorithm sibson implements single link voorhees method voorhees implements average link algorithm clink implements complete link 
referenced 
related problem finding euclidean minimal spanning tree yao complexity 
methods inter cluster distances defined terms pairs points respective clusters subsets called graph methods 
cluster representation set points 
name naturally relates connectivity graph introduced data partition corresponds graph partition 
methods appended called geometric methods cluster represented central point 
results centroid median minimum variance linkage metrics 
assumption numerical attributes center point defined centroid average cluster centroids subject agglomeration 
linkage metrics derived instances lance williams updating formula lance williams ci ck ci ck ck bd ci ci ck ck coefficients corresponding particular linkage 
formula expresses linkage metric union clusters third cluster terms underlying components 
lance williams formula utmost importance manipulation dis similarity computationally feasible 
survey linkage metrics murtagh day edelsbrunner 
base measure distance methods capture inter cluster closeness 
similaritybased view results intra cluster connectivity considerations possible 
original average link agglomeration group average method jain dubes introduced 
linkage metrics hierarchical clustering suffers time complexity 
reasonable assumptions reducibility condition graph methods satisfy condition linkage metrics methods complexity olson 
despite unfavorable time complexity algorithms widely 
example algorithm nesting kaufman rousseeuw plus 
connectivity matrix graph methods directly dealing connectivity graph 
particular hierarchical divisive mst minimum spanning tree algorithm graph partitioning jain dubes 

hierarchical clusters arbitrary shapes linkage metrics euclidean distance hierarchical clustering spatial data naturally clusters proper convex shapes 
visual scanning spatial images frequently attests clusters appearance 
guha introduced hierarchical agglomerative clustering algorithm cure clustering representatives 
algorithm number novel features general significance 
takes special care outliers label assignment stage 
uses devices achieve scalability 
data sampling section scalability vldb extensions 
second device data partitioning partitions fine granularity clusters constructed partitions 
major feature cure represents cluster fixed number points scattered 
distance clusters agglomerative process equal minimum distances scattered representatives 
cure takes approach graph points methods geometric centroid methods 
single average link closeness replaced representatives aggregate closeness 
selecting representatives scattered cluster possible cover non spherical shapes 
agglomeration continues requested number clusters achieved 
cure employs additional device originally selected scattered points shrunk geometric centroid cluster user specified factor 
shrinkage suppresses affect outliers outliers happen located cluster centroid scattered representatives 
cure capable finding clusters different shapes sizes insensitive outliers 
cure uses sampling estimation complexity straightforward 
low dimensional data authors provide complexity estimate defined terms sample size 
exact bounds depend input parameters shrink factor number representative points number partitions sample size 
illustrates agglomeration cure 
clusters representatives shown merge shrinkage 
closest representatives connected arrow 
sample algorithm cure works numerical attributes particularly low dimensional spatial data algorithm rock developed researchers guha targets hierarchical agglomerative clustering categorical attributes 
surveyed section occurrence categorical data 
hierarchical agglomerative algorithm chameleon karypis utilizes dynamic modeling cluster aggregation 
uses connectivity graph corresponding nearest neighbor model sparsification connectivity matrix edges similar points point preserved rest pruned 
chameleon stages 
stage small tight clusters built ignite second stage 
involves graph partitioning karypis kumar 
second stage agglomerative process performed 
utilizes measures relative inter connectivity ri ci relative closeness rc ci locally normalized quantities related clusters sense modeling dynamic 
normalization involves certain non obvious graph operations karypis kumar 
chameleon strongly relies graph partitioning implemented library hmetis see section occurrence categorical data 
agglomerative process depends user provided thresholds 
decision merge combination ri ci rc ci local relative measures 
algorithm depend assumptions data model 
algorithm proven find clusters different shapes densities sizes dimensional space 
complexity nm log log number sub clusters built initialization phase 
analogous karypis kumar presents choice clusters merge 
cure merge clusters chameleon intuitively better choice merging 
agglomeration cure 
chameleon merges 

binary divisive partitioning linguistics information retrieval document clustering applications binary taxonomies useful 
linear algebra methods singular value decomposition svd purpose collaborative filtering information retrieval berry browne 
svd application hierarchical divisive clustering document collections resulted pddp principal direction divisive partitioning algorithm boley 
notations object document th attribute corresponds word index term matrix entry measure tf idf term frequency document pddp constructs svd decomposition matrix ex 
algorithm bisects data euclidean space hyperplane passes data centroid orthogonally eigenvector largest singular value 
way splitting possible largest singular values considered 
bisecting way categorize documents results binary tree 
means means bisecting dividing hyperplane orthogonal line connecting centroids 
comparative study approaches boley 
hierarchical divisive bisecting means proven steinbach preferable document clustering 
pddp means concerned split cluster problem cluster split important 
casual strategies split node level split cluster highest cardinality split cluster largest intra cluster variance 
strategies problems 
analysis regarding subject better alternatives see 

developments ward method ward implements agglomerative clustering linkage metric objective function means sub section means methods 
merger decision viewed terms effect objective function 
popular hierarchical clustering algorithm categorical data cobweb fisher important qualities 
utilizes incremental learning 
divisive agglomerative approaches dynamically builds dendrogram processing data point time 
second cobweb belongs conceptual modelbased learning 
means cluster considered model described intrinsically collection points assigned 
cobweb dendrogram called classification tree 
tree node cluster associated conditional probabilities categorical attribute values pairs pr lp easily recognized specific na bayes classifier 
classification tree construction new point descended tree tree potentially updated insert split merge create operation 
decisions analysis category utility gluck cu cu cu pr lp pr similar gini index 
rewards clusters increases predictability categorical attribute values lp incremental cobweb fast complexity tn depends non linearly tree characteristics packed constant similar incremental hierarchical algorithm numerical attributes called gennari 
associates normal distributions cluster nodes 
algorithms result highly unbalanced trees 
chiu proposed conceptual model approach hierarchical clustering 
development contains different useful features extension birch preprocessing categorical attributes outliers handling step strategy monitoring number clusters including bic defined 
model associated cluster covers numerical categorical attributes constitutes blend gaussian multinomial models 
denote corresponding multivariate parameters cluster associate logarithm classification likelihood lc xi log algorithm uses maximum likelihood estimates parameter 
distance clusters defined linkage metric decrease log likelihood lc caused merging clusters consideration 
agglomerative process continues stopping criterion satisfied 
determination best automatic 
algorithm commercial implementation spss 
complexity algorithm linear summarization phase 
traditional hierarchical clustering inflexible due greedy approach merge split selected refined 
cobweb reconsider decisions inexpensive resulting classification tree sub par quality 
fisher studied iterative hierarchical cluster redistribution improve constructed dendrogram 
karypis researched refinement hierarchical clustering 
particular brought attention relation refinement studied refinement way graph partitioning kernighan lin 
related parallel implementation hierarchical clustering see olson 

partitioning relocation clustering section survey data partitioning algorithms divide data subsets 
checking possible subset systems computationally infeasible certain greedy heuristics form iterative optimization 
specifically means different relocation schemes iteratively reassign points clusters 
traditional hierarchical methods clusters revisited constructed relocation algorithms gradually improve clusters 
appropriate data results high quality clusters 
approach data partitioning take conceptual point view identifies cluster certain model unknown parameters 
specifically probabilistic models assume data comes mixture populations distributions priors want find 
corresponding algorithms described sub section probabilistic clustering 
clear advantage probabilistic methods interpretability constructed clusters 
having concise cluster representation allows inexpensive computation intra clusters measures fit give rise global objective function see log likelihood 
approach starts definition objective function depending partition 
seen sub section linkage metrics pair wise distances similarities compute measures iter intra cluster relations 
iterative improvements pair wise computations expensive 
unique cluster representatives resolves problem computation objective function linear number clusters 
depending representatives constructed iterative optimization partitioning algorithms subdivided medoids means methods 
medoid appropriate data point cluster represents 
representation medoids advantages 
presents limitations attributes types second choice medoids dictated location predominant fraction points inside cluster lesser sensitive presence outliers 
means case cluster represented centroid mean usually weighted average points cluster 
works conveniently numerical attributes negatively affected single outlier 
hand centroids advantage clear geometric statistical meaning 
corresponding algorithms reviewed sub sections medoids methods means methods 

probabilistic clustering probabilistic approach data considered sample independently drawn mixture model probability distributions mclachlan basford 
main assumption data points generated randomly picking model probability second drawing point corresponding distribution 
area mean supposedly unimodal distribution constitutes natural cluster 
associate cluster corresponding distribution parameters mean variance data point carries observable attributes hidden cluster id class pattern recognition 
point assumed belong cluster estimate th probabilities assignment pr model 
likelihood training data probability drawn mixture model pr log likelihood log serves objective function gives rise expectation maximization em method 
quick em see mitchell 
detailed descriptions numerous regarding topic dempster mclachlan krishnan 
em step iterative optimization 
step estimates probabilities pr equivalent soft fuzzy reassignment 
step finds approximation mixture model current soft assignments 
boils finding mixture model parameters maximize log likelihood 
process continues log likelihood convergence achieved 
restarting tricks facilitate finding better local optimum 
moore suggested acceleration em method special data index kd tree 
data divided node descendents splitting widest attribute center range 
node stores sufficient statistics including covariance matrix similar birch 
approximate computing pruned tree accelerates em iterations 
probabilistic clustering important features modified handle complex structure stopped resumed consecutive batches data clusters representation totally different sets points stage iterative process intermediate mixture model assign cases line property results easily interpretable cluster system mixture model clear probabilistic foundation determination suitable number clusters tractable task 
data mining perspective excessive parameter set causes overfitting probabilistic perspective number parameters addressed bayesian framework 
see sub section clusters details including terms mml bic paragraph 
algorithm wallace dowe uses mixture model conjunction mml principle 
algorithm autoclass cheeseman stutz utilizes mixture model covers broad variety distributions including bernoulli poisson gaussian log normal distributions 
fitting particular fixed mixture model autoclass extends search different models different autoclass heavily relies bayesian methodology model complexity reflected certain coefficients priors expression likelihood previously dependent parameters values 
algorithm history industrial usage 
algorithm fraley raftery software package commercially linked plus hierarchical mixture model clustering discriminant analysis bic estimation goodness fit 
uses gaussian models ellipsoids different volumes shapes orientations 
important property probabilistic clustering mixture model naturally generalized clustering heterogeneous data 
important practice individual data object multivariate static data demographics combination variable length dynamic data customer profile smyth 
dynamic data consist finite sequences subject order markov model transition matrix dependent cluster 
framework covers data objects consisting sequences number sequences xi subject geometric distribution cadez 
emulate sessions different lengths finite state markov model transitional probabilities web site pages augmented special state 
cadez mixture model customer profiling transactional information 
model clustering hierarchical framework cobweb development chiu 
early example conceptual clustering algorithm cluster michalski stepp 

medoids methods medoids methods cluster represented points 
mentioned easy solution covers attribute types medoids embedded resistance outliers peripheral cluster points affect 
medoids selected clusters defined subsets points close respective medoids objective function defined averaged distance dissimilarity measure point medoid 
early versions medoid methods algorithm pam partitioning medoids algorithm clara clustering large applications kaufman rousseeuw 
pam iterative optimization combines relocation points perspective clusters re points potential medoids 
guiding principle process effect objective function obviously costly strategy 
clara uses samples points subjected pam 
dataset assigned resulting medoids objective function computed best system medoids retained 
progress associated ng han introduced algorithm clarans clustering large applications randomized search context clustering spatial databases 
authors considered graph nodes sets medoids edge connects nodes differ exactly medoid 
clara compares neighbors corresponding fixed small sample clarans uses random search generate neighbors starting arbitrary node randomly checking neighbors 
neighbor represents better partition process continues new node 
local minimum algorithm restarts local minima value recommended 
best node set medoids returned formation resulting partition 
complexity clarans terms number points 
ester extended clarans spatial vldb 
trees beckmann relax original requirement data resides core memory allowed focusing exploration relevant part database resides branch data tree 

means methods means algorithm hartigan hartigan wong far popular clustering tool scientific industrial applications 
name comes representing clusters mean weighted average points called centroid 
obviously categorical attributes geometric statistical sense numerical attributes 
sum discrepancies point centroid expressed appropriate distance objective function 
example norm objective function sum squares errors points corresponding centroids equal total intra cluster variance 
xi sum squares errors negative log likelihood normally distributed mixture model widely statistics sse 
means algorithm derived general probabilistic framework see sub section probabilistic clustering mitchell 
note means estimated 
simple modification normalize individual errors cluster radii cluster standard deviation lot sense clusters different 
objective function norm unique algebraic properties 
example coincides pair wise errors yi difference total data variance inter cluster variance 
cluster separation achieved simultaneously cluster tightness 
versions means iterative optimization known 
version similar em algorithm consists step major iterations reassign points nearest centroids recompute centroids newly assembled groups 
iterations continue stopping criterion achieved example happen 
version known forgy algorithm forgy advantages easily works lp norm allows straightforward parallelization dhillon modha insensitive respect data ordering 
second classic iterative optimization version means iterative optimization points detailed analysis effects objective function caused moving point current cluster potentially new 
move positive effect point relocated centroids recomputed 
clear version computationally feasible outlined analysis requires inner loop member points involved clusters affected centroids shifts 
case known duda hart computations algebraically reduced simply computing single distance 
case versions computational complexity 
experimental evidence compared forgy algorithm second classic version frequently yields better results larsen aone steinbach 
particular dhillon noticed forgy spherical means cosine similarity euclidean distance tendency get stuck applied document collections 
noticed version reassigning points immediately recomputing centroids works better 
illustrates implementations 
versions attempts find minimum means objective function 
example early algorithm isodata ball hall merges splits intermediate clusters 
wide popularity means algorithm deserved 
simple straightforward firm foundation analysis variances 
means algorithm suffers usual suspects result strongly depends initial guess centroids assignments computed local optimum known far cry global obvious process sensitive respect outliers algorithm lacks scalability numerical attributes covered resulting clusters unbalanced forgy version empty reassign points recompute centroids step major iterations forgy algorithm point assignment changed 
iterative optimization centroid recomputation simple way mitigate affects clusters initialization suggested bradley fayyad 
means performed small samples data random initial guess 
constructed systems potential initialization union samples 
centroids best system constructed way suggested intelligent initial guesses ignite means algorithm full data 
interesting attempt babu murty ga see 
initialization guarantees global minimum means 
common combinatorial optimization logical attempt cure problem simulated annealing brown 
zhang suggested way rectify optimization process soft assignment points different clusters appropriate weights em moving decisively cluster 
weights take account point fits recipient clusters 
process involves called harmonic means 
discuss scalability issues section scalability vldb extensions 
comprehensive approach relation means see excellent study bradley 
generic method achieve scalability preprocess squash data 
preprocessing usually takes care outliers 
preprocessing drawbacks 
results approximations negatively affect final cluster quality 
pelleg moore suggested directly squashing accelerate means iterative process utilizing kd trees moore 
algorithm means pelleg moore goes step addition accelerating iterative process tries incorporate search best process 
comprehensive criteria discussed sub section clusters require running independent means comparing results costly means tries split part constructed cluster outcome bic criterion 
gives better initial guess iteration covers user specified range admissible tremendous popularity means algorithm brought life extensions modifications 
mahalanobis distance cover clusters mao jain 
maximum intra cluster variances sum serve objective function gonzales 
generalizations incorporate categorical attributes known 
term prototypes context huang 
modifications constructs clusters balanced size discussed sub section constrained clustering 

density partitioning open set euclidean space divided set connected components 
implementation idea partitioning finite set points requires concepts density connectivity boundary 
closely related point nearest neighbors 
cluster defined connected dense component grows direction density leads 
density algorithms capable discovering clusters arbitrary shapes 
provides natural protection outliers 
illustrates cluster shapes problem partitioning relocation clustering means handled properly density algorithms 
scalability 
outstanding properties tempered certain 
general data description point view single dense cluster consisting adjacent areas significantly different densities higher threshold informative 
drawback lack interpretability 

irregular shapes difficult means excellent methods contained textbook han kamber 
density algorithms require metric space natural setting spatial data clustering han 
computations feasible index data constructed tree 
topic active research 
classic indices effective reasonably low dimensional data 
algorithm fact blend density clustering grid preprocessing lesser affected data dimensionality 
major approaches density methods 
approach pins density training data point reviewed sub section density connectivity 
representative algorithms include dbscan optics 
second approach pins density point attribute space explained sub section density functions 
includes algorithm 

density connectivity crucial concepts section density connectivity measured terms local distribution nearest neighbors 
algorithm dbscan density spatial clustering applications noise ester targeting low dimensional spatial data major representative category 
input parameters minpts define neighborhood point core object point neighborhood consisting minpts points concept point density reachable core object finite sequence core objects exists belongs neighborhood predecessor density connectivity points density reachable common core object 
defined density connectivity symmetric relation points reachable core objects factorized maximal connected components serving clusters 
points connected core point declared outliers covered cluster 
non core points inside cluster represent boundary 
core objects internal points 
processing independent data ordering 
far requires limitations dimension attribute types 
obviously effective computing neighborhoods presents problem 
case lowdimensional spatial data different effective indexation schemes exist meaning log fetches search 
dbscan relies tree indexation kriegel 
low dimensional spatial data theoretical complexity dbscan log experiments confirm slight super linear runtime 
notice dbscan relies neighborhoods frequency count neighborhoods define concept core object 
spatial databases contain extended objects polygons points 
reflexive symmetric predicate example polygons non empty intersection suffice define neighborhood 
additional measures intensity point simple count 
generalizations lead algorithm sander uses parameters algorithm dbscan 
regard parameters minpts straightforward way fit data 
different parts data require different parameters problem discussed earlier conjunction chameleon 
algorithm optics ordering points identify clustering structure ankerst adjusts dbscan challenge 
builds augmented ordering data consistent dbscan goes step keeping parameters minpts optics covers spectrum different constructed ordering automatically interactively 
point optics stores additional fields called core reachability distances 
example core distance distance minpts nearest neighbor exceeds undefined 
experimentally optics exhibits runtime roughly equal dbscan runtime 
optics considered dbscan extension direction different local densities mathematically sound approach consider random variable equal distance point nearest neighbor learn probability distribution 
relying user defined parameters possible cluster typical distance nearest neighbor scale 
goal discover scales 
nonparametric approach implemented algorithm distribution clustering large spatial databases xu 
assuming points inside cluster uniformly distributed may may realistic defines cluster non empty arbitrary shape subset expected distribution distance nearest neighbor required confidence maximal connected set quality 
algorithm handles spatial data example 
test check distribution requirement standard consequence requirement cluster points 
regarding connectivity relies grid approach generate polygons 
algorithm contains devices handling real databases noise implements incremental unsupervised learning 
venues 
assignments final points change cluster membership 
second certain points noise assigned tried 
incrementally fetched points revisited internally 
known run faster clarans factor examples 
comparison efficient dbscan times slower 
requires user input empirical search appropriate parameter requires dbscan runs 
addition discovers clusters different densities 

density functions hinneburg keim shifted emphasis computing densities pinned data points computing density functions defined underlying attribute space 
proposed algorithm density clustering 
firm mathematical foundation 
uses density function superposition influence functions 
term depends formula recognized convolution kernel 
examples include square wave function equal distance equal gaussian influence function provides high level generality example leads dbscan second means clusters 
examples depend parameter 
restricting summation enables practical implementation 
concentrates local maxima density functions called density attractors uses flavor gradient hill climbing technique finding 
addition center defined clusters arbitrary shape clusters defined continuations sequences points local densities prescribed threshold 
algorithm stable respect outliers authors show choose parameters 
scales initial stage builds map hyper rectangle cubes edge length 
reason algorithm classified grid method 
applications include high dimensional multimedia molecular biology data 
clustering algorithm complexity runtime scales sub linearly 
explanation points fetched bulk analysis clustering stage involves points highly populated areas 

grid methods previous section crucial concepts density connectivity boundary required elaborate definitions 
way dealing inherit topology underlying attribute space 
limit search combinations segments considered 
recall segment cube cell region 
direct cartesian product individual attribute sub ranges contiguous case numerical attributes 
binning usually adopted numerical attributes methods partitioning space frequently called grid methods 
elementary segment corresponding single bin single value sub ranges called unit 
shift attention data space partitioning 
data partitioning induced points membership segments resulted space partitioning space partitioning grid characteristics accumulated input data 
advantage indirect handling data grid data space partitioning data partitioning accumulation grid data grid clustering techniques independent data ordering 
contrast relocation methods incremental algorithms sensitive respect data ordering 
density partitioning methods best numerical attributes grid methods attributes different types 
extent grid methodology reflects technical point view 
category eclectic contains partitioning hierarchical algorithms 
algorithm previous section uses grids initial stage 
important grid algorithm clique descendent algorithm mafia section clustering high dimensional data 
section survey algorithms grid technique major principle instrument 
bang clustering improves similar hierarchical algorithm 
grid segments summarize data 
segments stored special bang structure grid directory incorporating different scales 
adjacent segments neighbors 
common face maximum dimension called nearest neighbors 
generally neighbors degree defined 
density segment defined ratio number points volume 
grid directory dendrogram directly calculated 
algorithm sting statistical information grid method wang works numerical attributes spatial data designed facilitate region oriented queries 
doing sting constructs data summaries way similar birch 
assembles statistics hierarchical tree nodes grid cells 
presents proliferation cells dimensional space construction corresponding tree 
cell default children stores point count attribute dependent measures mean standard deviation minimum maximum distribution type 
measures accumulated starting bottom level cells propagate higher level cells minimum equal minimum children minimums 
distribution type presents problem test bottom cell distribution types 
cell tree constructed time certain cells identified connected clusters similar dbscan 
number leaves cluster construction phase depends algorithm simple structure suitable parallelization allows multiresolution defining appropriate granularity straightforward 
sting enhanced algorithm sting wang targets dynamically evolving spatial databases uses similar hierarchical cell organization predecessor 
addition sting enables active data mining 

cell generation tree construction sting 
supports user defined trigger conditions region cellular phones square mile total area square miles usage drops described region 
related measures sub triggers stored updated hierarchical cell tree 
suspended trigger fires user defined action 
types conditions supported absolute relative conditions regions set adjacent cells absolute relative conditions certain attributes 
algorithm works numerical attributes advanced multi resolution 
known outstanding properties high quality clusters ability relatively high dimensional spatial data successful handling outliers complexity ideas signal processing 
applies wavelet transforms filter data 
notice high frequency parts signal correspond boundaries low frequency high amplitude parts signal correspond clusters interiors 
wavelet transform provides useful filters 
example hat shape filter forces dense areas serve attractors simultaneously suppresses lesser dense boundary areas 
getting back signal attribute space clusters sharp eliminates outliers 
goes stages 
bins dimension assigns points corresponding units applies discrete wavelet transform accumulated units finds connected components clusters transformed attribute space corresponding certain level resolution assigns points algorithm complexity dimension 
low dimensions exponentially grows hierarchy grids allows definition hausdorff fractal dimension 
set negative slope log log plot number cells cell occupied set function grid size fast algorithm box counting compute introduced toth 
concept fundamental fc fractal clustering algorithm barbara chen numeric attributes works layers grids cardinality dimension increased times layer 
occupied cells kept save memory memory usage significant problem 
fc starts initializing clusters 
initialization threshold data sample stage come appropriate fc scans full data incrementally 
tries add incoming point cluster results certain increase 
smallest increase exceeds threshold point declared outlier point assigned minimally impacted 
fc algorithm appealing properties incremental structure batches data fetched core memory nature ready line assignments ability discover clusters irregular shapes complexity problems data order dependency strong dependency clusters initialization dependency parameters threshold initialization 
occurrence categorical data section talk categorical data frequently relates concept variable size transaction finite set elements called items common item universe 
example market basket data form 
transaction point attribute format enumerating items associating transaction binary attributes indicate items belong transaction 
representation sparse random transactions items common 
similarity sub section proximity measures usually measured jaccard coefficient sim common examples point attribute format categorical data high dimensionality significant amount zero values small number common values objects 
conventional clustering methods similarity measures 
categorical transactional data important customer profiling assortment planning web analysis applications different clustering methods founded idea occurrence categorical data developed 
algorithm rock robust clustering algorithm categorical data guha deals categorical data common features algorithm cure section hierarchical clustering hierarchical clustering agglomeration continues specified number clusters constructed uses data sampling way cure 
rock defines neighbor point point sim threshold proceeds definition links link points equal number common neighbors 
clusters consist points high degree connectivity pair wise points inside cluster average high number links 
rock utilizes objective function link data dependent function 
represents specifically normalized measure 
put formula perspective notice linkage metrics normalize aggregate measures number edges 
example average link metric sum distances point point divided factor value general level 
expected number edges cluster aggregate inter cluster similarity normalized factor representing number intercluster edges 
average link normalization factor corresponds highest expected connectivity 
rock objective function uses idea fits parameters 
model fits particular data open question 
frequently different regions data different properties global fit impossible 
rock relies input parameter function fit data 
complexity sample sample log coefficient product average maximum number neighbors 
algorithm snn shared nearest neighbors blends approach idea rock 
snn similarity matrix unfortunately resulting complexity keeping nearest neighbors derives total strength links matter idea shared nearest neighbors clustering suggested jarvis patrick long ago 
see krishna 
algorithm cactus clustering categorical data summaries ganti looks hyper rectangular clusters called interval regions point attribute data categorical attributes 
terminology clusters segments 
cactus idea occurrence attribute value pairs 
implicitly uniform distribution range values attribute assumed 
values different attributes strongly connected number data points having larger frequency expected independency assumption userdefined margin 
definition extended subsets different attributes value pair strongly connected segments projection strongly connected similarity pair values single attribute connectivity attributes 
cluster defined maximal strongly connected segment having times elements expected segment attributes independency assumption 
cactus uses data summaries generate strongly connected similar attribute value pairs 
second step heuristic generate maximum segments 
complexity summarization phase cn constant depends attribute value summaries fit memory data scan multiple data scans 
situation clustering transactional data aggravated size item universe grows 
classic case low separation high dimensional space section clustering high dimensional data 
categorical data idea auxiliary clustering items generally categorical attribute values gained popularity 
similar idea clustering sub section clustering 
formally speaking preprocessing step major concern data clustering remains lesser issue 
start development han exemplifies approach 
items clustered major step simple method cluster transactions transaction assigned cluster items having common defined function choices come mind primary objective find item groups 
achieve association rules hypergraph 
frequent item sets generated transactional data 
hyper graph associated item universe vertices items 
common graph pairs vertices connected edges hypergraph vertices connected hyper edges 
hyper edge corresponds frequent item set vs weight equal average confidences association rules involving item set 
solution problem way partitioning hyper graph provided algorithm hmetis karypis 
algorithm sieving iterated gibson deals occurrence dimensional categorical objects tuples 
extension transactional data obvious 
uses beautiful technique functional analysis 
define configurations weights wv different values attributes 
consider example value attribute 
tuples containing result weight update wv terms depend combining operator example combining operator weight redistributed different values 
major iteration scans data results propagation weights different nodes equal described update followed normalization weights values attribute 
function considered dynamic system non linear non linear 
relies deep analogy spectral graph partitioning 
linear dynamic system defined graph reorthogonalization gram schmidt process engaged compute eigenvectors introduces negative weights 
non principal eigenvectors non principle basins define graph partitioning corresponding positive negative weights 
process works weights configurations initialized 
major iteration zx wu ud wd 
wd updates new new weights re orthogonalized 
process continues fixed point dynamic system achieved 
non principle basins analyzed 
dynamic system association rules formalizes cooccurrence 
additional related spectral graph partitioning gibson 
convergence process cause problem progress related modification dynamic system guarantees zhang 

clustering techniques number clustering algorithms developed 
deal specific application requirements 
constraint clustering belongs category 
theoretical significance data mining applications 
briefly discuss developments sub sections relation supervised learning gradient descent ann evolutionary methods 
sub section developments briefly mention developments simply fit classification 

constraint clustering real world applications customers rarely interested unconstrained solutions 
clusters frequently subjected problem specific limitations suitable particular business actions 
building conditioned cluster partitions subject active research example see survey han 
framework constrained clustering introduced tung 
taxonomy clustering constraints includes constraints individual objects customer purchased parameter constraints number clusters addressed preprocessing external cluster parameters 
taxonomy includes constraints individual clusters described terms bounds aggregate functions min avg cluster 
constrains essential require new methodology 
particular existential constraint bound count objects certain subset frequent customers cluster 
iterative optimization partitioning clustering relies moving objects nearest cluster representatives 
may violate constraint 
methodology resolve conflict developed tung 
frequent requirement bound number cluster points 
unfortunately means algorithm frequently provides number small certain implementations empty clusters 
modification means objective function means updates incorporate lower limits cluster volumes suggested bradley 
includes soft assignments data points coefficients subject linear program requirements 
banerjee ghosh modification means algorithm 
objective function corresponds isotropic gaussian mixture widths inversely proportional numbers points clusters 
result frequency sensitive means 
approach building balanced clusters convert task problem strehl ghosh 
important constraint clustering application cluster spatial data presence obstacles 
regular euclidean distance length shortest path points obstacle distance 
cod clustering obstructed distance algorithm tung deals problem 
best illustrated showing difference constructing clusters absence obstacle left presence river bridge right 

obstacle river bridge difference 

relation supervised learning forgy means implementation em algorithms iterative optimizations 
initialize models engage series step iterations reassign hard soft data points update combined model 
process generalized framework relating clustering predictive mining 
model update considered training predictive classifier current assignments serving target attribute values supervising learning 
points correspond forecasting trained classifier 
liu suggested elegant connection supervised learning 
considered binary target attribute defined points subject clustering defined non existent artificial points uniformly distributed attribute space 
decision tree classifier applied full synthetic data 
labeled leaves correspond clusters input data 
new technique clustering decision trees resolves challenges populating input data artificial points adding points gradually tree construction making process virtual physical additions input data problems uniform distribution higher dimensions 

gradient descent artificial neural networks soft lot sense means objective function slightly modified incorporate similar em fuzzy errors accounts distances closest fit centroids xi ij exponential probabilities defined gaussian models 
objective function differentiable respect means allows application general gradient decent method 
girosi detailed subject context vector quantization 
gradient decent method means known local means algorithm 
iteration modifies means ij xi wij direction gradient decent 
second case selected randomly 
scalars satisfy certain monotone asymptotic behavior converge zero coefficients defined trough bottou bengio 
updates different context artificial neural network ann clustering som self organized map kohonen 
som popular vector quantization 
bibliography related dynamic field monograph kohonen 
elaborate som important features som uses incremental approach points patterns processed som allows map centroids plane provides straightforward visualization 
addition som ann developments adaptive resonance theory carpenter relation clustering 
discussion see jain mao 

evolutionary methods substantial information simulated annealing context partitioning main focus hierarchical clustering accumulated including algorithm simulation near optima internal clustering criteria brown 
perturbation operator general annealing simple meaning clustering amounts relocation point current new randomly chosen cluster similar means scheme 
tries address interesting problem choosing appropriate objective function 
real application surveillance monitoring ground entities airborne ground sensors 
similar simulating annealing called tabu search 
genetic algorithms ga goldberg cluster analysis 
example gga genetically guided algorithm fuzzy hard means hall 
article 
applied ga context means objective function 
population set means systems represented grid segments centroids 
segment described rules genes attribute range 
population improved mutation crossover specifically devised rules 
normal means clusters different size elongation shapes restricted segments far cry density methods 
ga applied clustering categorical data called generalized entropy define dissimilarity 
evolutionary techniques rely certain parameters empirically fit data high computational costs limit application data mining 
usage combined strategies generation initial guess means attempted babu murty babu murty 
usage ga variable length genome simultaneously improve means centroids lee merit comparison running multiple means determine changes happen full convergence achieved 

developments developments terms performance qualify data mining 
spatial data example gis database algorithm amoeba castro lee uses delaunay diagram dual voronoi diagram represent data proximity log complexity 
harel koren suggested approach related agglomerative hierarchical graph methodology showed successfully find local clusters 
consider connectivity graph delaunay diagram keeping point nearest neighbors graph 
method relies random walk find separating edges clusters connected components 
scalability vldb extensions clustering algorithms face problems scalability terms computing time memory requirements 
data mining reasonable runtime ability certain limited core memory especially important 
interesting attempts extend clustering large databases vldb divided incremental mining data squashing reliable sampling 
algorithm compare leader clustering algorithm hartigan example incremental unsupervised learning 
means handles data point time discards 
uses means cluster representation iterative optimization 
centroids pushed pulled depending loose win coming point 
line clustering needs data pass strongly depends data ordering result sub quality clusters 
handles outliers clusters dynamically born discarded training process 
appealing dynamic vldb 
tools improve obtained clusters 
data squashing techniques scan data compute certain data summaries sufficient statistics dumouchel 
obtained summaries original data clustering 
pivotal role belongs algorithm birch balanced iterative reduction clustering hierarchies zhang zhang 
significant impact direction scalability research clustering 
birch creates height balanced tree nodes summarize data accumulating zero second moments 
node called cluster feature cf tight small cluster numerical data 
construction tree residing core memory controlled parameters 
new data point descends tree closest cf leaf 
fits leaf leaf cf statistics incremented nodes leaf root 
new cf constructed 
maximum number children node branching factor limited splits happen 
tree reaches assigned memory size rebuilt threshold controlling new point assigned leaf starts new leaf updated coarser 
outliers sent disk gradually tree rebuilds 
final leaves constitute input algorithm choice 
fact cf tree balanced allows log efficient search 
birch depends parameters control cf tree construction branching factor maximum points leaf leaf threshold depends data ordering 
tree constructed data pass additionally condensed optional nd phase fit desired input cardinality post processing clustering algorithm 
rd phase global clustering cf considered individual points happens 
certain irregularities example identical points getting different cfs resolved optional th phase 
passes data reassigning points best possible clusters means 
complexity summarization phase birch extended mixed numerical categorical attributes chiu 
full interface vldb relocation clustering means includes requirements bradley 
algorithm take early termination data scan provide line solution solution progress available able incorporate additional data incrementally able prescribed memory buffer utilize different scanning modes sequential index sample able operate forward cursor view database article suggests data compression accumulates sufficient statistics birch phases 
points compressed primary stage discarded 
attributed clusters high confidence points shift 
rest taken care secondary phase tries find dense subsets means method higher requested stage kept retained set rt singletons analyzed 
birch preprocessing substantially relies vector space operations 
applications objects example strings belong metric space 
words data points compute distances 
ganti proposed birch type data squashing bubble vldb metric spaces 
leaf bubble tree characterized number points medoid called delivers minimum error squared distance points belonging leaf radius equal square root average error point problem overcome insert new points absence vector structure 
bubble uses heuristic relates distance preserving embedding leaf points low dimensional euclidean vector space 
embedding known isometric map geometry multidimensional scaling statistics 
certain analogy embeddings support vector machines 
euclidean distance birch cheap computation distance metric space example edit distance strings expensive 
insertion requires compute distances nodes descending leaf 
similar algorithm bubble fm handles difficulty 
relaxes computations approximate isometric embedding 
possible due algorithm fastmap faloutsos lin 
context hierarchical density clustering vldb breunig analyzed data reduction techniques sampling birch summarization noticed result deterioration cluster quality 
cure approached data reduction accumulation data bubbles summaries local information distances nearest neighbors 
data bubble contains extent distance bubble representative points array distances minpts nearest neighbors 
data bubbles conjunction algorithm optics see sub section density connectivity 
grid methods generate data summaries summarization phase relates units segments cfs 
scalable 
algorithms old fashioned sampling rigorous statistical reasoning 
especially handy different initializations clarans sub section medoids methods fractal clustering section grid methods means bradley fayyad 
notice clusters constructed sample assigning data appropriate clusters minimally adds term complexity 
sampling got new life adoption data mining community special uniform check control adequacy 
check chernoff bounds motwani raghavan says independent distribution real valued random variable average independent observations lies actual mean probability soon ln bounds clustering algorithm cure guha development scalable decision trees predictive mining hulten 
context balanced clustering statistical estimation sample size provided banerjee ghosh 
due nonparametric nature bounds ubiquitous significance 

clustering high dimensional data objects data mining hundreds attributes 
clustering high dimensional spaces presents tremendous difficulty predictive learning 
decision trees example irrelevant attributes simply picked node splitting known affect na bayes 
clustering high dimensionality presents dual problem 
definition similarity presence irrelevant attributes eliminates hope clustering tendency 
searching clusters clusters hopeless enterprise 
happen low dimensional data likelihood presence number irrelevant attributes grows dimension 
second problem dimensionality curse loose way speaking lack data separation high dimensional space 
mathematically nearest neighbor query unstable distance nearest neighbor indistinguishable distance majority points beyer 
effect starts severe dimensions greater 
construction clusters founded concept proximity doubtful situations 
interesting insights complications high dimensional data see aggarwal 
basic exploratory data analysis attribute selection preceding clustering step best way address problem irrelevant attributes 
consider topic section general algorithmic issues 
techniques dealing situation number pre selected attributes high 
sub section dimensionality reduction talk briefly traditional methods dimensionality reduction 
sub section subspace clustering review algorithms try circumvent high dimensionality building clusters appropriate subspaces original attribute space 
approach perfect sense applications better describe data fewer attributes 
approach divides attributes similar groups comes new derived attributes representing group discussed sub section clustering 
important source high dimensional categorical data comes transactional market basket analysis 
idea group items similar clustering discussed section occurrence categorical data 

dimensionality reduction talking high dimensionality high high 
spatial clustering algorithms depend indices spatial datasets sub section data preparation facilitate quick search nearest neighbors 
indices serve proxies respect dimensionality curse performance impact 
indices clustering algorithms known effectively dimensions 
dimension performance degrades level sequential search newer indices achieve significantly higher limits 
arguably claim data attributes high dimensional 
large gap 
dealing retail application weeks sales volumes represent typical set features special example general class time series data 
customer profiling dozens generalized item categories plus basic demographics result attributes 
web clustering site contents results attributes pages contents modest web sites 
biology genomic data dimensions easily surpass attributes 
text mining information retrieval deal thousands attributes words index terms 
gap significant 
general purpose techniques fight high dimensionality attributes transformations domain decomposition 
attribute transformations simple functions existent attributes 
sales profiles olap type data roll ups sums averages time intervals monthly volumes 
due fine sales brute force approaches rarely 
multivariate statistics principal components analysis pca popular mardia approach problematic leads clusters poor interpretability 
singular value decomposition svd technique reduce dimensionality information retrieval berry berry browne statistics fukunaga 
low frequency fourier harmonics conjunction parseval theorem successfully analysis time series agrawal wavelets transformations keogh 
domain decomposition divides data subsets canopies mccallum inexpensive similarity measure high dimensional computation happens smaller datasets 
dimension stays costs reduced 
approach targets situation high dimension large data clusters 

subspace clustering algorithms better adjust high dimensions 
example algorithm cactus section occurrence categorical data adjusts defines cluster terms cluster projections 
section cover techniques specifically designed high dimensional data 
algorithm clique clustering quest agrawal numerical attributes fundamental subspace clustering 
ideas density clustering grid clustering induction dimensions similar apriori algorithm association rules mdl principle select appropriate subspaces interpretability clusters terms dnf representation clique starts definition unit elementary rectangular cell subspace 
units densities exceed threshold retained 
bottom approach finding units applied 
dimensional units dividing intervals equal width bins grid 
parameters algorithm inputs 
recursive step dimensional units dimensional units involves self join units having common dimensions apriori reasoning 
subspaces sorted coverage lesser covered subspaces pruned 
cut point selected mdl principle 
cluster defined maximal set connected dense units 
represented dnf expression associated finite set maximal segments called regions union equal cluster 
effectively clique results attribute selection selects subspaces produces view data different perspectives 
result series cluster systems different subspaces 
versatility goes vein data description data partitioning different clusters overlap 
highest subspace dimension selected complexity dense units generations const qn identification clusters quadratic task terms units 
algorithm enclus entropy clustering cheng follows footsteps clique uses different criterion subspace selection 
criterion derived entropy related considerations subspace spanned attributes entropy smaller threshold considered clustering 
subspace subspace aq aq aq aq aq low entropy subspace corresponds skewed distribution unit densities 
computational costs enclus high 
algorithm mafia merging adaptive finite intervals significantly modifies clique 
starts data pass construct adaptive grids dimension 
bins compute histograms reading blocks data core memory merged come smaller number variable size bins clique 
algorithm uses parameter called cluster dominance factor select bins times densely populated relative volume average 
candidate dense units 
mafia proceeds recursively higher dimensions time data scan involved 
difference mafia clique construct new cdu mafia tries soon share dimensions face 
creates order magnitude candidates 
adjacent merged clusters clusters proper subsets higher dimension clusters eliminated 
parameter default value works fine presents problem comparison global density threshold clique 
reporting range single run supported 
highest dimensionality cdu complexity const qn algorithm hinneburg keim uses data partitioning divisive recursion multi dimensional grids 
authors effects high dimension geometry 
familiar concepts example uniform distribution blurred large uses density estimations way algorithm authors 
primarily focuses separation clusters hyper planes necessarily axes parallel 
find planes consider set contracting linear projectors functionals attribute space line 
density kernel form tool trade contracting projection density induced projection concentrated 
cutting plane chosen goes point minimal density discriminates significantly dense half spaces 
cutting planes chosen recursion continues subset data 
algorithm proclus projected clustering aggarwal associates subset low dimensional subspace projection subspace tight cluster 
subset subspace pair exists constitutes projected cluster 
number clusters average subspace dimension user inputs 
iterative phase algorithm deals finding medoids associated subspace 
sample data greedy hill climbing technique 
manhattan distance divided subspace dimension useful normalized metric searching different dimensions 
additional data pass follows iterative stage finished refine clusters including subspaces associated medoids 
algorithm orclus oriented projected cluster generation aggarwal yu uses similar approach projected clustering employs non axes parallel subspaces high dimensional space 
fact developments address generic issue low dimensional space different portions data exhibit clustering tendency different subspaces consider non parallel non intersecting cylinders space 
case attribute selection doomed 
orclus means transparent model defines clusters sets points partition low sum squares errors energy certain subspace 
specifically directions el specific projection defined el projection decreases energy 
svd diagonalization find directions eigenvectors corresponding lowest eigenvalues covariance matrix 
reality algorithm results partitioning outliers excluded clusters subspace directions algorithm builds clusters larger dimensional gradually fitting optimal subspace requested suggestion picking parameter provided uniform certain liability 
comparison aside projected clusters provide data partitioning cluster systems resulted clique overlap 

clustering olap attribute roll ups viewed representatives attribute groups 
interesting general idea producing attribute groups conjunction clustering points leads concept clustering 
clustering simultaneous clustering points attributes 
approach reverses struggle improve clustering points attributes tries cluster attributes points 
far concerned grouping rows matrix talking grouping columns 
utilizes canonical duality contained point attribute data representation 
idea clustering data points attributes old anderberg hartigan known names simultaneous clustering bi dimensional clustering block clustering conjugate clustering distributional clustering information bottleneck method 
duality analysis categorical data dual multidimensional scaling long history statistics 

learning referring traffic web site 
page amount sale store item category 
similar approach building groups item section occurrence categorical data 
section turn numerical attributes 
assume matrix non negative elements 
context known incidence relational frequency contingency matrix 
applications reflect intensity gene response tissue sample frequency visitation activity researched simultaneous block clustering rows columns contingency tables 
reviewed earlier subject 
advanced algebraic approach clustering bi partite graphs minimal cuts conjunction text mining proposed dhillon 
contains excellent relations simultaneous clustering graph partitioning connection svd 
simple algorithm ping pong suggested find populated areas sparse binary matrix 
redistributes influence columns rows vice versa compare algorithm transversal connection matrix elements provides example clustering related development 
series publications deal distributional clustering attributes informational measures attribute similarity 
attributes columns matrix exactly probability distributions identical purpose data mining deleted 
attributes probability distributions close terms kullback leibler kl distance kullback leibler grouped impact 
addition natural derived attribute mixed distribution normalized sum columns available represent group 
process generalized 
grouping simplifies original matrix compressed form attribute clustering productive minimally impacts information reduction mutual information contained cover thomas 
attribute grouping intimately related na bayes classification predictive mining baker mccallum 
outlined technique relevant grouping words text mining 
context technique explored name information bottleneck method tishby 
facilitate agglomerative clustering words document clustering slonim tishby classification slonim tishby 
showed deep algebraic connection distributional clustering means 
means adaptation kl distance major iterative step algorithm gradually clusters points attributes 
development industrial application web analysis 
shows original incidence matrix web site traffic rows web site pages columns clustered matrix information loss 
kl distance distance symmetric symmetrized called jensen divergence 
dhillon jensen divergence cluster words means fashion text classification 
text web mining idea clustering finds way applications example clustering gene microarrays 

general algorithmic issues different clustering techniques 
common issues addressed clustering algorithm successful 
ubiquitous specific unsupervised learning considered part data mining framework 
resolved certain algorithms 
fact algorithms specifically designed reason 
overview common issues necessarily coverage fragmented 
scalability vldb high dimensional clustering surveyed significant issues discussed assessment results choice appropriate number clusters data preparation proximity measures handling outliers 
assessment results data mining clustering process starts assessment cluster tendency place correspondingly includes appropriate attribute selection cases feature construction 
finishes validation evaluation resulting clustering system 
clustering system assessed expert particular automated procedure 
traditionally type assessment relates issues cluster interpretability cluster visualization 
interpretability depends technique 
model probabilistic conceptual algorithms cobweb better scores regard 
means medoid methods generate clusters interpreted dense areas centroids medoids score 
review jain extensively covers cluster validation discussion cluster visualization related 
regarding automatic procedures partitions constructed different number subsets order business compare 
actual class label partition known 
clustering performed generating label situation similar testing classifier predictive mining actual target known 
comparison labels similar computing error confusion matrix predictive mining 
simple criterion rand serves purpose rand 
computation rand index defined involves pairs points assigned different clusters partitions 
complexity feasible 
conditional entropy known label clustering partitioning cover thomas log measure 
ps probabilities cluster conditional probabilities complexity 
measures example measure larsen aone 

clusters 
methods number clusters construct input user parameter 
running algorithm times leads sequence clustering systems 
system consists granular separated clusters 
case means objective function monotone decreasing 
answer question system preferable trivial 
criteria introduced find optimal industrial applications sas report pseudo statistic 
sense means clustering context anova 
earlier publications subject analyzed cluster separation different hartigan milligan cooper 
instance distance centroids medoids normalized corresponding cluster radii standard deviations averaged cluster weights reasonable choice coefficient separation 
coefficient low complexity 
popular choice separation measure silhouette coefficient kaufman rousseeuw 
example silhouette coefficient conjunction clarans ng han 
complexity 
consider average distance point cluster points compare averaged distance best fitting cluster min silhouette coefficient max values close corresponding perfect values bad clustering choice 
average individual gives indication cluster system appropriateness 
approach separation employ possible soft fuzzy assignments 
intermediate kn complexity 
remember assignment point particular cluster may frequently involve certain arbitrariness 
depending point fits particular cluster different probabilities weights introduced hard strict assignment defined partition coefficient bezdek equal sum squares weights compare gini index 
discussed measures plotted function graph choose best strong probabilistic foundation mixture model discussed sub section probabilistic clustering allows viewing choice optimal problem fitting data best model 
question adding new parameters results better model 
bayesian learning example autoclass cheeseman stutz likelihood model directly affected priors model complexity number parameters proportional 
criteria suggested including minimum description length mdl criterion rissanen schwarz rissanen minimum message length mml criterion wallace freeman wallace dowe bayesian information criterion bic schwarz fraley raftery akaike information criterion aic non coding information theoretic criterion approximate weight evidence awe criterion banfield raftery bayes factors kass raftery criteria expressed combinations log likelihood number clusters number parameters cluster total number estimated parameters different flavors fisher information matrix 
example mdl log min arg mdl bic log bic best details discussion bock oliver fraley raftery 
examples means bic criterion uses mml criterion clique evolutionary approach determination lee mdl 
significant expertise developed estimation goodness fit criteria 
example different ranges bic suggested weak positive strong evidence favor clustering system versus fraley raftery 
smyth suggested likelihood cross validation technique determination best 
data preparation irrelevant attributes chances successful clustering futile negatively affect proximity measures eliminate clustering tendency 
sound exploratory data analysis eda essential 
framework eda 
order business eda eliminates inappropriate attributes reduces cardinality retained categorical attributes 
provides attribute selection 
different attribute selection methods exist 
inconsistency rates utilized liu setiono 
idea markov blanket koller sahami 
methods example jebara jaakkola primarily predictive descriptive mining address general purpose attribute selection clustering 
conclude cluster specific attribute selection invented 
attributes transformation clustering discussed context dimensionality reduction 
practice assigning different weights attributes scaling values especially standardization widespread allows constructing clusters better shapes 
extent attribute scaling viewed continuation attribute selection 
real life applications crucial handle attributes different nature 
example images characterized color texture shape location resulting attribute subsets 
modha suggested interesting approach attribute scaling pursues objective clustering attribute subset computing weights simplex minimize product intra cluster inter cluster ratios attribute subset projections called generalized fisher ratio 
applications data points different significance 
example assortment planning stores characterized profiles sales particular items percentage 
sale volume gives additional weight larger stores 
partitioning relocation algorithms easily handle weighted data centroids centers weights means 
described practice called case scaling 
algorithms depend effectiveness data access 
facilitate process data indices constructed 
examples include extension algorithm clarans ester algorithm dbscan ester 
index structures spatial data include kd trees friedman trees guttman trees kriegel 
blend attribute transformations dft polynomials indexing technique keogh 
indices numerous generalizations exist beckmann faloutsos berchtold wang karypis han keogh 
major application data structures nearest neighbors search 
preprocessing multimedia data embedding euclidean space algorithm fastmap faloutsos lin 
fairly diverse range preprocessing variable length sequences 
handling directly sub section probabilistic clustering fixed set features represent variable length sequences derived karypis 

proximity measures hierarchical partitioning methods different distances similarity measures jain dubes 
usual distance numerical data lower corresponds robust estimation affected outliers 
euclidean distance far popular choice means objective function sum squares distances points centroids clear statistical meaning total inter clusters variance 
manhattan distance corresponds 
distance returns maximum absolute difference coordinates corresponds applications profile analyses points scaled unit norm proximity measure angle points arccos specific tools section scalability vldb extensions particular applications text mining 
distances assume attributes independence diagonal covariance matrix 
distance mardia algorithms orclus aggarwal yu assumption 
formula defines similarity numerical attributes 
choices cosine dice coefficients distance exponent exp cos exp shift attention categorical data 
number similarity measures exist categorical attributes dubes everitt 
assuming binary attributes values number attributes having outcomes rand jaccard known tanimoto indices equal notice jaccard index treats positive negative values asymmetrically measure choice transactional data meaning item 
simply fraction common items transactions relative number items transactions 
collaborative filtering sequence analysis text mining pattern recognition 
extended jaccard coefficient advocated ghosh 
construction similarity measures market basket analysis see aggarwal baeza yates 
similarity constructed axiomatically information theoretical considerations lin 
contain material related strings similarity biology application 
strings alphabet edit distance frequent choice 
length sequence transformations insertion deletion transposition necessary transform string 
classic hamming distance cover thomas 
review jain 
historically textual mining source major inspirations concept similarity resnik 
proximity measures clusters derived proximities pairs points discussed sub section linkage metrics 

handling outliers applications derive data measurements associated amount noise viewed outliers 
alternately outliers viewed legitimate records having abnormal behavior 
general clustering techniques distinguish noise abnormalities fit clusters 
correspondingly preferable way deal outliers partitioning data keep extra set outliers pollute factual clusters 
multiple ways descriptive learning handles outliers 
summarization data preprocessing phase usually takes care outliers 
example case grid methods 
simply rely input thresholds eliminate low populated cells 
algorithms section scalability vldb extensions provide examples 
algorithm birch zhang zhang revisits outliers major cf tree rebuilds general handles separately 
approach shared similar systems chiu 
framework bradley utilizes multiphase approach outliers 
certain algorithms specific features outliers handling 
algorithm cure guha uses shrinkage cluster suppress effects outliers 
medoids methods generally robust means methods respect outliers medoids feel outliers 
algorithm ester uses concepts internal core boundary reachable outliers non reachable points 
algorithm clique agrawal goes step eliminates subspaces low coverage 
algorithm known handle outliers filtering dsp foundation 
algorithm orclus aggarwal yu produces partition plus set outliers 
outlier 
statistics defines outlier point fit probability distribution 
approach problem testing unknown multivariate distribution 
classic data analysis utilizes concept depth tukey defines outlier point low depth 
concept computationally infeasible 
data mining gradually develops definitions 
consider positive parameters 
point declared outlier neighborhood contains fraction dataset knorr ng 
ramaswamy noticed definition improved eliminating parameter 
rank points distance nearest neighbor define fraction points highest ranks outliers 
definitions uniformly global 
describe local outliers 
essence different subsets data different densities may governed different distributions 
point close tight cluster probable outlier point away dispersed cluster 
concept local outlier factor lof specifies degree outlier ness comes rescue breunig 
definition distance nearest neighbor 
knorr addressed related problem eliminate outliers order compute appropriate covariance matrix describes locality 
utilized donoho estimator dimensional space 
crude handling outliers works surprisingly applications simple truth applications concerned systematic patterns 
example customer segmentation objective direct mail campaign 
hand philosophically outlier non typical leftover regular clustering easily attain prominent significance 
addition eliminating negative effects outliers clusters construction separate reason driving interest outlier detection 
reason applications outlier commodity trade 
medical diagnostics fraud detection network security anomaly detection computer immunology 
connections forrest lee stolfo ghosh 
crm commerce web site analytics outliers relate concept interesting unexpected piatetsky shapiro matheus silberschatz tuzhilin padmanabhan tuzhilin padmanabhan tuzhilin 
research applications directly related clustering pruning association rules 
cooperation jonathan essential appearance text 
resulted numerous discussions various improvements 
am grateful jiawei han reading text thoughtful remarks concerning presentation material 
am thankful sue help text preparation 
aggarwal hinneburg keim 
surprising behavior distance metrics high dimensional space 
ibm research report rc 
aggarwal procopiuc wolf yu park 
fast algorithms projected clustering 
proceedings acm sigmod conference philadelphia pa aggarwal wolf yu 
new method similarity indexing market basket data 
proceedings acm sigmod conference philadelphia pa aggarwal yu 
finding generalized projected clusters high dimensional spaces 
sigmod record 
agrawal faloutsos swami 
efficient similarity search sequence databases 
proceedings th international conference foundations data organization algorithms chicago il 
agrawal gehrke gunopulos raghavan 
automatic subspace clustering high dimensional data data mining applications 
proceedings acm sigmod conference seattle wa 

tabu search approach clustering problem 
pattern recognition 
anderberg 
cluster analysis applications 
academic press new york 
ankerst breunig kriegel sander 
optics ordering points identify clustering structure 
proceedings acm sigmod conference philadelphia pa arabie hubert 
overview combinatorial data analysis arabie hubert 
eds 
clustering classification world scientific publishing nj 

efficient algorithms normalized edit distance 
journal discrete algorithms 
babu murty 
near optimal initial seed value selection means algorithm genetic algorithm 
pattern recogn 
lett 

babu marty 
clustering evolution strategies 
pattern recognition 
baeza yates 
data structures algorithms related information retrieval 
frakes baeza yates 
eds 
information retrieval data structures algorithms prentice hall 
baker mccallum 
distributional clustering words text classification 
proceedings st acm sigir conference melbourne australia 
ball hall 
isodata novel method data analysis classification 
technical report ad sri stanford ca 
banerjee ghosh 
scaling balanced clustering algorithms 
proceedings nd siam icdm arlington va banfield raftery 
model gaussian non gaussian clustering 
biometrics 
barbara chen 
fractal dimension cluster datasets 
proceedings th acm sigkdd boston ma 
freeman 
automating exploratory data analysis efficient data mining 
proceedings th acm sigkdd boston ma 
beckmann kriegel schneider seeger 
tree efficient access method points rectangles 
proceedings international conference geographic information systems ottawa canada 
berchtold hm kriegel 

pyramid technique breaking curse dimensionality 
proceedings acm sigmod conference seattle wa 

learning simple relations theory applications 
proceedings nd siam icdm arlington va ben dor yakhini 
clustering gene expression patterns 
proceedings rd annual international conference computational molecular biology recomb lyon france 
berry browne 
understanding search engines mathematical modeling text retrieval 
siam 
berry dumais landauer brien 
linear algebra intelligent information retrieval 
siam review 
bottou bengio 
convergence properties means algorithms 
tesauro touretzky 
eds 
advances neural information processing systems mit press cambridge ma 
beyer goldstein ramakrishnan shaft 
nearest neighbor meaningful 
proceedings th icdt jerusalem israel 
bezdek 
pattern recognition fuzzy objective function algorithms 
plenum press new york ny 
bock 
probability models partitional cluster analysis 

eds 
developments data analysis slovenia 
boley 
principal direction divisive partitioning 
data mining knowledge discovery 

determining number component clusters standard multivariate normal mixture model model selection criteria 
tr uic quantitative methods department university illinois chicago il 

mixture model cluster analysis model selection criteria new information measure complexity 
proceedings st japan conference frontiers statistical modeling informational approach dordrecht netherlands 
bradley bennett demiriz 
constrained means clustering 
technical report msr tr 
microsoft research redmond wa 
bradley fayyad 
refining initial points means clustering 
proceedings th icml madison wi 
bradley fayyad reina 
scaling clustering algorithms large databases 
proceedings th acm sigkdd new york ny 
breunig kriegel sander 
data bubbles quality preserving performance boosting hierarchical clustering 
proceedings acm sigmod conference santa barbara ca 
breunig kriegel ng sander 
lof identifying density local outliers 
proceedings acm sigmod conference dallas tx 
brown 
practical application simulated annealing clustering 
technical report ipc tr university virginia 
jacobsen kr mer 
double conjugated clustering applied leukemia microarray data nd siam icdm workshop clustering high dimensional data arlington va cadez smyth 
general probabilistic framework clustering individuals 
technical report uci ics 
cadez smyth mannila 
probabilistic modeling transactional data applications profiling visualization prediction proceedings th acm sigkdd san francisco ca 
carpenter grossberg rosen 
fuzzy art fast stable learning categorization analog patterns adaptive resonance system 
neural networks 
cheeseman stutz 
bayesian classification autoclass theory results 
fayyad piatetsky shapiro smyth uthurusamy 
eds 
advances knowledge discovery data mining aaai press mit press 
cheng fu zhang 
entropy subspace clustering mining numerical data 
proceedings th acm sigkdd san diego ca 
chiu fang chen wang 
robust scalable clustering algorithm mixed type attributes large database environments 
proceedings th acm sigkdd san francisco ca 
cooley mobasher srivastava 
data preparation mining world wide web browsing 
journal knowledge information systems 
gluck 
explaining basic categories feature predictability information 
psychological bulletin 
cover thomas 
elements information theory 
john wiley sons new york ny 

information theoretical approach clustering categorical databases genetic algorithms 
nd siam icdm workshop clustering high dimensional data arlington va cutting karger pedersen tukey 
scatter gather approach browsing large document collection 
proceedings th acm sigir conference copenhagen denmark 
daniel wood 
fitting equations data computer analysis data 
john wiley sons new york ny 
day edelsbrunner 
efficient algorithms agglomerative hierarchical clustering methods 
journal classification 

efficient algorithm complete link method 
computer journal 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society series 
dhillon 
clustering documents words bipartite spectral graph partitioning 
proceedings th acm sigkdd san francisco ca 
dhillon fan guan 
efficient clustering large document collections 
grossman kamath kegelmeyer kumar 
eds 
data mining scientific engineering applications kluwer academic publishers 
dhillon guan kogan 
refining clusters high dimensional data 
nd siam icdm workshop clustering high dimensional data arlington va dhillon kumar 
enhanced word clustering hierarchical text classification proceedings th acm sigkdd edmonton canada 
dhillon modha 
data clustering algorithm distributed memory multiprocessors 
th acm sigkdd large scale parallel kdd systems workshop san diego ca 
dubes 
cluster analysis related issues 
chen pau wang 
eds 
handbook pattern recognition computer vision world scientific publishing river edge nj 
duda hart 
pattern classification scene analysis 
john wiley sons new york ny 
dumouchel johnson cortes pregibon 
squashing flat files flatter 
proceedings th acm sigkdd san diego ca 
hartigan 
percentage points test clusters 
journal american statistical association 
steinbach kumar 
finding clusters different sizes shapes densities noisy high dimensional data technical report 
ester kriegel sander 
spatial data mining database primitives algorithms efficient dbms support 
data mining knowledge discovery kluwer academic publishers 
ester kriegel sander xu 
density algorithm discovering clusters large spatial databases noise 
proceedings nd acm sigkdd portland oregon 
ester kriegel xu 
database interface clustering large spatial databases 
proceedings st acm sigkdd montreal canada 
castro lee 
amoeba hierarchical clustering spatial proximity delaunay diagram 
proceedings th international symposium spatial data handling 
beijing china 
everitt 
cluster analysis rd ed 
edward arnold london uk 
faloutsos lin 
fastmap fast algorithm indexing data mining visualization traditional multimedia 
proceedings acm sigmod conference san jose ca 
faloutsos ranganathan manolopoulos 
fast subsequence matching time series databases 
proceedings acm sigmod conference minneapolis mn 

analysis clustering algorithms 
technical report uw cse university washington 
fisher 
knowledge acquisition incremental conceptual clustering 
machine learning 
fisher 
iterative optimization simplification hierarchical clustering 
journal artificial intelligence research 
forgy 
cluster analysis multivariate data efficiency versus interpretability classification 
biometrics 
forrest hofmeyr somayaji 
computer immunology 
communications acm 
foss wang 
non parametric approach web log analysis 
st siam icdm workshop web mining chicago il 
fraley raftery 
software model cluster discriminant analysis tech report dept statistics univ washington 
fraley raftery clusters 

clustering method 
answers model cluster analysis 
computer journal 
friedman bentley finkel 
algorithm finding best matches logarithmic expected time 
acm trans 
math 
software 
fukunaga 
statistical pattern recognition 
academic press san diego ca 
ganti gehrke ramakrishnan 
cactus clustering categorical data summaries 
proceedings th acm sigkdd san diego ca 
ganti ramakrishnan gehrke powell french 
clustering large datasets arbitrary metric spaces 
proceedings th icde sydney australia 
gennari langley fisher 
models incremental concept formation 
artificial intelligence 
gersho gray 
vector quantization signal compression 
communications information theory 
kluwer academic publishers norwell ma 
ghosh 
scalable clustering methods data mining 
ye ed 
handbook data mining lawrence erlbaum appear 
ghosh schatz 

learning program behavior profiles intrusion detection 
proceedings sans conference workshop intrusion detection response san francisco ca 
gibson kleinberg raghavan 
clustering categorical data approach dynamic systems 
proceedings th international conference large databases new york ny 
choudhary 
mafia efficient scalable subspace clustering large data sets 
technical report tr northwestern university 
goldberg 
genetic algorithms search optimization machine learning 
addison wesley 
gonzalez 
clustering minimize maximum intercluster distance 
theoretical computer science 

simultaneous clustering rows columns 
control cybernetics 
krishna 
agglomerative clustering concept mutual nearest neighborhood 
pattern recognition 
guha rastogi shim 
cure efficient clustering algorithm large databases 
proceedings acm sigmod conference seattle wa 
guha rastogi shim 
rock robust clustering algorithm categorical attributes 
proceedings th icde sydney australia 
karypis 
scalable algorithm clustering sequential data 
ieee icdm silicon valley ca 
guttman 
trees dynamic index structure spatial searching 
proceedings acm sigmod conference boston ma 
hall bezdek 
clustering genetically optimized approach 
ieee trans 
evolutionary computation 
han karypis kumar mobasher 
clustering association rule hypergraphs 
acm sigmod conference data mining workshop dmkd tucson arizona 
han kamber 
data mining 
morgan kaufmann publishers 
han kamber tung 
spatial clustering methods data mining survey 
miller han 
eds 
geographic data mining knowledge discovery taylor francis 
harel koren 
clustering spatial data random walks proceedings th acm sigkdd 
san francisco ca 
hartigan 
clustering algorithms 
john wiley sons new york ny 
hartigan wong 
algorithm means clustering algorithm 
applied statistics 
chi 
identification web user traffic composition multimodal clustering information scent 
st siam icdm workshop web mining chicago il 
hinneburg keim 
efficient approach clustering large multimedia databases noise 
proceedings th acm sigkdd new york ny 
hinneburg keim 
optimal grid clustering breaking curse dimensionality high dimensional clustering 
proceedings th conference vldb edinburgh scotland 
huang 
extensions means algorithm clustering large data sets categorical values 
data mining knowledge discovery 
hulten spencer domingos 
mining time changing data streams 
proceedings th acm sigkdd san francisco ca 
jain dubes 
algorithms clustering data 
prentice hall englewood cliffs nj 
jain flynn 
image segmentation clustering 
advances image understanding festschrift rosenfeld ieee press 
jain mao 
artificial neural networks tutorial 
ieee computer 
jain murty flynn 
data clustering review 
acm computing surveys 
jarvis patrick 
clustering similarity measure shared nearest neighbors 
ieee transactions computers 
jebara jaakkola 
feature selection dualities maximum entropy discrimination 
proceedings th uia conference stanford ca 

principal component analysis 
springer verlag new york ny 
langley wagstaff yoo 
generalized clustering supervised learning data assignment 
proceedings th acm sigkdd san francisco ca 

visualizing multi dimensional clusters trends outliers star coordinates 
proceedings th acm sigkdd san francisco ca 
karypis aggarwal kumar shekhar 
multilevel hypergraph partitioning application vlsi domain proceedings acm ieee design automation conference 
karypis han kumar 
chameleon hierarchical clustering algorithm dynamic modeling computer 
karypis han kumar 
multilevel refinement hierarchical clustering 
technical report 
karypis han 

concept indexing fast dimensionality reduction algorithm applications document retrieval categorization 
technical report tr department computer science university minnesota minneapolis 
karypis kumar 
fast highly quality multilevel scheme partitioning irregular graphs 
siam journal scientific computing 
kass raftery 
bayes factors 
journal amer 
statistical association 
kaufman rousseeuw 
finding groups data cluster analysis 
john wiley sons new york ny 
keogh chakrabarti mehrotra pazzani 
locally adaptive dimensionality reduction indexing large time series databases 
proceedings acm sigmod conference santa barbara ca 
keogh chakrabarti pazzani mehrotra 
dimensionality reduction fast similarity search large time series databases 
journal knowledge information systems 
keogh chu pazzani 
ensemble index new approach indexing large databases 
proceedings th acm sigkdd san francisco ca 
kernighan lin 
efficient heuristic procedure partitioning graphs 
bell system technical journal 
kohonen 
self organizing map 
proceedings ieee 
kohonen 
self organizing maps 
springer series information sciences springer 

clustering algorithms spatial databases survey 
pdf available web 
koller sahami 
optimal feature selection 
proceedings th icml bari italy 
knorr ng 
algorithms mining distance outliers large datasets 
proceedings conference vldb new york ny 
knorr ng 
robust space transformations distance operations 
proceedings th acm sigkdd san francisco ca 
kriegel seeger schneider beckmann 
tree efficient access method geographic information systems 
proceedings international conference geographic information systems ottawa canada 
kullback leibler 
information sufficiency 
annals mathematical statistics 
lance williams 
general theory classification sorting strategies 
computer journal 
larsen aone 
fast effective text mining linear time document clustering 
proceedings th acm sigkdd san diego ca 
lee 

dynamic partitional clustering evolution strategies 
proceedings rd asia pacific conference simulated evolution learning nagoya japan 
lee stolfo 
data mining approaches intrusion detection 
proceedings th usenix security symposium san antonio tx 
toth 
fast algorithm determine fractal dimensions box counting 
physics letters 
lin 
information theoretic definition similarity 
proceedings th icml madison wi 
liu xia yu 
clustering decision tree construction 
sigmod 
liu setiono 
probabilistic approach feature selection filter solution 
proceedings th icml bari italy 

decomposition event sequences independent components 
proceedings st siam icdm chicago il 
mao jain 
self organizing network clustering hec 
ieee transactions neural networks 
mardia kent bibby 
multivariate analysis 
academic press 
girosi 
extensions means algorithm image segmentation pattern classification 
memo 
mit cambridge ma 
massart kaufman 
interpretation analytical chemical data cluster analysis 
john wiley sons new york ny 
mccallum nigam ungar 
efficient clustering highdimensional data sets application matching 
proceedings th acm sigkdd boston ma 
mclachlan basford 
mixture models inference applications clustering 
marcel dekker new york ny 
mclachlan krishnan 
em algorithm extensions 
john wiley sons new york ny 
michalski stepp 
learning observations conceptual clustering 
machine learning artificial intelligence approach 
san mateo ca morgan kaufmann 
milligan cooper 
examination procedures determining number clusters data set 
psychometrika 

mathematic classification clustering 
kluwer academic publishers 
mitchell 
machine learning 
mcgraw hill new york ny 
modha 
feature weighting means clustering 
machine learning 
moore 
fast em mixture model clustering multiresolution kd trees 
advances neural information processing systems 
motwani raghavan 
randomized algorithms 
cambridge university press 
murtagh 
survey advances hierarchical clustering algorithms 
computer journal 
murtagh 
multidimensional clustering algorithms 
physica verlag vienna 
choudhary 
adaptive grids clustering massive data sets proceedings st siam icdm chicago il 
ng han 
efficient effective clustering methods spatial data mining 
proceedings th conference vldb santiago chile 

analysis categorical data dual scaling applications 
university toronto 
oliver baxter wallace 
unsupervised learning mml 
proceedings th icml bari italy 
olson 
parallel algorithms hierarchical clustering 
parallel computing 

application matrix clustering web log analysis access prediction 
th acm sigkdd webkdd workshop san francisco ca 
padmanabhan tuzhilin 
measure interestingness knowledge discovery 
decision support systems journal 
padmanabhan tuzhilin 
small beautiful discovering minimal set unexpected patterns 
proceedings th acm sigkdd boston ma 
pelleg moore 
accelerating exact means algorithms geometric reasoning 
proceedings th acm sigkdd san diego ca 
pelleg moore 
means extending means efficient estimation number clusters 
proceedings th icml stanford university 
piatetsky shapiro matheus 
interestingness deviations 
proceedings aaai workshop knowledge discovery databases 
ramaswamy rastogi shim 
efficient algorithms mining outliers large data sets sigmoid record 
rand 
objective criteria evaluation clustering methods 
journal american statistical assoc 
resnik 
information content evaluate semantic similarity taxonomy 
proceedings ijcai montreal canada 
rissanen 
modeling shortest data description 
automatica 
rissanen 
stochastic complexity statistical inquiry 
world scientific publishing singapore 
sander ester kriegel xu 
density clustering spatial databases algorithm applications 
data mining knowledge discovery 
trinder 
genetic rule data clustering toolkit 
published congress evolutionary computation cec honolulu usa 
boley 
performance bisecting means pddp 
proceedings st siam icdm chicago il 
boley 
cluster selection divisive clustering algorithms 
proceedings nd siam icdm arlington va 
pattern recognition 
approaches 
john wiley sons new york ny 
statistical structural neural 
grid clustering fast hierarchical clustering method large data sets 
proceedings th international conference pattern recognition 

bang clustering system grid data analysis 
proceeding advances intelligent data analysis reasoning data nd international symposium london uk 
schwarz 
estimating dimension model 
annals statistics 
scott 
multivariate density estimation 
wiley new york ny 
chatterjee zhang 
multiresolution clustering approach large spatial databases 
proceedings th conference vldb new york ny 
sibson 
optimally efficient algorithm single link cluster method 
computer journal 
silberschatz tuzhilin 
patterns interesting knowledge discovery systems 
ieee trans 
knowledge data eng 
slonim tishby 
document clustering word clusters information bottleneck method 
proceedings sigir 
slonim tishby 
power word clusters text classification 
rd european colloquium information retrieval research 
smyth 
model selection probabilistic clustering cross validated likelihood 
ics tech report statistics computing 
smyth 
probabilistic model clustering multivariate sequential data 
proceedings th international workshop ai statistics 
spath 
cluster analysis algorithms 
ellis horwood chichester england 
steinbach karypis kumar 
comparison document clustering techniques 
th acm sigkdd world text mining conference boston ma 
strehl ghosh 
scalable approach balanced high dimensional clustering market baskets proceedings th international conference high performance computing springer lncs bangalore india 


clustering algorithm clustering data fusion 
ieee trans 
aerospace electr 
systems 
tishby pereira bialek 
information bottleneck method 
proceedings th annual allerton conference communication control computing 
tukey 
exploratory data analysis 
addison wesley 
tung hou han 
spatial clustering presence obstacles 
proceedings th icde heidelberg germany 
tung ng lakshmanan han 
constraint clustering large databases proceedings th icdt london uk 
voorhees 
implementing agglomerative hierarchical clustering algorithms document retrieval 
information processing management 
wallace dowe 
intrinsic classification mml program 
proceedings th australian joint conference artificial intelligence une world scientific publishing australia 
wallace freeman 
estimation inference compact coding 
journal royal statistical society series 
xu ester kriegel sander 
distribution clustering algorithm mining large spatial datasets 
proceedings th icde orlando fl 


comparative study self organizing clustering algorithms art 
neural networks 
ward 
hierarchical grouping optimize objective function 
journal amer 
stat assoc 
wang yang muntz 
sting statistical information grid approach mining 
proceedings rd conference vldb athens greece 
wang yang muntz 
pk tree spatial index structure high dimensional point data 
proceedings th international conference foundations data organization 
wang yang muntz 
sting approach active spatial data mining 
proceedings th icde sydney australia 
xu ester kriegel sander 
distribution clustering algorithm mining large spatial databases 
proceedings th icde orlando fl 
yao 
constructing minimum spanning trees dimensional space related problems 
siam journal computing 
zhang 
generalized harmonic means dynamic weighting data unsupervised learning 
proceedings st siam icdm chicago il 
zhang ramakrishnan livny 
birch efficient data clustering method large databases 
proceedings acm sigmod conference montreal canada 
zhang ramakrishnan livny 
birch new data clustering algorithm applications 
journal data mining knowledge discovery 
zhang fu cai heng 


clustering categorical data 
proceedings th icde san diego ca 

