robust multipitch estimation analysis manipulation polyphonic musical signals klapuri tuomas jan markus holm tampere university technology signal processing laboratory box fin tampere finland university jyv skyl department box fin jyv skyl finland cs tut fi jan markus holm fi method estimation multiple pitches concurrent musical sounds described 
experimental data comprised sung vowels pitch range musical instruments 
multipitch estimation performed level single time frame random pitch sound source combinations 
note error rates mixtures ranging simultaneous sounds respectively 
musical interval chord identification tasks algorithm outperformed average trained musicians 
particular emphasis laid robustness presence sounds noise 
algorithm iterative estimation separation procedure able resolve couple prominent pitches sound polyphonies 
sounds exhibit handled problems inharmonicity factor spectral envelope sound estimated pitch 
examples musical signal manipulations possible proposed method 

pitch perception plays important part human hearing understanding acoustic complexes 
listening musical signals humans able resolve perceive fundamental frequencies simultaneous sounds 
computational modeling function relatively little explored compared massive efforts estimating pitch monophonic speech signals communication purposes 
generally admitted single pitch estimation methods appropriate multipitch estimation 
days computational multipitch estimation mpe fallen clearly humans accuracy flexibility 
attempts field automatic transcription music limited regard polyphony number simultaneous sounds pitch range variety sounds involved 
years progress taken place 
martin proposed system utilized musical knowledge transcribing voice piano compositions 
kashino describe model able handle different instruments 
goto system particularly designed extract melody bass lines real world musical recordings 
psychoacoustic knowledge succesfully utilized models brown cooke de kawahara 
purely mathematical approaches proposed 
aim propose general purpose mpe algorithm operates reliably rich polyphonies wide mixture signal predominant pitch detection store pitch iterate estimate sound spectrum pitch range variety sound sources 
applications numerous including automatic transcription music content music indexing retrieval sound separation timbre parameter estimation polyphonic signals 
example application sound separation application digital audio effects musically meaningful part incoming signals 
organization follows 
section mpe algorithm described 
followed validation experiments comparison musicians performance section 
database sounds diverse noise conditions statistical evaluation listening tests conducted comparison human performance 
section sound separation mechanism described mpe algorithm apply audio effects polyphonic musical signals 

multipitch estimation remove partials iterative estimation separation approach multipitch estimation 
algorithm consists main parts applied iterative succession illustrated fig 

part predominant pitch estimation finds pitch prominent sound interference harmonic noisy sounds 
second part spectrum detected sound estimated subtracted mixture 
estimation subtraction steps repeated residual signal 
review discussion earlier iterative approaches see 

predominant pitch estimation overview predominant pitch estimation algorithm calculate independent pitch estimates separate frequency bands combine results yield global estimate 
approach taken handle sounds exhibit provide robustness case badly corrupted signals fragment frequency range 
sake computational efficiency bandwise processing done frequency domain 
single fast fourier transform needed local regions spectrum separately processed 
illustrates processing sequence predominant pitch estimation algorithm 
discrete fourier transform discrete fourier transform spectrum preprocessing spectrum acoustic input signal xe magnitude db bandwise processing combine bandwise results frequency hz calculated hamming windowed time domain signal 
passing spectrum pitch analysis certain amount preprocessing takes place order eliminate noise provide robustness sounds spectra 
enhanced spectrum xe obtained logarithm magnitude spectrum highpass result 
enhanced spectrum xe processed logarithmically distributed bands extend hz khz illustrated fig 

band comprises octave region spectrum subject weighting triangular window 
logarithmic amplitude scale approximates roughly critical band response human hearing 
overlap adjacent windows making sum unity 
band fundamental frequency likelihood vector lb calculated 
resolution vector enhanced spectrum frequency sample xe having corresponding fundamental frequency likelihood sample lb 
capital letter denote fundamental frequency lower case letter denote frequency 
sample corresponds fundamental frequency value fs size time frame samples fs sampling rate 
frequency samples xe band defined range lowest sample number samples band 
bandwise fundamental frequency likelihoods lb calculated finding series nth processing sequence predominant pitch estimation algorithm frequency bands calculations take place 
kb kb kb spectrum samples band maximizes likelihood lb max xe kb hn offset series partials 
value varied find maximum value stored lb 
different offsets tested series higher harmonic partials may shifted due inharmonicity 
kb number harmonic partials sum normalization factor varies different coefficients important training musical samples varying conditions 
final phase bandwise likelihoods drawn yield global pitch likelihoods 
straightforward summation likelihood vectors associate likelihoods appropriately fundamental frequencies different bands match sounds 
inharmonicity appears rising tendency fundamental frequency function center frequency bands 
overcome inharmonicity factor estimated taken account 
useful raise likelihoods second power prior summing order provide robustness strong interference pitch may observable limited frequency range 
maximum global likelihood determine true fundamental frequency 
output algorithm consists fundamental frequency inharmonicity factor frequencies amplitudes harmonic series sound 
optional step calculate perceptually corrected pitch value psychoacoustic measurements 
general inharmonicity causes slight rise perceived pitch 

extension multipitch estimation pitch model capable making robust predominant pitch detections polyphonic signals 
provided time frame long correct pitches certainty voice polyphonies 
precise places individual harmonic calculated fundamental frequency inharmonicity factor detected sound 
natural strategy extending algorithm mpe remove partials detected sound mixture apply pitch algorithm iteratively residual spectrum 
detected sounds efficiently separated frequency domain 
things needed remove sinusoidal partial mixture spectrum 
estimates frequency amplitude phase partial obtained 
assumed parameters remain constant analysis frame 
second estimated parameters partial spectrum approximated vicinity partial linearly subtracted mixture spectrum 
initial estimates amplitude angular frequency phase sinusoidal partial st cos st sound produced predominant pitch estimation algorithm 
efficient techniques estimating precise values parameters proposed 
method widely adopted apply hamming windowing zero padding time domain quadratic interpolation spectrum 
continuous short time fourier transform defined wt st performs temporal weighting window function defined zero 
window model expressive accommodate hamming window standard sine window rectangular window 
integral eq 
dt wt aw bw cos wt magnitude db frequency hz illustration spectral smoothing principle 
enhanced spectrum contains sounds lower detected 
see text details 
solved analytically closed form straightforward algebra 
expressed function parameters sinusoid window 
easy matter apply solution discrete domain calculate efficiently desired fourier transform samples vicinity known sinusoid 
solution contains twelve exp operations significantly efficient generating samples time domain calculating discrete fourier transform 
parameter estimation local magnitude spectrum calculation subtraction repeated partial sound removed mixture spectrum 
simulations run evaluate performance described iterative estimation separation approach 
distribution remaining errors revealed problem fix 
cases sounds rational number relation lot partials sounds coincide share frequency 
firstly detected sound removed coinciding harmonics remaining sound removed subtraction procedure 
cases particularly iterations remaining sound gets corrupted correctly analyzed coming iterations 
solution problem intuitive efficient valid spectra detected sounds smoothed subtracting mixture 
idea derived psychoacoustics human auditory system prefers associate series partials single acoustic source smooth spectrum decreasing amplitude function frequency 
harmonics raised intensity segregate readily stand independent sound 
consider enhanced spectrum sound mixture fig 

lower pitched sound detected coinciding partials tend higher magnitudes ones 
sound spectrum smoothed partials rise smooth spectrum remain residual subtraction 
smoothing operation implemented calculating moving average amplitudes harmonic partials 
octave wide hamming window centered harmonic weighted mean calculated window 
smooth spectrum illustrated thin horizontal line fig 

minimum original averaged amplitudes taken illustrated thick line fig 

smoothed amplitude values subtraction ner polyphony note error rates predominant pitch estimation different polyphonies 
stage drastic improvement simulations approximately halving error rate polyphonies 

simulation results comparison human performance 
simulation results large amount simulations run monitor behaviour proposed algorithm 
test material consisted database sung vowels plus different musical instruments comprising string instruments brass reed instruments 
introduce different sound mechanisms variety spectra 
sound mixtures generated instrument random note playing range restricting pitch octaves hz hz 
desired number simultaneous sounds allotted mixed equal mean square levels 
acoustic input fed mpe algorithm estimated pitches single time frame 
note error rate ner metric taken measure pitch estimation accuracy 
correct pitch defined deviate half semitone correct value making round correct note western musical scale 
ner defined sum pitches error divided number pitches transcription 
errors types 
substitution deletion errors counted number pitches correctly estimated system 
insertion errors occurred number detected pitches exceeds 
shows predominant pitch estimation different polyphonies 
predominant pitch estimate defined correct matched true pitch component sounds 
random mixtures sounds generated instances 
pitch estimation performed single ms time frame 
may long speech processing point view long musical chord identification tasks frequency partial density may high mixtures low pitches 
ner predominant pitch detection stays note mixtures showing significant robustness polyphonic signals 
surprisingly increasing polyphony helps detect true pitches 
phenomenon consistently observed mpe ner pitch detections smaller note mixtures 
explanation richer mixtures probable contain clear sound irregularities detected difficult cases remain subsequent iterations 
ner polyphony note error rates multipitch estimation different polyphonies 
bars represent different shades gray error cumulation iteration 
ner pink noise white noise drum sounds polyphony effect additive noise interfering percussive sounds 
note error rates function polyphony 
different noise levels noise type db db db reading left right 
results multipitch estimation different polyphonies shown fig 

random mixtures generated estimator requested find pitches single ms time frame ms onset sounds 
number sounds extract number iterations run acoustic mixture signal 
bars represent function polyphony ner random voice polyphonies average 
different shades grey bar indicate error cumulation iteration errors occurred iteration bottom errors iteration top 
general impression system works reliably exhibits graceful degradation increasing polyphony abrupt breakdown point 
strongest advantage chosen iterative approach 
performance predominant pitch detection observed bottom slices bar discussed 
analysis error cumulation reveals errors occurred iteration account approximately half errors polyphonies probability error increases rapidly course iteration 
indicating subtraction process perfectly conducted listening tests suggest feature problem symptom algorithms 
mixtures sound difficult hear spectrum virtually buried sounds 
illustrates effect different types levels additive noise 
pink white noise generated band hz khz 
instrument interference generated randomizing drum samples roland mk ii drum machine 
test set comprised bass drum hi hat sounds 
drum samples set time harmonic sounds 
mean square levels harmonic sounds mixture equalized noise level set relation individual sounds analysis frame 
noise levels represent signal noise ratios viewpoint individual sound mixture 
ms frame ms offset position applied 
experiments different time frame lengths revealed shortening frame ms ms approximately doubles error rate polyphonies 
partly caused fact applied technique able resolve pitch required accuracy 
irregularities sounds vibrato difficult handle short frames 
despite reservations fact remains reliable mpe require significantly longer time frames single pitch estimation 

comparison human performance listening tests conducted measure human pitch identification ability particularly ability trained musicians transcribe polyphonic sound mixtures 
detailed analysis results scope published holm klapuri 
summary main findings reviewed 
test stimuli consisted computer generated mixtures simultaneously sounds reproduced sampled grand piano sounds mcgill university master samples collection 
number occurring sounds varied 
gap highest lowest pitch individual mixture wider semitones order task feasible subjects absolute pitch rare ability name pitch sound tone 
mixtures generated partly overlapping pitch ranges 
results reported different ranges 
low register extended hz hz middle register hz hz high register hz hz 
total test comprised stimuli different categories 
task write musical intervals pitch relations sound mixtures 
absolute pitch values asked number sounds mixture told 
test resembles musical interval chord identification tests part basic musical training western countries 
total subjects participated test 
trained musicians sense having taken years musical ear training 
subjects students university level 
advanced musicians possessing absolute pitch distinguished pitch identification abilities 
subject amateur musician similar musical ability students 
shows results listening test 
chord error rates cer plotted different stimulus categories 
cer percentage sound mixtures pitch identification error occurred 
labels categories consist number signifies polyphony letter tells pitch register 
letter refers middle high low register 
performance curves aver cer chord error rates subjects weakest skilled bars computer model stimulus category chord error rates human listeners computational model different stimulus categories 
aged different groups 
lowest curve represents skilled subjects middle curve average subjects highest curve clearly weakest subjects 
directly compared fig 

cer metric demanding accepting sound mixtures pitches correctly identified 
taken absolute pitch values asked 
case ways matching pitch intervals transcription intervals correct 
rule thumb half erroneously identified note mixtures cases notes remained undetected 
note mixtures usually incorrect pitches skilled subjects having note error 
sake comparison stimuli performance criteria listening test re evaluate proposed computational model 
instances generated category included fig 
exactly software code produced samples listening test 
fed described mpe system tailoring code parameters 
cer metric performance measure 
results illustrated bars fig 

general impression skilled subjects perform better computational model 
performance differences high low registers quite revealing 
devised algorithm able resolve combinations low sounds chance human listeners 
due frequency resolution applied 
hand human listeners perform relatively high register 
due efficient temporal features onset asynchrony different decay rates high piano tones 
available single time frame mpe system 

application signal manipulation mpe intimately linked auditory scene analysis 
algorithm outputs pitches mixed sounds indicates spectrum components belong source 
motivated sound separation system developed attempts extracts original time domain waveforms sound mixing 
dedicated mechanism developed purpose mpe system operates frequency spectrum single time frame 

sound separation enable manipulation selected parts signal sinusoidal modeling chosen signal representation 
standard sinusoidal model signal analyzed short frames 
frame prominent spectral peaks located frequencies amplitudes phases solved connected form frame frame trajectories 
output model set sinusoids time varying frequencies amplitudes phases 
synthesized time domain represent harmonic components signal sum trajectories 
sinusoidal model allows manipulation signals parametric form altering sinusoidal parameters resynthesis 
sinusoids different sound sources order synthesize sounds separately different manipulations different sounds 
applied system differs sinusoidal model ways 
mpe algorithm gives frequencies harmonic components need located time varying amplitudes phases estimated 
frame frame tracking needed frequencies harmonic components assumed constant inside single mpe window longer sinusoidal modeling frame 
unfortunately method fails detect small changes fundamental frequency vibrato 
set sinusoids known frequencies amplitudes phases solved square solution 
method gives results especially case frequencies sinusoids close situation methods obtaining amplitudes phases directly short time amplitude spectrum perform poorly 
frequencies sinusoids close amplitudes resolved directly 
parameters resulting summary sinusoid stored component sinusoids deduced procedure described 
amplitudes phases sinusoids estimated time frame 
doing parameters coinciding components directly resolved deduced sum 
frequencies components exactly amplitude envelope sum components modulates rate difference frequencies components 
assuming original amplitude envelopes slowly varying solve mixed components follows 
amplitude envelope obtained lowpass filtering envelope mixed components subtracting original rectifying lowpass filtering difference 
association separated amplitude curves due sources production done comparing curves solved amplitude envelopes overlapping 
comparison done example perceptual distance measures 
harmonic components overlapping amplitudes simply interpolated solved components sound 

manipulation experiments simulations run validate separation procedure experiment audio effects process meaning ful part incoming musical signal 
audio examples available www cs tut fi dafx 
experiment aimed applying basic audio effects concurrently playing notes musical performance 
target sound selected varying criteria separated subtracted mixture obtain residual signal 
chosen sound manipulated desired effect residual signal 
enabled processings comprise basic effects vibrato chorus complicated ones sliding successive pitch values melody breaking chords notes playing 
general observation separation mechanism able extract sounds reliably mixtures number concurrent sounds increases harmonics coincide quality result decreases rapidly 
single misclassified sinusoid may disturbing audible effect separated sound listened isolation 
problem outstanding separated manipulated sound played residual problem exists 
timbre instrument detected sound changed separation needed produce residual signal separated note reproduced clean sound 
second set experiments analyzed signals resynthesized symbolic information pitch values produced mpe system 
separation needed case acoustic database separated sounds provides material play midi information 
enabled processings include inevitable change timbre transposition higher lower pitch register rule addition removal supplementary play parts 
main drawback approach concept acoustical residual detected pitches include voices time prominent ones effects probably aimed applied 
turned difficult estimate number concurrent voices reliably utilizing musical context 
hand detection weakest sounds difficult impossible 
third set experiments aimed extracting expressive control information original complex musical signal order instrument changes sound natural original context 
sound completely separated mixture harmonics tracked interference 
monitor loudness pitch contour brass reed instruments drive parameters resynthesis samples sound mechanistic 

multipitch estimation performed quite accurately level single time frame temporal features available 
applies proposed computational method human listeners wide pitch range 
variety musical sounds priori knowledge involved sounds necessary 
algorithm works reliably rich polyphonies presence noisy sounds drums 
processing examples demonstrate system generic reliable enable novel flexible ways processing polyphonic musical mixtures 
efficient utilization musical predictions context needed enhance quality separated sounds detect reliably weakest sounds rich polyphonies 

bregman auditory scene analysis mit press 
rabiner cheng rosenberg 

comparative performance study pitch detection algorithms ieee trans 
acoust speech signal processing vol assp 
klapuri 

automatic transcription music msc thesis tampere university technology 
martin 

automatic transcription simple polyphonic music robust front processing massachusetts institute technology media laboratory perceptual computing section technical report 
kashino kinoshita tanaka 

organization hierarchical perceptual sounds music scene analysis autonomous processing modules quantitative information integration mechanism proc 
international joint conf 
artificial intelligence montr goto 

robust predominant estimation method real time detection melody bass lines cd recordings proc 
ieee international conf 
acoust speech signal processing istanbul turkey 
brown cooke 

perceptual grouping musical sounds computational model new music research 
brown 

blackboard architecture computational auditory scene analysis speech communication 
de cheveign kawahara 

multiple period estimation pitch perception model speech communication 


periodicity transforms ieee trans 
signal processing vol 

de cheveign 

separation concurrent harmonic sounds fundamental frequency estimation cancellation model auditory processing acoust 
soc 
am 

klapuri 

wide band pitch estimation natural sound sources th audio engin 
soc 
convention preprint munich germany 
inen verma lim ki 

effect inharmonicity pitch string instrument sounds proc 
international computer music conf berlin 
rodet 

musical sound signal analysis synthesis sinusoidal residual elementary waveform models ieee time frequency time scale workshop coventry grande ao 
ph 
lie 

extraction spectral peak parameters short time fourier transform windows 
ieee workshop applications signal processing audio acoustics 
new york 
klapuri 

separation harmonic sound sources sinusoidal modeling proc 
ieee international conf 
acoust speech signal processing istanbul turkey 
