bagging boosting quinlan university sydney sydney australia quinlan cs su oz au breiman bagging freund schapire boosting methods improving predictive power classifier learning systems 
form set classifiers combined voting bagging generating replicated bootstrap samples data boosting adjusting weights training instances 
reports results applying techniques system learns decision trees testing representative collection datasets 
approaches substantially improve predictive accuracy boosting shows greater benefit 
hand boosting produces severe degradation datasets 
small change way boosting combines votes learned classifiers reduces downside leads slightly better results datasets considered 
renewed interest increasing accuracy generating aggregating multiple classifiers 
idea growing multiple trees new see instance quinlan buntine justification methods empirical 
contrast new approaches producing classifiers applicable wide variety learning systems theoretical analyses behavior composite classifier 
data classifier learning systems consists attribute value vectors instances 
bootstrap aggregating bagging breiman boosting freund schapire manipulate training data order generate different classifiers :10.1.1.32.8918
bagging produces replicate training sets sampling replacement training instances 
boosting uses instances repetition maintains weight instance training set reflects importance adjusting weights causes learner focus different instances leads different classifiers 
case multiple classifiers combined voting form composite classifier 
bagging component classifier vote boosting assigns different voting strengths component classifiers basis accuracy 
breiman introduces concept order correct classifier learning system training sets tends predict correct class test instance frequently class 
order correct learner may produce optimal classifiers breiman shows aggregating classifiers produced order correct learner results optimal classifier 
breiman notes vital element instability prediction method 
perturbing learning set cause significant changes predictor constructed bagging improve accuracy 
boosting version boosting investigated adaboost freund schapire :10.1.1.32.8918
drawing succession independent bootstrap samples original instances boosting maintains weight instance higher weight instance influences classifier learned 
trial vector weights adjusted reflect performance corresponding classifier result weight misclassified instances increased 
final classifier aggregates learned classifiers voting classifier vote function accuracy 
denote weight instance trial trial classifier constructed instances distribution weight instance reflects probability occurrence 
