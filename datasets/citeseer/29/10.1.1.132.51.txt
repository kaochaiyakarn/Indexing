semi supervised support vector machines bennett department mathematical sciences rensselaer polytechnic institute troy ny rpi edu department decision sciences engineering systems rensselaer polytechnic institute troy ny rpi edu introduce semi supervised support vector machine vm method 
training set labeled data working set unlabeled data vm constructs support vector machine training working sets 
vm solve transduction problem risk minimization orm posed vapnik 
transduction problem estimate value classification function points working set 
contrasts standard inductive learning problem estimating classification function possible values fixed function deduce classes working set data 
propose general vm model minimizes misclassification error function capacity available data 
accepted publication proceedings neural information processing systems denver 
propose method semi supervised support vector machines vm 
vm constructed mixture labeled data training set unlabeled data working set 
objective assign class labels working set best support vector machine svm constructed 
working set empty method standard svm approach classification :10.1.1.15.9362:10.1.1.117.3731
training set empty method form unsupervised learning 
semi supervised learning occurs training working sets nonempty 
semi supervised learning problems small training sets large working sets form semi supervised clustering 
successful semi supervised algorithms means fuzzy means clustering 
margin separation euclidean distance norm 
maximize margin minimize subject constraints 
structural risk minimization fixed empirical misclassification rate larger margins lead better generalization prevent overfitting high dimensional attribute spaces 
classifier called support vector machine solution depends points called support vectors located supporting planes 
general classes separable generalized optimal plane problem :10.1.1.15.9362
slack term added point point misclassified 
final formulation min yi xi fixed penalty parameter 
capacity control provided margin maximization imperative achieve generalization 
robust linear programming approach svm identical margin term changed norm norm wj 
statistical learning theory potentially extended incorporate alternative norms 
major benefit dimensionality reduction 
minimize magnitude weights forces weights due properties norm 
benefit solved linear programming quadratic programming 
approaches extended handle nonlinear discrimination kernel functions :10.1.1.117.3731
empirical comparisons approaches significant difference generalization formulations 
semi supervised support vector machines formulate vm start svm formulation add constraints point working set 
constraint calculates misclassification error point class constraint calculates misclassification error point class 
objective function calculates minimum possible misclassification errors 
