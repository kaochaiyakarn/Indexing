onemercury towards automatic annotation environmental science metadata suppawong tuarob line c pouchard natasha noy je ery s horsburgh giri palanisamy pennsylvania state university university park pa usa oak ridge national laboratory oak ridge tn usa stanford university stanford ca usa utah state university logan ut usa suppawongpouchardlcnoyje horsburghpalanisamyg abstract rapid growth diverse data types greater vol umes available environmental sciences prompts scientists seek knowledge data multiple places times scales facilitate need onemercury recently implemented part dataone project serve portal accessing environmental observational data across globe onemercury harvests metadata data hosted multiple repositories makes searchable however harvested metadata records sometimes poorly annotated lacking meaningful keywords hence unlikely retrieved search process paper develop algorithm automatic metadata annotation transform problem tag recommendation problem propose score propagation style algo rithm tag recommendation experiments four data sets environmental science metadata records show great promises performance method also shed light di erent natures data sets introduction environmental sciences become complex data intensive needing accesses heterogenous data collected multiple places times matic scales example research climate changes involve exploring analyzing observational data migration animals temper ature shifts across world time time needs access heterogenous data apparent rapid expansion observational data quantity heterogeneity poses huge challenges data seekers obtain right information research problems behoove tools auto matically manage discover link big data diverse sources present data forms easily accessible comprehensible onemercury search service recently dataone federated data network built facilitate accesses preservation environmental ecological science data across world come exist gain increasingly popularity dataone harvests meta data di erent environmental data providers make searchable via search interface onemercury built mercury distributed metadata man https cn dataone org onemercury agement system onemercury o ers two modes searching basic advance basic mode requires user input set keywords system return matching results advance mode adds capability lter search results authors projects keywords challenge proposed solution linking data heterogenous sources always cost one biggest problems onemercury facing di erent levels annotation harvested metadata records poorly annotated metadata records tend missed search process lack meaningful keywords records compatible advance mode o ered onemercury requires metadata records semantically annotated keywords keyword library explosion amount metadata records harvested increasingly number data repositories makes even impossible annotate harvested records manually hand urging need tool capable automatically annotating poorly curated metadata records paper address problem automatic annotation metadata records goal build fast robust system annotates given metadata record meaningful related keywords given ontology idea annotate poorly annotated record keywords associated well annotated records similar propose solution problem rst transforming problem tag recommendation prob lem set recommended tags used annotate given metadata record propose algorithm deals problem problem de nition de ne document tuple textual content set tags d c e c textual content represented sequence terms document d e set tags associated document given tag library t set annotated documents s non annotated query document q task recommend ranked set k tags taken t query q document said annotated least one tag otherwise non annotated formal description variable given t t t tm ti tag s s s sn si csi esi esi t esi q cq contributions paper four key contributions follows address real word problem linking data multiple archives faced onemercury transform problem tag recommendation problem generalize problem proposed solution can apply domains propose novel score propagation technique tag recommendation given document query q rst calculate similarity score query document source s score propagated tags document source tags ranked scores top k tags returned recommendation propose two di erent measures computing similarity two documents term frequency inverse document frequency tfidf topic model tm crawl environmental science metadata records di erent archives data sets oak ridge national laboratory distributed active archive center daac dryad digital repository knowledge net work biocomplexity knb treebase repository phyloge netic information select roughly records archive experiments validate proposed method using aggressive empirical evaluations use document wise fold cross validation evaluate schemes evaluation metrics precision recall f mrr mean reciprocal rank bpref binary preference evaluation metrics extensively used together evaluate recommendation systems related works since choose transform setting tag recommendation problem brie y state related literature tag recommendation gained substantial amount interest recent years work however focuses personalized tag recommendation suggesting tags user s object based user s preference social connection mishne et al employ social connection users recommend tags weblogs based similar weblogs tagged users wu et al utilize social network simi larity contents objects learn model recommending tags system aims towards recommending tags flickr photo objects personalized schemes proven useful domains data limited information authors users social connections liu et al propose tag recommendation model using machine translation algorithm basically trains translation model translate textual descrip tion document training set tags krestel et al employ topic modeling recommending tags use latent dirichlet allocation algo rithm mine topics training corpus using tags represent textual content evaluate method association rule based method proposed data sets obtain data sets environmental metadata records experiments di erent archives oak ridge national laboratory distributed active archive center daac dryad digital repository dryad knowledge network biocomplexity knb treebase repository phylogenetic information treebase statistics data sets including number docs tags avg tags doc tags tag util words avg words doc daac dryad knb treebase table statistics data sets documents total number tags average number tags per document num ber unique tags tag library size tag utilization number words data set size average number word per document summarized table tag utilization average number documents tag appears tags de ned unique tags setting assume documents independently annotated tags training sets represent gold standard however metadata records may independent since may originated projects authors hence annotated similar styles sets keywords mitigate problem randomly select subset anno tated documents except daac data set documents hence select archive experiments combine textual attributes e title abtract description together textual content document preprocess textual content document removing common stop words punctuation stemming words using porter stemming algorithm preliminaries proposed solution built upon concepts cosine similarity term frequency inverse document frequency tfidf latent dirichlet alloca tion lda brie y introduce fortify readers background going cosine similarity general cosine similarity measure similarity two vectors measuring cosine angle given two vectors b cosine similarity de ned using dot product magnitude n b ai bi cosinesim b b nn ai bi cosinesim b outputs indicating independence value indicates level similarity cosine similarity heavily used calculated similarity two vectorized documents term frequency inverse document frequency tf idf used extensively information retrieval area re ects im portant term document corpus tf idf two components term frequency tf inverse document frequency idf tf frequency term appearing document idf term measures important term corpus computed based document frequency number documents term appears formally given term t document d corpus document collection d tf t d count t d idf t d log d d e d t e d tfidf t d d tf t d idf t d can construct tf idf vector document d given corpus d follows t f idf d d tfidf t d d tfidf t d d tfidf tn d d consequently one wishes compute similarity score two docu ments d d cosine similarity can computed tf idf vectors representing two documents docsimt f idf d d d cosinesim tf idf d d t f idf d d latent dirichlet allocation text mining latent dirichlet allocation lda generative model allows document represented mixture topics basic tuition lda topic modeling author set topics mind writing document topic de ned distribution terms author chooses set terms topics compose document assumption whole document can represented using mixture di erent topics mathematically lda model described follows z p ti d p ti zi j p zi j d j p ti d probability term ti document d zi latent hidden topic z number topics number needs prede ned p ti zi j probability term ti topic j p zi j d probability picking term topic j document d topics modeled can assign distribution topics given document using technique called inference document can represented vector numbers represents probability document belonging topic infer d z z z zq z q z set topics d document zi probability docu ment d falling topic since document can represented using vector numbers one can compute topic similarity two documents d d using cosine similarity follows docsimtm d d z cosinesim infer d z infer d z method section describe score propagation method tag recommenda tion show algorithm works using simple example section later discuss variation document similarity measures use system overview figure illustrates ow score propagation algorithm simple exam ple three documents source annotated tags water seagull seagull soil bird bird air respectively algorithm proceeds follows step document similarity score computed document query fig overview score propagation method document source step scores propagated tags source document scores combined tag receives multiple scores example tags seagull bird obtain multiple scores respectively step tags ranked scores top k tags returned suggested tags document similarity measures explore two di erent document similarity measures computing similarity document query documents source tfidf based rst measure relies term frequency inverse doc ument frequency discussed section setting d document source order compute idf part scheme documents source need rst indexed hence training phase preprocess involves indexing documents compute similarity query q source document d using docsimt f idf q d d de ned equation use lingpipe perform indexing calculating tfidf based similarity tm based second document similarity measure utilizes topic distribu tions documents hence training process involves modeling topics source using lda algorithm discussed section use stanford topic modeling toolbox collapsed variational bayes approximation identify topics source documents document generate uni grams bi grams tri grams combine represent textual con tent document algorithm takes two input parameters number topics identi ed maximum number training iterations experiments varying two parameters x respectively assigning topic distribution document use inference method proposed evaluation discussion evaluate methods using tag prediction protocol arti cially create test query document removing tags annotated document task predict removed tags two reasons behind choosing evaluation scheme evaluation can done fully automatically since data sets large manual evaluation e human identify whether recommended tag relevant infeasible evaluation can done existing gold standard established manually tagged expert annotators good understanding data manual evaluation lead evaluation biases test algorithm using document similarity measures data set using two di erent source training set modes self source cross source self source mode documents training set selected archive query cross source mode combines train ing documents archives together evaluate algorithms di erent source modes using document wise fold cross validation data set split equal subsets fold e subset used testing set subsets combined used source training set results fold summed averages reported evaluation done windows pc intel core cpu ghz gb ram evaluation metrics precision recall f document query test set use original set tags ground truth tg assume set recommended tags tr correctly recommended tags tg tr precision recall f measures de ned follows tg tr tg tr precision recall precision recall f tr tg precision recall experiments number recommended tags ranges wise note better tag recommendation systems tend rank correct tags higher incorrect ones however precision recall f measures take ranking account evaluate performance ranked results employ following evaluation metrics mean reciprocal rank mrr mrr measure takes ordering account measures well rst cor rectly recommended tag ranked formally given testing set q let rankq rank rst corrected answer query q e q mrr query set q de ned follows mrr q rankq qeq precision c f d precision vs recall fig precision recall f precision vs recall tfidf based method performed di erent data sets source selection modes run algorithm tfidf based document similarity data sets using self cross source modes figure summarizes precision recall f prec vs rec graph table summarizes mmr bpref time wise training recommending performances ttt trt att art stand total train time total recommend time average train time per fold average recommend time per fold respectively metric self recommendation cross recommendation daac dryad knb treebase daac dryad knb treebase mrr bpref ttt hours trt min att sec art sec table mrr bpref time wise performance statistics tm based method performed di erent data sets source selection modes metric self recommendation cross recommendation daac dryad knb treebase daac dryad knb treebase mrr bpref ttt sec trt sec att sec art sec table mrr bpref time wise performance statistics tfidf based method performed di erent data sets source selection modes results get following observations first performance di ers signi cantly across data sets overall tfidf based method performs better daac knb data sets daac data set smaller tag library unique tags hence chance recommending correct tags re ected recall growth rates higher data sets knb data set though largest tag library high tag utilization rate hence chance correctly guessing tags expectedly higher second self source recommendations always perform better cross source recommendations respect evaluation scheme given document query cross recommendation system may introduce alien tags data sets certainly identi ed incorrect tags note even though cross recommendation systems may perform worse self recommendation ones respect evaluation setting real world alien tags may actually semantic relevance query evaluation tm based method run score propagation algorithm tm based document similarity data set using self cross recommendation modes figure summarizes precision recall f along prec vs rec comparison table summarizes mmr bpref time wise performances comparison among di erent data sets similar result tfidf based method except performance knb data set seems surprisingly outstanding performance comparison methods compare performances two document similarity measures tfidf based tm based data sets self recommendation figure precision b recall c f d precision vs recall fig precision recall f precision vs recall tm based method performed di erent data sets source selection modes summarizes precision recall f prec vs rec graphs tm based approach obviously outperforms tfidf based approach daac dryad knb data sets performance tm based approach dominant applied knb data set seen precision vs recall graph figure d curve forms shape close ideal precision vs recall curve comparison however dominant treebase data set actually algorithms perform poorly treebase data set hypothesize treebase documents sparse tags statistics document treebase data set words tags average sparse texts lead weak relationship nding textually similar documents tfidf based approach poor quality topic model used tm based approach small number tags per document makes even harder predict right tags note though overall tm based approach recommends better quality tags training times take signi cantly longer tfidf based approach example takes roughly minutes train precision b recall c f d precision vs recall fig comparison tfidf tm approaches di erent data sets using self sources tm based method modeling topics using documents takes seconds train index amount documents via tfidf based approach however also note evaluation done local pc issue training times much diminished system employed powerful computing server conclusions future research paper propose algorithm automatic metadata annotation inspired real world problem faced onemerucy search system environmental science metadata harvested multiple data archives metadata di erent archives di erent levels curation hence behooves system automatically annotates poorly annotated meta data records treat metadata record tagged document transform problem tag recommendation problem propose score propagation model tag recommendation two variations document similarity measures tfidf based topic model tm based tm based approach yields impressive results though cost longer training times future works include evaluating approaches well known state art method mines association rules tag recom mendation also plan adopt classi cation technique rank tags tag library finally aim implement automatic meta data annotation system onemercury search service give rise implementation system integration issues references asuncion welling m smyth p teh y w smoothing inference topic models proceedings twenty fifth conference uncertainty arti cial intelligence pp uai auai press arlington virginia united states blei d m ng y jordan m latent dirichlet allocation j mach learn res mar buckley c voorhees e m retrieval evaluation incomplete information proceedings th annual international acm sigir conference research development information retrieval pp sigir acm new york ny usa heymann p ramage d garcia molina h social tag prediction proceed ings st annual international acm sigir conference research development information retrieval pp sigir acm new york ny usa krestel r fankhauser p nejdl w latent dirichlet allocation tag recommendation proceedings third acm conference recom mender systems pp recsys acm new york ny usa liu z chen x sun m simple word trigger method cial tag suggestion proceedings conference empirical meth ods natural language processing pp emnlp sociation computational linguistics stroudsburg pa usa michener w vieglais d vision t kunze j cruse p jan ee g dataone data observation network earth preserving data enabling innovation biological environmental sciences dlib magazine mishne g autotag collaborative approach automated tag assignment weblog posts proceedings th international conference world wide web pp www acm new york ny usa treeratpituk p teregowda p huang j giles c l seerlab system extracting key phrases scholarly documents proceedings th international workshop semantic evaluation pp semeval association computational linguistics stroudsburg pa usa wu l yang l yu n hua x s learning tag proceedings th international conference world wide web pp www acm new york ny usa