journal arti cial intelligence research submitted published parameter learning logic programs symbolic statistical modeling sato kameya dept computer science graduate school information science engineering tokyo institute technology ku tokyo japan sato mi cs ac jp mi cs ac jp propose logical mathematical framework statistical parameter learning parameterized logic programs de nite clause programs containing probabilistic facts parameterized distribution 
extends traditional herbrand model semantics logic programming distribution semantics possible world semantics probability distribution unconditionally applicable arbitrary logic programs including ones hmms pcfgs bayesian networks 
propose new em algorithm graphical em algorithm class parameterized logic programs representing sequential decision processes decision exclusive independent 
runs new data structure called support graphs describing logical relationship observations explanations learns parameters computing inside outside probability generalized logic programs 
complexity analysis shows combined oldt search explanations observations graphical em algorithm despite generality time complexity existing em algorithms baum welch algorithm hmms inside outside algorithm pcfgs singly connected bayesian networks independently research eld 
learning experiments pcfgs corpora moderate size indicate graphical em algorithm signi cantly outperform inside outside algorithm 
