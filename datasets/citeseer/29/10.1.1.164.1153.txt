ieee transactions neural networks vol 
november face recognition independent component analysis marian stewart bartlett member ieee javier movellan member ieee terrence sejnowski fellow ieee number current face recognition algorithms face representations unsupervised statistical methods 
typically methods find set basis images represent faces linear combination images 
principal component analysis pca popular example methods 
basis images pca depend pairwise relationships pixels image database 
task face recognition important information may contained high order relationships pixels reasonable expect better basis images may methods sensitive high order statistics 
independent component analysis ica generalization pca method 
version ica derived principle optimal information transfer sigmoidal neurons 
ica performed face images feret database different architectures treated images random variables pixels outcomes second treated pixels random variables images outcomes 
architecture spatially local basis images faces 
second architecture produced factorial face code 
ica representations superior representations pca recognizing faces days changes expression 
classifier combined ica representations gave best performance 
index terms eigenfaces face recognition independent component analysis ica principal component analysis pca unsupervised learning 
redundancy sensory input contains structural information environment 
barlow argued redundancy provides knowledge role sensory system develop factorial representations dependencies separated independent components manuscript received may revised may 
supported university california digital media innovation program national science foundation iit national research service award mh lawrence livermore national laboratories agreement howard hughes medical institute 
abbreviated version appears proceedings spie symposium electronic imaging science technology human vision electronic imaging iii vol 
rogowitz pappas eds 
portions feret database facial images collected feret program army research laboratory 
authors university california san diego la jolla ca usa mail salk edu javier ucsd edu terry salk edu 
sejnowski howard hughes medical institute salk institute la jolla ca usa 
digital object identifier tnn ics 
barlow argued representations advantageous encoding complex objects characterized high order dependencies 
atick redlich argued representations general coding strategy visual system 
principal component analysis pca popular unsupervised statistical method find useful image representations 
consider set basis images pixels 
standard basis set consists single active pixel intensity basis image different active pixel 
image pixels decomposed linear combination standard basis images 
fact pixel values image seen coordinates image respect standard basis 
goal pca find better set basis images new basis image coordinates pca coefficients uncorrelated linearly predicted 
pca seen partially implementing barlow ideas dependencies show joint distribution pixels separated marginal distributions pca coefficients 
pca separate pairwise linear dependencies pixels 
high order dependencies show joint distribution pca coefficients properly separated 
successful representations face recognition eigenfaces holons local feature analysis pca :10.1.1.12.7580
task face recognition important information may contained high order relationships image pixels important investigate generalizations pca sensitive high order relationships just second order relationships advantageous 
independent component analysis ica generalization 
number algorithms performing ica proposed 
see reviews 
employ algorithm developed bell sejnowski point view optimal information transfer neural networks sigmoidal transfer functions 
algorithm proven successful separating randomly mixed auditory signals cocktail party problem separating eeg signals functional magnetic resonance imaging fmri signals 
performed ica image set architectures 
architecture treated images random variables pixels outcomes architecture ii treated ieee bartlett face recognition independent component analysis pixels random variables images outcomes 
matlab code ica representations available ucsd edu 
face recognition performance tested feret database 
face recognition performances ica representations benchmarked comparing performances pca equivalent eigenfaces representation :10.1.1.12.7580:10.1.1.12.7580
ica representations combined single classifier 
ii 
ica number algorithms performing ica 
chose infomax algorithm proposed bell sejnowski derived principle optimal information transfer neurons sigmoidal transfer functions 
algorithm motivated follows dimensional random vector representing distribution inputs environment 
boldface capitals denote random variables plain text capitals denote matrices 
invertible matrix random variable representing outputs neurons 
component invertible squashing function mapping real numbers interval 
typically logistic function variables linear combinations inputs interpreted presynaptic activations neurons 
variables interpreted postsynaptic activation rates bounded interval goal bell sejnowski algorithm maximize mutual information environment output neural network achieved performing gradient ascent entropy output respect weight matrix gradient update rule weight matrix follows ratio second partial derivatives activation function stands transpose expected value entropy random vector gradient entropy matrix form cell row column matrix derivative respect computation matrix inverse avoided employing natural gradient amounts multiplying absolute gradient resulting learning rule identity matrix 
logistic transfer function gives multiple inputs outputs maximizing joint entropy output encourages individual outputs move statistical independence 
form preliminary versions appear 
longer discussion unsupervised learning face recognition appears 
nonlinear transfer function cumulative density functions underlying ics scaling translation shown maximizing joint entropy outputs minimizes mutual information individual outputs :10.1.1.31.5414
practice logistic transfer function sufficient separate mixtures natural signals sparse distributions including sound sources 
algorithm speeded including sphering step prior learning 
row means subtracted passed whitening matrix twice inverse square root covariance matrix removes second order statistics data mean covariances set zero variances equalized 
inputs ica sphered data full transform matrix product sphering matrix matrix learned ica mackay pearlmutter showed ica algorithm converges maximum likelihood estimate generative model data vector independent random variables called sources cumulative distributions equal words logistic activation functions corresponds assuming logistic random sources standard cumulative gaussian distribution activation functions corresponds assuming gaussian random sources :10.1.1.48.120:10.1.1.48.120
inverse weight matrix bell sejnowski algorithm interpreted source mixing matrix variables interpreted maximum likelihood ml estimates sources generated data 
ica statistical techniques ica pca pca derived special case ica uses gaussian source models 
case mixing matrix sense infinite number equally ml solutions 
possible ml solutions pca chooses orthogonal matrix optimal sense regardless distribution linear combination input allows optimal linear reconstruction input mean square sense fixed allows optimal linear reconstruction class linear combinations uncorrelated sources gaussian likelihood data depends second order statistics covariance matrix 
pca rows fact eigenvectors covariance matrix data 
second order statistics capture amplitude spectrum images phase spectrum 
high order statistics capture phase spectrum 
sample principal square root unique square root eigenvalue nonnegative real part 
ieee transactions neural networks vol 
november natural images scramble phase spectrum maintaining power spectrum 
dramatically alter appearance images change second order statistics 
phase spectrum power spectrum contains structural information images drives human perception 
example illustrated fig 
face image synthesized amplitude spectrum face phase spectrum face perceived image face 
fact pca sensitive power spectrum images suggests particularly suited representing natural images 
assumption gaussian sources implicit pca inadequate true sources non gaussian 
particular empirically observed natural signals including speech natural images eeg better described linear combinations sources long tailed distributions 
sources called high kurtosis sparse super gaussian sources 
logistic random variables special case sparse source models 
sparse source models appropriate ica potential advantages pca provides better probabilistic model data better identifies data concentrate dimensional space 
uniquely identifies mixing matrix finds necessarily orthogonal basis may reconstruct data better pca presence noise 
sensitive high order statistics data just covariance matrix 
fig 
illustrates points example 
shows samples dimensional distribution constructed linearly mixing high kurtosis sources 
shows basis vectors pca ica problem 
ica basis vectors nonorthogonal change relative distance data points 
change metric may potentially useful classification algorithms nearest neighbor decisions relative distances points 
ica basis alters angles data points affects similarity measures cosines 
basis set chosen pca ica may span different subspaces 
example fig 
dimensions selected pca ica choose different subspaces 
metric induced ica superior pca sense may provide representation robust effect noise :10.1.1.31.5414
possible ica better pca reconstruction noisy limited precision environments 
example problem fig 
bits allowed represent pca ica coefficients linear reconstructions ica db better reconstructions pca noise power reduced half 
similar result obtained pca ica subspaces 
bits allowed represent pca ica coefficients ica reconstructions db better pca reconstructions 
problems think actual inputs noisy versions canonical inputs 
example variations lighting expressions seen noisy versions canonical image person 
having input representations robust noise may potentially give representations better reflect data 
fig 

left face images 
center faces scrambled phase 
right reconstructions amplitude original face phase face 
faces images feret face database reprinted permission phillips 
sources models sparse ica closely related called nonorthogonal rotation methods pca factor analysis 
goal rotation methods find directions high concentrations data similar ica sources sparse 
cases ica seen theoretically sound probabilistic method find interesting nonorthogonal rotations ica cluster analysis cluster analysis technique finding regions dimensional space large concentrations data 
regions called clusters typically main statistic interest cluster analysis center clusters 
source models sparse ica finds directions significant concentrations data points observed 
sparse sources ica seen form cluster analysis 
emphasis ica finding optimal directions specific locations high data density 
fig 
illustrates point 
note data concentrates ica solutions pca solutions 
note case clusters equal mean better characterized orientation position space 
noted ica general technique 
super gaussian sources ica seen doing akin nonorthogonal pca cluster analysis source models sub gaussian relationship techniques clear 
see discussion ica context sub gaussian sources 
architectures performing ica images data matrix rows columns 
think column outcomes independent trials random experiment 
think th row specific value taken random variable independent trials 
defines empirical probability distribution column probability mass independence defined respect bartlett face recognition independent component analysis fig 

top example data distribution corresponding pc ic axes 
axis column mixing matrix pca ica 
note pc axes orthogonal ic axes 
components allowed ica chooses different subspace pca 
bottom left distribution pca coordinates data 
bottom right distribution ica coordinates data 
note ica axes nonorthogonal relative distances points different pca ica angles points 
distribution 
example say rows independent possible predict values taken columns corresponding values taken empirical distribution 
goal find set basis images represent database faces 
organize image database long vector dimensions number pixels image 
ways ica applied problem 
organize database matrix row vector different image 
approach illustrated fig 
left 
approach images random variables pixels trials 
approach sense talk independence images functions images 
images independent moving pixels possible predict value taken pixel image value taken pixel image similar approach bell sejnowski sound source separation eeg analysis fmri 
transpose organize data images columns approach illustrated fig 
right 
approach pixels random variables images trials 
sense talk independence pixels functions pixels 
example pixel independent moving entire set images possible predict value taken pixel corresponding value taken pixel image 
approach inspired bell sejnowski ics natural images 
fig 

architectures performing ica images 
architecture finding statistically independent basis images 
performing source separation face images produced ic images rows 
gray values pixel location plotted face image 
ica architecture finds weight vectors directions statistical dependencies pixel locations 
architecture ii finding factorial code 
performing source separation pixels produced factorial code columns output matrix 
face image plotted gray values taken pixel location 
ica architecture ii finds weight vectors directions statistical dependencies face images 
iii 
image data face images employed research subset feret face database 
data set contained images individuals 
frontal views individual neutral expression change expression session neutral expression change expression second session occurred years 
examples views shown fig 

algorithms trained single frontal view ieee transactions neural networks vol 
november fig 

example feret database frontal image viewing conditions neutral expression change expression session neutral expression change expression session 
reprinted permission jonathan phillips 
table image sets training testing fig 

image synthesis model architecture find set ic images images considered linear combination statistically independent basis images unknown mixing matrix 
basis images estimated learned ica output fig 

image synthesis model architecture ii 
image dataset considered linear combination underlying basis images matrix basis images associated set independent causes vector coefficients basis images estimated learned ica weight matrix 
individual 
training set comprised neutral expression images change expression images 
algorithms tested recognition different conditions session different expression different day expression different day different expression see table 
coordinates eye mouth locations provided feret database 
coordinates center face images crop scale pixels 
scaling area triangle defined eyes mouth 
luminance normalized linearly rescaling image interval 
subsequent analyses image represented dimensional vector luminance value pixel location 
iv 
architecture statistically independent basis images described earlier goal approach find set statistically independent basis images 
organize data matrix images rows pixels columns rows columns image zero mean 
fig 

independent basis image representation consisted coefficients linear combination independent basis images comprised face image approach ica finds matrix rows statistically independent possible 
source images estimated rows basis images represent faces 
face image representations consist coordinates images respect image basis defined rows shown fig 

coordinates contained mixing matrix number ics ica algorithm corresponds dimensionality input 
images training set algorithm attempt separate ics 
previous performance improved number components separated intractable memory limitations 
order control number ics extracted algorithm performing ica original images performed ica set linear combinations images recall image synthesis model assumes images linear combination set unknown statistically independent sources 
image synthesis model unaffected replacing original images linear combination images 
adopting method applied ica fmri data chose linear combinations pc eigenvectors image set 
pca image set pixel locations treated observations face image measure gives linear combination parameters images accounts maximum variability observa bartlett face recognition independent component analysis tions pixels 
pca vectors input throw away high order relationships 
relationships existed data separated 
denote matrix containing pc axes columns 
performed ica producing matrix independent source images rows implementation coefficients linear combination basis images comprised face images determined follows 
pc representation set zero mean images defined minimum squared error approximation obtained ica algorithm produced matrix sphering matrix defined 
rows contained coefficients linear combination statistically independent sources comprised minimum squared error approximation just pca 
ic representation face images set statistically independent feature images rows matrix representation test images obtained pc representation training images obtain computing note pca step required ica representation faces 
employed serve purposes reduce number sources tractable number provide convenient method calculating representations test images 
pca step pc axes training set calculating eigenvectors pixelwise covariance matrix set face images 
ica performed eigenvectors pcs accounted variance images 
eigenvectors comprised rows input matrix input matrix sphered weights updated iterations 
learning rate initialized annealed potentially obtained calculating pseudoinverse normalizing length rows making approximately orthonormal calculating ica remove second order dependencies precisely orthonormal 
pilot face recognition performance improved number components separated 
chose components largest number separate processing limitations 
pca removed covariances data variances equalized 
retained sphering step 
fig 

ics image set obtained architecture provide set statistically independent basis images rows fig 

ics ordered class discriminability ratio 

training took minutes dec alpha 
training set statistically independent source images contained rows output matrix fig 
shows subset basis images rows 
images interpreted follows row mixing matrix ica represents cluster pixels similar behavior images 
row matrix tell close pixel cluster identified ica 
sparse independent source model basis images expected sparse independent 
sparseness case means basis images large number pixels close zero pixels large positive negative values 
note ica images local regions nonzero pixels nearby 
majority statistical dependencies spatially proximal pixel locations 
set pc basis images pca axes shown fig 
comparison 
face recognition performance architecture face recognition performance evaluated coefficient vectors nearest neighbor algorithm cosines similarity measure 
coefficient vectors test set assigned class label coefficient vector training set similar evaluated cosine angle face recognition performance pc representation evaluated identical procedure pc coefficients contained rows ieee transactions neural networks vol 
november fig 

percent correct face recognition ica representation architecture ics pca representation pcs pca representation pcs 
groups performances test set test set test set 
error bars standard deviation estimate success rate bernoulli distribution 
fig 

pc axes image set columns ordered left right top bottom magnitude corresponding eigenvalue 
experiments date ica performs significantly better cosines euclidean distance similarity measure pca performs 
cosine similarity measure equivalent length normalizing vectors prior measuring euclidean distance doing nearest neighbor contrast normalization consistent neural models primary visual cortex 
cosine similarity measures previously effective computational models language face processing 
fig 
gives face recognition performance ica pca representations 
recognition performance shown pca representation pc vectors eigenface representation pentland 
best performance pca obtained coefficients 
excluding pcs improve pca performance selecting intermediate ranges components 
trend ica representation give superior face recognition performance pca representation components 
difference performance statistically significant test set 
difference performance ica representation eigenface representation components statistically significant test sets test sets test set 
recognition performance different numbers ics examined performing ica image mixtures steps 
best performance obtained separating ics 
general ics separated better recognition performance 
basis images increasingly spatially local number separated components increased 
subspace selection components retained pca ica working subspace 
illustrated fig 
subsets axes selected ica chooses different subspace pca 
full benefit ica may tapped ica defined subspaces explored 
face recognition performances pca ica representations compared selecting subsets components class discriminability 
mean coefficient faces mean person pca ica representations calculated ratio class class variability coefficient variance class means sum variances class 
class discriminability analysis carried subjects frontal view images available 
ratios calculated separately test set excluding test images analysis 
pca ica coefficients ordered magnitude 
fig 
top compares discriminability ica coefficients pca coefficients 
ica coefficients consistently greater class discriminability pca coefficients 
bartlett face recognition independent component analysis fig 

factorial code representation consisted independent coefficients linear combination basis images comprised face image fig 

selection components class discriminability architecture ii 
top discriminability ica coefficients solid lines discriminability pca components dotted lines test cases 
components sorted magnitude bottom improvement face recognition performance ica pca representations subsets components selected class discriminability improvement indicated gray segments top bars 
face classification performance compared discriminable components representation 
fig 
bottom shows best classification performance obtained pca ica representations discriminable components ica representation discriminable components pca representation 
selecting subsets coefficients class discriminability improved performance ica representation little effect performance pca representation 
ica representation outperformed pca representation 
difference recognition performance ica pca representations significant test set test set conditions required recognition images collected different day training set respectively subspaces selected criterion class discriminability 
ica defined subspace encoded information facial identity pca defined subspace 
architecture ii factorial face code goal architecture ica find set spatially independent basis images 
basis images obtained architecture approximately independent coefficients code face necessarily independent 
architecture ii uses ica find representation coefficients code images statistically independent factorial face code 
barlow atick discussed advantages factorial codes encoding complex objects characterized high order combinations features 
include fact probability combination features obtained marginal probabilities 
achieve goal organize data matrix rows represent different pixels columns represent different images 
see fig 
right 
corresponds treating columns set basis images 
see fig 

ica representations columns column contains coefficients basis images reconstructing image fig 

ica attempts outputs independent possible 
factorial code face images 
representational code test images obtained zero mean matrix test images weight matrix performing ica training images 
order reduce dimensionality input performing ica directly image pixels ica performed pca coefficients face images 
pcs accounted variance images 
coefficients comprised columns input data matrix coefficient zero mean 
architecture ii representation training images contained columns ica weight matrix resulting coefficients face image consisting outputs ica filters 
architecture ii representation test images obtained columns follows basis images representation consisted columns sample basis images shown pixel zero mean 
image filter defined ieee transactions neural networks vol 
november fig 

recognition performance factorial code ica representation ica coefficients compared ica independent basis representation ica pca representation coefficients 
fig 

basis images ica factorial representation columns obtained architecture ii 
fig 
pc reconstruction visualize 
approach column mixing matrix ica attempts get close cluster images look similar pixels 
approach tends generate basis images look face basis images generated pca bases ica average images look alike 
ica output algorithm force columns sparse independent 
basis images global properties basis images ica output architecture shown fig 

face recognition performance architecture ii face recognition performance evaluated nearest neighbor procedure cosines similarity measure 
fig 
compares face recognition performance ica factorial code representation obtained architecture ii independent basis representation obtained architecture pca representation coefficients 
trend ica factorial representation ica outperform pca representation recognizing faces days 
difference performance test set significant 
significant difference performances ica representations 
class discriminability ica factorial coefficients calculated 
coefficients independent basis representation ica factorial coefficients differ substantially discriminability selection subsets components fig 

improvement recognition performance ica representations pca representation selecting subsets components class discriminability 
gray extensions show improvement recognition performance coefficients 
representation class discriminability little effect recognition performance ica factorial representation see fig 

difference performance ica ica test set discriminability analysis just misses significance 
implementation separated components samples bare minimum 
test images learn ics recognition results due overlearning 
order determine findings artifact due small sample size recognition performances tested separating components estimating fewer weight parameters 
pattern results obtained components separated 
ica representations significantly outperformed pca representation test sets 
ics ica obtained correct performance respectively test sets ica obtained correct performance pca bartlett face recognition independent component analysis fig 

kurtosis sparseness ica pca representations 
fig 

pairwise mutual information 
mean mutual information basis images 
mutual information measured pairs gray level images pc images independent basis images obtained architecture 
mean mutual information coding variables 
mutual information measured pairs image pixels gray level images pca coefficients ica coefficients obtained architecture ii 
obtained correct respectively 
separated components selection subsets components class discriminability improved performance ica respectively little effect performances pca ica representations 
suggests results simply artifact due small sample size 
vi 
examination ica representations mutual information measure statistical dependencies face representations obtained calculating mean mutual information pairs basis images 
mutual information calculated fig 
compares mutual information basis images original gray level images pc basis images ica basis images obtained architecture principal component pc images uncorrelated remaining high order dependencies 
information maximization algorithm decreased residual dependencies 
remaining dependence may due mismatch logistic transfer function employed learning rule cumulative density function independent sources presence sub gaussian sources large number free parameters estimated relative number training images 
fig 
compares mutual information coding variables ica factorial representation obtained architecture ii pca representation gray level images 
gray level images mutual information calculated pairs pixel locations 
pca representation mutual information calculated pairs pc coefficients ica factorial representation mutual information calculated pairs coefficients considerable high order dependencies remaining pca representation reduced information maximization algorithm 
ica representations obtained simulations accurately described independent redundancy reduced redundancy half pc representation 
sparseness field argued sparse distributed representations advantageous coding visual stimuli 
sparse representations characterized highly response distributions large concentration values near zero rare occurrences large positive negative values tails 
code redundancy input transformed redundancy response patterns individual outputs 
maximizing sparseness loss information equivalent minimum entropy codes discussed barlow 
relationship sparse codes minimum entropy advantages sparse codes outlined field mirror arguments independence barlow 
codes minimize number active neurons useful detection suspicious coincidences 
nonzero response unit relatively rare high order relations increasingly rare informative stimulus 
field information maximization consistent minimum entropy coding 
maximizing joint entropy output entropies individual outputs tend minimized 
ieee transactions neural networks vol 
november fig 

recognition successes failures 
left face image pairs ica algorithms correctly recognized 
right face image pairs misidentified ica algorithms 
images feret face database reprinted permission phillips 
contrasts compact code pcs units relatively high probability response high order combinations group relatively common 
sparse distributed code different objects represented units active active 
representations added advantage signal noise need determine units active regard precise level activity 
additional advantage sparse coding face representations storage associative memory systems 
networks sparse inputs store memories provide effective retrieval partial information 
probability densities values coefficients ica representations pca representation shown fig 

sparseness face representations examined measuring kurtosis distributions 
kurtosis defined ratio fourth moment distribution square second moment normalized zero gaussian distribution subtracting kurtosis kurtosis pca representation measured pc coefficients 
pcs face images kurtosis 
coefficients independent basis representation architecture kurtosis 
basis images architecture sparse distribution gray level values face coefficients respect basis sparse 
contrast coefficients ica factorial code representation architecture ii highly 
vii 
combined ica recognition system ica representations gave similar recognition performances examined representations gave similar patterns errors face images 
significant tendency algorithms misclassify images 
probability ica factorial representation ica error ica representation error respectively test sets 
conditional error rates significantly higher marginal error rates fig 

face recognition performance ica classifier compared individual classifiers ica ica pca 
respectively 
examples successes failures algorithms shown fig 

algorithms errors assign incorrect identity 
total common errors systems algorithms assign incorrect identity 
representations conjunction provide reliability measure classifications accepted algorithms gave answer 
ica recognition system reliability criterion gave performance test sets respectively classification performance 
total test images met criterion 
confusions algorithms differed combined classifier employed similarity test image gallery image defined correspond similarity measure ica ica respectively 
class discriminability analysis carried ica ica calculating performance combined classifier shown fig 

combined classifier improved performance test cases respectively 
difference performance combined ica classifier pca significant test sets 
viii 
discussion information perceptually distinguishes faces contained higher order statistics images phase spectrum 
basis images developed pca depend second order images statistics desirable find generalizations pca sensitive higher order image statistics 
explored generalization bell sejnowski ica algorithm 
explored different architectures developing image representations faces ica 
architecture treated images random variables pixels random trials 
architecture related bell sejnowski separate mixtures bartlett face recognition independent component analysis auditory signals independent sound sources 
architecture ica basis set statistically independent images 
images basis set sparse localized space resembling facial features 
architecture ii treated pixels random variables images random trials 
architecture image coefficients approximately independent resulting factorial face code 
ica representations outperformed eigenface representation pc analysis recognizing images faces sampled different day training images :10.1.1.12.7580:10.1.1.12.7580
classifier combined ica representations outperformed eigenfaces test sets 
ica allows basis images nonorthogonal angles distances images differ ica pca 
subsets axes selected ica defines different subspace pca 
selecting axes criterion class discriminability ica defined subspaces encoded information facial identity pca defined subspaces 
ica representations designed maximize information transmission presence noise may robust variations lighting conditions changes hair facial expression considered forms noise respect main source information face database person identity 
robust recognition different days particularly encouraging applications automated face recognition contain noise inherent identifying images collected different day sample images 
purpose comparison examine ica pca representations identical conditions 
number methods enhancing recognition performance eigenfaces 
ica representations place eigenfaces techniques 
open question techniques enhance performance pca ica equally interactions type enhancement representation 
number research groups independently tested ica representations 
liu wechsler yuen lai supported findings ica outperformed pca 
moghaddam employed euclidean distance similarity measure cosines 
consistent findings significant difference pca ica euclidean distance similarity measure 
cosines tested 
thorough comparison ica pca large set similarity measures conducted supported advantage ica face recognition 
section ica provided set statistically independent coefficients coding images 
argued factorial code advantageous encoding complex objects characterized high order combinations features prior probability combination features obtained individual probabilities 
arguments field barlow ica factorial representation architecture ii optimal object representation architecture representation sparse factorial properties 
due difference architecture ica factorial representation fewer training samples estimate number free parameters architecture representation 
fig 
shows residual dependencies ica factorial representation higher architecture representation 
ica factorial representation may prove greater advantage larger training set images 
prediction born experiments larger set feret face images 
possible factorial code representation may prove advantageous powerful recognition engines nearest neighbor cosines bayesian classifier 
image set containing frontal view images subject collected different days needed test hypothesis 
number sources controlled reducing dimensionality data pca prior performing ica 
limitations approach 
reverse dimensionality problem 
may possible linearly separate independent sources smaller subspaces 
retained dimensions may serious limitation implementation 
second may desirable throw away subspaces data low power higher pcs 
low power subspaces may contain ics property data seek independence amplitude 
techniques proposed separating sources projection planes discarding ics data 
techniques estimating number ics dataset proposed 
information maximization algorithm employed perform ica assumed underlying causes pixel gray levels face images super gaussian response distribution 
natural signals sound sources shown super gaussian distribution 
employed logistic source model shown practice sufficient separate natural signals super gaussian distributions 
underlying causes pixel gray levels face images unknown possible better results obtained source models 
particular sub gaussian sources remained mixed 
methods separating sub gaussian sources information maximization developed 
direction research examine sub gaussian components face images 
information maximization algorithm employed assumed pixel values face images generated linear mixing process 
linear approximation shown hold true effect lighting face images 
influences changes pose expression may linearly approximated limited extent 
nonlinear ica absence prior constraints ill conditioned problem progress assuming linear mixing process followed parametric nonlinear functions 
algorithm nonlinear ica kernel methods 
kernel methods shown improve face recognition performance ieee transactions neural networks vol 
november pca fisherfaces 
direction research examine nonlinear ica representations faces 
pca ica architecture spatially local face representation 
local feature analysis finds local basis images faces second order statistics 
basis images performing whitening pc axes followed rotation topographic correspondence pixel location 
kernels sensitive high order dependencies face image ensemble tests date recognition performance kernels significantly improved pca 
interestingly downsampling methods sequential information maximization significantly improve performance 
ica outputs architecture sparse space image pixels ica outputs architecture ii sparse images 
architecture produced local basis images face codes sparse architecture ii produced sparse face codes holistic basis images 
representation appeared literature nonnegative matrix factorization nmf produced local basis images sparse face codes 
representation interesting theoretical perspective proven useful recognition 
innovative face representation employs products experts restricted boltzmann machines 
representation finds local features nonnegative weight constraints employed 
experiments date outperformed pca recognizing faces changes expression addition removal glasses performed poorly recognizing faces different days 
open question sparseness local features desirable objectives face recognition 
properties emerged objective independence 
capturing likelihood may principle generating unsupervised representations classification 
mentioned section ii pca ica derived generative models data pca uses gaussian sources ica typically uses sparse sources 
shown natural signals ica better model assigns higher likelihood data pca 
ica basis dimensions may captured likelihood face images pca provides possible explanation superior performance ica face recognition study 
ica representations degree biological relevance 
information maximization learning algorithm developed principle optimal information transfer neurons sigmoidal transfer functions 
contains hebbian correlational term nonlinearly transformed outputs weighted feedback linear outputs 
biological plausibility learning algorithm limited fact learning rule nonlocal 
local learning rules ica presently development 
principle independence specific learning algorithm employed may relevance face nmf codes sparse minimum entropy code independent code objective function maximize sparseness preserving information 
object representations brain 
barlow atick argued redundancy reduction general coding strategy brain 
notion supported findings bell sejnowski image bases produce independent outputs natural scenes local oriented spatially opponent filters similar response properties simple cells 
olshausen field obtained similar result sparseness objective close information theoretic relationship sparseness independence 
conversely shown gabor filters closely model responses simple cells separate high order dependencies 
see detailed discussion 
support relationship gabor filters ica gabor ica architecture representations significantly outperformed image representations task facial expression recognition performed equally 
psychophysical support relevance independence face representations brain 
ica architecture representation gave better correspondence human perception facial similarity pca nonnegative matrix factorization 
desirable filters may adapted patterns interest capture interesting structure 
dependencies encoded structure learned 
information theory provides means capturing interesting structure 
information maximization leads efficient code environment resulting learned structure 
mechanisms predict neural codes vision audition 
research face representations high order dependencies separated individual coefficients gave superior recognition performance representations separate second order redundancies 
acknowledgment authors grateful lades mckeown gray 
lee helpful discussions topic valuable comments earlier drafts 
amari cichocki yang new learning algorithm blind signal separation advances neural information processing systems 
cambridge ma mit press vol 

atick information theory provide ecological theory sensory processing network vol 
pp 

atick redlich retina know natural scenes neural comput vol 
pp 

bach jordan kernel independent component analysis machine learning res vol 
pp 

barlow unsupervised learning neural comput vol 
pp 

bartlett face image analysis unsupervised learning 
boston ma kluwer vol 
kluwer international series engineering computer science 
face image analysis unsupervised learning redundancy reduction ph dissertation univ california san diego la jolla 
bartlett donato movellan hager ekman sejnowski image representations facial expression coding advances neural information processing systems solla leen 
muller eds 
cambridge ma mit press vol 

bartlett face recognition independent component analysis bartlett lades sejnowski independent component representations face recognition proc 
spie symp 

imaging science technology human vision electronic imaging iii vol 
rogowitz pappas eds san jose ca pp 

baum moody internal associative memory biol 
cybern vol 
pp 

bell sejnowski information maximization approach blind separation blind deconvolution neural comput vol 
pp 

independent components natural scenes edge filters vision res vol 
pp 

cichocki unbehauen robust learning algorithm blind separation signals electron 
lett vol 
pp 

comon independent component analysis new concept signal processing vol 
pp 

cottrell metcalfe face gender emotion recognition holons advances neural information processing systems touretzky ed 
san mateo ca morgan kaufmann vol 
pp 

donato bartlett hager ekman sejnowski classifying facial actions ieee trans 
pattern anal 
machine intell vol 
pp 
oct 
draper bartlett beveridge recognizing faces pca ica comput 
vision image understanding special issue face recognition submitted publication 
field relations statistics natural images response properties cortical cells opt 
soc 
amer 
vol 
pp 

goal sensory coding neural comput vol 
pp 

girolami advances independent component analysis 
berlin germany springer verlag 
hallinan deformable model face recognition arbitrary lighting conditions ph dissertation harvard univ cambridge ma 
hancock alternative representations faces british psych 
soc cognitive section 
essex univ essex 
heeger normalization cell responses cat striate cortex visual neurosci vol 
pp 

hinton shallice attractor network investigations acquired dyslexia psych 
rev vol 
pp 

jutten herault blind separation sources adaptive algorithm neuromimetic architecture signal processing vol 
pp 

ensemble learning advances independent component analysis girolami ed 
new york springer verlag pp 

simple coding procedure enhances neuron information capacity vol 
pp 

lee seung learning parts objects nonnegative matrix factorization nature vol 
pp 


lee independent component analysis theory applications 
boston ma kluwer 

lee girolami sejnowski independent component analysis extended infomax algorithm mixed sub gaussian super gaussian sources neural comput vol 
pp 


lee koehler blind source separation nonlinear mixing models proc 
ieee int 
workshop neural networks signal processing sept pp 

lewicki olshausen probabilistic framework adaptation comparison image codes opt 
soc 
amer 
vol 
pp 

lewicki sejnowski learning overcomplete representations neural comput vol 
pp 

lin cowan source separation density estimation faithful equivariant som advances neural information processing systems mozer jordan petsche eds 
cambridge ma mit press vol 
pp 

liu wechsler comparative assessment independent component analysis ica face recognition int 
conf 
audio video biometric person authentication 
mackay maximum likelihood covariant algorithms independent component analysis :10.1.1.48.120
makeig bell 
jung sejnowski independent component analysis electroencephalographic data advances neural information processing systems touretzky mozer hasselmo eds 
cambridge ma mit press vol 
pp 

marks movellan diffusion networks products experts factor analysis proc 
rd int 
conf 
independent component anal 
signal separation 
mckeown makeig brown 
jung kindermann bell sejnowski analysis fmri decomposition independent spatial components human brain mapping vol 
pp 

mackay ensemble learning blind source separation ica principles practice 
cambridge cambridge univ press 
moghaddam principal manifolds bayesian subspaces visual recognition int 
conf 
comput 
vision 
:10.1.1.31.5414
nadal parga non linear neurons low noise limit factorial code maximizes information transfer network vol 
pp 

olshausen field emergence simple cell receptive field properties learning sparse code natural images nature vol 
pp 

natural image statistics efficient coding network comput 
neural syst vol 
pp 

oppenheim lim importance phase signals proc 
ieee vol 
pp 

toole valentin abdi structural aspects face recognition race effect memory cognition vol 
pp 

palm associative memory biol 
cybern vol 
pp 

pearlmutter parra context sensitive generalization ica advances neural information processing systems mozer jordan petsche eds 
cambridge ma mit press vol 

redundancy dimensionality reduction sparse distributed representations natural objects terms local features advances neural information processing systems leen dietterich tresp eds 
cambridge ma mit press 
atick local feature analysis general statistical theory object representation network comput 
neural syst vol 
pp 

pentland moghaddam starner view modular eigenspaces face recognition proc 
ieee conf 
comput 
vision pattern recognition pp 

phillips wechsler juang rauss feret database evaluation procedure face recognition algorithms image vision comput 
vol 
pp 

campbell demonstration visual importance flexibility spatial frequency amplitude phase perception vol 
pp 

simoncelli statistical models images compression restoration synthesis st asilomar conference signals systems computers pacific grove ca nov 
stone independent component analysis signal separation dimension reduction tech 
rep dept psych univ sheffield sheffield 
teh hinton rate coded restricted boltzmann machines face recognition advances neural information processing systems leen dietterich tresp eds 
cambridge ma mit press 
turk pentland eigenfaces recognition cognitive neurosci vol :10.1.1.12.7580
pp 


lee sejnowski chromatic structure natural scenes opt 
soc 
amer 
vol 
pp 

yang 
amari cichocki theoretic approach blind separation sources nonlinear mixture signal processing vol 
pp 

yang face recognition kernel methods advances neural information processing systems diederich becker ghahramani eds vol 

yuen lai independent component analysis face images ieee workshop biologically motivated computer vision seoul korea 
ieee transactions neural networks vol 
november marian stewart bartlett received degree mathematics computer science college vt ph degree cognitive science psychology university california san diego la jolla 
dissertation conducted sejnowski salk institute 
assistant research professor institute neural computation university california san diego 
interests include approaches image analysis unsupervised learning focus face recognition expression analysis 
presently exploring probabilistic dynamical models application facial expression analysis university california san diego 
studied perceptual cognitive processes ramachandran university california san diego cognitive neuroscience section national institutes health department brain cognitive sciences massachusetts institute technology cambridge brain perception laboratory university bristol terrence sejnowski sm received degree physics case western reserve university cleveland oh ph degree physics princeton university princeton nj 
joined faculty department biophysics johns hopkins university baltimore md investigator howard hughes medical institute professor salk institute biological studies la jolla ca directs computational neurobiology laboratory professor biology university california san diego la jolla 
long range goal research build linking principles brain behavior computational models 
goal pursued combination theoretical experimental approaches levels investigation ranging biophysical level systems level 
issues addressed research include sensory information represented visual cortex 
dr sejnowski received ieee neural networks pioneer award 
javier movellan born spain received degree universidad de madrid madrid spain 
fulbright scholar university california berkeley berkeley received ph degree university 
research associate carnegie mellon university pittsburgh pa assistant professor department cognitive science university california san diego la jolla 
currently research associate institute neural computation head machine perception laboratory ucsd 
research interests include development perceptual computer interfaces system recognize react natural speech commands expressions gestures body motions analyzing statistical structure natural signals order help understand brain works application stochastic processes probability theory study brain behavior computation 
