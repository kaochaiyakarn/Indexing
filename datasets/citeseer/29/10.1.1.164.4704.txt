indexing time vs query time trade offs dynamic information retrieval systems stefan charles clarke school computer science university waterloo waterloo ontario canada plg uwaterloo ca uw technical report cs examine issues design fully dynamic information retrieval systems support instantaneous document insertions deletions 
system discuss major design decisions 
decisions affect indexing query processing efficiency system represent genuine trade offs indexing query processing performance 
aspects retrieval system fast incremental updates garbage collection delayed document deletions discussed detail focus respective trade offs 
depending relative number queries update operations different strategies lead optimal performance 
special attention particular case dynamic search systems desktop file system search 
main results demonstrate security mechanisms necessary multiuser support extended realize efficient document deletions 
categories subject descriptors systems textual databases systems software performance evaluation general terms experimentation performance keywords information retrieval dynamic indexing file system search indexing performance query performance 
indexing performance query processing performance closely related aspects information retrieval 
optimization techniques indexing performance query processing performance discussed aspects usually considered separate unconnected university waterloo technical report cs wumpus technical report 
copyright held authors 
entities optimization techniques aspect examined independently 
reflect reality query optimization techniques necessitate additional indexing time frequency ordered lists speed query processing require additional indexing time postings sorted document frequency word stemming usually applied indexing time performed query time allowing faster indexing faster query processing 
subtleties trade offs play great role traditional retrieval systems static collections large number queries processed systems obviously require maximum performance query time important dynamic information retrieval systems underlying text collection continuously changing number queries processed may vary greatly 
discuss opportunities indexing performance vs query processing performance tradeoffs 
done context dynamic information retrieval system indexing refers index maintenance includes types index update operations document insertions document deletions 
section give overview related 
section gives indexing system wumpus file system search engine 
describes general layout system security mechanisms necessary multi user environments internal index structure 
sections discusses particular component search system involving essential indexing vs query time trade sub index merging strategies necessary incremental updates section index garbage collection support delayed index updates document deletions closely related security subsystem section 
www wumpus search org 
related methods support dynamically changing text collections divided categories support document insertions support document deletions 
techniques support document insertions existing index studied researchers decade 
follow basic scheme 
maintain disk memory index 
postings new documents accumulated main memory exhausted data memory combined disk index 
tomasic place update scheme inverted files distinction short lists long lists 
discuss different allocation strategies long lists affects index maintenance query processing performance 
lester give evaluation different methods combine memory information disk data 
kabra hybrid ir db system delayed update operations memory buffers 
solutions common entire disk index read written time main memory exhausted causes performance problems large collections 
show number disk operations significantly reduced minimal cost query performance 
contrast case document insertions thorough evaluation techniques document deletions available 
chiueh huang lazy invalidation approach keeps memory list deleted documents performs postprocessing step query contents list account 
approach document deletions similar theirs general done postprocessing step integrated actual query processing 
related provides general discussion different index maintenance strategies affect query processing performance implies opportunities indexing versus query processing performance trade offs 

wumpus search system retrieval system described wumpus file system search engine 
wumpus similar file system search engines google desktop search apple spotlight beagle desktop search systems spotlight true multi user search system single index files file system security restrictions applied query time order guarantee query results consistent file permissions 
addition mere file system search wumpus supports standard information retrieval methods okapi bm multitext qap 
search system query language implementation framework proposed clarke 
remainder section give short specific requirements file system search explain system deals individual aspects file system search describe basic experimental setup performance evaluation methodology 
desktop google com www apple com features spotlight www gnome org projects beagle user memory index user 
disk index index manager security manager query processor user 
disk index user input files general layout wumpus search system 
wumpus maintains memory index updates disk indices persistent storage 
user specific security restrictions applied data transferred index manager query processor 
file system search file system search different traditional information retrieval task 
search engine deal large heterogeneous document collection file system truly dynamic environment files constantly created modified deleted 
expected number index update operations greater number queries processed 
wumpus authors counted index update operations document insertions deletions laptop computer typical day 
furthermore mail arrives new file created user expects search system reflect change immediately 
delays greater seconds acceptable 
great number update operations performed suggest indexing performance plays greater role query processing performance particular domain 
wumpus supports fast instantaneous updates changes file system reflected search system fractions second 
indexing techniques achieve section 
addition dynamic environment file system search multi user application 
order avoid wasting disk space due indexing file times single index users system 
special care taken guarantee file system security 
wumpus built security mechanisms guarantee query results depend content files readable user submitted query 
security subsystem support document deletions briefly discussed section 
indexing document insertions wumpus uses inverted files main index structure 
posting lists contain fully positional information exact locations occurrences term 
positional indexing instance necessary phrase queries term proximity ranking supported hash table trade dynamic information retrieval disk dynamic memory dynamic information retrieval retrieval trade memory index hash table linked lists 
disk index level search tree 
basic structure memory index disk index 
vocabulary terms memory arranged hash table 
terms disk sorted lexicographical order allowing efficient prefix search operations 
wumpus 
results easily applied document centered search systems maintain fully positional index 
actual indexing pass process 
described memory inversion ad hoc text partitioning cf 
witten pp 

new document added index tokens read input file inverted index built memory memory consumption reaches predefined threshold 
point disk inverted file created postings memory memory index deleted system continues read tokens input file 
wumpus able maintain multiple disk indices time 
different strategies merging sub indices discussed section 
memory index hash table move front heuristics efficiently search existing terms add new terms vocabulary 
postings stored compressed form byte aligned gap compression linked lists allow flexibility efficient insertion new postings 
shown 
new data added memory index postings immediately assigned vocabulary terms hash table 
posting added posting list accessed query processor delay 
instantaneous updates needed real time file system search supported data structure 
disk index memory postings stored compressed form 
terms sorted lexicographical order minimizes number disk seeks necessary prefix searches query time stemming special kind prefix search 
terms postings kept decreases number disk seeks query time 
disk index part indexing system main index meta information kept memory 
conceptually meta information thought tree height reduce search space postings fetched disk index shown 
multiple sub indices wumpus able maintain multiple disk indices time 
important property sub indices form ordered partitioning index address space postings sub index ik come sub index ik 
property preserved index maintenance operations sub index merging garbage collection 
important implications query processing posting list term created concatenating sub lists retrieved individual sub indices sub index merge process postings decompressed may simply copied compressed form avoiding expensive list merging allowing fast sub index merge operations 
query processing wumpus query processor query language shortest substring paradigm 
supports variety operators impose structural constraints query results 
context need generates intervals called index extents occurs index address occurs index address generates index extents satisfy expression contained extent satisfies 
exact sequence operations performed system query processed course depends scoring function rank documents collection 
general query processing consists steps 
create list index extents scored 
traditionally list documents collection wumpus supports arbitrary expressions 
text collections experiments document extents generated expression doc doc 

fetch postings query terms disk indices memory index 

compute score extent step information posting lists collected step 
report top extents scores user 
disk indices memory index form ordered partitioning index address space posting list term created concatenating lists individual sub indices 
number disk seeks necessary fetch postings term linear number sub indices point advisable merge sub indices order increase query processing performance 
security restrictions document deletions pointed section special security mechanisms needed file system search engine users system share global index 
wumpus security manager keeps track file system meta information directory structure file ownership file permissions 
user submits query meta data generate list vu index extents correspond files may searched user 
query processed time posting list fetched index vu create new list pu vu consists parts refer files may searched query processor accesses directly pu 
guarantees query results consistent user view file system security permissions respected 
implementation pu allows lazy evaluation security restrictions applied parts original list needed process query 
security mechanism delay applying update operations index 
file deleted postings file immediately removed index 
index extent corresponding file removed security manager database 
equivalent marking file read anybody 
time query processed vu contain extent question query processor behaves postings interval physically removed index 
index fully positional partial document deletions file supported 
invalidation scheme certain advantages scheme chiueh huang 
postprocessing approach uses outdated slightly wrong collection statistics compute query term weights unable restrict number result candidates query processing user interested top documents scores documents examined kept arbitrarily documents may removed result set postprocessing step 
problems solved integrating invalidation actual query processing 
security subsystem delay hard index updates postings belong deleted files removed index point 
garbage collection strategies discussed section 
experimental setup experiments text collections having different size different collection characteristics trec disks congressional record referred trec cr query set topics trec robust track 
trec genomics collection subset pubmed medline corpus referred trec genomics queries ad hoc topics genomics track 
collections general corpus statistics basic performance figures table 
performance val table collection statistics performance figures different trade levels 
indexing static text collection final sub index merging sub index merging stemming indexing time stemming query time 
trec cr trec genomics collection size mb mb documents tokens distinct terms index size mb mb indexing time qry 
performance queries queries index size mb mb indexing time qry 
performance queries queries index size mb mb indexing time qry 
performance queries queries index size mb mb indexing time qry 
performance queries queries ues represent systems configured different levels tradeoff indexing query processing performance 
order able discuss indexing time vs query time trade offs respect amount indexing subsystem query processor experiments discussed sections conducted varying degrees system dynamics 
dynamics search system expressed number update operations document insertions deletions search query denoted system processes queries static text collection 
hand describes system performs update operations processes queries 
dynamic retrieval system value extremes 
file system search due high frequency file changes typical computer system expected 
addition number queries update operation 
order decrease number disk seeks necessary read input files able conduct experiments timely manner documents grouped files containing documents files trec genomics 
uniformly decreases running time experiments affect 
experiments conducted pc amd athlon processor gb main memory rpm hard drive 
gnu linux 
operating system 
sub index merging retrieval systems build index text collection partitioning collection smaller parts size determined amount available memory 
postings accumulated memory main memory exhausted 
point memory postings sorted written disk forming new sub index 
entire collection indexed sub indices generation generation generation generation add new sub index memory postings 
generation generation generation collisions generations merge sub indices new generation 
generation generation resulting index contains sub indices 
logarithmic merge example 
new sub index added memory postings 
generation merged new sub index generation 
created indexing process merged big inverted file represents collection 
technique perfectly reasonable static collections dynamic collections index continuously updated point collection indexed reached 
indices merged point large number sub indices significantly decreases query processing performance due disk seek latency 
decide acceptable multiple sensible merge 
different merge strategies evaluate performance different conditions 
strategy immediate merge merge strategy proposed lester 
analyze different techniques deal dynamically growing text collections 
techniques strategy called re merge exhibits best performance 
indexing system maintains disk memory index 
soon main memory full re merge sorts memory postings merges existing disk index creating new disk index contains postings gathered far 
call immediate merge memory postings immediately merged disk index written disk 
advantage strategy order fetch posting list cases single disk seek necessary sub index postings retrieved 
disadvantage merge operation entire index scanned 
number disk operations necessary create index size text collection amount available main memory 
devastating large text collections systems little available main memory halving available main memory doubles number disk operations 
strategy merge second strategy perform merge operations 
memory full postings sorted written disk creating new disk sub index 
disk indices merged 
posting list term retrieved index sub lists fetched sub indices 
sub indices ordered term posting list created concatenating sub lists 
advantage merge high indexing perfor average time query seconds query processing performance growing text collection merge logarithmic merge immediate merge number documents indexed thousands development query performance growing index 
logarithmic merge immediate merge stay close 
merge gets worse number sub indices increases 
mance sub index accessed exactly created memory postings 
implies 
disadvantage order fetch term posting list disk operations particular disk seeks nec essary causing low query processing performance collections larger available main memory 
behavior shown 
strategy logarithmic merge strategies described far immediate merge merge represent extremes 
third strategy compromise newly created disk sub index merged existing 
order determine merge sub indices introduce new concept index generation 
disk index created directly memory postings generation 
index created merging indices generation highest generation indices involved merging process 
new disk index created indices generation merged 
repeated collisions 
call strategy logarithmic merge logarithmic method bentley saxe 
similar incremental indexing scheme lucene logarithmic merge vector sub index generation ai behaves binary number increased time new disk index created 
follows immediately point time number sub indices bounded log size collection available main memory respectively 
better lucene apache org total time minutes trec genomics corpus mb memory index merge logarithmic merge immediate merge queries document insertions total time minutes trec genomics corpus mb memory index merge logarithmic merge immediate merge queries document insertions comparison sub index merging strategies growing text collections trec genomics mb main memory trec genomics mb main memory 
data point represents experiment indexing collection processing relevance queries parallel 
time total time indexing collection processing queries 
varied table exact times experimental results shown 
extrapolated point equality 
log 
merge immediate merge merge log 
merge imm 
merge merge strategy implies increased query processing performance 
number disk operations necessary build index log smaller immediate merge 
number disk operations reduced constant factor anticipating merge operations starting multi way merge process merging indices cause new collision new merge process 
process shown 
results experiments run evaluate different merging strategies different query update conditions involve monotonically growing document collection 
trec genomics collection ran series experiments mb memory index respectively 
experiments trec cr shown collection small allow 
starting empty index system concurrently adds documents index processes relevance queries collection indexed 
number relevance queries update operation document insertion varied order examine effect merge strategies indexing performance query processing performance 
total time needed system finish job index entire collection process queries measured 
results series experiments shown 
addition exact numbers mb series table 
queries update operations 
logarithmic merge stays close 
asymptotical performance lower immediate merge test collection 
pointed logarithmic merge robust decreasing available memory 
going mb mb significantly decreases merge query performance doubles indexing time immediate merge indexing query performance remain constant logarithmic merge sub index merging strategy 
expected merge best strategy light query load 
number queries update operation increases merge worse worse due high number sub indices accessed time query processed 
logarithmic merge shows excellent indexing performance slower merge mb memory 
increases logarithmic merge soon merge best strategy 
experiments performance logarithmic merge better immediate merge 
extrapolating experimental results predict immediate merge optimal strategy discussion shown depending dynamic underlying text collection different sub index merging strategies chosen order achieve optimal performance search system 
merge strategy offers best indexing performance number queries processed extremely small 
applications logarithmic merge best choice scales index large text collections immediate merge causes problems indexing complexity 

garbage collection previous section discussed sub index merging strategies continuously growing document collections 
truly dynamic environment collection grow monotonically 
update operations may document insertions deletions 
postings added insert operation average time query seconds impact garbage postings query performance logarithmic merge immediate merge relative amount garbage postings index experimental results sub collection trec genomics containing active varying number deleted documents 
query processing performance drops number garbage postings increased 
logarithmic merge stays close immediate merge 
simply appended existing posting lists assuming newly added documents reside index address space 
possible create new sub index memory postings having access disk sub indices great reduction number disk accesses 
true document deletions potentially affect entire address space 
impact limited single small part index address space deletions difficult deal insertions 
wumpus security mechanism helps deal document deletions 
user access part posting list lies files may read user respective file permissions automatically applied time query processed cf 
section 
mechanism support document deletions document deleted collection file associated document marked read anybody 
postings lying file ignored query processor 
filtering posting lists query processing part solution 
point postings belong deleted documents removed time takes process query essentially linear total number postings index shown 
need garbage collection strategy 
threshold garbage collection relatively simple strategy keep track relative number postings index belong documents deleted deleted postings postings soon number exceeds predefined threshold garbage collector started superfluous postings removed index 
basic garbage collection strategy wumpus 
different values affect indexing performance query processing performance different ways garbage collector run single document deletion guarantees maximum query performance cost bad indexing performance 
hand garbage collector run indexing performance maximal query processor spends great amount time fetching decompressing postings irrelevant query belong deleted documents 
garbage collection sub indexes read completely anyway wumpus automatically merges sub indexes big index time garbage collector run 
fly garbage collection threshold garbage collection strategy disadvantage completely independent sub index merging strategy employed causes additional disk access operations avoided garbage collector integrated sub index merging process 
call integration fly garbage collection time sub indices merged bigger sub index garbage collector filter postings read input indices write postings output index belong documents deleted 
fly garbage collection employed addition simple threshold approach 
garbage collection requires decompression posting lists causes notable reduction sub index merging performance ordinary sub index merging require decompression postings see section 
desirable run merge operation 
define new threshold value garbage collector integrated merge process pk pk deleted postings index ii postings index ii 
ik input indices merge operation 
reasonable choices interval 
experimental results conducted experiments compare different garbage collection threshold values study integration garbage collector sub index merging increase system performance 
text collection trec cr trec genomics series experiments conducted 
experiments limited size memory index mb logarithmic merge sub index merging strategy 
starting index contains documents text collection documents trec genomics documents trec cr documents added removed random fashion equal probabilities insertions deletions 
contrast experiments described previous section system process fixed number queries varied number update operations queries 
results visualized show update loads safe choice leading acceptable query performance 
trec genomics outperformed 
means additional caused eager garbage collection usually rewarded superior query performance low update loads 
collection integration fly garbage collection merge process improves system performance marginally indicating total time minutes trec cr corpus logarithmic merge mb ram threshold rho threshold rho threshold rho fly rho rho update operations query total time minutes trec genomics corpus logarithmic merge mb ram threshold rho threshold rho threshold rho fly rho rho update operations query garbage collection strategies fully dynamic text collections 
trec cr 
trec genomics 
number update operations query varied 
total time needed process queries concurrently perform update operations 
relatively simple threshold method fact bad thought suited scenarios 

fully dynamic information retrieval system supporting document insertions deletions 
contribution fold pointed different ways realize index update operations examined respective effect indexing query processing performance leading discussion associated indexing vs query processing performance trade offs 
shown broad range relative query update loads including typical desktop file system search combination logarithmic sub index merging threshold garbage collection garbage threshold appropriate way address index updates 
extreme conditions large small number updates query configurations exhibit better performance 
main results demonstrated security mechanisms necessary multi user support easily extended support efficient document deletions delayed index garbage collection 
number index updates query describe dynamic text collection ad hoc approach 
chose immediate 
measures relative number documents relative number postings changed consecutive queries give better characterization system 
experimental evaluation large number different corpora necessary find measure degree retrieval system dynamics 

bentley saxe 
decomposable searching problems static dynamic transformations 
journal algorithms 
chiueh huang 
efficient real time index updates text retrieval systems 
technical report stony brook new york usa august 
clarke cormack burkowski 
algebra structured text search framework implementation 
computer journal 
clarke cormack 
exploiting redundancy question answering 
proceedings th annual acm sigir conference pages november 
clarke cormack 
relevance ranking term queries 
inf 
proc 
management 
kabra ramakrishnan 
engine hybrid system 
technical report madison wisconsin usa 
lester zobel williams 
place versus re build versus re merge index maintenance strategies text retrieval systems 
proceedings th conference australasian computer science pages australia 
australian computer society persin zobel sacks davis 
filtered document retrieval frequency sorted indexes 
journal american society information sciences 
porter 
algorithm suffix stripping 
readings inf 
retr 
robertson walker jones hancock beaulieu 
okapi trec 
proceedings third text retrieval conference november 
williams zobel 
compression inverted indexes fast query evaluation 
proceedings th annual acm sigir conference pages 
tomasic garc molina 
incremental updates inverted lists text document retrieval 
sigmod proceedings acm sigmod conference pages new york ny usa 
acm press 
witten moffat bell 
managing gigabytes nd ed compressing indexing documents images 
morgan kaufmann publishers san francisco ca usa 
zobel heinz williams 
memory hash tables accumulating text vocabularies 
information processing letters 
zobel moffat ramamohanarao 
inverted files versus signature files text indexing 
acm trans 
database systems 
