survey web caching schemes internet jia wang cornell network research group nrg department computer science cornell university ithaca ny cs cornell edu world wide web considered large distributed information system provides access shared data objects 
popular applications currently running internet world wide web exponential growth size results network congestion server overloading 
web caching recognized effective schemes alleviate service bottleneck reduce network traffic minimize user access latency 
describe elements web caching system desirable properties 
survey state art techniques web caching systems 
discuss research frontier web caching 
size distinct static pages jun nov mar may size distinct static web pages 
world wide web www considered large distributed information system provides access shared data objects 
predicted size www shown 
www continues exponential growth size static web pages increases approximately month major problems today web users suffering network congestion server overloading 
rapid growth www attributed fact till usage quite inexpensive accessing information faster www means 
www documents appeal wide range interests news education scientific research sports entertainment stock market growth travel shopping weather maps internet backbone capacity increases year demand bandwidth supply foreseeable information services moved web 
kind solution undertaken problems caused rapidly increasing growth www congested entire appeal eventually lost 
researchers working improve web performance early caching popular objects locations close clients recognized effective solutions alleviate web service bottlenecks reduce traffic internet improve scalability www system 
idea proxy servers cache arose firstly allow accesses internet users firewall see 
security reasons companies run special type servers called proxy firewall machines 
proxy material supported national science foundation graduate fellowship 
server typically processes requests firewall forwarding remote servers intercepting responses sending replies back clients 
proxy servers typically shared clients inside firewall naturally leads question effectiveness proxies cache documents 
clients firewall usually belong organization share common interests 
probably access set documents client tends browse back forth short period time 
proxy server previously requested cached document result hits 
web caching proxy server save network bandwidth lower access latency clients 
clients firewall proxy firewall machine server server server proxy running firewall machine service clients inside subnet 
documents cached clients proxies servers 
effects web caching fold 
shown caching documents improve web performance significantly 
web caching 

web caching reduces bandwidth consumption decreases network traffic lessens network congestion 

web caching reduces access latency due reasons frequently accessed documents fetched nearby proxy caches remote data servers transmission delay minimized 
reduction network traffic documents cached retrieved relatively faster caching due congestion path workload server 

web caching reduces workload remote web server disseminating data proxy caches wide area network 

remote server available due remote server crash network partitioning client obtain cached copy proxy 
robustness web service enhanced 

side effect web caching provides chance analyze organization usage patterns 
furthermore suggested group caches cooperating terms serving requests making storage decisions result powerful paradigm improve cache effectiveness 
worth note disadvantages caching system web services 

main disadvantage client looking stale data due lack proper proxy updating 

access latency may increase case cache due extra proxy processing 
cache hit rate maximized cost cache minimized designing caching system 

single proxy cache bottleneck 
limit set number clients proxy serve 
efficiency lower bound proxy system ought efficient direct contact remote servers enforced 

single proxy single point failure 

proxy cache reduce hits original remote server lot information providers maintain true log hits pages 
decide allow documents cacheable 
lot research done study effect web caching maximize benefits 
subtle issues employing caching system facilitate web services need studied solved proxy location cache routing dynamic data caching 
naive caching system may degrade web performance drastically introduce instabilities network 
intelligent careful design crucial improve quality web service 
remainder organized follows 
section outlines elements world wide web caching system section describes desirable characteristics 
section gives brief survey previous works schemes improve web performance 
summarize identifying research frontier web caching section 
elements world wide web caching system generic model web caching system shown 
system documents cached clients proxies servers 
client requests page local proxy doesn valid copy page browser cache 
receiving request client proxy checks see requested page 
returns page client 
doesn requested page cache sends request cooperative proxies server 
receiving request proxy proxy checks requested page 
returns page requesting proxy 
proxy may forward request proxies server 
cooperative proxies page requested page fetched server 
order www caching system problems need solved properly cache proxies organized hierarchically distributed hybrid 
caching system architecture place cache proxy order achieve optimal performance 
proxy placement cached caching system data connection computation 
caching contents proxies cooperate 
proxy cooperation kind data information shared cooperated proxies 
data sharing proxy decide fetch page requested client 
cache resolution routing proxy decide prefetch web server proxies reduce access latency 
prefetching proxy manage page stored cache page removed cache 
cache placement replacement proxy maintain data consistency 
cache coherency control information url routing information distributed proxies 
control information distribution deal data cacheable 
dynamic data caching questions addressed reasonable caching system 
depending choices answering question variety schemes proposed 
discussed section 
desirable properties www caching system obvious goals web caching system web caching system number properties 
fast access robustness transparency scalability efficiency adaptivity stability load balanced ability deal heterogeneity simplicity 
discuss turn 
proxy clients web server cooperation clients clients generic www caching system 
web server fast access 
users point view access latency important measurement quality web service 
desirable caching system aim reducing web access latency 
particular provide user lower latency average employing caching system 
robustness 
users prospect robustness means availability important measurement quality web service 
users desire web service available want 
robustness aspects 
desirable proxies crash wouldn tear entire system 
caching system eliminate single point failure possible 
second caching system fall back gracefully case failures 
third caching system design way easy recover failure 
transparency 
web caching system transparent user results user notice faster response higher availability 
scalability 
seen explosive growth network size density decades facing rapid increasing growth near 
key success environment scalability 
caching scheme scale increasing size density network 
requires protocols employed caching system lightweight possible 
efficiency 
aspects efficiency 
overhead web caching system impose network 
caching system impose minimal additional burden network 
includes control packets extra data packets incurred caching system 
second caching system shouldn adopt scheme leads utilization critical resources network 
adaptivity 
desirable caching system adapt dynamic changing user demand network environment 
adaptivity involves aspects cache management cache routing proxy placement essential achieve optimal performance 
stability 
schemes web caching system shouldn introduce instabilities network 
example naive cache routing dynamic network information result oscillation 
oscillation desirable network utilization variance access latency proxy server high 
load balancing 
desirable caching scheme distributes load evenly entire network 
single proxy server shouldn bottleneck hot spot degrades performance portion network slow entire service system 
ability deal heterogeneity 
networks grow scale coverage span range hardware software architectures 
web caching scheme need adapt range network architectures 
simplicity 
simplicity asset 
simpler schemes easier implement accepted international standards 
ideal web caching mechanism simple deploy 
web caching schemes having described attributes ideal web caching system survey schemes described literature point inadequacies 
caching architectures performance web cache system depends size client community bigger user community higher probability cached document previously requested soon requested 
caches sharing mutual trust may assist increase hit rate 
caching architecture provide paradigm proxies cooperate efficiently 
hierarchical caching architecture approach coordinate caches system set caching hierarchy 
hierarchical caching caches placed multiple levels network 
sake simplicity assume levels caches bottom institutional regional national levels 
bottom level hierarchy client browser caches 
request satisfied client cache request redirected institutional cache 
document institutional level request forwarded regional level cache turn forwards unsatisfied requests national level cache 
document cache level national level cache contacts directly original server 
document cache original server travels hierarchy leaving copy intermediate caches path 
requests document travel caching hierarchy document hit cache level 
hierarchical web caching proposed harvest project 
examples hierarchical caching adaptive web caching access driven cache hierarchical architecture bandwidth efficient particularly cooperating cache servers high speed connectivity 
structure popular web pages efficiently diffused demand 
problems associated caching hierarchy 
set hierarchy cache servers need placed key access points network 
requires significant coordination participating cache servers 

hierarchy level may introduce additional delays 

high level caches may bottlenecks long queueing delays 

multiple copies document stored different cache levels 
distributed caching architecture number researchers proposed setup totally distributed caching scheme caches bottom level 
distributed web caching systems intermediate cache levels institutional caches serve misses 
order decide institutional cache retrieve document institutional caches keep meta data information content institutional cache 
distribution meta data information efficient scalable hierarchical distribution mechanism employed 
hierarchy distribute directory information location documents actual document copies 
distributed caching traffic flows low network levels congested additional disk space required intermediate network levels 
addition distributed caching allows better load sharing fault tolerant 
large scale deployment distributed caching may encounter problems high connection times higher bandwidth usage administrative issues 
approaches distributed caching 
harvest group designed internet cache protocol icp supports discovery retrieval documents neighboring caches parent caches 
approach distributed caching cache array routing protocol carp divides url space array loosely coupled caches lets cache store documents url hashed 
harrison proposed distributed internet cache 
scheme upper level caches replaced directory servers contain location hints documents kept cache 
hierarchical meta data hierarchy distribution location hints efficient scalable 
tewari proposed similar approach implement fully distributed internet caching system location hints replicated locally institutional caches 
central directory approach crisp central mapping service ties certain number caches 
system cache servers establish cache routing table cache server designed server number web sites 
user requests forwarded proper cache server cache routing table 
summary cache cache digest project caches messages indicating content keep local directories facilitate finding documents caches 
hybrid caching architecture hybrid scheme caches may cooperate caches level higher level distributed caching 
icp typical example 
document fetched parent neighbor cache lowest rtt 
rabinovich proposed limit cooperation neighbor caches avoid obtaining documents distant slower caches retrieved directly origin server lower cost 
performance caching architectures main performance measure expected latency retrieve web document 
debatable caching architecture achieve optimal performance 
research shows hierarchical caching shorter connection times distributed caching placing additional copies intermediate levels reduces retrieval latency small documents 
shown distributed caching shorter transmission times higher bandwidth usage hierarchical caching 
configured hybrid scheme combine advantages hierarchical distributed caching reducing connection time transmission time 
cache resolution routing scalability deployment concerns led designers web caching infrastructures schemes deploying large number web caches scattered internet 
main challenge approaches quickly locate cache containing desired document 
problem similar general problem network routing solved way 
conventional routing protocols scale route aggregation possible hierarchical addressing 
documents url prefixes server address prefixes necessarily delivered clients necessary location cache locations 
way aggregate routes cache routing tables large 
addition updated frequently 
date cache routing information leads cache misses 
order minimize cost cache ideal cache routing algorithm route requests proxy believed contain desired document close path client web server 
common approach grow caching distribution tree away popular server sources high demand cache resolution cache routing table hash functions 
works requests popular documents documents propagate caches quickly 
popular documents search may follow long circuitous path numerous failed checks 
impact substantial hit rate web caches typically indicating large number documents low moderate popularity 
cache routing table problem making group caches function 
user request page directed arbitrary cache 
page stored returned user 
cache forwards requests caches ip multicast 
page cached request forwarded home site page 
harvest cache system organizes caches hierarchy uses cache resolution protocol called internet cache protocol icp 
requests web documents forwarded hierarchy search cached copy 
attempt keep overloading caches root caches query siblings passing requests upwards 
adaptive web caching uses mesh caches distribution trees server built 
caches mesh organized overlapping multicast groups request travels search cached document 
scheme benefits constructing different distribution trees different servers root node overloaded robust 
popular objects queries travel caches check requires query responses group machines 
authors suggest dealing problem limiting number caches request access 
harrison construct manually configured hierarchy traversed requests 
scheme promising way reduces load top level caches keeping location pointers hierarchy 
wang describes preliminary plan system put cache routing tables caches specify page server look local cache hold document 
default route documents help keep table size reasonable 
reduce time needed find relatively unpopular cached documents latency searching documents cached guttag integrate routing requests datagram routing services provided network layer 
hashing function cache array routing protocol carp allows distributed caching hash function array membership list url provide exact cache location object cached downloading internet 
proxy server added removed urls need reassigned new hash function need distributed proxies number proxy servers 
summary cache proxy keeps summary urls cached documents participating proxy checks summaries potential hits sending queries 
reduce overhead summaries stored bloom filter updated periodically 
experiments shown summary cache reduces number inter cache protocol messages bandwidth consumption protocol cpu overhead significantly maintaining cache hit ratio icp internet caching protocol 
karger describe theoretically technique constructing server distribution trees load balancing properties special kind hashing called consistent hashing 
consistent hash function needs minimal changes range function changes 
hashing technique designed relieving hot spots www development 
additionally may solve reassignment problem carp 
prefetching web performance improved caching documents proxies benefit technique limited 
previous research shown maximum cache hit rate achieved caching algorithm usually 
words regardless caching scheme documents cache 
way increase cache hit rate anticipate document requests preload prefetch documents local cache 
prefetching applied ways web contexts 
browser clients web servers 

proxies web servers 

browser clients proxies 
browser clients web servers early studies focus prefetching schemes browser clients web servers 
padmanabhan mogul analyze latency reduction network traffic prefetching web server traces trace driven simulation 
prediction algorithm prediction partial matching ppm data compressor prefix depth 
study shows prefetching web servers individual clients reduce client latency expense doubling network traffic 
bestavros cunha model speculative dissemination world wide web documents 
shows patterns observed web server effective source information drive prefetching reaches similar results 
cunha collection web client traces study effectively user web accesses predicted past web accesses 
show number models prefetching 
crovella barford analyzed network effects prefetching shows prefetching reduce access latency cost increasing network traffic increasing network traffic burstiness increasing network delays 
proposed rate controlled prefetching scheme minimize negative network effect minimizing transmission rate prefetched documents 
early studies consider model caching proxies fail answer question performance prefetching completely 
proxies web servers proxies assist web access research interest shifted investigating prefetching techniques proxies web servers 
kroeger investigate performance limits prefetching web servers proxies show combining perfect caching perfect prefetching proxies reduce client latency high bandwidth clients 
markatos propose web servers regularly push popular documents web proxies push documents clients 
evaluate performance strategy web server traces find technique anticipate client request 
technique requires cooperation web servers 
study evaluate client latency reduction technique 
cohen investigate similar techniques 
proxy software prefetches documents links embedded images 
proxy push documents client 
gwertzman seltzer discuss technique called geographical push caching web server selectively sends documents caches closest clients 
focus study deriving reasonably accurate network topology information information select caches 
browser clients proxies prefetching done browser clients proxies 
bharghavan proposed design implementation proxy system performs prefetching image filtering hoarding mobile clients 
fan proposed approach reduce latency prefetching caching proxies browsers 
approach relies proxy predict cached documents user ppm data compressor takes advantage idle time user requests push pull documents user 
simulation results show prefetching combined large browser cache delta compression reduce client latency 
summary approaches run risk increasing wide area network traffic affects traffic modems lans 
approaches attempt prefetch documents considered popular servers documents predicted accessed user near access pattern 
cache placement replacement key aspect effectiveness proxy caches document placement replacement algorithm yield high hit rate 
cache placement studied number cache replacement algorithms proposed studies attempt minimize various cost metrics hit rate byte hit rate average latency total cost 
classified categories suggested 

traditional replacement policies direct extensions lru evicts object requested 
lease frequently lfu evicts object accessed frequently 
pitkow recker evicts objects lru order objects accessed day case largest removed 

key replacement policies replacement policies category evict objects primary key 
ties broken secondary key tertiary key size evicts largest object 
lru min biased favor smaller objects 
objects cache size lru min evicts object cache 
objects size lru min starts evicting objects lru order size 
object largest log size object objects log size evicted 
lru threshold lru objects larger certain threshold size cached 
hyper refinement lfu break ties recency size 
lowest latency minimizes average latency evicting document lowest download latency 

cost replacement policies replacement policies category employ potential cost function derived different factors time access entry time object cache transfer time cost object expiration time 
size gd size associates cost object evicts object lowest cost size 
hybrid associates utility function object evicts utility reduce total latency 
lowest relative value evicts object lowest utility value 
normalized cost replacement employs rational function access frequency transfer time cost size 
bolot employs weighted rational function transfer time cost size time access 
size adjusted lru orders object ratio cost size choose objects best size ratio 
server assisted scheme models value caching object terms fetching cost size request time cache prices time period requests 
evicts object value 
hierarchical hierarchical gd object placement replacement cooperatively hierarchy 
sum great deal effort maximize hit rate 
performance replacement policies depends highly traffic characteristics www accesses 
known policy outperform web access patterns 
cache coherency caches provide lower access latency side effect cache provide users stale pages pages date respect master copies web servers pages originated 
web cache update pages cache give users pages fresh possible 
caching problem cache coherency world wide web similar problems caching distributed file systems 
web different distributed file system access patterns larger scale single point updates web objects 
commands assist web proxies maintaining cache coherence dealing cache coherence mechanisms give brief overview commands provides assist web proxies maintaining cache coherence 

get 
retrieves document url 

conditional get 
get combined header modified 
date proxies ask remote server return copy modified 

pragma cache 
header appended get indicate object reloaded server irrespective modified 
browsers netscape offer reload button uses header retrieve original copy 

modified date 
returned get message indicates time page modified 

date date 
time object considered fresh different modified header 
netscape popular browsers provide mechanism displaying value page date header document info window 
commands clients web proxies 
remote server receives conditional get request support just sends entire document 
reported major servers support conditional get header 
cache coherence mechanisms current cache coherency schemes providing types consistency 
strong cache consistency weak cache consistency proposed investigated caches world wide web 

strong cache consistency client validation 
approach called time 
proxy treats cached resources potentially date access sends modified header access resources 
approach lead responses response code modified server resource change 
server invalidation 
detecting resource change server sends invalidation messages clients accessed potentially cached resource 
approach requires server keep track lists clients invalidating cached copies changed resources unwieldy server number clients large 
addition lists date causing server send invalidation messages clients longer caching resource 

weak cache consistency adaptive ttl 
adaptive ttl called alex protocol handles problem adjusting document time live observations lifetime 
adaptive ttl takes advantage fact file lifetime distribution tends bimodal file modified long time tends stay unchanged 
time live attribute document assigned percentage document current age current time minus modified time document 
studies shown adaptive ttl keep probability stale documents reasonable bounds 
proxy servers cern httpd mechanism 
harvest cache mainly uses approach maintain cache consistency percentage set 
problems expiration coherence 
user wait expiration checks occur tolerant staleness requested page 
second user satisfied staleness returned document choice pragma cache request load entire document home site 
third mechanism provides strong guarantee document staleness 
forth users specify degree staleness willing tolerate 
user aborts document load caches abort document load 
piggyback invalidation 
krishnamurthy propose piggyback invalidation mechanisms improve effectiveness cache coherency 
invalidation mechanisms proposed 
piggyback cache validation pcv capitalizes requests sent proxy cache server improve coherency 
simplest case proxy cache reason communicate server piggybacks list cached potentially stale resources server validation 
basic idea piggyback server invalidation psi mechanism servers piggyback reply proxy list resources changed access proxy 
proxy invalidates cached entries list extend lifetime entries list 
proposed hybrid approach combines psi pcv techniques achieve best performance 
choice mechanism depends time proxy requested invalidation volume 
time small psi mechanism longer gaps pcv mechanism explicitly validate cache contents 
rationale short gaps number invalidations sent psi relatively small time grows longer overhead sending invalidation larger overhead requesting validations 
caching contents cache proxy recognized effective mechanism improve web performance 
proxy may serve roles data cache connection cache computation cache 
study shown caching web pages proxy reduces user access latency comparing proxy scheme 
presence proxy connection cache 
persistent connections clients proxy proxy web server total latency improvements grow substantially 
computation caching viewed web server replicates migrates services proxies alleviate server bottleneck 
application computation caching dynamic data caching 
motivation presence current caching schemes hit ratio proxy limited fact significant percentage web pages dynamically generated cacheable 
computation caching improve performance retrieve dynamic data caching dynamic data proxies migrating small piece computation proxies generate maintain cached data 
user access pattern prediction proxy policies managing cached resources prefetching coherence placement replacement tcp connections rely assumptions client access pattern 
improve information exchanges web servers proxies variety techniques proposed predict requests 
set approaches group resources accessed likelihood pairs resources accessed server file system structure 
prediction partial match ppm model predict page accessed near 
load balancing experienced hot spot phenomenon context web 
hot spots occur time large number clients wish simultaneously access data get services single server 
site provisioned deal clients simultaneously service may degraded lost 
approaches overcoming hot spots proposed 
kind replication strategy store copies hot pages services internet spreads serving hot page service servers proxies 
proxy placement placement proxies important achieve optimal web performance 
desirable properties proxy placement policies self organizing efficient routing efficient placement load balancing stable behavior little study done address issue 
li attempted solve assumptions underlying network topologies minimum spanning tree modeled dynamic programming problem 
dynamic data caching mentioned benefit current web caching schemes limited fact fraction web data cacheable 
non cacheable data personalized data authenticated data server dynamically generated data significant percentage total data 
example measurement results show user requests contain cookies 
data cacheable reduce latency access non cacheable data crucial problems order improve web performance 
current approaches classified categories active cache server accelerator 
active cache supports caching dynamic documents web proxies allowing servers supply cache applets attached documents requiring proxies invoke cache applets cache hitting finish necessary processing contacting server 
shown active cache scheme result significant network bandwidth saving expense cpu cost 
due significant cpu overhead user access latency larger caching dynamic objects 
web server accelerator resides front web servers speed user accesses 
provides api allows application programs explicitly add delete update cached data 
api allows accelerator cache dynamic static data 
invalidating updating cached data facilitated data update propagation dup algorithm maintains data dependence information cached data underlying data graph 
web traffic characteristics understanding nature workloads system demands created users world wide web crucial properly designing provisioning web services 
effectiveness caching schemes relies presence temporal locality web streams appropriate cache management policies appropriate web workloads 
number measurements done exploit access properties clients proxies servers 
web service popular users suffering network congestion server overloading 
great efforts improve web performance 
web caching recognized effective techniques alleviate server bottleneck reduce network traffic minimize user access latency 
give overview web caching schemes 
surveying previous works web caching notice open problems web caching proxy placement cache routing dynamic data caching fault tolerance security research frontier web performance improvement lies developing efficient scalable robust adaptive stable web caching scheme easily deployed current network 
special prof keshav department computer science cornell university valuable comments 
abdulla fox abrams williams www proxy traffic characterization application caching cs vt edu abdulla proxy proxy char ps 
abrams abdulla williams fox caching proxies limitations potentials proceedings th international www conference boston ma dec 
aggarwal wolf yu caching world wide web ieee transactions knowledge data engineering vol 
january february 
bloom space time trade offs hash coding allowable errors communications acm pp 
july 
bharat broder measuring web www research digital com src sem html 
barford bestavros bradley crovella changes web client access patterns characteristics caching implications world wide web special issue characterization performance evaluation 
bestavros cunha server initiated document dissemination www ieee data engineering bulletin sept 
breslau cao fan phillips shenker web caching zipf distributions evidence implications proceedings infocom 
bhattacharjee calvert zegura selforganizing wide area network caches ieee infocom april 
bolot performance engineering world wide web application dimensioning cache design proceedings th international www conference paris france may 
cate alex global file system proceedings usenix file system workshop pp 
may 
crovella network effects prefetching proceedings infocom 
caceres douglis feldmann glass rabinovich web proxy caching devil details acm performance evaluation review pp 
december 
chankhunthod danzig neerdaels schwartz hierarchical internet object cache usenix january 
cao irani cost aware www proxy caching algorithms proceedings usenix symposium internet technologies systems usits monterey ca dec 
challenger iyengar dantzig scalable system consistently caching dynamic web data proceedings infocom 
cunha determining www user access application pre fetching proceedings iscc second ieee symposium computers communications july 
cohen krishnamurthy rexford improving performance web server volumes proxy filters proceedings sigcomm 
cohen krishnamurthy rexford evaluating server assisted cache replacement web proceedings european symposium algorithms 
cohen krishnamurthy rexford efficient algorithms predicting requests web servers proceedings infocom 
cao liu maintaining strong cache consistency world wide web proceedings th ieee international conference distributed computing systems may 
yamaguchi interactive prefetching proxy server improvement www latency proceedings inet june 
cao zhang beach active cache caching dynamic contents web proceedings ifip international conference distributed systems platforms open distributed processing middleware pp 

dias cope smart internet caching system www isoc org ar inet proc htm 
douglis feldmann krishnamurthy mogul rate change metrics live study world wide web proceedings usenix symposium internet technologies systems usits dec 
measured access characteristics world wide web client proxy caches proceedings usenix symposium internet technologies systems cs ubc ca spider feeley html 
web cache coherence fifth international world wide web conference paris france 
ewing hall measurement study internet file transfer traffic technical report cu cs university colorado dept computer science boulder colorado january 
fan cao almeida broder summary cache scalable wide area web cache sharing protocol proceedings sigcomm 
feldmann caceres douglis glass rabinovich performance web proxy caching heterogeneous bandwidth environments proceedings infocom 
fan cao lin jacobson web prefetching low bandwidth clients proxies potential performance proceedings sigmetrics 
cache relay www proceedings st international www conference geneva switzerland may www research digital com src personal steve glassman ps 
gadde rabinovich chase reduce reuse recycle approach building large internet caches proceedings hotos workshop may www cs duke edu ari cisi crisp recycle htm 
seltzer case geographical pushing caching hotos conference ftp edn techreports tr ps gz 
seltzer world wide web cache consistency proceedings usenix technical conference pp 
january 
yates diffusion caching routing paths bu edu faculty ps 
hypertext transfer protocol rfc 
hypertext transfer protocol rfc 
jung nation wide caching project korea design experimentation proceedings nd web cache workshop ircache nlanr net cache workshop papers html 
dahlin coordinated placement replacement large scale distributed caches proceedings ieee workshop internet applications july technical report tr department computer science university texas austin december 
karger lehman leighton levine lewin panigrahy consistent hashing random trees distributed caching protocols relieving hot spots world wide web stoc 
kroeger long mogul exploring bounds web latency reduction caching prefetching proceedings usenix symposium internet technologies systems monterey ca dec 
plaxton rajaraman placement algorithms hierarchical cooperative caching proceedings th annual acm siam symposium discrete algorithms january 
krishnan utility cooperating web proxy caches computer networks isdn systems pp 
april 
krishnamurthy wills study piggyback cache validation proxy caches world wide web proceedings usenix symposium internet technology systems pp 
december 
krishnamurthy wills piggyback server invalidation proxy cache coherency proceedings www conference pp 

krishnamurthy wills proxy cache coherency replacement complete picture june 
internet cache protocol extension internet draft draft icp ext txt 
luotonen world wide web proxies computer networks isdn systems international conference www april 
bharghavan alleviating latency bandwidth problems www browsing proceedings usenix symposium internet technologies systems usits dec 
guttag network level support improve cache routing computer networks isdn systems pp 
nov 
li golin italiano deng optimal placement web proxies internet proceedings infocom 
levy iyengar song dias design performance web server accelerator proceedings infocom 
rizzo vicisano replacement policies proxy cache www iet unipi luigi research html 
client cache communication internet draft draft com txt 
markatos top approach prefetching web proceedings inet 
lorch berger making world wide web caching servers cooperate proceedings th international www conference boston ma dec www com lorch html 
michel nguyen rosenstein zhang floyd jacobson adaptive web caching new caching architecture computer network isdn systems november 
building web caching system architectural considerations proceedings th joint european networking conference edinburgh scotland may 
japan cache project experiment domain cache computer networks isdn system september 
harrison distributed internet cache proceedings th australian computer science conference sydney australia feb 
mendelzon web prefetching partial match prediction proceedings wcw 
padmanabhan mogul predictive prefetching improve world wide web latency proceedings sigcomm 
rabinovich issues web content replication 
rabinovich chase gadde hits created equal cooperative proxy caching wide area network computer networks isdn systems pp 
nov 
cooperative caches world wide web www sor inria fr projects 
marshall variations cache behavior computer networks isdn systems pp 
april 
wessels cache digest proceedings rd international www caching workshop june 
rodriguez spanner biersack web caching architectures hierarchical distributed caching proceedings wcw 
scheuermann shim case delay conscious caching web documents proceedings th international www conference santa clara apr 
tewari dahlin vin kay hierarchies design considerations distributed caching internet technical report tr department computer science university texas austin february 
tewari vin dan sitaram resource caching web servers proceedings spie acm conference multimedia computing networking mmcn january 
ross cache array routing protocol internet draft draft vinod carp txt 
wang distributed cache system world wide web web cache workshop 
wessels intelligent caching world wide web objects proceedings inet honolulu hawaii june info isoc org hmp archive papers ps 
worrell invalidation large scale network object caches thesis department computer science university colorado boulder colorado december ftp ftp cs colorado edu pub cs techreports schwartz ps 
abrams proxy caching estimates page load delays proceedings th international www conference april www cs vt edu docs www 
williams abrams abdulla fox removal policies network caches world wide web documents proceedings sigcomm 
wessels claffy internet cache protocol ipc version rfc 
wessels claffy application internet cache protocol ipc version rfc 
yin alvisi dahlin lin leases support server driven consistency large scale systems proceedings th international conference distributed computing system icdcs may 
yu performance study collaborative method hierarchical caching proxy servers computer networks isdn systems pp 
april 
yang wang muntz wang access driven web caching ucla technical report 
