personal news agent talks learns explains daniel billsus michael pazzani department information computer science university california irvine irvine ca ics uci edu pazzani ics uci edu intelligent information agents far focused systems accessible world wide web 
demanding schedules prohibit people continuous access computers clear demand information systems require workstation access graphical user interfaces 
personal news agent designed part intelligent ip enabled radio uses synthesized speech read news stories user 
voice feedback user system automatically adapts user preferences interests 
addition time coded feedback explore components system facilitate automated induction accurate interest profiles 
motivate multistrategy machine learning approach allows induction user models consist separate models long term short term interests 
time coded feedback agent designed operate environments graphical user interfaces practical voice operation natural alternative 
news stories read user speech synthesizer user interrupt synthesizer point provide different forms feedback described previous section 
agent goal feedback learn model user multiple interests 
order fully exploit information provided kind feedback need algorithms specifically designed task 
substantial amount learning user preferences text documents :10.1.1.40.2101
scenarios users rate text documents respect interests assign binary class labels scores certain scale 
labeled documents training examples learning algorithm resulting hypothesis seen user model allows classifying new documents 
similar methodology applied spoken text important note spoken text time coded feedback contain additional information facilitate learning classification process 
believe point time user provides feedback interrupts news story informative incorporated classification algorithms 
natural choice achieve desired functionality nearest neighbor algorithm nn 
nn algorithm simply stores training examples case rated news stories memory 
order classify new unlabeled instance algorithm compares stored instances defined similarity measure determines nearest neighbor nearest neighbors 
class label assigned new instance derived class labels nearest neighbors 
utility nn algorithm previously explored text classification applications :10.1.1.1.4610
apply algorithm natural language text define similarity measure quantifies similarity text documents 
studied problem information retrieval rely commonly document representation associated similarity measure 
convert news stories tf idf vectors term frequency frequency cosine similarity measure quantify similarity vectors 
rated story converted tf idf representation stored user model 
tracking abilities nearest neighbor algorithm explored researchers similar project 
contrast learning algorithms require large number training examples identify strong pattern 
modeling long term interests purpose long term user model model user general preferences news stories compute predictions stories classified short term model 
achieve selected probabilistic learning algorithm na bayesian classifier 
na bayes shown perform competitively complex algorithms increasingly popular algorithm text classification applications :10.1.1.46.1529
represent news stories boolean feature vectors feature indicates presence absence word 
words appear news stories features 
explicit goal model user general preferences provide algorithm background knowledge set domain specific features words indicators commonly recurring themes daily news stories 
approximately words selected ranging countries crime disaster politics technology business sport related terms 
