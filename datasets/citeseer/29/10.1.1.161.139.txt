ieee transactions pattern analysis machine intelligence vol 
september simple algorithm nearest neighbor search high dimensions sameer nene nayar problem finding closest point high dimensional spaces common pattern recognition 
unfortunately complexity existing search algorithms tree tree grows exponentially dimension making impractical dimensionality 
nearly applications closest point interest lies user specified distance simple practical algorithm efficiently search nearest neighbor euclidean distance projection search combined novel data structure dramatically improves performance high dimensions 
complexity analysis helps automatically determine structured problems 
comprehensive set benchmarks clearly shows superiority proposed algorithm variety structured unstructured search problems 
object recognition demonstrated example application 
simplicity algorithm possible construct inexpensive hardware search engine times faster software equivalent 
implementation algorithm available request search cs columbia edu cave 
index terms pattern classification nearest neighbor searching slicing benchmarks object recognition visual correspondence hardware architecture 
nearest neighbors continues prove important problem fields science engineering 
nearest neighbor problem multiple dimensions stated follows set points novel query point dimensional space find point set distance lesser equal distance point set 
variety search algorithms advanced knuth stated post office problem 
need new algorithm 
answer existing techniques perform poorly high dimensional spaces 
complexity techniques grows exponentially dimensionality high dimensional mean say 
high dimensionality occurs commonly applications eigenspace appearance matching real time object recognition visual positioning tracking inspection feature detection 
techniques require nearest neighbor search performed euclidean distance norm 
hard problem especially dimensionality high 
high dimensionality observed visual correspondence problems motion estimation mpeg coding disparity estimation binocular stereo optical flow computation structure motion 
propose simple algorithm efficiently search nearest neighbor distance authors department computer science columbia university new york 
mail sameer nayar cs columbia edu 
manuscript received feb revised may 
recommended acceptance webb 
information obtaining reprints article please send mail tpami computer org ieeecs log number 
high dimensions 
shall see complexity proposed algorithm small grows slowly algorithm successful tackle nearest neighbor problem originally stated finds points distance novel point 
property sufficient pattern recognition problems problems stated match declared high confidence novel point sufficiently close training point 
occasionally possible assume known suggest method automatically choose briefly outline proposed algorithm 
algorithm projection search paradigm friedman 
friedman simple technique works follows 
preprocessing step dimensional training points ordered different ways individually sorting coordinates 
sorted coordinate arrays thought axis entire dimensional space collapsed projected 
novel point nearest neighbor follows 
small offset subtracted added coordinates obtain values 
binary searches performed sorted arrays locate positions values 
axis minimum number points positions chosen 
points positions chosen axis exhaustively searched obtain closest point 
complexity technique roughly nde clearly inefficient high simple projection search improved 
utilizes precomputed data structure maintains mapping sorted unsorted original coordinate arrays 
addition mapping indicator array elements 
element ieee ieee transactions pattern analysis machine intelligence vol 
september indicator array henceforth called indicator corresponds point 
search indicators initialized number small offset subtracted added novel point coordinates obtain values 
binary searches performed sorted arrays locate positions values 
mapping sorted unsorted arrays find points corresponding coordinates values 
indicators corresponding points binary shifted left bit entire process repeated dimensions 
points indicators value lie hypercube 
exhaustive search performed hypercube points find nearest neighbor 
data structure able find points hypercube primarily integer operations 
total number machine operations required integer floating point find points hypercube similar friedman algorithm roughly nde 
due fact modern cpus significantly penalize floating point operations improvement slight benchmarked section 
propose data structure significantly reduces total number machine operations required locate points hypercube roughly ej data structure facilitates simple hardware implementation result increase performance orders magnitude 
previous search algorithms divided broad categories exhaustive search hashing indexing static space partitioning dynamic space partitioning randomized algorithms 
algorithm described falls category 
algorithms categorized vector spaces metric spaces 
categories fall category falls 
metric space search techniques possible compute distance measure sample points pieces data space points reside lacks explicit coordinate structure 
focus vector space techniques 
detailed discussion searching metric spaces refer 
exhaustive search term implies involves computing distance novel point point set finding point minimum distance 
approach clearly inefficient complexity nd 
hashing indexing fastest search techniques run constant time 
space required store index table increases exponentially hybrid schemes hashing high dimensional space low dimensional space indexing low dimensional space proposed 
dimensionality reduction called geometric hashing 
problem increasing dimensionality difficult construct hash function distributes data uniformly entire hash table index 
added drawback arises fact hashing inherently partitions space bins 
points adjacent bins closer third point bin 
search algorithm uses hash table index correctly find point adjacent bin 
hashing indexing really effective novel point exactly equal database points 
space partitioning techniques led elegant solutions multidimensional search problems 
method particular theoretical significance divides search space voronoi polygons 
voronoi polygon geometrical construct obtained intersecting perpendicular adjacent points 
search space voronoi polygons allow nearest neighbor log operations number points database 
unfortunately cost constructing storing voronoi diagrams grows exponentially number dimensions 
details 
algorithm interest binary search generalized dimensions 
runs log time requires storage impractical 
widely algorithm searching multiple dimensions static space partitioning technique dimensional binary search tree called tree 
tree data structure partitions space hyperplanes placed perpendicular coordinate axes 
partitions arranged hierarchically form tree 
simplest form tree constructed follows 
point database chosen root node 
points lying side hyperplane passing root node added left child points side added right child 
process applied recursively left right children small number points remain 
resulting tree hierarchically arranged hyperplanes induces partition space hyper rectangular regions termed buckets containing small number points 
tree search nearest neighbor follows 
coordinates novel point descend tree find bucket contains 
exhaustive search performed determine closest point bucket 
size query hypersphere set distance closest point 
information stored parent nodes determine hypersphere intersects buckets 
bucket exhaustively searched size hypersphere revised necessary 
fixed certain assumptions underlying data tree requires nlog operations construct log operations search 
trees extremely versatile efficient low dimensions 
performance degrades ex nene nayar simple algorithm nearest neighbor search high dimensions increasing dimensionality 
high dimensions query hypersphere tends intersect adjacent buckets leading dramatic increase number points examined 
trees dynamic data structures means data added deleted small cost 
impact adding deleting data search performance quite unpredictable related amount imbalance new data causes tree 
high imbalance generally means slower searches 
number improvements basic algorithm suggested 
friedman recommends partitioning hyperplane chosen passes median point placed perpendicular coordinate axis direction spread points maximum 
sproull suggests truncated distance computation increase efficiency high dimensions 
variants tree address specific search problems 
tree space partitioning structure trees partitioning element hyperplane hyper rectangular region 
hierarchical rectangular structure useful applications searching image content needs locate closest manifold cluster novel manifold cluster 
tree addresses problems involved implementing trees large disk databases 
tree dynamic data structure tree search performance affected addition deletion data 
number variants trees improve basic technique packed trees trees trees 
trees useful implementing sophisticated queries managing large databases performance nearest neighbor point searches high dimensions similar trees complexity grows exponentially static space partitioning techniques proposed branch bound quad trees vp trees hb trees significantly improve performance high dimensions 
clarkson describes randomized algorithm finds closest point dimensional space log operations rpo randomized post office tree 
time taken construct rpo tree space required store 
impractical number points large 
algorithm searching slicing illustrate proposed high dimensional search algorithm simple example space shown fig 

call set points wish search closest point point set 
goal find point point set closest novel query point 
appears contradictory previous statement claim log complexity assuming fixed varying 
exact relationship complexity established observed roughly exponential 
distance approach find points lie inside cube see fig 
side centered typically small number points inside cube small 
closest point performing exhaustive search points 
points inside cube know points fig 

proposed algorithm efficiently finds points inside cube size novel query point closest point performing exhaustive search cube euclidean distance metric 
points cube follows 
find points pair parallel planes see fig 
add list call candidate list 
planes perpendicular axis coordinate frame located side point distance trim candidate list discarding points parallel pair planes perpendicular located side distance procedure repeated planes candidate list contains points cube size centered number points final trimmed list typically small cost exhaustive search negligible 
major computational cost technique constructing trimming candidate list 
data structure candidate list construction trimming done variety ways 
propose method uses simple pre constructed data structure binary searches efficiently find points pair parallel hyperplanes 
data structure constructed raw point set depicted fig 

assumed point set static ieee transactions pattern analysis machine intelligence vol 
september point set data structure needs constructed 
point set stored collection arrays jth array contains jth coordinate points 
point set coordinates point lie row 
illustrated dotted lines fig 

suppose novel point coordinates qd 
recall order construct candidate list need find points point set lie pair parallel hyperplanes separated distance perpendicular coordinate axis centered need locate points coordinate lies limits done help binary searches limit coordinate array sorted 
fig 

data structures constructing trimming candidate list 
point set corresponds raw list data points ordered set coordinate sorted 
forward backward maps enable efficient correspondence point ordered sets 
sort coordinate arrays point set independently obtain ordered set 
unfortunately sorting raw coordinates leave information regarding points arrays ordered set correspond point point set vice versa 
purpose maintain maps 
backward map maps coordinate ordered set corresponding coordinate point set conversely forward map maps point point set point ordered set 
notice maps simple integer arrays point set ordered set forward backward maps respectively 
backward map find corresponding points point set shown dark shaded areas add appropriate points candidate list 
construction candidate list complete 
trim candidate list iterating follows 
iteration check point candidate list forward map see kth coordinate lies limits limits obtained binary search 
points kth coordinates lie outside range shown light gray discarded list 
final iteration points remaining candidate list ones lie inside hypercube side centered discussion proposed constructing candidate list dimension performing list trimming dimensions order 
wish emphasize operations done order yield desired result 
section shall see possible determine optimal ordering cost constructing trimming list minimized 
important note operations trimming list integer comparisons memory lookups 
proposed data structure limited floating point operations just binary searches needed find row indices corresponding hyperplanes 
feature critical efficiency proposed algorithm compared competing ones 
facilitates simple software implementation permits implementation hardware search engine 
previously stated algorithm needs supplied appropriate prior search 
possible large class problems pattern recognition instance match declared novel point sufficiently close database point 
reasonable assume priori choice prove problematic case 
solution set large seriously impact performance 
hand small result hypercube empty 
determine optimal problem 
exactly affect performance algorithm 
seek answers questions section 
complexity section attempt analyze computational complexity data structure storage construction nearest neighbor search 
saw previous section constructing data structure essentially sorting arrays size done time 
additional storage necessary hold forward backward maps 
requires space nd 
nearest neighbor search major computational cost process candidate list construction trimming 
number points initially added candidate list depends distribution data point set location novel point facilitate analysis structure problem assuming widely distributions point set 
notation 
random variables denoted uppercase letters instance vectors bold suffixes denote individual elements vectors instance qk kth element vector probability density written discrete fq continuous 
nene nayar simple algorithm nearest neighbor search high dimensions hyperplane pair 
points candidate list lie hyperplane pair 
time replacing number points candidate list entire point set 
assume point set independently distributed 
total number points candidate list iteration fig 

projection point set novel point dimensions search space 
number points inside bin binomial distribution 
fig 
shows novel point set points space drawn known distribution 
recall candidate list initialized points hyperplane pair dimension generally cth dimension 
corresponds points inside bin fig 
entire point set projected cth coordinate axis 
boundaries bin hyperplanes intersect axis number points bin order determine average number points added candidate list compute 
define distance point candidate list 
distribution may calculated distribution point set 
define probability projected point point set distance possible write expression density terms irrespective distribution points binomially distributed kn pmc pc expression average number points bin easily determined em kq np note mc qc random variable depends location distribution known expected number points bin computed mc mc qc 
perform lookup backward map point hyperplane pair main computational effort directly estimates cost candidate list construction 
derive expression total number points remaining candidate list trim dimensions sequence cd 
recall iteration perform forward map lookup point candidate list see lies 
equivalent elementary probability problem success point bin occur probability number successes occur independent trials points binomially distributed 
ck ci define total cost constructing trimming candidate list 
trim need perform forward map lookup integer comparisons 
assign cost unit operations expression written aid hg average nm ci kj enq nep equation suggests distributions fq fz known compute average cost terms section shall examine cases particular interest uniformly distributed normally distributed 
note left cost exhaustive search points final hypercube 
reason cost exhaustive search dependent distance metric 
cost small neglected cases needs considered added 
section making observation 
mentioned earlier advantage examine dimensions specific order 
order 
expanding summation product factoring terms rewritten hg ci qp ii immediate value minimum cd words chosen numbers points hyperplane pairs ascending order 
easily ensured simply sorting numbers points 
note ieee transactions pattern analysis machine intelligence vol 
september numbers obtained time simply difference indices ordered set returned pair binary searches 
cost sorting numbers dlog heap sort 
clearly costs negligible problem reasonable dimensionality 
uniformly distributed point set look specific case point set uniformly distributed 
point point set assume independent uniform distribution extent coordinates caf rst fact expression density written zc rst qc written cs af zc qc eq dz dz substituting considering upper bound worst case get hg hg kj hg hg en 
ii kj ii neglecting constants write en ej small observe independent hg cost kj en ne fig 
plotted different fig 
different fig 

observe long cost varies little linearly proportional means keeping small crucial performance algorithm 
shall see fact kept small problems 
cost algorithm grows linearly small real problems better pay price linearity exponential dependence normally distributed point set look case point set normally distributed 
point point set assume independent normal distribution variance coordinates fx exp caf ps zc xc qc expression density zc obtained get cz exp zc ps pc written zc qc eq dz hg fig 

average cost algorithm independent grows linearly small point set cases assumed uniformly distributed extent 
point set contains points spaces 
point set contains points 
af ci kj qc erf erf nene nayar simple algorithm nearest neighbor search high dimensions respective norm central point 
formally distance vectors defined nm ab qp distance metrics known minkowski metrics 
relevant determining 
norm occurs frequently pattern recognition problems 
unfortunately candidate list trimming algorithm find points hypercube 
bounds naively perform exhaustive search inside seen fig 
correctly find closest point 
notice closer exhaustive search cube incorrectly identify closest 
simple solution problem 
performing exhaustive search impose additional constraint points radius considered see fig 

increases possibility hypersphere empty 
example instance discarded able find point 
clearly need consider fact automatic method determining describe 
fig 

average cost algorithm independent grows linearly small point set cases assumed normally distributed variance 
point set contains points spaces 
point set contains points 
expression substituted evaluated numerically estimate cost fig 
shows cost function 
uniform distribution observe cost nearly independent grows linearly variety pattern classification problems data take form individual gaussian clusters mixtures gaussian clusters 
cases results serve basis complexity analysis 
determining apparent analysis preceding section cost proposed algorithm depends critically setting high results huge increase cost setting small may result empty candidate list 
freedom choose may attractive applications may prove non intuitive hard 
cases automatically determine closest point high certainty 
distribution point set known 
review known facts lp norms 
fig 
illustrates norms selected values points surfaces equidistant sense fig 

illustration various norms known minkowski metrics 
points surfaces equidistant central point 
metric bounds 
fig 

exhaustive search hypercube may yield incorrect result 
closer just exhaustive search cube incorrectly identify closest point 
remedied imposing constraint exhaustive search consider points distance length side hypercube 
ieee transactions pattern analysis machine intelligence vol 
september fig 

computed methods 
finding radius smallest hypersphere contain point high probability 
search performed setting radius constraining exhaustive search 
finding size smallest hypercube contain point high probability 
searching set half length side 
additional searches performed areas marked bold 
propose methods automatically determine computes radius smallest hypersphere contain point specified probability 
set radius algorithm proceeds find points circumscribing hypercube side 
method efficient high dimensions reason follows 
increase dimensionality difference hypersphere hypercube volumes great hypercube corners contain far points inscribed hypersphere 
consequently extra effort necessary perform distance computations corner points eventually wasted 
find circumscribing hypercube second method simply find length side smallest hypercube contain point specified probability 
set half length side 
leads problem described earlier searching points outside hypercube closer sense points inside 
shall describe methods detail see remedy problem 
smallest hypersphere method see analytically compute minimum size hypersphere want able guarantee non empty probability radius hypersphere hs 
total number points hypersphere 
novel point define distance point point set 
binomially distributed density rj pm kq ehs kn pm hs kk fig 

radius necessary find point inside hypersphere varies little probability 
means set knee probability close unity 
point set cases uniformly distributed extent 
point set contains points dimensional space 
point contains points 
probability point hypersphere simply hs rj equation suggests know density probability solve ehs 
example consider case point set uniformly distributed density 
cumulative distribution function uniform distribution integrated hypersphere simply volume 
ehs ehs nene nayar simple algorithm nearest neighbor search high dimensions substituting solving hs get hs hs plotted probability cases 
fig 
fixed different values fixed fig 
fixed different values fixed 
figures illustrate important property large changes probability result small changes hs suggests hs set right hand knee curves probability close unity 
words easy guarantee point hypersphere 
search performed setting length side circumscribing hypercube hs imposing additional constraint exhaustive search points distance hs considered 
smallest hypercube method attempt analytically compute size smallest hypercube want able guarantee non empty probability number points hypercube size hc define distance cth coordinate point set point novel point binomially distributed density hc hc cs pm kq hg ehc zc ehc hg kj probability point hypercube simply hg pm hc zc hc qc equation suggests know density probability solve zc hc specific case point set uniformly distributed expression ehc obtained closed form follows 
density uniform distribution 
get hc hc hg hc kj kj kj fig 

value necessary find point inside hypercube varies little probability 
means set knee probability close unity 
point set cases uniformly distributed extent 
point set contains points dimensional space 
point set contains points 
substituting solving hc get hc hc plotted probability cases 
fig 
fixed different values fixed fig 
fixed different values fixed 
similar graphs obtained case hypersphere hc set right hand knee curves probability close unity 
notice value hc required hypercube smaller required hypersphere especially high precisely reason prefer second smallest hypercube method 
recall sufficient simply search closest point hypercube point outside ieee transactions pattern analysis machine intelligence vol 
september closer point inside 
remedy problem suggest technique 
exhaustive search performed compute distance closest point hypercube 
call distance fig 
closest point hypercube distance clearly closer point exists hypersphere radius parts hypersphere lie outside original hypercube search hyper rectangular regions shown bold performing additional list 
performing exhaustive search hyper rectangles impose constraint point considered distance fig 
hyper rectangular region happens closer 
method complicated gives excellent performance sparsely populated high dimensional spaces high dimensional uniform distribution 
conclude wish emphasize hypercube hypersphere methods interchangeably guaranteed find closest point choice methods depend dimensionality space local density points 
densely populated low dimensional spaces hypersphere method performs quite searching hyper rectangular regions worth additional overhead 
sparsely populated high dimensional spaces effort needed exhaustively search huge circumscribing hypercube far overhead searching hyper rectangular regions 
difficult analytically predict methods suits particular class data 
encourage reader implement methods performs best 
discussion relevant norm equivalent analysis easily performed norm 
benchmarks performed extensive set benchmarks proposed algorithm 
looked representative classes search problems may benefit algorithm 
class data statistical structure 
case instance points uniformly normally distributed 
second class problems statistically unstructured instance points lie high dimensional multivariate manifold difficult say distribution 
section results benchmarks performed statistically structured data 
benchmarks statistically unstructured data refer reader section 
tested commonly occurring distributions normal uniform 
proposed algorithm compared tree exhaustive search algorithms 
algorithms included benchmark yield comparable performance 
set benchmarks normally distributed point sets containing points variance 
test search execution time set points shall call test set constructed 
test set contained points normally distributed variance 
algorithm execution time calculated averaging total time required perform nearest neighbor search points test set 
determine smallest hypercube method described section 
point set normally distributed closed form solution numerically computed follows 
substituting get hg hg qc erf erf ii kj kj setting probability point hypercube variance computed search point fast simple bisection technique 
figs 
show average execution time search point set contains points respectively 
execution times include time taken search computation time taken percent additional searches necessary point hypercube 
varies values sample points follows 
values point 
corresponding respectively 
point values corresponding respectively 
values point 
corresponding respectively 
point values corresponding respectively 
observe proposed algorithm faster tree algorithm fig 

fig 
proposed algorithm faster 
notice tree algorithm runs slower exhaustive search 
reason observation follows 
high dimensions space sparsely populated radius query hypersphere large 
consequently hypersphere intersects buckets large number points examined 
additional overhead traversing tree structure inefficient search sparse high dimensional space 
second set benchmarks uniformly distributed point sets containing points extent 
test set contained points uniformly distributed extent 
execution time search calculated averaging total time required perform closest point search points test set 
determine 
point hypercube incremented searched 
process repeated till point 
nene nayar simple algorithm nearest neighbor search high dimensions fig 

average execution time proposed algorithm benchmarked statistically structured problems 
point set normally distributed variance contains points 
point set normally distributed variance contains points 
proposed algorithm clearly faster high 
point set uniformly distributed extent contains points 
point set uniformly distributed extent contains points 
proposed algorithm perform uniform distributions due extreme sparseness point set high smallest hypercube method described section 
recall uniformly distributed point sets computed closed form 
figs 
show execution times point set contains points respectively 
values corresponding respectively 
values corresponding respectively 
uniform distribution proposed algorithm perform appear slightly faster tree exhaustive search algorithms 
reason high dimensional space sparsely populated requires quite large 
result algorithm ends examining points approaching exhaustive search 
example application appearance matching demonstrate applications fast efficient high dimensional search technique desirable 
real time object recognition requires closest point points space 
second closest point required points lying multivariate high dimensional manifold 
problems examples statistically unstructured data 
briefly review object recognition technique murase nayar 
object recognition performed phases appearance learning phase appearance recognition phase 
learning phase images objects poses captured 
images compute high dimensional subspace called eigenspace 
ieee transactions pattern analysis machine intelligence vol 
september images projected eigenspace obtain discrete high dimensional points 
smooth curve interpolated points belong object 
way object get curve univariate manifold parameterized pose 
manifolds second phase object recognition easy 
image object projected eigenspace obtain single point 
manifold closest point identifies object 
closest point manifold identifies pose 
note manifold continuous order find closest point manifold need finely sample obtain discrete closely spaced points 
benchmark columbia object image library slam software package compute univariate manifolds eigenspace 
manifolds correspond appearance models objects objects shown fig 

manifolds sampled equally spaced points obtain discrete points space 
impossible manually capture large number object images needed large test set 
automatically generated test set points sampling manifolds random locations 
roughly equivalent capturing actual images image sensor noise lens blurring perspective projection effects 
important simulate effects cause projected point shift away manifold substantially affect performance nearest neighbor search algorithms unfortunately difficult relate image noise perspective projection distortion effects location points eigenspace 
simple model add uniformly distributed noise extent coordinates points test set 
approximates real world data 
determined setting gave recognition accuracy 
fig 
shows time taken search different algorithms 
search time calculated averaging total time taken perform closest point searches points test set 
seen proposed algorithm outperforms techniques 
set predetermined value point hypersphere time 
object recognition useful search closest point provides means reject points far manifold objects database 
examine case data statistically unstructured 
closest point required points lying single smooth multivariate high dimensional manifold 
manifold appears frequently appearance matching problems visual tracking visual inspection parametric feature detection 
object recognition manifold representation visual appearance 
novel appearance point algorithm time secs 
proposed algorithm tree exhaustive search projection search fig 
proposed algorithm recognize estimate pose objects columbia object image library 
objects shown 
point set consisted points object eigenspace 
average execution time search compared algorithms 
matching involves finding point manifold closest point 
manifold continuous pose appearance matching nearest neighbor problem sample manifold densely obtain discrete closely spaced points 
trivariate manifold benchmarks obtained visual tracking experiment conducted nayar 
benchmark manifold sampled obtain discrete points 
second benchmark sampled obtain points 
cases test set randomly sampled manifold points 
explained previously noise extent added coordinate test set 
execution time search averaged test set points 
point set determined gave recognition accuracy 
fig 
shows algorithm orders magnitude faster algorithms 
notice exponential behavior tree algorithm 
notice algorithm slightly faster friedman difference due integer operations 
benchmark algorithm till due bit word indicator array 
fig 
seen proposed algorithm faster tree fig 
proposed algorithm faster 

instance tree large query hypersphere result large increase number adjacent buckets may searched 

extent eigenspace 
maximum noise amplitude percent extent eigenspace 
nene nayar simple algorithm nearest neighbor search high dimensions fig 

average execution time proposed algorithm benchmarked unstructured problem 
point set constructed sampling high dimensional trivariate manifold 
manifold sampled obtain points 
proposed algorithm orders magnitude faster algorithms 
manifold sampled obtain points 
manifold sampled obtain points 
tree algorithm slightly faster low dimension degrades rapidly increase dimension 
hardware architecture major advantage algorithm simplicity 
recall main computations performed algorithm simple integer map lookups backward forward maps integer comparisons see point lies hyperplane boundaries 
consequently possible implement algorithm hardware shelf inexpensive components 
hard envision case competitive techniques trees trees difficulties involved constructing parallel stack machines 
proposed architecture shown fig 

field programmable gate array fpga acts algorithm state machine controller performs cpu 
dynamic rams drams hold forward backward maps downloaded cpu initialization 
cpu initiates search performing binary search obtain hyperplane boundaries 
passed search engine held static rams 
fpga independently begins candidate list construction trimming 
candidate looked backward map forward maps 
integer comparator returns true candidate range discarded 
trimming candidate points going dimensions final point list form point set indices returned cpu exhaustive search processing 
note described architecture single comparator number added run parallel near linear performance scaling number comparators 
search engine trimming candidate list cpu course free carry tasks parallel 
begun implementation proposed architecture 
result intended small low cost scsi module plugged standard workstation pc 
estimate module result fold speedup optimized software implementation 
discussion nearest neighbor search section saw possible determine minimum value necessary ensure point hypercube hypersphere high probability 
possible extend notion ensure points high certainty 
ieee transactions pattern analysis machine intelligence vol 
september need look dimensions data 
hard envision case trees example space partitioned hyperplanes particular dimensions 
traversing tree locate bucket contains query point possible choose traversal direction node data corresponding partitioning dimension node missing query point 
fig 

architecture inexpensive hardware search engine proposed algorithm 
recall probability exists point hypersphere radius 
define probability points hypersphere 
write kq pm pm pm pm iq rj expression substituted numerically solved hs 
similarly substituted compute minimum value hc hypercube 
dynamic point insertion deletion currently algorithm uses floating point arrays store ordered set integer arrays store backward forward maps 
result possible efficiently insert delete points search space 
limitation easily overcome ordered set stored array set binary search trees bst bst corresponds array ordered set 
similarly forward maps replaced single linked list 
backward maps done away completely indices reside node bst 
bsts allow efficient insertion deletion nearest neighbor searches longer efficient integer arrays 
order get maximum efficiency bsts balanced see discussion balancing techniques 
searching partial data times required search nearest neighbor absence complete data 
instance consider application requires features extracted image matched features feature space 
possible extract features matching done partially 
trivial adapt algorithm situation trimming list acknowledgments wish simon baker bhat detailed comments criticisms suggestions helped greatly improving 
research conducted center research intelligent systems department computer science columbia university 
supported parts arpa contract dod onr muri national science foundation national young investigator award 
aho hopcroft ullman design analysis computer algorithms 
addison wesley 
arya nearest neighbor searching applications 
cs tr univ maryland june 
aurenhammer voronoi diagrams survey fundamental geometric data structure acm computing surveys vol 
pp 
sept 
beckmann kriegel schneider seeger tree efficient robust access method points rectangles proc 
acm sigmod pp 
atlantic city nj may 
bentley multidimensional binary search trees associative searching comm 
acm vol 
pp 
sept 
bentley multidimensional binary search trees database applications ieee trans 
software engineering vol 
pp 
july 
bentley weide optimal expected time algorithms closest point problems acm trans 
mathematical software vol 
pp 
dec 
bentley multidimensional divide conquer comm 
acm vol 
pp 
apr 
califano mohan multidimensional indexing recognizing visual shapes proc 
ieee conf 
computer vision pattern recognition pp 
june 
clarkson randomized algorithm closest point queries siam computing vol 
pp 
aug 
dobkin lipton multidimensional searching problems siam computing vol 
pp 
june 
edelsbrunner algorithms combinatorial geometry 
berlin heidelberg springer 
linder fast nearest neighbor search dissimilarity spaces ieee trans 
pattern analysis machine intelligence vol 
pp 
sept 
friedman baskett algorithm finding nearest neighbors ieee trans 
computers pp 
oct 
friedman bentley finkel algorithm finding best matches logarithmic expected time acm trans 
mathematical software vol 
pp 
sept 
fukunaga narendra branch bound algorithm computing nearest neighbors ieee trans 
computers pp 
july 
effective way represent quadtrees comm 
acm vol 
pp 
dec 
guttman trees dynamic index structure spatial searching proc 
acm sigmod pp 
june 
nene nayar simple algorithm nearest neighbor search high dimensions horowitz sahni fundamentals data structures nd ed 
rockville md computer science press 
klee complexity dimensional voronoi diagrams arch 
math vol 
pp 

knuth sorting searching art computer programming vol 

reading mass addison wesley 
lomet salzberg hb tree multiattribute indexing method guaranteed performance proc 
acm tods vol 
pp 
dec 
oncina vidal new version nearest neighbor approximating eliminating search algorithm linear preprocessing time memory requirements pattern recognition letters pp 

murase nayar visual learning recognition objects appearance int computer vision vol 
pp 
jan 
nayar baker murase parametric feature detection proc 
ieee cs conf 
computer vision pattern recognition cvpr pp 
san francisco calif june 
nayar murase nene learning positioning tracking visual appearance proc 
ieee int conf 
robotics automation san diego calif may 
nayar nene murase real time object recognition system proc 
ieee int conf 
robotics automation twin cities may 
nene nayar slam software library appearance matching proc 
arpa image understanding workshop monterey calif nov 
technical report cucs 
netravali digital pictures representation compression standards nd ed 
new york plenum press 
petrakis faloutsos similarity searching large image databases technical report cs tr dept computer science univ maryland dec 
preparata shamos computational geometry 
new york springer 
press teukolsky vetterling flannery numerical recipes nd ed 
cambridge univ press 
robinson tree search structure large multidimensional dynamic indexes proc 
acm sigmod pp 

roussopoulos direct spatial search pictorial databases packed trees proc 
acm sigmod may 
sellis roussopoulos faloutsos tree dynamic index multidimensional objects proc 
th int conf 
vldb pp 
sept 
sproull refinements nearest neighbor searching dimensional trees algorithmica vol 
pp 

reducing overhead metric space nearest neighbour searching algorithm information processing letters 
wolfson model object recognition geometric hashing proc 
european conf 
comp 
vision pp 
apr 
yianilos data structures algorithms nearest neighbor search general metric spaces proc 
acm siam symp 
discrete algorithms pp 

technique identify nearest neighbors ieee trans 
systems man cybernetics vol 
pp 
oct 
sameer nene received degree computer engineering university india ms degree electrical engineering columbia university new york 
currently pursuing phd electrical engineering columbia university new york 
research interests include appearance matching nearest neighbor search applications computer vision image processing computer graphics uncalibrated stereo stereo mirrors image rendering high performance computer graphics 
nayar professor department computer science columbia university 
received phd degree electrical computer engineering robotics institute carnegie mellon university 
primary research interests computational vision robotics emphasis physical models early visual processing sensors algorithms shape recovery pattern learning recognition vision manipulation tracking machine vision computer graphics virtual reality 
dr nayar authored coauthored papers received david marr prize international conference computer vision iccv held boston mass siemens outstanding award ieee computer vision pattern recognition conference cvpr held seattle annual pattern recognition award pattern recognition society best industry related award international conference pattern recognition icpr held jerusalem david marr prize international conference computer vision iccv held osaka 
holds international patents inventions related computer vision robotics 
dr nayar recipient david packard fellowship science engineering national young investigator award national science foundation 
