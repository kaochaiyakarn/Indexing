bayesian approaches failure prediction disk drives greg cs ucsd edu charles elkan elkan cs ucsd edu department computer science engineering university california san diego la jolla california hard disk drive failures rare costly 
ability predict failures important consumers drive manufacturers computer system manufacturers alike 
investigate abilities bayesian methods predict disk drive failures measurements drive internal conditions 
view problem anomaly detection stance 
introduce mixture model naive bayes submodels clusters trained expectation maximization 
second method naive bayes classifier supervised learning approach 
methods tested realworld data concerning drives 
predictive accuracy algorithms far higher accuracy thresholding methods disk drive industry today 

computer industry failures hard disk drives rare costly 
typical model disk drive probability failure year 
low failure rates course desirable collecting data failures predicting failures difficult 
disk drives ability report information internal conditions nass 
information system manufacturers assist failure prediction 
manufacturers developed failure prediction methods rely excessively simple methods particular thresholding single drive attributes 
methods generate false alarms correct failure predictions 
describe learning approaches bayesian methods predict hard disk drive failures 
pose problem anomaly detection viewpoint introduce mixture naive bayes submodels 
model estimates probability distribution readings drives behaving normally trained expectation maximization 
second method standard supervised naive bayes classifier 
test models dataset readings disk drives fail drives fail 

anomaly detection algorithm consider problem labeling data classes class rare 
situation disk drive failure detection 
rare class may data available allow supervised learning algorithm estimate probability model class 
additionally data rare class may incomplete due collection problems 
example historical data concerning drive conditions stored inside disk drive data available drives functioning correctly drives failed 
alternative supervised learning overcomes problems build probabilistic model majority class anomaly detection approach classify test data 
anomaly detection algorithm attempts classify data normal anomalous probability model normal behavior 
anomaly detection widely studied computer network security research lee stolfo 
term data point refers single example learning algorithm 
example data point may summary behavior hard drive hour 
anomaly data point majority class model assigns low probability occurring 
machine learning standpoint model parameters may learned training data concerning normal behavior lane brodley towell 
model parameter unknown learnable quantity part model mean gaussian distribution 
anomalous normal classification similar positive negative classification 
anomaly detection approach differs builds probability model normal class data anomalous class 
anomaly detection algorithm learn parameters ways fully unsupervised fashion learning normal anomalous data 
method assumes anomalous data rare affect model parameters significantly eskin 
semi supervised fashion learning model normal data removing data anomalous class training 
general semi supervised training preferable learn accurate model normal class 
unsupervised training useful training data labeled assumption true anomalous data rare training set 
method constructing anomaly detector follows 
choose probabilistic model data takes data point input outputs probability data point 
learn parameters training data semi supervised unsupervised fashion 
choosing probability threshold model classify data point typical anomalous follows anomalous iff supervised learning data point labeled class highest posterior probability generating data point 
contrast anomaly detection data point labeled normal anomalous depending probability occurrence normal data point 
threshold value may chosen hand assumption rarity anomalous data learned experimentally data known anomalous available 

mixtures naive bayes submodels anomaly detection task model mixture naive bayes submodels clusters 
mixture thought clustering model intended represent multimodal probability distribution 
model trained data expectation maximization em algorithm call approach method 
algorithm similar autoclass method cheeseman stutz 
autoclass general framework mixture model clustering 
autoclass uses maximum likelihood em learn model parameters 
autoclass attempts learn optimal number submodels lets number parameter chosen user 
model overview naive bayes submodel nonparametric data model 
word nonparametric mean parameters learn single simple parameterized probability density gaussian assumed 
probability distribution naive bayes submodel determined frequency counts training data 
submodel estimated prior probability submodel index 
probability estimate assigns data point term probability submodel generates data point estimated training data frequencies 
equation clear submodels contribute probability data point conceptually data points assigned submodels hard way data point generated exactly submodel 
different submodels may generate identical data points data point unknown submodel generated 
assigns data point submodel soft way proportion quantity determined bayes rule 
soft assignment allows model fit data better submodel memberships unknown blurs manifold separates submodels 
naive assumption naive bayes attributes data point conditionally independent submodel attributes typically true assumption simplifies probability estimation works practice lewis 
dimensional data point class discrete naive bayes submodels 
values attribute placed small finite number bins 
bin internal value place true value attribute 
discrete data value gets separate bin transformation merely re mapping 
continuous data naive bayes divides data range bins translates continuous value bin number 
naive bayes em uses equal width binning bin represents interval size input space 
value input parameter 
binning causes loss information continuous data allows smooth probability estimates 
binning advantages allows attribute take continuous discrete values compresses data replacing continuous values small integers representing bin numbers 
naive bayes em estimates probability attribute value training data frequencies count count count count count number data points training dataset satisfy predicate soft assignment data point may contribute fraction count 
formal definition count train model choose number submodels number continuous bins model initialized assigning points randomly submodels em training determines submodel probability data probability conditioned submodel allow apply equation 
em training proceeds rounds expectation step followed maximization step 
step computes data point probability submodel producing point 
probability soft assign data point partially submodel computed bayes rule predicate count count indicator function conditioned sum ranges entire training set 
individual naive bayes models define unimodal distributions familiar exponential family 
naive bayes model may regions high probability 
compared clustering algorithms unimodal distributions gaussians may produce surprising results 
true distribution unknown multimodality may preferable 
disk drive modeling immediately obvious unimodal distribution associate region highest probability 
give flexibility model naive assumption class conditional independence gain flexibility choice number submodels 
example naive bayes model represent xor concept requires dimensional dependence mixture multiple submodels 
training expectation maximization multiple submodels known submodel data point truly belongs may known submodels appropriate 
submodel membership point missing information standard expectationmaximization em algorithm dempster maximize likelihood data model 
avoid underflow floating point calculations mathematical convenience maximize logarithm likelihood right side comes equations 
step computed estimated memberships step updates model parameters equations 
step maximizes log likelihood model expected membership information 
em steps repeat log likelihood defined equation data change 
implementation issues naive bayes model estimates probabilities training data may noisy incomplete smooth probabilities ways 
mentioned continuous attribute values placed bins probabilities estimated intervals individual continuous values 
second method probability smoothing needed deal problem zero counts 
zero count exists bin attribute contains data points training set 
probability estimate causes equation yield zero regardless dimension probabilities 
zero probabilities prevent generalization cause instability em training 
instability refers inconsistent model output trained multiple times slightly varying initial conditions created example cross validation 
address problem zero counts adding artificial counts bins 
effect increasing low probabilities decreasing high probabilities 
popular method zero count smoothing law succession number data points submodel value number values may take total number data points submodel smoothing parameter 
experimental evidence suggests choose small non zero kohavi 
results kohavi choose total number training data points 
probability estimate equation count count total number bins 
models converge consistent results arithmetic smoothing procedure 
table 
smart attributes quantum dataset 
abbreviation description ret read error rate sut time css start count gdc grown defects count ske seek errors count power hours rrt calibration retries pcc power cycles count rse read soft errors count dmc crc errors count oss offline surface scan 
supervised naive bayes learning explore disk drive dataset second method naive bayes classifier 
naive bayes learning known supervised learning method yields classifier distinguishing class data 
information standard naive bayes classifier reader referred lewis 
applied boosting standard classifier obtain ensemble voting classifiers freund elkan application boosting produces appreciable improvement results 
naive bayes em naive bayes classifier place continuous attribute values bins 
supervised naive bayes method equal frequency bins equal width bins placing approximately number data points bin 
experiments show results approximately equal frequency bins 
results sensitive number bins range 
major advantage naive bayes classifiers simple implemented easily inside disk drive field programmable gate array fpga hardware 

quantum smart dataset data comes real world collection quantum modern disk drives incorporate socalled smart self monitoring reporting technology firmware allows disk drive report data activity number hours operation number seek errors occurred corrected information smart nass 
table lists smart attributes available quantum dataset 
smart attributes vendor interface protocol reading values standardized 
standard industry procedure warning potential failure smart attribute number drives number snapshots 
number snapshots drive drives snapshots 
addition drives snapshots drives snapshots 
values separate threshold attribute 
thresholds chosen engineering knowledge operating parameters empirical data analysis 
warning supposed issued attribute surpasses fixed threshold 
practice smart data usually ignored completely number warnings false alarms unacceptably high 
quantum dataset data point time stamped snapshot smart attribute values 
snapshot simply record smart values drive particular time 
snapshots taken semi regular intervals ranging half hour days 
shows drives dataset snapshots drives snapshots maximum snapshots drive 
thousands snapshots single drive may may indicate anomaly data collection 
view wide range snapshots example challenges real world data collection valid snapshots experiments described 
data preparation real world datasets quantum dataset inconsistencies invalid data require preprocessing 
remove snapshots clearly invalid values 
remove duplicate snapshots 
smart attributes quantum drives 
include power hours seek errors spin time 
attributes positively correlated failure perfectly correlated 
attributes read error rate offline surface scan zero 
specification smart attributes cumulative meaning values reset drive firmware 
conceptually sense incremental values cumulative values drive long life may large attribute value growing slowly indicative problem 
transform dataset computing difference snapshot previous 
computed differences negative contradicting specification attribute values cumulative 
negative differences set zero 
zero values cumulative versions dataset 
zero bin 
conceptually value seek error different value zero 
predicting drive failure predict disk drive fail snapshots identified anomalous model failures naive bayes classifier 
tests alarm may sound drive 
additional information number snapshots predicted fail 
assume impossible predict disk drive failure hours happens 
want maximize utility predicting drive fail causing replaced truly necessary 
data concerning drive fails assumed represent drives snapshots hours life represent failed drive prior snapshots represent drive 
approach adds data available drives 
quantum dataset data concerning eclipse drives 
drives labeled failures users returned factory due apparent fault 
failures reproducible drive engineers consider drives include training test sets drive 
failed drive snapshots dataset unusable 
leaves drives labeled failures drive engineers labeled non failures 
accounting failed drives having fail snapshots gives additional table 
labeling true false positive negative drives 
true failure true non failure predict failure true positive tp false positive fp predict false negative fn true negative tn drives snapshots failed drives failed drives snapshots hours 
total snapshots representing drives snapshots representing fail drives 

experimental setup goal obtain high true positive rate identifying fail drives correctly low false positive rate predicting drive fail 
classification labels table 
true false positive rates defined true positive rate number true positives divided total number drives identified model anomalies true failures 
means false negative failed drives labeled anomalous 
false positive rate number false positives divided total number non failed drives non failures dataset 
means true negative non failed drives labeled 
em algorithm random initialization perform fold cross validation obtain average prediction performance 
hold fail drives training making approach semisupervised method 
hold drives testing cross validation iteration 
place fail drives test set due small number 
note cross validation performed drive level number snapshots training testing varies 
typical fold uses snapshots training snapshots testing 
trained models perform parameter sweep threshold obtain receiver operating characteristic roc curve swets plots true positive rate false positive rate 
standard naive bayes classifier plot similar roc curve 
naive bayes classifier gives estimate probability snapshot belongs class failed drives 
choosing threshold class label predicted depending shows result training testing standard true positive rate true positive rate attributes best attributes false positive rate attributes best attributes false positive rate 
performance disk drive failure prediction 
point plotted true positive false positive rate averaged fold cross validation selected threshold value 
threshold values shown 

standard naive bayes performance disk drive failure prediction 
point plotted true false positive rate selected threshold value naive bayes classifier 
threshold values shown 
naive bayes classifier entire quantum dataset cross validation 
results may overfitting 
naive bayes classifiers typically overfit large datasets informal experiments data subsets show overfitting negligible 
mentioned smart attributes quantum dataset value zero 
research hughes shown attributes predictive grown defect count gdc read soft errors rse seek errors ske 
searching combinations attributes ranking classification performance classification methods 
train test models separately attributes predictive 
experiments submodels equal width continuous bins bins attribute zero quartiles non zero attribute values 
performed tests shown showed choices number submodels bins give best performance 

results results naive bayes em standard naive bayes predicting hard drive failures figures respectively 
receiver operating characteristic roc curves show predictive accuracy different threshold values 
threshold values shown figures 
optimal performance top left high true positive rate low false positive rate 
note different scales axes 
cross validation plotted point corresponds single threshold value 
coordinates point plotted averages taken folds fold cross validation 
point independent variable threshold dependent variables average false true positive rates 
shows roc curve single naive bayes classifier 
figures show adjust threshold trade true false positive rates 
decision expected cost type error 
example threshold achieve true positive rate fail drives false positive rate drives predicted fail soon 
dataset means detecting fail drives giving incorrect warnings 
standard naive bayes able detect failures dataset avoiding predicting drives failures 
example best attributes snapshot threshold identify failures having false positive rate 
similarly predictive attributes class threshold standard naive bayes identify failures having false positive rate 
threshold values chosen inspecting roc curves 
error bars shown small clearly visible 
table 
errors small statistically table 
error bars true false positive rates 
number average relevant standard deviation thresholds 
true positive rate false positive rate attributes best attributes significant difference trained attributes versus best 
best attributes gives better true positive rate false positive rate 
considered measuring performance snapshot prediction accuracy believe measuring drive prediction performance useful metric 
experiments snapshot true positive rates significantly higher lower false positive rates compared drive rates 
example achieves true positive rate false positive rate snapshots 
supervised naive bayes classifier performs better smart attributes 
general naive bayes classifiers combining contributions multiple predictors isolation low predictive power 
naive bayes classifiers robust face irrelevant attributes 
general characteristics confirmed dataset 
hand clustering methods better low dimensions high dimensions 
reason method performs worse predictors may ability find clustering degraded 
experiments results shown show arithmetic smoothing law succession important reducing variability model 
smoothing zero counts em training converges different models different initializations 
adding zero count smoothing gives consistent results em converge quickly 

failure prediction methods perform better current industry standard methods perform useful practice 
thresholding methods standard today disk drive industry estimated yield drive level true positive rate false positive rate hughes 
false positive rate achieves true positive rate times better 
point view results suppose quantum dataset representative raid redundant array inexpensive disks containing drives stressful environment snapshot drive raid taken hour 
suppose anomaly detection best attributes 
sound alarm anomalous snapshots alarm hours average 
percentage snapshots corresponds drive level true positive rate false positive rate ratio true failures predicted false alarms 
alarm sounded hours probability alarm predict true failure probability alarm false 
drive level false alarm rate tolerable hot swapping drive designed raid easy operation 
acknowledgments gordon hughes joseph murray center magnetic recording research smart project providing data project time advice 
chris reynolds quantum provided help original data 
cheeseman stutz 

bayesian classification autoclass theory results 
advances knowledge discovery data mining pp 

aaai press 
dempster laird rubin 

maximum likelihood incomplete data em algorithm 
journal royal statistical society 
elkan 

boosting naive bayesian learning technical report cs 
university california san diego 
eskin 

anomaly detection noisy data learned probability distributions 
proceedings international conference machine learning pp 

freund 

boosting weak learning algorithm majority 
information computation 
hughes murray kreutz delgado elkan tran 

improved disk drive failure warnings 
appear ieee transactions reliability see ucsd edu smart 
kohavi becker sommerfield 

improving simple bayes 
proceedings european conference machine learning pp 

lane brodley 

application machine learning anomaly detection 
national information systems security conference 
lee stolfo 

data mining approaches intrusion detection 
proceedings th usenix security symposium pp 

lewis 

naive bayes independence assumption information retrieval 
conference proceedings european conference machine learning pp 



note general case bayes laplace formula inductive posteriori probabilities 
transactions faculty 
mitchell 

machine learning 
new york mc hill 
nass 

smart failure prediction method endorsed scsi disk drives 
electronic design 


natural law succession technical report cs tr 
princeton university 
swets monahan 

better decisions science 
scientific american 
towell 

local expert anomaly detection 
proceedings international conference machine learning 
