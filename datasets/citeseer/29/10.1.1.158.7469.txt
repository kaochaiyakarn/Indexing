temporal sequence learning data reduction anomaly detection lane carla brodley school electrical computer engineering coast laboratory purdue university west lafayette email ecn purdue edu anomaly detection problem formulated learning characterize behaviors individual system network terms temporal sequences discrete data 
approach problem instance learning ibl techniques 
cast anomaly detection task ibl framework employ approach transforms temporal sequences discrete unordered observations metric space similarity measure encodes intra attribute dependencies 
classication boundaries selected aposteriori characterization valid user behaviors coupled domain heuristic 
empirical evaluation approach user command data demonstrates accurately di erentiate pro led user alternative users available features encode su cient information 
furthermore demonstrate system detects anomalous conditions quickly important quality reducing potential damage malicious user 
techniques reducing data storage requirements user pro le including instance selection methods clustering 
empirical evaluation shows new greedy clustering algorithm reduces size user model small loss accuracy 
comparison greedy clustering technique clustering centers shows greedy clustering preferable terms accuracy computation time domain 
examine problem anomaly detection learning characterize behaviors individual system network terms temporal sequences discrete data 
focus user oriented anomaly detection level shell command input methods generalizable learning arbitrary streams discrete events gui events network packet tra system call traces 
anomaly detection problem di cult copyright association computing machinery permission digital hard copies part personal classroom granted fee provided copies distributed pro commercial advantage copies bear notice full citation rst page 
copyrights components owned acm honored 
abstracting credit permitted 
copy republish post servers redistribute lists requires prior speci permission fee 
request permissions publications dept acm fax permissions acm org 
cially level user command traces 
encompasses broad spectrum possibilities trusted system user turning legitimate usage abuse system resources system penetration sophisticated careful hostile outsiders time worker borrowing workstation automated penetrations launched relatively naive attacker scripted attack sequence 
time spans interest vary seconds months 
patterns may appear data gathered number different hosts networks possibly spread thousands miles geographically 
amount data sift truly staggering security may responsible thousands hosts generate megabytes audit data hour 
selection data sources interest di cult 
patterns interest evidence clearly command data system call traces network activity logs cpu load averages disk access patterns hundreds possible sources 
patterns interest may corrupted noise interspersed examples normal system usage 
normal usage may vary greatly user changes tasks software learns new behaviors command actions 
di erentiating innocuous anomalies associated actual abuse misuse intrusion di culty 
top di culties practical security system accurate false alarms reduce user con dence system falsely accepting anomalous hostile activities render system useless 
subsets general problem addressed specialized techniques 
short term hit run attacks attacks launched automated scripts detected pattern matching databases known attack patterns example kum 
similarly numerous free commercial programs detecting presence known vulnerabilities viruses signatures fv gor 
interested subset anomaly detection oriented longer term patterns known misuse signatures insu cient distinguish space possible anomalies 
subset covers intrusions hostile activities trusted user relatively innocuous policy violations inappropriate system resources authorized user 
take machine learning viewpoint problem task train classi er known normal data distinguish normal behaviors anomalous 
eld machine learning arti cial intelligence general strongly motivated pattern detection analysis problems possesses techniques di erent pattern recognition problems 
approach anomaly detection machine learning task de ne learning model representational format input data 
hypothesize temporal interactions carry signi cant amount identifying information learning model explicitly examine interaction 
source independent representation encodes temporal aspects data stream 
popular highly general class machine learning techniques instance learning ibl aka 
model concept interest implicitly represented set instances exemplify concept instance dictionary 
new instance classi ed relation stored instances 
typical scheme nearestneighbor classi cation new instance label majority dictionary instances closest closest domain speci measure taken euclidean distance 
ibl techniques may contrasted learning techniques build explicit models data summary statistics decision trees qui 
required adapt anomaly detection task ibl learning framework 
particular need settle xed length vector feature vector representation data de ne concept closeness similarity oftwo vectors 
need di erent decision process popular nearest neighbor rules 
space possible malicious behaviors intruder actions potentially nite impractical characterize normal behavior contrast known abnormal behaviors 
desirable privacy reasons user anomaly detection agent employ data originates pro led user publicly available 
requirement leads learning situation positive instances available 
learning positive examples presents challenge classi cation easily lead overgeneralization iba 
widely acknowledged di culty instance learning techniques overhead incurred explicitly storing set class exemplars 
dynamic environment xed set training data anomaly detection size instance dictionary conceivably grow bound 
necessary consider data reduction techniques reduce resource consumption ibl system 
possible solutions include removal instances dictionary re representation instances space intensive form 
explore clustering algorithms reduce dictionary size 
formulation group similar instances replaced single exemplar instance 
rest examine methods representing anomaly detection domain ibl task including temporal encoding discrete data streams de nition similarity encodes aspects temporal sequence data 
clustering technique data reduction domain 
nish empirical examination performance di erentiating users learning scheme 
learning temporal sequence data traditional approaches learning temporal sequence data applicable anomaly detection domain base data consists discrete unordered nominal valued elements command strings 
time series numeric values techniques spectral analysis os principle component analysis nearest neighbor matching similarity dgm neural networks proven fruitful 
techniques typically employ euclidean distance related distance measure de ned real valued vectors 
number learning algorithms amenable learning spaces nominal valued attributes typically assumption independence attributes 
example decision trees qui suited representing decision boundaries discrete spaces 
bias search structures generally employs greedy search examines feature independently 
bias ignores internal relations arising causal structures data generating process 
method circumventing di culty convert data atemporal representation causal structures represented explicitly 
norton salzberg independently technique domain learning recognize coding regions dna fragments 
dna coding temporal exhibit interrelations positions di cult conventional learning systems acquire directly 
features extracted dna sequences selected domain experts generalized sequential domains 
approach applied anomaly detection domain require considerable ort part domain expert developed features apply data source 
interested developing techniques applied di erent data sources tasks 
approach similarity measure transforms native data format stream discrete events metric space 
classi cation performed ibl technique selects decision thresholds distance members di erent classes probability falling known patterns 
section describe similarity measure employ describe classi cation procedure transformed space 
description data reduction methods domain 
similarity measure currently similarity measure treats sequences tokens equal xed length 
tokens may drawn discrete nite unordered alphabet gui events unix command names keystrokes system calls 
length similarity sequences xl yl de ned pair functions yi xi yi de ned sim converse measure distance de ned dist sim function accumulates weight linearly matching subsequences sim integral total weight time 
limiting case identical sequences measure collapses sim pl run contiguous matching tokens accumulate large similarity changing single token middle run greatly reduce similarity 
measure depends strongly interactions adjacent tokens comparisons corresponding tokens sequences tokens set sequence 
sequence length user dependent parameter explored lb acceptable compromise users 
user pro le collection sequences selected user observed actions 
similarity pro le newly observed sequence de ned simd rule related nearest neighbor classi cation rule performing classi cation stage de ning similarity known patterns 
examined possibility average similarity entire pro le measure lower accuracy measure 
average decreases ability classi er resolve ne structure patterns classi cation space 
design similarity measure motivated observation human computer interaction fundamentally causal process computer responds human request human turn responds computer output 
weighting adjacent matches attempt capture short term causal linkages user input stream 
similarity measures anomaly detection domain examined lb shown similarity measure described ective anomaly classi cation number di erent pro led users 
segmenting event stream similarity measure de ned xed length sequences necessary partition raw event stream component sequences 
raises question optimal sequence alignments sequence de ned start 
approach hoc initially segmenting data stream possible overlapping sequences length replicating token times 
position event stream considered starting point sequence length referred th sequence sequence time step instance selection see sequences remaining pro le considered de ne desired alignments 
classi cation procedure similarity pro le measure de nes transformation original ary nominal space dimensional real valued space point set command trace appears probability distribution pt possible similarity values su ciently accurate models question guaranteeing observed history pro le user originates user critical examine problem known data accurate assumption 
frequency bayes optimal threshold acceptable false alarm threshold similarity profile comparison unweighted bayes optimal decision boundary acceptable false alarm rate boundary 
rightmost curve user represents pro led user 
distribution normal abusive actions simply construct bayes optimal decision boundary proceed classi cation 
possess data pro led user bayes optimal boundary unobservable 
furthermore data sets examined unweighted bayes optimal threshold overly critical pro led user 
example normal anomalous similarity distributions displayed bayes optimal classi cation threshold alternative possible classi cation threshold acceptable false alarm threshold described 
sequences similarity pro le falls right classi cation threshold labeled normal points falling left labeled abnormal 
area distribution left threshold false alarm probability probability valid user falsely accused anomalous area distribution right threshold probability falsely accepting anomalous user 
example employing unweighted bayes optimal threshold classi cation yields unacceptably high false alarm rate 
light considerations seek method selecting decision boundary 
conveniently constraints domain provide practical heuristic reduce false alarm rate 
pro le choose acceptable false alarm rate set decision boundaries rule class pt pt similarity sequence classi ed denotes normal denotes anomalous 
acceptable false alarm rate site speci value de ned security policy 
practice similarity stream produced comparing input data stream pro le far noisy ective classi cation 
attribute high degree noise natural variations user actions patterns 
example user may temporarily suspend writing deal urgent incoming email disrupting standard writing routine 
disruption appear similarity profile similarity profile time time unsmoothed mean smoothed similarity stream 
spuriously low similarity spike high similarity period 
time average similarity signal yields stable data stream 
employ noise reduction lter selecting decision thresholds performing classi cation 
described employ trailing window mean value lter de ned vd jx simd simd similarity th token sequence user pro le window length vd nal value sequence respect small desirable window length de nes minimum time detection occur 
great deal damage window length short term attacks readily handled matching known attack signatures ks 
primarily concerned class long term low pro le attacks resource theft industrial data theft 
storage reduction instance selection widely acknowledged weakness instance learning algorithms large data storage requirement accurate classi cation 
number techniques examined reducing memory overhead reviewed wilson martinez 
operational setting data reduction critical size data directly impacts time required classi cation 
note rst chosen similarity measure selects single historical sequence similar input sequence 
assume characteristics user behavior change relatively slowly wecan invoke locality predict matched dictionary sequences detection near 
suggests analogy tasks operating systems page replacement resources released favor 
examine analogy lru pruning strategy 
new instances acquired classi cation performed pro le instance selected similar time stamped 
pro le constrained desired size removing sequences 
analogy constructed tested pruning heuristics fifo equivalent preserving stored sequences lifo preserve oldest sequences lfu remove frequently sequences 
lb examined properties methods 
instance selection reliably reduce data storage requirements small accuracy losses 
best instance selection method user dependent 
storage reduction clustering second method reducing data storage modify representation sets points data space 
example salzberg represented sets points hyperrectangles 
propose greedy clustering algorithm builds individual clusters consecutively attempting minimize criterion dist val jcj cluster measure generalization mean inter cluster distance employed clustering 
initial seed point cluster grown incrementally including point increases val halting criterion reached 
growth halted cluster value reaches local minimum 
cases cluster value monotonically approaches halting criterion rst derivative empirically selected value sequence added cluster removed set available sequences 
cluster complete de ne center cluster tobe point possessing minimum total distance points similarity sequence cluster sim 
practice cluster selection algorithm somewhat lenient accepts points decrease cluster ectiveness classi cation 
solve manner analogous pruning process employed decision tree learning qui 
growing single cluster completion halting criterion clustering algorithm removes outlying points returns pool available sequences possibility contributing di erent clusters 
pruning function removes points cluster fall outside cluster mean radius points distance center greater mean distance center points cluster 
points falling mean radius discarded removed consideration nal cluster represented center mean radius 
similarity cluster computed terms cluster center realize substantial space savings discarding cluster elements center 
complete clustering algorithm structurally similar single cluster construction algorithm 
sequentially select individual clusters ability maximize analog mean intra cluster distance cng nx nx dist ci cent cj cent case single cluster halting criterion ine ective typically data set points exhausted derivative intra cluster distance approached 
allowed clustering process absorb available points clusters contribute classi cation accuracy actively harmful 
halt clustering process minimum inter cluster value current clusters falls threshold currently select empirically 
empirical evaluation section describe requirements anomaly detection system measures characterize technique terms requirements 
proceed summaries experimental results characterizing data sets users approach successful 
greedy clustering algorithm ective reducing pro le size maintaining accuracy centers clustering unable domain 
performance criteria goal anomaly detection task identify potentially malicious occurrences falsely innocuous actions rarely possible 
shall denote rate incorrectly normal behaviors false alarm rate rate failing identify abnormal malicious behaviors false acceptance rate 
null hypothesis behavior normal correspond type type ii errors respectively 
detector practical important false alarm rate low 
users security quickly learn ignore security system wolf ags innocuous behavior 
practical security system resource conservative space time 
goal security enhance productivity inhibit consumption system resources 
detection accuracy reveal full story 
second issue importance time detection 
quantity de ned average time detector initialized ags anomalous condition measure quickly anomalous hostile situation detected 
case false alarms time detection represents average time initialization false alarm occurs 
wish time detection short hostile users dealt quickly doing harm long valid user normal interrupted false alarms seldom possible 
examining command line data see measure detection times token counts wall clock time 
token count nearly correlated quantity damage accomplished hostile user detection wall clock time 
comparison current anomaly detection systems results relative known anomaly detection systems ides lj lun haystack sma nsm hdl proved impossible 
descriptions systems tend focus architecture omit performance measures 
spa ord spa reports unaware publication performance measures intrusion anomaly detection systems idiot kum refereed forums 
idiot intrusion detection system employs pattern matching algorithm detect known attack signatures audit data 
patterns intended generalize unknown cases accuracy time space performance measures reported 
data literally thousands possible data sources features characterize system user chose examine unix shell command data 
unix operating system widely extensively studied security operating systems communities 
user environment highly con gurable rich command language permits large range possible behaviors 
unix model user interactions take place command line environment shell command data strongly re ective user activities 
available mechanisms collection shell command data convenient unix environment 
lacking shell traces actual misuse intrusive behaviors demonstrate behavior detection system task di erentiating di erent authorized users unix hosts purdue millennium machine learning lab 
framework anomalous situation simulated testing legitimate user command data legitimate user pro le 
framework simulates subset possible misuse scenarios naive intruder gaining access unauthorized account allows evaluate approach 
hoped naive intruder scenario constitutes large fraction attacks progress domain practical bene acknowledge inability generalize result broader de nitions abuses able test techniques real misuse data 
shell command data di erent unix users course year 
data events tokenized internal format usable anomaly detector 
phase command names behavioral switches preserved le names omitted assumption behavioral patterns approximately invariant le names 
pattern vi file gcc file example represents class action regardless file homework cluster amount data available varied users just tokens tokens depending rates tested pro led user user table correct classi cation percentages pro les test sets 
frequency user entered left study 
uniformity testing selected earliest calendar time tokens user representing average approximately months usage person 
unclustered pro le results user data split separate train set tokens parameter selection set tokens test set tokens 
train set basis pro le classi cation boundaries selected distribution parameter selection data respect pro le 
false accept false alarm rates generated pro le test set 
results table best global choice parameters 
values main diagonal table generated comparison user pro le represent percent true acceptance 
diagonal elements generated testing user di erent user pro le represent percent true detections 
results achieved acceptable false alarm rate sequence length mean ltering window length sequences 
note vary parameters user basis achieve higher accuracies 
anumber points key table 
main diagonal correct classi cations valid user uniformly high 
users achieved self detection accuracy lower speci ed chosen acceptable false alarm rate 
result parameter selection data decision threshold selection failing re ect true distribution user behaviors 
problem leads increased false accept rates 
dramatic illustration problem visible user pro le 
examination user command data discovered user largely changed tasks generation training threshold selection data tasks concerned mainly system maintenance programming tasks 
case particular skew parameter estimation data resulted extremely wide range similarities yielding decision thresholds classi ed nearly valid user 
overly lenient decision boundaries produced spuriously high accuracy 
second source false accept error demonstrated 
valid user behaviors common generic account maintenance directory creation le copy remove operations 
high degree similarity re ected substantial overlaps similarity distributions making di erentiation impossible space 
contrast engaged mainly programming writing similarity profile false accept errors data bears high resemblance pro led user 
time 
possible sources degree overlap 
underlying observations encode su cient information distinguish users 
data sources available user conjunction techniques operational security system 
second fundamental source error similarity measure 
measure fairly coarse having possible values sequence length models single type temporal interaction 
currently investigating sophisticated similarity measures edit distance clr 
time detection explained previously section wish examine mean time detection base system 
measured detection times data users tested false alarm rate sequence length tokens smoothing window length sequences 
longer window length improves time detection gures demonstrate potentially achievable times 
relation window length time detection covered detail 
reasons time smaller subsets available data chosen tokens devoted training parameter selection test 
larger training set chosen mitigate ects behavioral changes see previous section representing larger range behaviors user pro le 
time detection values pro le test pairs table 
wish values high user tested indicating infrequent false alarms small pairings indicating rapid detection anomalous circumstances average 
desire large values main diagonal table small values diagonal 
delays time detection introduced sequence length tokens anumber data sources described den lj sma hdl 
extended version uni ed results parameter settings expect changes little impact general nature results 
tested pro led user user table times detection pro le test data set 
see section noise suppression smoothing window sequences see section omitted table represent constant factors tests 
see table detection system displaying desirable behaviors 
general time detection pro led user time generation false alarm appearing main diagonal long relative time detection alternate users pro le time detection anomaly non diagonal elements reading column wise 
examination raw classi cation data reveals time detections equivalent inverse mean detections unit time 
speci cally false alarms tend occur tight clusters interspersed long strings true accepts yielding long time detection true user 
true detections hand tend evenly distributed yielding shorter expected time detection 
cases time detection indicating average anomalous situation detected tokens minimum possible time 
detection system biased detecting anomalous conditions quickly generating false alarms rare clusters 
type behavior desirable valid user wishes bothered little possible tight group false alarms investigated disregarded group malicious user discovered quickly single true alarm 
clustering techniques examine ectiveness greedy clustering algorithm produced clustered versions user rst experiment section various values clustering halting threshold 
baseline comparison implemented centers clustering algorithm 
centers iterative clustering algorithm attempts class assignments di erent clusters simultaneously gradient descent log likelihood parameter space special case em expectation maximization algorithm rip 
table shows average standard deviation false alarm rate user clustering method 
values obtained greedy clustering halting criteria ranging values single cluster clusters 
centers allowed run iterations 
algorithms run mean median lters 
centers closely related means requires cluster exemplar drawn cluster members interpolation 
vectors unordered discrete elements unix commands mean value available exemplar cluster element 
see false alarm rates generally low greedy clustering matches outperforms centers clustering users 
clustering methods higher false alarm rates unclustered 
false accept rate greedy clustered profile false accept rate unclustered profile relative false accept rates unclustered greedy clustered pro les 
diagonal indicates equal performance 
relative false accept rates unclustered greedy clustering approaches displayed 
false accept rate greedy clustering appears vertical axis rate unclustered appears horizontal 
plotted point single user pro le pair diagonal line indicates equal performance 
points left line indicate superior performance unclustered technique denote higher performance greedy clustering 
see points fall fairly close line indicating greedy clustering generally incurs small accuracy hit 
mitigating loss accuracy data reduction parameters greedy clustering achieved average reduction 
classi cation algorithm runs time input sequences pro le containing jdj instances expect obtain corresponding improvement classi cation speed 
practice classi cation entire token test set sparc ultra required minutes clustering minute 
greedy clustering algorithm typically formed clusters pro le centers converge acceptable solution reasonable period time iterations 
amortized entire month period test data represents percent cpu time 
pro led user clustering greedy centers table false alarm rates percentage clustering method averaged parameter values standard deviations slash 
ltering methods 
halt achieve somewhat higher performance 
false accept error rate averaged users parameters ltering methods dramatically worse greedy clustering clustering 
note passing clusters constructed greedy clustering algorithm intuitive sense terms actions performed underlying sequences 
example ed clusters correspond programming writing reading email navigating directories 
demonstrated technique mapping temporal data occurring anomaly detection task space ibl learning formulated 
results demonstrate technique useful tasks underlying data supports su cient class separation 
furthermore system biased detecting anomalous conditions quickly generating false alarms rarely 
new clustering technique sequential greedy selection clusters 
greedy clustering technique able produce large saving storage requirements small loss accuracy 
centers clustering unable match performance greedy clustering domain convergence rate detection accuracy 
algorithm reported probably insu cient standalone anomaly detection number ways easily augmented improve accuracy decrease time detection 
currently examining similarity measures anomaly detection domain edit distance hidden markov models behavioral patterns 
sophisticated similarity measures improve class separability system accuracy 
weare examining ects changes user behaviors time 
noted section change user behaviors gathering user pro le employing user classi cation lead extremely distorted inaccurate picture user typical behaviors 
developing techniques dynamically adapt pro le user changes time adopt uctuations arising hostile anomalous activities 
note techniques developed intended task independent employed little domain knowledge design 
adding greater degree priori knowledge advice site security specialist system performance improved 
system possesses number parameters set sequence length target false alarm rate noise suppression window length greedy cluster halting criteria results apply single parameter settings users pro les simultaneously 
signi cant impact parameter settings detection accuracy time detection 
parameters properly set pro le basis global accuracy doubtless improved 
currently investigating methods automatically adapting system parameters pro led user 
algorithms employed implemented single detection elements anomaly detection scheme employs alternative data sources biometric measurements resource consumption measurements activity time day 
ensemble classication methods known machine learning community sch body theory surrounding directly applied domain 
summary machine learning oriented approach anomaly detection 
possible learn distinguish anomalous behavior patterns normal type framework 
believe general computer security machine learning communities bene interactions 
ml community studied pattern recognition techniques valuable variety security problems computer security tasks number challenging issues motivate new research directions machine learning community 
aka aha kibler albert 
instancebased learning algorithms 
machine learning 
bollobas das gunopulos mannila 
time series similarity problems separated geometric sets 
th annual acm symposium computational geometry 
association computing machinery 
clr thomas hoa 
cormen charles leiserson ronald rivest 
algorithms 
mit press cambridge ma 

multicomponent nonlinear prediction system index 
neurocomputing 
den dgm denning 
intrusion detection model 
ieee transactions software engineering 
das gunopulos mannila 
finding similar time series 
proceedings fourth international conference knowledge discovery data mining august 
fukunaga 
statistical pattern recognition second edition 
academic press san diego ca 
fv farmer venema 
satan overview security administrator tool analyzing networks 
electronic release mar 
program documentation satan santa tool 
gor gordon 
current computer virus threats countermeasures strategic solutions 
white mcafee associates 
hdl iba ks kum heberlein dias levitt mukherjee wood 
network security monitor 
proceedings ieee symposium research security privacy pages may 
iba 
learning disjunctive concepts examples 
master thesis massachusetts institute technology september 
kumar spa ord 
application pattern matching intrusion detection 
technical report csd tr purdue university west lafayette indiana jun 
kumar 
classi cation detection computer intrusions 
phd thesis purdue university lafayette 
lane 
filtering techniques rapid user classi cation 
proceedings aaai icml joint workshop ai approaches time series analysis appear 
lb lane brodley 
application machine learning anomaly detection 
national information systems security conference baltimore md 
lb lb lj lane brodley 
detecting abnormal machine learning computer security 
technical report tr ece purdue university school electrical computer engineering west lafayette 
lane brodley 
sequence matching learning anomaly detection computer security 
inproceedings aaai workshop ai approaches fraud detection risk management 
lunt jagannathan 
prototype real time intrusion detection expert system 
proceedings ieee symposium security privacy pages 
lun lunt 
ides intelligent system detecting intruders 
proceedings symposium computer security threat countermeasures rome italy 
norton 
learning recognize promoter sequences coli modelling uncertainty training data 
proceedings twelfth national conference onarti cial intelligence pages seattle wa 
os oppenheim schafer 
discrete time signal processing 
signal processing 
prentice hall englewood cli new jersey 
qui quinlan 
programs machine learning 
morgan kaufmann san mateo ca 
rip sal sal ripley 
pattern recognition neural networks 
cambridge university press cambridge uk 
salzberg 
nearest learning method 
machine learning 
salzberg 
locating protein coding regions human dna decision tree algorithm 
journal computational biology 
staniford chen cheung crawford frank levitt wee yip 
grids graph intrusion detection system large networks 
proceedings th national information systems security conference 
national institute standards technology national computer security center oct 
sch scha er 
cross validation stacking bi level methods stacking meta methods classi cation learning 
cheeseman editors selecting models data arti cial intelligence statistics iv 
springer verlag new york 
sma spa wil 
haystack intrusion detection system 
proceedings fourth aerospace computer security applications conference pages 
spa ord 
personal communication january 
wilson 
advances instance algorithms 
phd thesis brigham young university provo ut 

