cognitive science 
forward models supervised learning distal teacher michael jordan department brain cognitive sciences massachusetts institute technology david rumelhart department psychology stanford university internal models environment important role play adaptive systems general particular importance supervised learning paradigm 
demonstrate certain classical problems associated notion teacher supervised learning solved judicious learned internal models components adaptive system 
particular show supervised learning algorithms utilized cases unknown dynamical system actions desired outcomes 
approach applies supervised learning algorithm capable learning multi layer networks 
revised version mit center cognitive science occasional 
learning algorithms connectionist networks seen progressive weakening assumptions relationship learner environment 
classical supervised learning algorithms perceptron rosenblatt lms algorithm widrow ho strong assumptions output units adaptive units network teacher provides desired states output units 
early development algorithms recognized powerful supervised learning algorithms realized weakening rst assumption incorporating internal units adaptively input representation provided environment rosenblatt 
subsequent development algorithms boltzmann learning hinton sejnowski backpropagation lecun parker rumelhart hinton williams werbos provided means training networks adaptive nonlinear internal units 
second assumption weakened learning algorithms require explicit teacher developed becker hinton grossberg kohonen linsker rumelhart :10.1.1.183.1750
unsupervised learning algorithms generally perform sort clustering feature extraction input data assumptions statistical topological properties input ensemble 
examine detail notion teacher supervised learning paradigm 
argue teacher liability commonly assumed assumption environment provides desired states output network weakened signi cantly abandoning supervised learning paradigm altogether 
feel appropriate interpretation role teacher crucial range problems paradigm applied 
inaccurate jacobian matrix remove zeros estimated gradient points zero introduce additional zeros spurious local minima 
second estimated gradients obtained approximate forward model positive inner product stochastic gradient equation expected step algorithm downhill cost 
algorithm principle nd exact inverse model forward model approximate 
may advantages predicted performance error 
particular may easier situations obtain learning trials internal model external environment rumelhart smolensky mc hinton sutton :10.1.1.48.6005
internal trials thought form mental practice case backpropagation weights planning case backpropagation activation 
procedures lead improved performance forward model su ciently accurate 
exact solutions procedures forward model exact 
modularity cases unknown mapping actions sensations decomposed series simpler mappings modeled independently 
