proceedings ieee international conference acoustics speech signal processing detroit mi may hierarchical static scheduling dataflow graphs multiple processors jos luis pino edward lee department electrical engineering computer science university california berkeley ca pino eal eecs berkeley edu discuss hierarchical scheduling framework reduce complexity scheduling synchronous dataflow sdf graphs multiple processors 
core framework clustering technique reduces number actors expanding sdf graph directed acyclic graph dag 
internals clusters scheduled uniprocessor sdf schedulers optimize memory usage 
clustering done manner leave ample parallelism exposed multiprocessor scheduler 
illustrate framework real time example constructed ptolemy 

dataflow natural representation signal processing algorithms 
strengths exposes parallelism expressing actual data dependencies exist algorithm 
applications specified dataflow graph nodes represent computational actors data tokens flow arcs graph 
ptolemy framework supports dataflow programming computational models discrete event 
generating stand application dataflow graph description consists phases scheduling synthesis 
scheduling phase dataflow graph partitioned parallel execution 
splice send receive actors graph interprocessor communication 
actors synchronization necessary self timed implementation 
target processor sequence actor firings determined 
synthesis phase code segments associated actor stitched order specified scheduler 
commercial systems threading technique include dpc descartes 
techniques describe complementary dpc descartes principle combination 
forms dataflow defined ptolemy 
synchronous dataflow sdf number tokens produced consumed firing actor constant 
property possible determine execution order memory requirements compile time 
systems overhead run time scheduling contrast dynamic dataflow predictable run time behavior 
production consumption property arcs provides natural representation multirate signal processing blocks 
focus scheduling sdf graphs multiple processors 
sections review scheduling sdf graphs including uniprocessor scheduling dag construction 
discuss clustering techniques hierarchical scheduling framework 
look extensions current dag schedulers declustering order break larger grain clusters expose parallelism 
circumstances able delay possibly avoid expansion sdf sub graphs dag 

synchronous dataflow shows simple multirate sdf graph 
graph actor produces tokens actor consumes tokens firing 
valid sdf schedule fifo buffers arc return initial state schedule period 
balance equations written arc integral repetitions vector solves system equations 
simple example balance equation arc ra rb repetition vector valid schedules rb 
simple sdf graph 

sdf graph exhibiting dag nodes 
graph 
sdf specification find schedule compile time iteratively repeated run time 
schedule sdf graphs multiple processors directed acyclic graph dag constructed original sdf graph 
sdf graph exposes functional parallelism algorithm dag addition exposes data parallelism available 
dag graph shown 
notice actor original sdf graph multiple nodes dag corresponding repetitions count derived balance equations 
unfortunately expansion due repetition count sdf actor lead exponential growth nodes dag 
sdf graph exhibits growth shown 
order number nodes dag calculated mn 
growth undesirable especially considering known optimal multiprocessor scheduling algorithms precedence constraints complexity exponential number nodes dag 
uniprocessor sdf schedulers hand require dag generated scheduling purposes 
limit explosion nodes translating sdf graph dag graph introduce clustering connected subgraphs larger grain composite actors 
composite actors scheduled available uniprocessor schedulers 
cluster actors manner simplifies dag graph hiding parallelism 
multiprocessor schedulers clustering heuristics schedule dag graph multiple processors 
important note resultant cluster mapped single processor 
purpose introduce simple clustering techniques directly sdf graph reducing number sdf nodes expanded final dag graph 
clustering sdf graph gives opportunity specialized uniprocessor sdf schedulers 
uniprocessor schedulers optimize parameters code size memory usage 

clustering techniques section review clustering techniques sdf graphs 
currently clustering techniques user specified resource constraint limited homogeneous sdf chain structured subgraphs multirate chain structured subgraphs actors internal state 
clustering technique far simplest allow user specify clusters mapped single processor 
clustering technique empowers user fundamental scheduling decisions 
potential problem user introduce artificial deadlock 
error easily caught compile time 
automatically cluster subgraphs ensure constructed clusters introduce artificial deadlock 
apply cluster conditions listed 
clustering technique takes account resource constraints 
mapping sdf graphs heterogeneous processors group connected actors may required mapped particular processor 
free cluster sdf subgraphs long introduce artificial deadlock 
clustering techniques cluster chains sdf actors 
chain structured sdf subgraph actor connected actors 
source actor connected input arcs destination actor connected output arcs 
clustering chain structured sdf subgraphs group branch merge sdf actors actors multiple sources destinations functional parallelism exposed 
third clustering technique groups actors homogeneous chain structured sdf subgraph actors internal state equivalently self loop arcs 
homogeneous sdf subgraph 
dag sdf graph 

homogeneous chain structured sdf graph bis pack bits pseudo random bits dsp modem error display unpack bits bis error display delay control constellation display unpack bits coder phase transmitter channel variable delay phase receiver decoder pack bits quadrature transmitter peek quadrature transmitter poke 
qpsk acoustic modem 
top center block diagram top level modem schematic 
hierarchy pseudo random bits dsp modem error display blocks expanded accompanying block diagrams 
blocks dsp modem execute host workstation 
dsp modem executes ariel dsp board 
number outputs produced arc equal number inputs consumed arc see 
clustering hide available parallelism exposed final dag 
clusters obey linear clustering heuristic described dag multiprocessor scheduling 
clustering technique groups actors chain structured subgraphs multirate actors having internal state 
internal state introduces dependencies various repetitions actor schedule period reducing data parallelism available 
example actors sdf graph shown internal state resultant dag shown additional precedence arcs connecting 
previous clustering heuristics technique hide available parallelism case 

acoustical modem example section detail quadrature phase shift keying qpsk acoustical model scheduled heterogeneous processors risc dsp 
sdf specification shown 
pseudo random bit stream generated workstation packed dsp word stream bits word 
stream words sent dsp word form bit stream 
bits encoded symbol bits symbol 
dsp transmits receives symbol stream speaker microphone channel 
received symbols decoded packed sent back workstation errors displayed user 
user control alignment symbol period examine resultant constellation peek poke mechanism described 
transmitter receiver filters polyphase fir filters interpolation decimation factors samples respectively 
note sdf graph shown expressed hierarchically 
total sdf actors corresponding dag total nodes 
able sdf uniprocessor schedulers sdf subgraph clusters example able obtain single appearance schedule leads compact code 
single appearance schedule sdf schedule actor appears 
obtain single appearance schedule uniprocessor schedulers multiprocessor scheduler hierarchical scheduling framework 
cluster hierarchy multiprocessor scheduler schedule dag nodes 
multiprocessor schedule generated fully expanded dag graph function call inlined procedure nodes compared function calls hierarchical schedule 
makespans schedules generated hierarchical scheduler traditional full dag expansion varied hierarchical longer 
difference due fact cluster sdf actors treated atomic sdf actor outside scheduler 
inputs available cluster fires 
furthermore outputs available cluster schedule iteration completed 
investigating cyclo static dataflow method eliminate variance makespans 
cyclo static dataflow actor firing distinct phases 
phase produces consumes fixed amount data input output 
cluster schedule expressed schedule phases allowing part cluster fire soon input available versus waiting input phases 

introduced hierarchical scheduling framework sdf graphs mapped multiple processors 
framework drastically reduce number nodes final dag graph parallel scheduling 
shown practical example scheduling technique greatly improved final schedule 
plan augment sdf graph clustering techniques specializing dag clustering heuristics multiprocessor schedulers direct sdf graph 
objective hide parallelism exploited anyway doing simplifying dag 
acknowledgments research part ptolemy project supported advanced research projects agency air force program contract semiconductor research project dc national science foundation mip office naval technology naval research laboratories state california micro program companies bell northern research cadence hitachi mentor graphics mitsubishi nec pacific bell philips rockwell sony synopsys 
jos luis pino supported bell laboratories part cooperative research fellowship program 
buck ha lee messerschmitt ptolemy framework simulating prototyping heterogeneous systems international journal computer simulation special issue simulation software development vol 
pp 

pino ha lee buck software synthesis dsp ptolemy journal vlsi signal processing appear special issue synthesis dsp 
lee ha scheduling strategies multiprocessor real time dsp ieee global telecommunications conference exhibition 
communications technology dallas tx usa 
powell lee newman direct synthesis optimized dsp assembly code signal flow block diagrams ieee international conference acoustics speech signal processing san francisco ca 
ritz meyr high level software synthesis signal processing systems international conference application specific array processors berkeley ca usa 
lee messerschmitt synchronous data flow proceedings ieee vol 
pp 

buck ha lee messerschmitt multirate signal processing ptolemy ieee international conference acoustics speech signal processing toronto ont canada 
garey johnson computers intractability guide theory np completeness 
new york freeman 
yang comparison clustering heuristics scheduling directed acyclic graphs multiprocessors journal parallel distributed computing vol 
pp 

rabaey scheduling dsp programs multiprocessors maximum throughput ieee transactions signal processing vol 
pp 

kim browne general approach mapping parallel computations multiprocessor architectures international conference parallel processing university park pa usa 
lee declustering new multiprocessor scheduling technique ieee transactions parallel distributed systems 
bhattacharyya buck ha lee compiler scheduling framework minimizing memory requirements multirate dsp systems represented dataflow graphs university california berkeley ucb erl april 
pino parks lee automatic code generation heterogeneous multiprocessors ieee international conference acoustics speech signal processing adelaide south australia 
lee messerschmitt digital communication nd ed 
boston kluwer academic publishers 
pino parks lee mapping multiple independent synchronous dataflow graphs heterogeneous multiprocessors ieee asilomar conference signals systems computers pacific grove ca 
engels static scheduling multi rate cyclo static dsp applications ieee international workshop vlsi signal processing la jolla california 
