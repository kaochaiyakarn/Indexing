managing online self adaptation real time environments robert goldman david musliner kurt automated reasoning group honeywell laboratories mn technology drive minneapolis mn goldman musliner honeywell com 
provides solution deliberation scheduling problem self adaptive hard real time intelligent control self adaptive cooperative intelligent real time control architecture sa circa 
self adaptive software deliberation scheduling problem deciding aspects artifact improved methods improvement chosen time devoted activities 
time spent deliberation scheduling carefully controlled time available primary self adaptation task 
provide markov decision process mdp model deliberation scheduling sa circa 
directly solving mdp feasible relatively modest domains 
provide polynomial time greedy myopic approximation algorithm 
evaluate approximation gold standard provided dynamic programming value iteration algorithm mdps 
experimental results show approximation produces competitive solutions quickly 
suppose autonomous aircraft flying complex mission broken different phases takeoff ingress target surveillance egress landing 
mission phase aircraft control system prepared plan controller specifying particular actions reactions phase 
suppose autonomous control system onboard aircraft self adaptive modify behavior plans improve performance 
adapt 
mission changed flight aircraft equipment fails damaged weather cooperate original mission plans formed quickly optimized 
case aircraft self adaptive control system facing deliberation scheduling problem 
decide mission phase plan try improve self adaptation improve plan time spend self adaptation process 
deliberation scheduling problem strong real time components 
deliberation scheduling process take account time self adaptation require value adaptation affected time produced relationship alternative uses computation time 
second deliberation scheduling process deciding think consumes time affects potential value self adaptation 
developing self adaptive cooperative intelligent real time control architecture sa circa address precisely type domain including deliberation scheduling problem 
sa circa domain independent architecture intelligent self adaptive autonomous control systems applied hard real time mission critical applications 
sa circa includes controller synthesis module csm automatically synthesize reactive controllers environments include timed discrete dynamics 
controller synthesis process occur offline system begins operating environment online execution phase plans 
online controller synthesis adapt changing circumstances continually improve quality controllers current mission phases 
sa circa adaptive mission planner amp responsible control sa circa agent decomposing mission phases managing agent responsibilities negotiating agents deliberation activity 
currently developing amp deliberation scheduling functions emphasizing real time aspects problem 
experimental sa circa module uses stochastic models controller synthesis process allocate computational effort controller improvement mission phases 
synthesis process model addresses real time aspect deliberation scheduling attempts predict long controller synthesis process take particular type improvement particular mission phase 
information decision theoretic estimate expected utility proposed self adaptation 
address second real time aspect deliberation scheduling time cost meta level decision developing computationally feasible heuristics deliberation scheduling decisions greedily quickly 
assess performance greedy heuristics building somewhat simplified markov decision process mdp models amp deliberation scheduling problem assessing optimal greedy solution policies 
preliminary results indicate greedy heuristics able high quality deliberation scheduling decisions polynomial time expected utility measures quite close np complete optimal solutions 
sa circa agent designed control mission critical systems time pressure 
current experiments working teams sa circa agents controlling simulated aerial vehicles uavs combat missions 
sa circa automatically dynamically generates hard real time control programs guaranteed keep platform safe executes mission 
sa circa state space planner ssp generates evade simple radar missiles start reliable temporal transition done resume normal path 
instance action name evasive preconds path normal path evasive delay instance reliable temporal name evade radar missile preconds radar missile tracking path evasive radar missile tracking delay range instance action name evasive preconds path evasive path normal delay radar threats occur time 
instance event name radar threat preconds radar missile tracking radar missile tracking don defeat threat seconds re dead 
instance temporal name radar threat kills preconds radar missile tracking failure delay fig 

example circa description radar launched sam threat 
controllers models system environment guarantees provided control timing information models 
example sa circa uav model radar guided sam threats containing information fast threats operate see fig 

things model specifies minimum delay uav detecting painted enemy radar destruction missile type 
sa circa uses information ensure controllers monitor enemy radar lock ons frequently take countermeasures fast 
sa circa unlimited resources disposal 
particular suffers problem bounded reactivity monitor react limited number threats concurrently 
overcome problem sa circa adaptive mission planner decomposes extended missions start regions reactive plan competence stable regions entire state space goal fig 

decomposition mission control problem multiple single phase control problems 
multiple mission phases different controller tailored particular needs see fig 

example air mission high low altitude components different controllers 
high altitude phase uav monitor radar guided sam threats low altitude relevant 
low altitudes hand aircraft relatively safe radar guided sams guard shoulder launched ir guided sams 
order deal dynamic situations limited information sa circa able tailor mission phase controllers line 
example process traversing enemy airspace way target agent may informed previously unknown sam site exit path 
agent generate new controller egress phase mission able handle threat 
due bounded resources opportunity dynamic adaptation poses corresponding problem deliberation scheduling :10.1.1.47.4260
sa circa agent determine best allocate limited computational resources improving controllers various mission phases 
example agent improve controller final phase perceived worst allocate resources polishing controller earlier phase knowing final phase 
describes initial deliberation scheduling sa circa architecture 
adaptive mission planner amp circa adaptive mission planner amp responsible highest level control circa agent determining modifying agent responsibilities threats handle mission goals achieve controlling agent reasoning plans construct managing agent deliberation resources best computation time improve mission plan 
specifically amp manages agent responsibilities negotiating agents contract bidding 
controls agent reasoning modifying problem configurations csm invoking halting csm appropriate 
amp manages agent deliberation resources scheduling csm improve certain plans manner yields highest utility mission plan 
working bringing planning activity deliberation controller synthesis module csm real time control adaptive mission planner amp manage control deliberation negotiation process 
amp decomposes problem appropriate phases csm generates safety preserving real time control plans 
planning process performed prior execution continues system executing portions high level plan 
amp csm cooperate effectively allocate planning effort entire high level plan meeting intermediate deadlines imposed execution time constraints 
problem structure team mission divided phases correspond modes time intervals share fundamental set common goals threats dynamics 
example military unmanned aerial vehicle uav scenarios include missions phases ingress attack egress 
ingress phase distinguished attack phase characteristics flight path nap earth stealthy approach vs popup maneuver near target expected threats types missile threats different altitudes goals reaching target zone vs deploying weapon 
agent responsibilities team circa agents arrange different agents take responsibility different goals threats depending available capabilities resources ecm equipment weapons 
goals threats vary phase fact mission typically split phases specifically decompose mission manageable chunks aligned common set threats common goal achieved signals phase 
mission phase circa agents plans controllers custom designed mission execution execute mission phase best possible effort achieve goals defeat threats associated phase 
csm described capable automatically building controllers controller synthesis complex time consuming process 
complexity duration csm process controlled varying problem configuration passed csm describe characteristics desired controller particular mission phase 
problem configuration contains information initial state world goals achieve threats state transitions happen due world actions available agent affect world 
varying details amp planning problem fall complexity spectrum simple infeasible 
predictive deliberation management primary responsibilities amp determine mission phase csm trying build controller moment hard modifying phase problem configurations 
mean amp deliberation management function 
current experiments center allocating effort maintain system safety altering phase potential threats considered long 
phase threats handled improving current plan phase better agent team survival probability phase mission 
problem cast follows set planning phases quality measures current plan phase set tradeoff methods improvement operators applicable phase amount time try improve current plans amp allocate segment time improve expected utility mission plan 
effectively decide deliberation happen amp consider potential deliberation schedule 
example amp consider starting lower priority csm task earlier shorter window opportunity execute task expected execution time longer 
case amp need consider expects leave time execute higher priority task 
see efficient incomplete approaches problem suffer local maxima solutions require type lookahead complex analysis 
second part problem select improvement operators apply phase selected 
assume improvement operator deliberation action takes equal amount time quanta action taken multiple quanta applicable phase 
general action selection interesting decision tradeoffs various operators 
current tradeoff amount expected improvement successful action probability success 
simple mdp model amp current experiments deliberation scheduling markov decision process mdp model deliberation scheduling problem 
posed problem choosing time phase mission plan focus computation plan improvement method 
decision agent mission probabilistic measure quality plan 
current model quality plan measured reward expected achieve distribution potential rewards mission phases fixed 
system improves expected reward reducing likelihood failure eliminates possibility reward attainment 
form formulate circa deliberation scheduling problem follows amp decomposed mission sequence phases bn 
csm direction amp determined initial plan individual state space plans phase bi 
element set possible plans general may possible enumerate set certainly possible efficiently represent set 
see usefully reason classes plans equivalent respect measure quality 
refer pas mission plan 
state system may represented ordered triple time index phase agent currently operating current mission plan bi bi 
abuse notation refer components state operators andp fors simplicity sake assume duration mission phases known mission phases occur sequence 
phase bi exists known start bi bi dur bi 
determine corresponding mission phase phase bi satisfying start bi bi 
amp access plan improvement methods mm 
point time amp choose apply method mj toa phase bi written mj 
application method may yield new plan mission phase bi producing new follows pt 
note application method may fail yielding application method yields new plan lower measured quality original plan generate worse phase plan simply discard keep previous 
specifically circa available methods implemented code generates new problem configuration amp download csm 
csm run fixed amount time planning quantum terminate new state space plan interrupted quantum consumed 
complete formulation utility reward function applying states 
simplify assess agent reward completion mission phase example aircraft completes mission successfully survives receive reward completing final phase 
missions appropriate add reward intermediate phase successful completion corresponds achieving mission goal reconnaissance target 
different phases mission different degrees danger 
represent different probabilities making transition designated failure state 
probability surviving phase function hazards posed phase quality state space plan phase 
accordingly representing plans explicitly system state need vector survival rates 
abuse notation represent plan associated survival probability aspect plan reflected mdp 
chance surviving phase expected reward phase start start 
representation plans survival rates plan improvement operators represented actions may take state survival probability phase higher current state 
considering plan improvement operators increase likelihood achieving reward avoiding failure 
note expected utility take account chance agent destroyed phase 
mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state nil phase quanta left surv probs nil mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state nil phase quanta left surv probs nil mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs mdp state phase quanta left surv probs fig 

simple amp mdp phases quantum phase deliberation action choice phase 
fig 
illustrates simple amp mdp phases quantum phase deliberation action choice phase 
trivial problem forms space states diagram unreadable page 
zoomed area illustrates model works edges labeled leaving uppermost state correspond amp deciding perform deliberation action phase succeed result improvement phase survival probability right edge state 
percent time action expected fail yielding survival probability improvement left edge state time system expected destroyed deliberation quanta rightmost edge leading zoomed area failure node 
simplifying assumptions problem achieving reward transformed surviving complete phases provide reward 
problem choosing deliberation action state limited choosing phase mission plan try improve improvement operator apply improve 
conventional formulation mdp policy arg max action probability reaching agent executes action andu expected utility state pursuing optimal policy 
model deliberation schedule reformulate problem policy bk arg max destroyed bk mj bk corresponds choice phase improved choice deliberation planning operator improve phase 
state representation constrained phase identical possibly phase eliminating constants equation policy arg max mj 
conducted experiments formulation problem directly evaluated value iteration 
common lisp version developed peter norvig stuart russell 
expect performance suffers problem scale experimental results reported section 
accordingly developing heuristic alternatives exact evaluation comparing results optimal policies 
optimal deliberation scheduling agent optimal mdp agent determines optimal decision possible state employing algorithm called value iteration 
basic idea value iteration calculate utility state utilities successor states iterating states policy stabilizes 
optimal mdp agent constructs optimal policy uses repeatedly take action policy accounts possible state agent encounter 
unfortunately value iteration feasible approach mdp model small 
fig 
illustrates quickly number states computation intractable simple mdp representations 
graph show number unique states generated optimal mdp agent mission phases number quanta phase number actions phase allowed vary 
fig 
similarly demonstrates computation time generate optimal policy set states increases exponentially small increases problem size 
note results shown assume optimal mdp agent need generate optimal policy 
world dynamics cause deliberation management problem change dramatically policy states quanta phase actions phase fig 

number states generated simple mdp models 
need recomputed 
occur example discover hitherto unknown threat phases mission 
recomputations multiply computational cost making optimal mdp policy computation expensive initially apparent 
recomputations impose prohibitive cost greedy myopic approach propose 
discuss alternative approach section 
greedy deliberation management agent optimal solution deliberation scheduling problem quickly intractable investigated simpler heuristic mechanism making dynamic deliberation scheduling decisions 
computing policy indicates actions taken possible state maximize expected utility greedy agent looks state ahead immediate action choices selects action results state mission plan highest expected utility 
expected utility computation necessarily incomplete project possible paths greedy agent scalable suboptimal 
time ms quanta phase actions phase fig 

time mdp solver find optimal policy note huge axis scale 
formally say greedy policy expressed terms greedy utility measure policy arg max mj 
conventional utility measure mdp formulation see sect 
take expectation states different plans 
myopic utility function hand ignores planning assumes agent complete rest mission plan 
greedy utility state bi defined follows bi bi destroyed bi phase greedy agent need compute complete policy computes policy lazily determining action choice state queried 
kronecker delta function valued argument meets condition time point phase zero 
time ms quanta phase actions phase fig 

greedy agent runtime performance scales linearly optimal agent exponential 
note small axis scale compared fig 

computation local speed depend size mdp 
fact scales linearly branching factors mdp number quanta phase number alternative operators quantum 
fig 
illustrates runtime difference optimal greedy agents 
time optimal agent called decision computes complete policy simply looks answer resulting hash table 
greedy agent performs policy computation time asked decision state 
price efficiency lack optimality greedy agent making decisions limited lookahead trouble assessing relative merit addressing near term vs far term risks 
example easy construct mdp problems non monotonic reward profiles fool greedy policy focusing attention phases causing opportunities improvement addressed precluding phase improvements 
example illustrated fig 
illustrates simple mdp survival probability distribution dips early mission falls dramatically 
assessing possible actions early time mission simplest greedy policy recognize potential large important gains survival probability phase choose improve phase 
optimal policy phase survival probability phase fig 

non monotonic initial survival probability distribution simple greedy heuristic 
hand recognize plenty time mission improve phase nearer term dip survival probability addressed quickly effect 
scenario expected utility optimal policy computed mdp approximately expected utility greedy agent utility normalized zero range 
minimize greedy agent susceptibility effect apply discounting factor improvements 
discount factor captures fact opportunities perform plan improvements mission phases farther 
assuming discounting factor discounted myopic utility estimate follows bi bi destroyed bi phase addition discounting factor adds minimally cost computing greedy action selection improves performance agent considerably 
scenario time discounted optimal agent greedy agent discount greedy agent expected utility experiment fig 

results experiments comparing optimal greedy time discounted greedy agents 
greedy agent performance optimal agent 
conducted number experiments randomly generated domains mission phases initial plans survival probabilities phase drawn uniform distribution ranging 
plot results fig 

time discounted greedy agent performed better simple greedy agent experiments 
average loss optimal policy average loss simple greedy agent 
related anytime algorithms best knowledge term deliberation scheduling introduced boddy dean 
great deal area early boddy dean horvitz russell wefald :10.1.1.52.1027
researchers investigated methods decision theory address problem managing computation bounded resources 
boddy dean categorize deliberation scheduling sorts discrete anytime 
discrete case agent choose procedures run procedures assumed run times fixed 
anytime case procedures assumed continuously interruptible anytime agent choose procedure run long 
boddy dean horvitz analyses prescriptions directly applicable circa deliberation scheduling problem particularly designed controlling inference suites anytime algorithms 
circa state space planner suited treatment anytime algorithm result relatively continuous smooth improvement plans time 
csm acts batch mode computation particular problem configuration general returning successful plan controller failure amount time 
rational metareasoning closely fits model proposed russell wefald concerned discrete units computation anytime algorithms :10.1.1.52.1027
russell wefald provide framework call rational metareasoning framework centers notion agent continually trading performing atomic computation executing real action affect environment 
framework evaluating computation treat having effects utility 
causes time pass incur opportunity cost 
specifically cause agent postpone real action duration computational step 
second computation effect real actions chosen agent 
possible outcomes computation 
simpler may change agent believes best available action 
difficult analyze second case computation cause change action choice adds information agent state 
additional information turn cause computation change action choice 
call indirect utility computation 
fits framework analyzing benefits atomic computation actions 
differs important ways 
draw structure circa domains specific survival oriented utility function relatively easy compute 
second simplified problem involve indirect utility computation discussed 
current model quantum computation provide direct utility form new state space plan particular phase produce 
third difference faced problem trading deliberation versus action 
circa designed act hard real time environments circa execution engine real time subsystem designed execute parallel ai subsystem compete computational resources 
circa deliberation scheduling involves tradeoffs alternative planning activities planning action 
simplifications mean trivial estimate value single quantum computation model 
simplifications impose cost performance agents 
particular possible agents gain benefit computation takes single quantum time 
aimed relaxing restriction 
relaxation correspond allowing amp resume continue controller synthesis tasks started prior deliberation quantum 
design criteria closely related stream research includes design time dtt design criteria dtc efforts consider agent deliberation scheduling context task models 
task models capture characteristics amp problem alternative atomic deliberation actions success probabilities include complex aspects task decomposition interdependencies resource constraints 
dtt dtc techniques heuristics build satisficing schedules full sequence activities contrast current approach amp deliberation scheduling problem emphasized bounded time methods return single decision deliberation action take 
principle model problem compare current dtc system myopic heuristics 
software available compatible may prove profitable avenue investigation 
concentrate attention amp management controller synthesis module deliberation 
general plan endow amp broad power responsibility requiring extensive sophisticated reasoning capabilities intelligently consider aspects realistic problem domains 
examples plan expand set techniques adjust csm problem complexity explicitly bringing goals control enable agents negotiate intelligently load burdens agents allow amp add remove control actions set available agent example plan feasible force plan efficient 
scope deliberation management plan incorporate richer set problem configuration modification operators varying characteristics 
example time horizons cases amp simplify csm planning problem exploiting observation resulting plan needs guarantee safety bounded time period horizon 
example amp knows default plan switch certain length time spent current plan csm need plan states possibly reached horizon 
call horizon amp guarantee swap new plan horizon action transition new plan definitely taken time bound 
horizon imposing time horizon csm planning compromise safety improvement optimization tradeoff 
case tradeoff likelihood finding agent unhandled state horizon 
timing modifications temporal transitions circa traditionally considered worst case time temporal transitions move world state state 
overconstrained domains assumption lead csm conclude safe plan 
situations likelihood temporally transitioning earliest possible time low tradeoff modify lengthen case temporal transition time 
course transition occurs outside modified interval safety guaranteed 
minimal regions competence problem configuration amp specify goal achieving wants csm generates plan 
csm faced decisions action choose state choose actions increase probability goal achievement prefer bend back state generated handled 
preference decreases complexity planning problem minimizing set states csm plan 
general safety compromised method goal achievement 
systematic search feasible problem amp know csm returns feasible controller return controller acceptable amount time 
solution amp heuristically decide simplify problem configuration systematic way essentially searching highest utility problem configuration csm find feasible plan 
acknowledgments material supported darpa ito air force research laboratory contract 

opinions findings recommendations expressed material authors necessarily reflect views darpa government air force research laboratory 
mark boddy guiding gently literature deliberation scheduling 
entirely fault 
steven harp advice experimental design statistical hypothesis testing 
peter norvig stuart russell implementation value iteration book artificial intelligence modern approach 
boddy dean decision theoretic deliberation scheduling problem solving time constrained environments artificial intelligence 
garvey lesser design time real time scheduling ieee transactions systems man cybernetics vol 
pp 

horvitz cooper heckerman reflection action scarce resources theoretical principles empirical study proceedings th international joint conference artificial intelligence pp 

morgan kaufmann publishers 
horvitz reasoning varying uncertain resource constraints proceedings seventh national conference artificial intelligence pp 
los altos ca morgan kaufmann publishers musliner imposing real time constraints self adaptive controller synthesis lecture notes computer science number springer verlag 
musliner durfee shin circa cooperative intelligent real time control architecture ieee transactions systems man cybernetics vol 
pp 

musliner durfee shin world modeling dynamic construction real time control plans artificial intelligence vol 
pp 
march 
musliner goldman andk sa circa self adaptive software hard real time environments ieee intelligent systems vol 
pp 
july august 
russell norvig artificial intelligence modern approach prentice hall 
russell wefald principles metareasoning international conference principles knowledge representation reasoning pp :10.1.1.52.1027

morgan kaufmann publishers 
wagner garvey lesser criteria directed task scheduling international journal approximate reasoning vol 
pp 

