active learning support vector machines greg gcs justresearch com david cohn cohn justresearch com just research henry street pittsburgh pa usa describe simple active learning heuristic greatly enhances generalization behavior support vector machines svms practical document classification tasks 
observe number benefits surprising svm trained subset available corpus frequently performs better trained available data 
heuristic choosing subset simple compute information test set 
training time svms depends heavily training set size heuristic offers better performance fewer data frequently time naive approach training available data 

uses document classifier sorting mail mailboxes filtering spam routing news articles 
evidence maximizing margin acts form structural risk minimization vapnik 
limit position optimal hyperplane 
support vectors 
special meaning bound examples examples incorrectly classified margin hyperplane 
support vector machines demonstrated excellent performance domains particularly involving text classification joachims dumais :10.1.1.11.6124
advances joachims platt sped optimization problem practical solve support vector problems involving tens thousands documents reasonable amount time :10.1.1.11.6124
complexity finding optimal hyperplane support vectors involves form quadratic programming np complete worst case typical running times training set 
superlinear time dependence number training examples cost obtaining labels examples place reasonable try minimize number labeled examples needed achieve performance 

limit position optimal hyperplane 
support vectors 
special meaning bound examples examples incorrectly classified margin hyperplane 
support vector machines demonstrated excellent performance domains particularly involving text classification joachims dumais :10.1.1.11.6124
advances joachims platt sped optimization problem practical solve support vector problems involving tens thousands documents reasonable amount time :10.1.1.11.6124
complexity finding optimal hyperplane support vectors involves form quadratic programming np complete worst case typical running times training set 
superlinear time dependence number training examples cost obtaining labels examples place reasonable try minimize number labeled examples needed achieve performance 

active learning support vector machines size learners traditionally attempt minimize error data 
document classification vector space model successful approaches document classification vector space model ignores word location context treats document unordered bag words space model dimension word corpus vocabulary coordinate example dimension number times corresponding word appears document 
frequently list stopwords common non content bearing words removed 
vector space model lead domain see baum lang example applying divide conquer identify hyperplanes active learning setting 
dimensions making traditional machine learning approaches infeasible 
model shown naive bayes classifiers nigam svms joachims :10.1.1.11.6124:10.1.1.14.1043
experimental setup ran experiments text domains binary classification newsgroup pairs newsgroups data set nigam topic classification subset topics reuters news articles lewis :10.1.1.14.1043
document normalized document length weighting tfidf performed vectors 
accuracy iteration iteration iteration iteration training set size iteration 
effect sample granularity active learning earn reuters group 
frequently list stopwords common non content bearing words removed 
vector space model lead domain see baum lang example applying divide conquer identify hyperplanes active learning setting 
dimensions making traditional machine learning approaches infeasible 
model shown naive bayes classifiers nigam svms joachims :10.1.1.11.6124:10.1.1.14.1043
experimental setup ran experiments text domains binary classification newsgroup pairs newsgroups data set nigam topic classification subset topics reuters news articles lewis :10.1.1.14.1043
document normalized document length weighting tfidf performed vectors 
accuracy iteration iteration iteration iteration training set size iteration 
effect sample granularity active learning earn reuters group 
large initial difference little asymptotic effect number training examples added iteration 
instance earn group reuters experiments reaches accuracy active learner attains accuracy entire set bound support vector removal 
bound support vector removal helps shown systematic improvement traditional classifiers active learning consistently outperformed soft margin classifiers built examples 
active learning heuristic describe reach misclassified examples cutoff may better heuristic remove noise 
relation previous svm solvers reduce size original problem disregarding dormant examples training set 
chunking boser shrinking joachims heuristics reduce size training set :10.1.1.11.6124
chunking solves sub problems iteratively building set examples violate optimality 
shrinking may viewed chunking reverse temporarily removes examples training set support vectors trains model adds examples final optimization 
active learner begins small training set iteratively increases size computational performance parallels chunking active learner attempts minimize number labels non support vectors affect improving model active learning may thought priori shrinking examples included labeled training set support vectors 
important forget key distinction chunking shrinking disregard labeled examples support vectors purely computational gain 
