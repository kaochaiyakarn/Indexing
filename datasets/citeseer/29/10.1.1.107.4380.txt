automated state abstraction options tree algorithm anders jonsson andrew barto department computer science university massachusetts amherst ma barto cs umass edu learning complex task significantly facilitated defining hierarchy subtasks 
agent learn choose various temporally actions solving assigned subtask accomplish task 
study hierarchical learning framework options 
argue take full advantage hierarchical structure perform option specific state abstraction scale larger tasks state abstraction automated 
adapt mccallum tree algorithm automatically build option specific representations state feature space illustrate resulting algorithm simple hierarchical task 
results suggest automated option specific state abstraction attractive approach making hierarchical learning systems effective 
study hierarchical learning framework options 
argue take full advantage hierarchical structure perform option specific state abstraction scale larger tasks state abstraction automated 
adapt mccallum tree algorithm automatically build option specific representations state feature space illustrate resulting algorithm simple hierarchical task 
results suggest automated option specific state abstraction attractive approach making hierarchical learning systems effective 
researchers field reinforcement learning focused considerable attention temporally actions :10.1.1.187.8212:10.1.1.37.2027:10.1.1.32.8206:10.1.1.25.1865
term temporally describes actions take variable amounts time 
motivation temporally actions exploit hierarchical structure problem 
things hierarchical structure natural way incorporate prior knowledge learning system allowing reuse temporally actions policies learned tasks 
learning hierarchy significantly reduce number situations learning agent needs discriminate 
update occurs action executed non zero probability executed 
similarly base distinctions tree associated option transition instances recorded execution option 
adding instances recorded execution option history associated option 
associating instance vector leaves tree option approach require additional memory keeping multiple copies instance 
scheme introduce vector rewards rt ro instance ro discounted sum local rewards option associated ot experiments tested version tree algorithm taxi task agent taxi moves grid :10.1.1.32.8206
taxi assigned task delivering passengers locations destination chosen random set pick drop sites taxi agent observation vector composed position taxi location current passenger passenger destination actions available taxi pick drop passenger delivered new passenger appears random pickup site 
rewards provided taxi delivering passenger aid taxi agent introduced navigate options letting denote set observation vectors gp location action including moving walls policy getting agent trying learn 
cardinal directions 
introduced local reward identical global reward provided agent exception reaching application tree algorithm taxi problem history option maximum length instances 
acknowledgments authors tom dietterich providing code taxi task andrew mccallum valuable correspondence regarding tree algorithm ted perkins reading providing helpful comments 
funded national science foundation 
ecs 
opinions findings recommendations expressed material authors necessarily reflect views national science foundation 
dietterich :10.1.1.32.8206

hierarchical reinforcement learning maxq value function decomposition 
artificial intelligence research 
dietterich 
