artificial intelligence review 
kluwer academic publishers 
printed netherlands 
perspective view survey meta learning ricardo youssef ibm watson research center saw mill river rd hawthorne ny usa mail ibm com ibm com 
different researchers hold different views term meta learning exactly means 
part provides perspective view goal build self adaptive learners learning algorithms improve bias dynamically experience accumulating meta knowledge 
second part provides survey meta learning reported machine learning literature 
find despite different views research lines question remains constant exploit knowledge learning meta knowledge improve performance learning algorithms 
clearly answer question key advancement field continues subject intensive research 
keywords classification inductive learning meta knowledge 
meta learning studies learning systems increase efficiency experience goal understand learning flexible domain task study 
learning systems adapting specific environment reduces imposing partial ordering bias set possible hypotheses explaining concept mitchell 
meta learning differs base learning scope level adaptation meta learning studies choose right bias dynamically opposed base learning bias fixed priori user parameterized 
typical inductive learning scenario applying decision tree neural network support vector machine data produces hypothesis depends fixed bias embedded learner 
learning takes place base level quality hypothesis normally improves increasing number examples 
successive applications learner data produces hypothesis independently performance knowledge extracted domains tasks pratt thrun 
meta learning aims discovering ways dynamically search best learning strategy number tasks increases thrun 

computer program qualifies learning machine ricardo youssef performance improves experience mitchell cohen feigenbaum 
experience best understood knowledge gained analysis tasks definition limited ability refine hypothesis presenting examples belong task 
meta learning advocates need continuous adaptation learner different levels abstraction 
base learner fails perform efficiently expect learning mechanism adapt case task 
learning take place example base level task meta level 
describing perspective view meta learning posing interesting challenges research provides survey field reported machine learning literature 
areas study bear close relationship meta learning include building meta learner base learners section selecting inductive bias dynamically section building meta rules matching task properties algorithm performance section inductive transfer learning learn section learning classifier systems section section 
survey shows term meta learning means differently different research groups find areas mentioned covers pieces big puzzle conformed field meta learning 
ultimate goal see field progressing uniform coherent view 
organized follows 
section gives definitions background information classification 
section provides perspective view nature potential avenues research meta learning detailed analysis section provided 
section survey meta learning reported machine learning literature 
section ends discussion 

preliminaries study centered classification problem exclusively 
problem learn assign correct class set different objects events situations 
learning algorithm trained set pre classified examples xi ci object characterized features vector dimensional feature space xn 
feature xk take different number values 
xi labeled class ci unknown target function xi ci 
classification ci takes fixed number categorical values 
consist independently identically distributed examples obtained fixed unknown joint probability survey meta learning distribution space possible feature vectors classes known input output space 
goal classification produce hypothesis best approximates minimizes loss function input output space distribution 
classification begins learning algorithm receives input training set conducts search hypothesis space hl finds hypothesis hl approximates true function learning algorithm maps training set hypothesis hl space training sets size selected hypothesis guess class unseen examples 
learning algorithm embeds set assumptions bias affects learning process ways restricts size hypothesis space hl imposes ordering ranking hypotheses hl 
bias learning algorithm la stronger bias learning algorithm lb size hypothesis space considered la smaller size hypothesis space considered lb hla 
case bias embedded la conveys extra evidential information watanabe bias lb enables narrow number candidate hypotheses estimating true target concept say bias learning algorithm correct target concept contained hypothesis space hl 
incorrect bias precludes finding perfect estimate target concept 
perspective view meta learning section lay definitions concepts helpful compare current research directions adopted metalearning 
view field advocates construction self adaptive learners 
base learning hypothesis space hl learning algorithm fixed 
applying learning algorithm decision tree neural network support vector machine data produces hypothesis depends fixed bias embedded learner 
represent space possible learning tasks algorithm learn efficiently limited region rl favors bias embedded algorithm learn efficiently tasks long bias remains fixed schaffer watanabe wolpert rao 

may rightly argue space tasks contains random regions failing learn regions carries fact negative consequences 
reason assume rl belongs subset structured tasks task non random ricardo youssef 
learning algorithm covers region structured tasks favored bias 
task best learned algorithm la best learned lb best learned la lb 
lies outside scope la lb 
ascribed low degree kolmogorov complexity li vitanyi 
assumption left unspecified simply want distinguish sets tasks structured random 

goals meta learning goal meta learning learn causes dominate region rl 
problem decomposed parts determine properties suitable region determine properties components contained algorithm interact contribute dominate rl 
solution problem provide guidelines choosing right learning algorithm particular task 
illustrated task ti may lie inside outside region favors bias embedded learning algorithm task best learned algorithm la lies region rla similarly best learned algorithm lb best learned la lb 
solution meta learning problem indicate match learning algorithms task properties way yielding principled approach dynamic selection learning algorithms 
addition meta learning solve problem learning tasks lying outside scope available learning algorithms 
shown task lies outside regions la lb 
lb available algorithms hand task prone receiving poor concept estimation 
approach solve problem meta learner survey meta learning combine predictions base learners order shift dominant region task study 
goal embed meta learner bias favoring region tasks includes 
section describes current research heading direction 
combination base learners meta learner offers guarantee covering possible structured task interest 
claim potential avenue research meta learning provide foundations construct self adaptive learning algorithms learning algorithms change internal mechanism task analysis 
mean enabling learning algorithm move space structured concepts algorithm learns cover task study 
assume achieved continuous accumulation meta knowledge indicating appropriate form bias different task 
experience learning algorithm initially fixed form bias approximate target concept 
tasks observed algorithm able accumulated meta knowledge change bias characteristics task 
kind life long learning thrun 
hypothetical flow diagram self adaptive learner 
input output components system training set hypothesis respectively 
time hypothesis produced performance assessment component evaluates quality 
resulting information new entry performance table entry contains vector meta features characterizing training set bias employed algorithm quality hypothesis exceeded acceptable threshold 
assume self adaptive learner contains meta learner takes input performance table generates set rules experience meta hypothesis mapping training set form bias 
lack rules experience learner life force mechanism fixed form bias 
training sets observed expect expertise meta learner dominate deciding form bias best suits characteristics training set 

self adaptive learning algorithms self adaptive learner described poses major challenges meta learning community detailed analysis challenges provided 
briefly need define assess quality hypothesis assess quality bias employed learning algorithm 
need define characterize domain terms relevant meta features 
aware problem related flexibility self adaptive learner ricardo youssef 
flow diagram self adaptive learner 
bias selected dynamically meta learner employs fixed form bias 
clearly meta learner seen learning algorithm lacking adaptability ascribed base learner 
ideally meta learner self adaptive improve experience 
solution continue logical fashion define meta meta learner helping meta learner improve experience 
problem disappear meta meta learner exhibit fixed form bias 
challenge lies apparently infinite chain needed achieve complete flexibility selection bias 
problems just described provide interesting goals hope stimulate research community contribute field metalearning 

survey meta learning section provides survey meta learning reported machinelearning literature 
survey kind prone omit relevant adopt single minded view offer apologies 
goal simply unify current views definitions meant term meta learning 

meta learner base learners originally proposed wolpert common approach metalearning known stacked generalization 
set base learners applied training set xi ci produce hypotheses hj called level generalizers 
meta learning takes place training set survey meta learning redefined new set train redefinition replaces vector xi class predicted hypothesis xi train ci xi xi hq xi ci new training set train serves input set meta learners produce new set hypotheses level generalizers 
redefinition train done fold cross validation kohavi 
stacked generalization considered form meta learning transformation training set conveys information predictions base learners conveys meta knowledge 
ignore techniques idea produce variations data bagging breiman boosting freund schapire definitions relevant meta features obtained 
stacked generalization severe limitation base learners meta learners fixed form bias dynamic selection bias takes place 
dominant task region meta learner may different base learners ultimately fixed section 
research stacked generalization paradigm investigates meta learners produce best empirical results chan stolfo chan stolfo chan 
transforming original training set example contains predictions may contain original features 
results show certain combinations learners meta learners yield significant improvements accuracy 
variations stacked generalization explored 
example chan stolfo experiment modified approach base learner trained fraction total data 
running learning algorithm parallel hierarchical tree structure built leaf level generalizer internal node high level generalizer see details 
strategy outperformed approach 
similar vein prodromidis stolfo build tree generalizers meta data prune tree eliminate redundant generalizers 
idea studied distributed system prodromidis 
prodromidis stolfo 
todorovski dzeroski introduce meta decision trees leaf comprises hypothesis prediction 
domingos shows empirical evidence supporting claim meta learner improve accuracy base learners retaining comprehensibility 
study combine predictions base learners produced novel meta features meta features useful understand predict accuracy meta learner 
example fan 
introduce ricardo youssef conflict measure indicates proportion examples training set accurately classified base learners 
meta features include coverage brodley lane fraction examples base classifiers produces correct predictions diversity brodley lane ali pazzani degree difference predictions base learners correlated error ali pazzani fraction examples base learners incorrect prediction 

dynamic selection bias dynamic selection bias enables learning algorithm shift region expertise set structured tasks 
goal modify hypothesis space better coverage task analysis 
meta learning necessary component dynamic bias selection acting guideline search bias space 
field dynamic bias selection desjardins gordon 
authors develop framework study dynamic bias search different tiers desjardins gordon 
tier refers search hypothesis space hl learning algorithm looks best hypothesis approximating target concept learning algorithms assume space fixed 
dynamic bias selection take place learning algorithm search second tier strength size hl modified separately section 
third tier helps modify meta spaces defined second tier 
tiers introduced framework problem building tiers meta meta spaces evident section 
approach dynamic selection bias change representation feature space adding removing features 
earliest systems form dynamic bias utgoff 
goal generating hypothesis space strong correct section continually exerts form change representation 
example system able construct new feature disjunction original features additional features increase size hypothesis space help alleviate problem strong hypothesis space having available hypotheses 
contrast gordon shows weaken hypothesis space eliminating features bias deemed inappropriate 
bias stronger eliminating features weaker restoring features gordon 
addition filter hypotheses meta rules form explicit bias selection gordon perlis 
describes framework dynamic selection survey meta learning bias case meta learning system concepts displaying similarity target concept retrieved memory define hypothesis space 
dynamic bias selection applies algorithm selection problem 
rendell 
describe system learns select learning algorithm depending properties task 
uses dynamic similarity measure evolves experience tasks attempted learns relationships task characteristics biases embedded learning algorithms rendell 

domain characteristics simple number features bias modified depends available learning algorithms 
related approach described rule system 
predicting class new examples depends quality rule quality updated testing phase dynamic process changes bias rule selection policy 

meta rules matching domains algorithm performance important facet meta learning provide guidelines relate learning algorithm domains algorithm performs 
main performance criterion predictive accuracy reality criteria may equally important computational complexity expressiveness compactness comprehensibility prior knowledge encoding 
giraud 
general approach consists defining set domain characteristics meta features relevant performance learning algorithm meta features enable build meta domain relating domain characteristics algorithm performance sufficient number domains analyzed 
induce set rules meta learner discover conditions learning algorithm outperforms 
framework aha aims obtaining rules specifying learning algorithm outperforms significantly 
examples domain characteristics degree correlation features target concept distribution examples concepts disjuncts distribution examples concepts rules reveal conditions significant differences performance hold 
gama brazdil extract domain characteristics number examples number attributes number classes standard deviation ratio feature skewness kurtosis noise signal ratio generate metarule models 
similar reported brazdil proposes meta learning pre processing step model selection experimentation ricardo youssef accuracy performance select best algorithm 
meta rules matching domain characteristics inductive bias crafted manually brodley brodley 
addition domain may represented properties final hypothesis data 
example 
measure properties decision tree nodes feature maximum tree depth shape tree imbalance convert meta features 

finding regions feature space meta feature space meta learning select learning algorithm particular domain granular approach consists selecting learning algorithm individual test example 
idea choose learning algorithm displaying best performance neighborhood test example merz merz 
algorithm selection done performance cross history 
slight variation approach look neighborhood test example space meta features 
specifically learning domains construct meta domain element pair description domain meta feature vector class label corresponding best performance learning algorithm domain 
assume arrival new domain gathering nearest neighbor examples simply select learning algorithm best averaged performance keller 

meta features accuracy storage space running time performance evaluation keller 

similar approach defined brazdil soares learning algorithms corresponding nearest neighbor domains ranked function accuracy running time 

landmarking piece meta learning called landmarking 
idea sets learning algorithms 
set composed simple learners exhibit significant differences mechanism 
accuracy error rate characterize domain refer 
second set contains advanced learners selected current domain 
meta domain constructed follows 
example domain characterized error rates 
label class example algorithm best accuracy 
meta learner associate performance best algorithm 
point view meta learning process finding areas expertise learners called correlating areas performance survey meta learning advanced learners giraud carrier pfahringer 


inductive transfer learning learn learning isolated task starts scratch time new problem domain appears 
experience accumulates learning mechanism expected perform increasingly better section 
learning improve time knowledge learning meta knowledge transferred domains tasks 
process known inductive transfer pratt thrun 
interesting study inductive transfer falls realm neural networks 
review neural networks learn related tasks provided pratt jennings 
caruana shows multitask learning works context neural networks backpropagation 
claim training domains parallel single neural network induces information accumulates training signals new domain benefit past experience 
thrun sullivan propose learning algorithm domains clustered mutually related 
new domain assigned related cluster inductive transfer takes place generalization exploits information selected cluster 
multitask learning learning paradigms kernel regression decision trees 
benefits learning multiple tasks improve generalization provided thrun pratt 
authors propose general framework shows distinction learning baselevel meta level 
base level simply tries find correct hypothesis fixed hypothesis space hl 
meta level needs find properties target functions characterize entire hypothesis spaces 
clear levels require form bias free lunch theorems schaffer watanabe wolpert rao 
apply levels 

learning learn learning learn relies main assumption learning simplified continues working life long context thrun 
assumption supported existence patterns domain domains 
general understanding nature patterns domains invariant transformations 
example image recognition target object simplified object invariant rotation translation scaling learning learn studies improve learning detecting extracting exploiting invariant transformations ricardo youssef domains 
example thrun mitchell describe search certain forms invariance life long learning neural network 
kinds invariance bias learner selects hypothesis new domain 

theoretical studies theoretical analysis learning learn paradigm empirical bayesian view baxter probably approximately correct valiant pac view 
focus pac view baxter 
case learner assumed embedded environment related learning domains 
meta learning takes place learner looking right hypothesis hypothesis space hl addition searching right hypothesis space family hypothesis spaces 
right hypothesis space hl large embed solution problem domain small form generalization possible 
study draws analogy role vc dimension blumer 
size family hypothesis spaces 
turns measures derive bounds number domains number examples domain required ensure high probability find solution having low error new training domains 
certain assumptions number examples required domain decreases number observed domains increases 

learning classifier systems learning classifier systems originated pioneer holland holland holland reitman 
excellent review subject 

classifier system parallel message passing rule system 
message rule referred context classifier condition action pair message matches condition part rule candidate activate execute action part 
system assumes input interface set detectors translates signals external environment messages 
similarly output interface translates messages effectors external actions booker 

classifier system learning mechanism working different levels 
level system learns identify rules return high profit environment 
problem assign credit right rules known credit assignment problem solved form reinforcement learning sutton barto bucket brigade profit sharing plan learning 
mechanism assigns credit value survey meta learning strength rule contribution 
second level system learns construct new rules potential increasing reward environment 
normally set genetic operators come play evolving rule set 
rules high strength higher probability selected produce new offspring rules holland 

classifier systems may appear glance disconnected metalearning 
closer examination reveals opposite 
example learning algorithm set components specific function classification select relevant features partition training set separate conquer approach divide conquer approach hypothesis pruning 
domain activating components may give higher reward higher predictive accuracy 
framework adopted learning classifier systems meta learning mapping classifiers rules learning components 
form reinforcement learning decide learning strategy combination learning components maximizes learner performance 
addition discovery system may try find new components produce efficient learning algorithms 
idea sheds light research direction build self adaptive learners assessment hypothesis successful performance combination learning components meta learner meta knowledge build new learning algorithms 

approaches outside scope classification meta learning applied areas case reasoning constraint satisfaction learning agents survey briefly mentioning related areas 
context cased reasoning goel describes casebased interactive system problem solving 
system displays ability reason performance keeping track problem solved keeping track meta cases 
result system able provide explanations reasoning justifications solutions 
meta learning analytic learning problems minton 
analytic learning explanation learning derivational analogy exploits problem solving experience minton 
applied meta learning level idea meta level theories help system reason problem solver baselevel theory 
meta level analysis appropriate base level theory intractable minton 
ricardo youssef meta learning applied areas learning agents 
baum provides extensive study discussion agents collaborate kind reinforcement learning 
system embeds learning agents generate agents 
approaches include meta level information problem solving knowledge cooperation multi agent system prasad lesser 

discussion survey shows term meta learning ascribed different meanings different research groups 
building meta learners base classifiers section looking dynamic forms bias section studying learning continue life long environment section meta learning continues enrich field machine learning constant question exploit knowledge learning metaknowledge improve performance learning algorithms 
spite research directions clear answer emerged 
broadening view scope meta learning provide better insights meta knowledge 
example approach adopted stacked generalization section assumes fundamental distinction learning base level meta level 
transforming training set including predictions base learners form re learning tools different levels abstraction 
idea making fundamental differences learning meta learning shared researchers schmidhuber 
meta learning may radically different learning base level 
example define meta learning problem right action right bias specific world state type input output distribution 
definition allows equate meta learning form reinforcement learning ring 
definition points mechanism learning classifier systems section 
consider meta learning fundamental structure base learning important goal machine learning combine ability learning algorithm improve performance number examples increases ability learning algorithm improve learning bias number tasks increases 
achieve goal believe field meta learning benefit greatly study learning algorithms improve performance experience meta knowledge section 
survey meta learning supported ibm watson research center 
note learning task tuple comprising target concept training set size sample distribution examples training set drawn 
aha david 

generalizing case studies case study 
proceedings ninth international workshop machine learning 
morgan kaufman 
ali kamal pazzani michael 

error reduction learning model descriptions 
machine learning 
jacky 
case meta learning sustained learning supported dynamically biased version space 
proceedings machine learning workshop biases inductive learning 
baum eric 

manifesto evolutionary economics intelligence 
neural networks machine learning 
editor bishop springer verlag 
baxter jonathan 
theoretical models learning learn 
learning learn 
kluwer academic publishers ma 
baxter jonathan 
model inductive learning bias 
journal artificial intelligence research 
giraud carrier christophe 
casa landmarking expertise space 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
giraud carrier christophe kennedy 

high order approach meta learning 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
blumer ehrenfeucht warmuth 

learnability vapnik chervonenkis dimension 
journal acm 
booker goldberg holland 

classifier systems genetic algorithms 
artificial intelligence 
brazdil pavel 

data transformation model selection experimentation meta learning 
proceedings ecml workshop upgrading learning meta level model selection data transformation 
technical university chemnitz 
brazdil pavel soares carlos 
ranking classification algorithms relevant performance information 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
breiman 
bagging predictors 
machine learning 
ricardo youssef brodley carla 
addressing selective superiority problem automatic algorithm model class selection 
proceedings tenth international conference machine learning 
san mateo ca morgan kaufman 
brodley carla 
recursive automatic bias selection classifier construction 
machine learning 
brodley carla lane 

creating exploiting coverage diversity 
proceedings aaai workshop integrating multiple learned models 
portland oregon 
ivan 
feedback loop refining rule qualities classifier strategy 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
caruana rich 
multitask learning 
second special issue inductive transfer 
machine learning 
caruana rich 
multitask learning 
chan philip stolfo 

accuracy meta learning scalable data mining 
kerschberg 
ed 
journal intelligent integration information 
chan philip stolfo 

experiments multistrategy learning meta learning 
proceedings international conference information knowledge management 
chan philip 

extensible meta learning approach scalable accurate inductive learning 
phd thesis graduate school arts sciences columbia university 
cohen paul feigenbaum edward 
learning inductive inference 
handbook artificial intelligence volume iii 
addison wesley 
desjardins marie gordon diana 

special issue bias evaluation selection 
machine learning 
desjardins marie gordon diana 

evaluation selection biases machine learning 
machine learning 
domingos pedro 
knowledge acquisition examples multiple models 
proceedings fourteenth international conference machine learning 
morgan kaufmann nashville tn 
domingos pedro 
knowledge discovery multiple models 
intelligent data analysis 
fan wei stolfo chan philip 

conflicts multiple base classifiers measure performance stacking 
giraud carrier christophe pfahringer bernhard eds 
proceedings icml workshop advances meta learning 
stefan institute publisher ljubljana 
freund schapire 

experiments new boosting algorithm 
proceedings thirteenth international conference machine learning 
morgan kaufman bari italy 
gama brazdil 

characterization classification algorithms 
proceedings seventh portuguese conference artificial intelligence 
madeira island portugal 
giraud carrier christophe 
predictive accuracy 
proceedings ecml workshop upgrading learning meta level model selection data transformation 
technical university chemnitz 
survey meta learning goel ashok 

meta cases explaining case reasoning 
proceedings third european workshop case reasoning 
published advances case reasoning lecture notes computer science 
springer new york 
gordon diana perlis donald 
explicitly biased generalization 
computational intelligence 
gordon diana 

queries bias testing 
proceedings workshop change representation problem reformulation 
gordon diana 

active bias adjustment incremental supervised concept learning 
phd thesis university maryland 
holland john booker colombetti marco dorigo marco goldberg david forrest stephanie riolo rick smith robert pier luca wolfgang wilson stewart 
learning classifier system 
lecture notes artificial intelligence lnai 
springer verlag 
holland john 
adaptation natural artificial systems 
university michigan press ann arbor republished mit press 
holland john reitman 

cognitive systems adaptive algorithms 
waterman hayes roth 
eds 
pattern directed inference systems 
newyork academic press springer verlag 
keller jorg paterson iain 
integrated concept multi ranking data mining algorithms 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
kohavi ron 
study cross validation bootstrap accuracy estimation model selection 
proceedings fourteenth international joint conference artificial intelligence 
pier luca wolfgang wilson stewart 

learning classifier systems foundations applications 
lecture notes artificial intelligence 
springer verlag new york 
li ming vitanyi paul 
kolmogorov complexity applications 
springer verlag new york 
merz christopher 

dynamic learning bias selection 
preliminary papers fifth international workshop artificial intelligence statistics 
florida 
merz christopher 

dynamical selection learning algorithms 
fisher lenz 
eds 
learning data artificial intelligence statistics 
springer verlag 
michie spiegelhalter taylor 

machine learning neural statistical classification 
ellis horwood chichester england 
minton steve 
analytic learning system specialized heuristics 
proceedings thirteenth international joint conference artificial intelligence 
minton steve 
explanation learning problem solving perspective 
artificial intelligence 
mitchell tom 
need biases learning generalizations 
technical report cbm tr 
computer science department rutgers university new brunswick nj 
mitchell tom 
machine learning 
ed 
hill 
bernhard giraud carrier christophe 
meta learning landmarking various learning algorithms 
proceedings seventeenth international conference machine learning 
stanford ca 
ricardo youssef prasad lesser victor 

meta level information learning situation specific coordination 
proceedings fifteenth international joint conference artificial intelligence 
nagoya japan 
pratt thrun sebastian 
second special issue inductive transfer 
machine learning 
pratt sebastian jennings barbara 
survey connectionist network reuse transfer 
learning learn 
kluwer academic publishers ma 
prodromidis andreas chan philip stolfo 

meta learning distributed data mining systems issues approaches 
kargupta chan eds 
advances distributed data mining 
book aaai press 
prodromidis andreas stolfo 

comparative evaluation meta learning strategies large distributed data sets 
giraud carrier christophe pfahringer bernhard eds 
proceedings icml workshop advances meta learning 
stefan institute publisher ljubljana 
prodromidis andreas stolfo 

minimal cost complexity pruning meta classifiers 
proceedings aaai extended 
rao gordon spears 

generalization action really equal opposite reaction 
analysis conservation law generalization performance 
proceedings twelfth international conference machine learning 
morgan kaufman 
rendell larry raj david 
robust concept learning dynamically variable bias 
proceedings fourth international workshop machine learning 
morgan kaufman 
rendell larry raj david 
layered concept learning dynamically variable bias management 
proceedings international joint conference artificial intelligence 
milan italy 
ring mark 

child step continual learning 
learning learn 
kluwer academic publishers ma 
schaffer 

conservation law generalization performance 
proceedings eleventh international conference machine learning 
san francisco morgan kaufman 
schmidhuber jurgen 
discovering solutions low kolmogorov complexity high generalization capability 
proceedings twelve international conference machine learning 
morgan kaufman 
sutton richard barto andrew 
reinforcement learning 
mit press cambridge massachusetts 
thrun sebastian mitchell tom 
learning thing 
proceedings international joint conference artificial intelligence 
morgan kaufman 
thrun sebastian pratt 
learning learn overview 
learning learn 
kluwer academic publishers ma 
thrun sebastian 
lifelong learning algorithms 
learning learn 
kluwer academic publishers ma 
thrun sebastian sullivan joseph 
clustering learning tasks selective cross task transfer knowledge 
learning learn 
kluwer academic publishers ma 
todorovski dzeroski saso 
combining multiple models meta decision trees 
eleventh european conference machine learning workshop meta learning building automatic advice strategies model selection method combination 
barcelona spain 
survey meta learning utgoff paul 
shift bias inductive concept learning 
michalski 
eds 
machine learning artificial intelligence approach vol 
ii 
morgan kaufman california 
valiant 

theory learnable 
comm 
acm 


development inductive learning algorithms generating flexible adaptable concept representations 
phd thesis university illinois urbana champaign 


research directions meta learning building self adaptive learners 
international conference artificial intelligence 
las vegas nevada 
watanabe 
knowing guessing formal quantitative study 
john wiley sons watanabe 
pattern recognition human mechanical 
john wiley sons wolpert 

stacked generalization 
neural networks 
wolpert 

lack priori distinctions learning algorithms existence priori distinctions learning algorithms 
neural computation 
