generating accurate rule sets global optimization frank department computer science university hamilton new zealand cs waikato ac nz dominant schemes rule learning ripper operate stages 
induce initial rule set re ne complex optimization stage discards adjusts ripper individual rules better 
contrast shows rule sets learned rule time need global optimization 
algorithm inferring rules repeatedly generating partial decision trees combining major paradigms rule generation creating rules decision trees separate conquer rule learning technique 
algorithm straightforward elegant despite experiments standard datasets show produces rule sets accurate similar size generated accurate ripper 
operates ciently avoids postprocessing su er extremely slow performance pathological example sets method criticized 
rules basis popular concept description languages machine learning 
allow knowledge extracted dataset represented form easy people understand 
gives domain experts chance analyze validate knowledge combine ian witten department computer science university hamilton new zealand cs waikato ac nz previously known facts domain 
variety approaches learning rules investigated 
generating decision tree transform rule set nally simplify rules quinlan resulting rule set accurate original tree :10.1.1.98.9054:10.1.1.167.3624
separate conquer strategy pagallo haussler rst applied aq family algorithms michalski subsequently basis rule learning systems furnkranz 
essence strategy determines powerful rule underlies dataset separates examples covered repeats procedure remaining examples 
dominant practical implementations emerged strands research quinlan ripper cohen 
perform global optimization process set rules induced initially 
ered rule iteratively induce rules remaining instances 
multi class setting automatically leads ordered list rules type classi er termed decision list rivest 
various di erent pruning methods separate conquer algorithms investigated furnkranz shows prune immediately generated separate stopping criterion determine cease adding rules furnkranz widmer 
originally formulated class problems procedure applied directly multi class settings building rules separately class ordering appropriately cohen 
ripper implements strategy reduced error pruning quinlan sets training data aside determine drop tail rule incorporates heuristic minimum description length principle stopping criterion :10.1.1.98.9054:10.1.1.167.3624
follows rule induction post processing step revises rule set closely approximate obtained expensive global pruning strategy 
considers replacing revising individual rules guided error modi ed rule set pruning data 
decides leave original rule substitute replacement revision decision minimum description length heuristic 
claimed cohen generates rule sets accurate 
