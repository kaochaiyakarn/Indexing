policy temporal difference learning function approximation precup cs mcgill ca school computer science mcgill university montreal quebec canada richard sutton sutton research att com dasgupta dasgupta research att com shannon laboratory park ave florham park nj usa introduce algorithm policy temporal difference learning stable linear function approximation 
policy learning interest forms basis popular reinforcement learning methods learning known diverge linear function approximation critical practical utility multi scale multi goal learning frameworks options hams maxq 
new algorithm combines td state action pairs importance sampling ideas previous 
prove training soft policy algorithm converges close approximation tsitsiklis van roy action value function arbitrary target policy 
variations algorithm designed reduce variance introduce additional bias guaranteed convergent 
illustrate method empirically small policy evaluation problem 
