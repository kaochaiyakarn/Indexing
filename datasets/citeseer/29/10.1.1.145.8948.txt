multitask learning rich caruana september cmu cs school computer science carnegie mellon university pittsburgh pa submitted ful llment requirements degree philosophy 
thesis committee tom mitchell chair herb simon dean pomerleau tom dietterich oregon state supported nsf bes wright laboratory aeronautical systems center air force materiel command usaf darpa agency health care policy research hs pittsburgh research center 
government authorized reproduce reprints government 
views contained authors necessarily represent wright laboratory national science foundation government 
keywords machine learning neural networks nearest neighbor multitask learning inductive bias medical decision making pneumonia alvinn autonomous vehicle navigation pattern recognition inductive transfer learning learn dedicated parents fostering interest science herb simon teaching ask bigger questions diane willing come pittsburgh 
go rst advisors tom mitchell herb simon members thesis committee dean pomerleau tom dietterich 
great job pushing questioning interpreting suggesting research progressed 
greg cooper michael fine tom mitchell members pitt cmu cost ective health care group help pneumonia databases dean pomerleau road simulator tom mitchell reid simmons joseph sullivan members xavier robot project help xavier robot tom mitchell dayne freitag david zabowski members calendar apprentice project help cap data 
go mitre group aspirin neural net simulator geo hinton group university neural net simulator 
rankprop developed baluja tom mitchell 
input features useful extra output tasks joint virginia de sa 
research bene ted discussions people notably baluja justin boyan tom dietterich virginia de sa dayne scott fahlman ken lang tom mitchell andrew moore dean pomerleau herb simon sebastian thrun dave touretzky valdes perez 
bene ted feedback received friends sat nearly dozen pizza seminars related topics 
tom mitchell served thomas early days source support encouragement days 
tom 
multitask learning approach inductive transfer improves learning task information contained training signals related tasks 
learning tasks parallel shared representation learned task help tasks learned better 
thesis demonstrate multitask learning dozen problems 
explain multitask learning works show opportunities multitask learning real domains 
show cases features normally inputs better multitask outputs 
suggestions get multitask learning arti cial neural nets algorithm multitask learning case methods nearest neighbor kernel regression sketch algorithm multitask learning decision trees 
multitask learning improves generalization performance applied di erent kinds domains di erent learning algorithms 
conjecture opportunities real world problems 
contents motivation 
mtl backprop nets 
motivating example 
brief analysis 
second example 
training signals inductive bias 
thesis roadmap 
chapter summary 

alvinn 
problem 
results 
doors 
problem 
results 
pneumonia prediction medis 
medis problem 
medis dataset 
performance criterion 
predict 
contents methodology 
results 
mtl perform extra tasks 
extra tasks help main task 
comparison feature nets 
pneumonia prediction port 
port problem 
port dataset 
main task 
extra tasks port 
methodology 
results 
combining multiple models 
chapter summary 

mtl requires related tasks 
related tasks 
related tasks correlated tasks 
related tasks share input features 
related tasks share hidden units bene trained mtl backprop 
related tasks won help 
summary 
task relationships mtl backprop exploit 
data ampli cation 
eavesdropping 
attribute selection 
representation bias 
tting prevention 
backprop bene ts relationships 
contents peaks functions 
peaks functions 
experiment 
experiment 
experiment 
feature selection peaks functions 
backprop mtl discovers tasks related 
related revisited 
chapter summary 

predict 
multiple metrics 
multiple output representations 
time series prediction 
non operational features 
extra tasks focus attention 
tasks hand crafted domain expert 
handling categories classi cation 
sequential transfer 
multiple tasks arise naturally 
similar tasks di erent data distributions 
learning quantized noisy data 
learning hierarchical data 
outputs beat inputs 
chapter summary 
inputs better extra outputs promoting poor features supervisors 
poorly correlated features 
contents noisy features 
classi cation problem 
discussion 
selecting inputs extra outputs 
feature selection 
dna splice junction problem 
experiments 
features inputs mtl outputs 
network architecture isolate outputs inputs 
results 
discussion 
chapter summary 
basics early stopping 
learning rates 
learning rate optimization 
ect main task 
learning rates fast tasks train 
performance extra tasks 
learning rates harmful tasks 
computational cost 
learning rate optimization tasks 
fully connected hidden layers 
net capacity 
private hidden layers 
combining mtl feature nets 
chapter summary 
mtl nearest neighbor 
contents background 
nearest neighbor 
locally weighted averaging 
feature weights distance metric 
multitask learning knn lcwa 
pneumonia risk prediction review 
soft ranks 
error metrics 
empirical results 
methodology 
experiment learning task weights mtl 
full advantage lcwa 
experiment large mtl bene 
experiment mtl extra tasks 
feature weights learned stl mtl 
summary discussion 
related backprop nets multiple outputs 
constructive induction 
serial transfer 
hints 
unsupervised learning 
theories parallel transfer 
methods handling missing data 
bayesian graphical models 
uses mtl 
committee machines 
input reconstruction ire 
task speci selective attention 
contents contributions discussion contributions 
discussion 
predictions multiple tasks 
sharing architecture capacity 
computational cost 
task selection 
inductive transfer hurt 
related tasks 
mtl psychologically plausible 
parallel transfer 
intelligibility 
mtl complexity 
combining mtl boosting 
mtl learning methods 
combining mtl learning methods 
bibliography net size generalization backprop nets 
nets big generalize poorly 
empirical study generalization vs net capacity 
goals 
methodology 
results 
excess capacity hurt generalization 

final note 
contents rank error metrics motivating problem pneumonia risk prediction 
traditional approach sse targets 
rankprop 
soft ranks 
discussion 
applications rank methods 
summary 
ability juggle tasks take far 
fortune cookie chapter multitask learning approach inductive transfer improves learning task information contained training signals related tasks 
learning tasks parallel shared representation learned task help tasks learned better 
thesis demonstrate multitask learning dozen problems 
explain multitask learning works show opportunities multitask learning real domains 
show cases features normally inputs better multitask outputs 
suggestions get multitask learning arti cial neural nets algorithm multitask learning case methods nearest neighbor kernel regression sketch algorithm multitask learning decision trees 
multitask learning improves generalization performance applied di erent kinds domains di erent learning algorithms 
conjecture opportunities real world problems 
motivation world live requires learn things 
things obey physical laws derive human culture preprocessed sensory hardware 
similarity tasks learn enables learn little experience 
chapter 
learn play tennis world asks learn things 
learn walk run jump exercise grasp throw swing recognize objects predict trajectories rest talk read study practice tasks running tennis di erent running track related 
similarities thousands tasks learn enable learn including tennis little training data 
arti cial neural network decision tree 
trained tabula rasa single isolated di cult task learn 
example net pixel input retina learn recognize complex objects real world scenes number training patterns available 
better require learner learn things simultaneously 
tasks share learn learner may nd easier learn isolation 
simultaneously train net recognize object outlines shapes edges regions subregions textures re ections highlights shadows text orientation size distance may learn better recognize complex objects real world 
call approach learning multitask learning mtl 
thesis research task learned better leverage information contained training signals related tasks learning 
term task refer target function learned sample points called training set drawn target function 
training set consists nite number data points de ned vector attributes input features xn associated target value yn training signal yn xn ng supervised learning goal learn models accurately predict new values instances test set 
call task wish learn better main task 
related tasks training signals multitask learning learn chapter 
main task better extra tasks 
usually care extra tasks learned sole purpose help main task learned better 
call union main task extra tasks domain 
thesis usually restrict domains tasks de ned common set input features xk extra tasks may functions subset features 
tasks domain necessarily bene cial main task 
goal thesis develop learning methods robust interference tasks methods allow performance main task worse extra tasks helpful 
goal develop heuristics help select tasks domain helpful 
mtl backprop nets hinton proposed generalization arti cial neural networks improves networks learn represent underlying regularities domain hinton 
learner learns related tasks time tasks inductive bias better learn domain regularities 
learning accurate may allow hard tasks learned learned isolation 
shows separate arti cial neural nets 
net function inputs output 
output backprop net training signals target function fed net training predictions read net testing 
thesis term output synonym task target function 
backpropagation applied nets training net isolation 
nets connected learned net ect nets 
call single task learning stl 
shows single net inputs nets outputs nets 
note outputs fully connected hidden layer share 
backpropagation done common machine learning assumption features necessary su cient inputs learning accurate models tasks including main task 
complex architectures fully connected hidden layer better 
see section chapter 
task task task task 
inputs inputs inputs inputs single task backprop stl tasks inputs 
parallel outputs mtl net 
outputs share common hidden layer possible internal representations develop hidden layer task tasks 
sharing learned di erent tasks tasks trained parallel central idea multitask learning suddarth dietterich hild bakiri suddarth holden caruana baxter caruana de sa 
task task task task 
inputs multitask backprop mtl tasks inputs 
multitask learning collection learning algorithms analysis methods heuristics single learning algorithm 
approach inductive transfer learned problem help problem emphasizes learning multiple tasks parallel shared representation learned tasks avail chapter 
able main task 
learning multiple tasks parallel mtl able extra information domain contained training signals related tasks 
backpropagation mtl allows features developed hidden layer task tasks 
allows features developed support tasks developed stl net trained tasks isolation 
importantly mtl backprop allows hidden units specialized just tasks tasks ignore hidden units connected small 
nd useful keeping weights motivating example consider boolean functions de ned bits ask arity ask arity ask arity ask arity bi represents ith bit logical negation disjunction conjunction arity parity bits 
bits functions 
tasks related ways de ned inputs bits ignore bits inputs de ned common computed arity inputs task compute arity task need compute parity vice versa task need compute arity task vice versa chapter 
inputs task compute arity compute parity vice versa 
task need train arti cial neural nets tasks backpropagation 
bits inputs net 
task values computed functions target outputs 
create data set tasks enumerating combinations input bits computing setting bits task signals tasks de nitions 
yields di erent cases di erent training signals case 
synthesized cases randomly sample cases place training set 
remaining cases test set 
test set training evaluate trained nets instances trained 
simplicity ignore complexity early stopping need set aside halt sets determine training 
tasks carefully devised tting signi cant 
done experiment train task nets shown 
left task trained 
stl backprop task 
center task trained net task 
mtl backprop tasks 
right task trained tasks 
mtl backprop tasks 
task learned di erent nets 
task task task task task task task 
inputs inputs inputs neural net architectures learning task nets fully connected feed forward nets input units hidden units outputs 
multiple outputs output fully connected hidden units 
nets trained backpropagation mitre aspirin chapter 
learning rate momentum 
weights nets updated epoch full pass training set 
epochs evaluate performance nets held test set 
measure performance ways 
measure root mean squared error rmse output respect target values 
error criterion optimized backpropagation 
measure percent accuracy output predicting boolean values function 
net output treated prediction treated prediction 
trial train trial test rmse correct trial train trial test training epochs training epochs training curves run backprop stl task shows training curves single run backpropagation stl net task 
graph left shows rmse error function training epochs 
lower rms error better 
graph right shows percent accuracy model 
graphs show performance training set data backpropagation train net test set 
happens nets learn training set rms error training set approaches accuracy approaches 
performance independent test set 
net training set 
perform independent trials sampling training test sets cases training evaluating nets sets 
di erent random seeds generate training test sets initialize nets trial 
trial train chapter 
nets stl net task mtl net tasks mtl net tasks 
experiment measure performance output task 
extra outputs task tasks trained backpropagation ignored net evaluated 
sole purpose extra outputs ect learned hidden layer outputs share task 
test set rmse average trials stl task mtl tasks mtl tasks training epochs rmse test set performance di erent nets task 
shows test set rmse training curves nets task 
curves graph average trials 
rmse task reduced task trained net simultaneously trained related tasks 
rmse reduced task trained task reduced tasks added 
training multiple tasks net increase number training patterns seen net 
net sees exactly training cases 
mtl nets average training curves misleading particularly training curves monotonic 
example possible method achieve better error method average method worse average method regions performance method best align align method presenting average training curves examine individual curves sure average curve misleading 
chapter 
see training cases receive training signals case 
test set correct average trials stl task mtl tasks mtl tasks training epochs test set percent correct di erent nets task 
shows test set percent correct task di erent nets 
curve average trials 
table summarizes results examining training curve trial 
table test set performance task stl task mtl tasks mtl tasks 
indicate performance statistically better stl better respectively 
net stl mtl mtl root mean squared error percent correct average task boolean value time 
simple learner learned predict output value time achieve accuracy 
trained stl performance task 
task trained task performance increases 
task trained tasks performance increases 
qualitatively similar graphs measurements result examine performance chapter 
tasks trained combination tasks 
unique task tasks help helped 
performance poorest task trained isolation stl 
better generalization achieved single net trained tasks time 
tasks trained mtl net better performance 
brief analysis task learned better trained net learning related tasks time 
tasks related learned tasks helps tasks backpropagation just works better nets outputs outputs related 
ran number experiments verify performance increase mtl due fact tasks related just side ect training multiple outputs net 
adding noise neural nets improves generalization performance holden 
extent mtl tasks uncorrelated contribution aggregate gradient noise tasks improve generalization 
see ect explains bene ts see mtl rst experiment train task net random tasks 
lets test lack relationship tasks improves performance 
second ect concerned adding tasks change backprop weight update dynamics favor nets tasks 
example having outputs tends increase ective learning rate input hidden layer weights gradients multiple outputs add hidden layer 
performance improve mtl tasks just extra outputs help backprop train multilayer nets 
test train mtl net copies task 
outputs receives exactly training signals 
degenerate form mtl extra information net extra task training signals 
third ect needs ruled net capacity 
hidden units lot tasks 
mtl net share hidden units tasks chapter 
generalize better just task fewer hidden units 
test train task stl nets hidden units hidden units 
tell generalization better capacity 
run fourth experiment heuristic valdes perez simon discover complex patterns data 
training signals target output values tasks data set training mtl net outputs 
shu training signals tasks independently mix training signals tasks 
shu ing randomly target values yn input vectors xn training set task 
task ected shu ing function inputs 
training signals outputs distributions tasks longer related task functional relationship inputs task signals randomized 
powerful test potential rule mechanisms depend relationships tasks 
ran experiment times exactly data sets previous section 
shows generalization performance task experiments 
comparison performance stl mtl tasks mtl tasks previous section shown gure 
task trained random extra tasks performance task drops performance task trained stl net 
conclude mtl tasks probably learn task better di erences tasks promotes generalization adding noise learning process 
task trained additional copies task performance comparable task trained stl 
conclude mtl learn task better just backprop works better multiple outputs 
observe training multiple copies task net improve performance task 
observed size bene large explain away bene ts observed mtl 
interesting surprising ect improvement gained additional information net 
explanation multiple connections hidden layer allow di erent hidden layer predictions averaged act boosting mechanism perrone 
chapter 
test set correct average trials stl task mtl tasks mtl tasks stl task hidden units stl task hidden units copies task task shuffled tasks task random tasks training epochs rmse test set performance task trained mtl random tasks mtl copies task mtl shu ed training signals tasks stl nets hidden units 
task trained stl net hidden units performance comparable performance hidden units 
task trained stl net hidden units slightly better 
di erences stl hidden units statistically signi cant 
conclude performance task relatively insensitive net size nets hidden units task bene net capacity capacity 
mtl tasks performs better task tasks extra capacity hurting task 
see appendix discussion ect excess capacity generalization nets trained backpropagation 
task trained training signals tasks shu ed performance mtl drops performance task trained stl net 
chapter 
clearly bene see mtl problems due accident caused extra outputs 
extra outputs related main task help 
experiments rule explanations mtl outperforms stl task require tasks related task 
learned better trained parallel tasks 
reason task needs learn compute arity shares tasks 
tasks give net information get task 
example training signal task contains information arity disjunction operator combines parity insensitive value parity 
say blocks arity 
training signals task provide information parity exactly cases task blocked 
hidden layer net trained tasks gets twice information parity net trained tasks despite fact see exactly training cases 
mtl net getting information training case 
reason mtl helps task tasks functions inputs bits ignore inputs 
feature selection di cult learning complex function nite sample 
tasks overlap features don mtl better able select input features 
discuss section feature selection ect goes away di erent tasks completely di erent functions features 
third reason mtl helps task relationships way di erent tasks inputs promote learning internal representations 
example tasks logically combine input function inputs 
similarity tends prevent net learning internal representations example directly combine bits 
net trained tasks biased learn modular correct internal representations support multiple tasks 
conjecture bias modular internal representations helps reduce net tendency learn spurious correlations occur nite training sample may chapter 
random correlation bit output task looks fairly strong training set spurious correlation help tasks learned 
biasing net learn hidden representations support multiple tasks tting spurious details training set reduced 
continuing note task trained extra tasks random functions extra related tasks task signals shu ed performance dropped performance training task stl net 
rst example mtl hurting performance extra tasks related main task 
issue comes section section sections 
second example tempted conclude previous example mtl help hard problems functions internally hard learn subfeatures bit parity 
mtl worthwhile simpler problems 
tempted conclude unused inputs important success mtl 
mtl help feature selection problem 
tempted conclude bene mtl comes adding rst related task particularly task completes dataset important task bit parity example 
mtl bene tasks particularly tasks don special relationship 
consider boolean functions bits bits bits bits bits simple procedure counts number bits set argument bits 
standard boolean conditional test 
multiply bits function bits chapter 
comparing bits function bits balance outcome conditional test true time 
balancing achieved number bits sides 
balancing essential simpli es functions 
note bits functions don care bits 
tasks easier learn tasks principle compute bits bits easier learn parity 
prevent nets trained functions achieving nearly generalization accuracy reduce training set size cases tasks cases 
remaining cases trial test sets 
test set rmse task trained nets 
rst net stl task second net task trained task third net task trained tasks test set percent correct task trained nets 
mtl outperforms stl 
better train task net related tasks train 
bene adding task task net small 
spite fact task task share blocking relationship common bits tasks shared previous problems 
largest increase bene task occurs tasks added net 
table summarizes performance nets 
accuracy task trained 
task added net accuracy increases half percent 
task trained tasks accuracy increases 
improvement due mtl tasks observed tasks 
part reason improvement tasks easier learn 
cases training set accuracy higher stl task mtl tasks 
tasks feature selection problem achieving performance mtl depend tasks having feature selection problem 
mtl bene observed tasks come task blocked chapter 
test set rmse average trials stl mtl mtl training epochs rmse test set performance di erent nets task table test set performance task stl task mtl tasks mtl tasks indicates performance statistically better stl better 
net stl mtl mtl root mean squared error percent correct completed task mtl unusual relationships tasks 
interesting result learned tasks mtl help simple problems learned better data set small 
simple problems hard little training data 
training signals inductive bias inductive bias causes inductive learner prefer hypotheses hypotheses 
bias free learning impossible fact inductive learner follows directly power inductive bias mitchell 
mtl notion tasks serve mutual sources inductive bias 
chapter 
test set correct average trials stl mtl mtl training epochs test set percent correct di erent nets task mtl particular kind inductive bias 
uses information contained training signal related tasks bias learner hypotheses bene multiple tasks 
usually think training data bias training data contains teaching signal task easy see point view task tasks training signals may serve bias 
multitask bias exist inductive learner biased prefer hypotheses utility multiple tasks 
mtl way achieve inductive transfer tasks 
goal inductive transfer leverage additional sources information improve performance learning current task 
inductive transfer improve generalization accuracy speed learning intelligibility models 
thesis focus solely improving accuracy 
concerned computational cost learning intelligibility learned 
way transfer improves generalization providing stronger inductive bias available extra knowledge 
yield better generalization xed training set reduce number chapter 
training patterns needed achieve xed level performance 
thesis roadmap chapter introduced multitask learning backprop nets showed synthetic problems 
chapter demonstrates mtl works real problems 
compare performance single task learning multitask learning backprop nets problems 
problems real world problem created researchers author consider mtl collected data 
chapter discusses related tasks explains mtl works backprop nets 
section reviews evidence showing tasks related mtl improve learning 
section discusses tasks related backprop mtl bene 
section presents speci kinds relationships tasks mtl backprop leverages information extra training signals improve generalization 
section introduces peaks functions set related tasks designed speci cally research parallel transfer 
section uses peaks functions show backprop mtl nets discover tasks related explicit training signals task relatedness 
section revisits notion relatedness proposes de nition 
chapter important part thesis 
shows opportunities mtl inductive transfer general real world problems 
surprising rst glance problems sees machine learning today look multitask problems 
believe current problems machine learning appear single task trained machine learning 
fact believe real world problems multitask problems performance sacri ced treat single task problems 
chapter shows extra tasks useful better input feature extra output task 
surprising feature output input feature ignored learned model prediction 
chapter show features useful inputs chapter 
extra outputs bene ts uses di erent 
approach learning allows features inputs extra outputs time gain bene ts 
chapter discusses get best performance mtl backprop nets 
thesis rst study thoroughly happens multiple outputs trained backprop net 
important heuristics help mtl backprop nets better 
heuristics important mtl nets perform worse stl nets better 
chapter mtl algorithm nearest neighbor kernel regression 
chapter sketch algorithm mtl decision trees 
algorithms look di erent mtl backprop nets strong overlap mechanisms issues mtl algorithms address essentially set problems speci mechanism algorithm di erent 
showing mtl leverage source extra knowledge backprop nets nearest neighbor decision trees di erent learning methods successful machine learning methods date able demonstrate generality utility mtl approach 
related chapter 
chapter summarizes contributions thesis discusses directions research 
appendix discusses ects excess capacity generalization arti cial neural nets trained backprop 
appendix discusses error metrics ranking training data directly learning target function data 
chapter summary standard methodology machine learning learn thing time 
large problems broken small reasonably independent subproblems learned separately recombined see example waibel connectionist glue waibel 
thesis argues modularity counterproductive ignores potentially rich source information available real world problems information chapter 
contained training signals related tasks 
chapter 
chapter demonstrated multitask learning backprop nets sets problems carefully devised introduce reader mtl 
jumping multitask learning works related tasks mtl subjects chapters rst demonstrate chapter works real problems 
convince reader mtl useful real problems examples help reader develop intuitions mtl works applicable 
chapter presents applications mtl backprop nets 
rst uses simulated data alvinn road domain 
second uses real data collected robot mounted camera 
data collected speci cally demonstrate mtl 
third fourth apply mtl medical decision making domains 
data domains collected researchers consider mtl collecting data 
chapter spent working medical domains 
alvinn problem alvinn uses road image simulator developed pomerleau permit rapid testing learning methods road domains pomerleau 
original simulator generates synthetic road images number user de ned parameters road width number lanes angle eld view camera 
modi ed simulator chapter 

generate road images comprised single pixel horizontal scan line original pixel image 
speed learning thorough experimentation done computers available training nets full retina computationally expensive size nets necessary mtl performance allow replications rapid testing ideas 
shows road images 
sample single lane roads generated pomerleau road simulator 
images horizontal stripes taken way images bottom 
smaller input size retinas pixels vs pixels learning easier smaller training sets 
training sets contain images 
alvinn retains complexity original domain 
main complexity lost road curvature longer visible 
simulated roads curvature simulator ects desired steering direction 
loss curvature information limits accuracy achievable perfect learning alvinn domain 
contrary expect road curvature important part learning steer alvinn domain 
backprop nets know training input pixels spatially related learn input pixels arranged 
di cult 
evident generated road images allow vehicle positioned road far left right driver keep vehicle 
done promote robustness insuring net learns recover broad range situations 
train images containing chapter 

lane roads 
greatly increases variety input images 
correct steering direction dependent driving single lane road lane road vehicle centered right lane road center 
principal task alvinn alvinn predict steering direction 
mtl experiments additional tasks road lanes location left edge road location road center intensity region bordering road location centerline lane roads location right edge road intensity road surface intensity centerline lane roads additional tasks computable internal variables simulator 
modi ed simulator training signals extra tasks added synthetic data training signal main steering task 
learning retinas road curvature rst derivative internal parameters generator additional extra tasks 
results table shows performance runs single multitask learning alvinn nets hidden layer 
mtl net inputs hidden units outputs 
stl nets inputs hidden units output 
note size mtl nets optimized 
entries stl mtl headings generalization error nets speci ed size early stopping halt training 
bold stl entries stl runs yielded best performance 
di erences stl runs di erent size nets statistically signi cant 
columns compare stl mtl 
rst column percent reduction error mtl best stl run 
negative percentages indicate mtl performs better 
test biased favor stl compares runs mtl unoptimized net size independent similar experiment nets hidden layers containing hidden units layer stl hidden units layer mtl yielded similar results 
chapter 

table performance stl mtl hidden layer tasks alvinn domain 
underlined entries stl columns stl runs performed best 
di erences statistically signi cant better marked 
root mean squared error test set task single task backprop stl mtl change mtl change mtl hu hu hu hu hu best stl mean stl lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering runs stl di erent random seeds able nd near optimal net size 
column percent improvement mtl average stl performance 
di erences marked statistically signi cant better 
note important steering task mtl outperforms stl 
having access extra training patterns exactly training patterns stl mtl 
di erence mtl training patterns training signals tasks stl training patterns training signals task time 
doors problem alvinn real domain data generated simulator 
test mtl realistic problem created object recognition domain similar respects alvinn 
doors main tasks locate recognize door types single double images doors collected robot mounted color camera 
collected images robot somewhat randomly th oor wean hall cmu 
images images chapter 

visible image selected 
pictures doorways 
images grouped doorway represented 
thirds groups training testing 
sample doorways images doorways want test sets contain doorways nets trained 
sampling process yielded training sets containing images 
shows door images database 
alvinn problem simpli ed horizontal stripes images green channel blue channel 
stripe pixels wide accomplished applying gaussian smoothing original pixel wide image occurs vertical height image located 
tasks 
horizontal location horizontal location doorway center horizontal location left door jamb width left door jamb horizontal location left edge door single double door width doorway horizontal location right width right horizontal location right edge door sample single double doors doors domain 
real domain training signals tasks acquired manually 
mouse click appropriate features image training test sets 
necessary process image manually acquire training signals chapter 

main tasks di tasks 
cult acquire training signals extra results di culty doors precluded running exhaustive set experiments alvinn comparison done tasks considered important location door type 
stl tested nets hidden units 
mtl tested nets hidden units 
results trials stl mtl table 
mtl generalizes better stl tasks compared best di erent runs stl 
note training patterns stl mtl identical mtl training patterns contain additional training signals 
information contained extra training signals helps hidden layer learn better internal representation recognizing door types location 
table performance stl mtl main tasks doors 
underlined entries stl columns stl runs performed best 
di erences statistically signi cant better marked 
root mean squared error test set task single task backprop stl mtl change mtl hu hu hu hu best stl loc door type alvinn domain simulated data 
simulator built mtl mind modi ed extra task signals available training data 
doors domain real data collected real camera real robot wandering real hallway 
attempt keep domain challenging robot kept parallel hallway distance doors illumination allowed vary training signals collected trackball laptop computer riding public bus domain contrived speci cally demonstrate mtl 
mtl real domain chapter 

customized 
pneumonia prediction medis pneumonia risk prediction problem examine excellent test bed mtl research 
complex problem unusually large complete data set available 
easier thorough experiments 
real domain 
data collected researchers know learning methods applied 
turns opportunities apply mtl domain 
medis problem problem diagnosis pneumonia 
goal diagnose patient pneumonia determine risk illness poses patient 
cases pneumonia year admitted hospital 
pneumonia patients recover appropriate treatment treated ectively hospitalization 
pneumonia serious pneumonia die elevated risk 
primary goal medical decision making accurately swiftly economically identify patients high risk diseases pneumonia may receive aggressive testing treatment patients low risk may comfortably safely economically treated home 
goal problem information available patients pneumonia admitted hospital patient history results simple tests blood pressure predict patient risk dying pneumonia 
low risk patients considered care 
note diagnosis pneumonia 
goal assess risk pneumonia represents 
useful tests predicting pneumonia risk usually measured available preliminary assessment indicates chapter 

hospitalization testing warranted 
low risk patients identi ed measurements prior admission hospital 
database patients 
extra lab tests patients admitted hospital extra tasks mtl inputs available patients decision 
medis dataset medis pneumonia database fine contains pneumonia cases collected hospitals 
patient database diagnosed pneumonia 
measurements available patients 
include basic measurements acquired prior hospitalization age sex pulse lab results blood counts blood gases usually available hospitalization 
database indicates long patient patient lived died 
patients died 
useful decision aid problem predict patients live die 
di cult 
practice best achieved estimate probability pod observed symptoms 
fact su cient learn rank patients pod lower risk patients discriminated higher risk patients patients risk may considered care 
performance criterion performance criteria working medis database cooper accuracy select prespeci ed fractions patient population live 
example population patients nd population risk 
learn risk model threshold model allows population patients fall 
patients threshold die error rate 
say error rate fop fop stands fraction population 
consider 
goal learn models model thresholds chapter 

error rate fop minimized 
predict medis database contains results lab tests usually available patients 
results typically available model patients admitted 
mtl bene lab results 
extra lab values extra backprop outputs shown 
expectation extra outputs bias shared hidden layer representations better capture important features patient condition 
mortality rank white blood cell count potassium labs rankprop output 
output layer 
shared hidden layer 
input layer age sex chest pain heart inputs lab results extra outputs bias learning main risk prediction task 
rankprop described section appendix 
lab tests help inputs measured risk predicted extra mtl outputs 
interesting note researchers tackled problem database ignored extra lab tests knew lab tests available run time see ways inputs 
chapter 

methodology straightforward approach problem backprop train stl net learn predict patients live die real valued predictions net sort patients risk 
stl net inputs basic measurements single hidden layer single output trained targets lived died 
nite training set net trained way learn predict probability death patient patients live die 
real world rarely nite number training cases 
training sample small net learn nonlinear function outputs values near cases training set generalize 
critical early stopping halt training happens 
developed method called rankprop speci cally domain learns rank patients learning predict mortality 
rankprop short backpropagation sum squares errors sse repeatedly re estimated ranks 
compares performance sse targets rankprop problem 
rankprop outperforms traditional backprop sum squares errors targets lived died domain depending fop comparison 
see appendix details rankprop comparison performance rankprop traditional backprop domain 
stl net hidden units output rankprop risk prediction 
mtl net hidden units 
preliminary experiments suggested hidden units optimal stl mtl perform somewhat better nets large hidden units 
hidden units stl hidden units mtl ord run experiments 
mtl net shown 
inputs stl net rankprop output learns order patients tried squared error cross entropy outputs lived died 
di erences approaches small squared error performing slightly better 
results report thesis squared error 
rankprop experiments mtl best performer know problem 
outperforms sse stl mtl 
interested developing methods improve inferior algorithms 
want mtl best algorithms better 
chapter 

stl sse targets stl rankprop test set error rate fraction population fop performance sse targets rankprop pneumonia risk prediction domain 
lower error indicates better performance 
risk 
main task 
addition main task mtl net extra outputs 
extra tasks net learn learning predict risk 
domain extra tasks predict results lab tests usually ordered preliminary risk assessment suggests patient 
train net training sets containing patients randomly drawn database 
training halted halt set containing patients drawn database 
training halted stl mtl nets tting observed main rankprop risk task 
tting detected observing performance backprop nets training independent test set called halt set backpropagation 
performance halt set stops improving begins getting worse training stopped model weights frozen 
mtl net performance extra tasks taken account early stopping 
performance output main task considered deciding halt training 
see section discussion early stopping mtl nets 
section shows interesting assortment halt set curves early stopping 
chapter 

training halted net tested remaining unused patients database 
process randomly sampling training halt sets testing remaining cases repeated times 
medis database contains patients 
training sets containing cases reasons 
main reason time began working data preparing di erent complex database contains cases 
viewed medis database warm exercise interesting database 
unfortunately access database delayed years complications coding verifying data 
database complex routine manipulations require days manual labor done correctly 
gained access subset database 
results rst experiments database section chapter 
reason small training sets medis database illustrated 
gure shows performance nearest neighbor medis pneumonia problem function number training cases 
performance asymptotes number training cases increases cases 
preliminary experiments suggest backprop nets bene little training sets containing cases 
de nition consistent learning procedures converge true function data 
interesting di erences consistent procedures knn backprop large nets show small moderate sample sizes 
mtl bene ts derive mechanisms extra tasks compensate di culties training limited sample see section 
expect little bene mtl problem training sets containing cases 
borne preliminary experiments suggested mtl helped performance training sets containing training cases 
mtl improve performance training sets large cases largest tested improvement small di cult achieve statistical signi cance comparing methods 
believe worthwhile try show statistical signi cance di erences small interesting 
third reason small training sets experiments run faster 
chapter 

fop fop fop fop test set error rate number patients training set generalization performance nearest neighbor function training set size pneumonia fop 
cost epoch increases linearly worse considers cache performance number training cases number epochs required tting increases number training patterns 
things worse rankprop trains slower backprop lives dies targets 
rankprop best stl performer problems want 
factors greatly favored smaller training sets 
settled train halt sets containing cases number practical largest sizes usable pneumonia database hoped 
important realize possible accurate predictions report medis pneumonia problem training available data 
feel diminishes importance results report medical databases contain cases medis database 
chapter 

results table shows mean performance runs rankprop stl mtl 
bottom row shows percent improvement stl 
negative percentages indicate mtl reduces error 
mtl lowers error fop compared stl di erences fop statistically signi cant trials standard test 
table error rates fraction deaths stl rankprop mtl rankprop fractions population predicted low risk fop 
mtl fewer errors stl 
fop stl rankprop mtl rankprop change improvement due mtl 
improvement considerable consequence medical domain 
verify bene ts seen due relationships learned labs main task ran shu test see section pneumonia problem 
shu ed training signals extra tasks training sets training nets mtl 
shows results mtl shu ed training signals extra tasks 
comparison results stl mtl ed extra tasks shown 
shu ing training signals extra tasks reduces performance mtl stl 
conclude probably relationship main task extra tasks lets mtl perform better main task bene disappears relationships broken shu ing extra task signals 
mtl perform extra tasks 
mtl net performed extra tasks compared stl nets learning tasks 
extra tasks learned inputs don expect see large di erences performance 
trained stl nets extra task 
inputs nets inputs chapter 

stl mtl mtl shuffled extra task signals test set error rate fraction population fop ed extra task signals performance stl mtl mtl shu risk prediction 
regular pre admission patient measurements 
repeated times samples trials 
trained individual nets 
early stopping training net individually 
computationally training stl nets far expensive training mtl nets stl nets compared 
compared performance individual stl nets tasks performance mtl net trained main task extra tasks 
trick training stl nets running experiment simpler saves computation 
training separate net output train net outputs 
hidden layer net broken smaller pieces connect output 
rst hidden units connect output output hidden layers fully connected inputs 
equivalent training outputs separately long early stopping outputs individually 
advantage procedure machinery developed mtl net stl net nets inputs outputs 
di erence hidden layers allowed share learned di erent tasks 
chapter 

shows percent change rms error going stl mtl extra tasks 
mtl yields lower error stl outputs 
sign test shows signi cant level 
cases stl performs better mtl di erences small 
mtl outperforms stl percent 
average improvement due stl average improvement due mtl 
change rms error mtl extra task percent improvement rms error extra tasks mtl compared stl 
negative improvements indicate mtl performs better 
caution tempted view results extra tasks di erent experiments comparing stl mtl 
example interpret results suggesting mtl outperform stl roughly time 
tasks drawn domain tests independent risky inference 
extra tasks help main task 
natural question ask mtl extra tasks ected main task 
related di erent question extra tasks helped main task 
chapter 

unfortunately answering questions expensive 
thorough approach addressing questions train possible combinations extra tasks main task see sets extra tasks change improve performance main task 
combinatorial approach course usually impractical 
practical approach ask extra tasks learnable 
presumably extra task learnable inputs contribute little main task learned 
possible task learned just little bit better random substantial ect learned hidden layer 
poor performance task necessarily imply value learned task 
task may di cult predict optimal learned representation 
conversely task easily learned high accuracy may lead development interesting internal representations useful tasks 
extreme example consider output duplicates inputs training signal output values input features 
output learned perfectly backprop net net need learn feed value input directly hidden layer output duplicates 
doing new learned hidden layer available input 
examined training curves outputs mtl net 
extra outputs learnable inputs 
come surprise 
assume lab test worth measuring outcome test predicted doing test 
second lab tests re ect speci accurate measurements patient measurements available patient admitted hospital 
going di cult impossible predict detailed internal measurements blood chemistry simpler general measurements age sex blood pressure 
shows training curves extra outputs learnable 
judged learnable output examining test set learning curves 
learning curve showed signi cant improvements accuracy training assumed interesting learnable output 
comparison sse output main task included 
chapter 

rapid drop rmse occurs rst passes backprop meaningful 
net just learning mean distribution output 
changes rmse occur drop consequential 
changes small 
tasks learned 
mean learned meaningful useful 
example output non rankprop output main task shows similarly small drop error 
model learned create small drop error allows patients ranked risk accuracy 
small changes rmse re ect signi cant changes model learned 
bun blood nitrogen task quantized bun task creat blood task rmse test set rmse test set rmse test set backprop passes epochs quantized blood task backprop passes epochs glucose task backprop passes epochs quantized glucose task rmse test set rmse test set rmse test set backprop passes epochs blood task backprop passes epochs quantized task backprop passes epochs lived died main task rmse test set rmse test set rmse test set backprop passes epochs backprop passes epochs backprop passes epochs learning curves learnable extra tasks 
learning curve sse output main task shown comparison 
interestingly tasks judged learnable tasks show largest di erences performance stl mtl 
learn chapter 

able tasks selected seen results biased results 
comparison feature nets lab tests extra tasks mtl lab tests doctors order help assess pneumonia risk decide patient treatment 
excellent features pneumonia risk prediction 
shows performance obtained able lab tests extra inputs 
stl inputs basic labs stl inputs basic labs test set error rate fraction population fop basic labs available inputs include items patient histories simple measurements blood pressure conveniently measured prior hospitalization 
lab tests extra inputs improve performance considerably 
unfortunately regular inputs net learning predict risk usually available model 
missing 
available training set 
alternate approach training signals labs extra outputs learn models predict lab chapter 

tests missing provide predictions extra inputs net learning main risk prediction task 
feature nets davis stentz competing approach mtl 
trains nets predict missing measurements uses predictions hidden layers learned predictions extra inputs 
see 
predictions imputed missing values inputs learning predict standard technique statistics 
hidden layers trained values extra inputs new interesting approach outperforms simple value imputation 
main task 
task task task 
inputs feature nets allow main task trained stl bene learned auxiliary tasks 
tried feature nets pneumonia problem 
trained extra tasks stl nets hidden units 
extra tasks trained stl nets trials 
early stopping halt training nets performance tasks maximized measured halt set 
training halt sets train nets 
samples data train chapter 

mtl net 
training individual stl nets trial experiments 
experiment predictions nets labs provided extra input features stl net learning main risk prediction task 
net regular inputs plus additional inputs predictions stl feature nets 
second experiment predictions stl nets hidden layer activations nets additional inputs net learning main task 
net regular inputs extra inputs hidden layers stl nets 
stl mtl stl feature nets predictions stl mtl stl feature nets hidden layers test set error rate test set error rate fraction population fop fraction population fop performance approaches feature nets compared stl mtl 
compares performance feature nets lab tests stl mtl 
left graph performance predictions feature nets extra inputs net learning main risk prediction task 
graph right performance hidden layers learned feature nets extra inputs net learning main task 
approach feature nets yields improvements comparable mtl domain 
mean mtl outperform feature nets 
extra tasks highly predictable predictions extra inputs yield performance chapter 

comparable achieved real values inputs measured regular inputs 
domain lab tests predicted accurately models learned provide little useful extra information inputs 
extra outputs help 
surprising 
complete analysis happen chapter 
summarize predictions tasks extra inputs noise predictions injected input network 
learning di cult learned model sensitive noise input predictions net tested 
output net function noisy inputs output noisy 
noisy predictions extra inputs may reduce bias increase variance 
variance increases bias reduced prediction accuracy hurt 
extra outputs noise problem 
training signals net sees extra tasks outputs noisy real training signals collected training cases 
training signals corrupted marginal learning process 
pneumonia prediction port section medis pneumonia risk problem 
section apply mtl pneumonia risk problem 
pneumonia problem tackle uses database called port database 
ll refer problem port problem avoid confusion medis pneumonia problem previous section 
port problem medis pneumonia problem section port problem real domain data collected researchers know mtl methods 
diagnosis pneumonia 
goal diagnose patient pneumonia determine risk pneumonia poses patient 
previous pneumonia domain patients port domain chapter 

admitted hospital 
roughly patients treated 
principal task port domain predict patients low risk considered treatment previous section predict patients high risk pneumonia 
port domain patients high risk de ned develop dire outcomes need treatment critical care unit icu develop di erent severe complications die goal domain accurately predict patients highest risk developing dire outcomes 
port dataset medis database section contained patients port pneumonia database contains pneumonia cases 
total number cases available port database similar number cases training medis pneumonia problem 
accident 
knew port database began working larger medis database viewed medis database warm exercise working richer complex smaller port database 
patient port database diagnosed pneumonia 
variables available database patients 
ort required preprocess variables daunting measurements core database coded far available 
measurements available patients 
include basic measurements acquired prior hospitalization age sex pulse lab results blood counts blood gases available hospitalization 
patients variables missing values 
nearest neighbor method devised speci cally dataset impute ll missing values 
know missing values results problem chapter 

port database indicates long patient total cost hospitalization patient admitted intensive care patient developed complications patient alive days admitted 
main task useful decision aid port predict patients high risk 
problem high risk patients de ned icu comp comp comp death icu boolean indicating patient entered intensive care unit comp comp booleans di erent severe complications death boolean indicating patient survived days 
main task port domain predict 
medis pneumonia problem predicting patients experience dire outcome di cult 
practice best achieved estimate probability dire outcome observed variables patients higher probability distinguished lower probability 
performance criteria working port database predict accuracy positive predictive value negative predictive value sensitivity speci city roc curve area 
de ned follows model prediction true outcome tried running experiments lled missing values 
discuss method lling missing values 
chapter 

accuracy positive pv negative pv sensitivity specificity accuracy usual measure fraction cases properly predicted 
domain expect achieve accuracies signi cantly better default accuracy achieved predicting patients frequent class 
positive predictive value accuracy cases true outcome predicted 
measure model misses cases true outcome 
negative predictive value accuracy cases true outcome predicted 
measure model misses cases true outcome 
sensitivity isthe fraction cases predicted outcome outcome 
measure reliable prediction predicts outcome 
speci city fraction cases predicted outcome outcome 
measure reliable prediction predicts outcome 
roc curve graph sensitivity vs speci city threshold boundary high low risk limit 
see examples roc curves 
relationship model prediction true outcome roc curve possibly noisy diagonal line area curve 
model predictions strongly predict true outcome roc curve rises quickly area near 
model prediction strongly predicts anti truth roc area 
summary models roc areas greater better models having roc areas closer 
extra tasks port port database indicates long patient total cost hospitalization patient intensive care patient developed severe complications predictions logistic regression model developed medical chapter 

experts predict pneumonia risk database patient alive days admitted 
variables extra outputs mtl training main task output predict 
expectation extra outputs bias shared hidden layer representations better capture important features patient condition improve performance main prediction task 
extra tasks port disjunctive subcomponents main task see equation case applied mtl medis problem section 
methodology straightforward approach problem backprop train stl net learn predict boolean compute error measures roc area real valued predictions trained net 
stl net inputs single hidden layer single output trained boolean targets 
training sets small net eventually learn nonlinear function outputs values near cases training set generalize 
critical early stopping halt training happens 
stl net hidden units output prediction 
mtl net hidden units 
mtl net inputs stl net output 
main task 
addition main task mtl net extra outputs 
split cases port database nal test set containing patients training set containing remaining cases 
done nal test set training done cases nal test set 
randomly split training cases training sets containing cases early stopping test sets containing cases 
di erent times run trials 
trial stl mtl nets trained backpropagation port database available applied rankprop 
experiments report train nets standard squared error targets 
know rankprop yield better performance sse targets probably 
di erence results independent results section 
chapter 

training sets 
training halted performance halt set maximized 
roc area performance criterion early stopping sse error 
performance measured main task output extra tasks mtl nets ignored deciding halt training 
results table shows average performance stl mtl nets held test set 
mtl outperforms stl measure 
average improvement mtl stl 
important roc area measure mtl improves roc area 
note know best roc area achieved domain domain stochastic roc areas near achievable 
mtl probably improves roc area 
table performance stl mtl port prediction problem number di erent performance measures 
di erence column percent reduction error mtl stl 
metric stl mtl difference accuracy positive pv negative pv sensitivity speci city roc area average shows average roc curves trials stl mtl 
roc curve mtl dominates roc curve stl graph 
di erence re ected roc area stl mtl table roc area mtl closer stl roc area 
performed experiments port database members larger project studying problem 
members project applied learning methods port problem test training sets stl mtl 
held test set trials inappropriate tests estimate signi cance improvements mtl stl test sets independent 
chapter 

average stl average mtl sensitivity specificity roc curve mtl dominates roc curve stl regions graph 
researchers applied rule learning methods bayesian methods logistic regression port problem 
researchers experts methods tried ran experiments concurrently stl mtl experiments know methods perform time ran experiments backprop nets trained stl mtl yielded better performance methods tried problem 
mtl currently best performing learning method know problem 
combining multiple models results reported table average performance models trained cases early stopped cases 
need early stopping models trained entire cases available training 
test set trials combine predictions models trials prediction case test set 
cases chapter 

training randomly re sampled cases trial combined prediction better utilizes total cases available training 
combine models averaged predictions case test set 
table shows roc areas stl mtl combining model predictions way 
expected combining model predictions improve performance stl mtl 
ect large 
bene mtl large model predictions combined combined 
demonstrates domain bene ts mtl bene ts achieves combining multiple experts bene ts achieved combining multiple experts additive bene ts mtl 
table roc area stl mtl port prediction predictions di erent models trials combined 
entry bottom right cell di erence stl model combining mtl model combining 
stl mtl difference combining combining difference chapter summary chapter demonstrated multitask learning realistic domains 
rst domain alvinn data generated simulator written pomerleau 
modi cations simulator internal variables available extra task signals simplify problem learning single horizontal stripe image 
mtl reduced error important steering task domain 
second domain doors attempt create domain similar alvinn real data data generated simulator 
domain robot hallway wean hall collected images doorways 
main tasks domain nd horizontal location images chapter 

estimate width doorways 
domain designed data collected speci cally experiments mtl attempt domain realistic 
robot imaged doorways di erent distances di erent angles di erent illuminations types doorways included data set varied th oor wean hall permits 
doors mtl improved accuracy main tasks 
third domain medis pneumonia risk prediction real medical decision making problem 
data collected researchers author 
got involved project looked promising mtl asked apply backprop domain comparison learning methods 
rankprop method developed author baluja tom mitchell single task learning domain strongest single task competitor know 
rst rankprop improved performance stl domain didn think room left improvement mtl 
mtl reduces error trained samples containing training cases 
additional experiments demonstrated bene achieved feature nets alternate method extra task signals 
section show howto combine mtl feature nets get better performance 
fourth domain port pneumonia risk prediction problem 
data port problem di erent data medis problem 
order magnitude data order magnitude features case features extra outputs medis inputs port extra tasks mtl port measurements available medis dataset 
prediction problems di erent 
medis goal predict patients risk pneumonia 
port goal predict patients experience dire outcome patients high risk pneumonia 
rankprop medis problem port problem 
port traditional sse targets 
error metrics port medis di er 
port measure accuracy prediction positive negative predictive values sensitivity speci city roc curve area 
port chapter 

problem mtl reduces error measures yielding average reduction error including reduction error important roc area measure 
results reported chapter conclude mtl works real problems yields large improvements worthwhile 
chapter 
chapters showed mtl works backprop nets 
mtl backprop nets bene information training signals tasks 
relationships tasks enable mtl backprop 
backprop nets trained mtl know tasks related 
chapter attempt de ne related means 
discussing related tasks section brie reviews experiments section show mtl works tasks related 
section informal discussion tasks related backprop mtl 
section presents detailed task relationships allow backprop mtl nets learn better internal representations related tasks 
mechanism enables mtl backprop bene relationships constructive destructive interference backprop error gradients summed hidden layer shared tasks 
section introduces peaks functions set synthetic problems speci cally designed elucidate mtl backprop works 
demonstrating mtl works peaks functions peaks functions demonstrate task relationships described section 
section employs peaks functions show backprop mtl discovers tasks related explicit training signals task relatedness 
section introduce measure task sharing examines di erent tasks overlap hidden layer 
section returns issue related tasks 
section propose de nition related perfect hopefully step right direction 
chapter 

mtl requires related tasks potential reasons adding extra outputs backprop net improve generalization performance 
section mentioned adding noise backpropagation improves generalization holmstrom 
extent tasks uncorrelated contribution aggregate gradient gradient sums error fed back layer outputs appear noise tasks 
uncorrelated tasks improve generalization acting source noise 
adding tasks change weight updating dynamics favor nets tasks 
example adding extra tasks increases ective learning rate input hidden layer weights relative hidden layer output weights 
larger learning rates rst layer improves learning 
reduced net capacity improve generalization 
mtl nets share hidden layer tasks 
reduced capacity improves generalization 

example backprop prone getting stuck local minima 
extra tasks help push hidden layer inferior local minima local minima di erent tasks di erent places 
example mtl introduce competitive ect hidden layer acts regularizer 
task trained net hidden unit correlates errors output tuned task 
tasks trained net competition hidden layer hidden units assuming tasks require identical hidden layer representation 
competition cause hidden units trained task force exerted task hidden unit stronger forces exerted hidden unit tasks 
means hidden units relevant task trained task 
nal example neural nets trained single task su er problem called herd ect fahlman causes hidden units try largest source error early training 
hidden units error remaining hidden units herd try largest residual error words learning backprop nets serial parallel looks sequence concepts learned weigend 
training chapter 

multiple tasks net reduce herd ect causing early di erentiation hidden units di erent error signals try time 
potential explanations training multiple tasks parallel backprop net improve performance 
mtl mainly interested improvements due tasks related 
ects worthwhile interesting mtl method designed inductive transfer inductive transfer unrelated tasks sensible 
interested mtl works tasks related section ran experiments try disprove alternate mechanisms 
experiment trained main task mtl net extra random functions 
experiment trained multiple copies main task mtl net 
third experiment varied number hidden units see restricting capacity net improve generalization 
experiments attempts disprove single alternate explanation 
possible alternate explanation 
impractical devise tests disprove individually 
section ran experiment aimed disproving speci alternate mechanism 
experiment shu ed training signals extra tasks disrupt relationships main task extra tasks preserving distributions extra tasks 
shu test directly tests assumption mtl works tasks related 
bene disappears relationship tasks broken shu ing evidence relationships important 
experiments performance bene ts mtl disappear relationship main task extra tasks disrupted 
similar ndings resulted performing shu test pneumonia risk prediction problem section 
conclude improvement mtl due mechanism depend tasks related 
mtl leverages information contained training signals related tasks 
tasks related mtl learn better 
tasks related mtl may learn worse stl 
chapter 

related tasks 
mean related 
di cult question 
ideally extra tasks improve performance main task related maint ask ask learning maint ask learning maint ask says de ne relation related main task extra task true learning generalizes better main task learns extra task parallel main task 
potential problem de nition specify learning procedure 
clearly learning methods equivalent 
learning methods may better multitask learning methods may able exploit relationships tasks methods 
useful de nition related related maint ask ask maint ask maint ask de nition acknowledges bene may depend learning algorithm multitask learning 
de nition related appealing raises important issues 
rst issues mentioned previous section 
suppose related maint ask ask says maint ask learned better trained ask 
suppose ask random function inputs 
maint ask bene ts trained ask ect ask learning procedure learned extra task useful main task 
wouldn better modify learning method bene ts ect bene may depend factors number training patterns parameters control learning learning rates 
assume information encapsulated descriptions main task extra tasks learning algorithm 
chapter 

needing training signals ask 
ask backprop net acting source random signals wouldn better add randomness backpropagation method need extra training signals 
ask helps alters learning rates wouldn better nd way directly control learning rates 
related de ned extra tasks considered related bene cial solely perturb learning ways achieved modifying learning algorithm throwing away extra task training signals 
extra task unrelated improved algorithm 
called extra task related rst place 
second issue exempli ed related maint ask ask related maint ask ask ask bene ts maint ask di erent learning algorithms 
assume bene ts 
assume case extra task helps ect achieved extra task training signals modifying algorithm 
able exploit relationships tasks exploit 
example suppose tasks identical training signals corrupted independent noise processes 
ask ask noise ask ask noise information task learned task signals 
ask ask clearly related 
inductive transfer method recognize bene relationship clearly imperfect 
reasonable say ask ask unrelated just able bene relationship 
wouldn better recognize relationship tasks devise algorithms bene type relationship 
third issue probably important 
suppose tasks 
determine related relationship true false tasks applying chapter 

learning 
relatedness judged mechanisms di erent hopefully easier reliable multitask learning 
know reliable ways judge task relatedness information typically tackling real world machine learning problems 
mean resort trying possible extra tasks see help 
believe heuristics developed judging task relatedness reliable practical applications multitask learning real world 
heuristics exist 

chapter hospital tests pneumonia patients extra tasks alvinn 
possible training signals patient medical history help learn drive car better 
largely unconsciously dismissed nearly nite number potential training signals models driving suggest relationships extra tasks steering 
certainly true failed recognize extra tasks bene ted steering main task alvinn certainly true successfully ignored tasks helped steering 
formal models backpropagation multitask learning autonomous navigation 
heuristics 
possible heuristics precise 
thesis interested kinds heuristics 
heuristics de ne relationships tasks exploited particular learning algorithm 
heuristics de ne relationships tasks exploitable multitask learning algorithm remainder chapter devoted heuristics rst type 
chapter devoted heuristics second type 
section speci relationships tasks allow backprop bene learning tasks parallel 
relationships precise de nition related means backprop mtl 
relationships somewhat 
remainder section address issue task relatedness informal level jumping chapter 

level detail 
related tasks correlated tasks correlation simplest ways measuring relationship variables 
correlation measures joint variation variables 
regression correlation assume variables dependent 
correlation assumes variables measured drawn population instances 
ways correlation similar regression 
section linear correlation 
interested models necessarily linear 
real world relationships complex linear reasonably strong linear components 
linear correlation serves useful easily computable proxy precise relationships variables information 
de nition correlation coe cient sample points xi yi pn xi yi formula clear correlation measure degree variation mean occurs variation negative correlations 
assume tasks related correlated 
true 
counts mtl task signals correlated internal representations di erent tasks correlated 
related tasks correlated level representation necessarily output level 
see consider synthetic tasks sigmoid sigmoid sigmoid correlate correlate 
correlation coe cients training sets create problem typically chapter 


shows scatter plot vs uniformly sampled interval 
scatter plot vs 
shows correlation suppose inputs backprop net coding rst standard powers binary code 
bits bits inputs net coding inputs net coding net trying learn learn decode inputs 
correlate internal representations learn hidden layer decode inputs strongly correlate 
trained stl net just mtl net 
stl net inputs hidden units output 
mtl net architecture outputs 
generate training sets containing patterns 
data get performance stl room improvement 
trial uses new random training halt test sets 
large halt test sets cases minimize ect sampling error measured performances 
target outputs unary real unencoded values 
table shows mean performance trials stl mtl 
mtl net chapter 

generalizes little better 
correlated related bene decoding binary input encodings correlated hidden layer representations 
related tasks correlated correlated tasks related 
table mean test set root mean squared error network trials mean rmse signi cance stl mtl improvement mtl stl previous experiment small statistically signi cant 
experiments synthetic functions chapter rest thesis show modest improvements 
bene task usually small particularly task designed take advantage task relationships section 
larger ects obtained adding extra tasks synthetic domains 
extra tasks possible synthetic problems keep simple count careful experiments trials large test sets show ect 
extra task kind worst case mtl 
related tasks share input features suppose tasks functions subsets inputs backprop net 
tasks related way backprop mtl bene 
uses uses functions compute disjoint sets input features disjoint sharing hidden layer occur 
simple mtl nets share weights input hidden layer share hidden layer 
share hidden output layer weights 
see bengio experiments mtl architectures share output weights 
limitation backprop mtl method discussed thesis 
approaches inductive transfer limitation 
basic problem chapter 

backprop nets propositional 
learn rst order theories 
restricts mtl bene ting tasks related propositional functions inputs 
way measure task relatedness measure amount input features share 
tasks share input features related share hidden units computed input features 
measure task relatedness sections 
related tasks share hidden units bene trained mtl backprop su cient tasks overlap input features 
tasks compute completely di erent functions subfunctions input features probably bene trained 
mtl backprop bene related tasks tasks share representation learned hidden layer 
usually internal representations learned task di cult notion task relatedness operational 
backprop nets learn internal representations surprisingly di erent representations expect want learn 
tasks look completely unrelated write mathematical description turn related hidden layer representations learned nets 
related tasks won help just tasks related mean necessarily help 
ect learning related tasks depends algorithm 
better algorithms bene di erent task relationships 
see consider simple case modi ed backprop algorithm trained multiple outputs rst training net completion output trained net completion output hidden units output 
legitimate algorithm training nets multiple outputs speci cally precludes mtl 
wrong decide tasks unrelated just algorithm bene relationships 
tasks related algorithm failed take advantage 
goal chapter 

theory task relatedness mtl inductive transfer general nd task relationships di erent algorithms take advantage 
nd task relationships algorithm bene hurt mission improve algorithm 
summary tasks related ways backprop mtl bene 
backprop mtl tasks functions inputs subfunctions computed inputs correlated 
section speci relationships tasks mtl backprop able develop better hidden layer representation 
task relationships mtl backprop exploit section presents speci task relationships improve generalization backprop nets trained simultaneously tasks relationships 
mechanism allows backpropagation bene relationships summing error gradient terms hidden layer di erent task outputs 
relationships bene ts error gradient summing somewhat di erent way 
task relationships bene learning backprop perform unsupervised clustering learned hidden layer di erent tasks explicit training signals tasks related 
critical unsupervised learning component mtl examined section 
data ampli cation data ampli cation ective increase sample size due extra information training signal related tasks 
types data ampli cation 
chapter 

statistical data ampli cation consider tasks target functions learned training sets 
simplicity assume number training patterns learned input features training signals input vectors 
words training set pattern training set training signal statistical ampli cation occurs noise training signals 
suppose independent noise added training signals 
suppose bene computing hidden layer feature common inputs 
epsilon epsilon epsilon epsilon independent noise sources 
net learning recognizes tasks share training signals learn better averaging di erent noise processes 
simplest case case outputs independently corrupted versions signal 
known apriori train net task training signals average training signals situation rarely occurs practice training average training signal incorrect 
training mtl net separate outputs widely applicable 
nite sampling data ampli cation sampling ampli cation similar statistical ampli cation occurs noise training signals 
consider tasks noise added training signals bene computing hidden layer feature inputs 
learning small training sample may di cult nonlinear regions functions may sampled adequately small training sample 
number data points necessary adequately sample nonlinear function chapter 

input dimensions grows exponentially number input dimensions worst case 
rarely training data high dimensional spaces fully characterize complex functions 
may di erent models class functions learned similar error particular nite training set 
words free parameters model class set reliably small training sample 
supposition bene computing hidden layer feature inputs 
net learning recognizes tasks share training signals learn better di erent uses yield di erent samples simple functions nets training see high delity error signals hidden layer net may bene training training samples identical 
function inputs little bene internally computing error signals sets inputs 
training patterns di erent samples input space error signals computed internally redundant 
case training net doubles ective sample size improve learning help learned better 
simplest case outputs function di erent training samples trivial case knew relationship better pooling independent samples 
interesting realistic case sampling ampli cation occurs bene di erent complex functions small training sets provide reliable error signals nets learning cases error signals provided redundant sampled training set 
case net learning parallel recognizes share learn better internal model combining error signals backpropagated simplest cases chapter 

simple linear functions common slopes linear relationships estimated data 
small training sample relative complexity estimates imperfect yield di erent error signals points input space 
net learning parallel combine estimates yield improved internal model turn yield improved estimates learned models blocking data ampli cation third form data ampli cation really just extreme form sample ampli cation 
consider tasks common feature computable inputs uses di erent training patterns 
simple example parity functions section instances class 
uses provides information 
conversely provides information 
net learning just gets information training patterns blocked 
net learning time gets information training pattern blocked 
see training patterns gets information pattern 
net learning tasks recognizes tasks share see larger sample experiments blocked functions hard learnable function inputs indicate backprop learn common subfeatures better due larger ective sample size 
eavesdropping consider feature useful tasks easy learn learning di cult learn learning uses complex way 
net learning learn net learning just may 
net learning learns chapter 

eavesdrop hidden layer learned learn better 
connection evolving representation extra information help net learn better relationships 
simplest case eavesdropping abu mostafa calls catalytic hints abu mostafa 
case net told explicitly learn feature useful main task 
eavesdropping causes non monotonic generalization curves tasks eavesdrop tasks 
happens eavesdropper begins nds useful learned task begins perform better starts new information 
attribute selection consider tasks common suppose inputs net function inputs 
net learning limited training data signi cant noise di culty distinguishing inputs relevant tof irrelevant 
net learning better select attributes data ampli cation provides better training signals allows better determine inputs compute 
attribute selection depends data ampli cation 
data ampli cation depend attribute selection problem 
run experiments synthetic problems arti cially create attribute selection problem 
mtl attribute selection mechanism observed comparing magnitude weights input hidden layer relevant input features irrelevant features 
weights relevant features grow quickly net trained mtl 
see section 
representation bias nets initialized random weights backprop stochastic search procedure multiple runs rarely yield identical nets 
consider set nets xed architecture learnable backprop task generalize better better represent domain regularities 
consider regularity learned chapter 

di erently di erent nets 
consider set nets learnable backprop task learns regularity trained net net recognizes tasks share search biased representations near intersection learned 
conjecture representations near intersection better capture true regularity satisfy task domain 
representations backprop best reps form representation bias easier experiment occurs representations sampled tasks represent di erent local minima representation space 
suppose minima net nd task means net learning nd distinct hidden layer representations paths weight space joining distinct representations yield higher training set error local minima 
local minima located surrounded basins attraction error gradient leads minima 
simplicity assume minima task basins attraction similar size 
suppose net learning task local minima attractor basins similar size 
note share local minimum dissimilar located di erent regions weight space 
suppose roughly equidistant origin 
high dimensional weight space 
backprop nets initialized near origin weight space 
backpropagated error signals net trained parallel tend constructively interfere direction directions fact assumption equidistant origin gradients partially cancel gradients average vice versa 
destructive interference partial 
combined gradient hidden layer stronger combined gradient chapter 

net fall representation local minimum little pressure output pull away representation tasks falls attractor basin 
moves reduce error 
supposition local minima near direction 
task learn zero valued weights representation forming hidden layer counter tide deep attractor basin signi cantly ected hidden layer representations learned disjoint 
situation arise bias early search representation share 
ran experiments test 
rst selected minima nets trained equally nd nets trained equally nd nets trained usually fall tasks 
backprop nets outputs tend hidden layer representations tasks 
second experiment selected minima strong preference net trained falls preference trained net falls expected bias unable pull surprisingly usually falls minimum share creates tide hidden layer representation ows away preference subject tide created usually falls ght tide fall backprop nets outputs tend hidden layer representations output outputs tend avoid 
experiments nets su cient capacity nd independent minima tasks 
forced share hidden layer representations 
initial weights random initially share hidden layer separate tasks independent chunks hidden layer task learning causes 
chapter 

tting prevention suppose tasks feature suppose trained point trained isolation 
situations help prevent turn tend prevent tting 
suppose reached point provides gradient continues drive better models tted models 
net recognizes overlap leads sharing hidden layer representation provide pressure tends keep tting 
second situation similar 
suppose depend di erent ways 
ready tting di erently changes ect di erent ways 
share direction reduces error changing raises error result change 
changes allowed lower error conjecture fewer changes available lower error tting tting 
tasks share features tasks 
backprop bene ts relationships tide mentioned discussing representation bias results aggregation error gradients multiple tasks hidden layer 
nets randomly initialized movement hidden layer caused output felt tasks 
random initialization critical mtl backprop 
allows error gradients constructively destructively interfere shared hidden layer biases search trajectory better performing regions weight space 
di erent relationships tasks exploited mechanism easy relationships act concert 
combined ect substantial 
relationship tasks di erent ects learned 
changes architecture representation learning procedure ect may alter way backprop bene ts tasks di erent relationships di erent ways 
particularly chapter 

thy di erence relationships local minima representation bias ects learning nite sample size 
relationships ective nite sample size data ampli cation attribute selection eavesdropping tting prevention bene cial sample size small training signal task provide information net learn models 
peaks functions section task relationships mtl backprop bene 
help set tasks di erent relationships tasks relationships tasks known apriori 
created peaks functions serve purpose 
peaks functions devised set test problems called peaks functions 
peak function form instantiated alphabet fa fg duplication 
functions 


chapter 

variables de ned real interval 
provided inputs backprop net learning peaks functions 
values net encoding simple continuous inputs 
net learning peaks functions learn functions learn properly decode input encodings 
encoding inputs inputs inputs altogether 
shows input representation peaks functions 
variable inputs 
gaussian peak standard deviation height centered real value variable code value 
coded input values input bit position input representation peaks functions generate synthetic data peaks problems uniformly sampling values variables interval 
numbers coded input encoding 
gives real valued inputs net code input variables 
set values compute function values functions 
synthetic domain de ned reals generate data want 
relatively small training sets keep learning interesting problems learned perfectly backprop large training samples 
chapter 

relatedness peaks functions depends variables common variables way 
example share variables related 
shares variables way moderately related 
shares variables variables way 
related 
run experiments peaks functions ll book 
consideration reader results interesting experiments 
experiment rst experiment demonstrates mtl ective peaks functions 
trained strongly related peaks functions mtl net compared performance stl net trained time 
peaks functions de ned variables strongly related functions de ned subfeatures 
nets inputs inputs codings variables shows graphs 
left graph test set training curves task 
right graph task 
graph shows performance stl task mtl additional copies task outputs net receive training signals mtl task trained strongly related peaks tasks listed 
training sets contain training patterns peaks functions carefully tweaked adjusting input representations chapter 

stl mtl copies mtl related tasks stl mtl copies mtl related tasks generalization performance stl mtl copies task mtl strongly related tasks left right 
vertical axis rms error test set 
lower error indicates better performance 
horizontal axis passes 
graph best performing curve mtl strongly related tasks 
left graph mtl copies performs better stl right graph stl performs slightly better copies 
complexity boolean function combines input terms reasonable performance obtained training sets small cases making practical run experiments 
test sets contain cases 
note graphs average multiple runs 
results single trials 
examined training curves additional runs insure behavior typical 
vertical axis root mean squared error test set 
zero error perfect generalization 
clear graphs stl performs poorest 
training net copies task improves performance 
training mtl net strongly related peaks tasks yields best performance 
mtl works peaks tasks tasks related 
chapter 

experiment section trained strongly related peaks functions mtl net observed better generalization 
happens train strongly related peaks functions completely unrelated peak function mtl net outputs 
related tasks bene unrelated sixth task see bene tasks 
generalization performance strongly related functions compared performance completely unrelated function trained mtl net 
shows test set training curves tasks trained mtl net 
tasks 
strongly related 
sixth task 
share features 
lower error indicates better generalization 
clear graph related tasks bene 
task related tasks bene fact performance task somewhat worse trained stl net 
training tasks hurts 
results experiment provide strongest evidence chapter 

bene ts mtl depend tasks related 
evidence strong fact output distributions peaks functions identical 
training signals peak function value variables variables drawn uniformly interval 
distribution 
changing peaks functions trained net ect distribution outputs 
shu test peaks function learnable inputs peaks function 
shu ing maintains output distributions shu ed functions harder learn destroys relationship inputs task signals shu ed function 
experiment convincingly demonstrates bene see mtl due relationships tasks trained mtl net 
experiment experiment compares generalization performance stl mtl strongly related peaks functions function number training patterns training set 
experiment run joseph sullivan 
peaks functions explore combining mtl explanation neural nets ebnn serial inductive transfer method developed mitchell thrun 
see section information ebnn results experiment run sullivan compare mtl ebnn robotics task 
shows test set performance stl mtl task 
measure average percent accuracy prediction task 
error bars con dence intervals 
number training patterns low methods perform comparably 
number training patterns increases mtl begins outperform stl 
region training patterns mtl performs stl data 
stl performs cases training set room mtl better 
chapter 

percent error test set multitask learning single task learning size training set generalization performance stl mtl function number training patterns 
feature selection peaks functions peaks functions demonstrate mtl backprop bene relationships tasks described earlier section 
section demonstrate feature selection mechanism described section 
feature selection allows backprop better di erentiate relevant irrelevant inputs tasks learned 
trained stl mtl nets strongly related tasks experiment 
stl net trained task time 
tasks functions inputs code inputs coding nets irrelevant tasks 
training measured sensitivity learned di erent sets inputs 
computing average derivative output input input vectors large test set 
inputs computed derivatives point test set 
average derivative tells sensitive output changes input 
averaged absolute value chapter 

sensitivities inputs inputs gives average sensitivity learned relevant irrelevant inputs 
plots average sensitivities di erent groups inputs stl left mtl right 
sensitivity inputs increases number backprop passes 
expected 
backprop poor job keeping weights low irrelevant inputs 
reasons tting problem backprop 
graphs sensitivity relevant inputs increases faster sensitivity irrelevant inputs 
relative sensitivity relevant vs irrelevant inputs grows faster mtl net stl net 
mtl net better job determining inputs relevant 
stl inputs stl inputs mtl inputs mtl inputs average sensitivity inputs average sensitivity inputs backprop passes backprop passes sensitivity stl left mtl right inputs coding inputs coding relevant inputs functions trained 
graphs demonstrate mtl helps prevent tting 
sensitivity inputs levels nearly passes mtl 
stl net poorer distinguishing sets inputs rapidly increasing sensitivity inputs passes 
stl net tting mtl net 
chapter 

backprop mtl discovers tasks related section relationships tasks mtl backprop nets exploit learn tasks better 
section frequently phrase net learning recognizes tasks share training signals learn better 
mtl nets told tasks related 
told tasks share di erent tasks 
mtl backprop nets discover tasks related 
clearly 
shown synthetic problems bene mtl backprop depends tasks related 
tasks related relationship tasks broken shu ing training signals bene mtl backprop disappears 
bene mtl backprop depends exploiting task relationships mtl backprop nets discover relationships tasks 
told tasks related 
backprop nets primarily supervised learning perform limited kind unsupervised learning hidden layer features learned di erent tasks di erent outputs 
details unsupervised learning occurs works fully understood 
worthwhile demonstrate backprop discover task relatedness 
trained mtl net peaks functions 
net inputs outputs peaks functions 
examined weights see di erent outputs shared hidden layer 
sensitivity analysis output hidden unit input points contained representative test set 
outputs hidden units sensitivity analyses 
comparing sensitivity output hidden unit output hidden unit able measure outputs share hidden units hidden layer 
compare sensitivity di erent outputs hidden units rst ranking hidden units output sensitivity 
hidden units important output ranked higher 
compare di erent outputs share hidden layer computing rank correlation rankings obtained di erent hidden units 
rank correlation nonparametric measure similar correlation 
way compute chapter 

rank correlation compute ranks measurements independently compute usual continuous correlation coe method formula cient ranks 
simpler xi yi xi rank assigned value yi rank assigned value 
non parametric rank correlation uncertain distributions sensitivities 
rank correlations behave similarly regular correlations 
value indicates rankings agree perfectly avalue indicates rankings disagree perfectly value indicates rankings related 
output tasks net 
pair tasks compute degree sharing rank correlation procedure described 
rank correlation tasks agree disagree hidden units important important 
expected value rank correlation random tasks hidden layer contains hidden units 
rank correlation signi cantly greater indicates tasks sensitive hidden units 
hidden units important task important 
words tasks share parts hidden layer 
rank correlation indicates hidden units important task important vice versa 
anti correlation means tasks di erent parts hidden layer 
overlap expected chance 
tasks pairs tasks 
computed degree sharing pairs tasks 
try show raw correlations pairs tasks summarize results computing average rank correlation tasks related di erent ways 
example pairs tasks features common 
pair pairs tasks exactly feature common 
pair chapter 

similarly pairs tasks features common 
pair pairs tasks features common 
pair compute average degree sharing groups tasks 
expectation groups contain related tasks higher average degree sharing groups containing related tasks 
shows average degree sharing tasks function related groups de ned 
graph data point features common compares tasks having features common share hidden layer 
data points features common show degree hidden unit sharing tasks exactly features features necessarily places tasks 
line labelled feature disregards position features tasks 
tasks feature common common feature way 
line labelled test match requires feature conditional test 
tasks feature common feature feature conditional 
general trend lines tasks share hidden units related 
small negative correlation tasks share variables suggests complete lack relatedness functions leads anti correlated sharing outputs unrelated functions tend di erent hidden units 
tasks sensitive hidden units tend somewhat randomly sensitive chapter 

feature test match rank correlation hidden units number features common sharing hidden layer function similarity tasks 
tasks related share hidden units 
remaining hidden units expect see strong negative rank correlations unrelated tasks hidden layer large 
negative correlation observed small statistically signi cantly di erent 
don show con dence intervals graph small see 
net capacity tightly constrained usually hurts performance tasks unrelated tasks tend act randomly related tasks correlations near zero anti correlated tasks negative correlations 
correlations test match line higher correlations feature line 
thing lines di erent test match line contains pairs tasks share feature conditional 
suggests overlap conditional test important hidden layer sharing overlap part tasks 
degree sharing test match line task relatedness score equals tells interesting 
section synthetic test functions show tasks uncorrelated related ways backprop chapter 

mtl bene 
feature pair functions matches test match feature common test 
data point represents pairs functions mentioned section distributions variables 
means distributions 
sampled randomly correlation correlation 
means correlation task pair tasks group 
tasks group related share variable conditional test 
training kinds tasks improve performance shows degree sharing tasks substantial 
section showed task correlation necessary mtl bene shows degree sharing tasks high despite uncorrelated 
shows average degree sharing di erent groupings tasks 
di erences gure 
groups groups 
tasks placed rst groups groups procedure initialize group similarity score 
add feature common tasks di erent places 
add feature clause tasks feature place 
add feature conditional part task suggests sharing conditional feature important sharing features 
maximum score pair achieve 
requires feature conditional test match features feature place 
tasks identical maximum score achieve points overlapping conditional points overlapping chapter 

rank correlation hidden units score number features common sharing hidden layer function similarity score tasks 
see text score computed 
score pairs identical tasks trained net 
features 
group di erence figures 
trained mtl net peaks tasks tasks training copies task net 
outputs trained task mtl net know output tasks copies 
groups score pairs identical tasks trained di erent outputs 
relationships peaks functions examine 
example looked degree sharing tasks share conditional feature tasks features place 
relationship peaks functions examined degree sharing positively correlated hidden unit sharing 
suggests peaks functions backpropagation shared hidden layer able discover tasks related hidden layer features explicit training signals task relatedness 
backprop mtl discovers relationships tasks constructive destructive interference error gradients summed shared hidden layer 
chapter 

nal note leaving peaks functions experiments restricted peaks functions functions feature 
allow functions interesting run experiments possible peaks functions 
part interesting functions directly map coded inputs unencoded output values 
kind function serve strong hint net help net learn decode inputs complexity learn boolean function combines variables time 
related revisited thesis purport propose general theory general mechanisms inductive transfer 
scope thesis inductive transfer performed training related tasks parallel shared representation 
backprop nets shared representation hidden layer shared outputs 
learning procedures shared 
nearest neighbor distance function shared 
decision trees splits shared 
mtl algorithms devise de nition relatedness 
multitask learning backprop nets de nition tasks related backprop mtl correlation positive negative training signal task correctly backpropagated errors task training signals learned hidden layer task trained 
important fact correlation learning necessarily mean mtl bene 
algorithm kinds correlation may hurt performance helping 
theory expect correlation task hidden layer representation improve note net necessarily learn complete representation tasks coding input hidden layer output weights hidden layer output shared tasks learn model 
chapter 

performance correlation suggests extra signal provides additional information 
theory practice agree 
deal imperfect learning procedures going correlations learned theory help learning practice hurt learning 
part problem deal small data sets apriori information nature relationships tasks 
means correlations discovered small data set process fraught uncertainty error 
chapter summary section reviewed showing mtl helps learning tasks related 
section discussed basic properties related tasks 
backprop mtl bene related tasks tasks related having overlapping sets relevant input features able share hidden units 
tasks functions di erent inputs help backprop mtl 
surprisingly able show related tasks need correlated 
section relationships tasks backprop net trained multiple tasks exploit learn tasks better 
relationships statistical data ampli cation sampling data ampli cation blocking data ampli cation attribute selection eavesdropping representation bias tting prevention 
relationships improve learning constructive destructive interference error gradients summed shared hidden layer 
easy mechanisms act concert 
section introduced peaks functions set problems designed serve test bed inductive transfer algorithms 
experiments peaks functions provides solid evidence bene backprop mtl due relationships tasks 
section opened mtl net trained peaks functions showed tasks related share hidden layer 
part result interesting backprop mtl explicit training signals tasks related 
discovers task relationships form unsupervised learning clusters tasks similarity hidden chapter 

layer representation learned 
heretofore unrecognized capability backpropagation plan investigate 
section proposed heuristic de nition relatedness 
tasks related inductive transfer correlation learned task loss function applied training signals task 
chapter presents dozen cases real world tasks satisfy heuristic 
half trick nding clues knowing re 
sherlock holmes chapter chapter number mechanisms allow backprop bene di erent kinds relationships tasks attempted de ne relatedness 
practice important able nd useful related tasks able de ne precisely related task chapter designed help recognize related tasks real world problems 
training data useful extra tasks available 
chapter shows real world problems opportunities multitask learning 
important doesn matter multitask learning works won applicable problems real world 
chapter presents dozen prototypical applications multitask transfer training signals related tasks available leveraged 
prototypical application described concrete examples described 
cases empirical data sample problems 
believe real world problems fall domain types 
claim sound surprising test problems traditionally machine learning multitask problems 
believe problems traditionally machine learning heavily preprocessed mtl eliminated learning attempted 
stl opportunities chapter 
simplest chapters thesis 
important 
chapter shows opportunities mtl real world problems potentially useful extra tasks available di erent kinds domains 
predict valuable features available predictions 
features inputs available run time 
learning done ine collected training set extra mtl tasks 
predictions learner extra tasks ignored system 
sole function provide extra information learner training 
application learning medical risk evaluation 
consider pneumonia risk problem section 
patient diagnosed pneumonia 
measurements available patients 
include basic measurements acquired prior hospitalization age sex pulse lab tests blood counts blood gases hospital 
useful tests assessing risk lab tests available patient 
table shows improvement performance obtained domain lab measurements extra outputs shown 
table gure table stl mtl errors pneumonia risk fop stl mtl change measurements available ine learning problems added training set fact 
di erent example robot autonomous vehicle accurately measure size location identity objects passes near 
example road stripes edge road de chapter 
mortality rank white blood cell count potassium labs rankprop output 
output layer 
shared hidden layer 
input layer age sex chest pain heart inputs lab results extra outputs bias learning reliably vehicle passes alongside detecting far ahead vehicle hard 
driving brings road closer car stripes road borders measured accurately passed added training set 
inputs available time driving 
seen alvinn extra tasks kind extra mtl outputs provide extra information help learning requiring available run time 
measurements extra output tasks probably frequent sources extra tasks real problems 
multiple metrics hard capture important error metric output representation 
alternate metrics representations capture di erent useful aspects problem mtl bene 
example mtl di erent metrics pneumonia domain section 
error metric called rankprop see appendix designed specifically tasks important order instances correctly 
rankprop outperforms backprop traditional sse problem 
rankprop trouble learning rank cases virtually patients survive 
rankprop outperforms sse low risk patients di culty learning stable rank 
chapter 
interestingly sse best cases high purity regions feature space cases low risk 
sse di culty regions similar cases di erent outcomes 
sse best rankprop weakest 
suppose add additional sse output network learning predict risk rankprop 
table adding extra sse task rankprop fop sse sse change adding extra sse output expected ect 
lowers error rankprop output low risk slightly increasing error high risk 
table shows results rankprop adding extra sse output 
note extra output completely ignored predicting patient risk 
added solely provides useful bias net training 
examined combining extra output predictions rankprop output yield improvements 
earliest example multiple output representations know weigend uses sse cross entropy outputs task 
multiple output representations apparent output encoding problem 
alternate codings main task extra outputs way alternate error metrics 
example sigmoid output units outputs interval clear boolean task values represented values force sigmoid output units extreme values 
reason believe di erent sets output values yield di erent bene ts mtl achieve bene ts output representations time 
train multiple outputs mtl net code boolean output third 
chapter 
combine multiple outputs addition voting select whichever output appears perform best 
reason improve performance output trained representation learns separate classes output driven learn nonlinear mapping 
output learn separate classes may prone learning unnecessarily nonlinear mappings 
learning models strongly distinguish di erent classes usually 
learning nonlinear functions 
mtl provides way bias backprop net try accomplish objectives 
similar reasoning applied cases polar cartesian output representations problems involving spatial recognition 
radius angle may easily represent regularities problem coordinates may easily represent regularities 
coordinate systems redundant 
output representation su cient 
learning improved representations mtl net 
example distributed output representations help parts problem learned parts separate error gradients 
prediction requires outputs distributed representation correct non distributed representation accurate 
mtl way merge con icting requirements net 
example consider problem learning classify face faces 
output representation problem output persons net supposed recognize 
output representation train net set face features su cient classify faces 
features beard beard glasses glasses long hair short hair bald hair color red white brown black eye color blue brown male female easy imagine set features su cient correctly classify individuals 
correct classi cation require feature correctly predicted 
features may di cult predict high accuracy 
non distributed output representation uses output individual may reliable average 
training recognition net recognize speci traits help training 
mtl allows output representations problem representation prediction 
chapter 
redundant output representations interesting issue outputs nal prediction 
better accuracy achieved combining predictions redundant representations choosing representations 
issue orthogonal mtl principle goal provide mechanism improving accuracy representations 
similar accuracy achieved redundant output representations suspect accuracy improve combining predictions 
possible optimize performance output representations expense representations better performance achieved better performing representation 
combining predictions desirable multiple independent mtl nets trained predictions combined net possibly optimized perform representation time 
see chapter 
discussion optimize mtl nets task time 
interesting related approach multiple alternate output encodings problem error correcting codes dietterich bakiri 
approach multiple encodings outputs designed predictions multiple outputs combined combined prediction sensitive occasional errors outputs 
clear time error correcting codes bene mtl mechanisms 
fact ecoc methods may bene trained stl nets mtl nets di erent outputs share hidden layer correlated predictions 
time series prediction applications type subclass predict tasks identical current task occur time 
large subclass deserve special attention 
additional knowledge tasks identical current task allows additional structure brought bear mtl approaches problems 
simplest way mtl time series prediction single net chapter 
multiple outputs output corresponding task di erent time 
output refers prediction time series task time tk net predictions task di erent times 
performance obtained output prediction middle output temporally tasks earlier trained net 
tested mtl time sequence data robot domain goal predict sensory states current sensed state planned action 
interested predicting sonar readings camera image sensed meters current sonar camera readings meters 
shows mtl architecture problem 
robot moves collects stream sense data 
strictly speaking sense data time series robot moves constant speed 
dead reckoning determine distance robot traveled data described spatial series 
sonar ring horizontal camera stripe meter meters meters meters 
inputs predicting temporal sequence sense measurements mtl backprop net sets outputs 
set predicts sonar camera image sensed distance 
output set prediction chapter 
meter set meters set meters set meters 
performance net prediction distance compared table stl nets learning predict distance separately 
entry sse averaged sense predictions 
error increases distance mtl outperforms stl distances meter 
table stl mtl sse sensory prediction meters stl mtl change loss accuracy meter statistically signi cant 
conjecture pattern data may common 
mtl may help harder predictions possibly expense easier predictions 
insurmountable problem 
known true stl shorter term predictions mtl harder longer term predictions 
note shorter term predictions mtl net longer term predictions may provide bene longer term predictions 
goal mtl extra tasks available help main task performance extra tasks important worse mtl 
non operational features features impractical run time 
expensive compute need human expertise won slow 
training sets small usually luxury spend time preparing 
practical compute non operational feature values training set may extra mtl outputs 
example scene analysis human expertise required label important features 
usually human loop learned system 
mean features labelled humans learning 
labels acquired training set extra chapter 
tasks learner features extra tasks required system 
example doors domain section 
mouse de ne features images doorways collected robot mounted camera 
main tasks horizontal location doorway center 
extra features created just give backprop net information 
human manually de ne features inputs 
human de ne features robot operating autonomously 
human process image de ne training signals location doorway center main tasks easy collect additional features time training set 
extra tasks employed horizontal location horizontal location doorway center horizontal location left door jamb width left door jamb horizontal location left edge door single double door width doorway horizontal location right width right horizontal location right edge door extra tasks helped mtl learn main tasks 
see section information domain 
domains human labelled data available training sets available trained system 
examples include hand labelled images hand labelled text data hand labelled medical data hand labelled acoustic speech data hand labelled features main focus learning may extra output tasks potentially bene tasks focus learning 
extra tasks focus attention learning learns large ubiquitous patterns inputs ignoring small common inputs useful 
mtl coerce learner attend patterns input ignore 
done forcing chapter 
learn internal representations support related tasks depend patterns 
example road 
stl nets ignore lane markings learning steer lane markings usually small part image constantly changing di cult see humans poor lighting wear 
net learning steer required learn recognize road stripes net learn attend parts image stripes occur 
extent stripe tasks learnable net develop internal representations support 
net learning steer hidden layer steering task parts stripe hidden representation useful steering 
section road image simulator developed pomerleau generate synthetic road images 
main tasks predict steering direction location center road 
extra tasks related centerline mtl road lanes 
horizontal location centerline meters ahead intensity centerline performance bene mtl extra tasks shown section 
easy analyze net trained alvinn see learned centerlines 
ran experiment stl mtl nets trained steering alvinn test important images stl mtl nets 
data generated simulator able eliminate stripes generated road images test set training data contains 
replaced image grey levels surrounding road 
mtl learned stl uses learned main steering task expect see steering performance degrade mtl stl remove images 
images removed error increased factor stl nets error increased factor mtl nets 
mtl performance main steering task sensitive presence image chapter 
presumably extra tasks trained mtl net coerce net learn 
tasks hand crafted domain expert experts excel applying expertise poor codifying 
learning algorithms poor incorporating unstructured advice experts learning examples 
mtl way collect domain speci inductive bias expert give learning procedure capitalizing strengths 
having domain experts de ne helper tasks convenient way human expertise bias learning 
extra outputs extra error terms applied existing outputs provide hints anns documented abu mostafa 
example hints extra tasks help net learn desired properties monotonicity symmetry 
example want relationship household income maximum size loan safely awarded household rise monotonically income things equal 
hints provide way biasing net learn models satisfying condition 
done constructing carefully designed extra tasks easily accomplished applying additional error terms penalize nonmonotonicity output main task 
handling categories classi cation consider problem digit recognition 
classi cation problem goal label input images classes 
real world applications digit recognition common images classi er digits 
example images containing alphabetic characters punctuation marks classi er 
want classi er accidentally classify digit 
common way help prevent create additional category called correct classi cation images contain digits 
mtl provides better way 
consider large variety characters mapped class 
diversity need chapter 
classi er allow images legal digits confused class learning class di cult 
throwing di erent images class learning class potentially di cult 
better approach split class separate classes individual characters trained parallel main digit tasks 
breaking separate tasks separate mtl tasks net better chance learning discriminate digits non digits 
lecun private communication sequential transfer mtl parallel transfer 
sequential transfer pratt mostow pratt sharkey sharkey thrun mitchell thrun easier 
may case 
advantages parallel transfer full detail learned tasks available tasks tasks learned time 
applications extra tasks available main task learned 
parallel transfer require choose training sequence order tasks trained usually signi cant impact serial transfer 
tasks bene mutually linear sequence capture 
task learned task task help task 
reduces performance task reduce task ability help task 
sequential transfer bene prior learned tasks re trained probably best done parallel method 
chapter see important optimize mtl technique favor performance main task expense worse performance extra tasks 
di cult perform optimization extra tasks learned xed 
tasks arise serially prudent tasks learning 
cases straightforward necessarily computationally chapter 
cient parallel transfer sequential transfer 
training data stored perform mtl tasks available re learning new tasks new data arise 
training data stored models learned previous data longer available synthetic data generated models learned extra training signals 
approach sequential transfer avoids serious problem catastrophic interference forgetting old tasks learning new ones 
applicable analytical methods evaluating domain theories serial transfer methods pratt thrun mitchell available 
example domain theory need di erentiable inspectable 
merely needs able prediction 
tested synthetic data approach problems 
performance indistinguishable having original training data prior models learned accurately 
interestingly performance degrade rapidly prior learned models accurate mtl nets ected noise extra outputs stl net amount noise inputs 
see section thorough discussion di erence 
issue arises synthesizing data prior models distribution sample 
distribution training patterns current task 
pass input features current training patterns prior learned models predictions models extra mtl outputs learning new main task 
sampling may satisfactory 
learned models complex suggesting large sample needed represent high delity new sample training data small bene cial sample prior model points current sample 
see craven shavlik thorough discussion synthetic sampling 
interesting note relatively straightforward parallel transfer serial transfer easy serial transfer parallel transfer 
important note possible combine serial parallel transfer get bene ts 
sullivan mitchell currently doing research methods combine mtl ebnn life long learning robots 
chapter 
multiple tasks arise naturally world gives sets related tasks learn 
traditional approach separate independent problems trained isolation 
counterproductive related tasks bene trained 
early accidental multitask transfer anns nettalk sejnowski rosenberg 
nettalk learns phonemes stresses give pronounce words inputs 
nettalk net outputs partly goal control synthesizer needed phonemes stresses time 
analyzed contribution multitask transfer nettalk evidence nettalk harder learn separate nets dietterich hild bakiri 
example multiple tasks arising naturally mitchell calendar apprentice system cap dent mitchell 
cap goal learn predict location ime day day eek duration meetings schedules 
tasks functions data share common features 
early results mtl decision trees domain suggest mtl outperforms stl 
similar tasks di erent data distributions instances virtually problem distribution instances data sampled di er instantiation 
example hospitals diagnose treat pneumonia patients demographics patients hospital serves may di erent 
hospitals florida may see older patient populations urban hospitals may see poorer patient populations access health care hospitals san francisco may see aids patients rural hospitals may see fewer aids patients predictive models learned hospital accurate hospital models learned hospital 
medicine cases hospitals 
may possible collect large training sample hospital 
rural hospital see fewer cases pneumonia year year cases may aids related 
year chapter 
hospital see aids related cases 
clearly pneumonia prediction hospital california strongly related problem pneumonia prediction hospital wyoming 
probably suboptimal pool data hospitals learn model predictions hospitals 
mtl provides solution problem 
pneumonia prediction hospital hospital hospital hospital 
symptoms predicting problem di erent hospitals mtl consider mtl backprop net shown 
net takes patient histories symptoms lab tests inputs 
outputs 
output predicts medical condition pneumonia risk di erent hospital 
may training cases hospital cases hospital cases hospital cases hospital 
note patient training case hospital 
means target value output input vector 
backpropagation done mtl net errors backpropagated output target value input vector 
outputs share hidden layer representation learned hospital prediction model available hospital models 
hospitals bene larger pneumonia populations seen hospitals 
chapter 
model learned hospital necessarily models learned hospitals 
hospital bene learned hospital models constrained model 
output hospital model di erent hidden output weights trained patient population hospital 
tasks presumably strongly related features may develop hidden layer useful hospitals 
domains multiple instances strongly related problems instance problem di erent pooling data inappropriate 
collecting su cient data learn models instance problem may impractical 
mtl provides approach sharing data collected problems committing strong sharing results pooling data 
domains type include learning steer di erent types cars cars di erent types tires cars driven di erent types roads di erent countries 
learning control multiple manufacturing process control lines manufacturing line composed similar equipment processes similar jobs 
learning quantized noisy data suppose main task wish predict variable heavily quantized polluted noise 
quantization process takes variable distinct values re represents values 
example temperature continuous variable process quantize continuous variable discrete values cold warm hot 
quantization type common human judgment part measurement process 
quantization di cult train model predict quantized variable measurements system 
quantization represents instances similar di erent classi es instances di erent similar 
example temperatures degrees degrees classi ed warm degrees classi ed hot 
abrupt change quantized chapter 
function learning hard requiring model relatively degrees sharp transition degrees 
quantization map similarity input space similarity output space 
quantized task correlates variable training extra task mtl net help main quantized task 
di erent example consider stochastic process converts probability outcome 
medicine example rarely know probability adverse outcome patients 
collect training set consisting patients whichwe know adverse outcome happened 
know original probability outcome patients outcome 
system learning predict outcomes new patients great di culty outcome higher high risk patients low risk patients 
example suppose high risk patients positive outcome probability low risk patients outcome probability 
high risk patients twice probability positive outcome low risk patients 
large training set patients positive outcomes low risk cases vast majority cases negative outcome 
learning distinguish high risk low risk cases class noise di cult reason quantization learning di cult 
patients virtually identical symptoms may erent outcomes patients dissimilar symptoms may outcomes 
similarity input space mapped similarity output space random process 
quantization tasks disrupted random sampling extra outputs mtl net aid learning main task 
observe pneumonia domain 
patient probability risk unknown 
know patient lived died 
tasks hospital duration admission icu doctor assessment patient risk point scale low medium high help guide mtl net assess risk better 
hospital stay particularly interesting extra task long stays indicators higher risk short stays may due low risk causing patient discharged high risk causing patient die 
relationship tasks help may complex 
chapter 
learning hierarchical data classi cation domains admit structuring classes semantic hierarchy 
example classi cation living things species usually treated hierarchical classi cation problem descends hierarchy classes subclasses 
examples 
vehicles classi ed hierarchy 
documents library usually classi ed hierarchically 
considerable manual ort gone hierarchically classifying documents web yahoo 
hierarchy 
surprisingly applications machine learning data hierarchically classi ed little hierarchical information 
mtl provides way exploiting hierarchical information 
training classi er class distinctions particular point hierarchy include extra tasks classi cation tasks arise ancestors descendants current classi cation task 
example training backprop net distinguish student faculty web pages department extra tasks mtl net require net distinguish associate professor full professor research faculty descendant tasks extra tasks require net distinguish undergraduate graduate students descendant tasks extra tasks require net distinguish di erent departments university academic institutions ancestor tasks 
way accomplish train mtl net predict class distinctions total hierarchy 
outputs beat inputs sections chapter domains impractical features inputs available time expensive compute require human expertise 
cases mtl provides way bene ting features ignoring extra tasks 
domains contain features inputs useful extra outputs 
cases features harmful inputs helpful outputs 
cases feature useful input useful extra output 
application mtl surprising chapter 
potentially ubiquitous dedicate chapter 
chapter summary chapter shows domains potentially useful extra tasks available 
contributions thesis show di erent kinds extra tasks mtl 
list prototypical domains provided chapter complete 
con dent types extra tasks identi ed 
chapter inputs better extra outputs previous chapter di erent domain types training signals extra tasks available 
chapter presents source extra tasks may ubiquitous 
chapter show bene cial move features normally inputs input side backprop net output side net extra tasks mtl 
supervised learning usually clear distinction inputs outputs inputs measure outputs predict measurements 
mtl blurs distinction features useful extra outputs inputs 
feature output get just case values learn mapping inputs feature 
longer access case values doing prediction mapping learned mtl net case values training set 
features mapping may useful feature value 
section regression problems classi cation problem performance improves features inputs extra outputs 
section uses synthetic problems carefully constructed show material chapter joint virginia de sa 
chapter 
inputs better extra outputs ect clear features better extra outputs inputs 
problems section synthetic carefully designed demonstrate features useful extra outputs input 
real world problems features useful extra outputs 
determine features useful extra outputs 
section demonstrate features real world problems better extra output tasks 
section feature selection determine features inputs treat remaining features inputs candidates extra output tasks 
results sections clear features help learning input features help learning extra outputs 
possible features inputs extra outputs time accrue bene ts 
section mtl architecture able achieve bene ts features inputs extra outputs net 
demonstrate approach synthetic problems section 
promoting poor features supervisors goal supervised learning learn functions map inputs outputs high predictive accuracy 
standard practice neural nets features available test cases inputs outputs features predicted 
mtl shows instance attributes outputs useful 
input output inputs useful outputs 
surprisingly 
ective give information backprop net output input 
features useful harmful inputs extra outputs 
demonstrates bene ts outputs di erent bene ts inputs 
section presents synthetic problems better features extra outputs inputs 
basic approach synthetic problems move features output side mtl net noisy poorly correlated chapter 
inputs better extra outputs main task helpful inputs 
outputs bias learning input hidden layer weights 
leads shared hidden layer develop useful features improving performance main task 
problems simple functions input variables 
input variables encoded task challenging 
extra features chosen inputs properly decoded little bene extra features inputs 
information extra features redundant regular inputs 
extra features coded regular input variables 
potentially easier learning extra features encoded regular inputs 
extra features noisy tradeo ease learning uncoded extra features problems created noise features 
section uses regression problem section feature correlation main task useful input 
underlying subfeatures depends main task useful extra output 
section presents similar regression problem features useful inputs noise low harmful inputs noise increases 
noise di erent ects inputs outputs features remain useful extra outputs noise harmful inputs 
section presents binary classi cation problem information extra input feature unnecessary optimal class boundary provably independent feature 
extra feature correlates input features class boundary de ned helps classi cation 
adjusting problem de ned way able create variations bene extra feature greatest extra output extra input 
section discusses issues common problems 
chapter terms main task output learned 
goal improve performance main task 
regular inputs features provided inputs experiments 
regular inputs inputs outputs 
extra inputs extra features inputs 
extra outputs extra features extra outputs 
chapter 
inputs better extra outputs poorly correlated features section presents simple synthetic problem easy see feature extra output better feature extra input 
problem section show tasks need correlated useful mtl 
consider function sigmoid sigmoid stl net inputs hidden units output 
backpropagation net learn 
data generated uniform random sampling interval 
inputs network binary coding range discretized bins binary code resulting bin number input coding 
rst input units receive code second receive code target output unary real unencoded value 
stl main output fully connected hidden layer binary inputs coding binary inputs coding stl architecture learning regular inputs 
backpropagation done epoch updating early stopping 
trial uses new random training halt test sets 
training sets contain patterns 
data get performance room improvement 
large halt test sets cases minimize ect sampling error measured performances 
halt test sets containing cases yield similar chapter 
inputs better extra outputs results 
table shows mean performance trials stl regular inputs trained backpropagation early stopping 
table mean test set root mean squared error network trials mean rmse signi cance stl stl ns mtl consider similar function sigmoid suppose addition bit codings unencoded unary value extra input feature 
extra input help learn better 
probably 
correlate random correlation coe cient training sets typically 
knowing value tell target value vice versa 
shows scatter plot vs large sample randomly generated values poor correlation hurts backprop ability learn predict 
stl net shown inputs binary codes extra input 
second line table shows performance stl training halting test sets stl di erence extra input feature data sets stl 
note performance stl signi cantly di erent stl extra information contained feature help backpropagation learn extra input 
help backpropagation learn input ignore altogether 
strongly related 
note correlate ja bj just 
knowing information 
unfortunately backprop usually needs correlation inputs current output errors bene inputs 
chapter 
inputs better extra outputs scatter plot vs shows correlation 
bene decoding binary input encoding compute subfeatures extra input extra output trained backpropagation bias shared hidden layer learn better help net learn predict better 
shows net inputs outputs 
error back propagated outputs performance net evaluated output early stopping done performance output 
third line table shows mean performance stl main output fully connected hidden layer binary inputs coding binary inputs coding extra input stl architecture learning regular inputs plus extra input 
chapter 
inputs better extra outputs mtl main output extra output fully connected hidden layer binary inputs coding binary inputs coding mtl architecture learning extra task regular inputs 
trials mtl net 
extra output improves performance 
extra feature extra output better extra input 
output just individual output values learn extract information function mapping inputs 
key di erence features inputs outputs 
help extra output 
bene computing features inputs hidden layer gradients backpropagated outputs constructively reinforce directions weight space lead shared features 
extra information contained training signal biases shared network representation features useful 
noisy features section presents problems extra features useful inputs useful outputs noise increases 
extra features ideal features problems demonstrates observed previous section depend extra features contrived correlation main task low features high correlation main task training signals useful outputs 
chapter 
inputs better extra outputs problem consider main task previous section sigmoid consider extra features ef noise scale noise ef noise scale noise features ef ef encoded noise noise uniformly sampled 
noise scale large ef ef excellent input features learning net avoid learning decode binary input representations coding needs learn add new inputs ef ef 
noise scale increases ef ef useful better net learn binary inputs try extra features extra inputs extra outputs 
training sets patterns halt test sets patterns 
ran preliminary tests nd best net size 
results showed hidden units optimal stl nets early stopping problem 
plots average performance trials stl extra inputs mtl features extra outputs noise scale varies 
performance stl regular inputs ef ef shown horizontal line independent noise scale 
rst examine results stl ef ef extra inputs 
expected noise small ef ef extra inputs improves performance considerably 
noise increases improvement decreases 
eventually noise ef ef longer help net inputs 
noise increases ef ef extra inputs hurts performance 
noise gets large performance asymptotes back performance obtained extra features 
ef ef extra outputs yields quite di erent results 
noise low help extra inputs 
noise increases chapter 
inputs better extra outputs test set rmse stl mtl stl feature noise scale performance stl regular inputs stl extra input mtl extra output task 
point help extra outputs extra inputs hurt performance way noisy extra inputs 
noise scale greater better extra feature extra output input 
noise cause stl extra inputs perform worse stl inputs 
nite training sample correlations sample noisy inputs main task cause network noisy inputs 
extent main task function noisy inputs pass noise output causing output noisy 
net comes depend noisy inputs depends noise free binary inputs 
noisy inputs explain away training signal available encourage learning decode binary inputs 
noise extra outputs hurt mtl noise extra inputs hurts stl 
outputs net learning mapping regular inputs ef ef 
early training net learns interpolate noise learns smooth functions ef ef reasonable delity chapter 
inputs better extra outputs true mapping 
learning sensitive noise added features 
problem mildly nonlinear go far tails sigmoid 
results depend smoothness 
check modi ed nonlinear 
consider function sigmoid expand sigmoid sigmoid expand scales inputs sigmoid sigmoid range drawn 
signi cantly nonlinear expanded scales expanding di erence passing sigmoid cause data fall tails inner outer sigmoids 
consider extra features ef sigmoid noise scale noise ef sigmoid noise scale noise noises sampled 
shows results extra features ef ef extra inputs extra outputs 
trend similar bene mtl extra outputs larger low noise 
blow region probably interest real problems shown left graph 
similarity graphs raise concern behavior seeing artifact problems aspect trained 
similarity graphs due ubiquity phenomena 
data sets experiments generated di erent seeds 
rst experiment run steepest descent mitre aspirin simulator 
second experiment conjugate gradient toronto simulator 
functions similar de nitions suggest expanding range easy shift graphs stl extra inputs mtl relative changing functions sampling distributions 
example sampling values closer sigmoid sigmoid smaller sensitive input noise 
shifts tradeo point stl extra outputs mtl lower noise scale 
chapter 
inputs better extra outputs test set rmse stl mtl stl feature noise scale performance stl regular inputs stl extra input ef ef mtl extra output tasks ef ef 
data passing sigmoid passing di erences sigmoid creates nonlinear problem 
large halt test sets able run trials method noise level 
results reliable 
classi cation problem section presents problem combines feature correlation section feature noise section problem 
consider classi cation problem shown separating gaussian distributions means standard deviations 
problem simple learn input coded single continuous input 
harder embedding non linearly higher dimensional space 
consider encoding input values de ned interpolated gray code gc 
interpolated gray code integer values mapped binary gray code usual way 
intervening non integers mapped linearly intervening vectors binary gray codes chapter 
inputs better extra outputs bounding integers 
gray code ips bit neighboring integers mapping involves simply interpolating dimension unit cube changes 
example value encoded gc gc gc 
gc 
gc 
nd bit left changes going 
represent decimal part value scale nd bit yielding 
interpolated gray codes useful property regular gray codes bit changes transitions neighboring values representation continuous 
classi cation requires decoding gray code input representation determining classi cation threshold 
overlapped gaussian classes left extra feature axis correlated di erent amounts correlation perfect correlation unencoded version regular input axis extra feature value correlated correlation original unencoded regular input extra feature drawn gaussian distribution mean standard deviation 
examples distributions unencoded original dimension extra feature various correlations shown 
problem carefully constructed optimal classi cation boundary change varies 
consider extreme cases 
extra feature exactly unencoded version regular input 
stl net feature extra input ignore encoded inputs solve problem feature 
mtl net extra feature extra output hidden layer biased representations decode gray code useful main classi cation task 
extreme expect nets extra feature learn better just regular inputs useful information provided uncorrelated extra feature 
interesting case extremes 
imagine situation chapter 
inputs better extra outputs output extra feature able help mtl guiding decode gray code input help stl high level noise 
test set error stl mtl stl correlation extra feature stl stl feature extra input mtl feature extra output vs classi cation problem 
improvement mtl stl statistically signi cant appear mtl trend 
suspect improvement due noise injected uncorrelated output hidden layer acting regularizer 
see section discussion ect 
class output unit uses sigmoid transfer function cross entropy error measure 
output unit correlated extra feature uses linear transfer function squared error measure 
shows average performance trials stl stl extra feature extra input mtl uses extra feature extra output function networks hidden units training patterns halt test sets patterns 
previous section stl sensitive changes extra feature mtl curves cross dimension useful output dimension extra input 
graph right side shows blow interesting region 
chapter 
inputs better extra outputs discussion problems section contrived 
simplest problems devise exhibit phenomenon 
evidence sensitivity noise inputs pneumonia problem 
recall tried feature nets pneumonia problem section observe improvements performance comparable mtl 
mtl net learning internal representation extra tasks 
feature nets provide learned internal representation extra tasks extra inputs net 
approaches di erent 
di erence models learned extra tasks pneumonia domain noisy extra tasks learned 
models poor act noisy inputs 
see noise inputs hurt learning inputs contain useful information 
extra mtl outputs noise task signals signals database predictions 
compares zero noise points mtl moderate noise points stl extra inputs figures easy see mtl outperform feature nets domains extra tasks learned 
choice extra tasks extra mtl outputs poor predictions extra tasks extra inputs extra mtl outputs probably better 
selecting inputs extra outputs previous section synthetic problems demonstrate input features useful extra outputs inputs 
section feature selection real problem dna splice junction nd features useful outputs inputs 
feature selection method devised koller sahami koller sahami select features inputs 
ignoring features eliminated feature selection extra outputs mtl 
dna splice junction problem features inputs features extra outputs yields better performance features inputs just selected features inputs 
real world problems excess features chapter 
inputs better extra outputs process mtl applicable real world domains sources extra tasks may exist 
feature selection feature selection process selecting subset available features inputs learning 
features relevant learning feature selection important 
real world problems excess features 
features may irrelevant tothe learning task hand 
features may redundant information contained features 
learning algorithms usually di culty coping large numbers redundant irrelevant features performance improves considerably learning method subset features useful learning task 
feature selection method developed koller sahami 
method learning algorithm independent feature selector uses information theoretic measures feature importance select features useful inputs 
currently koller sahami algorithm applicable classi cation problems de ned boolean features 
theoretical motivation koller sahami algorithm remove attributes remaining attributes 
markov blanket attribute minimal set attributes attributes blanket conditionally independent attribute conditioned markov blanket attributes 
markov blanket isolates attribute attributes 
attribute markov blanket attributes attribute provides additional information class decision independent value attribute conditioned values attributes blanket 
practice nding markov practical large number attributes 
koller sahami algorithm simplifying approximations allow degree attribute attributes estimated reasonable time 
approximations yield algorithm capable doing feature selection problems containing hundreds features hours workstation 
chapter 
inputs better extra outputs koller sahami feature selector greedy feature selector 
preferred way algorithm backward elimination 
start features set remove attributes time step removing attribute covered attributes remaining set 
step algorithm removes attribute appears provide additional information class remaining attributes 
greedy approach suboptimal domains ective works domains including dna splice junction domain 
dna splice junction problem dna contains coded information cells construct proteins 
process building messenger rna mrna molecule template build protein large sections original dna coding ignored 
coded sequences known exons ignored sequences known introns 
nature boundaries exons introns known splice junctions subject active research 
dna splice junction problem available uci machine learning repository noordewier towell shavlik 
case database sequence nucleotides 
goal predict center nucleotide sequence codes exon intron boundary exon boundary 
cases ei boundaries boundaries ei boundaries 
compatibility nucleotide coding scheme koller sahami 
scheme codes nucleotides dna sequence bits 
yields total boolean attributes inputs 
typical performance problem accuracy trained training sets containing cases 
experiments run experiments dna problem 
rst experiment determine hidden units backprop nets 
experiment shows bene feature selection limit number features inputs nets 
second experiment determine features extra outputs improves chapter 
inputs better extra outputs performance splice junction recognition 
experiments backprop nets composed sigmoid units 
train nets conjugate gradient simulator university 
early stopping independent halt set determine training 
performance net measured independent test set backpropagation early stopping 
dataset contains cases 
randomly split set train halt test sets containing cases respectively 
repeatedly sample dataset way generate multiple trials 
coding main splice junction task uses outputs ei 
normalized cross entropy loss function outputs main task 
normalized cross entropy standard way preserving probability semantics multiple outputs code mutually exclusive classes 
output activations normalized dividing output activation sum activations outputs coding ei 
normalization done prior computing backpropagating error output 
classi cation net prediction done usual way nding outputs highest activation 
boolean attributes extra outputs non normalized cross entropy loss function train 
experiment performance vs net size purpose experiment net size yields best performance dna domain 
tried nets containing hidden units 
nets outputs code main task 
shows test set cross entropy error nets di erent sizes trained input features trained input features selected koller sahami feature selector 
select features number features koller sahami selected experiments domain 
data point average trials vertical bars con dence intervals estimates 
graph clear better performance achieved nets hidden units 
common early stopping favor large nets 
chapter 
inputs better extra outputs cross entropy loss test set inputs inputs number hidden units logscale cross entropy performance di erent size nets inputs selected inputs graph clear cross entropy performance signi cantly better nets selected features inputs compared nets features inputs 
percent accuracy test set inputs inputs number hidden units logscale prediction accuracy di erent size nets inputs selected inputs shows splice junction prediction accuracy input nets function net size 
performance best large nets graph suggests accuracy best nets nearer hidden units hidden units 
graph shows reduced set input features improves accuracy domain 
chapter 
inputs better extra outputs conclude experiments section optimal net size approximately hidden units training nets features selected koller sahami feature selector yields better performance inputs 
experiment unused features extra outputs previous experiment features selected inputs feature selection thrown away 
inputs outputs 
section features inputs extra outputs multitask learning 
koller sahami algorithm told attributes remove 
automatically determine removing attributes 
ran koller sahami feature selector remove attributes dna problem 
feature selector greedy algorithm removes attributes time creates ordering attributes 
attributes removed algorithm inputs 
ignore remaining attributes attributes extra outputs multitask learning 
attributes remaining attributes feature selector considers useful 
remaining attributes extra outputs mainly computational ciency 
number extra outputs net large number hidden units increased proportionately output guaranteed certain minimum number hidden units 
unused inputs extra outputs yields nets large ord run trials 
multitask learning net inputs outputs main task additional outputs attributes selected inputs 
multitask learning net hidden units learning tasks 
attempted nd optimal number hidden units multitask learning net suspect multitask learning net perform better hidden units 
biases experiments favor nets extra outputs nearly optimal number hidden units nets near optimal net size determined dataset 
chapter 
inputs better extra outputs table cross entropy performance di erent combinations inputs outputs 
di erences di erence net net statistically signi cant better 
net inputs stderr net net net net table shows cross entropy error di erent nets 
table shows prediction accuracy nets 
net hidden units uses inputs 
traditional way training task feature selection 
net number hidden units uses features selected feature selection inputs 
net multitask learning net 
uses attributes inputs net 
net uses best attributes extra outputs 
attributes ignored net 
net uses inputs attributes net inputs attributes net extra outputs 
net uses attributes net uses net uses inputs 
extra outputs 
table predictive accuracy di erent combinations inputs outputs 
di erence net net just misses signi cant trials 
net inputs accuracy stderr net net net net net clearly worst performer problem 
attributes inputs best thing 
features selected koller sahami algorithm inputs net yields signi cantly better performance 
net performs better 
best features inputs extra outputs ignoring 
net uses features net inputs perform net net 
net reduces cross entropy compared net compared net uses features 
predictive accuracy net reduces error chapter 
inputs better extra outputs compared net compared net 
dna splice junction domain better features extra outputs inputs 
domain koller sahami feature selection algorithm ective way selecting input features candidates extra outputs 
know koller sahami algorithm ective way selecting available outputs mtl 
features inputs extra mtl outputs know yields best outputs mtl 
results splice junction show bene feature extra output di erent bene feature input 
input net access feature values training test cases prediction 
output net biased learn mapping input features output 
splice junction results demonstrate learned mapping useful feature value particularly value feature additional input marginal harmful 
section showed dna splice junction domain contains features improve recognition accuracy extra outputs inputs 
result con rms expectation real world problems features better extra outputs inputs 
features selected koller sahami feature selector inputs yields better accuracy features inputs 
better accuracy obtained features inputs extra outputs ignoring additional inputs 
realworld problems bene similar combination feature selection multitask learning 
features inputs mtl outputs tasks inputs inputs hurts performance noisy 
bene extra mtl outputs large bene inputs noisy 
furthermore interesting regime help learning chapter 
inputs better extra outputs output input 
shows blow regions problems section 
test set rmse stl mtl stl test set error stl mtl stl feature noise scale correlation extra feature blow ups regions practical interest problem section classi cation problem section 
stl stl regular inputs 
stl stl extra feature extra inputs 
mtl uses extra feature extra output 
region bene ts extra features extra inputs extra outputs 
wouldn nice extra tasks extra input features extra output tasks 
di culty task values inputs outputs backprop certainly learn connections directly map input corresponding output 
direct connection zero error output interest learned extra outputs hidden layer 
putting task values inputs outputs simple fully connected feedforward mtl net ectively turns mtl network architecture isolate outputs inputs shows architecture combines architectures figures 
uses disjoint hidden layers prevent output tasks seeing task value chapter 
inputs better extra outputs input 
architecture allows bene ts mtl 
learns models internally extra tasks inputs learned models available main task 
extra output main output mtl hidden layer stl hidden layer binary inputs coding binary inputs coding extra input mtl architecture combines learning main task extra input feature learning extra task input feature 
arrow represents full feed forward connections layers 
hidden layers di erent depths connect di erent inputs outputs 
hidden layer right sees inputs connects output side main task extra tasks extra inputs 
similar hidden layer stl net extra inputs 
hidden layer left see extra inputs sees regular inputs 
output side connects main task extra tasks extra inputs 
hidden layer similar hidden layer mtl net 
learns extra tasks see tasks inputs 
hidden layer see extra tasks inputs learn direct connections map tasks inputs tasks outputs 
learn model extra outputs di erent part net extra tasks extra inputs 
results shows results architecture problem ef ef extra input features extra output tasks 
mtl chapter 
inputs better extra outputs extra features inputs outputs performs mtl just extra outputs high noise regions graph better low noise regions graph 
performance stl extra features extra inputs better extra features low noise 
tradeo point better extra features extra outputs shifts lower noise compared 
mtl appears perform better mtl high noise regions graph di erences signi cant 
methods statistically distinguishable noise scales 
test set rmse stl mtl stl mtl feature noise scale performance stl regular inputs stl extra input ef ef mtl extra output tasks ef ef 
shows results architecture classi cation problem section 
extra feature inputs outputs improves performance mtl region closer features noise useful inputs shifts point tradeo extra feature extra input extra inputs outputs happens 
performance appears slightly worse low part graph di erences statistically signi cant trials 
chapter 
inputs better extra outputs test set error stl mtl stl mtl correlation extra feature stl stl feature extra input mtl feature extra output vs classi cation problem shows blow ups figures similar shown 
graphs curve mtl yields performance stl mtl extra feature useful low noise high correlation 
shifts tradeo points better just extra feature input stl 
suggests mtl outperform stl real problems 
demonstrates existence regions noise scales mtl best performer 
want best performance problems regions mtl 
discussion conclude approach features inputs extra outputs promise 
devise better architectures allow mtl perform better best stl mtl reason stl stl 
features extra outputs architecture 
chapter 
inputs better extra outputs test set rmse stl mtl stl mtl test set error stl mtl stl mtl feature noise scale correlation extra feature blow ups regions shown 
stl stl regular inputs 
stl stl extra feature extra inputs 
mtl uses extra feature extra output 
mtl addition graphs 
uses extra feature inputs extra mtl outputs 
order extra outputs useful extra inputs information inputs learn problem 
fortunately real world domains considerable redundancy input features 
convinced real problems bene inputs outputs 
currently exploring alternate architectures may improve performance allow features inputs outputs 
chapter summary chapter shows bene feature extra output di erent bene feature input 
input net access value feature training test cases 
output net access value feature training biased learn mapping inputs training set output 
mapping available net testing value feature 
di erence better features outputs inputs 
chapter 
inputs better extra outputs section demonstrated features useful extra outputs 
section synthetic problems easy understand features useful outputs inputs 
section showed real world problem dna splice junction features useful outputs inputs 
showed feature selection employed nd inputs useful extra outputs 
feature selection nds subset features inputs 
features inputs candidates extra outputs 
approach avoids combinatorial explosion occur tried evaluate possible combinations features inputs extra outputs 
graphs section clear features help input output 
bene feature extra output di erent input get bene ts 

followed break single fully connected hidden layer previous mtl nets disjoint hidden layers isnot able see inputs 
architecture reaps bene ts allowing features simultaneously inputs outputs preventing learning direct feedthrough identity mappings 
method re ned early results promising 
able achieve performance synthetic problems section features inputs extra outputs achieve features just inputs just extra outputs 
development testing real problems necessary judge useful practice features inputs extra mtl outputs 
performance di erences observe chapter small 
bene features inputs extra outputs large 
inputs extra mtl outputs probably important application mtl real problems 
chapter show mtl potentially applied real world problem real problems feature selection problem creates possibility features selected inputs best outputs discarded 
improve technology allows features inputs extra mtl outputs net mtl potentially applicable problems machine learning 
chapter basics basic machinery doing multitask learning neural nets backpropagation 
backprop designed mtl 
chapter presents techniques multitask learning backprop nets better 
techniques may counterintuitive 
important followed multitask learning hurt generalization performance helping 
mtl trains multiple tasks parallel cient way learn tasks information training signals tasks help task learned better 
optimal task optimal tasks 
case important optimize technique performance main task best hurts performance extra tasks 
tasks important may best rerun learning important task technique optimized important task time 
point view important 
allows develop asymmetric methods favor performance task expense poorer performance tasks 
previous chapters methods chapter improve performance main task treating main task di erently extra tasks 
method described chapter problems earlier thesis early stopping tasks individually 
methods chapter applied problems examined thesis 
expect cases improve performance mtl 
chapter 
basics early stopping neural net experiments reported thesis early stopping 
early stopping way preventing tting halting training error driven procedures backprop achieve minimum error training set 
early stopping usually done independent test set halt set backpropagating errors 
performance halt set monitored backpropagation done training set training halted performance halt set stops improving starts getting worse 
early stopping important applications backprop nets achieve best performance 
recall alvinn domain section 
problem main task predict steering direction autonomous vehicle images road front vehicle 
applied mtl alvinn training neural net extra tasks trained main steering task road lanes location left edge road location road center intensity region bordering road location centerline lane roads location right edge road intensity road surface intensity centerline lane roads mtl net alvinn outputs main steering task extra tasks 
shows graphs tasks trained mtl net 
graph root mean squared error outputs halt set mtl net trains 
usually training causes error halt set fall level rise performance training set shown quickly falls bottom scale continues fall training 
early stopping halts training epoch performance halt set best 
examining graphs clear best place halt training di ers task 
road center task reaches peak performance backprop passes main steering task perform best halted passes 
table shows best place halt task 
epoch training stopped achieve maximum performance tasks 
tasks important net chapter 
basics number lanes road left edge road right edge root mean squared error root mean squared error root mean squared error backprop passes epochs line center backprop passes epochs road center backprop passes epochs road greylevel root mean squared error root mean squared error root mean squared error backprop passes epochs greylevel backprop passes epochs line greylevel backprop passes epochs steering direction root mean squared error root mean squared error root mean squared error backprop passes epochs backprop passes epochs backprop passes epochs test set performance mtl net trained alvinn tasks 
predict tasks place halt training error outputs combined minimized 
shows mean rms error tasks combined mtl net trained 
best average rmse occurs backprop passes 
net predictions tasks suboptimal 
better performance achieved halting training output individually snapshot net taken epoch predictions task 
refer net halted performance particular task best snapshot mtl net trained tasks snapshot tasks interest 
alvinn chapter 
basics tasks combined root mean squared error backprop passes epochs combined test set performance alvinn tasks 
tasks interest probably little predictions road intensity snapshots mtl net tasks 
table compares performance alvinn early stopping done task performance obtained halting training entire mtl net place combined rmse 
average halting tasks individually reduces error 
large di erence 
tasks performance mtl net worse performance stl task mtl net halted task individually halted point combined error lowest 
conclude tasks reach peak performance time usual case important early stopping individually task interest 
early stopping tasks individually important 
experiments reported thesis 
section shows performance nettalk improved stopping tasks individually 
leaving topic important recognize training curves chapter 
basics table performance mtl alvinn task training halted task individually compared performance tasks halting combined rmse tasks 
halting task individually reduces error average 
task halted individually halted combined difference bp pass performance bp pass performance lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering individual outputs net multiple outputs mtl net necessarily monotonic 
test set error single output net nonmonotonic training set error single output net descend monotonically 
batch gradient descent done properly training set error increase 
hold errors measured individual outputs multiple output net 
aggregate training set error summed outputs increase aggregate test set error usually single minimum output may exhibit complex behavior 
graph road greylevel graph number shows strong multimodal test set curve 
corresponding training set curve output similar shape 
extra complexity mtl training curves judging halt training di cult 
generalization curves individual tasks multimodal early stopping training mtl nets halt set performance tasks appears levelled begun tting 
point main task stopped improving 
examine entire generalization curve main task nd backprop pass performance maximized 
network saved time predictions repeat training backprop pass 
chapter 
basics learning rates graphs showing learning curves alvinn tasks previous section raise interesting questions 
possible control rates di erent tasks train reach best halt set performance time 
controlling rates di erent tasks train yield better mtl performance main task 
best performance task achieved task reached peak performance time 
better extra tasks learn slower faster main task 
general statement fast extra tasks learn relative main task di erent extra task 
rate di erent tasks learn vanilla backpropagation certainly optimal mtl 
consider task trains times slower main task 
learned slow task learned snapshot main task taken 
learned slow task bene main task 
surprisingly task learned times faster main task hurt performance main task 
fast task tting time main task learned representation hidden layer fast task probably useful main task began main task shares considerably faster task faster task may pull main task premature tting 
learning rate optimization easiest direct method controlling rate di erent tasks learn di erent learning rate task output 
consider alvinn problem 
mtl net alvinn outputs main task extra tasks 
previous experiments learning rate output 
roughly balance importance task training preprocessed data sets rescaling outputs task variance 
variance preprocessing observed tasks train di erent rates shown 
chapter 
basics learning rate task adjust learning rates performance main task optimized 
problems alvinn small number extra tasks gradient descent optimize learning rates extra tasks 
perturbation estimate gradient generalization performance main task respect learning rates extra tasks 
estimate generalization performance initial learning rates usually initialize learning rates tasks training mtl net early stopping main task halts training 
performance halt set estimate performance learning rates 
perturb learning rate task increasing 
train net initial weights train halt sets halt training main task halt set measure performance net halt set 
extra task 
extra tasks train neural nets estimate gradient 
ect main task applied gradient descent learning rates extra tasks alvinn estimated gradients computed described 
minimize number times gradient computed line searches gradient fully exploited new computed 
line search converges recompute gradient new point 
repeat process early stopping performance halt set stops improving 
procedure repeatedly evaluates performance halt set ting halt set halt set early stopping 
possible analytically compute gradient learning rate output reduce error main task output fastest backprop pass 
disadvantage favoring learning rates optimize performance training set generalization performance 
works best training set generalize 
main goal mtl improve generalization accuracy 
performance test set criterion wish optimize 
unfortunately know general way analytically compute estimate ect di erent learning rates test set performance may heuristic methods practice 
chapter 
basics problem far 
usual report results second independent test set prevent yielding optimistically estimated generalization performance 
tting halt set problem solution split halt set halt sets early stopping net trained halt outer level learning rate optimization process ts rst halt set 
table shows performance main task optimizing learning rates extra tasks 
rst rows table results di erent runs di erent data sets initial network weights 
bottom row table average trials 
optimizing learning rates extra mtl tasks improved performance main task additional 
improvement original improvement mtl stl 
table performance mtl main steering direction task optimizing learning rates extra task 
performance measured independent test set backpropagation training learning rates 
trial optimization optimization difference trial trial trial trial trial average learning rates fast tasks train table shows nal optimized learning rates extra mtl tasks trials 
learning rates initialized gradient descent 
table know optimizing learning rates extra tasks improves performance considerably main task 
strong pattern emerges learning rates learned extra tasks table 
small training sets considerable variation runs expected 
clear pattern average learning rate learned extra tasks somewhat smaller main task 
chapter 
basics table learning rates learned extra tasks alvinn 
learning rates initialized training 
task trial trial trial trial trial average lanes left edge right edge line center road center road greylevel edge greylevel line greylevel average looks road greylevel task consistently receives large learning rates road center task receives low learning rates 
examining training curves tasks learning rates optimized shows changes learning rates extra tasks signi cant ect rate extra tasks learned 
interestingly signi cant ect rate main task learned 
di cult learning curves tasks gradient descent learning rates concise intelligible fashion form animation 
chapter attempt summarize ect learning rate optimization shorter optimization runs 
horizontal axis number epochs required peak generalization performance task achieved 
measure fast tasks training 
points left side graph indicate tasks trained quickly epochs points right side graph indicate tasks trained slowly required epochs 
gure shows snapshots learning 
rst snapshot optimization begun learning rates equal 
second snapshot steps gradient descent third steps descent snapshot shows learning speed tasks 
things evident looking graphs 
task predicting greylevel centerline predicted best mtl net trained backpropagation 
consistent learning curve chapter 
basics task shown shows begins tting immediately 
surprising centerline extremely small feature images learning probably di cult relatively small training sets experiments 
speed task main steering task reaches optimum performance changes considerably learning rate optimization 
surprising learning rate main task changed 
way learning rate optimization ect main task ecting hidden layer representation developing extra tasks main task share 
learning rate optimization tasks task reach peak performance main task task train faster main task learning rates optimized 
see trials 
trials speed main task task slowed tasks come trial 
trials speed main task slowed tasks speeded fall nearer main task 
general learning rate optimization drives extra tasks learn roughly times faster main task 
suggests tasks bene cial main task help learned somewhat faster main task faster 
task predicting road greylevel 
trials task ended learned 
surprisingly looks learning rates task table task consistently receives learning rate greater 
absence ects expects increasing learning rate output train faster 
conclude just learning speed main task slowed reducing learning rates tasks shares task slowed reduced learning rates tasks sensitive 
increase learning rate task may attempt optimization partially overcome slowing task learned learning rate increased 
pushing task train faster necessarily mean reach peak performance faster observe usually practice 
chapter 
basics performance extra tasks performance extra tasks learning rates tasks optimized maximize performance main task 
performance extra tasks sacri ced obtain better performance main task 
table shows rms error extra outputs learning rate optimization 
performance extra tasks improves 
surprising criterion optimized performance main task performance extra tasks 
goose appears 
main task learned best performance extra tasks improved 
domain learning rate optimization improves performance main task adjusting learning rates extra tasks hidden layer representation learned broad utility tasks domain 
interesting see optimization increases sharing hidden layer 
table performance mtl nets extra tasks learning rates optimized improve performance main task 
task optimization optimization difference lanes left edge right edge line center road center road greylevel edge greylevel line greylevel average learning rates harmful tasks interestingly task performance hurt learning rate optimization task task learns slowest learning rate optimization task consistently gets largest learning rates optimization 
raises interesting question experiment early stopping nal training run task individually see extra task learned learning rates optimized main task 
chapter 
basics task bene cial main task 
learning rate optimization slow rate task learns mitigate con ict task main task 
larger learning rate task receives suggest task bene cial main task unnecessary learn task faster main task main task get bene 
learning rate optimization learning rate extra tasks related main task 
try answer added additional task alvinn problem consists noisy training signal 
training targets random numbers uniformly distributed interval similar training signals 
training signals extra task random related main steering task 
say adding extra noisy output backprop net improve performance main task 
general expect extra tasks useful 
table performance main steering direction task unrelated noisy extra task added mtl net extra tasks learning rate optimization 
learning rates learned noisy extra task shown third column 
trial optimization optimization noise learning rate trial trial trial trial trial average table shows performance main steering task learning rate optimization 
expected average performance optimization worse extra noise task mtl net compare optimization column tables 
comparing nal performance learning rate optimization extra noise task shows learning rate optimization able achieve performance extra noise task table comparable performance learning rate optimization extra noise task table 
learning rate optimization able mitigate impact having extra output tasks chapter 
basics harmful main task 
table shows learning rate learned noisy extra output trials 
average learning rate learned extra noise task 
smaller learning rates learned tasks 
con rms suspicion noisy extra task useful real task drawn domain 
demonstrates learning rate optimization perform limited kind output task selection 
say limited drive learning rate irrelevant extra task zero 
backprop nets fairly learning disjoint hidden layer representations outputs little overlap su cient capacity hidden layer 
computational cost gradient descent optimize learning rates expensive 
average trial computed gradient times performed average line search steps gradient 
trial required training mtl nets 
important applications medicine autonomous vehicle navigation cost prohibitive impractical 
currently popular procedures improving generalization performance boosting bagging require models trained 
may possible amortize cost training learning rates extra tasks combining form boosting learning rate gradient descent 
learning rate optimization tasks optimizing learning rates di erent outputs applicable problems may thought problems 
example classi cation problems classes trained net multiple outputs class 
suspect learning rate optimization yield improved accuracy kinds problems 
potentially valuable approach di erent output classes di erent frequencies 
increasing learning rate low frequency classes may improve accuracy learned models classes 
chapter 
basics fully connected hidden layers net capacity think important mtl hidden layers small promote sharing 
usually correct 
experience limited capacity hurts mtl hurts stl 
better think mtl way providing additional constraint learned think mtl providing opportunity tasks share learn 
minor di erence point view 
practice signi cant di erence 
adopts constraint point view begins apply methods falsely assume compact representation fully support tasks high accuracy 
real world problems multiple tasks di erent 
learned task useful tasks 
possible better allow su cient capacity tasks learned independently 
way sharing happen su ciently strong statistical correlation cause happen 
private hidden layers providing su cient capacity main task extra tasks bene cially coexist di cult tasks 
discussed appendix surprising hidden units needed optimal performance task 
nd optimal number hidden units hidden units output 
extra tasks translates thousands hidden units 
creates computational di culties eventually degrade performance main task 
reason simple hidden units developed representations useful mainly tasks output unit main task massive feature selection problem 
nd relatively small number hidden units useful 
limit usefulness mtl situations extra tasks 
case 
single large fully connected hidden layer shared equally tasks develop asymmetric chapter 
basics architecture optimal main tasks extra tasks 
allows arbitrarily large number extra tasks risking swamping main task sea largely irrelevant hidden units 
extra outputs main output 
mtl hidden layer private hidden layer main fully connected input features fully connected input features mtl architecture private hidden layer just main task shared hidden layer main task extra tasks 
shared hidden layer smaller necessary performance extra tasks 
shows simplest asymmetric net architecture accomplishes 
hidden layer shared equally tasks disjoint hidden layers 
hidden layer private hidden layer main task 
hidden layer hidden layer shared main task extra tasks 
hidden layer supports mtl transfer 
net architecture asymmetric main task see ect hidden layer extra tasks extra tasks see ect hidden layer reserved main tasks 
size private hidden layer optimized usual way stl main task 
hidden layer probably contain hundreds hidden units 
mtl hidden layer shared main extra tasks need large support optimal performance extra tasks 
size hidden layer optimized provide maximum performance main task 
chapter 
basics combining mtl feature nets feature nets approach extra tasks learning models provide extra inputs net learning main task 
idea 
compared feature nets mtl pneumonia risk prediction domain section 
feature nets mtl domain con dent domains feature nets outperform mtl 
nice away combine feature nets mtl 
shows feature net architecture 
gure copy 
possible combine mtl feature nets di erent levels 
rst level note separate nets learn models extra tasks main net trained main task 
words models extra tasks learned stl 
mtl learn models extra tasks 
mtl yield better predictions average extra task signals yield useful hidden layer mtl net learned extra tasks 
level straightforward application mtl feature nets 
second level little interesting 
suppose inputs main net learning main task coming feature net models learned extra tasks 
main net mtl net learning extra tasks 

shows net uses mtl levels feature nets 
stl net traditional feature net architecture replaced mtl net 
mtl feature nets uses mtl net learn models extra tasks extra inputs 
mtl feature nets uses mtl net learn main task extra outputs net extra tasks predictions provided extra inputs previous net 
concerned providing inputs mtl net predictions tasks extra outputs prevent mtl net learning interesting extra tasks 
backprop learn direct connections predictions task provided input task chapter 
basics main task 
task task task 
inputs feature nets allows train main task stl bene learned auxiliary tasks 
output 
large problem 
consider cases 
rst case predictions extra tasks poor room improvement 
mtl net extra outputs training signals accurate input predictions backprop attempt learn models mtl accurate predictions provided inputs 
input predictions probably strong component models mtl net learn possible information available 
mtl net possibility predictions extra inputs inputs 
second case predictions extra task 
little improvement data hand 
case mtl net learn models mainly jump connections feeding predicted inputs corresponding chapter mtl architecture able task signals inputs extra outputs 
chapter 
basics main task task task mtl level 
main task task task mtl level 
regular inputs feature nets mtl di erent levels 
level net learn models extra tasks mtl net 
level main net learn main task regular inputs extra task models extra inputs mtl net 
diagram shows mtl feature nets hidden layer representation learned mtl net level passed inputs mtl net level 
possible pass output predictions mtl net level net level 
usually passing hidden layer activations works better passing output predictions 
tried passing 
outputs 

assume main task learned better extra tasks provided extra inputs mtl net learning main task opportunity high delity predictions extra tasks inputs perform 
summary mtl feature nets provide advantages mtl feature nets 
mtl helps better models learned extra tasks 
provides mtl bias main task learned 
allows main task bene high delity predictions extra tasks inputs possible 
shows performance pneumonia problem mtl nets chapter 
basics stl mtl mtl feature net level test set error rate fraction population fop performance feature nets mtl applied levels 
nets levels feature nets 
performance improves considerably larger may mtl lowest 
know data point fop representative 
chapter summary goal mtl learn main task better advantage information contained training signals extra tasks 
main task extra tasks treated equally 
better performance main task achieved employing methods favor performance main task possibly expense worse performance extra tasks 
section saw tasks trained equal outputs mtl net important early stopping main task considering error outputs 
note usual way doing early stopping machine learning community 
typically net training halted total error measured outputs reaches minimum test set 
certainly inferior way chapter 
basics train net multiple outputs 
better performance usually achieved output halting training output individually di erent snapshots acquired way predictions di erent outputs 
true think learning problem multitask problem 
multiple outputs problem 
section saw training output tasks mtl net way probably yield optimal performance main task 
optimization nd learning rates extra tasks yielded best performance main task 
gradient descent procedure expensive approach practical problems having fewer tasks 
problems bene substantial 
tuning learning rates yielded reduction error mtl alvinn domain 
domains extra tasks applying gradient descent learning rate extra task probably practical 
domains approach group extra tasks clusters receive learning rate reducing number learning weights need optimized 
simplest way learning rate extra tasks optimize single parameter maximize performance main task 
drew experiments learning rate optimization extra tasks bene main task learned just main task 
suggests simple approach tuning learning rates increase learning rates tasks learned main task learned rate similar main task 
fairly simple optimization problem tractable extra tasks 
chapter feature selection nd features outputs useful inputs 
section showed features useful extra outputs worth architecture allows features inputs outputs 
approaches beg question tell extra tasks useful 
task selection method nd useful extra outputs may hundreds thousands extra outputs train 
creates problems 
chapter 
basics training hidden layer large support main tasks extra tasks may prohibitively costly 
second ord train large hidden layer number hidden units dedicated extra tasks eventually grow large main task output su er internal representation selection problem hurt performance 
avoid problems section architecture uses private hidden layer main task public hidden layer shared main tasks extra tasks 
public hidden layer large support optimal performance extra tasks 
keeping public hidden layer small promotes generalization learned extra tasks insures hidden units dedicated extra tasks main task unable selection hidden layer total number weights trained smaller 
section examined architecture expanded usefulness mtl 
combined feature nets multitask learning 
architecture nal example treating main task di erently extra tasks 
reason architecture demonstrates important point mtl nets mtl net employed stl net 
extra tasks mtl net improve performance main task 
mtl net inputs stl net extra outputs mtl net ignored net trained mtl nets functionally equivalent stl nets way generalize better 
chapter 
basics step lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering main step lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering main step lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering main step lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering main step lanes left edge right edge line center road center road greylevel edge greylevel line greylevel steering main 
pattern presentations epochs peak performance task learning speeds learning rate optimization chapter mtl nearest neighbor multitask learning inductive transfer method improves generalization learning extra tasks parallel main task shared representation learned extra tasks help main task learned better 
previously demonstrated multitask learning backprop nets 
backprop mtl representation multitask transfer hidden layer shared tasks 
multitask learning useful arti cial neural nets 
learning methods representation naturally shared tasks 
mtl methods 

chapter shows multitask learning case methods nearest neighbor kernel regression built means sharing representation multiple tasks 
approach follow error metric combines performance main task weighted contribution performance extra tasks 
causes models learned perform main task extra tasks 
demonstrate approach multitask transfer pneumonia risk prediction domain mtl backprop nets 
see mtl reduces error kernel regression problem 
introduce soft ranks ranking procedure rank error metrics di erentiable amenable gradient search 
chapter 
mtl nearest neighbor background basic assumption underlying machine learning methods similarity feature space correlates similarity prediction space 
nearest neighbor kernel regression explicitly heuristic prediction 
search training set cases similar new case return prediction new case class value similar cases 
similarity usually de ned distance metric computed case features 
distance metric commonly weighted euclidean distance dist ance vu eat cases eat dimensionality feature space feature case weight feature dimension controls important dimension distance calculation 
simple unweighted euclidean distance 
nearest neighbor nearest neighbor knn searches training set cases closest new case 
classi cation problems knn returns prediction new case predominant class nearest neighbors probability class estimated number nearest neighbors class probability kx class number neighbors probability predicted probability new case belongs class class indicator equal case member class 
predominant class class highest predicted probability 
regression knn returns average nearest neighbors predicted value kx predicted value regression value knn predict new case value training case chapter 
mtl nearest neighbor best value depends structure problem space density samples 
large knn insensitive ne structure problem neighborhoods large 
small predictions noisy smaller samples necessary capture problem structure 
values usually cross validation 
locally weighted averaging locally weighted averaging lcwa known kernel regression similar knn uses distance metric determine similar new case case training set 
distance weight contribution training case prediction new case training cases closest new case having largest ect 
classi cation problems weight accumulate probability new case belongs class probability rain class distance ci cnew kernel width pno rain distance ci cnew kernel width rain number cases training set distance ci cnew distance case ci training set new case measured distance metric class indicator numerator accumulates predictions training cases weighted inversely exponentially decreasing function distance relative width denominator normalization factor 
regression problems distance weight value training case adds predicted value predicted value rain distance ci cnew kernel width distance ci cnew kernel width predictions lcwa ected cases training set cases far away little ect 
controls size neighborhood prediction knn kernel width controls scale neighborhood ect lcwa 
cases closer new case kernel width signi cant impact prediction case cases away kernel width impact falls exponentially distance 
chapter 
mtl nearest neighbor feature weights distance metric performance knn lcwa depends quality distance metric 
simple euclidean distance feature weights equal works reasonably usually suboptimal 
finding feature weights essential optimal performance 
search feature weights cast optimization problem cross validation 
leave cross validation loocv particularly cient easy implement knn lcwa remove case training set time remaining cases pool nd neighbors prediction 
gradient descent loocv search feature weights 
feature weights initialized starting value 
loocv performance initial weights calculated yielding estimate generalization performance 
gradient loocv performance respect feature weights calculated analytically numerical approximation 
step taken negative gradient 
step changes feature weights usually small amount 
updated feature weights yield improved performance measured new loocv training set step accepted 
step rejected step size reduced 
step accepted gradient new point computed process repeats 
search terminates local minimum loocv performance 
local minima detected step size needed improve loocv performance small 
search repeatedly uses training set optimization tting training set particularly training set small 
protect separate test set determine halt training 
halt set calculate gradients performance halt set training set case database watched gradient search determine tting occurs 
gradient search terminated performance halt set appears getting worse 
advantage lcwa knn lcwa predictions cases lcwa performance di erentiable respect feature weights 
knn usually discontinuous cases move nearest neighborhoods 
modi cations knn di erentiable search done optimization method require di erentiability 
chapter 
mtl nearest neighbor multitask learning knn lcwa finding feature weights essential optimal performance knn lcwa 
mtl nd better weights 
knn lcwa distance metric feature weights share tasks 
assumption feature weights appropriate task drawn domain tend appropriate tasks domain nding feature weights perform tasks average improve performance task 
basic approach nd feature weights yield performance main task set related tasks drawn domain 
approach follow error metric combines performance main task weighted contribution performance extra tasks 
causes models learned perform main task extra tasks 
possible extra tasks swamp error signal main task extra tasks dissimilar 
prevent weight contribution extra tasks combined error metric 
degree extra task ects evaluation function controlled weights eval metric perf main ask perf eval metric criterion minimized gradient descent feature weights perf main ask performance main task perf performance extra task nonnegative weight 
causes learning ignore extra task causes learning give weight performance extra task main task causes learning pay attention performance extra tasks main task 
chapter consider case take value reduce computational cost experiments run simplify things ask kernel width shared mtl 
assumption sullivan thrun 
feature weights learned previous task new task number samples new task small support learning 
approach di ers mtl goal learn better feature weights learning available extra tasks parallel 
learning set feature weights multiple tasks feature weights learned separately multiple independent tasks thing 
chapter 
mtl nearest neighbor tation results 
run experiments permitted vary individually gradient descent halt set determine optimal task weights 
outperforms single extra tasks experiments run far appear perform better worth extra complexity add discussion 
tting appears problem separate values extra task 
simplify presentation scaled lambda interval 
eval metric perf main ask perf weight main task extra tasks completely ignored 
traditional single task learning stl 
equal weight main task extra task 
multitask learning tasks comparable weight 
weight extra tasks main task ignored 
pneumonia risk prediction review demonstrate mtl knn lcwa medis pneumonia risk prediction task mtl backprop chapter 
problem primary goal identify patients high risk pneumonia may receive aggressive testing treatment 
useful tests predicting pneumonia risk usually require hospitalization available preliminary assessment indicates testing hospitalization warranted 
low risk patients identi ed measurements prior hospitalization 
medis pneumonia database fine indicates patient lived died 
patients died 
useful decision aid problem predict patients live die 
di cult 
practice best achieved estimate probability death pod observed symptoms 
fact su cient learn rank patients pod lower risk patients discriminated higher risk patients 
patients risk may considered care 
chapter 
mtl nearest neighbor criterion evaluate learning accuracy select fraction patients die 
example population patients nd population risk 
learn risk model model threshold allows population patients fall 
patients threshold die error rate 
error rate fop fop stands fraction population 
consider 
goal learn models minimize error rate fop 
medis database contains results lab tests available patients 
results available model tests ordered 
previously mtl backpropagation bene lab results 
extra lab values extra tasks extra outputs backprop net learning main risk prediction task 
extra tasks biased shared hidden layer learn representations yielded better performance main risk prediction task 
extra tasks demonstrate mtl lcwa 
soft ranks di cult directly learn models minimize error rates 
di erent criteria error rates measured discrete lives dies boolean 
discrete metrics gradient descent 
neural net solution pneumonia problem devised error metric training procedure called rankprop learned predict ranks data 
rankprop adapted knn lcwa 
rankprop requires rank models learned gradually epochs learning interleaved repeated re rankings performed internal rankprop algorithm 
see appendix rankprop algorithm 
issue backpropagation usually trains slowly 
experience feature weights knn lcwa trained faster 
unfortunate slow knn lcwa learning small gradient step size just rankprop opportunity frequently re rank training data 
led chapter 
mtl nearest neighbor search way learn ranks knn lcwa 
result soft rank sum generalization standard discrete ranks call soft ranks 
modi cation gives ranks continuous avor making easy create di erentiable error metrics ranks 
qualitatively soft ranks behave traditional ranks nice additional property continuous small changes item values yield small changes soft ranks 
small changes values cause items swap positions neighboring items soft ranks re ect smooth way 
see appendix detail soft ranks 
error metrics main prediction task mortality risk 
knn lcwa predict risk new case examining neighbors training set lived died 
predicted cases sorted predicted risk 
optimization error metric task sum soft ranks patients sample live 
goal order patients risk risk rst 
successfully ordering patients live patients die minimizes sum 
scale sum soft ranks indicates patients live ranked lower risk patients die 
ideal performance 
scaling done soft rank sum indicates patients die ranked lower risk patients live 
maximally poor performance 
random ordering patients yields soft rank sums 
performance domain requires soft rank sums 
extra tasks include tasks predicting white blood cell count partial pressure oxygen blood 
error metric extra tasks standard sum squares error sse 
note extra tasks predict risk sort order patients know values combinations values extra tasks raise lower risk 
soft rank sum computed main mortality prediction task knn lcwa predictions mortality 
learning predict sse extra tasks useful helps learn feature weights improve performance chapter 
mtl nearest neighbor main risk task 
empirical results run experiments knn lcwa pneumonia 
small medium size training sets lcwa consistently outperforms knn 
reason simple 
roughly patients survive patients high risk relatively low probability death pod 
small knn neighborhoods include deaths 
means predicted pod cases pods fewer pods small number discrete pods support useful ranking patients 
large reduces problem sensitivity ne structure problem lost 
lcwa accumulates contributions cases training set small distinctions cases forced gloss ne structure provides better basis predicting relative risk 
report lcwa results 
results mtl knn qualitatively similar 
mtl applicable knn lcwa 
methodology chapter report results large experiments mtl lcwa soft ranks 
experiments goal nd feature weights yield performance main task predicting relative mortality risk pneumonia 
experiments similar methodology 
original dataset cases randomly subsampled create learning test sets 
learning set split equally sized training halt sets 
training set gradient descent feature weights halt set halt gradient descent feature weights tting begins 
remaining cases test set independent test set evaluate performance learned feature weights 
caution careful confuse feature weights task weights 
feature weights trained gradient descent 
determine distance metric nd neighbors 
task weights control task contributes error criterion chapter 
mtl nearest neighbor optimized gradient descent 
chapter task weights controlled single parameter set cross validation 
feature weights input features initialized 
gradient descent line searches done loocv training set 
kernel width avalue preliminary experiments indicated performed problem 
kernel width trained gradient descent training feature weights allows distance metric adjust ective kernel width 
learning performance gradient step evaluated halt set 
halt set performance monotonic premature stopping potential problem 
prevent gradient descent run large xed number steps feature weights yielding best performance halt set examining entire training curve 
learned weights evaluated independent test set 
experiment learning task weights mtl rst experiment examines attention learning pay extra tasks 
better ignore extra tasks optimize performance main task better performance main task achieved optimizing performance tasks 
training cases shows mean rank sum error independent test sets trials learning function training halt sets containing patterns 
data point error bars indicating standard error mean 
graphs tables performance shown main mortality risk prediction task 
horizontal line top graph performance lcwa feature weights training done 
lcwa simple unweighted euclidean distance 
weights train weight learning performance independent learning taken place 
lower curve shows varying ects mtl performance 
points curve better performance horizontal line representing untrained weights 
unweighted euclidean distance feature weights equal performs worse chapter 
mtl nearest neighbor rank error independent test set weight extra tasks compared main task rank sum error function mtl train cases halt cases 
stl extra tasks ignored 
horizontal line near top graph performance feature weights trained 
performance simple unweighted euclidean distance 
feature weights trained gradient descent 
point performance lcwa trained traditional single task learning stl extra tasks completely ignored gradient descent 
stl training feature weights reduces rank sum error compared weights equal 
points correspond multitask learning 
larger values give weight extra tasks 
graph clear learning yields better performance main task searches feature weights main task extra tasks 
mtl extra training patterns uses extra training signals pattern 
optimal value 
interestingly give similar weight main task extra task 
tasks including main task equal weight 
optimal mtl reduces error 
improvement mtl stl larger improvement stl trained vertical axis shows performance main risk prediction task 
contribution extra tasks error metric gradient descent optimizing shown ect learned apparent 
chapter 
mtl nearest neighbor fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task performance di erent fractions population varies train halt weights stl untrained weights 
shows performance mtl function di erent fop metrics 
shape fop curves qualitatively similar soft rank sum curve 
table summarizes performance stl mtl lcwa 
necessarily optimal value 
choose performance value performance appears sides value fop contains cases fop graphs statistically independent 
errors deaths occur fop learning working graphs independent population fractions suggest 
roc curves probably appropriate 
fop metrics compatibility previous studies database 
chapter 
mtl nearest neighbor represents point tasks equal weight 
di erences marked statistically signi cant better respectively 
mtl reduces fop errors compared stl 
table error rates stl lcwa mtl lcwa pneumonia problem train test sets cases 
fop stl lcwa mtl lcwa change training cases figures show performance training halt sets sets containing patterns 
backprop mtl experiments domain chapter train halt sets containing patterns 
figures table show performance stl mtl lcwa cases train halt sets 
results mtl lcwa training halt sets size qualitatively similar size main di erence performance improves considerably larger training sets 
improvement due doubling size training sets larger improvement due mtl stl smaller training sets 
return issue section table error rates stl lcwa mtl lcwa pneumonia problem train test sets cases 
fop stl lcwa mtl lcwa change full advantage lcwa figures showed performance lcwa patterns training halt sets 
knn lcwa training set predictions need retrained new training data available 
take chapter 
mtl nearest neighbor rank error independent test set weight extra tasks compared main task rank sum error function mtl train halt advantage better data halt sets 
train feature weights gradient descent training set training performance halt set starts get worse 
discarding halt set add cases halt set training set making predictions unseen instances 
experiments doubles number cases predictions 
feature weights trained gradient descent half data knn lcwa certainly perform better learned feature weights data 
figures table show performance lcwa patterns train halt set halt set added case base making predictions test set 
feature weights trained cases training halted cases nal predictions cases 
halt set way improves performance considerably 
mtl improves performance di cult backprop halt set way 
backprop need retrain neural net model scratch training halt set patterns 
expensive learning extra patterns follow di erent trajectory clear halting net trained sets data number epochs halt net trained just training set reliable procedure 
chapter 
mtl nearest neighbor fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task performance di erent fractions population varies train halt training patterns room improvement fewer patterns 
summary experiment experiment examined bene mtl function values mtl outperforms stl depending criterion sample size 
mtl having access additional cases 
merely information available case 
mtl uses extra information cases way require information available test cases 
uses extra feature values extra tasks extra inputs 
extra tasks extra information solely chapter 
mtl nearest neighbor rank error independent test set weight extra tasks compared main task rank sum error function mtl train halt runtime table error rates stl lcwa mtl lcwa pneumonia problem train test sets cases combining train halt sets form runtime set cases 
fop stl lcwa mtl lcwa change bias learned capture better regularities domain 
proceeding experiment interesting note experiment considered possible di erent weightings extra tasks including giving weight determined problem best performance resulted giving weight extra task main task 
believe true general 
suspect domains better give weight tothe main task extra tasks 
experiment large mtl bene 
multitask lcwa outperforms traditional single task lcwa domain training done cases 
improvement stl due chapter 
mtl nearest neighbor fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task performance di erent fractions population varies train halt runtime doubling size training set larger improvement mtl stl size training set 
training examples needed stl yield improvement comparable mtl 
ran experiments training sets containing training patterns stl mtl 
shows performance trials traditional stl lcwa mtl lcwa function training set size 
performance improves quickly increasing sample size sample size small 
region cases improvement due mtl equivalent increase number training patterns decreases sample size gets large 
training sets larger cases performance chapter 
mtl nearest neighbor rank sum error independent test set stl lambda mtl lambda total patterns training train halt rank sum error stl mtl function size training halt sets need inductive bias extra tasks sample size large insure excellent performance optimizing main task 
values range may yield better performance stl large training sets 
interesting see optimal value function amount training data problem 
haven done experiment reducing strength mtl bias data available improve performance 
limit nite data best 
experiment mtl extra tasks experiments lab tests available training data usually available patients extra tasks help learn feature weights main task 
suppose extra tasks 
mtl 
sort 
elegance knn lcwa allows treat input extra task help learn better distance metric main task 
suppose main task learn attributes 
predicting main task apply knn lcwa distance metric de ned attributes 
chapter 
mtl nearest neighbor treat attribute extra task predicted attributes distance metric de ned attributes 
feature weights distance metric feature weights predict main task feature weight attribute ignored predictions attribute 
tasks total 
figures show performance stl lcwa mtl lcwa pneumonia risk prediction train test sets containing cases basic measurements extra tasks predicted remaining attributes 
experiment lab tests doing mtl solely input features extra tasks 
attributes extra tasks improve performance main risk prediction task nearly lab tests extra features 
performance rank error metric possibly worse mtl attributes extra tasks 
mtl performance fop probably improved compared stl performance fop comparable stl performance fop probably worse stl 
interesting result 
knn mtl features extra tasks equivalent performing unsupervised learning problem seeing resulting clusters predict main risk task 
fact see improvements performance doing mtl way strongly suggests unsupervised learning ective domain goal predict pneumonia risk unsupervised model 
imagine main task attribute interested learning models functions main task signal 
treating main task attribute giving equal weight tasks ectively turn mtl knn lcwa unsupervised learning algorithms 
domains best thing 
supervised learning typically outperforms unsupervised learning main prediction task known 
mtl intermediate point supervised unsupervised learning 
usually mtl performs best takes advantage fact goal maximize performance task time 
chapter 
mtl nearest neighbor rank error independent test set weight extra tasks compared main task rank sum error function mtl attributes extra tasks train halt horizontal line baseline performance weights initialized 
lower curve performance weights trained mtl function ignores extra tasks completely equivalent stl 
feature weights learned stl mtl goal mtl lcwa learn feature weights yield distance function predictions returned lcwa accurate 
experiments previous sections clearly demonstrate mtl labs extra mtl tasks signi cantly improves performance pneumonia risk prediction 
weights learned stl mtl di er 
table lists feature weights learned stl mtl train halt sets containing cases point training stopped performance halt set best 
rst column gives feature number 
second column gives feature weights learned stl trial 
third column gives feature weights learned trial mtl 
fourth column gives average feature weights learned stl trials 
fth column average mtl 
results single trial average weights averages tend detail learned individual trials 
sixth column signi cance chapter 
mtl nearest neighbor fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task fraction population fraction population percent mortality independent test set percent mortality independent test set weight extra tasks compared main task weight extra tasks compared main task performance di erent fractions population attributes extra mtl tasks train halt varies di erences weights learned stl mtl 
indicate feature weight learned trials stl signi cantly di erent weight learned mtl con dence level respectively 
examining weights individual dimensions high dimension space way questionable 
tests strong meaning valuable focusing attention interesting di erences learned feature weights 
feature weights initialized learning 
stl typically learn feature weights di er learned mtl 
examining feature weights explored stl gradient descent observes stl explore settings feature weights far typically yield performance chapter 
mtl nearest neighbor halt set 
words stl appears signi cantly training set 
mtl learns feature weights perform halt sets 
mtl appears stl 
cases di erence feature weights learned stl mtl considerable 
see example features 
nal note 
learned feature weights far initial value 
pneumonia problem real problem 
hard believe features useful roughly similarly useful predicting risk 
features values near larger 
suspect search space local minima prevents search successfully exploring regions far initial weights 
interesting run experiments times starting di erent initial conditions search procedure immune local minima genetic algorithm 
lead improvements performance lead increased tting training sets 
interesting run experiments weight decay regularization keep feature weights near zero larger weights bene ted learning signi cantly 
summary discussion soft ranks soft rank sum useful domains part ranks functions easier learn functions 
soft ranks broaden utility rank error metrics making easier gradient learning methods 
currently theory predict extra tasks helpful 
theory predict best surprised nd best problem expect optimal sample sizes domains 
knn lcwa perform large sample limit 
extra information training signals extra tasks unnecessary possibly misleading near asymptotic limit 
large training sets probably best 
running experiment test 
currently way choose cross validation 
devised algorithm uses loocv halt set search require additional chapter 
mtl nearest neighbor training examples 
algorithm cient able learn separate extra task 
useful explicitly learns useful extra task main task learn ignore harmful extra tasks setting tasks 
knn lcwa perform feature spaces dimensions 
points tend equidistant dimension increases 
knn lcwa depend di erences distances cases estimates 
way view samples sparse high dimensional space sparse samples rarely closer points points 
neighborhoods rural high dimensional spaces 
neighborhoods dense high dimensional spaces nding feature weights important di cult high dimensional spaces 
conjecture mtl useful high dimensional feature spaces 
pneumonia domain mtl improved performance lcwa lab tests extra tasks 
cross validation parameter determines emphasis extra tasks indicates domain optimal performance results giving near equal weight main task extra tasks 
experiments mtl input features extra tasks indicate unsupervised learning able yield bene ts comparable mtl extra tasks domain 
chapter 
mtl nearest neighbor table feature weights learned stl mtl 
columns weights learned rst trial 
columns average feature weights learned trials 
feature stl trial mtl trial stl avg 
trials mtl avg 
trials signi cance chapter related backprop nets multiple outputs common train neural nets multiple outputs 
done usually multiple outputs encode ectively single task 
example classi cation tasks common output code class see example le cun 
usually bene cial train multiple outputs net separate nets reasons described thesis outputs coding di erent classes task usually thought di erent tasks 
unfortunate 
treating multiple outputs coding di erent classes di erent tasks allows optimize performance class individually stopping early individual outputs adjusting relative learning rates outputs thesis emphasizes mtl tasks heterogeneous outputs coding multi class problem learned improve learning multi class problems 
bene ts mtl multi class problems probably smaller see heterogeneous sets tasks 
backprop net train strongly related tasks time new 
classic nettalk sejnowski rosenberg application uses backprop net learn phonemes stresses applied phonemes 
backprop net natural nettalk goal learn control synthesizer needs phoneme stress commands time 
nettalk early example chapter 
related stress phonemes test set accuracy number pattern presentations nettalk stress task trains quickly ts long phoneme task reaches peak performance 
mtl 
builders nettalk viewed multiple outputs codings single problem independent tasks bene ted trained 
example graphs nettalk learning curves phoneme stress tasks separately 
gure clear stress tasks long phoneme tasks reach peak performance 
stress tasks reach peak performance backprop passes phoneme tasks don reach peak performance backprop passes time stress task signi cantly tted 
better performance easily obtained nettalk doing early stopping stress phoneme tasks individually balancing learning rates di erent outputs reach peak performance roughly time 
dietterich hild bakiri performed thorough comparison nettalk id nettalk text speech domain 
explanation considered backpropagation outperformed id problem backpropagation bene ts sharing hidden units di erent outputs id 
conclude hidden unit sharing mtl help largest di erence chapter 
related learning methods suggest adding sharing id probably worthwhile 
constructive induction constructive induction branches machine learning interested learning representations 
eld attempts assess representation quality single task 
best summary current state eld relation mtl comments sutton constructive induction workshop knows representations key learning performance 
constructive induction science nding representations able incremental improvements performance machine learning systems 
people learn amazingly fast bring representations problem representations learned previous problems 
people constructive induction large di erence performance 
di erence argue di erence people machines way assessing performance 
standard machine learning methodology consider single concept learned 
crux problem 
paradigm constructive induction doomed appear small incremental second order ect 
single problem constructive induction rst half training set learn better representation second half potentially improve performance second half 
learning 
learning occurs early training 
may possible detect improvements due constructive induction paradigm second order 
swamped rst order ects quality base learning system importantly quality original representation 
chapter 
related way study constructive induction 
need methodology away testing methods emphasize minimize ect constructive induction 
standard concept learning task abandoned 
look natural learning systems people get better sense real task facing 
think nd key di erence practical purposes people face task series tasks 
di erent tasks di erent solutions share useful representations 
completely breaks dilemma facing facing constructive induction rst order ect 
come nth task excellent representation learned preceding tasks learn dramatically faster system constructive induction 
system constructive induction learn faster nth task st 
constructive induction major ect ect ect 
importantly sensitive measure quality constructive induction methods measure tricky issues original learner original representation 
things factored 
rst time see pure ects due changes representation 
hope enable evaluate methods better lead faster progress eld 
sutton early reinforcement learning recognizes importance learning multiple examples 
methods develops signi cantly address mtl clear original motivation identical mtl broad importance looking series related tasks non stationary tracking task opposed conventional single learning tasks 
single learning tasks certainly proved extremely useful limited ways exploring important issues representation change identi cation relevant irrelevant features 
meta learning issues may chapter 
related small second order ect single learning task large ect continuing sequence related learning tasks 
cross task learning may key powerful human level learning abilities 
sutton serial transfer transferring learned structure related tasks new 
early sequential transfer learned structure neural nets pratt pratt sharkey sharkey clearly demonstrates learned task bias tasks 
unfortunately failed nd improvements generalization performance main bene speeding learning 
mitchell thrun devised serial transfer method called explanation neural nets ebnn thrun mitchell thrun tangent prop simard yields improved generalization trained sequence learned tasks 
ebnn trains partial derivative outputs respect inputs time outputs trained target values 
partial derivative information computed previously learned related models 
example partial derivative output previously learned model strong positive respect input ebnn biases new model trained strong positive derivative respect input 
noteworthy component ebnn heuristic uses moderate strength bias 
current instance predicted previous model ebnn assumes partial derivative information previous model relevant new model gives weight tangent prop error term 
important applying constraint directly output new task stronger bias applying additional output shares large hidden layer new task 
ability moderate strength ebnn bias allows ebnn degrade gracefully performance stl cases previous tasks related new task 
disadvantage ebnn compared mtl backprop ebnn access internal representations learned backprop previously learned tasks 
chapter 
related expect ebnn feature selection capabilities comparable better mtl backprop information captured input output relations partial derivatives poorer eavesdropping features developed tasks 
derivatives sensitive noise sources nonlinearity mtl backprop bene ebnn noisy related tasks related tasks highly nonlinear ways match nearly perfectly tasks 
ebnn mtl backprop di erent mechanisms may bene different kinds task relationships combining may bene cial 
sullivan exploring thesis attempt build life long learning robots 
part performed comparison ebnn mtl backprop robot perception task 
shows percent improvement due ebnn mtl backprop traditional stl backprop robot domain function number training examples 
percent improvement stl mtl ebnn sample size training patterns improvement ebnn mtl backprop stl backprop robot life long learning task courtesy joseph sullivan 
domain mtl backprop yields signi cantly bene ebnn sullivan reports combining methods problem performs better mtl backprop ebnn suggesting bene ts ebnn mtl chapter 
related backprop di erent 
sullivan thrun devised serial transfer mechanism called tc knn clusters previously learned tasks sets related tasks 
tc knn attribute weights learned previous tasks cluster similar new task new task number training patterns new task small support accurate learning 
tc similar ways mtl knn method chapter 
main di erence mtl knn attempts learn set attribute weights yields optimal performance main task extra tasks 
tc method learn set attribute weights optimal group tasks 
uses weights optimized previous task new task training patterns new task available optimizing attribute weights new task feasible 
combining mtl knn tc yield method bene ts 
breiman friedman method called combines sequential parallel learning 
takes advantage correlations di erent prediction tasks 
models di erent tasks trained separately stl predictions separately learned models combined making nal predictions 
sharing predictions models internal structure learned models quite di erent mtl combining methods straightforward domains 
hints hinton suggested generalization arti cial neural nets improve nets learned represent underlying regularities domain better 
suddarth abu mostafa rst recognize accomplished providing extra information outputs net 
suddarth suddarth holden extra outputs inject rule hints networks learn 
mtl extra tasks carefully engineered coerce net learn speci internal representations 
centerline extra tasks alvinn domain chapter 
related section examples rule injection hints 
suddarth holden successful making approach real problems 
abu mostafa provides hints backprop nets extra terms error signal backpropagated main task output 
extra error terms constrain learned satisfy desired properties main task monotonicity sill abu mostafa symmetry transitivity respect certain sets inputs 
mtl currently extra error terms task outputs easily concert techniques 
ebnn provides extra information output adding extra error term output error term partial derivative form hint information extra error term comes expertise domain previously learned related tasks 
unsupervised learning showed section mtl backprop depends heretofore unrecognized ability backprop discover relationships tasks explicit training information task relationships 
ect mtl backprop unsupervised clustering outputs hidden layer representations 
come surprise mtl similar ways methods clustering unsupervised learning 
example small changes indices cobweb fisher probabilistic information metric yields metric suitable judging splits multitask decision trees 
cobweb considers features tasks predict mtl decision trees allow user specify signals inputs training signals 
easier create additional tasks committing extra training information available run time learning simpler domains input features reasonably predicted 
martin martin explore concept formation systems cobweb extended acquire overlapping concept descriptions 
system incremental concept learner learns overlapping probabilistic descriptions improve predictive accuracy 
de sa minimizing disagreement algorithm mda de sa unsupervised chapter 
related learning method similar spirit mtl backprop 
mda multiple unsupervised learning tasks trained parallel bias supervisory signals unsupervised tasks 
point view helps unify approaches follows mtl backprop attempt bring unsupervised learning component backpropagation supervised learning method giving extra information mtl net extra training signals applied extra outputs net 
mda attempt bring supervised learning component quantization unsupervised learning method giving auxiliary signals vector quantization process extra training signals derived vector quantization processes learning related unsupervised problems 
goal mtl backprop mda improve generalization capability learned 
chapter joint de sa 
mda supervised unsupervised learning components de sa interested understanding information best supervised unsupervised learning 
theories parallel transfer attempts develop theories parallel transfer abu mostafa baxter 
advanced far baxter theory representation learning neural nets 
shows number training patterns required learn strongly related tasks net grows bound minimum number training examples required learn single task bound number examples required learn tasks independently 
bound says su ciently large number tasks number training examples needed learn nth task gets smaller previous tasks learned net 
true assume tasks learned accurately common compact representation training patterns task independently sampled learning procedure empirical risk minimizer able bene training signals chapter 
related multiple tasks 
unfortunately theory developed far little relation real world uses mtl 
limitations current theory theory assumes training patterns task independent apply uses mtl training patterns tasks 
theory de ned notion task relatedness 
lieu current theory assumptions tasks overlap 
example baxter representation learning theory assumes tasks learned shared hidden layer small relative number tasks trained 
words theory assumes bottleneck hidden layer appropriate architecture tasks 
bottleneck assumption rarely satis ed practice tasks strongly related 
usually nd optimal performance requires increasing number hidden units shared hidden layer number tasks increases 
empirical nding con icts assumption theory hidden layer constant size number tasks 
mtl applied number tasks small relative number hidden units hidden layer mtl applied tasks strongly related 
theory yields loose worst case bounds 
possible create synthetic problems satisfy assumptions theory increasing number tasks hurts performance helping theory predicts 
results consistent theory bounds loose allow 
theory assumptions search procedure easily justi ed unable account behaviors search procedure practice critical 
just example early stopping done correctly mtl backprop hurts performance helping 
theory unable account critical phenomena early stopping model nets trained 
failure model search procedure serious 
consider arti cial data set training signals multiple tasks generated common pre de ned hidden layer 
mtl backprop nets trained tasks unable learn tasks trained number hidden units generator net theory predicts net number hidden units generator net perform best 
practice necessary hidden units net trained generator net 
backpropagation greedy search procedure perform tightly constrained search spaces 
nets trained backpropagation need extra hidden units facilitate search smaller number hidden units su cient represent model learned 
theory model search procedures train nets practice di erent predictions observed practice di cult 
chapter 
related fundamental problem theories inductive transfer developed far restricted capacity arguments xes size model class xing size hidden layer increases complexity learned making predict outputs odds nding model xed model space falsely appears high accuracy reduced 
equivalent saying task training signals accounted xed number bits probability model captured bits reliably predict patterns greater 
capacity arti cial neural nets trained backprop poorly understood 
number hidden units poor measure net capacity 
training weights net changes ective capacity 
train nets stl mtl achieve maximum accuracy training halt sets claim net capacity trained 
net large trained zero error training set 
large nets trained nal ective capacity 
empirical results suggest best performance usually requires hidden units number tasks increases 
part reason small nets nonlinear training set larger weights 
nonlinear 
larger nets nonlinear training set smaller weights weights available 
nonlinear 
larger nets learn smoother functions training set 
theory account phenomena ignores training procedure backprop applies nets restricted capacity 
methods handling missing data application mtl take features missing run time available training set outputs inputs 
ways handle missing values 
approach treat missing feature separate learning problem predictions missing values inputs 
tried pneumonia problem achieve performance comparable mtl domains works 
approaches missing data include marginalizing chapter 
related missing values learned probabilistic models little rubin tresp ahmad methods em iteratively reestimate missing values current estimates data density ghahramani jordan 
bayesian graphical models models trained supervised learning usually model likelihood output inputs usually learn conditional probability output inputs 
mtl better predictions outputs inputs learns complete models training model multiple tasks drawn domain helps model better learn regularities domain helps prediction 
bayesian methods frequently called graphical models learn domain models complete usually learned supervised learning 
learn full joint probability distribution function relates inputs outputs 
comprehensiveness models allows handle missing values 
graphical models mtl attempting similar things try better predictions learning complete models 
mtl largest di erences graphical models 
graphical models strong probability semantics normative normative approximating procedures doing learning making predictions learned 

graphical models attempt model entire joint probability density features outputs doing treat inputs outputs alike 

graphical models attempt learn models causal semantics 
di erence point graphical models practical strong probability semantics desirable 
di erence may advantage 
main strength supervised learning unsupervised learning supervised learning knows outputs inputs free yields better prediction outputs inputs 
supervised learning tradeo reduced accuracy chapter 
related outputs order achieve increased delity models inputs 
graphical models attempt learn models capture causal structure domain constrained traditional unsupervised learning techniques may minimize di culties associated trying learn models features 
models learned bayesian graphical model methods may learn structure domain needed optimal prediction prespeci ed set outputs 
clear just graphical models represent better approach accomplishing mtl accomplishes extra complexity models inferior traditional supervised learning mtl 
uses mtl committee machines munro extra tasks improve generalization performance committee machine combines predictions multiple learned experts 
committee machines better errors di erent committee members decorrelated di erent extra task committee member bias learns main task 
committee member learns main task slightly di erent way performance committee improves 
committee machines trained extra tasks viewed mtl architectures complex simple fully connected mtl architectures 
interesting feature committee mtl architectures multiple copies main task improves performance main task 
ect observed simpler fully connected mtl nets caruana 
dietterich bakiri examine sophisticated approach bene tting multiple copies main task multi bit error correcting codes output representation 
input reconstruction ire pomerleau alvinn system arti cial neural nets learn steer autonomous vehicle 
important issues arose alvinn research assess chapter 
related con dences steering predictions net 
pomerleau developed method called ire input reconstruction help assess con dences predictions 
shows ire net 
encoder output array sharp left straight ahead sharp right output units hidden units sensor input retina pomerleau 
ire net assessing prediction con dences alvinn courtesy dean input net retina image road front vehicle 
sets outputs 
rst set outputs distributed output encoding represent steering direction 
call main task 
second set outputs rectangular image outputs trained reconstruct input retina image 
reconstruction trained parallel main steering task shares hidden layer steering task 
hidden layer small prevent net learning direct connections retina inputs reconstructed output insure hidden layer representation retina reconstruction main steering task 
assessing closely reconstructed image matches input images ire able chapter 
related estimate internal representations capture structure particular road image 
image reconstructed presumably hidden layer representation job understanding road image expects steering direction predicted net reliable 
image poorly reconstructed hidden layer presumably recognize image expect steering prediction poorer 
goal ire provide mechanism assessing con dences predictions alvinn net image reconstruction extra task improve performance main steering task 
pomerleau points ire potential hurt performance main steering task training hidden layer learn steering features necessary reconstruct image unrelated steering 
pomerleau notes practice ire hurt performance main steering task 
pomerleau goes suggest complex ire architecture separates hidden layer reconstruction hidden layer main task 
architecture virtually identical mtl backprop architecture separate private public hidden layers described section 
shown pomerleau alvinn nets distributed output coding main steering task 
continuous output unit code entire steering range uses outputs trained reproduce gaussian bump centered correct steering angle 
distributed output representation improves accuracy reduces variance steering predictions 
clear relation multiple output representation mtl backprop 
may similar error correcting output codes dietterich bakiri mtl 
example steering accuracy improve distributed outputs trained separate nets de correlate errors tted gaussian bump accurate 
trained single alvinn net pomerleau steering performance probably improved doing early stopping outputs individually 
better performance achieved training mtl nets outputs net outputs net optimized perform best output time 
chapter 
related task speci selective attention baluja thesis baluja considers problem training backprop nets problems knowing look improves recognition accuracy 
example trains backprop nets locate recognize sequence images move input retina predictable learnable fashion 
main result shows noise input images form spurious show random locations net learns better locate identify non spurious net predict non spurious symbol appear image prediction focus attention net sees image 
focus attention mechanism train hidden layer jointly prediction recognition tasks mtl 
prediction task modify inputs net sees image ects net learns trained backpropagation 
di erent approach related extra tasks case location prediction improve performance main tasks case symbol localization recognition 
main task components location recognition baluja performs experiments comparing separate nets trained tasks single net trained tasks 
results experiments noise high bene training tasks backprop net 
chapter contributions discussion contributions thesis provided clear demonstration generalization performance improved learning sets related tasks learning time chapter 
thesis done backpropagation arti cial neural nets chapters algorithm multitask learning nearest neighbor kernel methods chapter sketch algorithm multitask learning decision trees section 
mature successful learning methods date 
fact multitask learning applied machine learning methods demonstrates generality potential impact research multitask transfer 
applied multitask learning arti cial neural nets nearest neighbor number problems real synthetic 
multitask learning helps generalization performance rarely hurts generalization performance 
experience problems yielded number prescriptions get best results counter intuitive important success chapter 
developed method automatically balancing relative importance extra tasks nearest neighbor chapter 
arti cial neural nets method auto chapter 
contributions discussion matically adjusting rate di erent tasks learn maximizes opportunity bene cial cross task transfer section 
method multitask learning better easier may subsume class frequency balancing techniques applied real world problems 
showed learning problems opportunities multitask learning problems rst overly sanitized standard practice single task learning paradigm currently dominates machine learning sections chapter 
stl throwing away valuable information realizing merely know 
multitask learning way making information easily traditional single task mold 
thesis demonstrated bene extra tasks substantial 
bene task usually small ect multiple extra tasks additive bene large number extra tasks large 
careful experiments able show bene ts multitask learning due extra information contained training signals extra tasks due property backpropagation nets achieved way sections 
able elucidate di erent kinds relationships tasks enable bene learned parallel chapter 
relationships serve heuristics help identify backpropagation bene training signals extra tasks 
may adequate theory predict extra tasks helpful believe similar set heuristics developed multitask learning procedure 
examine happening inside arti cial neural nets learning related tasks parallel developed method measuring di erent tasks share hidden layer representations section 
applied tasks know related di erent tasks tasks related tasks share features developed hidden layer section 
interestingly happen backpropagation doing form unsupervised clustering tasks hidden layer representations 
mtl backprop clustering tasks function space chapter 
contributions discussion feature space 
suspect heretofore unrecognized largely capability backpropagation perform unsupervised clustering may useful multitask learning general clustering 
particularly interesting helps forge link supervised unsupervised learning 
empirical analysis bene certain features extra inputs extra outputs clearly demonstrates bene feature input quite di erent bene feature output 
able demonstrate domains features inputs useful outputs chapter 
features bene cial inputs outputs devised demonstrated multitask learning method allows backprop net features inputs outputs time section 
method yielded better performance features just extra input features just extra multitask outputs 
acquiring domain speci inductive bias subject usual knowledge acquisition bottleneck 
multitask learning allows inductive bias acquired training signals related additional tasks drawn domain 
inductive learning probably isn going keep getting better background knowledge isn brought bear learning problem 
multitask learning way bringing domain speci background knowledge bear exploiting thing current learning algorithms best tabula rasa learning examples 
contributions thesis directly connected multitask learning empirical study generalization performance vs capacity backprop nets trained early stopping appendix development rank error metrics rankprop section appendix soft ranks section appendix 
believe rank metrics useful number problems currently interest machine learning information retrieval 
important contribution thesis identi ed number situations commonly arise real world domains multitask learning applicable chapter 
surprising standard test problems machine learning today multitask problems 
conjecture machine learning chapter 
contributions discussion applied real world problems opportunities multitask learning increase 
discussion predictions multiple tasks mtl trains multiple tasks parallel learner 
mean learned model predictions multiple tasks 
reason training multiple tasks learner tasks bene information contained training signals tasks reduce number models learned 
tradeo mediocre performance tasks optimal performance task 
case better optimize performance important task time allow performance extra tasks degrade 
adaptive learning rates mtl backprop see section weight extra tasks mtl knn lcwa see section tradeo explicit learning ignore extra tasks achieve better performance main task 
architecture reserves private hidden layer main task training extra tasks resource limited public hidden layer see section example optimizing training favor main task 
current standard approach early stopping backprop nets training aggregate test set measure sum squared error outputs begins get worse 
early stopping mtl important apply task individually tasks train rate 
regularization procedures decay early stopping important adjust weight decay parameters task individually 
reason early stopping weight decay mtl 
early stopping train mtl net tasks take snapshots net performance task best continue training mtl net peak performance important task reached 
cient training nets main tasks tasks di erent weight decay parameters optimized net main task 
advantage early chapter 
contributions discussion stopping weight decay mtl weight decay restricts net capacity forces sharing 
discuss section sharing bad 
early stopping allows independent control regularization prevent tting pressure sharing 
sharing pressure controlled architecture size hidden layer regularization controlled early stopping 
extra gives control better performance mtl 
exibility sharing architecture capacity important lesson learned important provide strong bias sharing usually hurts performance 
tasks di erent alike case important allow tasks learn reasonably independent models overlap common structure learned models 
example observe mtl backprop performance drops size shared hidden layer smaller sum sizes stl hidden layers provide performance tasks trained separately 
making hidden layer tight promote sharing usually hurts performance 
time observe tight net helps mtl performance synthetic tasks generated generator net small hidden layer 
training tasks net just right size little larger usually improve performance 
real tasks rarely strongly related 
applications mtl backprop single fully connected hidden layer shared equally tasks 
complex net architectures better 
example bene cial private hidden layer main task separate public hidden layer shared main task extra tasks see section 
similarly features inputs extra output tasks architectures disjoint hidden layers prevent outputs seeing corresponding input signals see 
private hidden layers private hidden layer task reduce opportunities sharing reduce bene ts mtl 
principled ways determine architecture best problem 
fortunately simple architectures chapter 
contributions discussion optimally 
bengio experiment di erent architectures mtl backprop nets 
deeper net architectures better mtl backprop extra hidden layer possible task form non linear functions hidden layer representation developed tasks 
mtl experiments nets deeper hidden layer 
experiments observe bene ts deeper nets 
nets took longer train 
suspect reasons observe bene deeper nets current backprop algorithms training deep nets 
modi cation way deep nets trained prove bene cial mtl train standard mtl net hidden layer training rst task begins main task begins aggregate error tasks begins insert new randomly initialized hidden layer hidden layer outputs continue training new deeper net 
early training inputs new hidden layer deeper net hidden layer representation learned shallower mtl net 
training progresses rst hidden layer new second hidden layer updated backprop 
potential advantage approach second hidden layer opportunity nonlinearly combine representations developed di erent tasks rst hidden layer 
approach similar architecture combine mtl feature nets allow backpropagation change representation learned rst hidden layer 
see section process inserting new hidden layers repeated additional hidden layers performance 
tried 
computational cost main goal mtl improve generalization reduce computational cost 
ect mtl learning speed 
backprop nets mtl net usually larger stl net requires computation backprop pass 
tasks need learned training mtl net usually requires total computation training individual stl nets tasks 
advantage disappears chapter 
contributions discussion architecture learning rates optimized main task training multiple mtl nets probably costly training multiple stl nets 
nd tasks trained mtl need fewer epochs tasks trained 
partially compensates extra computational cost mtl epoch 
mtl nets complex training curves training test set error curves multimodal output early stopping di cult 
train mtl nets past apparent early stopping point sure performance main task start getting better 
table shows time required train stl mtl nets problems thesis 
timing results actual experiments 
realistic measure relative cost stl mtl problems results theoretical analysis complexity 
larger mtl nets machine cache size smaller stl nets penalty cache misses included measured cost 
theoretical analyses algorithm complexity ignore important issues 
results table experiments run di erent workstations sun dec alphas intel di erent memory size memory architectures cpu speeds 
problem stl mtl run architecture 
main extra cost training mtl nets mtl nets require larger hidden layers 
number weights backprop net grows linearly number hidden units hidden layer fully connected inputs outputs 
largest cost training mtl nets mtl nets trained longer epochs stl nets trained tasks 
mtl nets train slower multimodal behavior mtl training curves early stopping di cult trains longer insure stopped prematurely 
third largest cost training mtl nets cost updating weights connect hidden layer extra outputs 
extra tasks cost usually small 
extra training signals mtl training test sets larger stl training test sets may computer memory easily 
results table combine ects 
tasks chapter 
contributions discussion table relative speed stl backprop mtl backprop problems thesis 
time trial columns clock time required run single trial problem 
problems run di erent machines speed di erent problems compared 
problem stl mtl run architectures comparable 
problem method stl mtl run number hidden units preliminary experiments suggested worked 
cases mtl run fewer hidden units optimal larger nets expensive train 
means optimal results mtl take longer cases reported 
nal column ratio telling longer took train mtl stl problem 
input extra hidden units time trial time problem features outputs stl mtl stl mtl ratio parity hu hu hr hr alvinn hu hu hr hr medis hu hu hr hr port hu hu hr hr average table mtl nets take average times computation train stl nets 
seen entries table problem di erence stl mtl problem dependent 
mtl net trained extra cost mtl net predictions compared similar sized stl net extra weights hidden layer extra tasks needed training completed 
predictions extra tasks usually ignored weights nodes associated extra tasks removed net prediction kept small fast possible 
mtl nets larger stl nets main task 
mtl nets larger slower stl nets weights outputs extra tasks removed 
nearest neighbor kernel regression decision trees mtl adds little cost training mtl model 
extra cost computation needed evaluate performance multiple tasks main task 
small constant factor easily dominated expensive steps methods computing distances cases nding nearest neighbors nding best threshold splits continuous attributes decision trees signi cant additional cost chapter 
contributions discussion mtl algorithms cross validating relative weight main extra tasks 
parameters control task selection real world domains features feature selection serious problem 
mtl provides machinery allows features inputs features extra outputs features inputs extra outputs 
multitask learning giving options feature selection problem worse 
need develop methods ciently determine available features inputs outputs inputs outputs 
input features extra outputs may large number extra tasks mtl 
extra tasks may unrelated main task 
related harmful mtl algorithm 
need task selection procedures analogous feature selection procedures currently machine learning select large set potential extra tasks related helpful main task 
discuss sections nding tasks related main task nding tasks helpful main task necessarily thing 
inductive transfer hurt mtl improve performance 
medis pneumonia domain prediction performance dropped high risk patients extra sse output added mtl rankprop net predicting risk see section performance patients improved 
result consistent model relative strengths weaknesses main extra task problem 
mtl source inductive bias 
inductive biases help 
inductive biases hurt 
depends problem 
learning tasks don know internal structure advance 
internal structural sharing critical success mtl way predict advance task bene mtl task 
measurements mutual information tasks mutual information chapter 
contributions discussion tasks input features pairwise correlations tasks suggest opportunity structural sharing heuristics 
furthermore reliably predict structural overlap tasks don know particular algorithm backprop able discover exploit 
operational theory tasks help hurt mtl 
safest approach treat mtl tool tested problem 
fortunately problems mtl helps 
reasons intuition useful extra tasks correct 
chapter attempt collect heuristics place 
second tasks help main task appear hurt main task 
easily create harmful extra tasks synthetic problems tasks don arise practice 
bene helpful extra tasks larger loss due harmful helpful extra tasks 
related tasks 
important open problems inductive transfer characterize formally heuristically tasks need related mtl improve generalization accuracy 
lack adequate operational de nition task relatedness obstacles standing way development useful theories inductive transfer 
characteristics task relatedness clear 
di erent tasks function independent noise added task signals clearly tasks related 
tasks predict di erent aspects health individual tasks related tasks predict di erent aspects health di erent individuals 
tasks negatively correlated negative mutual information related 
tasks correlation mutual information related see section correlation representations learn learning algorithm 
careful 
di erence tasks related tasks helpful 
related tasks may harmful trained mtl algorithms 
mean tasks related just chapter 
contributions discussion mtl algorithm unable bene relationship 
algorithm needs improved 
hand unrelated tasks may helpful 
just tasks help trained necessarily mean related 
example injecting noise extra output backprop net improves generalization outputs regularizing hidden layer mean noise task related tasks helps 
tasks strongly related necessarily ones helpful 
example identical tasks maximally related provides additional information 
relatedness symmetric bene may 
mtl algorithm task help task task hurt task see section 
task related bene ts vice versa 
precise de nition relatedness able devise far tasks related exists algorithm learns better training data modi cation allows learn training data precise de nition operational 
may easy demonstrate training signals improve learning particular algorithm di cult show exist algorithms modi cations perform better just training signals notion task relatedness misses mark 
don care tasks related 
just care tasks help 

really want mtl algorithms bene tasks related 
attempt achieve need notion task relatedness goes statements task improves performance task trained method 
task improve performance task trained method want bene ts 
improve bene ts 
furthermore task helps task method just task injects noise method just task reduces capacity method left task just task increases ective learning rate method similar reason task task related want know 
probably better chapter 
contributions discussion controllable ways introducing ect method control won need training signals task train task may theory relatedness allows reliably predict tasks help hurt inductive transfer 
focusing part ort ways ciently determine tasks bene cially related task selection developing methods robust interference unrelated extra tasks 
algorithms automatically adjust mtl bias heuristics cross validation important steps making mtl useful practice 
important continue developing heuristics better enable characterize recognize related tasks real problems 
mtl psychologically plausible 
mtl intended cognitive model 
worn analogy mtl intended help planes better explain birds interesting ask evidence mtl mechanisms natural learning mtl suggest directions cognitive neurophysiological research 
inductive transfer occurs human learning probably subject debate 
common saying learn know 
need learned know suggests learn learned 
humans tackle new problems bring bear learned related problems 
interesting speculate natural de ne related problems 
may evidence psychology natural cluster tasks 
natural usually context information cues learning recall performance 
contrived example learn math diving learn proofs better underwater dry land 
context underwater learning activity linked performance activity 
contextual clues essential elements system natural attempts predict tasks related 
heuristic may help prevent natural trying share representations tasks chapter 
contributions discussion strongly related 
learning cluster tasks auxiliary information context data collected kind task data recognition tasks vs speaking tasks vs positioning tasks may provide valuable heuristics nding related tasks mtl 
example example tasks machine learning associated short text description methods information retrieval useful clustering tasks mtl 
seemingly large di erence mtl natural intelligence animals don save experiences learn things need learn parallel point time 
mtl emphasizes parallel learning transfer serial process evident natural learning 
mtl psychologically implausible 
necessarily 
natural experience di erent tasks usually interleaved 
learn task moving task 
general trend learning simpler tasks learning complex tasks phenomenon mtl addresses 
learning algorithms mtl thesis memoryless batch algorithms 
store experience learning single explicit training phase 
algorithms depend system embedded collect training data coherent fashion training 
learning systems memory interleave learning experience multiple tasks perform parallel learning transfer 
online non batch model mtl easily perform interleaved learning transfer related tasks 
key parallel transfer learning completely nishes task tasks potential share learned related tasks 
brief discussion attempt argue mtl plausible psychologically 
little known mechanisms underlying natural intelligence prefer claims psychological plausibility mtl 
easy mtl online observation experience nature rarely comes monolithic single task chunks see little reason believe mtl psychologically plausible inductive transfer methods 
statement con dent making natural mtl mechanisms complex simple ones explore thesis 
chapter 
contributions discussion parallel transfer 
inductive transfer idea 
try learning related tasks time 
wouldn easier learn tasks time save learning main task 
probably 
reasons parallel transfer better serial transfer 
important doing tabula rasa learning know task contained training data task 
train tasks independently transfer models learned task training signals tasks probably lost information contained training signals captured models 
representations learned achieve performance tasks trained individually may representations learner learning related task nd useful 
di cult know information training data useful task doing inductive transfer models trained considering main task risks losing valuable information compared training tasks time 
problem important technique optimized maximize performance main task 
optimize learning extra tasks extra tasks learned training main task begins 
advantage sequential transfer steps sequence need optimized maximize performance step 
advantage parallel learning task access representation tasks evolve learning 
mtl allows tasks see full trajectory tasks learning just nal state learning completes 
di erence dancing partner dancing partner nished 
advantages subtle potentially signi cant 
example tasks early search lead complex representation shaping sharing search 
happen tasks access representation early search 
related di culty di erent representations learning problem 
learning system choices better select representation useful inductive transfer chapter 
contributions discussion useful tasks 
possible learning previous task completed learning related task attempted 
key mtl tasks share substructure 
detect shared substructure best search space hypotheses nd hypotheses tasks 
searching space hypothesis task considering hypotheses perform task reduces transfer 
choose particular structural hypothesis shares substructure task lose transfer 
signi cant advantage parallel learning serial learning tasks bene mutually 
task learns better trained task task learns better trained task sequential transfer forced train tasks sequence achieve bene ts 
problem interested tasks 
task help main task task doesn matter 
just train necessarily case 
expect task help task task learned better wouldn worry training 
way learn task better train parallel task task signals available simultaneously itis probably suboptimal de ne sequence tasks train serially 
serial transfer naturally parallel transfer domains tasks naturally arrive sequences 
principle motivation life long learning 
showed section parallel transfer serial transfer previously learned models generate synthetic data extra mtl outputs learning current task unfortunate incur expense training new models new task arrives 
reuse old models just add new models 
sullivan exploring techniques combine serial parallel transfer thesis 
approach may trying net growing algorithms potential ective growing mtl nets able grow mtl nets dynamically new tasks arise 
beauty methods freeze hidden units learned previously making available subsequent learning new features 
may methods chapter 
contributions discussion modi ed mtl 
example adding hidden unit time promote sharing aggressively 
hidden units need added time new unit mtl task 
intelligibility main goal mtl improve generalization performance learn intelligible models 
breiman suggested uncertainty principle relating model intelligibility accuracy accuracy breiman principle says ways 
models accurate going intelligible 
mtl models usually accurate relation suggests may intelligible 
nets mtl backprop usually hidden units connection weights stl probably understanding net model di cult 
main reason attempted open mtl nets trained thesis optimal mtl performance usually requires nets large analyzing nets hard 
domains natural dimensional representations input variables image recognition domains retinas inputs di cult interpret kind hidden unit activation diagrams nets large mtl nets 
hidden units mtl net appear sensible activation patterns necessarily mean understand net predictions 
hidden units say problem severe attempt understand role hidden unit combined form nal prediction 
trying understand stl mtl nets currently trying methods rule extraction try understand di erence stl mtl nets 
learn rules mimic stl net mtl net look di erences rules trying learn rules directly represent di erence stl mtl nets 
successful approach give chapter 
contributions discussion insight mtl net learns generalize better stl net 
mtl complexity important lesson learned applying mtl real problems mtl practitioner get involved problem data sanitized 
mtl bene ts extra information engineered away traditional stl techniques able 
standard problems collections uci machine learning repository suitable mtl research carefully simpli ed suitable stl 
opportunities applying mtl decrease removed raw data data collection process 
mtl provides new ways information obvious traditional stl point view 
necessary nudge gently 
charge data collection data management provide extra information mtl 
uncommon told asked 
experienced applying mtl easily opportunities 
best suggestion applying mtl new domain collect consider collecting bit information possibly imagine collecting throw away don collect pieces absolutely certain 
ll probably wrong half time 
part mtl inductive transfer exciting provides hooks di erent kinds information traditionally di cult exploit 
combining mtl boosting bagging breiman boosting schapire freund error correcting codes dietterich bakiri voting schemes combine multiple predictions task di erent learned models exciting advance machine learning 
hopefully bene ts provided mechanisms partially orthogonal bene ts mtl 
case combining mtl boosting methods generalize better method 
interesting direction explore lines chapter 
contributions discussion discovery thesis training multiple copies task mtl backprop net improve performance 
suspect may due boosting mechanism arises net initialized di erent random weights copies task outputs shared hidden units 
mtl learning methods thesis discusses mtl mainly context arti cial neural nets trained backpropagation methods nearest neighbor kernel regression 
mtl particular algorithm 
approach learning attempts improve accuracy leveraging information contained training signals related tasks 
mtl applied di erent learning algorithms ways mtl algorithm 
sketch algorithm mtl decision trees basic recursive step top induction decision trees tdidt determine available splits add current decision tree 
typically done information gain metric measures class purity improved available splits 
class purity measure accuracy task improved adding split 
decision trees usually single task leaves assign cases class task 
multitask decision trees possible leaves assign cases classes tasks 
example leaf assign cases class task class task 
advantage multiclass decision trees 
decision trees induced top greedy fashion signi cant ort spent greedy induction process nd splits 
split installed tree subsequent decisions ected 
splits decision tree cause data rapidly sparse 
usually ord install useless suboptimal splits large training set 
usually information available splits separate classes single task 
multitask decision tree evaluates splits separate classes multiple tasks 
multiple tasks related preferring splits utility chapter 
contributions discussion multiple tasks improve quality selected splits 
basic assumption boundaries classes di erent related tasks tend lay similar regions input space 
preferring splits bene multiple tasks help class boundaries reliably 
bene preferring splits utility multiple tasks dramatic inducing decision trees small samples 
little training data important nd splits properly discriminate underlying structure problem 
failure results leaf classes high purity training data represent regions high purity real problem distribution 
splits multiple tasks 
basic approach straightforward compute information gain split task individually combine gains select split best aggregate performance 
mtl decision tree algorithm caruana combines task gains averaging selected splits ones average utility tasks highest 
problem simple averaging 
splits task necessarily task 
split decision tree ects nodes di cult multitask decision tree isolate tasks di er 
mtl backprop nets capacity hidden units specialize di erent tasks 
mtl backprop worsens performance insu cient capacity specialization 
number tasks grows large fewer splits tree optimal task 
recursive splitting data structure needed task learned 
words tasks starve multiclass decision tree 
bad task main task 
goal mtl improve performance task leveraging information contained training signals tasks 
care mtl decision tree grown task performs task 
task important grow separate mtl decision tree 
gives freedom splits preferred tasks help main task 
averaging information gain tasks places tasks equal footing 
chapter 
contributions discussion average allows bias splits favor speci tasks 
assume main task weight 
weight extra task near task ignored contributes little aggregate information gain 
conversely task weight installed splits sensitive gain task 
hillclimbing hold set learn task weights yield generalization main task 
unfortunately partial derivatives performance respect task weights discontinuous di erentiable small weight changes ect learned tree large changes performance occur test installed node suddenly changes 
gradient descent 
fortunately simple accounting tricks interior nodes decision tree keep track smallest weight changes alter learned tree 
allows steepest descent hillclimbing learn task weights 
approach learning task weights requires decision tree induction fast run times 
may practical problems large data sets attributes 
danger tting test set small 
attractive feature scheme weights learned inspected see extra tasks bene cially related main task 
combining mtl learning methods learning methods bene mtl 
example reinforcement learning challenging learning method supervisory signals received environment infrequent rewards success failure positive negative reward scale 
learning di cult learner may need perform complex series actions reward received 
contrast traditional supervised learning action associated training signal guides learner performance 
training reinforcement learner multiple related reinforcement learning problems give rewards di erent states di erent sequences behavior way guide reinforcement learning learn behaviors 
example reinforcement learner learning navigate start position goal position rewards related tasks crossing room chapter 
contributions discussion wall passing doorway crossing trajectory second time negative reward trajectories smooth trajectories hit objects trajectories go close objects extra tasks viewed way giving reinforcement learning partial credit successfully executing behaviors bene cial success main task 
applying mtl learning methods important direction research 
learning areas interested applying mtl methods scienti discovery methods unsupervised learning 
led rst consider mtl trying answer simple question backprop net scienti discovery 
backprop net trained single set data say data points planet orbiting sun learn simple interpolating model data 
discover general law gravitation 
backprop net trained dozens di erent problems depended gravity way planets orbiting sun stars orbiting galactic center moons orbiting planets apples falling earth biased learn single comprehensive model captured discovery tasks discover gravity 
course example 
original motivation thesis poses challenging potentially rewarding direction research 
forging stronger connection mtl unsupervised learning important clear mtl depends implicitly unsupervised learning 
may supervisory training signals task individually training signals supervision tasks related shared 
discovered mtl algorithm unsupervised learning mechanism 
better understanding role unsupervised learning mtl learning better important directions improving mtl 
chapter bibliography abu mostafa learning hints neural networks journal complexity pp 

abu mostafa hints vc dimension neural computation 
abu mostafa hints neural computation pp 

baluja expectation selective attention doctoral thesis carnegie mellon university cmu cs 
baluja pomerleau representation neural network hidden layer task speci focus attention proceedings international joint conference onarti cial intelligence ijcai montreal canada pp 

baum haussler size net gives valid generalization neural computation pp 

baxter learning internal representations ph thesis univeristy south australia dec 
baxter learning internal representations proceedings th acm conference computational learning theory colt santa cruz ca 
baxter bayesian information theoretic model bias learning proceedings th international conference computational learning theory colt del italy 
becker hinton self organizing neural network discovers surfaces random dot stereograms nature pp 

breiman bagging predictors tr department statistics university california berkeley 
chapter 
bibliography breiman friedman predicting multivariate responses multiple linear regression ftp ftp stat berkeley edu pub users breiman ps caruana multitask learning knowledge source inductive bias proceedings th international conference machine learning ml university massachusetts amherst pp 

caruana multitask connectionist learning proceedings connectionist models summer school pp 

caruana learning related tasks time backpropagation advances neural information processing systems proceedings nips pp 

caruana baluja mitchell sort rankprop multitask learning medical risk prediction advances neural information processing systems proceedings nips pp 

caruana de sa promoting poor features supervisors inputs better outputs appear advances neural information processing systems proceedings nips 
cooper aliferis aronis buchanan caruana fine glymour gordon meek mitchell richardson spirtes evaluation machine learning methods predicting pneumonia mortality arti cial intelligence pp 

craven shavlik sampling queries extract rules trained neural networks proceedings th international conference machine learning ml rutgers university new jersey pp 

davis stentz sensor fusion autonomous outdoor navigation neural networks proceedings ieee intelligent robots systems conference 
dent mcdermott mitchell zabowski personal learning apprentice proceedings national conference arti cial intelligence 
de sa learning classi cation unlabelled data advances neural information processing systems proceedings nips pp 

dietterich hild bakiri comparative study id backpropagation english text speech mapping proceedings seventh international conference arti cial intelligence pp 

dietterich hild bakiri comparison id backpropagation english text speech mapping machine learning pp 

chapter 
bibliography dietterich bakiri solving multiclass learning problems error correcting output codes journal arti cial intelligence research pp 

fine singer lave kapoor validation pneumonia prognostic index comparative hospital database american journal medicine 
fisher conceptual clustering learning examples inference proceedings th international workshop machine learning 
freund boosting weak learning algorithm majority information computation 
ghahramani jordan supervised learning incomplete data em approach advances neural information processing systems proceedings nips pp 

ghahramani jordan mixture models learning incomplete data computational learning theory natural learning systems vol 
iv greiner petsche hanson eds cambridge ma mit press pp 

bengio multi task learning stock selection advances neural information processing systems proceedings nips 
hinton learning distributed representations concepts proceedings th international conference cognitive science society pp 

holmstrom additive noise back propagation training ieee transactions neural networks pp 

hsu simmons learning evaluation walking robot proceedings th international conference machine learning pp 

lang newsweeder learning filter news proceedings th international conference machine learning pp 

le cun boser denker henderson howard hubbard backpropagation applied handwritten zip code recognition neural computation pp 

little rubin statistical analysis missing data wiley new york 
liu setiono selection filter solution proceedings th international conference machine learning icml bari italy pp 

martin pittman recognizing hand printed letters digits chapter 
bibliography backpropagation learning neural computation pp 

martin goal directed clustering proceedings aaai spring symposium goal directed learning 
martin acquiring combining overlapping concepts machine learning pp 

mitchell need biases learning generalizations rutgers university cbm tr 
mitchell caruana freitag mcdermott zabowski experience learning personal assistant communications acm special issue agents july pp 

munro competition networks improves committee performance appear advances neural information processing systems proceedings nips 
sullivan thrun discovering structure multiple learning tasks tc algorithm proceedings th international conference machine learning icml bari italy pp 

pomerleau neural network perception mobile robot guidance doctoral thesis carnegie mellon university cmu cs 
pratt mostow kamm direct transfer learned information neural networks proceedings aaai 
pratt non literal transfer neural network learners colorado school mines mcs 
pratt mostow kamm direct transfer learned information neural networks proceedings aaai 
quinlan induction decision trees machine learning pp 

quinlan programs machine learning morgan kaufman publishers 
rumelhart hinton williams learning representations backpropagating errors nature pp 

sejnowski rosenberg nettalk network learns read aloud john hopkins jhu eecs 
schapire strength weak learnability machine learning 
sharkey sharkey adaptive generalisation transfer knowl chapter 
bibliography edge university exeter 
sill abu mostafa monotonicity hints appear neural information processing systems proceedings nips 
simard lecun denker tangent prop formalism specifying selected invariances adaptive neural network advances neural information processing systems proceedings nips pp 

suddarth holden symbolic neural systems hints developing complex systems international journal man machine studies pp 

suddarth rule injection hints means improving network performance learning time proceedings eurasip workshop neural networks pp 

sutton adapting bias gradient descent incremental version delta bar delta proceedings th international conference arti cial intelligence aaai pp 

thrun mitchell learning thing carnegie mellon university cs 
thrun lifelong learning case study carnegie mellon university cs 
thrun learning th thing easier learning advances neural information processing systems proceedings nips pp 

thrun explanation neural network learning lifelong learning approach kluwer academic publisher 
tresp ahmad training neural networks de cient data advances neural information processing systems proceedings nips pp 

saxena learning preference predicate proceedings th international conference machine learning pp 

valdes perez simon powerful heuristic discovery complex patterned behavior proceedings th international conference machine learning ml rutgers university new jersey pp 

waibel shikano modularity scaling large phonemic neural networks ieee transactions acoustics speech signal processing pp 

chapter 
bibliography weigend rumelhart huberman generalization weight elimination application forecasting advances neural information processing systems proceedings nips pp 

appendix net size generalization backprop nets appendix summarizes results experiments ran 
conventional wisdom arti cial neural networks big generalize poorly 
appendix empirical results suggest early stopping prevent tting excess capacity signi cantly reduce generalization performance fully connected feed forward backprop nets 
little capacity hurts generalization performance capacity 
analysis suggests backprop nets regardless size learn task subcomponents similar sequence 
big nets pass intermediate stages similar learned small nets 
early stopping big nets point yields generalization performance comparable smaller nets 
big net large penalty higher computational cost poorer generalization 
small net small bigger nets generalize better 
important thesis mtl net trained multiple tasks needs capacity stl net trained tasks 
perform fair comparison results obtained stl mtl need train stl mtl net sizes appropriate method 
unfortunately backprop nets expensive train infeasible search optimal net size 
fortunately quite unexpectedly experiments suggest generalization performance remarkably insensitive net size long net large 
excess capacity rarely hurts generalization early stopping appendix net size generalization backprop nets prevent tting 
great news 
means fair comparison stl mtl long don nets small method 
feasible determine net size large determine net size optimal 
fact suggested generalization performance sensitive net size necessary nd optimal net size experiment pursued thesis neural nets 
nets big generalize poorly commonly believed arti cial neural networks big generalize poorly 
argument net capacity learn table lookup training data generalize 
way obtain generalization restrict capacity net forced generalize insu cient capacity memorize training data 
argument vc dimension analysis net capacity generalization 
free parameters net larger vc dimension hypothesis space net larger number hypotheses net represent weights 
higher vc dimension training sample large select correct nearly correct net hypothesis 
baum haussler empirical study generalization vs net capacity goals groups backprop noted performance task worsen continues improve try larger networks 
nd marginal inconsistent indications constraining net capacity improves generalization 
martin pittman unfortunately anecdotal evidence su ers methodological aws 
comes experiments questionable criteria halt training consider large networks 
critique studies 
studies motivated achieve performance respective tasks investigate capacity ects 
goal methodologically sound investigation capacity ects backprop nets 
want empirically answer questions appendix net size generalization backprop nets 
sensitive generalization performance network capacity 
critical nd just right size performance insensitive small changes capacity 

excess capacity reduce generalization performance widely believed 


ective early stopping mitigating ects tting 

large networks learn qualitatively di erent internal representations small networks 
methodology selected test problems trained nets di erent sizes hidden units backpropagation 
hold sets measure generalization performance training 
possible collected complete generalization curves trained generalization performance began fall reasonably con dent improve 
possible ran multiple trials 
kept training sets small generalization challenging 
study required approximately sparc year computation 
problems nettalk sejnowski parity bit bit inverse kinematic model robot arm sensor modeling tasks real sonar data collected real robot vision data steer autonomous vehicle pomerleau boolean continuous 
noise noise free 
large numbers inputs outputs small numbers inputs outputs 
real synthetic 
results shows generalization curves obtained test problems 
results surprised 
tasks nets large poorer peak generalization performance smaller networks 
drop generalization performance small 
replications required statistical tests con rm sebastian thrun letting robot arm simulation code 
appendix net size generalization backprop nets di erences statistically signi cant 
data suggest generalization performance hurt network small large 
better err side making network large small generalization performance training time important criterion 
cross validation rms error nettalk hidden units hidden units hidden units hidden units hidden units hidden units hidden units pattern presentations cross validation rms error inverse kinematics hidden units hidden units hidden units hidden units hidden units pattern presentations cross validation rms error base average runs hidden units hidden units hidden units hidden units hidden units pattern presentations cross validation rms error base average runs hidden units hidden units hidden units hidden units hidden units pattern presentations generalization performance vs network size test problems tasks net sizes trained point generalization performance peaked 
complete generalization curves noticed expect 
tasks small nets tted considerably 
conclude early stopping critical nets sizes just ones big 
safe assume net restricted capacity data 
excess capacity hurt generalization proper theoretical analysis net capacity generalization take account search procedure nd hypotheses consistent data 
backpropagation train net hypotheses di erent complexity equal opportunity 
usually initializes weights small values 
weights large data require number appendix net size generalization backprop nets weight updates large allow 
backprop biased consider net hypotheses small weights considering hypotheses large weights 
net larger weight ranges greater representational power tantamount searching simpler hypotheses searching complex hypotheses 
analyzed nets di erent sizes learned train 
compared input output behavior networks di erent stages learning large samples test patterns drawn domain 
example compared input output behavior large net trained behavior smaller nets trained problem 
discovered large nets go intermediate stages training similar behavior smaller nets 
large net rst learns similar small net learns 
begins learn somewhat larger nets learn 
behavior similar intermediate sized nets 

nets excess capacity rst learn small nets learn 
small nets run capacity large nets behave intermediate size nets 
large net big early stopping detect generalization performance begins drop 
point functionally similar smaller net trained task 
penalty net big extra computation required train 
early stopping provides apparently reliable means stopping training net stage functionally equivalent obtained smaller net 
net big perform better smaller net 

early stopping just important small nets large nets 

tasks generalization performance decrease excess net capacity 
generalization performance remarkably insensitive excess net capacity 
excess capacity reduces generalization reduces little 

nets small hurts generalization nets large 

nets excess capacity appear go sequence stages learning functionally similar smaller nets learn 

comparing methods need di erent sized nets stl mtl fair comparison carefully nets small 
need precisely tune net size task set tasks 
appendix net size generalization backprop nets final note completing empirical study trained thousands backprop nets dozen additional problems 
problems performed preliminary studies quickly assess ect net size generalization performance 
computers signi cantly powerful studies able consider nets thousands hidden units 
ran studies conjugate gradient backprop steepest descent 
results experiments consistent results report 
nd little loss generalization performance nets large early stopping halt training 
small sensitivity excess net capacity net size optimal usually larger expect 
example uncommon optimal net size problem dozen inputs outputs training patterns hidden units 
net size contains free parameters clear traditional rules number free parameters number training cases apply backprop nets trained early stopping 
appendix rank error metrics methods described appendix applicable domains goal learn rank instances usually unknown function probability distribution 
learning function probability unknown function probability function 
addition medical decision making class includes problems diverse investment analysis nancial markets 
motivating problem pneumonia risk prediction medis pneumonia database fine contains patients diagnosed pneumonia 
database indicates patient lived died 
patients died 
useful decision aid problem predict patients live die 
di cult 
practice best achieved estimate probability death pod observed symptoms 
fact su cient learn rank patients pod lower risk patients discriminated higher risk patients 
patients risk may considered care 
performance criterion working medis database cooper accuracy select prespeci ed fraction patient population die 
example population patients nd population risk 
learn risk model threshold model allows population patients fall 
patients threshold died error rate 
error rate fop model fop stands fraction population 
consider 
goal appendix rank error metrics train rms plot test rms plot sse targets error fraction deaths fop fop fop fop fop fop pattern presentations epochs pattern presentations epochs learning curves left graph error rates fop right graph learn models model thresholds error rate fop minimized 
models acceptably low error rates employed help determine patients require hospitalization 
traditional approach sse targets straightforward approach problem backprop train net learn predict patients live die real valued predictions net sort patients risk 
net inputs observed patient measurements hidden layer units single output trained lived died 
nite training set net trained way learn predict probability death patient patients live die 
real world rarely nite number training cases net learn nonlinear function outputs values near cases training set generalize 
domain critical early stopping halt training happens 
shows learning curve fully connected feedforward nets hidden units trained described learning rate momentum 
clear plot signi cant tting occur 
shows error rates di erent fop values comparisons methods fair rst hidden layer sizes learning parameters performed method 
di erent representations di erent error metrics cross entropy perform better sse targets 
comparison methods fair size hidden layer learning parameters tuned method preliminary experiments performance method 
nd settings yielded appendix rank error metrics measured halting set nal test set function training 
note minimum fop error occur epoch sse minimized 
fact di erent reach minimum error di erent epochs 
fact error rate performance reach best value sse test set minimized suggests things 
better performance obtained halting training fop error rates sse 
second sse targets correlate performance criterion training criterion 
second issue addressed rankprop section 
goal predict patient risk represents serious lack appropriate training information motivates rank learning methods 
table shows error rates nets trained sse targets 
entry mean trials 
rst entry table indicates average test population predicted nets risk died 
know best achievable error rates data 
table error rates sse targets fop error rate rankprop goal nd fraction population die su cient just learn rank patients risk 
rankprop learns rank patients learning predict mortality 
rankprop short backpropagation sum squares errors estimated ranks 
basic idea sort training set target values scale ranks sort scale uniformly sigmoid output units scaled ranks target values standard backprop sse values database 
ideally rank training set true probabilities death 
unfortunately know patients lived died 
medis database target values 
possible sorts consistent values 
sort backprop try 
large number possible sorts training set appendix rank error metrics backpropagating ranks challenging 
rankprop solves problem net model learned order training set target values tied 
database ties target values nding proper ranking training set serious problem 
rankprop learns adjust target ranks training set time learning predict ranks training set 
rankprop 
rankprop alternates rank passes backprop passes 
rank pass records output net training pattern 
sorts training patterns target values medis database network predictions pattern secondary sort key break ties 
basic idea nd legal rank target values maximally consistent ranks current model predicts 
closest match ranking target values de ne target ranks backprop pass training set 
rankprop pseudo code foreach epoch foreach pattern network output pattern forward pass pattern target rank sort scale patterns target value network output foreach pattern backprop target rank pattern network output pattern sort scale patterns sorts ranks training patterns sort keys speci ed arguments second break ties rst 
net learn order backwards ranking lower risk higher risk 
theory possible 
prevents practice net learn rank patterns targets implementation collects net outputs time backpropagating errors computed sorted outputs collected previous epoch 
saves time collection forward pass eliminated rst pass means error signals fed back epoch date 
appendix rank error metrics ranked patterns targets biases net models give lower rank cases risk 
table shows mean rankprop performance nets hidden units 
bottom row shows improvements sse targets 
di erences statistically signi cant better 
table error rates rankprop improvement standard backprop fop error rate change soft ranks soft ranks 
suppose items associated real value order data 
sorting ranking data usual way yields ranks discrete small changes predicted value case usually ect rankings cases 
example predicted value changes gets ranked second 
di cult apply gradient descent error metrics de ned discrete ranks plateaus error metric 
small modi cation ranks eliminates problem preserving semantics 
order data usual temporarily assign item traditional rank 
post process traditional ranks follows prev val val prev val ost val prev appendix rank error metrics traditional rank item continuous rank item val value item prev ost denote items rank just just item respectively 
soft ranks computed way items consider item value closer value item ranked just value item ranked just 
soft rank re ects assigning item soft rank closer soft rank soft rank notice soft rank rst items traditional rank 
items interior range 

qualitatively soft ranks behave traditional ranks nice additional property continuous small changes item values yield small changes soft ranks 
small changes values cause items swap positions neighboring items soft ranks re ect smooth way 
example increase value item example new soft ranks little ort possible de ne similar range means 
useful circumstances extra complexity necessary simpler de nition 
appendix rank error metrics traditional ranks items change abruptly passes soft ranks 
possible soft ranks error metrics traditional ranks 
error metrics de ned soft ranks behavior similar behavior de ned traditional ranks smoothness soft ranks error metric discontinuous traditional ranks 
means apply gradient descent error metrics soft ranks 
main prediction task pneumonia domain mortality risk 
knn lcwa predict risk new case examining neighbors training set lived died 
predicted cases sorted predicted risk 
optimization error metric pneumonia risk sum soft ranks patients sample live 
goal order patients risk risk rst 
successfully ordering patients live patients die minimizes sum 
scale sum soft ranks indicates patients live ranked lower risk patients die 
ideal performance 
scaling done soft rank sum indicates patients die ranked lower risk patients live 
maximally poor performance 
random ordering patients yields soft rank sums 
performance domain requires soft rank sums 
discussion sort methods rankprop soft rank sums better learning rank patients rst learning estimate patients probabilities death 
consider traditional sse targets medis 
attempts drive person lived value person dies value regardless true unknown probability death 
compare rank metric database 
assume drive patients live xed value 
nd ordering patients live 
means possible patients live death sorted left patients live high er probability death 
ditto patients die 
orderings appendix rank error metrics function learned nonlinear function learned sse targets 
reasoning similar quantized data exists ranking database contains ranking similar original underlying probability function function sse targets tries learn 
consider function 
backprop di culty learning sigmoid 
imagine function quantized process discrete levels 
longer know function get training data 
large training set backprop learn new function 
number training patterns reduced di culty 
suppose true objective sort patterns original underlying function small number samples 
learn function bene cial learn 
really need learn function 
functions may easier learn small training set 
quantized rank sort quantized ects quantizing ranking friendly function shows possible ranking data 
note ranks evenly spaced nonlinear 
net learn ranking similar training sample drawn time learning ranking function predicts outputs patterns corresponding rankings sort patterns 
hand net learns directly small sample di culty nding function nonlinear appendix rank error metrics nonlinear nonmonotonic hurt sort performance 
coarsely quantized data larger potential di erence rankprop sse quantized targets 
pneumonia database worst case scenario quantization maximally coarse corrupted binomial noise 
net sse corrupted targets learn nonlinear quantization function attempts learn function nonlinear drive similar cases chance di erent outcomes 
precise data target function 
suppose goal learn model learn sort patterns 
learn model predictions sorting 
su ces learn function 
functions may easier learn 
consider probability function assigns probability outcome probability outcome 
shows training set sampled distribution 
probability 
probability high 
probability near 
region causes problems backprop sse targets similar inputs mapped dissimilar targets 
probability outcome targets traditional sse targets best rank 
sse targets ranks simple probability function learning sees avery nonlinear function trained 
unfortunate smooth maps similar inputs similar outputs 
goal learn rank data learn simpler nonlinear function 
exists ranking training data ranks target values resulting function nonlinear original target function 
shows target appendix rank error metrics rank values 
similar input patterns similar rank target values original target values 
rank methods rankprop try learn simple functions directly support ranking 
di culty rankprop learn ranking training data training model predict ranks 
know conditions parallel search converge 
conjecture rank methods converge simpler models learned original target values medis simpler models generalize better 
rankprop best assumptions satis ed original underlying function nonlinear discretized function quantized data exists function rank rank quantized nonlinear quantized rankprop learn rank quantized ranks imposed training set backprop sse learn predict ranks inputs backprop generalizes better limited data learning nonlinear functions 
applications rank methods rank methods applicable relative assessment useful learnable absolute 
application domains quantitative measurements available relative ones hsu 
example game player able evaluate moves quantitatively excel relative saxena 
application goal learn order data drawn probability distribution medical risk prediction 
applied goal order data 
example information ltering usually important useful information user rst predict important lang 
appendix rank error metrics summary appendix presents rank methods improve generalization broad class problems 
rst method rankprop tries learn simple models support ranking cases simultaneously learning rank training set 
second method soft rank sum error criterion results generalizing ranks di erentiable 
experiments database pneumonia patients indicate rankprop outperforms standard backpropagation 
