finding interesting associations support pruning cohen datar fujiwara gionis piotr indyk rajeev motwani jeffrey ullman cheng yang july association rule mining heretofore relied condition high support efficiently 
particular known priori algorithm effective rules interest relationships occur frequently 
number applications data mining identification similar web documents clustering collaborative filtering rules interest comparatively instances data 
cases look highly correlated items possibly causal relationships infrequent items 
develop family algorithms solving problem employing combination random sampling hashing techniques 
provide analysis algorithms developed conduct experiments real synthetic data obtain comparative performance analysis 
keywords data mining association rules similarity metric min hashing locality sensitive hashing 
prevalent problem large scale data mining association rule mining introduced agrawal imielinski swami :10.1.1.40.6984
challenge referred problem due origins study consumer purchasing patterns retail stores applications extend far specific setting 
suppose relation containing tuples set boolean attributes am 
fai ai aj sets attributes 
say association rule conditions satisfied support set appears fraction tuples confidence tuples appears fraction appearing 
goal identify valid association rules relation 
extent relative popularity problem attributed paradigmatic nature simplicity problem statement wide applicability identifying hidden patterns data general applications original market basket motivation 
arguably success availability surprisingly efficient algorithm lack models pattern discovery data mining 
algorithmic efficiency derives idea due agrawal called priori exploits support requirement association rules 
key observation set attributes appears fraction tuples subset appears fraction tuples 
principle enables approach pruning determine list lk sets attributes high support compute list lk gamma gamma sets attributes high support consider candidates lk sets gamma subsets lk gamma 
variants enhancements approach underlie essentially known efficient algorithms computing association rules variants 
note worst case problem computing association rules requires time exponential priori algorithm avoids pathology real data sets 
observe confidence requirement plays role algorithm completely ignored game high support sets screened high confidence 
motivated long standing open question devising efficient algorithm finding rules high confidence extremely weak support 
example market basket data standard association rule algorithms may useful commonly purchased high support items beer essentially useless discovering rules bought people purchase items 
develop body techniques rely confidence requirement obtain efficient algorithms 
motivation seeking associations high confidence support requirement rules high support obvious known rules low support provide interesting new insights 
support free associations natural class patterns data mining right arise variety applications copy detection identifying identical similar documents web pages clustering identifying similar vectors high dimensional spaces purposes clustering data collaborative filtering tracking user behavior making recommendations individuals similarity preferences users :10.1.1.24.779
note applications formulated terms table columns tend sparse goal identify column pairs appear similar support requirement 
notion confidence asymmetric uni directional convenient purpose symmetric bi directional measure interest 
conceptual level view data matrix rows columns 
typically matrix fairly sparse assume average number row 

applications mind large small 
define ci set rows column ci define density column ci di define similarity columns ci cj ci cj jci similarity ci cj fraction rows containing ci cj contain ci cj 
observe definition similarity symmetric respect ci cj contrast confidence rule conf ci cj jci ij identify pairs columns similarity exceeding threshold easy matrix small fits main memory brute force enumeration algorithm requires time 
interested case large data disk resident 
primary focus problem identifying pairs columns similarity exceeding pre specified threshold lambda restricting basic version problem enable clearly showcase techniques dealing main issue achieving algorithmic efficiency absence support requirement 
possible generalize techniques complex settings discuss briefly moving techniques 
easy verify basic approach generalizes problem identifying high confidence association rules pairs columns discussed section 
noted papers expressed dissatisfaction confidence measure interest association rules suggested various alternate measures 
ideas applicable new measures interest 
major restriction deal pairs columns 
believe possible apply techniques identification complex rules matter discussed detail section 
algorithms identifying pairs similar columns follow natural phase approach compute signatures generate candidates prune candidates 
phase pass table generating small hash signature column 
goal deal large scale tables sitting secondary memory phase produces summary table fit main memory 
second phase operate main memory generating candidate pairs column signatures 
third phase pass original table determining candidate pair high similarity 
phase identical algorithms scanning table data maintain candidate column pair ci cj counts number rows having columns number rows having columns 
consequently limit ensuing discussion proper implementation phases 
key ingredient course hashing scheme computing signatures 
hand needs extremely fast produce small signatures able single pass data 
competing goal requirement false positives candidate pairs really highly similar time required third phase depends number candidates screened 
related requirement extremely ideally false negatives highly similar pairs list candidates 
section family schemes technique called min hashing mh inspired idea cohen estimate size transitive closure reachability sets see broder 
idea implicitly define random order rows selecting column signature consists row index ordering column 
show probability columns signature proportional similarity 
reduce probability false positives false negatives collect signatures independently repeating basic process picking rows column 
main feature min hashing scheme suitably large choice number false positives fairly small number false negatives essentially zero 
disadvantage rises space time required second phase candidate generation increases 
second family schemes called locality sensitive hashing lsh section inspired ideas gionis indyk motwani high dimensional nearest neighbors see indyk motwani 
basic idea implicitly partition set rows computing signature pattern column example just compute bit column denoting number column greater zero 
family schemes suffers disadvantage reducing number false positives increases number false negatives vice versa previous scheme 
tends produce false positives false negatives advantage having lower space time requirements min hashing 
conducted extensive experiments real synthetic data results section 
expected experiments indicate schemes outperform priori algorithm orders magnitude 
illustrate point trade accuracy speed algorithms 
important avoid false negatives recommend min hashing schemes tend slower 
speed important complete accuracy generating rules hashing schemes preferred 
section discuss extensions provide interesting directions conclude section summarizing algorithms distinctive features 
motivation main contribution develop techniques mine low support rules done effectively existing techniques priori 
number applications clustering copy detection collaborative filtering low support rules significance 
looked application report findings 
applied algorithms mine pairs words occur news documents check provide interesting information 
news articles obtained reuters press 
similar pairs provide interesting information seen examples provide 
pairs names famous international personalities cities terms medicine fields phrases foreign languages miscellaneous items author book pairs organizations get clusters words groups words pairs group high similarity 
example cluster chess soviet stands chess event 
noted pairs low support 
running time comparison priori algorithms provided section 
names terminology phrases misc relations dalai avant encyclopedia britannica fibrosis cystic cosa buenos aires emperor examples different types similar pairs news articles min hashing schemes min hashing scheme idea due cohen context estimating transitive closure reachability sets 
basic idea min hashing scheme randomly permute rows column ci compute hash value ci index row permutation column 
reasons efficiency wish explicitly permute rows compute hash value column single pass table 
scanning rows simply associate row hash value number chosen independently uniformly random range assuming number rows suffice choose hash value random bit integer avoiding birthday paradox having rows get identical hash value 
furthermore scanning table assigning random hash values rows column ci keep track minimum hash value rows contain column 
obtain min hash value ci column ci single pass table memory 
proposition column pair ci cj prob ci cj jci cj easy see columns min hash value random permutation rows defined hash values row column ci row column cj 
words ci cj restriction permutation rows ci cj row belongs ci cj 
row probability coming random permutation probability event ci cj exactly cardinality set ci cj cardinality set ci cj exactly ci cj 
order able determine degree similarity column pairs necessary determine multiple say independent min hash values column 
single pass input table select parallel independent hash values row defining distinct permutations rows 
mk memory single pass determine corresponding min hash values say cj hk cj column cj row permutations 
effect obtain matrix cm rows columns hi cj entries column min hash values 
matrix cm viewed compact representation matrix show theorem similarity column pairs captured similarity cm definition bs ci cj fraction min hash values identical ci cj ci cj jfl jfl hl ci hl cj gjk example give simple illustration ideas consider boolean matrix min hash functions defined permutations ss ss notation denotes permutation ss maps th row th 
concentrate moment column row permutation ss row 
similarly row row permutation ss 
working similarly columns get matrix cm smaller size original matrix pairwise similarities columns roughly maintained 
particular bs bs bs respectively 
cm rows approximation actual similarities coarse see considering hash functions boost accuracy estimation arbitrarily high 
defined bs ci cj fraction rows bs min hash entries columns ci cj identical 
show bs ci cj estimator ci cj 
recall set threshold lambda columns said highly similar ci cj lambda assume lambda lower bounded constant theorem shows get false positives false negatives bs determine similarity column pairs original matrix theorem ffi ffl ffi gamma gamma log ffl gamma 
pairs columns ci cj properties 
cj cj lambda bs ci cj gamma ffi lambda probability gamma ffl 
cj cj bs ci cj ffi probability gamma ffl 
sketch proof part theorem proof second part quite similar omitted 
fix columns ci cj having similarity cj cj lambda xl random variable takes value hl ci hl cj value define xk 
proposition xl ci cj lambda ks lambda applying chernoff bound random variable obtain prob 
gamma ffi ks lambda prob 
gamma ffi gamma ffi gamma ffi ks lambda gamma ffi kc ffl establish part theorem simply notice bs ci cj theorem establishes sufficiently large columns high similarity lambda agree correspondingly large fraction min hash values conversely similarity low agree correspondingly small fraction min hash values cm cm computed single pass data km space obtain desired implementation phase signature computation 
turn task devising suitable implementation second phase candidate generation 
candidate generation min hash values having computed signatures phase discussed previous section wish generate candidate column pairs second phase 
point theta matrix cm containing min hash values column 

assume cm smaller original data fits main memory 
goal identify column pairs agree large fraction gamma ffi lambda min hash values cm brute force enumeration require time column pair total km 
techniques avoid quadratic dependence considerably faster typically case average similarity ci cj low 
row sorting algorithm view rows cm list tuples containing min hash value corresponding column number 
sort row basis min hash values 
groups identical min hash values sequence runs 
maintain column index position min hash value sorted row 
estimate similarity column ci columns algorithm counters column ci jth counter stores number rows min hash values columns ci cj identical row index run containing value ci column represented run increment corresponding counter 
avoid counter initializations re counters processing different columns remember re initialize counters incremented 
estimate running time algorithm follows 
sorting rows requires total time km log indexes columns built time km 
remaining time amounts total number counter increments 
processing row column ci number counter increments fact length run 
expected length run equals sum similarities ci cj 
expected counter increment cost processing ci ci cj expected combined increments cost ci cj ksm 
expected total time required algorithm km log km 
note average similarity typically small fraction term running time really quadratic appears 
hash count section introduces min hashing algorithm signatures column ci set exactly min hash values 
similarity column pair ci cj estimated computing size clearly suffices consider ordered pairs cj ci task accomplished hash count algorithm 
associate bucket min hash value 
buckets indexed hash function defined min hash values store column indexes columns ci element hashing bucket 
consider columns cm order column ci gamma counters jth counter stores 
min hash value access hash bucket find indexes columns cj 
column cj bucket increment counter cj ci 
add ci bucket 
hash count easily adapted original min hash scheme want compute pair columns number cm rows columns agree 
different hash table set buckets row matrix cm execute process min hash 
argument row sorting algorithm shows hash count min hashing takes ksm time 
running time hash count min hash amounts number counter increments 
number increments counter ci cj exactly size 
simple argument see lemma shows expected size minfk jci ci cj minf jci ci cj 
expected total running time hash table scheme ksm cases 
min hashing algorithm disadvantage min hashing scheme outlined choosing independent values column entailed computing independent hash values row matrix negative effect efficiency signature computation phase 
hand min hash values column essential reducing number false negatives 
modification called min hashing mh single hash value row setting min hash values column hash values rows induced row permutation containing column 
similar approach mentioned analysis 
words column pick smallest hash values rows containing column 
column ci fewer assign min hash values hash values corresponding rows column 
resulting set min hash values forms signature column ci denoted 
proposition min hashing scheme column ci signature consists hash values uniform random sample distinct rows ci 
number column significantly larger hash values may considered independent analysis min hashing applies 
situation slightly complex columns sparse case interest 
denote smallest elements ci cj jci ci cj 
view signature column correspond ci cj 
observe obtained time fact set smallest elements 
corresponds set rows selected uniformly random elements ci cj expected number elements belong subset ci cj exactly jj theta jci jci cj jj theta ci cj 
ci cj signatures just smallest elements 
obtain theorem 
theorem unbiased estimator similarity ci cj expression jj consider computational cost algorithm 
scanning data generate hash value row column maintain minimum hash values corresponding rows contain column 
maintain minimum hash values column simple data structure allows insert new value smaller current maximum delete current maximum log time 
data structure maximum element current min hash values column readily available 
computation row constant time entry additional log time column entry hash value row smallest seen far 
simple probabilistic argument shows expected number rows min hash list column ci gets updated log log 
follows total computation cost single scan data jm mk log log jm number matrix second phase generating candidates need compute sets column pair merge join operations merging find elements belong 
total time phase km 
quadratic dependence number columns prohibitive caused need compute column pair 
apply considerably efficient biased approximate estimator similarity 
biased estimator computed pairs columns hash count ksm time 
perform main memory candidate pruning phase unbiased estimator theorem explicitly computed pairs columns approximate biased estimator exceeds threshold 
choice threshold biased estimator guided lemma 
lemma minf jci ci cj minfk jci alternatively biased estimator choice threshold derived analysis 
ci cj column pair define cij ci cj 
column ci choose set min hash values 
cij cij 
expected sizes 
min 
compute expected value kx kx prob prob min 
assume prob ss orp ss 
equation kx kx prob prob kx prob kx prob obtain estimator ss 
estimate calculate estimate similarity know 
compute hash table technique described earlier section 
time required compute hash values jm mk log log described earlier time computing ksm 
locality sensitive hashing schemes section show obtain significant improvement running time respect previous algorithms resorting locality sensitive hashing lsh technique introduced indyk motwani designing main memory algorithms nearest neighbor search high dimensional euclidean spaces subsequently improved tested 
apply lsh framework min hash functions described earlier section obtaining algorithm similar column pairs 
problem differs nearest neighbor search data known advance 
exploit property showing optimize running time algorithm constraints quality output 
optimization input sensitive takes account characteristics input data set 
key idea lsh hash columns ensure hash function probability collision higher similar columns dissimilar ones 
subsequently hash table scanned column pairs hashed bucket reported similar 
process probabilistic false positives false negatives occur 
order reduce lsh amplifies difference collision probabilities similar dissimilar pairs 
order reduce false negatives process repeated times union pairs iterations reported 
fraction false positives false negatives analytically controlled parameters algorithm 
main focus mention lsh algorithm adapted line framework 
particular follows analysis iteration algorithm reduces number false negatives fixed factor add new false positives removed small additional cost 
user monitor progress algorithm interrupt process time satisfied results produce far 
higher similarity earlier pair discovered 
user terminate process output produced appears interesting 
min lsh scheme min lsh lsh scheme finding similar column pairs matrix cm min hash values 
lsh algorithm splits matrix cm sub matrices dimension theta recall cm dimension theta assume delta sub matrices repeat 
column represented min hash values current sub matrix hashed table hashing key concatenation values 
columns similar high probability agree min hash values hash bucket 
phase scan hash table produce pairs columns hashed bucket 
amplify probability similar columns hash bucket repeat process times 
pr ci cj probability columns ci cj hash bucket value depends ci cj simplify notation writing 
lemma assume columns ci cj similarity lambda similarity threshold 
ffi ffl choose parameters ffl ffi lambda pr ci cj gamma ffl ffl gamma ffi lambda pr ci cj ffl proof proposition probability columns ci cj agree min hash value exactly probability agree group values sr repeat hashing process times probability hash bucket pr ci cj gamma gamma sr lemma follows properties function lemma states large values function pr approximates unit step function translated point lambda filter pairs similarity lambda time space requirements algorithm proportional delta increase values subject quality efficiency trade 
shown graphically larger values parameters get better approximation unit step function 
scheme approximates function pr uses min hash values product delta reason want improve efficiency algorithm time taken generate signatures linear number min hash values 
assume value fixed specified time constraints product ideal parameters exceeds approximate pr picking uniformly random min hash values available concatenating create hashing key repeating process times 
notice min hash values participate hashing keys 
similarity shape filter function function function similarity shape filter functions function function function larger values parameters filter function pr provides better approximation unit step function 
function qr approximation pr min hash values 
example implementation need min hash values approximation min hash values 
similarity columns ci cj qr probability columns ci cj hash bucket 
ci cj agree exactly min hash values probability collide qr gamma gamma dk summing expression values get qr kx gamma gamma dqr function qr similar shape function pr fact values function qr approximation pr pr sharper qr sharp larger values example filter functions shown 
practice willing allow number false negatives gamma false positives determine optimal values achieve quality 
specifically assume estimate similarity distribution data defined distr si number pairs having similarity si 
unreasonable assumption approximate distribution sampling small fraction columns estimating pairwise similarity 
expected number false negatives psi distr si gamma si expected number false positives psi distr si si 
problem estimating optimal parameters turns minimization problem minimize delta subject psi si gamma si gamma si distr si si easy problem parameters optimize feasible values small integers 
approach solve minimization problem iterating small values finding lower bound value solving inequality performing binary search second inequality satisfied 
experiments optimal value 
hamming lsh scheme propose scheme hamming lsh lsh finding highly similar column pairs 
idea reduce problem searching column pairs having small hamming distance 
recall hamming distance dh vectors number positions vectors differ 
order solve problem employ techniques similar solve nearest neighbor problem 
start establishing correspondence similarity hamming distance proof easy 
lemma ci cj gamma dh ci cj dh ci cj follows consider pairs ci cj sum ae fixed high value ci cj corresponds small values dh ci cj vice versa 
partition columns groups similar density group find pairs columns small hamming distance 
briefly describe search pairs columns small hamming distance 
scheme similar technique analyzed tools developed 
scheme finds highly similar columns assuming density columns roughly 
done partitioning rows database subsets 
partition process previous algorithm 
declare pair columns candidate agree subset 
scheme exactly similar earlier scheme dealing actual data min hash values 
problems scheme 
problem matrix sparse subsets just contain zeros columns similar densities assumed 
algorithm call lsh improves basic algorithm 
basic idea follows 
perform computation sequence matrices increasing densities denote 
matrix mi obtained matrix mi randomly pairing rows mi placing mi pair 
see mi contains half rows mi illustration purposes assume initial number rows power 
algorithm applied matrices set 
pair columns candidate matrix mi sufficiently dense densities belong certain range 
false negatives controlled repeating sample times union candidate sets runs 
kr rows extracted compressed matrix 
note operation may increase false positives 
algorithm implemented 
experiments show scheme better min hashing algorithms terms running time number false positives larger 
number false positives increases rapidly try reduce number false negatives 
case min hashing algorithms decreased number false negatives increasing number false positives decrease 
algorithm 
set generate described 

select sets sample rows mi 

column pair candidate exists column pair density gamma mi ii identical hash values essentially identical bit representations runs 
note parameter indicates range density candidate pairs experiments 
notice operation gives similar results hashing columns set increasingly smaller hash table provides alternative view algorithm 
number similar pairs similarity histogram sun data set number similar pairs similarity histogram sun data set figures shows similarity distribution sun data 
second shows distribution focuses region similarities interested 
experiments conducted experiments evaluate performance different algorithms 
section report results different experiments 
sets data synthetic data real data 
synthetic data data contains columns number rows vary 
column densities vary columns pair similar columns 
pairs similar columns similarity fall ranges 
real data real data set consists log requests period days sun microsystems web server www sun com 
columns case url rows represent distinct client ip addresses accessed server 
entry set hit url particular client ip 
data set thirteen columns rows 
columns sparse density 
histogram shows number column pairs different values similarity 
typical examples similar columns extracted data urls corresponding gif images java applets loaded automatically client ip accesses parent url 
compare algorithms existing techniques implemented executed priori algorithm 
mention priori designed task existing technique gives benchmark evaluate algorithms 
comparison support number columns priori mh mh lsh lsh threshold support pruning sec sec sec sec sec running times news articles data set done news articles data mentioned section 
conducted experiments news article data results summarized 
priori algorithm run original data runs memory 
support pruning remove columns ones 
pruned data stands row table comparative results data reported row 
noted support threshold priori algorithm runs memory systems lot thrashing 
noted algorithms probabilistic report set pairs reported priori 
results implemented algorithms described previous section mh mh lsh lsh 
algorithms compared terms running time quality output 
due lack space report experiments give graphs sun data case interesting performed tests synthetic data algorithms behave similarly 
quality output measured terms false positives false negatives generated algorithm 
plot curve shows ratio number pairs algorithm real number pairs similarity range 
resulting plot typically shaped curve gives visual picture false positives negatives algorithm 
intuitively area curve left similarity cutoff corresponds number false positives area curve right cutoff corresponds number false negatives 
real number pairs similarity range computed line fashion brute force counting algorithm comparison fraction pairs similarity performance mh sun data set value total time sec running time mh sun data set fraction pairs similarity performance mh sun data set value total time sec running time mh sun data set quality output total running time mh algorithm varied experiments 
feasible case number columns real data small permit keeping counters pairs main memory 
achieve making multiple passes data 
clearly scalable approach 
describe behavior algorithm parameters varied 
mh mh algorithms parameters lambda user specified similarity cutoff number min hash values extracted represent signature column 
figures plots curves different values mh mh algorithms 
value increases curve gets sharper indicating better quality 
figures keep fixed change value lambda similarity cutoff 
expected curves shift right cutoff value increases 
figures show value total running time decreases marginally generate fewer candidates 
shows fraction pairs similarity performance mh sun data set value total time sec running time mh sun data set fraction pairs similarity performance mh sun data set value total time sec running time mh sun data set quality output total running time mh algorithm varied total running time mh algorithm increases linearly case mh algorithm depicted 
sub linear increase running time due sparsity data 
specifically number hash values extracted column upper bounded number ones column hash values extracted increase linearly similar exploration parameter space lsh lsh algorithms 
parameters algorithm illustrates fact increases probability columns mapped bucket decreases number false positives decreases trade consequence number false negatives increases 
hand shows increase corresponds increase collision probability number false negatives decrease number false positives increases 
figures show total running time increases similarity fraction pairs performance lsh sun data set value parameter total time sec running time lsh sun data set similarity fraction pairs performance lsh sun data set value parameter total time sec running time lsh sun data set quality output total running time lsh algorithm varied hash column times results increase number candidates 
implementation lsh extraction min hash values dominates total computation time increases linearly value showed 
hand implementation lsh checking candidates dominates running times result total running time decreases increases candidates produced 
showed 
compare different algorithms implemented 
comparing time requirements algorithm compare cpu time algorithm time spent algorithms 
important note algorithms number false negatives important quantity requires kept control 
long number false positives large candidates fit main memory eliminate pruning phase 
compare algorithms fraction pairs similarity performance lsh sun data set total time sec value parameter running time lsh sun data set fraction pairs similarity performance lsh sun data set time sec value parameter running time lsh sun data set quality output total running time lsh algorithm varied fix percentage false negatives tolerated 
algorithm pick set parameters number false negatives threshold total running time minimum 
plot total running time number false positives false negative threshold 
consider figures 
figures shows total running time false negative threshold 
see lsh algorithm requires lot time false negative threshold better limit high 
general lsh lsh algorithms better mh mh algorithms 
noted lsh algorithm interested similarity cutoffs low 
graph shows best performance shown lsh algorithm 
gives number false positives generated algorithms tolerance limit 
false positives plotted logarithmic scale 
case lsh lsh algorithms number false positives decreases ready tolerate false negatives case hash column fewer times 
false positive graph mh mh monotonic 
exists tradeoff time spent candidate generation stage pruning stage 
maintain number false negatives threshold increase spend time candidate generation stage decrease similarity cutoff spend time pruning stage get false positives 
points graph correspond different values similarity cutoff lambda algorithms run get candidates similarity certain threshold 
result observe monotonic behavior case algorithms 
comment results provided analyzed caution 
reader note refer time refer cpu time expect time dominate signature generation phase pruning phase 
aware nature data smart choice algorithms 
instance mh algorithm mh sparse data sets takes advantage sparsity 
extension high confidence association rules far devised techniques finding column pairs high similarity 
interested finding column pairs high confidence measure 
association rules support requirement 
problem motivated explained earlier 
look techniques extended finding rules 
confidence rule ci cj denoted conf ci cj conf ci cj jci ci cj jci 
consider min hash schemes 
obtain summary matrix cm estimate value ci cj counting fraction rows columns agree 
matrix sufficiently large seen earlier theorem get estimate ci cj 
remains calculate estimate value jci 
easily seen ci cj jci 
order estimate quantity get fraction rows hash values ci greater cj 
row sorting technique extended 
maintain sets counters column ci counting number rows column cj agrees hash value ci counting number rows hash value cj proof identical proof ci cj ci cj 
total time sec false negative threshold time vs false negatives similarity mh mh lsh false negative threshold false positives vs false negatives similarity mh mh lsh total time sec false negative threshold time vs false negatives similarity mh mh lsh number false positives false negative threshold false positives vs false negatives similarity mh mh lsh comparison different algorithms terms total running time number false positives different negative thresholds 
ci 
time required km 
value ci cj jci cj may small 
result may require bigger table cm accurately estimate 
note hash count technique 
similar reasons min lsh scheme purpose 
suggest alternate technique looking high confidence column pairs 
note ci cj lower bound conf ci cj conf cj ci 
surely declare candidates column pairs estimate ci cj exceeds confidence threshold 
easy see conf ci cj ss ci cj ss 
declare candidates column pairs ci cj ss 
experimental results qualitatively similar column pairs 
extensions briefly discuss extensions results directions 
min hashing scheme determine complex relationships ci cj cj hash values induced column cj cj easily computed component wise minimum hash value signature cj cj extending cj cj difficult 
works follows 
observe ci implies cj cj means ci implies cj ci implies cj 
implications generated 
conclude ci implies cj cj cardinality ci roughly cj cj presents problems cardinality ci really small difficult 
case small ci may interesting anyway difficult associate statistical significance similarity case 
possible define anti correlation mutual exclusion pair columns 
statistical validity require imposing support requirement extremely sparse columns mutually exclusive sheer chance 
interesting note hashing techniques extended deal situation priori effective support requirements 
extensions columns complex boolean expressions possible suffer exponential overhead number columns 
summary summary problem various algorithmic techniques described 
relation containing tuples set boolean attributes am form theta boolean matrix 
goal find pairs columns ci cj similarity ci cj defined section greater user specified threshold lambda problem easily solved data fits main memory 
address case data size large 
techniques solve problem 
techniques probabilistic generate set candidates 
propose candidates verified eliminate false positives 
briefly summarize candidate generation techniques 
technique called min hashing mh generates signature column set min hash values 
signatures stored main memory column pair count number min hash values agree 
agree certain fraction pair flagged candidate 
probability min hash value columns equal similarity 
result technique allows generate summary data generate candidates 
technique drawbacks requires generate min hash values column order get accurate candidates increases running time generation summary linear number min hash values 
secondly generation candidates summary quadratic number columns worst case 
order address drawback introduced second technique called mh lets generate signature column computing different min hash values 
slightly compromises quality output helps reducing running time 
way smallest min hash values column just minimum repeating times 
address second drawback introduced technique called min lsh lsh 
column hashed bucket concatenation min hash values hashing key 
repeated times 
columns agree certain fraction min hash values high probability fall bucket 
columns hash bucket pairwise declared candidates 
avoids quadratic number columns running time candidate generation phase proven effective reducing running time 
results show technique gives results 
technique called hamming lsh lsh different generate signature min hash values works directly data 
columns density similarity columns related hamming distance 
smaller hamming distance greater similarity 
intuition hash columns similar density columns small hamming distance fall bucket 
columns falling bucket declared candidates 
technique effective looking high similarity cutoffs ready accept false negatives 
agrawal imielinski swami :10.1.1.40.6984
mining association rules sets items large databases 
proceedings acm sigmod conference management data pp 

agrawal srikant 
fast algorithms mining association rules 
proceedings th international conference large databases 
brin motwani ullman tsur dynamic itemset counting implication rules market basket data 
proceedings acm sigmod conference management data pp 

broder 
resemblance containment documents 
compression complexity sequences sequences pp 

cohen 
size estimation framework applications transitive closure reachability 
journal computer system sciences 
duda hart 
pattern classification scene analysis 
wiley inter science publication new york 
gionis indyk motwani 
similarity search high dimensions hashing 
proceedings th international conference large data bases pp 

goldberg nichols oki terry 
collaborative filtering weave information tapestry 
communications acm 
guha rastogi shim 
cure efficient clustering algorithm large databases 
proceedings acm sigmod international conference management data pp 

hellerstein haas wang 
online aggregation 
proceedings acm sigmod international conference management data 
indyk motwani 
approximate nearest neighbor removing curse dimensionality 
proceedings th annual acm symposium theory computing pp 

motwani raghavan 
randomized algorithms 
cambridge university press 
shivakumar garcia molina 
building scalable accurate copy detection mechanism 
proceedings rd international conference theory practice digital libraries 
silverstein brin motwani 
market baskets generalizing association rules dependence rules 
preliminary version proceedings acm sigmod conference management data pp 

journal version data mining knowledge discovery 
silverstein brin motwani ullman 
scalable techniques mining causal structures 
proceedings th international conference large data bases pp 

varian resnick eds 
cacm special issue recommender systems 
communications acm 

