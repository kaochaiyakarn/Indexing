university california san diego information extraction hidden markov models thesis submitted partial satisfaction requirements degree master science computer science timothy robert leek committee charge professor charles peter elkan professor larry carter professor sejnowski copyright timothy robert leek rights reserved 
masters thesis timothy robert leek approved acceptable quality form publication chair university california san diego iii table contents signature page iii table contents iv facts hard find ii automatic annotation generation iii hidden markov models facts iv importance null model learning parameters hmm non emitting states vi implementation optimization vii performance training novel sentences remarks prior knowledge ix bibliography iv thesis information extraction hidden markov models timothy robert leek master science computer science university california san diego professor charles peter elkan chair thesis shows design tune hidden markov model extract factual information corpus machine readable english prose 
particular thesis presents hmm classifies parses natural language assertions genes located particular positions chromosomes 
facts extracted hmm inserted biological databases 
hmm trained small set sentence fragments chosen collected scientific abstracts line inheritance man database judged contain target binary relationship gene names gene locations 
novel sentence contiguous fragments ranked log odds score log ratio probability fragment target hmm null hmm trained sentences 
phrases cardiac tokens il rn prim valid parts gene names 
gene locations similarly mixed bag 
statistics common words infer syntax semantics deal differently words sparsely represented corpus 
uncommon elements treat en gaps holes 
fortunately stochastic approaches hidden markov models demonstrate impressive tolerance noisy sources missing information domains speech recognition protein family characterization :10.1.1.131.2084
chapter iii hidden markov models facts hmms long model speech recommend fact finding problem 
offer compact representation word word occurrence probabilities shown carry information syntax semantics english 
efficient algorithms exist learning model parameters sequences words computing probability sequence model finding highest probability path states model sequence words 
hmm trained set example sentence fragments known contain fact classify candidate sentence fragments contains fact 
