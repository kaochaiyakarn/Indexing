computational intelligence methods data understanding aw duch hayashi department computer methods nicholas university toru poland 
www www phys uni pl department computer science university japan 

experts machine learning fuzzy system frequently identify understanding data logical rules 
reasons inadequacy crisp fuzzy rule explanations 
approach analysis probabilities classification ci function size neighborhood case 
explanations referring features analyzed lower levels visual system functions particular shapes colors movements unnatural ultimately impossible 
important enabling final classification done pre processing level defining complex transformations allow recognize particular pattern face 
explanation rely sophisticated transformation input features rarely may reduced rules conditions large receptive fields defined membership functions applied raw measurements 
receptive fields usually called linguistic terms linguistic variables 
crisp logical rules easiest interpret problems explanations rules class predicted winner :10.1.1.43.99
cases may rejected unclassified justification 
crisp rules stable small perturbations input values 
non gradient optimization methods cost function number errors discontinuous 
fuzzy systems overcome problems continuous membership functions provide adequate explanation data 
select linguistic variables subsets discrete values interval xk 
extract logical rules data neural machine learning statistical techniques 
optimize linguistic variables xk intervals extracted rules exploring reliability rejection rate tradeoff 
repeat procedure stable set rules 
steps described details :10.1.1.43.99
simplicity accuracy tradeoff explored rough description data appropriate regularization parameters hierarchy complex models optimal complexity generalization point view rule base 
selecting satisfactory level data description tradeoff explored reliability predictions rejection rate classifier number vectors don know class 
ci cj confusion matrix rule classifier model containing intervals xk subsets defining linguistic variables 
number wrong predictions min ci cj minimized simultaneously maximization predictive power tr ci cj classifier adaptive parameters model cost function minimized constraints ci cj tr ci cj parameter determines tradeoff reliability rejection rate 
crisp rule classifier non zero probabilities classes alternative winning class gradually appear 
way probabilities change shows reliable classification alternatives worth remembering 
probability ci changes rapidly value case near classification border analysis ci si function si xi needed see features strong influence classification 
displaying allows detailed evaluation new data cases analysis rules complicated 
detailed analysis probabilities confidence intervals probabilistic confidence intervals :10.1.1.43.99
confidence intervals calculated individually input vector logical rules extracted training set 
confidence intervals measure maximal deviation feature value xi assuming features vector fixed change probable classification vector vector lies near class border confidence intervals narrow vectors typical class confidence intervals wide 
intervals facilitate precise interpretation allow analyze stability sets rules 
classification models probabilities ci may calculated analytically 
crisp logical rules data gaussian distribution errors equivalent fuzzy rules soft trapezoid membership functions defined difference sigmoids crisp input value 
slope membership functions determined parameter inversely proportional uncertainty inputs 
mlp ln neural model membership functions computed network linguistic units 
relating slope input uncertainty allows calculate probabilities agreement monte carlo sampling 
way calculating probabilities softmax neural outputs cj oi :10.1.1.43.99
uncertainty inputs taken account probabilities depend continuous way intervals defining linguistic variables 
error function ci ci depends uncertainties inputs variants models may considered gaussian triangular shaped assumptions input distributions neural models transfer functions hidden layer 
confusion matrix computed probabilities number errors allows optimization eq 
gradient methods 
