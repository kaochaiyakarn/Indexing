cs cs cl oct selective sampling example word sense disambiguation fujii university library information science institute technology tokunaga tanaka tokyo institute technology tokyo institute technology proposes efficient example sampling method example word sense disambiguation systems 
construct database practical size considerable overhead manual sense disambiguation overhead supervision required 
addition time complexity searching large sized database poses considerable problem overhead search 
counter problems method selectively samples smaller sized effective subset example set word sense disambiguation 
method characterized reliance notion training utility degree example informative example sampling training system 
system progressively collects examples selecting greatest utility 
reports effectiveness method experiments sentences 
compared experiments example sampling methods method reduced overhead supervision overhead search performance system 

word sense disambiguation potentially crucial task nlp applications machine translation brown pietra pietra parsing lytinen nagao text retrieval croft voorhees 
various approaches word sense disambiguation proposed bruce wiebe charniak dagan itai fujii hearst edelman nagao li matwin ng lee sch tze yarowsky :10.1.1.122.539
corpus approaches grown machine readable texts conventional rule approaches relying hand crafted selectional rules reviewed example hirst corpus approaches release task generalizing observed phenomena set rules 
verb sense disambiguation system approach approach 
preliminary experiment showed system performs department library information science university library information science tsukuba japan department artificial intelligence faculty computer science systems engineering institute technology japan department computer science tokyo institute technology tokyo japan association computational linguistics computational linguistics volume number compared systems approaches motivated explore example approach elaborate experiment section 
time concede approaches word sense disambiguation worth exploration focus example approach wish draw premature regarding relative merits different generalized approaches 
training phase system selects samples training previously produced outputs 
phase human expert samples provides correct interpretation verbs appearing samples 
samples simply incorporated database computational overhead associated globally parameters statistics systems meaning system trained remaining examples residue iteration 
iterating phases system progressively enhances database 
note note problems associated corpus approaches general identified number researchers engelson dagan lewis gale yarowsky :10.1.1.122.539:10.1.1.14.13:10.1.1.16.3103
fujii tokunaga tanaka selective sampling database system examples wsd wsd outputs iteration flow control example sampling system 
sampling sample residue human supervision selective sampling procedure gives optimally informative database size irrespective stage processing terminated 
researchers proposed type approach nlp applications 
engelson dagan proposed committee sampling method currently applied hmm training part speech tagging 
method system samples outputs uncertain level correctness 
example approach take account training effect example unsupervised examples 
introduced training utility method 
devote section comparison approach related works 
respect problem overhead search possible solutions include generalization similar examples reconstruction database small portion useful instances selected supervised example set aha kibler albert smyth keane :10.1.1.138.635
approaches imply significant overhead supervision example prior system execution 
shortcoming precisely approach aims avoid aim reduce overhead supervision overhead search 
section describes basis verb sense disambiguation system preliminary experiment compared method disambiguation methods 
section elaborates example sampling method 
computational linguistics volume number higher example case filler sets share fewer elements equation 
ccd nc constant parameterizing extent ccd influences verb sense disambiguation 
larger stronger ccd influence system output 
avoid data sparseness smooth element noun example practice involves generalizing example noun digit class thesaurus commonly smoothing 
preliminary experimentation estimated performance verb sense disambiguation method experiment compared methods lower bound lb system systematically chooses frequently appearing verb sense database gale church yarowsky rule method rb system uses thesaurus automatically identify appropriate semantic classes selectional restrictions verb complement naive bayes method nb system interprets verb probability takes verb sense example method vector space model vsm system uses mentioned occurrence data extracted text base example method thesaurus system uses table similarity computation :10.1.1.11.9982
rule method selectional restrictions represented thesaurus classes allow nouns dominated class thesaurus structure verb complements 
order identify appropriate thesaurus classes association measure proposed resnik computes association degree case fillers thesaurus classes verb sense equation 
log association degree verb sense class selectional restriction candidate respect case conditional probability case filler example associated case sense dominated class thesaurus 
conditional probability case filler example case disregarding verb sense dominated class probability estimated training data 
experiment conducted cross validation divided training test data equal parts conducted trials different part test data time rest training data database 
evaluated performance method accuracy ratio number correct outputs compared total number inputs 
training test data experiment contained simple japanese sentences collected news articles 
sentence training test data contained complement followed eleven verbs described table 
table number experimental results shown effectiveness naive bayes method word sense disambiguation gale church yarowsky leacock towell voorhees mooney ng pedersen bruce wiebe :10.1.1.11.5417:10.1.1.14.9674
may argue goes basis rule method proper threshold value association degree system improve accuracy potentially sacrificing coverage trade coverage accuracy appropriate evaluation criterion 
trials rule method different threshold values show significant correlation improvement accuracy coverage 
ideally speaking training test data drawn different sources simulate real application 
sentences provided identify original source corresponding sentence 
column sentences denotes number sentences corpus senses denotes number verb senses contained 
column accuracy shows accuracy method 
looking table see example method performed better methods irrespective similarity computation naive bayes method relatively comparable performance 
surprisingly despite relatively ad hoc similarity definition utilized see table thesaurus led greater accuracy gain vector space model 
order estimate upper bound limitation disambiguation task extent human expert errors disambiguation gale church yarowsky analyzed incorrect outputs roughly system errors thesaurus fell category :10.1.1.11.9982
noted vector space model requires computational cost time memory order proportional size vector determination paths thesaurus comprises trivial cost 
investigated errors rule method find rational explanation 
association measure equation tends give greater value frequently appearing verb senses lower level specified classes chosen rules generally 
consequently frequently appearing verb senses rejected 
comparison different approaches word sense disambiguation investigated experimental result gives motivation explore example verb sense disambiguation approaches introduce notion problem identified charniak 
fujii tokunaga tanaka selective sampling selective sampling 
enhancement verb sense disambiguation discuss enhancements example verb sense disambiguation system 
inputs simple sentences information word sense disambiguation inadequate cases 
external information discourse domain dependency word sense guthrie yarowsky expected lead system improvement :10.1.1.122.539
second expressions represent highly restricted collocations semantically thesaurus cause errors 
possible solutions include proposed expressions described separately database system control overgeneralization 
third number existing nlp tools juman morphological analyzer matsumoto morphological syntactic analyzer kameda broaden coverage system inputs currently limited simple morphologically analyzed sentences 
noted japanese case markers omitted example marked wa issue framework currently consider 
shortcoming presents semantic different verb senses closely aligned semantic ranges disjunctive 
consider case parallel semantic space shown closely 
relying similarity case greater ccd done system aim map semantic space way achieve higher semantic disparity minimize shortcoming 

evaluation comparative experimentation order investigate effectiveness example sampling method conducted experiment compared sampling methods control random certain proportion corpus randomly selected training uncertainty sampling examples minimum interpretation certainty selected lewis gale committee sampling cbs engelson dagan method notion training utility tu :10.1.1.14.13:10.1.1.16.3103
elaborate uncertainty sampling committee sampling section 
compared sampling methods evaluating relation number training examples sampled performance system 
conducted cross validation carried sampling training set 
regard training test data set corpus experiment described section 
shows performance various methods general tendency seen observable 
case method generally superior methods 
comparative experiments conclude example sampling method able decrease number training data overhead supervision searching degrading system performance 
related uncertainty sampling 
procedure uncertainty sampling lewis gale follows represents interpretation certainty example see sampling procedure section comparison wsd arg min goto computational linguistics volume number accuracy tu cbs random :10.1.1.16.3103
training data sampled relation number training data sampled accuracy system examples 
discuss theoretical difference method 
considering see concept training utility supported properties example neighbors unsupervised examples informative example similar existing database informative 
uncertainty sampling directly addresses second property ignores 
uncertainty sampling directly addresses second property ignores 
differs method crucially unsupervised examples remain unsupervised examples greater influence computation training utility 
seen comparative experiments section method outperformed uncertainty sampling highest degree early stages 
committee sampling 
committee sampling engelson dagan follows query committee principle seung opper sompolinsky system selects samples degree disagreement models randomly taken training set models called committee members :10.1.1.14.13
achieved iteratively repeating steps number committee members loss generality draw models randomly classify unsupervised example model producing classifications fujii tokunaga tanaka selective sampling sense sense case selected committee sampling 
committee members disagree select training system 
shows typical disparity evident committee sampling sampling method 
basic notation denote unsupervised examples formally 
contrast method similar examples informative 
method preferred sample 
contrast correlate fact committee sampling currently applied statistics language models hmm classifiers words statistical models generally require distribution training data reflects text 
argument assume committee sampling better suited statistics systems method suitable example systems 
engelson dagan criticized uncertainty sampling lewis gale call single model approach distinct multiple model approach sufficient statistics may yield accurate probability estimate class example making certain appropriate classification :10.1.1.16.3103
certainty correct classification low chance wrong class example 
single model estimate second type uncertainty correlate directly utility additional training 
note criticism applied sampling method despite fact method falls category single model approach 
sampling method sufficient statistics increment certainty degree unsupervised examples training utility additional supervised examples small theoretically example statistics systems 
critical issue process decide example selected sample iteration 
resolve problem considered properties example neighbors unsupervised examples influential subsequent training informative verb sense disambiguation nearest neighbor resolution example similar existing database redundant 
motivated properties introduced formalized concept training utility criterion example selection 
sampling method gives preference example maximizes training utility 
reported performance sampling method way experiments compared method random sampling uncertainty sampling lewis gale committee sampling engelson dagan :10.1.1.14.13:10.1.1.16.3103
result experiments showed method reduced overhead supervision overhead searching database larger degree methods degrading performance verb sense disambiguation 
experiment discussion claim uncertainty sampling considers property mentioned lacks property 
claim committee sampling differs sampling method terms suitability statistics systems compared example systems 
acknowledgments authors japan timothy baldwin japan michael france dan academy anonymous reviewers comments earlier version 
