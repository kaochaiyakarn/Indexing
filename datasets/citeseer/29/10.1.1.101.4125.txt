technical report computer sciences department university wisconsin madison nov framework combining symbolic neural learning jude shavlik computer sciences department university wisconsin madison shavlik cs wisc edu article describes approach combining symbolic connectionist approaches machine learning 
stage framework research groups reviewed respect framework 
stage involves insertion symbolic knowledge neural networks second addresses refinement prior knowledge neural representation third concerns extraction refined symbolic knowledge 
experimental results open research issues discussed 
keywords knowledge neural networks theory refinement prior knowledge rule extraction neural networks kbann algorithm nofm algorithm shorter version appear machine learning 
framework combining symbolic neural learning jude shavlik computer sciences department university wisconsin madison years produced explosion amount research machine learning 
appears worthwhile investigate neural learning methods produce refine symbolic information 
addition neural network approaches proven successful wide range real world tasks speech understanding lippmann handwritten character recognition le cun control dynamic systems jordan rumelhart gene finding language learning touretzky 
experiments strongly suggest connectionist learning powerful approach neural networks symbolic knowledge merits exploration 
important note connectionist architectures simple feed forward single hidden layer neural networks 
particular recurrent networks elman jordan feedback loops memory especially appealing application symbolic tasks sequential nature :10.1.1.117.1928
page combining symbolic neural learning get symbolic information neural networks 
assuming convinced merit framework techniques inserting symbolic information neural network needed 
think preexisting information prior knowledge task hand question neural networks effectively hints 
answer kbann approach towell shavlik noordewier towell creates knowledge artificial neural networks producing neural networks topological structure matches dependency structure rules approximately correct domain theory collection inference rules current task 
