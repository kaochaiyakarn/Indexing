discriminant analysis eigenspace partition tree face object recognition views daniel swets john weng college michigan state university computer science department computer science department falls south east michigan swets inst edu weng cps edu method self organizing hierarchical optimal subspace learning inference framework shoslif 
uses theories linear discriminant projection automatic optimal feature selection internal nodes tree 
demonstrate technique relatively large image database human faces widely varying real world objects taken natural settings show applicability approach variability position size orientation 
require framed images input recognition 
framed images mean relatively small variation size position orientation objects input images allowed 
report experimental results show performance difference subspaces linear discriminant analysis principle component analysis effect tree opposed flat eigenspace 
demonstrate technique relatively large image database human faces widely varying real world objects taken natural settings show applicability approach variability position size orientation 
require framed images input recognition 
framed images mean relatively small variation size position orientation objects input images allowed 
report experimental results show performance difference subspaces linear discriminant analysis principle component analysis effect tree opposed flat eigenspace 
alternative hand crafting features selforganizing approach machine automatically determine features organize knowledge structure eigenfaces view recognition :10.1.1.12.7580
allowing system organize raises important efficiency issues 
feature selection issue 
distribution known adding features produces better results worse results bayesian estimation 
typically distributions known computationally expensive estimate adequately 
allowing system organize raises important efficiency issues 
feature selection issue 
distribution known adding features produces better results worse results bayesian estimation 
typically distributions known computationally expensive estimate adequately 
example principal component analysis known karhunen lo eve projection eigenfeatures face recognition lip reading :10.1.1.12.7580
may represent aspects imaging process unrelated recognition example illumination direction 
increase decrease number eigenfeatures necessarily lead improved success rate 
second issue system organize 
dimensional feature space objects linear search impractical recognition probe requires computations 
extracting just single fovea image attention point scale family fovea images generated varying attention point scale supplied points shown fig 

allow system learn measure positional scale variation training set 
mef mdf projections explained sections 
expressive features mef principal component projection called karhunen lo eve projection represent kirby sirovich recognize face images pentland planning illumination objects recognition tasks murase nayar lip reading system bregler omohundro :10.1.1.12.7580
features produced projection give minimum error approximating image show performance image reconstruction call expressive features contrast discriminating features described 
discriminating features mdf mef projection suited object representation features produced necessarily discriminating classes defined set samples 
describe major variations set sample images due lighting direction variations may irrelevant classes divided 
labeling scheme available training images discriminant analysis performed 
computer vision pattern recognition pp 
june seattle washington 
swets weng shoslif shoslif object recognition image retrieval phase ii tech 
rep cps michigan state university department computer science wells hall east michigan october 
turk pentland eigenfaces recognition journal cognitive neuroscience vol :10.1.1.12.7580
pp 

weng ahuja huang learning recognition segmentation proc 
international conference computer vision pp 
