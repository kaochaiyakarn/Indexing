august src research report efficient flexible value sampling mike burrows shun tak leung mark vandevoorde carl waldspurger kevin walker william weihl systems research center lytton avenue palo alto california www research compaq com src compaq systems research center src charter advance state art computer systems doing basic applied research support business objectives 
interests projects span scalable systems including hardware networking distributed systems programming language technology internet including web commerce information retrieval human computer interaction including user interface technology computer appliances mobile computing 
src established digital equipment 
test value ideas building hardware software prototypes assessing utility realistic settings 
interesting systems complex evaluated solely practical enables investigate properties depth 
experience useful short term refining designs invaluable long term advancing knowledge 
major advances information systems come approach including personal computing distributed systems internet 
perform complementary mathematical character 
lies established fields theoretical computer science analysis algorithms computer aided geometric design security cryptography formal specification verification 
explores new ground motivated problems arise systems research 
strongly committed communicating results exposing testing ideas research development communities leads improved understanding 
research report series supplements publication professional journals conferences technical note series allows timely dissemination research findings 
seek users prototype systems common interests encourage collaboration university researchers 
efficient flexible value sampling mike burrows shun tak leung mark vandevoorde carl waldspurger kevin walker william weihl august publication history version report appear proceedings ninth international conference support programming languages operating systems cambridge ma usa 
republished permission 
currently working decode genetics 
mark vandevoorde currently working altavista 
carl waldspurger currently working vmware kevin walker currently working bill weihl currently working akamai technologies fl acm association computing machinery permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copyrights components owned acm honored 
abstracting credit permitted 
copy republish post servers redistribute lists requires prior specific permission fee 
request permissions publications dept acm fax permissions acm org 
presents novel sampling techniques collecting statistical profiles register contents data values information associated instructions memory latencies 
values interest sampled response periodic interrupts 
resulting value profiles analyzed programmers optimizers improve performance production uniprocessor multiprocessor systems 
value sampling system extends dcpi continuous profiling infrastructure inherits desirable properties value profiler low overhead approximately slowdown profiles code system including operating system kernel operates transparently requiring modifications profiled code 
hardware value prediction mechanisms originally proposed lipasti shen reduce pipeline delays long latency operations 
simulations indicated surprising amount locality values computed instructions allowing result values predicted accurately prior executions instruction 
software value profiling investigated calder feller eustace :10.1.1.40.2933
value profiler records values generated instructions program maintains statistics observed values 
example value profiler report time instruction pc generates result value rest time result value 
possible approaches implementing value profiler 
binary rewriting tool instrument program adding code capture results generated instructions calder atom instrument binaries 
alternatively machine simulator emulator modified record values interest simulation 
approach various architectural studies value prediction 
timer interrupts employed periodically sample values program executes 
pursued technique refer value sampling wish distinguish approaches 
generalize traditional notion value profiling allowing users capture wide variety values associated execution code 
example addition recording values generated program profiled collect timing information load took ns state directly visible running program load hit second level cache physical address accessed store 
value profiling number practical uses 
provide data evaluating proposed hardware features 
value profiles provide feedback help focus manual tuning drive automated optimizations 
debugging currently little experience application 
code optimizations enabled value profile reveals places values invariant semi invariant places variable register contains value :10.1.1.40.2933
optimizations include ffl prefetching value profile reveal addresses accessed identify absolute addresses relative offsets highly predictable 
ffl specialization value profile identify common values procedure arguments allowing significantly better code generation 
example call site log routine may called argument admits particularly fast implementation 
similarly virtual method calls object oriented languages specialized common receiver classes 
ffl speculation value profile expose opportunities software speculation allowing predicted values dependent instructions actual values resulting long latency operations computed 
optimizations particularly effective architectures support predicated execution ia 
value profiles highlight reasons piece code performing poorly allowing tuning effort focused effectively 
example observing load latency information programmer realize data structure shared processors inefficient way 
value sampling system extends digital continuous profiling infrastructure dcpi briefly review :10.1.1.124.5957
dcpi profiler statistical sampling combined set profile analysis tools 
dcpi uses frequent randomized periodic interrupts obtain samples code running machine including operating system kernel 
dcpi sample contains pc address space identifier may optionally include information events cache misses branch mispredictions depending specific processor implementation 
device driver aggregates samples passes user space daemon process 
daemon uses information dynamic linker operating system map address space identifiers object files executable libraries file system stores samples files grouped object files refer 
analysis tools samples various ways providing traditional cpu time profiles procedures inferring reasons dynamic pipeline stalls individual instructions 
careful implementation yields overhead percent despite sampling interval instructions 
building dcpi inherit structure kernel device driver user space daemon analysis tools access profiles file system 
inherit number dcpi advantages ffl efficiency periodic sampling dramatically overhead value profiling schemes binary modification interpretation 
apply value sampling address spaces see overheads sampling intervals normally dcpi 
overhead compares favorably order magnitude slowdowns reported value profiling systems binary instrumentation 
ffl completeness able apply value sampling operating system kernel privileged address spaces difficult handle means 
ffl transparency programs slowed slightly unaffected profiled 
danger unexpected interactions arising address space resources virtual addresses file descriptors 
similarly inherit dcpi primary disadvantage sampling approach capture values observed run program 
practice problem 
sections provide details implementation experiences believe learned 
approach value sampling system extends dcpi key ways 
interrupt routine captures values interrupted program addition usual pc samples event records 
second limit space needed hold value samples employ sampling techniques described gibbons matias 
allow maintain efficiently containing frequently seen values pc constant space hotlist 
developed additional analysis tools process value samples 
example user display values observed associated assembly language instructions higher level source statements 
tools automatically find semi invariant values code executed significant number times 
gathering value samples performance counters available alpha processors interrupt running cpu periodically 
interrupt record values current context 
typically sampling interval instructions small amount randomization added avoid unwanted timing interactions 
question system obtain data values interrupted context 
knowledge path followed processor pc just prior interrupt trivially associate values registers particular instructions 
early attempt attempt solving problem bounce back technique arranges second performance counter interrupt occur small number instructions issue block executed immediately resuming original interrupted code 
setup interrupt return pc instructions issue block fetched recorded determine registers contain values interest 
second bounce back interrupt values interest register values return address captured recorded 
ensuring exactly issue block executed interrupts proved fairly difficult large number kernel instructions executed interrupt return path 
assisted feature alpha cpu generate interrupt specified number cycles user mode 
able delivery interrupt fairly predictable evicting cache line containing issue block interest cache fill time account 
observe progress user mode second interrupt delivered 
case increase number user mode cycles trigger bounce back interrupt 
progress give attempt collect data interrupt happened percent interrupts 
rarer problem amount progress interrupts ambiguous tight loops interrupted code 
successfully prototyped bounce back mechanism worked user mode code alpha processors family 
light limitations sought alternative 
interpreter ultimately added complete interpreter alpha instruction set dcpi kernel module 
interrupt routine interprets instructions advancing interrupted context instructions executed directly processor 
conceptually simple practical concerns approach 
interpreter correct reasonably complete 
interpreter give encounter instruction handle important instructions rare profiling significant blind spots 
handle entire instruction set rigorous testing gain confidence interpreter 
think run interpreter having side effects interrupted context relax need correctness interpreter 
error interpreter produce erroneous value profiles affect profiled program 
dismissed approach wished apply value sampling operating system kernel performs loads device registers may side effects 
matter complete interpreter coverage limitations 
unable apply code interrupts permitted alpha pal code certain small parts kernel 
operations easily emulated interpreter running high interrupt level 
particular interpreter gives encounters ffl traps page faults handled high interrupt levels ffl change interrupt level ffl change kernel stack pointer interpreter stack 
interpreter provides flexibility available earlier bounce back scheme 
particular interpreter modified record timing information individual long running instructions loads discussed section 
similarly interpreter record system state page table contents interrupt level interrupted context 
modified simulate internal state particular processor order deduce processor perform poorly 
quite complex analysis performed interrupt routine provided time critical interrupts masked long 
user mode interpretation support alternative means invoking interpreter different set advantages disadvantages 
running interpreter interrupt routine able run user mode library profiled address space upcall mechanism 
address space created dynamic linker loads value profiling shared library application 
library registers address space profiling driver 
profiling interrupt driver context library user mode trap handler runs interpreter logs data obtained returns control interrupted context 
similar intended signal unix systems 
user mode approach different practical implications ffl address space disturbed ways timing new shared library loaded new code run user mode thread stacks 
ffl interpreter run high interrupt level limit amount time spent interpreter 
ffl page faults encountered interpreter resolved operating system normal way interpretation cease page faults 
ffl values available kernel physical addresses available directly user mode 
similarly data may easier obtain user mode data revealed stack trace interrupted context 
ffl correctness interpreter affects single address space principle users modify interpreter collect specialized information 
ffl user mode approach straightforward perform value sampling interpreted languages 
expect users prefer run value profiling interpreter user mode want run kernel 
data reduction basic mechanism capturing values second problem data reduction 
number values observed point program large far large store conveniently 
calder feller eustace employed small table hold frequently seen values 
ad hoc update policy required tuning get results 
gibbons matias techniques summarizing stream data 
techniques provide statistically sound basis keeping list frequently seen values stream values main advantage ad hoc scheme tuning required memory result quality 
briefly describe simplest scheme keeping track top frequently seen values data stream details recommend gibbons matias 
conceptually algorithm keeps probability table maps possible value counter 
algorithm maintains invariant unbiased estimate number times seen data stream 
nz number non zero counters initially nz 
table space values non zero counters nz data stream added counter probability causes nz temporarily exceed operation repeated nz arbitrary value reduced value instance recorded retained probability non zero replaced number heads seen tossing biased coins probability heads typical value 
chose keep track frequently seen values captured program location 
run instance gibbons matias algorithm value type captured program location 
interesting values value sampling system capture different values associated interrupted context generated directly programmed instructions 
implemented ffl stack context information current procedure return address 
ffl latencies long running instructions memory accesses 
measured instruction interpreted surrounding operation reads cycle counter 
possibilities ffl processor hardware state current physical processor processor set physical addresses associated memory accesses processor interrupt priority level 
similarly interpreter simulate execution instructions processor pipeline memory system exist capture relevant internal state 
ffl os runtime system state including various identifiers current process parent process user group controlling tty privilege level effective user set pending blocked unix signals current scheduling priority policy 
ffl application state current thread holds certain locks 
useful values capture conjunction values return address current procedure 
allows value sampling system identify values semi invariant call site 
obtain return addresses take simple approach logging values value return address register value top stack 
conventions followed compilers generate alpha code return address places 
downstream analysis tools deduce values valid stack unwinding information object file 
customized value profiling system customized various ways 
particular user may specify information capture transform value samples merged profile database format values reporting 
user writes dynamically loadable customization module loaded dcpi user mode daemon 
plug module users may specify captured interpreter instruction opcode 
option capture particular opcodes usually basic information collected including pc bit instruction code 
addition users may opt record content explicitly named register instruction operand result memory operand virtual address latency loads 
instruction captured values form value tuple 
time interpreter runs generates tuple sequence interpreted instruction sequence 
tuple sequences generated interrupt handler processed user mode daemon 
sequence daemon calls routine customization module transform pc value pairs merged profile database data reduction 
transformation arbitrarily complex 
example daemon may transform value tuples consisting pc operand address load store instructions pc value pairs pc instruction accessing address instruction 
idea application section current implementation maintains value hotlist pc 
may extended maintain different kinds values data address latency load composite values address latency pairs 
modified analysis tool report frequent values associated instruction format specified customization module 
example operands floating point instructions printed floating point numbers default hexadecimal format 
written customization modules module capturing load latencies discussed section 
experience feedback value sampling system direct automatic optimizations performed compiler 
experience highlight performance problems programmers able address 
discuss uses expected 
expected uses collecting register values expected system provide information similar obtained previous value profiling systems 
reason believe quality data significantly better worse obtained systems claim system easier 
repeated experiments verify value profiles agreed prior 
looked programs demonstrate profiles give useful hints programmers bent optimization 
give brief examples 
leveraging ability dcpi pinpoint performance bottlenecks tools direct programmer places consume significant amount time contain semi invariant values 
showed tools straightforward programmer discover specialization opportunities calder mk sim :10.1.1.40.2933
opportunities specialization ray tracer povray working particular test images 
exponentiation routine specialized integer exponents common 
adding extra case yielded speedup 
similarly specializing routine degree polynomials yielded large improvement 
smaller optimization opportunity gzip speedup achieved noticing constant read repeatedly global variable 
identifying replay traps alpha processor attempts execute memory access instructions soon possible means executing order order program order 
part way processor pipeline load store may exceed resource limit architectural constraint instruction ordering may encountered prevents immediate issue instruction 
case performs replay trap aborts instruction instructions follow program order replays fetch stage pipeline 
details replay traps manual 
replay traps quite expensive programmer care know event occurring inner loop 
observed unusual programs chip spends half time recovering 
commonly expect improve performance percent having information causes replay traps 
replay traps particular interest chip performance counters provide information wish 
interesting replay trap types ffl order load issues order store accesses bytes load replayed ensure fetches stored bytes 
ffl size load follows narrower store accesses bytes load replayed store merged bytes 
ffl synonym chip memory accesses addresses cache index congruent modulo replayed avoid displacing data cache needed 
cases pair memory accesses involved 
instruction pair difficult identify simply looking program text 
example encountered inner loop synonym trap caused load global variable interacting load stack location 
starting value sampling interpreter built mechanism called assist cases 
chip hardware identifies pc pair memory accesses incurred large number replay traps 
code identifies pc memory access type replay trap involved 
mechanism works interpreting runs instructions detect accesses may potentially conflict 
interpretation runs need long include instructions pair cause replay trap 
distance bounded maximum number instructions flight traps involving loads loads retire data back memory 
expensive simulation way interpreter know replay trap really happened 
combining data interpreter data samples ensures user attention directed instruction pairs fact causing replay traps 
eliminate false alarms accesses potentially conflict interpreter tracks data dependencies interpreted instructions 
data dependence instructions access memory replay trap 
interpret long run instructions wished 
tru unix tlb mechanism uses interprocessor interrupts remove tlb entry tlb multiprocessor 
processor respond ipi time bound operating system crashes 
bound imposed limit number instructions kernel mode interpreter process provided additional motivation user mode value interpreter 
load latency measurements value sampling system measure latencies loads reading cycle counter 
sixteen different latencies observed load 
simplify report generated user typically assigns latencies bins known times cache hits various parts memory hierarchy 
automatic programs determine interesting thresholds experimentally 
pc instruction nv latencies ldt 
ldt 
mult example load latency value profile example load latency value profile floating point benchmark 
column number value samples instruction column probability value sample added hotlist nv column length hotlist latencies column hotlist binned load latencies means primary cache hit means secondary board cache hit means memory 
column comes data indicates average number cycles instruction stalled cpu 
mult instruction obvious bottleneck suffering cache consumes cycles benchmark 
operands mult uses loads load latency profiles essential tell second loads missing 
latency profile clear load usually hits second load usually goes memory 
concern recording load latencies system disturb measurements worthless 
measured system perturbs primary data cache creating program repeatedly touches block cache block set coordinate 
program uses separate load instruction block 
ideal world interrupts loads get cache misses 
results shown table 
rate fraction cache blocks table fraction primary cache blocks experiencing various rates due perturbation value profiling 
key point notice table cache blocks evicted value profiling system small number evicted 
fraction blocks evicted second level cache lower due larger size 
load latency values correct wrong 
expect results improved carefully tuning interpreter minimize number cache blocks touched 
overhead measurements assess cost value profiling measured slowed cpu benchmark suite mhz alpha machine 
dcpi interrupts generated average instructions 
table shows average integer benchmarks suite slowdown various cases 
value profiling vprof overhead 
basic value profiling vprof interrupt handler interprets instructions interrupts 
slowdown nontrivial lower instrumentation 
slowdown includes effect dcpi related average dcpi option slowdown vprof vprof vprof context context overhead various profiling options interpret interpret average length frequency slowdown overhead increasing interpret length interpret interpret average length frequency slowdown overhead average number interpreted instructions interrupt table slowdown cpu integer benchmarks percent value traditional profiling driver daemon processing 
requires complex processing vprof costs reasons 
handler interprets instructions time versus vprof compensates high cost doing interrupts 
instructions driver emits value samples daemon conflicting instructions report vprof produces sample interpreted instruction 
vprof recording return address information discussed section context imposes small extra cost expected 
tables illustrate manage overhead balancing run interpreter interpret frequency indicated interrupts instructions interpret time interpret length 
table shows slowdown different interpret lengths interpreter runs half time 
slowdown increases approximately rate instruction interpreted 
table shows slowdown different cases lead average number interpreted instructions interrupt 
overhead roughly case declines slightly interpreter run interrupt cost amortized instructions 
increase interpret length keep overhead acceptable interpreting 
important order study interaction instructions may need interpret relatively long instruction sequence getting useful data 
related value sampling primarily influenced prior research hardware mechanisms value prediction software techniques value profiling 
motivated growing interest static dynamic optimizers capable exploiting value profiles 
lipasti shen introduced idea value prediction proposing hardware attempts predict result value computed instruction cache previous result values instruction 
studies revealed surprising amount temporal locality nearly half instructions produced result value computed execution 
subsequent proposals improved hardware value predictors 
gabbay mendelson explored profiling techniques identify instructions exhibit high degree value locality 
showed hardware value misprediction rates reduced tagging opcodes predictable instructions marking candidates hardware prediction 
low overhead value sampling techniques provide detailed information hardware predictors 
calder feller eustace investigate software techniques value profiling :10.1.1.40.2933
atom binary rewriting tool instrument executable profiled adding code keep track frequently occurring values computed instruction 
table top values maintained instruction limiting storage requirements 
heuristic replacement policy maintain top values approximately 
table full frequently encountered value evicted half table periodically cleared avoid pathological behavior certain value sequences 
contrast ad hoc approach required tuning results application gibbons matias sampling algorithms provides sound statistical basis maintaining value table 
approaches impose substantial overhead profiled programs calder reported average slowdowns ranging factor factor depending various parameters 
sampling approach imposes dramatically overhead enabling transparent value profiling production systems 
rubin explored limited value profile information dynamic runtime code specialization 
wiggins optimizer identified hot spots dcpi statistical profiling dynamically added instrumentation frequently executed code collect path value information 
suitable traces dynamically specialized optimized program executed 
user mode value sampling interpreter ideal match optimizer 
approach aimed transparent dynamic optimization developed bala duesterwald banerjia dynamo system 
instrumentation dynamo relies interpretation observe program behavior requiring modifications 
interprets dynamo increments counters identify hot instruction traces 
hot traces selected dynamic recompilation emits optimized code fragment cache 
interpreter encounters branch jumps optimized native code fragment cache contains entry branch target 
dynamo resumes interpretation program execution leaves fragment cache 
dynamo limited interpretation common value sampling approach dynamo collect value information interpreter triggered periodic interrupts 
examples systems employ techniques essentially limited forms value profiling 
example run time systems languages self examine types call sites order replace indirect procedure calls direct procedure calls pick subroutines specialized types 
profile driven optimizations exploit value profiles 
usual example specializing code sequences frequently occurring values example speculatively reducing critical path high latency computation assuming computes common values checking assumption 
alpha simple effective optimization set hint bits predict target indirect jump common jump target 
new types values system collect enable additional optimizations 
load latency value profiles guide prefetching 
profiles profiles eliminate replay traps 
upcall handler allow profile driven optimizations done program running 
fixing jump hint bits eliminating size order replay traps candidates required code analysis local 
optimizations practical multiprocessor optimization cost amortized cpus 
see bias distribution interrupted pc locations despite randomization interrupt period 
occurs modern processors probability interrupt delivered pc depends just instruction pc executed microarchitectural issues causes pipeline trap 
interpretation runs interrupted pc location distribution value samples inherits bias 
example loads significantly different numbers value samples despite basic block 
believe eliminate bias interpreting random number instructions sampling values 
promising system value sampling 
believe system convenient collect value profiles previous approaches 
experimented new types values collected 
remainder section discuss felt went badly design 
interpreter success 
fears difficult sufficiently reliable proved 
contrasts bounce back technique introduced interpreter 
bounce back involved code interpreter tied particular hardware type harder implement correctly 
issues remain interpreter 
main interpreter interrupt level diagnose replay traps long interpretation runs cause operating system crash described section 
upcalls may answer problem 
minor irritation things interpret instructions cause operating system traps instructions modify kernel stack pointer 
gibbons matias algorithm maintaining simplified things 
employing founded algorithm saved time spent tuning experimenting ad hoc approaches 
user level upcalls profiling shows promise need experience 
upcalls interact interesting ways unix signal handlers exceptions 
see insurmountable problems 
tim mann comments corrections draft report 
alpha microprocessor hardware manual 
compaq computer june 
order number ec url gatekeeper dec com pub dec semiconductor literature hrm pdf 
anderson dean ghemawat henzinger :10.1.1.124.5957
leung sites vandevoorde waldspurger weihl 
continuous profiling cycles gone 
proceedings th symposium operating systems principles pages saint malo france oct 
appears acm transactions computer systems november 
url gatekeeper dec com pub dec src abstracts src tn html 
bala duesterwald banerjia 
transparent dynamic optimization 
technical report hpl hp laboratories cambridge june 
url www hpl hp com techreports hpl pdf 
calder feller eustace :10.1.1.40.2933
value profiling 
proceedings th international symposium microarchitecture pages dec 
url www cse ucsd edu users calder abstracts micro vp html www acm org pubs articles proceedings micro calder calder pdf 
calder feller eustace 
value profiling optimization 
journal instruction level parallelism mar 
url www org vol index html 
ucsd edu users calder abstracts vp html 
chambers ungar 
customization optimizing compiler technology self dynamically typed object oriented programming language 
proceedings sigplan conference programming language design implementation pages june 
sigplan notices july 
dean hicks waldspurger weihl 
hardware support instruction level profiling order processors 
proceedings th international symposium microarchitecture pages dec 
url www research digital com src dcpi papers micro ps www acm org pubs articles proceedings micro dean dean pdf 
rubin 
wiggins line program specializer 
proceedings ieee hot chips xi conference aug 
url rob com files pdf gz 
feller 
value profiling instructions memory locations 
master thesis university california san diego apr 
ucsd technical report cs 
url www cse ucsd edu users calder papers 
ps gabbay mendelson 
program profiling support value prediction 
proceedings th international symposium microarchitecture pages dec 
url www ee technion ac il micro ps gz www acm org pubs articles proceedings micro gabbay gabbay pdf 
mendelson 
speculative execution value prediction 
technical report tr ee department technion israel institute technology nov 
url 
technion ac il ps gz 
gibbons matias 
new sampling summary statistics improving approximate query answers 
proceedings acm sigmod international conference management data pages seattle washington usa june 
url www 
com user matias papers sigmod ps 
lipasti shen 
exceeding dataflow limit value prediction 
proceedings th international symposium microarchitecture pages dec 
url www acm org pubs articles proceedings micro lipasti lipasti pdf 
calder 
predictive techniques aggressive load speculation 
proceedings st international symposium microarchitecture pages dec 
url www acm org pubs articles proceedings micro pdf 
smith 
predictability data values 
proceedings th international symposium microarchitecture pages dec 
url www acm org pubs articles proceedings micro pdf 
srivastava eustace 
atom system building customized program analysis tools 
proceedings conference programming language design implementation pages 
acm 
url www research digital com wrl techreports abstracts html 

