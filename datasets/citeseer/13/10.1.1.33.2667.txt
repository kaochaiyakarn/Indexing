copa parallel programming language collections dan suciu val tannen propose new framework parallel processing collections 
define high level language called copa processing nested sets bags sequences generalization arrays lists 
copa includes features query languages object oriented object relational databases addition powerful form recursion query languages 
copa formal declarative definition parallel complexity part specification 
prove existence complexity preserving compilation copa offers upper bound guarantees parallel complexity compiled code 
majority compilation process architecture independent parallel vector machine model bvram 
bvram instructions form sequence algebra independent interest carefully chosen reconcile conflicting demands supporting complexity preserving compilation copa high level constructs efficient implementability variety architectures 
allows establish comparisons parallel algorithms provably optimal implementation bvram butterfly networks 
targeting practical architectures logp model 
prove monotone data communications admit optimal implementations logp model implement bvram efficiently 
tested feasibility entire approach compilation running experiments logp simulator 
goal compare speedup scaleup components total running time data communication cost control communication cost local computations 
focuses parallel processing collection data structures 
main motivation comes database perspective 
relational database queries proven highly suitable parallel evaluation 
hand relational data uniform easily partitioned uniformly nodes parallel architecture 
hand operators relational algebra simple efficiently computed parallel load balance 
sharedmemory shared architectures studied intensively parallel databases having potential scaleup 
today commercial database management systems dbms achieve linear speedup constant scaleup architectures 
modern application require data complex relational model 
labs suciu research att com 
done author university pennsylvania supported nsf ccr onr contract fellowship institute research cognitive science 
university pennsylvania val cis upenn edu 
author supported nsf ccr onr contract 
scaleup measures running time database size number nodes parallel architecture increase factor 
meet new demands new data models proposed 
object oriented databases view data collection interlinked objects 
focus query evaluation switches processing massive uniform data sets link traversal highly interconnected collection objects 
parallel shared architecture link traverses node boundaries query data migrate nodes 
consequence efficient parallel evaluation harder achieve model relational 
additional complication caused absence genuine query languages 
important exception oodbms programming done general purpose object oriented languages extended collection datatypes persistence mechanism 
objectstore 
attempt parallelize language face usual problems dealing side effects situation improved odmg standard proposal oql query language adopted commercial systems 
difficulties hindered emergence parallel implementations oodbms 
contrast object relational model shifts focus back sets 
data represented relations relations attributes allowed user defined types relations 
sets model includes bags multisets arrays lists generically called collections short object relational model extends relational allowing additional kinds collections nested collections user defined types 
model predominance query language accessing processing data opposed generalpurpose language 
typically query language obtained extending sql new data features related ongoing sql standardization process 
note simple modifications oql serve superior object relational query language 
existing parallel evaluation techniques relational query languages rely mainly efficient parallel join algorithms hashing techniques appear extend objectoriented object relational languages new features 
nested collections give rise naturally nested parallelism 
shortly section give example illustrates desirability nested parallelism difficulties creates compilation 
main challenge avoid data skew 
fact relational databases hash techniques perform poorly presence data skew :10.1.1.104.8594
second object relational queries involve user defined functions expensive create additional data skew problems 
ordered collections arrays lists require new processing techniques different sets 
deal data parallel techniques languages part data parallel exist parallel extensions fortran high performance fortran parallel extensions lisp cm list lisp applicative parallel programming languages nesl sisal crystal proteus data parallel ml 
concerned query constructs integration languages 
propose new framework parallel processing collections 
define highlevel language called copa processing nested sets bags sequences generalization arrays lists 
copa includes includes features query languages object oriented object relational databases link traversal 
features coexist naturally powerful form recursion allows expressing parallel algorithms slowdown 
main contribution parallel compilation technique copa characteristics see ffl majority compilation process architecture independent intermediate languages interest sa algebra operations flat sequences bvram sa code generation rewriting copa compilation architecture dependent architecture independent copa seq logp model butterfly network copa complexity preserving compilation bvram 
ffl formal declarative definitions time complexity part specification copa intermediate languages 
prove corresponding compilation phases preserve complexity code 
ffl architecture independent compilation step targets parallel vector machine model called bvram bounded vector random access machine 
bvram instructions carefully chosen reconcile conflicting demands supporting compilation copa high level constructs efficient implementability variety architectures 
ffl establish comparisons parallel algorithms provably optimal implementation bvram butterfly networks 
ffl maintain measure independence targeting practical architectures logp model 
prove optimality results 
ffl tested feasibility entire approach compilation running experiments logp simulator 
goal compare speedup scaleup components total running time data communication cost control communication cost local computations 
follows discuss details technical contributions 
declarative complexity traditionally declarative query languages carry explicit information complexity query 
query cost concern optimizer choose physical execution plans different costs 
copa parallel complexities part specification language operational semantics complexity declarative queries 
new allows provide formal proofs compilation techniques preserve complexity 
goals show high level declarative complexity achieved implementation language complex copa 
guaranteeing preservation complexity focus main architecture independent compilation phases representation sets bags sequences elimination recursion flattening nested parallelism 
especially concerned guaranteeing complexity resulting flat program sure potential parallelism lost flattening process 
choosing compilation target flat sequences possibility existing parallel algorithms relational algebra operators 
choice reasons wanted techniques uniformly kinds collections including lists arrays wanted offer complexity guarantees presence data skew 
recursive functions declarative query languages limited expressive power 
instance relational algebra express transitive closure 
limitation remains true extensions relational algebra nested relations 
increase computing power applications query language sql embedded general purpose programming language 
limitations data structures exchanged languages impedance mismatch problem limitations optimization opportunities sql query time 
interested design powerful language queries say oql just program phrases combined variety parallel algorithm implementations maintaining goal complexity preserving compilation 
introduced special recursion schema copa called map recursion 
note map recursion stronger traditional extensions relational algebra fixpoints datalog recursion map recursion language turing complete fixpoint extensions usually limited expressive power 
show map recursion eliminated preserving complexity 
bvram sequence algebra target compilation designed parallel vector machine model called bvram bounded vector random access machine 
bvram consists fixed number vector registers holding flat sequence sequence atomic values performs sequence instructions registers 
instruction parallel sense operates parallel elements input sequence 
bvram instructions form basis new algebra flat sequences call sequence algebra sa provide declarative parallel complexities 
believe algebra independent interest natural extension relational algebra sets sequences 
extensions considered bags order inherent sequences harder deal 
typical properties considered set bag algebras results transitive closure expressible algebra 
prove new kind results sa give lower bounds complexity certain sequence operations sequence reversal matrix transposition expressible sa 
factoring compilation bvram sa provides clearer specification translation better proofs complexity preservation 
monotone communications architecture dependent step target parallel architectures butterfly network logp model 
consider butterfly network theoretical purposes 
show bvram instructions admit optimal implementation butterfly network 
result copa parallel complexities high level formalism express algorithms butterfly network derive low level parallel complexity logp model proposed culler way model accurately existing parallel shared architectures 
model consists fixed number nodes node processor local memory 
nodes communicate network model focuses communication cost captures parameters latency overhead gap logp 
focus logp model lies programming parallel algorithms communications interfere 
karp proved results logp model simple parallel algorithms broadcast summation prefix scan implemented optimal parallel time optimal means absolute minimum running time constant factor 
problems considered size input data depends number processors 
extend list results proving monotone communications admit optimal implementation logp model 
bvram instructions admit optimal implementations logp model 
sense result differs previous ones data size larger number processors dominates parallel running time 
monotone communication problem nodes holds sequence data items item sent node possible communication monotone items change order global sequence 
give absolute optimal algorithm monotone communication 
monotone communication algorithm needs followed parallel broadcast step prove optimal additive cost broadcast operation 
call algorithm near optimal communication time dominated size data additive cost depends experiments tested feasibility implementation techniques running simple experiments logp simulator 
goal experiments compare components total running time data communication cost control communication cost local computations 
comparisons important implementation techniques achieve processor balance basically expense massive data communications 
results show medium large data sets number nodes range gamma data communication costs low price worthwhile paying guaranteed processor balance 
number nodes grows threshold cost control messages exceeds total communication cost making communications expensive 
example start example illustrating features parallel language collections nested parallelism user defined functions monotone communications 
consider relation stores name sales storing name set sale transactions store sale transaction consists item name price 
object oriented object relational system allow declare data class sale float price string item class store string name bag 
sale sales val stores bag 
store consider query fun stores select name sales stores name applies parallel function store satisfying predicate returns bag results 
suppose function turn applies function parallel sales say fun select nested parallelism 
note user defined function access name store sale transactions copa syntax specify query queries expressible minor syntax changes virtually languages proposed object oriented object relational databases oql odmg sql related language 
take close look parallel evaluation query course start applying parallel stores stores uniformly distributed nodes order get load balance 
want apply parallel selected stores ensure load balance redistribute selected stores nodes 
face dilemma due fact stores nested collections distribute stores uniformly sales dilemma typical nested collection associated nested parallelism 
solution flattening technique segment descriptors 
works sequences sets bags part deals encodings nested sets bags terms sequences 
illustrate technique suppose database stores sales respectively total 
split stores flat sequence names nested sequence sales sales nested sequence sales split flat sequences ss ss numbers ss lengths subsequences sales called segment descriptors 
database represented flat sequences distribute sequences uniformly nodes 
illustrates nodes 
name name result ss name stores node node node names ss sales implementation query explain query computed data representation step step 
apply predicate store 
assume returns true stores shaded 

send flag element saying store selected step involves data communication 
resulting subsequence call elements shaded 

redistribute uniformly nodes 

apply elements needs access name store 
replicate names selected stores resulting sequence contains names stores multiplicities respectively 

apply name sale pair done locally perfect load balance 
call sequence results 

ss subsequence ss corresponding selected stores ss 
distribute ss uniformly nodes 

final result nested sequence represented sequences ss step perfectly balanced parallel computation price paid frequent data communications 
insight communications particular simple form monotone communications 
describe optimal algorithm monotone communications 
example key step consisted expressing nested collections terms flat sequences 
interesting question generalizes complex queries nested collections 
show case identifying minimal set flat sequence operations support nested queries 
simple parallelize sufficient implement efficiently oql style queries nested collections 
related bubba fad svp bancilhon describe database language fad designed parallel database machine bubba 
fad functional language featuring nested sets object identifiers main parallel constructs parallel map called filter parallel divide conquer construct called pump 
parker describe value model parallelism bulk data processing svp sets streams represented trees 
complex parallel operator called transducer generalizing parallel map parallel divide conquer parallel stream processing 
fad svp explicit sequence operations 
query languages collections collection operations consider inspired theory monads 
idea monads organize semantics programming constructs due moggi 
wadler showed useful organizing syntax particular explain list comprehension syntax functional programming 
trinder wadler showed extension comprehension implement flat relational calculus 
trinder watt sought uniform algebra different collection types 
followed penn 
nesl nesl powerful general purpose parallel functional languages designed guy blelloch comes high level definition parallel complexity 
compiled vector random access machine flattening nested parallelism segment descriptors techniques described earlier 
flattening technique uses segment descriptors encoding nested sequences terms flat sequences 
compilation improves nesl ways need stack sequences economical communication primitives needed improves complexity iterations 
able guarantee complexity compiled program combination language design copa compilation techniques nesl preservation holds contained programs see sec 
detailed discussion 
logp base communication cost analysis logp model proposed culler 
precise model virtually modern multiprocessors logp model simple serve framework design analysis parallel algorithms 
optimal algorithm monotone communication logp model 
previous results previously announced 
seen materialization theoretical result 
give characterization nc terms query language sets featuring monad constructs seen divide conquer recursion dcr easy see dcr admits nc implementation map recursion 
overview organized follows 
describe copa sec 
give examples 
copa declarative complexities described sec 

sec 
describes architecture independent part compilation sec 
shows encoding sets bags terms sorted sequences sec 
shows eliminate recursion sec 
show actual compilation bvram 
application complexity preserving compilation sec 
gives lower bound cost certain permutations expressed copa 
describe architecture dependent implementations sec 
implementation butterfly network discussed logp model 
sec 
give optimal near optimal logp algorithms monotone communications sec 
report logp simulation experiments 
conclude sec 
specification copa language copa 
language inspired developments query language adds novel kind recursion map recursion 
monomorphic functional language emphasis operations collections combinations user defined external functions 
language order treatment functions functions arguments results functions higher order treatment collections allowing arbitrary nesting 
restricted form recursion quite general 
major restriction copa object pointers 
features meant enable state side effects presence completely change problem 
intend formally prove compilation technique preserves complexity interest controlling size formalism 
copa specified relatively small number essential constructs additional syntactic sugar examples demonstrate practicality language 
language definition types copa strongly typed 
kinds types types complex values types functions 
play auxiliary role avoided altogether price heavier syntax expressions functions order 
value types constructed set base types combinations product type sum type collection type constructors sets bags sequences 
simplify presentation consider tuples records course records treated similarly major changes 
base types denoted include types string real int user defined types 
view objects base types black boxes attempt parallelize operations values 
complex value types theta theta ftg fjtjg function types stands arbitrary domain base type 
usual theta theta denotes product type contains tuples hx xn xn dually sum disjoint union type values form xn denote unit empty product type obtained theta theta single value empty tuple hi 
define boolean type def unit unit identify values hi hi true false respectively 
take disjoint sum type resulting type values interest sequel 
expression type meaning variable dp cp external function sigma base type eni theta theta tn tuple theta thetat projection tn tn injection case xn en see text abstraction function application general purpose operators copa 
interesting type constructs languages collection types sets bags sequences 
differ treat multiplicities order 
set multiplicities order irrelevant 
bags multiplicities matter fj jg different fj jg 
sequences lists order multiplicities matter 
operations similar collection types consider limited form collection polymorphism may define functions uniformly collections 
notation dtc collection types ftg fjtjg 
deep collection polymorphism just convenient way avoid repeating notation times 
language constructs constructs expressions copa listed figures 
complete definition language appendix usual distinguish free bound variables 
bound 
explained earlier language order functional point view bound variables value type range complex values 
language parameterized set external functions constants examples constants abc external functions play major role copa programs 
external functions sequential copa attempt parallelize 
simplest external functions scalar functions domain codomain base types gamma 
aggregates max fjnjg sum fjnjg general aggregate function type agg dsc base types 
complex user defined function type external function 
attempt parallelize external functions consequence aggregates performed sequentially 
copa follows design principles considers product sum collection types orthogonal 
constructs associated product types associated sum types fig 
associated collections fig 

recursion iteration fig 

meaning product sum copa expressions standard briefly describe completeness denotes tuple theta thetat projections theta thetat hx xn def sum type denotes value value 
meaning case meaning meaning case ex expression type meaning dc dtc empty collection dec dtc singleton collection ftg set union phi fjtjg bag addition sequence concatenation ext dt dt extension see text map dt dt map see text flatten dtc flattening nested collections length dtc number elements get dtc get single element see text set bag ftg fjtjg bag seq fjtjg theta order predicate seq bag fjtjg bag set fjtjg ftg zip theta theta sequence zip see text enumerate enumerates sequence split theta inverse flatten see text collection oriented operators copa 
expression type meaning iteration map recursion theta iteration recursion copa 
pression 
type case statement provided xn see appendix complete definition 
statement expressed case lambda expression denotes function input variable construct function application 
collections dc empty collection dec denotes singleton collection phi set union bag addition sequence concatenation respectively 
context generic collection write operations dtc theta dtc dtc 
extension function dtc defined ext dx xn gamma def xn gamma map defined function map dx xn gamma def df xn gamma flatten flattens nested collection obvious way 
note ext express map flatten conversely 
alternatives lifting functions collections traced back alternative ways defining monads refer reader discussion relationship collection languages monads 
proves equivalence ext gamma map gamma flatten 
proving properties copa ext gamma times map gamma flatten feel free switch back forth presentations 
operation get attempts retrieve unique element collection returns error collection singleton get zip enumerate defined xn gamma yn gamma def hx hx gamma yn gamma enumerate xn gamma def gamma zip returns error sequences different lengths 
function split kind inverse flatten 
expects sequence integers sum equals length split splits number subsequences lengths numbers split 
iteratively computes false returns formally smallest number false 
map recursion discussed subsection 
shall drop type superscripts types abstractions deduced context abbreviate dx dxn gamma dx xn gamma freely pattern matching expressions function swap theta theta write swap def hx hx hx hx official theta thetat thetat typing rules novelties copa typing rules 
typing rules important copa associated parallel operational semantics parallel complexities discussed briefly describe complete listing rules appendix rules contexts keep track variables types 
context set gamma fx xn xn distinct variables types 
strictly map ext flatten ext ext flatten map translations ext gamma map gamma flatten 
speaking expressions copa tiers value expressions function expressions rules appendix consequences form gamma denoting fact expression type context gamma form gamma example rules expressions gamma gamma gamma theta theta gamma gamma somewhat special rule important context parallel evaluation weakening rule gamma gamma allows add unused variables context gamma 
rule needed typecheck certain copa expressions 
example rule requires context fact need exactly variables forget unused variables typing derivation expression 
applying weakening rule different places yields different correct type derivations copa expression 
shall see may correspond different parallel evaluations different parallel complexities values free variables broadcast parallel threads 
due interest database applications closed free variables expression function type called query 
example simple examples consider functions shall need sequel function definition comments pi dt theta theta dt map database projections filter ext predicate select theta pi filter hb making copa practical syntactic sugar extend core copa concrete syntax including ffl ml style expressions allowing give names values functions 
ffl select gamma block various query languages sql oql 
ffl records opposed tuples 
extensions merely syntactic sugar show easily compiled away 
ml style expressions val fun equivalent second 
allow val fun declarations allow patterns function arguments fun meaning fun theta theta pi pi pi 
select gamma construct select collection expressions kind sets bags sequences boolean conditions 
drop clause empty 
translated rules ffl select oe dec dc ffl select fun select ext example function distribute left theta dt dt theta meaning distribute left hx dy yn ci def hx yn ic defined fun select syntactic sugar distribute left hx ext hx yi 
note essential role free variable function hx yi 
distribute right theta theta defined similarly 
example illustrate realistic example copa 
consider set customers consisting name orders 
orders form sequence attributes itemno qty desc free text description order 
types defined class customer class order name string itemno int orders sequence order 
qty int description description due processing errors customers place orders twice 
orders itemno known placed sequence may differ quantities 
tell duplicate orders looking free text description 
user defined function related takes descriptions tells duplicate orders returns integer range describing likelihood duplicates 
want retrieve customers duplicate orders likelihood 
achieved fun cs set customer 
fun customer val ord orders val length ord val ord ord val ord ord select related description description 
zip ord ord itemno itemno length max select name cs ord shorthand extracting subsequence sequence expresses copa pi filter hx ki enumerate ord recursion copa general recursion parallel function language difficult compile 
blelloch blelloch describe compilation technique parallel functional programming language 
technique preserve parallel time complexity program certain programs contained 
compiler check program contained undecidable property 
adopt different approach 
impose syntactic restrictions recursion schema programmer allowed 
compiler simply verify function definition looks fun map fun chg fun fun chk hk fun fun hx jc chy fun recursive schemas translations map recursion syntactic sugar written type provided theta intuitively generalized form divide conquer 
compute divides computing xn gamma applies subproblem xn gamma applies conquer function note may refer original input addition results subproblems 
recursive schemes technically speaking map recursive rephrased easily 
contains examples recursive definitions 
way conquer translation map recursive scheme shown 
function tail recursive translation map recursion straightforward omitted 
illustrates complex divide conquer recursion input divided subproblems translation map recursion straightforward omitted 
informal examination variety parallel algorithms persuaded map recursion suffices express natural way large classes parallel algorithms 
easy write preprocessor translates recursive schemas map recursive definitions process 
wonders functions easily translated map recursion 
primitive recursion sequences particular case map particular unary binary representation arithmetical primitive recursive functions representable 
turns definition ackerman function gamma gamma exhibits kind recursion scheme map recursion order express copa express program stack 
practical example linear time median finding algorithm 
parallel evaluation parallel complexity copa parallel language statement precise definition copa parallel complexity part language definition 
exposing complexity language level novel context declarative query languages complexity traditionally related query computed presumes query specifies computed 
copa complexity computation independent just number language definition assigns expression prescribe expression evaluated 
say complexity declarative 
burden ensuring complexity preserved running time falls complexity preserving compilation 
section describes copa parallel complexity complexity operational semantics full definition appendix parallel complexities spirit blelloch blelloch give completely formal definition rules accompany operational semantics 
structured operational semantics style pioneered refined 
parallel complexity function copa expression gives number defining parallel running time expression function defined inductively structure expression evaluation tree defined definition copa operational semantics 
defines parallelism copa 
example expression map gamma defined map gamma def max gamma effect stipulating map computed applying parallel element sequence term allows evaluation pre postprocessing meaningful constant factor 
similarly consider second complexity associated copa expression called complexity essentially sequential complexity expression 
complexity preserving compilation ensure relate running time parallel machine 
exact definition may depend target architecture 
example assuming shared architecture processors running time tp required tp log complete definitions operational semantics parallel time complexity complexity appendix table copa type inference rules 
highlight basic principles underlying definitions 
operational semantics operational semantics set rules telling copa expressions evaluate constants grammar hc ci tm dc cc encoding object base type consider typed constants 
evaluation expression free variables occurring bound constants 
association variables constants captured environment finite set form ae fx xn cn xn variables cn constants 
variables xn distinct 
environment ae defines type context gamma fx xn type say gamma associated ae 
see 
natural operational semantics style defines ternary relation ae ffl meaning term environment ae evaluates constant ary relation ae ffl meaning function applied constant environment ae evaluates simple example flatten ffl 
example environment consider enumerate ae fx ae ffl 
relations ae ffl ae ffl defined environments ae associated context gamma gamma gamma type judgments gamma operational semantics rules ae ffl defined simultaneously appendix prove expected fact environment ae expression exists constant ae ffl may generates error diverges 
similarly ae ffl unique 
reason abbreviate ae ffl ae ffl evaluation result understood context 
complexities rule operational semantics associated rule computing strictly speaking depend ae ae ae denoting complexities ae ffl ae ae denoting complexities ae ffl 
follows simple rule sum sizes values involved rule including values environment ae simple base types int bounded length strings adopt unit size measure size objects type user defined types may arbitrary types 
interesting rules dictate computed parallel 
highlight key sources parallelism copa reflected definition 
ffl order operations collections operations flatten specialized operations bags sequences take inherently parallel 
example flatten def ffl map ext map similarly ext main source parallelism 
execute threads parallel constructs copa sequence length maps function 
ffl map recursion iterating map parallelism achieved map recursion 
defined follows 
suppose xn gamma def gamma def def gamma def hx yn def max intuitively definition suggests way computing 
compute xn gamma 
takes time 
compute gamma 
perform computations parallel 
total time step max 

compute hx yn gamma takes time note steps done sequentially addition equation 
comment relationship weakening rule subsection parallel evaluation 
consider example expressions hx map cn gamma assume 
starting empty environment evaluating ae ffl hx map ae cn gamma 
turn requires evaluate ae ffl ae ffl map ae ffl map cn gamma 
expression needs environment ae evaluates cn gamma second expression choices 
evaluate directly evaluating expressions ae ffl get replicated ae times 
second choice apply weakening rule map rule evaluate cn gamma complexities 
example illustrates applying weakening rule early reduce complexity 
assume weakening rule applied early possible 
illustrating examples comment impact weakening rule recall allows drop useless variables type contexts 
environment counts computation environment replicated map ext rules 
useless variable environment may add significantly increasing 
important typechecking copa applies weakening rule close root possible 
example illustrate simple functions indexing sequence sequel index theta meaning index hx ii gamma length length 
sought generalization indexing array 
complexities mn 
function lets element sequence know position xe replicates sequence times selects parallel copy element number fun index hx ii val xe enumerate fun pi filter hx pi xe flatten map replication done map ing function free variable xe expect mn 
fig 
illustrates relevant fragment actual operational semantics 
denotes value xn gamma value gamma 
recall apply rewriting rules subsection evaluation starts ffl index hx ii proceeds fx ig ffl enumerate 
denoting result xe ffl xe xe ffl xe xe ffl gamma gamma xe xe ffl map gamma fx xe ffl map gamma fx xe ffl map gamma ffl flatten fx xe ffl flatten map gamma fragment operational semantics tree evaluation proceeds fx xe ffl flatten map shown fig 

top part tree responsible mn complexity rules carries environment xe xe size mn 
note applied weakening rule earlier get rid environment complexity 
applied weakening left right branches corresponding flatten gamma gamma cluttered reducing complexity 
height tree independent 
interesting assume gamma index expressed refer reader details 
complexity preserving compilation section complexity preserving compilation technique copa 
target kinds parallel architectures 
butterfly network consequently copa high level language describe parallel algorithms butterfly network infer running time high level complexities second architecture logp model introduced culler 
model captures accurately modern shared architectures choosing logp model target copa express parallel programs architectures practical interest 
techniques described architecture independent 
compilation achieved number steps illustrated architecture dependent defer step section discuss steps 
step preprocessing step encoding bags sets sorted sequences 
denote copa seq target language copa restricted sequences 
set bag operations translated immediately sequences need sorting 
step main result consists showing sorting sequence length expressed copa log fixed 
course particular set bag operations join current parallel relational systems offer practical implementations hashing 
argued techniques main goal guarantee asymptotic complexity hash algorithms help 
second step actual compilation phases 
replaces map recursion loops 
program complexities rewritten recursion free program 
real number depends program 
describe fact rewriting scheme produce different recursion free programs different 
note translating recursive programs recursion free ones eliminate need stack 
beneficial reasons 
database context input collections database relations intermediate results typically large relations stored disc stack free implementation fixed number intermediate relations needed implement program 
second simplifies memory management mimd simd architectures simd architectures associate relatively small amount memory processor making stack impractical 
second compilation phase translates recursion free copa programs intermediate code called sequence algebra sa 
new language abstraction simd architecture manipulates flat sequences hard part compilation consists encoding operations nested sequences containing nested parallelism terms flat sequences time preserving parallel complexities previous step program complexities mapped complexities 
third step generates code simple parallel vector model 
model called bvram bounded vector random access machine related blelloch 
finite number vector registers number registers needed depends source program compiled 
bvram communication instructions simpler 
external functions aggregates complex user defined functions set apart bvram 
bvram instructions external functions definition parallel time complexity complexity equal sum sizes input output sequences 
complexity preserving translation sa bvram straightforward 
interesting observation show complexity preserving translation bvram sa obvious proving bvram sa strongly equivalent 
fourth step fig 
architecture dependent implements bvram particular target parallel architectures 
considered architectures butterfly network logp model 
butterfly network bvram instruction complexity executed log parallel steps network log nodes 
note possible precisely bvram simple communication primitives logp model complex butterfly prove bvram instructions admit near optimal implementations logp 
optimal respect communication cost main complexity addressed logp model 
bvram instruction prove implementation optimal support claim efficiency experiments 
discuss fourth step section 
considering architecture independent compilation copa seq bvram obtain result theorem fixed copa seq program complexities compiled equivalent bvram program complexities 
offer complexity guarantees falls short preserving complexity leave open question result improved 
notice achieve ideal complexities particular case 
believe case importance database applications select gamma gamma blocks nested 
step account map copa function bvram increasing complexities notice copa expression 
result borodin hopcroft shows arbitrary permutation computed butterfly network oblivious algorithms 
step improved prove lower bound independent interest 
copa seq express sorting 
implementing sets bags sorted sequences start describing function sort 
assume element sequence sorted size 
theorem exists copa function sort sorts sequence length log 
fixed yields 
proof 
multiway merge sorting function related log log log sorting algorithm hypercube attributed section cypher plaxton 
need auxiliary functions introduce 
sorting small integers start theta theta theta 
mi sorts sequence integer keys assumption keys gamma 
assuming constructs sequence gamma filter enumerate replicates times selects copy gamma elements key similar index example 
complexities mn 
direct sorting derive sorts sequence 
sequence xn gamma compute elements sequence ranking takes replicating times 
sort numbers guaranteed 
direct merging function theta takes sorted sequences lengths merges 
expressed copa mn 
starts ranking sequence takes mn 
splits ranks subsequences flatten zm gamma returns xm gamma zm gamma steps take 
efficient permutation sequence length permutation form sequence containing numbers gamma arbitrary order want permute output sequence defined yp gamma 
compute permutation need sort sequence def keys range gamma 
achieve better follows 

represent key base def requires digits 
perform standard radix sort 
step sort certain digit keys starting significant digit significant 
range digit gamma need steps 
step consists call complexities bn 
efficient merging multiple sequences core sorting algorithm lies function merging sorted sequences total length 
restriction algorithm complexities log 
note implies merge copa sequences total length log 
describe function 
assuming input gamma sequence start choosing set splitters gamma 
contain exactly splitters dividing subsequences equal size 
easily achieved 
sort total splitters assume allowed complexity 
call resulting sequence 
split sequence subsequences splitters requires direct merging length 
summing obtain total complexity 
transpose nested sequence get permutation problem achieved 
apply recursively sequence xx def gamma length ij length follows total length sequences xx gamma repeating process observe successive recursive calls multi merge merge nested sequences length gamma gamma 
log log gamma log steps merge nested sequences total length 
complexities log 
efficient sorting describe efficient sorting algorithm copa sort complexities log 
start splitting input sequence subsequences equal size 
sort sequence recursively merge sort called sequences lengths gamma gamma gamma 
log log gamma log recursive calls sort sequences length complexities log 
hard part sorting algorithm achieve keeping complexity control 
course want optimality obtain log proposition copa express sort complexities log log log log 
proof 
achieved valiant merge algorithm expressed copa note need user defined external sorting function express part algorithm sequential merging small sequences 
sorting set bag operations implemented straightforwardly sorted sequences 
catch external functions example aggregates 
example sum fjnjg external function bags need corresponding function sum sequences order implement bags sequences 
call set external functions closed sequences external function sets bags exists equivalent sequences complexities 
equivalent means functions commute seq bag bag set operators see sec 
definitions omit giving formal boring definition equivalent theorem assume set external functions closed sequences 
copa expression complexities translated equivalent expressions complexities log sets bags 
elimination map recursion copa point copa seq copa set bag operations 
second compilation step consists eliminating map recursion translating loops 
central construct lemma eliminates occurrence map recursion 
lemma contain map recursion complexities expressed copa recursion complexities proof 
consider particular case detail function fig 
way divide conquer recursion 
show generalize arbitrary map recursion 
recall types theta compute steps input type divide phase start singleton sequence type apply repeatedly function ext having type elements satisfy predicate 
need tag elements resulting avoid applying repeatedly omit details 
call resulting sequence 
combine phase start map ing function apply repeatedly adjacent elements additional bookkeeping necessary sure applied correct pairs suffices store depth divide conquer tree element combine adjacent elements depth 
element resulting list 
obviously translated time complexity 
complexity preserved case divide conquer tree perfectly balanced 
leaves reached sooner sequence nodes need divide steps add total complexity 
refine steps order limit increase complexity 
number different levels divide conquer tree contain leaves 
example perfectly balanced tree perfectly balanced tree totally unbalanced tree may equal depth 
obviously compute time complexity simulating divide phase retaining results 

improve divide phase time complexities translation copa map recursion respectively 
start variables initialized initialized singleton 
apply repeatedly divide phase leaves reached move allow touched times move entire content empty repeat process allow touched times point empty moving general allow accumulate times empty moving obviously number levels leaves discovered making move filled exactly leaves levels 
refined divide phase 
compute complexity 
addition def pay price unnecessarily touching elements variables moving leaf travels exactly moving part accounts additional sitting leaf touched times touching part costs complexity divide phase bounded 
omit details complex bookkeeping necessary keep elements sorted see example 
compute time complexity divide phase 
need useful divide plus cost moving 
variables gamma touched times respectively added 
time complexity divide phase 
combine phase done similarly reverse 
concludes special case way divide conquer recursion 
general map recursive function proceed similar fashion intermediate values recursive call map introduce additional leaf 
general case equal height divide conquer tree 
interesting visualize translated function particular cases 
simple case perfectly balanced way divide conquer function function fig 
recursion tree perfectly balanced 
leaves depth translated function uses auxiliary variables complexity improves 
second way recursion fun simple function represents worst case recursion elimination value recursive call stored recursion unfolding 
traditional implementation stack store 
stack forced split virtual stack fixed set sequences move values sequences minimize number unnecessary touches 
proceeding induction structure copa expression applying lemma obtain theorem consider function defined copa seq time step complexity construct function copa seq map recursion equivalent time complexity respectively integer depending compiling intermediate code intermediate code target compilation sequence algebra sa fig 

algebra independent interest playing similar role flat sequences relational algebra flat sets relations 
sa datatype flat sequences values type product base types 
functions sa map tuples flat sequences tuples flat sequences types theta theta theta theta example theta unit unit theta types sa recall unit obtained product theta theta theta theta unit unit valid sa types 
copa language variables sa algebra functions function expressions value expressions 
value type expressed function type unit sa allows functions combined function composition tuples 
external functions handled copa follows 
scalar external function exists corresponding map sa 
general copa scalar function sa contains map includes combinations scalar external functions conditionals projections 
non scalar external functions corresponding functions sa 
simplify presentation consider aggregate functions defer discussion general external functions section 
aggregate agg copa exists function agg theta meaning si map agg si 
sa sequence operations select defined primitives copa 
defined copa require nested sequences intermediate results include primitives sa 
describe 
need convention boolean types sa 
don union types longer take def unit unit encode booleans context scalar operations sequence operations 
case true false second case true false 
select returns subsequence elements having true position see example 
bounded monotone routing theta theta meaning xi replicates element sequence number times dictated corresponding element required match length final result called bound 
example 
name monotone routing comes fact elements routed different positions relative order elements preserved 
definition copa xi def pi flatten map distribute right xi segmented monotone routing similar replaced nested sequence si def sii copa time complexities defined evaluation function sa constants 
operations external functions total sizes inputs outputs external functions complexities copa 
follows sa function complexities equal constant factor expressed copa 
example technical level compilation steps need function combine theta theta example identify yi shuffles sequences tags example true false false true false true true yi arguments satisfy length length length length result combine undefined 
function useful lemma lemma expression type meaning map scalar function expressible copa see text agg theta agg aggregate external function copa see text id identity ffi composition theta thetat theta theta tn projection unit hf fk theta theta unit empty sequence singleton unit unit returns hi theta concatenation length length select theta see text zip theta theta enumerate theta theta see text theta theta theta see text sequence algebra sa 
move elements sequence preserve relative order elements combine show express combine sa obviously expressed copa 
start computing enumerate example 
compute select ei select ei select complement select selects elements having value false true 
example 
lists tell position element 
suffices route element corresponding position 
subtract number right neighbor considering def length right neighbor element exception position add number similarly formally map hi bi gamma tail ui similarly example get gamma gamma gamma gamma gamma gamma gamma replication sequences xx xi yy yi tail um gamma um gamma defined pi select ui 
example xx yy respectively length 
zip map scalar function hb yi describe compilation recursion free copa seq intermediate code sa 
eliminate free variables copa expressions subexpressions 
sketch step refer reader full details 
copa expression rewrite equivalent subexpression closed 
rewriting changes types follows 
recall free variables occur context gamma fx xn rewriting translates ffl value expression gamma function theta theta ffl function expression gamma function theta theta theta note rewriting value expressions function expressions particular value type function type unit shown translation rewrites copa expression formalism differs copa expressions subexpressions functions free variables additional operators ffl function composition ffi ffl distribute left see example 
needed rewrite expressions map free variable need distribute order eliminate free variable ffl functional case statement meaning def needed replace case statement relies free variables 
ffl function ffi theta theta theta meaning yi def hin hx needed case statement free variables 
refer reader details translation 
consider copa expressions closed functions move main part compilation flattening 
segment descriptors 
sequence types encoded sequences types respectively 
example encoded pair seq component sequence body flatten second component segment descriptor map length 
applying idea arbitrary types may contain levels nestings unions describe detail level unnesting 
type sa define seq encoding sa 
referring grammar subsection define formally sequ def theta seq theta theta def sequ theta theta sequ theta equation clear discussion 
equation component stores length encoded sequences necessary sequence hi hi encoded length 
keep component uniformity 
nested sequence type define seq encoding type seq 
formally show binary product ary product similar sequ xn gamma def hx xn gamma gamma seq thetau hx hx gamma gamma def xn gamma sequ gamma def length gamma 
reached crucial step compilation level complexity preserving flattening 
lemma map lemma function sa map complexities exists function seq seq sa complexities simulates map 
precisely xn gamma seq map xn gamma seq xn gamma 
structure expression independent value occurs integer constant proof 
done induction structure see fig 

map essentially map precise map map theta theta theta theta ffi say essentially map 
similarly essentially select essentially select 
difficult case 
describe informally compute xn gamma 
suppose variable additional variables initially empty 
number iterations assume gamma conceptually group having implies ffi gamma 
follows ffi moment assume sequence value position smallest size denoted simulation proceeds stages numbered denote ffi gammak indexes divide sequence xn gamma groups group finalized stage cardinalities groups increase geometrically group elements second gamma gamma starting stage repeatedly apply application check reached iteration move stage group fx gamma moved stage done redundant touched values stored times 
redundant ffi 
stage completed move entire remaining stages similar 
apply repeatedly move iterations terminate corresponding elements precisely stage elements group fx gamma gamma moved stage move entire redundant stage due repeatedly touching elements stored group sizes increase stage additional touches larger larger 
elements groups allowed touched times contributed complexity putting formulas stored touched additionally total ffi gammak gamma ffi gammak ffi gammak ffi gammak recall map copa sa complexities refer copa 
notice seq sequ theta theta theta 
ffi gammak ffi additional complexity ffi added moved stage accounts ik gamma gamma 
adding stages find total additional done 
redundant done stages touched times additional complexity 
stage contains result 
assumption gamma critical 
may assume elements finish iterations order need additional bookkeeping trace relative order elements function combine example 
maintain boolean sequences total length length length says elements interleaved total length length length length length says interleaved move elements function combine put right position complexity length length analysis remains unchanged 
moving combine combine result drop elements coming total complexity afford operation done times 
show define general case sequence minimum size position necessarily 
case compute done complexities simply applying repeatedly eliminating elements reach iteration 
split iteration parts essentially synchronizing parallel iterations moment reach minimum size perform parallel iterations described iteration step continue parallel iterations step technique reverse minimum sizes 
reverse means elements initially stored progressively moved main iteration done elements apply successively 
elements moved decreasing order gamma moments elements moved chosen iterations simultaneously 
note requires know values gamma gamma gamma gamma mn gamma advance 
computed easily essentially simulating keeping results 
show flatten arbitrary types copa involving sequence nesting unions 
type copa define compile sa type compile def compile theta theta def compile theta theta compile compile def compile theta theta compile compile def seq compile addition define function encode compile encode def encode theta thetat hx xn def encode encode tn def encode encode xn gamma def seq compile encode encode gamma prove theorem copa function complexities exists function compile compile compile sa equivalent sense compile encode encode time complexities compile 
way expression compile depends integer constant equal proof 
induction structure recall setting belong copa slightly modified formalism described earlier cases illustrated fig 

cases simple exceptions map lemma split 
briefly explain simple ones describe split 
obvious types explained 
starting scalar external function assume theta theta theta theta compile theta theta compile theta theta 
value hx encode expression fig 
assumed zip zip sequences 
aggregate agg theta theta 
theta input type theta theta theta theta theta output type theta theta 
equality recall equality base types copa compile compile return value type 
eq theta equality function returning equal values different ones 
hf notice compile may return tuple wider compile returns tuple sequences single sequence 
reason compiling projection requires inspection compiled types compile return flat sequence components encoding component 
notice id may fact tuple contributes position result 
case statement def interesting 
recall value returns 
value encoded encode computed applying compile compile respective component append results append mean component wise append result may tuple 
course compile returns desired result argue return low complexities 
observations value encode encoding non empty flat sequence compiled function compile computation takes 
assume type compile theta theta 
encode seq theta theta sequ tuple explains corresponding table entry 
briefly describe distribute left hx recall meaning replicated element sequence encoding consists sequences replicate sequences done details omitted 
cases split similar omitted 
map map lemma 
illustrate si 
case flat sequence simple just new segment descriptor 
nested sequence encode form sd bd sd sd segment descriptor body bd length 
segment descriptors length bodies various lengths 
si additional segment descriptors just def length times require computations encode si new sd bd new sd example illustrates new storage descriptors case considering si bd sd bd sd new sd understand encode si notice vertical stripes encodes nested sequences respectively rows bd sd 
need compute new storage descriptor sd new sd si 
define sd si si assumes presence aggregate function sum want compilation dependent existence particular aggregate functions 
describe function fig 

illustrates function running example 
delta xn def gamma gamma xn gamma xn gamma easily expressible sa 
note contrast theorem number registers depends 
remarks order 
external functions presentation purposes considered scalar external functions aggregate ones 
fact results subsection carry arbitrary external functions 
suffices require function copa sa contain primitive compile compile implementing map 
relationship previous blelloch blelloch discuss flattening compilation data parallel languages deployed implementation nesl 
techniques apply functions arbitrary recursion stack sequences 
complexity guaranteed certain recursive functions contained semantic condition checked compiler 
objective offer complexity guarantees program language obtained imposing syntactic restrictions recursion schemas map recursion 
true restriction implies recursive function contained flattening techniques improve theirs ways don need stack economical communication primitives flat sequences sa arbitrary permutation primitive prefix sums deal addition recursion 
subtle important point deserves comments 
expression translated tail recursive function blelloch copa expression compiled sa expression compile scalar function pi pi ffi map ffi zip aggregate function agg pi pi ffi agg ffi ffi pi pi pi pi map eq ffi zip ffi compile hf fk compile fk tn ffi id ffi fk compile ffi compile fk ffi ffi compile ffi compile map ffi length ffi length ffi map ffi ffi compile compile theta theta ffi ffi hk gamma gamma map ffi zip ffi hk ii compile theta theta map compile flatten length get eq ffi error zip eq ffi hk error enumerate ffi map ffi split see text distribute left see text compile compile compiling recursion free copa sa 
bd sd es enumerate esi sd ui delta map enumerate bd ii sd new delta function sd si needed compile split 

instruction meaning move instruction map scalar external functions agg aggregates empty sequence singleton sequence sequence concatenation length singleton sequence length bounded monotone routing vm segmented bounded monotone routing select selection goto unconditional jump empty gotol conditional jump halt halts program instruction set bvram 
techniques compile recursion 
translation may incur significant increase complexity additional recursion unfolding 
example consider statement iterations complexity log iterations constructs sequence length starting sequence length doubling length step returns result 
total complexity delta compilation technique compile map applied 
equivalent tail recursive function additional cost copying result recursion unfolds blelloch techniques compile tail recursive function 
practical matters encoding nested sequences flat sequences redundancies 
example simple flat sequence type compiled flat sequences holds useful information store respectively 
implemented small copa compiler techniques described 
simple static flow analysis generated code identify eliminated unnecessary flat sequences analysis identify sequences redundant eliminate 
discovered minor changes code generation compile result significant savings 
example consider compilation length type compute length body component simply return third component 
choice better second component non redundant add significantly instance code subject 
optimized distribute left hx scalar type 
generating code bvram compilation step generates code bounded vector random access machine bvram 
bvram consists fixed number sequence registers hold flat sequence vector arbitrary length 
keep model simple include scalar registers number represented sequence length consisting number 
bvram instruction set shown fig 

operations simply inherited sa 
conditional jump empty goto takes jump instruction holds empty sequence continues instruction 
bvram special set instructions related external functions 
follow exactly external sa map scalar functions agg 
example map sum meaning map sum split 
case sa consider complex external functions 
bvram program sequence labeled instructions 
bvram instruction instr external functions define parallel complexities def def length length length complexity sum lengths input sequences output sequence 
exception output larger sum inputs exception inputs length may produce output length 
external functions scalar aggregates complexities sa copa may 
bvram program takes input sequences designated input registers returns results designated output registers 
input result undefined enters infinite loop error occurs 
terminating execution define complexities sum instructions executed straightforward generate complexity preserving bvram code sa 
surprisingly converse expressing bvram program sa function immediate prove 
proposition sa bvram strongly equivalent function sa time complexity executed bvram complexities conversely 
proof 
traditional way simulating register machine single loop preserve complexity statement touches register iteration just relevant ones 
number registers bvram function sa type theta theta performing step program program counter encoded singleton sequence position 
said iterating results increased complexity 
avoid define sequence functions inputs outputs values smallest registers particular moment indexes registers size largest register program counter 
iterates step function long affects registers sees long sizes stay conditions violated stops 
job calls gamma iterates steps looking smallest gamma registers gamma finishes tries step account smallest register gamma ignores 
returns 
performs operation calls gamma possibly different set gamma registers set registers sees 
direction proposition needed compilation theorem converse significant point view optimizations implies optimizations done bvram performed level sa language 
application lower bounds copa complexity compilation theorem prove copa communications aware language 
arbitrary sequence xn gamma copa allow construct arbitrary permutation gamma pay certain price complexities corresponding communication cost needed achieve permutation shared multiprocessor 
permutations subject lower bound reverse tr meanings reverse gamma gamma tr gamma gamma gamma gamma gamma gamma show computed uniformly 
uniformly mean particular knowledge elements type uniformity condition particular inputs may compute reverse tr obviously reverse sequence gamma subtracting element sequence gamma 
uniformity condition precise follows 
bvram uniform type external function type theta theta bvram uniform assume existence external functions theta shall assume sequel 
theorem bvram uniform algorithm computing reverse tr linear complexity requires omega gamma log parallel steps 
proof appendix apply complexity preserving compilation obtain corollary reverse tr expressed uniformly copa 
proof 
suppose 
compilation theorem obtain bvram program computing reverse tr contradiction 
architecture dependent implementations implementing bvram butterfly network butterfly network bounded degree log diameter network 
communication algorithms studied extensively butterfly network refer reader terminology follow 
goal prove bvram instruction admits optimal implementation butterfly network 
believe logp implementation described evidence claim bvram instructions simple implement large variety architectures 
nodes butterfly network arranged matrix rows log columns 
traditionally input data items reside left column computation proceed left right sweeps back sweep log steps 
bvram implementation follows principles input sequences stored left column 
assume input sequences aligned instruction expects input sequences row 
requirement essential alignment achieved log steps 
subsection optimal implementation means constant number sweeps log steps 
simplify presentation assume number rows larger length input output sequence 
case sequences wrapped show algorithms slowed factor equal number omit details 
assume bvram scalar external functions complexity 
theorem bvram instruction complexity implemented optimally log steps butterfly network 
communications oblivious 
proof 
sketch scalar external functions involve communication input sequences aligned implemented steps 
append operation requires monotone routing sense pp 
done log steps greedy routing algorithm 
instruction requires prefix sum followed routing routing monotone log steps suffice 
involves non monotone routing explain 
recall meaning viewed nested sequences segment descriptors equal length length length 
replicated number times equal length 
example 
assume length length 
single sequence replicated times 
start simpler case length powers say output length may assume rows 
communication problem 
data items reside rows 
data item index sent addresses gamma achieved single sweep network simple greedy oblivious algorithm 
length power pad dummy elements closest power run greedy algorithm 
result dummy data items eliminate packing routing runs log steps 
case power simpler 
consider general case arbitrary lengths 
def length length meaning replication subsequence occupy rows 
round nearest power 
communication algorithm proceeds follows 
starts spreading subsequences introduces gaps starts row gamma idea owns rows 
spreading takes log steps 
applies previous algorithm locally order replicating length times 
done parallel exploiting recursive nature butterfly network due spreading parallel computations interfere 
packs results eliminating gaps due rounding values power 
illustrate power theorem application 
known items sorted node hypercube log parallel steps 
items sorted log parallel steps node hypercube see section preparata 
derive algorithm complexity butterfly network follows 
consider sorting algorithm sort subsection complexities 

compile theorem get bvram program time complexities 

apply theorem result log log time sorting algorithm butterfly network log log nodes 
logp model logp model parallel computation introduced culler goal capturing accurately communication costs parallel computers 
main purpose model serve basis design analysis parallel algorithms encouraging loopholes existing parallel models 
logp consists fixed number processors local memory connected network allowing point point communications 
parameters define communication network 
latency upper bound delay delivering word message word sent time arrive destination gap amount time node needs wait sending receiving consecutive words message processor sent word time may send word takes gamma time send message size 
overhead time processor spends preparing network sending receiving message processor computations prepare message spending overhead 
show bvram admits near optimal implementation logp model 
near optimal mean running time larger lower bound plus constant stronger asymptotic notation spirit optimal algorithms described 
details logp model discussed original presentation affect algorithms 
important implementation bvram discuss 
allow variable length messages fixed length ones option considered 
second allow node send receive message simultaneously 
issue original messages short addition algorithms discussed sends node wait data preceding receive 
setting restriction applies allowing disallowing send overlap receive huge impact algorithm assume node separate input output port allowing send receive overlap 
long messages raise question receiving processor spends overhead message starts arriving completed choice corresponds case node network dma 
assume incoming message contain header destination memory address dma deliver message right address interrupt processor completion processor spends overhead process message 
assumption realistic setting bvram fixed number registers fixed number possible destinations packet 
fig 
illustrates detail steps sending message words processor 
sender receiver spent units time communication free time activity sender processor busy send word send word send word 
gamma send word time activity receiver receive word receive word 
gamma receive word processor busy gamma ready sending message size logp model perform computations 
sender able send message time sg receiver ready receive message time sg 
particular case logp called postal model 
logp model equivalent postal model normalize 
data partitioning bvram register general longer process splitting large collection nodes called data partitioning declustering :10.1.1.104.8594
current parallel database systems variety partitioning techniques :10.1.1.104.8594
partition sequences opposed sets new method block partitioning sequence split continuous subsequences xp stored consecutive nodes 
call global sequence subsequence local sequence 
block partitioning global sequence concatenation local ones 
node know length global sequence 
achieve load balance strive uniform partitioning local sequences lengths length divisible length mod local sequences element 
implementation bvram instruction intermediate results may non uniformly partitioned 
bvram instruction bvram registers uniformly partitioned 
control communications karp provably optimal logp algorithms broadcast prefix sum implicit summation algorithm 
broadcast node holds word send gamma nodes 
prefix sum node holds integer word purpose compute node sum problems algorithms absolutely optimal constant factor running time exact complex formula asymptotically log 
bvram implementation algorithm form control communications data communications addition bvram instruction needs data communications expects account bulk cost bvram implementation 
communications different nature broadcast summation treated 
case bvram data communications monotone communications 
data communication called monotone element order global sequence communication 
fig 
illustrates monotone non monotone communication 
describe subsection greedy algorithm monotone communication problem running time optimal communications larger discussed block partitioning equivalent round robin case sets order matter :10.1.1.104.8594
proc proc proc proc proc proc monotone non monotone communication optimal cost broadcast operation call algorithm near optimal monotone communication algorithms form bases bvram implementation logp 
implementing bvram bvram instruction implemented sequence local computations control communications monotone data communications requiring non monotone data communications 
illustrate ffl implemented exactly monotone communications shift left second shift right 
fig 
illustrates 
ffl starts prefix sum segment descriptors followed monotone communication fig 
data communication ffl external functions 
setting external functions sequential 
concern bvram expressions form map parallelized 
scalar function takes run locally processor obtain load balance uniformly distributed 
interesting case scalar say nested sequence segment descriptors flatten body 
aggregate bvram instructions agg fall category 
want run sequentially subsequence problem subsequences may cross node boundaries distributed uniformly 
redistribute fist subsequence crosses node boundaries call process clustering run sequentially node subsequences node decluster result 
intermediate steps sequence may distributed unevenly nodes 
need clustering way subsequent executions balanced 
describe detail 
xn gamma running time 
assumption external functions proc proc proc step implementation compute cost length length segment descriptor 
define def gamma def clustering send entire sequence node ensures load node max gamma higher node 
summary proposition bvram instructions implemented logp model combinations provably near optimal communication steps 
near optimal monotone communications logp model recall monotone communication node holds input local sequence elements sent zero nodes 
elements arrive node assembled output local sequence 
referring fig 
input local sequences output local sequences 
subsection denote input global sequence output global sequence 
communication called monotone order elements note requirement uniformly distributed nodes 
denote input output elements respectively xm gamma ym gamma 
view monotone communication requiring sent continuous subset elements fact sent node holding 
assume subsection node holding knows indexes global output sequence sent node numbers holding output elements offsets output elements occur local sequence 
monotone communications required bvram implementation informations directly available computable prefix sum 
node gamma node gamma node gamma gamma node gamma node send blocks optimal monotone algorithm monotone communication data elements send node possible addition nodes example element fig 

assume node detects elements preprocessing step consider part communication problem node may need copy elements locally final destination output sequence monotone communication data element sent different node 
sequel optimal means absolute minimal running time near optimal means cost broadcast communication absolute minimal running time 
algorithm local decisions node data available node 
theorem suppose sg size packets 
exists optimal local algorithm monotone communication problem 
exists near optimal local algorithm general monotone communication problem 
proof 
start describe algorithm node outgoing packet node divide outgoing packets blocks destination nodes see 
communication monotone nodes gamma receive messages node message contention destinations matter order node sends messages 
block send care avoid contention nodes messages coming nodes gamma gamma respectively 
note nodes gamma may send messages strategy avoid contention arrange messages arriving destination arrive left right 
suffices node send blocks right left order nodes gamma may proceed full speed block needs wait node gamma finish sending messages explain details 
algorithm node consists threads send thread receive thread 
send thread described 
idea delay sending block node node left sent packets node takes time dg equal number packets arrive node prove optimality identifying critical node algorithm node busy time execution doing necessary local data proving algorithm node run long 
consider postal model messages don need received explicitly need receive thread 
process sending word message time gamma gamma gamma running time algorithm 
cases node didn wait line 
node sent messages full speed procedure send thread send block node delta size blocks sent offset destination node dg wait gamma units time continue send block node send thread optimal monotone algorithm send thread block sg gammao block sg gammao block gamma sg gammao receive thread block gamma sg gammao block sg gammao block sg gammao possible interference send thread receive thread critical node optimal running time 
node wait 
destination processor message argue receives incoming messages full speed critical node algorithm optimal 
logp model processors spend additional overhead receive incoming message problem overhead may compete send thread 
design receive thread accept incoming messages eagerly disturbing 
receive thread initiate receiving new message time left send thread sends message case wait send thread completes send proceed receiving message 
refering fig 
means receive thread shifts black boxes right far necessary order overlap black box send thread 
inspecting see sg disturb black box receive thread black box needs shifted right units distance black box sg gamma 
shifting affect black box critical node discuss 
analyze running time critical node argument postal model 
node sending word message say time distinguish cases 
send thread node didn wait 
node sent messages full speed 
destination node message receive word time send thread node finished receive thread handle message delay node critical node algorithm optimal 
send thread node wait sending message 
destination node message 
postal model case argue received messages full speed may processed delay 
argue message processed delay 
obvious time word message arrives outgoing messages node sent 
node critical 
prove monotone communications 
note general monotone communication decomposed communication followed series parallel broadcasts elements destination need broadcast 
addition processor may required local replication element assume cost negligible compared communication cost account 
show final parallel broadcasts implemented cost higher single global broadcast 
obvious local broadcasts interference 
recall broadcast algorithm logically arranges nodes tree root holding item broadcast 
possible overlap multiple broadcast trees node may root tree simultaneously leaf tree 
root performs send operations leave performs single receive operation overlapped 
condition sg realistic 
existing multiprocessor architectures typically larger worst suffice assume packets size words 
condition satisfied algorithm problems performing sends receives simultaneously 
experiments order test feasibility logp implementation techniques run preliminary experiments simple benchmarks bare bones copa compiler logp simulator 
compiler takes copa front syntax generates bvram code techniques described 

performs optimization dead code elimination resulted significant savings explained 
common subexpression elimination 
implement union types 
implemented bvram instructions logp outlined subsections straightforward algorithm 
ran benchmarks logp simulator 
components compiler bvram implementation logp simulator written ml sml nj compiler 
fed simulator parameters connection machine measured clock units sp multiprocessors observed changes behavior report experiments parameters cm 
primary goal compare cost communications useful computation cost control communications data communications 
ran benchmarks simple merge algorithm object oriented benchmark inspired oo benchmark 
assembly assembly part part part assembly assembly assembly assembly example assembly hierarchy depth parts merge function pragmatic adaptation valiant parallel merge algorithm 
sorted sequences xm gamma yn gamma inputs 
order merge algorithm starts dividing subsequences length gamma parallel subsequence finds corresponding subsequence merged 
merged external sequential sequential merge function 
valiant algorithm continues recursively total log log parallel steps 
single divide step generates subproblems allow processor balance 
second benchmark object oriented flavor inspired oo benchmark 
consists assembly hierarchy collection parts 
assembly composite assembly base assembly 
composite assembly contains number assembly components base assembly contains number parts 
assembly part binary information associated large text file image benchmark parts 
traverses assembly hierarchy applies external predicate inspect binary data stored assembly predicate decides assembly bad second phase applies external function adjust parts direct indirect members bad assembly 
data sets merge benchmark generated uniformly distributed interval xm gamma uniformly distributed middle third implies empty testing ability bvram implementation load balance calls sequential merge worse distribution simple merge algorithm non empty possible extend algorithm second divide step applied parallel pair hy guarantee bad cases 
data sets object oriented benchmark chosen follows 
depth assembly hierarchy kept constant order facilitate comparisons different experiments deeper hierarchy require iteration steps 
base assemblies tree leaves depth hierarchy assembly tree perfectly balanced 
flawed assemblies represent assemblies chosen uniformly prefix order assembly tree 
root assembly flawed trivial data set parts need processing second half benchmark 
size binary data associated assembly part constant words 
point graphs represent single run simulator deterministic single data set subsequent runs produced results 
simulator ignores factors communication computation time cost start time system load ran experiment modes 
communication mode simulator counts communication time ignores computation time communication overhead assuming infinite processor speed obtain running time node 
mode useful measuring communication costs 
communication computation mode computation time estimated taken account 
components computation time counted mode 
computation time external functions 
time strictly decreases increases 
second computation time spent preparing communications bvram operators sense time 
tested performance metrics speedup scaleup :10.1.1.104.8594
speedup experiments kept data size constant varied merge length assembly hierarchy benchmark height fan total na assemblies np parts assemblies bad 
scaleup experiments merge varied chose length delta assembly kept depth assembly hierarchy constant varied fan gave total number assemblies na gamma gamma varied shown na na number parts np describe experiment results 
speedup merge reveals nice surprise communication time decreases communications 
increases time control communications log forcing total communication time increase 
time processor send data messages input data size constant total communication cost decreased increased observed increase communication time starts dominated control communications 
course larger data sets increase observing decrease communication costs 
account computation time graph shows speedup 
second graph shows total number words sent 
reinforces observation communication time dominated data communications 
total number words data messages constant input size constant control messages increases gamma broadcast log scan graph shows total number words sent grows slowly constant component significant 
plots graph reveal negative phenomenon implementation logp model 
grows smaller data messages exchanged total number messages grows linearly scaleup experiment communication time increases 
normal cost data communications node remains roughly constant control communications increases 
growth significant long communication phase dominated data messages range 
communi processors running time clock units ideal running time communications computations communications processors parameters total words sent total messages sent maximum message size speedup merge 
cation time starts getting dominated control messages grows sharply 
maximum message size shown stabilizes means point processor sends subsequence processor 
speedup experiment total number words sent increases linearly data messages control messages 
speedup experiment oo benchmark shows behavior speedup experiment merge 
communication time decreases sharply 
larger gap communication time ideal computation time shown scaleup experiment due relatively high cost external methods inspect adjust general applications costly external methods easier speed scale pure relational database applications 
believe issues important 
sequence optimizations database query optimizations performed level query execution plans 
optimizer chooses equivalent execution plans smallest cost 
major components optimizer algebra describing operators physical plans cost model 
algebras sets bags considered context optimizers bvram promising choice sequence optimizer 
equations sets bags operators carry naturally bvram bvram novel operations amenable similar kinds equations 
designing 
processors length length running time clock units ideal running time communications computations communications 
processors length length parameters total words sent total messages sent maximum message size scaleup merge 
processors running time clock units ideal running time communications computations communications processors parameters total bytes sent total messages sent maximum message size speedup oo benchmark 

processors number parts running time clock units ideal running time communications computations communications 
processors number parts parameters total words sent total messages sent maximum message size scaleup oo benchmark 
cost model bvram operations obvious hope bounded nature bvram operators help 
complexities set operations copa special join operation express nested loops 
written complexity join easy problem complexity preserving compilation 
phenomenon occurs operations frequent set oriented query languages nesting 
better way additional set primitives language lower complexities require compiler preserve complexities 
object ids object encapsulation components objects objectoriented object relational database encapsulation methods ability refer object object id pointer 
regarding methods copa addresses extent form external functions 
methods add complexity set methods database may vary dynamically 
object ids allow object sharing object updates 
bvram model logp implementation currently deal features 
implementation database primitives logp model results optimal implementation monotone communications discussing database operations context logp model 
monotone communications specific sequences definition monotone order traditional database operations join nest deal specifically unordered collections require new approach 
study database operations context logp model help lot understanding communication costs parallel database systems 
borodin hopcroft 
routing merging sorting parallel models computation 
jcss 
albert alexandrov mihai klaus schauser chris 
incorporating long messages logp model 
proceedings seventh annual acm symposium parallel algorithms architectures pages 
frances allen michael burke philippe charles ron cytron jeanne ferrante 
overview analysis system multiprocessing 
journal parallel distributed computing 
malcolm atkinson francois bancilhon david dewitt klaus dittrich david maier stanley zdonik 
object oriented database system manifesto 
francois bancilhon claude delobel paris kanellakis editors building object oriented database system 
story morgan kaufmann publishers 
bancilhon briggs khoshafian valduriez 
fad powerful simple database language 
proceedings th international conference large data bases pages 
bar noy shlomo 
designing broadcasting algorithms postal model message passing systems 
proceedings th annual acm symposium parallel algorithms architectures pages 
guy blelloch 
vector models data parallel computing 
mit press cambridge massachusetts 
guy blelloch 
nesl nested data parallel language 
technical report cmu cs carnegie mellon university pittsburgh pa 
guy blelloch 
high cost communication hardware vs software development 
invited talk workshop suggesting computer science agendas high performance computing march 
guy blelloch siddhartha chatterjee 
vcode data parallel intermediate language 
proc 
rd symposium massively parallel computation pages university maryland october 
guy blelloch siddhartha chatterjee 
implementation portable nested data parallel language 
proceedings th acm sigplan symposium principles practice parallel programming pages san diego may 
guy blelloch gary 
compiling collection oriented languages massively parallel computers 
journal parallel distributed computing 
blum floyd pratt rivest tarjan 
time bounds selection 
jcss 
breazu tannen buneman naqvi 
structural recursion query language 
proceedings rd international workshop database programming languages greece pages 
morgan kaufmann august 
available upenn technical report ms cis 
val breazu tannen peter buneman limsoon wong 
naturally embedded query languages 
biskup hull editors lncs proceedings th international conference database theory berlin germany october pages 
springer verlag october 
available upenn technical report ms cis 
buneman libkin suciu tannen wong 
comprehension syntax 
sigmod record march 
peter buneman naqvi val tannen limsoon wong 
principles collection types 
theoretical computer science 
michael carey david dewitt michael franklin nancy hall mark mcauliffe jeffrey naughton daniel schuh marvin solomon tan seth white michael 
persistent applications 
proceedings acm sigmod conference management data minneapolis mn may 
michael carey david dewitt jeffrey naughton 
oo benchmark 
proceedings acm sigmod conference washington may 
cattell editor 
object database standard odmg 
morgan kaufmann san mateo california 
marina chen 
parallel language compilation multiprocessor machines vlsi 
proceedings acm symposium principles programming languages pages 
david culler richard karp david patterson klaus erik schauser santos ramesh thorsten von eicken 
logp realistic model parallel computation 
proceedings fourth acm sigplan symposium principles practice parallel programming ppopp pages san diego california may 
curien 
ae calculus framework environment machines 
technical report ura laboratoire informatique departement de informatique ecole normale superieure rue ulm paris cedex france 
ron cytron jeanne ferrante vivek sarkar 
experiences control dependence 
david gelernter alexandru nicolau david padua editors languages compilers parallel computing pages 
mit press cambridge massachusetts 
deux 
story ieee transactions knowledge data engineering march 
dewitt naughton burger 
gamma high performance dataflow database machine 
proceedings twelfth international conference large data bases pages 
david dewitt jim gray :10.1.1.104.8594
parallel database systems high performance database systems 
communications acm 
digital equipment 
iso ansi working draft database language sql sql august 
leonidas fegaras david maier 
effective calculus object query languages 
proceedings acm sigmod international conference management data pages june 
john feo 
arrays sisal 
mullin michael jenkins robert guang goa editors arrays functional languages parallel systems pages 
kluwer boston 
john feo david 
report sisal langauge project 
journal parallel distributed computing pages 
christian julie 
de la implantation 
des february 
ghandeharizadeh david lin xiaoming zhao 
object placement parallel object oriented database systems 
proceedings tenth international conference data engineering pages february 
goldberg mills prins reif 
specification development parallel algorithms proteus system 
manuscript available www cs unc edu proteus publications html 
stephane grumbach tova milo 
tractable algebras bags 
proceedings th acm symposium principles database systems pages washington may 
carl gunter 
semantics programming languages structures techniques 
foundations computing 
mit press 

programmation fonctionelle une approche 
manuscript august 
christian 
data parallel categorical machine 
parle conference parallel architectures languages europe 
springer verlag 
daniel hillis guy steele 
data parallel algorithms 
communications acm 
joseph 
parallel algorithms 
addison wesley 
gilles kahn 
natural semantics 
proceedings symposium theoretical aspects computer science pages 
springer verlag 
richard karp santos klaus erik schauser 
optimal broadcast summation logp model 
proceedings th acm symposium parallel algorithms architectures pages 
charles koelbel david robert schreiber guy steele jr mary 
high performance fortran handbook 
mit press cambridge massachusetts 
charles lamb gordon landis jack orenstein dan weinreb 
objectstore database system 
communications acm october 
larus 
large grain object oriented data parallel programming language 
proc th int wkshp languages compilers parallel computing pages 
frank thomson leighton 
parallel algorithms architectures arrays trees hypercubes 
morgan kaufmann publishers 
leonid libkin limsoon wong 
conservativity nested relational calculi internal generic functions 
information processing letters march 
see upenn technical report ms cis 
leonid libkin limsoon wong 
properties query languages bags 
beeri atsushi ohori dennis shasha editors proceedings th international workshop database programming languages new york august pages 
springer verlag january 
see upenn technical report ms cis 
leonid libkin limsoon wong 
query languages bags aggregate functions 
jcss 
maclane 
categories working mathematician 
springer verlag berlin 

tpl imp lisp 
technical report school math sciences univ bath 
eugenio moggi 
notions computation monads 
information computation 
mohan pirahesh tang wang 
parallelism relational database systems 
ibm systems journal 
peter lars jan prins john reif robert wagner 
prototyping parallel distributed programs proteus 
proceedings third ieee symposium parallel distributed processing pages december 
jan paredaens dirk van gucht 
converting nested relational algebra expressions flat algebra expressions 
acm transaction database systems march 
parker eric simon patrick valduriez 
svp model capturing sets streams parallelism 
li yan yuan editor proceedings th international conference large databases vancouver august pages san mateo california august 
morgan kaufmann 
plotkin 
structural approach operational semantics 
technical report daimi fn aarhus university 
franco preparata 
new parallel sorting schemas 
ieee transactions computers july 
jan prins daniel palmer 
transforming high level data parallel programs vector operations 
proceedings fourth acm sigplan symposium principles practice parallel programming pages san diego ca may 
acm press 

model architecture independent simd programming 
mit press 
donovan schneider david dewitt 
performance evaluation parallel join algorithms shared multiprocessor environment 
proceedings sigmod conference portland 
stephen 
sisal 
szymanski editor parallel functional languages compilers pages 
addison wesley publishing 
michael dorothy moore 
object relational dbmss wave 
morgan kaufmann san francisco ca 
dan suciu 
parallel programming languages collections 
phd thesis department computer information science university pennsylvania philadelphia pa august 
available university pennsylvania ircs report 
dan suciu val breazu tannen 
query language nc 
proceedings th acm sigact sigmod sigart symposium principles database systems pages minneapolis minnesota may 
dan suciu val tannen 
efficient compilation high level data parallel algorithms 
proceedings th acm sigact sigmod sigart symposium parallel algorithms architectures pages june 
dan suciu val tannen 
query language nc 
journal computer system sciences october 
dan suciu limsoon wong 
forms structural recursion 
georg gottlob moshe vardi editors proceedings fifth international conference database theory number lecture notes computer science pages 
springer verlag january 
thinking machines cambridge massachusetts 
programming guide may 
trinder 
comprehensions query notation 
proceedings rd international workshop database programming languages greece pages 
morgan kaufmann august 
trinder wadler 
list comprehensions relational calculus 
proceedings glasgow workshop functional programming pages scotland august 
tucker mainwaring 
active messages cm 
parallel computing april 
patrick valduriez khoshafian 
parallel evaluation transitive closure database relation 
international journal parallel programming 
leslie valiant 
parallelism comparison problems 
siam journal computing 
philip wadler 
comprehending monads 
proceedings acm conference lisp functional programming nice june 
david watt phil trinder 
theory bulk types 
fide technical report glasgow university glasgow qq scotland july 
limsoon wong 
querying nested collections 
phd thesis department computer information science university pennsylvania philadelphia pa august 
available university pennsylvania ircs report 
limsoon wong 
normal forms conservative extension properties query languages collection types 
jcss 
syntax operational semantics complexities gamma ae ffl ae def ae def size size ae gamma sigma ae ffl ae def ae def size ae gamma dp cp sigma ae ffl sigma ae def ae def size ae variables constants external functions copa formal definition complexities figures contain definitions copa typing rules operational semantics complexities 
external function assume function returns time needed compute sequential time 
assume size computable constant amount time 
proof theorem assume bvram kinds vector registers type type 
step sequence type obtained concatenating values vector registers time get sequence sequences call trace bvram permutation consideration may assume condition holds non input registers initialized second condition enforced extending assignments registers output register 
introduce definition definition potential trace length input output constant sequence properties 

obtained ways deleting elements 
operation 
exists number sequences numbers times mk times syntax operational semantics complexities gamma gamma en gamma en theta theta ae ffl ae ffl en cn ae ffl en hc cn ae en def ae ae en def ae cn size ae gamma theta theta gamma theta thetat ae ffl hc cn ae def ae ae def ae size size ae gamma gamma tn ae ffl ae ffl ae def ae ae def ae size size ae gamma gamma xn gamma en gamma case xn en ae ffl ae ffl ae ffl case xn en ae case def ae ae ae case def ae ae size size ae product types sum types syntax operational semantics complexities gamma gamma gamma ae ffl ae ffl ae ffl ae def ae ae ae def ae ae size size ae gamma gamma ae ffl ae ffl ae def ae ae def ae size size ae abstraction function application syntax operational semantics complexities gamma gamma gamma ae ffl false ae ffl ae def ae ae def ae size size ae ae ffl true ae ffl ae ffl ae ffl ae def ae ae ae ae def ae ae ae size ae note size occur 
theta ae ffl 
gamma ae ffl ae ffl gamma gamma ae ffl chc gamma ae def ae max ae ae gamma ae def ae ae ae gamma size gamma size ae iteration map recursion syntax operational semantics complexities gamma ae ffl ae def ae def size ae gamma gamma ae ffl ae ffl ae def ae ae def ae size size ae gamma gamma gamma ae ffl gamma ae ffl gamma ae ffl gamma gamma ae def ae ae ae def ae ae size gamma size ae gamma gamma flatten ae ffl ae ffl flatten ae flatten def ae ae flatten def ae size size ae gamma gamma length ae ffl gamma ae ffl length ae length def ae ae length def ae size ae gamma gamma get ae ffl ae ffl get ae get def ae ae get def ae size size ae gamma gamma map ae ffl ae ffl gamma gamma ae ffl map gamma gamma ae map def max gamma ae ae map def gamma ae size gamma size ae operational semantics collection operations 
sequences shown sets bags conversions similar 
syntax operational semantics complexities zip theta theta ae ffl gamma ae ffl gamma ae ffl hc hc gamma gamma ae def ae ae ae def ae ae size hc size ae enumerate ae ffl gamma ae ffl enumerate gamma ae enumerate def ae ae enumerate def ae size ae split theta ae ffl gamma gamma ae ffl gamma ae ffl gamma cn gamma gamma gamma gamma ae split def ae ae ae split def ae ae size size ae operations sequences syntax operational semantics complexities gamma gamma ae ffl ae ffl ae def ae ae def ae size size ae gamma gamma ae ffl ae ffl weakening rules particular equal 
length 
prove trace transformed potential trace doubling length 
lemma trace bvram linear complexity 
exists potential trace input output constant proof 
lemma easily proven induction essential note set bvram instructions affect vector registers type restricted due uniformity condition 
append select 
illustrate cases ffl 
translates deleting elements get ffl involved case 
illustration assume registers appear follows operation define times left right ends suffices delete elements groups leave respectively gives note size times larger size 
ffl select 
type type 
essentially delete operation preceded case append 
ffl treated similarly 
follows size constant 
suffices choose gamma sequence type suppose total order defined set fa gamma define ascending subchain length sequence gamma gamma gamma order relation ff fi fl ascending length sequence fi fl ff fi ff fi fl 
ff fi fl 
key lemma 
lemma gamma output potential trace length constant 
assume elements gamma distinct set fa gamma ordered gamma exists ascending sub chain length gamma input potential trace 
proof 
gamma input equals output sequence gamma ascending subchain length induction hypothesis sub chain length gamma gamma dn consider derived case obtained deleting elements ascending subchain subchain certainly gamma case exists number sequences numbers times mk times ascending subchain length dn 
denote subsequence lies inside length length dn 
furthermore ij length subsequence falling copy ij max ij pick corresponding maximal subsequence ij having length concatenating sequences get sub chain length prove length large 
dn see cn length length cn ij max cn schwartz inequality gamma prove theorem follows 
suppose input gamma bvram produce output gamma time 
lemma exists potential trace length gamma input output constant input gamma increasing longer 
get gamma gamma log log log transposition input increasing length get gamma gamma log log log 
