review cocktail party effect barry arons mit media lab ames street cambridge ma media lab mit edu cocktail party effect ability focus listening attention single talker conversations background noise recognized time 
specialized listening ability may characteristics human speech production system auditory system high level perceptual language processing 
investigates literature known effect original technical descriptions current research areas auditory streams spatial display systems 
underlying goal analyze components effect uncover relevant attributes speech production perception chain exploited speech communication systems 
motivation build system simultaneously multiple streams speech information user focus stream easily shift attention 
set speech applications user interfaces take advantage ability computationally simulate cocktail party effect considered 
striking facts ears hear acoustic world voice speaker ct investigates aspects selective attention auditory system conditions listener attend competing messages 
humans adept listening voice midst conversations noise mechanisms process completely understood 
attentional ability colloquially termed cocktail party effect han 
phenomenon viewed ways 
listener point view task intuitive simple 
psychological physiological perspective vast complex array evidence explain effect interactions signal auditory system central nervous system 
acoustically problem akin separating single talker speech spectrogram containing signals speakers noisy conditions 
expert spectrogram reader find task impossible bre 
evidence obtained perceptual experiments performed odd years 
unfortunately perceptual evidence quantifiable example physical resonances vocal tract 
bulk ideas experimental results qualitative exact solution cocktail party problem 
focus voice signals speech communication note low level perceptual evidence experiments simple stimuli clicks pure tones noise 
separation speech channels cocktail party effect analyzed related different problems 
primary problem interest traditionally recognition humans segregate speech sounds possible build machine task 
cues signal important separating voice conversations background noise 
machine cues task acoustical evidence humans efficient detecting 
inverse problem synthesis cues enhance listener ability separate voice interactive speech system 
user interface may desirable multiple digitized speech recordings simultaneously providing browsing capabilities circumventing time bottleneck inherent speech communication serial nature audio aro sa 
synthesis perceptual cues machine human listeners allow application perceptually nudge user making easier attend particular voice suggest new voice come focus 
early early area traced problems faced air traffic controllers early 
time controllers received messages pilots loudspeakers control tower 
hearing intermixed voices pilots single loudspeaker controller task difficult ks 
recognition speech ears cherry reported objective experiments performed mit recognition messages received ears che 
appears technical directly addresses author termed cocktail party problem 
cherry proposed factors may ease task designing filter separate voices 
voices come different directions 
lip reading gestures 
different speaking voices mean pitches mean speeds male vs female forth 
different accents 
transition probabilities subject matter voice dynamics syntax 
factors removed recording messages talker magnetic tape 
author stated result babel messages may separated 
analysis cherry suggested humans vast memory transition probabilities easy predict word sequences sw 
series experiments performed involved shadowing recordings subject repeated words hearing tape recording 
contents recordings related style selecting adjacent paragraphs book 
recognition phrases subjects task difficult recordings repeated unlimited number times 
cases long phrases words incorrectly identified errors typically syntactically correct 
slight variant setup subject allowed notes pencil 
long term memory aid task easier time required perform task shortened messages entirely separated subject 
similar experiment spoken phrases composed strings strung simple conjunctions pronouns artificially constructed highly probable phrases nearly impossible separate 
transition probabilities phrases low subject select phrases equally speech streams 
subjects listened different spoken messages ear headphones 
configuration directionality simply signal 
subjects difficulty listening message played ear rejecting sounds ear 
recognition process easily switched ear 
subject readily shadow message listening slight delay 
norman states longer lag greater advantage taken structure language 
note subject voice usually monotonic typically little idea content message attended ear 
virtually recalled message content rejected ear sounds occurring 
called say phenomenon 
listening asks question reaction say uh say 
question repeated memory 
experiment tried laboratory results agreed intuitions temporary memory items attending cherry james point long term memory 
page follow experiments language signal rejected ear switched german english speaker subjects notice change 
changes male female speaker usually identified change pure tone identified 
reversed speech tape played backwards having spectrum original signal semantic content identified having listeners thought normal speech 
summary broad statistical properties signal rejected ear recognized details language individual words semantic content unnoticed 
texts generated speeches reported newspapers 
example am happy today talk man street 
time come beating bush brink ruin welfare workers great majority people 
interesting variant studies recording played ears variable delay ears 
experiment proceed subject shadowing recording 
time delay slowly decreased point recordings seconds subject ear getting thing 
nearly subjects reported point recognized words phrases rejected ear attended ear 
note result surprising light previous tests subjects unable identify single word rejected ear 
switching message periodically ears time interval needed transfer attention ears determined 
subjects interval ms study investigates detail defining average word recognition delay ct 
note represents entire complex hearing process just sensory system 
responding simultaneous messages navy electronics laboratory san diego performed series experiments investigating responses presentation simultaneous messages 
goal set experiments find conditions communication operator best recognize attend speech message simultaneously irrelevant message 
communication messages provide visual cues aid identification sender perception message 
redundancy message high competing messages similar form content vocabulary 
configurations tried messages horizontally separated loudspeakers 
loudspeakers gamma ffi ffi ffi azimuth increased channel identification scores single loudspeaker ffi azimuth larger separation gamma ffi ffi ffi azimuth improved scores variants experiment performed added visual cues low pass filtering messages increased horizontal separation reliably improved scores 
messages high low pass filtered khz improved operator ability answer correct message identify channel 
note filtering significantly decrease intelligibility messages 
high low pass messages easier attend separated unfiltered message 
relates phenomenon cherry transition probabilities suggests possibility increases element element predictability competing messages decreases predictability element stream succeeding element stream stream easier listen 
note fundamental theme studies 
authors propose narrowing frequency bands increasing separation improve ability listen stream 
limited point bandwidth narrow frequency extreme intelligibility individual messages impaired 
separation aids time filtering spatial separation correct identification scores particular task conditions increased 
scores usually improved respect single aid effect fully additive 
authors hypothesize reason effects additive general ease tasks difficult achieve score 
responding simultaneous messages related study webster thomas investigated responding overlapping messages wt 
previous experiment correct identifications sequential messages loudspeakers 
having facility ability manually switch audio particular loudspeaker near field loudspeaker gave considerably better results 
louder simultaneous messages heard correctly 
note having multiple loudspeakers improve results necessary attend competing simultaneous messages 
ability rapidly shift attention multiple loudspeakers help information rate high 
worst conditions simultaneous messages information received results greater total information intake unit time messages occurred sequentially 
selective listening speech broadbent summarized early including experiments variety researchers bro 
experimentally established time probability listener correctly hearing word varies probability word occurring particular context 
example hearing word bread subsequent occurrence butter knife eraser 
shown word heard correctly listener knew alternatives compared small number 
performance selective listeners vary information defined communication theory amount physical stimulation 
broadbent concludes webster experiments messages containing little information dealt simultaneously high information content may 
notes statement tasks depends meant task 
pointed spatial separation helpful situations similar task listener ignoring channel responding spatial effect important listener dealing channels simultaneously 
note time shift attention increased messages come different directions may cancel advantages spatial separation 
broadbent summarizes main selective listening experiments 
central nervous system factors sensory factors involved message selection 

effects vary information content messages 

information discarded discarded random 
information irrelevant better come different place different loudness different frequency characteristics eye ear 
material discarded little advantage sensory channels presenting information 
binaural ability detect signal background masking signal greatly improved ears 
ideal conditions detection threshold binaural listening exceed monaural listening db dc 
consider example control condition signal noise played single ear 
signal played simultaneously ears phase noise ear shifted ffi respect ear db improvement detectability signal 
improvement control condition called binaural masking level difference mld 
noise played ears signal ears ffi phase db 
cocktail party effect partly explained 
listening desired signal coming direction effectively masked noise originates different direction bla 
technique exploited fighter pilots help separate speech signals high noise level cockpit 
headphones simply wired signal ear ffi phase signal ear 
auditory scene analysis great variety research relating perceptual grouping auditory stimuli streams performed summarized bregman bre 
book bregman talks perceptual audition relate vision friend voice perceived timbre quiet room cocktail party 
party set frequency components arising voice mixed listener ear frequency components sources 
total spectrum energy reaches ear may significantly different different environments 
recognize unique timbre voice isolate frequency components responsible time 
wrong choice frequency components change perceived timbre voice 
fact usually recognize timbre implies regularly choose right components different contexts 
just visual timbre constancy explained terms complicated analysis brain merely terms simple registration input brain 
practical reasons trying understand constancy 
engineers currently trying design computers understand person saying 
noisy environment speaker voice comes mixed sounds 
naive computer different sound voice comes mixed sound different words spoken spoken different person 
machine correct particular listening conditions human 
study human audition able lay bare principles govern human skill hope computer designed mimic 
bre page scene analysis audition concerned perceptual questions deciding sound sources characteristics source source located han 
baby example imitates mother voice insert occurred simultaneously mother speech 
baby rejects part perceptual object formed mother voice infant solved scene analysis problem audition 
bregman states problem different way 
convenient able hand spectrogram machine equivalent set coloring color regions spectrogram came source 
auditory scene analysis 
sounds acoustic events created physical things happen 
perceptual unit represents single happening called auditory stream 
series footsteps example represent individual sounds usually experienced single perceptual event 
streams way putting sensory information 
properties far lion assigned auditory stream near fire assigned different stream probably behave differently distance percepts reversed bre han 
ideas auditory scene analysis traced back visual done early han 
visual auditory events combined coherent perceptual objects 
elements belonging stream maximally similar predictable elements belonging different streams maximally dissimilar 
gestalt psychologists organizational principles visual field include similarity elements similar physical attributes tend grouped proximity elements close space time tend grouped continuity elements appear follow direction tend grouped common fate elements appear move tend grouped symmetry closure elements form symmetrical enclosed objects tend grouped perspective expect acoustic events grouped perceptual stream similar frequency timbre intensity spatial temporal proximity follow temporal trajectory terms frequency intensity position rhythm primitive segregation focus bregman primitive unlearned stream segregation 
sections qualitatively summarize bregman findings relevant cocktail party effect 
ideas general attributes auditory scene analysis move emphasize perception speech streams 
grouping processes 
classes grouping processes broadly classified simultaneous integration sequential integration called spectral grouping temporal grouping 
figures visually illustrate types groupings circles represent sounds particular frequency 
bre segregation stronger frequency separation high low tones greater 
similarly segregation greater increase speed 
tones tightly packed visual representation auditory stimuli 
spatial location 
primitive scene analysis groups sounds coming location sounds originate different locations 
cherry showed person job segregating sounds monaural recordings 
spatial cues strongest combined auditory cues spatial evidence just cue complex scene analysis system 
note reflections room body significantly alter received acoustical signals 
engineers working automatic segregation concurrent sounds spatial separation uniquely powerful way determining sounds come physical event usually talker 
humans spatial origin assign overwhelming role 
quite segregating stream sound coming single point space example single loudspeaker 
bre page spatial continuity 
sound sources talkers listeners don move far fast 
experiments shown spatial discontinuities break streams spatial important holding streams 
loudness differences 
differences loudness may cause segregation spatial location cues may strengthen stream segregation evidence 
continuity 
sounds hold single stream better discontinuous sounds 
continuity fundamental frequency temporal proximity shape spectra intensity spatial origin 
sound instant sound ends spectra incoming sensory data change suddenly conclude sound started stopped 
complicated spectrum example may simpler spectrum embedded heard earlier 
simpler spectrum may adjacent complicated spectrum discontinuity 
reasonable consider part spectrum matches earlier continuation treat portion resulting addition new sound mixture 
visual channel effects 
tend perceive sounds coming locations visual events 
think illusion watching television movie actor voice appears emanating mouth regardless loudspeaker located 
example interrelationship grouping sounds influence grouping visual events synchronized vice versa tendency experience sound coming location visual events occurring temporal pattern called effect interpreted way visual evidence location event supplement unclear auditory evidence 
direction influence just vision audition reverse direction 
bre page interpretation auditory spatial cues strongly influenced perceived visual orientation 
correctly highest level spatial representation involves integration information different senses 
moo page history 
stream analysis processes history adjust momentary spatial estimates 
fact sounds objects tend move slowly space time cause coherent structure 
segregation time constant 
takes seconds build segregate stream seconds go away sequence stops 
long time constant probably prevents auditory system oscillating ambiguous conditions 
sudden change properties signal reset streaming mechanism quickly silence 
harmonics frequency modulation 
perceived pitch complex tone depends estimate fundamental frequency set harmonics tone fundamental missing 
scene analysis mechanisms favor grouping harmonics fundamental 
fundamentals account harmonics conclude sound sources 
pitch rises fundamental frequency go harmonics go proportion 
plausible believe correlated change detected tell changing partials came voice 
auditory system group correlated changes hear changing sound 
evidence suggest types frequency change modulation purpose 
tiny fluctuations pitch human voices occur speakers think holding steady pitch type frequency modulation slow kind occurs voluntarily vary pitch voice smooth way example raise pitch question synchronization slow modulation different parts spectrum cause parts treated parts single sound 
bre page weighting evidence 
collaboration competition features stream segregation decision 
number factors favor particular grouping sounds large grouping strong sounds heard part stream 
schema segregation segregation learned involves attention considered higher level central processing 
consciously listened part schema 
recall findings earlier studies limited number things attended simultaneously limitation ability process schemas 
primitive segregation symmetrical 
separates sounds frequency location attend high tones low tones left right equally 
schema recognition symmetrical 
name mixed sounds may easy recognize mixture easier identify elements sound 
example schema reasoning involves simultaneous presentation synthetic vowels 
vowels produced fundamental start time came spatial location 
primitive preattentive clustering theories suggest complex sounds fused single stream 
higher level schema distinguish vowels mixture 
bregman suspects schema vowel picking needs total spectrum requiring partitioning done primitive processes 
evidence scene segregated primitive processes schemas 
example formant speech sound synthesized formant constructed harmonics related different fundamental 
listeners hear sounds corresponding related group harmonics time perceive single speech sound formed complete set harmonics 
speech recognition schemas combine evidence segregated primitive process 
speech scene analysis addition grouping processes mentioned additional extensions ideas specific analysis speech signals 
note difficult separate primitive processes schema speech schemas tend obscure contributions primitive processes 
considering primitive segregation rules somewhat surprising voices hold 
speech consists sequences low frequency complex tones vowels intermixed high frequency noise fricatives 
production rate roughly phonemes sec speech break streams alternating high low tones 
listeners able understand repeat rapid sequence speech able report order short unrelated sounds buzz played sequence played slower rate corresponding phonemes 
warren argues listeners cycle unrelated events decompose signal constituent parts recognize part construct mental representation sequence 
listeners speech go process global analysis speech event match stored representation holistic pattern 
warren continues children recognize word idea break constituent phonemes 
bre page pitch trajectory 
general pitch speaker voice changes slowly follows melodies part grammar meaning particular language 
listeners constraints follow voice time 
shadowing experiments interesting results shown 
target sound rejected sound suddenly switched ears subjects prevent attention passage ear shadowing 
author original research argued tracking voices mixtures governed meaning content message 
secondly pitch contour switched ears subjects repeated words rejected ear semantic content follow 
continuity pitch contour degree controlling subject attention 
spectral continuity 
vocal tract instantaneously move articulatory position formants successive sounds tend continuous 
features provide spectral continuity utterances 
fundamental formant frequencies important keeping speech signals integrated single stream 
pitch segregation 
harder separate spoken stories pitch bn 
digitally re synthesizing speech lpc analysis possible hold pitch utterance perfectly constant 
fundamentals passages separated frequency number errors decreased reported zero semitones separation hears single auditory stream garbled speech sounds half semitone clearly hears voices possible switch attention 
note fundamental hz half semitone octave corresponds factor frequency 
experiment fundamental pitch difference hz synthesized syllable virtually subjects reported voices heard 
difference hz voice reported 
harmonics 
log scale speech harmonics move parallel pitch utterance changes 
harmonics maintain relationship probably perceived related sound source 
evidence supports idea changing harmonics help trace spectral envelope formant frequencies speech 
adjacent harmonic peaks connected spectral envelope 
analyzing movement peaks fundamental changes possible unambiguously define formant envelope 
automatically recognizing streams focuses attributes cocktail party effect enhancing user interfaces speech information user worth considering recognition problem briefly 
generally difficult find tractable accurate computational solutions recognition problems humans find simple speech image comprehension 
want understand segregation speech sounds sounds practical theoretical reasons 
example current computer programs recognize human speech seriously disrupted speech nonspeech sounds mixed speech recognized 
attempts evidence partitioning process modeled human auditory system 
approach infancy implemented heuristics described earlier chapters book met limited success 
bre page note increase error rate signals exactly octave apart 
researchers bell labs reported signal processing system separating speech signal originating known location background sounds 
system array microphones simple computational elements achieve db noise suppression 
scheme somewhat impractical source remain exactly centered microphone array 
proposed ultrasonic transmitter carried system track speaker 
beam forming signal seeking microphone arrays appears promising effort geared teleconferencing environments 
microphones possible reject interfering speech arriving non preferred directions lm bregman discusses systems primarily tracking fundamentals computationally separating speakers see zis 
scheme somewhat impractical speech sounds voiced fundamental frequency difficult track number speakers increases 
weintraub improvements speech recognition accuracy separating stronger voice weaker wei 
keep mind speech segregation task performed humans part knowledge transition probabilities words particular context 
technique feasible limited domain tasks computationally tractable large domains near 
stream segregation synthesis surge area real time dimensional auditory display systems coh 
activity partially motivated availability inexpensive digital signal processing hardware great interest virtual environments teleoperator systems 
contributing factor advances understanding human spatial hearing computational ability synthesize head related transfer functions directionally sensitive models head body transfer functions bla 
systems usually rely stereo headphones synthesize sounds localized outside head 
fundamental idea binaural simulators addition creating realistic cues reflections amplitude differences computational model person specific hrtf simulates audio world 
multiple sound sources example placed virtual locations allowing user move simulated acoustical environment 
user translate rotate tilt head receive auditory cues physical sound source 
systems provide compelling realistic experience may basis new generation advanced interfaces 
current research focuses improving system latency time required create user specific hrtf models modeling room acoustics 
different approach synthesis auditory streams developed integrated media architecture laboratory bellcore context multimedia teleconferencing system lpc 
audio windowing system primarily uses shelf music processing equipment synthesize enhance primitive segregation features mentioned previous sections 
filters pitch harmonic distortions create peer hierarchical relationships spoken channels 
rock roll effects may extreme description discusses just noticeable effects barely edge cl 
similar effects highlighting pieces audio draw attention 
unfortunately combination auditory effects needed generate relations appears chosen somewhat ad hoc manner formal perceptual studies performed 
important begun stimulate awareness telecommunications research communities regarding feasibility simultaneously presenting multiple streams speech structured manner 
application areas variety applications benefit synthetic segregation system multi party audio teleconferencing 
conferencing systems limitations number participants speak simultaneously usually difficult identify speaker 
video added conferencing environment possible add spatial audio cues help disambiguate speakers 
example theta video mosaic audio person upper right hand quadrant localized corresponding spatial location 
system stream segregation effects enhance voice speaker floor instant 
emerging application area speech hypermedia aro 
context speech provides navigational input hypermedia database linked network voice recordings 
desirable multiple streams audio information simultaneously easily done graphics system circumvent linear single channel nature speech signals 
techniques described may possible enhance primary speech signal remains auditory focus compared secondary background channels played parallel 
goal keep speech signals identifiable differentiable user shift attention various sound streams 
allow new type speech navigation ability move overheard conversations 
final area interest speech handheld computer environment 
hypermedia system limitation small computer tiny non existent keyboard display navigating information spaces 
spatial perceptual streaming cues help presenting high bandwidth information user displaying multiple streams audio information simultaneously 
intent perceptual ideas applications help de clutter acoustic space user interface 
incorporation techniques new problems challenges 
user shifts attention background stream communicated computer 
full spatial audio system head movements head gestures glancing nod direction desired stream 
speech recognition provide input system may obtrusive application environments 
spatial cues user world centered coordinate system 
probably depends application 
summary percepts cocktail party problem complex intertwined simple closed form solution practical embed speech user interfaces 
brings relevant information variety sources summarizes large body 
brief summary components effect may prove useful building interactive speech communication applications ffl provide spatial continuity channels ffl provide spatial disparity channels ffl associate visual images audio streams ffl provide continuity ffl enhance voices ffl filter streams separate frequency bands ffl different voices synthetic recorded ffl pitch shift voices away ffl information simultaneously ffl provide mechanism pull voice focus ffl provide time user fully fuse streams determined perceptual evidence relating cues combined brain 
research performed determine relevant weightings effects different environments cues synergistically 
unclear useful information background channels gleaned attending particular foreground channel 
shown users shift attention particular interest applications providing cues suggest time scan channels 
higher level way summarize ideas provide continuity stream possible making differentiable streams practical adding effects distracting 
kenneth stevens lisa stifelman provided comments earlier drafts 
sponsored apple computer sun microsystems 
aro arons 
navigating speech hypermedia 
hypertext pages 
acm 
bla 
spatial hearing psychophysics human sound localization 
mit press 
bn 
intonation perceptual separation simultaneous voices 
journal phonetics 
bre bregman 
auditory scene analysis perceptual organization sound 
mit press 
bro broadbent 
perception communication 
press 
che cherry 
experiments recognition speech ears 
journal acoustic society america 
cl cohen ludwig 
multidimensional window management 
international journal man machine systems 
coh cohen 
technologies dimensional sound presentation issues subjective evaluation spatial image 
audio engineering society th convention 
preprint number 
ct cherry taylor 
experiments recognition speech ears 
journal acoustic society america 
dc durlach 
binaural phenomena 
friedman editors hearing volume iv handbook perception chapter 
academic press 
flanagan berkley 
microphone systems 
preprint invited special issue honoring professor 
han handel 
listening perception auditory events 
mit press 
ks sorkin 
human factors understanding people system relationships 
john wiley sons 
lm liang malik 
reducing cocktail party noise adaptive array filtering 
proceedings international conference acoustics speech signal processing pages 
ieee 
lpc ludwig cohen 
extending notion window system audio 
ieee computer august 
moo moore 
psychology hearing 
academic press edition 
mitchell ross yates 
signal processing cocktail party effect 
journal acoustic society america 
norman 
memory attention 
john wiley sons 
sa schmandt arons 
desktop audio 
unix review october 
curtis webster 
responding simultaneous messages 
journal acoustic society america may 
sw shannon weaver 
mathematical theory communication 
university illinois press 
wei weintraub 
computational model separating simultaneous talkers 
proceedings international conference acoustics speech signal processing pages 
ieee 
wt webster thompson 
responding overlapping messages 
journal acoustic society america may 
wenzel foster 
virtual display system conveying dimensional acoustic information 
proceedings human factors society nd annual meeting pages 
zis 
channel talker interference suppression 
phd thesis massachusetts institute technology 
barry arons doctoral candidate speech research group massachusetts institute technology media laboratory 
research interests include highly interactive systems emphasis conversational voice communication 
leader desktop audio project primary architect audio server olivetti research california member technical staff hewlett packard laboratories 
holds bs civil engineering mit ms architecture machine group mit designed phone slave conversational desktop 
