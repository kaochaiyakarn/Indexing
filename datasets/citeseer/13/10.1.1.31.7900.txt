centroid document classification analysis experimental results hong sam han george karypis university minnesota department computer science army hpc research center minneapolis mn cs umn edu 
simple linear time centroid document classification algorithm despite simplicity robust performance extensively studied analyzed 
experiments show centroid classifier consistently substantially outperforms algorithms naive bayesian nearest neighbors wide range datasets 
analysis shows similarity measure scheme allows classify new document closely behavior matches behavior documents belonging different classes 
matching allows dynamically adjust classes different densities accounts dependencies terms different classes 
seen tremendous growth volume online text documents available internet digital libraries news sources wide intranets 
forecasted documents unstructured data predominant data type stored online 
automatic text categorization task assigning text documents pre specified classes topics themes documents important task help people find information huge resources :10.1.1.33.4944:10.1.1.11.9519:10.1.1.11.6124
text categorization presents unique challenges due large number attributes data set large number training samples attribute dependency multi modality categories 
led development variety text categorization algorithms address challenges varying degrees :10.1.1.42.7488:10.1.1.11.9519:10.1.1.11.6124
simple centroid document classification algorithm 
algorithm centroid vector computed represent documents class new document assigned class corresponds similar centroid vector measured cosine function 
extensive experiments section show centroid classifier consistently substantially outperforms algorithms naive bayesian nearest neighbors supported nsf ccr army research office contract da daag doe asci program army high performance computing research center contract number daah :10.1.1.11.9519
access computing facilities provided minnesota supercomputer institute 
related papers available www url www cs umn edu karypis wide range datasets 
analysis shows similarity measure centroid scheme allows classify new document closely behavior matches behavior documents belonging different classes 
matching allows dynamically adjust classes different densities accounts dependencies terms different classes 
believe feature reason consistently outperforms classifiers take account density differences dependencies 
reminder organized follows 
section experimentally evaluates algorithm variety data sets 
section analyzes classification model centroid classifier compares algorithms 
section provides directions research 
centroid document classifier centroid classification algorithm documents represented vector space model 
model document considered vector term space 
simplest form document represented tf vector tf tf tf tf tf frequency ith term document 
widely refinement model weight term inverse document frequency idf document collection 
commonly done multiplying frequency term log df total number documents collection df number documents contain ith term document frequency 
leads tf idf representation document tfidf tf log df tf log df tf log df 
order account documents different lengths length document vector normalized unit length kd tfidf 
rest assume vector representation document weighted tf idf normalized unit length 
vector space model similarity documents commonly measured cosine function cos delta kd kd delta denotes dot product vectors 
document vectors unit length formula simplifies cos delta set documents corresponding vector representations define centroid vector jsj vector obtained averaging weights various terms documents refer supporting set centroid analogously documents similarity document centroid vector computed cosine measure follows cos delta kck delta kck note document vectors length centroid vectors necessarily unit length 
idea centroid classification algorithm extremely simple 
set documents belonging class compute centroid vectors 
classes training set leads centroid vectors fc ck centroid ith class 
class new document determined follows 
document frequencies various terms computed training set compute tf idf weighted vector space representation scale unit length 
compute similarity centroids cosine measure 
similarities assign class corresponding similar centroid 
class arg max cos computational complexity learning phase centroid classifier linear number documents number terms training set 
computation vector space representation documents easily computed performing passes training set 
similarly centroids computed single pass training set centroid computed averaging documents corresponding class 
amount time required classify new document km number terms computational complexity algorithm low identical fast document classifiers naive bayesian 
experimental results evaluated performance centroid classifier comparing naive bayesian nearest neighbor classifiers variety document collections 
obtained naive bayesian results rainbow multinomial event model 
results obtained locally modified version algorithm capable handling sparse data sets 
nearest neighbor results obtained tf idf vector space representation documents identical centroid classification algorithm number neighbors 
document collections classification algorithms data sets west group trec trec trec collections reuters text categorization test collection distribution ohsumed collection webace project wap :10.1.1.50.8204
detailed characteristics various document collections experiments available note data sets list remove common words words stemmed porter suffix stripping algorithm 
furthermore selected documents document class label 
words set classes collected documents class set 
classification performance classification accuracy various algorithms different data sets experimental testbed shown table 
results correspond average classification accuracies experiments 
experiment documents randomly selected training set remaining test set 
rows table show results naive bayesian nearest neighbor schemes row shows results achieved classification algorithm denoted cntr table 
data sets boldface font highlight algorithm achieved highest classification accuracy 
table 
classification accuracy achieved different classification algorithms 
west west west oh oh oh oh re re tr tr tr nb knn cntr tr tr tr tr la la la fbis wap new nb knn cntr looking results table see naive bayesian outperforms schemes data sets better centroid scheme better nearest neighbor algorithm outperforms schemes 
accurate comparison different schemes obtained looking extent performance particular scheme statistically different scheme 
resampled paired test compare accuracy results obtained different classifiers 
statistical significance results resampled paired test summarized table pair classification algorithms shows number data sets performs statistically better data sets available www cs umn edu han data tar gz 
worse similarly 
looking table see scheme compared naive bayesian better data sets worse data set statistically similar twelve data sets 
similarly compared knn better statistically similar data sets 
compared centroid scheme better eighteen worse statistically similar data sets 
table 
statistical comparison different classification algorithms resampled paired test 
entries table show number data sets classifier row performs better worse similarly classifier column 
nb knn cntr nb knn results see simple centroid classification algorithm outperforms remaining schemes naive bayesian second nearest neighbor third 
note better performance nb knn decision tree classification algorithms agrees results reported precision recall binary classification :10.1.1.50.8204:10.1.1.11.9519
support vector machines svm shown effective text classification :10.1.1.11.6124
able directly compare centroid scheme svm svm code written binary classification :10.1.1.11.6124
plan perform comparison studies svm centroid scheme performing binary classification 
analysis classification model surprisingly performance centroid classification scheme suggests employs sound underlying classification model 
goal section understand classification model compare schemes 
order understand model need understand formula determine similarity document centroid vector particular class equation computation essential determining class equation 
equation see similarity cosine ratio dot product divided length set documents create equation delta delta jsj jsj delta jsj cos dot product average similarity measured cosine function new document documents set 
meaning length centroid vector easily understood fact kck delta equation kck jsj delta jsj jsj cos length centroid vector square root average pairwise similarity documents support centroid 
summary classification model centroid document assigns test document class documents better match behavior test document measured average document similarities 
computes average similarity test document documents class amplifies similarity similar documents class 
average pairwise similarity documents class small class loose amplification higher average pairwise similarity high class tight amplification smaller 
detailed 
comparison classifiers advantages centroid scheme summarizes characteristics class form centroid vector 
similar summarization performed naive bayesian form class term probability distribution functions 
advantage summarization performed centroid vectors combines multiple prevalent features features simultaneously single document 
look prominent dimensions centroid vector highest weight terms correspond terms appear frequently documents class necessarily set documents 
particularly important high dimensional data sets coverage individual feature quite low 
case documents summarization additional benefit addressing issues related synonyms commonly synonyms represented centroid vector see centroid vectors data sets experiments 
reasons centroid classification algorithm naive bayesian tend perform better nearest neighbor classification algorithms 
better performance centroid scheme naive bayesian classifier due method compute similarity test document class 
case naive bayesian done bayes rule assuming conditioned class occurrence different terms independent 
far true real document collections :10.1.1.11.8264
existence positive negative dependence terms particular class causes naive bayesian compute distorted estimate probability particular document belongs class 
hand similarity function centroid scheme account term dependence class 
discussion section know similarity new document particular class computed ratio quantities 
average similarity documents class second square root average similarity documents class 
large extent quantity similar character probability estimate naive bayesian algorithm suffers similar estimation problems case term dependence 
second quantity similarity function square root average similarity documents class account term dependency 
average similarity depends degree terms occur different documents 
general average similarity documents class high documents high degree term occurrence similarity pair documents computed cosine function high documents similar set terms 
hand average similarity documents decreases degree term occurrence decreases 
average internal similarity amplify similarity test document class amplification minimal large degree positive dependence terms class increases positive dependence decreases 
consequently amplification acts correction parameter account estimation similarity computed quantity document centroid similarity function 
believe feature centroid classification scheme reason outperforms naive bayesian classifier experiments shown section 
discussion concluding remarks focused simple linear time centroid document classification algorithm 
experimental evaluation shown centroid classifier consistently substantially outperforms classifiers wide range data sets 
shown power classifier due function uses compute similarity test document centroid vector class 
similarity function account term similarity test document documents class dependencies terms documents 
ways improve performance centroid classification algorithm 
current form suited handle multimodal classes 
support multi modality easily incorporated clustering algorithm partition documents class multiple subsets potentially corresponding different mode similar techniques generalized instance set classifier 
second classification performance improved techniques adjust importance different features supervised setting 
variety techniques de veloped context nearest neighbor classification extended centroid classifier 

baker mccallum 
distributional clustering words text classification 
sigir 

boley gini gross han hastings karypis kumar mobasher moore 
document categorization query generation world wide web webace 
ai review accepted publication 

cohen 
fast effective rule induction 
proc 
twelfth international conference machine learning 

cohen hirsh 
joins generalize text classification whirl 
proc 
fourth int conference knowledge discovery data mining 

curran thompson 
automatic categorization documents 
proc 
th asis sig cr classification research workshop tucson arizona 

han karypis 
centroid document classification algorithms analysis experimental results 
technical report tr department computer science university minnesota minneapolis 
available www url www cs umn edu karypis 

hersh buckley leone 
ohsumed interactive retrieval evaluation new large test collection research 
sigir pages 

joachims 
text categorization support vector machines learning relevant features 
proc 
european conference machine learning 

wai lam chao yang ho 
generalized instance set automatic text categorization 
sigir 

lewis 
naive bayes independence assumption information retrieval 
tenth european conference machine learning 

lewis 
reuters text categorization test collection distribution 
www research att com lewis 

mccallum nigam 
comparison event models naive bayes text classification 
aaai workshop learning text categorization 

andrew mccallum 
bow toolkit statistical language modeling text retrieval classification clustering 
www cs cmu edu mccallum bow 

porter 
algorithm suffix stripping 
program 

ross quinlan 
programs machine learning 
morgan kaufmann san mateo ca 

salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley 

shankar karypis 
feature weight adjustment algorithm document classification 
sigkdd workshop text mining boston ma 

trec 
text retrieval conference 
trec nist gov 
wettschereck aha mohri 
review empirical evaluation methods class lazy learning algorithms 
ai review 

yang liu 
re examination text categorization methods 
sigir 
