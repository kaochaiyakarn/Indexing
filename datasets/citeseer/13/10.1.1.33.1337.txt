scaling law validation set training set size ratio isabelle guyon bell laboratories berkeley california isabelle research att com address problem determining fraction training set reserved development test set validation set 
determine ratio validation set size training set size scales square root complexity parameters complexity second level inference minimizing validation error complexity level inference minimizing error rate training set 
keywords cross validation learning theory statistics machine learning pattern recognition training set validation set test set experiment design 
problem arises organizing benchmarks pattern recognition determine size test set give statistically significant results 
companion tackled problem point view benchmark organizer corpus available data data reserved benchmark test set 
tackle problem point view benchmark participants 
benchmark participants access benchmark test set final test 
development period common practice benchmark participants reserve part training data test compare various systems 
subset training data usually called development test set validation set 
problem address data reserved validation set 
optimum tradeoff having data train data validate 
cross validation method model selection widely studied criticized 
foundational papers include contributions include 
emphasis exhibiting simple general scaling law guide pattern recognition ratio validation set size training set size scales square root complexity second level inference minimizing validation error complexity level inference minimizing error rate training set 
result easy remember require refering complicated formula worse abacus 
contain parameters impossible calculate shall explain empirically obtain complexity parameters 
simplifying hypotheses large number examples small error rates discuss solution altered alternative hypotheses 
hypotheses include assumptions nature target function noise level nature structure hypothesis space learning algorithm 
problem determining size benchmark test set solved classical statistics 
contrast problem determining size validation set involves complexity learning process theory uniform convergence 
derivation method follows similar lines bound probability error recognizer selected cross validation classical bounds vc bounds optimize resulting bound training validation split 
similarly exhibit tradeoff terms balance decides optimum 
spite similarity method difference set hypotheses definition tradeoff terms yield different framework describe problem different solution 
authors seek best training validation split specific problem preventing overtraining neural networks 
find fraction patterns reserved validation set inversely proportional square root number free adjustable parameters 
result generalizes confirms result 
problem statement notations call total size training database 
call fraction training development period referred training set 
call gamma remaining fraction validation set 
adopt learning statement proposed training test set patterns drawn randomly independently source patterns fixed unknown probability distribution 
patterns labeled class categories fixed unknown probability distribution jx 
training recognizer mean selecting family recognizers recognizer gives smallest number errors training set 
family recognizer characterized complexity may may related vc dimension description length number adjustable parameters measures complexity 
consider recognizer trained examples 
call probability error patterns distributed similarly training validation test patterns 
call empirical error rate calculated ft examples validation set 
call opt true best recognizer recognizer having smallest probability error opt recognizers trained examples 
call val recognizer selected cross validation see 
adopt statement cross validation proposed cross validation consists identifying families recognizers family val recognizer val smallest number errors ft examples validation set recognizers trained remaining gt examples ii training new recognizer examples training set plus validation set family val step ii statement omitted important implications derivation sense practical standpoint benchmark participants 
note opt fixed training data val function training validation split 
notation elliptic precise val 
omit notation simplicity want emphasize dashed curve learning curve val gamma learning curve val gamma 
testing consists calculating number errors independent test set distinct training set validation set 
lift remaining ambiguity refer set benchmark test set 
error rates opt val opt val val val opt val opt opt error rates opt val opt val opt val val opt opt val 
learning curves 
recognizer val recognizer chosen cross validation gt training examples gamma validation examples 
smallest error rate validation set point circled dashed line 
recognizer opt smallest probability error trained examples point circled full line 
want avoid situation val gt opt gt val opt 
arise limit case small validation set large empirical error rates close mathematical expectations val val opt opt learning curves may cross possible val opt val opt 
learning curve term dominates 
large validation set small val opt estimated precision empirical values 
possible val opt val opt 
uncertainty term dominates 
result proof sketch going show ratio optimum number examples reserved validation corresponding number examples reserved training proportional square root ratio complexity parameters logarithm number families recognizers considered ln largest complexity parameter families max denominator hmax complexity level inference selecting recognizer smallest training error 
numerator ln complexity second level inference consisting choosing recognizers trained level smallest validation error 
reach result shall number simplifying hypotheses including size training database large error rate small 
discussion hypotheses reported section 
obtain want minimize difference performance recognizer val selected cross validation recognizer opt want minimize val gamma opt 
rewrite difference sum terms term term term val gamma opt val gamma val gt val gt gamma opt gt opt gt gamma opt 
similarly find upper bounds term obtain prediction minimizing resulting upper bound 
tradeoff arises competition terms term learning curve term term uncertainty term see 
term negative dropped 
proof learning curve term address problem finding bounds val gamma val gt opt gt gamma opt 
obtain differences learning curves predict probability error function number training examples see 
authors proposed justified theoretically experimentally learning curves type number training examples 
complexity parameter determined experimentally curve fitting 
learning curves valid large values training set size predict expected value error rate samples size small samples variance particular set patterns drawn 
neglect variance analysis assuming sufficiently large region interest assume learning curve describes particular sequence patterns 
additional simplifying assumption 
assumption valid training error rate vanishingly small learnable rule 
see section discussion hypotheses 
consider particular recognizer val gamma obtained training set gt examples validation set ft gamma examples 
follow learning curve particular recognizer function equation term val gamma val gt val gamma gt gammaf val term negative null 
bound zero drop 
equation term opt gt gamma opt opt gt gamma opt term function opt recognizer opt unknown bound opt max maximum complexity family classifiers considered term opt gt gamma opt hmax uncertainty term second address problem finding bound val gt gamma opt gt 
decompose term term term term val gt gamma opt gt val gt gamma val gt val gt gamma opt gt opt gt gamma opt gt hat designates empirical error rate calculated ft examples validation set 
definition cross validation procedure val gt opt gt term negative term 
write term term term val gt gamma opt gt val gt gamma val gt opt gt gamma opt gt 
error rate calculated test set size particular recognizer converges probability error law large numbers 
probability gamma ff jp gamma ff opt particular unknown fixed recognizer determined data inequality applies opt term opt gamma opt ff recognizer val determined validation set inequality directly applicable 
shall bound deviation jp val gamma val largest deviation sup jp gamma inequality gamma ff ff recognizers jp gamma ff gamma ff ff substituting ff ff obtain jp gamma ff ff probability gamma ff sup jp gamma ff term val gamma val ff note derivation typical vc theory 
inequalities replacing number test examples size validation set ft obtain term term term val gt gamma opt gt ff ff 
various values ff proposed literature 
chernoff bound hypothesis error rate small value ff valid ff ln ff small constant 
discussion bound see section 
value ff obtain equation term val gt gamma opt gt ln ff ft af learning curve term term uncertainty 
validation set size tradeoff 
terms competing learning curve term tends increase training set size expense validation set size uncertainty term tends increase validation set size 
result bounded terms equation 
bounds term zero term inequality term inequality obtain val gamma opt max ln ff bound function form learning curve term uncertainty term gammaf number families recognizers considered 
ff risk wrong ff 
constant chernoff bound 
hmax largest complexity families recognizers considered max 
total size training database examples 
fraction reserved validation 
fraction reserved training 
ln ff hmax table 
summary steps taken determine validation set size notations typical values parameters 
ratio number validation examples number training examples minimizes bound difference val gamma opt wherea max ln ff proposed bound tight minimum curve informs optimum training validation split 
derivative respect gamma gamma derivative null particular values replacing values obtain result table 
alternatively table 
note fo numerical application consider typical values parameters confidence level ff 
table give values obtained various values hmax number recognizers involved cross validation procedure 
max table 
values hmax vary ff 
notice degenerate case method predict logical answer 
case val gamma opt single recognizer 
value works 
term gamma ln ff ignored satisfy 
doing dramatically change values simplifies formula 
value max may estimated previous experiments fitting empirical learning curves equation method proposed 
max number free parameters rule thumb neural networks trained back propagation early stopping 
discussion hypotheses learning curve term sample average confidence interval 
considered particular split training validation set value equality equation implies represents average samples size replaced inequality involving error bar confidence interval 
vc theory provides confidence intervals 
probability gamma jp gamma training error rate calculated examples vc dimension particular measure complexity family recognizers complete formula page 
call quantity ln gamma ln small values training error large values purpose making qualitative statements behaviour bound case approximated power law 
learning curves equation connected vc bound making simplifications large values reach symmetrically 
bound split gamma gamma 
bound learning curve interest 
ii ln 
keeping log factor refinement considerably complicate solution change result qualitatively 
iii ln dropping term ln clearly justified typical values 
value exponent 
solving keeping general exponent equation yield simple elegant solution 
exponent chosen calculations corresponds learnable rule case case vanishingly small training error 
large fraction pattern recognition problems closely fulfill requirement 
hypothesis violated qualitatively understand effect smaller exponent looking 
typical values hmax af gamma part curve 
af gamma af gamma near minimum 
tend decrease value learnable rule hypothesis violated value proposed table estimate 
uncertainty term chernoff bounds 
chernoff bounds valid probability gamma ff gamma gamma ln ff gamma gamma gamma ln ff test error rate calculated examples 
call ff quantity ff ln ff large values bounds simplify gamma gamma gamma refined bounds obtained solving second degree equation explained page 
instance right side bound obtained gamma ln ff np gamma ln ff small values bounds simplify gamma gamma gamma purpose making qualitative statements replace bounds simple power law jp gamma constant 
value exponent 
equation chose simplify calculations 
hypothesis vanishingly small 
applied opt val means error validation set recognizer opt recognizer val close zero learnable rule second level inference 
simplifying hypothesis may quite violated 
effect smaller exponent uncertainty term qualitatively understood 
typical values ln ff part curve 
near minimum 
tend increase value hypothesis small error rate validation set violated value proposed table estimate 
derived formula splitting training database training set validation set valid large training databases small error rates 
call number families recognizers max largest complexity families validation set size training set size ratio scales ln max instance max training data reserved validation max sufficient 
framework perfect simplifying assumptions sheds light tradeoff training set size validation set size 
training set serves determine recognizers parameters level inference validation set serves select family recognizers best second level inference 
find optimum training validation split monitored ratio complexity levels inference 
originally motivated organization benchmark 
simplicity result appeal involved benchmark 
grateful vladimir vapnik guidance michael kearns communicating prior publication providing helpful comments draft 
guyon makhoul schwartz vapnik 
size test set gives error rate estimates 
bell labs memorandum bl submitted pami 

design analysis pattern recognition experiments 
bell systems technical journal pages march 
stone 
cross choice ans assessment statistical predictions 
journal royal statistical society 
stone 
asymptotics cross validation 

kearns 
bound error cross validation approximation estimation rates consequences training test split 
advances neural information processing systems nips appear 
amari murata 
muller finke yang 
asymptotic statistical theory overtraining cross validation 
submitted ieee trans 
neural networks 
vapnik 
estimation dependences empirical data 
springer new york 
rissanen 
stochastic complexity statistical inquiry volume 
wold scientific series computer science 
akaike 
new look statistical model identification 
ieee trans ac 
cortes jackel solla vapnik denker 
learning curves asymptotic values rate convergence 
technical report tm bell labs holmdel new jersey 
chernoff 
measure tests hypothesis sums observations 
ann 
math 
stat 
guyon 
project data exchange database benchmark 
technical report tm bell laboratories holmdel new jersey usa 

