technical report evaluation item top recommendation algorithms george karypis university minnesota department computer science army hpc research center minneapolis mn karypis cs umn edu explosive growth world wide web emergence commerce led development recommender systems personalized information filtering technology identify set items interest certain user 
user collaborative filtering successful technology building recommender systems date extensively commercial recommender systems 
unfortunately computational complexity methods grows linearly number customers typical commercial applications grow millions 
address scalability concerns item recommendation techniques developed analyze user item matrix identify relations different items relations compute list recommendations 
class item recommendation algorithms determine similarities various items identify set items recommended 
key steps class algorithms method compute similarity items ii method combine similarities order compute similarity basket items candidate recommender item 
experimental evaluation different datasets show proposed item algorithms times faster traditional user neighborhood recommender systems provide recommendations quality better 
explosive growth world wide web emergence commerce led development recommender systems 
recommender systems personalized information filtering technology predict particular user particular item prediction problem identify set items interest certain user top recommendation problem 
years recommender systems number different applications recommending products customer buy movies tv programs music user find enjoyable identifying web pages interest suggesting alternate ways searching information :10.1.1.30.6583:10.1.1.39.2552
supported nsf ccr eia aci army research office contract da daag doe asci program army high performance computing research center contract number daah 
various approaches recommender systems developed utilize demographic content historical information 
collaborative filtering cf probably successful widely techniques building recommender systems 
user cf recommender systems historical information identify neighborhood people past exhibited similar behavior accessed type information purchased similar set products liked disliked similar set movies analyze neighborhood identify new pieces information liked user 
refer class approaches user recommendation algorithms 
despite success cf recommender systems major limitations 
related sparsity second related scalability 
recommender systems amount historical information user item quite limited 
result cf recommender systems accurately compute neighborhood identify items recommend leading poor recommendations 
address problem variety techniques dimensionality reduction content software agents automatically generate ratings developed increase density datasets :10.1.1.38.5499:10.1.1.29.8381:10.1.1.42.639
unfortunately nearest neighbor algorithms require computations grows linearly number users items 
millions users items existing cf recommender systems suffer serious scalability problems 
way reducing complexity nearest neighbor computations cluster users limit nearest neighbor search users belong nearest cluster cluster centroids derive recommendations 
approaches significantly speed recommendation engine tend decrease quality recommendations 
alternate approach build recommendation models items 
approaches historical information analyzed identify relations items purchase item set items leads purchase item set items :10.1.1.21.4665
approaches pre computed model quickly recommend set items shown produce recommendation results cases comparable traditional neighborhood cf recommender systems 
refer class approaches item recommendation algorithms 
class model top recommendation algorithms 
algorithms determine similarities various items identify set items recommended 
key steps class algorithms method compute similarity items ii method combine similarities order compute similarity basket items candidate recommender item 
particular different methods computing item item similarity 
method models items vectors user space uses cosine measure measure similarity 
second method computes item item similarity technique inspired conditional probability items extended differentiate users varying amounts historical information differentiate frequently infrequently purchased items 
furthermore method combining item item similarities accounts item neighborhoods different density incorrectly bias recommendation 
experimentally evaluate algorithms different datasets arising various applications 
experiments show item item algorithms times faster traditional user neighborhood recommender systems 
furthermore algorithms achieve substantially higher quality 
particular cosine conditional probability algorithms average better user recommendation algorithm respectively 
rest organized follows 
section presents overview traditional user top recommendation algorithms 
section describes various phases algorithms item top recommendation system 
section provides experimental evaluation various parameters proposed algorithms compares user algorithms 
section provides concluding remarks outline research 
overview user top recommendation algorithms user collaborative filtering cf successful technology building recommender systems date extensively commercial recommender systems 
schemes rely fact person belongs larger group similarly behaving individuals 
consequently items products frequently purchased various members group form basis recommended items 
user item matrix containing historical purchasing information customers items 
matrix th customer purchased th item zero 
set items purchased customer want compute top recommendations 
refer customer active customer order simplify presentation assume active customer belong customers stored matrix user cf recommender systems compute top recommended items customer follows 
identify similar customers database 
done modeling customers items vector space model widely information retrieval :10.1.1.38.5499:10.1.1.21.4665
model customers active customer treated vector dimensional item space similarity active existing customers measured computing cosine vectors 
set similar customers discovered corresponding rows aggregated identify set items purchased group frequency 
set user cf techniques recommend frequent items active user purchased 
note frequency items set computed just counting actual occurrence frequency normalizing row length 
normalization gives emphasis items purchased customers frequent buyers leads somewhat better results 
despite popularity user cf recommender systems number limitations related scalability real time performance 
computational complexity methods grows linearly number customers typical commercial applications grow millions 
furthermore matrix sparse user user similarity matrix quite dense 
frequently purchased items lead dense user user similarities 
real time top recommendations current basket items utilized commerce sites take advantage pre computed user user similarities 
throughput user recommendation engines increased increasing number servers running recommendation engine decrease latency top recommendation critical near real time performance 
item top recommendation algorithms address scalability concerns user recommendation algorithms item recommendation techniques known model developed :10.1.1.21.4665
approaches analyze user item matrix identify relations different items relations compute list top recommendations 
key motivation schemes customer purchase items similar related items purchased 
schemes need identify neighborhood similar customers recommendation requested lead faster recommendation engines 
number different schemes proposed compute relations different items probabilistic approaches traditional item item correlations 
study class item top recommendation algorithms item item similarity compute relations items 
model building phase item similar items 
computed corresponding similarities 
recorded 
customer purchased set basket items information compute top recommended items follows 
identify set candidate recommended items union similar items item removing union items item compute similarity set sum similarities items similar items items sorted non increasing order respect similarity items selected top recommended set 
item similarity critical step proposed item recommendation algorithm method determine similarity items 
rest section describe different classes similarity algorithms developed 
derived vector space model derived probabilistic methods 
cosine similarity way computing similarity items treat item vector space customers cosine measure vectors measure similarity 
formally user item matrix similarity items defined cosine dimensional vectors corresponding vth column matrix cosine vectors si cos denotes vector dot product operation 
equation see similarity items high customer purchases items purchases item 
furthermore important feature cosine similarity takes account purchasing frequency different items achieved denominator equation 
result frequently purchased items tend similar frequently purchased items infrequent purchased items vice versa 
important tends eliminate obvious recommendations recommendations frequent items items tend recommended frequently purchased items current basket items 
case user recommendation algorithms rows correspond original binary purchase information scaled row unit length norm differentiate customers buy small large number items 
depending customers represented cosine item similarity different 
case pair items customer treated equally second case importance customers purchased fewer items 
motivation second scheme purchasing information customers bought items tends reliable purchasing information customers buy items group tends represent consumers focused certain product areas 
conditional probability similarity alternate way computing similarity pair items measure conditional probability purchasing items items purchased 
particular conditional probability purchasing purchased number customers purchase items divided total number customers purchased freq uv freq freq number customers purchased items set note general measure similarity leads asymmetric relations 
limitations conditional probabilities measure similarity item tend high conditional probabilities items purchased frequently 
quite high result fact occurs frequently tend occur 
problem recognized earlier researchers information retrieval recommendation systems 
way correcting problem divide quantity depends occurrence frequency item different methods proposed achieving 
inspired inverse document frequency scaling performed information retrieval systems multiplies log divides 
experiments shown scaling greatly affects performance recommender system furthermore optimal scaling degree problem depended 
reasons formula compute similarity items si freq uv freq freq parameter takes value 
note equation identical similar scaling factor formulation divided 
limitations equation provides mechanism discriminate customers purchase items customers purchase items 
discussed section customers buy fewer items may reliable indicators determining similarity items 
reason extended similarity measure equation way 
normalize row matrix unit length 
define similarity items si freq freq 
difference equation equation occurrence frequency sum corresponding non zero entries column user item matrix 
rows normalized unit length customers purchased items tend contribute similarity giving emphasis purchasing decisions customers bought fewer items 
similarity normalization recall section basket items item top recommendation algorithm determines items recommended computing similarity item items selecting similar items recommended set 
similarity set item determined adding similarities item similar items 
potential drawbacks approach raw similarity item similar items may significantly different 
item neighborhoods different density 
especially true items purchased somewhat infrequently moderate overlap infrequently purchased items lead relatively high similarity values 
consequently items exert strong influence selection top items leading wrong recommendations 
reason actual similarities computed various methods described section item normalize similarities add 
experiments section show lead dramatic improvements top recommendation quality 
computational complexity computational complexity item top recommendation algorithm depends amount time required build model item identify similar items amount required compute recommendation model 
model building phase need compute similarity item items select similar items 
upper bound complexity step need compute similarities potentially requiring operations 
actual complexity significantly smaller resulting item item similarity matrix extremely sparse 
datasets item item similarity matrix general sparse 
reason sparsity levels customer purchases relatively small number items items purchased tend clustered 
consequently sparse data structures store computing similarities pairs items purchased customer substantially reduce computational complexity 
amount required compute top recommendations basket need access similar items items identify similar items 
experimental results section experimentally evaluate performance item top recommendation algorithms compare performance user top recommendation algorithms 
experiments performed pentium ii workstation running mhz mbytes memory linux operating system 
data sets evaluated performance different top recommendation algorithms different datasets characteristics shown table 
user item matrix columns labeled rows columns non zeros show number customers users number items total number transactions respectively 
name 
rows 
columns 
non zeros ecommerce catalog skills movielens table characteristics various datasets evaluating top recommendation algorithms 
ecommerce dataset corresponds web purchasing transactions commerce site 
catalog dataset corresponds catalog purchasing transactions major mail order catalog retailer 
dataset corresponds store credit card purchasing transactions major department store 
skills dataset corresponds related skills resumes various individuals obtained major online job portal 
movielens dataset corresponds movie ratings obtained movielens research project 
note experiments ignored actual ratings movielens dataset 
experimental design metrics goal experiments evaluate quality performance top recommendations provided various recommender algorithms 
order evaluate quality top recommendations split datasets training test set randomly selecting non zero entries row part test set remaining entries training customer user obtained top recommendations items training set basket customer user 
case item algorithms top recommendation computed training set build item similarity models 
similarly case user algorithms nearest neighbors top recommendations computed training set 
quality measured looking number hits number items test set top recommended items returned customer user 
particular total number datasets row non zero entries 
customers users computed recall recommended system recall number hits recall value indicates recommendation algorithm able recommend hidden item recall value indicates recommendation algorithm able recommend hidden items 
order ensure results statistically accurate experiments performed different runs time different random partitioning training test 
results reported rest section averages trials 
experiments number items top recommended top recommendation algorithms 
effect similarity normalization experiment designed evaluate effect similarity normalization discussed section 
shows recommendation accuracies achieved different item recommendation algorithms 
cosine similarity function conditional probability 
difference pair algorithms normalize similarities labeled cos normalizes labeled cos 
algorithms rows matrix normalized unit length number nearest items model set value 
ecommerce catalog skills movielens recall cos cos effect similarity normalization recommendation quality achieved cosine recommendation algorithms 
looking results see algorithms similarity normalization achieve higher recommendation accuracies compared counterparts 
actual improvement dataset algorithm depended 
general relative improvements tend higher conditional probability scheme cosine scheme 
performance cosine scheme improves average improvement performance conditional probability scheme improves average improvement 
due clear performance advantage rest experiments similarity normalization 
effect row normalization second experiment designed evaluate effect row normalization customers purchase items weigh item similarity calculations 
shows recall achieved different item recommendation algorithms 
cosine similarity function conditional probability 
difference pair algorithms normalize rows labeled cos normalizes labeled cos 
experiments set conditional probability algorithms value 
ecommerce catalog skills movielens recall cos cos effect row normalization recommendation quality achieved cosine conditional probability recommendation algorithms 
results see row normalized version better dataset cosine conditional probability algorithms 
average improvement datasets cosine conditional probability similarity 
row normalized version somewhat worse dataset especially cosine algorithm 
consistent improvements achieved majority datasets rest experiments row normalization 
model size sensitivity recall section item recommendations computed model utilizes similar items different items 
evaluate sensitivity different algorithms value performed experiment take values 
recommendation accuracies experiments shown cosine conditional probability algorithms 
conditional probability algorithms experiments performed value 
see experiments recommendation accuracy item algorithms tend improve increase value exception movielens dataset recommendation accuracies decrease slightly increase ignore dataset average recommendation accuracies cosine algorithm incrementally improve vary items case conditional probability algorithm average incremental improvements 
results indicate small values item recommendation algorithms provide reasonably accurate recommendations ii increasing value lead significant improvements 
particularly important small values lead fast recommendation rates low computational requirements materially affecting quality recommendations 
note conditional probability similarity cosine similarity ecommerce catalog skills movielens ecommerce catalog skills movielens recall recall function number similar items computing top recommendations cosine conditional probability recommendation algorithms 
diminishing incremental improvements achieved increasing value direct consequence fact looking recommended items 
result sufficiently large ensure various item item lists sufficient common items increases change order top items 
item frequency scaling sensitivity parameters conditional probability top recommendation algorithm value control extend similarity frequently purchased occurring items de emphasized 
study sensitivity recommendation algorithm parameter performed sequence experiments varied increments 
shows recall achieved different datasets different values relative recall achieved cosine algorithm 
value greater indicates conditional probability scheme outperforms cosine scheme value indicates performs better 
note results obtained 
various values relative recall ecommerce catalog skills movielens recommendation quality function item frequency scaling achieved parameter conditional probability recommendation algorithms relative achieve cosine algorithm 
number interesting observations looking results shown 
datasets value significant impact recommendation quality different values lead substantially different recalls 
second increase value changes recall fairly smooth 
third value leads highest recall depends dataset 
highest performance ecommerce catalog skills movielens obtained values respectively 
fourth datasets exist set values lead higher quality recommendations computed cosine algorithm 
fifth datasets conditional probability scheme achieved consistently performance 
results suggest optimal value needs estimated particular dataset 
done hiding portion training set estimate value leads highest recommendation accuracy 
results show cosine conditional probability schemes compare 
results see datasets wide range values conditional algorithm leads somewhat higher recalls cosine scheme 
average conditional probability scheme better equal respectively 
furthermore compare results obtained optimal values see conditional probability algorithm better cosine scheme 
believe improvements direct results higher degree provided parameter 
comparison user recommendation algorithm compare performance item recommendation algorithms achieved user algorithms performed experiment computed top recommendations item user recommendation algorithms 
results shown 
user recommendations obtained algorithm described section user neighborhoods size unit length normalized rows 
furthermore similarity weighted approach determine frequency item include neighbors identical set items active item neighbors contribute recommendation 
includes different sets item results obtained 
results labeled cosine correspond cosine results 
results labeled correspond conditional probability algorithm set 
results labeled opt correspond conditional algorithm uses dataset value achieved highest performance experiments discussed section 
includes top recommendation quality achieve naive algorithm labeled frequent recommends frequent items active user set items 
results see cosine algorithms outperform user algorithm datasets opt outperforms user scheme datasets 
interesting note item algorithms perform substantially better datasets marginally worse remaining 
fact average improvement achieved datasets significant cosine respectively 
item algorithm uses optimal values performs better achieving average improvement 
note user item algorithms produce recommendations quality substantially better recommendations produced naive frequent algorithm 
advantages item algorithm smaller computational requirements user top recommendation algorithm 
table shows amount time required algorithms compute top recommendations datasets 
column labeled shows amount time required build item recommendation model compute similar items columns labeled shows amount time required compute recommendations dataset columns labeled shows rate top recommendations computed terms recommendations second 
note implementation user top recommendation ecommerce catalog skills movielens recall frequent user cosine opt quality recommendations obtained naive item user recommendation algorithms 
algorithm takes advantage sparse user item matrix order identify nearest users quickly possible 
times table seconds 
user item name ecommerce catalog skills movielens table computational requirements computing top recommendations user item algorithms 
number interesting observations looking table 
recommendation rates achieved item algorithm times higher achieved user algorithm 
add various data sets see recommendation rate item algorithm recommendations second compared recommendations second achieved algorithm 
translates recommendation item algorithm versus user algorithm 
second discussed section amount time required build models item algorithm quite small 
third accounting model building time item algorithm times faster user algorithm 
summary item top recommendation algorithms improve recommendations produced user algorithms terms recommendation accuracy times faster 
directions research experimentally evaluated class model top recommendation algorithm uses item item similarities compute recommendations 
results showed cosine conditional probability item similarity schemes lead recommenders average provide accurate recommendations provided traditional user cf techniques 
furthermore proposed algorithms substantially faster allowing real time recommendations independent size user item matrix 
believe top recommender algorithms improved combining elements user item approaches 
user approaches dynamically computing neighborhood similar users better suited provide truly personalized information 
hand item approaches directly computing similarity items appear compute accurate recommendations 
potential limitation item approaches large user collections globally computed item item similarities may able provide sufficiently degree personalization combined context basket item similarity 
case approach identifies reasonably large neighborhood similar users subset derive item recommendation model may able combine best worlds perform better recommendations 
marko balabanovic yoav shoham 
fab content collaborative recommendation 
communications acm march 
basu haym hirsh william cohen 
recommendation classification social content information recommendation 
proceedings workshop recommender systems pages 
aaai press 
doug beeferman adam berger 
agglomerative clustering search engine query log 
proceedings acm sigkdd international conference pages 
billsus pazzani 
learning collaborative information filters 
proceedings icml pages 
chan 
non invasive learning approach building web user profiles 
proceedings acm sigkdd international conference 
konstan borchers sarwar herlocker riedl :10.1.1.42.639
combining collaborative filtering personal agents better recommendations 
proceedings aaai pages 
aaai press 
hill stead rosenstein furnas 
recommending evaluating choices virtual community 
proceedings chi 
brendan david freed martin 
cross sell fast promotion tunable customer item recommendation method conditional independent probabilities 
proceedings acm sigkdd international conference pages 
konstan miller maltz herlocker gordon riedl 
grouplens applying collaborative filtering usenet news 
communications acm 
mobasher dai tao luo nakagawa jim 
discovery aggregate usage profiles web personalization 
proceedings webkdd workshop 
resnick varian 
recommender systems 
communications acm 
resnick iacovou suchak bergstrom riedl 
grouplens open architecture collaborative filtering netnews 
proceedings cscw 
john breese david heckerman carl kadie 
empirical analysis predictive algorithms collaborative filtering 
proceedings th conference artificial intelligence pages 
salton 
automatic text processing transformation analysis retrieval information computer 
addisonwesley 
sarwar karypis konstan riedl 
analysis recommendation algorithms commerce 
proceedings acm commerce 
sarwar karypis konstan riedl 
application dimensionality reduction recommender systems case study 
acm webkdd workshop 
schafer konstan riedl 
recommender systems commerce 
proceedings acm commerce 
shardanand patti maes 
social information filtering algorithms automating word mouth 
proceedings acm chi conference human factors computing systems pages 
terveen hill brian amento david mcdonald josh 
phoaks system sharing recommendations 
communications acm 
lyle ungar dean foster 
clustering methods collaborative filtering 
workshop recommendation systems th national conference artificial intelligence 
wolf aggarwal wu yu 
hatches egg new graph theoretic approach collaborative filtering 
proceedings acm sigkdd international conference knowledge discovery data mining 

