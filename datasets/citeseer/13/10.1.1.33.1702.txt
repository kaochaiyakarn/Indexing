modeling ga performance control parameter optimization vincent cicirello robotics institute carnegie mellon university forbes avenue pittsburgh pa vincent cs cmu edu phone stephen smith robotics institute carnegie mellon university forbes avenue pittsburgh pa sfs cs cmu edu phone optimization control parameters genetic algorithms time consuming tedious task 
take meta level genetic algorithm approach control parameter optimization 
enhance process incorporating neural network fitness evaluation 
neural network trained learn complex interactions genetic algorithm control parameters predict performance genetic algorithm relative values control parameters 
validate approach describe genetic algorithm largest common subgraph problem develop neural network enhanced meta level genetic algorithm 
resulting genetic algorithm significantly outperforms hand tuned variant shown competitive hill climbing algorithm practical applications 
genetic algorithms number parameters control evolutionary search solution problems 
include rate crossover rate mutation maximum number generations number individuals population forth 
hard fast rules choosing appropriate values parameters 
optimal near optimal set control parameters genetic algorithm genetic algorithm application generalize cases 
choosing values control parameters handled problem trial error 
common practice hand optimize control parameters tuning time 
time consuming tedious task 
furthermore practice tuning control parameters time result optimal parameter set parameters independent interact complex ways 
problem finding optimal control parameters genetic algorithms studied de jong grefenstette schaffer wu chow eiben michalewicz 
approach shown promise contexts genetic algorithm search control parameter settings called meta level genetic algorithm approach 
drawback approach computational requirements 
process executing primary genetic algorithm evaluate fitness set control parameters expensive operation particularly set control parameters results high convergence times 
describe approach improving efficiency meta level genetic algorithm approach control parameter optimization 
specifically incorporate neural network alternative basis fitness evaluation meta level 
neural network trained learn effects complex interactions control parameters accuracy genetic algorithm computational time 
neural network meta level genetic algorithm predict performance genetic algorithm optimal control parameters sought 
fitness evaluation far expensive operation 
motivation development genetic algorithm largest common subgraph problem 
primary genetic algorithm context describing evaluating approach evolving control parameter values 
describing genetic algorithm largest common subgraph problem attempt hand tuning control parameters 
neural network learns model genetic algorithm performance relative control parameter values 
optimal control parameters evolved meta level genetic algorithm surrogate neural network model fitness evaluation 
resulting genetic algorithm largest common subgraph problem shown competitive circumstances superior hill climbing algorithm practical applications 
section describes genetic algorithm developed largest common subgraph problem 
section describe techniques employed optimize control parameters 
experimental results metalevel optimization process results comparing performance optimized genetic algorithm hill climbing algorithm section 
related discussed section 
section discusses 
largest common subgraph genetic algorithm largest common subgraph problem closely related problems maximum subgraph matching graph isomorphism subgraph isomorphism error correcting graph isomorphism important applications 
applications include chemical structure classification sub circuit identification vlsi mcgrath cad model comparison nau regli cicirello regli cicirello pattern recognition cho kim lu ren suen pearce caelli bischof machine vision wong christmas kittler petrou case reasoning andersen sanders hendler 
largest common subgraph problem seeks subgraph pair graphs subgraphs isomorphic common subgraph largest number edges possible common subgraphs 
problem known class np complete problems computationally intractable garey johnson 
due utility wide array application areas efficient approximation largest common subgraph problem beneficial 
describe inexact solution largest common subgraph problem stage hopfield neural network 
show algorithm easily parallelized compare performance similar algorithm 
inexact solution largest common subgraph problem hill climbing approach cicirello regli cicirello regli cicirello 
take iterative improvement approach restart algorithm random starting points attempt combating problem local extrema 
algorithms closely related problem error correcting graph isomorphism include messmer bunke messmer bunke wang 
wang fan 
develop genetic algorithm approach largest common subgraph problem 
chromosomes represent node permutations individual alleles representing correspondences nodes 
indices chromosome represent nodes graph smaller number nodes 
values individual locations chromosome represent nodes second graph 
complete chromosome represents mapping nodes graph represented indices second graph represented values 
fitness chromosome number matched edges mapping represented chromosome 
roulette wheel selection chromosome population portion roulette wheel value fitness evaluation 
elitist strategy incorporated best chromosomes population carried generation 
elite individuals undergo mutation crossover 
swap mutation value allele swapped allele small probability 
graphs differing numbers nodes choices mutation operator swap alleles swap value allele node currently chromosome 
crossover operator loosely partially matched crossover pmx 
wang 
wang fan pmx described goldberg goldberg genetic algorithm closely related problem error correcting graph isomorphism 
adopted uniform variation pmx 
choosing segment chromosomes exchange allele exchanged probability 
consider example 
ffl consider chromosomes ffl consider crossing points swap values positions chromosomes result ffl result necessary crossover points swapping values positions chromosomes obtain halting criteria fitness individual equal number edges graphs case graphs subgraph isomorphic subgraph isomorphism fitness individuals population equal fitness fit chromosome small tolerance fitness fit individual maximum number generations evolved number generations evolve improvement fitness fit individual 
control parameter optimization genetic algorithm described section defined control parameter set pi fp sg ffl size population 
ffl crossover rate 
ffl probability allele involved crossover 
ffl mutation rate 
ffl halting tolerance described section 
genetic algorithm halts fitness gammaf fitness ffl controls mutation operator case graphs differing numbers nodes 
mutation occurs operator swaps values alleles chosen probability operator swaps value allele node current mapping chosen probability gamma attempt optimization control parameters hand tuning 
began initial set control parameter settings taken standard practice gradually perturbed parameter time keeping result provided improved average performance genetic algorithm 
genetic algorithm hill climbing genetic algorithm hill climbing plots comparing genetic algorithm hand tuned control parameters hill climbing algorithm accuracy vs graph size cpu time seconds vs graph size 
result hand optimization control parameter set fp 
compares genetic algorithm largest common subgraph problem hand tuned control parameters hill climbing approach cicirello regli cicirello 
hand tuned parameters genetic algorithm accurate hillclimbing algorithm 
requires far cpu time convergence 
possible trade cpu time added accuracy solutions sophisticated control parameter optimization strategy 
section formulate approach optimizing control parameters genetic algorithm largest common subgraph problem 
meta level genetic algorithm approach taken 
neural network generate predictions genetic algorithm perform set control parame ters 
neural network prediction fitness evaluation meta level genetic algorithm 
neural network prediction performance fitness function meta level genetic algorithm uses neural network prediction performance primary genetic algorithm set control parameters 
idea computationally expensive operation metalevel genetic algorithm execute primary genetic algorithm control parameter set examines neural network learn complex interactions control parameters 
neural network develop input units 
input units values control parameters pi fp sg 
hidden layer sigmoid units network sigmoid output units 
output units encode value round 
average accuracy genetic algorithm control parameters runs algorithm 
accuracy defined jes jej edge set resulting approximation largest common subgraph edge set actual largest common subgraph 
defined ratio gamma cm average cpu time convergence control parameters cm maximum cpu time convergence control parameter set neural network training set 
output units treated binary representation value 
training data neural network gathered generating large number control parameter sets random 
genetic algorithm executed times random control parameter sets true value calculated 
collection isomorphic pairs random graphs ranging size nodes generated 
collection test performance sets control parameters 
total control parameter sets generated randomly training data 
control parameter sets distributed value ranges defined meta level genetic algorithm chromosome representation see section 
control parameter sets calculated batch executing largest common subgraph genetic algorithm pair graphs randomly generated collection 
data divided training set control parameter sets hold set control parameter sets 
back propagation train neural network learning rate momentum approximately epochs 
accuracy obtained training set accuracy obtained hold set define accuracy percentage parameter sets neural network correctly predicts performance genetic algorithm 
correct prediction means fitness value predicted neural network actual fitness value 
hold set prevent overfitting training data 
hold set training data neural network resulted best performance hold set maintained training phase 
meta level genetic algorithm meta level genetic algorithm crossover operator crossover rate mutation rate population size 
roulette wheel selection fitness individuals population elitist strategy ensuring fit individuals population survive tact generation 
stopping criterion entire population fitness 
meta level genetic algorithm uses neural network developed section evaluate fitness individuals population 
individuals encoded binary strings control parameter encoded number bits 
population size encoded bits 
substrings correspond population size ranging increments 
crossover rate encoded bits representing values increments 
uniform parameter uniform crossover operator mutation operator selector encoded bits representing values increments 
mutation rate encoded bits representing values gammai 
fitness tolerance encoded manner mutation rate 
complete individual bits length allowing unique individuals 
table sample control parameter sets evolved meta level genetic algorithm 
experimental results control parameter experiments meta level genetic algorithm described section neural network described section fitness evaluation population sets control parameters evolved 
small sample final population seen table 
thing stands final population parameter sets individuals population state optimal mutation rate 
essentially signifies convergence value mutation rate values consecutive encoding scheme meta level genetic algorithm 
looking lists human eye reveals obvious relationship values parameters respect performance genetic algorithm 
final population evolved generations metalevel genetic algorithm 
entire run meta level genetic algorithm necessarily unique parameter sets examined population generations 
factoring elitism results necessarily unique parameter sets 
crossover rate approximately population result crossover leaving possibly unique control parameter sets 
number sets duplicates leaving rough estimate unique parameter sets examined meta level genetic algorithm 
recall neural network trained training examples 
training neural network learn control parameters interact required executing largest common subgraph genetic algorithm control parameter sets required neural network 
take look just evolved control parameters perform 
note plots comparing performance control parameter sets table set plot accuracy vs graph size plot cpu time seconds vs graph size 
control parameter sets table neural network training set 
chosen random final population 
experiment conducted compare performance control parameter set derived 
seen evolved control parameter sets perform better parameter set terms accuracy 
difficult judge best terms accuracy 
choosing accuracy necessary 
shows plot average cpu time required largest common subgraph genetic algorithm parameter sets 
control parameter set clearly winner sets faster hand tuned set 
accuracy genetic algorithm hill climbing genetic algorithm hill climbing plots comparing genetic algorithm approach hill climbing algorithm 
control parameters obtained means meta level optimization accuracy vs graph size cpu time seconds vs graph size 
cpu time consideration clear argument favor control parameter set best 
comparison hill climbing experimentally compare genetic algorithm described control parameter settings derived section hill climbing algorithm described cicirello regli cicirello 
results shown 
algorithms executed randomly generated isomorphic pairs graphs size nodes nodes 
isomorphic pairs chosen experiment allow basis computing accuracy result 
experiments performed pentium iii linux operating system implementation 
genetic algorithm hill climbing algorithm compare similarly terms accuracy 
interesting result cpu time comparison 
graphs nodes hillclimbing algorithm requires cpu time genetic algorithm 
graphs nodes genetic algorithm developed meta level optimization approach far performs hill climbing algorithm 
related earliest studies genetic algorithm control parameters de jong de jong 
analyzed class genetic algorithms function optimization 
de jong optimal control parameters widely despite lack knowledge optimality respect problems outside test collection 
schaffer 
schaffer expanded de jong test suite performed systematic study effects control parameters 
grefenstette grefenstette saw problem tuning control parameters primary genetic algorithm secondary meta level optimization problem apply meta level genetic algorithm approach 
grefenstette meta level genetic algorithm parameterized de jong optimal control parameters population crossover rate mutation rate generation gap scaling window elitist strategy de jong 
grefenstette results showed slight improvement de jong control parameters population size cross rate mutation rate elitist strategy grefenstette 
applied meta level genetic algorithms control parameter optimization 
presents modified methods selecting initial populations mutation operators improving performance genetic algorithms function optimization 
tests techniques meta level genetic algorithm optimize control parameters genetic algorithm 
wu chow wu chow apply meta level genetic algorithm approach optimizing control parameters genetic algorithms nonlinear mixed discrete integer optimization problems 
de jong de jong applies genetic algorithm approach control parameter optimization dynamical systems necessarily control parameters genetic algorithm 
developed neural network enhanced meta level genetic algorithm approach control parameter optimization 
fitness evaluation meta level genetic algorithm neural network prediction performance primary genetic algorithm set control parameters input 
training neural network learn complex interactions control parameters genetic algorithm able provide efficient alternative running actual algorithm purposes meta level optimization 
approach meta level control parameter optimization allowed develop genetic algorithm evolving inexact solutions largest common subgraph problem efficiently accurately 
approach genetic algorithm finding approximate solutions largest common subgraph problem shown asymptotically efficient hill climbing 
solutions produced genetic algorithm just accurate solutions hill climbing algorithm 
results experiments suggest relatively small graphs roughly nodes hill climbing algorithm performs best larger graphs genetic algorithm far performs hill climbing algorithm 
experimental evidence necessary fully understand benefits evolutionary approach largest common subgraph problem 
example beneficial conduct experiments examining performance genetic algorithm types random graphs varying density edges graphs labeling nodes 
broadly approach described optimization search control parameters appears quite general 
may beneficial apply techniques control parameter optimization problems 
example neural network models performance algorithms simulated annealing tabu search relative respective control parameters may built purpose control parameter optimization 

linear programming approach weighted graph matching problem 
ieee transactions pattern analysis machine intelligence 
andersen hendler 
massively parallel matching knowledge structures 
kitano hendler eds massively parallel artificial intelligence 
menlo park california aaai press mit press 


initialization mutation selection methods genetic algorithms function optimization 
belew booker eds proceedings fourth international conference genetic algorithms 
san mateo ca morgan kaufmann 
cho kim 
recognizing objects forward checking constrained tree search 
pattern recognition letters 
christmas kittler petrou 
structural matching computer vision probabilistic relaxation 
ieee transactions pattern analysis machine intelligence 
cicirello regli 
resolving non uniqueness design feature histories 
anderson eds proceedings fifth symposium solid modeling applications 
new york acm siggraph 
cicirello 
intelligent retrieval solid models 
master thesis drexel university philadelphia pa de jong 
analysis behavior class genetic adaptive systems 
ph dissertation university michigan ann arbor mi 
de jong 
adaptive system design genetic approach 
ieee transactions systems man cybernetics 
eiben michalewicz 
parameter control evolutionary algorithms 
ieee transactions evolutionary computation 
nau regli 
feature similarity assessment solid models 
hoffman eds fourth symposium solid modeling applications 
new york acm 
garey johnson 
computers intractability guide theory npcompleteness 
new york freeman 
goldberg 
genetic algorithms search optimization machine learning 
addison wesley 
grefenstette 
optimization control parameters genetic algorithms 
ieee transactions systems man cybernetics 
mcgrath 
compare program verifying vlsi layouts 
ieee design test 
lu ren suen 
hierarchical attributed graph representation recognition handwritten chinese characters 
pattern recognition 
messmer bunke 
fast errorcorrecting graph isomorphism model precompilation 
technischer bericht iam institut fur informatik universitat bern 
ebeling sather 
identifying fast subgraph isomorphism algorithm 
proceedings th international design automation conference 
pearce caelli bischof 
graph matching pattern recognition 
pattern recognition 
sanders hendler 
case graph structured representations 
proceedings second international conference case reasoning iccbr 
new york springer verlag 
schaffer caruana eshelman das 
study control parameters affecting online performance genetic algorithms function optimization 
schaffer ed proceedings third international conference genetic algorithms 
san mateo ca morgan kaufmann 

neural network approach solving maximal common subgraph problem 
ieee transactions systems man cybernetics part cybernetics 
wang fan 
genetic search error correcting graph isomorphism 
ieee transactions systems man cybernetics part cybernetics 
wong 
model matching robot vision subgraph isomorphism 
pattern recognition 
wu chow 
genetic algorithms nonlinear mixed discrete integer optimization problems meta genetic parameter optimization 
engineering optimization 
