protocol independent technique eliminating redundant network traffic neil spring david wetherall computer science engineering university washington seattle wa technique identifying repetitive information transfers analyze redundancy network trac 
insight dynamic content streaming media trac caught today web caches derive similar information 
adapted similarity detection techniques problem designing system eliminate redundant transfers 
identify repeated byte ranges packets avoid retransmitting redundant data 
nd high level redundancy able detect repetition web proxy caches 
traces web proxy caching applied additional original volume web trac redundant 
technique assumptions protocol syntax caching semantics provides immediate bene ts types content streaming media ftp trac news mail 

focused problem improving web performance reducing download times bandwidth requirements 
despite adoption browser proxy caching compression standards jpeg web performance lags user demands 
proxy caching appears limited ability improve web performance 
study predicts proxy caches squid rules eliminate trac valuable start complete solution 
analyze redundancy network trac view eliminating means improving web performance 
naive user behavior web quite strange take long time download appears page similar email cs washington edu content 
redundant uncached content number possible origins 
may dynamically generated personalized mirrored di erent server named di erent url delivered new unsupported protocol updated static content access counted advertising revenue 
regardless origin transfers represent source ine ciency aim remove 
possible approach improve caching protocols deal situations 
caching entire documents name fundamentally coarse grained suppress redundant content just described 
documents may need transferred entirety categories quite similar data transferred 
addition application level caching adapt new protocols carrying new types information streaming media emerge popular 
explicit cache support protocol added deployed interim mismatches usage cache support result unnecessary transfers 
explore new protocol independent technique identifying redundant information su er disadvantages 
technique adaptation algorithms rst proposed manber identify similar les le system 
identi es similarity di erent documents generalizes content schemes aware duplication suppression 
ef cient workstation prototype runs data rates approximately mbps 
redundancy suppression technique analyze network trac nd high level repetition information transferred trace site 
potential byte savings exploiting redundancy focus 
comparing packet contents nd incoming trac outgoing trac redundant measure 
incoming web trac cacheable proxy cache uses squid rules identi ed redundant 
nd nearly redundancy web traf proxy caching including redundancy documents web proxy caches prohibited caching 
suggests redundancy suppression web proxy caching combination 
rest organized follows 
describe technique nding redundancy section 
section architecture caching scheme exploit redundancy reduce bandwidth bandwidth constrained link 
describe implementation including choice algorithm parameters section 
analysis redundancy network traces paying particular attention web trac section 
discuss related section conclude section 
finding repetition fingerprints goal process stream packets input packet quickly identify regions repeated earlier packets 
adapt technique developed manber nding similar les large le system applied broder detect similar web documents 
set representative ngerprints computed object 
fingerprints integers generated way function applied set bytes 
ngerprint algorithms generate distributed ngerprints ngerprint compact unique high probability 
manber broder compare representative ngerprints di erent les estimate similarity 
contrast ngerprints pointers data stream nd regions repeated content 
store representative ngerprints index maps ngerprint region describes cached packet payload 
ngerprints anchors hints nding larger regions repeated content region 
computing representative fingerprints representative ngerprints packet generated computing rabin ngerprint length substring packet selecting deterministic subset ngerprints 
rabin ngerprint sequence bytes length expression constant integers rf mod form expression length substring fft ft computationally ecient 
compute ngerprints window size packet step ngerprint de ned terms previous rf rf mod fast execution precomputed stored table 
constant table entries 
generate new ngerprint scratch advancing ngerprint manner requires subtraction multiplication addition mask perform mod operation power 
worth noting md sha secure ngerprint algorithms allow decomposition incremental computation 
ecient purpose 
fingerprint selection impractical index ngerprint computed require nearly index entry byte 
simply select nth ngerprint locate shifted content 
packets identical extra byte inserted redundancy select nth ngerprint strategy 
manber insight select fraction ngerprints depending values locations 
selecting fraction ngerprint values gives deterministic sample content sensitive location 
means content packetized di erent ways interspersed data recognized repetitive 
ngerprints random uniformly distributed fraction provides probabilistically coverage 
selecting fraction easily accomplished practice selecting binary ngerprints speci ed number zeros denote number zeros experiments 
algorithm algorithm nding repeated content run packet possibly nite input stream 
cache hold packets cache input packet checked redundancy 
cache indexed representative ngerprints packets holds 
packet algorithm rst generates representative set ngerprints 
ngerprint set checked index cache 
packet cache content input packet regions correspond ngerprint 
region compared input cached packets verify collision ngerprint name space 
ngerprints suciently large observed collisions practice 
matching region expanded left right byte byte packet nd largest matching region 
total repeated content simply union largest matching regions 
packet cache ngerprint index updated inserting newly processed packet evicting oldest packets fifo order internet packets tokens users shared cache architecture 
tokens passed place replicated bytes caches opposite sides bandwidth constrained link 
user machines continue communicate unencoded packets 
room necessary 
index ngerprint refers packet longer cache released 
details 
select ngerprint packet packet shorter ngerprint window ensure packet represented cache 
second ngerprint generation content matching interleaved sequential exposition implies 
change algorithm conceptually results ecient implementation 

shared cache architecture envision redundancy suppression technique improve web protocol performance architecture shown 
caches running algorithm placed ends bandwidth constrained channel 
channel access link wireless link network path server proxy server client 
cache converts repeated strings tokens passes encoded smaller packets channel original packet reconstructed 
trades memory computation bandwidth savings 
emphasize implemented architecture 
focus redundancy network trac potential bandwidth savings characterize analysis describe architecture provide appropriate context discussion 
key problem explored addressed complete implementation synchronization mechanisms keep contents caches consistent 
caches lose consistency packet losses tokens decoded far channel 
fingerprints value 
assuming collisions loss consistency detected unrecognized ngerprint token received 
repaired requesting missing packet upstream 
aspects architecture worth noting 
improve performance non web protocols 
matching technique completely protocol independent 
second complements replaces traditional web caching 
making application level semantics web caches eliminate need contact remote server directly cutting latency saving bandwidth 
analogous understanding system dispense web transfer entirely 
comparable sophisticated get modified mechanism channel returns parts packet document sent channel 

implementation describe implementation redundancy analysis engine terms design selection operational parameters performance 
design implemented analysis engine user level process running pc processes trace le outputs statistics redundancy 
design straightforward realization algorithm described section features chose base modular arithmetic performed algorithm suciently large ensure ngerprint collisions range memory sizes implies lower performance ngerprint calculations bit machines 
chose factor computing rabin ngerprint large prime 
simple rst rst policy packets manage packet store 
clever implementations improve redundancy detect admission policy treats di erent types data di erently eviction policy holds referenced packets cache longer screening avoid multiple copies content 
index maps ngerprint packet cache simplicity performance 
strip packet headers including udp tcp searching redundancy 
required analysis improves eciency headers typically repetitive 
ective schemes exist compressing tcp headers 
part computing number redundant bytes charge match region small penalty intended represent space needed encode transmission 
felt penalty important ultimately detect redundancy observing short combination bytes repeated 
penalty bytes ample encode ngerprint plus description matched range 
description consists set ngerprint packet count redundant bytes encoded bit integers sucient internet datagrams 
practice penalty small ect percent overhead average match region hundreds bytes long 
algorithm parameters rst task faced implementation complete determine remaining algorithm parameters 
recall determines fraction average byte savings ect redundancy 
bits bytes subsequent experiments 
ngerprints selected determines minimum width match regions 
concerned choice large large regions matched increases average quality matches decreases potential byte savings detected 
small average quality matches sacri ced shorter matches may better longer matches 
tradeo terms frequently packet sampled increase likelihood nding match packet cut memory available storing packets 
practice tradeo problematic 
shows amount redundancy trace data di erent values 
trace data described section 
small ective limit values choose due performance considerations discussed subsection 
chose bytes bits subsequent experiments 
setting results memory consumption split roughly index packet cache nds close maximum redundancy 
proportion index may large indexing comprehensive order useful 
performance gauge approximate performance expect practice measured throughput implementation range parameter settings 
done dual processor pentium iii gb memory running linux 
second processor negligible ect processor analysis 
throughput measured number packet payload bytes trace data processed second cpu accounted time reported unix time utility 
shows throughput function cache mb 
computational load increases decrease ngerprints computed indexed representative 
clear large possible performance issue falls size index grows exponentially degrades performance mbps throughput mbytes cpu second throughput function di erent values cache size xed megabytes 
memory size megabytes mbps throughput mbytes cpu second throughput function cache size 
interrupting process reducing memory locality operations 
shows throughput function memory size 
bytes bits parameters selected experiments throughput mbps mbps rates 
throughput falls memory size especially sizes mb presumably due memory cache behavior 
expect little locality access index randomizing ect ngerprints 
results suggest reasonable performance obtained modest ort 
system sucient network interface memory performance speeds readily achievable better tuned kernel implementations 

traffic analysis section results trace analysis redundancy network trac 
compare redundancy protocol independent technique alternative approaches web proxy caching packet compression 
nd high level redundancy especially web trac redundancy adequately exploited alternative approaches 
trace data trace data analyze comes corporate research environment consisting roughly users handful web servers 
traces include packets exchanged site rest internet network connecting border router rewall gateways region commonly called 
best knowledge web proxy caches site 
mix online ine analysis 
analyze data online possible order process large volume trac 
online analysis limited available computation memory monitoring system 
user ine analysis shorter volume trac insucient resources online analysis 
analyze traces ine analysis 
traces taken tuesday november th thursday november th am pm eastern standard time hour 
intent capture representative sample despite variation time day day week 
trace machine lose packets capture 
total analyze packets gb data 
limit current analysis capability save process entire packets just headers 
amount redundancy rst question considered amount repetitive data embedded traces 
function size cache 
recall cache memory divided packet storage ngerprint index portions 
include portions describing required memory size 
recall calculate amount redundancy match region small penalty bytes needed describe real system prevents ultimately claiming redundancy byte seen previously 
nd third trac redundant 
results incoming trac outgoing trac di er shown 
class trac signi cant redundancy relatively little memory mb 
redundancy increases better logarithmically memory size mb 
outgoing trac twice redundant incoming trac mb memory 
corresponds working set site web servers 
incoming trac diverse rising redundancy mb memory 
appears redundancy observed systems memory available disk packet store 
results memory size mb line mb line analyses 
redundancy protocol narrow source type redundancy classi ed trac di erent protocols calculated amount redundancy protocol 
done known ports matching source destination port 
results shown table 
consider incoming trac mb cache 
memory size megabytes byte savings memory size megabytes byte savings redundancy function total memory allocated 
incoming trac top outgoing trac bottom separated 
bulk trac web agreeing common perception 
exclude cacheable web responses nd trac highly repetitive redundant 
web trac signi cant fraction remaining trac streaming media delivered protocols developed real networks microsoft 
trac mildly redundant 
cant trac contributors surprisingly redundant 
particular telnet lotus notes redundant respectively 
note signi cant amount trac redundancy categorized carried high numbered ports able associate known services 
peak traffic periods ective redundancy suppression engine peak usage times 
trac redundant clients 
fast link operating capacity appear enhanced redundancy suppression 
answer related questions output number redundant bytes total number payload bytes minutes months february april 
cache size bytes machine mb analysis 
shows fraction trac redundant function trac rate 
draw media type protocol ports trac byte byte savings web service real streaming media rtsp music transfer napster lotus notes lotus secure web https file transfer ftp data usenet news nntp name service dns microsoft media asf aol aol name service smtp mail receipt pop remote terminal telnet unknown table redundant incoming trac protocol sorted decreasing order trac contribution 
volume incoming trac excluding cached proxy cache gb 
web service includes incoming requests uncached incoming responses 
traffic rate megabits second byte savings percentage redundant trac vary link utilization 
results 
redundant fraction minute periods extend 
periods lesser activity practical 
peak times fewer clients active cache split fewer clients 
believe implies performance system scale additional clients additional cache memory 
second notice redundancy generally stays relatively high link utilization 
combination web caching compare approach web caching studied web trac removed proxy cache deployed 
number reasons documents may cached addition cache misses example protect user privacy ensure page fresh 
motivations expressed set rules squid proxy cache 
request characteristics document uncacheable question object name includes 
cgi object name includes cgi bin 
cache control request includes cache control header private cache store 
method request get head 
pragma request request includes pragma cache header 
authorization auth request header includes authorization header access control 
older caching proxies cache responses requests included cookies 
squid version cache responses consider requests include cookies uncacheable 
addition response may uncacheable properties cache control response header includes cache control header prohibits caching 
pragma response response includes pragma cache header 
set cookie response attempts set cookie client 
response status response status code prohibits caching temporary redirect unauthorized 
push content type suggests server may continuously stream data client 
analysis incoming response classi ed cached cacheable cached uncacheable 
packets responses cached passed redundancy suppression engine 
document trac volume redundancy type total bytes category cached web uncached web cacheable uncacheable table summary web document 
documents cached cacheable consisting cache misses uncacheable consisting responses cached 
total web trac observed consisted gb requests 
reason trac volume redundant uncacheable total bytes category question method cgi cache control pragma response pragma request set cookie authorization response status push table summary redundancy uncacheable documents reason 
total web trac observed consisted gb requests 
ngerprints cacheable object names inserted entry list held accessed order 
average size web document kb roughly simulates mb web cache 
smaller cache simulate limit analysis system 
documents uncacheable tagged uncacheable attributes 
may tagged cgi bin appear request 
analysis ran mb redundancy suppression cache may may 
summary byte savings cached uncacheable cacheable missed proxy cache documents table 
table presents byte savings class uncacheable document ordered volume trac represents 
uncacheable documents represent quarter bytes transferred 
tremendous amount redundancy responses include pragma cache header little redundancy responses authorization necessary 
requests responses identi ed examining packet headers consideration source destination port numbers volume trac agree table 
percentage repeated content object object prefix server common property redundant match characteristics new old packets share 
total volume repeated content gb 
locality redundancy section attempt determine toend solution appropriate suppressing redundancy 
signi cant redundancy streams originating di erent servers 
solution network paired caches describe section appropriate protect slow link 
solution network little bene solution 
answer question redundant string bytes nd consider various attributes newly arrived packet stored packet match responses 
server source ip addresses match completely redundancy server addressed server proxy system 
object pre known object requested text requested objects match 
consider object pre match 
comparison various approaches leverage matching object pre xes nd redundancy 
object holds rest object name matches consider redundancy local object 
includes repeated transfers object similarity single transfer object 
scope locality summarized 
total redundancy line web trac represented axis bar represents number bytes matching packets similar sources 
suggests solution capture bulk redundancy 
redundant trac generally time server bene looking redundancy server trac small 
demonstrates solutions seek similarity transfers documents name signi cant source additional redundancy 
server proxy content solution detect signi cant redundancy name cache 
caching compression algorithm byte savings web proxy zlib packet compression web proxy zlib compression redundancy suppression web proxy redundancy suppression table average byte savings line traces di erent approaches cache size bytes 
clients anonymous correlate redundancy destination compare server proxy system server client system 
expect locality client requests server responses system advantageous 
comparison packet compression compare value technique traditional compression algorithms packet compression tool redundancy analysis 
lacking standard packet level scheme widespread elected individually compress packet payload zlib compression library library gzip utility point 
compression able reduce line traces average half average gain works independently web caching 
experience form compression compute intensive technique 
earlier experiments demonstrate compression taps di erent source redundancy algorithm 
gzip implementation searches history window kb looking repeated sequences compress 
results show technique nds increasing amounts redundancy memory sizes mb range gzip 
combination zlib caching web proxy line traces able eliminate bytes trace 
encouraged orthogonality web proxy zlib 
combining relative orthogonality zlib compression packet caching described expect integrated solution web proxy cache eliminate requests redundancy suppression remove long term repetition zlib compress individual packets signi cantly improve performance low bandwidth links 
summary section supported belief redundancy suppression technique complements web proxy caching traditional content compression 
line byte reductions approach shown table 
web proxy eliminates bytes 
small appear solely artifact short time scale traces proxy cache hit rates cited terms documents bytes 
fact web proxy hit rate document observe approaches 
compression yields similar bene ts operates independently caching 
redundancy suppression provides greater bene ts captured proxy caching 
result believe technique complements web caching traditional packet compression taps distinct source repetition 
url proxy caching advantage service requests incurring latency communication remote server 
technique nds content matches web caching 
information readily reduce bandwidth requirements implication latency 

related previous targeted reducing web related bandwidth requirements 
omit general discussion web caching data compression brevity compared technique previous section 
discuss prior approaches similar 
delta encoding delta encoding proposed studied mogul motivated observation pages updated changed minor ways 
ecient transfer changes variant get modi ed supports versions 
conceptually main di erence delta encoding di erences versions single document technique able eciently identify di erences documents 
expect technique nd strictly repetition 
evidence support belief seen signi cantly redundancy available server url 
duplicate suppression duplicate suppression involves identifying suppressing transfer exact duplicates typically identi ed ngerprints 
mogul explored approach proposed document level santos explored packet level 
conceptually proposal extends duplicate suppression signi cant dimension look similar overlapping information identical duplicated information 
harder problem potentially greater bene ts 
evidence support claim 
parameter increased longer regions considered matching 
large values right side graph correspond packet matching equivalent packet level duplicate suppression 
apparent graph reduced twice redundancy 
data compare directly document level duplicate suppression reason believe results di erent 
mogul reports value duplicate suppression varies data type average low 

new technique nding redundancy network trac 
technique builds manber detect similar necessarily identical information transfers 
terms improving web performance potential exceed bene ts approaches delta coding duplicate suppression 
similarity algorithms include subset exact matches duplicate suppression di erences versions document delta coding 
distinguishing feature system protocol independent 
assumptions syntax semantics 
distinct advantages 
able identify ne grained sharing may common dynamically generated personalized pages inter protocol sharing 
need updated take advantage new types content streaming media emerge delivery protocols revised 
technique characterize redundancy network trac 
high degree repetition dynamically generated web documents roughly cgi question categories 
class documents server prohibited caching redundancy approaches 
uncached web documents redundancy originated di erent web servers 
redundancy server thirds objects name 
protocol analysis byte savings ranging di erent protocols savings protocols unable identify 
sources redundancy detected web caches exploited improve performance 
step face build complete system uses technique conjunction web caching 
experience implementation far convinced basic algorithm suited online network web infrastructure 
certainly su ciently fast nd applications untuned user level prototype run approximately mbps pc hardware 
speculate increasingly large amounts memory protocol independent caching may applied bandwidth constrained links routinely known technique trade memory bandwidth 

wish alec wolman maureen help analysis software 
srinivasan seshan vern paxson assistance 
udi manber furnished source si described 
je mogul kept giving credit section 
bartels stefan savage mike swift tom anderson hank levy anonymous reviewers provided helpful feedback greatly improved quality 
research supported part darpa 
neil spring partially supported hunter simpson fellowship arcs foundation 

squid web proxy cache 
www squid cache org 
national institute standards technology speci cations secure hash standard april 
federal information processing standards publication 
broder 
resemblance containment documents 
proceedings compression complexity sequences sequences pages march 
caceres douglis feldmann glass rabinovich 
web proxy caching devil details 
proceedings workshop internet server performance june 
caida 
trac workload overview 
www caida org learn flow html june 
cla miller thompson 
nature beast trac measurements internet backbone 
proceedings inet july 
feldmann caceres douglis glass rabinovich 
performance web proxy caching heterogeneous bandwidth environments 
proceedings ieee infocom may 
fielding gettys mogul frystyk masinter leach berners lee 
hypertext transfer protocol june 
networking working group requests comment rfc 

system optimizing web browsing wireless environment 
proc 
nd annual intl 
conf 
mobile computing networking pages new york november 
acm 
www networking ibm com art htm 
jacobson 
compressing tcp ip headers low speed serial links february 
rfc 
manber 
finding similar les large le system 
proceedings usenix winter technical conference january 
mogul 
trace analysis duplicate suppression 
technical report compaq computer western research laboratory november 
available www research 
digital com wrl techreports abstracts html 
mogul douglis feldmann krishnamurthy 
potential bene ts delta encoding data compression 
technical report compaq computer july 
available www research digital com wrl techreports abstracts html 
rabin 
fingerprinting random polynomials 
technical report tr department computer science harvard university 
rivest 
md message digest algorithm 
networking working group requests comment mit laboratory computer science rsa data security rfc 
santos wetherall 
increasing ective link bandwidth suppressing replicated data 
proceedings usenix annual technical conference 
thompson miller wilder 
wide area internet trac patterns characteristics 
ieee network nov 
van ho carter medin 
distribution replication protocol 
technical report note drp world wide web consortium august 
www org tr note drp html 
wolman voelker sharma cardwell brown karlin levy 
organization analysis web object sharing caching 
proceedings second usenix symposium internet technologies systems usits pages october 
wolman voelker sharma cardwell karlin levy 
scale performance cooperative web proxy caching 
proceedings th acm symposium operating systems principles sosp pages december 
