evolutionary ensembles negative correlation learning yong liu university aizu aizu fukushima japan email aizu ac jp xin yao school computer science university birmingham birmingham tt email yao cs bham ac uk higuchi evolvable systems laboratory computer science division mbox electrotechnical laboratory tsukuba ibaraki japan email higuchi etl go jp negative correlation learning evolutionary learning presents evolutionary ensembles negative correlation learning eencl address issues automatic determination number individual neural networks nns ensemble exploitation interaction individual nn design combination 
idea eencl encourage different individual nns ensemble learn different parts aspects training data ensemble better learn entire training data 
cooperation specialization different individual nns considered individual nn design 
provides opportunity different nns interact specialize 
experiments real world problems demonstrate eencl produce nn ensembles generalization ability 
real world problems large complex single monolithic system solve 
examples natural artificial systems show integrated system consisting subsystems reduce total complexity system solving difficult problem satisfactorily 
success neural network nn ensembles improving classifier generalization typical example 
nn ensembles adopt divide conquer strategy 
single network solve task nn ensemble combines set nns learns subdivide task solve efficiently elegantly 
nn ensemble offers advantages monolithic nn 
perform complex tasks components individual nns ensemble 
second system easier understand modify 
robust monolithic nn show graceful performance degradation situations subset nns ensemble performing correctly 
advantages nn ensembles complexity problems investigated clear nn ensemble method important pervasive problem solving technique 
designing nn ensembles difficult task 
relies heavily human experts prior knowledge problem 
idea designing ensemble learning system consisting subsystems traced back early 
early algorithms similar ideas developed different related forms nn ensembles mixtures experts various boosting bagging methods 
algorithms rely manual design design individual nns division training data 
number individual nns ensemble system predefined fixed human experience prior knowledge problem solved 
generally unclear subtasks performed nns 
case speech image processing tasks task decomposition done manually 
manual design fixed ensemble architecture may appropriate experienced human experts sufficient prior knowledge problem solved certainly case real world problems prior knowledge 
tedious trial error processes involved designing nn ensembles practice 
presents evolutionary ensembles negative correlation learning eencl designing nn ensembles automatically negative correlation learning evolutionary learning 
eencl differs previous designing nn ensembles major aspects 
previous acknowledge exploit negative correlation individual nns ensemble driving force control problem solving activity 
individual nns trained independently sequentially 
disadvantages approach loss interaction individual networks learning 
eencl emphasizes specialization cooperation individual nns ensemble 
eencl evolutionary algorithm evolutionary programming search population diverse individual nns solve problem classify examples 
maintain diverse population applying selection operator evolutionary algorithm incorporate kind speciation technique individuals population form species automatically evolution 
fitness sharing negative correlation learning encourage formation different species 
fitness sharing refers class speciation techniques evolutionary computation 
idea negative correlation learning encourage different individual networks ensemble learn different parts aspects training data ensemble better learn entire training data 
negative correlation learning individual networks trained simultaneously independently sequentially 
provides opportunity individual networks interact specialize 
negative correlation learning create negatively correlated nns correlation penalty term error function encourage specialization 
second previous separated design individual nns combination procedures stage design process generating individual nns combining 
possible interactions exploited combination stage 
feedback combination stage individual nn design stage 
possible independently designed individual nns contribution system 
contrast negative correlation learning learns combines individual nns process 
provides opportunity different nns interact specialize 
approach resemble negative correlation learning mixtures experts architectures 
negative correlation learning different architecture consists gating network number expert networks architecture produce biased individual networks estimates negatively correlated 
negative correlation learning need separate gating network 
uses totally different error functions 
strength parameter negative correlation learning provides convenient way balance bias variance covariance trade 
architecture provide control trade 
third number nns ensemble predefined fixed previous 
usually number nns determined manually trial error process 
eencl number nns ensemble predefined determined number species formed automatically evolution 
rest organized follows section gives ideas evolutionary learning design nn ensembles section describes eencl detail section presents experimental results eencl discussions section concludes summary remarks 
evolutionary learning evolutionary learning population learning method 
minimize error functions robust global search capability compared gradient algorithms 
incorporate nn weight learning structure learning learning process 
epnet evolutionary learning system designing feedforward nns 
essence evolutionary learning kind global optimization algorithm 
common best individual individual smallest error selected output evolution 
consideration individuals population 
unfortunately nn smallest training error may nn best generalization 
little learning opportunities improving population evolutionary learning 
best individual learning individual best generalization individuals population better contain useful information 
ensemble system combines entire population expected better generalization single individual 
combining individual nns population nn ensemble close relationship design nn ensembles 
population nns regarded ensemble 
evolutionary process regarded natural automatic way design nn ensembles 
tested idea form final result combining individuals generation 
interaction individual nn design combination considered ensemble size fixed 
evolving neural network ensembles eencl studied address issues exploitation interaction individual nn design combination automatic determination number individual nns 
eencl evolutionary algorithm evolutionary programming search population diverse individual nns solve problem 
maintain diverse population fitness sharing negative correlation learning encourage formation different species 
current implementation eencl nn ensemble feedforward nn logistic transfer functions 
major steps eencl follows 
generate initial population nns set 
number hidden nodes nn specified user 
random initial weights distributed uniformly inside small range 

train nn initial population training set certain number epochs negative correlation learning 
number epochs specified user 

randomly choose group nns parents create offspring nns gaussian mutation 

add offspring nns population train offspring nns negative correlation learning remaining nns weights frozen 

calculate fitness nns population prune population fittest nns 

go step maximum number generations reached 
go step 
form species means algorithm 

combining species form ensembles 
levels adaptation eencl negative correlation learning individual level evolutionary learning evolutionary programming ep population level 
details component eencl sections 
negative correlation learning suppose training set delta delta delta scalar size training set 
assumption output scalar merely simplify exposition ideas loss generality 
section considers estimating forming ensemble output simple averaging outputs set neural networks sigma number individual neural networks ensemble output network nth training pattern output ensemble nth training pattern 
negative correlation learning introduces correlation penalty term error function individual network ensemble networks trained simultaneously interactively training data set error function network negative correlation learning defined sigma sigma gamma sigma value error function network presentation nth training pattern 
term right side eq empirical risk function network second term correlation penalty function 
purpose minimizing negatively correlate network error errors rest ensemble 
parameter adjust strength penalty 
penalty function form gamma sigma gamma partial derivative respect output network nth training pattern gamma gamma sigma gamma gamma gamma gamma gamma gamma gamma assumption constant value respect 
standard back propagation bp algorithm weight adjustments mode pattern pattern updating 
weight updating individual networks performed simultaneously eq presentation training pattern 
complete presentation entire training set learning process called epoch 
negative correlation learning eq simple extension standard bp algorithm 
fact modification needed calculate extra term form gamma ith network 
eqs may observations 
training process individual networks interact penalty terms error functions 
network minimizes difference difference 
negative correlation learning considers errors networks learned training network 

correlation penalty terms error functions individual networks individual networks just trained independently 
independent training individual networks special case negative correlation learning 

eq get gamma note empirical risk function ensemble nth training pattern defined ens sigma gamma partial derivative ens respect nth training pattern ens sigma gamma gamma case get ens minimization empirical risk function ensemble achieved minimizing error functions individual networks 
point view negative correlation learning provides novel way decompose learning task ensemble number subtasks different individual networks 
fitness evaluation fitness evaluation eencl carried fitness sharing 
explicit implicit fitness sharing proposed encourage speciation years 
fitness sharing accomplishes speciation degrading raw fitness unshared fitness individual presence similar individuals 
type speciation requires distance metric phenotype genotype space individuals 
traditionally measurement hamming distance binary strings 
sharing scheme suitable eencl individual networks represented binary strings eencl 
fitness sharing eencl idea covering training patterns shared individuals 
procedure calculating shared fitness carried pattern pattern training set 
training pattern learned correctly individuals population individuals receives fitness rest individuals population receive zero fitness 
individuals population receive zero fitness 
fitness summed training patterns 
fitness evaluation encourages individual population cover different patterns training set 
selection mechanism replacement strategy different selection mechanisms roulette wheel selection rank selection select individuals reproduce evolutionary algorithms 
selection mechanisms encourage algorithm quickly find best individual 
eencl individual selected mutated equal probability 
reflects emphasis eencl evolving diverse set individuals 
mutation individuals population evaluated sorted 
fittest individuals selected replace current population 
mutation mutation eencl carried steps weight mutation weight training 
step selected parent networks create offspring weight mutation ij ij ij ij denote weights offspring parent respectively delta delta delta index number weights 
denotes gaussian random variable mean zero standard deviation 
second step offspring nns added population indexed offspring nns trained negative correlation learning weights remaining nns population frozen 
error function offspring nn defined sigma gamma gamma sigma gamma delta delta delta number training patterns output individual network nth training pattern desired output nth training pattern sigma fm 
error function uses feedback current population guide learning offspring 
forming ensembles population nns generated evolutionary process 
direct method individual nns population form ensemble 
interesting investigate individual nns generation useful forming ensemble 
size ensemble reduced worsening performance 
methods constructing nn ensembles tested eencl 
individual nns generation selected representative species generation 
species population determined clustering individuals population means algorithm 
resulting clusters correspond different species 
representative species fittest individual species 
output nodes nn number classes classification problem 
nn output training patterns forms theta dimensional vector 
output vectors om delta delta delta individual nns means algorithm classifies determined user advance different clusters 
algorithm proceeds follows 
choose set cluster centers fc delta delta delta arbitrarily 

om delta delta delta assign om cluster minimum euclidean distance rule om belongs cluster kom gamma kom gamma 
compute new cluster centers minimize cost function ko gamma 
cluster center changes return step 
combination methods combination methods determining output ensemble investigated eencl 
simple averaging 
output ensemble formed simple averaging output individual nns ensemble 
second majority voting 
output greatest number individual nns output ensemble 
tie output ensemble rejected 
third winner takes 
pattern testing set output ensemble decided individual nn output highest activation 
experimental studies applied eencl benchmark problems australian credit card assessment problem diabetes problem 
data sets obtained uci machine learning benchmark repository 
available anonymous ftp ics uci edu directory pub machine learning databases 
australian credit card assessment problem assess applications credit cards number attributes 
patterns total 
output classes 
attributes include numeric values discrete ones having possible values 
diabetes data set class problem examples class class 
attributes example 
data set difficult classify 
called class value really form attribute highly indicative certain types diabetes correspondence medical condition 
order compare eencl previous experimental setup previous experimental setup described 
fold cross validation technique divide data randomly mutually exclusive data groups equal size 
train process data group selected testing set gamma groups training set 
estimated error rate average error rate groups 
way error rate estimated efficiently unbiased way 
parameter set australian credit card data set diabetes data set respectively 
parameters eencl set problems population size number generations reproduction block size strength parameter number training epochs minimum number cluster sets maximum number cluster sets 
nns population multilayer perceptrons hidden layer hidden nodes 
parameters selected preliminary experiments 
meant optimal 
experimental results population ensemble tables show results eencl data sets ensembles constructed population generation 
accuracy rate refers percentage correct classifications produced eencl 
comparison accuracy rates obtained combination methods winner takes outperformed simple averaging majority voting problems 
simple averaging majority voting individuals treated equally 
individuals equally important 
different individuals created eencl able specialize different parts testing set outputs specialists considered final decision ensemble part testing set 
combination method performed better poor individuals pattern testing set winner takes selects best individual 
simple averaging majority voting winner takes accuracy rate training testing training testing training testing mean sd min max table accuracy rates eencl australian credit card data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
subset population ensemble previous implementation eencl individuals generation ensembles 
interesting investigate reduce size ensembles selecting representative individuals population 
investigation provide hints individuals generation contain useful information 
means algorithm divide individuals population different clusters 
cluster corresponds species 
species construct nn ensemble representative species selected combination 
representative species fittest individual species 
simple averaging majority voting winner takes accuracy rate training testing training testing training testing mean sd min max table accuracy rates eencl diabetes data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
number species number clusters starts population size 
optimal number species determined measuring performance constructed ensembles training set 
accuracy rate chosen measure performance 
results ensemble formed representatives species table 
combination method winner takes 
test statistics comparing accuracies ensembles representatives species ensembles population australian credit card data set gamma diabetes data set 
statistically significance difference observed data sets implies ensemble population achieve performance 
size ensemble substantially smaller population size 
reduction size ensembles seen table gives sizes ensembles representatives species 
comparisons direct comparison evolutionary approaches designing ensembles difficult due lack results 
best latest results available literature regardless algorithm evolutionary bp statistical comparison 
tables compare results eencl including results ensembles population ensembles representatives species produced algorithms tested michie 
algorithms categorized groups statistical algorithms discrim smart alloc nn castle default decision trees cart newid ac cal rule card diabetes accuracy rate training testing training testing mean sd min max table accuracy rates ensemble formed representatives species 
results averaged fold cross validation australian credit card data set fold crossvalidation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
size ensembles mean sd min max card diabetes table sizes ensembles representatives species 
results averaged fold cross validation australian credit card data set fold cross validation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
methods cn neural networks backprop kohonen lvq rbf 
details algorithms appear 
eencl data setup fold cross validation australian credit card data set fold cross validation diabetes data set 
error rate refers percentage wrong classifications testing set 
ensembles population winner takes combination method average testing accuracy rates eencl respectively australian credit card data set diabetes data set 
accordingly average testing error rates respectively 
ensembles representatives species similarly get average testing error rates eencl table data sets 
respectively australian credit card data set diabetes data set 
demonstrated results eencl able achieve generalization performance comparable better best algorithms tested australian credit card data set diabetes data set 
algorithm error rate algorithm error rate algorithm error rate eencl cart discrim cal newid kohonen fd ac smart backprop alloc rbf nn cn lvq castle default table comparison eencl terms average testing error rate australian credit card data set 
results averaged fold cross validation fd indicates kohonen algorithm failed data set 
error rates listed eencl results ensembles population ensembles representatives species 
introduces eencl learning designing nn ensembles 
negative correlation learning fitness sharing adopted encourage formation species population 
sense eencl provides automatic way designing nn ensembles nn algorithm error rate algorithm error rate algorithm error rate eencl cart discrim cal newid kohonen ac smart backprop alloc rbf nn cn lvq castle table comparison eencl terms average testing error rate diabetes data set 
results averaged fold cross validation 
error rates listed eencl results ensembles population ensembles representatives species 
individual representative species population 
eencl tested australian credit card assessment problem diabetes problem 
competitive results produced eencl comparison algorithms 
rosen proposed ensemble learning algorithm decorrelated nns 
idea individual networks attempt minimize error target output decorrelate errors networks trained previously 
rosen algorithm trains individual networks sequentially 
major disadvantage algorithm training network ensemble affect networks trained previously ensemble errors individual networks necessarily negatively correlated 
negative correlation learning extends rosen simultaneous training negatively correlated nns 
extension produced significant improvement nn ensembles performance 
negatively correlated nns obtained negative correlation learning 
architecture nn ensemble predefined current implementation eencl 
improvements eencl evolve architectures nns epnet 
improvement form ensemble output linear combination individual nn outputs linear combination weights evolve nn ensembles order exploit interaction nns combined output 
authors grateful anonymous referees dr david fogel constructive comments criticism helped improve 
yao liu 
making population information evolutionary artificial neural networks 
ieee trans 
systems man cybernetics part cybernetics 
sharkey 
combining artificial neural nets 
connection science 
selfridge 
pandemonium paradigm learning 
mechanisation thought processes proc 
symp 
held national physical lab pages 
london 
nilsson 
learning machines foundations trainable pattern classifying systems 
ny mcgraw hill new york 
hansen salamon 
neural network ensembles 
ieee trans 
pattern analysis machine intelligence 
jacobs jordan nowlan hinton 
adaptive mixtures local experts 
neural computation 
jacobs jordan 
competitive modular connectionist architecture 
lippmann moody touretzky editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
jacobs jordan barto 
task decomposition competition modular connectionist architecture vision task 
cognitive science 
jacobs 
bias variance analyses mixture experts architectures 
neural computation 
drucker cortes jackel lecun vapnik 
boosting ensemble methods 
neural computation 
schapire 
strength weak learnability 
machine learning 
drucker schapire simard 
improving performance neural networks boosting algorithm 
hanson cowan giles editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
liu yao 
negatively correlated neural networks produce best ensembles 
australian journal intelligent information processing systems 
liu yao 
cooperative ensemble learning system 
proc 
ieee international joint conference neural networks ijcnn pages 
ieee press piscataway nj usa 
liu yao 
simultaneous training negatively correlated neural networks ensemble 
ieee trans 
systems man cybernetics part cybernetics 
yao liu 
new evolutionary system evolving artificial neural networks 
ieee trans 
neural networks 
liu yao 
designing neural network ensembles evolution 
parallel problem solving nature ppsn proc 
fifth international conference parallel problem solving nature volume lecture notes computer science pages 
springer verlag berlin 
fogel 
evolutionary computation new philosophy machine intelligence 
ieee press new york ny 
horn goldberg deb 
implicit niching learning classifier system nature way 
evolutionary computation 
darwen yao 
automatic modularization speciation 
proc 
ieee int conf 
evolutionary computation icec nagoya japan pages 
ieee press new york ny 
darwen yao 
niching method niche fitness sharing implicit sharing compared 

voigt ebeling rechenberg 
schwefel editors parallel problem solving nature ppsn iv volume lecture notes computer science pages 
springer verlag berlin 
yao liu darwen 
best evolutionary learning 
jelinek editors complex systems local interactions global phenomena pages 
ios press amsterdam 
goldberg 
genetic algorithms search optimization machine learning 
addison wesley reading ma 
jordan jacobs 
hierarchical mixtures experts em algorithm 
neural computation 
rumelhart hinton williams 
learning internal representations error propagation 
rumelhart mcclelland editors parallel distributed processing explorations cognition vol 
pages 
mit press cambridge ma 
mahfoud 
niching methods genetic algorithms 
phd thesis university illinois urbana champaign 
darwen yao 
speciation automatic categorical modularization 
ieee trans 
evolutionary computation 
macqueen 
methods classification analysis multivariate observation 
proc 
th symposium mathematical statistics probability volume pages 
university california press 
michie spiegelhalter taylor 
machine learning neural statistical classification 
ellis horwood limited london 
stone 
cross choice assessment statistical predictions 
journal royal statistical society 
rosen 
ensemble learning decorrelated neural networks 
connection science 
table captions table accuracy rates eencl australian credit card data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
tables accuracy rates eencl diabetes data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
table accuracy rates ensemble formed representatives species 
results averaged fold cross validation australian credit card data set fold crossvalidation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
table sizes ensembles representatives species 
results averaged fold cross validation australian credit card data set fold cross validation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
table comparison eencl terms average testing error rate australian credit card data set 
results averaged fold cross validation fd indicates kohonen algorithm failed data set 
error rates listed eencl results ensembles population ensembles representatives species 
table comparison eencl terms average testing error rate diabetes data set 
results averaged fold cross validation 
error rates listed eencl results ensembles population ensembles representatives species 
tables individual pages simple averaging majority voting winner takes accuracy rate training testing training testing training testing mean sd min max table accuracy rates eencl australian credit card data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
simple averaging majority voting winner takes accuracy rate training testing training testing training testing mean sd min max table accuracy rates eencl diabetes data set 
results averaged fold cross validation 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
card diabetes accuracy rate training testing training testing mean sd min max table accuracy rates ensemble formed representatives species 
results averaged fold cross validation australian credit card data set fold crossvalidation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
size ensembles mean sd min max card diabetes table sizes ensembles representatives species 
results averaged fold cross validation australian credit card data set fold cross validation diabetes data set 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
algorithm error rate algorithm error rate algorithm error rate eencl cart discrim cal newid kohonen fd ac smart backprop alloc rbf nn cn lvq castle default table comparison eencl terms average testing error rate australian credit card data set 
results averaged fold cross validation fd indicates kohonen algorithm failed data set 
error rates listed eencl results ensembles population ensembles representatives species 
algorithm error rate algorithm error rate algorithm error rate eencl cart discrim cal newid kohonen ac smart backprop alloc rbf nn cn lvq castle table comparison eencl terms average testing error rate diabetes data set 
results averaged fold cross validation 
error rates listed eencl results ensembles population ensembles representatives species 

