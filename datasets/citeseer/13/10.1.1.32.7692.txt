course notes reinforcement learning richard sutton andrew barto fl rights reserved try give basic intuitive sense reinforcement learning differs relates fields supervised learning neural networks genetic algorithms artificial life control theory 
intuitively rl trial error variation selection search plus learning association memory 
argue rl field seriously addresses special features problem learning interaction achieve long term goals 
learning interaction idea learn interacting environment probably occur think nature learning 
infant plays waves arms looks explicit teacher direct sensorimotor connection environment 
exercising connection produces wealth information cause effect consequences actions order achieve goals 
interaction undoubtedly major contributor infant developing sense environment role 
experience remains powerful teacher infant grows child adult nature interaction changes significantly time 
learning drive car hold conversation acutely aware environment responds seek influence behavior 
learning interaction foundational idea underlying nearly theories learning 
reinforcement learning computational approach study learning interaction 
decade seen study reinforcement learning develop unusually multi disciplinary field includes researchers specializing artificial intelligence psychology control engineering operations research neuroscience artificial neural networks genetic algorithms 
reinforcement learning particularly rich roots psychology animal learning takes name 
number impressive applications reinforcement learning developed 
growing interest reinforcement learning fueled part challenge designing intelligent systems operate dynamic real world environments 
example making robots robotic agents autonomous reliant carefully controlled conditions requires decision making methods effective presence uncertainty meet time constraints 
conditions learning essential achieving skilled behavior conditions reinforcement learning significant advantages types learning 
develop reinforcement learning point view artificial intelligence ai engineering 
reinforcement learning developed respect psychology neuroscience 
perspective reinforcement learning corresponds particular mathematical formulation problem learning interaction 
examine problem carefully explore algorithms solving proposed different disciplines 
presenting algorithms single perspective unified notation try easy see different methods relate combined profitably 
surprisingly algorithms understood various combinations underlying principles 
surprising outcome modern view reinforcement learning close relationship reveals learning planning planning mean deciding course action considering possible situations experienced 
earliest simplest reinforcement learning algorithms possible learn directly environmental interaction having consider situations experienced 
type reinforcement learning system achieve highly skilled behavior having ability predict environment behave response actions having sort model environment 
opposite planning 
complex forms reinforcement learning devised closely related computational methods known dynamic programming take advantage environment models methods closely related state space planning methods artificial intelligence 
today clear reinforcement learning various forms applied planning problem significant advantages conventional planning methods 
examples way introduce reinforcement learning consider examples possible applications guided development ffl master chess player move 
choice informed planning anticipating possible replies counter replies immediate intuitive judgements desirability particular positions moves 
ffl adaptive controller adjusts parameters petroleum refinery operation real time 
controller optimizes yield cost quality tradeoff specified marginal costs sticking strictly set points originally suggested human engineers 
ffl gazelle calf feet minutes born 
half hour running miles hour 
ffl phil prepares breakfast 
closely examined apparently mundane activity reveals complex web conditional behavior interlocking goal subgoal relationships walking opening selecting cereal box reaching grasping retrieving 
complex tuned interactive sequences behavior required obtain bowl spoon milk jug 
step involves series eye movements obtain information guide reaching locomotion 
rapid judgements continually carry objects better ferry dining table obtaining 
step guided goals grasping spoon getting refrigerator service goals having spoon eat cereal prepared ultimately obtaining 
ffl mobile robot decides enter new room search trash collect start trying find way back battery recharging station 
decision quickly easily able find past 
examples share features basic easy overlook 
involve interaction active decision making agent environment agent seeks achieve goal despite uncertainty environment 
agent actions permitted affect state environment chess position level refinery location robot affecting options opportunities available agent times 
correct choice requires account indirect delayed consequences actions may require foresight planning 
time effects actions fully predicted agent frequently monitor environment react appropriately 
example phil watch milk cereal bowl keep overflowing 
examples involve goals explicit sense agent judge progress goal basis directly sense 
chess player knows wins refinery controller knows petroleum produced mobile robot knows batteries run phil knows enjoying breakfast 
agent goals goals goals outside agent designer 
want reinforcement learning system engineering application improving yield petroleum refinery reinforcement learning system goals 
examples agent experience improve performance time 
chess player refines intuition uses evaluate positions improving play gazelle calf improves efficiency run phil learns streamline breakfast making 
level knowledge agent brings task start previous experience related tasks genetic programming influences useful easy learn interaction environment essential adjusting behavior exploit specific features task 
reinforcement learning reinforcement learning learning mapping situations actions maximizes scalar reward reinforcement signal 
learner need directly told actions forms machine learning discover actions yield reward trying 
interesting challenging cases action may affect immediate reward situation consequently subsequent rewards 
characteristics trial error search delayed reward important distinguishing characteristics reinforcement learning 
reinforcement learning algorithms require particular synergistic combination search memory 
search required find actions memory required remember actions worked situations past 
arises search provides information remembered memory search easier faster 
reinforcement learning involves systematic caching search results search efficient eliminated 
search memory key computational elements reinforcement learning algorithm best define reinforcement learning terms particular class learning problems particular algorithms 
algorithm suited solving problems consider reinforcement learning algorithm 
chapter precise formulation reinforcement learning problems drawing heavily mathematical definition markov decision process 
formulation allows take advantage great wealth existing mathematical theory primary intent provide fairly straightforward representation real problem facing learning agent interacting environment achieve goal achieve multiple goals 
clearly agent able sense information pertinent state environment able take actions affect state 
agent goal goals defined terms environment behaves time influence actions 
aspects sensation action goal building blocks theoretical framework book 
reinforcement learning different supervised learning kind learning studied current research machine learning statistical pattern recognition artificial neural networks 
supervised learning learning knowledgeable supervisor teacher explicitly tells learning agent respond training inputs 
kind learning provide important component complete learning systems adequate kind learning autonomous agents accomplish 
costly impossible obtain set examples desired behavior correct representative situations agent act 
territory expect learning beneficial agent able learn experiences knowledgeable teacher 
reinforcement learning agent take advantage knowledgeable instruction available primary source information feedback interaction environment 
challenges arises reinforcement learning kinds learning called tradeoff exploration exploitation 
obtain lot reward reinforcement learning agent prefer actions tried past effective producing reward 
discover actions select actions tried 
agent exploit knows order obtain reward explore order better action selections 
dilemma exploitation exploration pursued exclusively failing task 
agent try variety actions progressively favor appear best 
stochastic task action tried times reliably estimate expected reward 
exploration exploitation dilemma intensively studied mathematicians decades 
simply note entire issue balancing exploitation exploration arise supervised learning usually defined 
key feature reinforcement learning explicitly considers problem goal directed agent interacting uncertain environment 
contrast approaches address subproblems addressing fit larger picture 
example mentioned machine learning research concerned supervised learning explicitly specifying ability useful 
researchers developed theories planning general goals considering planning role real time decision making question predictive models necessary planning come 
approaches yielded useful results clear focus isolated subproblems significant limitation 
reinforcement learning takes opposite tack starting complete interactive goal seeking agent 
reinforcement learning agents explicit goals sense aspects environments choose actions influence environments 
usually assumed agent operate despite significant uncertainty environment faces 
reinforcement learning involves planning address interplay planning real time action selection question environmental models acquired improved 
reinforcement learning involves supervised learning specific reasons determine capabilities critical 
learning research progress important subproblems surely isolated studied subproblems motivated clear roles complete interactive goal seeking agents details complete agent filled 
components reinforcement learning agent reinforcement learning agent generally consists basic components policy reward function value function model environment 
policy decision making function agent specifying action takes situations encounter 
psychology correspond set stimulus response rules associations 
core reinforcement agent suggested sufficient define full behaving agent 
components serve change improve policy 
policy ultimate determinant behavior performance 
general may stochastic 
policy reward value model environment main components reinforcement learning agent 
reward function defines goal reinforcement learning agent 
agent objective maximize reward receives long run 
reward function defines bad events agent 
rewards immediate defining features problem faced agent 
reward function necessarily fixed 
may basis changing policy 
example action selected policy followed low reward policy may changed select action situation 
reward indicates immediate sense value function specifies long run predicts reward 
difference value reward critical reinforcement learning 
example playing chess opponent associated high reward winning queen associated high value 
defines true goal task winning game just predicts true goal 
learning value states state action pairs critical step reinforcement learning methods consider 
fourth final major component reinforcement learning agent model environment external world 
mimics behavior environment sense 
example situation action model predict resultant state reward 
model drawn largest component expect take storage space 
jsj states jaj actions complete model take space proportional size jsj theta jsj theta jaj maps state action pairs probability distributions states giving probability possible result state action taken state 
contrast reward value functions just map states real numbers size jsj stochastic policy size jsj theta jaj 
reinforcement learning agent uses model environment 
meth ods learn model called model free reinforcement learning methods 
model free methods simple surprisingly generally able find optimal behavior 
model methods just find faster fewer experiences 
interesting case agent perfect model environment priori learning methods align reality 
summary chapter sketched reasons growing numbers researchers paying attention reinforcement learning 
reinforcement learning focuses learning online normal interaction dynamic environment 
contrasts focus machine learning symbolic artificial neural network systems learn offline pre specified set training examples provided explicit knowledgeable teacher 
reinforcement learning system able take advantage knowledgeable teachers environment real source information experience 
machine learning systems learn 
appropriate call learned systems learning systems 
reinforcement learning way conceptual reinforcement learning learning system experience entire existence improve performance 
reinforcement learning uses formal framework defining interaction agent environment terms situations states actions rewards 
framework intended simple way representing essential features ai problem 
features include sense cause effect uncertainty nondeterminism existence explicit goals 
relevant formalism markov decision processes provides precise relatively neutral way including key features 
scratch surface theory allows take advantage related perspectives methods developed field stochastic optimal control 
concepts value value functions key features kinds reinforcement learning methods consider book 
take position value functions essential efficient search space policies 
value functions distinguish reinforcement learning methods conceptually simpler evolutionary methods search directly policy space guided scalar evaluations entire policies 
approach value functions enable algorithms take advantage details individual behavioral interactions 
evolutionary methods may provide useful results problems value function methods profitably tion way learning evolution nature believe applied reinforcement learning problems evolutionary methods inherently efficient value function methods 
takes estimation learning value functions key computational step question best 
book identify principle classes methods 
monte carlo methods estimate value state simply running trials starting state 
actual total rewards received trials averaged obtain estimate state value 
search methods dynamic programming heuristic search viewed straightforward model ways estimate value function 
temporal difference methods relatively new development learning states values values states follow actual trials 
book organized principle classes methods learning value functions totally different viewed members super family methods 
differences need pick mix match 
heart common operation called backup 
perform backups experience model backup wide set possible states 
backups different sizes shapes sources share common features contribute common computation 
bibliographical historical remarks provide necessarily abridged discussion history main ideas reinforcement learning 
specific term reinforcement learning psychologists roots reinforcement learning lie learning theories developed experimental psychologists century 
take far afield attempt overview reinforcement theories psychology available books 
concentrate best known early explorations computational power reinforcement learning trying obscure fact computational psychological perspectives hard distinguish 
finds terms reinforcement reinforcement learning engineering literature time minsky thesis 
minsky waltz fu waltz fu mendel mendel mendel 
terms refer general idea learning rewards punishments trial error learning actions followed bad outcomes respectively strengthened weakened 
early notion reinforcement learning exact mirror classical psychological principle thorndike law effect responses situation accompanied closely followed satisfaction animal things equal firmly connected situation recurs recur accompanied closely followed discomfort animal things equal connections situation weakened recurs occur 
greater satisfaction discomfort greater strengthening weakening bond 
principle generated considerable controversy psychology fields years see ref remains influential general idea supported experiments intuitive sense 
elementary obvious way combining search memory search form trying actions memory form remembering actions worked best 
dennett 
provides account continuing attractiveness law effect 
provides broad account utility methods law effect operate selectional opposed instructional principles 
earliest computational investigations law effect know minsky farley clark published 
ph dissertation minsky minsky describes construction analog machine stochastic neural analog reinforcement calculator designed learn trial error 
farley clark farley clark clark farley describe neural network learning machine noting ability generalize discussed terms supervised learning reinforcement learning 
began pattern confusion relationship types learning 
researchers believe studying reinforcement learning studying supervised learning confusion persists day 
modern neural network textbooks describe networks learn training examples trial error learning systems error information update connection weights 
understandable confusion misses selectional character learning law effect term trial error originally intended describe 
clear neural network pioneers rosenblatt rosenblatt widrow hoff widrow hoff psychologists bush mosteller bush mosteller thinking reinforcement learning language rewards punishments systems studied clearly supervised learning systems suitable pattern recognition perceptual learning direct interaction environment 
reinforcement learning gradually overshadowed lost distinct topic supervised learning particularly form pattern recognition widely studied 
discuss fine points transition including exceptions learning automata theory kiefer stochastic approximation methods chapter 
clear exceptions trend deserve mention 
described reinforcement learning machine called stella included call environment model facilitate learning 
explicitly concerned machine learn interacting environment 
developments included internal monologue deal problem partial state important issue reinforcement learning 
continued emphasize learning interaction placed emphasis role teacher 
pioneering research known holds lessons modern reinforcement learning research 
donald michie maintained clear focus reinforcement learning 
described simple reinforcement learning system learning play tic tac toe known crosses called crosses engine 
consisted possible game position containing number colored beads color move available position 
drawing bead random corresponding current game position determine move 
game beads added removed boxes play reinforce punish decisions 
regard collection simple stochastic learning automata chapter 
michie chambers michie chambers described advanced tic tac toe reinforcement learner called game learning engine estimated value function called 
recognize closely related dynamic programming 
michie tic tac toe players served inspiration tic tac toe example chapter discussion decomposing large problem number mutually independent sub problems lead efficient reinforcement learning influenced discussion contrasted value function methods evolutionary methods 
methods decompose problems way 
michie chambers michie chambers described advanced version approach implemented system called boxes applied problem learning balance pole movable cart basis failure signal occuring pole fell cart reached track 
partially inspired pole balancing system widrow smith widrow smith learned supervised learning teacher able accomplish task 
comparing pole balancing system widrow smith michie chambers way come appreciate difference supervised reinforcement learning 
boxes estimate value function inspired pole balancing system barto sutton anderson barto estimate value function 
systems followed pole balancing reinforcement learning systems numerous mention 
widrow colleagues maintained clear emphasis supervised learning recognized differed learning 
widrow gupta widrow modified widrow hoff supervised learning rule called mean square lms rule produce reinforcement learning rule learn success failure signals training examples 
called form learning selective bootstrap learning phrase learning learning critic learning teacher 
researcher supervised learning trend harry klopf klopf klopf hedonic theory neural function ai 
klopf recognized essential aspects adaptive behavior lost learning researchers came focus exclusively supervised learning 
hedonic aspects drive achieve result environment control desired ends away undesired ends 
course essential element reinforcement learning 
klopf especially important authors assessment klopf ideas barto sutton led appreciation distinction supervised reinforcement learning eventual focus reinforcement learning 
important contributions reinforcement learning john holland holland holland 
best known development genetic algorithms holland outlined general theory adaptive systems stresses interactive learning selectional principles 
fact classifier system holland reinforcement learning system updates value functions called bucket brigade algorithm closely related value function estimation methods discuss book 
genetic algorithms natural candidates implementing called evolutionary approach reinforcement learning contrasted value function methods holland suggest approach 
classifier systems genetic algorithms value functions 
idea learning estimating value functions experience appeared minsky minsky introduced samuel samuel program learning play game checkers call temporal difference method 
consider samuel seminal influence approach reinforcement learning book 
papers samuel samuel reveal extraordinary insight nearly issues challenging current researchers 
papers highly worthwhile reading today say samuel checkers player chapters 
minsky early reinforcement learning influential steps artificial intelligence samuel papers contains cogent discussions issues relevant modern reinforcement learning 
particular note minsky discussion considered major computational problem complex reinforcement learning systems solve successful 
called credit assignment problem applying methods complex problems encounters serious difficulty distributing credit success complex strategy decisions involved 
decisions involved achieving success reinforced relative contributions achievement assessed 
minsky discussed value function estimation method samuel checkers player important approach problem pointing closely related phenomenon conditioned reinforcement occurs animal learning 
methods discuss book directed making credit assignment problem reinforcement learning systems 
clear brief account main ideas reinforcement learning ai earliest days 
relatively attracting widespread attention 
reasons reinforcement ideas historically little influence ai association views learning intelligence 
ai research followed allied areas psychology shifting approaches animal behavior cognitive approaches leaving little room reinforcement theories fact leaving little room learning theories kind 
agree critics argued understand generate intelligent behavior basis reinforcement principles believe ai systems cognitive theories steer clear basic learning principles handicapped 
climate grown considerably warmer classical learning principles including reinforcement learning researchers systems owe cognitive perspectives earlier theories animal behavior 
related factor limited influence reinforcement learning principles ai reputation computationally weak 
ample evidence reinforcement learning powerful 
impressive accomplishments artificial learning systems achieved reinforcement learning 
needed history bibliography watkins campbell dennett models witten werbos early stuff 
heuristic search booker 
bellman howard 
add minsky selfridge quote novel situation try methods worked best similar situations barto ag sutton rs 
goal seeking components adaptive intelligence initial assessment 
technical report tr air force wright aeronautical laboratories avionics laboratory afb oh 
barto ag sutton rs anderson cw 
neuronlike elements solve difficult learning control problems 
ieee transactions systems man cybernetics 
reprinted anderson rosenfeld neurocomputing foundations research mit press cambridge ma 
bush rr mosteller 
stochastic models learning 
new york wiley 
farley bg clark wa 
simulation self organizing systems digital computer 
ire transactions information theory 
holland jh 
adaptation natural artificial systems 
ann arbor university michigan press 
holland jh 
escaping brittleness possibility general purpose learning algorithms applied rule systems 
machine learning artificial intelligence approach volume ii rs michalski jg carbonell tm mitchell eds pp 

san mateo ca morgan kaufmann 
klopf ah 
brain function adaptive systems theory 
technical report air force cambridge research laboratories bedford ma 
klopf ah 
neuron theory memory learning intelligence 
washington 
nj 
conditioning associative learning 
new york oxford university press 
mendel jm rw 
reinforcement learning control pattern recognition systems 
adaptive learning pattern recognition systems theory applications jm mendel ks fu eds pp 

new york academic press 
michie chambers ra 
boxes experiment adaptive control 
machine intelligence dale michie eds pp 

oliver boyd 
minsky ml 
theory neural analog reinforcement systems application brain model problem 
phd thesis princeton university 
minsky ml 
steps artificial intelligence 
proceedings institute radio engineers 
reprinted feigenbaum feldman editors computers thought 
mcgraw hill new york 
rosenblatt 
principles neurodynamics perceptrons theory brain mechanisms 
place washington spartan books 
samuel 
studies machine learning game checkers 
ibm journal research development 
reprinted feigenbaum feldman editors computers thought mcgraw hill new york 
samuel 
studies machine learning game checkers 
ii progress 
ibm journal research development 
waltz md fu ks 
heuristic approach learning control systems 
ieee transactions automatic control 
widrow gupta nk 
punish reward learning critic adaptive threshold systems 
ieee transactions systems man cybernetics 
widrow hoff 
adaptive switching circuits 
convention record part iv pp 

widrow smith fw 
pattern recognizing control systems 
computer information sciences coins proceedings washington spartan 

