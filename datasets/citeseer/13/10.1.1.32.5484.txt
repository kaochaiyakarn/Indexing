fast algorithm hierarchical text classification wesley chuang yang giovanni computer science department ucla los angeles ca usa cs ucla edu department computer science iowa state university ames ia usa cs iastate edu hrl laboratories llc canyon rd ca usa wins hrl com 
text classification important proliferation internet huge amount data transfers 
efficient algorithm text classification hierarchical classifiers concept hierarchy 
simple tfidf classifier chosen train sample data classify new data 
despite simplicity results experiments web pages tv closed captions demonstrate high classification accuracy 
application feature subset selection techniques improves performance 
algorithm computationally efficient bounded log samples 
amount line data increases leaps bounds design efficient algorithm approach accessing data classification clustering filtering great interest 
important aspects motivate design 
data needs arranged efficiently 
example placing data flat directory arrange hierarchically concept hierarchy see yahoo patent databases cnn major internet news directories 
querying respect concept hierarchy significantly efficient reliable searching specific keywords views data collected refined go hierarchy 
second text classification chosen approach efficient algorithm 
number algorithms proposed performances compared literature 
tfidf text classifier proceed steps hierarchical classification step define concept hierarchy domain knowledge collect text data corresponding concept hierarchy 
data training classifier testing performance classification system 
step convert data appropriate form classification bag words representation 
derive hierarchical classifiers supervised learning data collected 
classifiers classify new data 
steps described detail sections followed experimental results 
concept hierarchy depth depth depth depth depth baseball basketball teams teams news players wallace rider players news players players news brown clemens robinson duncan news fig 

sample concept hierarchy professional baseball basketball 
shows concept hierarchy categorizes web news reports professional baseball basketball 
initially concept graph generated domain knowledge 
node hierarchy contains text documents topic identified concept 
relational object oriented databases absolutely standard schema tables classes concept hierarchy 
fact look exclusively superior data 
need help alleviating humans semantic burden concept hierarchy encapsulates semantics facilitate achieving efficiency data arrangement searching capability 
relational databases object oriented databases web documents generally unstructured 
way describe schema different relational object oriented models 
unstructured convenient way describe concept hierarchy collection words features document 
usually easy humans come top level concepts schema propose human generated initial concept hierarchy 
concept hierarchy perform feature extraction classification assumptions 
assume initial concept hierarchy created node labeled terms representing concept 
second assume documents manually placed node serving training testing data supervised learning 
third assumption states parent node owns union documents child nodes 
training hierarchy initial hierarchy set training testing documents placed node proceed train hierarchy 
rationale follows characterize training documents residing node find range threshold various characteristics node classify test documents certain concepts find suitable nodes index new documents top bottom concept hierarchy 
ideally hope characterize documents node term label 
practical text documents feature term suffice describing document 
understand documents way 
absence satisfactory solution natural language understanding problem current approaches document retrieval bag words representation documents 
reason opt surface parsing obtain vector set word features weights document time complexity order number words document 
specifically restrict relatively simple effective approach tfidf term frequency theta inverse document frequency classifier 
trying separate documents distinguishable concepts intuitively combined effect term frequency inverse document frequency distinguish different document types 
definitions term frequency inverse document frequency follow 
representing features node convert collection documents node special representation examine documents closely 
document processed stopping stemming procedures obtain bag words 
stopping procedure eliminate common words text stemming procedure find unique representation root word 
procedures consider frequencies documents 
term frequency set words documents 
term frequency word ith vocabulary tf number times occurs document document frequency df number documents word occurs 
inverse document frequency idf log jdj df jdj total number documents sibling nodes 
term frequency theta inverse document frequency tf idf tf theta idf subsequently merge child feature vectors obtain tf vector node 
calculation tf vectors continues bottom reach root 
propagate df vector node way root 
merging process completed feature vector node 
tf idf tf idf tf idf jw union documents belonging node union set words determining threshold node having organized training documents different nodes classes having built feature vectors characterize class tfidf vector 
words tfidf serve norm prototype vector describe class 
formally collection document classes interest 
prototype vector class concept hierarchy generated class follows threshold prototype vector prototype vector class class fig 

learning threshold admit new documents class 
training documents complete hierarchical classifier ways 
prototype vector need introduce threshold distance measure indicate distance range prototype vector consider documents fall category class 
clear imagine tfidf vector lying dimensional hyper space shown 
seen threshold boundary class 
simplicity visualize normalization vector coordinate system 
second need examine hierarchical classifier prototype vectors thresholds accuracy classifier correctly classify documents 
check accuracy brand new test documents 
section consider accuracy training documents come prototype vectors 
deriving threshold computing training accuracy inter related 
classification training accuracy feedback adjust threshold 
words adjust threshold way documents considered node yield best accuracy 
accuracy shown concerns percentage documents correctly classifying class accuracy documents correctly categorized documents considered elements tfidf vector positive real numbers lie quadrant 
level depth hierarchy node level fn node docs node node fd docs dist cos fn find cut dist maximizes accuracy fig 

accuracy feedback adjust threshold 
equation indicate respectively number documents class selected number selected number rejected number selected 
starting highest level hierarchy compare training documents vector representation prototype vector node 
compare feature vectors cosine function commonly similarity measure 
compute similarity document prototype vector cos deltac node consider training documents belonging sibling child nodes 
sort distances dist prototype vector 
choose distance renders best accuracy 
threshold 
pseudocode computing shown 
functions self explanatory 
time complexity analysis approach involves surface parsing obtaining features words documents training features concept hierarchy 
parsing time linear 
time taken training especially computing thresholds 
assume total number documents total number nodes hierarchy 
contributing factors computing tf takes computing idf takes computing threshold takes log log sorting costs 
time remains bounded log claim classification algorithm fast 
testing hierarchy section test performance hierarchical classifier test set documents different training set 
ratio total number testing documents training documents 
node classifier node equipped tfidf vector threshold regard node classifier 
starting highest level hierarchy compare test document vector representation prototype vector node 
vectors close cosine measure treat test document belonging class node represents continue compare document child nodes 
close match conclude document belong class 
vector classified 
class oe nodeset root nodeset oe retrieve node nodeset nodeset nodeset gamma node compute prototype vector tf idf node 
compute similarity cos 
class class nodeset nodeset node return class fig 

finding class new text document 
hierarchical classifier document assigned classes prototypes sufficiently close 
pseudocode summarizes classification process 
test accuracy test accuracy defined ratio number correctly classified documents number documents filtered node test accuracy correctly classified classification performed top bottom hierarchy test documents filter certain nodes continue drill hierarchy stopped similarity measures pass threshold prototype vectors 
consequently number filtered documents diminishes testing process continues bottom level 
experiments training testing collected approximately documents professional baseball basketball news 
experimental results demonstrate feasibility approach classification accuracy 
training upper level nodes classifiers receive ratings training accuracy lower level nodes perform average rate 
testing accuracy performance relatively poorer especially lower nodes acceptable higher level nodes 
concepts specific go hierarchy 
addition number documents considered relatively small compared higher levels 
account classification error training testing phases look different types errors false positive fp false negative fn 
defined follows explained false positive mistakenly put topic false negative mistakenly missed topic reports breakdown classification errors training testing hierarchy 
testing phase lower level nodes resulted relatively high fn 
due depth nodes limited number documents tested nodes 
fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fn fp fp fp fn fn fn fp fn fp fn fp fn training phase 
fp fp fp fp fp fp fn fn fp fn fp fp fn fn fn fn fp fn fn fn fp fp fp fp fp fp fp fp fp fp fp fn fn fp fn fn fn fp fn fn fn fn fn fn fp fn fn fn fp fn fp fn fp fn fp fn testing phase 
fig 

false positive fp false negative fn errors percents 
feature subset selection experiment shown tfidf feature reliable indicator categorizing web text 
investigate subset features perform text classification 
straight tfidf subset feature selection represents node subset word features 
new feature vector node consists top leading sorting original vector tfidf values 
tf idf tf idf tf idf wm jw illustrates average accuracy percents classifiers depth training testing phases 
testing different subsets compared 
findings cut scarcely affect test accuracy 
implications tfidf indicator text classification higher values dominating terms 
second subset features reduce storage requirements drastically improve efficiency compromising classification accuracy 
special positive negative vectors way selection introduce special vectors positive negative represent background knowledge 
positive negative vectors manually 
human version positive terms may coincide average accuracy classifiers depth hierarchy testing subset tfidf features training fig 

average accuracy classifiers depth hierarchy 
positive vector find place tfidf vector shrink tfidf vector find place tfidf original tfidf vector new tfidf vector design 
training testing average accuracy 
fig 

combining background knowledge classification 
dominating negative terms words contribute classification human judgement 
shows background knowledge incorporated original node hierarchy 
training negative vector subtracted original tfidf vector 
testing impose confidence function positive vector node confidence function compete original similarity function 
background knowledge confidence reaches certain level abandon cosine measure determine category right away 
experiment simple confidence function number positive words ffi occur document 
background knowledge somewhat mimics way human determines category 
example ffi reveals combining background knowledge improve classification accuracy 
applied tv closed captions approach applied tv closed data mixed web pages 
closed captions usually contain typos web pages 
classification accuracy showed promising results 
important success classifying tv closed captions assist video generally multimedia classification case time great concern 
report game report game report game team news team news team news team news nba nfl report game rams concepts tv closed data 
training testing tfidf bk bk depth depth depth average accuracy 
fig 

classifying tv closed captions tfidf background knowledge bk 
related number existing approaches similar hierarchical classification pre defined concept hierarchy 
combined feature subset selection finds best subset features improves classification accuracy reduces measurement cost storage computational overhead 
example taper concept hierarchy classifies text statistical pattern recognition techniques 
finds feature subsets fisher discriminant 
similarly mladenic grobelnik proposed document categorization method concept hierarchy 
naive bayesian classifier feature vector word sequences employed feature subsets yield performance 
mccallum proposed hierarchical classification naive bayesian classifier 
particular suggested combining labeled unlabeled data boost classification accuracy 
numerous approaches automatic generation concept hierarchy 
incentive eliminate overhead manually constructing concept hierarchy 
sahami example applied unsupervised clustering generate concept hierarchy text data 
defined similarity measures find clusters feature subset selection 
sanderson croft means automatically deriving hierarchical organization concepts set documents 
cooccurrence subsumption conditions selected salient words phrases standard learning clustering techniques 
addition exist variety learning algorithms text 
yang compared performance learning algorithms 
mladenic surveyed text learning related intelligent agents key criteria representations documents select features learning algorithm 
mitchell book comprehensive source machine learning algorithms 
summary discussion design intelligent text classifier great importance current world filled vast amounts data 
algorithm fast time critical 
fulfill promises designed implemented hierarchical classification system leverages concept hierarchy simple fast learning algorithm 
hierarchical aspect narrows search space significantly eliminating irrelevant areas 
tfidf accuracy feedback quickly classifier 
regarding experimental results hierarchical classifiers performed fairly web data tv closed captions sports domain 
preliminary feature subset selection demonstrated improvements classification accuracy cost associated features 
avenues research include exploitation data structures structural information text title sections exploited differentiated 
consideration different types data system tested different types text data instance patent data 
incremental learning new data learned dynamically 
old data ignored time elapsed 
combination labeled unlabeled data reduce overhead data preparation prior learning unlabeled data combined labeled data 
automatic expansion shrinkage concept hierarchy dynamic change concept hierarchy needed accommodate newly formed concepts 

chakrabarti dom agrawal raghavan 
taxonomy discriminants signatures navigating text databases 
proceedings rd vldb conference 

cnn com 
www cnn com 
craven dipasquo freitag mccallum mitchell nigam slattery 
learning extract symbolic knowledge world wide web 
proceedings th conference artificial intelligence 

korfhage 
information storage retrieval 
new york wiley 

mccallum nigam rennie seymore 
building domain specific search engines machine learning techniques 
aaai spring symposium intelligent agents cyberspace 

mitchell 
machine learning 
new york mcgraw hill 

mladenic 
text learning related intelligent agents survey 
ieee intelligent systems vol pages july aug 

mladenic grobelnik 
selection classification text hierarchy 
working notes learning text web conference automated learning discovery 

patent trademark office 
www uspto gov 
sahami 
machine learning improve information access 
ph dissertation department computer science stanford university 


salton 
automatic text processing transformation analysis retrieval information computer 
reading massachusetts addison wesley 

sanderson croft 
deriving concept hierarchies text 
proceedings nd acm sigir conference pages 

yahoo 
www yahoo com 
yang 
re examination text categorization methods 
proceedings nd acm sigir conference pages 
