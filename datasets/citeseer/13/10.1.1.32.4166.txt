department computer science technical report gesture recognition james davis shah cs tr university central florida orlando fl gesture recognition james davis shah computer vision laboratory university central florida orlando fl presents method recognizing human hand gestures model approach 
finite state machine model qualitatively distinct phases generic gesture 
fingertips tracked multiple frames compute motion trajectories 
trajectories finding start position gesture 
gestures represented list vectors matched stored gesture vector models table lookup vector displacements 
results showing recognition gestures images sampled hz sparc special hardware 
gestures representatives actions left right grab rotate 
keywords motion recognition motion tracking gesture interpretation 
research reported supported national science foundation cda iri 
essential computer systems possess ability recognize meaningful gestures computers interact naturally people 
humans gestures daily life means communication pointing object bring attention object waving hello friend requesting raising fingers best example communication gestures sign language 
american sign language asl incorporates entire english alphabet gestures representing words phrases permits people exchange information non verbal manner 
currently human computer interface keyboard mouse 
physically challenged people may difficulties input devices may require new means entering commands data computer 
vision gesture input speech recognition touch sensory input possible means addressing users needs solve problem 
computer vision computer recognize perform user gesture command alleviating need keyboard 
applications vision system remote control robotic arm guiding computer presentation system executing computer operational commands opening window program 
method described presents computer vision gesture recognition method permits human users adorned specially marked glove command computer system carry predefined gesture action commands 
additionally subset gestures comprised select asl letters see 
gesture begins hand hello position ends recognizable gesture position 
current library gestures contains gestures left right rotate grab 
left gesture asl performed moving fingers letter position thumb index finger upright position rest fingers palm see 
right asl performed rotating hand fingers degrees right see 
asl fingers moved position resembling pointing upward see 
gesture moving index finger little finger parallel ground see 
rotate asl requires moving index middle ring finger palm see 
grab asl performed moving fingers position resembles grabbing small object see 
similar fingers thumb move palm parallel ground see 
system created recognize sequence multiple gestures 
user start designated start position initialization system able gestures termination gesture recognized system 
advantages system recognition methods 
uses inexpensive white video 
incorporating color markers glove interest points requires costly color imaging binary marked glove research detected low cost black white imaging 
second simple vision glove employed mechanical glove leds bulky wires 
current gesture input devices require user linked computer reducing autonomy 
vision input overcomes problem 
third duration parameter gestures incorporated 
example recognition system connected robotic arm user gesture left robotic arm continue move left user moves hand gesture back start position 
user control execution duration robotic arm 
due finite state machine fsm implementation generic gesture warping image sequences necessary 
related baudel beaudouin lafon implemented system remote control computeraided presentations hand gestures 
system user wears vpl dataglove linked computer 
glove measure bending fingers position orientation hand space 
user issues commands presentation pointing predefined active zone performing gesture desired command 
gesture models include information pertaining start position arm motion dynamic phase position gesture 
command set includes commands page previous page chapter previous chapter table contents mark page highlight area 
main types errors occur system gestures 
left 
right 


rotate 
grab 

system errors user errors 
system errors relate difficulties identifying gestures differ dynamic phase user errors correspond issuing command 
trained users recognition rate 
system vision recognize gestures uses linked hardware system track hand arm movements movement natural user 
cipolla okamoto kuno real time structure motion sfm method visual interpretation hand gestures man machine interface 
glove colored markers attached input vision system 
movement hand results motion images colored markers 
authors parallax motion vector divergence curl deformation components affine transformation arbitrary triangle colored points vertex determine projection axis rotation change scale 
information alter image model 
information extracted colored markers give position entire hand finger provides triangular plane sfm algorithm 
structure motion method assumes rigid objects true case hand gestures 
fukumoto mase system called finger pointer recognizes pointing actions simple hand forms real time 
system uses stereo image sequences require operator wear special glove 
requires special image processing hardware 
stereo images system uses location fingers location 
coordinates operator fingertip direction pointing determined stereo images cursor displayed target location opposing screen 
system robust able detect pointing regardless operator pointing style 
applications system similar gesture controlled computer aided presentations baudel beaudouin lafon video browser vcr 
darrell pentland proposed glove free environment approach gesture recognition 
objects represented sets view models matched stored gesture patterns dynamic time warping 
gesture dynamically length longest model 
matching normalized correlation image set view models view models comprised example images view object 
method requires special purpose hardware achieve real time performance uses gray level correlation highly sensitive noise 
method tested distinguishing gestures 
generic gesture system recognize sequence gestures able determine state user hand hand dormant moving gesture position 
approach relies qualitatively distinct events phases gestures frame frame correlation 
gesture user performs begins hand start position fingers upright wave hello person 
user moves fingers entire hand gesture position 
position system attempt recognize gesture system connected peripheral device robotic arm execute gesture command hand begins moving back start position 
system wait gesture occur 
user constrained phases making gesture 

keep hand fixed start position motion gesture begins 

move fingers smoothly hand moves gesture position 

keep hand gesture position desired duration gesture command 

move fingers smoothly hand moves back start position 
phases occur fixed order finite state machine fsm guide flow recognition gestures motion characteristics hand see 
state diagram represents motion motion respectively successive images 
due undesirable motion lack motion bound set control premature advancement phase 
frame similarity constraint states consecutive images motion properties advance phase inhibit premature phase advancement 
motion detected sequential images gesture motion 
similarly motion sequential images hand fixed 
notice machine requires successive depending particular phase sequential images advance phase reflecting frame similarity constraint 
due nature machine warping image sequences necessary required fixed number images gesture sequence 
fsm compensates varying numbers images looping current phase long frame similarity constraint satisfied 
actual number frames constitute motion gesture yields information system 
useful information start position fingertips 
system care fingers hand arrive gesture position wants know location fingertip gesture gesture 
path fingertips gesture position irrelevant need perform warping image sequence match models 
locations total displacement fingertips play crucial role gesture recognition compared motion characteristics instantaneous velocity 
need track fingertip initial position final gesture position 
fsm permits determination phase user currently executing tracks fingertips variable length frame sequence gesture position 
method image sequence analyzed find location fingertips section 
hand motion gesture position motion correspondence track points resulting gesture position section 
trajectories computed motion correspondence algorithm converted vector form matched stored gestures sections 
fingertip detection goal fingertip detection identify location marked fingertips vision glove 
location fingertips determines position fingers time 
point detection process extracting fingertip locations image histogram segmentation 
sequence images intensity state diagram 
states depict initial phase phase states depict motion gesture phase phase states depict gesture recognition phase phase external device robotic arm execute gesture exiting phase states depict motion initial phase phase 
fingertips known priori significantly different remaining regions multimodal histogram image generated fingertip regions correspond rightmost peak 
threshold established smoothing averaging histogram finding intensity value valley peaks see 
value greater threshold shall treat belonging fingertip region value threshold discarded 
segmenting image fashion results binary image features fingertip regions see 
prefer fingertip regions represented points ease calculations storage display logical representation fingertip region centroid see 
centroid points correspondence stage 
motion correspondence fingertips detected frame need compute trajectories motion correspondence 
motion correspondence maps points image points image points mapped point 
rangarajan shah threshold point detection process 
initial image 
smoothed histogram entire image threshold set dashed line 
image rightmost peak corresponds fingertip regions brightest regions 
binary image obtained applying threshold determined histogram 
centroids regions corresponding fingertips 
motion correspondence algorithm chosen exploitation proximal uniformity constraint says objects follow smooth paths cover small proximal distance small time 
stated previously phase gesture constraint fingers move smoothly gesture position 
additionally frame similarity constraint motion requires frames motion implies fingertips move small proximal distance successive frame 
algorithm proximal uniformity constraint agrees previously stated gesture motion constraints 
algorithm path known trajectory generated points starting points image points nth image 
resultant disjoint paths finger called trajectory set 
rangarajan shah algorithm establishes correspondence points minimizing proximal uniformity function ffi prefers proximal uniform path ffi gamma kx gamma gammax kx gamma phi gamma gammax phi gamma kx kx phi gamma phi correspondence points image image gamma phi gamma vector point image point image denotes magnitude vector 
term equation represents smoothness constraint second represents proximity constraint 
algorithm uses frames determine correspondence 
authors assume correspondence frame frame known 
propose optical flow yield initial correspondence frame frame 
determined studying gesture movements euclidean ordering points fingertip frames coordinate ordering farthest left farthest right fingertips thumb little finger similar frames 
initial correspondence derived location points 
rangarajan shah correspondence algorithm non iterative greedy algorithm keeps proximal smoothness function minimized possible addition fair individual assignment 
gesture modeling general human finger movements linear extrema moving extended position palm wrist area hand hello position hand making fist 
ability limited rotational movement fingers move fingers palm thumb moving left right palm 
fingers move relatively linearly move times approximate fingertip trajectory single vector 
vector originate location corresponding fingertip motion gesture position terminate location gesture position 
disregard actual path fingertip stated previously concerned location fingertip 
curvature fingertip trajectory disregarded 
motion information leading gesture position needed 
motion correspondence map starting points points means tracking points trajectories 
gesture determined start points 
see vector representations gesture set 
library model created averaging test models gesture represented data structure see contains 
gesture name 

mean direction mean magnitude mean displacement fingertip vector 

gesture motion code 
direction fingertip determined starting point stopping point trajectory 
direction theta easily calculated theta arctan gamma gamma magnitude displacement fingertip determined start points trajectory set disp gamma gamma vector extraction gesture 
image sequence selected images shown 
respective fingertip points images 
fingertip trajectories 
vector representation trajectories 
vector representation gestures 
left 
right 


rotate 
grab 

gesture name finger dir finger mag finger dir finger mag finger dir finger mag finger dir finger mag finger dir finger mag motion code gesture model data structure fields 
motion threshold necessary stage account shifts occur hand relatively stable position register motion 
bit motion code store motion activity fingertips gesture acts table key model 
bit code corresponds specific fingertip vector significant bit storing finger thumb motion information progressing significant bit finger little finger motion information stored 
bit set respective fingertip vector motion fingertip vector magnitude displacement threshold 
motion code gesture significant motion fingertip vectors represented binary number decimal notation stored gesture motion code 
gesture matching gesture matching consists comparing unknown gesture models determine unknown gesture matches model gesture system vocabulary 
motion codes enable matching scheme consider models similar motion code unknown gesture provide information motion category unknown gesture belongs 
library models loaded memory stored array linear linked lists array indexed motion codes 
matching stage unknown gesture need compared library models indexed unknown gesture motion code linear linked list 
known priori stored models differ respective motion codes random access obtained models comparison logical 
subset library models compare unknown gesture reduced search complexity dependent different motion codes current library gestures 
match determined comparison stored models unknown gesture 
match vector fields magnitude direction fingertip unknown gesture threshold corresponding model entries 
results sequences frames digitized hz stored recognition program 
run performed fashion starting gesture left progressing gesture shown horizontally table 
run frames left right rotate grab table results 
recognized recognized error sequence 
number images sequence depended duration gesture performed long execution gesture requires images 
results sequences images yielded perfect scores exception run error sequence caused remaining gestures 
shift hand threshold limit occlusion points due lighting conditions may cause premature advancement phase turn may result fsm continuing asynchronously image sequence 
image sequences performed real time user possibly compensate sequence error shifting back proper time interval preventing erroneous output remainder image sequence 
image set fixed order shown table altered grab rotate left right resulted perfect recognition implies gesture order concern 
plot fingertip respect frame number shown series images 
gesture recognition diagram see created sequence show length order execution gestures 
recognition frame gesture sequence sampled hz took cpu time ms sparc implies ms processing time frame 
noted system require special hardware 
experiments show sampling rate hz necessary gesture recognition hz sufficient 
processing time needed method small implementation recognition algorithm real time images sampled hz 
developed computer vision method recognizing sequences human hand gestures environment 
specialized fsm constructed alternative image sequence warping 
utilize vectors representing direction displacement fingertips gesture 
modeling gestures set vectors motion key allows reduction complexity model form matching may contain multiple lengthy data sets 
performance method real image sequences 
extensions pursued including gestures time plots 
thumb trajectory 
index finger trajectory 
middle finger trajectory 
ring finger trajectory 
little finger trajectory 
gesture recognition diagram 
diagram depicts order gesture execution number frames execution gesture length altered order image sequence 
gesture id grab rotate left right 
removing glove environment relaxing start requirement 
cipolla okamoto kuno robust structure motion motion parallax 
iccv pages 
ieee 
darrell pentland space time gestures 
cvpr pages 
ieee 
costello signing speak hands 
bantam books new york 
fukumoto mase real time detection pointing actions glove free interface 
iapr workshop machine vision applications pages dec 
rangarajan shah establishing motion correspondence 
cvgip image understanding july 
baudel beaudouin lafon charade remote control objects free hand gestures 
cacm pages july 
