statistical multiscale framework poisson inverse problems robert nowak department electrical computer engineering rice university ms box houston texas usa fax email nowak rice edu web www ece rice edu nowak eric kolaczyk department mathematics statistics boston university boston ma email kolaczyk math bu edu web math bu edu people kolaczyk accepted special issue ieee transactions information theory information theoretic imaging describes statistical modeling analysis method linear inverse problems involving poisson data novel multiscale framework 
framework founded multiscale analysis associated recursive partitioning underlying intensity corresponding multiscale factorization likelihood induced analysis choice prior probability distribution match factorization modeling splits underlying partition 
class priors interesting feature non informative member yields traditional maximum likelihood solution choices re ect prior belief smoothness unknown intensity 
adopting expectation maximization em algorithm computing map estimate corresponding model nd model permits remarkably simple closed form expressions em update equations 
behavior em algorithm examined shown convergence global map estimate guaranteed 
applications emission computed tomography astronomical energy spectral analysis demonstrate potential new approach 
index terms poisson processes inverse problems multiscale analysis imaging supported national science foundation 
mip oce naval research award nos 
army research oce 
daad 
problems science engineering involve recovery object intensity indirect poisson data counts poisson data collected underlying intensity function indirectly related object interest linear system equations 
high energy astronomical imaging emission computed tomographic imaging just examples 
call problems poisson inverse problems 
poisson inverse problems ill posed sense small perturbations data lead dramatically di erent solutions recovery problem method 
solving problems especially challenging low signal noise ratio snr situations total number counts observed limited situation photon imaging modalities 
maximum likelihood method estimation fairly standard exempt ects ill posed nature problem 
result treatments poisson inverse problems involved maximizing criterion likelihood equations augmented appropriate regularization penalization term stabilizes ill conditioned likelihood criterion 
regularization term takes form bayesian prior maximum posteriori map estimator place maximum likelihood estimator mle 
wavelet multiscale analysis regularization methods received considerable attention information theory statistics literatures see special issues ieee information theory 
particular multiscale regularization methods proposed inverse problems 
techniques developed date gaussian noise models directly applicable poisson inverse problems 
speci cally models developed gaussian problems capture non negativity intensity functions matched functional form poisson likelihood rendering analysis interpretation implementation dicult 
low snr cases greatest practical interest data modeled standard gaussian approximations poisson likelihood existing multiscale regularization methods simply inappropriate 
attempts wed multiscale analysis paradigm poisson estimation problems 
bayesian multiscale framework independently introduced problems involving direct poisson observations key example 
approaches multiscale factorization poisson likelihood function turn induces re parameterization underlying intensity terms canonical multiscale parameters 
conjugate priors multiscale parameter space framework admits remarkably simple bayesian multiscale analysis tool poisson data analogous wavelet counterparts gaussian denoising estimation problems 
demonstrates conventional wavelet multiscale analysis necessarily compatible poisson data equally appealing closely related alternative naturally suited case 
introduces novel bayesian multiscale framework poisson inverse problems extends authors earlier described just case directly observed poisson data 
framework shares characteristics advantages just described addition desirable features germane speci context poisson inverse problems 
multiscale framework admits simple em algorithm computing map reconstructions 
em strong information theoretic motivation connects probabilistic photon limited imaging models multiscale analysis formal precise fashion 
em algorithm involves closed form analytic steps iteration making computationally attractive 
second mild regularity assumptions multiscale prior density readily veri ed simple algebraic check hyperparameter settings proven em algorithm converges unique global map estimate 
third ects multiscale prior density hyperparameter settings easily interpreted important user perspective applications 
organized follows 
section ii give basic problem formulation discuss existing estimation methods 
section iii review bayesian multiscale approach modeling analyzing poisson data 
section iv apply framework poisson inverse problem derive multiscale em algorithm compute map estimate 
section study convergence em algorithm 
section vi discuss issue selecting hyperparameters prior 
section vii look applications new framework 
close section viii remarks 
ii 
problem formulation problem addressed 
suppose observe poisson distributed data counts denotes poisson distribution intensity parameter unknown intensities related unknown intensities primary interest relation fp matrix known non negative weights usually transition probabilities 
case exists known background information form vector alternative model typically shall assume simplicity proposed method extends immediately case 
assume rows sum unity necessary restriction 
problem estimate observed data fy assume integer arbitrary integer 
typically chosen user normally predetermined instrumental design constraints common condition diculties 
classical application estimation problem arises photon limited imaging 
photons emitted emission space intensity 
photons emitted location detected detection space position transition probability conceptual standpoint usage em framework useful introduce representation unobservable data denote total number emission detection events case indirectly observed incomplete data additionally able observe direct emission data location sums form xm follows xm 
known avoid inverse problem altogether simply deal issue estimating poisson intensity direct observations 
course device precisely known em algorithm exploits producing estimates indirect data fact fundamental approach introduced 
maximum likelihood estimation log likelihood log yj log log known maximizer expressed closed form determined numerically 
principle numerical optimization method iterative em algorithm rst proposed problem number features especially desirable notably natural probabilistic formulation computationally straightforward calculations iteration step numerical stability 
shown em algorithm monotonically increases log likelihood iteration converges global necessarily unique point maximum 
unfortunately due ill posed nature likelihood equations variance mle quite high particularly applications involving low counts 
fact cases mle practically useless 
popular remedy em algorithm prior convergence 
stopping algorithm acts implicitly smoothing operation produce acceptable results 
may preferable abandon strictly likelihood perspective altogether approach inverse problem di erent criterion smooths de ned optimal solution providing useful meaningful results 
bayesian map estimation penalized mle bayesian penalized maximum likelihood procedures developed prior information regularizing penalizing functionals produce map estimates desirable mle cases 
log posterior proportional log likelihood plus log prior density replaces likelihood optimization criterion 
log posterior log jy log yj log log yj prior example markov random field mrf 
log interpreted penalizing functional terminology penalized mle 
map estimate value maximizes 
case mle map estimate computed numerically general 
em algorithm popular choice optimization general steps closed form expressions mle case 
challenging nature optimization problem practical issue limited widespread application map methods poisson inverse problems vexing issues 
example selection useful hyperparameter regularization parameter settings focus considerable diculty interpreting ects various user selected parameters application techniques somewhat art 
cases prior ects readily understood case simple quadratic roughness penalties gaussian priors usually faces direct trade smoothness resolution edge preservation 
furthermore cases priors re ect strict non negativity poisson intensity functions gaussian prior quadratic penalty potential non negativity resulting map estimator ignored enforced additional constraints 
intensities inherently non negative bayesian context natural employ prior supports knowledge 
multiscale regularization methods multiscale methods er alternative conventional spatial regularization techniques host inverse problems notably tomographic image reconstruction inverse problems involving scale homogeneous operators image deblurring 
wavelet representations utilized multiscale schemes 
wavelet methods advantageous enable nonlinear estimation procedures adapt local characteristics underlying object 
roughly speaking recover edges singularities supported data simultaneously smoothing regions 
methods viable alternative non quadratic markov random eld priors 
attempts multiscale regularization conjunction gaussian observation model 
contexts poisson observation models especially appropriate tendency gaussian approximations 
may due diculty formulating appropriate multiscale analysis poisson case 
wavelet methods developed appropriately adapting schemes devised gaussian data crossvalidation techniques 
mentioned earlier previous demonstrated conventional wavelet analysis poisson data somewhat incompatible terms theoretical tractability algorithm implementation 
remarkable performance wavelets multiscale regularization gaussian arena motivates search similar treatment poisson data 
notably preliminary appeared multiresolution mrf bayesian tomography developed represent di erent steps direction 
uni ed bayesian multiscale framework poisson likelihood complemented suitable natural multiscale reparameterization prior initial 
iii 
multiscale analysis poisson problems direct data suppose moment emission data xm available 
observe data directly employ multiscale analysis estimation techniques poisson data developed 
brie review fundamental aspects techniques 
intensity parameterization prior tackle general inverse problem section iv 
conjunction notion unobservable data results enable simple natural em algorithm likelihood posterior maximization 
multiscale analysis refers study behavior structure signals data various spatial temporal resolutions 
ect multiscale analysis simple recursive summation data equivalent processing haar scale function 
illustrate consider dimensional case analysis de ned xm index refers resolution analysis index highest resolution nest scale corresponding lowest resolution coarsest scale 
multiscale data fx unnormalized haar scaling coecients organized represented binary tree graph shown 
haar multiscale analysis especially suited poisson data poisson distribution reproduces summation unweighted sum independent poisson variates poisson distributed 
analyses general wavelets result arbitrary linear combinations poisson random variables nice distributional characteristics result 
issues mathematical tractability interpretability quickly arise general wavelet analyses poisson data contrary case wavelets gaussian data 
data independent intensity standard conditional probability relationships express joint probability data terms multiscale representation factorized form pr pr pr jx expression holds generally just poisson data may viewed likelihood factorization respect particular graphical model case simple binary tree 
see additional investigations lines 
factorization captures basic relationship parent coarse scale child ner scale 
see point detail consider speci distributional form conditional likelihood child parent 
speci cally rst de ne multiscale analysis intensity analogous de ned data parameters unnormalized haar scaling coecients represented binary tree graph shown 
de nition hand expression parent child conditional likelihood 
denotes binomial distribution parameters 
expression identify canonical multiscale parameters associated poisson observation model viewed splitting factors govern multiscale re nement intensity 
splitting factors interpreted multiplicative weights represented edges links binary tree graph depicted 
see factorization may expressed denotes poisson probability mass function intensity maximum likelihood estimation intensity reconstruction inspection binomial conditional likelihood factors shows mle split scale fine scale scale coarse fig 

multiscale analysis modeling represented binary tree graph 
data coecient intensity coecient associated node binary tree 
edges links nodes represent multiplicative weights splitting factors governing re nement intensity function 
simply empirical splitting factor relating data scale 
note condition implies 
adopt convention 
mle total intensity simply total count mapping mle intensity computed simple reconstruction algorithm corresponding multiscale parameter estimates multiscale synthesis equations easily seen mle intensity element nest scale highest resolution dictated data xm mle simply returns raw data mle intensity estimate expected 
discussed shortcomings mle consider map estimation procedure 
maximum posteriori estimation crucial ingredient bayesian procedure selection suitable prior 
ideally prior re ects known assumed attributes intensity question computational purposes convenient prior matched functional form poisson poisson binomial likelihood 
parametric conjugate priors advantageous computational reasons posterior distribution obtained simply updating parameters prior observations see pp 

see conjugate priors provide current setting plausible models multiscale parameters 
family gamma densities conjugate family poisson likelihood beta family conjugate binomial adopt priors 
placing gamma density prior total intensity parameter expf 
model multiscale split parameter independent beta distributed random variable denotes standard beta function 
symmetric beta priors mean characterized related approaches parameters depend location location dependent signal characteristics usually known priori 
prior density unknown parameters gamma prior tailored re ect knowledge total intensity process consideration 
total count typically quite large reasonable settings hyperparameters ect gamma prior negligible 
important beta priors placed splits 
hyperparameters re ect belief prior knowledge regarding regularity intensity section vi 
illustrate brie setting uniform constant prior densities splits expressing absolute ignorance multiscale re nement intensity 
beta prior densities peaked point favoring regular re nement 
similar priors nonparametric probability density modeling estimation name polya trees 
combining prior likelihood making conjugacy beta gamma priors produces posterior density jx jx factorization posterior shows inferences multiscale parameter individually requiring complicated high dimensional analysis 
map estimates fb simple closed form expressions mapping map estimate intensity computed synthesis equations map estimates place 
iv 
bayesian multiscale approach poisson inverse problems return attention original formidable poisson inverse problem described emission process directly observed 
objective apply bayesian multiscale analysis similar just described case 
speci cally seek map estimate maximizes intensity prior induced multiscale prior 
de ned map estimation problem diculty face faced nding mle maximizing objective function straightforward performed numerically 
previously mentioned em algorithm popular maximization tool especially context poisson inverse problems 
maximization facilitated em framework particular unobservable data space 
example poisson inverse problem unobservable data de ned observed closedform maximizer accompanying complete observed unobserved data likelihood function zj available 
note observed data determined refer complete data 
em algorithm iterative method alternates computing conditional observed data expectation complete data log posterior log zj log maximizer resulting function leads map estimate observed data log posterior 
section develop details em algorithm associated particular bayesian multiscale framework 
multiscale framework recall section iii analysis directly observed poisson data multiscale factorization data likelihood played central role 
context indirectly observed data em algorithm led consider complete data likelihood just described 
show complete data likelihood yields multiscale factorization similar observed direct data likelihood 
fact somewhat remarkably proportional 
multiscale prior density direct data case just appropriate case indirectly observed data 
consequently corresponding complete data log posterior easily maximized respect multiscale parameters detail results derived follows 
recalling direct unobserved emission data xm 
de ne multiscale analysis data direct observation case 
unknown intensity parameter multiscale analysis 
calculations similar yielding equations show complete data likelihood factorized follows 
jp rst factor poisson mass function intensity factors form binomial conditional likelihoods 
factors multinomial parameters th column matrix transition probabilities total counts emission location assumption rows sum unity play critical role 
rst step deriving factorization write pr 
pr pr 
jx just summation elements 

step fact zj 
product factors results 
left step term form pr 
term simply direct data likelihood may factorized equation 
impact deceptively simple set steps apparent noted multinomial probability mass functions depend complete data transition probabilities 
particular depend unknown intensity parameter 
purposes studying ignore factors simply write words complete data likelihood proportional direct data likelihood 
fact result special con rmed easily example noting similar result follow case gaussian inverse problem normal analogy 
case term analogous second line product conditional multivariate gaussian factors involving 
nish discussion poisson case note combination logarithm prior result allows express log complete data posterior distribution log jz log log log log constant depend parameters 
equivalent expressions complete data log posterior spatial domain multiscale parameterization 
due simple form maximizing respect splits total intensity trivial simply di erentiate expression obtain map estimates expressions 
take advantage formulation em algorithm 
em algorithm multiscale map estimation general main diculty encountered map em algorithm step typically admit closed form solution case mle 
simplicity em algorithm lost map estimation problems exception obtained quadratic gaussian prior lead parameter space restricted insure non negative solutions quadratic priors de ned real valued images just non negative intensities 
strengths multiscale approach addition insuring non negative estimate closed form steps 
steps em algorithm take forms 
initial iterate chosen constant intensity suitable starting point reconstruction obtained simple ltered back projection reconstruction 
st iteration step step step compute expectation log posterior conditioned poisson law induced log zj jy log note log zj linear constant term depending data step reduces computing zjy zjy multinomial step maximize expected complete data log posterior transforming multiscale representation 
reduces step process 
generate 
ii 
calculate reconstruct algorithm desirable properties 
standard property em algorithm posterior probability non decreasing iterate 
second easily veri ed construction resulting estimate non negative 
third set case beta densities coincide uniform density noninformative case split prior set gamma prior limiting improper form gamma density recover classical mle method 
nal note mention surprising feature model computational simplicity accompanying implementation em algorithm 
fact implementation demanding proposed originally simple likelihood model 
map criteria proposed problem admit simple implementation usually maximization step closed form expression computed numerically approximately 
convergence multiscale em algorithm section establish convergence properties multiscale em algorithm developed form key results 
multiscale prior induces prior certain conditions hyperparameters strictly concave implies unique maximizer exists 
second conditions em algorithm converges unique maximum point log posterior 
result 
lemma non negative components ir multiscale prior de ned induces prior distribution density 
expf proof lemma follows induction log may appendix may proofs results stated section 
considering manner de ned respect multiscale prior clear necessarily change behaved manner 
fact dicult show consider simple case multiscale log prior concave 
lemma describes exists interesting condition induced log prior log 
strictly concave 
lemma log prior density function log strictly concave hyperparameters satisfy set positive numbers 

points worth noting light lemma 
hyperparameter prior distribution plays role 
second conditions strict inequality holding pair sucient 
words concavity achieve essentially doubling hyperparameters decreases moving ne coarse scale 
defer discussion practical impact hyperparameter constraints section vi 
continuing convergence analysis write log posterior density function log yj log simply re expressed emphasize prior density de ned lemma 
known incomplete data log likelihood concave strictly concave conditions 
log posterior density sum concave function strictly concave function condition lemma strictly concave 
result 
theorem conditions lemma iterates em algorithm de ned section iv converge limit point maximum point 
analysis convergence appendix essentially follows form seminal similar analyses 
interest note particular method proof di ers prove convergence em algorithm mle context 
case data log likelihood strictly concave may exist multiple global maxima 
additional complexity optimization function necessitates deeper technical conditions appendix drawing results 
ultimately course referenced methods rely certain fundamental conditions laid 
models poisson inverse problem model possible optimal solution occur boundary parameter space 
additional complication leads non trivial amount technical changes method proof seen proof appendix 
vi 
hyperparameter selection bayesian technique important consider ect values hyperparameters prior density quality nal map estimate 
ideally choice values uenced prior information available scientist regarding potential structure various scales aggregation 
argued earlier hyperparameters gamma prior placed total intensity critical estimation process practical problems interest total number counts fairly large data dominate gamma prior 
fact saw involved convergence analysis practice set small positive constant ectively eliminates role map estimation process see 
crucial choice beta density hyperparameters control regularity smoothness estimate 
hyperparameters may interpreted regularization parameters 
section iv noted map estimates splits coincide readily apparent 
setting tends stabilize estimates low count situations pushing map estimate away mle closer split indicative smoothness regularity intensity scale position 
large settings tend produce smoothing 
additional insight role hyperparameters may obtained considering stochastic process examining autocorrelation function 
handful examples demonstrate usefulness approach illustrating richness class possible models 
formally consider length vector stochastic process nite lattice 
technical reasons useful extend process shift invariant analogue discrete point circle may accomplished formally placing discrete uniform prior set possible shifts 
context proves stationary process 
autocorrelation function say may expressed non trivial closed form expression calculated straightforward manner xed choice hyperparameters 
course tremendous degree exibility choosing combination hyperparameters examine graphically 
result lemma suggests interesting point departure 
shows plots choices space hyperparameters region conditions lemma satis ed region boundary regions 
rst case process short range negative correlation induced second case process short range positive correlations case process zero correlation lags 
results illustrative suggest condition log prior density function concave delineates local separation space hyperparameters hyperplane sections corresponding processes positive negative short range dependencies 
issue currently studied greater depth authors 
fig 

autocorrelation shift invariant stochastic process 
cases shown examples corresponding choices inside outside boundary region conditions lemma satis ed 
left hand side greater zero 
left hand side zero 
left hand side equal zero 
practical perspective boundary case illustrated quite useful 
existing prior knowledge insucient knowing positive negative autocorrelation zero correlation model may acceptable option 
lines obtained satisfactory results approach see section vii 
set proportion average counts reconstructed intensity setting restricted greater equal 
set particular scheme selecting hyperparameters reduces free hyperparameters just key parameter gives adequate control behavior map estimator maintaining desire 
nal note mention previous results suggest interesting class priors obtained setting 
choice induced intensity prior spectral characteristics 
assume de ne log second moment beta prior density 
note lower upper bounds corresponds extreme limits beta density point mass point masses respectively 
implies 
shown autocorrelation function intensity prior induced multiscale prior approximated follows 
constants 
large term negligible correlation function behaves power spectrum decays jf see relationship autocorrelation functions power processes 
may relevant intensity analysis convincing empirical evidence natural intensity functions images similar spectral characteristics see comprehensive study 
suggests guideline hyperparameter selection 
prior knowledge spectral decay rate underlying intensity function seek may set accordingly 
indicated convergence analysis section setting beta hyperparameters common constant value general produce concave log posterior 
conversely general hyperparameter settings satisfy necessary sucient conditions lemma generate prior density spectral decay 
vii 
applications astronomical energy spectra analysis energy spectra standard task high energy astrophysics 
ultimate goal identify label spectral lines observed association object interest 
astrophysical spectroscopy stellar objects studied data take form photon counts di erent energy levels units electron volts ev 
high energy astrophysics necessary escape earth atmosphere obtain proper measurements task falls satellite instruments 
due geometry instruments things blurring introduced measurement process 
arrival high energy photons say ray gamma ray levels typically represented poisson process de blurring estimation underlying spectra may viewed poisson inverse problem 
calibration blurring ect may accomplished ground prior launching satellite knowledge transition matrix established 
depicts theoretical energy spectrum corresponding production gamma rays energetic particles interacting ambient solar atmosphere 
shows collection poisson counts corresponding spectrum simulated having observed instruments board compton gamma ray observatory 
due underlying physics measurement devices true energy photon entering instruments chance recorded lower energy level 
immediately apparent comparison figures 
recovery spectra notation corresponds sense redistribution counts higher energy levels matrix shows estimate recovered data multiscale method proposed preceding sections 
dicult specify explicitly underlying physics degree manner positive negative correlations exist set hyperparameter settings yield zero correlation model 
ideally spectra viewed simply collection lines entirely unrealistic model 
examining estimate obtained note locations spectral peaks relative heights widths reasonably captured 
energy mev energy mev energy mev fig 

bayesian multiscale map estimation astronomical spectral analysis 
theoretical energy spectrum mev energy range corresponding production solar 
counts simulated spectrum part observed instruments nasa 
map estimate underlying spectrum produced observed counts hyperparameter settings convergence declared jj jj jj jj required just iterations 
authors dr alex young unh simulating data example 
nuclear medicine imaging consider application multiscale framework emission computed tomography ect 
medical ect human subject injected radioactive pharmaceutical speci cally designed absorption certain bodily organs tissues 
distribution pharmaceutical subject provide functional anatomical diagnostic information 
obtain mapping pharmaceutical uptake data collected detecting gamma ray photons emitted subject pharmaceutical decays 
projection data indirect data problem wish estimate underlying pharmaceutical distribution intensity 
probability transition matrix derived physics geometry detection device data collection process 
ect intensity interest usually dimensional object basic multiscale framework easily extended multidimensional settings 
simple extension proposed 
illustrate extension focus dimensional problems ideas higher dimensions 
dimensions haar multiscale data analysis emission follows 
data fx de ne index refers resolution analysis correspond highest nest lowest coarsest resolutions scales respectively 
take multiscale splits factors corresponding multiplicative re nement coarse intensity ner intensities rst splitting horizontally vertically halves vertically horizontally splitting half quarters described 
take alternating vertical horizontal splitting fashion ectively maps problem multiscale representation handled bayesian framework 
alternatively possible consider fully re nement process simultaneously split coarse scaling coecient ner coecients 
case conditional parent child likelihoods binomial natural conjugate prior dirichlet beta density multiscale framework essentially 
illustrate application multiscale framework simulated ect problem 
underlying intensity simulation common shepp logan model standard benchmark ect 
intensity square image shown 
transition probability matrix corresponding parallel strip integral geometry radial samples angular samples distributed uniformly generated aspire software system 
applied obtain standard poisson random number generator synthesize projection data multiscale map reconstructions multiscale prior shown figures 
comparison show best likelihood reconstruction obtained stopping likelihood em algorithm best reconstruction reconstruction having smallest squared error impossible determine practice true intensity course unknown 
multiscale map em algorithms converge satisfactory reconstructions comparable quality obtained stopped likelihood em algorithm 
potential advantage multiscale approach ect hyperparameter settings reconstruction quality fairly interpretable stopping rules classical em approach notoriously dicult analyze 
fig 

bayesian multiscale map reconstruction emission computed tomography 
software phantom intensity total counts simulated projections 
likelihood em reconstruction stopped iterations optimal stopping minimum squared error reconstruction average squared pixel error reconstruction 
multiscale map em reconstruction average count pixel essentially weakest prior insures concavity convergence iterations average squared pixel error 
multiscale map em reconstruction average count pixel convergence iterations average squared pixel error 
multiscale map em reconstruction average count pixel convergence iterations average squared pixel error 
cases convergence declared jj jj jj jj viii 
extensions introduced new bayesian multiscale framework linear inverse problems involving poisson data 
foundation framework multiscale factorization poisson likelihood function induced recursive aggregation partitioning data space resulting re parameterization underlying intensity function directly captures intensity split location scale combination 
conjugate priors multiscale parameter space constrain manner splits may occur 
hyperparameters prior selected insure log posterior strictly concave allowed develop em algorithm guaranteed converge global map estimate 
furthermore prior simple interpretation easily tailored re ect prior belief smoothness unknown intensity 
class priors interesting feature non informative member yields traditional maximum likelihood solution 
bayesian approaches gauss markov random eld priors map solution guaranteed non negative 
computational perspective em algorithm comparable ecient techniques currently available em update equations simple closed form expressions 
potential new framework examined astronomical energy spectral analysis emission tomography applications 
extensions general framework outlined include translation invariant ti implementations wider classes prior densities 
ti implementations partially overcome strict dyadic underlying basic multiscale model 
additionally ti estimates regular approximately piecewise linear piecewise constant estimates associated traditional haar multiscale analysis 
terms prior models possible incorporate sophisticated information including known boundaries regions fusion information imaging modalities 
example structural information magnetic resonance image mri built multiscale prior selecting informative beta priors supporting smoothness edge position scale complementary multiscale decomposition mri 
extension replace beta priors beta mixtures 
beta mixture densities provide mechanism sophisticated modeling singularities 
example beta mixture consisting uniform density beta density sharply peaked represent possibility edge homogeneous structure respectively 
demonstrated map criterion associated certain beta mixture priors coincides minimum description length complexity regularization 
essentially em algorithm nd local map estimate conjunction priors course log posterior non concave cases 
possible account correlations nearby splits hidden markov model proposed poisson imaging problems 
models may provide ective modeling continuous boundaries images 
focused standard em algorithm quite possible implement framework expensive variants em may provide faster convergence sage 
example spect employed algorithm optimize multiscale map criterion 
remains study practical performance multiscale framework greater depth attempted section vii 
comparative studies example standard gibbs priors including analysis trade bias variance resolution noise needed explore potential new approach 
appendix convergence analysis proof lemma recall assume note restriction placed 
multiscale prior density de ned speci form expf standard change variables formula 
jacobian transformation 
may shown relation seen yield result equation 
proof lemma reduced proof expression equation 
show proof induction starting case 
case det fact matrix transpose share determinant applying method cofactors third fourth columns nd words existence non zero terms third fourth columns reduce determinant calculation matrix matrices 
algebra repeated equality terms scale yields result 
generally assume holds show implies case holds 
de ne il matrix partial derivatives 
note rows rst columns il obtained rows il matrix fashion 
rst elements rows equal elements th row il multiplied respectively 
follows fact scale re nement scale obtained simply splitting component pieces 
furthermore exactly new splitting factors moving di erentiation scale respect factors yields columns il reasons just mentioned variable components 
columns il contain nonzero terms zero terms 
nonzero terms rows preceded respectively rightmost product ancestral locations adopt approach proof transpose il applying method cofactors 
result reduce calculation determinant matrix il calculating weighted sum determinants matrices size weights determinants shown equal ml ml determinants expressed form 

ji write jl elements certain symmetry possible values value say th location mate contains components locations th 
combining elements discussion see write jl ml ml 
jl ml ml 
jl 
ml ml 
jl ml ml transition second third lines accomplished exploiting mentioned symmetry show sum 
completes proof 
term ancestral refers binary tree graphical representation multiscale parameterization 
location ancestor fn 
proof lemma noting term right double product involves summations components scales 
separating terms strictly scale yields expression log log 
log 
log constant depending 
follows hessian matrix log density expressed form log block diagonal matrix containing blocks size th block fully composed terms identically equal 
result non zero ir log de ned analogy letting pm see necessary sucient condition strict concavity fc satisfy inequalities 
see suces show equivalent inequality 
working right hand side ax ax ax ax step rst second line uses fact yz 
setting write necessary sucient condition strict concavity statement lemma immediately follows 
proof theorem proof follows result handful smaller lemmas establish sequence 
lemma monotonicity th iterate em algorithm denoted proof lemma follows case standard em algorithm likelihood see 
lemma iterates belong compact convex set 
proof lemma result lemma insures iterates belong set compact continuity behavior jj jj 
convexity follows concavity 
lemma euclidean distance jj jj tends zero 
proof lemma method proof nearly identical lemma 
de ne log zj jy log zj complete data likelihood function 
standard argument second order taylor series expansion right hand side may written line segment connecting algebra shows expression simpli es times 

jy 
rst component due conditional expectation complete data log likelihood standard maximum likelihood context shown greater equal jj constant strictly greater zero independent second component due log prior non negative conditions lemma 
follows jj jj lemma boundedness right hand side goes zero result follows 
lemma limit point sequence furthermore nite number limit points 
proof lemma argued analogous proof lemma 
rst part requires establish continuity positive components ir straightforward 
second part may argued number limit points bounded number possible subsets parameters 
lemma set limit points compact connected consists single member 
proof lemma identical lemma 
speci cally result lemma implies set limit points compact connected 
second part lemma elements set nite number consist single member order connected 
lemmas established theorem follows showing satis es kuhn tucker conditions optimization problem 
speci cally component require case established rst part lemma 
case argued proof contradiction proof analogous theorem 
completes proof theorem 
snyder miller random point processes time space 
new york springer verlag 
shepp vardi maximum likelihood reconstruction emission tomography ieee trans 
med 
imaging vol 
pp 

sullivan statistical perspective ill posed inverse problems statistical science vol 
pp 

basseville benveniste chou golden willsky modeling estimation multiresolution stochastic processes ieee trans 
inform 
theory vol 
pp 
mar 
donoho johnstone ideal adaptation wavelet shrinkage biometrika vol 
pp 

nowak multiscale modeling estimation poisson processes application photon limited imaging ieee transactions information theory vol 
pp 
april 
krim minmax description length signal denoising optimal representation ieee trans 
information theory vol 
april 
special issue wavelet transforms multiresolution signal analysis ieee trans 
inform 
theory vol 
march 
special issue multiscale statistical signal analysis applications ieee trans 
inform 
theory vol 
april 
starck multiscale image processing data analysis 
cambridge univeristy press 
donoho nonlinear solution linear inverse problems wavelet decomposition app 
comp 
harmonic analysis vol 
pp 

abramovich silverman wavelet decomposition approaches statistical inverse problems biometrika vol 
pp 

katsaggelos spatially adaptive wavelet multiscale image restoration ieee trans 
image processing vol 
pp 

wang 
pan solution inverse problem image processing wavelet expansion ieee trans 
image processing vol 
pp 

kolaczyk wavelet shrinkage approach tomographic image reconstruction amer 
statist 
assoc vol 
pp 

kolaczyk bayesian multi scale models poisson processes amer 
statist 
assoc vol 
pp 

kolaczyk observations tractability certain multi scale models bayesian inference wavelet models pp 
springer verlag 
editors uller vidakovic 
nowak multiscale hidden markov models bayesian image analysis bayesian inference wavelet models pp 
springer verlag 
editors uller vidakovic 
sullivan blahut snyder information theoretic image formation ieee trans 
info 
theory vol 
pp 

mclachlan krishnan em algorithm extensions 
new york wiley 
vardi shepp kaufman statistical model positron emission tomography amer 
statist 
assoc vol 
pp 

feasible images practical stopping rules iterative algorithms emission tomography ieee trans 
med 
imaging vol 
pp 

lange little theoretical study maximum likelihood algorithms emission transmission tomography ieee trans 
med 
imaging vol 
pp 

hebert leahy generalized em algorithm bayesian reconstruction poisson data gibbs priors ieee trans 
med 
imaging vol 
pp 

green bayesian reconstruction emission tomography data modi ed em algorithm ieee trans 
med 
imaging vol 
pp 

hero penalized maximum likelihood image reconstruction space alternating generalized em algorithms ieee trans 
image processing vol 
pp 

bouman sauer uni ed approach statistical tomography ieee trans 
image processing vol 
pp 

tsui simulation evaluation gibbs prior distributions maximum posteriori spect reconstructions ieee trans 
med 
imaging vol 
pp 

bhatia karl willsky wavelet method multiscale tomographic reconstruction ieee trans 
med 
imaging vol 
pp 

multiresolution tomographic reconstruction wavelets ieee trans 
image processing vol 
pp 

abramovich silverman wavelet thresholding bayesian approach roy 
statist 
soc 
ser 
vol 
pp 

kolaczyk wavelet shrinkage estimation certain poisson intensity signals corrected thresholds statistica sinica vol 
pp 

nowak baraniuk wavelet ltering photon imaging systems ieee trans 
image processing vol 
pp 

nowak kolaczyk multiscale map estimation method poisson inverse problems proc 
nd asilomar conf 
signals systems comp paci grove ca pp 
ieee computer society press 
bouman sauer multiresolution non homogeneous mrf model bayesian tomography preprint 
submitted ieee transactions image processing 
mallat wavelet tour signal processing 
san diego ca academic press 
lauritzen graphical models 
clarendon press 
robert bayesian choice decision theoretic motivation 
new york springerverlag 
mauldin sudderth williams polya trees random distributions ann 
stat vol 
pp 

aspects polya tree distributions statistical modelling ann 
stat vol 
pp 

modi ed expectation maximization algorithm penalized likelihood estimation emission tomography ieee trans 
med 
imaging pp 

lange carson em reconstruction algorithms emission transmission tomography comp 
assist 
vol 
pp 

cover algorithm maximizing expected log investment return ieee trans 
inform 
theory vol 
pp 

lange convergence em image reconstruction algorithm gibbs smoothing ieee trans 
med 
imaging vol 
pp 

csisz ar information geometry alternating minimization procedures statistics decisions supplementary issue pp 

wu convergence properties em algorithm annals statistics vol 
pp 

wornell signal processing fractals 
wavelet approach 
englewood cli new jersey prentice hall 
van der schaaf van hateren modelling power spectra natural images vision research vol 
pp 

murphy solar spectroscopy comparisons energetic particle coronal astrophysical journal vol 
pp 

instrument description performance imaging telescope aboard compton gamma ray observatory astrophysical journal supplement series vol 
pp 

aspire user guide sparse iterative reconstruction library communication signal processing laboratory technical report department electrical computer engineering university michigan ann arbor 
nowak figueiredo unsupervised progressive parsing poisson elds minimum description length criteria proceedings ieee conference image processing kobe japan october 
nowak multiscale hidden markov models photon limited imaging proceedings spie conf 
mathematical modeling bayesian estimation inverse problems denver july 
hero space alternating generalized expectation maximization algorithm ieee trans 
signal processing vol 
pp 

hudson larkin accelerated image reconstruction ordered subsets projection data ieee trans 
med 
im vol 
pp 

nowak kolaczyk tsui bayesian multiscale framework spect proceedings ieee medical imaging conference seattle wa october 

