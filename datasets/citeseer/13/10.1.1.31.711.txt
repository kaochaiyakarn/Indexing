conversation system framework designing embodied conversational agents justine cassell tim bickmore lee campbell hannes hao yan embodied conversational agents just computer interfaces represented way human animal bodies 
just interfaces human animal bodies lifelike believable actions reactions human users 
embodied conversational agents specifically conversational behaviors specifically way bodies conversation 
embodied conversational agents may defined properties humans face face conversation including ability recognize respond verbal nonverbal input ability generate verbal nonverbal output ability deal conversational functions turn feedback repair mechanisms ability give signals indicate state conversation contribute new propositions discourse design embodied conversational agents puts demands system architecture 
chapter describe conversational framework expressed list conversational properties abilities demonstrate lead set architectural design constraints 
describe architecture meets constraints implementation architecture exhibits properties abilities required real time natural conversation 
research computational linguistics multimodal interfaces computer graphics autonomous agents led development increasingly sophisticated autonomous semi autonomous virtual humans years 
autonomous self animating characters sort important production animation interfaces computer games 
increasingly autonomy comes underlying models behavior intelligence simple physical models human motion 
intelligence refers increasingly just ability reason social ability engage human interesting relevant conversation appropriate speech body behaviors 
research concentrates social linguistic intelligence conversational implement type virtual human social linguistic abilities carry face face conversation 
call embodied conversational agents 
current grows experience developing prior systems animated conversation cassell ymir th risson 
animated conversation system produce automatically context appropriate gestures facial movements intonational patterns animated agents deep semantic representations information provide real time interaction user 
ymir system focused integrating multimodal input human user including gesture gaze speech intonation capable limited multimodal output real time 
currently developing embodied conversational agent architecture integrates real time multimodal aspects ymir deep semantic generation multimodal synthesis capability animated conversation 
believe resulting system provides reactive character nuances human face face conversation intuitive robust 
believe system provides strong platform continue development embodied conversational agents 
believe conversational framework developed underpinnings system general inform development different kinds embodied conversational agents 
motivation number motivations exist relying research human face face conversation developing embodied conversational agent interfaces 
general motivation arises fact conversation primary skill humans early learned skill practiced fact infants mothers take turns fact body equipped support conversation 
facts lead believe embodied conversational agents may turn powerful ways humans interact computers 
essential part belief order embodied conversational agents live promise implementations actual study human human conversation architectures reflect intrinsic properties 
second motivation basing design architectures study human human conversation arises examination particular needs met current interfaces 
example ways dialogue systems robust face imperfect speech recognition increase bandwidth low cost support efficient collaboration human machines humans mediated machines 
believe embodied conversational agents fulfill needs functions exactly bodies bring conversation 
functions carefully modeled interface 
motivations expressed form beliefs date adequate embodied conversational agent platform existed test claims 
implementations smart exist turn evaluation abilities see example nass lee chap 
oviatt adams chap 
sanders scholtz chap 

remainder chapter conversational framework 
discuss framework drive design architecture control animated character participates effectively conversational interaction human 
architecture developing meet design requirements describe conversational character constructed architecture rea 
outlining challenges endeavor faces including evaluation design claim 
human face face conversation address issues motivations outlined developed functions modalities timing behaviors conversational framework structuring conversational interaction embodied conversational agent human user 
general terms conversational behaviors conversational framework support conversational functions conversational action modality may convey communicative goals 
section motivate describe framework discussion human face face conversation 
face face conversation exchange information order exchange proceed orderly efficient fashion participants engage elaborate social act involves behaviors mere information bearing words 
spontaneous performance seamlessly integrates number modalities effort 
key features allow conversation function distinction propositional interactional functions conversation conversational modalities importance timing conversational behaviors increasing synchrony conversational participants distinction conversational behaviors conversational functions interactional propositional functions conversation portion goes conversation said represent actual thought conveyed propositional content behaviors serve sole purpose regulating interaction goodwin kendon 
refer types contribution conversation behaviors propositional function behaviors interactional function respectively 
propositional information includes meaningful speech hand gestures intonation complement elaborate speech content 
interactional information likewise include speech non speech behaviors 
production interpretation propositional content rely knowledge wishes say dynamic model discourse context includes information previously conveyed kinds reasons conveying new information 
interactional content includes number cues indicate state conversation 
range nonverbal behaviors head nods regulatory speech huh go 
primary role interactional information negotiate speaking turns 
listeners indicate receive turn example raising hands space front bodies nodding excessively speaker reaches phrase 
speakers indicate want keep turn example keeping hands raised gazing away listener 
cues particularly useful speaker pauses speech may listener jump 
turn behavior listener feedback signs agreement simple am cues examples kind parallel activity occurs face face conversation 
speakers listeners monitor behavior continuously interaction simultaneously producing receiving information argyle cook simultaneously conveying content regulating process conveying content 
multimodality convey multiple communicative goals communicative behaviors different communicative behaviors carried time 
possible fact disposal number modalities overlap disruption 
example speaker add certain tone voice raising eyebrows elicit feedback form head nod listener interrupting production content 
different modalities communication hand gestures facial displays eye gaze forth allows pursue multiple goals parallel propositional nature interactional nature 
important realize speech prominent conveying content face face conversation spontaneous gesture integral conveying propositional content 
fact speech gesture produced simultaneously take form arises underlying representation cassell chap 
mcneill 
gets conveyed speech gets conveyed gesture matter particular surface structure shape 
interactional communicative goals modality chosen may function modality free example head currently engaged looking task free give feedback nod 
timing existence quick behaviors head nods immediate effect conversational participant emphasizes range time scales involved conversation 
able interpret full utterances produce meaningful responses sensitive instantaneous feedback may modify production go 
gaze speech nods gaze speech nods app nt ly 
ms sec ms right ms nod nod nod nod nod ms 
wide variety time scales human face face conversation 
circles indicate gaze moving lines indicate fixation squares withdrawal gaze question mark shows rising intonation adapted goodwin 
addition synchrony events lack thereof meaningful conversation 
slightest delay responding conversational events may taken indicate cooperate strong disagreement rosenfeld 
demonstrated speakers listeners attend produce behaviors wide variety time scales 
remarkable course conversation participants increasingly synchronize behaviors 
phenomenon known entrainment ensures conversation proceed efficiently 
conversational functions carried conversational behaviors conversation orderly event governed rules conversations look exactly set behaviors exhibited differs person person conversation conversation 
functions referred guide conversation 
typical discourse functions include conversation invitation turn providing feedback contrast emphasis breaking away 
successfully build model conversation works refer surface features conversational behaviors 
emphasis identifying fundamental phases high level structural elements conversation 
elements described terms role function exchange 
table especially important particular behaviors raising eyebrows employed variety circumstances produce different communicative effects communicative function may realized different sets behaviors 
form give particular discourse function depends things current availability modalities face hands type conversation cultural patterns personal style 
example feedback head nod nodding say uh huh see different context head nod indicate emphasis salutation feedback 
table shows important conversational functions behaviors realize 
discussion clear extensive body engaged face face conversation 
natural evolved language social competence 
elaborate system behaviors requires minimal conscious effort type real time human human interaction phone conversation rival face face interaction comes user satisfaction conclude affordances body conversation unique 
ability handle natural conversational interaction particularly critical real time embodied conversational agents 
conversational framework relies interaction properties conversation described pursuing interactional propositional functions multimodality timing distinction conversational behaviors conversational functions 
review related turning demonstration model provides natural design framework embodied conversational architectures related argued embodied conversational agents designed research function verbal nonverbal modalities human human conversation 
authors volume adhere principle greater lesser extent 
interface design followed path past particular domain multimodal interfaces 
research multimodal interfaces concentrated question understanding verbal nonverbal modalities embodied conversational agents understand generate behaviors different conversational modalities 
sections follow review previous research fields conversational interfaces multimodal interfaces turning embodied conversational agent resembles 
synthetic multimodal conversation animated conversation cassell system automatically generated context appropriate gestures facial movements intonational patterns 
case domain interaction bank teller customer 
order avoid issues involved understanding human behavior interaction took place autonomous graphical agents emphasis production nonverbal behaviors emphasized reinforced content speech 
animated conversation turn conversational behaviors content conveying conversational behaviors implemented distinction conversational behaviors functions fulfilled 
function filled behavior 
notion conversational function interactional propositional distinction explicitly 
problem system run real time interaction real user impossible extend actual human computer interaction 
andr 
chap 
implement system conversation synthetic characters purpose presenting information human motivated engaging effect teams 
domains explored car sales robocup soccer emphasis conveying character traits domain information 
car domain goal decomposition break presentation speech acts personality interest profiles combination multi attribute utility theory organize presentation automotive features values 
result sequence questions answers comments seller buyers 
modalities explored primarily speech intonation pointing hand gestures 
conversational behaviors generated system fulfill propositional goal convey personality emotional traits interactional goals considered 
conversational interfaces pioneers modeling computer interface basis human conversation 
provided list features face face conversation fruitfully applied human computer interaction including mixed initiative nonverbal communication sense presence rules transfer control 
concern necessarily systems carried conversations humans model allowed management explicit representation turn user expectations harnessed service clearer interaction computer 
brennan argues human computer interaction literature false dichotomy direct manipulation conversation 
observations human human conversation brennan develops guidelines designers wimp conversational interfaces 
key guidelines include modeling shared understandings provisions feedback repair sequences 
brennan essential model 
badler 
chap 
conversational interface avatar control task 
avatars interact jack moo virtual world controlled natural language commands walk door turn handle slowly developed parameterized action representation map high level action labels low level sequences avatar activity 
humans give orders avatars act speak avatars may converse fully automated characters virtual world 
human interface effectively command control multimodal conversation occurs avatars automatic characters 
interactional functions turn considered system 
addition hard mapping conversational behaviors conversational functions making different modalities somewhat inflexible 
multimodal interfaces multimodal systems study nonverbal modalities conversation put 
put speech recognition degree freedom space sensing device gather user gestural input allow user manipulate wall sized information display 
put simple architecture combined speech deictic gesture input single command resolved system 
example system understand sentence move mean move sofa depicted wall display position near table analyzing position pointing gestures user 
case speech drove analysis user input 
spoken commands recognized gesture input user command resolved speech analysis 
certain words speech grammar tagged indicate usually occurred deictic pointing gesture 
words encountered system analyzed user pointing gestures resolve deictic 
extended allowing users maneuver objects dimensional map spoken commands deictic hand gestures eye gaze th risson 
system nested frames employed gather combine information different modalities 
put speech drove analysis gesture information missing speech system search missing information gestures gaze 
time stamps united actions different modalities coherent picture 
wahlster similar method depending typed text input guide interpretation pointing gestures wahlster 
examples exhibit features common command control type multimodal interfaces 
speech driven input modalities speech recognition produces ambiguous incomplete results 
input interpretation carried user finished utterance meaning phrase level shortest time scale events occur 
interface responds complete formed input attempt nonverbal behavior interactional information control pace user computer interaction 
limitations partially overcome johnston described approach understanding user input unification strongly typed multimodal grammars 
pen speech interface gesture voice produce input drive recognition process 
multimodal input represented semantic frames empty slots missing information 
slots filled considering input events correct type occurred time 
different tack massaro 
chap 
nonverbal behavior baldi embodied character face increase synthetic speech prove efficacy testing speech readers recognition rate baldi 
output demonstrates improved intelligibility lip shapes correct authors shown utility system teaching spoken conversation deaf children 
missing systems distinction conversational behavior conversational function 
means addition notion particular modality goals achieved congruence different modalities 
case multiple communicative goals propositional interactional example considered 
role gesture voice input analyzed sentence constituent replacement level 
embodied conversational interfaces lester 
chap 
rely notion semantic function order generate verbal nonverbal behavior producing deictic gestures choosing referring expressions function potential ambiguity objects referred proximity objects animated agent 
system understanding achieved objects physical space animated agent utility deictic gestures reducing potential ambiguity 
generation gestures choice referring expressions library voice clips accomplished entirely independent additive processes description interaction function filled modalities 
rickel johnson chap 
designed pedagogical agent steve travel virtual ship guiding student equipment gaze deictic gesture verbal lesson equipment 
agent handles verbal interruption provides verbal nonverbal feedback form nods student performance 
steve verbal nonverbal conversational behaviors way time behaviors level word syllable 
nonverbal behaviors hardwired function steve reason modalities better suited serve particular functions particular places conversation 
contrast systems current approach handles multimodal input output conversational functions may interactional propositional nature 
basic modules architecture described section developed conjunction churchill 
chap 

architecture grows previous research group ymir architecture th risson 
main emphasis development multilayer multimodal architecture support fluid face face dialogue human graphical agent 
agent gandalf recognized displayed interactional information gaze simple gesture produced propositional information form canned speech events 
way able perceive generate turn back channel behaviors lead natural conversational interaction 
provided example verbal nonverbal function paired conversational multimodal interface 
gandalf limited ability recognize generate propositional information providing correct intonation speech emphasis speech output gesture occurring speech 
approach rea combines lessons learned gandalf animated conversation projects 
embodied conversational agent architecture model described summarized follows multiple interactional propositional communicative goals conveyed conversational functions expressed conversational behaviors modalities 
model serves strong framework system design lacking embodied conversational agents 
designed generic architecture derives directly conversational framework described 
feel crucial capable employing repertoire conversational skills human obviate need users learn interact agent maximize naturalness fluidity interaction 
believe order enable conversational skills architecture system designed affordances necessities conversation 
design draw directly rich literature linguistics sociology human ethnography described previous section derive requirements conversational framework 
general terms conversational model described leads set eca architectural design requirements understanding synthesis propositional interactional information 
dealing propositional interactional functions conversation requires models user needs knowledge user conversational process states 
producing propositional information requires planning module plan output manage order presentation interdependent facts 
architecture include static domain knowledge base dynamic discourse knowledge base 
understanding interactional information hand entails building model current state conversation respect conversational process current speaker listener listener understood speaker contribution 
multimodal input output 
humans face face conversation send receive information gesture intonation gaze speech architecture support receiving transmitting information modular new input output modalities easily added new technologies developed 
timing 
importance working different time scales synchrony behaviors system allow embodied conversational agent watch feedback turn requests human send time various modalities 
architecture flexible track different threads communication ways appropriate thread 
different threads different response time requirements feedback interruption occur time scale 
architecture reflect fact allowing different processes concentrate activities different timescales 
conversational function model 
explicitly representing conversational functions simply set conversational behaviors provides modularity principled way combine different modalities 
functional models influence architecture core modules system operate exclusively functions sentences example modules edges system infer functions input realize functions outputs 
produces symmetric architecture functions modalities input output 
previous experience animated conversation ymir developed architecture handles real time response interactional cues understanding generation propositional content 
interactional propositional functions capable filled conversational behaviors modalities 
input devices speech body position gaze gesture input manager hardwired reaction deliberative module understanding module architecture 
decision module interactional processing propositional processing response planner knowledge base discourse model generation module speech gesture generation action scheduler architecture follows sequential processing user input see fig 

input manager collects input output devices speech body position gaze gesture modalities decides data requires instant reaction deliberative discourse processing 
hardwired reaction handles quick reactions stimuli appearance side side movement user 
stimuli provoke modification agent behavior delay 
example agent gaze seamlessly track user movement 
deliberative discourse processing module handles input requires discourse model proper interpretation 
includes interactional behaviors propositional behaviors 
action scheduler responsible scheduling motor events sent animated representing agent 
crucial function scheduler prevent collisions competing motor requests 
modules architecture described 
input manager order support integration multimodal input user input manager obtains data various input devices converts form usable modules system routes results deliberative module 
interactional information forwarded directly action scheduler module way hardwired reaction module minimize system response time changing character gaze track change user location 
input manager typically receive information devices provide speech text user gesture location gaze information modalities 
cases features sent input manager time stamped start times milliseconds 
hardwired reactions hardwired reactions enable character respond immediately certain unimodal user inputs require fast reaction require inferencing discourse model 
examples include tracking user location character eyes responding user suddenly entering leaving interaction space 
deliberative module order maintain coherence conversation track user focus deliberative discourse processing module maintains discourse model entities introduced conversation previous statements user agent information user ultimate intermediate communicative goals terms housing requirements real estate domain 
components module grouped update data structures 
deliberative module performs action selection function architecture determines agent contribution conversation moment time 
receives asynchronous updates input manager uses information domain static knowledge base current discourse state determine conversational action perform 
processing split main components understanding decision generation see fig 

understanding module responsible fusing input modalities coherent understanding user doing translating set behaviors discourse function interactional propositional 
passes decision module form speech acts 
processing decision module split processing interactional communicative acts contribute management conversational situation processing propositional communicative acts contribute content discussion 
interactional processing submodule responsible updating conversational state conversation user started turn interaction put hold user momentarily attends see fig 

propositional processing submodule responsible choosing adequate responses propositional input example answering questions communicating response planner necessary 
conclude hold 
interactional conversational states 
important interactional propositional processes access common discourse model interactional information plays role validating discourse history updates 
example propositional submodule send generation module speech act realized 
interactional part detects agent successfully concluded utterance interruption user system consider add new proposition shared knowledge discourse history 
response planner responsible formulating sequences actions need executed execution cycles carry desired communicative task goals 
generation module responsible turning discourse functions giving turn conveying communicative goal chosen decision module actual surface behaviors producing set coordinated primitive actions speech gesture facial expression combination sending actions action scheduler performance 
action scheduling module action scheduler motor controller embodied agent responsible coordinating output actions lowest level 
takes set atomic modality specific commands executes synchronized way 
accomplished event conditions specified output action define action executed 
architecture summary moving studying conversation humans implementing computer systems moving rich description naturally occurring phenomenon parametric implementation 
process certain aspects phenomenon emerge feasible implement certain aspects phenomenon emerge key functions implementation sense 
conversational model way gathering functions essential implementation design framework architecture 
section address implementation comes architecture designed way 
implementation developing embodied conversational agent architecture capable having real time face face conversation human 
agent named rea real estate agent plays role real estate salesperson interacts users determine needs shows virtual properties attempts sell house 
chose domain real estate amount talk social function provokes couldn pass phrase experiment virtual 
order put clients ease able conceive amount money needed purchase house engage lot talk mixed social interactional function propositional function 
domain allowed agent capable dealing multiple communicative goals interactional propositional contributions discourse way conversational behaviors carried modalities 
rea fully articulated graphical body communicates verbal nonverbal modalities 
able describe features house combination speech utterances gestures respond users verbal nonverbal input 
user cues typically associated turn behavior gesturing rea allows interrupted takes turn able 
able initiate conversational repair user says 
rea speech gesture output generated real time underlying knowledge base description communicative goals spud natural language generation engine stone 
excerpt sample interaction lee approaches projection screen 
rea currently turned side gazing 
lee moves range cameras mounted screen rea turns face says rea hello 
help 
lee looking buy place near mit 
rea nods indicating 
rea house show 
picture house appears screen rea blinks looks house lee 
rea 
lee tell 
rea looks away plans say 
rea big 
rea expansive gesture hands 
lee brings hands speak rea continue waiting speak 
lee tell 
rea sure thing 
nice garden 
rea sketches curved gesture hands indicating garden extends sides house 
lee far 
rea minutes porter square station 
rea clear minutes foot station making walking gesture fingers 
lee big house 
rea bedrooms 
lee interrupts rea stops speaking immediately 
lee wait 
tell master bedroom 
rea sorry didn catch 
ask lee master bedroom 
rea 
rea points 
lee master bathroom 
rea bedroom 
rea brings hands indicate relationship bedroom bathroom 
house tour continues 
system currently consists large projection screen rea displayed front user stands 
cameras mounted top projection screen track user head hand positions space 
users wear microphone capturing speech input 
single sgi octane computer runs graphics conversation engine rea computers manage speech recognition generation image processing fig 

system implemented clips clips rule expert system programming language 
modularity system design possible kqml performatives common message protocol interagent communication finin send receive messages different modules 

rea says bedroom 
sections discuss detail implementation embodied conversational agent architecture rea system 
discussion rea implementation follow discussion architecture moving input manager discourse processing module action scheduler graphics generation 
input sensors function input manager architecture handle verbal nonverbal inputs different devices prepare understanding 
input rea input manager currently receives types gesture input vision software azarbayejani wren pentland uses video cameras track flesh color produce position orientation head hands fifteen updates second 
audio input simple audio processing routine detects onset pauses cessation speech 
grammar speech recognition speech piped pc running ibm returns text set phrases defined grammar 
data sent input manager time stamped start times milliseconds 
various computers synchronized milliseconds ntp network time protocol clients 
synchronization key associating verbal nonverbal behaviors 
low level gesture audio detection events sent deliberative module immediately 
events stored buffer recognized speech arrives high level multimodal kqml frame created containing mixed speech audio gesture events 
sent understanding module interpretation 
discourse processing deliberative processing module core part architecture 
handles interactional propositional facets discourse 
rea deliberative processing modules written clips 
propositional interactional elements considered integrated fashion points system describe separately expository purposes 
interactional discourse processing processing interactional information rea involves speech primarily handling non speech content inputs outputs 
understanding module receives kqml frame input manager contains tagged user input including information vision system presence absence user gesturing information audio threshold detector user started speaking paused finished speaking understanding module looks current conversational state shown fig 
known state inputs deciding map particular input discourse function 
example user paused speaking conversational state user floor rea take turn seconds functional descriptor created indicating user utterance acknowledged possible 
decision module center rea inputs input discourse functions describing user actions outputs output discourse functions rea execute 
receipt interactional message understanding module decision module consults current conversational state decides output action conversational state change 
example conversational state decision module receives message interactional output message constructed sent generation module execution state remains 
generation module maps requests output discourse functions specific output behaviors channel availability defines synchronization requirements action scheduler execute 
example interactional output function received rea head currently higher priority behavior action scheduler command generated sent cause rea nod head head busy feedback generated means uh huh 
propositional discourse processing processing propositional information primarily involves understanding processing speech inputs generation speech gestural outputs 
mentioned understanding module receives kqml frame input manager contains tagged user input 
understanding module main propositional task convert speech input valid speech act resolving referring expressions 
kqml tags speech recognizer describe contents utterance type speech act performed ferguson addition identification discourse entities 
understanding module finished binding discourse entities new utterance existent knowledge base entries tries fill speech act template 
template type chosen incoming speech act tag templates may preconditions associated fulfilled order selected 
way choice template sensitive discourse model states 
speech act template selected filled sent decision module needs evaluate effect choose response 
evaluation may update facts dynamic knowledge base create obligation agent needs attend 
agent perform simple plan reasoning come speech acts achieve obligation communicative goal 
agent commits execution plan intending execute speech act plan 
time act relevant speech act template filled handed generation module realization interactional functions need executed order contribute successfully conversation 
rea communicative goal speech act accomplished speech utterance combination speech utterance appropriate gesture gestures 
task speech gesture generation module construct communicative action achieves goals 
propositional goals need convey domain propositions encode specified kinds information specified object 
communicative action generated fit context specified discourse model best extent possible 
spud generator sentence planning introduced stone doran carry generation task 
shows structure simultaneous speech gesture generation process generation module 
utterance generation process starts decision module sends generation speech act 
generation speech act usually describe object aspect form 
request converts communicative goal understood spud generator 
structure context private shared knowledge generation speech acts request attentional state spud server discourse history shared knowledge speech gesture description pragmatics syntactic frames lexicon speech gesture generation 
structure context private shared knowledge syntactic frames lexicon construct basic background knowledge base spud draw communicative content 
lexical items speech constraints movements gestures treated equally lexicalized descriptors knowledge base 
organization background knowledge base defines common ground terms sources information user rea share 
describes relationship rea privately held information questions interest user information settle 
necessary syntactic semantic constraints utterances specified background knowledge base 
conversation spud gets dynamic updates rea discourse model keep top changing state context conversation 
updates include current attentional state discourse grosz sidner shared knowledge update common ground clark marshall pragmatics spud looks prove entry 
communicative goal background knowledge base updated context current conversation spud builds utterance element element stage construction spud representation current incomplete utterance specifies syntax semantics interpretation fit context 
generation process successful speech utterance appropriate gesture descriptions generated 
gestures generated generation process convey piece meaning conveyed speech utterances 
gestures condition increase expressiveness robustness communication 
gestures complement speech utterances convey additional information conveyed speech utterances 
case communicative load distributed speech gestures 
generation process currently uses combination kinds rules determine generate complementary redundant gesture grouping rules determine aspects object action articulated appropriateness rules determine aspects semantics appropriate easier expressed gesture channel appropriate gesture best represent semantics kqml frame containing description sent action scheduler execution 
output system multimodal real time architectural requirements call careful design output system 
particular embodied conversational agent needs near perfect coordination speech nonverbal behavior gesturing 
slightest mismatch look unnatural fact convey different intended 
modularity extensibility architecture require defined interfaces various components output system inspired implementation plug style motor skill mechanism 
output system rea consists main components scheduling component animation component rendering component 
map eca architecture action scheduler output devices respectively 
scheduler receives requests activation various behaviors generation module 
requests include interdependencies behaviors requirements behavior finishing starts 
scheduler responsible successfully sequencing pending behaviors 
animator assigns behavior ready executed motor skill responsible animating joints model communicating renderer fig 

behavior scheduling animation rendering layers output system scheduling animation rendering 
scheduler behavior description preconditions manner execution sent scheduler kqml message 
generation module typically sends scheduler set behaviors properly triggered meant carry single function example invitation start conversation 
scheduler instructed notify generation module kqml callback messages certain events occur completion output behavior sequence 
event callback action scheduler motor skill manager motor skill motor skill motor skill arbitrator body model speech execution behaviors scheduler event driven difficult accurately predict output behavior execution timings making impossible plan callback completely synchronized execution sequences advance 
addition behaviors produce meaningful events executed speech synthesis behavior produce event word produced allow behaviors started stopped events occur 
shows example event driven plan executed action scheduler dependencies individual behaviors 

look away 
look user 

ready ght 
beat pe 

bui ding 
hi gh gest re pe ding 
time pre event arti tg pre pl os del fo event st rt nga example synchronized speech gesture output action scheduler 
specification sent action scheduler contains description individual behavior executed content clause precondition start behavior clause optional symbolic label id preconditions behaviors 
shows kqml input specification plan shown 
action id away immediate content cmd away object user action id offset event away time content cmd object user action id event content speak content action event start content cmd ready action event word content cmd beat action id bldg offset event cond time content speak content building boston action event bldg word content cmd compose trajectory hand bend action event bldg content cmd relax action scheduler kqml input specification plan shown 
action scheduler works managing set primitive behavior objects represents set animations right arm gestures 
behavior commanded start acquires body degrees freedom dof requires set right arm hand joints 
goes starting phase perform initialization moving arm ready position 
behavior actions carried update phase ends behavior reaches natural stopping point explicitly commanded behavior preempts grabbing dofs 
returning idle behavior go phase perform wrap operations needed returning arm rest position 
scheduler nonverbal behavior ready execution passes description animator 
actions involving character body executed directly example verbal behavior sent speech synthesizer 
animator animator checks motor skill manager see motor skill capable handling request registered 
task animating joints model broken separate motor skills part different skills called different methods animation 
motor skills range straightforward ones executing single head nod elaborate ones employing inverse kinematics pointing objects playing key frame animation 
motor skill activated asks arbitrator body dofs needs modify 
skills ask dof higher priority captures 
depending implementation particular skills losing skill keep trying capture dof 
feature useful instances continuous behavior momentarily interrupted instantaneous character tracking user gaze gets asked glance away higher priority 
glance completed tracking automatically resumes 
arbitrator responsible keeping track dofs allocating skills request 
skills access information environment including virtual objects perceived user position shared world 
motor skills controlling facing accept names objects parameters 
renderer rendering engine abstracted away animator introducing body model layer essentially maps dof name corresponding model transformation 
implemented body model interfaces vrml scene graph rendered tgs 
naming character dofs follows anim vrml humanoid specification compatibility evaluation chapter argued architectures embodied conversational agents built model human human conversation 
provided model form set properties human human conversation believe essential allowing computers carry natural conversations humans 
note important point assumption order maximally effective systems permit interactions people computers resemble conversations respects argued chapter successful model conversation picks facets human human conversation feasible implement implementation eca sense 
claims evaluated 
date empirical evaluations kinds embodied interfaces results 
shneiderman points ample historical evidence form junk pile abandoned anthropomorphic systems exists designs interface 
van mulken specifically examining evaluations animated interface agents conclude benefits systems arguable terms user performance engagement system attributions intelligence 
point virtually systems evaluated exploited affordances human bodies inhabited design paradigm expected improve human computer interaction shows behavior functional regard system aim words embodiment sake pretty graphics probably 
note embodied conversational agents implemented near range conversational properties outlined 
reason start carry rigorous evaluations benefits conversational embodiment 
evaluation system takes forms 
evaluate adequacy model serves design framework evaluate implementation design evaluate artifact results evaluate eca human computer interface 
evaluation conversational model method evaluating conversational model look theory pointed implementation 
example earlier system animated conversation interactional propositional functions handled entirely separately system architecture 
assumed utterance communicative goal 
unexpected result head nods hand gestures generated performed interactional performed propositional function 
result current conversational model allows multiple communicative goals utterance may interactional propositional 
evaluation current conversational model pointed weak spot understanding relationship conversational behaviors conversational functions 
particular clear way predicting conversational behaviors vehicle particular conversational behaviors 
theory generativity conversational behaviors conversational functions 
particularly difficult arena true generation hand gestures 
may know gesture convey propositional content content garden surrounds house autonomously generate stages production process way predicting shape hands movement hands best represent content 
moment resolve providing list conversational behaviors 
hope principled method solving problem 
look issue morphology conversational behaviors see topic research group 
evaluation implementation method evaluating implementation simply see aspects architecture model translated system behaviors 
aspects badly imperfectly translated 
evaluation aspect conversational model strikingly difficult implement feature timing 
fact evaluation current implementation points weaknesses respect timing synchrony 
respect speed natural language generation engine currently fast provide sense entrainment human users 
users get sense rea thinking long speaks 
implemented deliberative discourse processing module hardwired reaction module handle different time scales slowness noticeable 
rea reacts instantly takes long 
respect synchrony resolved issue time gestures perfectly respect speech accompany 
example hand gestures may occur somewhat speech generated 
simply gives impression system working correctly rea bit dim 
problem due primarily difficulty synchronizing events output devices predicting advance long take execute particular behaviors 
difficult predict synchronize timing speech synthesis produced text speech engine graphical representations hand movements produced rendering engine 
order address problem currently looking text speech engines may give phoneme timings advance facilitate predicting long take utter particular phrase 
profound solution line conversational model endow action scheduler intelligence issues timing synchrony 
conceive action scheduler doesn allow behaviors generated works kinds timing constraints 
topic research 
evaluation interaction evaluate quality rea interface having interact untrained users 
course entirely free interaction user allow know rea ready prime time real estate market allow pinpoint source difficulties users interaction 
nass lee chap 
describe evaluate performance embodied conversational agent series wizard oz experiments manipulate variables time 
comparing rea ancestors see cassell th risson details citations identical body uttering identical words nonverbal interactional behaviors users judged version interactional behaviors collaborative cooperative exhibit better natural language versions identical natural language abilities 
hand performance task significantly different groups 
evaluation rea cousins graphical world anthropomorphic avatars autonomously generate conversational behaviors described show positive benefits task performance 
users study preferred autonomous version menu driven version behaviors cassell 
currently conducting evaluation compares face face conversation rea conversation telephone dialogue system user believes system rea dialogue system autonomous manipulated human real time 
look effect conditions users perception system efficiency carrying task performance task 
way hope evaluate particular conversational properties conversational model 
motivations embodied conversational agents dialogue systems comes increasing computational capacity objects environments outside desktop computer smart rooms intelligent toys environments diverse military battlefield children museum users different imagine 
part reason continue pursue dream computers keyboards accept natural untrained input 
situations need robustness face noise universality intuitiveness higher bandwidth speech 
need computers untrained users interact naturally 
believe naturalness interaction come systems built basis strong model human conversation 
chapter argued architectures embodied conversational agents need conversational model describes functionality properties affordances human face face conversation 
qualitative difference architectures designed way human body enables certain communication protocols face face conversation 
gaze gesture intonation body posture play essential role proper execution conversational behaviors conversation initiation termination turn interruption handling feedback error correction kinds behaviors enable exchange multiple levels information real time 
people extremely adept extracting meaning subtle variations performance behaviors example slight variations pause length feedback nod timing gaze behavior significantly alter message speaker sends 
particular interest interface designers communication protocols come free users need trained native speakers language skills daily 
embodied interface agent exploits potential provide higher bandwidth communication possible 
flip side communications protocols executed correctly embodiment bring benefit interface 
believe rea begins demonstrate correct communications protocols embodied conversational agents successful human computer interface 
notes research leading preparation article supported national science foundation award iis deutsche telekom generous sponsors mit media lab 
sincere kenny chang chang erin jennifer smith scott prevost kris th risson torres talented dedicated students students worked embodied conversational agents project 
colleague matthew stone continued invaluable contribution 
jeff rickel elisabeth andr helpful comments earlier draft 

architecture developed conjunction conversational characters project fx palo alto laboratory argyle cook 

gaze mutual gaze 
cambridge cambridge university press azarbayejani wren pentland 

real time tracking human body 
proceedings image com bordeaux france may bolt 
put voice gesture graphics interface 
computer graphics 
brennan 
conversation direct manipulation view 
laurel ed art human computer interface design 
reading mass addison wesley 
cassell th risson 

power nod glance envelope vs emotional feedback animated conversational agents 
journal applied artificial intelligence 
cassell 
fully embodied conversational avatars making communicative behaviors autonomous 
autonomous agents multi agent systems 
cassell pelachaud badler steedman becket douville prevost stone 

animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents 
computer graphics 
new york acm siggraph clark marshall 

definite mutual knowledge 
joshi webber sag eds elements discourse understanding 
cambridge cambridge university press 
clips 

manual technical report number 
houston tex software technology branch lyndon johnson space center 
mulken 
impact animated interface research review empirical research 
human computer studies 
forthcoming 
ferguson allen miller 

design implementation trains system prototype mixed initiative planning assistant technical note 
university rochester department computer science 
finin 

kqml agent communication language 
third international conference information knowledge management cikm gaithersburg maryland november 
goodwin 
conversational organization interaction speakers hearers 
new york academic press 
grosz sidner 

attention intentions structure discourse 
computational linguistics 
johnston 
unification multimodal parsing 
proceedings coling acl 
montreal morgan kaufman publishers 
kendon 
negotiation context face face interaction 
goodwin eds rethinking context language interactive phenomenon 
new york cambridge university press 
th risson 

integrating simultaneous input speech gaze hand gesture 
maybury ed intelligent multimedia interfaces 
cambridge mass aaai press mit press 
mcneill 
hand mind gestures reveal thought 
chicago university chicago press 

conversational interaction computers 
baecker buxton eds readings human computer interaction 
los altos calif morgan kaufman 
rickel johnson 

animated agents procedural training virtual reality perception cognition motor control 
applied artificial intelligence 
rosenfeld 
conversational control functions nonverbal behavior 
eds nonverbal behavior communication ed 
hillsdale lawrence erlbaum associates 
shneiderman 
designing user interface strategies effective human computer interaction ed 
reading mass addison wesley 
stone 
modality dialogue planning pragmatics computation 
unpublished doctoral dissertation department computer information sciences university pennsylvania philadelphia 
stone doran 

sentence planning description tree adjoining grammar 
proceedings th annual meeting association computational linguistics th conference european chapter association computational linguistics madrid spain 
th risson 
communicative humanoids computational model psychosocial dialogue skills 
unpublished doctoral dissertation department media arts sciences massachusetts institute technology cambridge massachusetts 

sharing sense making infant meaning 
steele eds language topics essays honour halliday vol 

amsterdam benjamins 
wahlster 
user discourse models multimodal conversation 
sullivan tyler eds intelligent user interfaces 
reading mass addison wesley 

