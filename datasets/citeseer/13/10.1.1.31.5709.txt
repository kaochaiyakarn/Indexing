originally published proceedings usenix symposium internet technologies systems monterey california december study piggyback cache validation proxy caches world wide web balachander krishnamurthy labs research craig wills worcester polytechnic institute information usenix association contact 
phone 
fax 
email office usenix org 
www url www usenix org study piggyback cache validation proxy caches world wide web balachander krishnamurthy craig wills labs research worcester polytechnic institute park ave institute road florham park nj usa worcester ma usa bala research att com cs wpi edu presents piggyback cache validation pcv addresses problem maintaining cache coherency proxy caches 
novel aspect approach capitalize requests sent proxy cache server improve coherency 
simplest case proxy cache reason communicate server piggybacks list cached potentially stale resources server validation 
trace driven simulation mechanism large independent data sets shows pcv provides stronger cache coherency reduces request tra comparison time live ttl techniques currently 
speci cally comparison best ttl policy best pcv policy reduces number request messages proxy cache server average cost considering response latency request messages bandwidth 
best pcv policy reduces staleness ratio comparison best ttl policy 
additionally pcv policies easily implemented protocol 
proxy cache acts intermediary potentially hundreds clients remote web servers requests clients various servers 
process proxy caches frequently requested resources avoid contacting server repeatedly resource knows heuristically decides information page changed server 
problem caching resources proxy browser cache issue cache coherency proxy know cached resource current 
server knows long resource valid newspaper generated am daily server provide precise expiration time 
cached copies fresh expiration time 
commonly resource available clear expiration time 
minutes remain unchanged long time 
addresses problem maintaining cache coherency proxy caches 
novel aspect approach requests sent proxy cache server obtain additional coherency information 
simplest approach proxy cache reason communicate server piggybacks list cached potentially stale resources server expiration time unknown 
compared techniques piggyback cache validation pcv approach potential ensuring stronger cache coherency reducing costs 
organized follows section discusses related area cache coherency web context 
section describes piggyback cache validation presents possible implementations top hypertext transport protocol 
section presents study variants pcv contrasts cache coherency approaches 
study trace driven simulation large logs evaluation criteria discussed section 
results simulations section 
section summarizes discussion ongoing directions 
related caching problem cache coherency world wide web similar problems caching distributed le systems 
pointed web di erent distributed le system access patterns larger scale single point updates web objects 
cache coherency schemes providing types consistency proposed investigated caches world wide web 
type strong cache consistency maintained approaches 
rst approach client validation proxy treats cached resources potentially outof date access sends modi ed header access resource 
approach provides strong cache consistency lead responses response code modi ed server resource change 
second approach server invalidation detecting resource change server sends invalidation messages clients accessed potentially cached resource 
approach requires server keep track lists clients invalidating cached copies changed resources unwieldy server number clients large 
addition lists date causing server send invalidation messages clients longer caching resource 
contrast weak consistency approaches seek minimize proxy validation server invalidation messages heuristic pre de ned value arti cial expiration time cached resource 
approach modi ed time proxy adopt adaptive time live ttl expiration time called alex protocol 
older resource longer time period validations 
adaptive ttl heuristic reasonable periods cached resource potentially stale 
related project mobile environments allows users set xed coherency interval objects capability change interval speci objects 
terms prior piggybacking improve cache coherency mogul proposed piggybacking server invalidations cached resources part replies client requests 
idea motivation piggyback cache validation directly investigated results reported 
concept piggybacking additional information request reply proposed limited forms uses 
previous suggests server knowledge access patterns requested resource returned resource 
knowledge client control prefetching 
extends approach client server knowledge 
mogul proposes hit metering technique cache report count information back origin server 
information predicting hit information passed hints cache server sends response cache 
proposes batch approach perform single check session cached objects older coherency interval 
batching related idea validation list carried piggybacked approach 
piggyback cache validation approach maintaining cache coherency reducing number messages exchanged server piggyback cache state information requests server 
individual browser clients approach bene cial proxy caches number resources cached particular server small short lived individual browser cache 
focus piggyback mechanism proxy cache 
simplest approach proxy cache reason communicate server piggybacks list cached resources server expiration time unknown heuristically determined ttl expired 
server handles request indicates cached resources list stale allowing proxy update cache 
proxy treats client requests cached resources validated age time live threshold current 
requests cached resources validated cause modi ed ims get request sent server 
performance piggyback cache validation depends number resources cached proxy particular server number requests sent proxy server 
requests meaning cache contents get validated piggybacking approach performs similar ttl policies generating validation check time expires 
tra proxy server cache contents validated granularity expiration time threshold need ims requests 
results prior studies indicate tra exists best case results yielded proxy cache hit rate 
similar hit rate studies 
piggyback validation allows relatively short expiration times resulting close strong cache coherency reducing number ims requests sent server comparison existing ttl policies 
added cost mechanism mainly increased size regular request messages due piggybacking 
new connections proxies servers 
number piggybacked validations appended single request controlled proxy cache 
cost proxy cache slightly increased maintain list cached resources server basis 
additional cost server validate piggybacked resources addition processing regular request 
absence piggybacking may done server separate connections 
implementation piggyback cache validation done independent particular cache replacement policy 
initial standard lru cache replacement policy 
validation information provided server replacement policy 
example proxy cache nds cached resource frequently invalidated resource candidate cache replacement 
approaches implement pcv mechanism 
rst approach implement mechanism new header type validation list requests replies 
request header eld consists list resource modi ed time pairs 
reply eld contain list invalid resources avalue indicating resources request list valid 
approach compact require server validate entire piggybacked list replies request 
alternately invalid resources return part footer allowed 
approach pipeline head requests trailing resource request 
approach requires bandwidth implemented changes protocol 
separates request cache validation 
implementation server implement mechanism proxy cache works ne albeit piggybacked validation information 
testing assume rst approach 
testing proxy cache logs constructed trace driven simulation test ideas sets logs digital equipment proxy logs sept get requests average rate requests hour mbyte hour 
distinct servers contacted top servers responsible resources accessed 
servers fewer resources accessed servers fewer resources accessed 
servers accounted half unique resources accessed 
labs research packet level trace nov get requests average rate requests hour mbyte hour 
distinct servers contacted top servers responsible resources accessed 
servers fewer resources accessed servers fewer resources accessed 
servers accounted half unique resources accessed 
cache coherency policies tested cache coherency policies logs 
pcv policy implements basic piggyback cache idea xed ttl time live expiration period 
default cached resource considered stale period hour elapsed 
expiration time reached resource validation check piggybacked subsequent request server 
resource accessed expiration validation modi ed get request sent server resource 

pcvadapt policy implements basic piggyback cache idea adaptive ttl expiration time fraction adaptive threshold age resource 
alex ftp protocol motivation newer resources change frequently older resources change 
believe piggybacked validations relatively inexpensive pcvadapt policy uses maximum expiration time equal xed ttl ect 
policy allows relatively tight limit resources shorter expiration newer resources 

ttl policy uses xed ttl expiration period resources piggybacking 
cached resource accessed expiration modi ed get request sent server resource 

policy uses adaptive ttl expiration time resource age piggybacking 
upper bound resource expiration time xed day 
pcvadapt policy tighter bound piggyback validation checks expensive modi ed get requests means validation approach 
policy squid internet object cache allows adaptive threshold maximum age con gurable 

policy generates modi ed get request access cached resource 
policy ensures strong coherency causes request server resource access 
measure policies 

policy nite expiration time cached resources validated 
policy minimizes costs cached copy resource results stale copies 
policy policies measured 
parameters cache coherency policies studied varying parameters cache size pcv size maximum size single piggyback list ttl value adaptive threshold 
focus presentation results able vary parameters established base set parameters parameter time 
base values established published testing policies different conditions 
base parameter values range studied cache size gb range mb gb maximum pcv size range ttl hour range hours adaptive threshold range 
vary cache replacement policy study lru tests 
variation replacement policy interaction cache coherency policies area 
evaluation criteria types costs traditionally considered evaluating performance web resource retrieval response latency long takes retrieve requested resource bandwidth bytes served server transmitted network requests requests handled server transmitted network 
context goal cache coherency policy combined cache replacement policy date non stale resources clients minimizing costs 
translating simulation results policy set data relative goodness done ways 
de ne justify determine cost staleness goodness metrics comparing di erent cache coherency policies 
cost evaluation typical measure cache replacement policies hit rate percentage time resource request provided cache 
measure account resource size byte hit rate common literature 
measures derive cost savings bandwidth requests re ect savings response latency 
mogul points measuring cache hits measure ect caching mechanisms cost cache 
addition cache replacement policy studies ignored cost cache coherency ratio stale resources 
studies distinguish cache hits resources directly hits resources validated server 
previous studies cache coherency report statistics stale cache hits information network server invalidation costs 
studies report values context cache activity speci cally cache replacement 
approach comprehensive cost model accounts combined costs cache replacement coherency 
model incorporates costs possible actions occur resource requested client proxy cache 
serve cache resource currently cached returned client contacting server 
de ne costs action zero 

validate resource currently cached returned client proxy validates cached copy current contacting server 
action involves request server latency cost corresponding distance server small bandwidth cost 

get resource cache cached copy 
resource returned client retrieval server 
action involves request server bandwidth transfer latency costs corresponding size resource distance server 
considering actions normalized cost model evaluation criteria actions represents cost action evaluation criterion denote matrix representing combinations proxy cache actions evaluation criteria 
computed data test logs 
costs shown tables explained 
evaluation criterion cost average get request full resource reply status normalized values log 
digital logs actual values bytes bandwidth includes contents headers table normalized cost matrix digital logs evaluation criterion re band re action sponse width quest avg 
get validate cache table normalized cost matrix logs evaluation criterion re band re action sponse width quest avg 
get validate cache seconds latency request average retrieval 
logs actual values bytes bandwidth seconds latency request 
cost resource cache de ned zero 
de nition focuses external costs resource access internal networks computers proxy cache contribute latency 
intermediate cost validate request returns validation current cache copy response computed relative cost full get request 
shown tables action just expensive full get request terms requests intermediate cost terms response latency little cost terms bandwidth 
tables show fourth evaluation criterion average costs criterion 
criterion introduced composite criterion assigns equal importance standard criteria 
matrix compute total cost cache coherency policy knowing relative proportion cache action policy 
represent proportional weight occurrence action policy denote matrix combinations policies actions 
matrix varies depending simulation parameters illustration tables show base set parameters discussed section 
matrices total cost table representative weight matrix digital logs action policy get validate cache pcv pcvadapt ttl table representative weight matrix logs action policy get validate cache pcv pcvadapt ttl policy evaluation criterion easily computed matrix product resulting values reporting costs cache coherency policies 
analyzing tables ratio resources causing full get request relatively constant cache coherence policies logs 
gure primarily dependent performance cache replacement policy 
de ned policy serves resource directly cache policy generates validate request 
interest performance study pcv policies generate requests 
calculating performance results reported adjustments 
cost full get request represents costs actual resources retrieved 
average size latency resources retrieved larger average entire log get bandwidth get response greater 
situation may occur cache replacement policy caches smaller resources increase hit rate results higher costs cache misses 
second fair measure impact pcv policies accounting increased costs 
consequently bandwidth response costs increased policies size bytes piggybacking validation response time server validation number piggyback validations request 
simulation bytes added request packet ms added response time piggybacked validation 
varies pcvadapt policy standard parameters average number piggybacked validations requests digital logs 
di erence averages stem fact higher degree locality logs digital logs possibly due higher user population case 
staleness evaluation staleness ratio stale cache hits divided number total requests serviced cache retrieved server 
chose measure staleness traditional ratio stale cache hits divided hits di erences cache hit ratio shown tables caused di erences validation invalidation approaches policies 
staleness ratio de nition allows fairer comparison policies de ates ratios comparison measuring ratio stale cache hits 
goodness evaluation believe cost staleness evaluations provide fair appropriate measures compare various policies 
cache coherency policy minimize cost relative cache replacement policy staleness 
combine cost staleness single metric compute goodness metric combines average cost staleness relative tothe range de ned policies cache size 
policies de ne minimum maximum costs staleness relative replacement policy cache size 
subjective minimizing cost staleness important 
results equal weight computing goodness metric 
results variation cache size parameter results shown variation cache size mb gb 
figures show response time bandwidth request message average costs respective policies digital logs 
expected policy performs worst performs best 
fact shows policy provides worst possible performance cost request message cost generates request get validate requested resource 
response time cost pcvadapt cache size mb response time cost versus cache size digital logs bandwidth cost pcvadapt cache size mb bandwidth cost versus cache size digital logs request message cost pcvadapt cache size mb request message cost versus cache size digital logs di erences policies gures primarily function ratio validate requests generates evaluation criterion cost request 
little distinction policies bandwidth costs validate request minimal 
hand di erentiation policies evaluation criteria validate request costs criteria nontrivial 
average cost pcvadapt cache size mb average cost versus cache size digital logs comparing policies pcv policies policy incurring cost 
result pcv policies reduce requests see table comparison ttl policies making better cache contents 
specif ically pcvadapt policy reduces number request messages average cost comparison policy gb cache 
reporting results note costs pcv policies 
due nature simulation discover invalidation cached resource time resource accessed 
cached resource invalidated removed cache replacement policy access invalidation discovered simulation 
cost results pessimistic cache space invalidated resources freed time invalidation case actual implementation 
limitation measure invalidation rate invalidations resources accessed just cache digital logs standard parameter set pcvadapt policy 
shows ratio requested resources returned stale cache relative cache size 
low staleness values small caches rises cache size gb digital logs 
policy results stale resources 
policies relatively low staleness ratios pcvadapt policy clearly providing strongest coherency 
comparison policy pcvadapt policy reduces staleness ratio gb cache 
staleness ratio pcvadapt cache size mb staleness ratio versus cache size digital logs shows goodness metric combining average cost staleness performance measures sum performance metric having equal weight 
de nition policies avalue cache sizes de ne upper lower bounds goodness 
shown pcvadapt policy exhibits high degree goodness large cache sizes indicating excellent policy providing date resources low cost 
policy second best 
larger cache sizes staleness ratio goes causes di erentiation relative policy staleness ratios 
ect causes relative di erences policy costs re ected goodness metric contributes goodness metric ttl policies 
goodness metric pcvadapt cache size mb goodness metric versus cache size digital logs figures show response time bandwidth request message average costs respective policies cache size varied logs 
relative ordering policies digital logs di erences policies generally pronounced 
di erentiation result relatively validate requests generated data shown table 
comparison digital data bandwidth costs di erentiated pcv policies resulting highest bandwidth costs 
result indicates piggybacked validations data add bytes slightly increase costs relative policies pcv policies provide lowest response time request average costs 
speci comparisons gb cache show pcvadapt policy reduces message cost average cost comparison policy 
invalidation rate logs accesses higher digital logs due piggyback validations ing generated 
response time cost pcvadapt cache size mb response time cost versus cache size logs bandwidth cost pcvadapt cache size mb bandwidth cost versus cache size logs shows similar staleness results logs digital logs policy returning nearly stale resources large cache sizes 
policies return close stale resources pcvadapt policy providing strongly coherent results improvement policy gb cache policy 
resulting goodness metric results logs shown comparable results shown digital logs 
request message cost pcvadapt cache size mb request message cost versus cache size logs average cost pcvadapt cache size mb average cost versus cache size logs staleness ratio pcvadapt cache size mb staleness ratio versus cache size logs goodness metric pcvadapt cache size mb goodness metric versus cache size logs variation parameters remaining results summarize ects goodness metric varying maximum pcv list size time live adaptive threshold parameters digital logs speci cost staleness results shown 
results output simulations dependent parameter varied parameters set base values base cache size gb 
goodness metric calculated relative policies cache size 
figures show little variation results maximum pcv list size 
smaller default result slightly degraded performance re ect generally tra client proxy server satisfy piggybacking needs proxy 
allowing larger pcv lists improve performance pcv policies 
figures show variation policies smaller ttl parameters performance ordering policies remains 
ttl value raised adaptive policies perform similarly xed ttl approaches 
bigger ttl value reduces potential bene pcv policies 
figures show expected lower adaptive threshold better relative results adaptive policies 
base value relatively range 
goodness metric pcvadapt maximum pcv size goodness metric versus maximum pcv size digital logs goodness metric pcvadapt maximum pcv size goodness metric versus maximum pcv size logs goodness metric pcvadapt time live hr goodness metric versus time live digital logs goodness metric pcvadapt time live hr goodness metric versus time live logs goodness metric pcvadapt adaptive threshold goodness metric versus adaptive threshold digital logs goodness metric pcvadapt adaptive threshold goodness metric versus adaptive threshold logs summary believe similarity results large independent data sets clearly demonstrates merits piggyback cache validation approach 
combining piggybacking adaptive threshold pcvadapt policy clearly best providing close strong coherency relatively low cost consider response latency request messages bandwidth average costs 
comparison policy best ttl policy pcvadapt policy best pcv policy reduces number messages server average cost 
pcvadapt policy reduces staleness ratio comparison policy 
additionally pcv policies easily implemented protocol 
directions piggybacking information include server piggybacking resource invalidations replies client 
invalidations resources site selected subsets resources 
clients list invalidations remove stale copies 
piggybacking information existing server replies introduce new network tra alleviates servers having maintain client lists comparison previous server invalidation 
studied cache coherency related cache replacement cache works provide date resources lowest cost 
piggybacking potential positively ect cache replacement decisions 
example frequently invalidated resources candidates cache replacement 
proxy caches information resource usage piggybacked server replies making replacement decisions 
additionally shows resources change accessed variation rate change content types frequently referenced resources cluster speci periods time deciding piggyback 
acknowledgments digital equipment making proxy traces available 
anja feldmann help trace steve bellovin phong vo discussions je rey mogul rabinovich jennifer rexford fred douglis anonymous reviewers making comments draft versions 
marc abrams charles abdulla stephen williams edward fox 
caching proxies limitations potentials 
proceedings fourth international world wide web conference december 
www org pub conferences www papers 
azer bestavros 
speculation reduce server load service time www 
proceedings th acm international conference information knowledge management november 
pei cao sandy irani 
cost aware www proxy caching algorithms 
symposium internet technology systems 
usenix association december 
cate 
alex global lesystem 
proceedings usenix file system workshop pages 
usenix association may 
digital equipment 
proxy cache log traces september 
ftp ftp digital com pub dec traces proxy html 
adam tomas 
web cache coherence 
proceedings fifth international world wide web conference may 
www conf inria fr html papers overview html 
fred douglis anja feldmann balachander krishnamurthy je mogul 
rate change metrics live study world wide web 
symposium internet technology systems 
usenix association december 
james gwertzman margo seltzer 
worldwide web cache consistency 
proceedings usenix technical conference pages 
usenix association january 
www usenix org publications library proceedings sd seltzer html 
barron david 
system optimizing web browsing wireless environment 
proceedings acm ieee mobicom conference october 
www networking ibm com art htm 
howard kazar menees nichols satyanarayanan sidebotham 
scale performance distributed le system 
acm transactions computer systems february 
internet engineering task force 
hypertext transport protocol january 
ds internic net internet drafts 
balachander krishnamurthy craig wills 
piggyback cache validation proxy caches world wide web 
proceedings nd web caching workshop boulder june 
national laboratory applied network research 
ircache nlanr net cache workshop papers wills wills html 
thomas kroeger long jeffrey mogul 
exploring bounds web latency reduction caching prefetching 
symposium internet technology systems 
usenix association december 
liu pei cao 
maintaining strong cache consistency world wide web 
proceedings th ieee international conference distributed computing systems may 
je rey mogul 
alternative explicit revocation january 
lut ac uk lists caching html 
je rey mogul 
hinted caching web 
proceedings sigops european workshop 
stanford edu sigops papers mogul ps 
je rey mogul fred douglis anja feldmann balachander krishnamurthy 
potential bene ts delta encoding data compression 
acm sigcomm conference september 
www acm org sigcomm sigcomm papers html 
michael nelson brent welch john ousterhout 
caching sprite network le system 
acm transactions computer systems february 
venkata padmanabhan je rey mogul 
predictive prefetching improve world wide web latency 
computer communication review 
squid internet object cache 
squid nlanr net squid 
stephen williams marc abrams charles abdulla edward fox 
removal policies network caches world wide web documents 
proceedings acm sig comm conference pages august 
www acm org sigcomm sigcomm williams html 
craig wills joel 
prefetching web merger client server pro les june 
www cs wpi edu papers ps 
