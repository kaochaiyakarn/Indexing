nearest neighbor meaningful 
kevin beyer jonathan goldstein raghu ramakrishnan uri shaft cs dept university wisconsin madison dayton st madison wi raghu cs wisc edu 
explore effect dimensionality nearest neighbor problem 
show broad set conditions broader independent identically distributed dimensions dimensionality increases distance nearest data point approaches distance farthest data point 
provide practical perspective empirical results real synthetic data sets demonstrate effect occur dimensions 
results interpreted mean high dimensional indexing meaningful illustrate point identifying high dimensional workloads effect occur 
results emphasize methodology universally database literature evaluate high dimensional indexing techniques flawed modified 
particular techniques proposed literature evaluated versus simple linear scan evaluated workloads nearest neighbor meaningful 
reported experiments analyzed carefully show linear scan outperform techniques proposed workloads studied high dimensionality 
years researchers focused finding efficient solutions nearest neighbor nn problem defined follows collection data points query point dimensional metric space find data point closest query point 
particular interest centered solving problem high dimensional spaces arise techniques approximate see complex data images sequences video shapes long feature vectors :10.1.1.161.139:10.1.1.45.9405:10.1.1.45.9405
similarity queries performed complex object approximating high dimensional vector obtain query point determining data point closest underlying feature space 
contributions show certain broad conditions terms data query distributions workload dimensionality increases distance nearest neighbor approaches distance farthest neighbor 
words contrast distances different data points nonexistent 
conditions identified happens broader independent identically distributed iid dimensions assumption assumes 
result characterizes problem specific algorithms address problem 
addition observations apply equally nearest neighbor variant problem 
combines result observation applications high dimensional nn heuristics similarity domain color histograms image similarity serious questions raised validity mappings similarity problems high dimensional nn problems 
problem exacerbated techniques find approximate nearest neighbors cases improve performance 
provide practical perspective empirical results synthetic distributions showing distinction nearest farthest neighbors may blur dimensions 
addition performed experiments data real image database indicate dimensionality effects occur practice see 
observations suggest highdimensional feature vector representations multimedia similarity search caution 
particular check workload yields clear separation nearest farthest neighbors typical queries sampling 
identify special workloads concept nearest neighbor continues meaningful high dimensionality emphasize observations misinterpreted saying nn high dimensionality meaningful 
observe database literature nearest neighbor processing techniques fails compare new techniques linear scans 
furthermore infer data linear scan performs techniques high dimensionality examined data sets 
unsurprising workloads evaluate techniques class badly behaving workloads identified results proposed methods may effective appropriately chosen workloads examined performance evaluation 
summary results suggest care taken thinking nearest neighbor approaches high dimensional indexing algorithms supplement theoretical results experimental data careful discussion 
significance nearest neighbor nn problem involves determining point data set nearest query point see 
frequently geographical information systems gis points associated geographical location cities 
typical nn query city closest current location 
natural ask nearest neighbor meaningful answer 
instance consider scenario depicted 
query point nearest neighbor fig 

query point nearest neighbor 
query point center circle nearest neighbor fig 

query point nearest neighbor 
defined nearest neighbor difference distance nearest neighbor point data set small 
difference distance small utility answer solving concrete problems minimizing travel cost low 
furthermore consider scenario position point thought lie circle high confidence see 
situation come numerical error calculating location heuristic error derives algorithm deduce point flat spherical map determine distance 
scenario determination nearest neighbor impossible reasonable degree confidence 
scenario depicted contrived geographical database practical dimensional application nn show norm broad class data distributions high dimensionality 
establish examine number points fall query sphere enlarged factor see 
points fall enlarged sphere means data point nearest query point separated rest data meaningful way 
hand 
data points fall enlarged sphere differentiating query point fig 

data points approximations 
circle denotes region true data point supposed 
dmin dmin dmax fig 

illustration query region enlarged region 
dmin distance nearest neighbor dmax farthest data point 
nearest neighbor data points meaningless small 
notion instability describing phenomenon 
definition nearest neighbor query unstable distance query point data points times distance query point nearest neighbor 
show situations fixed dimensionality rises probability query unstable converges 
note points fall enlarged query region valid answers approximate nearest neighbors problem described 
nn high dimensional spaces section contains formulation problem formal analysis effect dimensionality meaning result formal implications result enhance understanding primary result 
notational conventions notation rest vector probability event 
expectation random variable 
variance random variable var 
iid independent identically distributed 
phrase values assigned collection random variables 
random variable takes values distribution results probability theory definition sequence random vectors vectors arity converges probability constant vector probability am away converges 
words lim kam gamma ck denote property am treat random variables vectors vectors arity 
lemma sequence random variables finite variance lim bm lim var bm bm version theorem random variables vectors continuous function 
am finite am 
corollary theorem sequences random variables xm ym xm ym nearest neighbor formulation data set query point want analyze distance nearest neighbor differs distance data points 
evaluating number points farther away factor larger distance query point nn illustrated 
examining characteristic assume structure distance calculation 
study characteristic examining distribution distance query points data points variable changes 
note eventually interpret dimensionality 
proof rely interpretation 
view proof convergence condition series distributions happen call distance distributions provides tool talk formally dimensionality curse 
introduce terms stating result formally 
definition variable distance distributions may converge ranges positive integers 
data data sequence data distributions 
query query sequence query distributions 
fixed number samples data points distribution 
independent data points data qm query query point chosen independently constant 
dm function takes data point domain data query point domain query returns non negative real number result 
min fdm qm ng 
dmaxm max fdm qm ng 
instability result main theoretical tool 
essence states assuming distance distribution behaves certain way increases difference distance query point data points negligible query unstable 
sections show necessary behavior described section identifies large class larger classes aware distance result known readily inferred known results workloads 
formally show theorem conditions definition lim var qm qm lim dmaxm proof qm 
note value expectation independent distribution 
vm qm part ll show vm 
follows vm random variable divided expectation 
trivially lim 
condition theorem equation means lim var vm 
combined lim enables lemma conclude vm 
part ll show vm lim dmaxm xm qm dm qm vector arity 
part vector xm distribution vm follows xm 
min max continuous functions conclude theorem min xm min similarly max xm 
corollary max xm min xm get max xm min xm note min xm dmaxm max xm 
dmaxm max xm min xm max xm min xm dmaxm definition convergence probability lim fi fi fi fi dmaxm gamma fi fi fi fi dmaxm dmaxm gamma fi fi fi fi dmaxm gamma fi fi fi fi dmaxm absolute value term effect 
lim dmaxm lim fi fi fi fi dmaxm gamma fi fi fi fi summary theorem says precondition holds distance distribution behaves certain way increases points converge distance query point 
conditions concept nearest neighbor longer meaningful 
may able result directly showing vm part proof 
example iid distributions vm follows readily weak law large numbers 
sections demonstrate result provides handy tool discussing scenarios resistant analysis law large numbers arguments 
practical standpoint issues addressed determine theorem impact restrictive condition lim var qm qm lim var qm qm necessary results hold 
words says increase examine resulting distribution distances queries data variance distance distribution scaled magnitude distance converges 
provide better understanding restrictiveness condition sections discuss scenarios satisfy 
situations condition satisfied rate distances points indistinct dimensionality increases 
words dimensionality concept nearest neighbor meaningless issue difficult tackle analytically 
performed set simulations examine relationship ratio minimum maximum distances respect query point 
results simulations section 
application theoretical result section analyses applicability theorem formally defined situations 
done determining scenario condition equation satisfied 
due space considerations give proof condition equation satisfied 
contains full analysis example 
scenarios define workload distance metric multidimensional query data points dimensionality 
data query points vectors arity 
important notice section assign particular meaning dm distance metric parameter dimensionality 
theorem particular meanings 
explore scenarios satisfy equation 
start basic iid assumptions relax assumptions various ways 
start sanity checks show distances converge iid dimensions example show equation satisfied data queries fall line example 
discuss examples involving correlated attributes differing variance dimensions illustrate scenarios weak law large numbers applied examples 
example iid dimensions query data independence 
assume data distribution query distribution iid dimensions 
appropriate moments finite pe th moment 
query point chosen independently data points 
conditions theorem satisfied assumptions 
result original nice sanity check 
special case prove part theorem weak law large numbers 
true general 
assumptions example means necessary theorem applicable 
section examples workloads discussed weak law large numbers 
innumerable slightly stronger versions weak law large numbers example contains example meets condition weak law large numbers inapplicable 
example identical dimensions independence 
notation previous example 
contrast previous case consider situation dimensions query point data points follow identical distributions completely dependent value dimension value dimension 
conceptually result set data points query point diagonal line 
matter dimensions added underlying query converted dimensional nearest neighbor problem 
surprising find condition theorem satisfied 
example unique dimensions correlation dimensions 
example intentionally break assumptions underlying iid case 
dimension unique dimensions correlated dimensions variance additional dimension increases 
description problem 
generate dimensional data point query point xm xm follows take independent random variables um uniform 
define define gamma 
condition theorem satisfied 
example variance converging 
example illustrates workloads meet preconditions theorem variance distance added dimension converges 
expect finite number earlier dimensions dominate distance 
case 
suppose choose point xm xm independent 
condition theorem satisfied 
example marginal data query distributions change dimensionality 
example marginal distributions data queries change dimensionality 
distance distribution dimensionality increases described distance lower dimensionality plus new component new dimension 
result weak law large numbers implicitly sums increasing size provide insight behavior scenario 
distance distributions treated technique suggests series random variables variance expectation calculated examined terms dimensionality 
dimensional data space sm boundary dimensional unit hyper cube 
sm gamma :10.1.1.45.9405
addition distribution data points uniform sm words point sm equal probability sampled data point 
lastly distribution query points identical distribution data points 
note dimensions independent 
case condition theorem satisfied 
meaningful applications high dimensional nn section place theorem perspective observe interpreted mean high dimensional nn meaningful 
identifying scenarios arise practice separation nearest farthest neighbors 
classification approximate matching exact match approximate match queries reasonable 
instance dependence query point data points exists data point matches query point exactly 
assuming data points aren duplicates meaningful answer determined 
furthermore problem statement relaxed require query point small distance data point required identical data point call query point nearest cluster fig 

nearest neighbor query clustered data 
query meaningful 
note staying small distance difficult increases adding terms sum distance metric 
version problem remain meaningful dimensionality increases query point increasingly closer data point 
generalize situation follows data consists set randomly chosen points additional points distributed clusters radius ffi original points query required fall data clusters see 
situation perfectly realized classification problem data naturally falls discrete classes clusters potentially high dimensional feature space 
depicts typical distance distribution scenario 
cluster query point falls closer indistinguishable distance 
proper response query return points closest cluster just nearest point quickly meaningless compared points cluster dimensionality increases 
observe don guarantee query point falls cluster cluster nearest neighbor chosen subject meaningfulness limitations choice nearest neighbor original version problem theorem applies choice nearest cluster 
implicitly low dimensionality possible scenario high dimensional nearest neighbor queries meaningful occurs underlying dimensionality data lower actual dimensionality 
identifying situations determining useful dimensions uses principal component analysis identify meaningful dimensions :10.1.1.40.9848
course techniques useful nn underlying dimensionality meaningful 
distance random points fig 

probability density function distance random clustered data query points 
experimental studies nn theorem tells happens take dimensionality infinity 
practice dimensionality anticipate nearest neighbors unstable 
words theorem describes convergence tell rate convergence 
addressed issue empirical studies 
due lack space synthetic workloads real data set 
includes additional synthetic workloads workloads second real data set 
ran experiments iid uniform workload different correlated workloads 
shows average dmaxm dimensionality increases query points synthetic data sets tuples 
workload recursive line described example correlation pair dimensions new dimension larger variance 
degrees freedom workload generates query data points dimensional plane generated follows constants 
independent uniform 
workload satisfy equation 
shows degrees freedom workload behaves similarly dimensional uniform workload regardless dimensionality 
recursive workload predicted theorem affected dimensionality 
interestingly correlation changing variances recursive workload behaved iid uniform case 
graph demonstrates geometric intuition nearest neighbor dimensions fails alarming rate dmax dmin log scale dimensions degrees freedom recursive uniform fig 

correlated distributions tuples 
dimensionality increases 
distinction nearest farthest points dimensions tiny fraction dimensions 
dimension dmaxm uniform order providing plenty contrast nearest object farthest object 
dimensions contrast reduced orders magnitude 
dimensions farthest point times distance closest point 
empirical results suggest nn unstable dimensions 
shows results experiments done real data set 
data set dimensional color histogram data set tuple image reduced dimensions principal components analysis 
approximately tuples data set 
examine nn nn traditional application image databases 
determine quality answers nn queries examined percentage queries half data points factor nearest neighbor 
examine graph median distance distance 
graph says normal nn problem queries half data factor distance nn 
queries half data factor distance th nearest neighbor 
easy see effect changing quality answer significant small values cumulative percent queries median distance distance fig 

color histogram data 
data set provide meaningful answers nn problem 
nn problem 
nn problem 
keep mind data set derived heuristic approximates image similarity 
furthermore nearest neighbor contrast lower intuition suggests dimensions 
careful evaluation relevance results definitely called 
analyzing performance nn processing technique section discuss ramifications results evaluating techniques solve nn problem particular high dimensional indexing techniques motivated nn problem 
important point performance evaluations high dimensional nn queries include comparison linear scans sanity check 
results indicate exist situations high dimensional nearest neighbor queries meaningful specific nature quite different independent dimensions basis studies literature evaluate techniques controlled manner 
nn technique evaluations focus situations results meaningful 
instance answers meaningful data consists small formed clusters query guaranteed land near clusters 
terms comparisons nn techniques papers compare trivial linear scan algorithm 
results argue cases dimensionality increases data equidistant data surprising dimensions linear scan beats complicated indexing structures 
give detailed formal discussion phenomenon 
instance performance study parallel solution nearest neighbors problem indicates solution scales poorly parallel scan data beats parallel scan data 
provides information performance ss tree tree finding nearest neighbors 
conservatively assuming linear scans cost random examination data pages linear scan outperforms ss tree tree dimensions cases 
linear scan vastly outperforms sr tree cases dimensional synthetic data set 
dimensional real data set sr tree performs similarly linear scan experiments usually beaten linear scan 
performance numbers nn queries bounds imposed radius find nn 
performance high dimensionality looks cases trying duplicate results radius queries returned answer 
performance structures high dimensionality looks poor important keep mind reported performance studies examined situations distance query point nearest neighbor differed little distance data points 
ideally evaluated meaningful workloads 
workloads include low dimensional spaces clustered data queries described section 
existing structures may fact appropriate situations 
related curse dimensionality term dimensionality curse vague indication high dimensionality causes problems situations 
term bellman combinatorial estimation multivariate functions 
example statistics note multivariate density estimation problematic high dimensions 
linear scan set sequentially arranged disk pages faster unordered retrieval pages secondary indexes ignored query optimizers query estimated fetch data pages 
fetching large number data pages multi dimensional index usually results unordered retrieval 
area nearest neighbors problem indicating query processing technique performs worse dimensionality increases 
observed high dimensional cases estimate nn query cost index structure poor boundary effects taken account 
boundary effect query region sphere center query point mainly outside hyper cubic data space 
take account boundary effect query cost estimate higher actual cost 
term dimensionality curse describe phenomenon 
discuss meaning nearest neighbor query process query 
term dimensionality curse nn research community relevant section main results 
computational geometry nearest neighbor problem studied computational geometry 
usual approach take number dimensions constant find algorithms behave number points large 
observe problem hard define approximate nearest neighbor problem weaker problem 
algorithm retrieves approximate nearest neighbor log time data set 
algorithm retrieves true nearest neighbor constant expected time iid dimensions assumption 
constants algorithms exponential dimensionality 
recommend algorithm dimensions 
impractical algorithm number points lower exponential number dimensions 
fractal dimensions suggested real data sets usually fractal properties self similarity particular fractal dimensionality tool determining performance queries data set 
example illustrates fractal dimensionality data space sample data points may indicator utility nearest neighbor queries 
suppose data points sampled uniformly vertices unit hypercube 
data space points dimensions fractal dimensionality 
situation worst cases nearest neighbor queries 
iid bernoulli worse iid uniform 
number data points scenario close nearest neighbor queries stable impractical large real data sets estimated fractal dimensionality low separation nearest farthest neighbors 
intriguing question intend explore 
technique described real data sets described 
fractal dimensionality data sets estimated divided space dimension data points occupied different cells 
technique artificial dimensional data set known fractal dimensionality number points real data sets generated degrees freedom workload section data 
estimate got fractal dimensionality estimate 
real data sets inherently high dimensional possible explanation exhibit fractal behavior 
studied effect dimensionality nn queries 
particular identified broad class workloads difference distance nearest neighbor points data set negligible 
class distributions includes distributions typically evaluate nn processing techniques 
applications nn heuristic feature vectors describe images 
cases query instability indication meaningless query 
problem worsened techniques provide approximate nearest neighbor improve performance 
find dimensionality nn breaks performed extensive simulations 
results indicated distinction distance decreases fastest dimensions quickly reaching point difference distance query point nearest farthest data points drops factor 
addition simulated workloads examined real data sets behaved similarly see 
addition providing intuition examples distributions class discussed situations nn queries break high dimensionality 
particular ideal data sets workloads classification clustering algorithms reasonable high dimensionality 
scenario deviated instance query point lie cluster queries meaningless 
practical ramifications scenarios evaluating nn workload 
sure distance distribution random query point random data point allows contrast application 
distance nearest neighbor different average distance nearest neighbor may useful similar 
evaluating nn processing technique 
evaluating nn processing technique test meaningful workloads 
examples workloads section 
addition evaluation technique particular workload take account approximations technique uses improve performance 
ensure new processing technique outperforms trivial solutions sequential scan 
partially supported david packard foundation fellowship science engineering presidential young investigator award nasa research ord contract nsf gn 
prof robert meyer time valuable feedback 
prof rajeev motwani helpful comments 

agrawal faloutsos swami efficient similarity search sequence databases 
proc 
th inter 
conf 
fodo 
altschul gish miller myers lipman basic local alignment search tool 
journal molecular biology vol 

ang li ong image retrieval multidimensional feature properties 
spie vol 

arya nearest neighbor searching applications 
ph thesis univ maryland college park 
arya mount narayan accounting boundary effects nearest neighbors searching 
proc 
th acm symposium computational geometry 
arya mount netanyahu silverman wu optimal algorithm nearest neighbor searching 
proc 
th acm siam symposium discrete algorithms 
bellman adaptive control processes 
princeton university press 
faloutsos estimating selectivity spatial queries correlation fractal dimension 
proc 
vldb 
bentley weide yao optimal expected time algorithms closest point problem acm transactions mathematical software vol 

berchtold bohm keim kriegel fast parallel similarity search multimedia databases 
proc 
acm sigmod int 
conf 
management data 
berchtold bohm keim kriegel cost model nearest neighbor search high dimensional data space 
proc 
th acm sigart symposium pods 
bern approximate closest point queries high dimensions 
information processing letters vol 

beyer goldstein ramakrishnan shaft nearest neighbors meaningful 
technical report 
tr computer sciences dept univ wisconsin madison june 
ozsoyoglu distance indexing high dimensional metric spaces 
proc 
th acm sigact sigmod sigart symposium pods 
faloutsos efficient effective querying image content 
journal intelligent information systems vol 

faloutsos gaede analysis dimensional quadtrees fractal dimension 
proc 
acm sigmod int 
conf 
management data 
faloutsos kamel uniformity independence analysis trees concept fractal dimension 
proc 
th acm sigact symposium pods 
fayyad smyth automated analysis exploration image databases results progress challenges 
journal intelligent information systems vol 

katayama satoh sr tree index structure high dimensional nearest neighbor queries 
proc 
th acm sigact sigmod sigart symposium pods 
lin jagadish faloutsos tv tree index structure high dimensional data 
vldb journal vol 

manjunath ma texture features browsing retrieval image data 
ieee trans 
pattern analysis machine learning vol 

mehrotra gary feature retrieval similar shapes 
th data engineering conference 
murase nayar visual learning recognition objects appearance 
int 
computer vision vol 

nene nayar simple algorithm nearest neighbor search high dimensions 
ieee trans 
pattern analysis machine learning vol 

pentland picard photobook tools content manipulation image databases 
spie vol 

scott multivariate density estimation 
wiley interscience chapter 
shaft goldstein beyer nearest neighbors query performance unstable distributions 
technical report 
tr computer sciences dept univ wisconsin madison october 
swain ballard color indexing 
inter 
journal computer vision vol 

swets weng discriminant eigenfeatures image retrieval 
ieee trans 
pattern analysis machine learning vol 

taubin cooper recognition positioning rigid objects algebraic moment invariants 
spie vol 

white jain similarity indexing ss tree 
icde 
