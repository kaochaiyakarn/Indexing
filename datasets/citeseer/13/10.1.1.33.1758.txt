data analysis bayesian networks bootstrap approach nir friedman institute computer science hebrew university jerusalem israel nir cs huji ac il moises goldszmidt sri international ravenswood ave menlo park ca moises erg sri com abraham wyner department statistics wharton school university pennsylvania philadelphia pa stat wharton upenn edu years significant progress algorithms methods inducing bayesian networks data 
complex data analysis problems need go satisfied inducing networks high scores 
need provide confidence measures features networks existence edge nodes warranted 
markov blanket node robust 
say ordering variables 
able address questions amount data induce high scoring network 
propose efron bootstrap computationally efficient approach answering questions 
addition propose confidence measures induce better structures data detect presence latent variables 
decade great deal research focused learning bayesian networks data :10.1.1.112.8434
exceptions results concentrated computationally efficient induction methods issue hidden variables missing data 
main concern line induction high scoring networks score network reflects network fits data 
bayesian network contains structural qualitative information domain 
able exploit information complex data analysis problems situations available data sparse 
part motivation comes ongoing application bayesian networks molecular biology 
central goals molecular biology understand mechanisms control regulate gene expression 
gene expressed process rna sequence rna sequence turn translated protein molecule 
technical breakthroughs molecular biology enable biologists measure expression levels thousands genes experiment 
data generated experiments consists instances thousands attributes 
largest datasets available today contain hundreds instances 
expect learn detailed model sparse data set 
data sets clearly contain valuable information 
example induce correlation causation relations genes high expression levels gene cause suppression 
challenge separate measurable signal data noise genuine correlations properties spurious random correlations 
analysis data poses challenges 
examine determine level confidence various structural features bayesian networks induce data sets 
consider approach methodology bootstrap method efron addressing type challenges 
bootstrap computer method assigning measures accuracy statistics estimates performing statistical inference 
regard measures accuracy establishing level confidence estimates confidence interpreted ways 
important elusive notion assesses likelihood feature true 
confidence ultimately stand fall method estimation 
second notion akin assessment degree support particular technique feature 
idea nicely separates variation data shortcomings algorithm 
interpretation confidence pursued 
methods introduced encompass types confidence focuses 
bootstrap conceptually easy implement apply context open question theoretical foundations 
main difficulty compared classic statistical estimation methods lack closed form expressions events study edge appears network 
widespread bootstrap despite difficulties reflects general conditions bootstrap distributions consistent statistics concisely defined simple expression see 
example application bootstrap evolutionary biology measure confidence inferences phylogenetic trees 
applied re sampling tools estimate uncertainty edges evolutionary trees specify phylogenetic evolution gene time 
similar test re sampling strategies bayesian networks experimentally explicit probability distribution known network model golden model 
report preliminary results indicate practice high confidence estimates certain structural features indicative existence features generating model 
experiments edges partially directed graphs pdags feature interest 
edges describe features equivalence classes networks see 
extends results fundamental ways includes important features induced models markov neighborhood node confidence assert markov blanket ordering relations variables pdags confidence assert ancestor 
second focus examining extend degree confidence returned bootstrap interpreted establishing likelihood feature true generating model 
performed extensive set experiments varying various parameters search method learning algorithms sizes datasets bootstrap method 
third examine bootstrap providing information guide induction process 
look increase performance learning procedure biased information bootstrap estimates 
experiments section yield results best knowledge unknown application bootstrap establishing likelihood particular feature generating model 
bootstrap estimates quite cautious 
features induced high confidence rarely false positives 

markov neighborhood partial ordering variables features robust existence edges pdag 

established high confidence features reliable cases data sets small model induced 
section examine bootstrap estimated induce higher scoring networks 
results preliminary encouraging 
altogether results provide strong evidence bootstrap appropriate method extracting qualitative information domain study features induced bayesian network 
study methods establishing quality induced bayesian networks totally ignored literature 
cowell method log loss scoring function monitor variable network 
monitors check deviation predictions variables observations data 
heckerman approach bayesian considerations establish belief causal edge part underlying generating model 
problem confidence estimation study similar spirit investigated heckerman basis approach algorithmic implementation completely different 
relation explored propose show results bootstrap implement practical bayesian estimate confidence features models 
completeness summarized relation section 
learning bayesian networks briefly review learning bayesian networks data 
complete exposition refer reader 
consider finite set fx xng discrete random variables variable may take values finite set 
capital letters variable names lowercase letters denote specific values taken variables 
sets variables denoted boldface capital letters assignments values variables sets denoted boldface lowercase letters bayesian network annotated directed acyclic graph encodes joint probability distribution set random variables formally bayesian network pair hg thetai 
component directed acyclic graph vertices correspond random variables xn edges represent direct dependencies variables 
graph encodes set independence statements variable independent parents second component pair theta represents set parameters quantifies network 
contains parameter jpa pb pa possible value pa pa pa denotes set parents bayesian network defines unique joint probability distribution pb xn pb pa problem learning bayesian network structure stated follows 
training set fx instances find network best matches common approach problem introduce scoring function score evaluates fitness networks respect training data search best network score 
score proposed bayesian considerations scores network structure posterior probability graph structure training data constant :10.1.1.156.9918
note derivation score treats problem density estimation problems 
desire construct networks assign high probability new previously unseen data source 
structural features networks induced indirectly presumably right structure better generalize training data 
finding structure maximizes score usually intractable problem 
usually resort heuristic search find high scoring structure 
standard proposals search include greedy hill climbing stochastic hill climbing simulated annealing see 
greedy hill climbing strategy augmented tabu lists random restarts escape local maxima 
experiments assess directly confidence features induced network features class networks equivalent 
bayesian network structures equivalent imply exactly set independence statements 
characterization bayesian network equivalence classes studied 
results papers establish equivalent networks agree connectivity variables disagree direction arcs 
results show equivalence class network structures represented partially directed graph pdag directed denotes members equivalence class contain arc undirected edge denotes members class contain arc contain arc score structure equivalent sense equivalent networks receive score 
experiments learn network structures procedure described convert pdags 
bootstrap confidence estimation network structure 
feature interest structure existence pdag corresponds feature interest precedes pdag corresponds general treat features functions network structures set 
usually letters denote features 
suppose data set observations fx assignment values assume assignments sampled independently probabilistic network structure network structure returned induction algorithm invoked data input 
feature consider quantity pn jdj ng probability inducing network feature possible datasets size sampled induction procedure consistent expect grows larger pn converge 
give confidence close holds close 
quantity pn natural measure power induction algorithm 
goal estimate pn single set observations size mimic usual induction situation want learn model data 
describe possible algorithms parametric non parametric bootstraps 
start non parametric bootstrap 
underlying intuition confident features induced perturb data 
question perturb data maintain general statistical features dataset 
non parametric bootstrap generate perturbations re sampling dataset 
estimate confidence feature examining perturbed datasets appears induced 
non parametric bootstrap performed executing steps ffl re sample replacement instances denote resulting dataset 
apply learning procedure induce network structure 
ffl feature interest define parametric bootstrap similar process 
re sampling data replacement training data sample new datasets network induce ffl induce network ffl sample instances denote resulting dataset 
generally consider joint distribution features 
course nontrivial relationships confidence estimates different features 
example consider edges pdags clearly pn pn pn 
edge markov order true positives false positives false negatives quality prediction partially directed edges markov neighborhoods orders alarm domain non parametric bootstrap 
columns correspond average number true positives false positives false negatives classifications 
curve correspond value confidence threshold axis shows number instances axis shows average number edge features category 
averages taken bootstrap estimates resamples datasets sampled alarm network 
apply learning procedure induce network structure 
ffl feature interest define parametric bootstrap quite different nonparametric sense 
simulation answer question true network induce datasets size 
answering question determine level confidence results induction 
note main computational cost variants bootstrap dominated repeated calls induction procedure sampling steps 
important question conditions bootstrap estimate converge 
conditions jp gamma approach tend 
parametric bootstrap estimates pn converge general conditions non parametric bootstrap provided course parameterization converges true underlying model asymptotically 
hand condition satisfied consistency claim 
nonparametric bootstrap estimates require model consistency 
consistency non parametric bootstrap requires uniform convergence distribution bootstrap statistic continuity condition parameters 
experiments results designed verify convergence types bootstrap features tested existence edge pdags 
currently working providing thorough theoretical analysis conditions context bayesian network induction 
experiments section test extend bootstrap estimates expressing likelihood features tested belong generating model 
edge markov order true positives false positives false negatives quality prediction partially directed edges markov neighborhoods orders gene domain non parametric bootstrap 
see details 
empirical evaluation test bootstrap synthetic data generated known models 
allows compare features bootstrap confident true features generating network 
example bootstrap confidence node belonging markov blanket node high determined threshold expect markov blanket generating model 
addition want characterize bootstrap estimates depend various parameters size dataset type feature bootstrap method 
methodology performed simulation results networks ffl alarm 
network random variables edges undirected pdag 
standard benchmark learning literature 
ffl gene 
network induced gene expression dataset genes 
genes grouped clustering algorithm searches groups related genes details induction 
network edges undirected pdag 
ffl text 
network induced dataset messages newsgroup 
document represented instance variable denoting newsgroup boolean variables corresponding frequent words words denoting word appears message 
network edges undirected pdag 
networks performed experiments number instances data set 
network sample size sampled input datasets bootstrap procedure 
applied parametric non parametric bootstraps 
experiments bde score uniform prior distribution equivalent sample size 
prior chosen relatively uninformative 
search procedure greedy hillclimbing search random restarts 
procedure attempts apply best scoring change current network improvement 
edge markov order true positives false positives false negatives quality prediction partially directed edges markov neighborhoods orders text domain non parametric bootstrap 
see details 
hill climbing procedure stuck local maxima applies random arc changes addition deletion reversal restarts search 
search terminated fixed number restarts 
computed bootstrap estimates types features ffl edges pdags 
treat directed undirected edges pairs variables different features 
ffl ordering relations form ancestor pdag 
ffl markov neighborhoods form markov blanket vice verse 
variables markov neighbors arc parents variable 
evaluation possible ways interpreting bootstrap results 
simplest select threshold report features pn way label features positive confidence threshold negative threshold 
labeling features measure number true positives correct features generating network correctly labeled false positives wrong features labeled positives false negatives correct features labeled negative true negatives wrong features labeled correctly 
report numbers categories prediction type features figures alarm gene text domains respectively 
reported numbers averaged estimates generated non parametric bootstrap runs 
noticeable trends results 
expected number instances grow prediction quality improves 
number true positives increases number false positives false negatives decreases 
addition increase threshold label fewer features positive number true positives false positives decreases number false negative increases 
second interestingly bootstrap samples quite cautious 
see number false positives usually smaller number true positives false negatives 
note different scales graphs 
prediction errors sided usually omit correct features include incorrect ones 
alarm non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric text non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric gene non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric non parametric parametric edge markov order comparison parametric non bootstrap 
axis shows average number false positives axis shows average number false negatives 
curve shows tradeoff false positives false negatives different values predictions particular feature procedures 
columns correspond type feature predicted 
third notice reasonable level confidence thresholding depends domain 
example alarm domain setting leads false positives reasonable number true positives 
hand text domain setting leads positives predictions setting returns false positives 
inclined lower threshold value domain 
unclear stage source phenomena 
features easier predict 
example prediction markov neighborhood variables robust pdag edges 
similarly ordering information quite reliably predicted bootstrap confidence measures 
observation bit surprising 
clearly longrange orderings variables function edge direction 
fact predict reliably indicates variables recognized ancestors relation determined different directed paths different bootstrap runs 
ability predict markov neighborhoods hand line common sense 
type feature sensitive exact ordering variables 
fact argued features easily estimated methods 
test performed simple test suggested anonymous reviewer learning networks bootstrap samples learned bayesian networks degree 
networks easy learn take account pairwise interactions variables 
shows tradeoff curves non parametric bootstrap networks trees 
see treebased estimates worse terms false positives false negatives text domain 
suspect partially due sparse nature source network domain 
bootstrap confidence measures quite informative generating distribution 
global features partial ordering relations determined small data sets 
compared parametric bootstrap nonparametric 
shows graphs false positives vs false negative tradeoffs methods 
performance methods similar network tree network tree network tree network tree network tree network tree alarm gene text comparison non bootstrap network trees prediction markov neighborhoods 
see details 
uniform bayes uniform bayes uniform bayes uniform bayes uniform bayes uniform bayes edge markov order comparison non bootstrap bayesian weighted non parametric bootstrap alarm domain 
see details 
domain constrained unconstrained avg 
avg 
alarm gene text table average standard deviation normalized scores bde score divided networks learned ordering constrained nonparametric bootstrap estimation 
graphs suggest non parametric bootstrap better performance 
performance curves nonparametric bootstrap usually closer origin implying smaller number errors 
domain constrained unconstrained avg 
avg 
alarm gene text table average standard deviation test set log loss networks learned constraints non parametric bootstrap estimation 
bootstrap network induction common idea learning prior knowledge 
particular learning structure prior knowledge structures searching reduce size search space improve speed induction importantly quality learned network 
commonly prior information include ordering constraints random variables existence certain arcs 
section explore bootstrap determining information 
proposal consists re sampling dataset induce bootstrap sample gather estimates confidence features 
structural properties high confidence constrain search process 
preliminary exploration idea performed experiment 
generated non parametric bootstrap samples collected types constraints 
estimate precedes confidence higher require learned network respect order 
disallow learning networks ancestor addition confidence markov neighborhood smaller disallow parent intuition closely related able detect bootstrap runs 
tiny fraction bootstrap networks variables connected probably related 
collecting constraints invoke search procedure learn network original data set restrict consider structures satisfy constraints 
repeated experiment times different initial data sets 
table report score networks induced procedure 
table report error generating distribution measured terms log likelihood assigned test data networks 
results show small training sets find slightly better scoring networks constraints generated bootstrap 
note robustness estimates previous section improvements trusted cases standard deviations scores test set log loss experiments may relatively large 
remember variance due small sample size 
discussion bayesian estimation bayesian perspective confidence estimation quite different frequentist measures discussed 
bayesian compute estimate posterior probability feature 
reasoning cases simply pr pr denotes feature investigated term pr posterior structure training data certain classes priors computed multiplicative constant constant graphs 
serious obstacle computing posterior requires summing large potentially exponential number equivalence classes 
heckerman suggest approximate finding set high scoring structures estimating relative mass structures contains pr pr pr raises question construct simple approach finding set record structures examined search return high scoring ones 
set structures manner quite sensitive search procedure 
example greedy hill climbing set structures collect quite similar 
restricted set candidates show consider multiple restarts greedy hill climbing beam search 
serious problem run risk getting estimates confidence biased sample structures 
way avoiding problem run extensive mcmc simulation posterior expect get representative group structures 
procedure quite expensive terms computation time 
bootstrap approach suggests relatively cheap alternative 
structures dm non parametric bootstrap representative set structures bayesian approximation 
proposal re sampling bootstrap processes way widening set candidates examine 
confidence estimate quite similar non parametric bootstrap structures bootstrap samples weighted proportion posterior probability 
shows comparison predictions approach non parametric bootstrap alarm domain 
comparison domains quite similar omit 
general approaches agree high confidence features 
surprising high confidence features appear bootstrap networks bayesian reweighting assign mass examine lower thresholds see differences approaches 
particularly visible estimates ordering relations 
currently exploring bootstrap focused way get approximation bayesian posterior features 
proposes methodology computing confidence features induced model efron bootstrap method 
previous studied bootstrap assessing degree support particular technique feature examine important notion confidence assesses likelihood feature appears generating model 
experiments lead bootstrap estimates cautious trustworthy high confidence estimations seldom contain false positives 
second features establishing markov neighborhood partial ordering relations variables robust features existence edges pdag 
third established high confidence features reliable cases data sets small model induced 
results extend opinion role adaptive bayesian network currently playing data analysis tasks enabling users exploit amount qualitative information network structure provides domain 
provide preliminary results bootstrap induction networks discussed implementing practical version bayesian estimates 
results indicate bootstrap reliable method detecting latent causes 
problem signaling existence latent causes uncovering set variables directly influence great interest 
computing estimates markov blanket variables clique variables definitely markov blanket edge relationships unclear indicative existence hidden variable 
reliability estimates optimistic results currently experimenting approach 
acknowledgments done nir friedman abraham wyner university california berkeley 
group uc berkeley mosix group hebrew university computational resources 
moises goldszmidt supported part darpa high performance knowledge bases program contract 
beinlich suermondt chavez cooper 
alarm monitoring system 
proc 
nd euro 
conf 
ai medicine 

buntine 
guide literature learning probabilistic networks data 
ieee trans 
knowledge data engineering 
chickering 
transformational characterization equivalent bayesian network structures 
uai pp 


chickering 
learning bayesian networks npcomplete 
ai stat 
cowell dawid spiegelhalter 
sequential model criticism probabilistic expert systems 
ieee trans 
pat 
ana 
mach 
int 
derisi iyer brown 
exploring metabolic genetic control gene expression genomic scale 
science 
efron tibshirani 
bootstrap 
spellman comprehensive identification cell genes yeast cerevisiae microarray hybridization 
mol 
biol 
cell 

confidence limits approach bootstrap 
evolution 
friedman goldszmidt wyner 
application bootstrap computing confidence measures features induced bayesian networks 
ai stat vii 

friedman nachman peer 
bayesian networks analyze genome expression data 
tr cs inst 
computer science hebrew university 
progress 
see www cs huji ac il labs 
heckerman 
tutorial learning bayesian networks 
learning graphical models 

heckerman geiger chickering 
learning bayesian networks combination knowledge statistical data 
machine learning 
heckerman meek cooper 
bayesian approach causal discovery 
msr tr microsoft research 

probabilistic analysis rocchio algorithm tfidf text categorization 
ml 

lander 
array hope 
nature genetics 
lockhart dong byrne gallo chee want kobayashi horton brown 
dna expression monitoring hybridization high density oligonucleotide arrays 
nature biotechnology 
meek 
causal inference causal explanation background knowledge 
uai pp 


pearl 
probabilistic reasoning intelligent systems 
pearl verma 
theory inferred causation 
kr pp 


wen carr smith barker somogyi 
large scale temporal gene expression mapping central nervous system development 
proc 
nat 
acad 
sci 
