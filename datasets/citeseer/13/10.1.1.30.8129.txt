proceedings international conference computer languages pp 
oakland california april 
fl ieee 
personal material permitted 
permission reprint republish material advertising promotional purposes creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
designing programming languages analyzability fresh look pointer data structures laurie hendren guang gao school computer science mcgill university montreal canada propose programming language mechanism associated compiler techniques significantly enhance analyzability data structures frequently non scientific programs 
approach exploiting important properties pointer data structures structural speculative 
structural facilitates application static interference analysis method pointer data structures path matrices speculative utilized novel loop unrolling technique loops exploit fine grain parallelism speculatively traversing data structures 
effectiveness approach demonstrated applying collection loops typical programs 
past decade dramatic improvement vlsi technology led modern high performance microprocessors support level fine grain parallelism 
today risc processors degree instruction level parallelism required fully utilize architecture 
ultra large scale integration multi transistor processor chips way decade expect higher degree fine grain parallelism due deep instruction pipelining multiple functional units particularly multiple pipelined functional units 
rapid advance vlsi technology computer architectures provided important challenges programming language designers compiler writers alike 
increasingly important provide programming languages associated compiler support user programs effectively analyzed order effectively utilize supported part fcar nserc mcgill faculty graduate studies research 
underlying architectures 
particular critical provide compile time analysis results accurate alias analysis data dependency information complex data structures 
argue analyzability important principle program language design implementation particularly critical efficient mapping non scientific programs architectures supporting level instruction level parallelism 
importance analyzability demonstrated considerable success automatic parallelization optimization large scale scientific numerical programs 
scientific programs arrays important data structures programs array structures analyzed effectively 
keys analysis arrays frequently defined rectangular index regions dimensions shapes bounds known compiler array operations encapsulated structured loops loops gotos iteration space loop matching index regions arrays loops arrays frequently accessed traversed regular fashion 
example index expression affine function loop indices 
mathematical structure arrays regularity accesses embedded loops lead development variety dependence analysis loop transformation parallelization techniques 
techniques pioneered areas vectorizing parallelizing compilers techniques applied architectures supporting instruction level parallelism 
unfortunately analysis optimization non scientific programs successful 
fact researchers reported pessimistic results indicating exploitable instruction level parallelism non scientific programs low question merit advanced advanced processor architectures superscalar vliw machines machines 
fresh look study wall shows impressive instruction level parallelism assuming perfect alias analysis types data structures 
increasing importance fine grain parallelism evidence alias analysis aids exploitation parallelism clear programs analyzable 
illustrate importance analyzability programs pointer data structures solution methodology proposed propose programming language mechanism significantly enhances analyzability pointer data structures frequently non scientific programs 
approach important properties structural speculative 
structural facilitates application static interference analysis method pointer data structures path matrices speculative utilized novel loop unrolling technique loops exploit fine grain parallelism aggressively traversing data structures 
effectiveness approach demonstrated applying collection loops typical programs 
organized follows 
section detailed outline challenges compiling imperative programs pointer data structures machines instruction level parallelism 
section introduce programming language constructs enhance analyzability programs providing programmer means specifying important properties pointer data structures frequently non scientific programs speculative structural 
section give concrete case study show mechanisms effectively applied unroll loops traverse data structures 
lastly provide section 
instruction level parallelism pointer data structures section outline challenges compiling instruction level parallelism presence pointer data structures 
subsection show inaccurate alias analysis pointer structures greatly reduce effectiveness instruction scheduling second subsection discuss difficulties encountered applying loop transformations presence pointer data structures 
instruction scheduling compiling architectures instruction level parallelism instruction scheduling crucial component 
order effectively utilize architecture compiler take sequential list instructions rearrange instructions way increase parallelism reduce execution time preserving original meaning program 
instruction scheduling commonly performed pipelined risc architectures 
order fully utilize instruction scheduling techniques necessary accurate dependency analysis 
consider small example program 
naive translation architecture cycle latency loads additions get instructions shown due cycle latency load addition operations insert nop instructions 
example nop instructions inserted needed extra cycle wait load complete compute 
improve schedule noting numbered instructions necessarily need executed order generated 
example refer different memory locations load depend need proceed load compile time analysis determine distinct variables refer different memory locations represent partial order dependency diagram 
starting partial order produce better schedule cycles cycles shown 
improved schedule requires extra nop instructions load add instructions scheduled cycles results needed 
compiletime analysis methods determine pointer variables refer memory location dependencies shown 
dependencies get substantially longer schedule shown 
clear accurate alias analysis pointer variables lead better instruction scheduling 
loop transformations considerable effort spent developing compile time techniques transform scientific programs way expose parallelism 
order introduce notion benefit loop transformations consider loop unrolling note notation indicate storing memory location pointed indicate loading memory location pointed val val val val nop nop nop nop program naive risc schedule omega omega ae jj dependence analysis risc schedule omega omega ae omega omega ae au nop nop nop bad dependence analysis bad risc schedule instruction scheduling example transformation technique developed parallelizing optimizing compilers scientific programs arrays 
example loop unrolling transform loop equivalent unrolled loop multiple copies loop body 
loop unrolling initially developed technique reducing loop overhead exposing instruction level parallelism machines multiple functional units 
applied conjunction instruction scheduling pipelined risc architectures 
increasing size body loop instruction scheduler produce shorter schedule unrolled loop 
consider problem performing similar transformation loops pointer data structures 
give program fragments extracted source code gnu compiler lp lp key lp lp prev lp nextlp lp 
lp prev prev lp lp nextlp lp prev initialize item reverse list lp nextlp lp nextlp lp nextlp nextlp nextlp lp find item typical loops loop initialize simply traverses list initializing key field second loop reverse destructively reverses list 
third loop traverses list find item 
glance appear loops really suited techniques loop unrolling 
potential problems include ffl case arrays compute index array elements elements parallel 
pointer loops appear inherently sequential list processed traversing element turn 
ffl array example straightforward compute loop bounds increment unrolled loop 
case pointer loops idea length structure simple way construct termination condition results equivalent unrolled loop 
ffl access item time appear loops com modified presentation loops form variable names 
putation item may candidates loop unrolling 
ffl case arrays loop body modify values structure structure 
shape size arrays remain 
case linked structures loop may change structure list 
true case reverse 
analyzable pointer data structures illustrated previous section challenges effectively compiling programs instruction level parallelism 
particular illustrated negative effect poor alias analysis pointer data structures difficulties encountered designing loop transformations pointer data structures 
difficulties arise data structures scalars arrays fixed shape size pointer data structures dynamically changing shapes sizes 
addition programmers dynamic data structures implement wide variety structures including singly linked lists doubly linked lists circular lists nested lists binary trees threaded trees graphs 
programmer may pointers constrained manner example programmer may certain type node build non cyclical lists compiler way knowing sort structure programmer mind compiler exploit properties specific structure 
addition compiler knowledge size length dynamic data structure 
section introduce characteristics pointer data structures allow better compile time analysis 
give examples programming language analyzable 
sub section introduce class structurally inductive data structures illustrate path matrix analysis provide accurate alias analysis class data structures 
second sub section introduce speculative property allows perform loop transformations knowing length data structure 
practical reasons including wide spread non scientific programming chosen develop approach relative programming language fact techniques require small syntactic extensions implemented straight forward preprocessing step 
assume notion designing analyzable programming languages restricted hope take challenge designing better analyzable programming languages suitable architectures supporting instruction level parallelism 
structurally inductive pointer data structures alias analysis order provide accurate alias analysis pointer data structures programmers able classify data structures inductive non inductive 
inductive linked structure cycles node parent 
inductive structures include linked lists nested lists trees non inductive structures include dags cyclic graphs 
inductive structures nice properties analysis techniques alias analysis dependence analysis parallelizing transformations class structures developed 
exploitable properties inductive structures include component pieces structure head tail list left right sub trees binary tree share storage computations components non interfering breaking link yields independent pieces traversal series linked nodes revisits node 
approach exploiting analyzability inductive structures allow programmer indicate pointer data structures property 
order discuss language extension respect introduce high level recursive type statement rectype 
rectype statement consists list field names field having scalar type recursive type defined 
illustrated example linked lists rectype statement translated compiler traditional recursively defined pointer structures note compiler generate appropriate types nodes pointers nodes constant representing empty structure list null 
illustrated provide option indicating particular rectype inductive property 
noted inductive non inductive recursive structures implemented data types 
treat inductive specification directive type 
programming language designer choice directive 
easiest safe approach take directive promise programmer structures built type inductive 
analogous allowing arrays bounds checking 
rectype list inductive int key list name empty list define node type ordinary lists typedef struct list int key struct list listnode rectype implementation preferable approach directive aid compiler choosing correct sort alias analysis perform data type 
analysis best suited inductive structures rectype labeled inductive 
just dependence analysis natural choice analyzing array path matrix analysis natural choice inductive structures 
path matrix analysis interprocedural analysis technique specifically developed inductive data structures 
technique exploits special properties inductive structures order provide accurate static analyses safely determine pointer data structures guaranteed inductive perform alias analysis dependency analysis pointer variables point nodes inductive structure detect non interfering computations 
illustrate path matrix analysis program fragment 
program calls function build list executes loop reverse list 
loop orig lp points item loop new lp points item reversed list orig lp points cell reversed list 
order demonstrate analysis works path matrix analysis tool process program extracted pieces trace analysis 
program point trace give path matrix summarizes relationships paths exist pair pointer variables called handles live point 
note handle decorated pair looks ffl fi 
item pair corresponds handle second item corresponds field handle ffl means definitely nil ffi means definitely nil fi means interprocedural analysis tool written sml 
build list items points original head list lp prev lp get node nextlp lp reverse link lp lp prev get ready iteration prev lp lp nextlp points new head list points element prev example program reverse loop 
consider points path matrix analysis 
program point statement program fragment call procedure build list builds non cyclical list 
shown path matrix analysis call see resulting path matrix contains live handle orig lp relationship 
note relationship handles indicates variables point node 
fact entry path matrix indicates live pointer variables handles reached head list orig lp analysis procedure call successfully determined structure pointed orig lp inductive 
analysis call successful example programmer may created cyclic structure accurate alias analysis mechanism 
program point path matrix computed program point contains handles lp orig lp 
note entries reflect fact lp orig lp point node 
program point statement see occurrence nil pointer list null 
see handle prev definitely nil related handle 
program points path matrices computed iteration loop fixed point calculation 
think path matrices approximating state data structures iterations loop iteration 
note program point relationship lp lp exactly link relationship prev orig lp point node chain prev orig lp 
note relationship prev lp 
corresponds orig lp ffl fi orig lp lp orig lp ffl fi lp ffl fi orig lp lp prev orig lp ffl fi lp ffl fi prev ffi ffi orig lp lp prev iteration loop fixed point calculation nextlp lp orig lp lp prev lp ffl ffi ffl fi ffl fi fi fi orig lp 
lp prev lp lp prev orig lp ffl ffi lp ffl ffl lp fi fi orig lp lp lp prev lp orig lp ffl ffi prev ffl ffl lp fi fi orig lp prev lp lp nextlp orig lp ffl ffi lp fi fi prev ffl ffl orig lp lp prev repeat prev orig lp ffl fi new lp fi fi orig lp 
new lp partial trace path matrix computations fact original list split distinct pieces reversed part starting prev orig lp part starting lp 
program point program point see relationship new head list new lp original head orig lp 
corresponds case original list item corresponds cases lists item 
example shows get accurate alias analysis inductive structures apply alias analysis techniques carefully designed take advantage special properties structures 
analysis provides accurate information structure destructively traversed 
illustrates point able capture special properties data structures programming language level appropriate compiler analysis techniques developed structures 
speculatively traversable pointer data structures addition providing properties lead better alias analysis deal problem knowing length size pointer data structures 
order fully demonstrate problem return problem unrolling loops 
recall loops operate arrays easily unrolled simply modifying counter termination conditions loop 
loops pointers situation difficult 
consider example initialize loop 
order effect sort unrolling try brute force approach duplicating body loop appropriate conditionals 
gives example approach unrolling initialize loop times 
clearly semantically equivalent original loop approach appear improve code 
loop overhead improved need just tests instructions body remain sequential 
give strategy unrolling loop 
case extra list pointers lp lp introduced give independent pointers list 
result statements updating fields lp key lp key lp key executed parallel number tests reduced original loop 
unrolled loop necessarily semantically equivalent original loop 
problem lp lp key lp lp original loop lp lp key lp lp lp lp key lp lp lp lp key lp lp brute force approach lp lp lp lp lp lp key lp key lp key lp lp lp lp lp lp lp lp key lp lp unrolling loop unrolling initialize example don know items list speculative computation lp lp may cause run time errors occur original loop 
leads define property speculative 
idea speculatively traversable structure traversing empty structure yields empty structure 
knowing length list safely traverse items causing run time error 
formally define important property 
definition type speculatively traversable pointer data structure scalar fields recursive pointer fields pointer representing empty structure type equality holds note speculatively traversable recursive data structure really different type ordinary recursive data type changed meaning operations empty structure 
capture idea define new type statement illustrated 
note implementation definition identical rectype definition empty data structures 
implemented empty structure speculatively traverse data structure extra traversals empty structure result empty structure 
loop transformations discussed section loop transformations important components compiling list int key list name empty list define node implementing empty list static listnode pointer empty list static code initialize empty list 
void set pointer empty list node set scalar type approp 
zero key set recursive field self node type speculative list typedef struct list int key struct list listnode implementation instruction level parallelism 
section new loop unrolling technique applies structurally inductive speculatively traversable pointer data structures 
second part section provide experimental results indicate substantial performance gain loop unrolling technique 
order demonstrate wide variety loops consider loops additional loops 
sum loop typical loop traversing structure accumulating final value 
count loop example loop performs action subset items list 
important characteristic loop contains conditional body 
find loop typical loop traverse entire list 
characteristic importance loop complex termination condition 
new loop unrolling technique loops traverses processes linked list item time 
iteration loop item list processed 
basic strategy loop unrolling transform original loop loop processes item iteration 
advantages transformation include loop overhead reduced size loop body sum lp sum lp key lp lp count lp lp key count lp lp sum elements count equal lp lp key lp lp find element equal additional test loops increased providing flexibility traditional optimizations dead code removal instruction scheduling cases available parallelism increased operations different list items may proceed independently 
isolated general patterns performing loop transformations 
give patterns equivalent unrolling obvious generalization unrolling 
example loops reverse fit pattern pattern typical loops reverse updating structure list traversed 
note cases unrolling pattern consists adjacent loops 
loop processes items iteration second loop processes remaining tail list case length list multiple concise summary loop unrolling method 
detection loop examined see fits pattern case loop obey properties condition cond lp boolean expression defined variable lp variable 
body loop divisible non interfering sub pieces body lp traverse lp 
analysis done simple symbolic inspection loops require path matrix analysis complex loops reverse 
traverse lp computation traversal recursive field 
unrolling loop unrolled introducing new variables lp lp appropriate producing pair new loops illustrated 
kth copy body created replacing occurrence lp 
conditional optimization naive loop unrolling creates conditional cond lp cond lp cond 
greatly cond lp body lp lp traverse lp lp traverse lp lp traverse lp cond lp lp lp body lp body lp body lp lp traverse lp lp traverse lp lp traverse lp cond lp body lp lp traverse lp cond lp new lp traverse lp body lp lp new lp lp traverse lp lp traverse lp cond lp lp lp new lp traverse lp body lp body lp body lp lp new lp lp traverse lp lp traverse lp cond lp new lp traverse lp body lp lp new lp pattern pattern patterns unrolling times simplified 
example property speculatively traversable structures defined section simplify lp list null lp list null lp list null lp list null 
loop body optimization note unrolled loops adjacent copies body original loop 
provides opportunities traditional optimizations copy elimination dead code removal 
illustrates dead code removal loop 
parallelization final step determine different copies body independent 
determining fact particular linked structure inductive 
example case inductive structures guarantee different variables lp lp refer independent nodes 
experimental results section experimental results obtained applying loop unrolling techniques loops figures 
consider example unrolling loop 
show original loop unrolled loop unrolled loop conditional body optimized 
note optimizations straight forward applications speculatively traversable property dead code elimination 
due resulting reduced loop overhead removal unneeded computation unrolled version expect improved performance nextlp nextlp nextlp nextlp nextlp nextlp nextlp lp nextlp lp nextlp lp nextlp nextlp nextlp nextlp nextlp nextlp nextlp nextlp lp nextlp nextlp nextlp nextlp nextlp nextlp nextlp nextlp lp nextlp nextlp nextlp nextlp nextlp nextlp nextlp nextlp lp nextlp nextlp nextlp unrolled unrolled optimized unrolling unrolled version original loop 
performance improvement confirmed experimental figures table 
experiment performed original loop optimized unrolled loops equal 
case transformation performed source level resulting unrolled loop compiled native cc compiler optimizer option 
unrolling give time microseconds required execute loop lists length 
addition speedup indicated parentheses 
note excellent speedups ranging cases unrolling run list elements 
case cost speculative traversal outweighs benefits 
architectures note unrolling results performance lengths lists speedups ranging 
performed complete set experiments loops 
loop experimented effect technique variety compilers compiler effect optimizing option 
table summarizes part results case unrolling native cc compiler option 
resulted impressive speedups cases mips architecture average speedups sparcstation sun release cc compiler decstation mips cc compiler sparc orig loop unroll unroll unroll unroll mips orig loop unroll unroll unroll unroll table speedups speedups cases sparc architecture average speedups 
studying code produced various cc compilers note reasons speedup reduced number branches reduced number instructions better instruction scheduling due increased size block body 
sparc initialize reverse count sum find average mips initialize reverse count sum find average table speedups benchmarks unrolling observation loop unrolling technique lead better instruction scheduling risc machines shows techniques important effective exploitation parallelism available today advanced architectures 
furthermore refined alias analysis path matrix analysis incorporated expect speedups due improved instruction scheduling 
current generation high performance architectures support instruction level parallelism 
produce efficient code machines compiler able analyze programs detect opportunities optimization parallelization 
motivates central theme analyzability important principle programming language design implementation 
focused analyzability issues real life non scientific programs 
majority programs written imperative languages different hardware platforms sign trend slow soon 
feel challenge researchers areas programming language design implementation solutions easily assimilated adapted community programming languages lead effective current highperformance architectures 
illustrated negative effect poor alias analysis pointer data structures difficulties encountered designing loop transformations 
difficulties arise data structures scalars arrays pointer data structures dynamically changing shapes sizes 
addition programmers dynamic data structures implement wide variety structures including lists doubly linked lists circular lists nested lists binary trees threaded trees graphs 
proposed programming language mechanism utilized design pointer data structures important properties structural speculative 
illustrate path matrix analysis provide accurate alias analysis structural inductive data structures 
described novel loop transformation method aggressively exploit finegrain parallelism pointer data structures speculatively traversable provided experimental results show transformation results significant performance improvement 
randy allen david callahan ken kennedy 
automatic decomposition scientific programs parallel execution 
conference record th popl pages january 
todd allen michael burke ron cytron 
practical powerful algorithm subscript dependence testing 
technical report ibm 
internal report 
banerjee 
dependence analysis supercomputing 
kluwer academic publishers boston ma 
dongarra 
unrolling loops fortran 
software practice experience 
vincent jr technique analyzing pointer structure parallel restructuring compilers 
proceedings international conference parallel processing volume pages 
laurie hendren 
parallelizing programs recursive data structures 
phd thesis cornell university january 
laurie hendren guang gao 
designing programming languages analyzability fresh look pointer data structures 
acaps technical memo mcgill university 
laurie hendren alex nicolau 
parallelizing programs recursive data structures 
ieee transactions parallel distributed systems 
jouppi wall 
available parallelism superscalar machines 
proceedings asplos iii pages boston ma 
krishnamurthy 
brief survey papers scheduling pipelined processors 
sigplan notices 
james larus paul hilfinger 
restructuring lisp programs concurrent execution 
proceedings acm sigplan pages july 
padua wolfe 
advanced compiler optimizations supercomputers 
communications acm december 
smith johnson horowitz 
limits instruction issue 
proceedings asplos iii august 
wall 
limits instruction level parallelism 
proceedings asplos iv pages april 
shlomo weiss james smith 
study scalar compilation techniques pipelined supercomputers 
proceedings asplos ii pages 
acm 
michael wolfe 
optimizing supercompilers supercomputers 
pitman london mit press cambridge ma 

