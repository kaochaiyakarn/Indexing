decomposition human written summary sentences jing kathleen mckeown department computer science columbia university new york ny usa kathy cs columbia edu define problem decomposing human written summary sentences propose novel hidden markov model solution problem 
human summarizers rely cutting pasting full document generate summaries 
decomposing human written summary sentence requires determining constructed cutting pasting components sentence come original document document components come 
solving decomposition problem potentially lead automatic acquisition large corpora summarization 
sheds light generation summary text cutting pasting 
evaluation shows proposed decomposition algorithm performs 
define solution problem called summary sentence decomposition resolution believe improve performance automatic text summarizers 
goal decomposition program determine relations phrases summary written professional summarizers phrases original document 
linguistic research endres neugebauer suggest human summarizers rely cutting pasting text original document produce summary 
current automatic summarizers extract sentences paragraphs modification human summarizers edit extracted text fit new context 
call technique cut paste involves cutting phrases original document pasting novel ways summary 
task decomposition decode cut process 
summary sentence produced humans cut technique want reconstruct cut paste procedure deduce done 
specifically human written summary sentence decomposition program required answer questions summary sentence constructed cutting pasting text original document 
components sentence come original document 
document components come 
call summary sentence decomposition problem 
benefit solving decomposition problem fold 
large corpora training evaluating summarizers built decomposition result 
linking human written summaries original texts mark important content document 
doing automatically ord mark content importance large set documents providing valuable training testing datasets summarization 
second decomposition sheds light text generation problem summarization rarely studied date 
nearly current summarizers rely simple extraction produce summaries extracted sentences incoherent redundant misleading 
decomposing human written sentences learn kind operations usually performed humans edit extracted sentences develop automatic programs simulate successful operations 
discuss decomposition result purpose 
propose hidden markov model solution decomposition program 
section show example cut paste technique humans discuss di culties involved decomposition 
section solution mathematically formulating decomposition problem presenting hidden markov model 
corpus study decomposition program showing human written summary sentences corpus produced cut paste technique 
section demonstrate applications results discuss related 
conclude discuss 
cut paste technique expert summarizers reuse text original document produce summary 
manual analysis sentences human written summaries identified major operations involved cut paste procedure 
sentence reduction common technique 
humans select sentence document remove important material reduced sentence summary 
example sentence reduction 
infinitive adjunct removed 
document sentence bill require prescribe rules commercial web sites follow collecting personal information children 
summary sentence bill require right privacy rules commercial web sites 
deleted material granularity word phrase clause 
multiple components removed shown 
document sentence james attorney pointed west features legally copied 
summary sentence attorney noted west copied 
sentence combination humans generate summary sentence combining material sentences document 
shows summary sentence combined document sentences 
sentence combination sentence reduction shown example uses paraphrase text sentence raises serious questions privacy highly personal information digital world 
text sentence issue fits squarely broader debate privacy security internet involves protecting credit card number keeping children information 
summary sentence raises issue privacy personal information issue hits head nail broader debate privacy security internet 
syntactic transformation sentence reduction combination syntactic transformations may involved 
example position subject sentence may moved word order may reversed 
lexical paraphrasing humans may borrow block texts original document replace certain phrases paraphrases 
instance substituted point note fits squarely description hits head nail previous examples 
generalization specification similarly humans may replace certain phrases clauses high level descriptions 
example description proposed new law require web publishers obtain parental consent collecting personal information children replaced legislation protect children privacy line 
humans may replace phrases clauses detailed descriptions 
examples include substitution white house top drug cial gen barry rey white house top drug cial substitution policy expand availability need policy recommends doctors allowed administer private ces 

reordering borrowed sentences document necessarily retain precedence order appear summary 
example concluding sentence document may placed summary opening sentence 
intuitively specification counter purpose summarization 
reasons technique think substituting certain general statements specifics humans avoid repetition need separate sentence just mention detail 
course certain summary sentences cut paste totally created scratch 
amount small portion total number sentences analyzed 
operations cut paste process listed due infrequent occurrence 
note operations 
instance examples sentence reduction lexical paraphrasing sentence combination syntactic transformation generalization 
decomposition useful di cult 
sentence components coming original document granularity 
identifying boundary component complex issue 
determining origin component hard component may occur multiple times document slightly di erent forms 
multiple operations may performed cut paste procedure 
resulting summary sentence significantly di erent document sentences comes 
factors add di culty decomposition problem 
decomposition summary sentences di cult problem solution hinges novel approach reducing problem finding word summary sentence document position comes 
cutting pasting practice humans set general heuristic rules produced 
heuristic rules create hidden markov model baum 
viterbi algorithm viterbi ciently find document position word summary sentence 
formulating problem mathematically formulate summary sentence decomposition problem 
input summary sentence represented word sequence word sentence word 
position word document uniquely identified sentence position word position sentence 
example uniquely refers th word th sentence 
multiple occurrences word document represented list word positions 

notations formulate decomposition problem follows word sequence word sequence position original document determine word sequence document position 
formulation reduce di cult tasks identifying component boundaries determining component origins single unified problem finding document position word 
shown word summary sequence chooses position get sequence positions 
example position sequence get summary word chooses occurrence word document 
position sequence 
time summary word chooses di erent position get di erent position sequence 
word sequence total possible position sequences 
communication subcommittee 


representing possible sequences positions summary fragment finding document position word equivalent finding position sequence possible position sequences 
example see position sequence fragment comes document sentence position sentence word number 
automatically find sequence possible sequences 
hidden markov model hmm exactly document position word comes depends positions words surrounding 
bigram model assume probability word comes certain position document depends word directly sequence 
suppose adjacent words summary sentence prob represent probability comes sentence number word number document comes sentence const const sentence const sentence const hidden markov model sentence decomposition sentence number word number decompose summary sentence consider humans generate draw operations noted section 
general heuristic rules safely assume humans cut phrases summary cut single isolated words second humans combine nearby sentences single sentence combine sentences far apart 
rules guidance decomposition process 
translate heuristic rules bigram probability prob represent adjacent words input summary sentence noted earlier 
probability abbreviated prob discussion 
assigned manner words adjacent positions document prob assigned maximal value 
example prob subcommittee communications example assigned maximal value 
rule adjacent words summary come adjacent words document 
prob assigned second highest value 
example prob subcommittee assigned high probability 
rule adjacent words summary highly come sentence document retaining relative precedent relation sentence reduction 
rule refined adding restrictions distance words 
prob assigned third highest value 
example prob subcommittee 
rule adjacent words summary come sentence document reverse relative orders case sentence reduction syntactic transformations 
const prob assigned fourth highest value 
example prob subcommittee 
rule adjacent words summary come nearby sentences document retain relative order sentence combination 
const small constant 
const prob assigned fifth highest value 
example prob subcommittee 
rule adjacent words summary come nearby sentences document reverse relative orders 
const prob assigned small value 
example prob subcommittee 
rule adjacent words summary come sentences far apart 
principles create hidden markov model shown 
nodes represent possible positions document edges output probability going node 
hmm finding position sequence step 
assigning values experimental 
experiment maximal value assigned assigned evenly decreasing values 
determined orders rules observations set summaries 
values adjusted trained di erent corpora 
viterbi algorithm find sequence find sequence positions maximizes probability prob 
bigram model approximated prob prob prob assigned hmm 
information needed solve problem 
viterbi algorithm find sequence 
word sequence supposing word document frequency viterbi algorithm guaranteed find sequence steps constant compared brute force search algorithm 
viterbi algorithm viterbi finds sequence incrementally 
finds sequence possible position information compute sequence possible position process repeats words sequence considered 
slightly revised viterbi algorithm application 
initialization step equal chance assumed possible document position word sequence 
iteration step take special measures handle case summary word appear document empty position list 
mark word non existent original document continue computation appeared sequence 
example demonstrate program show example 
sample summary sentence follows input summary sentence shown arthur vice president law public policy time warner member direct marketing association told communications subcommittee senate commerce committee legislation protect children privacy online destroy spontaneous nature internet unique 
index document listing word possible positions document 
stemming performed indexing example 
augmenting word possible document positions input viterbi program shown input viterbi program words possible document positions arthur 

internet 
unique word sentence total possible position sequences 
hmm run viterbi program find position sequence 
intermediate output viterbi program shown follows intermediate output viterbi program possible position word attached score shown bracket 
score indicates maximal probability subsequence ends position 
example word internet means position sequences word internet assume internet take document position highest score achieve 
arthur 


internet 
unique choosing sequence highest score find position sequence 
word determined document posi summary sentence arthur vice president law public policy time warner member direct marketing association told communications subcommittee senate commerce committee legislation protect children privacy online destroy spontaneous nature internet unique source document sentences sentence proposed new law require web publishers obtain parental consent collecting personal information children destroy spontaneous nature internet unique member direct marketing association told senate panel thursday sentence arthur vice president law public policy time warner said association supported orts protect children online urged find middle ground allows interactivity internet sentence example child mail address necessary order respond inquiries updates mark mcguire sosa home run figures year updates online magazine said testimony communications subcommittee senate commerce committee sentence subcommittee considering children online privacy protection act recommendation federal trade commission sample output decomposition program tion 
di erentiate components sentence combining words coming adjacent document positions 
sentence components identified program simple post editing cancel certain 
viterbi program assigns word input sequence position document long word appears document 
step document sentence contributes words summary matching cancelled words inserted humans coming original document 
similarly remove document sentences providing single non word 
shows final result 
components summary tagged actual text sequential number component number document sentence component comes 
means component come original document 
borrowed components tagged actual text document sentences 
example program correctly identified document sentences summary sentence combined correctly divided summary sentence components exact document origin component 
example components borrowed document range single word long clauses 
certain borrowed phrases syntactically transformed 
despite program successfully decomposed sentence 
evaluation carried evaluation experiments detailed small scale experiment second larger scale experiment 
experiment documents zi davis corpus selected human judges human written summaries experiment done marcu marcu 
human judges instructed extract sentences original document semantically equivalent summary sentences 
sentences selected majority human judges collected build extract document serves gold standard evaluation 
program provide set relevant document sentences summary sentence shown 
union selected sentences build extract document 
compared extract gold standard extract majority human judgments 
achieved average precision recall measure documents 
average performance human judges precision recall measure 
detailed result document shown table 
precision recall measure computed follows prec sentences extract gold standard total sentences extract recall sentences extract gold standard total sentences gold standard measure recall prec recall prec docno prec recall measure zf zf zf zf zf zf zf zf zf zf average table evaluation result documents analysis indicates types errors program 
program missed finding semantically equivalent sentences di erent 
example failed find correspondence summary sentence running higgins easier installing document sentence program easy installation procedure somewhat complex 
really error program designed find paraphrases 
sentence decomposition program needs indicate summary sentence produced cutting pasting text original document 
program correctly indicated returning matching sentence 
second problem program may identify non relevant document sentence relevant contains common words summary sentence 
typically occurs summary sentence constructed cutting pasting text document share words certain document sentences 
post editing steps designed cancel false matchings remove completely 
program demonstrates advantages 
capture duplications gold standard extract 
extract human judgments perfect 
paraphrases document chosen equal number human subjects included extract 
exactly happened extract document zf 
program contrast picked paraphrases 
correct decision penalized evaluation due mistake gold standard 
program won perfect scores documents 
checked summaries texts largely produced cut paste compared summaries new sentences written humans 
indicates decomposition task considered algorithm performs finishes task successfully 
second experiment selected summaries corpus ran decomposition program documents 
human subject read decomposition results judge correct 
program answer considered correct questions posed decomposition problem correctly answered total sentences summaries 
sentences wrongly decomposed achieve accuracy 
errors occur summary sentence constructed cut paste overlapping words certain sentence document 
accuracy rate higher precision recall results experiment 
important factor require program find semantically equivalent document sentence summary sentence uses di erent 
corpus study decomposition program analyzed summaries news articles 
collected summaries free news service 
news articles come various sections number newspapers cover broad topic 
summaries contain sentences total ranging sentences summary sentences summary 
results show sentences matching sentences document sentences match single sentence document sentences match sentences document sentences match sentences document 
results suggest significant portion summary sentences produced humans cut paste 
applications related decomposition results development text generation system domain independent sentence constructed cut paste program needs answer question 
summarization 
generation system mimics certain operations humans cutting pasting process discussed section 
main modules generation system sentence reduction module sentence combination module 
decomposition program able collect corpus summary sentences constructed humans reduction operations 
corpus human written summary sentences train evaluate automatic sentence reduction module 
similarly collected corpus combination summary sentences reveals interesting techniques humans frequently paste fragments original document coherent informative sentence 
task decomposition somewhat related summary alignment problem addressed marcu 
alignment algorithm operates sentence clause level decomposition program aligns phrases various granularity 
furthermore methodology systems hidden markov model ir approach coupled discourse model di erent 
reduced decomposition problem problem finding document position word summary sense similar problem aligning parallel bilingual corpora brown gale church 
align sentences parallel bilingual corpus align phrases summary phrases document 
sentence length feature word position feature 
approach determining probabilities hidden markov model totally di erent theirs 
defined problem decomposing human written summary sentence proposed novel hidden markov model solution problem 
decomposition program automatically determine summary sentence constructed cutting pasting text original document accurately recognize components sentence despite wide variety granularities pinpoint exact origin document component 
algorithm fast straightforward 
need tools tagger parser preprocessor 
complex processing steps 
evaluation shows program performs decomposition task 
discussed detail cut paste technique summary sentence generation 
major operations involved cut paste procedure identified 
output decomposition program investigating methods automatically learn cut paste rules large corpora fast reliably generation higher quality summaries 
acknowledgment daniel marcu sharing evaluation dataset 
material supported national science foundation 
iri iri columbia university strategic initiative fund 
opinions findings recommendations expressed material authors necessarily reflect views national science foundation 
baum 

inequality associated maximization technique statistical estimation probabilistic functions markov process 
inequalities 
peter brown lai mercer 

aligning sentences parallel corpora 
proceedings th annual meeting acl pages berkeley california june 
association computational linguistics 
endres neugebauer 

professional summarising cognitive simulation observation 
proceedings international conference cognitive science san sebastian may udo 

summaries newspapers investigation 
udo editor structure texts 
gunter verlag tubingen 
william gale kenneth church 

program aligning sentences parallel corpora 
proceedings th annual meeting acl pages berkeley california june 
association computational linguistics 
daniel marcu 

automatic construction large scale corpora summarization research 
proceedings sigir university berkeley ca august 
viterbi 

error bounds convolution codes asymptotically optimal decoding algorithm 
ieee transactions information theory 
