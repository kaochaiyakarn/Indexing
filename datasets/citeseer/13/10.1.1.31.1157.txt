learning regular languages simple positive examples fran cois denis mail denis li fr grappa universit de lille cedex france 
learning positive data constitutes important topic grammatical inference believed acquisition grammar children needs syntactically correct positive instances 
classical learning models provide way avoid problem overgeneralization 
order overcome problem learning model simple examples notion simplicity de ned help kolmogorov complexity 
show general natural heuristic allows learning simple positive examples developed model 
main result class regular languages probably exactly learnable simple positive examples 
keywords grammatical inference pac learning kolmogorov complexity regular languages deterministic finite automata 

natural language learning constitutes typical human learning abilities 
dicult challenge researchers computational learning theory 
models learning theory gold identi cation limit model gold valiant probably approximatively correct model valiant results satisfactory simplest class formal languages class reg regular languages 
reg learnable pac model modulo usual cryptographic assumption kearns valiant reg learnable help trivial algorithm cognitive relevance gold model gold 
see pitt sakakibara survey eld 
things getting worse try take natural constraint account natural language learning sentences syntactically correct 
formal theories explain possible learn positive data 
gold proves gold soon class languages contains nite languages nite language identi able limit positive data 
corollary class reg kluwer academic publishers 
printed netherlands 
regfinkl tex fran cois denis learnable positive data gold model 
problem positive example refute general hypothesis 
impossible avoid overgeneralization simplest cases 
angluin characterization indexed families recursive languages identi able limit positive examples angluin 
gave general heuristic order avoid overgeneralization step current positive sample hypothesis may output consistent computable nite sample included sets interpreted characteristic samples output 
words general hypothesis refuted characteristic sample current sample 
angluin angluin introduced subclasses reg called reversible languages shown existence polynomially computable characteristic samples sucient identi cation positive data 
see sakakibara yokomori de kanazawa kanazawa head 
due free distribution polynomial running time requirements results weaker pac learning framework natarajan yokomori denis 
valuable heuristics learning algorithms positive examples proposed quite succesfully practical situations speech recognition natural language learning 
example see carrasco oncina approach probabilistic nite state automata pfsa stolcke omohundro rabiner juang hidden markov model hmm approach 
knowledge general result available pfsa hmms 
goal study conditions general classes languages learned eciently positive examples 
gold suggests reason natural language learning possible learner provided arbitrary examples gold 
ways give substance idea learner may ask queries 
angluin proved angluin reg exactly learnable polynomial time membership equivalence queries minimally adequate teacher mat 
think queries meaningful positive learning framework 
remarked children get feedback say 
example parents commonly repeat children say corrections 
arguments said natural language learning mainly regfinkl tex learning regular languages simple positive examples develops children systematically corrected parents 
completely incorrect utterances rarely observed 
think membership queries restricted way order positive learning framework 
may impose teaching set current sample gold angluin goldman mathias 
mainly study learning model goldman mathias 
teaching set may contain negative examples class reg eciently exactly learnable model goldman mathias oncina garcia 
teaching set composed positive examples easy show reg learnable 
pac framework class allowed distributions restricted li vit anyi denis denis gilleron 
starting point li vit anyi suppose simple examples importance learning process 
kolmogorov complexity measure complexity example supposed learning process examples drawn solomono levin distribution 
model generalized denis order take complexity representation target account supposed examples drawn conditional solomono levin distribution xjc 
simple examples low conditional complexity xjc probable class concepts said learnable simple examples pacs learnable short pac learnable provided examples drawn proved parekh honavar class reg pacs learnable 
learning models teaching sets raise problem representation target concept encoded means examples 
show case learning algorithm rendered trivial prevents teacher put encoding target concept teaching set prevents learner 
unfortunately class regular languages concerned collusion phenomenon teacher learner possible encode eciently dfa large string 
string encodes minimal dfa recognizes language low kolmogorov complexity knowing representation simple example learning model simple regfinkl tex fran cois denis examples concerned problem 
means models strong avoid collusion phenomena want verify case global information target directly provided learner 
despite problems pointed mainly interested learning model simple examples 
reasons 
theory kolmogorov complexity provides rigorous way de ne amount information shared example target language 
say example characteristic language small kolmogorov complexity relatively representation give rigorous de nition captures important features intuitive notion 

way eciently encode regular language means positive examples 

supposing simple examples higher weight learning process suggests heuristic avoid overgeneralization hypothesis consistent current sample compute new positive examples generally positive events composed positive examples characteristic low kolmogorov complexity relatively draw examples target concept drawn true reject think previous heuristic relevant cognitive point view 
don infer doubtless target expect see odd exponent 
reason reject hypothesis simple characteristic expected event having odd exponent true 
study learning simple positive examples show learning algorithms heuristic 
main result class regular languages probably exactly learnable simple positive examples 
model de ned section de ne section notion positive teaching set possible reconstruct dfa show existence simple teaching sets section eventually prove main result section 
corollary show class simple regular languages learnable model li vit anyi 
result generalizes regfinkl tex learning regular languages simple positive examples simple pac learnability simple reversible languages stated li vit anyi 

preliminaries 
deterministic finite automata nite alphabet set strings 
simplicity suppose results extended general case straightforward way 
write resp 
function maps element rst resp 
second component 
denote null string length string juj 
size nite subset de ned juj 
consider ordering juj jvj juj jvj smaller lexicographical ordering 
integer respectively set strings length respectively length 
language subset language pre strings uv implies 
integer string fv lg 
languages 

deterministic nite automaton dfa quintuple nite set states initial state set accepting states transition partial function 
denote extended transition partial function de ned denote language accepted fu tg 
state fu tg 

language regular recognized dfa 
write reg class regular languages 
automaton said trimmed state accessible initial state state nal state accessible dfa ecient procedure nd minimal dfa number states 
say non empty regular language states mean trimmed minimal dfa recognizes states 
note dfa states encoded string length log 
encoding function dfa function dfa dfa jc bounded log runs time polynomial card 
regfinkl tex fran cois denis automata dfa isomorphic 
exists polynomial time deterministic algorithm takes input string outputs automaton dfa error 
convenience suppose length equal number states jc card 
example take smallest string form card card card code state length max dlog card 
example 
minimal deterministic automaton recognizes previous scheme code encoding say 
kolmogorov complexity solomonoff levin distribution complete de nitions results proofs li vit anyi 
jxj self delimiting version hx yi yx 
hx hhx turing machine write hp yi mean program extra information terminates output de ne xjy hp yi xg exist xj 
xjy minimal length program computes consider pre variant kolmogorov complexity pre turing machine turing machine set terminating programs pre set 
note string pre regfinkl tex learning regular languages simple positive examples turing machine set programs hp yi halts pre set 
invariance theorem states exists additively optimal pre turing machine pre turing machine constant strings ku xjy xjy pair additively optimal pre turing machines constant strings xjy xjy note current programming languages additively optimal pre turing machines 
machine say call pre turing machine 
de ne ku xjy ku xjy 
proved strings xjr jxj log jxj element nite set strings identi ed program computes index card xjr log log log inequalities strings hx yi yjx interesting property pre kolmogorov complexity string xjr de ne xjr xjr 
string probability distribution function called solomono levin distribution 
shown dominates enumerable semi distribution computable 

learning models restrict classical de nitions classes languages 
class languages 
representation scheme associates set names language formally representation scheme function regfinkl tex fran cois denis exists polynomial time deterministic algorithm takes input pair strings outputs resp 
resp 
error 
representation scheme class regular languages deterministic nite automata reg fc ja dfa lg encoding function dfa chosen 
non empty regular language denote encoding minimal trimmed dfa recognizes supposed isomorphic dfas code correctly de ned 
usual size regular language de ned size min jrj 
example language pair 
example positive negative 
denote ex respectively pos set examples respectively positive examples language sample resp 
positive sample nite subset ex resp 
pos 
multiset examples 
learning model goldman mathias rst learning model consider model teacher goldman mathias 
reasons considering 
regular languages learnable model 
second close connections model pacs model learning mainly consider 
speci cally learnability reg model implies learnability pacs model 
third class regular languages learnable positive examples model prove pacs model 
de nition 
goldman mathias class language learnable model goldman mathias gm learnable short exist algorithms teach learn teach takes input representation language outputs teaching sample sl ex learn takes input sample sl ex outputs representation goldman mathias task constituting sl adversary goal prevent learning 
regfinkl tex learning regular languages simple positive examples learn runs time polynomial size class semi poly gm learnable 
teach runs time polynomial size class polynomially gm learnable 
proved goldman mathias class learnable deterministic polynomial time example queries semi poly gm learnable 
proved angluin reg learnable membership equivalence queries class regular languages semi poly gm learnable 
dicult provide polynomial teacher 
number algorithms teach learn dfas model gold oncina garcia 
example try build automaton incrementally initial state need know transition arrive new state come back de ned state 
teaching algorithm idea states current automaton letter teacher provides learner strings di erentiate 
learning algorithm merge states distinguished 
example 
minimal deterministic automaton recognizes see example 
di erentiate 
obeying order create new state absolutely necessary possible reconstruct incrementally set examples contains 
problem learning model goldman mathias suciently constrained avoid collusion learner teacher 
forbids teacher add encoding target automaton appropriate useless label teaching set 
prevents learner information 
polynomial teaching algorithm learn class regular languages gm model new teacher de ned code minimal trimmed automaton recognizes 
consider algorithm regfinkl tex fran cois denis input sample superset teaching set code automaton compute consistent halt output representation exists learning algorithm computes regular language sample containing regular language consistent sample contains 
equal learning algorithm reg rendered trivial 
mean learning algorithms gm model collusive exist polynomial teaching learning algorithms target concepts encoded examples exist collusive learning algorithms 

pac learning assume familiarity basic facts pac learning theory see example kearns vazirani natarajan valiant 
class language target language xed probability distribution ex procedure runs unit time call returns example drawn randomly independently 
concept de ne error respect probability inconsistent example drawn randomly error 

de nition 
class language representation scheme algorithm pac learning algorithm takes input integer language size probability distribution access ex outputs representation probability error 
pac learnable pac learning algorithm runs time polynomial size longest example drawn 
regfinkl tex learning regular languages simple positive examples parameter omitted input parameters guessed learning algorithm learner test hypothesis learning task haussler 
previous de nition relaxed way output learning algorithm belong larger hypothesis class 
say class language predictable pac learnable polynomially hypothesis class 
main result concerning pac learnability class regular language negative assuming cryptographic assumptions reg predictable 
theorem 
kearns valiant kearns vazirani discrete root assumption representation class dfa inherently unpredictable 
result isolated 
turned learning problems intractable standard pac model 
reason fact 
pac learning model algorithm learn distributions 
called distribution free requirement 
hope learn language shares relation distribution provides examples 
proved limiting allowed distributions improve drastically expressivity model 
limit allowed distribution restrictive unnatural way 
simple pac learning models section hypothesis examples low kolmogorov complexity higher weight learning process 

simple pac learning models variant pac learning model class probability distributions restricted universal solomono levin distribution de ned li vit anyi 
remarkable property distribution polynomial sample overwhelming probability examples logarithmic complexity simple examples represented 
learning algorithm simply needs reconstruct concept approximatively simple examples li vit anyi denis de ned simple pac learning model 
see denis gilleron study connections models 
underlying idea suppose oracle knows representation target concept gives higher weight examples simple representation 
regfinkl tex fran cois denis de nition give slightly general denis 
de ne language set admissible distribution dl suppose distribution draw examples admissible 
de nition 
class languages representation scheme language de ne set admissible distributions dl fm jr loosely speaking example simple representation xjr log size 
polynomial sample contain simple examples probability 
language canonical representation exists algorithm computes representation language polynomial sample drawn admissible distribution certainly contain simple examples rl jr exists program computes simple example simple xjr rl jr de nition 
class languages representation scheme algorithm simple pac learning algorithm takes input integer language size admissible distribution access ex outputs representation probability error 
pac learnable simple examples pacs learnable short simple pac learning algorithm runs time polynomial note arbitrarily long simple examples jrj size longest example seen appear parameters kept measuring time complexity learning algorithm 
retaining examples seen sucient learning strategy 
note hypothesis testing procedure designed haussler regfinkl tex learning regular languages simple positive examples anymore long examples handled 
impossible omit input parameter kolmogorov complexity string depends turing machine chosen 
known set pacs learnable classes depends turing machine 
independence easily veri ed classes proved learnable model sucient verify particular property machine 
general case conceivable require standard pac algorithm output exactly target language 
examples zero weight underlying distribution way identify exactly target 
solomono levin distribution puts positive weight example say learning algorithm probably exactly correct outputs representation target high con dence 
de nition 
class languages representation scheme algorithm simple pec learning algorithm takes input integer language size admissible distribution access ex outputs representation probability pec learnable simple examples simple pec learning algorithm runs time polynomial connections gm learnability pec learnability studied denis gilleron 
castro studied connections model exact learning queries castro 
dfa proved pacs learnable parekh honavar 
proposition 
class language polynomially gm learnable pec learnable simple examples 
proof 
sketch 
teaching algorithm 
runs polynomial time exists integer language card size representation computable element computed program length log size 
regfinkl tex fran cois denis xjr log size example simple representation target language 
polynomial sample drawn admissible distribution contain teaching set high probability 
corollary 
class dfa pec learnable simple examples 
pacs model gm model share defect possible encode directly target means examples learning rendered trivial 
model strong avoid collusion learner teacher 
verify case cheating employed 

learning positive examples importance learning positive data natural learning recognized 
reported gold seminal gold acquisition mother tongue sentences syntactically correct 
assertion argued incorrect sentence uttered child ect return play role negative example 
means learner able simulate negative data comparing provided expected information 
possible grammatical inference basis positive examples 
gold proved gold class languages contains nite languages nite language identi ed limit positive examples 
corollary regular languages learnable gold model 
natural languages certainly complex regular languages non learnability reg raises problem 
gold suggests ways solve contradiction 
consider examples provided learner arbitrary way 
learning positive data dicult 
main reason general hypothesis refuted new positive example 
learning algorithm classically prevent 
learning algorithm learn positive data prevent overgeneralization 
note result angluin characterizes indexed families recursive languages identi able limit positive examples 
loosely speaking give interpretation result order learn positive data necessary associate computable enumerable characteristic sample sl hypothesis current hypothesis consistent current regfinkl tex learning regular languages simple positive examples positive sample refuted sl provides general way prevent overgeneralization 
heuristic learning algorithm general principle 
gm learnable class identi able limit class reg learnable positive examples learning model goldman mathias 
easy direct proof suppose reg gm learnable positive examples 
teach learn teaching learning algorithms 
nite regular language teach 
language regular 
teach teach learn teach learn teach contradictory 
unfortunately situation getting worse pac learning model 
easily shown class pac learnable positive data class cnf output hypothesis included target concept 
impossible positive data di erentiate negative example absent positive simple classes pac learnable positive data 
see natarajan denis detailed study 
see sakakibara results grammatical inference learning structured positive examples kanazawa identi cation limit categorial grammars semantic categorical grammars 

learning simple positive examples priori reasons think complex classes learned positive simple examples 
suppose correct simple frequent sentences humphrey runs 
humphrey meets runs 
meets learner infers words humphrey belong syntactical category 
correct sentences meets humphrey talks humphrey suciently frequent absence sentences form regfinkl tex fran cois denis meets talks sucient learner give hypothesis 
simple correct produced 
pacs learning model characteristic example target example computed small program target known 
learner eciently compute characteristic examples current hypothesis examples appear reasonable time current sample reasons discard hypothesis characteristic example frequent 
words fact simple examples higher weight underlying distribution provide heuristic prevent overgeneralization 
goal show heuristic really learn regular languages 
adjust de nition 
de nition 
class languages representation scheme non empty language de ne set positive admissible distributions jr 
positive restriction admissible distribution target language note 
de nition 
class languages representation scheme algorithm probably exactly correct pec learning algorithm simple positive examples takes input integer non empty language size positive admissible distribution access ex outputs representation probability pec learnable simple positive examples pec learning algorithm simple positive examples runs time polynomial regfinkl tex learning regular languages simple positive examples roughly speaking simple positive example language positive example low kolmogorov complexity representation minimal trimmed automaton recognizes get heart matter show polynomial sized suciently large sample drawn positive admissible distribution certainly contain simple positive examples proof technical lemmas 
lemma 
recall strings de ned xjr exists constant string proof 
string xjr get exists constant string take lemma shows non empty regular language representation non null lower bound 
lemma 
class languages representation scheme exists constant non empty language representation get xjr xjr proof 
write rst string ordering 
exists program takes input representation non empty language outputs 
jr jr get result 
constants 
show lemmas encoding minimal dfa recognizes distributions kinds minimal elements multiplicative constant sets admissible respectively positive admissible distributions regfinkl tex fran cois denis lemma 
exists constant non empty regular language representation string cm proof 
exists program takes input representation regular language computes corresponding automaton minimizes outputs representation equivalent minimal dfa 
exists constant non empty regular language representation string xjr xjr previous lemma get get result 
proposition 
integers non empty regular language size sucient draw kl ln examples get elements log size con dence greater proof 
number programs size number elements log size size applying previous results easy show exists constant log size log cl probability element drawn independent draws cl regfinkl tex learning regular languages simple positive examples probability exists element drawn independent draws cl nx verify ln cl 
learning regular languages positive teaching sets de ne notion positive teaching set language sets designed satisfy essential property non empty regular language polynomially identi able positive teaching set de nition 
non empty regular language trimmed minimal dfa recognizes nite set positive teaching set 
lg 

state exists 
pair distinct states exists 

state letter de ned exists ux note notion robust superset positive teaching set necessarily positive teaching set 
lemma 
superset positive teaching set satis es item positive teaching set regfinkl tex fran cois denis proof 
straightforward example 
trimmed minimal dfa recognizes see example 
set positive teaching set show build particular positive teaching set 
rst need lemma lemma 
non empty regular language trimmed minimal dfa recognizes non empty exists vr mapping vr card card pair distinct states exists vr 
vr proof 
prove lemma induction card 
result clear card 
suppose card 
rst string exist distinct states 
fq fq strictly included apply induction hypothesis 
corresponding sets mappings 
de ne vr fv card card card card 
verify distinct states exists vr 
rst state 
vr de ne vr vr vr vr vr clearly vr de nition 
non empty regular language trimmed minimal dfa recognizes card 
state write rst string regfinkl tex learning regular languages simple positive examples ordering ua fu jq qg fu de 
vq de ned previous lemma 
rst string va fv jq qg sa ua va lg 
lemma 
ua elements length element ua 
va elements va length element va 
proof 

associate transition element ua corresponds transition card 
points straightforward 

clear card length string distinguishes states length element va 
prove va states terminal states vq states terminal rst element vq 
corollary get proposition 
non empty regular language trimmed minimal dfa recognizes sa positive teaching set designate canonical positive teaching set example 
trimmed minimal dfa recognizes 
ua vq va sa proposition 
exists polynomial algorithm non empty regular language positive teaching set takes input outputs trimmed minimal dfa proof 
non empty regular language minimal trimmed automaton recognizes positive teaching set relation de ned regfinkl tex fran cois denis 
relation equivalence relation 
write class string quotient set modulo 

de ned previous item ensures de nition correct 
verify de ned exists ux ux 
easy check algorithm de ned runs polynomial time output automaton dfa isomorphic algorithm input positive teaching set regular language de ning set states exist fug de ning initial state exists unique element de ning set nal states fq sg de ning transition function exist ux output regfinkl tex learning regular languages simple positive examples surprising rebuild regular language positive teaching set notion designed purpose 
show section natural ways nd sets 

simple positive teaching sets dicult build positive teaching set elements simple components 
interesting set form lg positive teaching set soon elements suciently simple components 
lemma 
exists constant non empty regular language states pair sa sa canonical positive teaching set log log log log log log constant 
proof 
exists program builds corresponding trimmed minimal dfa recognizes exists program computes ua see de nition 
element ua identi ed index ua ua elements element identi ed program length log log log see section 
second inequality proved similar way 
lemma 
exists constant non empty regular language string log log log log log constant 
regfinkl tex fran cois denis proof 
suppose 
exists program inputs nds rst string uw exists constant uw log similar way prove exists constant log min get result 
de nition 
non empty regular language states 

fu ag fv ag lg lemma 
card card card proof 
write fr set strings pre string fr fu fr pre set 
fr 
fu ju fr ju fr card fr regfinkl tex learning regular languages simple positive examples card fr hand string length pre xes 
card prove similar way card lastly card card card proposition 
non empty regular language states 
log de ned lemma 
positive teaching set size polynomial proof 
applying lemmas see superset sa lemma positive teaching set 
lemma cardinal polynomial corollary 
non empty regular language states log compute minimal dfa recognizes time polynomial proof 
apply propositions 
proved regular language simple positive teaching sets 
remains show possible nd teaching set simple positive examples 

learning regular languages simple positive examples lemma shows word uv simple components events small weight positive admissible distribution 
show kind converse frequent pre frequent sux uv uv frequent 
lemma 
exists constant non negative integer strings log log log log log log log log regfinkl tex fran cois denis proof 
de ned lemma 
exists constant strings hu log log log juj need know length compute pair hu vi string uv need program length log log log additive constant compute juj 
fundamental theorem kolmogorov complexity theory see symmetry algorithmic information li vit anyi says exists constant strings hu log log log log log log log log log log log get result 
second inequality showed similar way 
corollary 
exists constant non negative integer non empty regular language states pair uv log regfinkl tex learning regular languages simple positive examples proof 
exists constant uv uv previous lemma lemma log log log log similar way log uv log get result 
going show draw suciently large sample positive admissible distribution possible compute exactly positive teaching set target 
recall classical results hoe ding bounds lemma 
xn sequence independent bernoulli trials probability success xn random variable estimating parameter 
inequality holds js pj want estimate weight events am probability distribution accuracy con dence sucient draw elements satis es verify ln ln suitable 
consider algorithm algorithm input regfinkl tex fran cois denis log de ned lemma ln ln suppose target language states underlying distribution positive admissible distribution draw examples oracle ex discard examples length greater build remaining examples nw positive integer nw jwj drawn exactly nw times uv suciently large sample estimate weights accuracy con dence compute nw compute nw vg fu fv log ln draw examples ex discard examples length greater build sample remaining examples prove positive teaching set high con dence output proposition 
non empty regular language states representation positive admissible distribution running time algorithm polynomial 
probability greater outputs positive teaching set proof 
sets form lemma con dence greater regfinkl tex learning regular languages simple positive examples probability greater lg suppose inequalities satis ed 
prove probability greater 
corollary uv log lemma card number chosen way log log probability greater strings sg drawn algorithm output lemma positive teaching set get result 
algorithm clearly polynomial 
precisely verify number examples drawn ln running time ln 
theorem 
class regular languages probably exactly learnable simple positive examples 
proof 
consider algorithm learning algorithm input take upper bound number states target run algorithm inputs output run algorithm input output output regfinkl tex fran cois denis propositions show regular language size representation previous algorithm outputs representation probability greater oracle ex 
algorithm runs time ln 
lemma card card 
length longest element algorithm implemented time card card 
consequently total running time learning algorithm ln 

miscellaneous remarks important note result independent turing machine chosen de ne kolmogorov complexity 
choice particular turing machine mentioned 
don rigorous de nition collusion prove collusion phenomenon occur learning regular languages simple positive examples 
precise de nition target language encoded positive examples learner information class regular language learnable model goldman mathias 
fact reg gm learnable positive examples sucient reason think danger collusion avoided 
lastly note algorithm uses general heuristic principle stated section pair constitutes micro current hypothesis predicts string uv simple positive string 
uv appear reasonably large new sample learning algorithm discards hypothesis 
nice get rid possible classical pac framework haussler 
unfortunately impossible 
suppose example want di greater available running time allowed learn ecient strategy available 
exist long strings pretty small complexity turning regfinkl tex learning regular languages simple positive examples exact learning requirement approximative help 
fairer say integer class reg probably exactly learnable 
conclude study previous result adapted simple pac model li vit anyi li vit anyi 
li vit anyi reversible languages de ne notion simple regular language 
de nition 
non empty regular language trimmed minimal automaton recognizes integer card 
say simple state jr log jr log proposition 
class simple regular languages learnable positive simple examples provided examples drawn positive restriction solomono levin distribution proof 
place fact examples drawn representation target language lemma 
target simple get similar non conditional complexity 

jr 
lemmas adapted case straightforward way 
regular language reversible mirror automaton minimal trimmed dfa recognizes deterministic 
reversible language simple state string string simple 
li vitanyi proved li vit anyi simple reversible languages pac learnable reversible state string see notion simple regular language generalizes notion simple reversible language 
similar reversible languages 
proposition generalizes results li vit anyi mentioned 
regfinkl tex fran cois denis 
learning positive data important topic computational learning theory specially domain grammatical inference believed possible learn syntax natural language solely positive instances 
classical models provide tools overcome main diculty kind learning avoid overgeneralization 
specially true want learning ecient polynomial size target representation 
eld learning dfas positive results rely extra hypothesis concerning distribution examples learner contain teaching set class reversible languages angluin structured sakakibara 
generalization learning model li vit anyi li vit anyi denis hypothesis simple examples frequent complex ones notion kolmogorov complexity de ne simple example 
proved class regular languages probably exactly learnable model 
technical aspects result emphasize fact hypothesis model heuristic learning algorithm relevance cognitive point view 
simplicity example fact characteristic concept de ned 
kolmogorov complexity allows give rigorous de nition intuitive notion supposing simple examples frequent plausible hypothesis numerous natural learning contexts supposing current hypothesis may ruled simple expected events occur plausible heuristic lastly sole property model show learnability class regular languages exists subset language composed frequent words containing suciently rich information allow reconstruction language correct word components appearing 
think hypothesis plausible linguistic point view 
regfinkl tex learning regular languages simple positive examples develop result theoretical experimental directions 
class regular languages poor describe signi cant fragments natural language context free languages needed 
complexity levels reachable model techniques developed solomono levin distribution computable interesting isolate properties needed order keep result 
allow design practicable families admissible distributions 
collect real data natural language corpuses study extent possible suppose generated admissible distributions 
angluin 

inductive inference formal languages positive data 
inform 
control 
angluin 

inference reversible languages 
acm 
angluin 

learning regular sets queries counterexamples 
information computation 
carrasco oncina 

learning stochastic regular grammars means state merging method 
international conference grammatical inference pages heidelberg 
springer verlag 
castro 

query pacs simple pac learning 
technical report dept inform 
de kanazawa 

angluin theorem indexed families sets applications 
proc 
th annu 
conf 
comput 
learning theory pages 
acm press new york ny 
denis 

pac learning positive statistical queries 
richter smith editors proceedings th international conference algorithmic learning theory alt volume lnai pages berlin 
springer 
denis gilleron 

pac learning simple examples 
th annual symposium theoretical aspects computer science volume lncs pages grenoble france 
springer 
denis gilleron 

pac learning helpful distributions 
li editors proceedings th international workshop algorithmic learning theory alt volume lnai pages berlin 
springer 
denis gilleron 

pac learning helpful distributions 
submitted 
long version available ftp www grappa 
fr pub reports helpful ps 


apprentissage par plate forme apprentissage de langages 
phd thesis universit lille 
gold 

language identi cation limit 
inform 
control 
gold 

complexity automaton identi cation data 
inform 
control 
goldman mathias 

teaching smarter learner 
journal computer system sciences 
regfinkl tex fran cois denis haussler kearns littlestone warmuth 

equivalence models polynomial learnability 
inform 
comput 
head kobayashi yokomori 

locality reversibility learning languages positive data 
alt th international conference algorithmic learning theory volume lecture notes arti cial intelligence pages 
springer verlag 


characteristic sets polynomial grammatical inference 
machine learning 
kanazawa 

identi cation limit categorial grammars 
journal logic language information 
kearns valiant 

cryptographic limitations learning boolean formulae nite automata 
journal acm 
kearns vazirani 

computational learning theory 
mit press 
li vit anyi 

learning simple concepts simple distributions 
siam comput 
li vit anyi 

kolmogorov complexity applications 
text monographs computer science 
springer verlag 
natarajan 

machine learning theoretical approach 
morgan kaufmann san mateo ca 
natarajan 

probably approximate learning sets functions 
siam comput 
oncina garcia 

inferring regular languages polynomial update time 
pattern recognition image analysis pages 
parekh honavar 

learning dfa simple examples 
li editors proceedings th international workshop algorithmic learning theory alt volume lnai pages berlin 
springer 
pitt 

inductive inference dfas computational complexity 
proceedings aii workshop analogical inference lecture notes arti cial intelligence pages heidelberg 
springer verlag 
rabiner juang 

hidden markov models 
ieee assp magazine 
sakakibara 

ecient learning context free grammars positive structural examples 
information computation 
sakakibara 

advances grammatical inference 
theoretical computer science 


necessary condition learning positive examples 
machine learning 
stolcke omohundro 

inducing probabilistic grammars bayesian model merging 
lecture notes computer science 


learning deterministic linear languages positive examples 
theoretical computer science 


meaning helps learning syntax 
proceedings workshop grammatical inference volume lecture notes arti cial intelligence pages 
valiant 

theory learnable 
commun 
acm 
yokomori 
polynomial time learnability limit strictly deterministic automata 
machine learning 
regfinkl tex 
