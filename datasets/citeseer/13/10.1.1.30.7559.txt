trec amit singhal john choi donald hindle david lewis fernando pereira labs research choi hindle lewis research att com year participated ad hoc task filtering sdr vlc tracks 
effort trec concentrated sdr vlc tracks 
filtering track tested preliminary version text classification toolkit developing year 
ad hoc task introduce new tf factor term weighting scheme simplified retrieval algorithm 
weighting scheme algorithm sdr vlc tracks 
results sdr track show retrieval automatic transcriptions speech quite competitive doing retrieval human transcriptions 
experiments indicate document expansion improve retrieval automatic transcripts 
results filtering track line expectations early developmental stage classification software 
results vlc track support hypothesis retrieval lists distributed search effectively merged initial part documents 
spoken document retrieval sdr retrieval large collections vlc main areas interest trec 
internally modified version smart retrieval system developed cornell university 
process developing text classification toolkit called 
filtering track gave opportunity stress test early version toolkit large task 
speech retrieval believe parallel text corpora example printed news time period successfully exploited improve retrieval effectiveness system 
especially true news material currently sdr track 
ideas sdr track participation 
initial results parallel corpus quite encouraging 
amount data available electronically example web grows exponentially increasingly hard maintain single centralized index data 
distributed retrieval solution distributed retrieval algorithms expect cooperation individual servers hard impossible get 
vlc track simulate totally independent distributed collections new result merging algorithm leverages summary text retrieved documents usually provided search engines merge results various servers 
ad hoc runs year modified smart retrieval system minor changes shorter list stopwords standard smart list stopwords new tokenizer handles hyphens better manner phrase formation governed new set rules generated new set statistical phrases phrases news corpora included disks ap wsj ft fbis 
phrases ad hoc sdr smart run filtering track 
phrases vlc track 
tf factor ln ln tf tf idf factor log df pivoted byte length normalization factor theta length document bytes average document length bytes tf term frequency text query document total number documents training collection df number documents contain term average document length depends collection 
weighting factor theta factor dtb weighting factor theta factor theta factor dtn weighting factor theta factor table term weighting schemes poor performance logarithmic tf factor ln tf trec ad hoc task forced revisit term weighting methodology 
main reasoning logarithmic tf factor say raw tf terms ensure high tf query term document place document ahead documents multiple query terms low tf values 
logarithmic tf factor effect tf increasing tf values single match usually doesn outweigh multiple matches 
short queries main interest ad hoc task logarithmic tf factor adequately reduce effect large tf values 
need tf function reduces tf contribution logarithmic tf factor tf increases 
double logarithm ln ln tf obvious choice 
double logarithm doesn introduce new parameters weighting scheme 
revisited pivoted unique document length normalization function 
words phrases terms document vector definition number unique terms document elegant especially phrases formed words counted independent unique terms :10.1.1.50.9950
earlier shown byte length document successfully pivoted formula document length normalization 
switch pivoted byte size normalization weighting scheme :10.1.1.50.9950
side benefit weighting code inside smart simplified pivoted byte size normalization 
changes term weighting schemes shown table 
approach year simple pass pseudo feedback approach ad hoc task 
groups approach trecs 
steps process ffl pass dtn queries documents pass retrieval done 
ffl expansion top documents retrieved pass assumed relevant query documents ranked assumed non relevant 
rocchio method parameters ff fi fl expand query adding new words new phrases highest rocchio weights 
include idf factor expansion process documents dtb weighted 
ffl pass expanded query documents generate final ranking documents 
task baseline expansion conservative title desc dtn target collection trec collection enrichment trec avgp better worse trec att better worse table effect conservative collection enrichment conservative collection enrichment trec groups city university university massachusetts technique kwok calls collection enrichment 
main idea run pass larger collection target collection 
hope larger text collection relevant documents query methods pull relevant documents top documents strengthening assumption relevance employed query expansion stage 
employ technique ad hoc runs trec disks large collection 
obvious problem approach possible domain mismatch 
top documents retrieved large collection completely different domain top presumably query related documents target database collection enrichment cause query drift away target relevance 
test collection enrichment problem 
devised conservative collection enrichment technique forces expanded query remain target domain allowing expansion terms proposed expansion large collection 
example query journalist risks pass large corpus trec disks retrieves stories talk list missing workers world killed including journalist 
documents reasonably relevant topic focus documents different topical documents target database 
documents add terms related missing employees query drift query away relevance target database reports missing journalists 
fix problem allow new terms added query proposed top documents retrieved target database 
capture effect collection enrichment allow large collection impact term selection final weights terms 
steps involved conservative collection enrichment 
query retrieve top document target collection build list potential expansion terms proposed rocchio weights 
terms appear documents positive rocchio weight considered 

query retrieve document large collection compute rocchio weights expansion terms proposed step 
add term weights proposed steps add top weighted words phrases original query 
allows terms weakly proposed low weight target collection strongly proposed larger collection enter query vice versa 
results submitted fully automatic runs described algorithms 
run att atc title queries run att title description queries 
narrative portion trec topics runs don believe real users provide long queries 
highlight benefits conservative collection enrichment results running algorithm year trec adhoc task title description year task run att table 
second column table shows baseline average run average precision best median median att atc title att title desc att title desc table results adhoc runs precision straight retrieval documents weighted queries dtn weighted 
third column shows results target database query expansion process 
trec task get improvement average precision 
improvement year task 
large collection query expansion column shows performance improves 
column shows conservative collection enrichment improves performance 
terms average precision conservative method better expanding purely large collection rows labeled better worse show stable respect number queries improve deteriorate comparison expansion target collection sensible baseline comparison compare unexpanded queries baseline average precision rows expansion strategies show large gains relative performance different expansions hard judge 
trec task expansion done queries improve queries deteriorate column comparison base expansion 
conservative collection enrichment cut losses queries column gain average precision 
numbers striking year task 
expansion large collection worse expansion target collection half queries better half 
conservative expansion reduces losses queries queries losses general smaller 
results show conservative collection enrichment stable pure enrichment gains term average precision 
official results ad hoc runs shown table 
runs att atc att especially medians drawn pool includes runs full topic text rich content words narrative portion topics construct query 
runs just short queries title short queries title description 
submitted experimental run att enriched term set word cooccurrence pairs past routing task 
hoping pairs useful ad hoc setting word pairs didn improve retrieval effectiveness :10.1.1.48.7368
sdr runs speech recognizer process sdr track data 
submitted runs att uses best recognizer transcript retrieval algorithm quite similar algorithm ad hoc task 
run att uses word lattices generated recognizer parallel text corpora document expansion 
expanded documents retrieval best recognizer transcript 
speech recognizer speech recognition process involves steps 
prior recognition speech story segmented approximately minute long formed segments cart classifier 
resulting segments submitted wideband narrowband classifier selection acoustic model recognition segment 
recognizer standard time synchronous beam search algorithm 
probabilities defining transduction text dependent phone sequences word sequences estimated word level grapheme phone mappings implemented general framework weighted finite state transducers 
transducer composition generate word lattice output 
continuous density state left right context dependent hidden markov phone models 
models trained dimensional feature vectors consisting mel frequency cepstral coefficients second time derivatives 
training iterations included eigenvector rotations means clustering maximum likelihood normalization means variances viterbi alignment 
output probability distributions consist weighted mixture gaussians diagonal covariance mixture containing components 
training data divided wideband narrowband partitions resulting acoustic models 
language models pass recognition process 
pass built word lattices speech minimal trigram language model beam determined heuristically provide manageable word lattices 
word lattices removing trigram grammar weights retaining acoustic weights intersecting lattices gram language model 
best path extracted lattices 
pass trigram language model rescoring gram model standard katz backoff models word vocabulary 
choosing vocabulary words sdr training transcript 
base vocabulary supplemented words frequency greater appearing new york times la times segments ldc north american news corpus ldc catalog number ldc see www ldc upenn edu period june january 
vocabulary includes common acronyms training texts preprocessed include acronyms 
language model training transcription sources sdr training transcripts hub transcripts transcripts nbc nightly news print source ldc na news corpus newspaper text 
pass trigram model built constructing backoff language model words training text yielding grams grams 
model reduced size approach seymore rosenfeld grams grams 
composed lexicon smaller trigram model yielded manageable sized network 
second pass model grams grams grams 
model transcription sources sdr hub nbc effect interpolated text source na news give weight 
retrieval system sdr track na news corpus language model training described large collection conservative collection enrichment see section 
test data dated june january news dated may february month na news corpus 
algorithm algorithm run att baseline runs att att full sdr run att 
algorithm exactly algorithm ad hoc track parameters changed deal small size speech database 
ffl pass dtn queries documents pass retrieval done 
ffl expansion top documents retrieved pass assumed relevant query documents ranked assumed non relevant 
query expanded adding new words new phrases rocchio formulation parameters ff fi fl 
include idf factor expansion process documents dtb weighted 
ffl expansion step performed target collection large na news collection 
conservative collection enrichment done described section 
ffl pass expanded query documents generate final ranking documents 
main motivations algorithm keep ad hoc algorithm uniform tasks 
lattice document expansion best transcript recognizer misses content words adds spurious words spoken document 
misses reduce word recall proportion spoken words recognized spurious words reduce word precision proportion recognized words spoken 
believe information retrieval algorithms benefit higher word recall robust poor word precision 
approach enhance word recall add new words words probably spoken weren top choice speech recognizer automatic transcriptions spoken document 
techniques plausible bringing new words document 
obvious ir perspective document expansion similar documents find documents related document add new words related documents document hand 
speech recognition perspective obvious choice word lattices contain multiple recognition hypotheses utterance 
word lattice contains words acoustically similar recognized words said words recognized best transcription 
techniques controlled document expansion second full sdr run att 
experiments method adds spurious words document desirable 
controlled document expansion incorporated information sources helps reducing spurious words allowing words added document 
take best recognition story look similar stories print media na news 
done simply running best recognition story raw tf weighted query na news database 
idea important news reported print media leverage words enrich spoken documents 
enforce conditions returned stories na news day near date spoken document imagine possibly help 
speech stories reported print media marginally related stories retrieved response query speech story unrelated words brought story 
contain problem force expansion algorithm choose words word lattice generated recognizer speech story 
restriction guarantees words added document proposed speech recognizer albeit low confidence 
parameters document expansion chosen somewhat arbitrarily quick inspection expansion terms experience relevance feedback 
didn testbed tune parameters 
steps 
documents retrieved na news corpus speech document 
best transcription speech document weighted raw tf query 

unique words new words added speech document rocchio formula 
original best recognition unique counting repetitions words new words added new words added new words added 
details expansion process ffl rocchio parameters ff fi fl 
ffl words occurred documents retrieved step expansion terms 
ffl original speech document top documents step dtb weighted see table rocchio formula 
yields expanded document vectors idf weights 
transcription run wer term recall term precision att baseline att baseline att full sdr att expanded docs att table analysis recognition document expansion retrieval baseline expansion collection best condition dtn target collection na news enrichment median median att baseline att baseline att full sdr att full sdr att table results sdr track 
idf removed expanded document vectors dividing component words idf expanded document vectors weighted 
expanded documents best transcriptions retrieval algorithm run att run submitted second sdr track run att 
results analysis recognition word error rate average term recall proportion spoken words recognized average term precision proportion recognized words spoken various automatic transcriptions shown table 
compute word recall word precision take stories index terms non word stems indexed smart multiple occurrences stem counted term human transcription compute original index terms nonstop word stems repetitions counted recognized automatic transcription 
count number spurious terms recognized recognizer 
compute document term recall term precision average values documents get numbers reported table 
omit terms recall precision figures quite unstable 
main reason discounting multiple occurrence term tf factor weighting scheme similar effect 
recognizing word important correctly recognizing multiple occurrences word 
table shows word error rate recognizer slightly better medium error transcriptions provided nist 
reflected higher term recall precision recognizer 
document expansion doing job 
increase term recall average significantly reduces term precision 
discussed results deterioration term precision hurt retrieval effectiveness 
supports hypothesis term recall important retrieval systems 
results various runs shown table 
official numbers bold column various numbers 
baseline retrieval results documents dtn queries query expansion shown column 
average precision human transcription 
retrieval effectiveness falls retrieval done speech recognizer automatic transcription speech 
code provided wer human nist cambridge university dragon dragon systems att labs nist carnegie cmu shef sheffield university nist carnegie mellon cmu dera dera table different automatic transcriptions 
base effectiveness medium error baseline transcription loss 
expected average precision falls high error recognition 
retrieval done recognition marginally higher term recall precision retrieval effectiveness jumps gain running just retrieval human transcriptions 
document expansion removes difference retrieval expanded documents par retrieval human transcriptions 
quite encouraging especially expansion parameters chosen guidance 
shows term recall important term precision 
term precision expanded documents noticeably worse best recognition term recall marginally better retrieval effectiveness better despite poor term precision 
query expansion target collection done results improve noticeably column table 
retrieval transcriptions better retrieval medium error baseline transcription par retrieval human transcriptions 
retrieval effectiveness expanded documents gets average precision surpasses retrieval human transcriptions 
results encouraging 
conservative collection enrichment hurt environment official runs column table lower expanded just target collection 
official runs competitive full sdr runs att att median queries 
run expanded documents att yields best results quite substantial proportion 
results point possible advantages doing document expansion speech retrieval environments 
results tend confirm belief term recall plays important role retrieval effectiveness speech term precision 
afford lose term precision better term recall yield improved retrieval effectiveness speech 
larger query set results robust clear pattern table indicating document expansion consistently yields better results doing 
cross recognizer analysis official conference rigorous study document expansion 
discovered constraining document expansion allow terms word lattices generated recognizer held additional benefit doing 
document expansion na news results equally better 
allows test document expansion retrieval automatic transcriptions provided sdr track participants don 
secondly query expansion parameters sdr runs sub optimal 
standard set parameters ad hoc run yields consistently better results added advantage uniformity parameters 
test document expansion different automatic transcriptions provided nist various track participants 
table lists transcriptions word error rates 
cleaned timing mistakes transcripts correct wer scripts get wer reported table opposed wer reported table 
steps involved document expansion unexpanded documents expanded documents transcript baseline query expn 
coll 
baseline query expn 
coll 
dtn target na news enrich 
dtn target na news enrich 
ltt dragon att nist shef nist table cross recognizer analysis 

find documents related speech document 
running automatic transcription speech document query raw tf weighted na news corpus retrieving similar documents 
words nearest neighbors speech document process 
documents weighted raw tf query nearest neighbors raw tf weighted documents yield best expansion results 

speech transcriptions modified rocchio formula 
new old old initial document vector vector th related document new modified document vector 
documents weighted see table 
new words added document 
term selection rocchio weights new words multiplied idf terms selected idf stripped selected term final weight 
furthermore ensure document expansion process doesn change effective length document vectors change results due document length normalization effects force total weight terms new vector total weight terms initial document vector 
expand documents original length original document indexed terms add new terms document 
results unexpanded expanded documents listed table 
main highlights results ffl document expansion yields large improvements board ffl document expansion reduces performance gap retrieval perfect automatic transcriptions 
points highlighted 
left plot shows average precision axis wer axis 
number plotted unexpanded queries columns marked baseline table 
prevents effects query expansion affecting graphs allows study effects document expansion isolation 
horizontal lines human transcriptions lines different automatic transcriptions 
see left graph document expansion solid lines yields large improvements board task doing document expansion dashed lines 
right graph plots loss human transcriptions axis unexpanded expanded documents 
baseline expanded documents expanded human transcriptions solid horizontal line left graph 
observe poorest transcriptions document expansion yields improvement impressive reduces performance original documents expanded documents word error rate initial queries dragon nist original documents expanded documents word error rate initial queries att raw average precision loss human transcriptions initial user queries 
gap human transcription original despite high baseline 
results similar transcriptions 
results indicate document expansion useful tool retrieval speech corpus 
caution small test collection experimentation needed possibly larger test collection full effect document expansion analyzed details 
vlc runs come vlc track belief time collection sizes capability efficiently maintain single index collection 
see happening web 
published study reports single web search engine covers web 
collections various engines pooled coverage improves dramatically 
reason meta search systems systems search multiple search engines optionally merge results increasingly available web 
vlc track participation modeled meta search system 
divide collection independent collections 
query submitted parallel collections retrieval results processed various possible ways obtain single final ranking collection 
assume small collection available server user submits queries client passes servers gathers results merges single ranked list presentation 
assume client access text collection computation idf values needed merging process described 
things closer reality force client entirely different collection trec disks idf collection clients web collection target collection task gather idf runs submitted different set assumptions study different effects 
brief description runs 
server returns top documents client client generates single ranked list documents servers 
ffl att vi run assumes 
server running straight vector match documents dtn queries see table 
pseudo feedback query expansion done servers 

server returns bytes mark removed top documents client 
simulates web search environment commonplace engines return initial portion documents summary results page 

client indexes summaries fly creates documents 
client indexes query dtn weighting idf picked trec collection 

summaries ranked client straight vector match rank summary defines rank final document 
pseudo feedback query expansion done client 
result average ffl att vf run att vi servers return full document text initial bytes full document text client produce final ranking 
result average ffl att vie run assumptions 
server expands query pseudo feedback 

client expands query parallel pseudo feedback local collection trec 

server returns bytes summary documents retrieved expanded query step 
client indexed summaries fly 

summaries ranked client expanded query step 
result average ffl att run att vie servers return full document text initial bytes client produce final ranking 
result average wanted show merging initial bytes worse merging full text documents 
result internal studies split trec database servers evaluated merging methods trec queries 
disappointed see run att vi noticeably worse corresponding full text run att vf 
similarly att vie noticeably worse att 
investigate discrepancy behavior trec documents web documents 
thought inclined believe web documents just different traditional trec documents initial part web document representative entire document trec documents study effect 
filtering runs trec filtering track test alpha version toolkit machine learning classifiers mixed textual non textual information 
differs text retrieval software support numeric formatted data emphasis classification streams data retrieval static slowly changing collection 
differs machine learning software efficient flexible support textual data particularly mapping structured documents attribute vectors 
stand system library embedded applications 
extensive api careful class system enable new preprocessors data transformations classifier types training methods output formats easily added system 
stand mode trec filtering task 
support incremental training classifiers complete batch filtering routing tasks attempted 
meant batch filtering task take advantage training retrieved test documents 
uses xml internally document mark 
sgml mark trec data obeys xml conventions processing trec data trivial 
quick experiment reported mapped head text fields lower cased ap documents single vector raw tf counts 
stemming wording implemented 
early runs trec large data sets showed preprocessing unacceptably slow 
problem traced extensive streams communication preprocessor modules holdover prototype unix pipeline style 
reimplementation achieved rate mb hr creation disk vectors disk text processor sgi challenge xl gb ram 
comparable rate gb hr latest modification smart process richer set data types version fully optimized 
development date focused exclusively basic systems issues data modeling api design little time left implementing particular learning algorithms 
meet trec deadline quick implementation original rocchio algorithm 
trained linear models trec filtering topics judged ap documents rocchio parameters ff topic descriptions fi fl 
negative rocchio weights zeroed usual 
document weights training test data computed smart lnu style normalization slope parameter 
set linear models retrieve top scoring ap documents :10.1.1.50.9950
second set linear models trained union judged ap documents top ap documents documents top treated non relevant query zoning approach 
second set linear models run back training documents score threshold model chosen optimized desired effectiveness measure filtering measure 
models thresholds applied test ap documents documents exceeding threshold constituting submitted set batch filtering 
batch filtering submissions att fb measure att fb measure mediocre median utility tied best att fb median utility tied best att fb 
expected crude method implemented 
particular omission feature selection lists idf weighting dynamic feedback optimization led large models poorly calibrated weights 
routing run att fr scores output rocchio models equally poor 
average precision topic average precision median topics 
comparison submitted routing run att fr modern augmented rocchio approach implemented smart 
algorithm scaled version trec run att rc word cooccurrence pairs features 
average precision run topic average precision median topics best :10.1.1.48.7368
incorporating modern training methods obviously priority 
encouraged sdr performance especially possible advantages document expansion environment 
quite satisfied filtering performance initial developmental stage software 
study meta searching model searching large collections 
simplified adhoc algorithm complex algorithm year results 
acknowledgments thankful anna mandar mitra marcin kaszkiel yoram singer dan stern help various aspects 
grateful andrej mehryar mohri michael riley help building recognizer sdr track data 
chris buckley 
implementation smart information retrieval system 
technical report tr department computer science cornell university ithaca ny may 
julia hirschberg christine nakatani 
machine learning identify intonational segments 
proceedings aaai spring symposium applying machine learning discourse processing palo alto ca march 
katz 
estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech signal processing pages 
kwok 
improving stage ad hoc retrieval short queries 
proceedings annual international acm sigir conference research development information retrieval pages 
association computing machinery new york august 
steve lawrence lee giles 
searching world wide web 
science 
fernando pereira michael riley 
speech recognition composition weighted finite automata 
emmanuel roche yves schabes editors finite state language processing pages 
mit press cambridge massachusetts 
rocchio 
relevance feedback information retrieval 
smart retrieval system experiments automatic document processing pages englewood cliffs nj 
prentice hall gerard salton editor 
smart retrieval system experiments automatic document retrieval 
prentice hall englewood cliffs nj 
seymore ronald rosenfeld 
scalable backoff language models 
icslp volume 
amit singhal :10.1.1.48.7368
trec 
voorhees harman editors proceedings sixth text retrieval conference trec pages 
amit singhal chris buckley mandar mitra :10.1.1.50.9950
pivoted document length normalization 
proceedings nineteenth annual international acm sigir conference research development information retrieval pages 
association computing machinery new york august 
amit singhal mandar mitra chris buckley 
learning routing queries query zone 
proceedings twentieth annual international acm sigir conference research development information retrieval pages 
association computing machinery new york july 
