efficient mining association rules distributed databases david cheung vincent ng ada fu yy fu zz department computer science university hong kong hong kong 
department computing hong kong polytechnic university hong kong 
yy department computer science engineering chinese university hong kong hong kong 
zz school computing science simon fraser university burnaby canada 
sequential algorithms proposed mining association rules 
little done mining association rules distributed databases 
direct application sequential algorithms distributed databases effective requires large amount communication overhead 
study efficient algorithm dma proposed 
generates small number candidate sets requires messages support count exchange candidate set number sites distributed database 
algorithm implemented experimental test bed performance studied 
results show dma superior performance comparing direct application popular sequential algorithm distributed databases 
index terms data mining knowledge discovery distributed data mining association rule distributed database distributed algorithm partitioned database 
database mining attracted tremendous amount attention database research applicability areas including decision support marketing strategy financial forecast 
research community observed data mining data warehousing data repositories new uses database technology considered important areas database research 
interesting efficient data mining algorithms proposed see :10.1.1.103.5437:10.1.1.40.6984:10.1.1.50.1686:10.1.1.144.4956:10.1.1.40.6757
database oriented mining algorithms classified research authors supported part hong kong research council 
categories concept generalization discovery discovery primitive concept levels 
relies generalization concepts attribute values stored databases 
example dbminer system 
discovers strong regularities rules database concept generalization 
association rule important type rules approach :10.1.1.40.6984:10.1.1.50.1686:10.1.1.40.6757
algorithms mining association rules proposed far sequential algorithms 
algorithm pdm proposed parallel mining association rules 
adaptation dhp algorithm parallel environment 
algorithm count distribution cd adaptation apriori algorithm proposed parallel mining environment implementation ibm sp 
best knowledge little done mining association rules distributed database environment 
developed distributed algorithm dma distributed mining association rules solve problem 
distributed database model horizontally partitioned database 
database schema partitions records transactions set items 
dma modified case schema different sites completely identical 
distributed databases horizontally partitioned 
example retail chain may regional data centers manages transaction records region 
important mine association rules data centers 
distributed mining applied applications data sources located different places 
sequential environment algorithms proposed mining association rules 
popular apriori dhp partition algorithms :10.1.1.103.5437:10.1.1.50.1686:10.1.1.40.6757
candidate set generation function apriori gen adopted apriori algorithm supports efficient method candidate set generation 
dhp applies hashing technique prune away size candidate sets improve efficiency 
partition divides database small partitions processed efficiently memory independently find large itemsets 
large itemsets partitions combined form set candidate sets 
scan database required find large itemsets candidates 
parallel environment pdm algorithm proposed tries parallelize dhp algorithm 
node computes globally large itemsets exchanging support counts counts referred literatures candidate sets 
order apply hashing technique nodes broadcast hashing result causes huge amount communication 
technique proposed decrease number messages 
amount hash buckets total count larger threshold selected bucket count exchange buckets broadcasted 
node receives partial count selected buckets polls sites get total counts 
unfavourable features proposal 
firstly reduction candidate sets done second iteration 
number candidate sets iterations quite large 
secondly find large candidate sets messages required support count exchange candidate set number nodes 
algorithm proposed parallel mining association rules cd algorithm 
adaptation apriori algorithm parallel case 
iteration generates candidate sets site applying apriori gen function set large itemsets previous iteration 
site computes local support counts candidate sets broadcasts sites 
subsequently sites find globally large itemsets iteration proceed iteration 
algorithm simple communication scheme count exchange 
similar problems higher number candidate sets larger amount communication overhead 
efficiency algorithm dma developed attributed mainly features 

apriori dhp generate candidate sets applying apriori gen function large itemsets previous iteration 
cd pdm technique parallel environment 
dma uses new technique generate smaller set candidate sets apriori dhp 
explained section 

dma determine candidate set large messages needed support count exchange 
straight adaptation apriori requires messages support count exchange 
distributed database intrinsic data skewness property 
distribution itemsets different partitions identical items occur frequently partitions 
example distributed database national supermarket chain expected consumers purchasing patterns new york city quite different los angles 
result itemsets may large locally sites necessarily sites 
skewness property poses new requirement design mining algorithm 
furthermore dma applied mining association rules large centralized database partitioning database nodes distributed system 
particularly useful data set large sequential mining 
extensive experiments conducted study performance dma compare algorithm count distribution cd direct application apriori algorithm distributed databases 
remaining organized follows 
brief summary mining association rules sequential environment discussed section 
section problem mining association rules distributed database defined important results discussed 
algorithm dma section 
performance study discussed section 
discussion sections 
sequential mining association rules association rules fi mg set items 
db database transactions transaction set items itemset transaction contains association rule implication form 
association rule holds db confidence transactions db contain contain association rule support db transactions db contain minimum confidence threshold minconf minimum support threshold minsup problem mining association rules find association rules confidence support larger respective thresholds 
call association rule strong rule distinguish weak ones meet thresholds 
itemset support defined similarly percentage transactions db contains sup denote support count number transactions db containing minimum support threshold minsup itemset large support minsup 
presentation purpose call itemset size itemset 
shown problem mining association rules reduced subproblems 

find large itemsets pre determined minimum support 

generate association rules large itemsets 
crucial factor affects performance mining association rules find efficient method resolve problem 
apriori algorithm apriori algorithm popular algorithm mining association rules centralized database 
main idea apriori outlined 

large itemsets computed iterations 
iteration database scanned large itemsets size computed 
large itemsets computed ascending order sizes 

iteration size large itemsets computed scanning database 
subsequently th iteration set candidate sets created applying candidate set generating function apriori gen gamma gamma set large gamma itemsets iteration gamma 
apriori gen generates itemset gamma itemset subset gamma support counts candidate itemsets computed scanning database size large itemsets extracted candidates 
interesting extensions apriori algorithm dhp partition algorithms 
iteration computing support counts size itemsets dhp stores support counts size candidate itemsets hash table 
upper bounds support counts size candidates deduced hash table prune away size candidates second iteration 
result hashing pruning cost computing support counts size candidate sets reduced substantially dhp 
partition algorithm divides database partitions processed efficiently memory find itemsets large 
set consists itemsets candidate set finding large itemsets database 
advantage partition algorithm scan database required candidate sets partitions 
mining association rules distributed databases problem description db partitioned database located sites database partitions sites fdb db db 
adopt convention attaching superscript notation denote corresponding distributed notation site size db partitions db respectively 
itemset sup sup respective support counts db db call sup global support count sup local support count site minimum support globally large sup theta correspondingly locally large site sup theta denote globally large itemsets db denote globally large itemsets problem mining association rules distributed database db reduced finding globally large itemsets 
generate smaller set candidate sets discuss generate small set candidate sets interesting useful observations 
candidate sets generated applying apriori gen function needed search large itemsets 
fact natural effective method site generate set candidate sets typically smaller set candidate sets 
site needs find large itemsets candidate sets 
technique achieved effective division mining task sites database 
lemmas theorem described illustrate observations 
lemma itemset locally large site subsets locally large site proof 
follows definition locally large 
similar result lemma centralized database appeared 
lemma itemset globally large exists site subsets locally large site proof 
sup theta sup theta globally large 
locally large site follows lemma subsets locally large site itemset locally large site globally large say heavy site hl denote set heavy itemsets site hl denote set heavy itemsets site dma heavy itemsets site play important role generation candidate sets 
lemma itemset globally large exists site heavy site proof 
globally large follows lemma locally large site 
heavy site lemma itemset heavy site subsets heavy site proof 
heavy site globally large subsets globally large 
locally large site follows lemma subsets locally large site subsets heavy site lemma interesting property shows heavy itemsets site monotonic subset relationship 
relationship exists large itemsets centralized case necessary condition large itemsets computed iteratively 
lemma globally large itemset exists site size gamma subsets heavy site proof 
follows lemmas 
lemma equivalent combination lemma lemma 
basis design effective method generate smaller set candidate sets distributed environment 
general straightforward adaptation apriori th iteration set candidate sets generated applying apriori gen function gamma denote set candidate sets ca stands size candidate sets apriori 
order words ca apriori gen gamma site ch set candidates sets generated applying apriori gen hl gamma ch apriori gen hl gamma ch stands candidate sets generated heavy itemsets 
ch generated hl gamma subset gamma lemma large itemset exists site size subsets heavy site ch site ch apriori gen hl gamma ch denote set ch theorem set large itemsets subset ch ch ch apriori gen hl gamma 
ch set candidate sets size large itemsets 
proof 
proof follows lemma discussion 
hl gamma theorem subset gamma number candidate sets ch general smaller ca dma result theorem generate set candidate sets ch site iteration 
seen set candidate sets typically smaller direct application apriori gen example illustrate reduction candidate sets theorem 
example assuming sites database db partitions db db db iteration suppose set large itemsets fa gg locally large site locally large site locally large site hl fa cg hl fb dg hl fe gg 
follows theorem set size candidate sets site equal ch ch apriori gen hl fab bc acg 
similarly ch cd bdg ch fef fg egg 
set candidate sets large itemsets ch ch ch ch candidates 
apriori gen applied set candidate sets ca apriori gen candidates 
shows technique theorem effective reducing candidate sets 
local pruning candidate sets previous subsection shown set ch typically smaller set candidate sets ca find globally large itemsets subsequent generation ch support count exchange done 
observed candidate sets ch pruned away local information count exchange starts 
lemma globally large itemset exist site ch heavy site consequence locally large site site prune away candidates ch locally large words compute large itemsets site dma restrict search domain sets ch locally large site convenience ll denote candidate sets ch locally large site follows discussion iteration loop counter dma computes heavy itemsets site procedure 

candidate sets generation generate candidate sets ch apriori gen hl gamma heavy itemsets site gamma iteration 
doing site responsible generating set candidate sets computing set large itemsets 

local partition scanning ch scan partition db compute local support count sup 
local pruning ch locally large site pruned away remaining candidate sets stored ll 
pruning removes candidate set site candidate set site 

support count exchange broadcast candidate sets ll sites collect support counts compute global support counts find heavy itemsets site 
site received request support counts need scan partition compute support counts 
counts computed advance step 
detail discussion section 

broadcast mining result broadcast heavy itemsets sites 
extend example example illustrate execution procedure 
clarity purpose list notations far discussion table 
number transactions database db support threshold minsup set globally large itemsets ca set candidate sets generated sup global support count itemset number transactions partition db hl set heavy itemsets site ch set candidate sets generated hl gamma ll set locally large itemsets ch sup local support count itemset site table notation table 
example example assume database transactions partitions transactions 
assume support threshold 
illustrated example second iteration candidate sets generated site ch fab bc acg site ch bd cdg site ch fef fgg 
order compute large itemsets dma computes local support counts site 
result recorded table 
rows local support counts candidate sets corresponding sites 
example candidate sets site listed column local support counts listed second column 
table seen ac sup theta ac locally large 
candidate set ac pruned away site hand ab bc ch sup ch sup ch sup ab bc ef bc cd fg ac bd table locally large itemsets 
local support counts survive local pruning 
ll fab bcg 
similarly bd pruned away site ll cdg 
remaining candidate set site ef ll 
local pruning number size candidate sets reduced half original size 
local pruning completed site broadcasts messages containing remaining candidate sets sites collect support counts 
result count support exchange recorded table 
locally large request broadcast sup sup sup sup candidate sets sites ab bc cd ef table globally large itemsets 
request support count ab broadcast site counts sent back recorded site second row table 
rows record similar count exchange activities sites 
iteration site finds bc heavy bc sup theta ab sup theta 
heavy itemset site hl 
similarly hl cdg hl 
broadcast heavy itemsets sites return large itemsets cd efg 
terms message communication example candidate sets locally large site 
broadcast receive needed 
candidate set bc messages broadcast efficient single broadcast case 
section optimization technique eliminate duplication discussed 
message optimization finding large itemsets straight adaptation sequential apriori algorithm number candidate sets generated larger number messages count exchange candidate set large 
due broadcast candidate set sites 
requires messages total candidate set number partitions 
dma candidate set locally large site needs messages collect support counts general candidate sets locally large sites 
data skewness property percentage locally large candidate sets different sites small 
cases dma requires messages candidate set 
ensure dma requires messages candidate set cases optimization technique introduced 
achieve single broadcast dma uses simple assignment functions hash function determine polling site candidate set 
candidate set polling site responsible broadcasting polling request collecting support counts determine large 
polling site candidate set number messages required count exchange 
th iteration local pruning phase completed site dma uses procedure polling 

candidates sent polling sites acts home site candidate sets polling site finds candidate sets ll polling site stores ll candidates divided groups polling sites local support counts candidate sets stored corresponding set ll sends ll corresponding polling site 
polling site send polling requests acts polling site receives ll sent sites candidate set received finds list originating sites sent broadcasts polling requests sites list collect support counts 

remote site reply polling requests acts remote site reply polling requests sent polling request ll polling site sends local support counts candidates ll back 
need scan partition find local support counts 
local pruning 
please see section details 

polling site compute heavy itemsets acts polling site compute heavy itemsets receives support counts sites computes global support counts candidates ll finds heavy itemsets eventually broadcasts heavy itemsets global support counts sites 
example example assuming assigned polling site ab bc assigned polling site cd assigned polling site ef assignment site responsible polling ab bc 
simple case ab sends polling requests collect support counts 
bc locally large pair hbc bc sup hbc sent receives message sends polling request remaining site support count bc sup received finds bc sup 
bc heavy itemset polling site dma eliminated double polling messages bc 
algorithm distributed mining association rules section dma algorithm dma detail discussion 
description algorithm discuss technique computing local support counts candidate itemsets different sites performing single scan partition 
optimizing partition scanning count exchanges site dma find sets support counts order local pruning count exchange 
set local support counts candidate sets generated site 
candidate sets sets ch described theorem 
hash tree store support counts candidate sets 
scan partition db needed compute counts store hash tree 
hand order answer polling requests sites second set support counts candidate sets generated sites needed 
counts computed requests received second scan partition unavoidable 
order avoid doing scans dma required find sets support counts scan partition store counts hash tree 
possible heavy sets candidate set generation available sites iteration 
theorem site set candidate sets generated th iteration ch apriori gen hl gamma 
hand generated site ch apriori gen hl gamma 
hl gamma hl gamma available compute candidate sets put hash tree scan local support counts starts 
words site needs scan partition find local support counts itemsets ch apriori gen hl gamma 
technique sets support counts required local pruning count exchange single scan partition 
number scans dma minimized comparable sequential case 
site set candidate sets ch need send itemset names polling request positions ordered list itemsets ch required 
optimize message size needed count exchange 
dma algorithm section dma algorithm details 
algorithm dma distributed mining association rules algorithm input db database partition site size equal minimum support threshold submitted site output set large itemsets db returned site method iterates program fragment distributively site starting iteration loop counter algorithm terminates returned empty set candidate sets ch empty local pruning scan db compute array containing size itemsets db local support counts site ch ch apriori gen hl gamma generate size candidate sets scan db built hash tree contains candidate sets ch support counts site sup theta polling site add hx sup ll compute locally large candidates divide polling sites send candidates polling sites send ll site receive candidates polling site receive ll ll store lp update large sites lp record sites locally large send polling requests polling site collect support counts lp broadcast polling requests sites large sites receive sup sites large sites compute global support counts heavy itemsets lp sup sup sup theta insert filter heavy itemsets broadcast receive sites return performance study dma done depth performance study dma confirm analysis efficiency 
dma implemented share distributed system pvm parallel virtual machine 
mb lan connect rs workstations running aix system perform study 
database experiment composed synthetic data 
order study performance dma implemented algorithm cd test bed 
iteration cd generates candidate sets site applying function set large itemsets previous iteration 
site computes local support counts candidate sets broadcasts sites 
sites find globally large itemsets iteration 
performed experiments compare performance dma cd 
experiment test bed fixed number sites 
aim perform comparison respect different support thresholds database sizes 
second experiment threshold database size fixed performance algorithms compared respect different number sites 
result experiment described detail section second experiment section 
databases experiments synthetic data generated techniques introduced :10.1.1.50.1686
parameters similar 
table list parameters values synthetic databases 
readers familiar parameters refer :10.1.1.50.1686
notation tx iy dm denote database thousands performance comparison different thresholds database sizes experiment test bed consists sites 
purpose experiment compare performance dma cd respect different thresholds database parameter interpretation value number transactions database db mean size transactions mean size maximal potentially large itemsets number potentially large itemsets number items clustering size pool size correlation level multiplying factor table parameter table 
sizes 
site local disk partition loaded local disk experiments start 
partitions generated separately parameters values table 
order control skewness partitions control parameters introduced 
parameters primary range secondary range primary range interval items secondary range sub interval primary range 
items range possible pair primary secondary ranges :10.1.1.45.9405
described itemsets generated groups similar itemsets 
size group controlled clustering size size itemsets poisson distribution 
synthesizing model itemset group picked randomly primary range itemsets group contain parts head tail 
head random extraction itemset generated 
head fill itemset size tail picked randomly secondary range doing itemsets generated primary range clustering secondary range 
generate databases certain skewness secondary range 
data skewness distributed database controlled different primary secondary ranges different partitions 
table primary secondary ranges partitions experiment listed 
partitions skewed ranges respectively 
third partition db generated clustering ranges 
disjoint pools large itemsets synthesizing db range pair second range pair 
half transactions picked pool half second pool 
partitions exhibit certain degree skewness 
experiment sizes databases range transactions minimum support threshold ranges 
number candidate sets dma different site number cd remains sites 
comparing dma cd experienced average reduction number candidate sets site 
average number candidate sets generated partition primary range secondary range db db db table partition primary secondary ranges minimum support average number candidate dma cd minimum support dma cd candidate sets reduction :10.1.1.45.9405
dma cd site database size transactions plotted support thresholds 
dma candidate sets cases difference increases support decreases 
database ratios number candidate sets dma cd 
shows reduction number candidate sets dma cd gamma 
comparison number candidate sets site 
result direct implication reduction total number messages required site generate messages candidate set polling 
reduction total messages required bigger candidate sets comparing dma cd 
experienced reduction total message size cases 
database total message size needed dma cd plotted support thresholds 
ratios total message sizes dma cd 
reduction larger support threshold smaller large itemsets 
bar chart seen dma requires gamma messages cd 
compared execution time dma cd 
database dma faster cd depending support threshold 
execution time dma cd plotted thresholds database 
ratios speed bar chart 
database sizes experiment best speed reach 
minimum support dma cd minimum support ratio message dma cd message size reduction 
speed experiment substantial significant reduction message size 
main reason overhead communication relatively small test bed 
dma running distributed database partitions placed far apart locations speed significant 
minimum support dma cd minimum support ratio execution time cd dma execution time speed 
experiment compared dma cd series databases transactions 
terms candidate sets total message size reduction improvement dma cd steady 
average number candidate sets site dma compared cd databases threshold 
ratios plotted 
result shows percentage reduction cases 
total size message communication dma compared cd databases threshold 
ratios shows reduction cases 
execution time dma compared cd databases threshold 
ratios plotted dma faster cd 
database size dma cd candidate sets reduction 
database size dma cd message size reduction 
performance comparison different number sites second experiment test bed consists rs workstations 
synthetic database generated similar experiment 
aim experiment compare dma cd number sites changes 
describe result comparison number sites varies 
size database transactions partitioned equally sites 
minimum support threshold 
similar experiment significant reduction number candidate sets total message sizes cases number sites respectively 
average number candidate sets sites compared dma cd 
reduction gamma witnessed dma 
ratios total message sizes algorithms 
dma gamma reduction message sizes cases 
lastly execution time ratios described dma shown gamma faster cd cases 
general performance dma depends distribution data partitions 
itemsets distributed higher skewness partitions techniques local pruning candidate set generation reduction dma powerful 
comparing database size cd dma execution time speed 
number nodes dma cd candidate sets reduction 
results different experiments observed dma performs better number nodes higher 
consequence higher data skewness due increased number partitions 
discussion efficiency dma attributed techniques candidate sets generation local pruning messages optimization 
described dma local information available partition considered local pruning 
take advantage global information available pruning support count exchange starts fact iteration polling site candidate set knows global support count local support counts set local support counts broadcasted sites iteration 
discuss optimization technique global information prune candidate sets 
itemset respect partition db maxsup number nodes dma cd message size reduction 
number nodes dma cd execution time 
denote minimum value local support counts size gamma subsets maxsup sup ae jy gamma 
follows subset relationship maxsup upper bound local support count sup sum upper bounds partitions denoted maxsup upper bound sup 
sup maxsup maxsup 
note maxsup computed site th iteration 
maxsup upper bound global support count pruning maxsup theta candidate set 
call technique global pruning 
global pruning combined local pruning form different pruning strategies 
outline possible strategies 

local pruning followed global pruning local pruning site apply global pruning remaining candidate sets 
upper bound maxsup candidate set fine tuned sup maxsup sup available local pruning upper bound computed site effective value maxsup global pruning 

global pruning followed local pruning upper bound maxsup prune away candidate sets site apply local pruning remaining candidate sets 
extreme case may global pruning local pruning 

global pruning polling site local pruning done site pruning phase 
candidate set additional pruning done polling site 
polling site gamma set originating sites requests polling sent 
sites gamma local support counts sent 
site gamma locally large polling site deduce local support count sup bounded value min maxsup theta 
upper bound sup computed gamma sup gamma min maxsup theta upper bound prune away candidate sets polling site starts collect support counts 
effectiveness global pruning depends data distribution 
example ab candidate set size subset locally large small locally large size subset small large global pruning deduced ab globally large 
hand large small deduced global pruning ab small 
fact choice appropriate global pruning strategy depend data distribution 
additional cost doing global pruning storage required store local support counts message communication broadcast support counts 
trade cost reduction candidate sets 
depend data distribution number partitions 
believe global pruning pay distribution data certain degree skewness 
additional performance study required order investigate technique 
hashing technique relaxation factor proposed pdm integrated techniques dma 
example selection hash buckets broadcasting local pruning technique 
relaxation factor support threshold increase amount information available polling site global pruning 
point worthy mention original count distribution algorithm proposed designed high performance parallel environment improved introducing polling sites decrease amount message communication required 
merit requires synchronization 
fact high performance parallel environment dma cd combined form hybrid algorithm candidate sets cd slightly message communication dma synchronization 
investigate study 
issue related performance mining association rules distributed database difference partition sizes 
algorithms dma cd require synchronization iteration 
large size difference partitions favourable performance 
possible solution divide large partitions equalize sizes 
reduce time synchronization 
trade message communication 
studied efficient algorithm mining association rules distributed databases 
developed method reduces number candidate sets partition effectively local pruning 
communication scheme count exchange optimized polling sites 
method implemented performance studied compared direct application popular sequential algorithm 
study shows proposed technique superior performance mining association rules distributed databases 
efficiency local pruning enhanced global pruning local support counts stored sites 
discussed possibility integrating techniques dma pdm 
interesting studies finding multiple level generalized association rules large transaction databases 
extension techniques dma mining multiple level generalized association rules distributed database interesting problems research 
experimental purposes planning implement dma related algorithms ibm sp system nodes study problem mining association rules parallel system high speed communication 
agrawal faloutsos swami efficient similarity search sequence proc 
th int 
conf 
foundations data organization algorithms october 
agrawal ghosh imielinski iyer swami interval classifier database mining applications proc 
th int 
conf 
large data bases pp 
vancouver canada august 
agrawal imielinski swami database mining performance perspective ieee trans 
knowledge data engineering vol 
pp 

agrawal imielinski swami mining association rules sets items large databases proc 
acm sigmod int 
conf 
management data pp 
may 
agrawal shafer parallel mining association rules design implementation experience ibm research report rj 
agrawal srikant fast algorithms mining association rules proc 
int 
conf 
large data bases pp 
santiago chile september 
cheung 
fu han knowledge discovery databases rule attribute oriented approach proc 
int 
symp 
methodologies intelligent systems pp 
charlotte north carolina october 
cheung han ng wong maintenance discovered association rules large databases incremental updating technique proc 
ieee int 
conf 
data engineering new orleans louisiana february 
fayyad piatetsky shapiro smyth uthurusamy advances knowledge discovery data mining 
aaai mit press 
frawley piatetsky shapiro matheus knowledge discovery databases overview knowledge discovery databases piatetsky shapiro frawley editors pp 

aaai mit press 
geist beguelin dongarra jiang manchek sunderam pvm parallel virtual machine 
users guide tutorial networked parallel computing 
mit press 
han cai cercone data driven discovery quantitative rules relational databases ieee trans 
knowledge data engineering vol 
pp 

han fu discovery multiple level association rules large databases proc 
int 
conf 
large data bases zurich switzerland pp 
sept 
klemettinen mannila ronkainen toivonen verkamo finding interesting rules large sets discovered association rules proc 
rd int 
conf 
information knowledge management pp 
gaithersburg maryland nov 
ng han efficient effective clustering method spatial data mining proc 
int 
conf 
large data bases pp 
santiago chile september 
park chen yu effective hash algorithm mining association rules proc 
acm sigmod int 
conf 
management data pp 
san jose ca may 
park chen yu efficient parallel data mining association rules proc 
int 
conf 
information knowledge management baltimore md nov 
piatetsky shapiro frawley knowledge discovery databases 
aaai mit press 
savasere omiecinski navathe efficient algorithm mining association rules large databases proc 
int 
conf 
large data bases pp 
zurich switzerland sept 
silberschatz stonebraker ullman database research achievements opportunities st century report nsf workshop database systems research may 
srikant agrawal mining generalized association rules proc 
int 
conf 
large data bases pp 
zurich switzerland sept 
ullman 
principles database knowledge base systems vols 

computer science press 

