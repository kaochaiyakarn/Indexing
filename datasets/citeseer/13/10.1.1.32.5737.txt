analysis nonstationary time series mixtures self organizing predictors jens kohlmorgen steven gunnar ratsch klaus robert muller gmd german national research center information technology institute computer architecture software technology 
berlin germany mail gmd de web www gmd de 
method analysis time series drifting switching dynamics 
extension existing approaches identify switches drifts stationary dynamical modes method allows analyze continuously varying dynamics identify mixtures dynamical modes 
architecture mixture self organizing nadaraya watson kernel estimators 
mixture model trained barrier optimization technique constrained optimization problems 
apply proposed method artificially generated data eeg recordings wake sleep transition 
time series alternating dynamics ubiquitous real world systems example speech data physiological recordings eeg meg financial markets 
important find methods deal time varying dynamical systems possibly nonlinear 
introduced annealed competition experts ace method time series nonlinear switching dynamics ensemble neural network predictors specializes different dynamical regimes increasing competition predictors deterministic annealing scheme :10.1.1.4.9877
related approaches switching dynamics :10.1.1.53.917:10.1.1.29.8423
extended ability describe mode change switching appropriate continuous drift predictor physiological signals modeled appropriately drifting dynamics model 
different compared simple straightforward approach analysis switching drifting dynamics 
furthermore method able analyze continuously varying dynamics contain stationary segments mixture dynamics may consist components 
new method mixture self organizing kernel estimators apply approach artificially generated data eeg recorded wake sleep transition human subject 
algorithm consider time series nonstationary dynamical system consists pairs input target data particular target data value scalar time series fx input data dimensional vector past values gamma gamma gamma 
typical formulation time series prediction problem 
parameter called embedding dimension called delay parameter 
note extension multivariate time series straightforward 
simplicity restrict scalar notation 
model basic idea approach model dynamical system timevarying mixture potentially nonlinear predictors estimate target constraints regarding mixing coefficients predictors infinitely qualitatively different solutions fitting data 
example arbitrary predictors gamma arbitrarily chosen values time find perfect fit simply solving single remaining parameter previous approaches problem simply parameters estimated time independent parameterized functions called gating functions input input internal state prediction performance gamma individual predictors quantities :10.1.1.4.9877:10.1.1.53.917:10.1.1.29.8423
methods consider switching model assume single predictor responsible generating data time step 
functions interpretations probability functions conditional probability expert exclusively generated data time respective quantities 
actual mixing coefficients determined separately second stage order model mixing dynamics 
straightforward stage approach estimating mixing dynamics time series number experts mixing proportions simply parameters estimated optimization procedure subject constraints constraints applied order restrict space possible solutions discussed 
furthermore permit model convex hull underlying multi modal dynamical system 
includes cases switching drifting dynamics considered previous extension allows represent mixtures predictors restricted fixed number discrete mixture states 
allows analyze continuously drifting dynamics stationary periods 
note context mixtures mixing factors probabilities individual experts 
framework merely switching model probabilistic interpretation 
due limited space consider variant 
discuss optimization technique consider second part model function approximators represent set base dynamics model 
general function approximators contain parameters need adapted data 
case parameters add typically large number parameters making optimization problem harder 
elegant way introduce function approximators introducing new adaptive parameters nadaraya watson kernel estimators oe oe gaussian kernel data point training set oe exp gamma gamma oe kernel width oe determines smoothness estimator 
free parameter estimator fixed smoothness prior 
principle adapted training 
case care taken prevent oe getting small clearly lead overfitting 
want estimate single global predictor individual prediction experts different dynamical modes data set obtain individual experts weighting data point kernel estimator respective mixing proportion oe oe corresponds self organization experts optimization parameters case switching dynamics estimators contain exactly subset data points assigned simultaneously represent prediction functions respective modes 
data point represents mixture dynamics suited contribute predictors contains noise components 
fact turned linear weighting data points sufficient suppress contribution mixed noisy data estimators 
introduced nonlinearly weighted estimator oe ff oe ff contribution data points mixtures smaller larger ff chosen 
experiments ff turned choice analysis mixture dynamics 
note switching dynamics ff sufficient 
optimization fitting set parameters fp tg mixture model data set formulated constrained optimization problem 
objective function minimized gamma gamma gamma sum squared prediction errors plus additional regularization term weighted constant penalizes changes mixing coefficients time 
necessary avoid local minima objective function imposes smoothness prior solutions simple temporal structure frequent changes 
fact goal minimize prediction error training data find simple model respect dynamical structure 
minimizing subject constraints 
constrained optimization problem solved technique called barrier optimization 
constraints need transformed set inequalities form gamma gamma gammap gamma constrained optimization problem solved socalled barrier penalty error function fi fi gammac fi suitable barrier function fi penalty parameter 
typical choices fi fi gammafi log fi fi exp gammat fi 
note log barrier optimization start feasible inequalities satisfied need condition 
problem find feasible start case prefer exp penalty 
starting value fi function fi minimized unconstrained optimization technique 
conjugate gradient cg method line search 
optimization step fi decreased fi fi optimization procedure restarts decreased fi solution previous step stopping criterion error threshold final value fi reached 
case mixture model resulting fp represents drift switch mix segmentation time series time set nadaraya watson prediction experts extracted dynamical modes 
applications illustrate approach examples artificially generated drifting dynamics discussed 
application real world data eeg recording wake sleep transition human subject 
drifting dynamics mackey glass system generated time series drifting dynamics mackey glass delay differential equation dx dt fl gamma gamma gamma high dimensional chaotic system originally introduced model blood cell regulation 
example stationary operating modes established different delays respectively 
operating time steps mode respect subsampling step size delta dynamics switches mixture modes mixture dynamics generated time steps mixing equations dx dt fl fl fl 
system runs stationary mode time steps switches new mixture reaches 
runs stationary mode applied barrier optimization method mixture model predictors 
input predictor vector time delay coordinates scalar time series fx embedding dimension delay parameter subsampled data 
penalty parameter annealed fi 
parameters ff oe 
result optimization depicted fig 

predictors specialized prediction dynamics modes respectively 
intermediate mixture parts represented mixtures predictors mixing proportions nicely agree real coefficients 
second mixture part coincidence similar perfect 
considering fact data points complicated dynamical mixture system result remarkably 
long term prediction performance feeding back single step predictions predictors shown fig 
fig 
prediction starts mode 
iterated predictors individually thin black line dash dotted line dashed line ensemble mixing proportions grey line 
dashed predictor clearly dominates mixture output identical ensemble 
generated continuations similar target dynamics thick line continuations predictors 
fig 
shows respective predictions mixed dynamics 
expected ensemble yields long term prediction individual predictors 
fact ensemble predictors able reconstruct dynamics modes 
consider case continuously drifting dynamics 
time varying mixing factors sin gamma 
generated time series continuous drift modes period 
experts data points 
parameters chosen 
respective result shown fig 

sine shape nicely predictors captured dynamics mode respectively stationary parts data 
wake sleep eeg analyzed eeg data recorded wake sleep transition humans 
objective provide unsupervised method detect sleep onset give approximation signal dynamics ultimately diagnosis treatment sleep disorders 
applied method proposed data order find segmentation mackey glass time series mixture states 
prediction ensemble thin grey line printed top data black dots 
obtained mixing proportions expert predictors plotted dashed dash dotted solid line respectively 
nicely correspond original proportions 
iterated predictions individual experts thin black line dash dotted line dashed line ensemble grey line starting mode 
dashed predictor ensemble fits dynamics mode thick line 
mixture dynamics 
ensemble grey line properly predicts long term behavior system thick line individual predictors 
segmentation mackey glass time series continuous drift operating modes 
prediction ensemble thin line printed top data black dots 
obtained mixing proportions experts drawn dashed solid line 
largely agree sine drift data 
iterated predictions individual experts dashed thin solid line data training set stationary time series mode thick line 
dashed curve clearly resembles dynamics mode 
iterated predictions stationary time series mode thin solid line similar dynamics mode thick line 
segmentation eeg data thin line wake sleep transition 
obtained segmentation agreement manual segmentation medical expert previous analysis see text 
get similar results support previous findings 
data measured afternoon nap healthy human subject 
analyzed data single channel eeg recording position 
embedding predictors raw hz data 
order reduce amount data subsampled obtained training data set factor chose sequence data points sleep onset roughly 
applied new method data set predictors 
penalty parameter annealed fi 
parameters oe ff 
resulting segmentation depicted fig 

roughly points mainly assigned predictor thick solid line 
corresponds wake phase 
points mainly assigned second predictor dashed line corresponds sleeping phase 
clear transition sleep onset mixture level decay mixing proportion solid line zero 
transition behavior nicely coincides results 
subsequent drift back wake state predictor indicated manual segmentation medical expert assigned sleep stage hand prominent transition predictor clearly indicated manual segmentation intermediate arousal 
note interval mixing proportions indicate drift wake sleep state predictor marked artifact manual segmentation 
summarize obtained segmentation eeg data agreement manual segmentation previous analysis 
demonstrates approach find meaningful structure complex real world data 
summary discussion method unsupervised segmentation identification nonstationary drifting dynamics 
applies time series dynamical systems drift switch various operating modes 
contrast previous approaches time series necessarily need contain stationary periods 
mixtures predictors possible 
hand uses prediction experts necessary model degrees freedom may fit data various ways 
find appropriate number predictors efficiently open question far requires repeated application method different numbers predictors choosing complex ensemble solutions lowest error 
application wake sleep eeg demonstrated meaningful structure real world data approach 
expect useful applications method fields complex nonstationary dynamics plays important role climatology industrial applications finance 
providing physiological data acknowledge partial financial support deutsche forschungsgemeinschaft ja 
bengio frasconi 

input output hmm architecture 
nips advances neural information processing systems eds 
tesauro touretzky leen morgan kaufmann 
bishop 

neural networks pattern recognition oxford university press ny 
cacciatore nowlan 

mixtures controllers jump linear non linear plants 
nips eds 
cowan tesauro alspector morgan kaufmann 


stable exponential penalty algorithm superlinear convergence 

principe 

neighborhood map competing step predictors piecewise segmentation identification time series 
icnn proc 
int 
conf 
neural networks vol 

frisch 

logarithmic potential method convex programming 
memorandum university institute economics oslo 
jacobs jordan nowlan hinton 

adaptive mixtures local experts 
neural computation 
kehagias petridis 

time series segmentation predictive modular neural networks 
neural computation 
kohlmorgen muller pawelzik 

improving short term prediction competing experts 
icann proc 
int 
conf 
artificial neural networks ec cie paris 
kohlmorgen muller pawelzik 

segmentation identification drifting dynamical systems 
eds 
principe giles morgan wilson ieee 
kohlmorgen muller pawelzik 

identification nonstationary dynamics physiological recordings biological cybernetics 
pawelzik kohlmorgen muller 

hidden markov mixtures experts application eeg recordings sleep 
theory biosciences 
mackey glass 

oscillation chaos physiological control system 
science 
pawelzik kohlmorgen muller 

annealed competition experts segmentation classification switching dynamics 
neural computation 
shi weigend 

time seriously hidden markov experts applied financial engineering 
proc 
conf 
computational intelligence financial engineering ieee nj 
