appeared computer architecture news march hitting memory wall implications obvious wm 
wulf sally mckee wulf mckee virginia edu computer science report 
cs december hitting memory wall implications obvious appeared computer architecture news march 
hitting memory wall implications obvious wm 
wulf sally mckee department computer science university virginia wulf mckee virginia edu december brief note points obvious authors knew really understanding 
apologies understand offer missed point 
know rate improvement microprocessor speed exceeds rate improvement dram memory speed improving exponentially exponent microprocessors substantially larger drams 
difference diverging exponentials grows exponentially disparity processor memory speed issue downstream bigger 
big soon 
answers questions authors failed appreciate 
get handle answers consider old friend equation average time access memory cache dram access times probability cache hit want look average access time changes technology ll conservative assumptions ll see specific values won change basic note going hit wall improvement system performance basic changes 
avg hitting memory wall implications obvious appeared computer architecture news march 
assume cache speed matches processor specifically scales processor speed 
certainly true chip cache allows easily normalize results terms instruction cycle times essentially saying cpu cycle 
second assume cache perfect 
cache conflict capacity misses compulsory ones 
just probability accessing location referenced adjust line size won affect won argument complicated necessary 
small isn zero 
diverge avg grow system performance degrade 
fact hit wall 
programs instructions memory hen 
sake argument take lower number 
means average execution th instruction memory 
hit wall avg exceeds instruction times 
point system performance totally determined memory speed making processor faster won affect wall clock time complete application 
alas easy way 
assumed perfect cache bigger smarter won help re full bandwidth memory prefetching related schemes won help 
consider things done speculate hit wall 
assume compulsory rate hen level memory hierarchy currently times slower cache 
assume dram speeds increase year hen baskett estimate microprocessor performance increasing rate year bas average number cycles memory access 
assumptions wall decade away 
hitting memory wall implications obvious appeared computer architecture news march 
figures explore various possibilities showing projected trends set perfect near perfect caches 
graphs assume dram performance continues increase annual rate 
horizontal axis various cpu dram performance ratios lines top indicate dates ratios occur microprocessor performance increases rates respectively 
assumes cache misses currently times slower hits considers compulsory cache rates shows trends caches realistic rates 
figures counterpart assumes current cost cache times hit 
provides closer look expected impact average memory access time particular value baskett estimated 
assume cache hit rate conservative cache cost cycles starting point performance hits cycles access wall years 
hit rate hit wall decade years 
note changing starting point current hit cost ratio cache rates don change trends microprocessor memory performance gap continues grow similar rate years memory access cost average tens hundreds processor cycles 
scenario system speed dominated memory performance 
past years predictions eminent cessation rate improvement computer performance 
prediction wrong 
wrong unstated assumptions subsequent events 
example failure foresee move discrete components integrated circuits led prediction speed light limit computer speeds orders magnitude slower 
hitting memory wall implications obvious appeared computer architecture news march 
prediction memory wall probably wrong suggests start thinking box 
techniques authors aware including ones proposed mck mck provide time boosts bandwidth latency 
delay date impact don change fundamentals 
convenient resolution problem discovery cool dense memory technology speed scales processors 
aware technology affect development case contribution look architectural solutions 
probably bogus discussion start drive number compulsory misses zero 
fix way caches drive means eliminating compulsory misses 
data initialized dynamically example possibly compiler generate special write instructions 
harder imagine drive compulsory misses code zero 
time forgo model access time uniform parts address space 
false dsm scalable multiprocessor schemes single processors 
compiler explicitly manage smaller amount higher speed memory 
new ideas trade computation storage 
alternatively trade space speed 
dram keeps giving plenty 
ancient machines ibm burroughs magnetic drum primary memory clever schemes reducing rotational latency essentially zero borrow page books 
hitting memory wall implications obvious appeared computer architecture news march 
noted right solution problem memory wall probably haven thought see discussion engaged 
appear great deal time 
trends current cache hit cost ratio cache hit cost ratio average cycles access cache hit cost ratio average cycles access hitting memory wall implications obvious appeared computer architecture news march 
trends current cache hit cost ratio cache hit cost ratio average cycles access cache hit cost ratio average cycles access average access cost annual increase processor performance year average cycles access hitting memory wall implications obvious appeared computer architecture news march 
bas baskett keynote address 
international symposium shared memory multiprocessing april 
hen hennessy patterson computer architecture quantitative approach morgan kaufman san mateo ca 
mck mckee experimental implementation dynamic access ordering proc 
th hawaii international conference system sciences maui hi january 
mck mckee increasing memory bandwidth vector computations proc 
conference programming languages system architecture zurich march 
