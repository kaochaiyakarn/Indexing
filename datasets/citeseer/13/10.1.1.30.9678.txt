appear proc 
emnlp vlc word informativeness automatic pitch accent modeling pan kathleen mckeown dept computer science columbia university new york ny usa pan kathy cs columbia edu intonational phonology speech synthesis research suggested relative informativeness word predict pitch prominence 
information conveyed word accented 
express doubts correlation 
provide empirical evidence support existence correlation employing widely accepted measures informativeness 
experiments show positive correlation informativeness word pitch accent assignment 
show informativeness enables statistically significant improvements pitch accent prediction 
computation word informativeness inexpensive incorporated speech synthesis systems easily 
production natural intelligible speech remains major challenge speech synthesis research 
research focused prosody modeling silverman hirschberg santen determines variations pitch tempo rhythm 
critical issues prosody modeling pitch accent assignment 
pitch accent associated pitch prominence word 
example words may sound prominent sentence associated sharp pitch rise fall 
usually prominent words bear pitch accents prominent ones 
native speakers particular language di culty deciding words utterances accented general pattern language english open question 
linguists speculate relative informativeness semantic weight word influence accent placement 
ladd claims speakers assess relative semantic weight informativeness potentially words put accent informative point points ibid pg 

claims understand relative semantic weight automatically understand accent placement ibid pg 

bolinger bolinger uses examples illustrate phenomenon 
arrested killed man 
arrested killed policeman 
capitalized words examples accented 
man semantically empty relative kill verb kill gets accented 
po semantically rich accented 
di erent theories informativeness proposed explain phenomenon 
example bresnan explanation syntactic function 
suggests man sentence get accented man words guy person thing form category semi pronouns 
counter examples listed raise questions usefulness semantic informativeness 
accent pattern examples explained solely semantic informativeness 

hoover dam 

hoover tower 
researchers discussed possible influence semantic informativeness known empirical study claim type information incorporated computational models prosody 
employ measurements informativeness 
adopt information framework shannon quantifying information content ic word negative log likelihood word corpus 
second measurement tf idf term frequency times inverse document frequency salton salton widely quantify word importance information retrieval tasks 
ic tf idf established measurements informativeness candidates investigate 
empirical study shows word informativeness closely related word accentuation provides new power pitch accent prediction 
results suggest information content valuable feature incorporated speech synthesis systems 
sections define ic tf idf 
description corpus study provided 
describe set experiments conducted study relation informativeness pitch accent 
explain machine learning techniques pitch accent modeling process 
results show ic tf idf scores strongly correlated pitch accent assignment 
ic powerful predictor tf idf 
ic provides better prediction power pitch accent prediction previous techniques 
investigated pitch accent models easily adopted speech synthesis systems 
definitions ic tf idf standard definition information theory shannon fano cover thomas ic word ic log probability word appearing corpus estimated frequency corpus accumulative occurrence words corpus 
intuitively probability word increases informativeness decreases information focus 
similarly communicated pitch prominence 
tf idf defined components multiplied 
tf term frequency word frequency document idf inverse document frequency logarithm ratio total number documents number documents containing word 
product tf idf higher word high frequency document signifies high importance current document low dispersion corpus signifies high specificity 
research employed variant tf idf score smart buckley popular information retrieval package tf idf log fw log nw log fw log nw fw frequency word document total number documents nw number documents containing word number distinct stemmed words document ic tf idf capture di erent kinds informativeness 
ic matrix global domain corpus word corpus unique ic score 
tf idf captures balance matrix local document tf matrix global corpus idf 
tf idf score word changes document di erent tf 
global features captured tf idf 
example common word domain tends get low tf idf score documents corpus 
corpus description order empirically study relations word informativeness pitch accent medical corpus includes speech portion text portion 
speech corpus includes fourteen segments total minutes speech 
speech collected columbia medical center doctors informed residents nurses status patient just undergone bypass surgery 
speech corpus transcribed orthographically medical professional labeled pitch accents tobi tone break index silverman beckman hirschberg expert 
text corpus includes discharge summaries spanning larger group patients 
majority patients undergone cardiac surgery 
orthographic transcripts text corpus calculate ic tf idf scores 
words text corpus speech transcripts processed stemming model words receive receives treated word 
employ revised version lovins stemming algorithm lovins implemented smart 
usefulness stemming arguable choose stemming think receive receives equally accented 
ic tf idf calculated 
ectiveness informativeness accent placement verified speech corpus 
word speech corpus ic score tf idf score part speech pos tag pitch accent label 
ic tf idf test correlation informativeness accentuation 
pos investigated machine learning techniques automatic pitch accent modeling 
experiments conducted series experiments determine correlation informativeness pitch accent informativeness provides improvement known indicators pitch accent part speech 
experimented di erent forms machine learning integrate indicators single framework testing rule induction hidden markov modeling provides better model 
ranking word informativeness corpus table shows informative words corpus 
ic order indicates rank words corpus tf idf order table indicates rank words document 
document picked randomly corpus 
general informative words function words 
content words selected pa year old 
content words common domain mentioned documents corpus 
contrast majority informative words content words 
selections expected 
example ranks informative word document tf idf 
indicates listeners readers rarely addressed corpus 
appears entire corpus 
rank ic informative ic informative words ic words ic name patient synthetic rx day quote table ic informative words rank tf idf informative tf idf informative words tf idf words tf idf vol tank name name incomplete old year table tf idf informative words testing correlation informativeness accent prediction order verify word informativeness correlated pitch accent employ spearman rank correlation coe cient associated test conover estimate correlations ic pitch prominence tf idf pitch prominence 
shown table ic tf idf closely correlated pitch accent significance level respectively 
correlation coe cient positive indicates higher ic tf idf word accented 
learning ic tf idf accent models correlation test suggests strong connection informativeness pitch accent 
want show performance gain achieved adding information pitch accent models 
study ect tf idf ic pitch accent machine learning techniques learn models predict feature correlation coe cient significance level tf idf ic table correlation informativeness accentuation ect indicators pitch accent 
ripper cohen hidden markov models hmm rabiner juang build pitch accent models 
ripper system learns sets classification rules training data 
automatically selects rules maximize information gain employs heuristics decide prevent fitting 
performance ripper comparable benchmark rule induction systems quinlan 
train ripper speech corpus fold cross validation standard procedure training testing amount data limited 
experiment predictors ic tf idf response variable pitch accent assignment 
set ripper rules acquired predict word accented new corpus 
hmm probability model successfully applications speech recognition rabiner part speech tagging kupiec 
hmm defined triple state transition probability matrix observation probability distribution matrix initial state distribution vector 
experiment hidden states accent status words accented accented 
observations ic tf idf score word 
limitation size speech corpus firstorder hmm condition assumed 
state time employ supervised training process sophisticated parameter estimation procedure baum welch algorithm rabiner necessary 
parameters precisely calculated formula ij ij jm jm number hidden states number observations 
parameters hmm set employ viterbi algorithm viterbi forney find optimal accentuation sequence maximizes possibility occurrence observed ic tf idf sequence hmm 
ripper hmm widely accepted machine learning systems 
theoretical bases di erent 
hmm focuses optimizing sequence accent assignments isolated accent assignment 
employing want show hold approaches 
furthermore expect hmm better ripper influence context words incorporated 
baseline model words assigned default accent status accented words corpus accented baseline performance 
results models hmm performance ripper performance baseline tf idf model ic model table comparison ic tf idf model baseline model table show tf idf predict pitch accent performance increased baseline hmm ripper respectively 
ic model performance increased 
results obtained fold cross validation 
draw results 
ic tf idf ective pitch accent prediction 
improvements baseline model statistically significant test fienberg 
second ic model powerful tf idf model 
performs tf idf model hmm model ripper model 
low values show improvements achieved ic models significant 
ic performs better tf idf pitch accent prediction choose ic measure informativeness experiments 
observation results hmm models show improvements ripper models 
di erence marginal 
data needed test significance improvements 
incorporating ic accent models order show ic provides additional power predicting pitch accent current models need directly compare influence ic models 
section describe experiments compare ic reports underflow 
real value smallest value computer represent case part speech pos model pitch accent prediction compare model integrates ic pos pos model 
anticipating possibility features traditional tts combination pos may provide equal better performance addition ic carried experiments directly compare performance text speech tts synthesizer model integrates tts ic 
speech synthesis systems part ofspeech pos powerful feature pitch accent prediction 
showing ic provides additional power pos important 
addition importance pos tts predicting pitch accent clear overlap pos ic 
shown words highest ic usually content words words lowest ic frequently function words 
added incentive comparing ic pos models 
want explore new information added ic provide improvement predict accent assignment 
order create pos model utilize maximum entropy partof speech tagger ratnaparkhi get pos information word 
performance tagger comparable benchmark pos taggers brill tagger brill 
map part speech tags categories noun verb adjective adverb number pronoun 
mapping procedure conducted keeping initial tags drastically increase requirements amount training data 
models hmm performance ripper performance ic model pos model pos ic model table comparison pos ic model pos model models hmm performance ripper performance tts model tts ic model pos ic model table comparison tts ic model tts model obtained pos tag predictor pos model 
shown table performance pos models hmm ripper respectively comparable ic model 
comparison shows strength ic similar power pos pitch accent prediction easy compute 
pos models augmented ic pos ic model performance increased respectively 
improvement statistically significant hmm model ripper means new information captured ic provides additional predicting power pos ic models 
experiments produce new evidence confirming ic valuable feature pitch accent modeling 
tried model text speech tts synthesizer output evaluate results 
tts pitch accent model comprehensive pos model 
taken features consideration discourse semantic information 
established evaluated various situations 
research adopted bell laboratories tts system sproat olive liberman hirschberg 
run corpus get tts pitch accent assignments 
comparing tts accent assignment expert accent assignment tts performance statistically significantly lower hmm pos ic model 
tried incorporate ic tts model 
simple way doing tts output ic predictors train data 
obtained tts ic models achieve marginal improvement 
performance tts ic model increases hmm ripper respectively lower pos ic models 
speculate may due corpus 
bell laboratories tts pitch accent model trained totally di erent domain medical corpus negatively ect tts performance compared normal performance 
tts ic models involve totally different domains ectiveness ic may compromised 
assumption holds think tts ic model perform better ic trained tts internal features corpus directly 
requires retraining tts system new domain hard conduct experiment comparison conducted verify assumption 
tf idf powerful ic pitch accent prediction measure di erent kinds informativeness possible tf idf ic model perform better ic model 
similarly tf idf incorporated pos ic model performance may increase pos ic tf idf model 
experiment shows improvements tf idf incorporated ic pos ic model 
experiments show ic dominant predictor ic tf idf 
related information approaches applied natural languages applications 
resnik resnik ic measure semantic similarity words shown ective traditional measurements semantic distance wordnet hierarchy 
similar log measurement employed leacock chodorow measure semantic similarity 
tf idf scores mainly keyword information retrieval tasks 
example tf idf salton salton index words document implemented smart buckley general purpose information retrieval package providing basic tools libraries facilitate information retrieval tasks 
early pitch accent prediction speech synthesis uses distinction content words function words 
approach simple tends assign pitch accents necessary 
tried content function word model corpus expected powerful partof speech model 
advanced pitch accent models information part speech new distinctions contrast information hirschberg 
semantic information employed predicting accent patterns complex nominal phrases sproat 
comprehensive pitch accent models suggested pan mckeown framework concept speech generation output natural language generation system predict pitch accent 
discussion ic perfect measurement informativeness cause problems accent prediction 
perfect measurement informativeness available features may needed order build satisfactory pitch accent model 
section discuss issues 
ic directly measure informativeness word 
measures rarity word corpus 
word rare doesn necessarily mean informative 
semantically empty words ranked high ic 
example common operation domain 
operation mentioned 
instances referred operation 
result semantically empty word context operation gets high ic score hard distinguish high ic scores resulting situation accurately measure informativeness causes problems precisely measuring ic word 
similarly misspelled words high ic score due rarity 
ic ideal quantifying word informativeness perfect measurement informativeness cases information 
example word gets unique ic score regardless context known context information new contrast plays important role accentuation 
plan build comprehensive accent model pitch accent indicators syntactic semantic discourse features 
provided empirical evidence usefulness informativeness accent assignment 
positive correlation indicators informativeness ic tf idf pitch accent 
informative word pitch accent assigned word 
measurements informativeness improve baseline performance significantly 
show ic powerful measure informativeness tf idf pitch accent prediction 
comparing pos models pos models ic enables additional statistically significant improvements pitch accent assignment 
performance outperforms tts pitch accent model significantly 
ic ective shown results relatively inexpensive compute new domain 
speech synthesis systems text concept speech systems employ feature long large corpus 
plan explore information content measurements incorporate comprehensive accent model discourse semantic features included 
julia hirschberg vasileios hatzivassiloglou james shaw comments suggestions earlier version 
jordan helping collection speech text corpus 
research supported part national science foundation 
iri national library medicine project lm columbia university center advanced technology high performance computing communications healthcare funded new york state science technology foundation 
mary beckman julia hirschberg 

tobi annotation conventions 
technical report ohio state university columbus 
bolinger 

accent predictable re mind reader 
language 
joan bresnan 

sentence stress syntactic transformations 
language 
eric brill 

advances rulebased part speech tagging 
proceedings th national conference artificial intelligence 
chris buckley 

implementation smart information system 
technical report cornell university 
william cohen 

fast ective rule induction 
proceedings th international conference machine learning 
conover 

practical statistics 
wiley new york nd edition 
thomas cover joy thomas 

elements information theory 
wiley new york 
robert fano 

transmission information statistical theory communications 
mit press cambridge massachusetts 
stephen fienberg 

analysis cross classified categorical data 
mit press cambridge mass nd edition 
joseph 

statistical methods rates proportions 
wiley new york nd edition 
david forney 

viterbi algorithm 
proceedings ieee 
julia hirschberg 

assigning pitch accent synthetic speech new distinction 
proceedings seventh national conference american association artificial intelligence pages boston 
julia hirschberg 

pitch accent context predicting intonational prominence text 
artificial intelligence 
julian kupiec 

robust part speech tagging hidden markov model 
computer speech language july 
robert ladd 

intonational phonology 
cambridge university press cambridge 
claudia leacock martin chodorow 

combining local context wordnet similarity word sense identification 
christiane fellbaum editor wordnet electronic lexical database chapter 
mit press 
julie beth lovins 

development stemming algorithm 
mechanical translation computational linguistics volume 
joseph 
olive mark liberman 

text speech overview 
journal acoustic society america fall 
pan kathleen mckeown 

learning intonation rules concept speech generation 
proceedings coling acl montreal canada 
john quinlan 

programs machine learning 
morgan kaufmann san mateo 
lawrence rabiner juang 

hidden markov models 
ieee assp magazine pages january 
lawrence rabiner 

tutorial hidden markov models selected applications speech recognition 
proceedings ieee 
adwait ratnaparkhi 

maximum entropy part speech tagger 
eric brill kenneth church editors conference empirical natural language processing 
univ pennsylvania 
philip resnik 

semantic classes syntactic ambiguity 
proc 
arpa workshop human language technology pages 
morgan kaufmann publishers 
philip resnik 

information content evaluate semantic similarity taxonomy 
proceedings th international joint conference artificial intelligence pages montreal canada 
gerard salton 

automatic text processing transformation analysis retrieval information computer 
addison wesley reading massachusetts 
gerard salton 

developments automatic text retrieval 
science august 
jan van santen 

contextual effects vowel duration 
speech communication january 
claude shannon 

mathematical theory communication 
bell system technical journal july october 
kim silverman mary beckman john mari ostendorf colin patti price janet pierrehumbert julia hirschberg 

tobi standard labelling english prosody 
proceedings icslp volume 
kim silverman 

structure processing fundamental frequency contours 
ph thesis cambridge university 
richard sproat 

english nounphrase accent prediction text 
computer speech language 
richard sproat 

multilingual speech synthesis bell labs approach 
kluwer boston 
andrew viterbi 

error bound convolutional codes asymptotically optimum decoding algorithm 
ieee transactions information theory 
