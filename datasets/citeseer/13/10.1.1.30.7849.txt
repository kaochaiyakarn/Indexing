exponentiated gradient versus gradient descent linear predictors kivinen manfred warmuth ucsc crl june revised december center computer engineering information sciences university california santa cruz santa cruz ca usa consider algorithm line prediction linear model 
algorithms known gradient descent gd algorithm new algorithm call sigma maintain weight vector simple updates 
gd algorithm update subtracting gradient squared error prediction 
sigma algorithm uses components gradient exponents factors updating weight vector multiplicatively 
worst case loss bounds sigma compare previously known bounds gd algorithm 
bounds suggest losses algorithms general incomparable sigma smaller loss components input relevant predictions 
performed experiments show worst case upper bounds quite tight simple artificial data 
consider scenario learner learning algorithm tries accurately predict real valued outcomes sequence trials 
tth trial learner receives instance dimensional real vector 
components instances called input variables 
instance information received previous trials learner real valued prediction actual tth outcome observed learner charged possible discrepancy predicted outcome actual outcome discrepancy measured loss function example square loss function gamma long sequence trials learner tries minimize total loss simply sum losses incurred individual trials 
learning algorithm follows protocol called line prediction algorithm 
obviously assumptions concerning relation instances outcomes prediction algorithm 
set reasonable goal measure performance algorithm performances predictors fixed comparison class 
comparison class analogous touchstone class agnostic pac model learning kss :10.1.1.55.3936
algorithm required perform predictor comparison class performs 
extremes outcomes completely random case predicted algorithm predictor comparison class outcomes completely predicted fixed predictor case algorithm incur small loss learning follow predictor 
general predictors arbitrary mappings concentrate linear predictors vector associate linear predictor defined delta set vectors defines comparison class linear predictors trial sequence total loss algorithm loss tth prediction algorithm 
analogously total loss predictor loss 
linear predictors notation loss loss 
goal obtain bounds form loss inf loss allow length sequences total losses increase bound 
stage simplify presentation keeping number dimensions constant assuming fixed subset instances belong 
turns obtain better 
get coefficient leading term right hand side obtain loss inf loss quantity approaches inf loss approaches infinity 
bound means additive additional loss loss gamma inf loss algorithm grows sublinear rate function inf loss 
asymptotic notation hides dependence total loss algorithm number dimensions ranges predictor vectors comparison class domain instances 
dependences usually quite important consider constants shown asymptotic bounds 
note bounds worst case bounds respect may need assume instances belong restricted domain assume drawn probability measure assumptions outcomes related instances linear predictor trial sequence right hand sides bounds large bounds may interesting 
bounds hold 
contrast common approaches statistical assumptions distribution instances dependence outcomes instances order derive probabilistic loss bounds prediction algorithm ws hay 
research reported inspired littlestone lit lit proved worst case bounds case comparison class consists boolean monomials generally linear threshold functions 
case assumed components instances predictions outcomes boolean total loss measured number mistakes number incorrect predictions algorithm 
arbitrary finite comparison class predictors finite class called experts 
note finite comparison class considered comparison class restricted set linear predictors 
unit vector replace instance vector original predictor applied original instance represented linear predictor applied new instance original comparison class consider comparison class linear predictors consists unit vectors number dimensions number experts size original comparison class 
vovk proved large class loss functions simple algorithm achieves bounds form loss inf loss log constant depends loss function 
bounds tighter form 
absolute loss bounds obtained 
vovk littlestone warmuth lw bounds form absolute loss 
cesa bianchi showed bounds improved form careful choice certain parameters vovk algorithm 
results assumed outcomes generalized continuous valued outcomes haussler kivinen warmuth 
consider proving bounds form comparison class general linear predictors predictors choose components instance 
describe simple experiments verify worst case bounds reflect actual behavior algorithms 
succeeded proofs square loss gamma basic ideas phrased general loss functions 
immediate predecessors papers cesa bianchi littlestone 
cesa bianchi consider gradient descent algorithm gd algorithm linear predictions 
algorithm known widrow hoff algorithm mean squares algorithm 
main algorithms 
algorithm maintains weight vector updates trial 
tth weight vector considered hypothesis algorithm trial best linear predictor trial sequence 
trial algorithm gives prediction delta receiving outcome updates weight vector update rule gamma gamma positive learning rate 
motivate name gd algorithm note derivative loss gamma delta algorithm respect weight delta gamma update subtracts weight vector gradient rw gamma delta multiplied scalar gd algorithm considered simple application gradient descent heuristic line prediction problem 
choosing learning rate nontrivial significantly affect performance algorithm 
introduce new line prediction algorithm call exponentiated gradient algorithm algorithm 
algorithm closely related algorithm littlestone 
algorithm weight vector predicts delta update rule gamma gammay positive learning rate ith component gradient appears exponent factor multiplies weights algorithm positive sum 
restriction weight vector clearly restricts predictive ability algorithm 
introduce exponentiated gradient algorithm positive negative weights sigma algorithm 
sigma algorithm obtained applying simple transformation algorithm 
components weight vector positive negative 
sum fixed algorithm assumes fixed upper bound 
algorithms gd motivated common framework 
making update algorithm balance need conservative retain information acquired preceding trials corrective certain instance observed algorithm accurate prediction outcome 
old weight vector algorithm chooses new weight vector approximately minimizes jl delta measure distance old new weight vector loss function magnitude positive constant represents importance compared importance conservativeness 
measure typically metric 
square loss function squared euclidean distance jjw gamma sjj results gd algorithm 
algorithm results relative entropy known kullback leibler divergence re ln assumes components positive constraints maintained 
relative entropy distance measure motivated maximum entropy principle jaynes general minimum relative entropy principle kullback 
fundamental principles applications information theory physics economics see kapur kk overview 
central distance measure different ways motivates update rule second applied tool analysis algorithm obtained 
estimating change distance weight vector algorithm comparison vector update possible prove kind worst case loss bounds consider 
distance measure obtaining worst case loss bounds pioneered littlestone analysis winnow lit employs variant relative entropy 
amari ama ama approach relative entropy deriving neural network learning algorithms similar distance measure 
distance term minimized function somewhat analogous regularization terms neural network algorithms avoid overfitting hay 
discuss actual worst case bounds obtain gd sigma algorithms 
gd algorithm bounds cite cesa bianchi 
include bounds forms 
sigma algorithm give new bounds strictly better obtained littlestone algorithm 
particular bounds form littlestone bounds form 
importance considering algorithms gd sigma comes fact algorithms constants hidden notation quite different 
state exact bounds recall positive norm vectors defined jjxjj jx delta delta delta jx generalized setting jjxjj max jx bounds follow hold square loss omit mentioning loss function 
assume trial sequence satisfies jjx jj known constant arbitrary 
gd algorithm setting learning rate suitably results bound loss gd loss jjujj holds vectors 
coefficient front loss equal obtain bound form algorithm needs trial reasonably estimates characteristics trial sequence 
estimates help algorithm set learning rate addition bound algorithm need bounds vector norm loss algorithm trial values parameters bound loss gd loss jjujj holds weight vectors trial sequences loss jjujj hold jjx jj holds parameters low values bound vacuous conditions satisfied hand parameters overly conservative bound loose 
possible obtain satisfactory values parameters trial cases possible apply iterative scheme obtaining increasingly accurate estimates trial sequence proceeds 
leads bound similar slightly larger constant coefficients 
sigma algorithm necessary give parameter upper bound norm vectors comparison class 
assuming instances trial sequence bounded norm jjx jj known constant bound loss sigma loss ln holds jjujj gd algorithm additional knowledge trial sequence helps algorithm choose learning rate accurately 
addition algorithm parameter achieves bound loss sigma loss ln ln comparison vectors trial sequences jjujj loss hold jjx jj holds note dual norms roy 
norm comparison vectors norm instances bounds sigma algorithm dual 
norm comparison vectors instances bounds gd algorithm dual 
show different pairs dual norms upper bounds gd sigma algorithms result certain situations radically different behavior large simplicity consider case perfect linear relation instances outcomes comparison vector satisfies loss 
take bounds 
assume parameters set optimally write max jjx jj 
bound simplifies loss gd jjujj bound loss sigma jjujj ln clarity consider extreme cases 
assume exactly components value rest gamma components value 
input variables relevant prediction task 
assume instances set gamma vertices dimensional cube 
jjujj jjujj 
bounds loss gd kn loss sigma ln ae sigma algorithm clearly better bound 
hand instances rows theta unit matrix 
jjujj jjujj 
bounds loss gd loss sigma ln gd algorithm clearly better bound 
bounds gd sigma incomparable large difference arbitrarily large direction 
simplified scenario generalized 
input variables relevant predicting outcomes input variables take values roughly equal magnitudes sigma algorithm better bound 
gd algorithm better bound input variables equally relevant predicting norms instances larger norms 
happens total weight instance vectors concentrated largest components 
remain similar comparison vector achieves loss case noise instances outcomes 
differences total losses algorithms pronounced pure situation 
preceding comparison purely worst case bounds relative merits algorithms confirmed experiments simple artificial data 
true noise outcomes 
experiments seen learning rates suggested worst case upper bound analysis quite close optimal ones 
particular observed number examples gd algorithm needs obtains accurate hypothesis roughly comparable number input variables input variables irrelevant prediction task 
sigma algorithm dependence number irrelevant input variables logarithmic doubling number irrelevant variables results constant increase total loss 
sigma algorithm strong bias hypotheses relevant variables 
variables needed prediction loss bound sigma grows sublinearly number variables 
gd algorithm biased hypotheses small norm variables relevant uses dimensions futile search predictor small norm 
feel situation favors sigma algorithm natural arise practice 
linear predictors restricted natural extension expand instance including new input variables values suitably chosen basis functions linear prediction algorithm linear combination basis functions predictor 
example include products original input variables :10.1.1.103.1189
assuming input variables range gamma increase norms instances 
assume outcomes degree polynomial input variables terms constant coefficient 
loss bound sigma algorithm expansion instances log 
gd algorithm suffer fact expansion increases norms instances loss kn 
unfortunately expanding instances increases amount computations needed predictions updates 
worst case upper bounds powerful tool analyzing simple learning problems 
learning algorithms gd sigma directly applied feed forward neural networks 
gd algorithm leads back propagation algorithm 
sigma algorithm obtain neural network algorithm uses gradient information backpropagation algorithm applies radically different manner 
expect differences behavior gd sigma algorithms linear neuron carry feed forward neural networks prove worst case bounds complicated setting 
single neurons worst case bounds obtained 
define basic notation section 
main algorithms introduced section derivations various distance measures section 
section prove worst case upper bounds losses algorithms 
section section high level description approach technical application ideas various algorithms follows 
section gives related lower bound results 
section show algorithm upper bound proofs modified generalized scenario algorithm required predictions 
section contains brief discussion converting worst case total loss bounds expected instantaneous loss bounds 
experimental comparisons algorithms described section 
quickly get idea main results reader skim definitions section descriptions algorithms section go section comparison theoretical empirical results different algorithms 
section important gaining intuition algorithms 
important theoretical results section 
preliminaries line prediction algorithms function follows 
trial algorithm receives instance producing prediction algorithm receives outcome feedback 
performance algorithm trial measured terms loss function assigns nonnegative real loss possible pair property compact notation define 
particular write fixed value 
default loss function square loss gamma commonly loss function predictions outcomes interval entropic loss function ln gamma ln gamma gamma 
follow standard convention ln 
technically line prediction algorithm mapping maps sequence gamma instance outcome pairs new instance prediction gamma gamma 
consider line prediction algorithms represent information retain trials gamma weight vector predict delta weight vector considered algorithm linear hypothesis 
initial weight vector parameter algorithm 
trial algorithm updates previous weight vector account instance outcome discuss various update rules 
total loss sequence loss define total loss weight vector loss delta omit subscript square loss gamma gamma goal algorithms loss loss low possible trial sequences 
obviously knowledge trial sequence give useful guarantees loss 
set reasonable goal algorithms consider loss inf loss best linear hypothesis class weight vectors 
quantity loss gamma inf loss additional loss algorithm compared weight vectors class seek algorithms provable upper bounds additional loss hold arbitrary sequences call set comparison class vectors comparison vectors 
call particular comparison vector small loss target vector 
prove bounds additional loss usually need assumptions norms comparison vectors instances appear trial sequence observe infimum measures linear model sequence advance 
line learner sees example time additional loss infimum measures price algorithm pay seeing sequence advance 
positive real norm vectors defined jjxjj jx delta delta delta jx case jjxjj jx case euclidean length jjxjj vector norms norm jjxjj max jx obtained limit definition approaches 
various measures distance weight vectors applying distance measures shortly usually take comparison vector hypothesis algorithm trial 
general distance measure function mapping theta nonnegative reals way holds basic distance measures squared euclidean distance sq defined sq jju gamma distance measures defined particular subset relative entropy distance measure defined vector probability vectors means components nonnegative sum 
probability vectors relative entropy re defined re ln note allow components zero case usual convention ln 
re 
shown re nonnegative uniform probability vector probability vectors re ln gamma quantity gamma ln called entropy weight vector probability vector satisfies ln re ln uniform vector generalize relative entropy removing requirement components sum keeping requirement components vectors nonnegative 
define unnormalized relative entropy reu reu gamma ln note reu re holds probability vectors 
easy see reu holds vectors equality holds consider distance measure defined gamma gamma second equality assuming 
function gamma ln second order taylor expansion gamma gamma measure considered approximation measure reu 
ln gamma easy see re holds probability vectors note distance measures discussed satisfies triangle inequality exception squared euclidean distance sq distance measures symmetric 
squared euclidean distance sq clearly sq sq properties hold distance measures reu vectors restricted nonnegative components re restricted probability vectors 
see helmbold plots visualize distance measures probability vectors dimensional case 
algorithm gdl parameters loss function theta start vector learning rate 
initialization trial set prediction receiving tth instance give prediction delta update receiving tth outcome update weights rule gamma jl gradient descent algorithm gdl 
main algorithms section introduce main line prediction algorithms consider 
section give motivation shows algorithms naturally arises approximate solution certain minimization problem 
number additional algorithms introduced section 
algorithms share basic structure 
algorithm maintains weight vector considered algorithm guess linear predictor 
denote weight vector algorithm trial weight vector contains information algorithm retains trials gamma 
algorithm starts setting initial weight vector start vector seeing tth outcome algorithm updates weight vector update rule 
value new weight vector depends old weight vector instance prediction outcome learning rate exact dependence called update rule algorithm 
difference various algorithms different update rules 
learning rate may different different trials usually keep fixed 
prediction seeing instance trial delta algorithms 
small exception algorithms predictions restricted fixed interval value delta fall outside interval prediction closest value inside interval 
gives algorithm call gradient descent algorithm denote gdl recall notice ith component gradient rw delta delta deltax delta gradient descent algorithm updates weight vector subtracting gradient rw delta multiplied scalar gd algorithm seen straightforward application usual gradient descent minimization method line prediction problem 
gd denote algorithm gdl case loss function square loss function gamma algorithm gd names including widrow hoff algorithm mean square lms algorithm ws 
update gd simply gamma gamma start vector algorithm arbitrary 
typically choose 
trial sequence proceeds individual weights reach arbitrarily high low values 
algorithm parameters loss function theta start vector learning rate 
initialization trial set prediction receiving tth instance give prediction delta update receiving tth outcome update weights rule exp exponentiated gradient algorithm 
typical learning rate estimated upper bound largest norm max jjx jj instances 
theorem give theoretical results proper choice resulting performance gd 
general heuristic learning rate low expected example noise linear predictor loss low 
learning rate high expected linear predictors distance jju gamma sjj start vector large 
consider particular method letting learning rate gd vary trials 
name algorithm gd update replaced gamma jjx jj gamma variable learning rate algorithm particular interest assumed delta holds fixed unknown vector turn main new algorithms 
simpler 
call exponentiated gradient algorithm 
update weight multiplied factor obtained exponentiating ith component delta delta gradient rw delta 
multiplication weights normalized shown sum 
weights clearly change sign 
weight vector probability vector satisfies prediction delta weighted average input variables gives relative weights components weighted average 
contrast gd algorithm total weight jjw jj change 
fact weight vector probability vector clearly restricts abilities learn general linear relationships 
shall soon see restrictions avoided simple reduction 
gd algorithm algorithm loss function start vector learning rate parameters 
loss function square loss function denote simply 
square loss gamma gammay assume start vector satisfies usual choice uniform probability vector 
typical learning rate upper bound maximum difference max max gamma min components instance analogously gd algorithm algorithm low learning rate probability vector assumed predictor high learning rate assumed predictors distance re start vector large 
uniform vector distance largest nonuniform vectors having maximum value ln vector detailed results choice learning rate resulting total loss theorem 
proceeding second main algorithm give simplified alternative update rule algorithm 
alternative benefit avoiding exponential function possibly saving computation time 
name approximated algorithm obtained algorithm replacing update gamma jl gamma see approximated update arises note order taylor approximation close gamma gamma 
replacing exponentials right hand side approximation jl obtain gammaa gamma gamma gammaa gamma gamma get noticing gamma denominator right hand side equal gammaa admittedly may somewhat arbitrary center taylor approximation shall see subsection update rule motivation approximating 
noticed applying exponentiated gradient update certain unsupervised learning problem approximation leads generalization expectation maximization algorithm dlr 
note update rule maintains invariant 
may weights zero negative 
weight gets set recover multiplicative nature update problem 
way ensure weights remain positive update enforce learning rate satisfies gamma gamma indices quantity right hand side positive 
preliminary experiments performed performance approximated hardly distinguishable real problem weights going zero 
difficulties may arise complicated situations 
second new algorithm call exponentiated gradient algorithm positive negative weights sigma 
sigma algorithm best understood way generalize algorithm general weight vectors reduction 
trial sequence modified trial sequence obtained replacing instance ux gammau gammau xn 
number algorithm sigma gamma parameters loss function theta total weight weight vectors gamma pair start vectors gamma learning rate 
initialization trial set gamma gamma prediction receiving tth instance give prediction gamma gamma delta update receiving tth outcome update weights rules delta gamma gamma gamma delta gamma gamma gamma gamma exp ux gamma exp jl ux exponentiated gradient algorithm positive negative weights sigma gamma 
dimensions doubled 
start vector pair gamma sigma gamma gamma 
consider sigma gamma trial sequence modified trial sequence tth weight vector trial sequence easy see uw gamma gamma holds delta gamma gamma delta predictions sigma identical sigma result applying simple transformation 
transformation leads algorithm effect uses weight vector gamma gamma contain negative components 
scaling factor weight vector gamma gamma range vectors jjwjj jjw jj jjw gamma jj exactly vectors gamma gamma jjw gamma gamma jj result simply having gamma examples reductions type see littlestone 
parameters sigma loss function scaling factor pair gamma start vectors gamma learning rate simply write sigma sigma square loss function 
start vectors sigma typically gamma 
gives gamma gamma 
typical learning rate function estimated upper bound maximum norm max jjx jj instances 
detailed theoretical results theorem 
introduce particular variable learning rate version sigma name sigma algorithm sigma replaced exp gamma jjx jj gamma ux gamma exp jjx jj gamma ux sigma turns interesting noise free case delta algorithm replace exponential functions update rule sigma suitable approximation 
soon see leads update rule gamma jl gamma gamma gamma gamma jl gammax gamma call resulting algorithm approximated sigma algorithm 
approximated algorithm guarantee weights remain positive learning rate satisfy gamma gamma right hand side positive gammax gamma gamma right hand side positive 
order derive updates approximation gamma gamma jl gammax gammaa gamma gamma gamma gammaa gamma gammax gamma 
observing gamma gamma gamma see approximated sigma algorithm denominator right hand side gamma gamma gammaa ay gamma gamma gamma gamma gammaa follow easily 
derivation updates basic method section give common motivation algorithms gd introduced section additional algorithms 
consider algorithm trial weight vector 
trial algorithm receives instance gives prediction delta receives outcome algorithm updates weight vector choosing new weight vector main considerations 
algorithm learn trial 
instance outcome observed loss delta algorithm new weight vector smaller loss delta old weight vector 
call tendency improve prediction example second algorithm remember part learned preceding trials 
information algorithm retained preceding trials contained weight vector new weight vector close old weight vector measured distance measure 
call tendency remain close old weight vector conservativeness conservativeness requirements usually odds algorithm needs compromise 
way algorithm obtain compromise minimize function jl delta coefficient importance relative conservativeness 
close minimizing close merely minimizing algorithm tends small updates 
limit approaches infinity problem minimizing approaches problem minimizing subject constraint delta 
expect instances outcomes algorithm subject noise unreliable choose small value prohibits algorithm making radical changes single trial 
minimize need set partial derivatives zero 
delta delta means finding value satisfies jl delta solving general difficult 
replace delta delta get equation jl delta turns easy solve distance measures consider 
update small new weight vector close old weight vector replacing delta delta leads gives reasonable approximation 
apply algorithms update rules result solving various distance measures helmbold give alternative motivation 
recall goal minimize solving minimization problem exactly difficult delta depend simplify dependence delta approximate delta order taylor polynomial respect words minimizing minimize approximation defined delta delta delta gamma equation simplifies 
course approximating solving minimization problem exactly apply numerical method directly find approximate minimum clear results better prediction performance certainly computations complicated 
view meaning minimizing assume unique weight vector minimized write delta 
real number depends approaches relative importance delta increases approaches 
easy see unique solution constrained problem minimizing subject delta optimal weight vector seen obtained moving region low loss defined condition delta shortest possible route 
large values value close new weight vector required correct received instance outcome 
small values value slightly delta weight vector small corrective movement 
approach updating weight vector similar methods introduced amari ama ama general neural network learning problems 
subsections derive updates method described distance measures sq re reu particular distance measure re wish guarantee additional property 
usual method introducing lagrangian multiplier fl 
minimizing minimize defined fl delta delta delta gamma fl gamma setting partial derivatives zero gives equations jl delta fl additional equation additional constraint needed solve equations apply obtain value fl 
gradient descent algorithms gradient descent algorithm gdl obtained squared euclidean distance sq distance measure 
case equations result update gamma jl delta update rule gdl algorithm 
note loss function square loss gradient descent update gamma delta gamma square loss euclidean distance squared minimize directly making approximations 
case gamma delta gamma solve delta dot product sides delta substituted back gets gamma delta gamma minimizing gives update minimizing learning rate parameter changed manner independent squared euclidean distance constraint weights sum obtain algorithm gpl known gradient projection algorithm lue 
case equation implies gamma jl delta gamma fl substituting assumption obtain fl delta avg avg substituting back gives update rule gamma jl delta gamma avg gpl algorithm 
introduce gpl purpose comparison new algorithm maintains constraint weight sum 
new algorithm keeps weights positive 
keep weights gpl positive setting suitable upper bound learning rate approximated sigma algorithms section 
exponentiated gradient algorithms relative entropy distance measures reu re measures assume weight vectors non negative components re requires components weight vectors sum 
substituting reu gives ln jl delta solving obtain update rule exp delta call algorithm update rule exponentiated gradient algorithm unnormalized weights denote update rule algorithm update rule normalization update rule assuming components nonnegative components updated updated weight vector nonnegative 
nonnegativity constraints preserved update 
consider distance measure re requires constraint 
case equation ln jl delta fl obtain exp delta gamma gamma fl exp gammafl gamma exp delta applying obtain exp gammafl gamma gamma update rule note update rule keeps weights positive weights positive 
approximated exponentiated gradient section introduced simple approximation update rule algorithm 
show motivate update rule approximated algorithm starting directly distance measure gd algorithms 
approximated algorithm interest right 
distance measure motivate approximated algorithm 
noted section approximates reu close 
look restricted case 
case obviously approximate re 
distance function equation gamma jl delta fl solving fl gives get gamma jl delta gamma delta update rule approximated algorithm 
nonnegativity weights guaranteed bound learning rate requiring delta gamma delta gamma hold delta gamma delta positive 
update multiplicative component zero stay zero 
allow set 
measure sums necessarily 
omitting normalization constraint previous derivation gives update rule gamma jl delta approximation update rule algorithm 
simple unsupervised learning problem learning mixture coefficients noticed distance measure motivate generalization expectation maximization em optimization method 
summary seen different ways arriving approximated algorithm 
approximate exponential function update rule 
second distance measure approximation relative entropy re derive algorithm manner relative entropy derive algorithm 
approximation step derivations sections prove learning algorithms preceding motivations perform square loss 
prove worst case square loss bounds algorithms introduced section approximated versions exponentiated gradient updates 
experimental results suggest approximated version exponentiated gradient updates behave closely actual exponentiated gradient updates see subsection 
unable prove worst case loss bounds expressed function loss best linear weight vector loss functions square loss 
fact reason believe step evaluating derivative delta delta may lead bad results particularly loss function unbounded 
example relative entropy loss 
gamma gamma gamma value changes dramatically approaches 
prediction delta close value delta may close value delta relatively close 
approximation derivation algorithms may inaccurate 
see possible consequences algorithms questionable approximation consider algorithm relative entropy loss simple dimensional case gamma delta approaches remains fixed say value exp approaches remains 
write gamma weight vector update see approaches approaches 
similarly approaches approaches 
stage trial sequence weight vector get close consequent updates cause weight vector oscillate wildly outcomes remain constant 
eventually leads arbitrarily large losses algorithm fixed linear predictor small loss 
believe linear prediction relative entropy loss unbounded loss functions better prediction results obtained solving minimization problem numerically 
results 
obviously numerical solving increase computational cost algorithm 
worst case upper bounds total loss basic method introduce basic method proofs worst case upper bounds losses line prediction algorithms 
method abstraction proof method employed littlestone lit lit 
subsequent subsections show basic idea applied specific algorithms introduced section 
succeeded application square loss function hope applicable loss functions 
simpler situation learner trying learn linear function merely pick best single component instances predicting outcomes possible similar approach prove bounds general class loss functions 
noted section algorithms motivated applying distance measure weight vectors maintained algorithms 
distance measures useful proving worst case loss bounds 
role similar potential functions amortized algorithm analysis clr 
sequence weight vectors produced algorithm dimensional trial sequence tth prediction delta holds algorithms consider special cases constrain range convenience assume algorithm update trial resulting weight vector predicting 
distance measure loss function 
weight vector say gamma amount progress algorithm trial negative progress means moving away naturally domain distance measure instance satisfy re 
single trial expect algorithm positive progress vectors accurate prediction negative progress vectors predicted inaccurately 
reflected motivation algorithms goal move weight vector weight vectors exactly correct prediction 
sequence trials expect net effect algorithm positive progress vectors total loss loss relatively small negative progress vectors total loss loss relatively large 
consider special case particular vector delta loss 
say target vector algorithm try find 
require progress target trial proportional loss algorithm trial specific way saying algorithm learn mistakes 
generally wish allow situation loss holds obvious target vector algorithm try approach 
require trial weight vectors progress algorithm gamma bl delta positive coefficients algorithm large progress weight vectors predicted accurately algorithm 
try establish bounds form gamma bl delta gamma require hold weight vectors consider possible targets 
proving bounds form main technical problem 
get tightest bound wish large small possible 
trade positive value largest value prove 
turns convenient introduce new parameter functions values take largest value prove 
obtain learning rate set particular manner depends value bound total loss algorithm follows adding bounds yields loss gamma loss gamma gamma 
loss loss note holds possible weight vectors naturally get best bound small loss close start vector 
final step proof choose value minimizes right hand side gives tightest bound 
functions obtain proofs case approaches ratio approaches approaches infinity goes infinity ratio goes infinity approaches positive constant 
larger loss loss compared distance smaller value wish 
particular functions choosing optimal way gives bounds form loss inf loss loss coefficients depend norms instances learning rate achieved depends bound obtained choosing estimates loss suitable target directly obtain bound absence estimates 
estimates known trial sequence begins situations possible iterative method commonly known doubling technique obtaining increasingly accurate estimates trial sequence proceeds modifying learning rate accordingly 
leads bounds form slightly worse constant coefficients 
possibility settle weaker bounds form loss inf loss coefficient leading term loss 
weaker bounds achieved additional knowledge 
worst case loss bounds gd subsection give streamlined version worst case analysis gd algorithm 
analysis originally cesa bianchi 
start bounding loss algorithm single trial terms loss comparison vector trial progress algorithm lemma weight vector gd trial trial sequence arbitrary 
arbitrary jjx jj values learning rate satisfies gamma delta gamma gamma delta jju gamma jj gamma jju gamma jj values jjx jj learning rate trial sequences vectors hold 
proof write gamma delta gamma delta jp jju gamma jj gamma jju gamma jj gamma jp delta gamma delta gamma jjx jj gamma jp gamma gamma equality holds jjx jj prove sufficient show jp gamma ap gamma bq jjx jj necessary condition 
second degree polynomial positive easily see fixed value maximized jp sufficient show jp gamma easily see fixed value minimized choose 
optimal choice get ab gamma holds 
values easily construct trial sequence vector gamma delta gamma delta hold shows hold jjx jj simple lemma shows repeated application lemma trials sequence gives total loss bound 
introduce new parameter purpose choosing values applications lemma 
lemma arbitrary trial sequence 
arbitrary parameter upper bound jjx jj holds start vectors comparison vectors loss gd loss jju gamma sjj proof 
tth weight vector gd trial sequence holds lemma gamma delta gamma gamma delta jju gamma jj gamma jju gamma jj adding bounds get loss gd gamma jju gamma jj gamma jju gamma jj jju gamma jj equivalent 
show final loss bounds obtained choosing parameter lemma appropriately 
knowledge relative magnitudes loss loss comparison vector product jju gamma sjj choose way coefficients quantities 
estimates quantities obtain tighter bound choosing way larger quantity gets smaller coefficient 
theorem trial sequence upper bound jjx jj holds learning rate arbitrary start vector vector bound loss gd loss jju gamma sjj arbitrary constants learning rate satisfy ux loss jju gamma sjj hold loss gd loss jju gamma sjj note second bound vacuous loss jju gamma sjj typical start vector gd 
start vector upper bound norm proof apply lemma 
value bound gives 
bound holds learning rate required 
obtain notice satisfy assumptions theorem bound implies loss gd loss jju gamma sjj ck 
assume 
gamma ux 
value minimized ux 
substituting value yields 
special case loss right hand side limit jju gamma sjj approaches infinity 
denote learning rate 
lemma implies lim loss gd jju gamma sjj lim 
loss loss gd continuous function learning rate obtain loss gd lim loss gd jju gamma sjj results claim 
perform simple dimension check see learning rates theorem extent meaningful 
assume instance input variables represent times measured seconds outcomes represent lengths measured meters 
unit predictions delta meter unit weights meter second 
generally dimension input variables dimension outcomes 
dimension weights gamma 
considering update rule see dimension learning rate gamma dimensions gamma respectively see case 
true terms right hand side bounds dimension loss algorithm note analysis assumes input variables dimension 
case change unit measure certain input values keeping units unchanged behavior algorithm changed 
recall mean algorithm works gd learning rate replaced jjx jj words update rule replaced 
see algorithm particularly suited prediction losses trial suitably scaled 
consider measuring loss trial gamma jjx jj loss denote loss algorithm comparison vector trial sequence measured scaled square loss 
trial sequence consider modified trial sequence jjx jj jjx jj gamma jjx jj delta gamma jjx jj jjx jj delta gamma jjx jj loss loss note equivalent gamma delta gamma implies weight vectors trial sequence weight vectors gd trial sequence loss gd loss gd 
theorem applied trial sequence jjx jj gives corollary 
corollary arbitrary trial sequence 
arbitrary start vector comparison vector loss loss jju gamma sjj arbitrary constants learning rate loss jju gamma sjj hold loss loss ku jju gamma sjj algorithm applied situation assume trial sequence noise free delta theorem arbitrary consider trial sequence delta holds loss jju gamma sjj max jjx jj start vectors proof arbitrary parameter tth weight vector trial sequence applying lemma jjx jj jjx jj assuming delta get jjx jj gamma delta jju gamma jj gamma jju gamma jj tth weight vector trial sequence considering limit approaches see gamma delta jjx jj jju gamma jj gamma jju gamma jj particular jju gamma jj gamma jju gamma jj get gamma delta max jjx jj jju gamma jj gamma jju gamma jj adding inequalities observing jju gamma jj get 
worst case loss bounds gp subsection show worst case upper bounds square loss gd algorithm imply similar bounds gp algorithm uses update rule 
avg avg denote dimensional vector component value avg 
square loss update rule gamma gamma gamma avg delta new weight vector satisfies gp algorithm uses start vector algorithm maintains invariant trials consider applying algorithm gp trial sequence 
define modified trial sequence gamma avg gamma 
easy see weight vectors algorithm gd trial sequence weight vectors algorithm gp algorithm trial sequence tth prediction gp trial sequence tth prediction gd trial sequence gamma 
loss gp loss gd 
applying theorem obtain bounds 
corollary trial sequence upper bound jjx gamma avg jj holds learning rate arbitrary start vector vectors bound loss gp loss jju gamma sjj arbitrary constants uv loss jju gamma sjj hold loss gp loss kuv jju gamma sjj values concentrated close average value avg average values avg large know value comparison vectors wish gp algorithm additional knowledge incur lower loss gd algorithm 
gd algorithm define gp variant variable learning rates 
update rule gamma jjx gamma avg jj gamma gamma avg upper bound 
theorem consider trial sequence delta holds loss jju gamma sjj max jjx gamma avg jj worst case loss bounds subsection give worst case upper bounds loss algorithm derived section relative entropy distance measure 
similar bounds earlier proven littlestone algorithm related analogous derivation 
bounds lower littlestone particular bounds form unobtainable algorithm littlestone start proving upper bound loss algorithm single trial terms loss comparison vector progress algorithm trial 
lemma weight vector trial trial sequence vector 
consider arbitrary trial upper bound max gamma min constants learning rate gamma delta gamma gamma delta re gamma re proof fi gamma fi fi re gamma re ln ln fi gamma ln fi equivalent delta delta fi fn fi ln fi gamma ln fi gamma gamma gamma fi gamma holds gamma bound ff gamma gamma ff holds ff tight 
applying ff fi obtain fi fi fi gammab fi gamma gamma gamma fi gives ln fi ln fi ln gamma delta gamma gamma fi 
get fn delta fi delta fi fi ln fi ln gamma gamma gamma fi gamma ln fi gamma gamma gamma note inequality tight instance 
obtain sufficient show fi holds values fi gammay 
fi gamma value fi maximized fi 
solving gives gamma ln fi 
particular fi gammay see proving gammay gamma implies gammay values gamma gammay jb gamma ln gamma gamma gamma jr gammay gamma jy gamma gamma remains show 
apply bound ln gamma gamma pq holds lemma 
get jb gamma jr gamma gamma jr gamma gamma jy gamma gamma gamma gamma bj ab remains show gamma bj ab 
easily see minimized value 
gd algorithm combine bounds individual trials give bound total loss algorithm 
introduce parameter chosen suitable way balance terms loss bound 
lemma arbitrary trial sequence upper bound max gamma min holds arbitrary positive constant 
start vector comparison vector bound loss loss re proof 
tth weight vector trial sequence holds lemma gamma delta gamma gamma delta re gamma re adding bounds get loss gamma re gamma re re equivalent 
obtain actual loss bounds algorithm choosing suitable value lemma 
simplest way balance terms proportional loss comparison vector distance re 
estimates quantities careful analysis trade obtain tighter bound 
theorem trial sequence bound max gamma min holds 
start vector comparison vector bound loss loss re arbitrary constants additionally loss re hold loss loss kd re typically apply start vector 
case re ln gamma gamma ln entropy entropy positive re ln proof apply lemma 
choice bound simplifies bound achieved applying learning rate 
loss re implies loss loss re kc assume 
gamma value minimized substituting value yields 
special case follows considering limit approaches 
gd algorithm simple dimension analysis provides crude check learning rates theorem 
note due update weights algorithm dimensionless 
natural consequence requiring sum 
predictions dimension input variables outcomes dimension 
denote common dimension 
dimension learning rate gamma order exponent update factor gamma dimensionless 
true learning rates theorem quantity dimensionless quantities dimension 
note requires start vector hypotheses probability vectors 
doubling number components allow negative weights 
resulting algorithm sigma main competitor standard gradient descent algorithm gd 
sigma algorithm requires parameter comparison vectors jjujj arbitrary weight vector 
define weight vectors positive weights gamma setting gamma gammau 
gamma gamma instance vector define gamma gamma xn gammax gammax delta delta dimensional vector positive weights represents linear function assumed instances duplicated dot product weight vector 
vector defined jju jj jjujj wish define weight vector jju jj jjujj simply set gamma jjujj distribute excess weight gamma jjujj uniformly components distribute excess weight nonuniformly 
need maintain relations gamma weight vector jjujj say vector norm representation jju jj gamma see reduction obtain upper bound loss sigma algorithm positive negative weights known upper bounds algorithm 
theorem trial sequence bound jjx jj holds arbitrary weight vector jjujj arbitrary norm representation gamma theta pair start vectors gamma gamma 
learning rate loss sigma loss re positive constants ux weight vectors norm representations loss re hold loss sigma loss ux kd re finding norm representation minimizes relative entropy re nontrivial 
uniform start vector relative entropy ln ln leads reasonable bounds 
proof define new trial sequence setting ux ux gammau gammau 
algorithm sigma defined way predictions produced sigma trial sequence produced trial sequence particular loss sigma loss 
note loss loss max gamma min jjx jj bound learning rates achieve bound follow directly corresponding part theorem 
obtain apply lemma trial sequence comparison vector ux bound yields loss sigma loss re bound follows choosing 
resulting learning rates satisfies 
check dimension learning rates dimension input variables outcomes 
dimension weights parameter gamma 
update includes exponentiating value gamma ux value dimensionless means dimension learning rate gamma quantity theorem dimensionless quantity dimension case learning rates theorem 
recall defined algorithm sigma modification sigma replaced jjx jj update trial words formulas replaced 
gd situations obtain loss bounds sigma bounds sigma obtain upper bound scaled loss loss defined weight vector loss gamma delta jjx jj generalized define loss sigma obvious manner 
reduction analogous applied obtain corollary gives result 
corollary arbitrary trial sequence 
arbitrary vector bound jjujj arbitrary norm representation gamma theta start vector pair gamma gamma gamma 
loss sigma loss re arbitrary constants loss re hold loss sigma loss kd re second apply sigma noise free case 
theorem arbitrary vector bound jjujj arbitrary norm representation consider trial sequence delta holds gamma theta start vector pair gamma gamma gamma 
loss sigma max jjx jj re proof proof analogous proof theorem omit details 
worst case loss bounds consider algorithm introduced subsection 
algorithm uses multiplicative update similar algorithm 
difference algorithm algorithm total weight kept constant 
accordingly algorithm useful wish allow comparison vectors norm jjujj known 
algorithm able prove worst case loss bounds form case outcomes input variables positive comparison vectors positive components 
preliminary experiments suggest algorithm works input variables negative remains done 
proof necessary restrict range predictions outcomes 
give additional parameter algorithm understanding outcomes range 
write algorithm start vector learning rate function predicts delta delta holds 
usual start technical lemma 
lemma tth weight vector tth prediction trial sequence arbitrary 
consider arbitrary trial holds assume holds 
constants xy learning rate xy gamma delta gamma gamma delta reu gamma reu constants xy learning rate function weight vector comparison vector outcome hold 
proof 
estimate progress reu gamma reu fi fi 
reu gamma reu gamma ln fi gamma gamma ln fi applying bound ff gamma gamma ff holds ff ff fi obtain reu gamma reu fi gamma gamma ln fi delta fi gamma gamma delta ln fi substituting fi gamma see proving sufficient show delta delta xj gammay gamma gamma rj gamma gamma gamma gamma estimate ff gamma gamma ff tight case necessary show delta delta 
recall prediction algorithm delta delta holds need prove assumptions lemma clearly nonincreasing case condition follows holds 
loss generality consider differentiating respect see fixed value maximized gamma gamma note value gamma xj gammay gamma gamma jy gamma gamma obtain sufficient prove values statement lemma see hold necessary values satisfy conditions lemma 
see conditions sufficient main part claim 
xj gammay gamma gamma gamma jy gamma 
necessary condition having values close second derivative xj gammay gamma nonpositive need xy gamma range clearly maximized differentiating value minimizes seen xy 
value xy 
seen xy sufficient condition special case close proving condition sufficient general case show necessary claim lemma hold 
gamma small positive value 
supposing xy preceding argument shows holds 
value gamma positive 
nonzero instance find comparison vector weight vector delta delta case preceding argument delta delta 
choose particular instance bound holds equality delta delta implies hold trial 
xy see choices give explained preceding part proof sufficient proving lemma 
special case obtain gamma xy 
assume 
third derivative yx xj gammay strictly positive choices case imply xy xy gamma holds special case holds third derivative implies holds particular 
second derivative strictly negative function local maximum third derivative implies second derivative attain value 
function local maximum range zeroes derivative third local minimum zeroes second derivative 
obtains maximum value remains verify holds 
xj gamma gamma gamma xj gamma jy gamma gamma gamma je xj gamma xj gamma xj xj gamma gamma regardless choice get prove sufficient prove particular choices obtain xb gamma xb xy exp xb gamma xy holds algorithms gd combine single trial bounds lemma 
lemma consider trial sequence constants arbitrary positive constant xy 
start vectors comparison vectors bound loss loss xy reu proof xy xy xy 
tth weight vector trial sequence holds lemma gamma delta gamma gamma delta xy reu gamma reu adding bounds get loss gamma xy reu gamma reu xy reu equivalent 
show suitable values obtaining loss bounds lemma 
theorem consider trial sequence constants learning rate xy arbitrary start vector vector bound loss loss xy reu arbitrary constants kxy xy additionally loss reu hold loss loss xy reu proof apply lemma 
choice bound simplifies get xy 
loss reu assume 
implies loss loss xy reu kc gamma 
value minimized 
substituting value yields learning rate satisfies 
special case consider limits approaches infinity proof theorem 
check dimensions learning rates dimension input variables outcomes 
quantity gamma appears exponentiated update rule dimensionless dimension gamma gamma theorem dimension quantity gamma dimension learning rates satisfy condition 
lower bounds consider case instances target satisfy norm constraints jjujj jjx jj outcomes arbitrary 
recall norms dual 
norm dual norm dual norm 
norms dual cauchy schwartz inequality generalized show jjujj jjxjj imply ju delta xj ux roy 
theorem arbitrary line prediction algorithm arbitrary positive reals 
instance jjxjj outcome comparison vector jjujj trial sequence loss loss ux ux gamma gamma particular lim 
proof define potential target vectors un gamma un gamma gamma gammau instance vector xn gamma xn gamma 
jju jj jju gamma jj jjxjj delta gamma gamma prediction algorithm sees instance trial 
choose gamma gamma gammau xn gamma gamma gamma 
loss loss gamma loss get stated bound 
special case theorem noted cesa bianchi 
lower bound theorem case coincides upper bound theorem gd algorithm 
gd algorithm best obtainable worst case loss bound 
note theorem arbitrarily large making absolute value outcome arbitrarily large 
lower bound shows number dimensions arbitrarily large loss bound gd best possible range outcomes restricted 
comparison vector instances range outcomes gammau ux jjujj max jjx jj ux max delta jjujj jjxjj natural range outcomes 
theorem arbitrary positive reals dimension ux arbitrary line prediction algorithm 
comparison vector jjujj trial sequence gammax gammau ux loss loss ux ux consider lower bound theorem case related sigma algorithm 
lower bound upper bound sigma algorithm theorem includes factors re grow logarithmically large significant gap upper lower bounds 
know possible improve upper bounds eliminating ln factors 
general case success solving problem 
partial results hint upper bounds may reasonably tight 
consider upper bounds simpler algorithm bounds sigma obtained reduction 
able improve bounds improvement sigma automatically follow 
result littlestone shows case loss factor ln loss algorithm avoided 
simplicity consider case case loss lower bound results come close upper bound contain term proportional remains open question term avoided range outcomes gammau ux 
theorem positive integers arbitrary positive real arbitrary line prediction algorithm 
target vector trial sequence loss loss ln gamma ln ln gamma comparison vectors proof theorem contain components value rest components having value 
uniform vector re ln gamma ln theorem shows consider upper bounds form theorem constant coefficients theorem optimal 
leaves open possibility smaller coefficients obtained inserting example additive constant term 
theorem arbitrary prediction algorithm 
constants loss loss loss re qd re holds trial sequences weight vectors 
proof take instance sequence 
prediction trial weight vector violate assumptions theorem outcome 
consider gamma 
outcome trial 
loss loss hand re ln ln gamma ln gamma re 
case loss right hand side expanded re qd re hold small satisfy stated bounds 
batch predictions consider generalizing prediction problem setting trial prediction algorithm predicts batch instances receives outcomes instances 
generalized trial sequence sequence thetan define ith column tth instance matrix prediction algorithm generalized trial sequences defined usual trial sequences tth prediction vector measure loss algorithm need loss function theta 
consider square loss function defined jjy gamma yjj notions loss algorithm weight vector trial sequence defined obvious way 
algorithms introduced section converted generalized trial sequences straightforward manner 
predictions delta naturally replaced updates replace derivatives delta delta delta particular square loss generalization gd algorithm call gdm algorithm update rule gamma jm gamma generalization algorithm call algorithm update rule exp gamma gamma delta previously shown sw gdm algorithm loss bound similar gd 
recall norm jjajj matrix defined jjajj max jjxjj theorem generalized trial sequence jjm jj batch prediction algorithm gdm learning rate weight vectors bound loss gdm loss jjs gamma assume know bounds weight vector loss jjs gamma learning rate ux loss gdm loss ux jjs gamma proof theorem noticing proof theorem gd algorithm easily generalizes situations instances matrices vectors 
upper bound theorem shown tight sw 
give similar result algorithm 
proof reduction allows apply directly upper bound theorem algorithm 
easily generalize result general algorithm sigma applied matrices 
noise free case similar results littlestone 
reduction applied gd algorithm obtain theorem 
theorem generalized trial sequence norm ith column matrix jjm jj 
batch prediction algorithm learning rate comparison vector bound loss loss re assume know bounds loss re learning rate loss loss kd re proof prove theorem reducing upper bound theorem algorithm 
sequence weight vectors produces trial sequence define trial sequence trial sequence algorithm produces sequence weight vectors 
gamma jjm gamma jj delta gamma jjm gamma jj delta weight vector delta gamma gamma jjm gamma jj delta gamma applying get delta gamma jjm gamma jj delta gamma gamma delta defined gradients values 
weight vectors generated sequence weight vectors generated sequence get delta gamma jjm gamma jj loss loss 
applying get delta gamma gamma delta gamma jjm gamma jj jjm gamma jj loss loss 
jjm jj implies gammar applying upper bound theorem learning rate get loss loss loss re comparison vector 
assume loss re hold get loss loss loss loss kd re loss kd re learning rate 
obtaining expected instantaneous loss bounds far focus worst case bounds total loss line algorithms 
show worst case total loss bounds derive bounds expected total loss expected loss instance 
study simple probabilistic model 
seen proofs weaker probabilistic assumption lead similar bounds 
example pair consists instance outcome assume fixed unknown probability distribution example domain theta examples drawn independently random distribution 
bounds expected loss worst case sense assumptions distribution part section relies fact inequality form holds expectations sides get bound sd loss sd loss ed loss parameter learning rate optimized function upper bounds expected loss ed loss vector single example distance 
example case gd algorithm leads probabilistic version theorem 
theorem probability distribution jjxjj theta learning rate arbitrary start vector vector bound sd loss gd ed loss jju gamma sjj arbitrary constants learning rate ux ed loss jju gamma sjj hold sd loss gd ed loss jju gamma sjj cases interested worst case total loss bounds line algorithm looking hypothesis predicts random instance 
define hypothesis mapping instantaneous loss hypothesis respect distribution defined expected loss hypothesis predict random instance drawn common goal learning produce hypothesis small instantaneous loss seeing reasonable number examples 
case instantaneous loss measured respect distribution assumed training examples drawn independently random distribution 
giving sequence examples line predicting algorithm naturally leads hypothesis 
linear line prediction algorithms sequence interpreted trial sequence lead weight vectors defines hypothesis maps instance delta generally define tth hypothesis line prediction algorithm example sequence mapping maps instance prediction algorithm give tth instance instance outcome pairs gamma previous trials 
denote hypothesis gamma 
initial hypothesis obtaining hypothesis line prediction algorithm strategy give example sequence algorithm pick hypothesis examples 
additional information help learner think expected instantaneous loss hypothesis lower hypothesis gamma general earlier hypothesis 
formalized inequality gamma gamma gamma inequality necessarily hold algorithms 
trivial counterexample assume unique weight vector expected loss delta minimized 
start vector algorithm equal learning rate positive expected loss second hypothesis obviously higher initial hypothesis conclude section presenting simple method hw proving expected instantaneous loss bounds algorithms distributions 
rewrite expected total loss sd loss loss gamma gamma gamma ed loss gamma gamma gamma gamma hypotheses define randomized hypothesis hr follows 
give instance choose index uniform distribution prediction hr hypothesis prediction tth hypothesis 
definition hr preceding equality obtain gamma gamma sd loss hypotheses represented dimensional weight vectors 
ha denote average hypothesis represented average weight vector wa 
assume fixed value delta convex function reasonable assumption holds loss functions interested 
jensen inequality yields ha delta delta sigma gd target norms gd target norm smaller instance norms instance norm smaller norms increase schematic representation main factors affecting loss bounds gd sigma algorithms 
expectations drawn obtain gamma gamma gamma gamma equality seen crude method converting algorithm expected total loss bounded algorithm bounded instantaneous loss 
sophisticated conversion methods cesa bianchi littlestone lit 
experimental theoretical comparison algorithms comparison worst case upper bounds subsection compare worst case upper bounds gd sigma theorems 
considering upper bounds helps understand circumstances algorithms expected perform poorly 
perform experiments artificial data verify upper bounds give correct ideas actual behavior algorithms 
experimental setting described subsection experiments described subsections 
bounds theorems directly comparable terms different quantities 
algorithms bound form loss vector quantity depends distance start vector target vector norms instances 
simplicity replace discussion relative entropy re bound sigma upper bound ln gd algorithm jjujj max jjx jj sigma algorithm ln jjujj max jjx jj illustrates trade offs different norms bounds 
recall jjwjj jjwjj jjwjj tight inequalities depends vector sigma algorithm advantage gd algorithm instance side loss bound includes factor special cases equal factor loss bound gd 
similarly gd advantage target side factor bound gd exceeds factor bound sigma additional factor ln bound sigma favors gd 
products incomparable total effect favor gd sigma construct situation bound sigma large number dimensions better 
gd lose advantage target side choose 
advantage bound gd comes factor ln bound sigma maximize advantage sigma instance side take gamma gives maximizes ratio case upper bound ln loss sigma upper bound loss gd 
exaggerated setting leads similar results obtained choosing target nonzero components small gamma get noise free case bound ln sigma bound kn gd 
number gamma irrelevant variables large sigma advantage gd 
generally large part total weight jjujj concentrated components reasonably close gd small advantage target side 
subsection perform simple experiments situations just described 
see artificial random data actual losses algorithms compare predict analysis worst case upper bounds 
words random irrelevant variables confuse gd algorithm sigma algorithm 
number relevant variables kept constant loss gd algorithm grows linearly sigma algorithm growth logarithmic 
argued natural data irrelevant variables usually random 
propose applying algorithm nonlinear prediction problems expanding instances include values number basis functions see subsection details 
expansion small number truly random variables generates large number pseudorandom variables confuse gd algorithm 
show gd algorithm better 
instance vectors unit vectors direction coordinate axes 
sigma advantage instance side 
smaller possible choose minimizes ratio jjujj jjujj case upper bound gd upper bound sigma ln subsection study experimentally situation extreme variants 
see worst case upper bounds describe real behavior algorithms reasonably 
experimental setting theoretical results section derived worst case situations adversary may generate examples 
wish see theoretical results describe behavior algorithms examples chosen adversarially 
purpose consider simple artificial data 
generate instances drawing instance independently probability measure typical probability measures include uniform measure unit cube gamma uniform measure set gamma vertices unit cube uniform measure unit sphere jjxjj choose target suit particular experiment wish perform 
generate actual outcomes take values delta predicted weight vector add random noise 
quantify amount noise noise rate fl roughly gives error ju delta gamma fraction delta max ju delta scaling factor gives range predictions delta tth outcome chosen uniformly delta gamma flc delta flc 
run algorithms example sequence plot cumulative losses gamma various algorithms 
recall algorithms gd gp sigma variants sigma suggested theorems variable learning rate algorithms noise free case fl norms instances 
course say jjx jj difference gd just gd 
experiments artificial data 
experiments unusual way 
merely compare actual performances algorithms particular artificial data 
compare actual losses algorithms worstcase upper bounds 
cases loss bound larger loss bound typically see actual loss larger loss bound need experiments show performs taken care proving worst case loss bound point show simple artificial data competing algorithm exceeds worst case bound worst case bounds depend distance start vector target vector measured distance measure total loss target vector assumptions distributions instances noise mechanism 
consider data different instance distribution noise process target total loss target loss stay upper bound 
loss low 
represent experimental results showing cumulative loss curves typical experiments 
words plot cumulative loss algorithm trial function noted actual numerical values cumulative losses algorithms important 
experiments meant demonstrate changing target instances differences losses various algorithms arbitrarily large direction 
recall discuss forms upper bounds 
need little information bounds form 
sophisticated upper bounds form learning rates algorithms achieve bounds need number parameters parameter bounds norm target vector bounds norm instances bounds loss target bounds distance start vector target practice quantities usually known methods obtain learning rate 
parameters unknown strategies guessing value increasing accuracy 
strategies lead loss bounds form coefficient somewhat larger ones obtained theorems values parameters known 
experiments knowledge target set parameters optimally tune learning rate function optimal choices 
want difficulties choosing learning rates hinder fair comparison algorithms 
turns learning rates theorems experiments reasonably close best possible ones 
applying learning algorithm usually concerned cumulative loss quality final hypothesis 
experimental setting wish trials gd cumulative losses gd solid line sigma dotted line upper bounds instances gamma target gamma gamma 
hypotheses algorithm converge target vector shown section bounds rate convergence obtained worst case total loss bounds 
experiments performed noticed algorithm smaller cumulative loss usually converges faster 
methods particular choosing learning rates various algorithms designed convergence mind 
consequently possible approach result different algorithms better convergence 
particular wish initially high learning rate order quickly get close target decrease learning rate order decrease oscillations target cause noise 
improve convergence averaging hypothesis 
considerations scope 
sparse target instances unit cube consider situations analysis subsection suggests sigma better 
shows cumulative losses gd sigma algorithms typical experiment sparse target instances gamma number dimensions target chosen gamma gamma 
instances chosen uniformly gamma 
start vectors gd zero vector 
sigma set parameter components start vectors effectively starts sigma zero vector 
re ln 
noise rate set upper bounds obtained theorems delta gd delta ln sigma shows actual cumulative losses experiment respective upper bounds 
special case noise loss target learning rates suggested theorems experiment depend instances target outcomes 
see algorithms upper bound reasonably tight 
experiments observed typically cumulative loss gd approaches upper bound length trial sequence increases 
actual loss gd clearly higher worst case loss bound sigma loss curve sigma gd turns horizontal hypothesis algorithm converges target loss 
shows results experiment similar moderate amount noise 
noise rate fl set 
knowledge distance start vector target total loss target vector examples calculating learning rates worst case upper bounds loss 
notice worst case upper bounds tight performances algorithms compared similar observed noise free case 
due presence noise loss curves turn horizontal approach positive constant slope 
experiment illustrates behavior gd algorithm instances orthogonal 
square matrix components gamma hadamard matrix rows orthogonal 
take instance gamma mod st row hadamard matrix 
take target set noise rate 
cumulative losses algorithms shown 
special case instances xn orthogonal noise weight vector algorithm learning rate squares solution possibly underdetermined system equations delta solution norm 
applying linear squares prediction line manner situation results large loss shown gd 
generally shown algorithm uses weight vectors form smaller loss situation 
class algorithms includes basic variant weight decay additional jjw jj error term penalty large weights hin 
commonly accepted heuristic number examples needed learn linear functions roughly proportional number dimensions instances 
results contradict way 
number examples required sigma algorithm learn smaller number dimensions target functions nonzero components 
gd algorithm take advantage outperformed sigma experiments figures relevant ones input variables 
number relevant components increased keeping values relevant weights equal losses gd sigma approach 
relevant components losses algorithms roughly 
number relevant components increased gd algorithm outperforms sigma algorithm clearly 
forms loss bounds gd sigma expect sigma perform components target zero weight concentrated components jjujj larger jjujj dense target instances unit sphere consider case target dense sense component instance affects value delta dimensions choose target 
choose instances uniformly dimensional unit sphere jjxjj jjx jj cumulative losses gd sigma respective upper bounds plotted noise rate 
gd algorithm clearly outperforms sigma algorithm expect discussion subsection 
trials gd cumulative losses gd solid line sigma dotted line upper bounds instances gamma target gamma gamma noise rate 
trials gd cumulative losses gd solid line sigma dotted line upper bounds target rows hadamard matrix instances 
trials gd cumulative losses gd sigma upper bounds target instances dimensional unit sphere 
trials gd cumulative losses gd sigma upper bounds target rows unit matrix instances 
trials learning rate factor cumulative loss gd learning rate multiplied 
difference gd sigma algorithms clear possible consider nonrandom data 
choose instances going order rows theta unit matrix 
instance gamma mod 
target noise rate 
results depicted 
gd algorithm learns correct weight trial achieves perfect performance trial variants algorithms shows cumulative losses gd algorithm experiment slightly differing learning rates 
see algorithm robust respect small trials cumulative losses sigma instances target 
deviations learning rate learning rate obtained theorem close optimal 
algorithm additional information target vector performance improve 
section considered particular restriction 
discussed section incorporating restriction gd algorithm leads gp algorithm 
restrict weights gp nonnegative 
corollary vector cumulative loss gp bounded loss jjujj max jjx gamma avg jj values large close lower max jjx jj expect gp perform better gd 
algorithm thought sigma applied special case theorem bound ln max max gamma min 
values large concentrated favored sigma shows results experiment large concentrated values variables attain values target vector nonzero components 
noise 
algorithms fact clearly outperform algorithms sigma fact 
data appear practice want subtract constant input variables avoid problems large values 
value known know outcomes transformed order maintain linear relation instances 
experiments approximated algorithm introduced section 
advantage approximate algorithm needs addition multiplications exponentiation update computationally simpler 
situations considered approximated exact algorithms roughly learning performance 
learning rates suggested analysis sigma algorithms corresponding approximated versions 
experiments approximate algorithm extensive know trials gd cumulative losses gd sigma upper bounds sparse target expanded instances 
circumstances problems weights going zero 
performed preliminary experiments algorithm 
algorithms case input variables negative 
expanding instances experiment illustrates linear function learning learn nonlinear target functions means expanding instances way target function linear expanded inputs see boser :10.1.1.103.1189
example vector components monomials variables degree 
polynomial degree variables written delta coefficient vector accordingly polynomials degree learned linear functions expanded instances original instances input algorithm 
original instances components expanded instances components 
target polynomial terms target vector nonzero components sigma algorithm perform 
shows results experiment expanded instances 
original instances chosen uniformly gamma expanded instance consist products components original instance 
components gamma consider products include variable 
products 
chosen target polynomial terms encoding gives target coefficient vector noise rate set 
qualitatively similar 
case sparse target instances unit cube advantage sigma gd depend input variables independent case 
real world data truly independent variables possibly variables correlations complicated dependencies 
experiment suggests data new variables generated products original independent variables cause gd algorithm similar difficulties large number independent random variables introduced new variables truly independent 
instances expanded results may similar described subsection number independent random variables original instances small 
expand instances time predicting computing updated weight vector usually linear dimension expanded instances 
simplicity consider case gamma ignore products contain variable 
expansion method discussed expanded instances gamma delta dimensions 
expense prediction update time restricts choice sigma algorithm generalizes target sparse 
original instances gamma components gamma target expanded domain exactly components gamma remaining components zero notation subsection get norms gamma delta 
noise free case leads total loss bounds gamma delta kn gd ln gamma delta log sigma assume goal obtain hypothesis instantaneous loss 
take bounds reductions section fair indicators actual instantaneous losses algorithms algorithm total loss bound leads algorithm instantaneous loss examples 
gd require gamma delta examples sigma require log examples 
seen small sigma algorithm generalization performance 
useful time gamma delta prohibitive 
number examples small prediction update time gd algorithm significantly improved straightforward gamma delta start vector form tth weight vector linear combination gamma 
updating done adding new component linear combination computing prediction delta amounts computing dot products form delta dynamic programming dot product computed time qn 
tth example total prediction update time qn gamma delta special case computing dot products sped dimensional instance expanded components 
achieved simply equality delta total time tth example tn gamma delta know way speed prediction update sigma algorithm 
gd algorithm seemingly advantage 
argued algorithm require omega gamma delta examples trials gd algorithm save time methods 
large values update prediction time tn trial larger time gamma delta obtained simply maintaining weight dimensions expanded instances 
summary update prediction times gd reduced algorithm examples speed useless 
key methods 

worst case bounds total loss evaluating line learning algorithms 
bounds expressed function loss best linear predictor 

introduce common framework deriving learning algorithms tradeoff distance traveled current weight vector loss function 
different distance functions lead radically different algorithms 
framework adapted unsupervised setting 

distance function serves second role potential function proving worst case loss bounds amortized analysis clr 
bounds expressed function learning rate various norms instances target vectors loss target vector 
loss bounds obtained carefully tuning learning rate 
clearly sigma algorithm derived relative entropy distance measure 
distance measure motivated minimum relative entropy principle kullback kk 
resulting new algorithm sigma learns target sparse components instances small range 
situations naturally arise perform nonlinear predicting expanding instances include values nonlinear basis functions predict linear functions expanded instances 
loss sigma algorithm increases logarithmically number irrelevant input variables possible generalization performance number basis functions number dimensions expanded instances significantly exceeds number training examples 
possible heuristic suggest guessing reasonable set basis functions iteratively replacing functions receive small weight new hopefully useful functions 
cross validation avoid overfitting 
single linear neuron able prove worst case loss bounds terms loss best linear predictor square loss 
ideally loss bounds standard loss functions relative entropy loss 
interesting find new distance measures lead new linear prediction algorithms loss bounds depend pairs dual norms pairs correspond algorithms sigma gd respectively 
bounds gd provably optimal 
need matching lower bounds exponentiated gradient algorithms sigma bounds need generalized allow negative components instances 
applying gradient descent multilayer sigmoid networks leads known backpropagation algorithm 
exponentiated gradient algorithms similarly generalized obtain new exponentiated back propagation algorithm 
long term research goal suggest developing family derived relative entropy distance measure 
neural network algorithms belong gradient descent family algorithms framework derived squared euclidean distance 
family includes perceptron algorithm thresholded linear functions gd algorithm linear functions standard back propagation algorithm multilayer sigmoid networks linear squares algorithm fitting line data points 
new family includes respectively winnow algorithm lit sigma algorithm exponentiated back propagation algorithm algorithm fitting line data points relative entropy coefficient vector minimized :10.1.1.130.9013
new family uses new bias favors sparse weight vectors 
observed case linear regression leads improved performance high dimensional problems target weight vector sparse 
expect see similar behavior general settings 
helmbold able prove worst case loss bounds single linear neurons tanh function sigmoid function loss function relative entropy loss 
case worst case loss bounds obtained algorithms gradient descent exponentiated gradient family 
acknowledgments kivinen funded emil foundation university helsinki academy finland 
manfred warmuth funded nsf iri 
wish nicol cesa bianchi david helmbold yoram singer comments 
john denker inspiring dimension analysis checking update rules learning rates 
ama amari 
information geometry em em algorithms neural networks 
technical report university tokyo tokyo 
ama amari 
em algorithm information geometry neural network learning 
neural computation january 
boser guyon vapnik :10.1.1.103.1189
training algorithm optimal margin classifiers 
proc 
th annu 
workshop comput 
learning theory pages 
acm press new york ny 
cesa bianchi freund haussler helmbold schapire warmuth 
expert advice 
technical report ucsc crl univ calif computer research lab santa cruz ca 
extended appeared stoc 
cesa bianchi long warmuth 
worst case quadratic loss bounds line prediction linear functions gradient descent 
ieee transactions neural networks 
appear 
extended appeared colt 
clr cormen leiserson rivest 
algorithms 
mit press cambridge ma 
dlr dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society 
haussler kivinen warmuth 
tight worst case loss bounds predicting expert advice 
technical report ucsc crl university california santa cruz computer research laboratory november 
partial results appeared eurocolt eurocolt 
hay haykin 
adaptive filter theory 
prentice hall englewood cliffs nj 
second edition 
hay haykin 
neural networks comprehensive foundation 
macmillan new york ny 
helmbold kivinen warmuth 
worst case loss bounds linear neurons 
advances neural information processing systems 
mit press 
appear 
helmbold schapire singer warmuth 
comparison new old algorithms mixture estimation problem 
technical report university california santa cruz computer research laboratory october 
extended appeared colt 
hw helmbold warmuth 
weak learning 
journal computer system sciences june 
hin hinton 
learning distributed representations concepts 
proc 
th annual conf 
cognitive science society pages hillsdale 
erlbaum 

relative information 
springer verlag 
kk kapur 
entropy optimization principles applications 
academic press 
kss michael kearns robert schapire linda sellie :10.1.1.55.3936
efficient agnostic learning 
machine learning 
lit littlestone :10.1.1.130.9013
learning quickly irrelevant attributes abound new algorithm 
machine learning 
lit littlestone 
line batch learning 
proc 
nd annu 
workshop comput 
pages san mateo ca 
lit littlestone 
mistake bounds logarithmic linear threshold learning algorithms 
phd thesis technical report ucsc crl university california santa cruz 
lit littlestone 
redundant noisy attributes attribute errors linear threshold learning winnow 
proc 
th annu 
workshop comput 
learning theory pages san mateo ca 
morgan kaufmann 
littlestone long warmuth 
line learning linear functions 
journal computational complexity 
lw littlestone warmuth 
weighted majority algorithm 
information computation 
lue luenberger 
linear nonlinear programming 
addison wesley reading ma 
roy 
real analysis 
macmillan new york ny 
sw schapire warmuth 
worst case analysis algorithms 
proc 
th international conf 
pages san francisco ca july 
morgan kaufmann 
appear machine learning 
vovk 
aggregating strategies 
proc 
rd annu workshop comput 
learning theory pages 
morgan kaufmann 
ws widrow stearns 
adaptive signal processing 
prentice hall englewood cliffs nj 

