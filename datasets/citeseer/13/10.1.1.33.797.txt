class discovery gene expression data amir ben dor agilent laboratories university washington cs washington edu nir friedman hebrew university nir cs huji ac il zohar yakhini agilent laboratories technion labs agilent com studies alizadeh bittner golub demonstrate discovery putative disease subtypes gene expression data 
underlying computational problem partition set sample tissues statistically meaningful classes 
novel approach class discovery develop automatic analysis methods 
approach statistically scoring candidate partitions overabundance genes separate different classes 
biological datasets overabundance genes separating known classes typically observed 
measure overabundance stochastic null model 
allows highlighting subtle meaningful partitions supported small subset genes 
simulated annealing explore space possible partitions set samples seeking partitions statistically significant overabundance differentially expressed genes 
demonstrate performance methods synthetic data recover planted partitions 
turn tumor expression datasets show find highly pronounced partitions 

important application gene expression profiling technologies array hybridization assays improve understanding cancer related processes 
studies demonstrate discovery putative disease sub types gene expression data 
example alizadeh discover putative sub class certain type lymphoma bittner discover putative sub class cutaneous melanoma 
cases findings biologically validated 
discuss algorithmic approaches unsupervised inference novel putative tissue subclasses gene expression data 
current approaches problem combination clustering driven methods human intervention 
clustering approach starts computing similarity values pearson correlation expression profiles pair tis contact author 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
copyright acm 
sue samples uses values partition data 
approach suffers shortcomings 
measure similarity depends uniformly entire set measured genes 
practice dramatic differences effect relatively small subset mrna transcripts 
differences washed uniform measures similarity 
example classification proposed alizadeh appear tissues clustered genes 
authors hand pick small subset genes cluster tissue samples respect subset 
second clustering methods return single clustering data 
actual data expect multiple significant partitions different tissue classes separated different sets genes treatment success drugs targeting different pathway 
take direct approach class discovery 
process develop consists components 
start defining merit putative partitions set samples 
apply heuristic search methods simulated annealing find best partition space possible partitions set samples 
iterate process find additional different partitions 
develop effective merit basis comparing different putative classes guided fact overabundance significantly differentially expressed genes typically observed data contains meaningful biological partitions 
number genes sharply separate classes extremely higher expected null model partitions data uniformly drawn 
reasoning reverse seek putative partitions observe overabundance informative genes 
section describe measure genes separate different classes define null model 
section derive surprise score putative classifications data 
section consider alternative score ability predict putative class membership gene expression profile sample thought silico classification assay 
section describe search procedures 
section synthetic model gene expression data evaluate performance different methods 
section apply methods actual biological data 
conclude discussion section 
informative genes cells dramatically different biological characteristics normal cell versus tumor cell tissue expected different gene expression profiles 
important realize majority active cellular mrna effected differences 
dramatic biological difference gene expression level manifestation set genes involved small 
scoring informative genes start definitions 
assume data set consisting vectors hx xm sample expression pattern vector describes expression values genes clones particular biological sample 
binary labeling vector hl label associated negative example positive example control example 
consider set expression data known classification tissues 
typically auxiliary information measurements pathological analysis genetic level information 
want understand molecular level differences different classes tissues 
data spans thousands genes 
genes play major roles processes underly differences classes dramatically effected differences 
genes highly relevant studied phenomenon 
hand expression levels genes may irrelevant distinction tissue classes 
identifying highly relevant genes data basic problem analysis expression data 
literature discusses methods scoring genes relevance 
include parametric measures standard test score separation score golub nonparametric measures 
briefly describe tnom threshold number misclassification score ben dor scoring genes 
emphasize ideas easily applied relevance scores 
denote number tissues consisting tissues class tissues class assume want score gene relevance respect partition tissues 
intuitively relevant tissue partition class tissues compared class tissues viceversa 
formalize notion relevance consider expression levels class tissues expression levels class tissues 
denote th tissue ranked expression level express minimally maximally 
define rank vector vector length follows note rank vector captures essence differential expression profile expressed class positive entries concentrated left hand side vector negative entries concentrated right hand side 
similarly opposite situation 
relevance increases homogeneity left hand side homogeneity right hand side increase 
natural way define homogeneity sides combine score leads tnom scoring method 
score corresponds maximal combined homogeneity possible ways break parts 
define mincardinality vector cardinality minority symbol mc min tnom score rank vector defined tnom min mc mx values scoring gene relevant partition set samples important evaluate result null model probability gene expression values appearing relevant randomly drawn partition samples 
number value corresponding scoring method effect level genes low values rare random data relevance studied phenomenon biological mechanistic protocol reasons 
denote labelings entries entries entries 
labeling vector gene expression values 
scoring method tnom function takes returns score respect labeling random labeling drawn uniformly value score level pv prob unif combinatorial character tnom score distribution amenable rigorous calculations 
ben dor develop efficient procedures computing exact distribution tnom scores access values allows compute expected number genes score better null model 
examining data sets biologically meaningful classifications overabundance significantly informative genes 
example contrasts expected number genes particular value actual number genes tnom score various previously published datasets 
overabundance analysis instrumental evaluating statistical significance putative previously unknown classes 
biological significance experimentally established described 

surprise scores recall aim apply statistical methods discovery sample classifications 
clearly ultimate test putative classification biological validation test 
statistics tool 
approach components statistical score measuring significance suggested partition procedure attempts find labeling highest score 
significance score correlated biological meaning 
data help learn advantages disadvantages various scores 
section discuss candidate scores termed surprise scores 
significant overabundance informative genes biologically meaningful pre classified data see suggests biologically meaningful classifications sample set characterized overabundance 
biological class differences manifest dramatic differences expression levels large set genes resulting observed overabundance 
choose candidate putative sample classes label vectors show significant overabundance informative genes applied data 
formalize stochastic model follows 
suppose want evaluate labeling score set ps pv parameters characterize composition putative labeling want evaluate unif fs sg indicate event gene received score better colon tnom score tnom score log binomial surprise observed expected tnom score tnom score log binomial surprise observed expected leukemia tnom score number genes tnom score log binomial surprise melanoma tnom score number genes tnom score log binomial surprise comparison number significant genes actual dataset expected number null hypothesis random labels 
axis denotes tnom score 
top part graph axis number genes bottom part axis negative logarithm probability expected number genes binomial model exactly surprise score see 
data sets colon alon leukemia golub melanoma bittner 
smaller equal clearly bernoulli ps gn number genes score better simply 
defined set random variables putative labeling compute score gene summarize scores set numbers number value range scores scoring function 
ask rare observe values unif max surprise score simplest modeling assumptions ind genes indicator variables gn independent 
assumption implies knowing scores subset fg jg random labeling adds information score labeling 
clear assumption things expression levels genes correlated scores random labeling correlated 
modeling situations simplifying assumption allows efficient computations change essence results 
independence assumption sum independent bernoulli variables binomial distribution bin ps number genes dataset 
define surprise observing genes score better surprise log appropriate binomial probability measure 
smaller probability observing larger surprise 
compute surprise score tail probability binomial distribution 
course different score values get different surprise values 
find score observed number surprising max surprise max surprise quantity employed evaluate labeling vector 
matches intuition labeling surprisingly large number informative genes 
sanov score max surprise score computes score largest overabundance informative genes observed 
ignores distribution scores 
example suppose maximum score ps 
max surprise may genes score exactly non negligible fraction better scores smaller values 
suppose sk range possible scores set 
null hypothesis gene independence assumption set fns kg distributed 
frequency observe score actual data ns distribution describes type empirical sample 
null model probability drawing type samples exactly nq nq approximate probability information theoretic measure distance 
theorem 
theorem nd log log nd log kl divergence nd order exponential approximation probability type 
approximation bound probability observing types skewed theorem 
sanov theorem log fq log motivates definition surprise measure sanov surprise nd log type observed distribution gene scores labeling vector summarize defined measure surprise entire vector observed scores frequencies 
quantity bound probability observing types 
observe max surprise score measures probability having labeling vector informative candidate terms overabundance informative genes 
intuitive level entire distribution considered labeling vector informative type weight low better scores qk formalizing sanov bound probability improbable types informative types 

classification scores previous sections studied scores evaluate quality putative label vectors measuring significant deviations distribution scores expect null hypothesis models 
alternative approach seek classes predictable gene expression measurements 
classification gene expression patterns problem predicting tissue classification examined 
demonstrated actual labelings real life data sets possible train classifier predictive accuracy 
precisely classification algorithm function fd depends data set patterns sample labels 
new query function returns predicted label fd 
predictive accuracy means predicted labels match true label query 
classification methods applied gene expression data 
completeness briefly review method 
naive bayesian classifier probabilistic approach problem 
start estimating probability label gene expression level 
model distribution decision stump learn threshold prediction xg xg threshold chosen tnom score conditional distribution xg resp 
threshold estimated proportions labels samples expression level resp 
assuming expression patterns genes independent labeling naive assumption bayes rule get log log log xg xg log quantity positive predict predict 
see details 
key issue need address evaluate accuracy classification method applied labeled data set labeling 
follow standard methodology leave cross validation loocv estimate prediction accuracy classification method new examples 
procedure iterates samples data set 
iteration removes single sample trains classification procedure remaining data 
trained classifier applied held sample predicted label compared true label 
fraction errors committed entire process estimate error rate classification procedure 
final issue feature selection 
show predictions informative subset genes accurate genes 
procedure employ simple surprisingly effective procedure select genes 
training data compute score attains max surprise 
focus genes score better 
learned classifier genes 
note loocv iteration procedure applied data set held sample 
time different score attains maximum surprise different set genes selected 
classification score putative labeling vectors suppose putative labeling samples training data 
intuition outlined suggests labeling captures true phenomenon data loocv evaluation classification procedure naive bayesian classifier lead accurate predictions 
words score labeling accuracy reported loocv evaluation classification respect labeling 
suggests distinctions labelings inherent data artifact 
different point view suggested classes successfully silico diagnosed 
shortcomings classification score 
computationally intensive need perform loocv iterations perform gene selection turn requires computing scores genes 
second number samples small range score quite limited 
implies classification score gives little guidance search high scoring labeling vectors 
third classification score search going perform large number loocv evaluations statistical considerations show random data repetitions test find high scoring artifactual labeling vectors 
avoid problems mainly classification score evaluate candidate labeling vectors surprise scores discussed previous section 

search methods choose score putative labeling vectors need find labeling maximizes score 
discrete optimization problem heuristic search techniques find high scoring labelings 
formalize problem search graph goal find vertex maximum score assumes locality scores neighboring vertices similar scores 
presently vertices correspond potential labelings samples score attempt maximize max surprise score 
edges graph pairs labelings agree labels sample labeling changed 
move labeling modifying label exactly sample classified unclassified vice versa 
note set samples vertex neighbors 
common search method ascend hill climb 
procedure consider neighbors current labelings random order 
evaluate score neighbor find neighbor better score move continue 
neighbors worse scores current candidate local maximum returned 
procedure straight forward intuitive aspect climbing hill better solution 
get stuck local maxima 
unfortunately local maxima common class discovery optimization problem 
common method escape local maxima simulated annealing 
method resembles ascend procedure 
search procedure maintains temperature parameter parameter updated search exponentially decreasing cooling schedule kth step process temperature integer 
score current labeling random neighbor labeling scores move neighbor probability min 
high temperatures probability score decreasing step close 
gets closer temperature decreases 
procedure terminates fixed number steps equivalently reaches pre specified temperature returns best scoring labeling encountered 
recall want construct different partitions data 
employ simple strategy peeling data set 
perform heuristic search find high scoring putative labeling 
peel genes support labeling data set 
precisely remove genes score smaller equal score attains maximum surprise 
reiterate search remaining genes exhausted genes score best labeling genes falls pre specified threshold 
iteratively peeling data set discover set partitions supported disjoint set genes 
finalize search reevaluate labeling vectors respect original data set previously removed genes relevant putative partition effect score 

model simulations attempts stochastically model gene expression data intrinsically problematic 
impossible reasonable set model assumptions universally valid complicated system living cell 
modeling approaches successful highlighting biological phenomena follow model allow selective inference knowledge data 
purpose stochastic simulation exercise describe section threefold validate computational class discovery methods general stochastic model identify mode convergence planted classes compare performance methods test effects various parameter changes 
stochastic model planted classes assume gene expression dataset stochastically depends hidden biologically significant classification tissues subclasses 
real datasets assume classification effects small fraction genes called genes genes called random genes express independently simplicity describe binary classification model 
modelling data classes manner straight forward 
assume exists hidden classification partitions tissues class tissues class tissues 
denote total number genes fraction gene 
genes em random genes 
gene model expression levels different tissues distributions da class tissues db class tissues 
assume da db normal distributions constant coefficient variation da db bs means distribution uniformly chosen interval 
expected distance means parameter model 
expression level random genes tissues independent class assumed normally distributed zero mean standard deviation 
note classification tissues supported random genes 
true classification supported statistically significant number genes genes 
summary planted classification model fully specified classification tissues classes sizes respectively model parameters total number genes 
fraction random genes data 
expected distance mean expression levels pertaining planted classes 
coefficient variation expression level distributions 
results synthetic data section report simulation evaluation discovery process 
varied model parameters employed max surprise sanov defined section simulated annealing local search 
initial simulations observed max surprise searches perform better sanov score searches chose max surprise rest study real datasets 
simultaneously varying observed search results relatively insensitive parameter compared 
concentrate rest simulations 
order choose realistic parameter values examined leukemia data set best fit model parameters 
omitting details fitting process resulting values 
stochastic model implicitly assume genes independently distributed 
biological dataset complicated dependencies genes 
effective number independent genes real data set smaller assumption supported example expression levels logs red green signal ratios dye expression profiling measurement 
max surprise sanov loocv data set labeling score value score acc 
coeff 
leukemia original lymphoma original lymphoma original dlbcl table evaluation best discovered labelings original labelings data sets 
table reports composition labeling max surprise score value point max surprise number genes value sanov score loocv accuracy predictions labeling ignoring control samples coefficient measures similarity labeling original labeling 

way choose better model value choose max surprise score hidden classification fixing parameters values resemble max surprise score aml classification leukemia data 
approach derive 
set leukemia parameters test performance methods leukemia parameters generated synthetic datasets planted classification model compared returned classification tissues original planted classification 
cases original class recovered perfectly 
better study effect model parameters algorithm performance learn algorithm limits varied parameters turn fixing leukemia value 
reported results denote planted classification proportions class tissues vs class tissues classification returned algorithm 
recall algorithm searches tissue classification maximal max surprise score 
vary model parameters max surprise score advantage compared classifications changes algorithm performance accordingly effected increasing number genes increases max surprise easier search heuristic find 
phase transition point 
larger algorithm consistently recovers hidden classes 
smaller optimal classification respect max surprise score different classification recovered 
difference depends smaller larger difference 
example setting get average max surprise max surprise 
close differ average tissues 
expected distance means little effect max surprise limited effect algorithm performance 
particular varied range cases algorithm recovered perfectly 
model represented fraction random genes data genes express independently planted classification 
stated differently trying recover planted classifications supported fraction genes 
max surprise score classification reflects abundance informative genes expect max surprise methods perform high values study simulations varied range observed algorithm consistently recovered 
higher values typically get max surprise max surprise 
coefficient variation plays major role model 
represents inherent random nature expression profile gene tissues class 
large values get spread distributions contributing higher tnom scores lower max surprise 
study varied range 
transition point 
smaller planted classification recovered larger typically recover classification larger max surprise score 
simulation study summed follows 
algorithm robust performing high levels noise form random genes form high coefficient variation 
second wide range parameters pessimistic correspond leukemia dataset algorithm consistently recovers planted classification 
ar genes high noise level planted classification longer optimal classification hope perfectly recover 

class discovery gene expression data evaluate usefulness approach applied gene expression data sets 
come known classification pathological considerations discovered manual analysis gene expression data 
data sets leukemia expression profiles reported golub 
samples divided variants leukemia samples acute leukemia aml samples acute leukemia 
mrna extracted bone marrow samples peripheral blood samples 
gene expression levels samples measured high density oligonucleotide microarrays spanning genes 
lymphoma expression profiles reported alizadeh 
diffused large cell lymphoma dlbcl samples 
remaining samples types tissues 
analysis gene expression measurements genes shown 
lymphoma dlbcl data set subset dlbcl samples lymphoma data set 
alizadeh separated samples classes centre dlbcl activated dlbcl 
data sets run peeling procedure maximum surprise score section 
table summarizes scores top discovered classifications various scoring mechanisms discussed difference original classification data 
leukemia data set run search procedure additional constraint examine labeling control tissues 
peeling labelings shown table 
labelings score better original labeling max surprise sanov scores number significant genes 
labelings better loocv accuracy original score 
believe captures significant distinction 
note labelings quite different original coefficient low 
labelings similar original labeling receive slightly lower loocv scores 
lymphoma data set peeling labelings 
top labelings score better original labelings terms max surprise score loocv accuracy 
labeling contains large group contains dlbcl samples group consisting samples types lymphoma fl cll note additional dlbcl set controls 
suspect classification genes expression separates dlbcl samples types mentioned 
focused dlbcl samples constraining samples controls peeling labelings 
labelings quite different reported alizadeh 
score higher terms max surprise supported larger number genes 
classification alizadeh higher loocv accuracy 
dlbcl samples alizadeh report survival data 
show classification discover data predictor patient survival chances 
show distinction informative focus low clinical risk patients 
clinical risk evaluated international prognostic index standard medical index evaluated time sample taken 
plot survival rates patients putative dlbcl classifications described table 
see classifications forth predictive patient survival 
hand second third classifications predictive survival chances patients prognostic evaluation third classification predictive patient population 
shows classifications discover potentially relevant development disease 
data sets manage recover close approximations known biologically meaningful classifications 
addition data sets uncovered classifications strongly pronounced data large number genes classification patients deaths patients deaths patients deaths patients deaths classification patients deaths patients deaths patients deaths patients deaths classification patients deaths patients deaths patients deaths patients deaths classification patients deaths patients deaths patients deaths patients deaths kaplan meier survival plots dlbcl classifications described table 
axis number years samples taken axis fraction patients survived far 
plot shows survival rate classes defined putative classification 
plots left column show survival rate patients survival data available 
plots right column show survival rate patients low clinical risk see details 
significant value 
classifications biologically meaningful artifacts sample preparation hybridization procedures 
case important analysis results take account strong signals expression data 

contribution threefold 
put forth problem class discovery distinguish standard clustering problems 
second propose criteria evaluating putative classifications significance 
central idea quantify overabundance genes informative respect putative classification 
develop efficient search procedure finding multiple significant classifications data sets 
main criterion searching new classifications max surprise score 
score appealing definition clear easily mapped biological counterparts efficiently evaluated 
synthetic evaluation shows searching max surprise score recover true classification synthetic data wide range operating parameters including number relevant irrelevant genes amount variance expression level difference expression genes classes 
applied procedure real life cancer related gene expression data sets multiple highly pronounced classifications supported independent evaluation methods measure classifications 
procedure managed recover close approximations known classification data sets 
reported opens intriguing research questions 
max surprise sanov score exploit strong independence assumption 
assumption potentially surprise scores observe data 
procedures performed practice able improve relaxing independence assumption 
potential direction estimating distribution null hypothesis assuming independence 
cut approach stochastic simulation 
unfortunately simple stochastic simulation useful estimating distribution scores relatively large value 
scores small values need massive repetitions simulation get single case score attained 
currently working developing sophisticated methods estimating distribution null hypothesis estimates get better assessment surprise 
issue search procedure 
mainly focused criteria evaluating putative classifications simulated annealing fairly generic search method parameters ensure wide search 
addition peeling finding multiple classifications 
plan study theoretical properties optimization problem aiming developing principled methods task 
ash alizadeh losses useful discussions relating making dlbcl survival data available 
nir friedman supported isf israeli ministry science alon fellowship 

alizadeh eisen davis ma tran yu powell yang marti moore jr hudson lu lewis tibshirani sherlock chan greiner warnke staudt 
distinct types diffuse large cell lymphoma identified gene expression profiling 
nature 
alon gish mack levine 
broad patterns gene expression revealed clustering analysis tumor normal colon tissues probed oligonucleotide arrays 
proc natl acad sci 
ben dor friedman nachman schummer yakhini 
tissue classification gene expression profiles 
journal computational biology 
ben dor friedman yakhini 
scoring genes relevance 
technical report school computer science engineering hebrew university jerusalem 
www cs huji ac il nir abstracts html technical report agilent labs agilent technologies www labs agilent com resources techreports html 
bittner meltzer chen jiang hendrix simon yakhini ben dor dougherty wang pollock dietrich alberts hayward trent 
molecular classification cutaneous malignant melanoma gene expression profiling 
nature 
chen dougherty bittner 
ratio decisions quantitative analysis cdna microarray images 
journal biomedical optics october 
cover thomas 
elements information theory 
john wiley sons new york 
duda hart 
pattern classification scene analysis 
john wiley sons new york 
friedman 
bias variance loss curse dimensionality 
data mining knowledge discovery 
friedman geiger goldszmidt 
bayesian network classifiers 
machine learning 
golub slonim tamayo mesirov loh downing bloomfield lander 
molecular classification cancer class discovery class prediction gene expression monitoring 
science 
kirkpatrick gelatt vecchi 
optimization simulated annealing 
science 
sax 
multiple comparisons 
sage publications 
ng 
preventing overfitting cross validation data 
proc 
th inter 
conf 
machine learning pp 


schummer ng nelson schummer baldwin hood 
comparative hybridization array ovarian discovery genes ovarian 
gene 
slonim tamayo mesirov golub lander 
class prediction discovery gene expression data 
recomb 
