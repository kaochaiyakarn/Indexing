random walks view spectral segmentation marina jianbo shi university washington carnegie mellon university mmp stat washington edu cs cmu edu new view clustering segmentation pairwise similarities 
interpret similarities edge ows markov random walk study eigenvalues eigenvectors walk transition matrix 
view shows spectral methods clustering segmentation probabilistic foundation 
prove normalized cut method arises naturally framework provide complete characterization cases normalized cut algorithm exact 
discuss spectral segmentation clustering methods showing essentially ncut 
focuses pairwise similarity clustering image segmentation 
contrast statistical clustering methods assume probabilistic model generates observed data points pixels pairwise clustering de nes similarity function pairs points formulates criterion maximum total intracluster similarity clustering optimize 
optimality criteria quantify intuitive notion points cluster pixels segment similar points di erent clusters dissimilar 
similarities considered context clustering algorithm practice document clustering image segmentation nding similarity function part art domain practitioner 
increasingly popular approach similarity clustering segmentation spectral methods 
methods eigenvalues eigenvectors matrix constructed pairwise similarity function lsa 
spectral methods regarded approximations previously formulated criteria motivated graph theoretical considerations web clustering method :10.1.1.160.2324:10.1.1.25.1824
demonstrated methods capable delivering impressive image segmentation results simple low level image features 
computational eciency achieved sparse matrix techniques :10.1.1.37.9724
main achievement show simple probabilistic interpretation er insights serve analysis tool spectral methods cited 
view pairwise similarities edge ows markov random walk study properties eigenvectors values resulting transition matrix 
view able show methods subsumed normalized cut ncut image segmentation algorithm sense described :10.1.1.160.2324
focus ncut algorithm adopt terminology image segmentation data points pixels set pixels image keeping mind results valid similarity clustering 
normalized cut criterion algorithm image represented set pixels segmentation mutually disjoint subsets 
pair pixels similarity ij ji 
ncut framework similarities ij viewed weights edges ij graph ij edge ij 
matrix ij plays role real valued adjacency matrix ij called degree node volume set vol 
set edges complement edge cut shortly cut 
normalized cut ncut criterion graph theoretical criterion segmenting image minimizing ncut vol vol ij cuts minimizing ncut means nding cut relatively small weight subsets strong internal connections :10.1.1.160.2324
shown optimizing ncut criterion np hard :10.1.1.160.2324
ncut algorithm introduced approximate method solving minimum ncut problem way eigenvalues eigenvectors :10.1.1.160.2324
uses laplacian matrix diagonal matrix formed degrees nodes 
algorithm consists solving generalized eigenvalues vectors problem lx dx ncut algorithm focuses second smallest eigenvalue corresponding eigenvector call respectively 
shows example similarity matrix pronounced block structure ib rst generalized eigenvectors iiia 
gure see elements approximately value cluster 
shown partitioning optimal ncut value cut ncut result represents basis spectral segmentation normalized cuts :10.1.1.160.2324
solves generalized spectral problem nds partitioning elements sets containing roughly equal values 
partitioning done thresholding elements 
partitioning eigenvector induces partition desired segmentation 
obtain segments proceeds recursively 
call procedure ncut algorithm 
vector satis es called piecewise constant partition 
section consider eigenvectors piecewise constant partition sets 
ncut algorithm lacks satisfactory intuitive explanation 
particular ncut algorithm criterion er little intuition causes piecewise constant 
happens segments algorithm degrade performance piecewise constant 
random walk interpretation describe answer rst questions give better understanding spectral clustering achieving 
shall approach third issue point results apply ncut algorithm :10.1.1.25.1824
markov walks normalized cuts normalizing similarity matrix obtains stochastic matrix row sums 
known theory markov random walks ij represents probability moving node step eigenvalues eigenvectors 
rst eigenvector vector elements equal 
assume node degree 
examine spectral problem matrix solutions equation px proposition solutions solutions 
words ncut algorithm matrix eigenvectors eigenvalues identical di erence generalized eigenvalues 
proposition shows equivalence spectral problem formulated ncut algorithm eigenvalues vectors stochastic matrix helps explaining ncut algorithm uses second smallest generalized eigenvector smallest eigenvector corresponds largest eigenvector cases interest equal containing information 
proof proposition elementary left exercise reader 
ncut criterion understood framework 
de ne easy verify stationary distribution markov chain 
chain ergodic happens mild conditions distribution property 
note markov chain reversible ij ji ij ii iii seg seg seg seg seg seg seg seg seg seg seg seg matrices row eigenvalues row ii rst eigenvectors row iii 
matrices represented gray scale black lighter shades higher values 
matrices correspond images pixels forming segments 
approximately block diagonal stochastic matrix second third eigenvector approximately piecewise constant contain information segmentation 
symmetric similarity matrix produced note rst eigenvectors contain information segmentation 
eigenvectors solving matrix identical eigenvectors 
block stochastic matrix second third eigenvectors piecewise constant re ect correct segmentation 
symmetric similarity matrix produced rst eigenvectors roughly piecewise constant result wrong segmentation 
de ne pab bja probability random walk transitioning set set step current state random walk started stationary distribution 
pab ij ij vol follows ncut aa ncut small certain partition means probabilities evading set walk evading complement small 
intuitively set parts random walk parts tends remain 
ncut strongly related concept low conductivity sets markov random walk 
low conductivity set subset max aa small 
studied spectral graph theory connection mixing time markov random walks 
uses de ne new criterion clustering 
coincidentally heuristic analyzed strongly similar ncut algorithm 
stochastic matrices piecewise constant eigenvectors transition matrix achieve better understanding ncut algorithm 
recall ncut algorithm looks second largest eigenvector denoted equal order obtain de ne vector piecewise constant relative partition 
pixels set note rst eigenvector piecewise constant 
having piecewise constant eigenvectors essential spectral segmentation important understand matrix desired property 
study rst eigenvectors piecewise constant 
proposition matrix rows columns indexed independent eigenvectors 

partition eigenvectors piecewise constant 
correspond non zero eigenvalues sums ij constant matrix ss ss ij non singular 
lemma matrix dimension form symmetric non singular independent eigenvectors 
proof lemma elementary omitted proposition proved appendix 
call stochastic matrix satisfying conditions proposition block stochastic matrix 
intuitively proposition says stochastic matrix piecewise constant eigenvectors underlying markov chain aggregated markov chain state space 
fa transition probability matrix opens interesting connections eld spectral segmentation body markov chains 
shown disconnected graph resulting block diagonal ncut algorithm correctly :10.1.1.25.1824
block diagonal block stochastic matrix unit matrix 
represents case pixels di erent segments strongly dissimilar 
case illustrated gure far easiest situation segmentation problem 
proposition shows fact spectral clustering able group pixels similarity transition probabilities subsets situation shown gure experiments show ncut works graphs disconnected supporting result practical evidence :10.1.1.160.2324
having piecewise constant eigenvectors part story 
necessary eigenvalues corresponding piecewise constant eigenvectors larger eigenvalues shall call spurious eigenvalues 
insights de ne algorithm called modi ed ncut nds segments pass computing eigenvalues vectors selecting largest eigenvalues corresponding eigenvectors extracting segments nding approximately equal elements selected eigenvectors 
step done projecting means known dimensional space de ned rows 
image segmentation algorithm original image output edge detector segmentation rst respectively eigenvectors means clustering 
pixels dissimilar apart separated edge considered similar 
note simple similarity measure spite stripes tiger segmented correctly 
proposition algorithm exact block stochastic eigenvalues larger spurious eigenvalues 
exploits dissimilarities pixels di erent segments similarity transitions pixels segment 
approach potential advantage gap eigenvalues spurious eigenvalues gure number segments determined automatically 
happen approaches unit matrix eigenvalues tending ii rows segment tend equal pushing spurious eigenvalues 
mix dissimilarity clusters similarity transitions describes data set natu rally clustered 
relationship spectral segmentation methods ncut algorithm criterion proposed segmentation methods eigenvectors 
discuss segmentation algorithms perona freeman pf scott longuet higgins slh 
addition discuss clustering methods avor kleinberg algorithm discovering web communities long known latent semantic analysis lsa variant proposed kannan vempala kvv 
algorithms pf slh established ideal case exactly 
pf ideal case case block diagonal 
slh matrix eigenvectors element ij pixels segment 
algorithm allows pursue variety objectives 
nding clusters related documents 
objective ideal case corresponds directed link graph consisting disconnected regular clusters 
second eigenvector piecewise constant partition 
practice algorithm nds elements eigenvector largest magnitude returns representative authoritative cluster 
conjecture elements correspond pages highest degree links cluster 
proving conjecture topic current research 
easy show ideal situations imply resulting stochastic matrix satis es conditions proposition algorithm exactly situations 
sense ncut subsumes pf slh certain variants methods takes account information ncut 
important aspect spectral clustering algorithm robustness 
empirical results show ncut robust pf slh practical situations 
algorithm kvv essentially special case ij de ned vectors positive features method step projection scaled eigenvectors proves error bounds depend deviation block kvv recursive ncut algorithm 
robustness results ncut algorithm know 
relationship laplacian graph markov chains known far mainly estimate mixing properties chains way cuts 
opens new perspective revealing properties underlying weighted graph ways markov chain 
shift perspective valuable successes sampling techniques tractably obtaining low rank approximations large matrices :10.1.1.37.9724
case lsa proves algorithms practice large scale problems 
view provided elegant analysis method 
enabled give complete intuitive characterization ncut algorithm 
analyzed algorithms tool realize look kind features mainly dissimilarity pixels di erent clusters technically result point view fact variants algorithm 
argue studying algorithm clustering criterion right 
rare cases clustering method understandable computationally tractable approximable known bounds yielding analysis 
may study clustering criteria see approximating conclude di erent 
formulate clustering criteria genuinely di erent example eigenvalue near indication graph bipartite 
easily imagine algorithm bipartite clustering simply looking eigenvector corresponding negative eigenvalue 
exciting issue nding ways balance number clusters clustering quality words automatically nding number clusters 
think markov chain perspective fruitful respect 
innovative approaches exist 
implications reaching example cases obtained positive symmetric kernel 
transfer results characterizations kernel classes satisfy certain requirements characterizations data distribution clustering 
transition matrix view tells combat ridge ects kernel derived similarity matrices 
vision common issue combining multiple criteria color texture similarity matrix 
markov walk perspective helps nd combination operators preserve underlying clustering preserve block stochasticity 
example convex combination transition matrices preserves elementwise product popular method combining multiple matrices doesn 
address issues propose method learning optimal combination 
proof proposition assume independent piecewise constant eigenvectors partition 
correspond non zero eigenvalues piecewise constant vector 

mapping associates dimensional vector consisting element segment denote fix px ij px eigenvector denote ij equation get linear system equations unknowns coecients eigenvectors independent system matrix non singular implying system admits trivial solution 
segment arbitrary follows sums constant segment denoted symbol ss construct matrix ss easy verify eigenvectors values nonzero follows non singular 
prove converse exists non singular eigenvectors piecewise constant partition 
eigenvalues non zero 
denote eigenvectors values simply verify independent eigenvectors corresponding chung 
spectral graph theory 
american society 
deerwester dumais furnas landauer harshman 
indexing latent semantic analysis 
journal american society information science 
drineas kannan frieze vempala vinay 
clustering large graphs matrices 
proc 
th acm siam symposium discrete algorithms 
kannan vempala 
clusterings bad spectral 
proc 
st symposium foundations computer science focs 
kemeny snell 
finite markov chains 
van nostrand new york 
kleinberg 
authoritative sources hyperlinked environment 
technical report ibm research division almaden research center 
shi 
learning segmentation random walks 
leen dietterich tresp editors advances neural information processing systems volume cambridge ma 
mit press 
appear 
perona freeman 
factorization approach grouping 
european conference computer vision 
scott longuet higgins 
feature grouping eigenvectors proximity matrix 
proceeding british machine vision conference 
shi malik :10.1.1.160.2324
normalized cuts image segmentation 
pami 
tishby slonim 
data clustering markovian relaxation information bottleneck method 
leen dietterich tresp editors advances neural information processing systems volume cambridge ma 
mit press 
appear 
weiss 
segmentation eigenvectors unifying view 
international conference computer vision 
