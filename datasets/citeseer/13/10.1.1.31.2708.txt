independent components text thomas lars kai hansen department mathematical modelling technical university denmark dk lyngby denmark imm dtu dk communication analyze feasibility independent component analysis ica dimensional reduction representation word histograms 
analysis carried likelihood framework allows estimates loadings source signals mixing matrix noise level 
face noisy signals estimated sources non linear functionals observed signals contrast linear noise free case 
discuss generalizability estimated models show empirical test error estimate may optimize model dimensionality particular optimal number sources 
applied word histograms ica shown produce representations better aligned group structure text data lsa 
background pattern recognition text data statistical representations documents 
face limited sets labeled data pattern recognition algorithms typically fail generalize high dimensions need efficient robust means data reduction 
latent semantic analysis lsa approach defined :10.1.1.108.8490
lsa summarization term document matrix count set terms occur set documents analysis 
list terms adaptive derived words occur certain minimum frequency documents possibly screened list simple high frequency words 
lsa term occurrence histograms projected orthogonal set eigen histograms singular value decomposition 
lsa aid interpretation visualizing group structure set documents typically scatterplots term histograms salient eigen histograms see 
observation notable grouping documents structure spanned eigen histograms explained 
apparent cone structure noted points representation non orthogonal basis set :10.1.1.108.8490
show independent component analysis ica viable tool identification basis set 
apply new ica algorithm able identify generalizable low dimensional basis set face high dimensional noisy data 
term document matrix considered linear mixture set independent sources activating characteristic semantic network 
semantic networks take form 
pc comp 
pc comp 
pc comp 
ic comp 
ic comp 
ic comp analysis med set medical abstracts labeled classes coded colors 
upper panels show scatterplot documents latent semantic principal component basis 
lower panels show document location seen ica representation 
note group structure clearly visible pca plots ica plots group structure aligned independent components 
non orthogonal term occurrence histograms 
translating conventional ica speech separation terms play role microphones document index corresponds time index independent components sources corresponds speakers 
independent component analysis reconstruction statistically independent components sources linear mixtures relevant information processing contexts see review 
contribution knowledge application realm 
derive solution source separation likelihood formulation see :10.1.1.48.120
specific model investigated special case general framework proposed cardoso formulate parameter estimation problem terms boltzmann learning rule allows particular transparent derivation mixing matrix estimate 
focus generalizability ica representation generalization error means optimizing complexity representation 
observed mixture signals denoted matrix size theta number terms word histogram number documents 
noisy mixing model takes form source signal matrix size theta number sources thetam mixing matrix matrix noise signals parameterized distribution 
properties source signals introduced parameterized prior distribution sj 
likelihood parameters noise distribution parameters source distribution mixing matrix ja gamma sj ds parameterized noise distribution 
assumed sources eq 
assume noise modeled gaussian variables variance oe joe oe tn exp gamma oe index terms document variables 
assume parameter free source distribution nm exp gamma log cosh sum runs sources documents 
address problem estimating sources mixing parameters known oe bayes formula sjx js obtain posterior distribution sources sjx oe exp gamma oe gamma gamma log cosh maximum posteriori map source estimate maximizing expression providing non linear equation solve iteratively map estimate gammaa gamma oe tanh likelihood hidden gibbs form generalized boltzmann learning rule find gradients likelihood parameters oe averages estimated mean field approximation leading recursive rules oe fi gamma oe tn tr gamma gamma fi lumped effect fluctuations neglected mean field approach 
fluctuation corrections magnitude fi derived low noise limit gaussian approximation likelihood 
generalization bias variance dilemma parameters blind separation model estimated finite random sample random variables inheriting noise data set trained 
likelihood formulation generalization error specific set parameters average negative log likelihood gamma gamma log gamma sj ds dx true distribution data 
generalization error principled tool model selection 
context blind separation optimal number sources retained ic components error test train ica analysis med set medical abstracts 
training test errors function dimensionality mixing matrix 
generalization error shows shallow minimum independent components reflecting bias variance tradeoff function complexity estimated mixing matrix 
model crucial interest 
face typical bias variance dilemma 
components structured part signal lumped noise leading high generalization error lack fit 
hand sources expect overfit model additional degrees freedom fit non generic details training data 
generalization error eq 
estimated test set data independent training set 
learning ica text representations typically face problems thousands words terms list possibly fewer documents face called extremely ill posed learning problem cured loss generality pca projection 
pca decompose term document matrix eigen histograms 
eigen histograms subject orthogonality constraint eigenvectors symmetric real matrix 
interested slightly general separation sources independent sequences necessarily orthogonal word histogram able perform general decomposition data matrix corresponding model eq 

performing ica pca simplification ica problem 
approach taken similar called cure extremely ill posed learning simplify supervised learning short image sequences 
note likelihood considered function columns histograms split parts 
part orthogonal subspace spanned rows part situated subspace spanned columns part trivially minimized non zero configuration sources putting 
simply couple data 
remaining part projected dimensional hyperplane spanned documents 
way reduce high dimensional separation problem separation square projected size theta note 
comp 
comp med dataset medical abstracts 
dataset consists documents topics 
source signals recovered ica converted simple classifier coded classes different colors 
top bottom show scatterplots principal component representation vs vs colors signifying classification proposed ica independent components respectively 
may possible limit dimensionality pca subspace reducing histogram dimensionality remaining problem 
application med dataset med dataset commonly studied collection medical abstracts :10.1.1.108.8490
total consists abstracts group labels applied documents 
selected subset consisting abstracts corresponding groups dataset 
constructing histogram term document matrix words occurred abstracts chosen term word 
common words removed list leaving total terms 
abstracts chosen characterized briefly crystalline lens vertebrates including humans 
relationship blood fluid oxygen concentrations partial pressures 
method interest 
electron microscopy lung 
tissue culture lung 
crossing fatty acids barrier 
normal fatty acid levels 
results represent cure extremely ill posed learning method reducing learning problem theta problem loss generality 
expect fewer components needed creating generalizable model 
show test training set errors evaluated training sets patterns randomly chosen set 
test set remaining documents resample fold crossvalidation 
generalization error shows shallow minimum independent components reflecting bias variance tradeoff function complexity estimated mixing matrix 
show scatterplots prominent principal components variant independent components 
distribution documents forms defined group structure pca scatterplots clearly ica scatterplots better axis aligned 
conclude non orthogonal basis ica better explains group structure 
illustrate finding converted ica solution pattern recognition device simple heuristic 
assign group label magnitude recovered source signal 
table show device quite successful recognizing group structure ica training procedure completely unsupervised 
ica independent components recognized perfectly classes lumped 
component ica generalization optimal model recognizes classes perfectly confuses classes 
inspecting groups classes similar topics concern medical documents diseases human lungs investigating classifications ica component resolve ambiguity 
ability ica classifier identify topic structure illustrated show scatterplots color coded ica classifications 
shows ica better lsi identifying relevant latent semantic structure 
inspect histograms produced ica backprojection pca basis 
thresholding ica histograms find salient terms component 
terms keywords topic shown tables follow nicely 
keywords ic lens protein ic arterial blood cerebral oxygen rise ic acid blood cell fatty free glucose insulin table simple classifier constructed component ica 
med classes recovered independent component contains mixture remaining classes 
keywords ic lens protein ic arterial blood cerebral oxygen rise ic alveolar cell lens lung ic acid blood fatty free glucose insulin table simple classifier constructed component ica 
med classes recovered remaining classes mixed 
unresolved classes related making lung physiology 
likelihood map formulation noisy separation problem 
face additive noise map estimate independent sources nonlinear functional observed signal contrast linear classical solution 
learning rules mixing matrix noise parameter boltzmann learning 
proposed generalization error defined average negative log likelihood estimated independent test set means optimization source model complexity 
ica model representation word histograms 
non orthogonal basis ica explains group structure better semantic analysis pca 
substantiated confusion matrix simple pattern recognition device recovered sources 
acknowledgment funded danish research councils intermedia plan multimedia research thor center 

lee girolami bell sejnowski unifying information theoretic framework independent component analysis 
international journal mathematical computer modeling press 
cardoso 
maximum likelihood source separation expectationmaximization technique deterministic stochastic implementation proc 

geman bienenstock doursat neural networks bias variance dilemma neural computation 
deerwester dumais furnas landauer harshman indexing latent semantic analysis :10.1.1.108.8490
journ 
amer 
soc 
inf 
science 

hansen blind separation noisy mixtures 
department mathematical modeling 
tech 
univ denmark imm dtu dk pub 
hansen law strother massive weight sharing cure extremely ill posed problems 
eds 
supercomputing brain research tomography neural networks 
world scientific pub 

mackay maximum likelihood covariant algorithms independent components analysis 
draft 
pearlmutter parra context sensitive generalization ica 
proc 
international conference neural information processing 
hong kong 
peterson anderson mean field theory learning algorithm neural networks complex systems 
