empirical analysis overheads cluster environments brian schmidt sunderam department math computer science emory university atlanta ga usa phone email bs vss emory edu concurrent computing environments heterogeneous processing elements interconnected general purpose networks classes overheads contribute lowered performance 
attempt gain deeper insight exact nature overheads develop strategies alleviate conducted empirical studies selected applications representing different classes concurrent programs 
analyses identified load imbalance parallelism model adopted communication delay throughput system factors primary factors affecting performance cluster environments 
degree factors affect specific classes applications propose combination model selection criteria partitioning strategies software system heuristics reduce overheads enhance performance network environments 
demonstrate agenda parallelism load balancing strategies contribute significantly better performance improved communications system tuning 

cluster computing concurrent processing collections loosely coupled computer systems rapidly evolving technology tremendous potential high performance applications 
cluster systems widespread applications ranging computational quantum chemistry monte carlo simulations materials science calculations 
general systems permit collection networked machines unified general purpose concurrent computing resource 
hardware multiprocessors commercially available effective platforms highly compute intensive applications networked collections computer systems complement augment processing capabilities traditional parallel machines 
typically contemporary computing environments network include variety processing elements including general purpose workstations different kinds multiprocessors special purpose machines graphics processors vector computers 
advent high speed networks material supported national science foundation award 
ccr 
real time resource sharing geographically remote computer systems imminent 
network concurrent computing approach proven viable effective different computing power providing controlled access larger richer hardware base network concurrent environments increase application performance significant factors 
addition increasing computing resources may accessed individual users network environments enable exploitation specialized resources 
incremental scaling network concurrent computing environment usually straightforward network bandwidth limitations pose main obstacle scaling larger factors verge increasing orders magnitude advent fiber optics 
unrealistic expect communication speeds comparable hardware buses switches highspeed networks provide sufficient capacity performance variety applications 
right circumstances network approach effective coupling similar multiprocessors resulting configuration economically technically difficult achieve hardware 
application heterogeneity existing projected applications mentioned composed sub algorithms differ widely model computation programming language computing data handling requirements 
typical networks wide mix architectures capabilities applications benefit executing appropriate sub algorithms best suited processing elements 
months systems support cluster concurrent computing emerged production number sites general purpose concurrent applications 
pvm system network linda express environment 
approaches adopted programming development interface supported performance levels vary comparable systems 
classes applications systems demonstrated effectiveness terms functionality performance achieving performance levels matching exceeding supercomputers terms computing paradigms application languages resource requirements hardware multiprocessors 
clusters highly cost effective widely available provide straightforward access interfaces development monitoring tools 
reasons cluster computing expected receive widespread attention near continue viable alternative complement traditional high performance computing platforms 
performance levels observed cluster environments usually adequate frequently noticeable degradation compared execution collection computer systems external loads ignoring communication overheads 
course expected clusters typically composed general purpose systems interconnected networks carry various traffic 
believe overheads cluster computing reduced significant factors combination partitioning strategies simple approaches scheduling load balancing system level tuning 
describes experimental efforts optimize performance network concurrent computing environments distill general principles achieving optimality 
empirical analysis degree different factors affect cluster performance 
analysis propose implement alternative scheduling partitioning load balancing strategies specific cluster software system measure effectiveness approach 
discussion applicability strategies follows respect varying cluster platforms different classes applications 

system framework issues addressed applicable reasonably types distributed computing systems infrastructures support network concurrent computing 
analyses proposed techniques experimentation utilized pvm system basis remainder assume environment 
details regarding pvm system experiences descriptions supporting toolkits may section describe functions supported pvm parallel computing models may deployed partitioning scheduling strategies quantitative measures primitive facilities 

pvm infrastructure pvm system essentially emulates general purpose concurrent computing framework networked collection independent computer systems 
system level process executes machine user configurable pool processing elements cooperative distributed algorithms permits collection machines utilized coherent concurrent computing resource 
applications access virtual machine library routines embedded imperative procedural languages fortran 
support provided process management communication datagram stream oriented message passing synchronization barriers variants rendezvous auxiliary tasks 
internally library routines interact pvm service provider host provides requested actions cooperation peer entities virtual machine 
schematic pvm system infrastructure shown 
rs user process process user cray sparcstation user process user process pvm system daemon application process control data transfer high performance data channels user daemon interface pvm system infrastructure internetwork pvm architectural overview instance application subtask component realized process unit computational abstraction pvm system 
process executing instance application component component domain specific module amenable spmd execution 
application consists components may dynamically manifested multiple concurrent instances cooperate component boundaries 
instances independent sequential threads may spawn terminate instances synchronize instances exchange data 
illustrative example computing model shown 
synchronization data communication component input partitioning component matrix multiplication instance instance instance instance shared memory multiprocessor instance instance instance instance instance component cholesky factorization distributed homogeneous cluster result consolidation component graphical display instance instance example structure pvm computing model instances communicate messages message may contain multiple typed data areas 
message segments built provided library routines machine independent manner optimized system avoid unnecessary conversions possible 
data transfer message separate interfaces provided packetized stream data supporting bursty large volume continuous communication 
message exchange asynchronous sending process may continue execution prior physical message reception destination process 
probe mechanisms provided receiving instances need suspend execution pending message arrival 
synchronization provided form named barriers permit specification quorum event rendezvous mechanisms 

application development applications utilizing pvm infrastructure programmed manner similar distributed memory multiprocessors hypercube 
significant differences process orientation pvm applications may processes required base number instances problem characteristics 
processor oriented parallel machines instance processor mapping need 
multiple component execution inherent support provided cooperative execution multiple application modules may replicated hardware multiprocessors cumbersome programming manual intervention required accomplish 
exploiting heterogeneity multifaceted virtual machines configured framework potential subtasks best suited architectures significantly enhanced 
logical interconnection synchronization communication direct logical visibility provided arbitrary sets component instances 
communication logically complete graph synchronization points may assigned symbolic names 
pvm supports explicitly parallel computing model particularly respect partitioning scheduling 
graphical tools development ease parallel program development profiling principal technique representing concurrency appropriate host language control flow constructs augmented synchronization communication primitives 
may impose burden user significant amount flexibility enabling concurrency models represented specified straightforward convenient manner 
desire provide toolsets repertoire techniques enhance construction distributed concurrent applications described presents preliminary efforts regard 

application programming paradigms illustration different concurrency models may implemented pvm 
known examples discuss common partitioning scheduling organization techniques concurrent processing 
examples selected common understood exhibit characteristics embody terms behavior applications 
fundamentally different regard communication patterns computation communication ratios important factors affecting performance message passing concurrent systems 
subsections empirical results identify areas novel strategies may employed obtain gains development ease performance 
step pipe step multiply temp matrix matrix step roll step second pipe steps pipe multiply roll mesh connected machine matrix multiplication pipe multiply roll matrix multiplication classic technique matrix multiplication distributed memory architectures pipe multiply roll algorithm described 
method multiplies matrix subblocks locally uses row wise multicast matrix subblocks conjunction column wise shifts matrix subblocks shown 
communication matrix multiplication pipe multiply roll algorithm 
processor starts processes initiate endfor endif forall processors pij pipe 
mod send processors pxy snd pxy endfor rcv receive endif multiply 
running totals maintained 
multiply roll 
send processor pxy snd pxy rcv receive endfor endfor algorithm outline matrix multiplication pattern regular computation evenly balanced square grid processing elements 
outlines pseudo code form pvm program perform block matrix multiplication 
sorting algorithms contrast matrix multiplication algorithm sorting algorithms distributed memory architectures high communication computation ratio 
furthermore communication pattern regular symmetric algorithms 
owing differences typical dmm sorting algorithms considered belong different application category terms structure communication patterns 
novel sorting algorithm representative example regular tree structured class perform empirical measurements performance cluster environments 
illustrates method diagrammatically form algorithm skeleton 
branch bound techniques matrix multiplication sorting techniques described belong different categories similar viewpoint partitioning workload distribution 
total workload known priori algorithms particular utilize static partitioning 
volume performed processing stage stage stage stage stage stage stage stage stage stage time split sort merge algorithm tree connected processors element volume frequency communication known advance 
applications amenable concurrent execution nondeterministic respects 
order analyze characteristics algorithms branch bound technique described solve puzzle problem 
structure pvm program implemented shown 
pure data parallelism applications far possess non trivial straightforward communication patterns 
hand applications exhibit referred embarrassing parallelism 
essentially problem partitioned completely independent portions algorithm applied partial results combined simple combination schemes 
model permits dynamic load balancing agenda parallelism permitting processing elements share workload unevenly 
computing mandelbrot set commonly representative category parallel programs 
example experiments schematic outline implementation shown 
processor starts processes initiate endfor endif partition list broadcast tree pattern 
forall processors list send list xor snd xor list list maxsize rcv receive list endif endfor endfor sort remaining list 
quicksort list maxsize gather merge sorted sub lists 
downto forall processors snd xor send list xor rcv receive temp list merge list endif endfor endfor algorithm outline split sort merge 
performance basic primitives primary objective parallel processing faster execution multiple processing elements cooperatively single problem 
level efficiency speeding computations course dependent factors ranging inherent non parallelism algorithm overheads communication synchronization multiple processors 
cluster environments external influences general network processors may applications 
analyzing communication overheads take extraneous traffic account factor variable nature network characteristics terms delay throughput 
similarly trying formulate computation requirements unrelated processes executing usually general purpose computers contribute unpredictable large variations 
factors varied constructing precise model efficiency cluster environments appears difficult possibly intractable problem 
project attempt task intention verify accurate model constructed making simplifying assumptions 
platform branch bound search solution arrangement puzzle cost manhattan distance level state space tree encircled representative example branch bound application lightly loaded local area network computing elements similar workstations dedicated execute external compute intensive applications 
lightly loaded network informally mean operates capacity traffic fairly constant 
external workstation limited executing window server window system clients typically interactive instant 
point scenario typical encountered vast majority student laboratories university settings industrial commercial installations 
intend assumptions acquire cut understanding issues involved analyzing cluster environments 
assumptions low near constant external network loads attempt parametrize communications overheads cluster computing local networks 
basis conventional approach adopted analyzing communications message passing distributed memory multiprocessors 
approach define communication time simple linear function number bytes transmitted constant additive factor representing startup overheads 
comm master branch bound puzzle algorithm 
start worker processes initiate endfor level level state space tree send level send tasks level 
receive receive tasks level 
reorder reorder bag tasks keep minimal cost 
level level endwhile terminate worker processes terminate endfor worker branch bound puzzle algorithm 
true rcv receive task compute children state space tree keep minimal cost pack remaining children child endfor snd send remaining children master endwhile algorithm outline concurrent puzzle solution master slave slave slave slave mandelbrot tasks schematic typical data parallel applications startup time cost byte 
returning pvm architectural model seen pvm provides alternative mechanisms message transfer datagram protocols routed system daemons stream transport direct communicating processes 
datagram communication mechanism stage process experiments demonstrated mode communication modeled single equation shown 
order estimate coefficient number experiments conducted varying network host load conditions different message sizes 
results experiments shown table table table 
data set listed tables averages tens runs different data sets represent different levels machine network activity 
master mandelbrot algorithm 
initial placement initiate start worker snd send task worker endfor receive send rcv receive result send task available worker snd display result endwhile gather remaining results 
rcv receive result terminate terminate worker display result endfor worker mandelbrot algorithm 
true rcv receive task result task compute result snd send result master endwhile data parallel algorithm outline experimental results coefficients determined curve fitting mips sun interconnected mb ethernet pvm communication costs pack msec pack msec byte pack pack pack msec msec dg msec dg msec byte send dg dg dg msec msec stream msec stream msec byte send stream stream stream msec msec comm dg pack send dg msec comm stream pack send stream msec interesting note equations fit observed measurements outlying observations encountered 

issues application performance reiterate objectives project wish analyze factors affect performance heterogeneous networked systems construct reasonably accurate models application behavior 
motivations effort fourfold gain understanding basic characteristics concurrent algorithms execute network computing systems 
predict model execution times verify extent model scale retaining close relationship observed measurements 
determine breakeven number processors speedups obtainable problem size determine range processor values exhibit greatest efficiency levels 
identify bottlenecks effect parametric changes processor speeds network throughput size bytes data set data set data set average table measured time milli seconds pvm message packing size bytes data set data set data set average table measured time msecs pvm datagram message transmission size bytes data set data set data set average table measured time msecs pvm stream message transmission initial attempt traditional performance model adopted typical distributed memory multiprocessor analyses 
essentially time taken application dependent computation time communication time including synchronization load imbalance 
factor usually measure equitable distribution workload processing elements 
networked systems processors typically dedicated application consideration side load imbalance viz effect external cpu memory network loads 
example cluster identical workstations equal amounts may require different execution times owing externally generated computation swapping network activity 
course influences vary dynamically difficult incorporate accurately theoretical model 
described section proposed approach addressing issue combination flexible partitioning scheduling schemes controlled instantaneous monitoring conditions contributing external effects 
analyses revisit representative application algorithms discussed earlier 
load imbalance due uneven distribution workload issue matrix multiply sorting workload partitioning equal dynamic load balancing scheme puzzle problem mandelbrot computations prevent workload imbalance application execution 

experimental results order determine models constructed simple approximate pragmatic value experiments conducted reported section 
methodology conduct empirical studies compare results predicted application behavior obtained modeling applications 
algorithms outlined previous section implemented pvm timings measured 
form basis comparison applications executed intel ipsc distributed memory multiprocessor 
results significantly different branch bound approach agenda algorithm mandelbrot set calculations 
surprising actual implementations necessarily quite similar exception mandelbrot calculations deterministic sense total number tasks completed computed statically branch bound inherently non deterministic terms volume computation upper bound determined advance 
section report predicted versus measured results application algorithms compare findings similar measurements hypercube multiprocessor dedicated non multiprogrammed processing elements interconnection links 

matrix multiplication modeling pipe multiply roll algorithm described earlier communication computation factors yields comp mult add mult add comm mult add times single multiplication addition respectively comp computation time comm communication time 
specifically include additions opposed additions required general method implementation employs strategy set intermediate products repeatedly summed 
observed measurements executing algorithm network summarized tables 
average measured time seconds multiply integer matrices datagram protocol idle communication computation total time table subsequent experiments method timing various components algorithms 
time process blocked awaiting message arrival waiting subsequent unit considered idle time 
idle time essentially means quantifying degree load imbalance exhibited algorithm 
consider time process spends doing useful average measured time seconds multiply integer matrices stream protocol idle communication computation total time table contributed final result multiplication sub blocks roll algorithm computation time 
communication time includes time spent packing message transmission intended receiver total time measured single process waited instances finish execution 
process responsible gathering local timing results instances computation communication idle times reported arithmetic means corresponding individually measured timings 
number processors matrix multiplication pvm datagram predicted vs measured total measured time predicted time graphs figures show relationship predicted observed measurements matrix multiplication pvm datagram stream communication protocols respectively 
curves similar substantially different may seen number processors increases observed datagram timings appear diverge predicted ones 
order better understand reasons behavior detailed analysis observed times performed 
results shown graph 
computation times nearly identical stream datagram protocols match predicted computational load closely implies theoretical model number processors matrix multiplication pvm stream predicted vs measured total measured time predicted time number processors matrix multiplication pvm datagram vs stream idle stream communication stream computation stream total time stream idle datagram communication datagram computation datagram total time datagram accurate predictor cpu activity 
measured communication times reasonable limits important note pvm message passing semantics exactly mimic blocking send sending process wait destination process continuing execution 
measured communication time may significantly lower actual time spent packing transmitting unpacking various messages portion idle time fact include transmission time 
observed idle time key point interest clear large amount load imbalance incurred algorithm especially case datagram protocol utilized 
idle time due propagation delay remaining significant amount attributable fact communication medium shared channel forcing messages serialized unspecified order model assumes multiple dedicated channels 
deviation observed measurements predicted values primarily due contention physical communication medium clearly communication pattern regular symmetric approximately equally spaced intervals poor choice network cluster computing environment utilizes shared communication medium 
section strategies lead better match observed predicted results 
number processors matrix multiplication ipsc predicted vs measured measured communication measured computation total measured time predicted communication predicted computation total predicted time shows comparison predicted observed times matrix multiplication algorithm intel ipsc hypercube 
see divergence measured values predicted total times computation communication times appear consistent expected values 
surprising total time simply sum computation communication times reason behavior immediately apparent 
idle time significantly high warrant concern fact product poor clock resolution 
conjecture discrepancy due factors specific intel ipsc hypercube 
send primitive hypercube blocking procedure time process suspended equivalent time takes deliver entire message physical communication layer local node mentioned earlier experiments indicate time pack transmit message roughly equivalent measuring time send execute surprising amount transmission time omitted measured time simply transfer time byte message minimal unpacking trivial compared total communication time 
fact lost time probably smaller clock resolution represents significant difference actual cost true case single hop transmissions necessarily carry larger weight multi hop transfers 
matrix multiplication algorithm assumes mesh connected topology hypercube topology boolean cube 
messages require multiple hops reach destinations implies measured communication time align predicted time assuming mesh connected machine reality somewhat higher multi hop propagation delay included 
despite inconsistency arises non mesh topologies model fits measured values reasonable limits effectively utilized close approximation run time processing 

sorting split sort merge algorithm outlined earlier new algorithm developed order fully exploit topology hypercube 
utilizes familiar broadcast tree pattern distribute workload quickly possible assuming list sorted initially resides single node generally case practice known quicksort algorithm partitioning scheme workload fairly evenly distributed 
algorithm perform exhibit speedup presence low communication costs bus links hypercube 
algorithm modeled manner similar results obtained oper time perform single sorting operation test swap comp log oper comm log log log bn log log log bn timing studies performed implementation algorithm test beds matrix multiplication experiments summarizes results cluster environment datagram stream protocols 
clear graph match predicted measured values quite close ms deviation 
order understand algorithm behaved manner conducted experiments examining various components execution results network cluster intel ipsc hypercube shown figures respectively 
number processors sorting integers split sort merge pvm measured vs predicted predicted stream predicted datagram measured stream measured datagram interesting note graphs experiments observed computation times match predicted values closely predictions assumption exactly log operations performed reality computations loosely defined log 
evident number processors sorting integers split sort merge pvm datagram vs stream idle stream communication stream computation stream total time stream idle datagram communication datagram computation datagram total time datagram number processors sorting integers split sort merge ipsc predicted vs measured measured communication measured computation total measured time predicted communication predicted computation total predicted time communication cost primary factor affecting performance leads divergence expected results 
phenomenon partially accounted contention shared physical medium cluster environment explain main cause 
algorithm partitions list quicksort fashion average results dividing half iteration practice see wide variation median small sample space narrow divergence large number partitions necessary 
surprising average computation times match apply list understandably quite large general median approach expected value 
communication time hand involves log partitions large differences expected message sizes actual sizes 
may trivial concern list broken parts total volume communication constant 
unfortunately algorithm assumes symmetric communication pattern practice broadcast tree unbalanced terms workload idle time 
imbalance propagated tree results poor correlation predicted values 
tree significantly deeper expect see closer alignment expected results case computation time 
unrealistic terms cost scalability algorithm performance degrades rapidly 
new algorithm provides interesting theoretical solution sorting problem dmm practice communication overhead greatly outweighs benefits additional parallelism 

mandelbrot computation experiments conducted examine behavior agenda algorithm 
chose computation mandelbrot set experiments computation pattern known processing element independent 
communication model trivial consisting predetermined number master slave exchanges 
results shows observed expected values differ negligibly model approximates actual behavior high degree accuracy 
substantial idle time incurred processors unsurprising dynamic load balancing inherent programming paradigm 
interesting point note predicted times exceed measured values large numbers processors 
explained theoretical model assumes total comp comm actual practice computation communication overlapped amount directly proportional number processing elements 
addition providing close match predicted observed results mandelbrot computation experiment suggests algorithm dynamic load balancing yield superior results allow effective modeling behavior 
number processors total time compute mandelbrot set pvm pixel window ipsc measured times pvm stream measured times pvm datagram measured times ipsc predicted times pvm stream predicted times pvm datagram predicted times 
proposed techniques strategies previous section described experimental results obtained execution example applications compared predicted behavior pvm programs 
relatively close conformance expected observed values encouraging 
classes applications approximate modeling program characteristics viable proposition 
analyses experiments lead stage experimentation strategies techniques improve performance pvm programs achieve optimal efficiency constraints operating general purpose environment subject varying external influences 

efficiency analysis results section apparent theoretical model provides adequate framework analyze efficiency expected performance application algorithms 
addition modeling execution time benefits may drawn methodology 
example examining properties formulas expected times optimal number processing elements utilize inferred 
communication cost inversely related computation time generally increases number processors 
consequence algorithms scale number processing elements increases cost communication prohibitive impede performance gains 
graph total time scalable algorithm exhibit constant downward slope algorithms slope curve increase approach pass 
point additional processors wasteful contribute increased speed 
order avoid situation useful able predict number processing elements order ensure minimal time optimal resource usage 
consider sorting algorithm described preceding sections 
formula model behavior derivative function follows dp total oper log oper log log appropriate constants hypercube list size examined earlier inserted equation yields solution total zero slope time curve approximately processors 
minimum value curve occurs point optimum number processors 
finding supported slight increase total time processors observed estimated values seen 
constants pvm datagram stream protocols substituted equation optimal number processors respectively results supported graphs 
approach may useful making accurate prediction algorithms maximum efficiency ensured 
similar exercise carried matrix multiplication algorithm 
derivative estimator function follows taken total number processors dp total add mult solving equation hypercube previously discussed matrix dimension yields processing elements 
true minimum point graph total time performance noticeably degraded lower rate parallelism 
empirically demonstrates processors constitute inefficient resources 
minimum point graph total time important indicator performance magnitude curve slope 
analysis efficiency include upper bound slope total time slope rises user specified value efficiency degraded point parallelism considered counterproductive qualitative sense construed suboptimal resources 
particular concern algorithm model produces continuously decreasing function minimum exists 
pvm models exhibited similar behavior correctable establishing upper bounds 
examination performance levels various implementations mandelbrot set calculations see shows agenda parallelism ameliorate effects load imbalance noticeable degradation number processing elements employed increases 
utilizing notion upper bounds slope time curve yield superior efficiency performance 
analysis run time efficiency classes parallel applications provide effective means ensuring optimal performance maintaining efficient resources 

alternative protocols analysis pvm communication costs previous section observed communication mechanisms datagram stream drawbacks 
datagram communication method advantage connection maintenance overheads avoided scaling bottlenecks encountered 
stage scheme considerable overheads incurred communication prohibitively expensive 
stream approach exhibits superior performance drawbacks 
connection establishment expensive scheme unsuitable time short message exchanges 
systems number stream connections subject certain restrictions factor lead scaling limitations 
order address drawbacks investigating alternative protocol architectures aimed providing high performance services network computing 
effort dcl protocol suite preliminary description protocol may 
basic premise distributed systems inherently require different subset communication services provided local networks devising protocol operates directly data link layer 
schematic protocol architecture shown 
preliminary test implementation protocol showed communication costs greatly reduced estimates experimental platform conventional transport tcp udp network layer ip dcl protocol suite remote procedure call including presentation remote concurrent distributed 
multiway async communications data link protocol ethernet fddi distributed 
nfs window systems ftp telnet ms ms byte respectively 
protocol utilized pvm system application speedups improve significantly 
speedup curves previously examined applications pvm datagram stream protocol shown figures respectively estimated curves communication costs dcl protocol shown 
agenda parallel algorithm mandelbrot set calculation regular symmetric matrix multiplication algorithm approach linear speedup tree sorting algorithm approaches logarithmic speedup 
results encouraging demonstrate network cluster computing environment capable behaving near ideal manner 
notwithstanding results expected gains take account load imbalance due external factors 
improvements may possible conditions monitored algorithm dynamically adapted response 

partitioning scheduling schemes discussed section load imbalance caused external factors contributes performance degradation 
order test extent factor degrades performance matrix multiply application reorganized different ways executed conditions earlier 
method hierarchical pmr variant original pipe multiply roll algorithm 
method level hierarchy block multiplications level implemented number processors pvm speedup curves datagram communication mandelbrot matrix multiplication sorting number processors pvm speedup curves stream communication mandelbrot matrix multiplication sorting number processors pvm speedup curves dcl communication mandelbrot matrix multiplication sorting pmr algorithm second level 
results experiment disappointing worse regular pmr timings 
degradation caused combination increased low volume communication exacerbated effects load imbalance owing lowered granularity 
second approach reimplement matrix multiplication bag tasks algorithm retaining block multiplication paradigm maintaining volume communication 
done having master process maintain queue pending task multiplication matrix subblock 
dynamic load balancing scheme master process assigned tasks processing elements available collected results entered new tasks queue 
scheme assigns lightly loaded processing elements minimizes execution time 
results experiment extremely encouraging resulted identical correspondence predicted results 
empirically agenda parallelism possibly best model achieving maximal performance gains network environment 
comparison different strategies relationships expected behavior shown graph 
number processors matrix multiplication pvm datagram predicted vs measured predicted time measured pmr measured bag tasks measured hierarchical pmr 
dynamic resource monitoring experiment dynamic load balancing described resource characteristics individual processing elements determined early late completion application tasks assigned 
order able precisely determine usable resource levels different processors pvm machine configuration developed set extensions pvm system 
essentially extensions permit instantaneous measurements various system parameters including cpu load average available occupied memory interrupt levels activity addition time measurements message packing transmission times raw processor speeds primitive arithmetic operations 
currently attempting formulate model parameters combined similar parameterization application characteristics identify best suited location task subtask 
intend scheme operate different levels granularity process level initial placement data subblock level agenda parallelism model finer level explained subsection 
domain specific library interface user program pvm internetwork input data 
domain specific library architecture pvm pvm daemon domain specific pvm daemon domain specific pvm daemon domain specific pvm daemon domain specific library daemon library daemon library daemon library daemon init cc leave cc cc sort list cc factor 
domain specific concurrent libraries promising approach investigating concept domain specific libraries integrated pvm framework 
motivation approach derived fact concurrent applications composed distinct algorithms typically driven results previous 
algorithms defined computations matrix factorization solution pde fourier transforms algorithms understood different parallel solutions proposed 
providing predefined concurrent versions basic modules implemented multiple ways application user need invoke appropriate module sequential program pvm library subsystems execute modules concurrently utilizing best algorithm available depending user supplied flags heuristics problem size nature network approach permits partitioning scheduling schemes appropriate instantaneous resource usage levels readily available framework 
preliminary architectural design model shown 

discussion objectives investigate issues modeling concurrent applications executing heterogeneous networked environments 
owing multitude factors environments subject complete formal analysis thought difficult possibly intractable 
approach informal nature initial experiences promising 
representative applications studied simple models communication computation proven adequate informative 
models may predict application behavior determine appropriate number processing elements result near optimal efficiency 
results proposed strategies may employed order increase effectiveness network computing 
course findings preliminary may possible generalize wider range applications general networked environments 
direction intend analyze comprehensive set application categories address methods precisely identifying external processor network load factors integrate generalized model network concurrent computing 

fox parallel computing comes age supercomputer level parallel computations caltech concurrency practice experience vol 
pp 
september 
sunderam pvm framework parallel distributed computing concurrency practice experience vol 
pp 
december 
ahuja carriero gelernter linda friends ieee computer vol 
august 
flower express programming environment report july 
geist sunderam network concurrent computing pvm system appear concurrency practice experience 
sunderam heterogeneous environments network concurrent computing appear journal generation computer systems 
beguelin dongarra geist manchek sunderam graphical development tools network concurrent supercomputing proc 
acm supercomputing pp 
november 
fox solving problems concurrent processors vol prentice hall englewood cliffs 
quinn designing efficient algorithms parallel computers mcgraw hill new york 
carriero gelernter write parallel programs guide acm computing surveys vol 
september 
benchmarking ipsc hypercube multiprocessor concurrency practice experience vol 
pp 
september 
sunderam inclusive session level protocol distributed applications proc 
acm sigcomm symposium communication architectures protocols pp 
september 
quinn parallel sorting algorithms tightly coupled multiprocessors parallel computing pp 

evans parallel sorting merging algorithm tightly coupled multiprocessors parallel computing pp 

yeh efficient sorting algorithm hypercube multiprocessor proceedings third annual parallel processing symposium pp 
march 
guan time space optimal parallel merging sorting ieee transactions computers vol 
pp 
may 
