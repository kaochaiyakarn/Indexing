xrules effective structural classifier xml data mohammed zaki rensselaer polytechnic institute zaki cs rpi edu xml documents ubiquitous varied applicability number applications 
classification important problem data mining domain current classification methods xml documents ir methods document treated bag words 
techniques ignore significant amount information hidden inside documents 
discuss problem rule classification xml data frequent discriminatory substructures xml documents 
technique capable finding classification characteristics documents 
addition technique extended cost sensitive classification 
show effectiveness method respect classifiers 
note methodology discussed applicable kind semi structured data 
categories subject descriptors database management data mining keywords xml semi structured data classification tree mining 
classification problem defined follows 
input data set called training data consists set multi attribute records special variable called class 
class variable draws value discrete set classes 
training data construct model relates feature variables training data class variable 
test instances classification problem consist set records supported part nsf career award iis doe career award de fg er nsf eia 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigkdd august washington dc usa copyright acm 
aggarwal ibm watson research center ibm com feature values known class value unknown 
training model order predict class variable test instances 
classification problem widely studied database data mining machine learning communities :10.1.1.50.8204
methods developed general multi dimensional records 
particular data domain strings text classification models specific domains turn effective 
years xml popular way storing data sets semi structured nature xml allows modeling wide variety databases xml documents 
xml data forms important data mining domain valuable develop classification methods data 
currently problem classification xml data studied spite applicability wide variety problems xml domain 
xml documents text documents natural alternative cases standard information retrieval methods classification 
simple frequently method classification nearest neighbor classifier 
method works quite text applications containing small number class labels 
text format classification ignores significant amount structural information xml documents 
cases classification behavior xml document hidden structural information available inside document 
cases ir classifiers ineffective xml documents 
second promising methodology xml mining directly association classifiers cba xml data 
xml data record hierarchical structure structure flattened set allows association classifier 
results loss structural information accuracy somewhat better bag words approach text classifier 
focused rule classifiers effective tool data classification 
rule classifiers extended string classification problem 
rule classifiers interesting method integrate problem associations classification 
techniques provide effective scalable alternative classification turn highly interpretable nature 
discuss problem constructing structural rules order perform classification task 
training phase finds structures closely related class variable 
words presence particular kind structural pattern xml document related likelihood belonging particular class 
training phase completed perform testing phase rules perform structural classification 
show resulting system significantly effective association classifier ability mine discriminatory structures data 
main contribution propose xrules structural rule classifier semi structured data 
order develop mines pertinent structures multiple classes simultaneously 
extend classifier cost sensitive case handle normal skewed class distributions 
show class assignment decisions rooted bayesian statistics 

structural rules concepts model xml documents ordered labeled rooted trees child order matters node label 
distinguish attributes elements xml document mapped label set 
trees embedded subtrees denote tree xml document set labeled nodes set branches 
label node taken set labels called items different nodes label 
branch ordered pair nodes parent size number nodes say tree vs bs embedded subtree denoted provided vs ii bs ancestor note traditional definition induced subtree branch bs parent embedded subtrees generalization induced subtrees allow direct parent child branches ancestor descendant branches 
embedded subtrees able extract patterns hidden embedded deep large trees captured traditional definition 
say contains sub tree size called sub tree 
cost classification classification model discussed general case cost sensitive classification 
section provide definitions relevant topic 
assume training database classification consists set structures associated class variables 

ck classes data 
structure notation refer class associated assume structures xml document represented tree format 
database essentially forest components trees forest labeled class variable 
class label structure induces partition database disjoint parts 
tree structured xml documents widely occurring real applications 
note xml document tree converted node splitting methodology 
di ci di consists structures class ci 
clearly di 
goal classification learn model cj cj predict class label unlabeled test instance 
find classifier performs measuring accuracy 
collection structures known labels denote number correct predictions model examples di gives number correct predictions examples class ci di gives total number correct predictions classes 
accuracy classification model data set ratio correct predictions total number predictions classifier models accuracy biased favor classes higher probability occurrence 
real applications cost predicting class correctly preferable notion cost sensitive accuracy 
class ci wi denote positive real number called weight constraint wi 
cost sensitive accuracy denoted cs defined weighted average accuracy classifier class 
formally define cs wi di cost models compute classification accuracy proportional model uses wi di weights proportional probability class equal model uses wi classes weighted equally 
inverse model uses wi kj weights inversely proportional class probability 
custom model uses user defined weights wi 
lemma 
proportional model cs 
proof cs di di di di di di contrast inverse cost model proportional equal model 
inverse model works binary classification problems skewed class distribution gives higher reward correct rare class prediction 
rule support collections trees class labels drawn tree define absolute support denoted number trees contain relative support denoted fraction trees contain said frequent min min user defined minimum support threshold 
rules defined entities relate frequent structures left hand side class variables right 
rules able relate complex structural patterns data class variable 
formally structural rule entity form ci structure ci classes 
rule implies substructure xml record record belong class ci 
goodness implication defined parameters refer support strength 
global support ci database defined joint probability ci percentage trees database containing having class label ci 
formally ci ci di di di step follows equation 
local support rule ci simply relative frequency di di 
rule strength strength structural rule measured different measures focus confidence likelihood ratio weighted confidence defined 
confidence confidence structural rule ci defined conditional probability class ci ratio number trees containing having class label ci number trees containing entire database 
formally define ci ci ci di assume classes ci ci set classes ci 
define di di set trees classes taken ci 
approach multi class problems treat binary class problem follows compare class ci rest classes taken group form negative class ci 
compare ci ci 
observation di di rewrite equation ci di di di clear ci ci 
likelihood ratio likelihood ratio rule ci defined ratio relative support examples class ci relative support examples having negative class ci 
formally defined follows ci di di di di di di lemma 
likelihood ratio rule related confidence formula ci ci di ci di proof equation get di ci similarly di 
plugging equation ci ci ci di di ci di ci di weighted confidence define measure called weighted confidence combines measures follows ci di di di rewrite equation weighted version equation follows ci di di di di di di words confidence uses absolute supports weighted confidence uses relative supports weighted class probability 
lemma weighted confidence thought normalized likelihood measure 
lemma 
weighted confidence rule related likelihood formula ci ci ci proof equation di ci di 
plugging equation get ci di ci di di ci ci value lies take values 
experiments study effects measure 
denote measure strength confidence weighted confidence likelihood 
notation ci denote rule support strength 
goal learn structural rule set rule form min min rules satisfy user defined level minimum support min global minimum strength threshold min note min min weighted confidence measure min min likelihood measure 
set default minimum strength values min min bayesian interpretation strength classes 
ck ci ci 
di portion data set class ci di remaining data set class ci 
unseen example assigned class ci probability class ci ci greatest classes assign class ci ci cj 
compare class ci negative class ci assign class ci ci ci ci ci ci ci bayes thm 
ci ci ci ci strength measures differ equation class prediction 
instance confidence measure notation denotes entities equivalent 
directly uses equation definition equation ci ci 
confidence measure assigned class ci ci ci 
likelihood measure uses equation 
rearranging terms equation get ci ci ci ci ci plugging di similarly ci get di di ci definition likelihood equa ci tion ci di bayes rule di equation assigns class ci ci likelihood measure assigns class ci ci min default value min corresponds ignoring ratio class prior probabilities setting ratio 
general proportional equal cost model logical sense class priors absence information predict class class higher prior 
ci rare inverse cost model better ignore prior prior ratio biased favor class higher probability 
setting prior ratio set classes equal footing 
weighted confidence measure uses equation consider lhs lhs ci ci setting ci ci ci ci ci ci di di ci ci di di get ci ci ci ignoring class priors ratio setting obtain definition weighted confidence equation 
lhs equation corresponds ci bayes rules assign class ci ci ci 
described confidence measures strength entire database hand likelihood measures local tendency pattern associated target class compares local support rule target class ci local support negative class ci rest classes 
skewed data sets uneven class distributions confidence biased favor dominant class globally patterns associated class higher absolute supports compared minority class 
likelihood weighted confidence bias ignore class priors local relative supports 

xrules structural rule classification classification task contains phases 
training phase uses database structures known classes build classification model case set structural classification rules called rule set 
testing phase takes input database structures unknown classes goal classification model predict classes 
training phase classification database di known classes di set structures class ci 
goal learn structural rule set rule form min min main steps training phase mining frequent structural rules specific class sufficient support strength 
step find frequent structural patterns class generate rules satisfy user defined level minimum support class ci min global minimum strength threshold min ordering rules precedence relation 
set classification rules generated procedure required prioritize rule set decreasing level precedence prune rules 
determining special class called default class 
classifier predict class possible test cases need choose default class label test example rules predict label 
mining structural rules step accomplished efficient structural rule mining algorithm discuss detail section 
moment assume find structural rules related class 
accepts input list minimum support thresholds class min outputs set frequent rules class rj mj mj rules rule having cj consequent min cj pruning ordering rules want predictive rules need remove rule lacks predictive power 
consider rule ci ri 
weighted confidence likelihood ratio distinguish class ci negative class ci prune rule ri 
general acceptable range values user defined minimum confidence threshold min acceptable range minimum likelihood min 
goal precedence ordering derive final combined rule set rule set class precedence relation imposes total order method analogous proposed cba 
rules say precedes denoted conditions met 
strength greater 
support greater 
contains smaller number nodes 

true occurs lexicographically note lexicographic ordering tree structures pre order traversal nodes tree 
precedence ordering sort rules classes derive final ordered rule set ri 
testing phase ordered rules various ways predict target class new structure unknown class 
determining default class rule ci said match tree antecedent substructure rule set said cover example tree rule matches general rule set may necessarily cover examples training set 
classifier provide coverage possible cases need define default label denoted default class chosen label test example rules match 
ti set examples training set covered ordered rule set ci set uncovered training examples class ci 
simple way choose default class pick majority class default class arg 
pick default class majority class problem method take consideration real cost classes uses proportional cost model default 
approach adopt choose class maximizes cost sensitive accuracy resulting rule classifier 
denote number correct predictions data set rule set default class default class arg maxc see lemma 
default class maximum weight wi obtained setting di 
clear technique superior perspective approach 
lemma 
cost sensitive accuracy maximized default class arg maxc 
proof assume 
base accuracy class ci di di di equation di base cost sensitive accuracy cs old wi di di assume pick class cj default class 
affects accuracy class cj due addition correct predictions class cj accuracy ci cj remains unchanged 
dj dj new accuracy dj cs wj dj dj wi di di simplifying get cs cs old 
cs old remains matter class pick default accuracy maximized class yielding maximum value set dj 
class yielding maximum accuracy maximum wj 
corollary 
proportional cost model accuracy maximized default class majority class 
proof assume 
substituting wi di wi di term maximized get maximized class maximum value majority class 
setting di gives desired result 
described prune rules having min min 
recall building model compare confidence rule class ci versus negative class ci 
cases rules may poorly related example 
happens average weighted confidence likelihood rules matched example close respectively class ci 
means rule equally predictive ci ci suitable classification 
user sets min min example matching rules having average weighted confidence range min min having average likelihood range min min assumed ambiguous case accurately classified 
ambiguous added default set essentially treating examples having matching rule final determination default class described 
testing phase training classification model complete 
consists ordered collection predictive rules default class 
testing phase takes input classification model data set examples unknown classes 
goal testing phase predict class test example 
main steps testing rule retrieval find matching rules example test example 
class prediction combine statistics matching rule predict class test example 
rule retrieval step simple test example database find set matching rules called matching rule set 
predicting class different approaches combining statistics matching rule set 
cases considered matching rules 
case class predicted default class default class 
hand ri denote matching rules class ci consequent ri ri 
rule ri form min matching rule ri predictive class ci 
finds support classes see section compute strength negative class ci ci 
strength ci rule ci equations 
class ci find strength structural rule class 
matching rule corresponds rule positive predictive power ci matching rule predictive negative class negative predictive power ci 
possible methods combining evidence average strength compute average rule strength class ci min classify having class ci 
default min values min min classes means test instance easily predicted rules class signed default class 
approach gen case ambiguous min min weighted confidence min min likelihood 
case assign default class 
best rule find rule matches rule 
rule set ordered precedence rule ci best predictive nature total order matching rule strength support specific 
predict ci 
best rules apply average strength method rules 
simple generalization case discussed 
experiments average confidence method combining evidence gave best results 
note average strength methods classification behavior test instance ambiguous equal close default min values classifier output fact useful information user 
classifiers traditionally strive coverage predict label test case practical application may benefit greatly knowledge fact certain test instances harder classify 
results lower coverage better understanding classification process 

order determine set rules xrules needs mine frequent subtrees data 
methods tree mining proposed freqt treeminer :10.1.1.104.714
freqt apriori style level wise candidate generation pattern matching counting approach 
similar approach described 
uses inductive logic programming approach complete method frequent subtrees especially support lowered different trees database common node labels 
treeminer uses novel vertical representation fast subtree support counting 
com plete method outperforms level wise method similar freqt 
chose treeminer basis 
dataset classes partitions di approach mining structural rules mine di separately treeminer combine results 
problems approach xrules needs know support tree class may frequent class di dj 
need extra scan count missing class supports approach inefficient 
extends treeminer find frequent trees related class incorporates multiple minimum support criteria class 
ensures tree generated suitable classification purposes 
treeminer utilizes vertical tree representation fast support counting uses depth dfs pattern search 
node number scope match label subtree tree xk refer node node defined number position depth pre order traversal tree 
notation ni refer ith node numbering scheme 

nl refer subtree rooted node nl nr right leaf node nl 
scope node nl interval lower bound position node nl upper bound position node nr 
shows database trees classes tree shows node number ni node scope node label inside circle 
tree class tree class class index database trees tree class prefix prefix prefix minsup tree mining example denote database trees forest subtree occurrence identified match label set matching positions nodes formally :10.1.1.50.8204:10.1.1.40.6757
tn nodes 
sm nodes match label ti ti 
tim sk ti 
label node branch sj sk iff ti ancestor ti condition indicates node labels match indicates tree topology matching nodes match label unique occurrence prefix group scope lists say subtrees prefix equivalence group iff share common prefix th node 
prefix subtree size 
notation refer group contain items th node trees share prefix 
notation refer scope list element scope list triple tree id tid occurs scope xk match label subtree occur multiple times tree tid associated multiple scopes match labels 
initial scope lists created single items occur tree scope node label match label item simply omit storing dealing scope lists single items 
show compute pattern frequency joins scope lists 
shows scope lists frequent single items minimum support classes 
item shown frequent class support class 
tree mining shows high level structure 
main steps include computation frequent items enumeration frequent subtrees dfs search group 
maintains global class index showing class tree database 
index quickly update class support candidate tree check frequent class 
shows class index example database 
min frequent subtrees class enumerate xrules enumerate xrules elements px elements frequent class px px enumerate xrules px tree mining classification input enumerate xrules set elements group scope lists 
frequent subtrees generated joining scope lists pairs elements including self joins 
joining scope lists pruning step inserted ensure subtrees resulting tree frequent 
true go ahead scope list join avoid join 
collection candidate subtrees obtained extending tree group adding item item tree prefix group 
denote possible candidate subtrees may result extending tree node tree item denoted denote respective scope lists 
subtrees frequent current level form elements groups level 
recursive process repeated frequent subtrees enumerated 
terms memory management easy see need memory store intermediate scope lists groups current group new candidate group px 
scope list joins describe perform scope list joins subtrees group 
sz lz uz denote scope node say sx strictly sy denoted sx sy ux ly 
say sx contains sy denoted sx sy lx ly ux uy 
join elements group possible outcomes add child sibling class px 
check subtree obtained added child occurs input tree tid sufficient search exists triples ty sy tx sx mx ty tx ii sy sx iii mx 
words check occur tree tid scope extensions prefix subtree match label mx 
conditions satisfied add triple ty sy lx scope list px 
refer case scope test 
second pattern checks happens added embedded sibling happens descendants node position prefix scope strictly scope check occurs embedded sibling tid need check exists triples ty sy tx sx mx ty tx ii sx sy iii mx 
conditions satisfied add triple ty sy lx scope list px 
refer case scope test 
shows process scope list joins scope tests 
check new candidate frequent derive class count class index 
example consider tree prefix group branch 
appears tids count tid 
class index find occurs classes respectively 
support class class 
frequent locally classes 

empirical results compared xrules structural classification approach xml documents ir classifier cba classifier 
ir classifier irc centroids class constructed clustering process 
nearest neighbor classifier implemented sets clusters 
cba implementation provided authors 
data sets evaluate approach real synthetic classification data sets 
advantage synthetic data sets additional flexibility studying effects different kinds embedded patterns database size 
hand real data sets help validate approach practical setting 
real datasets log markup language logml describe log reports cs department website 
logml provides xml vocabulary structurally express contents log file information compact manner 
user session expressed logml graph includes structure content 
real data set spans weeks worth xml user sessions 
convert classification data set chose categorize user session class labels edu corresponds users edu domain class corresponds users visiting cs department domain 
shown table separate week logs different data set stands week combined data weeks 
notice edu class lower frequency rate 
goal minimize cost classification inaccuracy various models 
notation denote trained tested 
example means learned model tested predict 
synthetic datasets constructed synthetic data generation program simulating website browsing behavior 
construct master website browsing tree parameters supplied user 
parameters include maximum fanout node maximum depth tree total number nodes tree number node labels node master tree assign probabilities children nodes including option backtracking parent sum probabilities 
master tree generate subtree ti randomly picking subtree root ti recursively picking children current node probability link 
create classification data set group users classes 
generate small pool signature trees class denoted tp 
second generate larger collection trees denoted td 
subset trees tp selected training testing pools td split training testing sets 
tree td contains tree signature pool class class 
control effects structure classification process fraction fc called confusion ratio trees belong class added class flattening 
called way addition 
allow members added called way addition 
different synthetic data sets generated shown table 
dsx data sets trained dsx train tested dsx test 
master tree values 
generated td trees database tp trees pool 
td split training test sets table characteristics datasets db sessions edu edu db total ds train ds train ds train ds train ds train ds test ds test ds test ds test ds test split 
ds training testing pool size half trees common 
set fc way addition 
ds training testing pool identical size fc 
ds ds way confusion 
ds ds way addition half time fc 
small data set ds produced different synthetic xml document generator comparative classification results irc approach uses actual text data order perform classification 
uses greater amount information purely structural classifier xrules 
irc uses node content edge information user sessions 
contrast xrules uses structure tree format classification process 
cba uses associations different nodes visited session order perform classification 
table shows weighted accuracy results classifiers different data sets 
table shows accuracy cost models 
best accuracy highlighted bold 
see data sets cost models xrules best classifier 
data sets xrules delivers accuracy proportional model compared irc accuracy cba accuracy 
accuracy xrules higher absolute accuracy irc higher cba traditional proportional model 
model cba appears better classifier irc 
model cba learns generally rule 
rule predicts test case 
strategy pays proportional cost model majority class occurrence equal model accuracy fails completely inverse cost model accuracy 
irc better job cba distinguishing class 
example consider confusion matrix shown table shows number test cases class correctly incorrectly classified classifiers proportional cost model 
cba essentially labels test case ineffective provided personal communication table accuracy results db classifier accuracy proportional equal inverse xrules irc cba xrules irc cba xrules irc cba xrules irc cba ds xrules cba ds xrules cba ds xrules cba ds xrules cba ds xrules cba table confusion matrix predicted class xrules irc cba edu edu edu edu cost model proportional 
equal inverse cost models find xrules higher accuracy cba irc explicitly incorporates cost 
case data sets accuracy xrules higher irc higher cba equal cost model 
situation pronounced inverse model accuracy xrules higher irc higher cba 
synthetic data sets content structure ir classifier 
compared xrules cba 
results shown table 
cba degenerated default classifier time labeling test case majority class small number rules relating classes 
see proportional cost model ds ds ds cba fails classify test cases correctly delivering accuracy accuracy xrules higher 
ds ds cba discrimination power accuracy xrules higher 
equal inverse model xrules outperforms cba 
summary xrules gives consistently better performance classifiers cost models data sets 
works better associative classification approach cba flattens structure set representation 
outperforms ir classifier explicitly learns content implicitly structural information xml documents 
improved results structural classification process especially significant 
efficiency results table shows number frequent patterns rules mined time training testing 
results underscore high efficiency xm engine 
frequent trees classification determined seconds 
total training testing time comparable cases find matching rules example 
needed determine default class training find accuracy testing 
running time improved storing rules appropriate index structure currently xrules performs linear search matching rules 
table number rules time db sup rules train time testing xm total time ds ds ds ds ds choice rule strength study choice strength measure affects accuracy xrules shown table 
best results bold 
proportional model confidence performs better likelihood weighted confidence 
accuracy typically higher higher dsx data sets 
agreement bayesian interpretation section 
hand exception ds ds likelihood weighted confidence perform better confidence equal cost model 
weighted confidence slight insignificant edge likelihood proportional equal costs 
likelihood measure slight edge weighted confidence inverse cost model data sets 
results agreement discussion section 
exceptions ds ds confidence better 
reason data sets confusion factor complicates decision making way twoway addition adds patterns class vice versa 
ds measures give result 
summary conclude confidence better measure proportional model likelihood weighted confidence better equal inverse costs 
right choice strength measure depends data set characteristics cost model 
expect patterns similar global supports different local supports rare classes likelihood weighted confidence measure usually provide better results 
effect minimum strength table shows effect varying minimum likelihood min accuracy prediction 
best accuracy cost model bold 
proportional cost model accuracy tends increase point min starts drop 
effect table effect strength measure db strength proportional equal inverse ds ds ds ds ds observed inverse model model continues improve min 
equal cost model accuracy tails 
similar results obtained strength measures 
results suggest choosing appropriate min get model behave proportional model min get accuracy compared accuracy confidence table improve accuracy inverse model 
table effect likelihood ratio min proportional equal inverse rules time 
summary discussed effective rule classifier xml data called xrules 
technique mines frequent structures data order create classification rules 
xrules cost sensitive uses bayesian rule class decision making 
methods effective rule prioritization testing proposed 
technique implemented compared cba ir classifier 
technique performs better cba classifier indicates system relies classification information hidden structures effective rule generation process 
furthermore outperforms ir method spite greater amount input 
results show structural mining provide new insights process xml classification 

aggarwal 
effective classification strings wavelets 
sigkdd 
aggarwal gates yu 
merits supervised clustering build categorization systems 
sigkdd 
agrawal srikant 
fast algorithms mining association rules 
vldb conference 
ranka singh 
clouds decision tree classifier large datasets 
sigkdd 
andersen professional xml 
press 
asai efficient substructure discovery large semi structured data :10.1.1.104.714
nd siam int conference data mining 
cohen 
fast effective rule induction 
int conf 
machine learning 
domingos 
metacost general method making classifiers cost sensitive 
sigkdd 
dong zhang wong li 
classification aggregating emerging patterns 
int conference discovery science 
duda hart 
pattern classification scene analysis wiley new york 
gehrke ganti ramakrishnan 
loh 
boat optimistic decision tree construction 
sigmod 
james 
classification algorithms wiley 
li han pei 
accurate efficient classification multiple class association rules 
ieee int conf 
data mining 
quinlan 
programs machine learning 
morgan kaufmann 
rastogi shim 
public decision tree classifier integrates building pruning 
vldb 
liu hsu ma 
integrating classification association rule mining 
sigkdd 
nigam mccallum mitchell 
text classification labeled unlabeled documents em 
machine learning 
krishnamoorthy zaki 
logml log markup language web usage mining 
webkdd workshop sigkdd august 

rousset sebag 
step xml data mining 
ieee int conf 
data mining 
wang liu 
discovering typical structures documents road map approach 
sigir 
zaki 
efficiently mining frequent trees forest 
sigkdd 
