learning statistical structure object detection henry schneiderman robotics institute carnegie mellon university pittsburgh pa usa cs cmu edu www cs cmu edu index html 
classes images exhibit sparse structuring statistical dependency 
variable strong statistical dependency small number variables negligible dependency remaining ones 
structuring possible construct powerful classifier representing stronger dependencies variables 
particular bayes classifier compactly represents sparseness 
semi na bayes classifier decomposes input variables subsets represents statistical dependency subset treating subsets statistically independent 
learning structure semi na bayes classifier known np complete 
high dimensionality images statistical structure learning especially challenging 
describes algorithm searches structure semi na bayes classifier large space possible structures 
algorithm seeks optimize cost functions localized error log likelihood ratio function restrict structure global classification error choose final structure 
approach train detectors objects including faces eyes ears telephones push carts door handles 
detectors perform robustly high detection rate low false alarm rate unconstrained settings wide range variation background scenery lighting 
appear caip classes images sparse structuring statistical dependency 
variable strong statistical dependency small number variables negligible dependency remaining ones 
example geometrically aligned images faces cars push carts telephones exhibit property 
shows empirical mutual information wavelet variables representing frontal human face images 
mutual information measures strength statistical dependence variables 
image visualization mutual information values chosen wavelet variable indicated arrow variables wavelet transform 
brightness location indicates mutual information variable location chosen variable 
examples illustrate common behavior variable statistically related small number variables 
chosen variable chosen variable sparse structuring statistical dependency explains empirical success parts methods face detection face recognition 
parts methods concentrate modeling power localized regions dependencies tend strong weaker models larger areas dependencies tend significant 
general problem learning statistical dependency structure image classification received attention computer vision community 
previous parts methods hand picked parts propose method learn dependency structure data dependency structure build semi na bayes classifier 
semi na bayes classifier decomposes input variables subsets representing statistical dependency subset treating subsets statistically independent 
classifier 
xn takes form written log likelihood ratio test chosen variable fig 

empirical mutual information wavelet variables sampled frontal faces images 
sr log log 
log sr 
xn input variables 
sr subsets variables indicate classes 
problem object detection classes object non object non object class represents possible visual scenery contain object 
example may correspond face may correspond non face form classifier chooses class 
xn 
chooses class 
learning structure semi na bayes classifier challenging 
search space enormous 
super exponential input variables typically image classification 
solution np complete compare possible structure order find optimal solution 
bayesian score ideal metric comparing model structures 
naturally penalizes overfitting 
computing score model involves summing probabilities training data possible instantiations model parameters 
computational cost doing quite large 
solution heuristic search approximate metrics unavoidable 
lower dimensional domains variables proposed methods focused joining variable time estimates pair wise distributions accuracy cross validation 
method induces products decision tree structures 
strategy selects structure sequentially optimizing cost functions greedy search techniques 
function models local error log likelihood ratio function pairs variables 
function assumes pair variables independent remaining variables 
organize variables subsets measure minimized 
particular generate large semi redundant pool candidate subsets 
second optimization chooses final solution subset candidate subsets minimizing global measure classification error 
method context object detection 
object detection task finding instances object image size 
perform detection classifier discriminates object scenery contain object 
classifier operates fixed size input window frontal faces allows limited amount variation size alignment object window 
perform detection exhaustively scan classifier input image step size pixels resized versions input image scale factor step size 
approach construct classifiers detecting types objects faces eyes ears telephones push carts door handles 
detectors perform robustly high detection rate low false alarm rate unconstrained scenery wide range variation background scenery lighting 
construction classifier aspects constructing classifier learning structure classifier assignment variables subsets equation estimating probability distributions subset 
approach steps coupled 
section describes initial selection pool candidate subsets 
section describes estimation probability distributions candidate subsets 
section describes selection subset candidate subsets form final classifier 
training data consists images object class various images class 
input classifier 
xn wavelet transform input window 
method specific wavelet transform 
raw pixel variables transform image 
details image pre processing training data system detection refer 
minimizing local error log likelihood ratio step creates large collection subsets variables 
selection subsets reduces representational power 
dependencies subset represented 
decide variables represent dependencies represent 
evaluate cost proposed reduction error modeling log likelihood ratio function 
error metric difference true log likelihood ratio function log likelihood ratio reduction 
compute error pairs variables 
particular consider possible cases costs xi xi xi abs log log xi xixj xi xi xi abs log log xi xixj xi xi abs log xi xixj note random variables assumed discrete valued 
upper case notation denote random variable lower case notation denote particular instantiation variable sum possible values random variable 
error modeling variables xi xj independent cost removing dependency variables 
error removing variable xj pair 
error removing variables pair 
assumes pair xi xj independent remaining input variables 
obtain measures empirically estimating probability distributions xi xj xj pairings variables xi xj 
approximations error associated choice subsets 
sr computed xi ii sk sk sk sk sk sk sk sk xi sk xi xi sk xi sk seek set candidate subsets minimize localized error function 
search solution steps 
step assigns variables subsets greedy searches input variable seed search 
guarantees variable represented subset errors form step 
fairly reasonable way optimize errors due removing variable tend greater removing dependency 
greedy searches adds new variables choosing largest sum values formed pairing current members subset 
selection process guarantee variables subset strong statistical dependency 
second search may desirable reduce number subsets smaller collection 
propose sequentially removing subsets desirable number remaining 
step remove subset lead smallest increase modeling error 
particular follows equation error removing subset sk si si si si si si si si si si si si experiments describe number selected candidate subsets ranged 
computational cost linear number candidate subsets prohibitive large numbers 
sizes subsets somewhat open question 
larger subsets potential capture greater dependency 
subset size increases dimension probability distributions equation size balanced practical limits representational power limited training data 
possible way addressing issue terms vc dimension described bayesian scoring techniques simplicity describe algorithm assuming subsets number members experiments consider multiple sizes leading initially mn subsets number sizes allow greater variety representation 

estimating probability distributions step estimates log likelihood ratio functions log sk sk candidate subset sk 
functional form gaussian mixture model bayes net non parametric admissible choice sk sk 
general classification functions linear quadratic discriminants neural networks decision trees may admissible log sk sk proper normalization 
current experiments represent probability distribution table 
representation discretizes subset wavelet variables discrete feature value vector quantization 
see details representation 
probability tables estimated counting frequency occurrence feature value training data 

minimizing global classification error form structure semi na bayes classifier choosing group candidate subsets form final classifier 
choose combination minimizes empirical classification error score 
measure performance area receiver operating characteristic roc 
measure classification error accounts classifier full operating range values threshold equation 
difficulty making selection combinatorial space candidate subsets enormous 
greedy search incrementally combine subsets 
search cost evaluating candidate combination example small 
particular evaluation combination subsets takes form equation simply sum evaluations individual candidate subsets 
individual candidate log likelihood ratio functions evaluated example 
evaluate combination sum appropriate pre computed values 
practice may desirable repeat process times time prohibit identical choices previous searches 
particular experiments part strategy finds candidate combinations comparing performance training data images estimate probability distributions chooses best comparing performance cross validation data images separate aspects training 

object detection experiments method train detectors frontal faces eyes ears telephones door handles 
frontal face detection method achieves relatively accurate detection rates fairly low computational cost 
table show results mit cmu test set 
recognition rate false detections results equal superior state art detectors testing set including 
human eye detector trained method tested extensively 
eyes successfully located radius pixels accuracy images faces experiment independently conducted national institute standards technology nist nist employees reported back author 
dataset available public 
dataset consists images face person image face prominent object image 
algorithm assumed face image experiment 
telephone detector tested model telephone set images telephones 
telephones small variations design coloring age examples shown 
table gives performance different values classification threshold column recognition rate false detections author acknowledge jonathon phillips patrick sam assistance running experiments 
accurate efficient detectors trained human ears push carts door handles illustrated figures graphic overlays indicate detected positions objects 

sparse structuring statistical dependency possible construct powerful classifier representing stronger dependencies group variables 
illustrated structure exploited semi na bayes classifier model 
particular shown structure classifier learned search optimizes local error criterion equation followed search optimizes global error criterion described section 
shown classifier effective difficult object detection tasks 
believe techniques learning statistical structure carry complex models 
particular semi na bayes model basic form larger graphical probability family models including bayes nets markov random fields factor graphs chain graphs mixtures trees 
models possible represent complex structural relationships conditional independence hold promise improved image classification object recognition 

schneiderman kanade object detection statistics parts appear international journal computer vision 

rowley baluja kanade neural network face detection 
ieee transactions pattern analysis machine intelligence 

moghaddam pentland probabilistic visual learning object representation ieee transactions pattern analysis machine intelligence 
heisele serre pontil poggio 
component face detection cvpr 

viola jones rapid object detection boosted cascade simple features 
cvpr 

kononenko semi na bayesian classifier sixth european working session learning 
pp 


domingos pazzani 
optimality simple bayesian classifier zero loss 
machine learning 

theory applications attribute decomposition ieee international conference data mining 
pp 


cooper herskovits bayesian method induction probabilistic networks data machine learning 


sung poggio 
example learning view human face detection 
ieee transactions pattern analysis machine intelligence 

roth yang ahuja snow face detector 


schneiderman cmu robotics institute tech report 
preparation 

duda hart stork pattern classification 
john wiley sons 

heckerman geiger chickering 
learning bayesian networks combination knowledge statistical data machine learning 
friedman koller 
bayesian network structure bayesian approach structure discovery bayesian networks machine learning journal 
fig 

face eye ear detection fig 

door handle detection fig 

telephone detection fig 

push cart detection 
