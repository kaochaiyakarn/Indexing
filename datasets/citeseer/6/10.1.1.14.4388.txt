proceedings hlt naacl pp 
edmonton canada 
may weakly supervised natural language learning redundant views vincent ng claire cardie department computer science cornell university ithaca ny yung cardie cs cornell edu investigate single view algorithms alternative multi view algorithms weakly supervised learning natural language processing tasks natural feature split 
particular apply training self training em task find fs em new variation em incorporates feature selection outperform cotraining comparatively sensitive parameter changes 
multi view weakly supervised learning paradigms training blum mitchell em nigam ghani learn classification task small set labeled data large pool unlabeled data separate redundant views data disjoint feature subsets represent data :10.1.1.114.9164
multi view learning successfully applied number tasks natural language processing nlp including text classification blum mitchell nigam ghani named entity classification collins singer base noun phrase bracketing pierce cardie statistical parsing sarkar steedman :10.1.1.114.9164
theoretical performance guarantees multi view weakly supervised algorithms come fairly strong assumptions views 
view sufficient learning concept 
second views conditionally independent class label 
conditions met blum mitchell prove initial weak learner boosted unlabeled data 
unfortunately finding set views satisfies conditions means easy problem 
addition empirical results muslea 
nigam ghani shown multi view algorithms quite sensitive underlying assumptions views 
effective view factorization multi view learning paradigms remains important issue successful application 
practice views supplied users domain experts determine natural feature split expected redundant view expected sufficient learning target concept conditionally independent class label 
investigate application weakly supervised learning algorithms problems obvious natural feature split exists hypothesize cases single view weakly supervised algorithms perform better multi view counterparts 
motivated part results mueller 
task noun phrase coreference resolution illustration 
experiments compare performance blum mitchell training algorithm commonly single view algorithms self training expectation maximization em 
comparison training self training achieves substantially superior performance sensitive input parameters 
em hand fails boost performance attribute phenomenon presence redundant features underlying generative model 
consequently propose wrapper feature selection method john em results performance improvements comparable observed self training 
results suggest single view abney argues conditional independence assumption remarkably strong rarely satisfied real data sets showing weaker independence assumption suffices 
mueller 
explore heuristic method view factorization related problem anaphora resolution find training shows performance improvements type german anaphor pronouns baseline classifier trained small set labeled data 
weakly supervised learning algorithms viable alternative multi view algorithms data sets natural feature split separate redundant views available 
remainder organized follows 
section presents overview weakly supervised learning algorithms mentioned previously 
section introduce noun phrase coreference resolution describe machine learning framework problem 
section evaluate weakly supervised learning algorithms task coreference resolution 
section introduces method improving performance weakly supervised em feature selection 
conclude section 
weakly supervised algorithms section give high level description implementation weakly supervised algorithms comparison training em 
training training blum mitchell multi view weakly supervised algorithm trains classifiers help augment labeled data separate redundant views data :10.1.1.114.9164
classifier trained view data predicts labels instances data pool consists randomly chosen subset unlabeled data 
selects confident predictions pool adds corresponding instances predicted labels labeled data maintaining class distribution labeled data 
number instances added labeled data classifier iteration limited pre specified growth size ensure instances high probability assigned correct label incorporated 
data pool instances drawn unlabeled data process repeated iterations 
testing classifier independent decision test instance decision associated higher confidence taken final prediction instance 
self training self training single view weakly supervised algorithm appeared various forms literature 
version algorithm consider variation banko brill 
initially bagging breiman train committee classifiers labeled data 
specifically classifier trained bootstrap sample created randomly sampling instances replacement labeled data size bootstrap sample equal labeled data 
member committee bag predicts labels unlabeled data 
algorithm selects unlabeled instance adding labeled data bags agree label 
ensures unlabeled instances high probability assigned correct label incorporated labeled set 
steps repeated unlabeled data labeled fixed point reached 
breiman perform simple majority voting committee predict label test instance 
em em single view weakly supervised classification algorithm introduced nigam 

classic unsupervised em algorithm dempster weakly supervised em assumes parametric model data generation 
labels unlabeled data treated missing data 
goal find model posterior probability parameters locally maximized labeled data unlabeled data 
initially algorithm estimates model parameters training probabilistic classifier labeled instances 
step unlabeled data probabilistically labeled classifier 
step parameters generative model re estimated initially labeled data probabilistically labeled data obtain maximum posteriori map hypothesis 
step step repeated iterations 
resulting model predictions test instances 
machine learning framework coreference resolution noun phrase coreference resolution refers problem determining noun phrases nps refer real world entity mentioned document 
section give overview coreference resolution system weakly supervised algorithms described previous section applied 
framework underlying system standard combination classification clustering employed supervised learning approaches ng cardie soon 

specifically coreference resolution recast classification task pair nps classified referring constraints learned annotated corpus 
training instances generated pairing np preceding nps document 
classification associated training instance coreferent coreferent depending nps feature type feature description lexical pro str nps pronominal string pn str nps proper names string soon str nps non pronominal string np id matches np jd grammatical pronoun np id pronoun pronoun np jd pronoun demonstrative np jd starts demonstrative proper nouns nps proper names na exactly np proper name number np pair agree number disagree na number information nps determined 
gender np pair agree gender disagree na gender information nps determined 
nps match appositive nps appositive relationship nps form predicate nominal construction binding nps violate conditions binding theory nps indexed simple heuristics instance non pronominal nps separated preposition indexed 
span np spans nps maximal np projection syntax nps incompatible values binding span constraints indefinite np jd indefinite appositive pronoun np id pronoun np jd embedded np id embedded noun title nps title semantic nps wordnet semantic class don na semantic class information nps determined 
alias np alias positional distance nps terms number sentences 
pro resolve np jd pronoun np id antecedent naive pronoun resolution algorithm table feature set coreference system 
feature set contains relational non relational features generate instance representing nps np id np jd document np id precedes np jd non relational features test property nps consideration take value depending holds 
relational features test property holds np pair consideration indicate nps compatible incompatible value applicable property apply 
refer text 
separate clustering mechanism coordinates possibly contradictory pairwise classifications constructs partition set nps 
perform experiments coreference resolution system see ng cardie 
sake completeness include descriptions features employed system table 
linguistically features divided groups lexical grammatical semantic positional 
naive bayes decision tree induction underlying learning algorithm train coreference classifier simply provides generative model assumed em facilitates comparison different approaches robust skewed class distributions inherent coreference data sets decision tree learners 
coreference system weakly supervised setting weakly supervised algorithm bootstraps coreference classifier labeled unlabeled data larger set labeled instances 
conclude section noting view factorization non trivial task coreference resolution 
lexical tagging problems part speech tagging views drawn naturally left hand right hand context 
tasks named entity classification views derived features inside outside phrase consideration collins singer 
unfortunately options possible coreference resolution 
explore heuristic methods view factorization section 
evaluation section empirically test hypothesis single view weakly supervised algorithms potentially outperform multi view counterparts problems natural feature split 
experimental setup ensure fair comparison weakly supervised algorithms experiments designed determine best parameter setting algorithm terms effectiveness improve performance data sets investigate 
specifically keep parameters common weakly supervised algorithms labeled unlabeled data constant vary algorithm specific parameters described 
evaluation 
muc muc coreference data sets evaluation 
training set composed dry run texts selected annotated text remaining texts unannotated data 
muc training instances generated nps annotated text 
muc training instances generated nps 
unlabeled data composed instances instances muc muc data sets respectively 
testing performed applying bootstrapped coreference classifier clustering algorithm described section formal evaluation texts muc muc data sets 
training parameters 
training parameters set follows 
views 
tested pairs views 
table reproduces features coreference system shows views employ 
specifically view pairs generated methods 
mueller heuristic method 
starting empty views iterative algorithm selects view feature addition maximizes performance respective view labeled data iteration 
method produces view pair table muc data set 
different view pair produced muc 
random splitting features views 
starting empty views iterative algorithm randomly chooses feature view step split feature set 
resulting view pair muc muc data sets 
splitting features feature type 
specifically view comprises features remaining ones 
approach produces view pair data sets 
pool size 
tested pool sizes 
growth size 
tested values 
space limitation precludes detailed description method 
see mueller 
details 
feature pro str pn str soon str pronoun pronoun demonstrative proper nouns number gender appositive binding span syntax indefinite pronoun embedded title alias pro resolve table training view pairs employed coreference system 
column lists features shown table 
columns show different pairs views attempted training coreference classifiers 
number training iterations 
monitored performance test data iterations cotraining ran algorithm performance stabilized 
self training parameters 
labeled unlabeled data self training requires specification number bags 
tested odd number bags 
em parameters 
labeled unlabeled data em parameter number iterations 
ran em convergence kept track test set performance iteration 
results discussion results shown table performance reported terms recall precision measure model theoretic muc scoring program vilain 
baseline coreference system trained labeled document naive bayes achieves measure muc muc data sets respectively 
results shown row table correspond best measure scores achieved training parameter combinations described previous subsection 
parameter settings best results obtained shown table 
experiments muc muc best parameter setting best parameter setting baseline training self training em fs em table comparative results training self training em fs em described section 
recall precision measure provided 
training self training em best results measure achieved algorithms corresponding parameter settings views growth size pool size number iterations number bags shown 
number training iterations baseline recall precision measure learning curve training pool size growth size muc data set 
get better picture behavior training learning curve training run gives rise best measure muc data set 
horizontal dotted line shows performance baseline system achieves fmeasure described 
training progresses measure peaks iteration gradually drops baseline iteration 
training produces substantial improvements baseline best parameter settings closer examination results reveals corroborate previous findings algorithm sensitive number iterations input parameters pool size growth size nigam ghani pierce cardie 
lack principled method determining parameters weakly supervised setting labeled data scarce remains serious disadvantage training 
self training results shown row table self training performs substantially better baseline training data sets 
contrast training self training relatively insensitive input parameter 
shows fairly con number bags score baseline recall precision measure effect number bags performance self training muc data set 
sistent performance self training bags muc data set 
observe similar trends muc data set 
results consistent empirical studies bagging variety classification tasks bags deemed sufficient breiman 
gain deeper insight behavior plot learning curve self training bags muc data set 
iteration unlabeled data incorporated measure score achieved self training higher baseline system vs 
observed difference due voting self training algorithm 
voting proved effective technique improving accuracy classifier training data scarce reducing variance particular training corpus breiman 
iteration rapid increase measure accompanied large gains precision smaller drops recall 
results consistent intuition regarding self training iteration algorithm incorporates instances label confident labeled data ensuring precision number self training iterations baseline recall precision measure learning curve self training bags muc data set 
crease 
see table recall level achieved training lower self training 
indication training view insufficient learning concept feature split limits interaction features different views produce better recall 
results provide evidence self training better alternative training weakly supervised learning problems coreference resolution natural feature split exists 
hand em gives rise modest performance gains baseline system see row table 
performance em depends part correctness underlying generative model nigam case naive bayes :10.1.1.1.5684
model instance feature values xm class created choosing class prior probability generating available feature probability independently assumption feature values conditionally independent class 
result model correctness adversely affected redundant features clearly invalidate conditional independence assumption 
fact naive bayes known bad handling redundant features langley sage 
hypothesize presence redundant features causes generative model em tackling task confusion set disambiguation banko brill observe modest gains bootstrapping seed corpus words 
speculate labeled data set size possibly enable train reasonably classifier self training offer marginal benefits relationship behavior self training size seed labeled corpus remains shown 
form poorly 
self training depends model binary decisions returned model robust naive bayes assumptions reflected fairly impressive empirical performance 
contrast fact em relies probability estimates model sensitive correctness model 
meta bootstrapping feature selection hypothesis regarding presence redundant features correct feature selection result improved generative model turn improve performance weakly supervised em 
section discusses wrapper feature selection method em 
tiered bootstrapping algorithm describe fs em algorithm boosting performance weakly supervised algorithms feature selection 
named em algorithm described potentially applicable single view weakly supervised algorithms 
fs em takes input supervised learner single view weakly supervised learner labeled data set unlabeled data set addition assumes knowledge positive class prior true percentage positive instances data training requires deviation threshold explain shortly 
fs em level bootstrapping structure reminiscent meta bootstrapping algorithm introduced riloff jones 
outer level bootstrapping task feature selection inner level task learn bootstrapped classifier labeled unlabeled data described section 
high level fs em uses forward feature selection algorithm impose total ordering features order features selected 
specifically fs em performs steps feature selected 
uses weakly supervised learner train classifier labeled unlabeled data feature features selected far 
second algorithm uses classify instances fs em trains new model just labeled steps exactly model trained feature selected 
forward selection algorithm selects feature corresponding model achieves best performance true labels instances addi possible naive bayes classifiers return optimal classifications conditional independence assumption violated 
see domingos pazzani analysis 
tion fnew set features selected far 
process repeated features selected 
unfortunately small selecting feature incorporation fnew measuring performance corresponding model may accurately reflect actual model performance 
handle problem fs em preference adding features inclusion results classification positive class prior probability instance labeled positive deviate true positive class prior pre specified threshold value 
large deviation true prior indication resulting classification data correspond closely actual classification 
algorithmic bias particularly useful weakly supervised learners em optimize objective function classification accuracy potentially produce classification substantially different actual 
specifically fs em attempts ensure classification produced weakly supervised learner weakly agrees actual classification weak disagreement rate classifications defined difference positive class priors 
note weak agreement necessary sufficient condition classifications identical 
addition features fnew produce classification weakly agrees true fs em picks feature inclusion results positive class prior deviation 
step viewed introducing pseudo random noise feature selection process 
hope deviation high scoring features lowered incorporating low deviation continuing strive weak agreement potentially achieving better performance final set features final composed features chosen feature selection algorithm largest number features achieve best performance subject condition corresponding classification produced weakly supervised algorithm weakly disagrees true 
output fs em classifier weakly supervised learner learns features final pseudo code describing fs em shown 
reason validation step primarily preclude possibility getting poor estimation model performance result presence potentially inaccurately labeled data words imply corresponding classifications identical 
input supervised learning algorithm single view weakly supervised learning algorithm labeled data unlabeled data original feature set true positive class prior deviation threshold initialize fnew foreach learn classifier fnew underlying supervised learner classify instances probability instance labeled positive train classifier fnew classification accuracy scores scores argmax scores argmin fnew fnew max learn classifier underlying supervised learner return fs em algorithm 
results discussion instantiate fs em naive bayes supervised learner em weakly supervised learner providing amount labeled unlabeled data previous experiments setting 
em run iterations invoked 
results fs em shown row table 
comparison em measure increases muc muc allowing fs em surpass performance self training 
results consistent hypothesis performance em boosted improving underlying generative model feature selection 
fs em applicable problems generalized fairly easily handle multi class problems true label distribution follow choice previous muslea nigam ghani 
additional experiments em run iterations give similar results 
assumed available weak agreement rate measured similarity distributions 
investigated single view algorithms em alternative multi view algorithms training weakly supervised learning problems appear natural feature split 
experimental results coreference data sets indicate self training outperforms training various parameter settings comparatively sensitive parameter changes 
weakly supervised em able outperform training introduce variation em fs em boosting performance em feature selection 
self training fs em easily outperforms training 
training algorithms collins singer greedy agreement abney explicitly trade classifier agreement unlabeled data error labeled data may robust underlying assumptions training conceivably perform better blum mitchell algorithm problems natural feature split 
studied single view weakly supervised algorithms nlp community training different learning algorithms goldman zhou graph blum chawla similarly applied problems test original hypothesis 
plan explore possibilities research 
acknowledgments lillian lee thorsten joachims cornell nlp group including regina barzilay eric breck bo pang steven baker helpful comments 
anonymous reviewers feedback ted pedersen encouraging apply ensemble methods coreference resolution 
supported part nsf iis 
abney 

bootstrapping 
proceedings acl pages 
banko brill 

scaling large corpora natural language disambiguation 
proceedings acl eacl pages 
blum chawla 

learning labeled unlabeled data graph 
proceedings icml pages 
dasgupta 
show conditional independence assumption views satisfied view classifiers agreement unlabeled data explicitly maximized low generalization error 
blum mitchell 

combining labeled unlabeled data training 
proceedings colt pages 
breiman 

bagging predictors 
machine learning 
collins singer 

unsupervised models named entity classification 
proceedings emnlp vlc pages 
dasgupta littman mcallester 

pac generalization bounds training 
advances nips 
dempster laird rubin 

maximum likelihood incomplete data em algorithm 
journal royal statistical society series 
domingos pazzani 

optimality simple bayesian classifier zero loss 
machine learning 
goldman zhou 

enhancing supervised learning unlabeled data 
proceedings icml pages 
john kohavi pfleger 

irrelevant features subset selection problem 
proceedings icml 
langley sage 

induction selective bayesian classifiers 
proceedings uai pages 
muc 

proceedings sixth message understanding conference muc 
muc 

proceedings seventh message understanding conference muc 
mueller rapp strube 

applying cotraining resolution 
proceedings acl pages 
muslea minton knoblock 

active robust multi view learning 
proceedings icml 
ng cardie 

combining sample selection error driven pruning machine learning coreference rules 
proceedings emnlp pages 
nigam ghani 

analyzing effectiveness applicability training 
proceedings cikm 
nigam mccallum thrun mitchell 

text classification labeled unlabeled documents em 
machine learning 
pierce cardie 

limitations training natural language learning large datasets 
proceedings emnlp pages 
riloff jones 

learning dictionaries information extraction multi level bootstrapping 
proceedings aaai pages 
sarkar 

applying training methods statistical parsing 
proceedings naacl pages 
soon ng lim 

machine learning approach coreference resolution noun phrases 
computational linguistics 
steedman osborne sarkar clark hwa baker crim 

bootstrapping statistical parsers small datasets 
proceedings eacl 
vilain burger aberdeen connolly hirschman 

model theoretic coreference scoring scheme 
proceedings sixth conference pages 
