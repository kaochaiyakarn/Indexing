mixed ensemble approach semi supervised problem andreas kurt hornik report november november sfb adaptive information systems modelling economics management science vienna university economics business administration wien austria cooperation university vienna vienna university technology www wu wien ac am papers published report series preliminary versions journal articles quotations 
accepted publication proceedings icann international conference artificial neural networks madrid spain august 
springer verlag 
piece research supported austrian science foundation fwf sfb adaptive information systems modelling economics management science 
mixed ensemble approach semi supervised problem andreas kurt hornik introduce mixed approach semi supervised data problem 
approach consists ensemble unsupervised learning part labeled unlabeled points segmented clusters 
continuing take advantage priori information labeled points assign classes clusters proceed predicting ensemble method new incoming ones 
conclude classifying new data points segmentation set association clusters classes 
task supervised learning classification problem requires training data needs labeled accordingly 
practical domains unlabeled data abundant labeled data expensive difficult computationally hard generate relative scarce web text mining industrial process diagnosis medical diagnosis database marketing speech recognition 
necessity constructing classifier possibly small set labeled data additional set unlabeled data learn data sets 
idea em joint models generally generative methods assumes parametric forms class conditional distributions unrealistic problems 
purely discriminative methods unlabeled data data generation model modified predict unknown ones 
mixing generative discriminant methods authors 
papers commenting extent unlabeled data support classification methods coming asymptotic maximum likelihood theory fisher information techniques robust em variants 
kernel methods gaussian processes support vector machines applied problem finding kernels input spaces tedious job 
complete reviewing methods semi supervised task scope 
better extensive description strategies see example inspired area training methods 
training methods suppose structural knowledge data available aims learning restricted view examples trying example find features coherent different input sources 
methods broadly authors 
classification specific goal minimizing generalization error prior knowledge prevent algorithm overtraining unsupervised learning try find similar structures data set perform density estimation fitting data best way 
handling problem purely supervised unlabeled data belong class institut statistik und technische universit wien wien austria 
email firstname lastname ci tuwien ac transfer problem mixed supervised unsupervised 
propose unsupervised scheme priori information labeled data learn assign clusters classes distribution assumptions 
specifically data set segmented ensemble clustering procedure number clusters significantly larger number classes 
labeled data clusters assigned classes 
ensemble method clustering enables overcome limitations crisp assignment gathering information data structure 
want predict new data point compute probability distribution cluster membership point 
probabilities multiplied probabilities cluster belongs certain class 
organized follows 
section proposed mixed approach 
section describes experimental setup data sets results simulations 
section 
description mixed ensemble approach suppose data set labeled unlabeled points labeled ones belong classes 
order find structural information data set want partition clusters proposed scheme consists steps step unsupervised learning takes place ensemble method clustering runs different clustering algorithms combined result common partition 
method assure stability result help overcome initialization problems 
unsupervised procedure occurs labeled unlabeled data number clusters larger number known existing classes 
happens minimize possibility single cluster consists data points different classes 
partition resulting exhibits degree data point cluster 
means ensemble clustering returns measure probability point belongs cluster try find probability new point belongs existing classes specific value 
express concentrate calculating write probability labeled data mean data belonging class 
means mean introduces association clusters classes 
second step clusters associated classes information known labels way class calculate sum membership data points belonging class normalize result achieve values 
class know points distributed clusters 
means define contribution cluster class fuzzy number third step proceed classification new data 
new point just need calculate probability belong known classes classify point class maximum probability 
membership new points clusters ensemble method computed 
labels unknown assign new data point class fuzzy way membership clusters consequently contribution clusters classes 
simpler crisp case mean maximum value membership new point tell cluster data belong maximum value contribution cluster class exhibit crisp classification point 
terminology supervised tasks labeled unlabeled data points playing role training set unsupervised task 
knowledge labels learn association clusters classes 
new data point predicted classified setting learned 
experimental results experimental setup set implementation scheme unsupervised ensemble method implemented individual runs common clustering method hard competitive learning online version means see example 
initially tried procedure clusters decided error validation data set number final results 
individual cluster runs combined ensemble method assigning data point membership function 
map clusters classes labeled data 
experiments data labeled comparison standard classification methods experiments respectively data labeled 
experiments performed system statistical computation graphics implements known language statistics 
runs variety unix platforms linux windows nt 
available freely cran comprehensive archive network master site athttp www project org 
data sets results benchmark data sets simulations twonorm banana pima indians diabetes 
please note experimental setup comparisons 
twonorm dimensional data set classes gaussian clusters 
bayes error rate data points training set testing 
reach mean error rate standard deviation 
mean error reported adaboost em rfb 
training mixed model unlabeled points get misclassification standard deviation unlabeled points standard deviation 
best reported results variants em adaboost unlabeled points 
see method stable number unlabeled data points 
data points labeled respectively reach results data points labeled 
banana dimensional data set non convex classes best reported error adaboost variant see 
data set patterns training set testing 
mean misclassification rate achieved standard deviation papers report mean misclassification rate variants rfb svm em methods see 
case unlabeled data points reach misclassification rate standard deviation comparison papers report em adaboost mixed variants adaboost 
data difference performance unlabeled unlabeled large comparable methods literature 
pima indians diabetes data set consists observations variables describing plasma glucose concentration blood pressure skin fold thickness subjects 
classes negative positive 
mixed method applied set training observations returns mean error standard deviation 
results reported different methods recover classification rate 
unlabeled data classification rate turns standard deviation 
twonorm banana pima table experimental results scheme treat problem labeled unlabeled data 
semi supervised problem turns great interest due duality partially supervised task class labels data known unsupervised unlabeled data 
appears real world problems lack labeled data stresses necessity exploring methods maximize advantage priori information combination possible gain unlabeled data 
aim inject indirectly labels points introducing association unsupervised structures known classes 
unlabeled points learn labels behavior smaller entities clusters belong 
part algorithm structures data unsupervised manner information labels second step give performance small number data points labeled 
ensemble method clustering yields stable segmentation data set enables additional information cluster probabilities 
possible scheme pre processing scheme pre classifying available data points fitted real classification task assuming labels known 
piece research supported austrian science foundation fwf sfb adaptive information systems modelling economics management science 
anderson 
multivariate logistic compounds 
biometrika 
becker 
learning recognize moving objects model fitting problem 
advances nips volume pages 
becker hinton 
self organizing neural network discovers surfaces random dot stereograms 
nature 
blum mitchell 
combining labeled unlabeled data training 
proc 
colt 
breiman 
bias variance arcing classifiers 
technical report tech 
rep statistics department university california berkeley ca usa 
burges 
tutorial support vector machines pattern recognition 
data mining knowledge discovery 
collins singer 
unsupervised models named entity classification 
proc 
emnlp 
collins singer 
unsupervised models named entity classification 
proc 
joint sigdat conference empirical methods natural language processing large corpora pages 
andreas kurt hornik 
combination scheme fuzzy clustering 
advances soft computing pages 
freund schapire 
experiments new boosting algorithm 
machine learning proc 
th international conference 
bernd fritzke 
competitive learning methods april 
www neuroinformatik ruhr uni bochum de ini vdm research 

small sample results linear discriminant function estimated mixture normal populations 
statistical computation simulation 
goldman zhou 
enhancing supervised learning unlabeled data 
int 
joint conference machine learning 
buc 
boosting mixture models semi supervised learning 
dorffner bischof hornik editors icann pages vienna austria 
springer 
green silverman editors 
nonparametric regression generalized linear models 
chapman hall london 
miller 
mixture experts classifier learning labeled unlabeled data 
advances neural information processing systems 
mitchell 
role unlabeled data supervised learning 
proc 
th international colloquium cognitive science 
nigam mccallum thrun mitchell 
text classification labeled unlabeled documents em 
proc 
national conference artificial intelligence 
kamal nigam ghani 
analyzing effectiveness applicability training 
ninth international conference information knowledge management cikm 
kamal nigam ghani 
understanding behavior training 
kdd workshop text mining 
neil 
normal discrimination unclassified observations 
american statistical association 
original owners national institute diabetes kidney diseases 
pima indians diabetes 
donor database vincent vgs apl jhu edu 
ftp ics uci edu pub machinelearning databases 
mueller 
soft margins adaboost 
machine learning 
benchmark repository 
banana 
schapire singer 
improved boosting algorithms confidence rated predictions 
proc 
th annual conference computational learning theory 
matthias seeger 
input dependent regularization conditional density models 
technical report inst 
adaptive neural computation univ edinburgh 
matthias seeger 
learning labeled unlabeled data 
technical report inst 
adaptive neural computation univ edinburgh 
shahshahani landgrebe 
effect unlabeled samples reducing small size problem mitigating hughes phenomenon 
ieee trans 
geoscience remote sensing 
titterington smith makov editors 
statistical analysis finite mixture distributions 
wiley series probability mathematical statistics 
tong koller 
restricted bayes optimal classifiers 
proc 
national conference artificial intelligence pages 
vapnik 
statistical learning theory 
wiley 
wahba editor 
spline models observational data 
siam 
andreas kurt hornik 
voting scheme cluster algorithms 
gerald bernd detlef rudolf kruse editors neural networks applications proc 
th int 
workshop nn pages 
williams 
prediction gaussian processes linear regression linear prediction 
jordan editor learning graphical models 
kluwer 
williams rasmussen 
gaussian processes regression 
advances neural information processing systems 
zhang oles 
probability analysis value unlabeled data classification problems 
int 
joint conf 
machine learning 

