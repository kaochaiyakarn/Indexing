gib international journal computer vision kl november international journal computer vision kluwer academic publishers 
manufactured netherlands 
dynamic textures computer science department university california los angeles ca ucla edu alessandro dipartimento di ingegneria dell informazione universit di padova italy dei ying wu statistics department university california los angeles ca stat ucla edu stefano soatto computer science department university california los angeles ca soatto ucla edu received may revised february accepted july 
dynamic textures sequences images moving scenes exhibit certain stationarity properties time include sea waves smoke foliage novel characterization dynamic textures poses problems modeling learning recognizing synthesizing dynamic textures firm analytical footing 
borrow tools system identification capture essence dynamic textures learning identifying models optimal sense maximum likelihood minimum prediction error variance 
special case second order stationary processes iden uncorrected proof tify model sub optimally closed form 
learned model predictive power extrapolating synthetic sequences infinite length negligible computational cost 
experimental evidence framework low dimensional models capture complex visual phenomena 
keywords textures dynamic scene analysis textures minimum description length image priors image compression generative model prediction error methods arma regression subspace system identification canonical correlation learning 
consider sequence images moving scene 
image array positive numbers depend shape pose motion scene material properties reflectance light distribution environment 
known joint reconstruction photometry geometry intrinsically ill posed problem finite number images possible uniquely disk followed gib international journal computer vision kl november recover unknowns shape motion reflectance light distribution 
traditional approaches scene reconstruction rely fixing unknowns virtue assumption restricting experimental conditions estimating 
assumptions validated visual data possible construct scenes different photometry geometry give rise images 
ill posedness general visual reconstruction problem remarkable consistency solution performed human visual system reveals importance priors images zhu necessary fix arbitrary degrees freedom render problem posed kirsch 
general extra degrees freedom benefit ofthe application hand fix photometry estimate geometry robot vision fix geometry estimate photometry image rendering recover combination satisfies additional optimality criterion instance minimum description length sequence video data rissanen 
arbitrariness reconstruction interpretation visual scenes clear notion true interpretation criterion correctness somewhat arbitrary 
case humans interpretation leads correct euclidean reconstruction verified sensory modalities touch obvious appeal way correct euclidean interpretation retrieved visual signals 
analyze sequences uncorrected proof images moving scenes solely visual signals 
interpreting understanding signal amounts inferring stochastic model generates 
goodness model measured terms total likelihood measurements terms predicting power model able give accurate predictions signals akin called prediction error methods system identification 
model involve combination photometry geometry dynamics designed maximum likelihood minimal prediction error variance 
notice require reconstructed photometry geometry correct euclidean sense intrinsically impossible involving visually non verifiable prior assumptions 
require model capable predicting measurements 
sense look explanation image data allows recreate extrapolate 
thought compressed version essence sequence images 

contributions presents novel aspects field dynamic time varying textures 
issue representation novel definition dynamic texture general simplest instance capture statistics sequence images second order stationary process arbitrary covariance sequence precise allows making analytical statements drawing rich literature system identification 
learning propose criteria total likelihood prediction error 
hypothesis second order stationarity give closed form sub optimal solution learning problem 
recognition show textures alike tend cluster model space assessing potential build recognition system framework 
synthesis show simplest linear dynamical model order arma model white zero mean iid gaussian input captures wide range dynamic textures 
algorithm simple implement efficient learn fast simulate allows generating infinitely long sequences short input sequences control parameters simulation soatto :10.1.1.15.225:10.1.1.15.225
experiments consider simple choices input distributions general classes taken account particle filtering techniques general classes filter banks 
linear dynamical systems capture second order stationarity 
extensions devised closed form solutions available 
results may useful video compression image rendering synthesis image sequences 

prior related statistical inference analyzing understanding general images extensively gib international journal computer vision kl november decades mumford 
statistical characterization textures pioneered julesz decades back julesz 
extensive area texture analysis recognition synthesis 
approaches statistical models heeger bergen zhu popat picard portilla simoncelli de bonet viola paget longstaff cross jain sklansky rely deterministic structural models efros leung wei levoy :10.1.1.44.14
distinction directly pixel values project image intensity set basis functions 
physics algorithms target specific dynamic textures ebert fournier reeves 
simulations performed particle systems reeves sims :10.1.1.131.9652
approaches model scene derived principles approximated simulated 
techniques successfully applied synthesizing sequences natural phenomena smoke fire 
see instance stam fiume foster fedkiw walking gaits hodgins mechanical systems barzel 
main advantage techniques extent synthesis manipulated resulting great editing power 
physics models principled elegant disadvantage computationally expensive highly customized particular textures allowing dynamic textures uncorrected proof automatic ways inferring new models large class dynamic textures 
alternative physics techniques image ones 
framework new texture movies generated images building physical model process generates scene 
approaches distinguish subclasses called procedural techniques forego model altogether generate synthetic images clever concatenation repetition image data image techniques rely model albeit physical 
example subclass sch dl 
addresses problem finding transition points original sequence video looped back minimally invasive way 
process involves morphing techniques smooth visual discontinuities 
example wei levoy synthesize temporal textures generating new pixel spatiotemporal space video sequence searching original sequence pixel neighborhood best matches companion synthesized output 
procedural techniques result relatively quick solution purpose synthesis 
framework simulation generated explicitly inferring model results lack flexibility purposes editing classification recognition compression 
comparatively little specific area image techniques rely model 
problem modeling dynamic textures addressed nelson polana classify regional activities scene characterized complex non rigid motion 
problem considered 

bar joseph 
uses multi resolution analysis mra tree merging synthesis merging textures extends idea dynamic textures 
textures new mra trees constructed merging mra trees obtained input algorithm different de bonet algorithm de bonet viola operates single texture sample 
idea extended dynamic textures constructing mra trees wavelet transform 
impressive results obtained case finite length sequence synthesized computing combined mra tree 
approach captures essence dynamic texture form dynamical model infinite length sequence generated real time parameters computed line particular case linear dynamic textures closed form 
szummer picard temporal texture modeling uses similar approach capturing dynamic textures 
spatio temporal auto regressive model star imposes neighborhood causality constraint spatial domain 
severely restricts textures captured allow capture rotation acceleration simple non translational motions 
works directly pixel intensities smaller dimensional representation image 
incorporate spatial correlation imposing causal gib international journal computer vision kl november restrictions clear coming sections capture complex motions including ones star model ineffective see szummer picard borrow data processed section 

representation dynamic textures suitable definition texture 
single image say texture realization stationary stochastic process spatially invariant statistics zhu 
definition captures intuitive notion texture 
sequence images time varying texture individual images clearly independent realizations stationary distribution temporal coherence intrinsic process needs captured 
underlying assumption individual images realizations output dynamical system driven independent identically distributed iid process 
concept precise operative definition dynamic texture 

definition dynamic texture sequence images 
suppose instant time measure noisy version image independent identically distributed sequence drawn known distribution pw resulting positive measured sequence 
say sequence uncorrected proof linear dynamic texture exists set spatial filters stationary distribution defining ai bv nv iid realization density choice matrices ai nv initial condition 
loss generality assume redefine state model tobe linear dynamic texture associated auto regressive moving average process arma unknown input distribution ax bv iid unknown iid pw 
best knowledge characterization dynamic texture output arma model novel 
want clear definition explains mean dynamic textures 
argued definition capture intuitive notion dynamic texture possible 
showed section model captures intuition calls dynamic textures visual phenomena purpose modeling framework 
furthermore easily generalize definition arbitrary non linear model form leading concept non linear dynamic texture 

filters dimensionality reduction definition dynamic texture entails choice filters filters inferred part learning process dynamic texture 
criteria choosing suitable class filters ranging biological motivations computational efficiency 
simplest case take identity look dynamics individual pixels 
view choice filters dimensionality reduction step seek decomposition image simple linear form xi cx orthonormal basis set principal components wavelet filter bank instance 
alternative non linear choice filters obtained processing image filter bank representing collection positions maximal response mallat 
restrict attention linear filters 

learning dynamic textures sequence noisy images learning dynamic texture amounts identifying model parameters distribution input gib international journal computer vision kl november model 
system identification problem infer dynamical model time series 
literature dynamical systems commonly assumed distribution input known 
context dynamic textures additional complication having infer distribution input dynamical model 
learning system identification problem posed follows 

maximum likelihood learning maximum likelihood formulation dynamic texture learning problem posed follows find arg max log subject iid inference method depends crucially type representation choose note inference problem involves hidden variables multiplying unknown parameter realizations multiplying unknown parameter intrinsically non linear original state space model linear 
general iterative techniques alternate estimating sufficient statistics conditional density state maximizing likelihood respect unknown parameters fashion similar expectation maximization em algorithm dempster dynamic textures uncorrected proof 
order iterative techniques converge unique minimum canonical model realizations need considered corresponding particular forms matrices discuss realizations section closed form sub optimal solution wide class dynamic textures 

prediction error alternative maximum likelihood consider estimating model results prediction error instance sense mean square 
best step predictor depends unknown parameters pose problem lim arg min subject 
unfortunately explicit forms step predictors available restricted assumptions instance linear models driven white gaussian noise consider section 
details reader referred ljung 

representation driving distribution far managed defer addressing fact unknown driving distribution belongs principle infinite dimensional space needs said issue dealt algorithmically 
consider ways approach problem 
transform finite dimensional inference problem choosing parametric class densities 
done section postulate unknown driving density belongs finite dimensional parameterization class exponential densities inference problem reduced finite dimensional optimization 
exponential class quite rich includes particular multi modal skewed densities experiments show single gaussian model allows achieving results 
dynamic texture represented second order stationary process show closed form sub optimal solution obtained 
second alternative represent density finite number fair samples drawn model represent evolution conditional density state measurements density evolved updating samples remain fair realization conditional density time evolves 
algorithms sort called particle filters liu particular condensation filter blake isard best known instance computer vision community 
third alternative treat semiparametric statistical problem parameters lives infinite dimensional manifold probability densities satisfy certain regularity conditions endowed riemannian metric corresponding fisher information matrix gib international journal computer vision kl november design gradient descent algorithms respect natural connection done context independent component analysis ica amari cardoso 
avenue considerably laborious considering study 

closed form solution learning second order stationary processes known stationary second order process arbitrary covariance modeled output linear dynamical system driven white gaussian noise ljung 
case assume exist positive integer process initial condition symmetric positive definite matrices ax cx matrices rn rm problem system identification consists estimating model parameters measurements 
note model inv inv identity matrix dimensions nv nv 

uniqueness canonical model realizations uncorrected proof observation concerning model choice matrices unique sense infinitely matrices give rise exactly sample paths starting suitable initial conditions 
immediately seen substituting tat ct choosing initial condition tx gl invertible matrix 
words basis state space arbitrary process unique model equivalence class models tat ct gl 
order able identify unique model type sample path necessary choose representative equivalence class representative called canonical model realization sense depend choice basis state space fixed 
possible choices canonical models see instance kailath interested tailored data sense explained 
interested data dimensionality reduction assumptions model rank choose canonical model columns orthonormal identity matrix dimension see shortly assumption results unique model tailored data sense defining basis state space covariance limt asymptotically diagonal see eq 

problem set solve formulated follows measurements sample path process estimate canonical model process 
ideally want maximum likelihood solution arg max 
asymptotically optimal solutions problem maximum likelihood sense exist literature system identification theory ljung 
particular subspace identification algorithm sid described van de moor available matlab toolbox 
main reason section propose sub optimal solution problem dimensionality framework sid algorithm requires memory storage far capabilities current state art workstations 
result derived section closed form sub optimal solution sense frobenius takes seconds run common pc 
presenting solution learning problem point hypothesis far fact framework propose entails filtering space time gib international journal computer vision kl november separable means perform filtering space time separate stages 
reason choice computational simplicity resulting algorithm 

closed form solution rm rm notice similarly rn cx rm assumptions 
singular value decomposition svd golub van loan diag singular values consider problem finding best estimate sense frobenius arg minc subject 
follows immediately fixed rank approximation property svd golub van loan unique solution determined uniquely sense frobenius solving linear problem arg mina ax rn trivially done closed form state estimated dynamic textures uncorrected proof 
notice uniquely determined change sign components note lim diagonal mentioned section 
sample input noise covariance estimated 
full rank dimensionality reduced computing svd uq qu diag nv nv letting algorithm assumed order model 
practice needs inferred data 
arun kung propose determine model order empirically singular values choosing cutoff singular values drop threshold 
threshold imposed difference adjacent singular values 
notice model describe perform denoising original sequence 
immediate see denoised sequence estimate obtained 

asymptotic properties solution strictly speaking incorrect svd take account fact state particular structure state linear dynamical model 
possible adapt algorithm take account achieving closed form solution proven asymptotically efficient approach maximum likelihood solution 
resulting algorithm exactly sid asymptotic properties proven bauer 

optimal algorithm computationally expensive gain quality final model experiments reported marginal 

experiments coded algorithm described section matlab learning graylevel sequence frames takes seconds desktop pc ghz takes minutes color frames 
synthesis gib international journal computer vision kl november 
matlab code implementation closed form suboptimal learning algorithm proposed section synthesis stage 
order perform stable simulations synthesis function assumes poles linear system eigenvalues unit circle 
performed frame rate 
matlab routines implementing learning synthesis algorithms reported fig 

dimension state input nv input argument 
implementation nv 

synthesis uncorrected proof illustrates fact infinite length texture sequence synthesized typically short input sequence just drawing iid samples gaussian distribution 
frames belong water sequence 
frame long training sequence frames synthesized sequence dimensions pixels generated principal components 
sequence shown szummer picard example star model fails capturing non translational motion 
model hand difficulty capturing spatiotemporal statistics input sequence shown fig 


water 
shows infinite length texture sequence synthesized typically short input texture sequence just drawing samples 
data set comes mit temporal texture database 
particular structure sequence water synthesized principal components ones captured star model szummer picard :10.1.1.20.7763
figures show behavior algorithm representative set experiments training sequences figs 
borrowed mit temporal texture database 
case row show images original dataset second row show compressed version see section third row show extrapolated samples 
row show compression error function dimension state space left prediction error function length learning set right 
regular sequences prediction error decreases monotonically gib international journal computer vision kl november dynamic textures 
river 
top bottom samples original sequence corresponding samples compressed sequence compression ratio samples extrapolated sequence components compression error function dimension state space extrapolation error function length training set 
data set comes mit temporal texture database 
highly complex scenes smoke monotonic 
simula uncorrected proof tions set explains frames synthesized frames resemble ones training sequence 
notice example talking face fig 
included show output proposed technique underlying hypothesis input sequence realization second order stationary process violated 
course model fails capture non stationary nature sequence giving rise synthesized sequence shows artifacts 
example technique fails 
surprising note simple model pushed far modeling complex visual phenomena 
explained section choose model order learn parameters model 
crucial question long input sequence order capture temporal dynamics process 
answer question experimentally plot prediction error bottom right figs 
function length input training sequence 
means length predict frame part training set compute prediction error pixel gray levels 
times order infer statistics prediction error mean variance 
shows error bar plot including mean standard deviation prediction error pixel sequence 
average error decreases stable approximately frames 
notice plot fig 
meaning model verification sense plot prediction error validates posteriori model inferred sub optimal solution informative challenging model 
gib international journal computer vision kl november 
smoke 
top bottom samples original sequence corresponding samples compressed sequence compression ratio samples extrapolated sequence components compression error function dimension state space extrapolation error function length training set 
data set comes mit temporal texture database 
important parameter compare various texture synthesis models time takes uncorrected proof size 
established models gibbs sampling zhu sampling methods draw samples complex distributions computationally intensive 
uncertainty samples converged 
deterministic methods extend extrapolate sequences go back query input texture way obtain information generates frame efros leung wei levoy :10.1.1.44.14
model learning performed closed form seconds graylevel samples synthesis instantaneous frame rate matlab implementation 
control size parameters obtain particular synthesis speed change model parameters eigenvalues manipulate original dynam ics soatto :10.1.1.15.225:10.1.1.15.225
notice certain cases corresponding certain natural phenomena sequence far may possible correct learning process return marginally stable system capturing explosive nature input sequence 
fact system captures exact nature ongoing process training set generalizes time synthesis simulation 
analytically poles training sequences close unit circle case unstable dynamic textures order stable synthesis simulations just relocate unstable system poles unit circle 
accomplish task simply reducing distance unstable poles origin maintaining phase constant obtain stable synthesized sequences resemble original training set 
gib international journal computer vision kl november dynamic textures 
steam 
top bottom samples original sequence corresponding samples compressed sequence compression ratio samples extrapolated sequence components compression error function dimension state space extrapolation error function length training set 
data set comes mit temporal texture database 
figs 
show results synthesis 
dimension state set uncorrected proof drawn zero mean gaussian distribution covariance inferred estimated state 
experiments fig 
training sequences borrowed mit temporal texture database length sequences ranges frames synthesized sequences frames long 
experiments fig 
training sets color sequences captured authors fire sequence comes digital film library 
length sequences frames frames pixels synthesized sequences frames long 
extension learning algorithm case color images done ways 
experiments implies column vector time eq 
contains unfolded rgb channels ordered 
representation color suitable space hunt may lead efficient model terms ability capture information training sequence 

recognition definition section texture characterized arma model 
order compare textures need define base measure space linear dynamical systems characterize probability distributions space 
defining appropriate base measure space arma models trivial model entails combination input density state gib international journal computer vision kl november 
toilet 
top bottom samples original sequence corresponding samples compressed sequence compression ratio samples extrapolated sequence components compression error function dimension state space extrapolation error function length training set 
data set comes mit temporal texture database 
output transition matrices particular riemannian structure linear space 
uncorrected proof define inner product space models involves stiefel manifolds distance length geodesic joining models 
scope refer reader 

details 
compute kullback leibler divergence different realizations textures show similar textures cluster model space 
problem formalized follows 
infinitely long sequence images 
modeled stochastic process takes values subset image 
sequence images corresponding probability density function 
completely determined parameters define model 
correspond different dynamic textures 
divergence kl de fined kl lim kl kl log expectation taken respect 
fig 
display distance quantity kl different dynamic textures plotted length 
taken different realizations textures river steam computed distance realizations 
evident alike textures tend cluster 
principle comprehensive database parameters learned commonly occurring dynamic textures maintained new temporal sequence categorized learning parameters computing distance 
notice easy build gib international journal computer vision kl november dynamic textures uncorrected proof 
talking face 
top bottom samples original sequence corresponding samples compressed sequence compression ratio samples extrapolated sequence components compression error function dimension state space extrapolation error function length training set 
sequence proposed show synthesized sequence learned training set violates hypothesis realization second order stationary process 
result shows artifacts meaning information captured proposed model 
recognition framework dynamic processes procedural techniques 
wei levoy 
extensive assessment recognition capabilities system extensions non global representations segmentation ones scope 
issues discussed 



compression section preliminary comparison storage requirements estimated parameters relative original space requirement texture sequences get estimate sequence compression capabilities model 
thorough assessment compression capabilities model gib international journal computer vision kl november 
model verification verify quality model learned fixed number principal components representation considered sub sequences original data set length varying 
sub sequences learn parameters model maximum likelihood sense model predict image 
criterion learning ml validation prediction error informative challenging model 
average prediction error pixel shown function length training sequence sequence expressed gray levels range levels 
average error pixel decreases stable frames 
mean standard deviation trials shown error bar plot 
uncorrected proof research program right 
intention point potential model compression motivation model 
storage requirement original dataset components model necessary re create approximation sequence input 
need numbers counting orthogonality constraints nv numbers nv numbers input sequence 
storage requirement model mn nv nv effective rank consider fact typical values acceptable lossy nv immediate convince effectively compression power comes especially long sequences considered matrix responsible higher storage occupancy components negligible notice sequence frames long nv mn 
course systematic evaluation potential model compression due 
point algorithm provides compression temporal characteristics operates top mpeg encoding provides compression 
long sequences large algorithm modified order avoid computing svd large matrix 
particular model identified shorter gib international journal computer vision kl november dynamic textures uncorrected proof 
fountain plastic river far smoke far 
fountain sequence plastic sequence river far sequence smoke far sequence 
top row samples original sequence borrowed mit temporal texture database bottom row shows samples extrapolated sequence 
data available line www cs ucla edu projects html 
gib international journal computer vision kl november uncorrected proof 
fire color fountain ocean water color 
fire sequence color fountain sequence ocean sequence water sequence 
top row samples original sequence bottom row shows samples extrapolated sequence 
data available line athttp www cs ucla edu projects dynamic textures html 
gib international journal computer vision kl november dynamic textures 
demonstrates textures belonging class tend cluster sense kullback leibler 
particular distances computed realizations sequence sequence 
cluster graphs top refer steam river type distances ones refer river river type 
divergences computed monte carlo methods 
subsequence identified model compute input innovation form van de moor simple uncorrected proof linear kalman filter 
real time transmission broadcasting innovation estimated real time kalman filter transmitted lieu sequence images initial model identified transmitted receiver 
ensure real time coding decoding initial batch applications teleconferencing remote video broadcasting 

discussion introduced novel representation dynamic textures associated algorithms perform learning synthesis sequences training data 
somewhat surprisingly simplest choice order arma model driven white zero mean gaussian noise capture complex visual phenomena 
algorithm simple implement efficient learn fast simulate 
having model represents data general provides compact representation manipulation model parameters 
framework stimulates areas investigation ranging video compression classification recognition imagebased rendering synthesis editing image sequences 
acknowledgments research supported nsf iis iis iis ecs dms 
wish prabhakar gib international journal computer vision kl november assistance reviewing current literature data collection 
notes 
instance stereo structure motion assumes scene lambertian reflection properties exploits assumption establish correspondence estimate shape 
similarly shape shading assumes constant albedo exploits changes irradiance recover shape 

example sequence images sea sunset originated complex dynamic shape surface sea constant reflection properties homogeneous material water simple shape plane television monitor non homogeneous radiance spatio temporal signal 
similarly appearance moving lambertian cube mimicked spherical mirror projecting light distribution match albedo cube 

stochastic process stationary order joint statistics order time invariant 
instance process second order stationary mean constant covariance depends 

arma stands auto regressive moving average 

iid stands independent identically distributed 

common methods gabor filters bigun du buf steerable filters freeman adelson simoncelli heeger bergen :10.1.1.18.6984
infer choose best filters part learning process zhu 

distribution inferred physics imaging device 
ccd sensors instance approximation poisson distribution intensity related average photon count 
reason including term modeling dynamic textures necessary covariance sequence arbitrary 
standard results stochastic realization ljung state additional hypotheses see section secondorder stationary processes represented output models type include output noise term 

indicates combination output filters respectively applied state components see section details 

experiments color sequences graylevel sequences ranges nv ranges 
fitzgibbon appeared submitted advocates ar models registering non rigid scenes 

anonymous reviewer remarked result approach similar video textures 


movies available online www cs ucla edu projects dynamic textures html 

ftp media mit edu pub szummer temporal texture 
wei levoy new pixel search conducted similar neighborhood pattern original texture 

www com 

obtain similar plot compute distance divergence definition commutative 
amari cardoso 
blind source separation semiparametric statistical approach 
ieee transactions signal processing 
arun kung 
balanced approximation stochastic systems 
siam matrix analysis applications 
bar joseph el yaniv lischinski werman 
texture mixing texture movie synthesis statistical learning 
ieee transactions visualization computer graphics 
barzel 
physically modeling computer graphics structured approach 
academic press san diego ca 
bauer scherrer 
consistency asymptotic normality subspace algorithms systems observed inputs 
automatica 
bigun du buf 
folded symmetries complex moments gabor space application unsupervised texture segmentation 
ieee transactions pattern analysis machine intelligence 
ma soatto 
recognition human gaits 
proceedings ieee computer society conference computer vision pattern recognition kauai ha 
blake isard 
active contours 
springer verlag berlin 
cross jain 
markov random field texture models 
ieee transactions pattern analysis machine intelligence 
de bonet viola 
multiresolution sampling procedure analysis synthesis texture images 
proceedings ieee conf 
computer vision pattern recognition 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
statist 
soc 

soatto 
editable dynamic textures 
technical report ucla computer science department 
ebert carlson parent 
solid spaces inverse particle systems controlling animation gases fluids 
visual computer 
efros leung 
texture synthesis non parametric sampling 
seventh international conference computer vision corfu greece 
fitzgibbon 
stochastic rigidity image registration static scenes 
proc 
intl 
conf 
comp 
vis pp 

uncorrected proof gib international journal computer vision kl november foster fedkiw 
practical animation liquids 
proceedings siggraph computer graphics proceedings annual conference series acm press acm siggraph pp 

fournier reeves 
simple model ocean waves 
acm siggraph proceedings pp 

freeman adelson 
design steerable filters 
ieee transactions pattern analysis machine intelligence 
golub van loan 
matrix computations nd edn 
johns hopkins university press baltimore md sklansky 
markov random fields models texture 
image modeling 
academic press san diego ca 
heeger bergen 
pyramid texture analysis synthesis 
acm siggraph conference proceedings 
hodgins 
animating human 
robotics research eighth international symposium shirai hirose eds 
springer verlag berlin germany pp 

hunt 
reproduction colour th edn 
fisher books 
julesz 
visual pattern discrimination 
ire trans 
info theory 
kailath 
linear systems 
prentice hall englewood cliffs nj 
kirsch 
mathematical theory inverse problems 
springer verlag new york 

stochastic realization problem 
siam control optim 
liu chen 
theoretical framework sequential importance sampling resampling 
technical report stanford university department statistics 
ljung 
system identification theory user 
prentice hall englewood cliffs nj 
mallat 
theory multiresolution signal decomposition wavelet representation 
ieee transactions pattern analysis machine intelligence 
mumford 
stochastic models generic images 
technical report division applied mathematics brown university 
nelson polana 
qualitative recognition motion temporal texture 
computer vision graphics image processing 
image understanding 
paget longstaff 
nonparametric multiscale markov random field model synthesising natural textures 
dynamic textures fourth international symposium signal processing applications 

modeling waves surf 
siggraph conference proceedings pp 

popat picard 
novel cluster probability model texture synthesis classification compression 
proceedings spie visual communications image processing boston 
portilla simoncelli 
texture representation synthesis correlation complex wavelet coefficient magnitudes 
csic madrid 
reeves 
particle systems technique modeling class fuzzy objects 
acm trans 
graphics 
rissanen 
modeling shortest data description 
automatica 
wu soatto 
dynamic texture recognition 
proceedings ieee computer society conference computer vision pattern recognition kauai ha 
szeliski salesin essa 
video textures 
proceedings acm siggraph conference new orleans la simoncelli freeman adelson heeger 
shiftable multi scale transforms 
ieee trans 
information theory 
sims 
particle animation rendering data parallel computation 
computer graphics 
stam fiume 
depicting fire gaseous phenomena diffusion processes 
siggraph conference proceedings pp 

szummer picard 
temporal texture modeling 
ieee international conference image processing lausanne switzerland vol 

van de moor 
subspace algorithms stochastic identification problem 
automatica 
van de moor 
sid subspace algorithms identification combined deterministic stochastic systems 
automatica 
wei levoy 
fast synthesis tree structured vector quantization 
siggraph conference proceedings 
zhu wu mumford 
minimax entropy principle application texture modeling 
neural computation 
uncorrected proof 
