social constraints animate vision cynthia breazeal aaron paul fitzpatrick brian scassellati massachusetts institute technology cambridge ma usa cynthia ai mit edu 
ballard described implications having visual system actively position camera response physical stimuli 
humanoid robotic systems animate vision system interacts people social dynamics provide additional levels constraint provide additional opportunities processing economy 
describe integrated visual motor system implemented humanoid robot negotiate robot physical constraints perceptual needs robot behavioral motivational systems social implications motor acts 
animate vision introduces requirements real time processing removes simplifying assumptions static camera systems presents opportunities simplifying computation 
simplification arises situating perception behavioral context providing opportunities learn flexible behaviors allowing exploitation dynamic regularities environment 
benefits critical interest variety humanoid robotics projects robotics ai communities 
practical level vast majority systems limited complexities perception focus single aspect animate vision concentrate integration known systems 
theoretical level existing systems benefit advantages ballard proposed limited scope 
humanoid robotics problems particularly evident 
animate vision systems provide limited set behaviors supporting smooth pursuit tracking provide behaviors extremely limited perceptual inputs systems track bright light sources fail provide natural interaction human robot 
propose order allow realistic human machine interactions animate vision system address set social constraints addition issues classical active vision addressed 
social constraints robots humans interact meaningfully important understand able shape behavior 
implications 
basic robot human overlapping perceptual abilities 
little idea sensing responding 
vision important sensory modality human interaction focus article 
endow robots visual perception human physical implementation 
similarity perception requires similarity sensors 
sensed stimuli equally behaviorally relevant 
important human robot find types stimuli salient similar conditions 
robots set perceptual biases human pre attentive visual system 
biases modulated motivational state robot making perceptual stages behaviorally relevant 
approximates top influence motivation bottom pre attentive process human vision 
visual perception requires high bandwidth computationally demanding 
early stages human vision entire visual field processed parallel 
computational steps applied selectively behaviorally relevant parts visual field processed greater detail 
mechanism visual attention just important robots humans considerations resource allocation 
existence visual attention key satisfying expectations humans concerning perceived visually 
implemented context dependent attention system goes way 
human eye movements high communicative value 
example gaze direction indicator locus visual attention 
knowing person locus attention reveals person currently considers behaviorally relevant turn powerful clue intent 
dynamic aspects eye movement staring versus glancing convey information 
eye movements particularly potent social cynthia breazeal fig 

kismet robot capable conveying intentionality facial expressions behavior 
robot physical state expresses attention interest human 
person example photographer expect attract robot attention able influence behavior 
interactions conversational turn making breaking eye contact plays important role regulating exchange 
model eye movements robots humans may similar communicative value 
hope example human visual system robot behavior easily understood analogous behavior human similar circumstances see 
example anthropomorphic robot moves eyes neck orient object observer effortlessly conclude robot interested object 
traits lead behavior easy understand allows robot behavior fit social norms person expects 
advantages modeling implementation human visual system 
wealth data proposed models human visual system organized 
data provides modular decomposition mechanisms evaluating performance complete system 
advantage robustness 
system integrates action perception attention cognitive capabilities flexible reliable system focuses aspects 
adding additional perceptual capabilities additional constraints behavioral perceptual modules increase relevance behaviors limiting computational requirements 
example isolation difficult problems visual tracking system knowing track knowing switch new target 
problems simplified combining tracker visual attention system identify objects behaviorally relevant worth tracking 
addition tracking system benefits attention system maintaining object interest center visual field 
simplifies computation necessary implement behavioral habituation 
modules concert compensate deficiencies limit required computation 
physical form currently group robot sophisticated visual motor behavior kismet 
robot active vision head augmented expressive facial features see 
kismet designed receive send human social cues caregiver regulate environment shape experiences parent child 
kismet degrees freedom control gaze direction degrees freedom control neck fifteen degrees freedom expressive components face ears eyelids 
perceive caregiver kismet uses microphone worn caregiver color ccd cameras 
positions neck eyes important expressive postures directing cameras behaviorally relevant stimuli 
cameras kismet eyes high acuity narrow field view 
eyes unobtrusive central cameras fixed respect head wider field view correspondingly lower acuity 
reason mixture cameras typical visual tasks require high acuity wide field view 
high acuity needed recognition tasks controlling precise visually guided motor movements 
wide field view needed search tasks tracking multiple objects compensating involuntary ego motion common trade biological systems sample part visual field high social constraints fig 

kismet large set expressive features eyelids eyebrows ears jaw lips neck eye orientation 
schematic right shows degrees freedom relevant visual perception omitting eyelids 
eyes turn independently horizontal pan turn vertical tilt 
neck turn head horizontally vertically crane forward 
cameras narrow foveal fields view rotate eyes 
central cameras wide fields view rotate neck 
cameras unaffected orientation eyes 
resolution support set tasks sample rest field adequate level support second set 
seen animals foveate vision humans density photoreceptors highest center falls dramatically periphery 
implemented specially designed imaging hardware space variant image sampling multiple cameras different fields view done 
robots cog follows human sensing arrangement closely kismet 
cog degree freedom upper torso humanoid 
mechanical design head neck human anatomy performance 
cog eyes color ccd cameras wide field view peripheral vision narrow field view high acuity vision opposed kismet arrangement wide cameras fixed respect head 
cog axis inertial package detects head rotation gravity vector similar human vestibular system 
designs robots constantly evolving 
new degrees freedom added old degrees freedom reorganized sensors replaced rearranged new sensory modalities introduced 
descriptions treated snapshot current state robots 
hardware software control architectures designed meet challenge real time processing visual signals approaching hz minimal latencies 
kismet vision system implemented network mhz commercial pcs running qnx real time operating system see 
kismet motivational system runs collection motorola processors 
machines running windows nt linux networked speech generation recognition respectively 
kismet physical form control network rapidly evolving new behaviors sensory modalities come line 
levels visual behavior visual behavior conceptualized different levels shown 
levels correspond social level level level level 
decomposition motivated distinct temporal perceptual interaction constraints exist level 
temporal constraints pertain fast motor acts updated executed 
range real time vision rates hz relatively slow time scale social interaction potentially transitioning minutes 
perceptual constraints pertain level sensory feedback required coordinate behavior layer 
perceptual feedback originate low level visual processes current target attention system relatively high level multi modal percepts generated behavioral releasers 
interaction constraints pertain arbitration units compose layer 
range low level oculomotor primitives saccades smooth pursuit visual behavior regulate human robot turn 
level serves particular purpose generating observed behavior 
level address specific set issues 
levels abstraction help simplify control visual behavior restricting level address core issues best managed level 
doing coordination visual behavior level arbitration levels top bottom world maintained principled way 
cynthia breazeal fig 

system architecture kismet 
motivation system runs motorola microprocessors running multi threaded lisp developed lab 
vision processing eye neck control performed networked pcs running qnx real time operating system similar linux 
social level social level explicitly deals issues pertaining having human interaction loop 
requires careful consideration human interprets responds robot behavior social context 
visual behavior making eye contact breaking eye contact help regulate transition speaker turns vocal turn example 
behavior level behavior level deals issues related producing relevant appropriately persistent opportunistic behavior 
involves arbitrating possible goal achieving behaviors robot perform establish current task 
actively seeking desired stimulus visually engaging example 
motor skill level motor skill level responsible figuring move motors accomplish task 
fundamentally level deals issues blending sequencing coordinated ensembles motor primitives ensemble distinct motor skill 
skills level deal coordinating multi modal motor skills motor skills combine speech facial expression body posture 
fixed action patterns searching behavior example robot alternately performs ballistic eye neck orientation movements gaze fixation salient target 
ballistic movements important scanning scene fixation periods important locking desired type stimulus 
motor primitives level motor primitives level implements building blocks motor action 
level deal motor resource allocation tightly coupled sensorimotor loops 
example gaze stabilization take sensory stimuli produce motor commands tight feedback loop 
kismet distinct motor systems primitives level affective vocal system expression system system system 
focuses visual behavior discuss oculomotor system 
describe levels detail pertain kismet visual behavior 
lowest level motor primitives pertaining vision progress highest level discuss social constraints animate vision 
visual motor primitives kismet visual motor control modeled human ocular motor system 
human system providing stable percept world intuitive appreciation physical constraints robot responds human perceptual feedback coordination motor modalities social level behavior level skills level primitives level human responds robot current goal current primitive perceptual feedback motor acts inter motor system coordination oculomotor control human perceiving responding robot visuomotor skill behavior system vocal skill affective vocal synthesis social constraints task motor skills system face skill facial expression fig 

levels behavioral organization 
primitive level populated tightly coupled sensorimotor loops 
skill level contains modules coordinate primitives achieve tasks 
behavior level modules deal questions relevance persistence opportunism arbitration tasks 
social level comprises design time considerations robot behaviors interpreted responded social environment 
operates 
humans foveate vision 
fovea center retina higher density photoreceptors periphery 
means see object clearly humans move eyes image object falls fovea 
human eye movement smooth 
composed quick jumps called saccades rapidly re orient eye project different part visual scene fovea 
saccade typically period fixation eyes relatively stable 
means stationary continue engage corrective micro saccades small movements 
eyes fixate moving object follow continuous tracking movement called smooth pursuit 
type eye movement evoked voluntarily occurs presence moving object 
periods fixation typically hundreds milliseconds new saccade occur 
eyes normally move lock step making equal conjunctive movements 
close object eyes need turn somewhat correctly image object eyes 
disjunctive movements called vergence rely depth perception see 
eyes located head need compensate head movements occur fixation 
ocular reflex uses inertial feedback vestibular system keep orientation eyes stable eyes move 
fast response prone accumulation error time 
kinetic response slower compensation mechanism uses measure visual slip image retina correct drift 
mechanisms give humans stable gaze head moves 
implementation ocular motor system approximation human system 
motor primitives organized needs higher levels maintaining breaking mutual regard performing visual search motor primitives tightly bound visual attention discuss sensory component 
pre attentive visual perception human infants adults naturally find certain perceptual features interesting 
features color motion face shapes attract attention 
implemented variety perceptual feature detectors particularly relevant interacting people objects 
include low level feature detectors attuned quickly moving objects highly saturated color colors representative skin tones 
examples features shown 
looming objects detected pre facilitate fast reflexive withdrawal 
color saliency feature map basic widely recognized visual feature color 
models color saliency drawn complementary visual search attention itti koch niebur :10.1.1.53.2366
incoming video stream contains bit color channels andb transformed robot responds human body skill expressive posture human responds robot cynthia breazeal fig 

humans exhibit characteristic types eye motion 
saccadic movements high speed ballistic motions center target field view 
smooth pursuit movements track moving object low velocities 
ocular kinetic reflexes act maintain angle gaze head body move world 
vergence movements serve maintain object center field view eyes object moves depth 
color channels andy 
input color channel normalized luminance weighted average input color channels rn gn bn normalized color channels produce opponent color channels rn gn bn gn rn bn bn rn gn rn gn bn rn gn opponent color channels clamped bit values thresholding 
research indicate color channel considered individually choose maintain color information single feature map simplify processing requirements wolfe theoretical reasons 
motion feature map motion detected differences successive camera images robot moving 
motion detection performed wide field view rest move eyes see 
motion regions filled scan lines simple dynamic programming technique 
skin tone feature map colors consistent skin filtered see 
computationally inexpensive means rule regions contain faces hands 
visual attention implemented wolfe model human visual search attention 
implementation similar models part wolfe additionally operates conjunction motivational behavioral models moving cameras addresses issue habituation :10.1.1.53.2366
similar visual attention systems created humanoid robots operates complex visual stimuli focuses applying task demands direct attention 
attention process acts parts 
low level feature detectors discussed previous section combined weighted average produce single attention map 
combination allows robot select regions visually salient direct computational social constraints fig 

skin tone filter responds possible values 
grid left shows response filter values red green fixed value blue 
image right shows filter operation 
typical indoor objects may consistent skin tone include wooden doors cream walls fig 

overview attention system 
robot attention determined combination low level perceptual stimuli 
relative weightings stimuli modulated high level behavior motivational influences 
sufficiently salient stimulus modality pre attention similar human response sudden motion 
equal larger objects considered salient smaller ones 
design intended keep robot responsive unexpected events avoiding making slave environment 
model people intuitively provide right cues direct robot attention shake object move closer wave hand 
displayed images captured behavioral trial session 
cynthia breazeal fig 

manipulating robot attention 
images top row kismet upper wide camera 
images bottom summarize contemporaneous state robot attention system 
brightness lower image corresponds salience rectangles correspond regions interest 
rectangles correspond robot locus attention 
robot motivation stimuli associated faces stimuli associated toys equally weighted 
pair images robot attending face engaging mutual regard 
shaking colored block salience increases cause switch robot attention 
third pair shows head tracks toy moves giving feedback human robot locus attention 
eyes continually tracking target tightly neck 
fourth pair robot attention switches back human face tracked moves 
fig 

effect gain adjustment looking preference 
circles correspond fixation points sampled second intervals 
left gain skin tone filter higher 
robot spends time looking face scene face block 
bias occurs despite fact face block visual scene 
right gain color saliency filter higher 
robot spends time looking colored block face block 
behavioral resources regions 
attention system integrates influences robot internal motivational behavioral systems bias selection process 
example robot current goal interact people attention system biased objects colors consistent skin tone 
attention system mechanisms stimuli providing robot primitive attention span 
shows example attention system choosing stimuli complex scene potentially behaviorally relevant 
state attention system usually reflected robot gaze direction behavioral reasons case 
attention system runs time controlling gaze determines perceptual input motivational behavioral systems respond 
task influences attention goal achieving creature behavioral state bias creature attends 
instance performing visual search humans able preferentially select output broadly tuned channel feature red color shallow orientation searching red horizontal lines 
system top behavior driven factors modulate output individual feature maps summed produce bottom contribution 
process selectively enhances suppresses contribution certain features alter underlying raw saliency stimulus 
implement perceptual categorization person percept skin motion toy percept attention system color motion motivation system behavior system social drive social strategies engage person avoid person suppress skin gain bias skin gain seek person intensify skin gain level level stimulation drive stimulation strategies engage toy avoid toy suppress color gain bias color gain seek toy social constraints intensify color gain fig 

schematic behaviors relevant attention 
activation particular behavior depends perceptual factors motivation factors 
perceptual factors come post attentive processing target stimulus behaviorally relevant percepts 
drives motivation system indirect influence attention influencing behavioral context 
behaviors level behavior system directly manipulate gains attention system benefit goals 
behavior arbitration behaviors active time 
behaviors elaborated deeper levels behavior system 
bottom results feature map passed filter effectively gain 
value gain determined active behavior 
modulated feature maps summed compute attention activation map biasing attention way facilitates achieving goal active behavior 
example robot searching social stimuli sensitive skin tone sensitive color 
behaviorally robot may encounter toys search continue skin stimulus person face 
shown skin tone gain enhanced seek people behavior active suppressed avoid people behavior active 
similarly color gain enhanced seek toys behavior active suppressed avoid toys behavior active 
engage people engage toys behaviors active face color gains restored default values respectively 
habituation effects build believable creature attention system implement habituation effects 
infants respond strongly novel stimuli soon respond familiarity increases 
acts keep infant continually single object force caretaker continually engage infant slightly new interesting interactions 
robot habituation mechanism removes effects highly salient background objects currently involved direct interactions placing requirements caretaker maintain interaction slightly novel stimulation 
implement habituation effects habituation filter applied activation map location currently attended 
habituation filter effectively decays activation level location currently attended making locations lesser activation bias attention strongly 
consistency attention presence objects similar salience useful able commit attention objects period time 
gives time post attentive processing carried object downstream cynthia breazeal fig 

behavior tracker 
frames taken second intervals 
white squares indicates position target 
target centered images taken camera fixed respect head 
third row face slips away tracker immediately attention system 
images taken minute session tracker slipped times 
typical performance faces tend move rapidly 
social constraints fig 

eyes searched restricted part robot field view 
eye detector looks region eyes 
adequate performance limited range distances face orientations 
processes organize object 
soon decision object behaviorally relevant example may lack eyes searched post attention withdrawn visual search may continue 
committing object useful behaviors need atomically applied target example calling behavior robot needs stay looking person calling 
allow commitment attention system augmented tracker 
tracker follows target visual field simple correlation successive frames 
usually changes tracker target reflected movements robot eyes behaviorally inappropriate 
tracker loses target chance able reacquire attention system 
shows tracker operation 
post attentive processing attention system selected regions visual field potentially behaviorally relevant intensive computation applied regions applied field 
searching eyes task 
locating eyes important engaging eye contact point interpreting facial movements expressions 
currently search eyes robot directs gaze locus attention relatively high resolution image area searched available foveal cameras see 
target interest selected estimate proximity robot stereo match central wide cameras 
proximity important interaction things closer robot greater interest 
useful interaction distance person standing far face face interaction close closer 
clearly relevant behavior playing dependent proximity human robot 
eye detection real time robotic domain computationally expensive prone error due large variance head posture lighting conditions feature scales 
developed approach successive feature extraction combined inherent domain constraints achieve robust fast eye detection system kismet 
set feature filters applied successively image increasing feature granularity 
serves reduce computational overhead maintaining robust system 
successive filter stages detect skin colored patches image abort pass threshold 
scan image ovals characterize skin tone potential face 
extract sub image oval run ratio template candidate eye locations 
candidate eye location run pixel multi layer perceptron region 
perceptron previously trained recognize shading patterns characteristic eyes bridge nose 
doing set possible eye locations image reduced previous level feature filter 
allows eye detector run real time mhz pc 
methodology assumes cynthia breazeal fig 

organization kismet eye neck motor control 
cross level influences omitted 
modules gray active results 
lighting conditions allow eyes distinguished dark regions surrounded highlights bridge nose human eyes largely surrounded regions skin color head moderately rotated eyes reasonably horizontal people interaction distance robot feet 
eye movements shows organization kismet eye neck motor control 
kismet eyes periodically saccade new targets chosen attention system tracking smoothly move robot wishes engage 
vergence eye movements challenging implement social setting errors disjunctive eye movements give eyes disturbing appearance moving independently 
errors conjunctive movements smaller impact observer eyes clearly move lock step 
crude approximation kinetic reflex rolled implementation smooth pursuit 
analogue vestibular ocular reflex developed cog axis inertial sensor implemented kismet 
kismet uses efferent copy mechanism compensate eyes movements head 
attention system operates view central camera see 
transformation needed convert pixel coordinates images camera position setpoints eye motors 
transformation general requires distance target known objects locations project point single image see 
distance estimates noisy problematic goal center target exactly eyes 
practice usually get target field view foveal cameras eyes 
clearly narrower field view cameras accurately distance object needs known 
crucial factors distance wide foveal cameras closest distance robot need interact objects 
constraints determined physical distribution kismet cameras choice lenses 
central location wide camera places close possible foveal cameras 
advantage moving head center target seen central camera fact truly orient head target cameras locations accuracy orientation limited accuracy measurement distance 
higher level influences modulate eye neck movements number ways 
discussed modifications weights attention system translate changes locus attention eye movements organized 
posture robot controlled terms dimensional affective space 
social constraints fig 

distance information knowing position target wide camera identifies ray object lie uniquely identify location 
cameras close relative closest distance object expected foveal cameras rotated bring object narrow field view needing accurate estimate distance 
cameras far apart field view narrow minimum distance object large 
regime control eyes neck available set primitives higher level modules 
regimes include low commitment search high commitment engagement avoidance sustained gaze deliberate gaze breaking 
primitive percepts generated level include characterization salient regions image terms feature maps extended characterization tracked region terms results post attentive processing eye detection distance estimation signals related undesired conditions looming object object moving speeds tracker finds difficult keep 
move discuss level behavioral organization motor skills 
visual motor skills current task dictated behavior system motor skills level responsible figuring move actuators carry stated goal 
requires coordination multiple motor modalities speech body posture facial display gaze control 
requests modalities originate top emotion system behavior system bottom vocal system requesting lip jaw movements lip 
motor skills level address issue servicing motor requests different systems different motor resources 
furthermore requires sequence coordinated motor movements satisfy goal 
motor movement primitive combination primitives base motor systems vocal system oculomotor system 
coordinated series motor primitives called skill skill implemented finite state machine fsm 
motor skill encodes knowledge move motor state sequence designed bring robot closer current goal 
motor skills level arbitrate different fsms selecting active active goal 
decision process straight forward fsm tailored task behavior system 
skills thought fixed action pattern fap conceptualized early 
fap consists components action component taxis orienting component 
kismet correspond communicative gestures action component corresponds facial gesture taxis component gesture directed controlled gaze 
people intuitively understand kismet eye contact locus kismet attention robot behavior organized 
places person state action readiness poised respond kismet gestures 
simple example motor skill kismet calling fap see 
current task bring person interaction distance motor skill system activates fsm 
taxis component fap issues gaze request oculomotor system 
serves maintain robot gaze person 
state gestural component kismet body person request body posture motor system 
strengthens person perception robot taken particular interest 
ears creating significant amount motion noise cynthia breazeal fig 

calling 
attracts person attention robot request face motor system 
addition kismet perceived initiation engagement 
completion gesture fsm transitions second state 
state robot sits back waits bit expecting expression ears slightly eyes slightly widened brows raised 
person approached robot occur anticipation phase 
person approach allotted time period fsm transitions third state face relaxes robot maintains neutral posture gaze fixation released 
point robot shift gaze 
long fsm active determined behavior system cycle repeats 
interrupted state transition activation fsm greeting fsm person approached 
move layer abstraction behavior level hierarchy shown 
visual behavior behavior level responsible establishing current task robot arbitration kismet goal achieving behaviors 
doing observed behavior relevant appropriately persistent opportunistic 
current environmental conditions characterized high level perceptual releasers motivational factors emotion processes homeostatic regulation contribute decision process 
interaction behavior level social level occurs world determined nature interaction kismet human 
human responds kismet robot perceptual conditions change 
activate different behavior goal physically carried underlying motor systems 
human observes robot ensuing response shapes reply accordingly 
interaction behavior level motor skills level occurs world 
instance kismet looking bright toy toy behavior active 
task passed underlying motor skills carry search 
act scanning environment brings new perceptions kismet field view 
toy toy behavior successful released 
point perceptual conditions engaging toy relevant toy behaviors active 
new set motor skills active track smoothly pursue toy 
eye movements communicative value 
discussed previously indicate robot locus attention 
robot degree engagement conveyed communicate strongly robot behavior organized currently looking 
robot eyes flick place place resting indicates low level engagement appropriate visual search behavior 
prolonged fixation smooth pursuit orientation head target conveys greater level engagement suggesting robot behavior strongly organized locus attention 
eye movements obvious direct motor actions support visual perception 
means ones 
postural shifts fixed action patterns involving entire robot important role 
kismet number coordinated motor actions designed deal various limitations kismet visual perception see 
example person visible distant face imaged social constraints fig 

regulating interaction 
people distant seen clearly called closer come close robot signals discomfort withdraws 
withdrawal moves robot back somewhat physically effective signaling human back 
toys people move rapidly cause irritation 
adequate resolution kismet engages calling behavior person closer 
people come close robot cause difficulties cameras narrow fields view small part face may visible 
circumstance withdrawal response invoked kismet draws back physically person 
behavior aids cameras somewhat increasing distance kismet human 
behavior secondary greater effect social amplification human close kismet withdrawal response strong social cue back away analogous human response personal space similar kinds behavior support visual perception objects 
object close kismet lean away far away kismet crane neck 
social context actions power immediate physical consequences 
human reading intent robot actions may amplify actions 
example neck toy may interpreted interest toy resulting human bringing toy closer robot 
limitation visual system quickly track moving objects 
objects people move excessive speeds kismet difficulty tracking continuously 
bias people away excessively behavior movements movement objects manipulate kismet shows irritation tracker limits ability 
limits physical maximum rate eyes neck move computational maximum displacement frame cameras target searched 
regulatory mechanisms play roles complex social interactions conversational turn 
control gaze direction important regulating conversation rate 
general people glance aside turn eye contact prepared relinquish turn await response 
blinks occur frequently utterance 
cues allow kismet influence flow conversation advantage auditory processing 
visual motor system driven requirements nominally unrelated sensory modality just behaviors completely orthogonal vision ear call behavior attract person attention recruited purposes regulation 
mechanisms help protect robot 
objects suddenly appear close robot trigger looming reflex causing robot quickly withdraw appear 
event repeated response quickly robot simply appears annoyed best strategy repetitions clearly signal undesirable 
similarly rapidly moving objects close robot threatening trigger escape response 
mechanisms designed elicit natural intuitive responses humans special training 
carefully crafted mechanisms clear human kismet perception failing corrective action help robot perception reflected behavior familiar way 
inferences human preconceptions 
cynthia breazeal limited number trails naive subjects interacting kismet indicate read respond contingently types cues discussed 
analysis preliminary stage 
limitations extensions number ways current implementation improved expanded 
recommendations involve supplementing existing framework involve integrating system larger framework 
kismet visual perceptual world consists view cameras 
ultimately robot able construct ego centered saliency map interaction space 
representation robot keep track interesting things located currently view 
human infants engage social referencing caregiver young age 
event occurs infant unsure infant look caregiver face affective assessment 
infant assessment organize behavior 
instance caregiver looks frightened infant may probe 
caregiver looks pleased encouraging infant continue exploring 
respect kismet encounter situations explicitly programmed evaluate 
robot engage social referencing look human affective assessment bias learning organize subsequent behavior 
chances event question human face view time 
representation interesting ego centered interaction space important resource 
attention system extended adding new feature maps 
depth map stereo useful currently distance computed post 
interesting feature map incorporate system edge orientation 
wolfe argue favor edge orientation bottom feature map humans 
currently kismet shape metrics help distinguish objects toy block toy dinosaur 
adding features support important extension existing implementation 
auditory bottom contributions 
sound localization feature map nice multi modal extension 
currently kismet assumes salient person talking 
multiple people talking robot 
important robot knows addressing 
sound localization great benefit 
motor control social robot poses challenges issues stability accuracy 
motor actions perceived human observers semantically rich regardless imputed meaning intended 
powerful resource facilitating natural interactions robot human places constraints robot physical appearance movement 
allows robot readable behavioral intent motivational state transparent intuitive level interacts 
allows robot regulate interactions suit perceptual motor capabilities intuitive way humans naturally operate 
social constraints give robot leverage world extends far physical competence social amplification perceived intent 
properly designed robot visual behaviors matched human expectations allow robot human participate natural intuitive social interactions 
ballard 
behavioral constraints animate vision 
image vision computing 
ballard 
animate vision 
ai 
santos victor 
binocular visual tracking integration perception control 
ieee transactions robotics automation 
cynthia breazeal brian scassellati 
context dependent attention system social robot 
international joint conference artificial intelligence 
cynthia breazeal brian scassellati 
build robots friends influence people 
ieee rsj international conference intelligent robots systems iros korea 
social constraints cynthia breazeal brian scassellati 
infant social interactions robot human caretaker 
adaptive behavior 
appear 
brooks breazeal irie kemp marjanovi scassellati williamson 
alternative intelligence 
proceedings american association artificial intelligence aaai 
rodney brooks cynthia breazeal matthew marjanovic brian scassellati matthew williamson 
cog project building humanoid robot 
nehaniv editor computation metaphors analogy agents volume springer lecture notes artificial intelligence 
springer verlag 
cassell 
embodied conversation integrating face gesture automatic spoken dialogue systems 
appear 
michael goldberg 
control gaze 
eric kandel james schwartz thomas editors principles neural science 
mcgraw hill rd edition 
robert irie 
robust sound localization application auditory perception system humanoid robot 
master thesis mit department electrical engineering computer science 
itti koch niebur :10.1.1.53.2366
model saliency visual attention rapid scene analysis 
ieee transactions pattern analysis machine intelligence pami 
kawamura wilkes pack 
humanoids robots home factory 
proceedings international symposium humanoid robots pages tokyo october 
waseda university 
lorenz 
foundations ethology 
springer verlag new york ny 

role features preattentive vision comparison orientation motion color cues 
vision research 
brian scassellati 
finding eyes faces foveated vision system 
proceedings american association artificial intelligence aaai 
sinha 
object recognition image invariants case study 
investigative visual science may 
satoshi sato 
development head eye system humanoid robot 
proceedings ieee international conference robotics automation icra 
ieee press 
tinbergen 
study instinct 
oxford university press new york 
jan van der spiegel sandini dario 
foveated retina sensor ccd technology 
mead ismail editors analog vlsi implementation neural systems pages pp 

kluwer academic publishers 
jeremy wolfe 
guided search revised model visual search 
psychonomic bulletin review 
