undecidability probabilistic planning related stochastic optimization problems madani dept comp 
sci 
eng 
university washington box seattle wa usa madani cs washington edu steve hanks amazon com box seattle wa hanks com anne condon department computer science main mall university british columbia vancouver condon cs ubc ca automated planning problem agent achieves goal repertoire actions foundational widely studied problems ai literature 
original formulation problem strong assumptions regarding agent knowledge control world information complete correct results actions deterministic known 
research planning uncertainty relax assumptions providing formal computation models agent incomplete noisy information world noisy sensors effectors 
research mainly taken approaches extend classical planning paradigm semantics admits uncertainty adopt framework preprint submitted elsevier preprint february approaching problem commonly markov decision process mdp model 
presents complexity analysis planning uncertainty 
begins probabilistic classical planning problem showing problem formally undecidable 
fundamental result applied broad class stochastic optimization problems brief problem statement agent operates infinite indefinite time horizon available probabilistic information system state 
undecidability established policy existence problems partially observable infinite horizon markov decision processes discounted undiscounted total reward models average reward models state avoidance models 
results apply corresponding approximation problems undiscounted objective functions 
answers significant open questions raised papadimitriou tsitsiklis complexity infinite horizon pomdps paz decidability threshold isolation problem probabilistic finite state automata 
key words planning probabilistic stochastic optimization computability pacs don know needs resolved 
planning problem oldest studied problems ai research literature vast body devoted establishing theoretical results worst case time complexity various problem classes finding representations algorithms effectively solve important classes problems evaluating representations algorithms empirically 
planning exclusively posed problem logical deduction initial state world actions effect state changes set states identified goal states find sequence actions provably leave world goal states provided begins initial state 
strong assumptions implicitly underly model initial state known exact effects action known unknown exogenous changes state 
result agent omniscient world respect variables relevant achieving goal finding solution plan amounts constructing deduction executing plan known initial state leave world known goal state 
interesting side effect model observing world state dur ing plan execution unnecessary model sensing world required agent knows ahead time state world executes plan 
agent ability predict compensates inability sense world action decisions run time 
obvious limitations problem definition model human machine agency rarely world completely known thoroughly controlled 
address limitations various alternative models introduced 
line inquiry extends classical logical model admit incomplete information world state extending planning paradigm include observation actions contingency plans 
models represent incomplete information modeling agent state information set states true world state states set 
models allow reasoning incomplete information world initial state generally address issues associated uncertainty action effects exogenous change world effected agents 
approach step adopt probabilistic semantics agent state information distribution world states actions stochastic state transitions 
buridan presents model classical planning assumption agent unable observe world state plan execution buridan extends allow plan contain stochastic sensing actions 
third line see survey discards classical planning model altogether studies control models particular markov decision processes alternative way think planning scenarios 
doing logical semantics omniscience assumptions strict goal orientation classical planning replaced probabilistic semantics alternative set assumptions 
notable assumption full observability taken common mdp models uncertainty prevents agent predicting run time state ahead time complete accurate information state execution time extensive analysis computational complexity classical deterministic planning problems likewise complexity common mdp problems understood fully observable mdps analyzed papadimitriou tsitsiklis time research began applying partially observable pomdp models ai planning problems complexity planning partial observability limits practical application current 
mundhenk littman analyzes partially observable mdps provides results finite horizon problems bounded length plans 
probabilistic classical planning covered lines analysis due probabilistic semantics fact goal pursuit planning reduced problem planning fixed finite horizon 
length solution plan general bounded priori 
begins complexity analysis probabilistic planning problem 
ffl set states ffl probability distribution identity initial state ffl set goal states ffl set operators effect stochastic state transitions ffl rational threshold probability plan success determine sequence operators leave system goal state probability main result proves undecidability problem existing result establishing undecidability isomorphic problem area probabilistic finite state automata 
result applies widely variety problems stochastic planning control 
example result extended resolve open problem posed regarding undecidability infinite horizon pomdps conjecture paz undecidability related pfa problem 
shows problems analyzed 
problems bold rectangles established undecidable 
oval existing result rounded rectangles represent problems studied complexity results discussed put results contexts 
arrows point easier harder problems 
begins existing result regarding undecidability determining set input strings accepted pfa empty 
shows isomorphic probabilistic planning problem undecidable general classes unobservable partially observable mdp problems 
result applies optimization approximation versions problems discounted undiscounted objective functions 
organized follows 
section defines relevant stochastic optimization problems fully partially observable mdps probabilistic planning 
section begins explaining undecidability proof classical planning probabilistic planning infinite horizon umdp pfa emptiness pfa threshold isolation infinite horizon discounted pomdp infinite horizon undiscounted pomdp infinite horizon pomdp approximation infinite horizon finite horizon pomdp optimal finite controller existence fig 

summary undecidability results pfa emptiness problem extends result pfa threshold isolation problem establishes undecidability probabilistic planning problem 
section extends result various pomdp problems discounted undiscounted objective functions related approximation problems questions existence optimal policies special structure 
section presents related 
problem definitions standard assumption input parameters problems rational numbers 
matrices vectors points familiarity elementary linear algebra needed 
boldface font denote vectors 
vector denotes transpose denotes ith component 
denotes entry row column matrix denotes vector corresponding row matrix 
parenthesized superscript notation sequences objects scalars vectors 
example denotes jth object sequence delta delta delta fo refers sequence 
sequences may finite infinite 
sigma denote finite set symbols alphabet 
case sequence treated juxtaposition concatenation symbols sigma example oe oe delta delta delta oe sigma 
string finite sequence possibly empty 
sequences finite ww sequence corresponding concatenation denotes concatenated times denotes infinite concatenation wwww delta delta delta 
sequence oe oe delta delta delta oe sigma denotes ith element oe jwj denotes length sequence number symbols pre denotes length prefix pre oe oe delta delta delta oe sigma denotes set finite sequences strings elements sigma including empty string 
probabilistic planning originally motivated questions computability probabilistic planning problems problems introduced 
probabilistic planning problem studied kushmerick hanks weld example consists ffl finite set states equivalently assignment truth values finite number boolean variables ffl finite set actions effecting stochastic state transitions ffl start state probability distribution states ffl goal region state space subset states designated goal ffl threshold probability success 
problem find sequence actions move system start state goal state probability exceeding form problem described terms system states transition states may dissimilar appears literature probabilistic planning ai variations seen hard terms worst case computational complexity 
viewed point underlying states probabilistic planning problem just described thought special markov decision process problem 
markov decision processes markov decision process mdp model consists set states finite set actions sigma 
time discretized time point delta delta delta system occupies single state called current state system time means change system state action execution uncertainty outcome actions 
consider states indexed associated action sigma theta stochastic matrix specifies state transition probabilities action semantics state system time point action executed probability state system time point refer transition matrix dynamics matrix action associated action theta vector rewards semantics decision maker gains incurs cost state system action executed 
mdp models satisfy markov property state system aspects reward attained observation see depend current state system action executed example history previous system states executed actions 
states actions basically transition matrices reward vectors completely specified part problem instance 
informally problem decision maker confronted system execute actions maximize measure accumulated reward example expected total reward fixed number time steps indefinite number time steps 
observe making choice action immediate reward action important state action leads may significant obtaining high reward 
reader referred books mdps pomdps puterman white bertsekas comprehensive models motivational examples 
describe important aspects state observability time horizon value functions model specifications vary define computational problems 
observability traditional fully observable mdp model system state time point known decision maker time action selected executed 
partially observable pomdp generalization decision maker may partial information system state example probability distribution possible states 
consequently pomdp model sources uncertainty uncertainty outcome actions time point uncertainty current system state 
general partial observability life decision maker difficult current system state may known example decision maker may need act conservatively 
generally pomdps action execution decision maker obtains feedback possibly erroneous current state system 
common pomdp models state emits observation signal finite observable set 
source partial observability possibility multiple states may emit observation 
traditionally observation modeled random variable depending state state action executed 
distributions random variables part problem instance 
fully observable mdp model corresponds extreme case state maps unique observable 
consider extreme partial observability unobservable mdp umdp model states map observation 
umdp model simplifies analyses computability closely related probabilistic finite automaton model defined section 
course hardness results establish apply general pomdp variations 
note probabilistic planning problem described section viewed umdp special value function see section 
assume decision maker probability distribution initial state 
undecidability results decision maker may know initial state 
state probability distribution time denoted theta vector probability system state probability distribution time execution action time probability distribution time knowing current probability distribution action probability distribution easily computed 
distribution computed initial probability distribution sequence actions executed till time information available decision maker system state time infinite horizon criteria interested infinite horizon optimization objectives criteria assume decision maker executes actions system indefinite unbounded number time steps case consider finite infinite sequences actions 
contrasts finite horizon objectives decision maker executes fixed known number actions 
complexity finite horizon mdps pomdps extensively studied see example 
measures value action sequences solving planning mdps problems need measure value action sequence formulate optimization objectives computational problems 
refer choice value measure optimality criterion 
value measure defined optimization objective selecting action sequence highest value collection possible action sequences 
discuss value measures action sequences introduce notation expressing 
mdp models adopt additive value model value executing policy expressed function sum rewards collected stage 
model execution action distribution system state gives expected reward expressed compactly vector product notation xr denote nonempty finite infinite sequence actions 
execution sequence mean ith action executed time gamma executed time time 
express total reward value total expected reward obtained initial system distribution executed 
rw mw denote reward vector dynamics matrix ith action respectively 
gamma rw expected reward executing ith action time gamma 
note determined gamma mw function denote expected reward initial distribution jwj gamma rw jwj understood limit taken defined 
expected total reward measure called total reward criterion 
common studied variation optimality criterion called total discounted reward value discounted criterion short defined presence arbitrary reward state transition structure 
criterion discount factor fi fi discount rewards 
value sequence initial distribution expressed fi jwj fi gamma gamma rw average reward criterion natural common measure 
expected average reward finite action sequence expected total reward divided length 
average reward infinite sequence limit average rewards finite prefixes prefix length grows avg lim pre pre denotes total reward length prefix defined 
may limit infinite action sequences 
goal oriented optimality criteria important special case total reward criterion reward obtained entering specially designated goal state 
call special criterion goal oriented model criterion 
criterion defined basically equivalent criterion maximizing probability reaching goal state 
probabilistic planning problem falls criterion undecidability results reductions goal oriented problems 
policies computational problems optimality criterion number computational problems interest suggest 
formulate problems discounted criterion 
discounted umdp model specified fq sigma fm fr fig sigma states actions model fm fr sets transition dynamics rewards corresponding actions initial distribution fi discount factor 
simple decision problem call sequence existence problem problem discounted umdp threshold finite action sequence fi sequence existence problem major problem shown undecidable section 
similar problems specified criteria see problem 
define optimal values optimal action sequences discounted model 
set theta vectors probability distribution system state 
optimal value function defined sup sigma fi function defined bounded execution action time point falls gammar denotes highest reward absolute value components action reward vectors value fi bounded fi gammafi put words highest value expectation attainable initial distribution optimization problem umdp initial distribution compute approximate thereof 
case action sequence call optimal action sequence yields value possibly limit infinite executed initial distribution action sequence umdp example policy 
policy general prescription action function information available decision maker 
umdp case may think action sequences policies specify action take function time point 
optimization problem umdp initial distribution compute finite representation optimal action sequence compute finite prefix example action sequence 
representation policy elegant way controlling pomdp finite controller 
briefly finite controller controlling pomdp finite state machine prescribes action execute states prescribed action executed observation pomdp observed changes state observation current state 
algorithms generating finite controllers show promise fast finding optimal near optimal policies pomdp problems 
case observation output finite controller just periodic action sequence 
formally define periodic action sequence follows alphabet action set sigma call sequence periodic uv sigma note string finite sequence periodic definition 
pomdp problems optimal finite controllers simple state armed bandit counter example constructed see state umdp counter example 
section view action sequences desired output solving problem optimal finite controller exists addressed section 
assume umdp problem includes initial distribution states problem specification 
probabilistic finite automata probabilistic finite state automaton pfa defined quintuple sigma set states sigma input alphabet set theta row stochastic transition matrices symbol sigma initial state pfa accepting state 
pfa model shares dynamics umdp model pfa occupies state states point time stage transitions stochastically state 
state transition determined follows current input symbol determines transition matrix 
current state determines row probability distribution possible states 
state changes probability distribution 
undecidability proof restrict attention pfa accepting state absorbing sigma equivalent assumption automaton halting entering accepting state say pfa accepts string sigma automaton ends accepting state reading string say rejects string 
denote acceptance probability string pfa note infinite sequence acceptance probabilities prefixes pre decrease accepting state assumed absorbing consequently limit lim pre defined defined naturally acceptance probability language accepted pfa threshold denoted set strings take pfa accepting state probability greater fw sigma important problem call emptiness problem pfa threshold language accepted empty 
pfa models language acceptors probabilistic planning umdp problems stochastic optimization problems note underlying system models alphabet corresponding actions acceptance corresponding goal achievement 
change view allows see connection pfa models probabilistic planning leads undecidability results 
undecidability results probabilistic planning problems described models show problems interest undecidable showing reductions emptiness problem 
undecidability emptiness problem language emptiness problem follows problem pfa desired threshold decide input string sigma pfa accepts probability exceeding threshold paz lipton condon establish undecidability problem theorem emptiness problem undecidable 
describe properties reduction high level give detailed explanation proof 
details proof develop subsequent undecidability results probabilistic planning pomdp problems notably theorem establishes undecidability optimal policy construction discounted total reward infinite horizon pomdps 
properties reduction undecidable question turing machine tm accepts empty string reduced question pfa accepts string probability exceeding threshold 
pfa constructed reduction tests input concatenation accepting sequences 
accepting sequence legal sequence tm configurations initial configuration terminating accepting configuration 
reduction property tm accepting accepts empty string pfa accepts sufficiently long concatenations accepting sequences high probability 
tm accepting pfa accepts strings low probability 
formalize properties subsequent undecidability results 
section explains pfa generated reduction properties 
theorem exists algorithm counter tm input rational ffl integer outputs pfa satisfying tm accept empty string pfa accepts string probability exceeding ffl 
tm accepting string represent accepting sequence 
lim gamma gamma conclude section making additional points emptiness problem 
ffl due separation acceptance probability pfa cases tm accepting empty string emptiness problem remains undecidable strict inequality description existence problem replaced weak equality relation 
ffl problem posed terms existence finite strings result holds sequences infinite length 
details reduction class tms reduction counter tms powerful general tms 
constructed pfa supposed detect sequence computations represents valid accepting computation accepting sequence tm 
task reduces problem checking legality transition configuration tm amounts verifying ffl configuration machine start state ffl configuration machine accepting state ffl transition legal tm transition rules 
checks carried deterministic finite state automaton check tm counter contents remain valid consecutive configurations 
pfa rejects immediately easily verifiable transition rules violated leaves problem validating counters contents transition 
computation step taken counter tm counters contents stay get incremented get decremented 
assuming loss generality counter contents represented unary problem reduces checking strings length string 
question answered exactly pfa weak equality test developed inspired freivalds answer strict limited sense sufficient allow reduction 
weak equality test shown fig 
works follows 
pfa scans input string high probability enters indecision state equivalently say outcome test indecision 
event indecision thick edge denote high probability 
low probability pfa enters decisive states 
substrings equal length fig 
pfa enters correct state suspect state 
enters states 
suppose suspect reject decision suspect correct decision suspect correct mod mod indecision indecision fig 

outcomes weak equality test read probability making decision minute decision chances suspect correct suspect reading decision decision accept reject reading decision decision accept reject tm accepts denote accepting sequence 
legal sequence reject false accepting sequence tm doesn accept concatenate raise acceptance probability 
fig 

tm accepting accepting sequence probability making decisive decision minute pfa accept reject equal probability 
concatenating acceptance probability raised close desired 
tm accepting false accepting sequence pfa decision high probability rejection 
pfa enters decisive state input string composed unequal length substrings fig 

case suspect outcome times correct outcome discrimination factor large desired increasing size pfa 
test described detail appendix pfa reduction carries global test weak equality test fig 
candidate accepting sequence tm uses weak equality test check counter increments decrements consecutive configurations 
candidate accepting sequence outcome tests decisive correct pfa accepts input 
outcome tests suspect pfa rejects input 
probability decisive test course small positive 
pfa remains global indecision state detects start candidate accepting sequence start configuration tm reaches input 
follows outcome individual tests pfa illegal candidate accepting sequence counter contents changed legally outcome test decisive pfa rejects higher probability accepts fig 

pfa global indecision state input rejects 
original tm accepts empty string observe probability pfa accepts approach upper limit input string consisting concatenation sufficiently accepting sequences fig 

tm accept empty string follows properties weak equality test probability pfa rejects times probability accepts 
increase acceptance probability pfa tm accepting adding finite counter pfa discussed 
increasing pfa acceptance probability making minor adjustment pfa acceptance probability pfa tm accepts empty string arbitrarily close rejecting accepting sees suspect correct outcome single candidate accepting sequence pfa increment decisive counter finite upper limit pfa accepts input decisive counter reaches seen correct candidate sequence 
tm accepting pfa accepts concatenation sufficiently accepting sequences probability arbitrarily close gamma addition cases tm accepting acceptance probability pfa small desired counter upper limit choosing discrimination factor weak equality test large 
undecidability approximations question approximability important especially computing optimal answer impossible 
unfortunately follows corollary approximations computing string pfa accepts probability additive constant multiplicative factor ffl maximum acceptance probability pfa uncomputable 
maximum acceptance probability taken supremum acceptance probability strings 
corollary fixed ffl ffl problem undecidable pfa cases hold ffl pfa accepts string probability greater gamma ffl 
ffl pfa accepts string probability greater ffl 
decide case holds 
proof 
corollary immediate consequence properties outlined theorem fact ffl reduction small desired 
needs explanation 
added sentence 
undecidability threshold isolation problem hope decidability emptiness problem special cases example problems threshold isolated pfa definition pfa 
threshold ffl isolated respect jp gamma ffl sigma ffl 
problem threshold isolation problem pfa threshold decide ffl threshold ffl isolated pfa isolated thresholds interesting isolated thresholds expressive power general corresponding decision problems easier 
general powerful accept non contextfree languages 
rabin showed pfa isolated thresholds accept regular languages 
natural question pfa threshold threshold isolated pfa 
compute answer positive presumably compute regular language accepted pfa see empty 
afford opportunity recognize solve special case general emptiness problem 
decidability isolation problem raised paz heretofore open question best knowledge 
reduction shows recognizing isolated threshold hard corollary threshold isolation problem undecidable 
pfa literature threshold referred cutpoint problem referred cutpoint isolation 
proof 
stated theorem design reduction ffl 
follows tm accepting string pfa accepts probability greater tm accepting finite strings pfa accepts probability arbitrarily close 
words threshold isolated iff tm accepting 
undecidable problems probabilistic planning results previous section establish probabilistic problems general case restriction imposed length solution plans considered 
follows established sufficiently powerful probabilistic planning language model pfa question pfa reformulated probabilistic planning problem 
case probabilistic planning model investigated kushmerick hanks weld 
model strips propositional planning uncertainty form conditional probability distributions added action effects 
established boutilier dean hanks propositional encoding states sufficient represent finite state space extended probabilistic strips action representation sufficient represent stochastic transition matrix 
emptiness problem input string moves automaton start state accepting state probability directly reformulated planning context sequence actions moves system start state goal state probability 
algorithm solved planning problem answer question plan exists generating plan terminating having failed solving equivalent emptiness problem 
corollary undecidability emptiness problem obtain theorem plan existence problem undecidable 
note due tight correspondence probabilistic planning problems undecidability results previous section apply ffl approximately satisficing planning generating plan additive multiplicative factor threshold undecidable 
ffl deciding threshold particular planning problem represents isolated threshold problem undecidable 
undecidability results pomdp problems noted earlier probabilistic planning assumption observability restricted case probabilistic partial observation model goal pursuit planning objective restricted case general objective functions 
easy establish strictly general pomdp optimization problem maximizing arbitrary objective function infinite horizon undecidable 
section analyze commonly studied restrictions objective function positive bounded models average reward models discounted models show corresponding optimization problems undecidable 
define policy existence action sequence existence problem pomdps optimality criterion 
generic version problem formulated discounted criterion 
space policies considered definitions important consideration 
results hold space policies includes sets finite action sequences indefinite length infinite sequences algorithms create finite infinite sequences kind implicit policy representation 
problem policy existence problem respect optimality criterion pomdp threshold exist policy expected value greater threshold 
undecidability positive bounded models total undiscounted reward direct result involves special case infinite horizon undiscounted total reward models called positive bounded models 
essential feature model reward structure system dynamics problem ensure total reward gathered bounded convergent action sequences infinite horizon 
pfa emptiness problem planning problem easily posed positive bounded pomdp ffl observation received regardless state action ffl unit reward gathered execution action goal state fig 
ffl execution action goal state leads absorbing state system stays state gathers additional rewards fig 
ffl states actions incur reward 
equivalence immediately establish theorem policy existence problem positive bounded problems infinite horizon total reward criterion undecidable 
proof 
describe reduction plan existence problem 
planning problem posed positive bounded pomdp easily verify effective algorithm problem solve plan existence problem corollary algorithm exist 
see note plan say finite sequence actions exists planning problem probability reaching goal success probability exceeding finite sequence actions exist value exceeding corresponding umdp model outlined fig 
denote success probability finite sequence actions planning problem 
expected total reward action sequence corresponding umdp model 
conversely value sequence umdp model success probability sequence planning problem 
similar equivalence holds infinite action sequences 
undecidability average reward criterion indirect connection allows extension previous result undiscounted total reward models average reward models 
theorem policy existence problem infinite horizon average reward criterion undecidable 
proof 
proof complete observe questions acceptance probability strings pfa readily turned questions value similar strings related umdp model 
transformation achieved modeling probability reaching accepting state rewards fig 

verified string accepted pfa probability exceeding string average reward greater corresponding umdp model 
see assume string denote average reward corresponding umdp model 
action expected total reward wa probability entering start start start fig 

pfa criterion maximizing probability reaching goal state probabilistic planning model 
pfa emptiness problem modeled total reward criterion old accepting goal state action transition extra absorbing state giving reward 
rewards zero 
similarly pfa emptiness problem modeled average reward problem goal state executing obtaining rewards 
average reward wa jwj sufficiently large jwj conversely verify string similar equivalence holds infinite sequences 
undecidability discounted criterion turn commonly studied model maximizing total expected discounted reward infinite horizon 
proof theorem small change pfa constructed emptiness reduction 
theorem policy existence problem infinite horizon discounted criterion undecidable 
proof 
take pfa constructed reduction section change leaky discounted pfa follows 
rational value 
leaky pfa reading input symbol continues original pfa probability gamma say leaks case transition absorbing rejection state absorbing accepting state equal probability 
equal leak probabilities balance show original pfa accepts string probability greater leaky version accepts string probability greater 
hard verify maximizing probability reaching accepting state leaky pfa corresponds maximizing expected total discounted reward umdp problem discount fi gamma reward structure described proof theorem fig 

show tm accepting see section leaky pfa accepts strings probability greater tm accepting finite string accepted probability 
assume tm accepting accepting sequence tm 
assume original pfa constructed reduction accepts decisive outcomes decisive counter limit explained section 
denote probability pfa halts goes absorbing states reading event pfa leaked halted decisions denote probability 
pfa halts probability acceptance gamma gamma term corresponds probability leaked accepted halted second probability hasn leaked accepted halted 
probability acceptance ffl gamma ffl gamma ffl ffl may argue probability leaky pfa halting approaches increasing bounded constant greater show acceptance probability exceeds note ek probability pfa decisions argue ek event union disjoint events halting leaking concatenation gammak event halting halting leaking remaining gamma concatenations consequently ek gammaj ek ek gammaj ek assume tm accepting 
candidate accepting sequence refers sequence tm configurations initial tm configuration accepting configuration 
input string viewed concatenation candidate sequences appended possibly empty string prefixes candidate sequence delta delta delta probability acceptance leaky pfa qp probability halting probability leaking pfa halts 
possibility halting 
probability acceptance gamma gamma ffl probability halting probability leaking pfa halts 
pfa halts leak probability acceptance strictly pfa keeping counter probability suspect outcomes appropriately small 
similar conversion proof theorem reduces problem leaky pfa question policy existence umdp discounted criterion completing proof 
addition finite counter pfa reduction unnecessary proof establishing undecidability emptiness crucial making proof 
probability pfa acceptance exceed tm accepting 
hand infinite sequences corresponding valid non halting tm computations approach construction leaky pfa 
distinction cases tm accepting cases tm accepting 
undecidability negative model optimality criteria studied point involve maximizing expected benefits executing policy 
alternative goal choose policy avoid disaster 
cases state oriented negative models see example objective minimize probability entering designated negative states infinite horizon 
reduction previous proof establish undecidability particular negative model technique applicable negative models 
theorem policy existence state oriented negative model undecidable 
proof 
reduce string existence question leaky pfa reduction theorem problem 
note string existence reduction leaky pfa tm accepting exist infinite finite sequences symbols probability acceptance leaky pfa exceeds 
tm rejecting probability acceptance infinite sequence infinite sequences acceptance equals may exist 
take rejecting absorbing state leaky pfa state avoid undecidable question infinite sequence avoids rejecting state probability exceeding 
inapproximability pomdps hard argue inapproximability result similar holds pomdps total undiscounted reward average reward criteria 
discounted criterion optimal value approximable ffl due presence discount factor 
existence optimal finite controllers optimal strings question optimal finite controller exists pomdp interesting 
similar case threshold isolation motivating question pomdp initial distribution determine optimal finite controller answer positive possibly finding controller easier space finite controllers needs searched 
recall section finite controllers periodic action sequences 
simple construction example pomdps provably optimal periodic action sequence finite controller shows problem undecidable undiscounted total average reward criteria 
constructions gap acceptance probability pfa corresponding cases tm accepting 
showing discounted criterion difficult positive lower bound gap 
extensions proof theorem explain briefly 
explanation motivates proof undecidability follows 
proof theorem tm accepting exists optimal periodic sequence constructed pfa 
hand nonempty subset tms accepting aperiodic configuration sequences 
clear tm aperiodic configuration sequence corresponding pfa optimal action sequences success probability need necessarily correspond tm aperiodic legal configuration sequence consequently aperiodic 
note pfa reject sequence composed false candidate accepting sequences 
sequence ends accepting rejecting configuration legal ends periodic sequence configurations may obtain limiting acceptance probability leaky pfa optimal 
proof circumvent difficulty easing condition pfa accepts rejects corresponding tm halt aperiodic configuration sequence optimal sequence pfa provably aperiodic 
process give difference acceptance probability pfa cases tm accepting rejecting 
theorem problem optimal finite controller exists discounted pomdp undecidable 
proof 
construct leaky pfa similar ones proof undecidability emptiness problem theorem modification conditions acceptance rejection 
consequence modification maximum probability acceptance pfa corresponding tm accepting 
consider pfa proof undecidability emptiness problem 
modification way automaton behaves case decisive outcome weak equality test counter contents outcome suspect test pfa rejects immediately outcome correct test accepts immediately case indecision continues 
reaches configuration corresponding tm configuration accepting rejecting check start configuration continues 
conditions remain 
example pfa rejects easy check conditions checking tm transition fails pfa reaches input 
pfa keep finite counter 
pfa leaky just proof theorem capture discounting 
see pfa tests individual transitions legal acceptance probability affected corresponding tm accepting 
corresponding tm halts infinite concatenation accepting rejecting configuration sequence periodic pfa acceptance probability limit 
similarly tm halt repeats configuration corresponding configuration sequence periodic leaky pfa achieves probability limit 
tm halt repeat configuration leaky pfa limiting acceptance probability corresponding aperiodic configuration sequence 
aperiodic sequence optimal sequence pfa probability acceptance sequence strictly illegal sequence illegal transition pfa rejects decision particular test 
follows counter turing machine halting problem reduces periodic sequence existence problem leaky pfa optimal periodic sequence know tm halts eventually repeats sequence configurations forever 
simulate tm determine case finite time 
leaky pfa optimal periodic se quence know tm halt repeats configuration 
undecidability follows 
note consequence theorem seemingly easier problem exists string finite sequence optimal undecidable add single action start state leaky pfa theorem 
action leads accepting rejecting states equal probability 
umdp optimal finite sequence tm accepting 
consequently see related problem umdp initial distribution action sequence better action sequence umdp higher expected value action sequence provide undecidable discounted case 
summary related main technical result established undecidability wide class stochastic optimization problems ffl probabilistic extensions classical planning problem observability stochastic observability ffl infinite horizon pomdps variety optimization criteria including discounted models exact approximate solutions ffl threshold isolation problem ffl existence optimal finite controller discounted undiscounted pomdps 
hardly surprising general problem finding optimal policy partially observable system arbitrary objective function intractable reason impossible bound optimal policy expected reward 
surprising usual ways restrict simplify problem positive bounded models average reward models discounted models explicit state representation settling approximate solutions problem easier solve worst case 
related includes complexity analyses ffl deterministic classical planning ffl restricted variants probabilistic planning ffl fully observable mdps ffl restricted variants pomdps ffl probabilistic finite state automata complexity results deterministic planning available years chapman np hardness result strips planning followed additional analysis bylander 
results related historical connection planning problem earlier results rely combinatorial analysis quite different techniques establish results 
littman goldsmith mundhenk analyze complexity propositional probabilistic planning problems inspired model planning derived classical ai literature 
results restriction placed solutions limit analysis plans expressed size polynomial size problem specification 
result results parallel results finite horizon pomdps 
rintanen analyzes complexity probabilistic planning problems average reward criteria establishes undecidability results infinite horizon criteria results 
early papers pomdp problem formulations include drake astrom aoki 
sondik smallwood probably addressing computational difficulties associated solving pomdps 
key applications algorithms surveys 
analysis complexity solving pomdps began papadimitriou tsitsiklis formally establish np hardness results variety finite horizon problems conjecture undecidability infinite horizon case 
computational complexity finite horizon control problems received considerable attention see example :10.1.1.42.1702
infinite horizon case questions complexity goal state reachability nonzero probability probability reduce reachability computations decidable studied alur littman 
established optimal planning full observability prohibitively difficult theory practice 
results suggest may promising explore alternative problem formulations including restrictions system dynamics agent sensing effecting powers useful realistic problem domains amenable exact approximate solution algorithms 
discovery interesting problems computationally intractable worst case surprising discouraging ai researcher point 
bill rounds pointed connection probabilistic planning 
michael littman eric hansen valuable discussions input particular raising question existence optimal finite controller problem 
hanks madani supported part arpa rome labs part nsf iri 
anne condon supported nsf ccr 
alur yannakakis 
distinguishing tests nondeterministic probabilistic machines 
proc 
th stoc pages 
aoki 
optimal control partially observable markovian systems 
franklin inst 
astrom 
optimal control markov processes incomplete state information 
math 
anal 
appl 
bertsekas 
dynamic programming deterministic stochastic models 
prentice hall 
boutilier dean hanks 
decision theoretic planning structural assumptions computational leverage 
journal artificial intelligence research 
de 
complexity partially observed markov decision processes 
theoretical computer science pages 
bylander 
computational complexity propositional strips planning 
artificial intelligence 
chapman 
planning conjunctive goals 
artificial intelligence 
condon lipton 
complexity space bounded interactive proofs 
th annual symposium foundations computer science 
drake 
observation markov process noisy channel 
phd thesis massachusetts institute technology 
draper hanks weld 
probabilistic planning information gathering contingent execution 
proceedings second international conference artificial intelligence planning systems pages 
menlo park calif aaai press june 
fikes nilsson 
strips new approach application theorem proving problem solving 
artificial intelligence 
freivalds 
probabilistic way machines 
proc 
international symposium foundations computer science volume pages 
springer verlag 
goldsmith mundhenk 
complexity issues markov decision processes 
proc 
ieee conference computational complexity pages 
hansen 
finite memory control partially observable systems 
phd thesis university massachusetts amherst 
kushmerick hanks weld 
algorithm probabilistic planning 
artificial intelligence 
littman 
algorithms sequential decision making 
phd thesis brown 
littman goldsmith mundhenk 
computational complexity probabilistic planning 
artificial intelligence research 
lovejoy 
survey algorithmic methods partially observable markov decision processes 
annals operations research pages 
madani 
complexity results infinite horizon markov decision processes 
phd thesis university washington 
monahan 
survey partially observable markov decision processes theory models algorithms 
management science 
mundhenk goldsmith allender 
complexity policy existence problem partially observable finite horizon markov decision processes 
mathematical foundations computer science pages 
mundhenk goldsmith eric allender 
complexity policy evaluation finite horizon partially observable markov decision processes 
proc 
nd mathematical foundations computer science pages 
mundhenk goldsmith allender 
complexity results finite horizon markov decision problems 
journal acm 
papadimitriou tsitsiklis 
complexity markov decision processes 
mathematics operations research august 
paz 
probabilistic automata 
academic press 
puterman 
markov decision processes 
wiley inter science 
rabin 
probabilistic automata 
information control 
rintanen 
complexity probabilistic planning average rewards 
proceedings international joint conference artificial intelligence 
appear 
smallwood sondik 
optimal control partially observable markov processes finite horizon 
operations research 
sondik 
optimal control partially observable markov processes infinite horizon discounted costs 
operations research 
tseng 
solving horizon stationary markov decision process time proportional log 
operations research letters 
white 
markov decision processes 
wiley 
weak equality test describe algorithm carried pfa weak equality test detail 
see algorithm executed pfa easier think pfa model equivalent way tm machine model machine read input tape finite memory flip fair coin step base transition coin flip addition input state 
input question outputs algorithm state pfa ends indecision suspect correct described chapter 
pfa performs independent computations scans input letter algorithm flips coins 
letter algorithm flips coins 
letter letter algorithm flips coin 
letter letter algorithm flips coin 
algorithm checks mod constant 
easily verified algorithm carried pfa operations described 
mod outcome suspect 
event true computations get heads event true computations get heads 
algorithm outputs indecision pfa goes indecision state false common case true 
case decision outcome algorithm outputs suspect true false outputs correct false true 
show probability true case decision outcome probability outputting suspect higher outputting correct 
pa gamma gamma gamma gamma gamma pb gammai gammaj gammai gammaj gamma gamma gamma pa pb case decision outcome suspect correct outcomes equally 
assume loss generality lk integer 
note pa larger pb pa gamma pb gamma gamma lk probability suspect outcome decision aj ab bja ab ab ab ab gammap ab similarly probability correct decision bja ab gammap gammap gammap consequently decision outcome probability suspect times higher probability correct aj ab bja ab gammap gammap gamma gamma gamma lk gamma 
