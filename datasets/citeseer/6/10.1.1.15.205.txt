multi paragraph segmentation expository text describes texttiling algorithm parti expository texts coherent multi paragraph discourse units reflect subtopic structure texts 
algorithm uses domain independent lex ical frequency distribution information recog interactions multiple simultaneous themes 
fully implemented versions algorithm de scribed shown produce segmentation corre sponds human judgments major subtopic boundaries thirteen lengthy texts 
structure expository texts characterized sequence discussions occur context main topic discussions 
example popular science text called main topic existence life earth planets described consisting numbers indicate paragraph numbers intro search life space moon chemical composition early proximity moon shaped moon helped life evolve earth earth moon system binary star systems life un low probability non binary systems properties sun facilitate life summary subtopic structure marked cal texts headings divide text coherent segments brown yule state kind division basic discourse 
expository texts consist long sequences paragraphs little structural marti hearst computer science division evans hall university california berkeley berkeley ca xerox palo alto research center marti cs 
berkeley edu demarcation 
presents fully implemented gorithms lexical cohesion relations partition expository texts multi paragraph segments re subtopic structure 
model dis course structure text partitioned contiguous nonoverlapping blocks call general approach texttiling 
ultimate goal identify extents units label contents 
focusses discovery subtopic structure leaving determination subtopic content 
discourse segmentation done finer granularity suggested 
lengthy written expository texts multi paragraph seg mentation potential uses including im provement computational tasks dis information 
example disambiguation algorithms train arbitrary size text windows yarowsky gale ai 
gorithms lexical occurrence determine se mantic relatedness benefit windows motivated boundaries 
information retrieval algorithms subtopic structuring return meaningful portions text paragraphs short sections long 
motivated segments meaningful unit indexing long texts 
salton 
working encyclopedia text find comparing query sections paragraphs successful comparing full documents 
results text tiling new paradigm information access full text documents hearst 
section describes discourse model motivates approach 
followed descrip tion algorithms subtopic structuring lexical cohesion relations evalua tion algorithms summary discussion 
discourse model discourse models assume hierarchical tation model attentional intentional structure sidner rhetorical structure theory mann thompson 
aspects discourse analysis require model choose cast expository text linear sequence segments computational simplicity struc ture sufficient coarse grained tasks interest 
chained nl ko text structure types 
nodes correspond sentences edges nodes indi cate strong term overlap sentences 
ko suggests discovering text structure dividing sentences seeing word overlap appears sentences 
overlap forms kind intra structure fully con nected graphs indicate dense discussions topic long chains connectivity indicate sequential account see 
cen idea defining structure text function connectivity patterns terms comprise 
contrast segmenting guided primarily fine grained discourse cues register change focus shift cue words 
computa tional viewpoint deducing textual topic structure lexical connectivity appealing easy compute discourse cues misleading respect topic struc ture brown yule 
additionally passonneau litman concede difficulty eliciting hierarchical intentional structure degree consistency human judges 
topology interest final diagram piecewise monolithic structure represents sequences densely interrelated dis linked 
ogy maps nicely viewing documents sequence densely interrelated discussions 
assumption seen valid quite useful 
theoretical stance bears close resemblance chafe notion flow model discourse chafe description writes pp data suggest speaker moves focus focus thought thought certain points may radical change space time character config event structure world 
points change maximal way episode boundary strongly 
change considerably oth ers change radically kinds var ied interactions factors possible 
chafe concerns narrative text kind observation applies expository text 
texttiling algorithms designed recognize episode boundaries determining thematic components listed chafe change max way 
researchers studied patterns occur rence characters setting time matic factors chafe mentions usually con text narrative 
contrast attempt determine relatively large set active themes changes simultaneously regardless type thematic fac tor 
especially important expository text subject matter tends structure dis course characters setting ex ample text discussion tal movement shoreline gives way discussion binary unary star systems 
change setting character change subject matter 
recognize subtopic changes occur lexical cohesion relations halliday hasan manner similar suggested ko 
morris hirst pioneering computing dis course structure lexical relations morris hirst morris precursor reported 
influenced halliday hasan ory lexical coherence morris developed algorithm finds chains related terms comprehensive thesaurus roget fourth edition 
example interestingly chafe arrived flow model working extensively dissatisfied hierarchical model paragraph structure longacre 
algorithm executed hand thesaurus sentence 
form iii scientist ii space ii star binary astronomer orbit pull planet galaxy lunar life moon move continent shoreline time water say species sentence 
distribution selected terms text single digit frequency sentence number blanks indicate frequency zero 
words residential apartment index thesaural category considered coherence relation 
chains structure texts atten tional intentional theory discourse structure grosz sidner extent chains correspond extent segment 
algorithm rates notion chain returns repetition terms long close intention spans digression 
morris hirst algorithm attempts discover attentional intentional structure goals different texttiling 
specifically discourse structure attempt discover hierar fine grained discussed 
model set take advantage fact multiple simultaneous chains occur intention 
furthermore chains tend overlap extensively long texts 
shows distribution sentence number selected terms text 
terms fairly uniform distribution expected provide information di visions discussion 
terms occur mainly text terms binary planet considerable overlap generally available online 
sentences 
somewhat cluster terms sentences corresponding grouping paragraphs human judges read text 
diagram evident simply looking chains repeated terms sufficient deter mining subtopic breaks 
combining terms closely related semantically single chains ficient different themes active segment 
example sentences contain dense interaction terms move con shoreline time species life occur region 
case interlinked terms sentences space star binary astronomer orbit closely re lated semantically assuming appropriate senses terms determined 
algorithms discovering subtopic structure researchers halliday hasan tan hen walker noted term rep strong cohesion indicator 
term repetition useful subtopic structure analyzed terms multiple simultaneous information threads 
sec tion describes algorithms discovering subtopic structure term repetition lexical cohesion 
method compares window size pair adjacent blocks text similar lexically 
method assumes similar blocks text current subtopic continues conversely adjacent blocks text dissimilar implies change subtopic flow 
second method exten sion morris hirst approach keeps track active chains repeated terms membership chain determined location text 
method determines subtopic flow recording discourse bulk set chains ends new set chains begins 
core algorithm main parts 
tokenization 
similarity determination 
boundary identification tokenization refers division input text individual lexical units 
versions algorithm text subdivided pre defined size parameter algorithm actual syntactically determined sentences circumventing normalization problems 
purposes rest discussion groupings tokens referred token sequences 
prac tice setting tokens token sequence works best texts 
morphologically analyzed ken stored table record token sequence number occurred frequently appeared token sequence 
record kept locations paragraph breaks text 
closed class frequent words elimi nated analysis 
tokenization step comparison adjacent pairs blocks token sequences lexical similarity 
important parameter algorithm blocksize number token sequences grouped block compared adjacent group token sequences 
value labeled varies slightly text text heuristic average paragraph length token sequences 
practice value works texts 
actual paragraphs lengths highly irregular leading unbalanced comparisons 
similarity values computed token sequence gap number score assigned token sequence gap corresponding similar token sequences token sequence token sequences 
note moving window approach means token sequence appears similarity computations 
similarity blocks calculated cosine measure text blocks bl bz token sequences bx ranges terms reg tokenization step wt weight assigned term block version algorithm weights terms simply frequency block similarity score blocks high blocks terms common 
formula yields score inclusive 
scores plotted token sequence number similarity score 
similarity measured blocks bl bl spans token sequences spans measurement axis coordinate falls tween token sequences 
plot ting token sequence number axis plot token sequence gap number plot smoothed average smoothing practice round aver age smoothing window size works best texts 
boundaries determined changes se quence similarity scores 
token sequence gap numbers ordered steeply slopes plot side token sequence gap absolute similarity score 
token sequence gap algorithm looks scores token sequence gaps left long values increasing 
values left peak difference score peak score recorded 
proce dure takes place token sequence gaps right scores examined long continue rise 
relative height peak right added relative height peak left 
gap occurring peak score zero neighbors higher 
new scores called depth scores corresponding sharp change occurs sides token sequence gap sorted 
segment boundaries assigned token sequence gaps largest corresponding scores adjusted necessary corre true paragraph breaks 
proviso check done prevents assignment close adjacent segment boundaries 
currently intervening token sequences boundaries 
helps control fact texts spurious header information single sentence para graphs 
algorithm determine segments assigned document paragraph earlier weighted terms fre quency times inverse document frequency 
experiments simple term frequencies better 
il im ml mmm lm mmm 

la 
judgments readers text 
internal numbers indicate location gaps paragraphs axis indicates token sequence gap number axis indicates judge number break horizontal line indicates judge specified segment break 
ll la io io loo results block similarity algorithm text 
internal numbers indicate paragraph numbers axis indicates token sequence gap number axis indicates similarity blocks centered corresponding token sequence gap 
vertical lines indicate boundaries chosen algorithm example leftmost vertical line represents boundary paragraph 
note align boundary gaps 
potential segment boundary 
attempt absolute cutoff problematic need correspondence document style length 
cutoff particular valley depth similarly problematic devised method determining number boundaries assign scales size document sensitive patterns similarity scores produces cutoff function average standard deviations depth scores text analysis currently boundary drawn depth score exceeds 
evaluation way evaluate segmentation algorithms compare judgments human readers compare algorithms texts pre marked authors third way see results improve computational task 
section compares algorithm reader judgments author markups fallible usually applied text types algorithm designed hearst shows task show results algorithms better algorithm similar goals 
reader judgments judgments obtained readers thirteen magazine articles satisfied length criteria words contained little structural 
judges longer text words reader judgments obtained earlier ex periment 
judges technical researchers 
texts short headers removed consistency 
asked simply mark paragraph boundaries topic changed explicit instructions granularity seg mentation 
shows boundaries marked judges text 
format helps il general trends judges helps show disagree 
instance judge marked boundary tween paragraphs 
judge mark boundary judges 
major boundaries occur paragraphs 
contention paragraphs readers marked marked marked 
outline gives idea segment 
passonneau litman discuss length con evaluating segmentation algorithms reader judgment information 
shows agreement judges imperfect trends discerned 
passonneau litman data judges mark boundary segmentation significant variation test cochran 
data showed similar results 
isn clear useful signifi cance information simple majority provide overwhelming proof objective real ity subtopic break 
readers disagree draw boundary marking topic shift general trends basis compare different algorithms 
goals texttiling better served algorithms produce fewer boundaries set cutoff true boundaries judges paragraph 
remaining gaps consid ered 
results shows plot results applying block comparison algorithm text 
lowermost portion valley located para graph gap judgment moved nearest para graph gap 
part regions strong similarity correspond regions strong agree ment readers 
results text fifth highest test texts 
note similarity information paragraph weak 
paragraph briefly summarizes contents previous paragraphs paragraphs fewer sentences combined neighbor neighbor deemed follow true boundary paragraphs text 
explained part stark shows readers disagree measurably place paragraph boundaries texts boundaries removed 
ogy occurred reappears location spirit grosz sidner pop operation 
displays low similarity neighbors 
example breakdown caused assumptions subtopic struc ture 
possible additional pass text find structure kind 
final paragraph summary entire text algorithm recognizes change terminology preceding paragraphs marks boundary readers chose differentiate sum mary reason algorithm judged error sectioning decision reasonable 
illustrates inherent testing reader judgments part judges loose constraints 
advice gale 
compare upper lower bounds 
upper bound case reader judgment data 
lower bound baseline algorithm simple reasonable approach problem automated 
simple way segment texts place boundaries randomly document con number boundaries equal average number paragraph gaps assigned judges 
test data boundaries placed paragraph gaps 
program written places boundary potential gap time ing random number generator run times text average scores runs 
scores appear table results shown comparison purposes 
algorithms evaluated true boundaries select total selected precision true boundaries total possible recall salton 
recall measure implicitly signals number missed bound aries false negatives deletion errors number false positives insertion errors indicated 
cases algorithms correct paragraph especially texts gorithm performs poorly 
block similarity algorithm allowed paragraph dramatic improvement scores texts lower part table yielding precision recall 
case algorithm incorrect para graph gap blocking close judges intended 
table shows blocking algorithm chaining algorithm lower bounds 
table shows results detail 
block similarity algorithm slightly better chaining algo rithm difference may prove significant long run 
furthermore versions algorithm changes parameters algorithm baseline baseline chains blocks judges precision recall table precision recall values test texts 
perturbs resulting boundary markings 
undesirable property remedied kind information theoretic formulation problem 
summary described algorithms tation expository texts discourse units re subtopic structure expository text 
introduced notion recognition multiple si themes bears resemblance chafe flow model discourse ko text structure types 
algorithms fully imple mented term repetition thesaural relations knowledge bases inference mechanisms works experimental texts 
structure obtains coarse grained generally re human judgment data 
earlier hearst incorporated thesaural information algorithms surprisingly lat est experiments find information degrades performance 
due problems algorithm 
simple algorithm just posits relations terms small distance apart wordnet miller ro get thesaurus project gutenberg mod morris hirst heuristics bet ter 
feel issue closed stead consider successful grouping related words 
possible alternative kozima suggested computationally sive semantic similarity metric find similarity terms small window text words 
incorporate notion multi ple simultaneous themes just tries find breaks semantic similarity small number terms 
strategy may substitute kind similarity information term repetition gorithms described 
possibility semantic similarity information com puted resnik dagan ai 

discourse cues detection segment boundaries discourse purposes ex researched predominantly spo ken text see hirschberg litman sum mary research groups treatments cue words 
possible incorporation formation may provide relatively simple way improve cases algorithm paragraph 
acknowledgments benefited comments graeme hirst jan pedersen sibun jeff siskind 
anne fontaine interest help early stages robert sky supporting line research 
sponsored part advanced research projects agency 
mda national research initiatives cnri xerox palo alto research center 
brown george yule 

discourse anal ysis 
cambridge textbooks linguistics series 
cam bridge university press 
chafe wallace 
flow thought flow language 
syntax semantics discourse syntax ed 
talmy giv volume 
academic press 

comparison percentages matched samples 
biometrika 
dagan ido shaul marcus shaul markovitch 

contextual word similarity estimation sparse data 
proceedings th annual meet ing association computational linguistics 
gale william kenneth church david yarowsky 

estimating upper lower bounds performance word sense tion programs 
proceedings th meeting association computational linguistics 

method disambiguating word senses large corpus 
computers hu 
grosz barbara candace sidner 

atten tion intention structure discourse 
compu tational linguistics 
halliday hasan 

cohesion english 
london longman 
hearst marti 
texttiling quantitative ap proach discourse segmentation 
technical report sequoia computer science department univer sity california berkeley 

context structure automated full text information access 
university california ley dissertation 
computer science division technical report 
hirschberg julia diane litman 

empirical studies disambiguation cue phrases 
compu tational linguistics 
total baseline avg blocks chains judges avg text possible prec rec prec rec prec rec prec rec table scores text showing precision recall 
indicates number correctly placed boundaries indicates number inserted boundaries 
number deleted boundaries determined subtracting total possible 
kozima hideki 

text segmentation similar ity words 
proceedings th annual meeting association computational linguis tics columbus oh 
longacre 
paragraph grammatical unit 
syntax semantics discourse syntax ed 
talmy volume 
academic press 
mann william sandra thompson 

rhetorical structure theory theory text zation 
technical report isi rs isi 
miller george richard beckwith christiane fellbaum derek gross katherine miller 

wordnet line lexical database 
journal lexicography 
jane 

lexical cohesion thesaurus structure text 
technical report csri computer systems research institute university toronto 
graeme hirst 

lexical cohesion computed thesaural relations indicator structure text 
computational linguistics 
passonneau rebecca diane litman 

intention segmentation human reliability correlation linguistic cues 
proceedings st annual meeting association computa tional linguistics 
resnik philip 
selection information class approach lexical relationships 
university pennsylvania dissertation 
institute research cognitive science report ircs 
salton gerard 

automatic text processing transformation analysis retrieval information computer 
reading ma addison wesley 
james allan chris buckley 

ap proaches passage retrieval full text information systems 
proceedings th annual inter national acm sigir conference pittsburgh pa schutze hinrich 

word space 
advances neural information processing systems ed 
stephen hanson jack cowan lee giles 
san mateo ca morgan kaufmann 
ko 
adaptive method automatic abstracting indexing 
information processing proceedings ifip congress ed 

north holland publishing com 
stark heather 

paragraph markers 
discourse processes 
tannen deborah 

talking voices repetition dia imagery conversational discourse 
studies interactional sociolinguistics 
cambridge univer sity press 
walker marilyn 

redundancy collaborative dia 
aaai fall symposium discourse structure natural language understanding generation ed 
julia hirschberg diane litman kathy mccoy candy sidner pacific grove ca 
yarowsky david 

word sense disambiguation ing statistical models roget categories trained large corpora 
proceedings fourteenth interna tional conference computational linguistics nantes france 
