apples parameter sweep template user level middleware grid henri casanova berman richard wolski computer science engineering department university california san diego usa casanova berman cs ucsd edu computer science department university tennessee knoxville usa rich cs utk edu computational grid promising platform ecient execution parameter sweep applications large parameter spaces 
achieve performance grid applications scheduled shared data les strategically placed maximize reuse application execution adapt deliverable performance potential target heterogeneous distributed shared resources 
parameter sweep applications important class applications greatly bene development grid middleware embeds scheduler performance targets grid resources transparently 
describe user level grid middleware project apples parameter sweep template apst uses application level scheduling techniques various grid technologies allow ecient deployment parameter sweep applications grid :10.1.1.40.5011
discuss ieee 
research supported part nsf asc nasa npaci contract ad darpa ito contract possible scheduling algorithms detail software design 
describe current implementation apst systems globus netsolve network weather service experimental results :10.1.1.46.3287:10.1.1.25.8254
keywords application level scheduling adaptive runtime scheduling computational grid grid middleware parameter sweeps applications scheduling heuristics distributed storage 
fast networks possible aggregate cpu network storage resources computational grids 
environments ectively support largescale runs distributed applications 
ideal class applications grid class parameter sweep applications psas arise scienti engineering contexts 
applications typically structured sets experiments executed distinct set parameters 
technical challenges involved deploying largescale applications distributed computing environment 
parameter sweep experiments independent communicate psas structured distinct experiments share large input les produce large output les 
achieve ciency large scale runs shared data les located experiments psa scheduled adapt dynamically delays qualities service shared grid resources 
previous demonstrated runtime adaptive scheduling fundamental approach achieving performance applications grid :10.1.1.40.5011
psas great interest scienti community user level middleware targeted ecient execution deployment large scale parameter sweeps enormously helpful users 
describe design implementation middleware apples parameter sweep template apst 
purpose template provide framework easily eciently developing scheduling executing large scale psas computational grids 
complements nimrod project targets psas developing high throughput condor monte carlo simulations :10.1.1.42.8707:10.1.1.42.8707
nimrod scheduling approach di erent deadlines grid economy model focuses ecient location data experiments adaptive scheduling 
condor consider distributed data constraints 
di ers nimrod condor designed target multiple grid infrastructure environments simultaneously example 
section ii describe application grid model 
sections ii ii provide context describing previous psa scheduling algorithms 
section iii describe new design implementation apples parameter sweep template 
section iv presents experimental results evaluation apst software 
conclude discuss section ii 
scheduling parameter sweep applications application grid model de ne parameter sweep application set independent sequential tasks task precedences 
assume input task set les single le input task 
model assume loss generality task produces exactly output le 
model motivated real world psas see section iv 
assume computational grid available application consists sites contain computing resources called hosts workstations multiprocessors local storage resources called disks 
case large scale psas critical performance hosts site share data local disks ef ciently 
typically number computational tasks application orders magnitude larger number available processors 
implementation apst aims lever output files 
input files tasks storage host network user host storage site fig 

application grid model aging software infrastructure available distributed environment 
access remote computational resources facilitated various grid infrastructure projects approaches implementing distributed storage infrastructure low level systems gass ibp distributed le systems afs :10.1.1.25.8254
depicts application model grid model 
impose constraints performance characteristics resources 
scheduling algorithms described require estimates computation le transfer times 
estimates provided user analytical models historical information facilities network weather service nws env remos grid services globus computed combination previous :10.1.1.46.3287:10.1.1.25.8254
models assumptions discussed detail 
self scheduled workqueue straightforward popular adaptive scheduling algorithm scheduling sets independent tasks self scheduled workqueue workqueue short 
algorithm assigns hosts soon available greedy fashion 
adaptive may fail capture idiosyncrasies application respect computing environment data storage requirements data sharing patterns 
context application model see workqueue strategy appropriate certain application scenarios large shared input les large input les shared large number tasks making le transfer costs negligible compared computational costs 
topology nature grid available user justify workqueue large clusters interconnected high speed networks 
instances workqueue algorithm leads poor schedules typically large les shared relatively small number tasks tasks relatively small computational costs 
situations arise realworld psas user explores ranges parameters multiple scenarios scenario described large input le see section iv 
may rel slow networks interconnecting different sites combined relatively large le sizes critical application le transfer costs minimized 
certainly true grid wide psas large data sets stored distributed digital libraries internet 
importantly workqueue algorithm perform resource selection behalf application 
sheer amount resources soon available national computational grid necessary determine subsets resources ectively running psa 
need sophisticated adaptive scheduling algorithm automatically perform resource selection allocation data computation needed 
section describes rst approach designing implementing algorithm 
adaptive scheduling heuristics task host assignment ecient deployment psas computational grid requires scheduling algorithms specially designed adapted structure requirements psas 
dynamic nature grid environments adaptive algorithms provide exibility react changing resource conditions run time 
previous described scheduling algorithm provides fundamental building block apples parameter sweep template 
subsection review results order self contained 
psas focus scheduling algorithms objective minimize application makespan de ned 
proposed adaptive scheduling algorithm call sched 
general strategy sched takes account resource performance estimates generate plan assigning le transfers network links tasks hosts 
account grid dynamic nature algorithm called repeatedly schedule modi ed re ned 
denote points time sched called scheduling events terminology 
having multiple scheduling events possible achieve adaptive scheduling 
frequent events adaptive algorithm 
shows general skeleton sched 
step takes care setting scheduling intervals dynamically 
step sched creates gantt chart build scheduling plan 
chart contains column network link host 
column time line lled blocks indicate resource usage 
step inserts blocks corresponding ongoing le transfers computations 
step core algorithm assigns tasks le transfers hosts network links 
step gantt chart converted schedule implemented grid resources 
problem deciding optimal assignment le transfers network links computation hosts np complete 
usual heuristics decisions step algorithm heuristics implemented 
simple heuristics scheduling independent tasks proposed min min max min su erage 
heuristics iteratively assign tasks processors considering tasks scheduled computing expected minimum completion times 
task done tentatively scheduling resource estimating task completion time computing minimum completion time resources 
sched compute scheduling event create gantt chart foreach computation le transfer currently underway compute estimate completion time ll corresponding blocks host assigned heuristically assign tasks hosts lling blocks convert plan fig 

scheduling algorithm skeleton task metric computed task best metric assigned resource lets achieve mct 
process repeated tasks scheduled 
way computing evaluating metric entirely de nes heuristic behavior appendix gives basic algorithm heuristics succinct descriptions di erent metrics 
base heuristics ective environments tasks hosts exhibit hosts best tasks due specialized hardware optimized software libraries 
key idea presence input les disk close host akin idea task host 
expect heuristics ective setting 
adapted base heuristics take account le location constraints 
note step lls gantt chart assigned resources 
sched called scheduling event new assignments 
typically step assigns resources scheduling event plus xed amount time conservative account prediction inaccuracies 
intuitively rationale su erage applicable setting task scheduled host task su er scheduled host 
expect sufferage idea simple elegant ective way capture data distribution patterns 
proposed extension su erage heuristic adapted grid model create xsu erage heuristics see appendix 
heuristics mentioned evaluated simulation environments xsu erage proved promising heuristic see 
conducted simulations study impact inaccurate performance estimates perfect predictive accuracy rarely real programming environments 
increasing frequency calls scheduling algorithm words increasing adaptivity possible tolerate inaccuracies simulations show xsu erage performs particularly context multiple scheduling events poor information 
heuristics designed low computational complexity 
furthermore possible reduce set tasks considered heuristics 
section iv describes rst simple approach task space reduction 
possible run sched frequently 
note self scheduled workqueue algorithm performance estimates 
case single scheduling event execution workqueue cient scheduling algorithm accuracy performance estimates poor 
iii 
apples parameter sweep template motivation goals apples project focuses design development grid enabled highperformance schedulers distributed applications :10.1.1.40.5011
rst generation apples schedulers demonstrated simultaneously account application systemlevel information possible ectively schedule applications computational environments heterogeneous dynamic grid 
scheduler embedded application dicult re applications 
logical step consider classes applications structurally similar develop independent software frameworks templates schedule applications class 
focuses apples parameter sweep template apst targets psas 
goal twofold 
seek apst investigate dicult problems adaptive scheduling deployment psas 
second seek provide users convenient ecient way running psas available grid resources 
apst projects nimrod provide initial examples user level grid middleware :10.1.1.42.8707:10.1.1.42.8707
development user level middleware critical wide spread application performance computational grid 
achieve goals design software possible user enable disable di erent features globus resources tune various parameters scheduling algorithm choosing scheduling heuristic 
ultimately tuning occur automatically described section section describes justi es design choices 
software design shows design apples parameter sweep template 
software composed client daemon 
moment client executable takes various command line arguments user interact daemon 
possible client submit new computational tasks cancel tasks previously submitted inquire status ongoing computation 
submit new tasks user provide task description le contains task description line 
task description speci es program run required command line arguments location input les output les created written local disks left place remote storage 
user option provide estimate task relative computational cost 
focus scheduling algorithm developing user interfaces 
expect apst client current form serve building block sophisticated user interfaces pse nimrod web cgi interface :10.1.1.42.8707:10.1.1.42.8707
current apst users generally client shell generate task description les simple perl scripts 
current implementation daemon assumes single client user moment 
seen apst daemon consists distinct sub systems controller scheduler actuator meta data 
sub system de nes api 
apis communication noti cation subsystems 
providing multiple implementations apis possible plug different functionalities algorithms apst sub system 
instance writing multiple implementations scheduler api way provide multiple scheduling algorithms 
scheduler central component apst daemon 
api sched api noti cation events concerning application structure new tasks task cancellations status computational resources new disk new host host disk network failures status running tasks task completions failures 
behavior scheduler entirely de ned implementation api 
controller relays information client daemon noti es scheduler new tasks perform task cancellations 
uses scheduler api communicates client simple wire protocol 
actuator implements interaction grid infrastructure software accessing storage network computation resources 
interacts grid security infrastructure behalf user needed 
parts actuator api transport api handles le transfer storage ii env api handles task launching polling cancellation 
scheduler place calls apis actuator implement schedule grid resources 
actuator implementation standard apis grid infrastructure softwares interact resources 
sub system api consists functions 
design ensures possible mix match di erent implementations apis 
particular implementation scheduling algorithm completely isolated actual grid software deploy application tasks 
section iii describes implementations currently available 
intent design constant control cycle scheduler actuator necessary ective scheduling 
env api scheduler periodically polls actuator task completions failures events newly available computing resources 
leads actuator place calls sched api notify scheduler events 
scheduler opportunity react making decisions placing calls env api transport api 
design easy implement straightforward algorithms self scheduled workqueue complex algorithms section ii 
seen section ii promising scheduling algorithms base decisions part forecasted computation le transfer times 
meta data charge keeping track static dynamic meta data concerning resources application 
responsible performing obtaining forecasts various types metadata 
api meta api contains functions store meta data local application inside obtain forecast dynamic meta data 
dynamic static meta data concerning grid resources available grid information services giss accessible standard grid apis 
addition actuator stores netsolve ibp gass nfs nws local meta api impl 
meta data maxmin minmin sufferage actuate report actuate transfer ninf legion nws ibp gass netsolve env api impl 
transport api impl 
actuator scheduler sched api impl 
algorithm workqueue controller wire protocol daemon client gantt chart algorithms grid infrastructure execute query gsi gram gram apst daemon apst client retrieve fig 

apples apst software design meta data application observed le transfer duration network link inside 
scheduler requests forecasts dynamic meta data base scheduling decisions 
section gives details implementation forecasting facility 
current implementation beta prototype implementation apst demonstrated supercomputing conference running hosts 
document describes apst 
software developed linux ported unix platforms 
review implementation sub systems previous section 
implemented multiple versions sched api scheduling algorithms standard workqueue algorithm workqueue algorithm task duplication gantt chart algorithm heuristics introduced section ii 
moment algorithm parameters chosen starting apst daemon stays ective life cycle daemon 
described section plan perform investigation allow automatic dynamic scheduling algorithm selection user intervention 
interacts network weather service nws obtaining dynamic grid resource information concerning cpu loads network latencies bandwidths :10.1.1.46.3287
forecasting done nws forecasting module directly linked apst daemon nws version 
alternative query remote nws forecasters nws generated metadata linked nws forecaster apst generated meta data 
remote forecasters minimize network trac potentially large time series need transmitted network 
hand nws forecaster implementation simpler require distinction types meta data 
nal decision trade gain experience current implementation 
actuator handles interaction grid software moving les launching jobs 
currently provide implementations transport api 
top grid storage software gass part globus toolkit internet backplane protocol ibp developed university tennessee 
projects provide level abstraction handling remote distributed storage devices 
third implementation transport api top nfs 
host computation directly access user le system 
currently implementations env api top globus gram top netsolve 
netsolve client agent server system ers simple way submit computations remote servers current version implement security mechanisms 
hand gram implementation env api globus security infrastructure gsi submit jobs 
considering providing implementations env api ninf legion 
actuator design provides great exibility possible mix match env api transport api 
apst daemon simultaneously globus netsolve servers tasks ibp gass nfs servers storage 
possible task spawned env api les storage system 
moment implementation imposes restriction gram spawned tasks access les gass servers nfs 
likewise netsolve spawned tasks access les stored ibp servers nfs 
systems gass ibp possible tasks outside client le system share copies single le described section ii 
turn worthwhile heuristics section iic 
iv 
software evaluation psa parameter sweep applications arise various elds 
focus primarily application uses monte carlo simulation techniques study molecular bio chemical interactions living cells 
study trajectories neuro transmitters space cell membranes di erent deformations membranes 
currently laboratories world practical applications 
typical subsets tasks share large data les describing polygon surfaces expectation scheduling heuristics xsu erage lead performance real world grid environments 
criteria evaluate software 
discuss apst usability possible easy users deploy large scale simulations 
second experimental results show apst scheduling capabilities promote performance grid environment 
third show multi threading allows apst daemon achieve better grid resource utilization 
usability previously users wanting run distributed simulation manually upload input les remote computational sites create collection shell scripts perform simulation sequentially available host manually check task completions download produced output le 
support data management scheduling fault tolerance 
apst addresses issues 
user needs simply write task descriptions see section iii provide paths input les local disk les pre staged remote storage 
user performs explicit data upload download determined scheduler transparently implemented grid services 
scheduling decisions automatically real time resource availabilities loads 
apst inherits fault tolerance mechanisms grid computational services recover host failures gracefully 
addition new resources added deleted apst adapts current schedule accordingly 
users deploy simulations large sets resources modifying way design experiments 
far user concerned simulation runs locally desktop 
scheduling algorithm depicts computing environment experiments reported section 
hosts located di erent institutions university california san diego ucsd university tennessee knoxville utk tokyo institute technology titech 
hosts ucsd titech linux intel boxes hosts utk solaris sparc workstations 
deployed netsolve ibp titech utk globus gram gass ucsd version 
host breakdown institutions follows hosts ucsd hosts utk hosts titech 
hosts non dedicated mode nws deployed monitor cpus network links 
start apst daemon client titech rewall netsolve access hosts titech cluster 
note current developments possible hosts experiments 
experiments rst set experiment conducted standard application consisting tasks 
relative task computational costs range meaning netsolve ibp nws nws nws tokyo institute technology university tennessee univ california san diego globus gram gass netsolve ibp linux intel solaris sparc linux intel daemon client pst fig 

experimental grid con guration expensive task required times computation cheapest 
application structured monte carlo simulations containing tasks tasks simulation share common input le describing geometry di erent space 
shared les size mbytes respectively 
input les produced output les kbytes 
input les initially local storage host running apst client host titech call source 
experiments compare di erent schedulers self scheduled workqueue gantt chart algorithm introduced section ii 
shows results obtained di erent scenarios 
gure bar heights averages runs standard deviations shown error bars 
scenario measurements obtained back back runs simulation schedulers experiments performed period days 
scenarios input les available source scenario shared input les pre staged remote sites 
pre staging actively performed user setting simulation result distributed digital libraries replication better eciency just mean left les previous runs re 
extreme scenario shared input les pre staged remote sites 
expectation gantt chart algorithm outperform workqueue les pre staged performance algorithms similar les pre staged making gantt chart algorithm versatile consistent 
note give results heuristics mentioned section ii scenarios fig 

gantt chart vs workqueue scenarios stead just give generic gantt chart results 
fact observe real di erence heuristics experiments scheduling choices similar 
due topology testbed 
simulation results previously obtained indicated heuristics start behaving di erently grid topology contains larger number sites 
time constraints prevented gathering experimental results larger testbed report extensive experiments 
average experiments bandwidths source titech cluster times higher source ucsd cluster times higher source utk cluster 
scenario le pre staged 
workqueue sends tasks hosts greedy fashion leading large input les transfers slow links 
contrast gantt chart algorithm uses utk cluster tasks small input les mbyte ucsd cluster tasks small medium input les mbytes titech cluster tasks 
explains average gap scheduling algorithms 
scenario mbyte input les pre staged ucsd 
scheduling algorithms show improvement workqueue pays cost sending mbyte les utk 
scenario mbyte mbyte input les pre staged cluster utk addition les pre staged scenario 
leads improvements algorithms comparison scenario 
relative improvement larger workqueue mbyte le needs transfered 
scenario large input les pre staged clusters see workqueue gantt chart algorithm lead roughly performance 
results indicate scheduling algorithm leads better schedules takes account data storage data sharing patterns application 
data storage concern scenario performs similarly workqueue algorithm 
forecast accuracy scheduling cost large number available resources tasks psas techniques minimize time required apply heuristics section ii 
obvious cost incurred heuristics obtaining forecasts meta data 
detailed appendix heuristics heavy performance estimates constantly obtaining new forecasts leads prohibitive costs 
implementation provides caching forecasts re new forecast obtained 
caching mechanism transparent apst components 
shows typical percentage relative errors forecasting task execu time forecast performed fig 

forecast accuracy tion times run 
mentioned section iii user provide relative computational costs application tasks 
costs representative real task execution times compare tasks task cost requires twice computation task cost 
rst round scheduling initial guesses actual task execution times 
tasks complete uses observed execution times improve accuracy factoring relative costs observed cpu loads host speeds unloaded 
shows behavior relative errors initially dropping average seconds rst tasks complete 
experiment scheduling events seconds apart simulation result obtained relative error rate largely sucient justify gantt chart heuristics scheduling 
corroborates results previous section 
seen appendix heuristics implemented nested loops tasks scheduled 
total number tasks application large heuristics costly albeit polynomial time 
necessary run heuristic reduced task space 
current implementation heuristics apst scheduler reduces task space limiting number tasks processed inner loop heuristic algorithm xed number tasks experiment 
tasks randomly selected iteration outer loop 
comparison purposes ran experiments observe degradation performance obtained schedules 
fact long set tasks contains task uses large shared input le heuristic right decisions 
statistically case application distinct large input les 
true applications exhibit complex structures sophisticated task space reduction technique needed 
detailed investigations di erent reduction techniques impact quality resulting schedule left 
due caching mechanisms simple task space reduction time required run sched algorithm averaged seconds runs recall sched called seconds 
optimization gantt chart implementations possible released version apst exhibit lower scheduling costs 
multi threading performance critical actuator embedded apst daemon able launch computations grid resources case netsolve globus resources eciently possible 
psas consist tasks deployed resources overhead incurred starting remote computations may dramatic impact execution time 
overhead due network software latencies 
instance launch computation remote netsolve server netsolve client transparently user contacts netsolve agent downloads idl description kbytes performs idl check remote server 
server forks separate process handle computation process sends back client 
netsolve client returns control apst actuator 
similar overheads incurred launching remote jobs globus gram 
give example say apst daemon access identical remote hosts computation simulation performed consists tasks require seconds computation 
sake discussion assume actuator incurs overhead second initiating computation remote host 
setting optimistic assumption overhead acknowledging task completions apst daemon achieve utilization available resources leading execution time roughly times larger execution time second overhead 
apst users trying run large computations faced problem acutely performing simulations sp available san diego supercomputing center provides nodes computation 
overhead starting remote job average seconds machine utilization typical simulation times got low 
rst step dynamically measure include overhead scheduler performance model lling gantt number allowed threads fig 

multi threading execution time chart 
improving schedule accuracy new performance model led observable improvement user perspective 
opted providing ef cient implementation env api rst approach uses threads 
expectation multiple concurrent threads place simultaneous call grid software network software latencies partially hidden 
minor changes netsolve client library required order thread safe globus provides gram api 
experiments section netsolve nodes presto cluster node mhz pentium ii linux cluster available tokyo institute technology titech 
information cluster available 
experiments section iv apst daemon running titech inside rewall cluster 
conducted experiments simulation consisting tasks 
experiments tasks running seconds depending task cpu number allowed threads fig 

opportunities multi threading loads cluster dedicated 
input output le transfers done ibp standard workqueue scheduler choice environment 
shows execution times increasing number allowed simultaneous threads env api 
number allowed threads show data points runs total runs application 
execution time averages linked solid line 
see multi threading leads dramatic improvement ectively hides network software latencies 
allowing concurrent threads improves execution time multi threading 
allowing threads lead improvement 
behavior explained data 
gure experiments plot average numbers simultaneous threads actuator ectively spawn 
plot data point run link averages solid line 
see experiment actuator opportunity spawn threads 
strongly related rate tasks complete particular setting turns depends nature application number nature available resources 
experiment apst daemon spawns new tasks approximately seconds time tasks complete average 
shows decrease latency individual netsolve calls number concurrent threads increases 
call latency computed dividing time spent spawning netsolve calls multi threaded fashion data points shown averages computed experiments previously reported 
curve shows dramatic drop call latency initially stabilizes roughly threads 
means netsolve cluster multi threading ective hiding latency ectively threads 
expect larger numbers threads ective larger network latencies perform experiments di erent con gurations 
apst daemon spawns threads simultaneously average experiment close making best multi threading 
ideas implemented multi threaded implementation transport api allows concurrent le transfers top gass ibp nfs 
threads hide latencies associated overheads incurred acknowledging task completions 
leave implementation apst actuator 
described user level grid middleware project apples parameter sweep template apst number simultaneous threads fig 

netsolve latency multi threading deploy parameter sweep applications psas computational grid 
design software easy eciently adaptively resources managed multiple grid infrastructure environments largescale psas ii investigate ectiveness variety adaptive scheduling algorithms implementation strategies 
scheduling extended ways 
plan integrate possibly adapt scheduling algorithms literature :10.1.1.41.5581
current grid model restricts network communications user machine remote site extending allow inter site communication straightforward undertaking 
scheduling algorithms mentioned adaptive changing resource conditions 
goal apst select algorithm run time 
release version apst plan dynamically select workqueue algorithm xsu erage depending estimation accuracy 
initiated collaboration nimrod team attempt explore grid economy models impact scheduling algorithms 
investigate details impact techniques reduce cost computing schedule particularly task space reduction techniques nws forecast caching 
perform experiments larger testbeds applications 
expect experiments possible ectively compare different heuristics assigning tasks hosts 
software standpoint improvements current implementation apst 
allow apst daemon apst client reside di erent le systems 
allow daemon multiple users di erent applications 
multiple applications require nding way scheduling algorithms ensure degree fairness users compromising cient storage computation resources 
motivates development better long range forecasting techniques part nws authors collaborating nws team purpose 
components globus toolkit need integrated apst mds 
develop implementations apst actuator grid softwares ninf legion 
idea section iv push threads implementation actuator increased eciency 
grid services available ubiquitous plan deploy large scale parameter sweep simulations production mode grid resources 
simulations executed scale enable users achieve new disciplinary results 
authors reviewers insightful comments tokyo institute technology providing access computational resources team coping computer scientists members apples group comments help experiments 
appendix appendix task host selection heuristics general algorithm heuristics introduced section ii follows ct denotes completion time tasks schedule foreach task schedule foreach host compute ct ct task host foreach compute metric ct ct foreach choose best metric compute minimum ct schedule task host de ning function meaning best algorithm entirely de nes heuristic 
list de nitions heuristics 
minmin minimum ct best de ned minimum 
minmin minimum ct best de ned maximum 
su erage di erence second minimum ct minimum ct di erence called su erage value 
best de ned maximum 
xsu erage task site computes minimum completion times task hosts site 
call minimum site level completion time 
task returns di erence second minimum minimum site level completion time 
call di erence site level su erage value 
best de ned maximum 
berman wolski schopf shao :10.1.1.40.5011
application level scheduling distributed heterogeneous networks 
proc 
supercomputing pittsburgh 
foster kesselman :10.1.1.25.8254
globus metacomputing infrastructure toolkit 
international journal supercomputer applications 
casanova dongarra 
netsolve network server solving computational science problems 
international journal supercomputer applications high performance computing 
wolski :10.1.1.46.3287
dynamically forecasting network performance network weather service 
th high performance distributed computing conference pages august 
ian foster carl kesselman editors 
grid blueprint new computing infrastructure 
morgan kaufmann publishers san francisco usa 
www org 
stiles 
monte carlo simulation transmitter release general simulator cellular physiological processes 
computational neuroscience pages 
abramson cope mckenzie 
modeling pollution parallel distributed computing platforms 
proceedings parle pages 
livny 
harnessing capacity computational grids high energy physics 
conference computing high energy nuclear physics 
nelson rogers 
egs code system 
technical report slac stanford linear accelerator center 

aires users guide manual version 
technical report gap auger project 
ramshaw rourke 
computer program dimensional uid ows chemical reactions fuel 
technical report la ms los alamos national laboratory 
rogers 
comparison implicit schemes incompressible navier stokes equations arti cial compressibility 
aiaa journal oct 
spring wolski 
application level scheduling gene sequence library comparison 
proceedings acm international conference supercomputing july 
berman 
grid blueprint new computing infrastructure chapter 
morgan kaufmann publishers 
edited ian foster carl kesselman 
abramson giddy foster :10.1.1.42.8707:10.1.1.42.8707
high performance parametric modeling nimrod killer application global grid proceedings international parallel distributed processing symposium may 
appear 
raman livny 
high throughput monte carlo 
proceedings ot ninth siam conference parallel processing scienti computing march 
wolski spring su 
running computational grid 
proceedings supercomputing november 
grimshaw ferrari humphrey 
wide area computing resource sharing large scale 
ieee computer volume may 
page 
litzkow livny mutka 
condor hunter idle workstations 
proc 
th international conference distributed computing systems pages 
department computer science university madison june 
sato matsuoka 
ninf network information library globally high performance computing 
proc 
parallel object oriented methods applications santa fe pages february 

remote computational system 
parallel computing 
foster kesselman tuecke 
gass data movement access service wide area computing systems 
proceedings workshop parallel distributed systems may 
plank beck moore wolski 
internet backplane protocol storage network 
proceedings network storage symposium internet 
shao wolski 
ective network views promote distributed application performance 
proceedings international conference parallel distributed processing techniques applications 
lowekamp miller sutherland gross steenkiste 
resource query interface network aware applications 
proceedings th ieee high performance distributed computing july 
casanova berman 
heuristics scheduling parameter sweep applications grid environments 
proceedings th heterogeneous computing workshop hcw pages may 
hagerup 
allocating independent tasks parallel processors experimental study 
journal parallel distributed computing 

scheduling theory algorithms systems 
prentice hall englewood cli nj 
maheswaran ali siegel hensgen freund 
dynamic matching scheduling class independent tasks heterogeneous computing systems 
th heterogeneous computing workshop hcw apr 
clark 
gantt chart 
pitman sons london rd edition 
ibarra kim 
heuristic algorithms scheduling independent tasks processors 
journal acm apr 
berman wolski 
apples project status report 
proc 
th nec research symposium berlin germany may 
apples ucsd edu 
parker miller hansen johnson 
integrated problem solving environment computational steering system 
proceedings st hawaii international conference system sciences hicss vol 
vii pages january 
wolski spring hayes 
predicting cpu availability time shared unix systems computational grid 
proceedings th ieee international symposium high performance distributed computing hpdc aug 
czajkowski foster karonis kesselman martin smith tuecke 
resource management architecture metacomputing systems 
proceedings ipps spdp workshop job scheduling strategies parallel processing 
majumdar 
parallel performance study photon transport code shared distributed distributed shared memory architectures 
th parallel distributed processing symposium ipdps pages may 
stiles van 
miniature plate current rise times modeled passive di sion form synaptic 
proc 
natl 
acad 
sci 
volume pages 
tanaka sato amd 
resource management globus wide area cluster computing 
ieee international workshop cluster computing pages 
www titech ac jp cluster team 
braun siegel beck maheswaran robertson yao hensgen freund 
comparison study static mapping heuristics class heterogeneous computing systems 
proceedings th heterogeneous computing workshop hcw pages apr 
mitzenmacher 
useful old information 
proceedings th acm symposium principles distributed computing pages 

