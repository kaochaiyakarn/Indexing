high rate vector quantization detection gupta alfred hero iii submitted ieee transactions information theory sep revised nov final submission mar high rate quantization various detection reconstruction loss criteria 
new distortion measure introduced accounts global loss best attainable binary hypothesis testing performance 
distortion criterion related area receiver operating characteristic roc curve 
speci cally motivated sanov theorem de ne performance curve trajectory pair optimal asymptotic type type ii error rates powerful neyman pearson test hypotheses 
distortion measure de ned di erence area curve auc optimal pre encoded hypothesis test auc optimal post encoded hypothesis test 
compared previously introduced distortion measures decision making distortion measure advantage detection thresholds priors hypotheses generally dicult specify code design process 
high resolution type analysis applied characterize point density inertial pro le associated optimal high rate vector quantizer 
analysis applies restricted class high rate quantizers bounded cells vanishing volumes 
optimal point density specify algorithm allocates nest resolution regions gradient pre encoded likelihood ratio greatest magnitude 
area curve auc binary hypothesis testing cherno information compression discrimination error exponents receiver operating characteristic roc prof alfred hero iii room dept eecs beal avenue ann arbor mi tel 
fax email hero eecs umich edu applications source transmitted sensor user decisions source received data 
example imaging radar video camera transmit information user interested likelihood presence particular target object sensor eld view 
application essential reduce transmitted data rates encoding source prior transmission cost introducing small amount distortion decoder 
common distortion measure mean square error mse forms basis vast majority lossy compression algorithms today :10.1.1.116.3824
mse norm distortion incurred reconstructing source encoded values 
long recognized mse pertinent distortion measure interested ect compression decision making performance 
di erent distortion measures previously proposed assessing compression algorithms relative detection classi cation decision objectives 
contributions apply variant zador gersho method asymptotic high rate analysis cell multi dimensional quantizers incorporating kullback liebler kl type detection criterion weintroduce new design criterion type closely related area receiver operating characteristic roc curve 
new detection criterion area curve auc specifying optimal type type ii error exponents speci ed sanov theorem asymptotic large sample size false alarm probabilities 
compare auc criterion detection criteria including information discrimination exponent stein lemma cherno information exponent cherno bound 
criteria high resolution analysis yields expressions optimal point density encoder minimizes information losses similarly constrained quantizers xed rate 
auc optimal density lbg algorithm show obtain nite rate vector quantizers improved rate distortion terms auc characteristics relative quantizer designs 
distortion measure probability decision error minimum distortion optimal quantizer quantize minimal sucient statistic detection likelihood ratio 
call quantizer log likelihood ratio llr quantizer 
minimal sucient statistic typically non linear non invertible function source induced source domain quantization cells detection optimal quantizer may convex bounded cells may zero nite volumes 
general high rate characterization source domain cells quantizer dicult strongly dependent underlying probability densities 
example cases distribution llr discrete valued nite 
cases llr optimal nite rate encoder incurring zero loss detection performance higher rate quantization pointless 
analysis llr quantizers certainly worthwhile focus restricted class quantizers whichwe call small cell quantizers 
small cell quantizers property cells bounded rate increases 
quantizers source reconstructed distortion detection hypothesis number cells goes nity condition rarely satis ed llr quantizers 
furthermore conjecture high rate small cell assumption restrictive mixed objectives consisting linear combination mse distortion distortion measures considered 
show optimal point densities high rate small cell quantizers related important functions called fisher covariation pro le discriminability 
optimal point densities lloyd type compression algorithm proposed congruent cell hypothesis numerical comparisons performed illustrative examples 
general characterization contrasted mse optimal minimum mse quantizers detection optimal quantizers allocate ner resolution regions gradient likelihood ratio large magnitude 
background useful place contributions context previous 
quantization source coding studied decades rich history traced 
early research asymptotic high rate quantization reported zador gersho 
na derived formula asymptotic high rate mse vector quantizer terms functions characterize quantizer known point density inertial pro le 
functions describe quantizer asymptotic distribution points cell sizes respectively 
extend results distortion measures incorporate information discrimination penalties poor post quantization detection performance 
problem optimal quantization hypothesis testing analyzed various quantization schemes various distortion criteria 
considered quantization ecacy distortion measure testing composite hypotheses versus parameterized density scalar parameter 
poor thomas investigated quantization induced loss various ali distances densities characterizing simple hypotheses 
poor proposed generalized divergence distortion measure studied asymptotic high rate quantization ects measure 
seen loss kullback leibler distance due quantization functional quantity called discriminability plays central role 
considered de ection criterion similar signal noise ratio snr simple hypotheses 
shown maximization de ection criterion achieved transform coder scalar likelihood ratio 
tsitsiklis explores properties likelihood ratio quantizers investigates optimality respect divergence measures 
motivated cherno theorem bounds exponential error rates neyman pearson np test proposed loss alpha entropy called cherno distance distortion measure scalar quantizers 
asymptotically optimal functions derived high resolution analysis 
jain proposed bounds cherno distances distortion measure quantization context composite hypotheses 
flynn gray consider mixed distortion combining estimation probability detection correlated observations distributed sensing environments 
achievable rate distortion regions obtained case sensors extend lossless source coding analysis slepian wolf lossy source coding 
authors non asymptotic quantizer design optimum detection performance iterative maximization cherno distance 
distributed hypothesis testing problem quantized observations directly addressed longo gray iterative algorithm optimal scalar quantization derived loss bhattacharyya distance adopted distortion measure 
gray introduced method quantization classi cation mixed distortion measure de ned linear combination mse bayes risk 
iterative encoding algorithm minimizes measure 
worth mentioning weighted mse distortion metric introduced gardner rao studied linder etal better account perceptual distortion 
main di erence gardner rao weighted mse metric measures consider measures speci cally designed capture loss due quantization 
high rate results obtained weighted mse distortion impose condition positive de niteness sensitivity matrix mse norm condition pp 
high rate expressions bear similarity asymptotic expressions 
expressions weighting matrix rank de cient function likelihood ratio 
avoid positive de niteness condition assumed imposing aforementioned small cell restriction 
major di erence approach detection previous approaches tackle problem global optimization roc curve just optimization point roc curve 
auc di erence cherno information considered symmetric functionals hypothesized source densities furthermore optimal encoder arising minimizing auc di erence depend level signi cance decision thresholds test 
example divergence criteria adopted indexed speci es threshold level signi cance particular point roc curve 
likewise mixed distortion criterion depends bayes risk parameterized priors hypotheses specify point roc curve 
high resolution analysis follows lines approach taken mse loss function 
detection problem turns optimal high rate quantizer depends matrix generalization inertial pro le called covariation pro le characterizes cell shapes 
role covariation pro le expressions high rate similar normalized moment inertia de ned high rate analysis weighted mse distortion li etal 
framework permits lucid analysis merits various quantizers detection loss point densities covariation pro les 
outline follows 
brie review elements quantization general tasks discuss information discrimination criteria including cherno information auc section 
section perform asymptotic high rate analysis criteria 
section obtain optimal point densities various criteria 
examples section 
vector quantization dimensional real valued source ir dimensional quantizer consists codebook set cells partition bounded domain subset ir quantizer called scalar quantizer called vector quantizer 
codebook point lies cell quantizer operator written vector quantizer denote volume th cell 
speci point density de ned function normalized density non negative integral equals 
integrated region gives approximate fraction codebook points contained 
de ne diameter function quantizer sup scalar speci inertial pro le function note scaling function contains partial information shapes cells quantizer 
information provided matrix valued function call speci covariation pro le easily shown ellipsoidal cell form symmetric positive de nite unit sphere ir function depend size parameter scale invariant 
furthermore spherical cells scaled identity matrix 
restrict treatment product quantizers independent identically distributed samples dimensional source 
restriction allows average mse error exponents determine mse detection optimal dimensional component quantizers applied sample 
restricted framework applies scenarios repeated temporal measurements snapshots dimensional source single sensor single snapshot network spatially distributed sensors measuring dimensional source 
case framework evaluate average loss detection estimation performance arising restriction product quantizers 
details examples reader referred 
distortion measures sample probability density function 
class cell product quantizers ir de ned realization cell quantizer ir quality product quantizer measured average loss function called average distortion speci ed particular task performed compressed data 
task optimal reconstruction source appropriate mean squared reconstruction error mse mse def mse measure source estimation error call cell quantizer minimizes mse mse optimal cell quantizer 
task decide source distributions appropriate combination probability false alarm type error probability type ii error optimal detector vs operating quantized data 
composite hypotheses easily handled marginalization manner similar focus case simple hypotheses 
di erent distortion measures optimal post quantization detection 
measures optimal post compression detector likelihood ratio test lrt threshold chosen satisfy false alarm constraint re ect particular pair priors attain minimax detection performance 
comments comparing mse optimal detection optimal quantizers order 
distortion function mse optimal quantizer typically depends cell partition domain de nition codewords cell centers centroids strictly decreasing function rate quantizer increasing number cells quantizer decreases mse 
probability error detection optimal quantizer depends cell partition cardinality codeword set may strictly decrease detection optimal quantizer binary partition source space ir xed lrt threshold 
error probabilities false alarm constrained natural criterion consider probability lrt threshold selected meet prespeci ed false alarm constraint 
assuming prior option consider minimum average probability error false alarm probabilities lrt operating compressed data lrt threshold 
unknown minimax post compression probabilityof error adopted min achieved lrt minimax threshold minimizing solution 
performance described receiver operating characteristic roc parametric form ir probability detection detection criteria arises evaluating roc particular point respectively coordinate axis 
disadvantage aforementioned detection probability criteria local relevant compression detection performance single lrt threshold auc criterion discussed global independent alternative accounts entire range attainable false alarm probabilities mp lrt 
reconstruction detection performance quantizer interest gray proposed mixed criterion average distortion criteria minimized detection optimal mse optimal quantizers respectively 
weighting factor trade detection performance estimation performance quantizer 
distortion error exponents lrt denote false alarm probabilities lrt operating directly data 
equivalent direct parameterization pre quantization roc curve known power test 
speci ed level false alarm powerful mp pre quantization test level hypotheses lrt log single sample log likelihood ratio threshold set probability false alarm equal require randomization distribution lrt statistic discrete 
likewise denote false alarm amd probabilities lrt operating output ofan cell product quantizer mp post quantization test level lrt log probability mass functions output cell component quantizer cells 
large sample size performance mp lrt completely characterized set error exponents related kullback leibler kl divergence called relative 
kl divergence discrete sources log continuous sources densities kl divergence log stein lemma gives large asymptotic expression probability lrt arbitrary false alarm level lim wehave large approximation intrinsic loss probability performance due quantization expressed terms loss incurred discrimination appearing stein approximation def monotonically related loss ratio incurred probabilities due quantization 
stein approximation probability provides information tradeo false alarm probability 
sanov theorem provides information 
denote respective probabilities 
sanov theorem gives large function lrt threshold tilted density de ned tilt parameter de ned implicitly terms log note stein approximation special case sanov approximation 
similarly construction discrimination loss 
de ned sanov approximation allows quantify ect quantization roc curve ir considering di erence pre quantization error exponent curve post quantization error exponent curve discrete tilted mass probabilities priors consider large approximation average probability error lrt threshold associated tilt parameter best achievable attained equalizes error exponents sec 

equalizer property minimax bayes test value attains minimax probability error performance 
denoting value common value error exponents called cherno information 
area curve detection criterion observations area roc curve de ned auc widely global measure comparison di erent experiments 
criterion long history signal detection theory see green swets 
provost fawcett call curve metric di erentiate metrics single point roc curve discussed section 
area roc curve applied mathematical psychology diagnostic medical imaging machine learning 
area equivalent average power powerful test uniform prior user false alarm constraint 
auc equivalent probability error mann whitney wilcoxon rank order test randomly selected instances vs 
large auc better auc maximized mp lrt 
curve metric completely independent threshold priors bayes costs user associate decision errors 
integral related equally probability error bounds barrett shapiro 
comparing quantizers detection tasks natural measure quantizer distortion loss area roc due quantization 
auc auc auc auc auc areas roc lrt sample lrt product quantized sample respectively 
purposes asymptotic high rate analysis quantizer distortion convenient deal error exponent curves associated roc see fig 

discussed section closely related roc curves large 
de ne shorthand sanov error exponents pre quantized post quantized data respectively cell product quantizer large pre quantization roc curve parameterized error exponent curve whichwe write direct form function 
similarly write post quantization error exponent 
analogously de ne area error exponent curve simply denoted area curve auc auc auc maximized implementing mp lrt 
auc threshold independent attributes curve metric justify global distortion measure quantizer detection performance 
motivates new mixed detection estimation metric samples product quantizers mse 
auc mse mean square distortion constituent quantizer single sample similarly 
auc single sample loss auc 
auc auc auc due implementing product quantizer asymptotic high rate analysis asymptotic high rate quantization analysis commonly obtain interesting insights behavior quantizers having small cells whichwe call small cell quantizers 
bennet integral central analysis 
commonly technique asymptotic analysis sequence approach 
idea sequence approach consider sequence quantizers 
quantizer sequence cells associated speci point density speci inertial pro le speci covariation pro le diameter function 
assuming rst sequences functions converge functions sequence diameter functions converges zero limiting behavior quantizer sequence determined 
analyses suchas rigorous measure theoretic applications sequence approach 
bene cial outcome strategy assumptions regarding convergence sequences 
takes elementary non measure theoretic approach assumptions necessary 
section assumed conditions regarding sequence convergence listed 
additionally assume densities compact support twice continuously di erentiable open set probability bounded away zero support 
assumptions preclude gaussian densities include gaussian examples assume densities truncated satisfy assumptions 
log likelihood ratio quantizers performance mp lrt una ected processing observations long processing produces sucient statistic 
example deciding hypothesized source densities exists sucient statistic minimal sucient statistic log discrete valued sucient statistic equivalent quantizer 
gupta called sucient quantizer distortion equal zero relative previously de ned detection metrics 
sucient quantizers rarely exist practical problems reasonable quantize sucient statistic log likelihood ratio 
log likelihood ratio quantizer llr quantizer scalar quantizer applied log likelihood ratio de ned 
mp lrt threshold test roc curve mp lrt implemented level llr quantization roc curve meets roc curve exactly false alarm points 
roc continuous large loss detection performance goes zero entire range false alarm 
hand vector valued data ir dimensional cells induced level llr quantizer level sets log likelihood ratio convex bounded 
example sources gaussian cells induced quantizer unbounded strips slope leading poor mse performance 
mixed objective attain compromise mse detection distortion quantizer enforce small cell quantizer number cells increases 
alternatively sequence approach enforce small cell constraint 
stein exponent loss rst consider ect quantization type ii error arbitrarily small type error stein exponent equal discrimination loss discrimination incurred quantization th product quantizer sequence de ned 
quantized source 
appendix sequence approach show small cell quantizer cells lim tr whichwe call fisher covariation pro le 
adopt nomenclature tr fisher information matrix associated estimating shift parameter density de ned respect measure expression section derive discrimination optimal quantizers minimize loss stein error exponent 
sanov exponent loss consider ect quantization asymptotic high rate type type ii errors sanov exponents 
losses incurred quantization th product quantizer sequence de ned 

tilted quantized de ned 
appendix obtain lim lim log log optimal small cell quantizers results previous section obtain asymptotic expressions optimal point densities minimizing loss error exponents 
classical mse high rate quantization problem determination optimal cell shapes dicult open problem 
optimal cells high rate mse quantizers conjectured congruent minimum moment inertia cells 
small cell quantization detection problem determination optimal cell shape appears dicult open problem 
obtain qualitative characterizations optimal cell shapes attributes fisher covariation pro le 
de ne sanov optimal quantizer quantizer minimizes loss type ii sanov error exponent xed value determined satisfy type sanov error exponent false alarm constraint 
discrimination optimal quantizers discrimination optimal quantizers minimize loss error exponent stein lemma equal discrimination sources quantization 
discrimination optimal quantizer sanov optimal quantizer designed operating point 
optimize quantizer respect asymptotic discrimination loss necessary jointly optimize functions point density covariation pro le 
discrimination optimal point density obtained calculus variations holder inequality manner analogous discrimination loss optimal point density depends covariation pro le de ned 
quantizer cells congruent covariation pro le constant independent 
addition cells minimum moment inertia point density equation call function discriminability function equals zero hypotheses densities identical zero th rst order derivatives 
ellipsoidal cells cover ir overlap partition ir large analogy spherical cell approximation lattice quantizers plausible quantizer cells close ellipsoidal 
studying ellipsoidal quantizer cells yields important insights provide bound high rate distortion 
accordingly assume neighborhood point cell 
eigendecomposition positive eigenvalues corresponding orthonormal eigenvectors 
fisher covariation pro le nite upper bound eigenvalues upper bound restricts minimum diameter cell positive nondegenerate 
minimum matrices satisfying max achieved minimum eigenvalue corresponding minimizing eigenvector parallel 
case optimal fisher covariation pro le conclude cell centered ellipsoid nondegenerate minor axis aligned direction normal vector log likelihood ratio surface 
large see implies ellipsoidal cells aligned level sets log likelihood ratio 
cherno optimal quantization cherno optimal quantizer sanov optimal quantizer designed operating point minimizes loss cherno information due quantization 
unfortunately asymptotic loss cherno information dicult determine pre quantization equalization condition post quantization equalization condition seldom satis ed identical equalizer solution see fig 
illustration 
asymptotic cherno loss involves complicated interaction pre quantization post quantization equalizer solutions 
exception permits simple determination asymptotic cherno information loss occurs case equalizer solutions identical 
happens equalizing asymptotic expression valid whichwe rewrite follows de ned def denote dependency explicitly writing 

loss cherno information equal 
solution 
solving rarely performed closed form may accomplished numerical root nding techniques di erence 
equivalent nding obvious equalization solution strategy nding solutions asymptotic cherno information rst nd pre quantized equalizing solution satis es solution 
solution 
imply required 
follow strategy gaussian example considered 
auc optimal quantization alternative dicult cherno optimal quantizer simpler auc optimal quantizer minimizes loss area sanov error exponent curve 
de ned 
de ne area post quantized error exponent curve 
de ne area area pre quantized error exponent curve obtain lim note resemblance 
essentially source density simply replaced 
may closed form expression integral expression easily evaluated numerically 
analogous discrimination optimal point density derived derive auc optimal point density resulting loss area curve auc optimal point congruent cell quantizer constructed analogously section completely characterized optimal point density case minimum moment inertia cells ellipsoidal cells previous subsection equally apply auc optimal quantizer 
optimal quantizers mixed objective functions simple extend high rate analysis mixed criteria 
particular equation indicates loss auc due quantization sequence point small cell quantizers converges zero rate rate obtained na mse sequential approach 
speci cally sample dimensional vectors marginal mse mse mse denote conditional mse quantizer respectively single sample 
letting priors hypotheses average mse mse mse mse results previous section mixed measure appropriate normalization satis es lim point density density optimal point density mixed objective simply auc optimal point density mse optimal point density 
illustrative examples section demonstrate concepts procedures described previous section illustrative examples 
careful reader note gaussian densities considered examples support satisfy conditions appendix 
excepting overload distortion order results apply approximately gaussian densities obtained truncating gaussian support large bounded region containing density mass scalar gaussian sources rst example consider scalar unit variance gaussian sources di erent means 
assume priors equal 
point density minimizing asymptotic mse loss formula substitutions log likelihood ratio fisher covariation pro le constant 
discrimination optimal auc optimal point densities equations respectively 
equations see discrimination optimal quantizer concentrate points density auc optimal quantizer concentrates points density 
shows sources function note takes maximum source densities cross 
auc optimal discrimination optimal mse optimal point densities plotted 
priors equal point density peaks maxima source densities 
constant discriminability function auc optimal discrimination optimal point densities maximized points maximized respectively 
figures performances scalar quantizers various optimal point densities compared 
quantizers obtained lbg algorithm known generalized lloyd algorithm applied relevant point densities 
essence approach follows mse optimal point density source density 
note invertible 
quantizer produced generalized lloyd algorithm mse optimal point density 
arbitrary point density 
generalized lloyd algorithm run source density resulting quantizer point density 
large quantizer dimensional minimum moment inertia polytope cells 
details see 
shows error exponent curves quantization auc optimal discrimination optimal mse optimal quantizers cells 
expected auc optimal quantizer performs best terms area underneath curve criterion 
interesting note error exponent curve discrimination optimal quantizer quite poor 
quantizer minimizes loss type ii error exponent sanov optimal quantizer designed operating point 
shows roc curves mp lrt observations quantization various optimal quantizers cells 
note formulas accurate number observations large auc optimal quantizer may may yield optimum roc curve 
example see auc optimal quantizer best performance 
estimation performance quantizers cells compared 
reconstruction mse quantizer plotted versus prior probability def 
mse optimal quantizer assumed knowledge priors 
expected mse optimal quantizer yields minimum reconstruction mse considered quantizers 
note extremely poor performance discrimination optimal quantizer 
recall discrimination optimal quantizer concentrates points underneath density discrimination optimal mse optimal quantizers 
discrimination optimal quantizer di ers signi cantly mse optimal quantizer 
see example shows point densities case 
equal variance gaussian sources cherno optimal quantizer easily obtained approach outlined section 
show solution post quantized equalization condition equivalently asymptotic version condition satis es pre quantized equalization condition 
note pre quantized tilted density gaussian form easily veri ed value solves pre quantized equalization condition 
furthermore log likelihood ratios linear fisher covariation pro le constant 
equation solved 
shows optimal point density cherno information auc optimal point density point densities maximized point source densities cross 
point density cherno optimal quantizer concentrated point 
pre post quantized error exponent curves plotted quantizers cells 
note intersection curves diagonal line gives corresponding cherno information 
cherno optimal curve lies region close intersection unit slope line yielding greater cherno information 
hand area auc optimal curve greater expected 
note cherno optimal quantizer optimized speci cally value 
analysis extended obtain cherno information optimal vector quantizers vector gaussian sources matrices 
cases wemust restrict attention quantizers point densities covariation pro les symmetric mean tilted density 
example restricted polar quantizers shape gain quantizers satisfy constraint 
dimensional uncorrelated gaussian sources consider dimensional gaussian sources identity covariance matrices 
scalar gaussian example discriminability function constant dimensional gaussian sources matrices 
discrimination optimal auc optimal point densities equations respectively 
addition vector quantizers considered previous example cell optimal scalar llr quantizer auc criterion whichwe call auc optimal llr scalar quantizer auc optimal mixed vector quantizer implemented applying lbg algorithm point density 
shows contours source densities 
figures congruent cell vq optimal auc discrimination estimation cells shown 
quantizers obtained lbg algorithm 
similar dimensional case auc optimal quantizer cells concentrated source densities quantizer concentrates cells underneath density mse optimal quantizer cells dense underneath peaks densities 
hypothesis testing performance cell quantizers figures compared 
similar scalar gaussian example auc optimal quantizer performs best discrimination optimal quantizer yields largest discrimination quantized sources performs poorly average 
shows optimal quantizer cells mixed estimation detection objective function 
quantizer concentrates points source density peaks auc optimal quantizer underneath peaks mse optimal quantizer 
blowup shows dominance detection performance auc optimal llr scalar quantizer auc optimal vector quantizer auc optimal mixed vq mse optimal vector quantizer discrimination optimal vector quantizer respective order 
expected auc optimal llr quantizer outperforms rest terms detection performance virtually attaining optimal performance blow region shown 
gap shown auc optimal llr quantizer auc optimal vector quantizer small price paid auc optimal vector quantizer order attain improved mse performance shown 
wehave developed asymptotic theory quantization various measures detection performance sanov error exponents binary hypothesis testing 
theory applies large number observations large number quantization cells small cell assumption asymptotic large loss error exponent called discrimination resembles bennet integral formula reconstruction mse 
optimal small cell quantizer point densities minimize loss various functions sanov exponents including discrimination cherno information area error exponent curve auc derived 
numerical examples various optimal quantizers types scalar dimensional sources 
fisher covariation pro le signi cant uence placement codebook points quantizers optimal binary hypothesis testing 
think worthwhile avenues extending results mention 
area applied asymptotic results design optimum detector geometries emission tomography 
results limited xed rate quantizers variable rate high resolution analysis performed distortion criteria manner similar li etal analysis perceptual distortion measure gardner rao 
derivations high rate expressions follow classical relatively informal taylor series approach useful re ne extend results rigorous measure theoretic approaches described gray 
investigation loss detection performance due restrictive small cell condition worthwhile 
accomplished comparing high rate performance quantizers operate directly log likelihood ratio llr high rate small cell quantizers derived 
appendix derivation asymptotic discrimination losses asymptotic loss discrimination sources derive asymptotic loss discrimination follow sequence approach 
assumptions required necessary analysis 
consider sequence quantizers th quantizer contains cells codebook points 
discrimination quantization written terms cells th quantizer discrimination quantization th quantizer written goal maximize discrimination quantization refer loss discrimination distortion 
known discrimination increase processing quantization 
distortion nonnegative 
distortion resulting th quantizer note independent codebook lose assuming codebook points centroids cells 
volume th cell th quantizer 
note implies de ne sequences necessary analyzing asymptotic behavior quantizer sequence 

sequence diameter functions 

sequence speci inertial pro le functions 

sequence speci covariation pro le functions 
write 
sequence speci point density functions essence sequence approach conditions converges uniformly zero converges uniformly function speci inertial pro le uniformly bounded converges uniformly full rank matrix function covariation pro le 
facilitate analysis de ne simplifying notation 
density functions evaluated codebook point denoted similarly gradients hessians evaluated denoted log likelihood ratio evaluated matrix functions useful analysis 
fisher matrix function de ned outer product log likelihood ratio gradient matrix function keeping convention set forth de ne expand function series codebook points quantizer write similar expansion done shown terms explained follows 
de nition diameter function wehave wehave uniformly 
integer distortion th quantizer sum quantizer cells quantity call term single cell distortion cell bulk analysis required determine distortion involves studying single cell distortion whichwe section 
centroid condition wehave terms arise due fact matrix quadratic form ecting result 
algebra written 
simplify rst focus term 
integer conditions hold sequence converges zero write rewrite second term right hand side tr tr wenow turn attention term 
wehave tr combining yields tr tr de nitions wehave log taylor expansion log wehave tr tr tr tr get tr give tr tr having calculated single cell distortion total distortion obtained summing quantizer cells 
total distortion quantizer tr multiplying limit obtain 
asymptotic loss sanov exponents writing loss discrimination tilted source source due quantization quantizer log log keeping notational convention de ne de ne write expanding series get representation straightforwardly shown hessian tilted centroid assumption write taylor expansion obtain multiplying formulas yields get shall nd formulas useful tr tr write tr tr note written terms write tr tr tr tr tr taylor expansion log log write see term small note taylor expansions algebra second equality follows 
easily seen tr tr tr tr tr tr tr tr tr tr tr tr tr tr note lim gives tr tr give tr tr tr passing limit obtain 
symmetry arguments easily obtained 
gersho gray vector quantization signal compression kluwer boston ma 
gray quantization ieee trans 
inform 
theory vol 
pp 
oct 
optimum quantization signal detection ieee trans 
communications vol 
com pp 
may 
poor thomas applications ali distance measures design generalized quantizers ieee trans 
communications vol 
com pp 
sep 
poor approximation statistical divergence quantized data proc 
ieee conf 
decision control san antonio tx dec 
poor fine quantization signal detection estimation part ieee trans 
inform 
theory vol 
pp 
sep 
asymptotically optimal quantizers detection data ieee trans 
inform 
theory vol 
pp 
mar 
optimum quantization detection ieee trans 
communications vol 
pp 
nov 
tsitsiklis extremal properties likelihood ratio quantizers ieee trans 
communications vol 
pp 
apr 
flynn gray encoding correlated observations ieee trans 
inform 
theory vol 
pp 
nov 
longo gray quantization decentralized hypothesis testing communication constraints ieee trans 
inform 
theory vol 
pp 
march 
gray combining image compression classi cation vector quantization ieee trans 
pattern anal 
machine intell vol 
pp 
may 
bayes risk weighted vector quantization posterior estimation image compression classi cation ieee trans 
image processing vol 
pp 
feb 
moulin optimal design transform coders image classi cation proc 
conf 
information sciences systems baltimore md march 
jain moulin miller ramchandran information theoretic bounds target recognition performance degraded image data published dec 
gray quantization classi cation density estimation proc 
ieee information theory workshop detection estimation classi cation imaging santa fe nm feb 
zador development evaluation procedures quantizing multivariate distributions phd thesis stanford university stanford ca 
gersho asymptotically optimal block quantization ieee trans 
inform 
theory vol 
pp 
july 
na bennet integral vector quantizers ieee trans 
inform 
theory vol 
pp 
july 
zamir feder lattice quantization noise ieee trans 
inform 
theory vol 
pp 
july 
yamada gray asymptotic performance block quantizers di erence distortion measures ieee trans 
inform 
theory vol 
pp 
january 
gardner rao theoretical analysis high rate vector quantization lpc parameters ieee trans 
speech audio processing vol 
pp 
september 
li gray asymptotic performance vector quantizers perceptual distortion measure ieee trans 
inform 
theory vol 
pp 
may 
linder zamir zeger high resolution source coding non di erence distortion measures multidimensional ieee trans 
inform 
theory vol 
pp 
march 
slepian wolf noiseless coding correlated information sources ieee trans 
inform 
theory vol 
pp 
july 
gupta quantization strategies low power communications phd thesis university michigan ann arbor mi 
lehmann testing statistical hypotheses wiley new york 
blahut principles practice information theory addison wesley 
cover thomas elements information theory wiley new york 
large deviation techniques decision simulation estimation wiley new york 
dembo large deviation techniques applications springer verlag 
van trees detection estimation modulation theory part wiley new york 
green swets signal detection theory psychophysics wiley 
provost fawcett robust classi cation imprecise environments machine learning journal vol 
pp 
march 
non parametric measure signal discriminability 
math 
statist 
psychol vol 
pp 

area ordinal dominance graph area receiver operating characteristic graph journal mathematical psychology vol 
pp 

metz basic principles roc analysis seminars nuclear medicine vol 
pp 

swets pickett evaluation diagnostic systems methods signal detection theory kluwer academic press 
bradley area roc curve evaluation machine learning algorithms pattern recognition vol 
pp 

hanley mcneil meaning area receiver operator characteristic roc curve radiology vol 
pp 

barrett clarkson objective assessment image quality 
iii 
roc metrics ideal observers likelihood generating functions opt 
soc 
am vol 
pp 
june 
shapiro bounds area roc curve opt 
soc 
am vol 
pp 
jan 
linde gray algorithm vector quantizer design ieee trans 
communications vol 
com pp 
jan 
data compression morgan kaufman 
moo asymptotic analysis lattice quantization phd thesis university michigan ann arbor mi 
results asymptotic performance quantizers ieee trans 
inform 
theory vol 
pp 
march 
wise multidimensional asymptotic quantization theory th power distortion measures ieee trans 
inform 
theory vol 
pp 
march 
horn johnson matrix analysis cambridge 
hero emission tomography compressed data proc 
asilomar conf 
signals systems computers paci grove ca nov 
downloadable 
biographies gupta gupta received degree university california berkeley ph degrees university michigan ann arbor respectively electrical engineering 
rockwell science center oaks california 
joined trw space electronics space technology redondo beach california 
interests adaptive signal processing communications detection estimation 
alfred hero iii alfred hero iii born boston ma 

received electrical engineering summa cum laude boston university ph princeton university electrical engineering 
princeton held fellowship engineering 
professor university michigan ann arbor appointments department electrical engineering computer science department biomedical engineering department statistics 
held visiting positions univeristy nice sophia antipolis france ecole normale sup erieure de lyon ecole nationale sup erieure des el paris scienti research labs ford motor michigan ecole nationale superieure des techniques ecole superieure paris lincoln laboratory 
research supported nih nsf afosr nsa aro onr darpa private industry areas estimation detection statistical communications bioinformatics signal processing image processing 
served associate editor ieee transactions information theory ieee transactions signal processing 
chairman statistical signal array processing technical committee conference board ieee signal processing society 
chairman publicity ieee international symposium information theory ann arbor mi general chairman ieee international conference acoustics speech signal processing detroit mi 
chair ieee information theory workshop detection estimation classi cation filtering santa fe nm ieee workshop higher order statistics israel 
chair workshop genomic signal processing statistics 
currently member signal processing theory methods technical committee vice president finance ieee signal processing society 
chair commission signals systems national commission international union radio science 
member review panel national research council 
alfred hero fellow institute electrical electronics engineers ieee beta pi american statistical association asa industrial applied mathematics siam national commission commission international union radio science received ieee signal processing society service award ieee signal processing society best award ieee third millenium medal 
appointed distinguished lecturer ieee signal processing society 
roc curves associated error exponent curves gaussian hypotheses 
log likelihood ratio quantizer dimensional gaussian sources matrices 
sanov approximations type type ii errors indexed quantization dimensional gaussian example 
type type ii error probabilities de ne cherno information minimax operating 
source densities dimensional gaussian example 
auc optimal discrimination optimal mse optimal point densities dimensional gaussian example 
curves quantization quantization auc optimal discrimination optimal mse optimal quantizers cells dimensional gaussian example 
auc optimal quantizer best performance average detection optimal quantizer yields largest value 
roc curves observations data quantized optimal discrimination optimal mse optimal quantizers cells dimensional gaussian example 
reconstruction mse auc optimal mse optimal quantizers cells onedimensional gaussian example 
optimal point densities roc area cherno information dimensional gaussian sources 
curves quantization quantization optimal cherno information optimal quantizers dimensional gaussian sources 
source densities dimensional uncorrelated gaussian example 
auc optimal cell vector quantizer twodimensional uncorrelated gaussian example 
discrimination optimal cell vector quantizer twodimensional uncorrelated gaussian example 
mse optimal cell vector quantizer twodimensional uncorrelated gaussian example 
optimal cell vector quantizer mixed objective function dimensional uncorrelated gaussian example 
curves quantization quantization optimal discrimination optimal mse optimal vector quantizers cells dimensional uncorrelated gaussian example 
auc optimal quantizer best performance average detection optimal quantizer yields largest value 
curves cell vector quantizers dimensional uncorrelated gaussian example 
probability false alarm probability detection roc curves gaussian hypotheses observations quantization quantized cell uniform scalar quantizer vs gaussian hypotheses quantization quantized cell uniform scalar quantizer type ii error probabilities type ii error probabilities vs mm mm source densities optimal point densities auc optimal discrimination optimal mse optimal vs curves optimal quantizers quantization auc optimal quantizer discrimination optimal quantizer mse optimal quantizer roc curves optimal quantizers quantization auc optimal quantizer discrimination optimal quantizer mse optimal quantizer pr mse mse optimal quantizers auc optimal quantizer discrimination optimal quantizer mse optimal quantizer auc optimal chernoff info optimal point densities auc optimal chernoff info optimal vs auc optimal chernoff info optimal quantizers quantization auc optimal quantizer chernoff info optimal quantizer source densities auc optimal vq discrimination optimal vq mse optimal vq mixed vq vs curves optimal vq quantization auc optimal vq discrimination optimal vq mse optimal vq vs curves optimal vq quantization auc optimal vq discrimination optimal vq mse optimal vq auc optimal llr vq optimal mixed vq 
