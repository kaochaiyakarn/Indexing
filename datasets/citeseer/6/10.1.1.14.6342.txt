statistical approach anaphora resolution ge john hale eugene charniak dept computer science brown university nge th ec cs 
brown edu presents algorithm identi fying pronominal anaphora experi ments algorithm 
rate multiple anaphora resolution factors statistical framework specifically dis tance pronoun proposed antecedent gender number proposed antecedent governing head informa tion noun phrase repetition 
combine single probability enables identify referent 
experiment shows relative contribution source information demonstrates success rate sources combined 
second experiment investigates method learning gender number information 
experiments il accuracy method note information added pronoun resolution method achieves accuracy 
statistical method determin ing pronoun anaphora 
program differs earlier complete lack hand crafting relying small corpus penn wall street journal tree bank text marcus marked information 
sections describe program proba model implementation performance 
second half describes method portions tioned program learn automatically typi cal gender english words information pronoun resolution program 
particular scheme infers gender referent gender pronouns refer selects referents pro noun anaphora program 
typ ical results rigorous results blind evaluation output 
probabilistic model factors syntactic se mantic pronoun resolution sys tem relies 
detailed study factors anaphora resolution 
dis training features derive probability equations 
piece useful information con sider distance pronoun candidate antecedent 
obviously greater distance lower probability 
secondly look syntactic situation pronoun finds 
studied constraints involving reflexive pronouns 
classical approach resolving pronouns text takes syntactic fac tors consideration hobbs 
algorithm searches parse tree left right breadth fashion obeys major reflexive pronoun constraints giv ing preference antecedents closer pronoun 
resolving inter sentential pronouns algorithm searches previous sentence left right breadth der 
implements observed preference subject position antecedents 
actual words proposed noun phrase antecedent give information regarding gender number pro posed referent 
example marie giraud carries historical sig women france 
enabled buy jam cocoa war 
helpful recognize marie probably female re 
words proposed antecedent want find prob ability referent pronoun question 
collect probabilities training data marked links 
words antecedent test number agreement 
gener ally singular pronoun refer plural noun phrase resolving pro noun plural candidates ruled 
singular noun phrase ref erent plural pronoun illustrated example think tell need time take street says general manager ol network 
useful note interaction tween head constituent pronoun antecedent 
example japanese tele vision picture tubes japan ble tv sets malaysia indonesia 
compare degree possible candidate antecedent japanese television picture tubes japan tv sets malaysia example serve direct object export 
proba bilities give way implement selectional restriction 
canonical example selectional restriction verb eat se food direct object 
case export restriction 
nev give guidance candidates probable 
factor consider referents men tion count 
noun phrases mentioned repeatedly preferred 
training corpus marked number times referent mentioned point story 
concerned probability proposed antecedent correct repeated certain number times 
effect probability information identify topic segment belief topic referred pronoun 
idea similar centering approach brennan continued topic highest ranked candidate 
possible sources tion arrive equation denotes function pronouns antecedents alp random variable denoting referent pronoun proposed antecedent 
conditioning events head constituent list candidate antecedents considered type phrase proposed antecedent noun phrase study type head constituent sp describes syntactic structure appears distance antecedent number times referent mentioned 
note vector quantities entry corresponds possible antecedent 
viewed way regarded index vectors specifies value relevant particular choice antecedent 
equation decomposed pieces correspond factors statistically manageable 
decomposition bayes theorem certain independence assumptions discussed 
alp fir sp ala fir sp fir sp dim fir sp fir lla sp sp pch pc 
la oc tin sp 
pla 
sf cx ff lh plw equation simply application bayes rule 
denominator eliminated usual fashion resulting equation 
selec tively applying chain rule results equa tions 
equation term lla removed 
equation follows break component probability distributions 
equa tion independence sumptions particular choice antecedent candidates distance independent distances candidates distance non referents ignored ic structure st distance pronoun da independent number times referent mentioned 
sp sp la combine sp de vari able dit hobbs distance hobbs algorithm takes syntax dis tance account 
words antecedent depend parent constituent type words type parent ff la sp lh choice pronoun depends words antecedent pla sp pla treat index vector simply ath candidate list 
assume selection pronoun independent candidates antecedent 
pla plw vector need normal ize ff lh obtain probability element vector 
reason able assume antecedents independent words wo wo 
ff lh wil wdh wdh 
ff lh lt get probability candidate divide product lh oc lt lt lt lh lt arrive final equation comput ing probability proposed antecedent wo plw 
alm 
obtain dh running hobbs gorithm training data 
train ing corpus informa tion probability easily obtained 
building statistical parser penn tree bank various collected charniak lh lt 
avoid sparse data prob lem heads clustered behave lh 
probability computed basis clus ter 
corpus contains repetition information di rectly compute 
components equation estimated reason able fashion 
system computes product returns antecedent pronoun maximizes probability 
formally want program return antecedent function arg alp sp dh implementation small portion penn wall street journal tree bank training corpus 
data collect statistics detailed ha subsections 
hobbs algorithm hobbs algorithm assumptions syntactic trees operates satisfied tree bank trees form substrate algorithm 
hobbs algorithm depends ex parse tree node absent penn tree bank trees 
im plemented slightly modified version hobbs algorithm tree bank parse trees 
transform trees certain condi tions meet hobbs assumptions possible 
able duplicate exactly syntactic structures sumed hobbs 
trees proper form degree possible run hobbs algorithm repeatedly pronoun proposed experiment 
ith candidate regarded oc hobbs distance dh probability dh ila simply du ila correct antecedent hobbs distance correct antecedents denote number times observed training set 
gender statistics identified correct antecedents simple counting procedure compute wa wa correct antecedent pronoun note pronouns grouped gender pl antecedent multiple relevant words antecedent apply likelihood test designed dunning words candi date np 
limited data dunning test tells word informative call wi 
mention count statistics referents range mentioned mentioned times train hag examples 
computing proba group buckets rrt bucket num ber times mentioned 
ob serve position pronoun story influences mention count referent 
words nearer story pronoun occurs probable referent mentioned times 
measure position sentence number method compute probability antecedent rna alm ms omitted equations reduce notational load 
resolving pronouns collecting statistics training ex run program test data 
pronoun collect ex periment candidate antecedents proposed hobbs algorithm 
quite possible word appears test data program saw training data low probability 
case probability model dh lh alm 
percent correct standard deviation signifi cance level table cross validation incremental results simply prior probability pro noun 
parser project mentioned earlier obtain probability tj fi nally extract mention count number sociated candidate np obtain 
probabilities multiplied 
procedure repeated proposed np highest combined probability selected antecedent 
experiment algorithm modules 
collects statistics training corpus required equation uses probabil ities resolve pronouns test corpus 
data consists words sen tences contains pronouns singular 
corpus manually tagged indices referents repetition numbers 
result pre sented accuracy program finding antecedents various forms cases merely dummy subject cleft sentence example conventional unspecified referents example excluded computing precision example hard justify paying silly price jaguar bidding war start 
example raining 
performed way cross validation reserved corpus testing remaining training 
pre results shown line table 
interested finding relative importance probability factors equation pronoun tion 
ran program incre mentally time incorporating probability 
results shown table obtained cross validation 
column table contains values test ing statistical significance improve ment 
due relatively large differences tree bank parse trees hobbs trees hobbs implementation yield high accuracy perfect hobbs tree representations 
hobbs algorithm serves base scheme expect accuracy higher accurately transformed trees 
note simple model ignores syntax takes mentioned noun phrase referent performs quite bit worse correct 
indicates syntax play important role anaphora resolution 
see significant improvement word knowledge added program 
plw probability gives system informa tion gender 
con tribution factor quite significant ca seen table 
impact probability seen clearly experiment tested pro gram just hobbs distance gender formation training data 
pro gram thought having perfect gen der knowledge 
obtained suc cess rate 
success rate effect clear indication knowledge referent gender ity essential anaphora resolution 
hoped knowledge gov constituent gender large contribution 
surprise improvement 
partly selection restrictions cases 
head verbs general restrict selection np 
examples appear frequently wall street journal verbs selective associ ated probability strong rule erroneous candidates 
sparse data causes problem statistic 
consequently observe relatively small enhancement system 
mention information gives sys em idea story focus 
fre quently entity repeated topic story candidate 
results show case 
pronouns closely related topic center discourse 
np repetition simple way approximately identifying topic 
accurately topic seg ment identified higher success rate expect anaphora resolution system achieve 
unsupervised learning gender information importance gender information re previous experiments caused consider automatic methods estimating probability nouns occurring large cor pus english text inanimate line feminine things 
method described simply counting occurrences pronouns noun phrases employ method analysis text stream results referent pronoun pairs cf 
hatzivassiloglou mckeown application explicit indicators available stream 
simple methods finding referent pronoun pairs give appli cation salience statistic indicate confident predic tions method 
show results applying method word wall street journal cor pus different pronoun strate gies varying sophistication evaluate performance reliable gender indicators 
method simple mechanism harvesting kind gender information discourse fragments kim 
long time 
kim gender unknown seeing sentence second sentence known 
probability referent partic ular gender class just relative frequency referent referred pro noun part gender class 
probability referent ref gender class gc re gci refs gci el refs re considered gender classes masculine feminine mate indicated typical pro nouns 
variety pronouns indicate class plural pro pronoun gender class nouns reveal gender formation referent consequently aren useful way learn unsupervised manner 
order gather statistics gender referents corpus way identifying referents 
attempting lexical information referents gender consider strategies com pletely blind kind semantics 
naive pronoun strategies previous noun heuristic 
intuition pronouns closely follow refer ents heuristic simply keeps track noun seen submits noun refer ent pronouns 
strategy certainly simple minded noted earlier achieves accuracy 
system statistical parser see charniak simply tag ger 
apparent parser overkill control ensure part speech tags assigned words previ ous noun heuristic hobbs algorithm wish compare previous noun method 
fact part speech tags necessary indicating nouns pro nouns 
obviously superior strategy apply anaphora resolution strategy previous sections finding putative ref 
chose hobbs distance portion thereof 
mention probabilities alma unmarked text 
gender information gathered smaller hand marked text interested seeing unsupervised learning accomplish concerned inherit ing strong biases limited hand marked data 
second method finding pronoun noun occurrences simply parse text assume noun phrase hobbs distance antecedent 
pronoun resolution method cor pus result set pronoun referent pairs 
collating referent abstracting away gender classes pronouns individual pronouns relative fre referent referred pronouns gender class 
say gender class relative frequency highest gender class referent probably belongs 
syntax pronoun resolution strategy wrong time methods know discourse bound aries intentions real world knowledge 
know pat tern pronoun observe referent result supposed hypothesis pronoun pronoun strategy adopted order gather statistics result unidentified process 
decision ranking refer ents log likelihood ratio termed salience referent 
likelihood ratio adapted dunning page uses raw frequencies pronoun class cor pus null hypothesis pr gc pr ref gci equation 
salience re log making unrealistic simplifying assumption gender class com pletely independent classes likelihood function case just product classes probabil ities class power number observations class 
evaluation ran program words wall street journal text 
judge pro gram informally simply examining re sults determining program gender decisions correct occasionally looking text difficult cases 
shows noun phrases highest salience figures run hobbs algorithm 
tion show correct 
mistakes husband wife years 
return significance mistakes 
measure utility results ran pronoun anaphora program statistics added 
achieved accu racy rate 
small improve ment achieved data 
believe ways im prove accuracy learning method increase influence pronoun anaphora resolution 
attempted fully automatic di rect test accuracy pronoun meth ods gender determination 
devised objective test useful scoring subset referents names people 
particular assume noun phrase 
ms may confidently assigned gender classes respectively 
compute precision follows precision 
erl 
ms er ms varies referent types tokens 
precision score computed phrases containing target effect admitting ref erent different gender classes different observations 
word count salience woman president group reagan man president reagan government bank mother col north moody thatcher gm plan judge husband japan agency wife dollar standard poor father utility trump baker ibm maker years brazil spokesman simon daughter ford greenspan minister judge top noun phrases salience number precision scoring scheme syntactic hobbs algorithm noun method hobbs method 
things note results 
expect ready noted superior performance hobbs scheme noun hobbs performs bet ter determining gender 
secondly glance accuracy hobbs method disappointing slightly superior accuracy hobbs finding correct ref 
hoped statistics things considerably accurate 
fact statistics things consid accurate 
shows average accuracy function number referent 
seen significant improvement increased refer ent count 
reason average referents low counts referents obey zipf law mode distri bution counts 
accuracy mix relatively high accuracy referents counts greater rel low accuracy referents counts exactly 
previous literature pronoun anaphora ex summarize concentrate corpus anaphora research 
aone bennett ap proach automatically trainable anaphora resolution system 
japanese articles tagged discourse information training examples machine learning gorithm decision tree algo rithm quinlan 
train de cision tree anaphora antecedent pairs set feature vectors 
features lexical syntactic seman tic positional features 
machine learning resolver mlr trained ing decision trees ing referring multiple discontinuous report average success rate 
describes approach uses set factors constraints prefer ences 
constraints rule implausible preferences emphasize selec tion antecedent 
system entirely statistical consists various types rule knowledge syn tactic semantic domain discourse heuris tic 
statistical approach dis course module deter mine probability noun verb phrase center sentence 
system con tains domain knowledge including domain concepts specific list subjects verbs topic headings 
evaluation conducted paragraphs annotated computer sci ence text 
results show accuracy occurrences 
lappin report essen tially non statistical approach relies salience measures derived syntactic struc ture dynamic model attentional state 
system employs various constraints np pronoun non coreference sentence 
uses person number gender features ruling anaphoric dependence pro noun np 
algorithm cated mechanism assigning values salience parameters computing global salience values 
blind test conducted manual text containing pronoun occur algorithm successfully identified antecedent pronoun pro noun occurrences 
addition module contributes statistically measured preferences range factors algorithm considers improved performance 
research statistical method pronominal anaphora achieves accuracy 
main advantage method essential simplicity 
implementing hobbs referent ordering algorithm system knowledge imbedded tables giving various component probabilities probability model 
believe simplicity method translate comparative simplicity im prove method 
research described thought influences anaphora resolution statistical corre 
hope include 
indicated learning gender information growing arsenal learning techniques ap plied statistical problems 
consider high salience words learning program assigned incorrect gen der husband wife years 
sus pronoun assignment method able topic information complete method decided correctly 
suspect husband example decided correctly topic article woman mention husband article kept talking woman pronoun 
simple program got confused program better statistics 
topic research 
authors mark johnson members brown nlp group useful ideas nsf onr support nsf iri sbr onr 
aone scott william bennett 
evaluating automated manual ac anaphora resolution strategies pages 
springer 
susan brennan marilyn walker friedman carl pollard 

centering ap proach pronouns 
proc 
th annual meeting cl pages 
associa tion computational linguistics 
eugene charniak 

statistical parsing context free grammar word statis tics 
proceedings th national con ference artificial intelligence menlo park ca 
aaai press mit press 
ted dunning 

accurate methods statistics surprise coincidence 
com putational linguistics march 
vasileios hatzivassiloglou kathleen mckeown 

predicting semantic ori adjectives 
proc 
th annual meeting acl pages 
associa tion computational linguistics 
jerry hobbs 

pronoun resolution 
technical report city college new york 
shalom lappin herbert 

algorithm pronominal anaphora tion 
computational linguistics pages 
mitchell marcus beatrice santorini mary ann marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 


factors anaphora res things matter case study differ ent approaches 
proceedings cl ea cl workshop operational fac tors practical robust anaphora tion 
ross quinlan 

programs ma chine learning 
morgan kaufmann publish ers 
