proc 
th international conference automatic face gesture recognition fg 
washington dc 
may 
interacting steerable projected displays rick kjeldsen claudio pinhanez gopal pingali jacob hartman tony mark ibm watson research center river road hawthorne ny usa pinhanez ibm com computer vision combined steerable projector surface environment turned interactive interface having modify wire surface 
steerable projected displays offer rich opportunities pose new challenges interaction gesture recognition 
real time techniques recognizing touch point gestures steerable projected displays produced new device called displays projector 
demonstrate viability approach experiment involving hundreds users interacting projected interfaces 

displays today tethered special devices monitors 
projectors possible display surface static typically tied designated surface environment 
developed new device called displays projector ed projector uses computer controlled mirror steer projected display surface environment correcting distortion caused oblique projection 
ed projector surface display everyday objects enriched information having wire 
ability steer projected displays introduces challenge interacting naturally displays 
steerable displays steerable interfaces possible bring computer access user located user desires 
entire environment act output device invisible computer user natural gestures actions input 
lends dimension vision ubiquitous computing 
ed projector composed lcd projector computer controlled pan tilt mirror pan tilt zoom camera 
projector connected display output host computer controls mirror camera 
camera steered observe projected display 
shows prototypes ed projectors built shelf components rotating mirrors lighting steerable cameras lcd projectors 
projection systems augment reality demonstrated researchers different situations 
systems constrained fixed projector project information limited area environment 
projected images interactive vision system detect users hand gestures fig 
prototypes displays projector 
moving objects users body position 
document attempts interacting displays produced ed projector 
users interact projected displays touching hands 
hand gestures recognized computer vision system attached steerable camera ed projector 
gesture recognition poses new challenges context projected displays appearance user hand changes drastically moves projection projected light overwhelms inherent color surfaces 
fig 
steps followed user placing siggraph demo entrance panel touched start process color selected bucket containing selected color projected done button bucket touched picked user places highlighted pixels finger painting reveal full image button touched interaction done 
system camera 
experiment interaction projected displays designed experiment demonstrate test concept transforming ordinary surfaces interactive touch screens 
experiment engaged hundreds users augmented reality assembly task conducted emerging technologies area computer graphics conference siggraph 
assembly task individual contributes assembly object executing specific parts assembly process 
keeping theme entertainment venue chose assembled object picture multi colored sugar coated regarded pixel picture 
shows example portrait van gogh 
front experimental space table table lies flat transparent board coated double sided transparent stick tape 
board mounting canvas assembly hanging support pictures 
back walls space shelves unlabeled buckets containing different colors 
registered trademark mars 
bucket covered different color texture 
surfaces projection painter palette mounted wood board covered inch thick foam white fabric 
surrounding walls completed pictures giving users notion final goal assembly task 
user experience visitor arrives space sees image projected painter palette instruction touch shown fig 

visitor touches button system responds projecting arrow palette message inviting visitor come ed projector steered foam covered board images different colored ms projected invitation pick color see fig 

user select color place iteration simply touching desired color 
soon system detects user selecting color wants place projects message foam covered board asking user get certain number highlighted 
ed projector rotates mirror highlights bucket contains ms color 
displays message get number ms picked bucket bucket frontal face 
addition button word done image underlined pointing finger see fig 
displayed 
retrieving appropriate number inside bucket visitor touch done button communicate picking completed fig 

immediately afterward instruction go table projected bucket ed projector redirected board 
fig 
picture ed projector indicates precise location placed figs 
projecting image target locations canvas 
displays instructions place done button labeled 
user places communicates action touching button 
point user invited finger paint vision system tracks position user hand fills circles appropriate color vicinity fingertip interactively completing picture fig 

time user activity touching button right image fig 

system times seconds shows complete image user 

gesture recognition user input user interactions display detected single pan tilt zoom camera steered follow projected image 
vision system examines video stream user actions generates events application software 
camera located adjacent mirror assembly camera view user hand interacting display generally occluded occludes projected image situation apparent users assume quickly correct 
user interface composed individual interactive components widgets similar way current guis composed scroll bars buttons menus 
widget provides basic type interaction triggering event controlling value parameter 
widget need visible representation display 
just current interfaces task changes set active widgets changes 
insights design philosophy user interface see 
vision system attempt model user activity 
examines portions video stream image events indicate user interacted widget generates application event response 
implemented types widgets system button user touches tracking region location user pointing determined 
cases vision system determines user pointing 
buttons looks button touch motion trajectory pointing fingertip 
tracking passes fingertip position transfer function similar described obtain pleasing pointing dynamics translates coordinate system region 
pointing detection detecting user hand context ed projector presents challenges 
appearance user hand changes drastically moves projection 
techniques color appearance unusable 
similarly techniques background subtraction give unreliable results projected image completely overwhelm inherent color moving surface 
techniques gesture recognition systems projected displays 
appearance object change moves projected image create region changed pixels retains basic shape moving object see figs 

video frame subtracted frame noise removed computational morphology 
people reach touch point variety hand shapes invariably finger extends rest amount leading way 
assume fingertip provides accurate estimate user pointing 
fig 

camera view interaction bucket image difference data overlay search region square button active area circle fingertip template shown pointing location 
find fingertip shapes convolving fingertip template fig 
difference image matching function tuned gray level template determines desirability finding changed pixel location changed pixels black regions template penalized severely unchanged pixels white regions 
template match image assume user pointing 
fingertip template deliberately kept short match fingertips extend slightly neighbors match fingertips wider range angles 
result template matches points image 
resolve hypotheses fingertip furthest user 
approach supports tracking rate frames second mhz workstation image depending size search region size fingertip template determined expected size user hand 
button touch detection button touch event defined occur fingertip vicinity button travels away user point button returns user 
button touches detected examining hand trajectory specific patterns indicate type motion 
button configuration ambiguity touched button furthest user allowed generate event 
algorithm works interactions user asked touch button time 
importantly resists generating event user hand moves button way location 
algorithm fail user touches buttons retracting hand flies finger image touching button 
notice vision system built recognize touching button image button tends elicit user slightly different gesture pressing button 
address consequences difference 
calibration surface user interact display vision system requires knowledge location size user hand 
information inferred dynamically shape motion changed region keep implementation simple obtain calibration sizing rotating hand icon match image hand 
approach assumes user approach interaction area consistent location time 
practice assumption worked surfaces failed 
calibration show system location size buttons tracking regions 
search region identified surface order help system ignore extraneous movement image speed response see fig 

optimal recognition behavior varies surface surface depending requirements task 
example selection screen false positive button presses disruptive demo false negatives user press disruptive 
conversely buckets ms false negative rate naturally higher user pointing behavior consistent 
false positives disruptive demo false negative results problem worse 
parameters adjust inherent tradeoffs recognition system match desired characteristics 
case selection screen fig 
fingertip template 
system emphasize fingertip template match effect lowering false positive rate increasing false negative rate 
buckets place emphasis template match users tend point buttons wide range orientations 
ensure search region extends button user reaches ms trajectory fly button inside 
calibration information surface saved configuration file loaded time display switches surface 

experimental results days siggraph people went demo complete pictures composed 
camera video stream recorded tape users selections logged 
objective siggraph experiment large number subjects help determine main issues associated usage projected displays explored deeply controlled studies 
users confronting novel interaction paradigm shy giving instruction needed 
problem detected early second delay required move ed projector mirror adjust focus surfaces 
fastest transitions perceived long users system 
problem exacerbated lack familiarity application knowing surface environment display appear 
minimize perceived delay interaction changed user received information expect time consuming mirror movement 
instance user touched done button bucket see fig 
instruction go table immediately projected 
helped alleviate anxiety confusion frustration observed change delays long 
considering vision system projection system integrated time weeks preceding exhibition combined system worked remarkably 
sample consecutive users button touch events touching gestures false detections yielded correct detection touching gestures false negatives false positives shown table 
buckets excluded count performance exceeds 
buckets yielded high number errors reasons 
biggest problem picking bucket user partially completely occluded display head back 
success false positives false negatives entrance select board buckets board place board paint total buckets total table performance vision system users 
user motion situations triggered false positives button projected bucket 
false negative errors due fact system tuned detect straight forward touch mo tion user assumed 
example picking color users fly hand buttons press vertical motion readily visible camera 
tried wave hands buttons similar non touching actions 
problem particularly acute non standard interaction surfaces buckets 
assumption user interact occluded button held true interactions instance repeatedly violated 
picking ms bucket user walk table realize touched done button 
returning bucket occlude projection camera head back just arrived continued reach touch dark bucket 
credit high number false negatives finger painting reduced frame rate simultaneously tracking large area detecting touch events 
occasionally brief interval finger inside button fall video frames 
trying click button hard surface board soft foam board users applied pressure projected buttons button touch detected vision system common reaction try press pressure 
common reactions hand finger change touch motion wave action 
reduce excessive pressure users apply surfaces changed wording instruction press touch fig 

helped somewhat people expect buttons projected buttons react pressure 
users react differently various surfaces display projected 
users looked tentative interacting fabric covered soft board especially buckets painter palette entrance board table 
tell users click bucket picking ms interaction traditional surfaces came naturally 
buckets expected interactive tables 
experience siggraph suggests interesting hypothesis people attribute different interactive capabilities surfaces transformed touch screens nature surfaces 
true observation may implications variety areas 
ed projector introduces new concept projecting interactive display arbitrary surfaces environment 
technology generic input output device replace situations current displays interactive devices 
limited fixed display application move needed environment phone book phone database papers file cabinet 
computer information access provided spaces traditional displays broken stolen 
interactive display brought proximity user requiring user move 
particular ed projector facilitate access computers people locomotive disabilities 
instance project interactive display hospital bed sheet patient contact device 
projected displays enable new set applications computer acts physical world robotic arm light 
applications ed projector point physical objects show connections project patterns indicate movement change real world 
experiment described example class applications 
see displays projector potential enabler new generation games happen virtual world projected physical everyday world live 
viability ed concept demonstrated experiment guided time users assembly task 
experiment simple enable draw definitive people react system transforms everyday surfaces touch screens 
alerted limitations technology suggested guidelines design applications 
example evident switching time surfaces shortened filled sort user feedback 
analysis errors detecting user input points ways improve performance vision system 
clear computer vision systems domain knowledge essential obtaining performance 
include knowledge user located interaction types activities perform outside context interaction types errors disruptive interaction 
interesting research concerns interaction mechanisms best suited display projected arbitrary surface 
button right metaphor interaction 
demonstrated detect button pressing actions reasonable accuracy single camera right paradigm user point view widget detects hand position pressure 
flexible expressive hand gestures play role interfaces 
body gestures natural actions user play role 

bj rk pirates 
physical world game board 
proc 
interact 

tokyo japan 

crowley things see 
communications acm 


ishii ullmer 
tangible bits seamless interfaces people bits atoms 
proc 
chi 

atlanta georgia 

kjeldsen head gestures computer control proceedings workshop recognition tracking face gesture real time systems rts vancouver bc canada july 
kjeldsen hartman design issues vision computer interaction systems 
proc 
workshop perceptual user interfaces 

orlando florida usa 


maze 
proc 
siggraph 

los angeles california 

krueger artificial reality ii 
addison wesley 

talking head projected real objects 
proc 
multimedia modeling mmm 
world scientific 

pinhanez displays projector device create ubiquitous graphical interfaces 
proc 
ubicomp 

atlanta georgia 

rekimoto multiple device approach supporting whiteboard interactions 
proc 
chi 

los angeles ca 

pixels real world graphics luminous room 
proc 
siggraph 

los angeles ca 

weiser computer century 
scientific american 

welch projected imagery office 
ieee computer graphics applications july august 

wellner interacting digitaldesk 
communications acm 


wu huang vision gesture recognition review 
lecture notes artificial intelligence 


yang welch 
automatic continuous projector display surface calibration day imagery 
proc 
th international conf 
central europe computer graphics visualization computer vision 

czech republic 
