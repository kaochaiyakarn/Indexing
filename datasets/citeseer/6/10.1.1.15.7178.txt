artificial anomalies detect unknown known network intrusions wei fan ibm watson research hawthorne ny ibm com wenke lee college computing georgia tech atlanta ga wenke cc gatech edu intrusion detection systems idss capable detecting new unknown attacks anomalies 
study problem building detection models pure anomaly detection combined misuse anomaly detection detection known unknown intrusions 
propose algorithm generate artificial anomalies coerce inductive learner discovering accurate boundary known classes normal connections known intrusions anomalies 
empirical studies show pure anomaly detection model trained normal artificial anomalies capable detecting unknown intrusion classes accuracy intrusion class 
combined misuse anomaly detection models accurate pure misuse detection model detecting known intrusions capable detecting unknown intrusion classes accuracy measurements class 
classification anomaly detection common data analysis tasks 
anomaly detection tracks events inconsistent deviate events known expected 
example intrusion detection anomaly detection systems flag observed activities deviate significantly established normal usage profiles 
hand classification systems patterns known classes match identify known labels unlabeled completed author phd student columbia university matthew miller salvatore stolfo computer science columbia university new york ny sal cs columbia edu philip chan computer science florida tech melbourne fl pkc cs fit edu datasets 
intrusion detection classification known attacks called misuse detection 
anomaly detection systems studied explored applied classification systems 
leading commercial intrusion detection systems idss employ solely misuse detection techniques patterns known attacks detect intrusions 
anecdotes serious break ins major government military commercial sites shown adversaries knowing intrusion prevention detection systems installed networks attempting develop launch new attacks 
year distributed denial service ddos attacks caused major disruptions services provided internet 
generation classification models training data containing instances known classes available training human analysis goal simply detect instances known classes 
anomaly detection relies data belonging single class purely normal connection records limited instances known classes goal detecting unknown classes 
difficult traditional inductive learning algorithms task distinguishing boundaries classes data 
explore traditional inductive learning algorithms anomaly detection working dataset level 
methods generating artificial anomalies known classes coerce arbitrary machine learning algorithm learn hypotheses separate known classes unknown classes 
discuss generation anomaly detection models pure normal data discuss generation combined misuse anomaly detection models data contains known classes 
apply proposed approaches network intrusions 
rest organized follows 
section discusses motivation artificial anomaly generation different methods 
sections evaluate methods ripper inductive rule learner trained tested darpa intrusion detection evaluation dataset 
section reviews related anomaly detection 
section offers conclusive remarks discusses avenues 
longer version www cs columbia edu artificial anomaly generation major difficulty machine learning methods anomaly detection lies making learner discover boundaries known unknown classes 
examples anomalies training data definition task anomaly detection machine learning algorithm uncover boundaries separate different known classes training data 
behavior intended prevent overfitting model training data 
learners generate hypotheses provided class labels training data 
hypotheses define decision boundaries separate class labels 
achieve generalization avoid overfitting learning algorithms usually specify boundary necessary separate known classes 
learners generate default classification instances covered learned hypothesis 
label default classification defined frequently occurring class uncovered instances training data 
possible modify default prediction anomaly signifying uncovered instance considered anomalous 
possible tune parameters learners coerce learning specific hypotheses 
experimentation methods yield reasonable performance 
failure specific hypotheses modifying model default prediction motivated propose artificial anomaly generation task 
artificial anomalies injected training data help learner discover boundary original data 
artificial anomalies class label anomaly 
approach generating artificial anomalies focuses near misses instances close known data training data 
assume training data representative near misses safely assumed anomalous 
artificial anomaly generation methods independent learning algorithm anomalies merely added training data 
input output 
set features 
set unique values feature 

number occurrences frequently occurring value 
return number occurrences loop randomly chosen datum value feature replace randomly chosen value create note algorithm modified take factor produce artificial anomalies 

distribution artificial anomaly dba generation algorithm distribution artificial anomaly know exact decision boundary known anomalous instances assume boundary may close existing data 
generate artificial anomalies close known data useful heuristic randomly change value feature example leaving features unaltered 
regions known data instance space may sparsely populated 
compare sparse regions small islands dense regions large islands ocean 
avoid overfitting learning algorithms usually biased discovering general hypotheses 
known data want prevent hypotheses overly general predicting known classes 
sparse regions may grouped dense regions produce large regions covered overly general hypotheses 
analogy small islands unnecessarily grouped large islands form apparently larger islands 
possible produce artificial anomalies edges sparse regions coerce learning algorithm discover specific boundaries distinguish regions rest instance space 
words want generate data amplify sparse regions 
sparse regions characterized infrequent values individual features 
amplify sparse regions proportionally generate artificial anomalies sparse regions depending sparsity proposed gorithm detail 
assuming value feature infrequently dataset calculate difference number occurrences number occurrences frequently occurring value feature randomly sample data point sample replace value feature data points training set 
generate artificial anomaly learning algorithm specifically cover instances data value feature anomaly generation process called distribution artificial anomaly generation dba distribution feature values training data selectively generate artificial anomalies 
filtered artificial anomalies discussion assume artificial anomalies intersect known data 
check collision known instances expensive process 
approach filter artificial anomalies hypotheses learned original data 
training set plus initial generation artificial anomalies learn model 
evaluate model previously generated artificial anomalies remove anomalies classified known class 
process repeated size set artificial anomalies remains relatively stable 
experimental setup generation models chosen ripper inductive decision tree learner 
ripper learn unordered ordered rulesets 
types rulesets idss discussed previous 
reported results clearly stated ripper ruleset inject amount distribution artificial anomalies equal size training set dba 
experiments data distributed darpa intrusion detection evaluation program conducted mit lincoln lab available uci kdd repository kdd cup dataset 
taxonomy categorization intrusions darpa evaluation 
taxonomy places intrusions categories denial service dos probing prb remotely gaining illegal remote access local account service local user gaining illegal root access 
darpa data gathered simulated military network includes wide variety intrusions injected network period weeks 
table 
intrusions categories sampling dos prb buffer overflow ftp write back guess passwd land nmap multihop imap neptune perl phf pod satan spy smurf teardrop table 
anomaly detection rate false alarm rate pure anomaly detection far buffer overflow ftp write guess passwd multihop imap perl phf spy back land nmap neptune pod satan smurf teardrop dos prb significant data processed connection records madam id 
sample taken maintained distribution intrusions normal connections original data sample available kddcup data uci kdd repository 
sample training data left remaining unaltered test data evaluation learned models 
pure anomaly detection pure anomaly detection learned model available normal connections augmented dba anomalies generated normal connections 
refer collection dataset ripper learns large number rules normal anomaly dataset 
results table shows results pure anomaly detection model 
detection rate false alarm rate evaluate performance 
anomaly detection rate percentage occurrences unknown intrusion detected anomalies defined set predicted anomalies set occurrences label dataset 
omit sub script meaning clear context 
similarly calculate cumulative anomaly detection rate unknown intrusions cumulative anomaly detection rate different categories unknown intrusions 
measure false alarm rate anomalous classifications 
percentage predicted anomalies normal connections defined measurement value represent enhance readability tables 
cumulative anomaly detection rate intrusions false alarm rate shown table 
anomaly detection model successfully detects anomalous connections test data false alarm rate 
examine performance specific intrusion classes categories anomaly detection rate class category shown table 
anomaly detection model capable detecting intrusion classes intrusions training set 
total intrusion classes non null measurements detected anomalies 
intrusions entries highlighted proposed method catches occurrences 
intrusions guess passwd buffer overflow phf approach capable detecting perfectly 
intrusions belong harm ful categories 
anomaly detection rates categories intrusions indicate general category successfully detected 
categories dos model detects intrusion occurrences category important note categories potentially damaging prb 
combined misuse anomaly detection pure anomaly detection high false alarm rate boundaries implied artificial anomalies sharpened real intrusions 
separate modules anomaly misuse detection efficient single module detects misuse anomaly time 
motivated explore artificial anomalies task 
intrusion correct detection intrusion class tc correct detection anomaly unknown intrusion correct detection intrusion incorrect class false alarm far 
relationship metrics normal learn single ruleset combined misuse anomaly detection 
ruleset rules classify connection normal known intrusion classes anomaly 
order evaluate combined approach group intrusions small clusters details longer version 
create datasets dataset incrementally adding cluster normal dataset re generating artificial anomalies 
simulate process invention new intrusions incorporation training set 
learn models contain misuse rules intrusions known training data anomaly detection rules unknown intrusions left clusters rules characterize normal behavior 
cluster contains intrusions require similar features effective detection 
clusters confused attack categories taxonomy 
example cluster contains intrusions buffer overflow perl 
intrusions attempt gain unauthorized root access local machine require features root shell root shell obtained su flag indication su root command derivations 
clusters completely disjoint feature sets intersect slightly 
model trained detect intrusions cluster may difficulties detecting intrusions cluster 
clusters intersecting feature sets hope model learned training instances intrusions cluster may detect intrusions clusters anomalies 
explaining results define frequently terms 
intrusion class appears training data known intrusion 
similarly intrusion class training set unknown intrusion true anomaly 
predicted anomalies include true anomalies may include instances known intrusions normal 
anomaly refer predicted anomaly intention clear context 
results results combined misuse anomaly detection methods shown figures tables 
outcome detection calculate measurements true class detection rate anomaly de tection rate class detection rate 
relationship metrics shown venn diagram 
outside rectangle represents set data evaluated inside ellipse depicts set alarms generated learned detection models 
true class detection rate measures percentage connection class normal intrusions correctly predicted true class defined set predictions label defined section measured known unknown intrusions intrusion categories predicted anomalies 
class detection rate rate detection class intrusion percentage occurrences intrusion detected class intrusion true label anomaly defined additionally total detection rate defined examine results perspectives 
important see proposed method influences true class detection rate known intrusions 
ideally artificial anomalies allow anomaly detection classify true anomalies degrading performance detecting known intrusions misuse rules 
second evaluate effectiveness detecting true anomalies 
third examine anomalous classification compensate low detection rates known intrusions misuse rules 
show false alarm rates anomaly detection different test settings 
true class detection true class detection rates models learned dba shown 
axis shows dataset ranging dataset dataset explained section 
see curves dos prb indistinguishable 
difference curves reasonably small observation shows proposed dba method deteriorate effectiveness detecting particular categories known intrusions 
examine efficacy approach detecting anomalies 
true anomaly detection analysis consider anomaly detection model significant particular leave cluster testing 
note instances test data 
disagreements just examples significant difference true class detection rate percentage true class detection rate percentage dba dba dataset number dba dos dba dba dataset number dba true class detection rate percentage true class detection rate percentage dba dba dataset number dba prb dba dba dataset number dba 
comparison true class detection rate tc datasets dba table 
percentage significant true anomaly detections dataset anomaly types significant dataset anomaly types significant detection class experiment settings truly anomalous cases intrusions types experiment settings included training data significant 
experiment setting percentage cases significant shown table 
study effectiveness anomaly detection different categories true anomalies 
measure anomaly detection rate true anomalies intrusion category true anomalies ttl 
results table 
shown upper rightmost curve row table ttl true anomaly detection rate true anomalies remains relatively constant inject clusters intrusions 
curves prb categories bumpy dos anomaly detection model catches category fewer 
true anomaly detection rate percentage total detection rate percentage total detection rate percentage dataset number table 
percentage true anomalies detected anomalies true anomaly detection rate percentage dataset number true anomaly detection rate percentage dos dataset number true anomaly detection rate percentage prb dataset number dataset na na na na dos prb na na na na na ttl dataset number dos dataset number total detection rate percentage total detection rate percentage dataset number prb dataset number 
total detection rate known intrusions detected anomalies interesting determine proposed approach prove effective detecting un classified known intrusions anomalies 
consider anomaly detection method significantly compensate misuse detection anomaly detection increases total rate detection nearly low 
experiment settings cases candidates compensation 
cases significantly compensated detected anomalies 
remaining cases intrusions detected intrusion leaving room anomaly detection provide compensation 
show total percentage detection categories intrusions 
expected general trend increase 
comparing see higher total detection rate true class detection rate anomaly detection rate percentage anomaly detection rate percentage dataset number dos dataset number anomaly detection rate percentage detection rate percentage true anomaly detection rate percentage ttl dataset number dataset number prb dataset number 
percentage known intrusions true anomalies detected anomalies attributed known intrusions detected anomalies 
performance discussion covered performance true anomaly detection misuse detection compensation 
examine combined performance detecting true anomalies known intrusions 
results intrusion categories shown 
expected general trend decrease datasets augmented clusters intrusions 
caused fact learned misuse rules intrusions leaving room intrusions detected anomalies 
shape anomaly detection rate curves somewhat inversely related respective true class detection curves 
relationship explained observation indication amount additional detection anomaly detection provide 
decreasing inverse relationships apply dos curves seen prb curves dataset see intrusion clusters augment normal data true class detection rates increases leave room anomaly detection compensate 
explains generally decreasing tendency curves 
dos attacks true class detection rate rises dataset sufficient room compensation anomaly detection explains flatness dos curve 
prb rise takes place dataset see complimentary decrease dataset slight curve due inverse curve 
slight dos prb curves caused insufficient feature values available learning decision boundary anomalies 
false alarm rate anomalous classifications uniformly details shown longer version 
confirms nearly detected anomalies true anomalies known intrusions 
additionally rates normal connections normal correctly classified normal near 
observations show utility anomaly detection approach building highly precise models 
effects cluster ordering performed tests verify results influenced order clusters added training sets 
test reverse cluster ordering previous section random ordering totally different original second orderings 
results confirmed results influenced cluster order 
additional issues experimented different amounts injected artificial anomalies 
general trend increase injection amount normal connections decreases slightly increases slightly 
amount injected artificial anomalies increases artificial anomalies normal connections training data learning algorithm tends generate anomaly rules 
general proposed algorithm sensitive amount artificial anomalies training data 
experimented forms ripper rulesets rule sets 
rulesets classify connections order frequency followed normal default clas anomaly 
rule order normal anomaly alphabetically ordered intrusion classes essentially arbitrary 
results gathered ruleset close detailed results rulesets 
interesting observe rulesets similar rulesets datasets clusters intrusions added normal data 
dataset dataset datasets anomaly detection classify known intrusions anomalies 
due fact anomaly rules appear intrusion rules 
experimented filtering method dba proposed section 
generated artificial anomalies filtered times resulting reduction time 
see significant improvement performance method 
experimented filtering anomalies generated naive approach observed artificial anomalies removed 
main drawn filtering experiments artificial anomalies truly anomalous collide known training data 
related sri ides measures abnormality current system activity probability distributions past activities 
activities monitored host events cpu utilization file accesses monitor network events 
forrest record frequent subsequences system calls execution program sendmail 
absence subsequences current execution program stored sequences constitutes potential anomaly 
lane brodley similar approach focused incremental algorithm updates stored sequences data unix shell commands 
lee rule learning program generated rules predict current system call window previous system calls 
abnormality suspected predicted system call deviates actual system call 
ghosh proposed neural network learn profile normality 
similar approach random behaviors generated represent abnormality training purposes 
approach input features distance value exemplar sequence bsm events 
study attempts applying machine learning algorithms network events anomaly detection 
algorithms anomaly detection misuse detection traditionally studied separately 
sri emer ald anomaly misuse detection algorithms separate system components put responses correlated generate alarms resolver 
ghosh applied neural networks anomaly misuse detection compared relative performance 
unique goals study combination anomaly misuse detection model improve performance 
aware closely related generation training data belonging unknown opposite class 
unlabeled instances nigam assigned labels classifier trained labeled data put training set round training 
skewed distribution scenario kubat matwin attempted remove majority instances close far decision boundary 
maxion tan conditional entropy measure regularity training set shown easier detect anomalies data high regularity 
lee xiang applied entropy determine hard learn model normality abnormality 
chang lippman applied voice transformation techniques add artificial training talkers increase variabilities 
hacker activity evident importance network intrusion detection 
anomaly detection unknown intrusions important difficult area ids 
studied problems artificial anomalies detect unknown known network intrusions 
proposed distribution anomaly generation algorithm proven effective building anomaly combined misuse anomaly detection models successfully detect known unknown intrusions 
assumption dba dimension feature treated individually 
words examine generate anomalies dimension dimension possible variation algorithm consider multiple dimensions concurrently give dimension different weight depending importance 
eric chang richard lippmann 
voice transformations create additional training talkers word spotting 
tesauro editor advances neural processing systems 
mit press 
william cohen 
fast effective rule induction 
proceedings twelfth international conference machine learning icml pages 
morgan kaufman 
wei fan wenke lee salvatore stolfo matthew miller 
multiple model approach cost sensitive intrusion detection 
proceedings eleventh european conference machine learning ecml barcelona spain may 
stephanie forrest steven hofmeyr anil somayaji thomas longstaff 
sense self unix processes 
proceedings ieee symposium security privacy 
ghosh aaron 
study neural networks anomaly misuse detection 
proceedings usenix security symposium 
harold javitz alfonso valdes 
sri ides statistical anomaly detector 
proceedings ieee symposium security privacy page 
miroslav kubat stan matwin 
addressing curse training sets sided selection 
proceedings fourteenth international conference machine learning icml pages 
morgan kaufmann 
lane carla brodley 
approaches online learning concept drift user identification computer security 
proceedings fourth international conference knowledge discovery data mining kdd pages 
wenke lee 
data mining framework constructing features models intrusion detection systems 
phd thesis columbia university june 
wenke lee dong xiang 
information theoretic measures anomaly detection 
ieee symposium security privacy oakland ca may 
roy maxion tan 
benchmarking anomaly detection systems 
international conference dependable systems networks pages june 
peter neumann philip porras 
experiments emerald date 
proceedings usenix workshop intrusion detection 
kamal nigam andrew mccallum sebastian thrun tom mitchell 
learning classify text labeled unlabeled documents 
proceedings fifteenth national conference artificial intelligence aaai 
sunsoft 
basic security module guide 
sunsoft mountain view ca 
