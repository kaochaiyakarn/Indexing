report asymptotic analysis flow deviation method maximum concurrent flow problem daniel olga columbia university new york ny december analyze asymptotic behavior flow deviation method rst fratta gerla kleinrock show applied packing linear programs maximum concurrent ow problem yields fully polynomial time approximation scheme 
maximum concurrent ow problem frequently arises practical applications received attention due diculty 
input problem graph directed undirected capacities edges set multicommodity demands routed 
objective nd largest value fraction demand simultaneously routed exceeding available capacities possibly 
words want nd feasible ow maximum throughput 
precise de nition section 
equivalent problem minimum congestion problem simultaneously route demand maximum load edge ratio total ow capacity minimized 
literature problems regarded jointly referred maximum concurrent ow problem maximum throughput version 
problem arises telecommunications di erent versions directed undirected edges restrictions routings 
algorithms network design problems rely solving maximum concurrent ow problems order nd feasible routing 
problem especially noteworthy gives rise extremely dicult linear programs instances size type relevant applications prove reach state art linear programming codes 
facts spurred long line research alternative algorithms maximum concurrent ow problem particular approximation algorithms 
nature problem sense ideal approximation algorithm precision controlled 
fully polynomial polynomial time approximation scheme estimates relative error worst case complexity grows polynomially size graph 
rst algorithm sm late applied minimum congestion problem 
sm introduced potential function exponentially penalizes load edge approximate minimization potential function yields ow maximum load provably near optimal 
carry approximate optimization potential function research partially funded nsf awards ncr cda sm amounts frank wolfe scheme see dw fm fw 
algorithm proved worst case complexity bound grows proportional polynomially size graph 
algorithm viewed lagrangian relaxation approach capacity constraints relaxed violation constraints penalized special multipliers 
exponential multipliers roughly stated arise frank wolfe scheme gradient potential function 
results intense active research ort 
see gk gk lr pst kp 
research primarily showed better exponential potential function frank wolfe lagrangian relaxation framework obtain faster algorithms minimum congestion problem generalizations 
logarithmic sliding barrier function applied minimum congestion problem discussed vg 
analysis shows exponential potential function naturally arises derandomization probabilistic algorithms algorithms maximum concurrent ow problem described gk related ideas 
fastest algorithms running time bounded bounded times low order polynomial size graph number commodities 
altogether algorithms gk yield best bounds maximum concurrent ow problem precisely best depends complex manner number vertices edges commodities 
experimental testing algorithms yielded implementations substantially ective commercial linear programming codes see 
fratta gerla kleinrock fgk proposed general algorithmic scheme solution various optimization problems arising telecommunications nding feasible multicommodity ow tantamount solving maximum concurrent ow problem 
approach fgk quite di erent cited involves simple idea increasing throughput feasible ow rational barrier function prevent ows exceeding capacities frank wolfe procedure reduces barrier function 
partial convergence proof fgk 
ow deviation method known frequently telecommunications community poorly known algorithms community 
show ow deviation method properly implemented yields algorithm solves maximum concurrent ow problem relative error solving log ow computations respectively number edges commodities 
algorithm describe contains critical algorithmic ideas fgk re nements designed achieve performance 
re nements algorithm fgk shown converge shortest path computations width pst 
contrast note algorithm requires time 
de nitions consider graph vertices capacity edge suppose set commodities commodity consists pair vertices demand amount 
denote set paths edge denote subset consisting paths contain maximum concurrent ow problem linear program max tf de nition formulation apply graph directed 
point view linear programming path formulation ecient ow formulation compact 
note commodity linear program constraints reduces shortest path problem 
approximate solution tf ow throughput feasible tf approximates relative error 
say ow vector feasible exists nonnegative value satis es case say throughput ow vector say load max edge called load feasible say strictly feasible 
consider problem form min ff qg convex convex di erentiable classical frank wolfe procedure solves problem generating sequence fx 
contained iteration procedure solves convex program min rf solution sets chosen minimize 
called step size 
frank wolfe method closely related danzig wolfe decomposition steepest descent methods unconstrained optimization 
completeness state minimum congestion problem 
graph multicommodity demands maximum concurrent ow problem minimum congestion problem linear program min simple analysis shows follows deal exclusively maximum concurrent ow problem 
central idea section describe main idea fgk 
consider instance maximum concurrent ow problem strictly feasible throughput ideas suppose 
feasible throughput general feasible throughput 
suppose appropriate algorithmic construct obtain feasible vector throughput loads signi cantly lower skeletal outline algorithm outline 
strictly feasible throughput 

find feasible throughput substantially smaller 
reset go 
execution increases throughput spreads ow 
describe concrete implementation 
satisfy properties range increasing continuous convex ii way accomplish de ne strictly feasible choose solution min feasible ow fact property ii optimal solution optimization problem maximum load smaller 
note view construction step unde ned general may case unde ned amend step slightly obtain scale factor slightly smaller may strictly necessary minimize decrease value 
algorithmic scheme basic algorithm 
initialization 
strictly feasible throughput 
magni cation 
set parameter 

barrier reduction 
find feasible throughput suciently smaller 
exists 
reset go 
algorithm implicit steps main contribution fgk pp 

signi cantly di ers algorithms cited 
ingredients fgk 
barrier function 
frank wolfe procedure carry barrier reduction step 
choice parameter provides suciently rapid increase throughput 
provably choice starting point 
particular implementation describe di ers fgk aspects frank wolfe iterations minimum cost ow problems opposed shortest path computations may carry frank wolfe iterations gradient steps fgk uses single iteration 
implemented shortest path computations single frank wolfe iterations resulting algorithm shown converge approximate solution shortest path computations width parameter pst 
note fgk term ow deviation method appears refer frank wolfe procedure synonymous entire scheme 
algorithm section describe implementation 
notation section 
smallest positive integer 
algorithm fd step 
initialization 
edge graph assign length denote ow carries units shortest path metric denote multicommodity ow 

set 
step 
set step 
frank wolfe procedure 
write 

denote solution minimum cost ow problem send units ow edge cost capacity 
denote resulting multicommodity ow 
set chosen minimize 
exit loop set go step 
step 
terminate algorithm 
go step 

analysis algorithm fd denote min feasible order show correctness algorithm rst state theorem proof deferred theorem consider execution loop step input suppose loop exits iteration pending proof theorem sequence lemmas establish correctness workload algorithm 
lemma nonnegative integer 
suppose 
ii suppose 
proof 
consider feasible throughput throughput satis es 
ii proved similar way 
lemma suppose iterate step satis es proof 
assume contradiction hold 
feasible throughput throughput satis es result value contradicts theorem 
lemmas imply corollary termination algorithm fd feasible ow optimal throughput 
turn complexity algorithm fd 
lemma vector throughput proof 
result implied weak linear programming duality direct proof follows 
denote sum commodities shortest path lengths step 
multicommodity ow clearly consequently construction result follows 
follows integral denote phase algorithm set iterations note phase empty algorithm perform iterations phase lemma number iterations phase 
ii number iterations phase log 
iii total number iterations phases 

proof 
lemma consequently suppose de nition started phase throughput implies phase perform iterations desired 
ii follows lemma 
iii consider iteration phase algorithm terminated replace stronger condition obtain altogether iterations phases 
lemmas analyze complexity execution step 
lemma consider iteration step edge 
proof 

de nition result follows 
lemma consider iteration step phase minfr qg 
proof 
suppose rst 
theorem respectively lemma case second termination criterion step case minfr qg 
obtain desired result show 
see consider contributions edge 
respectively lemma denominator second expression half rst 
compare numerators note iteration phase consequently 
desired 
suppose 
theorem choice 
lemma follows previous paragraph 
edge satisfy 
lemma number iterations execution step phase minfr qg 
proof 
show minfr qg iterations achieve reach value smaller contradiction 
consider iteration holds 
suppose rst case recursion abstracted constant 
recursion property reduces factor iterations 
lemma obtain minfr qg iterations holds 
remainder proof handle iterations lemma ii conclude iteration satisfying decreases consequently iterations tighter analysis possible needed 
concludes proof 
just previous line conclude iterations obtain 
lemma variation analysis lemma shows time phase potential halved iterations iterations 
corollary total number frank wolfe iterations course algorithm fd log 
section prove theorem 
section show replace line search step provably step size rule requires time 
proof theorem consider iteration frank wolfe procedure corresponding input vector simplicity write 
write convex 
nd order taylor expansion 
choice right hand side decrease replace feasible ow throughput particular ow throughput obtain 
convex implies bound quadratic term 
consequently feasible 

get chosen convexity imply substituting obtain inequality holds satis es 
step choose left hand side minimized 
argument minimizes quadratic right hand side note simple check veri es stated bounds 
argue 
follow argue holds words satis es 
note small holds choice descent direction 
holds done 
holds closed interval hold outside interval 
holds equality clearly desired 
get calculation minimize quadratic obtain theorem proved 
choosing step size key step algorithm fd choice step size step expect point view computational ectiveness best carry numerical line search estimate rest section show choose value time preserves theoretical properties algorithm 
way choose minimize quadratic introduced proof theorem assuming words minimize decrease proof theorem bound decrease 
show alter algorithm fd step size correct algorithm complexity bound 
fact proved long choosing minimize guarantees decrease validity algorithm preserved 
lemma applies consider rst line proof 
shows complexity bound algorithm fd applies 
comments algorithm fd fgk procedures analysis pitched provably approximation eld existed embryonic form 
primary cause di erences algorithm fd fgk 
critical idea fgk key ingredient algorithm fd 
fact frank wolfe iterations minimum cost ow problems needed paragraph immediately guarantee 
replace minimum cost ow calls shortest path calls claim width pst context width problem upper bounded ratio largest demand smallest capacity 
results increase complexity estimate factor trick minimum cost ow calls avoid dependence new pst gk 
algorithms maximum concurrent ow problem avoid dependence resorting shortest path calls gk 
conjecture re ned version algorithm achieve behavior 
ii algorithmic outline fgk uses single frank wolfe iteration step 
algorithm adapted single frank wolfe iterations step shown dependence adapted algorithm grows 
adaptation entails ner tuning multiplier step 
iii magni cation factor step fgk choice parameter fgk states proper tolerance 
step choice ow precisely choice initialization step fgk 
start guarantee opposed 
iv proof theorem inequality follows fairly closely similar analysis fgk pp 

part proof follows fgk somewhat closely 
particular fgk analyze quadratic term key complexity estimate 
analysis prior proof theorem new 
algorithm fd easily generalized general packing linear programs pst 
vi fgk points ds contains ideas similar flow deviation method developed form 
courant cou credited earliest uses potential functions solution systems equations 
vii pointers reader decides tackle fgk 
notation fgk 
algorithm pp 
geared nding feasible ow throughput 
includes exit condition step 
step de nition fd operator page inductively show consequently ren ren 
error case exit condition re 
computational outlook despite clear theoretical worst case complexity bound proved algorithm fd compared gk practitioners employ ow deviation method ectiveness 
advantages rational potential function fd implicit exponential potential gk karmarkar function vg better numerical stability independence 
mean potential function fd include de nition fact entire algorithm uses termination conditions 
may lead cleaner implementations easier tune 
going computational research see forthcoming focused explicitly seeking reduce potential means accelerate convergence opposed gk potential function implicit feel ective paradigm leverage considerable machinery developed nonlinear programming community 
context exploring rational potential function computational standpoint topic 
approximately solving large scale linear programs 
strengthening lower bounds accelerating convergence report columbia university 
extended proc th 
ann 
acm siam symposium discrete algorithms january 
potential function methods approximately solving linear programs theory practice appear core lecture series monograph core belgium 
cou courant variational methods solution problems equilibrium vibration bull 
amer 
math 
soc 
ds sparrow trac assignment problem general network journal research national bureau standards 
dw danzig wolfe decomposition algorithm linear programming econometrica 
fleischer approximating fractional multicommodity ow independent number commodities siam disc 
math 

fm mccormick nonlinear programming sequential unconstrained optimization techniques wiley new york 
fw frank wolfe algorithm quadratic programming naval res 
logistics quarterly 
fgk fratta gerla kleinrock ow deviation method approach store forward communication network design networks 
goldberg plotkin stein implementation combinatorial approximation algorithm minimum cost multicommodity ow proc 
ipco 
gk khachiyan fast approximation schemes convex programs blocks coupling constraints siam journal optimization 
gk khachiyan exponential function reduction method block angular convex programs networks 
gk khachiyan coordination complexity parallel price directive decomposition math 
oper 
res 

gk garg faster simpler algorithms multicommodity ow fractional packing problems proc 
th ann 
symp 
foundations comp 
sci 

kp karger plotkin adding multiple cost constraints combinatorial optimization problems applications multicommodity ows proc 
th ann 
acm symp 
theory computing 
klein plotkin stein tardos faster approximation algorithms unit capacity concurrent ow problem applications routing nding sparse cuts proc 
nd ann 
acm symp 
theory computing 
ky klein young number iterations dantzig wolfe optimization approximation algorithms 
proc 
ipco 
leighton plotkin stein tardos fast approximation algorithms multicommodity ow problems proc 
nd ann 
acm symp 
theory computing 
lr leighton rao approximate max ow min cut theorem uniform multicommodity ow problems applications approximation algorithms proc 
focs 
pst plotkin shmoys tardos fast approximation algorithms fractional packing covering problems math 
oper 
res 

extended proc 
nd annual ieee symp 
foundations computer science 
fast deterministic approximation multicommodity ow problem proc 
th symp 
discrete algorithms 
ph 
dissertation dept columbia university 
sm maximum concurrent ow problem journal acm 
vg approximate lagrangian decomposition modi ed karmarkar logarithmic potential network optimization pardalos hager eds 
lecture notes economics mathematical systems springer verlag berlin 
young randomized rounding solving linear program maximum concurrent ow problem proc 
th acm siam symp 
discrete algorithms 

