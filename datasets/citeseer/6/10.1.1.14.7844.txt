multicast cache mcache adaptive zero delay video demand service sridhar ramesh rhee katherine guo department computer science bell laboratories north carolina state university lucent technologies raleigh nc holmdel nj csc ncsu edu lucent com presents closed loop demand driven approach vod services called multicast caching mcache 
servers multicast reduce bandwidth usage serving multiple requests single data stream 
requires clients delay receiving movie multicast starts 
regional cache servers mcache removes initial playout delays clients clients receive prefix requested clip regional caches waiting multicast start 
addition multicast containing portion movie wait prefix played 
caches proposed novelty scheme lies requests coming multicast starts batched served multicast patches playout delays 
patches proposed unicast playout delays 
mcache effectively hires idea multicast patch caches provide truly adaptive vod service bandwidth usage par best known openloop schemes high request rates minimal bandwidth low request rates 
addition efficient multicast caches removes need priori knowledge client request rates client disk storage requirements existing schemes assume 
mcache ideal current heterogeneous internet environments parameters hard predict 
video demand vod gaining popularity proliferation high bandwidth networks 
applications vod include news distribution www cnn com distance learning entertainment video distribution 
deployment new technologies mile access networks dsl cable modem vod internet possible 
typical vod system consists set centralized video servers geographically distributed clients connected high speed networks 
large number video files stored servers played clients 
accepting client request server reserve sufficient processing capacity network bandwidth video stream order guarantee continuous playback video 
channel refer unit server network bandwidth needed support video stream 
high bandwidth requirement video streams server network bandwidth considered expensive resource vod system 
critical part vod system design minimize server bandwidth requirement 
internet traffic bursty study indicates arrival rates requests web highly variable 
typically long periods idle times relatively little request traffic mixed short periods high request burst 
partially supported nsf career ani lucent technologies 
evidence vod requests follow characteristics web believe characteristics quite 
preliminary study suggests request patterns news demand services follow web zipf law web page popularity 
examines performance vod request scheduling protocols environment request rates may highly variable vod service highly adaptive optimizing server bandwidth usage level request traffic 
existing vod schemes fall categories closed loop schemes openloop schemes 
closed loop schemes server allocates channels schedules transmission video streams client requests batching patching techniques 
batching requests video clip delayed certain amount time serve requests possible multicast channel 
patching client issues request video clip immediately joins existing multicast channel clip 
missed part server establishes new unicast channel send missing part patch 
unicast patching introduce playout delay client network delays 
existing patching protocols high bandwidth high request bursts 
controlled multicast best patching protocol known date requires server channels mean arrival rate requests mean size video clips 
low arrival rates expected number server channels required desirable scheduling protocol server bandwidth usage independent request arrival rate rate high making bandwidth usage low rate low 
open loop schemes require constant bandwidth regardless request rates 
years seen number innovative open loop schemes differ multicast schedules server bandwidth requirements 
schemes require log server channels theoretical lower bound required server channels vod 
open loop schemes adaptive server broadcasts constant amount video streams regardless outstanding request 
open loop approach support unlimited number requests popular video clips constant amount bandwidth wastes bandwidth request frequency low 
proposes novel adaptive closed loop scheme called multicast cache mcache uses part client storage space caches store parts popular video clips offer zero delay playout lower server cache bandwidth requirements best known closed loop schemes 
properties low arrival rates mean channel usage server tends lower bound request necessitates complete playout video clip server 
high arrival rates mean channels usage server bounded log independent 
clients experience playout delay network delays receiving requested video clips 
bandwidth consumption client constant independent length video clips client requires channels time 
amount disk space clients caches impact performance cache approaches 
tradeoffs disk space bandwidth usage server caches better cache closed loop approaches 
require priori knowledge client request rates client disk space 
central idea mcache batching patching prefix caching techniques multicast complement 
mcache client sends request server local cache 
request immediately served cache prefix requested clip 
server batch request requests arriving duration prefix 
requests batched served multicast channel duration 
furthermore clients requesting clip multicast session clip begun join multicast session 
get missing part separate stream patch 
clients receive prefix caches patch delayed length prefix 
enables server batch requests patch 
batched patch requests served multicast session delay 
scheme introduce delay client point view 
batching requests patch unique feature scheme 
goal reduce bandwidth usage sharing multicast channels video clip patches clients possible 
major constraint offer clients instantaneous playback 
prefix caches essentially allows server delay starting time types multicast delaying client playout time providing opportunities serve requests existing channels 
analytically estimate server bandwidth usage vod services validate results simulation 
analysis shows performance mcache terms time average number server channels usually best schemes tested variety client request rates 
organized follows 
section ii contains overview existing protocols vod systems 
section iii provides outline vod system environment 
section iv presents basic mcache multicast algorithm uses prefix caching 
section discusses variation scheme called smcache partitioning video clips segments 
provide upper bound analysis smcache discuss generalization called partitioned smcache 
section vii compare performance smcache known open loop closed loop schemes numerical examples 
section viii concludes 
ii 
related patching proposed extended optimizing server bandwidth requirement 
threshold policy proposed resulting scheme referred controlled multicast 
controlled multicast closed loop approach shown provide performance low request rates 
hot videos performance deteriorates especially length clip large 
shown server bandwidth grows 
open loop schemes harmonic broadcasting schemes permutation pyramid scheme greedy disk conserving broadcast scheme provide performance terms server bandwidth utilization 
open loop schemes listed involve non zero delay client request playout video clip 
paris propose set schemes involving partial preloading certain objects set top box clients eliminate delay 
resulting protocols zero delay involve substantial server bandwidth utilization request rates clips relatively low 
catching scheme discussed parameter scheme server channel utilization provided accurately estimated 
parameters system chosen provide better performance openloop schemes request rate high 
major disadvantage approach request rate known priori system parameters need altered request rate changes 
involves monitoring request rate recalibration parameters 
estimation arrival rate complicated cases arrivals bursty 
controlled multicast combined catching provide pseudo adaptive protocol called selective catching bandwidth usage limited high request rates bandwidth usage controlled multicast low request rates 
eager proposed closed loop scheme called dynamic skyscraper potentially provide performance high request rates 
algorithm uses segments lengths follow fixed progression 
receiving request client server schedules fresh transmission segments clip 
client obtains remaining segments transmissions scheduled begun time request 
potential contentions scheduling segments transmission authors provide clear scheduling algorithm server regarding segments retransmit receives request client 
scheme disadvantages design performance dependent minimum disk space available client 
heterogenous environments client different amount disk space difficult know priori amount disk space available clients 
furthermore minimum disk space clients fairly small performance worse open loop schemes request rates 
amount video object needs stored regional caches increase tradeoffs server bandwidth cache bandwidth usages best exploited 
disadvantage dynamic skyscraper scheme quantization segments fixed length 
result client requests segment soon server begun multicasting requires retransmission entire segment 
smcache scheme proposed addresses problem variable length patches 
iii 
system environment vod systems normally consist set servers store video clips 
servers connected clients high speed network 
client storage capacity local disk clients connected proxy servers network 
shown videos follow zipf distribution skew factor means demand popular video clips 
limited number popular clips possible proxy server store minutes seconds video clip called prefix 
client connected proxy server assume local prefix cache space store prefix popular video clips 
simplicity refer proxy server local prefix cache cache 
server stores video clips entirety 
part clip prefix called body need transmitted client request 
typically server provided high bandwidth connection clients limited bandwidth devoted streaming video clips 
assume system features server may unlimited number channels transmitting particular video object 
reasonable particularly server stores large number video objects total number channels server instant approximately equal mean statistical multiplexing 
client local disk space 
response request client receives prefix prefix cache 
assume client knows location nearby cache cache contains prefix video clip requested client 
client bandwidth limited client may receive incoming transmissions channels time 
include transmissions video servers cache 
channels equal bandwidth 
transmission rate channels constant equal playout rate 
clients request entire clip 
iv 
multicast cache mcache section describes basic mcache scheme 
video server multicasts body video clips object transmissions patch transmissions 
object transmissions multicast entire body video clip patch transmissions multicast portions clip right prefix facilitate late arriving requests catch object transmission 
shown algorithm requires server bandwidth average 
section extend algorithm allow server store body multiple segments apply basic mcache algorithm segment independently achieve log server bandwidth usage request rate high 
mcache algorithm client action straightforward requests clip body video server requests prefix cache 
prefix received immediately cache played client 
server calculates schedule sends back client information regarding channels join time join channel 
server multicast schedule determined arrival time request status existing multicast channels 
ongoing object transmission server choose schedule patch transmission instruct client join existing object transmission patch transmission schedule new object transmission immediate need patch transmission 
tradeoff choice 
multicast running long time patch short client missed 
patch long 
cost effective receive body starting new object transmission receiving long patch 
apply threshold time units called cutoff threshold decide cases 
existing transmission running time units new object transmission created 
patch 
simplify description transmission propagation delays ignored 
algorithm easily modified delays account 
constants denote prefix length body length respectively time units 
algorithm describes actions taken client server client request comes time denote server algorithm mcache 
takes input request time prefix length cutoff threshold length movie body 
schedules object transmissions patch transmissions handle requests returns times client joins object transmission patch transmission 
note algorithm subroutine main algorithm section describe server algorithm mcache 
pseudocode iv 
batching client issues request clip time object transmission started scheduled start server schedules new object transmission latest possible time server action mcache server receipt request time client mcast body schedule mcast body mcast body time multicast body time join mcast body time send client elseif mcast body scheduled mcast body join mcast body time send client elseif mcast body started patch scheduled min schedule mcast patch min multicast patch join mcast patch listen join mcast body listen send client elseif mcast body started patch scheduled min expand patch range join mcast patch listen join mcast body listen send client endif instructs client join get entire body 
client receives prefix cache time units wait threshold determine new object transmission patch 
object transmission scheduled start client simply joins multicast starts 
patching object transmission started client joins multicast started client needs patch units clip body 
patch multicasted 
fact client joins object transmission time allows patch second channel time recall client receives prefix channel turn facilitates batching requests patch 
patch transmission scheduled service earlier requests client join channel starts 
patch length transmitted channel extended accommodate client 
requests patch batched 
patch transmission scheduled start client finishes receiving prefix cache receives prefix time server schedule start patch start existing object transmission started request coming time serviced new object transmission 
starting time patch set xg 
patch consists units clip body may extended accommodate requests 
threshold value controls frequency recruiting new object transmission affects average server bandwidth usage 
selecting small value results complete transmission clip body scheduled 
selecting large value results large patches require higher server bandwidth 
similar concept selection optimal patching threshold controlled multicast 
performance analysis mcache section provide discrete time analysis show mean server bandwidth minimized selecting optimal arrival requests server modeled poisson process rate 
client requests video clip time slot initiates new transmission new transmission began time slot 
new transmission scheduled start slot 
ongoing transmission began slot client joins multicast slot receives slots body patch 
patch scheduled transmission slot min 
time slot th complete transmission body video clip starts 
number patches transmitted server interval 
total length patches 
define th patching window 
server begins new full transmission body video clip start patching window 
applying renewal theory shown random variables means ep respectively mean bandwidth requirement server ep mean length patching window 
request arriving slots new transmission results patch 
slots new request arriving slot say results new patching window begins slot 
length patching window consideration slots 
request arrivals poisson geometric random variable mean equal estimate ep define concept patch segment help sample sequence requests typical patching window corresponding patches generated shown 
suppose request arrivals slots 
request arrives slot 
server waits time slot transmitting patch client 
patch multicast sent client request arrived slot define slots shown constitute patch segment denoted ps consists slots request followed request slot turn followed slots may feature requests clients 
significance ps clients request video clip ps receive patch call suppose request arrived request receives prefix channel patch second channel slot receives original multicast time slot 
length patch suppose requests server request arrives slot 
call segment constituting slots requests fig 

sample sequence requests server patch segment ps clients requests arrive ps receive patch corresponding patch multicast server length request ps arrives similarly say th patch segment ps consists slots jx 
length th patch assuming th patching segment psn consists slots nx 
assume nx nx exactly patch segments slots observe requests arrive prior slot served th patch 
requests arriving interval nx receive new complete transmission clip cut parameter nx estimate mean length patches assuming exactly patch segments slot en proof theorems omitted draft due space constraint technical draft :10.1.1.14.7844:10.1.1.14.7844
theorem identically distributed 
mean conditioned having exactly patch segments intervals wn random variables independent mean ew simply geometric random variables conditioned ew equation reduces ew simplification get ew un condition get en ew en en mean number patches interval theorem en mean length patch interval theorem mean bandwidth required server approximately equal ew ew optimal value obtained solving quadratic equation 
optimal value lx optimal value grows 
indicates bandwidth usage bounded independent 
reason certain value server transmit patches increases 
point server merely batches requests single patch increasing multicast efficiency 
possible prefix caching 
segmented mcache smcache mcache algorithm described previous section outperforms controlled multicast see :10.1.1.14.7844:10.1.1.14.7844
easily seen outcome batching requests arrive client accessing prefix clip 
hotter video clip gets larger number requests batched 
length cut order means mean bandwidth required server inferior known open loop schemes 
instance preloading schemes paris provide instantaneous video demand server bandwidth 
section extend basic mcache algorithm preserve advantages original algorithm nearly server bandwidth requirement open loop schemes high request rates 
algorithm called segmented mcache smcache 
smcache algorithm body video clip broken segments 
length body ln lengths segments respectively 
segment transmitted basic mcache scheme discussed earlier section 
length prefix cut parameter segment 
assume server begins full transmission segment object channel segment time 
consider client requests segment time client accordingly receives time units segment patch starting time note time client finishes receiving prefix length request coming new object channel segment 
min 
patch time observe client may receive transmission channels time client listens patching channel time note latest time client afford delay receiving second segment time segment fully played 
words client leaves patch channel time receive segment client listens channel object channel segment interval 
interval includes interval duration analogous having virtual prefix length second segment server delay serving request second segment duration length visualize suppose client original request arrived virtual request server segment time latest time server may delay transmitting segment client server time units virtual request transmit segment client ongoing transmission transmitting patch client 
situation mcache prefix length movie clip length stored cache client request movie arrives mcache server time consider body length prefix length transmitted basic mcache scheme 
assume cutoff threshold clip consider request clip arriving time client making request receives prefix channel interval 
transmission clip body scheduled client may join multicast channel 
existing object channel clip body began time client joins multicast time receives patch length server 
run mcache give schedule client get second segment associated patch required 
inductively apply argument segments schedule segment obtained running mcache smcache server algorithm shown 
server action smcache server sl mcache sl sl min od fig 

algorithm server smcache client disk limitations far assumed client store half entire video clip 
client may receive channels time playout speed assumed equal transmission speed client disk space limiting factor smcache algorithm 
take account dmax disk space available client making request modify algorithm accordingly 
constraints introduced 
client may receiving segment equivalent dmax units time scheduled playout time segment 
scheduled playout time segment instant virtual request segment larger equal dmax 
maximum patch size segment may exceed dmax dmax constraints server algorithm 
partitioned smcache section consider generalized version smcache proxy servers store initial segments video object addition prefix 
similar lines partitioned dynamic skyscraper model proposed 
assume main server regional caches network 
regional cache stores segments body clip addition prefix length main server stores remaining segments 
smcache server algorithm suitably modified facilitate regional cache multicast segments clients network neighbourhood main server transmit segments 
regional cache transmits server action smcache server sl mcache sl sl max sl dmax min dmax min min dmax od fig 

smcache limited client disk space prefix client immediately receiving request 
addition basic mcache algorithm executed proxy server segments stored cache 
main server proxy server algorithms shown 
proxy server action part smcache proxy server send prefix time length mcache min od main server action part smcache main server sl mcache sl sl min od fig 

partitioned smcache algorithms vi 
performance analysis section show mean number server channels non partitioned smcache algorithm upper bounded function provided limited disk capacity clients 
prove server bandwidth usage goes zero request rate goes zero 
analyze performance partitioned smcache develop optimization model dividing video clip main server regional caches 
upper bound analysis smcache suppose choose assume 
mean bandwidth required server transmitting segment may estimated 
rearranging terms shown bmax choose show bmax choose segment larger previous factor final segment ln exception ln ln ln xn ln xn shown bmax total bandwidth required server transmitting segments ln 
gives log bmax log seen required bandwidth greater 
closed loop advantage smcache rearranging terms equation show general see 
words bandwidth usage new scheme bounded log function small request rate small proportional 
open loop schemes periodic broadcast hand requires fixed server bandwidth irrespective request rates 
deciding advantage closed loop scheme efficient openloop schemes 
performance partitioned smcache section consider performance partitioned smcache addition prefix segments movie body moved proxy server 
discuss optimization model network costs transmitting video object storage costs replicating segments regional caches 
solution optimization model provides optimal regional caching strategy similar discussed 
mean request rate generated clients network neighbourhood regional cache mean bandwidth required regional cache mx mean bandwidth required regional cache transmitting segment neighbouring clients calculated 
mean bandwidth requirement main server mean bandwidth required main server transmitting th segment clients 
obviously moving segments regional caches results reduction network load main server increase regional caches 
note may preferable increase network load regional caches results decreasing load main server purposes distribution network traffic 
cost involved increasing fraction video object cached viz cost replicating data storing locations 
cost involved replication storage simple solution store entire video object regional cache 
helps distributing load evenly network reduces network load choice cache location carefully 
cost incurred replication storage leading segment set devise optimization model arrive best caching strategy 
time average cost incurred regional cache transmitting channel 
network cost regional cache 
corresponding cost main server 
loss generalization assume 
network cost main server 
cost unit time storing unit data regional cache storage replication cost regional cache cost unit time storing unit data main server storage cost main server total cost unit time smcache system rs rc expect main server multicasts larger number clients spread network regional cache multicasts relatively small number clients neighbourhood 
instance consider binary tree kind network topology 
main server root tree clients leaves 
assume regional servers intermediate nodes level 
multicast main server received clients traverses branches 
regional cache hand needs multicast log clients log branches 
indicates may advantage moving segments regional caches 
results increase storage costs replication costs segments regional cache 
trade network storage costs 
vii 
performance comparison section compare performance smcache scheme dynamic skyscraper gdb selective catching represent state art closed loop open loop hybrid vod algorithms respectively 
modified schemes include prefix cache prefix size equal smcache scheme allow zero delay increased batching 
prefix stored proxies transmitted unicast client immediately receiving request client 
study performance non partitioned smcache various arrival rates requests request arrival process bursty disk space clients variable various prefix lengths 
study performance partitioned smcache 
specifically study performance main server regional caches functions number segments stored regional caches 
compare results performance main server regional caches partitioned dynamic skyscraper algorithm assuming fraction video object stored regional caches 
consider sample cost function specified plot total network storage costs algorithm 
plot total cost main server regional caches highlight trade involved transferring data regional cache 
non partitioned smcache server bandwidth vs request rate plot average number server channels required function request arrival rate assuming poisson request arrivals 
show results smcache obtained analysis simulation 
assumed client disk space accommodate minutes clip 
dynamic skyscraper evaluated values represents maximum segment length allowed algorithm minutes minutes 
conclude approximate analytical algorithm provided evaluate algorithm poisson requests accurate 
conclude smcache considerable improvement gdb request rate low 
conclude smcache provides significant improvement dynamic skyscraper resources 
observe choice crucial performance dynamic request rate prefix min body min disk min smcache analysis selective catching prefix gdb prefix dynamic skyscraper prefix dynamic skyscraper prefix smcache simulation fig 

server channel usage vs time minutes arrivals fig 

pareto arrival process skyscraper 
chosen accommodate client disk space small fraction clients equivalent minutes disk space needs chosen accordingly 
importantly server needs know disk space available client advance design segment lengths correspondence 
conclude optimal selective catching performs better smcache 
selective catching optimized particular request arrival rate 
smcache hand rely priori knowledge request arrival rate easily adapts changing request rates 
server bandwidth bursty arrivals illustrate adaptiveness smcache compare performance pareto arrivals 
contains short term channel usages smcache selective catching prefix cache function time 
results obtained simulation 
pareto arrival process bursty arrival process longrange dependence shown 
selective catching scheme optimized mean arrival rate significant residual bandwidth arrivals 
requires server know mean request rate time smcache catching fig 

smcache vs selective catching pareto arrivals mean server channel requirement prefix min body min disk min disk min request rate min fraction clients disk smcache skyscraper partitioned skyscraper unpartitioned fig 

smcache heterogeneous clients advance 
smcache residual bandwidth significant performance degradation due request rate estimation errors 
server bandwidth limited client disk illustrate versatility smcache algorithm adapting clients variable disk space 
compare performance smcache dynamic skyscraper prefix cache clients varying disk space 
clients minutes disk space rest minutes 
dynamic skyscraper algorithm needs fix minutes 
consider versions dynamic skyscraper 
non partitioned version prefix stored cache 
partitioned version addition prefix initial segments called leading segments stored cache 
obtained number server channels smcache dynamic skyscraper simulation 
add mean number proxy channels partitioned dynamic skyscraper obtained sum channels main server proxy server assuming single proxy server 
plot results function fraction clients disk store minutes video 
observe smcache easily outperforms non partitioned dynamic skyscraper adaptive clients varying storage capacity 
smcache better partitioned version 
noted partitioned version requires replication resources local regional servers involves additional storage cost smcache benefit 
instance partitioned dynamic skyscraper example requires storing minutes video proxy server 
hand smcache needs store minute proxy server shows better performance 
furthermore partitioned skyscraper smcache require multicast capability proxy servers 
smcache performance vs prefix length study impact prefix length performance smcache 
compare performance various schemes different prefix sizes 
prefix large main server requires fewer channels transmitting video clip network load cache increases 
assume prefix length minutes request rate min body min disk min smcache simulation smcache analysis dynamic skyscraper prefix gdb prefix selective catching prefix fig 

server load vs prefix size fraction cached body prefix min request rate min regional cache load main server load non partitioned smcache partitioned smcache prefix min partitioned skyscraper prefix min fig 

partitioned smcache network load main server regional cache caches transmit prefix unicast mean number channels required proxy server length prefix times arrival rate requests particular proxy 
sum mean number channels required proxies total request rate main server times prefix length 
plot mean number channels required main server function prefix size 
values smcache obtained simulation analysis observe results obtained methods agreement 
infer smcache provides better performance scheme parameters considered 
furthermore relatively small prefix lengths minute smcache shows major improvement prefixed dynamic skyscraper prefixed gdb 
example infer performance smcache far superior dynamic skyscraper available cache space small 
partitioned smcache network load server cache plot number channels required main server partitioned smcache dynamic skyscraper function fraction stored regional cache network storage costs prefix min body min request rate min partitioned dynamic skyscraper partitioned smcache replication storage costs transmission network costs total cost min cost min cost fig 

transmission replication costs prefix min body min request rate min fraction stored regional cache main server regional cache costs total cost main server cost total regional cache cost partitioned smcache partitioned dynamic skyscraper fig 

main server regional cache costs fraction video object stored cache 
dashed lines plot sum mean number channels required regional cache values correspond scale right graph 
analyzed smcache algorithm assuming fraction video clip cached regional servers prefix 
parameters chosen partitioned smcache lower regional cache load partitioned dynamic skyscraper significant deterioration load main server 
infer partitioned smcache better need cache larger fraction object 
optimal partitioning illustrates trade plot replication transmission costs function fraction video object stored cache 
fraction stored cache increases total network cost expected decrease location regional cache chosen carefully 
replication cost increases 
shown cost partitioned dynamic skyscraper partitioned smcache 
cost parameters chosen follows 
correspondingly optimal cached fraction smcache dynamic skyscraper 
min imum cost smcache better dynamic skyscraper 
represents trade total cost network storage costs incurred main server versus regional cache vary fraction video object cached 
curves find optimal partition 
simplify special cases follows 
assuming segment played maximum rate located regional cache main server optimum number segments need stored cache shown opt log opt viii 
closed loop scheme called mcache providing zero delay video demand services 
prefix cache critical efficient utilization server bandwidth schemes 
due fact prefix caching allows batching requests different clients video clip providing zero delay service 
smcache protocol generalized improved version mcache clip partitioned segments order exploit availability receiving channels client greater extent mcache 
smcache shows marked improvement mcache terms server bandwidth usage prefix ratio large clips large prefix relatively small 
furthermore smcache limits server bandwidth requirement log length body clip 
open loop schemes periodic broadcast schemes 
smcache closed loop server bandwidth usage lower periodic broadcast request rates low 
complexity smcache server algorithm grows number segments proportional 
mcache smcache adaptive mean transmission rate server altered transient request rate clip 
notable improvement catching scheme pseudo adaptive sense requires recalibration parameters request rates change 
smcache adapts varying disk space clients 
distinct advantage dynamic skyscraper scheme design depends minimum disk space available client 
addition experiments show smcache significantly better performance dynamic skyscraper prefix small relation length clip 
aggarwal wolf yu 
permutation pyramid broadcasting scheme video demand systems 
proc 
ieee international conference multimedia computing systems pages jun 
aggarwal wolf yu 
optimal batching policies video demand storage servers 
proc 
international conference multimedia systems june 
de bey 
program transmission optimization mar 
birk 
tailored transmissions efficient near video ondemand service 
proc 
ieee international conference multimedia computing systems florence italy jun 
choi kim chung 
prefetching scheme analysis user access pattern news demand system 
proc 
seventh acm international multimedia conference oct 
dan heights sitaram 
generalized interval caching policy mixed interactive long video workloads 
proc 
spie conference multimedia computing networking pages san jose ca jan 
dan sitaram 
scheduling policies ondemand video server batching 
proc 
acm multimedia conference oct 
dan sitaram 
dynamic batching policies demand video server 
multimedia systems june 

empirical model www document arrivals access link 
proc 
ieee international conference communication jun 
eager ferris vernon 
optimized regional caching demand data delivery 
proc 
multimedia computing networking mmcn san jose california jan 
eager vernon 
dynamic skyscraper broadcasts demand 
proc 
th international workshop multimedia information systems mis istanbul turkey sept 
feldmann 
modelling characteristics tcp connections 
technical report laboratories 
gao kurose towsley 
efficient schemes broadcasting popular videos 
proc 
nossdav cambridge uk jul 
gao kurose towsley 
catching selective catching efficient latency reduction techniques delivering continuous multimedia streams 
proc 
acm multimedia conference oct nov 
gao towsley 
supplying instantaneous video demand services controlled multicast 
proc 
ieee international conference multimedia computing systems florence italy jun 

liu muntz 
reducing demand video demand storage servers 
proc 
acm sigmetrics pages 
hua cai sheu 
patching multicast technique true video demand services 
proc 
acm multimedia conference bristol england sept 
hua sheu 
skyscraper broadcasting new broadcasting scheme metropolitan video demand systems 
proc 
acm sigcomm sept 


tseng 
harmonic broadcasting video demand service 
ieee transaction broadcasting sept 

paris carter long 
low bandwidth broadcasting protocol video demand 
proc 
th international conference computer communications networks pages oct 

paris carter long 
efficient protocols video demand 
proc 
th international symposium modeling analysis simulation telecommunication systems pages july 

paris long 
zero delay broadcasting protocols video demand 
proc 
th acm international multimedia conference oct nov 
ramesh rhee :10.1.1.14.7844:10.1.1.14.7844
multicast cache mcache adaptive zero delay video demand service 
technical draft department computer science north carolina state university url www csc ncsu edu rhee www export mcache ps 
sen gao rexford towsley 
optimal scheme efficient multimedia streaming 
proc 
nossdav june 
sheu hua hu 
virtual batching new scheduling technique video demand servers 
proc 
th dasfaa melbourne australia apr 
viswanathan imielinski 
metropolitan area video demand service pyramid broadcasting 
acm multimedia systems pages 
