active semi supervised learning robust multi view learning ion muslea muslea isi edu information sciences institute university southern california admiralty way marina del rey ca usa steven minton minton fetch com fetch technologies admiralty way marina del rey ca usa craig knoblock knoblock isi edu information sciences institute university southern california admiralty way marina del rey ca usa multi view problem features domain partitioned disjoint subsets views sufficient learn target concept 
semi supervised multi view algorithms reduce amount labeled data required learning rely assumptions views compatible uncorrelated example identically labeled target concepts view label example descriptions view independent 
assumptions hold practice crucial understand behavior multi view algorithms problems incompatible correlated views 
address issue studying algorithms parameterized family text classification problems control view correlation incompatibility 
show existing semi supervised algorithms robust spectrum parameterized problems 
introduce new multi view algorithm emt combines semi supervised active learning 
emt outperforms algorithms parameterized problems additional real world domains 
experiments suggest emt robustness comes active learning compensating correlation views 

multi view problem partition domain features subsets sufficient learning target concept 
instance described blum mitchell classify segments broadcast video audio formation classify web pages words appear documents hyperlinks pointing 
focus types multi view algorithms reduce amount labeled data required learning semi supervised active learning algorithms 
type bootstraps views order boost accuracy classifier learned labeled examples 
detects informative unlabeled examples asks user label 
types multi view algorithms applied variety real world domains natural language processing collins singer speech recognition de sa ballard information extraction muslea 
theoretical foundations multi view learning blum mitchell assumptions views compatible uncorrelated 
intuitively problem compatible views examples labeled identically target concepts view 
hand views uncorrelated label example descriptions view independent 
real world problems assumptions violated variety reasons correlated insufficient features 
consequently study robustness multi view algorithms respect view incompatibility correlation 
practice difficult measure factors study parameterized family text classification problems control view incompatibility correlation 
empirical investigation consider algorithms semi supervised em nigam training blum mitchell em nigam ghani emt 
semi supervised algorithms successfully applied text classification problems 
emt new multi view algorithm interleaves active semi supervised learning emt uses multi view active learning algorithm testing muslea select labeled examples multi view semi supervised em 
experiments lead important 
emt clearly outperforms algorithms incompatibility space 
results obtained parameterized problems reinforced experiments additional real world domains 
second robustness emt due active learning compensating view correlation 

issues multi view setting multi view setting blum mitchell applies learning problems natural way divide features subsets views sufficient learn target concept 
problems example described different set features view 
example domain views example seen triple descriptions views label 
blum mitchell proved problem views target concept learned labeled unlabeled examples provided views compatible uncorrelated 
condition requires examples labeled identically target concepts view 
means example independent 
proof blum mitchell argument learn weak hypothesis labeled examples apply unlabeled examples 
views uncorrelated newly labeled examples seen random training set classification noise learn target concept 
requirements views compatible uncorrelated crucial process 
views correlated training set random views incompatible target concepts views label large number examples differently 
consequently perspective may examples learning target concept impossible 
introduce intuition view incompatibility correlation consider courses problem blum mitchell web pages classified course homepages pages views consist words hyperlinks pointing pages words web pages respectively 
updated version blum mitchell shows theoretical guarantees hold partially incompatible views provided uncorrelated 
practice ignore view incompatibility rarely encounters real world problems uncorrelated views 
view words hyperlinks related theory classes core theory classes algorithms cs related ai classes statistical models neural nets publications theory clump ai clump view words web pages cmu cs finite automata 
cmu cs intro algorithms 
uci cs theory algorithms 
usc cs artificial intelligence 
usc cs statistical learning 
usc cs neural networks 
mit cs intro neural nets 
doe papers neural networks 

illustrative clumps courses domain 
shows illustrative examples courses problem 
lines represents example depict example line connects descriptions views 
bottom examples lines course homepages consequently keep simple show examples labels 
note page may referred hyperlinks hyperlinks contain text may point different pages 
real world problems views partially incompatible variety reasons corrupted features insufficient attributes instance shown hyperlinks contain text neural nets point homepages neural nets classes third points publications page 
web pages different labels description 
consequently neural nets mit cs neural nets doe 
incompatible require neural nets simultaneously different labels 
practice views partially correlated domain best introduced example 
consider instance multi view examples ai homepages depicted lines ai clump rectangle 
call group examples clump bi partite subgraph vertices hyperlinks web pages respectively heavily connected edges representing examples 
note clumps class sufficient violate uncorrelated views assumption example highly descriptions views come clump 
intuitively means encounter examples cs uci cs theory algorithms connects theory ai clumps see 
learning problem views learning algorithm labeled unlabeled examples number iterations performed training loop iterations create classifiers class unlabeled examples confident predictions remove label respectively add combine prediction semi supervised em classifier obtained training loop iterations em classifier obtained training loop iterations combine prediction 
training semi supervised em em 

semi supervised algorithms section provide high level description semi supervised algorithms comparison training semi supervised em em 
training training blum mitchell semi supervised multi view algorithm uses initial training set learn weak classifier view 
classifier applied unlabeled examples training detects examples classifier confident predictions 
high confidence examples labeled estimated class labels added training set see 
new training set new classifier learned view process repeated iterations 
final hypothesis created voting scheme combines prediction classifiers learned view 
semi supervised em semi supervised em nigam ghani algorithm baseline 
shown applies probabilistic learning algorithm small set labeled examples large set unlabeled ones 
semi supervised em creates initial classifier solely labeled examples 
repeatedly performs step procedure probabilistically label unlabeled examples learn new maximum posteriori map hypothesis examples labeled previous step 
intuitively em tries find hypothesis generate distribution unlabeled data 
semi supervised em seen clustering unlabeled data examples original training set 
em em nigam ghani semi supervised multi view algorithm uses hypothesis learned view probabilistically label examples see 
intuitively em runs em view new em iteration inter changes probabilistic labels generated view 
em seen probabilistic version training 
fact algorithms underlying idea knowledge acquired view probable labels examples train view 
major difference algorithms em commit label unlabeled examples uses probabilistic labels may change iteration 
contrast training commitment high confidence predictions may add training set large number mislabeled examples especially iterations hypotheses may little prediction power 
empirical comparison section motivate need new robust multi view algorithm showing existing algorithms uneven performance different regions correlation incompatibility space 
purpose compare em training em parameterized family problems control level clumps class incompatibility examples incompatible 
keep presentation succinct information critical making case 
experimental framework complete results detail section parameterized family problems discussed 
nigam ghani em training contrasted iterative incremental respectively 
description equivalent em iteratively uses unlabeled data commit labels previous iteration 
contrast training incrementally uses unlabeled data committing labels iteration 
error rate training em em clump class incompatible examples error rate training em em clumps class incompatible examples 
comparison semi supervised algorithms 
show performance em training em regions correlation incompatibility space 
graph left algorithms compared problems uncorrelated views clump class highly compatible examples incompatible 
second graph algorithms applied problems highly incompatible views examples incompatible clumps class 
axis shows percentage incompatible examples problems represents error rates 
results show algorithms sensitive view incompatibility correlation 
example em training outperform em problems highly compatible uncorrelated views 
contrast views correlated incompatible multi view algorithms em em doing clearly worse training 
section introduce new algorithm emt robust behavior entire spectrum problems 

testing em emt testing muslea family multi view active learning algorithms start labeled examples pool unlabeled ones 
testing searches informative examples unlabeled pool asks user label 
shown testing repeatedly trains hypothesis view queries unlabeled examples hypotheses predict different labels called contention points 
intuitively compatible views disagree label wrong 
consequently asking user label contention point testing provides useful information view mislabeled 
emt novel algorithm interleaves em testing see 
opposed typical testing algorithm learns solely labeled examples emt induces hypotheses running em labeled unlabeled examples 
chosen combine testing em training difficulties encountered fine tuning sensitive changes number examples added iteration 
learning problem views learning algorithm labeled unlabeled examples number queries testing repeat times create classifiers select query ask user label move newly labeled contention point combine prediction emt number em iterations emt repeat times em learn select query ask user label move newly labeled contention point combine prediction 
testing emt algorithms 
testing multi view active learning training em multi view learning probabilistic learning emt em probabilistic multiview learning probabilistic multi view active learning 
lineage emt algorithm 
current implementation emt uses straightforward query selection strategy asks user label contention point combined prediction confident queries unlabeled examples equally strong confidence predicting different label 
order put emt larger context show relationship algorithms considered study 
side emt semi supervised variant testing turn inspired training 
side emt builds em state art semi supervised algorithm combines basic ideas training em 
note interleaving em testing leads interesting synergy 
hand testing boosts accuracy em selecting highly informative set labeled examples stand em chooses random 
hand hypotheses learned em accurate ones learned just labeled data compared stand testing emt uses accurate hypotheses select queries 
error rate clumps class clumps class clumps class labeled examples 
illustrative learning curves emt tasks incompatibility clumps class 

empirical results experimental setup empirical investigation apply em training em testing emt family problems control view incompatibility 
created problems clumps class 
level generated problems incompatible examples 
points incompatibility space created text classification problems total problems see appendix details 
accuracy algorithms estimated runs fold cross validation consequently training test set consist examples respectively 
semi supervised algorithms training examples split randomly groups labeled examples remaining unlabeled hide labels 
keep comparison fair emt testing start randomly chosen labeled examples query unlabeled ones total labeled examples see illustrative learning curves 
naive bayes underlying algorithm 
em training em naive bayes implemented versions described nigam ghani 
em em run iterations respectively 
training require significant fine tuning labels examples iterations 
avoid prohibitive running time emt perform em iterations testing query problems emt runs em queries runs folds queries fold 
point incompatibility space reported error rate averaged text classification problems 
shows performance emt testing em training em parameterized family problems 
graphs correspond levels views incompatibility 
graph show number clumps class error rate respectively 
emt obtains lowest error rates points correlation incompatibility space 
pairwise comparison testing training em em results statistically significant confidence points 
remaining points represent extreme situations occur practice training em conditional independent views clump class em highly correlated incompatible views clumps class incompatibility 
discussion empirical results deserve comments 
emt combines testing em clearly outperforms components 
intuitively emt power comes testing em compensating weaknesses 
hand exploiting unlabeled data em boosts accuracy classifiers learned testing 
hand testing improves em accuracy providing highly informative set labeled examples 
emt algorithm combines semisupervised active learning mccallum nigam various combinations semi supervised em query committee qbc shown outperform em qbc 
expect active learning algorithms select labeled examples em training em improve accuracy 
finding best combination active semi supervised learning scope 
main contribution show interleaving active semisupervised learning leads robust performance entire spectrum problems 
second em training highly sensitive domain 
problems uncorrelated views clump class em training clearly outperform em 
fact em accurate emt barely outperform 
behavior consistent theoretical argument blum mitchell best em qbc combinations appropriate multi view problems uses sophisticated heuristic estimates density various regions single view instance space density multi view instance space function local densities view 
implemented single view algorithm mccallum nigam similarly testing interleaves qbc em 
algorithm barely improved em accuracy parameterized problems decided show corresponding learning curves crowded 
error rate error rate incompatibility clumps class incompatibility clumps class uncorrelated views presence view incompatibility concept learned labeled unlabeled examples 
contrast problems clumps class em clearly outperforms em training 
multi view algorithms perform poorly domains disseminated entire instance space information exchanged views remains localized clump 
fact emt insensitive suggests testing compensates domain 
third performance algorithms degrades views compatible 
multi view algorithms sensitive view incompatibility information exchanged views misleading examples labeled differently views 
cope problem companion muslea introduce view validation technique detects views sufficiently compatible multi view learning 
note glance emt perform poorly problems highly incompatible views domains looks emt query incompatible examples convey little information misleading em 
understand emt avoids making queries reconsider situation section hyperlinks containing text neural nets fragments text artificial neu remember emt simply em labeled examples chosen testing queries 
error rate error rate incompatibility clumps class incompatibility clumps class 
results parameterized family problems 
error rate incompatibility clumps class emt test em train ral nets artificial neural networks point web pages having different labels 
ambiguity examples hypotheses learned hyperlink view low confidence predicting labels 
emt queries contention points views equally confident predictions follows incompatible example queried view equally low confidence prediction 
summary expect emt perform domains 
areas correlation incompatibility space clearly outperform algorithms uncorrelated views clump class correlated incompatible views clumps class incompatibility 
barely outperforms em problems occur practice 
barely outperforms em may expect em outperform emt higher incompatibility levels 
cope problem view validation muslea predict views sufficiently compatible learning 
results real world problems order strengthen results obtained parameterized family problems additional experiment real world domains courses blum mitchell ads kushmerick 
courses examples classify web pages course homepages 
views consist words appear pages hyperlinks pointing respectively 
ads examples classify images appear web pages ads non ads 
view describes em algorithm courses ads emt testing em em training table 
error rates real world problems 
image words image url view characterizes related pages words urls pages contain image pointed image 
domains perform runs fold cross validation 
courses em training em labeled examples emt testing start labeled examples queries 
ads semi supervised algorithms labeled examples emt testing start labeled examples queries 
em em training run iterations respectively training adds examples iteration 
emt perform em iterations testing query 
table shows emt obtains best accuracy algorithms 
comparison em courses results statistically significant confidence 

family parameterized problems analyze influence view correlation incompatibility performance multi view algorithms 
shown existing algorithms robust incompatibility space 
cope problem introduced new multi view algorithm emt interleaves active semi supervised learning 
shown emt clearly outperforms algorithms parameterized problems real world domains 
experiments suggest robustness emt comes active learning compensating view correlation 
plan continue main directions 
intend study combinations testing semi supervised algorithms semi artificial real world domains 
particular plan multiple mixture components nigam model cope domain automatically generate component clump class 
second intend view detection problem features ads boolean presence absence word document naive bayes multi variate bernoulli model mccallum nigam 
tries detect existence multiple views domain 
plan generate candidate views features partitions view validation muslea predict views appropriate multi view learning 
blum mitchell 

combining labeled unlabeled data training 
proc 
conference computational learning theory pp 

collins singer 

unsupervised models named entity classification 
proc 
empirical nlp large corpora conference pp 

de sa ballard 

category learning multi modality 
neural computation 
joachims 

probabilistic analysis rocchio algorithm tfidf text categorization 
computer science tech 
report cmu cs 
kushmerick 

learning remove internet 
proc 
auton 
agents pp 

mccallum nigam 

comparison event models naive bayes text classification 
aaai workshop learning text categorization 
mccallum nigam 

employing em pool active learning text classification 
proc 
intl 
conference machine learning pp 

muslea minton knoblock 

selective sampling redundant views 
proc 
national conference artificial intelligence pp 

muslea minton knoblock 

adaptive view validation case study wrapper induction 
appear proc 
icml 
nigam ghani 

analyzing effectiveness applicability training 
proc 
information knowledge management pp 

nigam mccallum thrun mitchell 

text classification labeled unlabeled documents em 
machine learning 
semi artificial problems create parameterized set problems control view correlation incompatibility generalize idea nigam ghani 
create semi artificial domain compatible uncorrelated views unrelated binary classification problems considering problem individual view 
view view view view clump class clumps class 
generating clumps class 
multi view examples created randomly pairing examples label original problems 
procedure easily modified introduce clumps incompatible examples 
instance consider creating binary classification problem positive examples consist clumps 
unrelated problems sets positive examples andd respectively 
newly created view problem positive examples views consist respectively 
shown left graph multi view examples created randomly pairing example obtain uncorrelated views 
contrast allow examples paired ones ones ones obtain problem clumps positive examples 
similarly unrelated problems create clumps class respectively 
adding incompatible examples straightforward task randomly pick positive negative multiview example say intro ai ai class doe homepage 
replace examples recombinations positive example intro ai homepage negative example doe ai class 
note labels new examples correct view hyperlink words incorrect words page 
context level say incompatibility means examples training test set assigned label correct views 
similarly emt queries incompatible example provide label correct views 
order generate problems clumps class newsgroups postings mini newsgroups dataset subset known newsgroups domain joachims 
newsgroup consists articles randomly chosen postings included original dataset 
divided newsgroups groups see table 
examples group www cs cmu edu afs cs project theo www naive bayes mini newsgroups tar gz comp os ms win misc comp windows pos comp sys ibm pc comp sys mac rec autos rec motorcycles rec sport baseball rec sport hockey sci crypt sci electronics neg sci space sci med talk politics guns talk politics mideast talk politics misc talk religion misc table 
newsgroups included domain 
positive negative examples views newsgroups comp os ms win comp sys ibm comp windows comp sys mac play roles examples 
creating compatible views levels clumps class 
clump class positive example paired positive example 
clumps class allow pairing comp examples view rec examples 
clumps class pair examples os ms win windows comp sys ibm sys mac level consider levels view incompatibility examples incompatible respectively 
corresponds total points incompatibility space mentioned point generate random problems total problems problem consists examples 
acknowledgments authors grateful daniel marcu kevin knight yolanda gil useful comments 
research reported supported part defense advanced research projects agency darpa air force research laboratory contract agreement numbers part air force office scientific research number part national science foundation award number dmi part integrated media systems center national science foundation engineering research center cooperative agreement number eec 
government authorized reproduce distribute reports governmental purposes notwithstanding copy right annotation thereon 
views contained authors interpreted necessarily representing official policies endorsements expressed implied organizations person connected 
documents tokenized usenet headers discarded words stoplist removed stemming performed words appear single document removed 
resulting views features words respectively 
