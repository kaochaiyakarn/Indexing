model face face grounding nakano tom justine cassell mit media laboratory ames street cambridge ma usa justine media mit edu investigate verbal nonverbal means grounding propose design embodied conversational agents relies kinds signals establish common ground human computer interaction 
analyzed eye gaze head nods attentional focus context direction giving task 
distribution nonverbal behaviors differed depending type dialogue move grounded pattern reflected monitoring lack negative feedback 
results eca uses verbal nonverbal grounding acts update dialogue state 
essential part conversation ensure participants share understanding said meant 
process ensuring understanding adding said common ground called grounding 
face face interaction nonverbal signals verbal participate grounding process indicate utterance grounded needed ground 
shows example human face face conversation 
verbal feedback provided speaker continues add directions 
listener gives explicit nonverbal feedback nods gaze clearly monitoring listener behavior see fact looks twice continuous lines words 
fact analyses show maintaining focus attention task dash dot lines underneath words listener public signal research institute science technology society ku tokyo japan nakano kc tokyo ac jp speaker behavior look map gaze listener go fourth floor listener behavior gaze listener hang left look map look map look map hang left 
look map human face face conversation understanding utterance sufficiently task hand 
manifestly attending signal signal allows jointly recognize contribution grounded 
provides empirical support essential role nonverbal behaviors grounding motivating architecture embodied conversational agent establish common ground eye gaze head nods attentional focus 
grounding received significant attention literature previous addressed questions predictive factors account people nonverbal signals ground information model face face grounding process adapt dialogue management face face conversation embodied conversational agent 
addresses issues goal contributing literature discourse phenomena building advanced conversational humanoids engage human conversational protocols 
section discuss relevant previous report results empirical study analysis conversational data propose model grounding verbal nonverbal information implementation model embodied conversational agent 
preliminary evaluation compare user interacting embodied conversational agent grounding 
related conversation seen collaborative activity accomplish information sharing pursue joint goals tasks 
view agreeing said meant crucial conversation 
part said interlocutors understand mutually shared called common ground process establishing parts conversation shared called grounding 
point participants conversation attempt minimize effort expended grounding 
interlocutors convey information disposal takes effort produce incomplete utterance repaired needs 
proposed computational approach grounding status contributions provisional shared part dialogue system representation information state conversation 
conversational actions trigger updates register provisional information shared 
actions achieve grounding 
acknowledgment acts directly associated grounding updates utterances effect grounding updates indirectly proceed task way presupposes prior utterances uncontroversial 
hand suggest actions conversation give probabilistic evidence understanding represented par uncertainties dialogue system speech recognizer unreliability 
dialogue manager assumes content grounded long judges risk misunderstanding acceptable 
mention eye gaze basic form positive evidence addressee attending speaker head nods similar function verbal 
suggest nonverbal behaviors mainly contribute lower levels grounding signify interlocutors access communicative actions attending 
similar goal broadening notion communicative action spoken word examine kinds multimodal grounding behaviors posting information whiteboard 
researchers suggested nonverbal behaviors undoubtedly play role grounding previous literature characterize precise role respect dialogue state 
hand number studies particular nonverbal behaviors exist 
early study reported conversation involves eye gaze time 
speakers look grammatical pauses feedback utterances received look task 
listeners look speakers follow direction gaze 
fact claimed speakers pause restart obtain listener gaze 
conversational difficulties mutual gaze held longer turn boundaries 
previous embodied conversational agents demonstrated possible implement face face conversational protocols human computer interaction correct relationships verbal nonverbal signals enhances naturalness effectiveness embodied dialogue systems 
reported users felt agent helpful lifelike smooth interaction style demonstrated nonverbal conversational behaviors 
empirical study order get empirical basis modeling face face grounding implementing eca analyzed conversational data conditions 
experiment design previous direction giving tasks students different universities gave directions campus locations 
pair conversation face face condition subjects sat map drawn direction giver sitting shared condition sr shaped screen subjects share map drawn direction giver see face body 
interactions subjects different angles combined video mixer synchronized video clips 
data coding experiment sessions resulted dialogues condition total transcribed follows 
coding verbal behaviors grounding occurs turn consists consecutive combinations speaker behavior listener behavior gp gm ge gp gp gp gp gm gp gp ge gm gm gp gm gm gm gm ge gp gm ge ge ge gp ge gm ge ge ge table nv statuses shift uu pause gm gm gm answer gp gp gm gm info req gp gm gp gp assertion gp gm gm gm table salient transitions utterances speaker tokenized turn utterance units uu corresponding single intonational phrase 
uu categorized coding scheme 
statistical analysis concentrated categories regular occurrence data answer information request info req assertion 
coding nonverbal behaviors previous studies types behaviors coded gaze partner gp looking partner eyes eye region face 
gaze map gm looking map gaze ge looking away head nod nod head moves single continuous movement vertical axis eyes go horizontal axis 
combining gaze nod complex categories ex 
gp nod gp nod generated 
follows analyze categories instances 
order analyze dyadic behavior combinations nonverbal behaviors defined shown table 
gp gm stands combination speaker gaze partner listener gaze map 
results examine differences sr conditions correlate verbal nonverbal behaviors conditions look correlations speaker listener behavior 
basic statistics analyzed corpus consists sr mean length conversations minutes sr minutes tail 
mean length utterances words uu significantly longer sr words uu 
nonverbal behaviors number shifts statuses table compared 
nv status shifts gp gp gm gm counted shift 
nv status shifts shifts sr number nv status shifts sr half tail 
results indicate visual access interlocutor body affects conversation suggesting nonverbal behaviors communicative signals 
sr mean length uu shorter speakers information smaller chunks leading chunks slightly longer conversation 
hand conversational participants convey information uu 
correlation verbal nonverbal behaviors analyzed nv status shifts respect type verbal communicative action experimental condition sr 
look continuity nv status analyzed amount time spent nv status 
gaze transition time spent gave similar results head nods brief discuss data terms transitions 
table shows frequent target nv status shift statuses speech act type 
numbers parentheses indicates proportion total number transitions 
uu dyad nv status frequently shifts gm 
speaker utters ok nodding listener looks map 
pauses shift frequent 
results sr listener see speaker nod 
findings suggest accompanied head nod behavior may function 
answer frequent shift uu gp gp 
suggests speakers listeners rely mutual gaze gp gp ensure answer grounded strategy sr addition speakers frequently look away answer plan reply 
info req frequent shift uu gp gm pauses shift gp gp frequent 
suggests speakers obtain mutual gaze asking question ensure question clear turn transferred listener reply 
sr rarely nv status shift participants continue looking map 
assertion conditions listeners look map time nod 
speakers nonverbal behavior different conditions 
sr speakers look map 
contrast frequently look listener shift gp gm frequent uu 
suggests speakers check listener paying attention referent mentioned assertion 
implies listener gazing speaker paying attention referent works positive evidence understanding 
summary known eye gaze signal turn request account results 
gaze direction changes usage nonverbal behaviors differs depending type conversational action 
note subjects rarely demonstrated communication failures implying nonverbal behaviors represent positive evidence grounding 
correlation speaker listener behavior far demonstrated difference distribution nonverbal behaviors respect conversational action visibility interlocutor 
uncover function nonverbal signals examine listener nonverbal behavior affects speaker action 
looked consecutive assertion direction giver analyzed relationship nv status uu direction giving strategy second uu 
giver second uu classified go ahead gives leg directions elaboration gives additional information uu example ll go little corridor 
long 
gaze map elaboration go ahead relationship receiver nv giver verbal behavior results shown 
listener begins gaze speaker uu maintains gaze pause uu speaker uu elaboration previous uu time 
hand listener keeps looking map uu uu elaboration 
listener keeps looking speaker speaker uu go ahead time 
contrast listener keeps looking map speaker uu go ahead time results suggest speakers interpret listeners continuous gaze evidence understanding add information previous uu 
similar findings reported map task suggested times communicative difficulty interlocutors utilize channels available 
terms floor management gazing partner signal giving turn indicates listeners trying elicit information speaker 
addition listeners continuous attention map interpreted evidence understanding speakers go ahead leg direction model face face grounding analyzing spoken dialogues reported grounding behavior occur percentage map sum cue phrases tag questions part leg direction convey content 
analyzed consecutive answer giver listener looks speaker pause speaker elaborates answer time 
listener looks speaker uu map uu positive evidence speaker elaborates time 
intonational boundary identify 
implies multiple grounding behaviors occur turn consists multiple 
previous models information grounded listener returns verbal feedback marks smallest scope grounding 
apply model example uu grounded listener returned spoken grounding clues 
contrast results suggest considering role nonverbal behavior especially eye gaze allows fine grained model grounding employing uu unit grounding 
results suggest speakers actively monitoring positive evidence understanding absence negative evidence understanding signs miscommunication 
listeners continue gaze task speakers continue leg directions 
incremental nature grounding implement nonverbal grounding functionality embodied conversational agent process model describes steps system judge user understands system contribution preparing uu speech act type uu nonverbal positive negative evidence agent expects receive specified 
monitoring monitors checks user nonverbal status signals uu 
speaking agent continues monitoring gets evidence understanding understanding represented user nonverbal status signals judging agent gets evidence tries judge groundedness soon possible 
previous studies length pause sec 
time judgment sec uu 
agent evidence uu remains ungrounded 
model information state approach update rules revise state conversation inputs system receives 
case inputs sampled continuously include nonverbal state require updates 
inputs indicate utterance pending allow agent wait 
particular task attention interval utterance triggers grounding 
gaze interval means contribution stays provisional triggers obligation elaborate 
likewise system times recognizing user feedback segment remains ungrounded 
process allows system keep talking multiple utterance units getting verbal feedback user 
user perspective explicit necessary minimal cost involved eliciting elaboration 
face face grounding empirical results propose dialogue manager handle nonverbal input grounding process implement mechanism embodied conversational agent 
system mack interactive public information eca kiosk 
current knowledgebase concerns activities mit media lab answer questions lab research groups projects demos give directions 
input side mack recognizes modalities speech ibm pen gesture map atop table embedded wacom tablet head nod eye gaze stereo camera degree head pose tracker 
inputs operate parallel threads allowing understanding module um interpret multiple modalities individually combination 
mack produces multimodal output speech synthesis microsoft whistler text speech tts api graphical synchronized hand arm gestures head eye movements lcd projector highlighting map allowing mack 
system architecture shown 
um interprets input modalities converts dialogue moves passes dialogue manager dm 
dm consists primary sub modules response planner determines mack action creates sequence utterance units grounding module grm updates discourse model decides response planner uu passed generation module gm 
gm converts uu speech gesture projector output sending mack system architecture synchronized modalities tts engine animation module am projector module 
discourse model maintains information state history discourse 
includes list grounded beliefs ungrounded history previous timing information history nonverbal information divided gaze states head nods organized timestamp information state dialogue current uu consideration started ended 
nonverbal inputs eye gaze head nod inputs recognized head tracker calculates rotations translations dimensions visual depth information taken cameras 
calculated head pose translated look mack look map look rotation head translated head nods modified version 
head nod eye gaze events timestamped logged nonverbal component discourse history 
grounding module look appropriate nonverbal information judge uu 
dialogue manager kiosk eca system needs ensure user understands information provided agent 
reason concentrated implementing grounding mechanism assertion agent gives user directions agent answers user questions generating response job dm plan response user query 
user asks directions dm receives event um stating intention 
response planner dm recognizing user direction request calculates directions broken segments 
seg ments added dm agenda stack processed 
point grm sends uu direction segment agenda gm processed 
gm converts uu speech animation commands 
mack nonverbal grounding acts gm determines mack gaze behavior type uu 
example mack generates direction segment assertion time keeps looking map 
elaborating previous uu time gazes user 
gm begins process uu logs start time discourse model finishes processing sends final command animation module logs time 
grm waits speech animation polling discourse model time available point retrieves timing data uu form timestamps uu start finish 
timing data look nonverbal behavior occurring utterance order judge uu grounded 
judgment grounding mack finishes uttering uu grounding module judges uu grounded user verbal nonverbal behaviors uu 
verbal evidence user returns ok grm judges uu grounded 
user explicitly reports failure perceiving mack speech ex 
understanding ex 
don understand uu remains ungrounded 
note moment verbal evidence considered stronger nonverbal evidence 
nonverbal evidence grm looks nonverbal behavior occurring utterance compares model shown table 
type speech act model specifies nonverbal behaviors signal positive explicit negative evidence 
grm compares uu nonverbal behavior model 
looks nonverbal behavior occurring pause uu 
behaviors pause match pattern signals positive evidence uu grounded 
match pattern negative evidence uu grounded 
pattern target uu type assertion answer evidence type positive negative positive nv pattern map pause map nod gaze pause gaze gaze pause map judgment ground grounded ungrounded grounded negative pause gaze ungrounded table grounding model mack suggested action go ahead elaboration go ahead elaboration go ahead elaboration go ahead elaboration matched grm waits tenth second checks 
required behavior occurred time uu judged 
grm continues looping manner uu grounded ungrounded explicitly second threshold reached 
threshold reached decision grm times judges uu ungrounded 
updating dialogue state judging grounding grm updates discourse model 
discourse state maintained discourse model similar kit store nonverbal information 
key fields list grounded list pending ungrounded current uu 
current uu judged grounded belief added 
ungrounded uu stored 
uu subsequent contributions elaboration stored single discourse unit grounded uu grounded 
determining action judging uu grounding grm decides mack 
mack continue giving directions normal sending segment agenda gm 
shown table happens time uu grounded time grounded 
note happens time verbal uh huh received uu 
mack elaborate stage directions 
elaborations generated time assertion judged ungrounded time ungrounded answer 
mack elaborates describing landmark detail 
example directions go hall right door elaborate saying big blue door case grm asks response planner rp provide elaboration current uu rp generates elaboration looking landmark database adds front agenda grm sends new uu gm 
user gives mack explicit verbal understanding mack simply repeat thing said sending uu back gm 
example shows example user interaction mack 
user asks mack directions mack replies speech pointing projector shared map 
grm sends segment agenda gm starting time uu noted sent am spoken animated 
time user nonverbal get room 
get room go door right 
look map walk hall left door look map gaze mack glass door red right outside 
look map nod room 
look map example user interacting mack 
user gives negative evidence grounding mack elaborates 
signals logged discourse model 
uu finished grm evaluates log uu pause waiting tenth second checking nonverbal history 
case mack noted user looked map uu continued just 
pattern matches model assertion 
uu judged grounded grounded belief added discourse model 
mack utters second segment time grm finds user looking mack uu signals uu grounded 
rp generates elaboration line 
utterance judged mack user grounded user continues looking map user nods final stage directions spoken 
grounded leaving mack ready new inquiry 
preliminary evaluation shown empirical basis implementation important ensure human users interact mack expect interaction effective nonverbal grounding 
issue effectiveness merits full scale study chosen concentrate mack elicits behaviors users interaction humans 
subjects assigned conditions run wizard oz speech recognition carried experimenter mack grounding mack recognized user nonverbal signals grounding displayed nonverbal signals speaker 
mack grounding mack paid attention user nonverbal behavior display nonverbal signals speaker 
gave directions single turn 
subjects instructed ask directions places told lead experimenters locations test comprehension 
analyzed second direction giving interaction subjects accustomed system 
results condition users return verbal feedback mack direction giving 
shown table mack grounding nonverbal status transitions observed direction giving consisted assertion elaboration 
transition patterns mack user shift grounding grounding num gpgp total table preliminary evaluation mack nonverbal grounding strikingly similar empirical study human communication 
transitions gm gm look map normal status map task conversation transitions gp gm mack looks user user looks map frequent transition assertion reported section 
mack third uu user began looking mack middle uu kept looking uu ended 
behavior successfully elicited mack elaboration uu 
hand mack condition user looked mack early 
shown table transitions observed shift interaction shift back 
larger scale evaluation quantitative data important issues results preliminary study strongly support model show mack potential interacting human user human human conversational protocols 
discussion reported people nonverbal signals process grounding 
nonverbal signals recognized positive evidence understanding different depending type speech act 
maintaining gaze speaker interpreted evidence understanding evoking additional explanation speaker 
empirical results proposed model nonverbal grounding implemented embodied conversational agent 
important directions establish comprehensive model face grounding 
study focused eye gaze head nods directly contribute grounding 
important analyze types nonverbal behaviors investigate interact eye gaze head nods achieve common ground contradictions verbal nonverbal evidence 
interlocutor says ok looks partner 
implementation proposed simple clear sophisticated dialogue management strategy warranted allow deal back grounding aspects miscommunication 
example useful distinguish different levels miscommunication sound may may speech grammar utterance utterance meaning ambiguous 
order deal uncertainty grounding incorporating probabilistic approach model face face grounding elegant possibility 
candy sidner matthew stone anonymous reviewers comments improved 
prof univ tokyo support research 
clark schaefer contributing discourse 
cognitive science 

clark wilkes gibbs referring collaborative process 
cognition 

matheson poesio traum 
modelling grounding discourse obligations update rules 
st annual meeting north american association computational linguistics naacl 

paek horvitz uncertainty utility misunderstanding working papers aaai fall symposium psychological models communication collaborative systems brennan traum editors 
aaai menlo park california 

clark language 
cambridge cambridge university press 
traum dillenbourg 
miscommunication multimodal collaboration 
aaai workshop detecting repairing preventing human machine miscommunication 

portland 
argyle cook gaze mutual gaze 
cambridge cambridge university press 
goodwin achieving mutual orientation turn conversational organization interaction speakers hearers 
academic press new york 

hansen ward 
coordinating turn gaze 
icslp 

philadelphia pa cassell just pretty face affordances embodiment 
iui 

new orleans louisiana 
traum rickel 
embodied agents multiparty dialogue immersive virtual worlds 
autonomous agents multi agent systems 

cassell power nod glance envelope vs emotional feedback animated conversational agents 
applied artificial intelligence 

nakatani traum coding discourse structure dialogue version 
university maryland 
pierrehumbert phonology phonetics english intonation 
massachusetts institute technology 
allen core draft dialogue act markup layers 
www cs rochester edu research resources da msl html 
duncan structure speaker auditor interaction speaking turns 
language society 

boyle anderson effects visibility cooperative problem solving task 
language speech 

traum heeman 
utterance units grounding spoken dialogue 
icslp 

nakajima allen 
prosody cue discourse structure 
icslp 

darrell 
view appearance model dof tracking proceed ings 
ieee conference computer vision pattern recognition 

madison wisconsin 
kapoor picard 
real time head nod shake detector 
workshop perceptive user interfaces 

orlando fl 
